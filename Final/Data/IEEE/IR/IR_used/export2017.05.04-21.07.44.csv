"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4665153,4665144,4666086,4665159,4666385,4666138,4665213,4666360,4666608,4666372,4666425,4666146,4666207,4666370,4666458,4666428,4666161,4666419,4666567,4666076,4665136,4666388,4666143,4665163,4665149,4666384,4666469,4666294,4666404,4665137,4666374,4666589,4665217,4666139,4666364,4666557,4665166,4665147,4666169,4666382,4666111,4665155,4665139,4664960,4663367,4663042,4664324,4664804,4664318,4664322,4664155,4664699,4664394,4662851,4663003,4664774,4664409,4663800,4664704,4663029,4664803,4662534,4664148,4664756,4663044,4664785,4662960,4662598,4662988,4662990,4653057,4664362,4664321,4664243,4664730,4664360,4664677,4664755,4662777,4659326,4659445,4657323,4660079,4659271,4660132,4659910,4656636,4658575,4656634,4656741,4658687,4656395,4658051,4658172,4657872,4656423,4657768,4654117,4654630,4655123",2017/05/04 21:07:44
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Research and Implementation of Intelligent Question Answering System in a Restricted Domain","Y. Wang; G. Gao","Coll. of Comput. Sci., Inner Mongolia Univ., Hohhot","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","6","In the age of Internet, with the online information explosive growth, people want to find information we need in the cyberworld fleetly and exactly. The information retrieval method based on the keyword or the simple logic-combination of the keywords has been unable to meet the people's need of information getting to a certain extent. Gradually intelligent question answering system has grown to satisfy the people's need. This paper revolves around design and implementation of intelligent question answering system in a restricted domain, does a series of research aiming at the construction of domain knowledge, questions' comprehension and analysis, FAQ question matching, and so on. The FAQ question match is implemented by sentence similarity computation, and this model can answer frequently-asked question fast and concisely. Besides the system constructs theme document library taking advantage of web pages which Web crawler fetches. For the question which can not be answered by FAQ, the system will find answers from the theme document library. That is supplement and perfection of question answering system.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663042","","Computer science;Educational institutions;Electronic mail;Explosives;HTML;Information retrieval;Intelligent systems;Internet;Libraries;XML","Internet;formal logic;information retrieval;knowledge based systems","Internet;Web crawler;Web pages;cyberworld;document library;domain knowledge;information retrieval;intelligent question answering system;logic combination;online information;question matching","","0","","5","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Web service discovery based on keyword clustering and ontology","Jianming Zhou; Tianlei Zhang; Hui Meng; Liping Xiao; Guisheng Chen; Deyi Li","PLA Communication Command Academy.WuHan.430010, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","844","848","One of the challenging problem that Web service technology is now facing is effective service discovery. To solve the deficiencies of Web service description, matching and choosing under WSDL language, this paper presents a web service discovery method based on keyword clustering and concept expansion, mainly from the content of Web service, reasoning of service request and service matching, through classification and subsumption of concept, this paper retrieve and extract Web service content. Meanwhile, use weighted bipartite graph to match user request and published Web service, so as to enhance Web service discovery ability.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664699","","Automation;Bipartite graph;Content based retrieval;Filters;Humans;Information retrieval;Ontologies;Programmable logic arrays;Systems engineering and theory;Web services","Web services;graph theory;information retrieval;ontologies (artificial intelligence);pattern clustering","WSDL language;Web service content extraction;Web service content retrieval;Web service discovery;Web service technology;concept expansion;keyword clustering;ontology;service matching;service request;weighted bipartite graph","","0","","6","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"A New Method of Evolution Event Tracking Based on Variable Query","C. Zhao; Q. Peng; C. Li; Q. Zhang; S. Sun","State Key Lab. for Manuf. Syst. Eng., Xi'an Jiaotong Univ., Xian","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","440","444","As a feature co-occurrence approach, the traditional event tracking technique encounters a dilemma when setting the tracking similarity threshold that can diminish its tracking effectiveness. In this paper we present a new event tracking method-variable query, which can automatically adjust query terms and its corresponding weights according to the event evolution stages and tracking similarity, and solve the dilemma well. Experiment shows that the method of variable query can improve the precision and decrease the false rate of tracking.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666425","","Data mining;Event detection;Fuzzy systems;Information retrieval;Internet;Knowledge engineering;Laboratories;Manufacturing systems;Sun;Systems engineering and theory","query processing","evolution event tracking;feature co-occurrence approach;variable query","","0","","9","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Unifying study on human and web problem solving: A brain informatics perspective","Ning Zhong","Maebashi Institute of Technology, Japan","2008 IEEE International Conference on Granular Computing","20081031","2008","","","25","26","Problem-solving is one of the most important capabilities of human intelligence and has been studied in cognitive science and AI, where it is addressed in conjunction with reasoning centric cognitive functions such as attention, control, heuristic search, reasoning, learning, and so on, using a logic based symbolic and/or connectionist approach. Logic based problem-solving may be viewed as theoretic models that are mathematical systems with no real time and memory constraints. Web-based problem- solving systems need real-time response and deal with global, multiple, ation sources. In order to develop a Web based problem-solving system with human-level capabilities, we need to better understand how human being does complex adaptive, distributed problem-solving and reasoning, as well as how intelligence evolves for individuals and societies, over time and place. Ignoring what goes on in human brain and focusing instead on behavior has been a large impediment to understanding complex human adaptive, distributed problem-solving and reasoning. Granular Computing can be viewed as a novel approach in computational intelligence focusing on simulating human thinking and problem solving at multiple levels of granularity. It results in a powerful viewpoint of understanding human thinking and problem solving in depth, which is perhaps more important than any of its specific and concrete methods. Furthermore, how to organize information sources is very important and the problem-solving and reason o the structure of information sources. In fact, the human brain can be regarded as a huge distributed knowledge base with multiple information granule networks. Why a people can give a reasonable answer within a reasonable time when he/she received a question (a reasoning problem)? Understanding principles and mechanisms of human information organization, retrieval and selection in depth aims to find more cognitively inspired methods of problem-solving and reasoning at a Web scale. In - - this talk, we describe studying on human and Web problem-solving and reasoning in a unified way from the viewpoint of Brain Informatics. The key question is ""can we find a new cognitive model for developing human-level Web based network reasoning and problem-solving?"" In order to answer this question, we investigate the cognitive mechanism and neural basis of human problem solving and reasoning, for developing new cognitively inspires. Based on the above results, we will implement problem solver markup language (PSML) for representing, organizing, retrieving, and selecting Web information sources with multiple levels of granularity, and develop PSML based Web inference engines for personalized wisdom Web problem solving and services.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664804","","Artificial intelligence;Cognitive science;Competitive intelligence;Humans;Informatics;Information retrieval;Logic;Mathematical model;Problem-solving;Real time systems","Internet;inference mechanisms;problem solving","Web information sources;Web problem solving;artificial intelligence;brain informatics;cognitive science;computational intelligence;connectionist approach;distributed problem-solving;human information organization;memory constraints;problem solver markup language","","1","","","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Resource Discovery Algorithm Based on Small-World Cluster in Hierarchical Grid Computing Environment","Y. Ma; B. Gong; L. Zou","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan","2008 Seventh International Conference on Grid and Cooperative Computing","20081031","2008","","","110","116","Grid is an environment of seamless and integrated sharing and collaboration. The heterogeneous, dynamic, various and autonomous characteristics of resources make grid resource discovery a challenging issue. Hierarchical grid computing environment (hierarchical grid for short) with many advantages is far and wide used. This paper introduces small-world cluster into hierarchical grid in which intra-cluster adopts centralized management and cluster center nodes form small-world network. The architecture strikes a balance between high efficiency of total centralized management and good scalability of absolute distributed disposal. In the process of constructing small-world network, a new construction method on the basis of NW (Newman-Watts) model is presented, that is, short range contacts and long range contacts are represented by routing tables in a logic and dynamic way not by Manhattan distance. SWRD (Small-World Resource Discovery) algorithm pertinent to user classification and data retrieval way is proposed. Results from simulation experiments demonstrate SWRD algorithm greatly prunes search space and improves query efficiency.","2160-4908;21604908","POD:978-0-7695-3449-7","10.1109/GCC.2008.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662851","","Clustering algorithms;Collaboration;Computer architecture;Computer network management;Grid computing;Information retrieval;Logic;Routing;Scalability;Waste management","grid computing;groupware;hierarchical systems","Manhattan distance;Newman-Watts model;centralized management;collaboration;hierarchical grid computing environment;resource discovery;small-world cluster","","6","","15","","","24-26 Oct. 2008","","IEEE","IEEE Conference Publications"
"Symbolic Reductionist Model for Program Comprehension","E. Laitila; S. Legrand","Univ. of Jyvaskyla, Jyvaskyla","2007 Sixth Mexican International Conference on Artificial Intelligence, Special Session (MICAI)","20081028","2007","","","363","372","This article presents the main features of a novel construction, symbolic analysis, for automatic source code processing. The method is superior to the known methods, because it uses a semiotic, interpretative approach. Its most important processes and characteristics are considered here. We describe symbolic information retrieval and the process of analysis in which it can be used in order to obtain pragmatic information. This, in turn, is useful in understanding a current Java program version when developing a new version.","","POD:978-0-7695-3124-3","10.1109/MICAI.2007.7","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4659326","program comprehension;reverse engineering;symbolic analysis","Artificial intelligence;Information analysis;Information retrieval;Information systems;Java;Object oriented modeling;Object oriented programming;Reverse engineering;Turing machines;Unified modeling language","Java;configuration management;object-oriented programming;program diagnostics;reverse engineering;symbol manipulation","Java program;automatic source code processing;pragmatic information;program comprehension;semiotic-interpretative approach;symbolic analysis;symbolic information retrieval;symbolic reductionist model","","0","","17","","","4-10 Nov. 2007","","IEEE","IEEE Conference Publications"
"An Efficient Hybrid Hierarchical Document Clustering Method","Y. Zhu; B. C. M. Fung; D. Mu; Y. Li","Northwestern Polytech. Univ., Xi'an","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","395","399","Document clustering is a technique for grouping document objects together such that documents within a cluster have high similarity while documents in different clusters have low similarity. Hierarchical document clustering organizes the clusters into a hierarchy such that a parent cluster is a general topic of its child clusters. In this paper, we propose a novel hierarchical document clustering method that is a hybrid version of partitioning and agglomerative clustering approaches. The proposed method inherits the merit of efficiency from the partitioning approach and the hierarchical structure from agglomerative approach. Experiments on real-life datasets suggest that our method is effective and efficient.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666146","clustering algorithm;data mining;document clustering;hybrid method","Clustering algorithms;Clustering methods;Fuzzy systems;Information retrieval;Itemsets;Keyword search;Partitioning algorithms;Performance analysis;Scalability;Search engines","document handling","agglomerative clustering;document objects grouping;hybrid hierarchical document clustering","","1","","9","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Keyword search over hybrid XML-relational databases","Liru Zhang; Tadashi Ohmori; Mamoru Hoshi","Graduate School of Information Systems, The University of Electro-Communications, Tokyo, Japan","2008 SICE Annual Conference","20081021","2008","","","97","102","How to realize keyword search over XML databases (XML DB) or relational databases (RDB) is a todaypsilas hot topic. In this paper, we first point out that existing keyword-search methods over those databases cannot get sufficient results. Then, we propose a new keyword-search method over hybrid XML-relational databases, and demonstrate that its answers are better than those of existing techniques. We propose a new join-operator for XML data, and utilize the new operator to enable keyword search in hybrid XML-relational databases.","","CD-ROM:978-4-907764-29-6; POD:978-4-907764-30-2","10.1109/SICE.2008.4654630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4654630","XML;hybrid database;keyword search","Books;Electronic mail;Information retrieval;Information systems;Keyword search;Relational databases;Search engines;Software libraries;XML","XML;information retrieval;relational databases","XML data;hybrid XML-relational databases;keyword search","","0","","9","","","20-22 Aug. 2008","","IEEE","IEEE Conference Publications"
"Reducing Impact of Inaccurate User Feedback in Face Retrieval","R. He; W. S. Zheng; M. Ao; S. Z. Li","Inst. of Autom., Chinese Acad. of Sci., Beijing","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","6","A main problem in face retrieval is the semantic gap between low-level features and high-level semantic concepts. Relevance feedback (RF) may be used to incorporate to reduce the semantic gap. However, in the search for a specific target in a facial image database, a user's assignment of RF instances may be mistaken. This would make the system prediction of the user's target in a wrong way. Addressing this problem, we propose a new query point movement technique for target search by posing the problem of reducing the impact of inaccurate user feedback as an optimization problem. We develop a support vector machine based method to learn a decision boundary to identify ideal irrelevant images. Then we propose a rank function for finding target images, which would assign high scores to the images near the relevant images and punish those close to the decision boundary. Experiments are performed to show the stability and efficiency of the proposed algorithm.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663003","","Bayesian methods;Biometrics;Feedback;Image databases;Information retrieval;Predictive models;Radio access networks;Radio frequency;Support vector machine classification;Support vector machines","face recognition;image retrieval;query formulation;relevance feedback;support vector machines;visual databases","face retrieval;facial image database;query point movement;relevance feedback;support vector machine;target search;user feedback","","1","","20","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Using FCA to Answer Fuzzy Queries in Cooperative Systems","H. Chettaoui; M. A. B. Hassine; N. Hachani; H. Ounelli","Fac. of Sci. of Tunis, Campus Univ., Tunis","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","3","","14","20","In this paper, we present a cooperative approach to deal with empty answers in the case of fuzzy conjunctive queries by referring to the formal concept analysis theory. We present an architecture combining databases with this theory. In this architecture, fuzzy querying processing based on Galois lattices allows to detect the reasons of empty answers by providing the subqueries that are responsible of the failure. We also use concept lattices to answer the user with the nearest answers through fuzzy alternative subqueries.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666207","Cooprative systems;FCA;Flexible queries;fuzzy sets","Cooperative systems;Data analysis;Database systems;Fuzzy sets;Fuzzy systems;Information analysis;Information retrieval;Lattices;Query processing;Relational databases","cooperative systems;fuzzy set theory;query processing","Galois lattices;cooperative systems;formal concept analysis theory;fuzzy alternative subqueries;fuzzy conjunctive queries","","0","","11","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Validation of rain attenuation time series synthesizers for temperate area - on the enhanced Maseng-Bakken model","G. Carrie; L. Castanet; F. Lacoste","Department of ElectroMagnetism and Radar, ONERA, Toulouse, France","2008 IEEE International Workshop on Satellite and Space Communications","20081024","2008","","","40","44","To develop and test real time fade mitigation techniques control algorithms, propagation time series are needed. An alternative to using real data collected from propagation experiments is to generate typical fading time series making use of climatological characteristics as well as geometrical and radio-electrical parameters of the link. The aim of the study presented in this paper is to validate time-series synthesisers relying on an enhanced Maseng-Bakken model for temperate areas. In the first part of this paper, the basic principles of the Maseng-Baken model are recalled and the parameterisation of this channel model is discussed for temperate climates. Then, Ka band beacon data collected in European and in North-American areas are used: on the one hand to retrieve the input parameters of the channel models and on the other hand to test them with respect to long-term statistics. The results of this testing analysis constitute the second part of this paper.","","CD-ROM:978-1-4244-1948-7; POD:978-1-4244-1947-0","10.1109/IWSSC.2008.4656741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4656741","Propagation modelling;Time-series generator;Time-series synthesiser;attenuation;rain","Attenuation;Electromagnetic modeling;Electromagnetic propagation;Frequency;Information retrieval;Rain;Statistical analysis;Stochastic processes;Synthesizers;Testing","electromagnetic wave transmission;fading;radiowave propagation;rain;satellite communication;time series","climatological characteristics;enhanced Maseng-Bakken model;fade mitigation techniques control algorithms;propagation time series;rain attenuation time series synthesizers;temperate area;temperate climates","","7","","10","","","1-3 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Biased Summary System and Its Implementation Technology","G. Liu","Sch. of Inf. Security Eng., Shanghai Jiaotong Univ., Shanghai","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","129","133","A biased summary system is a significant research task in the field of natural language processing. The implementation method of biased summary system is proposed in this paper based on a conception base that is used to expand conception. During the process of generating summary, weighting method correlated to subject and user's bias is discussed and the strategy of selecting sentences to generate summary is discussed too. It's proved by experiment that for a large proportion of articles this system can generate a biased summary which can satisfy user's bias and reflect the subject of the whole article.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.303","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666370","Biased summary;Conception expansion;Natural language processing","Agriculture;Dictionaries;Fuzzy systems;Government;Information retrieval;Information security;Internet;Knowledge engineering;Natural language processing","natural language processing;text analysis","biased summary system;natural language processing;sentence selection","","0","","7","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Resources Dispatch Model of Meeting Fatal Forest Disasters Emergency","D. s. Wu; Q. f. Yu; M. l. Huang; L. j. Liu","Sch. of Inf. Eng., Zhejiang Forestry Coll., Lin'an","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","617","620","When fatal forest disasters take place, only one retrieval depot usually can not provide enough supplies to resolve the emergency. So the problem about how to combine multi-depot-multi-resource has been put forward. The main objective of the multi-resource scheduling is how to achieve the least emergency time and the fewest retrieval depots. In this scheduling algorithm, there are mainly two factors that restrict the emergency time. One is path length, and the other is traffic road quality. Because the forest disaster usually takes place in remote mountain area, the factor of traffic road quality is very important. Therefore the least time (t<sub>ij</sub>) should be the optimal solution about the shortest path (d<sub>ij</sub>) and the road quality parameter (q<sub>ij</sub>). In this paper, taking a forest area as experiments region, we achieved some results mainly in the following aspects: (1) determined the value of qij through the experiment; (2) established the least emergency time model; (3) built the emergency resources scheduling optimal model in forest fatal disaster for meeting fewest rescue depots based on the fastest emergency time.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666458","Forest Disasters;Meet an emergency;Resources Dispatch model","Educational institutions;Forestry;Fuzzy systems;Information retrieval;Knowledge engineering;Layout;Roads;Routing;Scheduling algorithm","disasters;emergency services;forestry;resource allocation;road traffic;scheduling","fatal forest disaster emergency;multi depot multi resource;multiresource scheduling algorithm;remote mountain area;resource dispatch model;shortest path;traffic road quality","","0","","8","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Attribute-based access control using combined authentication technologies","Hyun-A Park; Dong Hoon Lee; Justin Zhan","CIST(Center for the information security technologies), GSIMS, Korea University, Anam 5-Ga, Sungbuk-ku, Seoul, Korea","2008 IEEE International Conference on Granular Computing","20081031","2008","","","518","523","As NETWORK attackers become more and more sophisticated and wireless communications make the potential risks in data protection more serious, we come to need much stronger authentication and access control systems. In this paper, we propose a combined authentication method including biometric and access control system based on attribute-wise encryption in wireless environment for ubiquitous computing era. It can accomplish both of the authentication of a user oneself and data retrieval by using one time padding in one round. Our access control method is flexible to dynamic policy or role changes.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664774","","Access control;Authentication;Authorization;Biometrics;Cryptography;Databases;Information retrieval;Protection;Ubiquitous computing;Wireless communication","authorisation;cryptography;ubiquitous computing;wireless channels","attribute-based access control;attribute-wise encryption;authentication technologies;biometric system;data protection;network attackers;ubiquitous computing;wireless communications","","0","","17","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Improving information availability in storage-centric sensor networks","N. Nguyen; S. Krishnamurthy; P. Xie; D. Jones","University of Illinois, Urbana-Champaign, USA","2008 33rd IEEE Conference on Local Computer Networks (LCN)","20081031","2008","","","82","90","We address the issue of improving information availability in a class of delay-tolerant sensor network applications, where the sensor nodes are deployed in disconnected environments. In such environments, since there is no continuous access to a remote base station, there is a need to leverage the collaborative resources of the sensor network to support in-network storage. The stored data can then be retrieved opportunistically by mobile collectors in the proximity. We have developed a data-centric, in-network storage architecture that partitions the network into storage zones. In such a scheme, some of the storage nodes may be unavailable at the time of storage and retrieval, because they are either sleeping to conserve energy or because they have failed.We present two schemes based on random linear network coding for improving information availability within such a storage architecture. In the centralized scheme, the encoding is performed by the managers in each storage zone, whereas in the decentralized scheme, the encoding is done locally by the zone members. We have implemented the network coding schemes in TinyOS and we present results that show the impact of the zone size, duty cycle, and the degree of encoding on the decoding probability, based on our experiments on a testbed of Micaz motes.","0742-1303;07421303","CD-ROM:978-1-4244-2413-9; POD:978-1-4244-2412-2","10.1109/LCN.2008.4664155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664155","data-centric storage;information availability;network coding;sensor networks","Availability;Base stations;Collaboration;Decoding;Encoding;Energy storage;Information retrieval;Memory;Network coding;Wireless sensor networks","linear codes;random codes;wireless sensor networks","collaborative resource;data-centric in-network storage architecture;delay-tolerant sensor network;energy conservation;information availability;mobile collector;network coding;random linear network coding;remote base station;storage-centric wireless sensor network","","4","","14","","","14-17 Oct. 2008","","IEEE","IEEE Conference Publications"
"Content-based image retrieval by a semi-supervised Particle Swarm Optimization","M. Broilo; P. Rocca; F. G. B. De Natale","Dept. of Information Engineering and Computer Science, University of Trento, Via Sommarive 14 I-38100 POVO (TN) - Italy","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","666","671","An innovative approach based on an evolutionary stochastic algorithm, namely the Particle Swarm Optimizer (PSO), is proposed in this paper as a solution to the problem of intelligent retrieval of images in large databases. The problem is recast to an optimization one, where a suitable cost function is minimized through a customized PSO. Accordingly, the relevance-feedback is used in order to exploit the information of the user with the aim of both guiding the particles inside the search space and dynamically assigning different weights to the features.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665159","","Content based retrieval;Data engineering;Feedback;Image databases;Image retrieval;Information retrieval;Particle swarm optimization;Radio frequency;Spatial databases;Stochastic processes","content-based retrieval;evolutionary computation;image retrieval;particle swarm optimisation;relevance feedback;search problems;very large databases","dynamic feature weight assignment;evolutionary stochastic algorithm;intelligent content-based image retrieval;large database;relevance feedback;search space;semisupervised particle swarm optimization","","6","","23","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Novel Arithmetic of Named Entity Identification","J. Wang; Z. Liu","Sch. of Comput. Sci. & Technol., Xidian Univ., Xi'an","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","457","461","This paper propose a novel method of named entity identification based on improved hidden Markov model, according to the specific characteristics of the named entities in recruitment information. The algorithm tags entity and improved hidden Markov model, which can be effective to identify entities. The experimental results showed that the accuracy rate has been significantly improved and increased by 19.3 percent, compared with the original algorithm.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.450","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666428","Entity Identification;Named Entity;a generalized Hidden Markov Model (GHMM)","Computer science;Dictionaries;Digital arithmetic;Electronic mail;Fuzzy systems;Hidden Markov models;Information retrieval;Natural language processing;Recruitment;Tagging","hidden Markov models;natural language processing;recruitment;word processing","hidden Markov model;named entity identification;recruitment information","","0","","5","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"An approach for semantic query mapping on the heterogeneous web data sources","A. Hajmoosaei; S. A. Kareem","Faculty of Computer Science and Information Technology, University of Malaya, PO Box 50603, Kuala Lumpur, Malaysia","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","555","562","There are a lot of valuable data on the web that users may need to improve their decision making process. The answer of user query often exists in multiple Web data sources. The extraction and combination of answers of user queries from different Web data sources often fails because of syntax and semantic heterogeneity between user queries and web data sources. The retrieval and extraction of these answers from the different web data sources impose a need for queries to be syntactically and semantically mapped to Web sources query languages. In this paper, we focus on semantic heterogeneity among user query terms and web data sources terms. We propose an approach for the semantic mapping of user query terms to web data sources terms.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664409","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664409","Semantic Heterogeneity;Semantic Query Mapping;Web data source","Computer science;Data mining;Database languages;Decision making;Electronic commerce;Information retrieval;Information technology;Knowledge management;Ontologies;Publishing","decision making;query languages;query processing;semantic Web","Web data sources;Web sources query languages;decision making process;semantic heterogeneity;semantic query mapping approach;syntax heterogeneity","","1","","23","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"iDistance Based Interactive Visual Surveillance Retrieval Algorithm","L. Qu; Y. Chen; X. Yang","Inst. of Adv. Digital Technol. & Instrum., Zhejiang Univ., Hangzhou","2008 International Conference on Intelligent Computation Technology and Automation (ICICTA)","20081028","2008","1","","71","75","This paper proposes an iDistance based interactive retrieval algorithm to accomplish semantic retrieval in visual surveillance system and improve the retrieval performance. The concept of user is interactively learned by training a SVM classifier from the user feedbacks. The search range of the algorithm is reduced by an iDistance based optimization algorithm. The surveillance objects are characterized by the color, texture and coefficient trajectory features. Experimental results on real scenes demonstrate the effectiveness of the proposed algorithm.","","POD:978-0-7695-3357-5","10.1109/ICICTA.2008.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4659445","metric space;relevance feedback;support vector machine;surveillance","Feedback;Information retrieval;Kernel;Layout;Principal component analysis;Spatial databases;Support vector machine classification;Support vector machines;Surveillance;Visual databases","image retrieval;interactive systems;pattern classification;support vector machines;surveillance","SVM classifier;iDistance;interactive visual surveillance retrieval;semantic retrieval","","3","","11","","","20-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Hierarchical Document Classification Based on a Backtracking Algorithm","C. Zhu; J. Ma; D. Zhang; X. Han; X. Niu","Sch. of Comput. Sci. &Technol., Shandong Univ., Jinan","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","467","471","Hierarchical document classification refers to assigning one or more suitable categories from a hierarchical category space to a document. This paper proposes a new hierarchical document classification method based on a backtracking algorithm. Utilizing the relationships between categories in category tree, a suitable threshold for every category is found to determine whether a document could be classified into the category. And the backtracking algorithm in our hierarchical classification approach effectively solves the problem that a misclassification at higher level directly leads to the misclassification at a lower level. Moreover, feature set is selected by integrating information gain with hierarchy information, which accords with the characteristic of a category tree. Experiments show that the method performs well when enough training documents are given.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666161","Backtracking Algorithm;Hierarchical Document Classification;information gain","Classification tree analysis;Computer science;Conference management;Fuzzy systems;Information management;Information retrieval;Knowledge management;Machine learning;Space technology;Technology management","backtracking;classification;document handling;feature extraction;tree searching","backtracking algorithm;category tree;feature set selection;hierarchical document classification method","","1","","10","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Detection of Protein Subcellular Localization Based on a Full Syntactic Parser and Semantic Information","M. Y. Kim","Sch. of Comput. Sci. & Eng., Sungshin Women's Univ., Seoul","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","407","411","A proteinpsilas subcellular localization is considered an essential part of the description of its associated biomolecular phenomena. As the volume of biomolecular reports has increased, there has been a great deal of research on text mining to detect protein subcellular localization information in documents. It has been argued that linguistic information, especially syntactic information, is useful for identifying the subcellular localizations of proteins of interest. However, previous systems for detecting protein subcellular localization information used only shallow syntactic parsers, and showed poor performance. Thus, there remains a need to use a full syntactic parser and to apply deep linguistic knowledge to the analysis of text for protein subcellular localization information. In addition, we have attempted to use semantic information from the WordNet thesaurus. To improve performance in detecting protein subcellular localization information, this paper proposes a three-step method based on a full syntactic dependency parser and semantic information. In the first step, we construct syntactic dependency paths from each protein to its location candidate. In the second step, we retrieve root information of the syntactic dependency paths. In the final step, we extract syn-semantic patterns of protein subtrees and location subtrees. From the root and subtree nodes, we extract syntactic category and syntactic direction as syntactic information, and synset offset of the WordNet thesaurus as semantic information. According to the root information and syn-semantic patterns of subtrees, we extract (protein, localization) pairs. Even with no biomolecular knowledge, our method shows reasonable performance in experimental results using Medline abstract data. In fact, our proposed method gave an F-measure of 74.53% for training data and 58.90% for test data, significantly outperforming previous methods, by 12-25%.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666419","","Bioinformatics;Data mining;Fuzzy systems;Information analysis;Information retrieval;Learning systems;Protein engineering;Testing;Text mining;Thesauri","biology computing;data mining;grammars;proteins","WordNet thesaurus;protein subcellular localization;semantic information;syntactic dependency path;syntactic parser;text mining","","0","","14","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Using cluster computing to support automatic and dynamic database clustering","S. Guinepain; L. Gruenwald","School of Computer Science, The University of Oklahoma Norman, 73019, USA","2008 IEEE International Conference on Cluster Computing","20081031","2008","","","394","401","Query response time is the number one metrics when it comes to database performance. Because of data proliferation, efficient access methods and data storage techniques have become increasingly critical to maintain an acceptable query response time. Retrieving data from disk is several orders of magnitude slower than retrieving it from memory, it is easy to see the direct correlation between query response time and the number of disk I/Os. One of the common ways to reduce disk I/Os and therefore improve query response time is database clustering, which is a process that partitions the database vertically (attribute clustering) and/or horizontally (record clustering). A clustering is optimized for a given set of queries. However in dynamic systems the queries change with time, the clustering in place becomes obsolete, and the database needs to be re-clustered dynamically. This paper presents an efficient algorithm for attribute clustering that dynamically and automatically generates attribute clusters based on closed item sets mined from the attributes sets found in the queries running against the database. The paper then discusses how this algorithm can be implemented using the cluster computing paradigm to reduce query response time even further through parallelism and data redundancy.","1552-5244;15525244","POD:978-1-4244-2639-3","10.1109/CLUSTR.2008.4663800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663800","","Clustering algorithms;Computer science;Concurrent computing;Delay;Humans;Information retrieval;Memory;Operating systems;Parallel processing;Transaction databases","data handling;pattern clustering;query processing","attribute clustering;cluster computing;data parallelism;data proliferation;data redundancy;data retrieval;data storage;dynamic database clustering;query response;record clustering","","6","","20","","","Sept. 29 2008-Oct. 1 2008","","IEEE","IEEE Conference Publications"
"XML Node Semantic Weight Model Based on VSM","X. Lai; C. Wan; D. Liu","Sch. of Inf. Technol., Jiangxi Univ. of Finance & Econ., Nanchang","2008 International Conference on Management of e-Commerce and e-Government","20081024","2008","","","247","251","XML has become an important format for exchange data. Ranking of XML search results directly relates to XML information retrieval performance. Most of the existing ranking models consider words statistical characteristics in the XML document, but they do not consider position of the node a word belongs to. That is to say, all of nodes in XML document have the equal importance. However, different node plays different role in the entire XML document. So, the same content in different node should have different weight. It means different nodes should have different node semantic weight. In this paper, we present a VSM based method for XML node semantic weight (XNSW-VSM), which is scaled by the similarity between the node and the whole document. Experiment data were selected from Wiki data sets. The Pearson correlation coefficient between semantic results given by experts and the model results is 0.827. It shows the node semantic weight model can analyze the importance of node in XML document and it will be helpful for improving ranking results.","","POD:978-0-7695-3366-7","10.1109/ICMECG.2008.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4656634","Node Semantic Weight;VSM;XML Node","Conference management;Electronic government;Engineering management;Financial management;Information retrieval;Information technology;Knowledge management;Sorting;Technology management;XML","XML;information retrieval;semantic Web;tree data structures","Pearson correlation coefficient;XML document;XML node semantic weight model;information retrieval;vector space model","","0","","13","","","17-19 Oct. 2008","","IEEE","IEEE Conference Publications"
"Design support classifier of filter circuit structure","Keita Ohe; Masami Konishi; Jun Imai","Department of Electrical and Electronic Engineering, The Graduate School of Natural Science and Technology, Okayama University, Japan","2008 SICE Annual Conference","20081021","2008","","","2695","2699","Accompanied with recent trend of high-mix and low-volume productions, demands for performance of analog circuits used for facilities become difficult. As an advanced knowledge and know-how are needed in the design of an analog circuit, only expert designers can cope with the recent trend. In this paper, structural classifier system to support circuit design of filter circuit was proposed. This system involves three functions, optimization, classification, and retrieval of the related database which bring synergetic effects. Using these functions, a filter circuit is designed treating as a multipurpose optimization problem by GP. Efficiency improvement of the design is achieved through inferences referring similar circuit data as an external information. Each function was confirmed through a numerical experiment.","","CD-ROM:978-4-907764-29-6; POD:978-4-907764-30-2","10.1109/SICE.2008.4655123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4655123","Classification;filter circuit;genetic programming;optimization","Analog circuits;Circuit synthesis;Databases;Design engineering;Design methodology;Design optimization;Filters;Genetic programming;Information retrieval;Production","analogue circuits;circuit optimisation;filters;genetic algorithms","analog circuit design;analog circuit performance;design support classifier;filter circuit design;filter circuit structure;genetic programming;high-mix production;low-volume production;optimization;structural classifier system;synergetic effects","","0","","6","","","20-22 Aug. 2008","","IEEE","IEEE Conference Publications"
"Recommended or Not? Give Advice on Online Products","B. Qin; Y. Zhao; L. Gao; T. Liu","Inf. Retrieval Lab., Harbin Inst. of Technol., Harbin","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","208","212","This paper introduces an opinion judgment system that automatically gives advice on whether to recommend this product and furthermore provides corresponding reasons.The core task of the system can be considered as a binary sentence sentiment classification problem. A novel ""polarityword-target"" related feature extraction method is proposed. An opinion judgment system is then built based on the sentiment of each sentence predicted by a maximum entropy (ME) classifier with the novel features. The experimental results on two domains show that the special feature extraction methods are promising; the opinion judgment system with 91.5% average accuracy is highly effective.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.441","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666385","","Batteries;Colored noise;Data mining;Digital cameras;Entropy;Feature extraction;Fuzzy systems;Information retrieval;Laboratories;Noise level","Internet;classification;information filters;information retrieval","binary sentence sentiment classification problem;feature extraction;maximum entropy classifier;online products;opinion judgment system;polarityword-target;product recommendation","","0","","14","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"An Ontology-Based Methodology for Semantic Expansion Search","G. Zou; B. Zhang; Y. Gan; J. Zhang","Dept. of Comput. Sci., Tongji Univ., Shanghai","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","5","","453","457","Matching search technology based on query keyword has been widely used by traditional search way. It still belongs to pure keyword matching and can not acquire satisfactory search results. The essential reason is that traditional Web search lacks semantic understanding to user's search behaviors. In this study, we propose a novel ontology-based framework for semantic expansion search. Based on constructed domain ontology, semantic annotation algorithm and semantic expansion reasoning algorithm are presented in detail, which are associated with semantic annotation unit and semantic expansion reasoning engine respectively. Then a semantic search prototype system is designed and implemented. The experimental results show that semantic expansion search by proposed methodology can overcome limitations in comparison with traditional keyword search mode, and achieve higher recall ratio and precision ratio.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666567","Domain ontology;Semantic annotation;Semantic expansion","Computer science;Fuzzy systems;HTML;Information resources;Information retrieval;Ontologies;Search engines;Taxonomy;Web pages;Web search","information resources;ontologies (artificial intelligence);search engines","constructed domain ontology;keyword matching;matching search technology;ontology-based methodology;query keyword;semantic annotation algorithm;semantic expansion reasoning algorithm;semantic expansion search","","3","","9","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Personalized search engine based on granular computing","Jian-Feng Xu; Zhi -Bing Zhao; Lan liu; Tao-Rong Qiu","School of Software, NanChang University, Jiangxi, 330047, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","690","694","A binary system in information granules is introduced in this article. Based on this system, a search engine of Web page abstract information is constructed, where the search results are processed by granular reasoning. Firstly, definitions for information granule and preprocess, such as accord degree, granular matrix, granular relation matrix, constrained relation matrix, association degree and so on, have been represented. Secondly, with these definitions, a personalized meta-info search engine experimental system is developed. Finally, the experimental results show that the search results returned by this system match userpsilas expectation effectively.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664704","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664704","Abstract Context;Granular Computing;Information Granule;Search Engine","Information analysis;Information filtering;Information filters;Information retrieval;Information systems;Internet;Matched filters;Matrix decomposition;Search engines;Web pages","Internet;classification;inference mechanisms;search engines","Web page abstract information;binary system;classification;granular computing;granular reasoning;information granule;personalized search engine","","0","","7","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Optimized Query Terms Creation Based on Meta-Search and Clustering","H. Yang; J. Chen; Y. Zhang; X. Meng","Beijing Univ. of Posts & Telecommun., Beijing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","38","42","Meta-search is a search engine that sends users' requests to several other search engines and/or databases and returns the results from each one. Concepts are defined in a semantic network that contains links to the original terms. This article provides a framework of three layers, meta-search layer, concept layer, concept clustering and sorting layer to guide user to refine the query terms. The first layer, meta-search layer provides the ability to get the relevant document fetched by traditional search engines, including title, brief, URL, and document. Concept layer derives concepts from retrieved documents by a concept dictionary. The last layer clusters the concepts, and provides the refined query terms for individual semantic domain of the origin query term. Then the system guides user to choose the query terms which describe options most precisely and get better results from search engines. At last the testing results prove that refined query terms can be developed and costing time is acceptable.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.513","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666076","","Clustering algorithms;Feedback;Fuzzy systems;Information retrieval;Internet;Metasearch;Search engines;Uniform resource locators;Web pages;Web server","document handling;meta data;pattern clustering;query processing;relevance feedback;search engines;semantic networks;sorting","concept clustering;concept layer;meta clustering;meta-search layer;optimized query terms creation;relevant document;search engine;semantic domain;semantic network;sorting layer","","1","","13","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Information System for Aquaculture Farms Using WINC Service","S. Ye; Y. Kang; M. Jang; H. Ceong; S. Han","Dept. of Digital Convergence, Chonnam Nat. Univ., Gwangju","International Symposium on Computer Science and its Applications","20081021","2008","","","365","368","To offer effective providing of seawater and selling produced marine products, we need information of tide and product price. Existing system cannot offer effective approaching method since it uses Web-service form under the base of Internet. In this research, we suggest providing plan of tide information in detailed areas, by using mobile interface. On mobile device, we increased the user's accessibility by describing tide information to 3 types, table, graph and calendar. Next, we suggest information retrieval service of product price on mobile device. Also, they can make decision when to sell their products by using cellular phone. Especially, it is useful to aquaculture farmer to retrieve information from the server because they are restricted by where they are.","2159-7030;21597030","POD:978-0-7695-3428-2","10.1109/CSA.2008.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4654117","","Aquaculture;Computer science;Information retrieval;Information systems;Internet;Mobile handsets;Tides;Uniform resource locators;Web pages;Web services","Web services;aquaculture;information retrieval;mobile computing;mobile handsets;user interfaces","Internet;WIMC service;Web-service;aquaculture farmer;aquaculture farms;cellular phone;information retrieval service;information system;mobile device;mobile interface;produced marine products;product price;tide information","","0","","16","","","13-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Feature-Based Document Image Retrieval Method","T. Zhang","Shandong Normal Univ., Jinan","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","5","A document image retrieval method based on the paragraph feature combining up with the relative difference of local pixel distributions and high-dimensional data index structure is developed in the article .First, the definitions of paragraph feature and relative difference of local pixel distributions are given, then the extraction method is described in detail, so is the retrieval method based on the two features. As a global feature, the paragraph feature combined with the relative difference of local pixel distributions, which is a local feature, could describe the document image sufficiently and give a good distinguish. High-dimensional data index structure used in the method could greatly improve the velocity. Based on them, an efficient retrieval method is derived.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663029","","Data mining;Image retrieval;Information retrieval;Optical character recognition software;Pixel;Smoothing methods","data structures;document image processing;feature extraction;image retrieval","data index structure;feature-based document image retrieval;local pixel distributions;paragraph feature","","1","","14","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Color restoration for objects of interest using robust image features","D. Chen; V. Chandrasekhar; G. Takacs; J. Singh; B. Girod","Information Systems Laboratory, Stanford University, CA 94305, USA","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","535","540","Illumination distortion due to uncontrolled lighting can severely degrade the color appearance of a photo. Frequently, the desired colors for objects in a newly taken query image are found in a previously stored database image. Then, the goal is to change the colors in the query image to match the colors in the database image. This paper presents a color restoration system that automatically retrieves a database image which matches the query image, even if the two images are taken from different viewpoints and under different illuminations. Robust features enable both accurate retrieval from the database and efficient sampling of the color differences between the query and database images. A spatially varying color mismatch model is generated, and the colors of the query image are effectively restored.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665136","","Color;Image databases;Image restoration;Image retrieval;Information retrieval;Laboratories;Painting;Photometry;Robustness;Spatial databases","image colour analysis;image matching;image restoration;image retrieval","color restoration system;database image;database image matching;illumination distortion;image retrieval;query image;robust image feature;varying color mismatch model","","0","","12","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"A new binary iterative LDPC decoding algorithm","G. Yue; X. Wang","NEC Laboratories America, Inc., Princeton, NJ 08540, USA","2008 5th International Symposium on Turbo Codes and Related Topics","20081024","2008","","","139","144","We introduce a new binary message-passing decoding method for low-density parity-check (LDPC) codes. The proposed decoding principle does not require the degree information of variable nodes and can be applied to both time invariant and time-variant decoding algorithms. We present the extrinsic error probability analysis and decoding threshold optimization for the new decoding method in both time-invariant and time-variant decoding scenarios. Both theoretical analysis and numerical results show that the proposed method provides the same performance as the existing methods for both time-invariant and time-variant decoding, while the proposed new method facilitates efficient circuit implementations of the LDPC decoder since it does not require the degree information.","2165-4700;21654700","POD:978-1-4244-2862-5","10.1109/TURBOCODING.2008.4658687","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658687","","Circuits;Error analysis;Information retrieval;Iterative algorithms;Iterative decoding;Laboratories;National electric code;Optimization methods;Parity check codes;Turbo codes","binary codes;error statistics;iterative decoding;message passing;parity check codes","binary iterative LDPC decoding algorithm;binary message-passing decoding method;decoding threshold optimization;extrinsic error probability analysis;low-density parity-check codes;time invariant decoding algorithm;time-variant decoding","","5","1","11","","","1-5 Sept. 2008","","IEEE","IEEE Conference Publications"
"Reverse Engineering Finite State Machines from Rich Internet Applications","D. Amalfitano; A. R. Fasolino; P. Tramontana","Consorzio Interuniversitario Naz. per l'Inf., Naples","2008 15th Working Conference on Reverse Engineering","20081024","2008","","","69","73","In the last years, rich Internet applications (RIAs) have emerged as a new generation of Web applications offering greater usability and interactivity than traditional ones. At the same time, RIAs introduce new issues and challenges in all the Web application lifecycle activities. As an example, a key problem with RIAs consists of defining suitable software models for representing them and validating reverse engineering techniques for obtaining these models effectively.This paper presents a reverse engineering approach for abstracting finite state machines representing the client-side behaviour offered by RIAs. The approach is based on dynamic analysis of the RIA and employs clustering techniques for solving the problem of state explosion of the state machine. A case study illustrated in the paper shows the results of a preliminary experiment where the proposed process has been executed with success for reverse engineering the behaviour of an existing RIA.","1095-1350;10951350","POD:978-0-7695-3429-9","10.1109/WCRE.2008.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4656395","Ajax;FSM;RIA;Reverse Engineering","Application software;Automata;Explosions;Information retrieval;Internet;Java;Reverse engineering;Search engines;US Department of Transportation;Usability","Internet;finite state machines;pattern clustering;reverse engineering","Web application lifecycle;clustering techniques;finite state machines;reverse engineering;rich Internet applications;state explosion","","15","","15","","","15-18 Oct. 2008","","IEEE","IEEE Conference Publications"
"Using structural and semantic metrics to improve class cohesion","A. De Lucia; R. Oliveto; L. Vorraro","Department of Mathematics and Informatics, University of Salerno, 84084, Fisciano (SA), Italy","2008 IEEE International Conference on Software Maintenance","20081024","2008","","","27","36","Several refactoring methods have been proposed in the literature to improve the cohesion of classes. Very often, refactoring operations are guided by cohesion metrics based on the structural information of the source code, such as attribute references in methods. In this paper we present a novel approach to guide the extract class refactoring (M. Fowler, 1999), taking into account structural and semantic cohesion metrics. The proposed approach has been evaluated in a case study conducted on JHotDraw, an open source software system. The achieved results revealed that the performance achieved with the proposed approach significantly outperforms the results achieved with methods considering only structural or semantic information. The proposed approach has also been integrated in the Eclipse platform.","1063-6773;10636773","CD-ROM:978-1-4244-2614-0; POD:978-1-4244-2613-3","10.1109/ICSM.2008.4658051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658051","","Data mining;Informatics;Information analysis;Information retrieval;Mathematics;Object oriented programming;Open source software;Programming profession;Software quality;Software systems","object-oriented programming;programming language semantics;public domain software;software maintenance","Eclipse platform;JHotDraw;class cohesion;extract class refactoring;open source software system;refactoring methods;semantic metrics;source code;structural metrics","","8","","28","","","Sept. 28 2008-Oct. 4 2008","","IEEE","IEEE Conference Publications"
"A novel scheme for protecting receiver's location privacy in wireless sensor networks","Y. Jian; S. Chen; Z. Zhang; L. Zhang","Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL","IEEE Transactions on Wireless Communications","20081028","2008","7","10","3769","3779","Due to the open nature of a sensor network, it is relatively easy for an adversary to eavesdrop and trace packet movement in the network in order to capture the receiver physically. After studying the adversary's behavior patterns, we present countermeasures to this problem. We propose a locationprivacy routing protocol (LPR) that is easy to implement and provides path diversity. Combining with fake packet injection, LPR is able to minimize the traffic direction information that an adversary can retrieve from eavesdropping. By making the directions of both incoming and outgoing traffic at a sensor node uniformly distributed, the new defense system makes it very hard for an adversary to perform analysis on locally gathered information and infer the direction to which the receiver locates. We evaluate our defense system based on three criteria: delivery time, privacy protection strength, and energy cost. The simulation results show that LPR with fake packet injection is capable of providing strong protection for the receiveriquests location privacy. Under similar energy cost, the safe time of the receiver provided by LPR is much longer than other methods, including Phantom routing [1] and DEFP [2]. The performance of our system can be tuned through a few system parameters that determine the tradeoff between energy cost and the strength of location-privacy protection.","1536-1276;15361276","","10.1109/T-WC.2008.070182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4657323","Sensor networks, location privacy","Costs;Diversity reception;Information analysis;Information retrieval;Privacy;Protection;Routing protocols;Sensor systems;Telecommunication traffic;Wireless sensor networks","data privacy;receivers;routing protocols;telecommunication traffic;wireless sensor networks","DEFP;Phantom routing;delivery time;energy cost;fake packet injection;location-privacy protection;locationprivacy routing protocol;privacy protection strength;receiver's location privacy;wireless sensor networks","","31","5","20","","","October 2008","","IEEE","IEEE Journals & Magazines"
"Query Graph Visualizer: A visual collaborative querying system","D. H. L. Goh; A. Y. K. Chua; C. S. Lee; B. Luyt","Wee Kim Wee School of Communication and Information, Nanyang Technological University, Singapore","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","78","83","Collaborative querying harnesses the collective search experiences of users for query formulation. We present the Query Graph Visualizer (QGV), a visual collaborative querying system that recommends related queries to a userpsilas submitted query through a network visualization scheme. Users are able to explore the query network and select queries for execution on an information retrieval (IR) system. The design of the QGV is discussed, focusing on its architecture and the implementation of the user interface. An evaluation of the QGV was also conducted to assess the performance of the system against to a conventional search engine. Results indicate that the evaluators who used the QGV completed their tasks much faster compared to those using a search engine alone. A usability evaluation also showed that the system complied with standard user interface heuristics.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664322","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664322","","Collaboration;Collaborative work;Data visualization;Displays;Information retrieval;Search engines;Usability;User interfaces;Visual perception;Vocabulary","data visualisation;groupware;query processing;search engines;user interfaces","information retrieval system;network visualization scheme;query graph visualizer;search engines;user interface;user submitted query;visual collaborative querying system","","0","","21","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"An overview of multi-resolution image processing techniques from the perspective of content-based image retrieval","X. D. Yang","Department of Computer Science, University of Regina, Saskatchewan S4S 0A2 CANADA","2008 IEEE International Conference on Granular Computing","20081031","2008","","","18","23","In recent years, the young and expanding research community of granular computing has begun to show interest in image processing, specifically in the area of image retrieval from image databases or the Web. It might therefore be beneficial to provide a background to researchers in granular computing, at a reasonable depth, of the techniques employed in image retrieval, particularly in the case of content-based image retrieval (CBIR). This article focuses on multi-resolution image processing techniques that are commonly used in CBIR, and, in my opinion, that are potentially of interest to researchers in the area of granular computing. Given the restrictions on the length of a paper, I am unable to sufficiently address all of the important techniques in this article. Instead, I emphasize several classical techniques, and suggest several references for further reading.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664803","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664803","","Computational efficiency;Content based retrieval;Convolution;Feature extraction;Image analysis;Image databases;Image processing;Image retrieval;Information retrieval;Multiresolution analysis","content-based retrieval;image resolution;image retrieval","content-based image retrieval;granular computing;image databases;multiresolution image processing","","0","","11","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Knowledge Mining and Visualization on News Webpages and Large-Scale News Video Database","H. Luo; J. Yang; A. Zhou; J. Fan; T. Hu","Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai","2008 IFIP International Conference on Network and Parallel Computing","20081031","2008","","","452","459","The traditional layout of news websites, the combination of classified hierarchical browsing, headline recommendation and keyword-based search, has been used for many years. The keyword-based search is considered to be the most powerful tool for news browsing and retrieval. Unfortunately, the keyword-based query formulation technique is very difficult to use for news audiences because of the mismatch between its requirements and the audience's ability. It requires the audiences are able to provide appropriate search keywords to represent their information needs. But the news audiences may have difficulty completing this simple task for some reasons: (1) The audiences may not have experience of video retrieval thus they do not know how to represent their information needs via keywords. (2) The audiences may even have no clear idea of what they need beforehand because the news contents are completely dynamic and may be unpredictable. (3) Many visual concepts are difficult to represent via keywords thus the problem is more severe for video news databases. In this paper a novel news browsing and retrieval framework is proposed to resolve this problem. Unlike the traditional news websites, the proposed framework indexes news webpages and video news reports via information extracted from the database and presents the information via visualization techniques as the browsing and retrieval interface. The visualization based interface can directly represent valuable information to the users. The users can browse the content of the news database efficiently and submit queries visually via the visualization interface even they cannot provide appropriate search keywords.","","POD:978-0-7695-3354-4","10.1109/NPC.2008.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663367","","Computer networks;Concurrent computing;Data mining;Information retrieval;Large-scale systems;Ontologies;Parallel processing;Videoconference;Visual databases;Visualization","Web sites;data mining;data visualisation;information retrieval;online front-ends;video retrieval","browsing interface;classified hierarchical browsing;headline recommendation;keyword based search;keyword-based query formulation;knowledge mining;knowledge visualization;large-scale news video database;news Web pages;news Web sites;news audiences;news browsing;news retrieval;retrieval framework;retrieval interface;video news database;video retrieval;visual concepts;visualization technique","","0","","16","","","18-21 Oct. 2008","","IEEE","IEEE Conference Publications"
"The Research about Web Page Ranking Based on the A-PageRank and the Extended VSM","Y. Zhang; L. b. Xiao; B. Fan","Sch. of Comput. & Commun., Lanzhou Univ. of Technol., Lanzhou","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","223","227","The Web page rank algorithm is always regarded as the core of the search engine. Firstly, this article analyzes the traditional and classical rank algorithms briefly. Then, it proposes a new rank algorithm, which is called A-PageRank. In this algorithm, the PageRank value of the source page is distributed to its link-out pages according to the topic similarity. Lastly, a new method which uses both the similarity and divergence to weigh the match degree between one web page and one user query is adopted in order to increase the precision and recall rate of the search engine.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666388","A-PageRank;PFT;PageRank;VSM;anchor text","Algorithm design and analysis;Databases;Delay;Fuzzy systems;Information retrieval;Internet;Marine technology;Oceans;Search engines;Web pages","Web sites;search engines","A-PageRank;Web page ranking;extended VSM;search engine","","1","","9","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Virtual Cord Protocol (VCP): A flexible DHT-like routing service for sensor networks","A. Awad; C. Sommer; R. German; F. Dressler","Computer Networks and Communication Systems, University of Erlangen, Germany","2008 5th IEEE International Conference on Mobile Ad Hoc and Sensor Systems","20081028","2008","","","133","142","Efficient data management techniques are needed in wireless sensor networks (WSNs) to counteract issues related to limited resources, e.g. energy, memory, bandwidth, as well as limited connectivity. Self-organizing and cooperative algorithms are thought to be the optimal solution to overcome these limitations. On an abstract level, structured peer-to-peer protocols provide O(1) complexity for storing and retrieving data in the network. However, they rely on underlayer routing techniques. In this paper, we present the virtual cord protocol (VCP), a virtual relative position based efficient routing protocol that also provides means for data management, e.g. insert, get, and delete, as known from typical distributed hash table (DHT) services. The key contributions of this protocol are independence of real location information by relying on relative positions of neighboring nodes, short virtual paths because successors and predecessors are in their vicinity, and high scalability because only information about direct neighbors is needed for routing. Furthermore, VCP inherently prevents dead-ends and it is easy to be implemented.","2155-6806;21556806","POD:978-1-4244-2574-7","10.1109/MAHSS.2008.4660079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4660079","","Bandwidth;Computer network management;Information retrieval;Memory management;Mobile ad hoc networks;Network servers;Peer to peer computing;Routing protocols;Scalability;Wireless sensor networks","cryptography;file organisation;peer-to-peer computing;routing protocols;wireless sensor networks","cooperative algorithms;data management techniques;distributed hash table;flexible DHT-like routing service;routing protocol;self-organizing algorithms;structured peer-to-peer protocols;virtual cord protocol;wireless sensor networks","","21","","23","","","Sept. 29 2008-Oct. 2 2008","","IEEE","IEEE Conference Publications"
"Towards data warehouse business quality through requirements elicitation","A. Gosain; J. Singh","USIT, GGSIP University, Kashmere Gate, Delhi-110006, India","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","464","469","Data warehouses are mainly used to support decision-making based on the analysis of highly heterogeneous sources to extract, transform and aggregate data, as well as facilitating ad-hoc queries that retrieve the decisional information. Data warehouse development involves many knowledge-intensive activities, of which requirements elicitation is recognized as being crucial and difficult to model. This paper adapts the data warehouse requirements elicitation process, namely informational scenarios, to incorporate business quality at the requirements engineering level of the DW development. To accomplish this, we look at DW business quality mainly from the context of changing economic factors and environmental concerns.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664394","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664394","","Aggregates;Data engineering;Data mining;Data warehouses;Decision making;Decision support systems;Information analysis;Information retrieval;Proposals;Warehousing","business data processing;data warehouses;decision making","ad-hoc queries;data warehouse business quality;decision-making;decisional information retrieval;heterogeneous sources;informational scenarios;knowledge-intensive activities","","2","","18","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"ACCF: Associative Classification Based on Closed Frequent Itemsets","X. Li; D. Qin; C. Yu","Coll. of Comput., Chongqing Univ., Chongqing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","380","384","Recent studies in data mining have proposed a new classification approach, called associative classification, which, according to several reports, such as , achieves higher classification accuracy than traditional classification approaches such as C4.5. However, the approach also suffers from one major deficiency: a training data set often generates a huge set of rules. It is challenging to store, retrieve, prune and sort a large number of rules efficiently for classification, especially on dense databases. In this study, we propose a new associative classification method, ACCF(associative classification based on closed frequent itemsets). The method extends an efficient closed frequent pattern mining method, Charm to mine all frequent closed itemsets (CFIs) and their tidsets, which would help to generate the class association rules (CARs). And we also adopt a new way to classify an unseen case correspondingly. Our extensive experiments on 18 databases from UCI machine learning database repository show that ACCF is consistent, highly effective at classification of various kinds of databases and has better average classification accuracy in comparison with CBA. Moreover, our performance study shows that the method helps to solve a number of problems that exist in the current classification systems.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666143","Closed frequent itemsets;associative classification.;class association rules","Association rules;Data mining;Databases;Educational institutions;Fuzzy systems;Information retrieval;Itemsets;Machine learning;Machine learning algorithms;Training data","data mining;pattern classification","associative classification;closed frequent itemset mining;data mining;dense database","","3","","11","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Test-bed system for improved induction machines diagnostics","A. Bellini; G. Franceschini; C. Tassoni; O. Bottauscio; M. Chiampi","DISMI- University of Modena and Reggio Emilia, Italy","2005 5th IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives","20081031","2005","","","1","6","Diagnostic techniques for induction machines based on the motor current signature analysis monitor the increase of specific frequencies of the stator current spectrum, that are directly linked to anomalous conditions. The stator current spectrum includes several lines, that need to be accurately analyzed in order to achieve a reliable fault diagnosis. Several papers in the literature deal with the analysis of stator currents lines, while it is hard to retrieve information on rotor cage variables. In this paper a dedicated induction machine and experimental set-up developed at IEN is used, that allows the acquisition of instantaneous bar currents, through current sensors mounted on the rotor bars. Though artificial faults are not introduced in the machine, intrinsic non-idealities introduce harmonic distortion in the machine variables. Rotor instantaneous currents are computed by finite element approach and the results are compared with the experimental ones. Then the FFT algorithm is applied to scalar and complex variables and the results are analyzed with the help of the rotating field approach. Reference is made to synchronous operating conditions in order to address the rotor current components caused only by non-idealities.","","CD-ROM:978-0-7803-9125-3; POD:978-0-7803-9124-6","10.1109/DEMPED.2005.4662534","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662534","FE analysis;diagnosis;induction motors;predictive maintenance;sensors","Condition monitoring;Fault diagnosis;Frequency;Induction machines;Induction motors;Information analysis;Information retrieval;Stators;Synchronous motors;System testing","asynchronous machines;electric current measurement;electric sensing devices;fast Fourier transforms;fault currents;fault diagnosis;finite element analysis;machine testing;rotors;stators","FFT algorithm;artificial faults;current sensors;fault diagnosis;finite element approach;harmonic distortion;induction machine diagnostic techniques;motor current signature analysis;rotor cage variables;rotor instantaneous bar currents;stator current spectrum;stator currents lines;synchronous operating condition","","1","","14","","","7-9 Sept. 2005","","IEEE","IEEE Conference Publications"
"Range queries and load balancing in a hierarchically structured P2P system","S. Rieche; B. T. Vinh; K. Wehrle","Distributed Systems Group, RWTH Aachen University, Germany","2008 33rd IEEE Conference on Local Computer Networks (LCN)","20081031","2008","","","28","35","Structured Peer-to-Peer (P2P) systems are highly scalable, self-organizing, and support efficient lookups. Furthermore, Distributed Hash Tables (DHTs), due to their features, are used more and more for file-sharing and content distribution applications. However, a major weakness of traditional DHTs is the search for stored content, as data is assigned to nodes based on hash functions, and the very nature of hash tables allows only exact pattern matches. We present Cerco, a solution for the problem of range queries by using the principles of order-preserving DHTs and a hierarchically structured P2P approach. To guarantee an efficient routing and load balancing, Cerco uses a dynamic hierarchy of DHTs by creating subrings on demand and two explicit load balancing strategies. Our evaluation shows that Cerco is able to achieve the goals of supporting range queries, logarithmic-hop routing, and efficient load balancing.","0742-1303;07421303","CD-ROM:978-1-4244-2413-9; POD:978-1-4244-2412-2","10.1109/LCN.2008.4664148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664148","Distributed Hash Tables;Load Balancing;Peer-to-Peer;Range Queries","Control systems;Costs;Fault tolerance;Information retrieval;Linux;Load management;Pattern matching;Peer to peer computing;Protocols;Routing","file organisation;peer-to-peer computing;query processing;resource allocation;telecommunication network routing","content distribution;distributed hash tables;file-sharing;hash functions;hierarchically structured P2P system;load balancing;logarithmic-hop routing;range queries;structured peer-to-peer systems","","0","","12","","","14-17 Oct. 2008","","IEEE","IEEE Conference Publications"
"A new framework of relevance feedback for content-free image retrieval","Rui Zhang; Ling Guan","Ryerson Multimedia Research Laboratory, Ryerson University, Toronto, ON, Canada","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","685","690","Human beings recognize similarity in scene perception based on their available high-level knowledge about the low-level visual features, which is gradually accumulated throughout their entire lives. Once there is not enough knowledge they tend to rely on low-level visual content. Inspired by this observation, we proposed a new framework of relevance feedback for content-free image retrieval to tackle the problem of sample sparseness. The framework is composed of two components, i.e. short-term feedback and long-term feedback. The former refers to an operation of query conversion and/or refinement during a retrieval session by incorporating a content-aware module, while the latter consists of incrementally updating the system model using the accumulated retrieval results since the last system update. 10000 images from 200 categories of the COREL image collection were employed for evaluating the performance of the framework using the criterion of averaged precision as a function of the number of relevance feedback needed. Experimental results demonstrated a human-like behavior of the proposed framework in that while long-term update helps the system accumulate more knowledge, the content-aware short-term relevance feedback further boosts its performance when the amount of knowledge is limited.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665163","","Content based retrieval;Entropy;Feedback;History;Humans;Image recognition;Image retrieval;Information retrieval;Laboratories;Layout","image retrieval;relevance feedback;visual perception","COREL image collection;content-free image retrieval;high-level knowledge;human-like behavior;long-term feedback;low-level visual features;query conversion;relevance feedback;scene perception;short-term feedback","","1","","10","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"A New Search Results Clustering Algorithm Based on Formal Concept Analysis","Y. Zhang; B. Feng; Y. Xue","Sch. of Electron. & Inf. Eng., Xian Jiaotong Univ., Xian","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","356","360","Organizing Web search results into a hierarchy of topics and subtopics facilitates browsing the collection and locating results of interest. In this paper, we propose a new method based on formal concept analysis (FCA) to build a two-level hierarchy for retrieved search results of a query. After formal concepts are extracted using FCA, anew algorithm is proposed to extract concepts most relevant to the query and a two-level hierarchy is built and presented to the user. Evaluating the quality of the resulting clusters is a non-trivial task. Two improved objective metrics of clustering quality, ANMI@K and ANCE@K, are proposed in this paper. We compare our method with three other search results clustering (SRC) algorithms: Suffix tree clustering (STC), Lingo, and Vivisimo, using a comprehensive set of documents obtained from the Open Directory Project hierarchy as benchmark. In addition to comparison based on objective measures, we also subjectively analyze the properties of cluster labels produced by different SRC algorithms. The experimental results show that our method outperforms the other three SRC algorithms, and is helpful for browsing and locating the results of interests.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666138","ANCE@K;ANMI@K;formal concept analysis;search results clustering","Algorithm design and analysis;Clustering algorithms;Fuzzy systems;Information analysis;Information retrieval;Knowledge engineering;Lattices;Organizing;Singular value decomposition;Web search","Internet;query formulation","Lingo;Suffix tree clustering;Vivisimo;Web search;formal concept analysis;information retrieval;query;search results clustering algorithm","","0","","12","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Attribute characters of formal contexts under homomorphisms","H. Z. Yang","Faculty of Science, Xi&#191;an Jiaotong University, Shaan&#191;xi 710049, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","724","729","In the paper, we introduce the notion of an formal contexts homomorphisms, which is a powerful tool to study the relation between two formal contexts. Based on the notion of homomorphisms of formal contexts, we discuss the invariant characters of formal contexts under homomorphisms, and reveal the relation of attributes characters and formal concepts between two formal contexts under homomorphisms and isomorphisms.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664756","","Application software;Data analysis;Database systems;Finance;Information retrieval;Information technology;Knowledge representation;Lattices;Logic;Power generation economics","data mining;formal logic","formal contexts;homomorphisms;isomorphisms","","1","","20","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"A volume image foreground identification method by dual multi-scale morphological operations","Jiann-Jone Chen; Chun-Rong Su; Lien-Chun How; Han-Yuen Yu","Electrical Engineering Department, National Taiwan University of Science and Technology, 43 Keelung Rd. Sec. 4, Taipei Taiwan","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","610","615","A simple and regular foreground identification (FGID) method is proposed for image indexing. The gray-level morphological open/close by reconstruction (MOR/MCR) is operated on one image in a dual and multi-scale approach to construct a background gray-level mesh to distinguish foregrounds (FGs). The highly regular MOR/MCR operations make it feasible to deal with FG segmentation of volume images. The FGID efficiency is verified by the image retrieval performance, i.e., recall, precision and rank.With precisely identified FGs, MPEG-7 shape descriptors, in additional to color ones, can be used to improve the image retrieval performance. For the retrieval unit, a greedy boosting retrieval method is used to perform shape-based multiinstance query in considering the feature element dependency. To perform multi-instance query with multiple features, the retrieval unit integrates the similarity ranks of different feature types according to the feature saliency among query samples to yield the final similarity rank. The normalized correlation coefficient of features among query samples is computed to provide weighting factors for integrating ranks. Experiments show that the FGID unit helps much in improving the retrieval performances, i.e., 7% improvement for the precision-recall (PR) and 20% improvement for the averaged normalized modified retrieval rank (ANMRR), as compared to non-FGID ones.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665149","","Chromium;Content based retrieval;Image reconstruction;Image retrieval;Image segmentation;Information retrieval;MPEG 7 Standard;Morphological operations;Multimedia databases;Shape","image reconstruction;image retrieval;image segmentation","averaged normalized modified retrieval rank;background gray-level mesh;dual multiscale morphological operations;feature element dependency;gray-level morphological open-close by reconstruction;image indexing;image retrieval;image segmentation;precision-recall;shape-based multi-instance query;volume image foreground identification method","","0","","15","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"Query Recommendation with TF-IQF Model and Popularity Factor","Q. Liu; M. Jiang; Z. Chen","Sch. of Humanities & Social Sci., Tsinghua Univ., Beijing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","203","207","Query recommendation is a technique that provides better queries to help users to get the needed documents when the original query submitted by the user may be insufficient or imprecise to retrieve those. In this paper a novel method for query recommendation is proposed. It is different from traditional methods in two aspects: (1) it breaks URLs into independent tokens and uses a TF-IQF model to present the queries, and calculates the query similarity based on that model in further steps, while traditional query log related methods take the clicked URLs recorded in query log as whole; and (2) it introduces a query popularity factor. The popularity factor adds weight to the queries that receive more user clicks, with the assumption that the quality of these popular queries is proven by previous users. In our experiments based on real commercial search engine query logs, our method out performs others, which demonstrates the effectiveness of the proposed TF-IQF model and popularity factor.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666384","Query Log Mining;Query Recommendation","Cognitive science;Computational linguistics;Frequency;Fuzzy systems;Information retrieval;Natural languages;Particle separators;Psychology;Search engines;Uniform resource locators","document handling;query processing;search engines","TF-IQF model;URL;query log;query popularity factor;query recommendation;search engine","","0","","10","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Joint audio-visual processing, representation and indexing of TV news programmes","J. Zdansky; J. Chaloupka; J. Nouza","Institute of Information Technology and Electronics, Technical University of Liberec, Studentska 2, 461 17, Czech Republic","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","960","965","In the paper we present a complex platform for automatic processing of Czech TV news programmes. Its audio processing module provides text transcription in form of metadata that contain information about spoken content, speaker identities, used pronunciation, word positions and intonation. The video processing module provides pictures representing individual video scenes and information about detected and possibly recognized human faces. The audio and video data are merged into single XML files that are indexed and stored in a searchable database. A simple Web-based search engine can be used to retrieve information from the database that recently contain more than 1800 hours of transcribed programmes from Czech CT24 station.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665213","","Audio databases;Face detection;Face recognition;Humans;Indexing;Information retrieval;Layout;Search engines;TV;XML","XML;audio databases;audio signal processing;database indexing;digital television;face recognition;image representation;meta data;speaker recognition;text analysis;video databases;video retrieval;video signal processing","Czech TV news programme indexing;Web-based search engine;XML file;human face detection;human face recognition;information retrieval;joint audio-visual processing;meta data;pronunciation;searchable database;speaker identity;spoken content;text transcription;video scene representation;word position","","1","","17","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"An Efficient Web Document Classification Algorithm Based on LPP and SVM","Z. Wang; Y. Liu; X. Sun","Sch. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","4","With the explosive growth of World Wide Web, it is of great importance to develop methods for the automatic classifying of large collections of documents. To efficiently tackle this problem, a novel document classification algorithm based on locality pursuit projection (LPP) and SVM is proposed in this paper. The high-dimensional document space are first mapped into lower-dimensional space with LPP, the SVM is then used to classify the documents into semantically different classes. Experimental results show that the proposed algorithm achieves much better performance than other classification algorithms.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663044","","Classification algorithms;Information retrieval;Information science;Large scale integration;Pursuit algorithms;Sun;Support vector machine classification;Support vector machines;Text categorization;Web sites","Internet;document handling;pattern classification;support vector machines","Web document classification;World Wide Web;locality pursuit projection;support vector machine","","0","","15","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Model Retrieval Based on Flattened Shape Comparison in 3D Databases","G. Yin; H. Chen; J. Zhang","Coll. of Comput. Sci. & Technol., Harbin Eng. Univ., Harbin","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","674","678","A method that flatten surface of 3D model is presented. It can flatten the surface of model into a 2D shape as well as automatically cut and partition. The method avoids global and local self-intersections and minimizes the total length of the introduced seams. Then, a 3D models retrieval methodology based on the shape comparison is proposed. By using the flattened surface, pole mapped version normalization and Fourier transform, the shape similarity comparison is performed. The method is effective in capturing characteristics of surface shape. Finally, the experiment results show that our method is better than other methods.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666469","model search;shape comparison;surface flattening;virtual reality","Computer science;Data engineering;Databases;Educational institutions;Feature extraction;Histograms;Information retrieval;Knowledge engineering;Shape measurement;Skeleton","Fourier transforms;image retrieval;solid modelling;visual databases","3D databases;3D models retrieval methodology;Fourier transform;flattened shape comparison;pole mapped version normalization;shape similarity comparison","","0","","14","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Smooth Surface Extraction from Unstructured Point-based Volume Data Using PDEs","P. Rosenthal; L. Linsen","Jacobs University","IEEE Transactions on Visualization and Computer Graphics","20081024","2008","14","6","1531","1546","Smooth surface extraction using partial differential equations (PDEs) is a well-known and widely used technique for visualizing volume data. Existing approaches operate on gridded data and mainly on regular structured grids. When considering unstructured point-based volume data where sample points do not form regular patterns nor are they connected in any form, one would typically resample the data over a grid prior to applying the known PDE-based methods. We propose an approach that directly extracts smooth surfaces from unstructured point-based volume data without prior resampling or mesh generation. When operating on unstructured data one needs to quickly derive neighborhood information. The respective information is retrieved by partitioning the 3D domain into cells using a fed-tree and operating on its cells. We exploit neighborhood information to estimate gradients and mean curvature at every sample point using a four-dimensional least-squares fitting approach. Gradients and mean curvature are required for applying the chosen PDE-based method that combines hyperbolic advection to an isovalue of a given scalar field and mean curvature flow. Since we are using an explicit time-integration scheme, time steps and neighbor locations are bounded to ensure convergence of the process. To avoid small global time steps, one can use asynchronous local integration. We extract a smooth surface by successively fitting a smooth auxiliary function to the data set. This auxiliary function is initialized as a signed distance function. For each sample and for every time step we compute the respective gradient, the mean curvature, and a stable time step. With these informations the auxiliary function is manipulated using an explicit Euler time integration. The process successively continues with the next sample point in time. If the norm of the auxiliary function gradient in a sample exceeds a given threshold at some time, the auxiliary function is reinitialized to a signed dista- - nce function. After convergence of the evolvution, the resulting smooth surface is obtained by extracting the zero isosurface from the auxiliary function using direct isosurface extraction from unstructured point-based volume data and rendering the extracted surface using point-based rendering methods.","1077-2626;10772626","","10.1109/TVCG.2008.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658172","Index Terms&#8212;PDEs;level sets;point-based visualization;surface extraction","Convergence;Data mining;Data visualization;Information retrieval;Isosurfaces;Jacobian matrices;Mesh generation;Partial differential equations;Sensor systems;Surface fitting","convergence of numerical methods;data visualisation;feature extraction;gradient methods;least squares approximations;partial differential equations;rendering (computer graphics);surface fitting","PDE;auxiliary function;convergence;explicit Euler time integration;four-dimensional least-squares fitting;gradient estimation;mean curvature;partial differential equation;point-based rendering;regular structured grid;scalar field;signed distance function;smooth surface extraction;unstructured point-based volume data visualization","Algorithms;Artificial Intelligence;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","8","","34","","","Nov.-Dec. 2008","","IEEE","IEEE Journals & Magazines"
"A fast and automatic video object segmentation technique","Guo Lihua","School of Electronic and Information, South China University of Technology, Guangzhou, 510641, China","2008 International Conference on Communications, Circuits and Systems","20081024","2008","","","714","717","The video object segmentation is a key component of digital video representation, transmission and manipulation, example application including content-based video retrieval, object-based video coding and so on. A fast and automatic video segmentation technique, which aims at foreground and background segmentation via effective combination of color and motion analysis module, is proposed in this paper. Firstly, the watershed segmentation algorithm is employed to provide initial regions according to pixels luminance gradient. Secondly, regions are merged according to their color and motion similarity. Finally, the semantic video object will be obtained after post-processes. The main advantage of this method is its fast and automatic implementation of video object segmentation.","","CD-ROM:978-1-4244-2064-3; POD:978-1-4244-2063-6","10.1109/ICCCAS.2008.4657872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4657872","","Colored noise;Content based retrieval;Filters;Gaussian noise;Image color analysis;Image segmentation;Information retrieval;Motion analysis;Object segmentation;Video compression","content-based retrieval;image colour analysis;image motion analysis;image representation;image resolution;image segmentation;video coding;video retrieval","automatic video object segmentation technique;background segmentation;color analysis module;content-based video retrieval;digital video manipulation;digital video representation;digital video transmission;foreground segmentation;motion analysis module;object-based video coding;pixels luminance gradient;semantic video object;watershed segmentation algorithm","","2","","6","","","25-27 May 2008","","IEEE","IEEE Conference Publications"
"Approximate Searching XML Elements Based on Semantic Restrictions","G. Deng","Higher Vocational Technol. Coll., Jiangxi Normal Univ., Nanchang","2008 International Conference on Management of e-Commerce and e-Government","20081024","2008","","","257","260","In last years, XML has become the standard for information representing, exchanging, and publishing. So, querying XML data is a well-explored topic in both database (DB) and information retrieval (IR) fields, which shows proximity search is well suited to XML documents, which are often modelled as labelled trees. Based on the observations that there are some semantic restrictions in userpsilas query, this paper first analysis query restrictions on elements and their values, and then proposes to approximately extract XML elements by using semantic restrictions.","","POD:978-0-7695-3366-7","10.1109/ICMECG.2008.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4656636","Keyword Proximity Search;Semantic Restrictions;XML","Conference management;Data mining;Databases;Educational institutions;Electronic government;Information retrieval;Search engines;Standards publication;Technology management;XML","XML;database management systems;information retrieval","XML data;information retrieval;proximity search;semantic restrictions","","0","","15","","","17-19 Oct. 2008","","IEEE","IEEE Conference Publications"
"Image retrieval based on edge classification method in BTC-VQ compressed domain","M. R. Sarshar; M. R. Ghahroudi","Azad University, Karaj Branch, Iran","2007 International Conference on Intelligent and Advanced Systems","20081024","2007","","","1204","1209","Because of high volume of graphic information, retrieval of compressed images is one of the needs of information era. One of the rapid methods for image compression which has the capability to maintain important information of images for retrieval is block truncation coding (BTC). In this article a new method for retrieval of images compressed by BTC has been provided. In our approach, we use some classified patterns, derived from BTC method as a retrieval feature. This method has been examined on a database consisting of 9983 images with different contents and its results have been compared with similar methods.","","CD-ROM:978-1-4244-1356-0; POD:978-1-4244-1355-3","10.1109/ICIAS.2007.4658575","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658575","","Graphics;Histograms;Image coding;Image databases;Image retrieval;Image storage;Information retrieval;Intelligent systems;Spatial databases;Transform coding","block codes;edge detection;image classification;image coding;image retrieval;vector quantisation","BTC-VQ compressed domain;block truncation coding;edge classification;image compression;image retrieval;vector quantisation","","0","","13","","","25-28 Nov. 2007","","IEEE","IEEE Conference Publications"
"Methods of Chlorophyll Concentration Retrieval","X. Zheng; W. Li; W. Liu; J. Wang","Tianjin key Lab. of Marine Resource & Chem., Tianjin Univ. of Sci. & Technol., Tianjin","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","76","80","Oceanic chlorophyll concentration is the important indicator of phytoplankton and water quality. So chlorophyll concentration retrieval is the key factor in ocean ecological system. The paper introduces the bio-optical algorithm of chlorophyll concentration retrieval, in which the algebra and neural networks methods are introduced in model methods. The SeaWiFS data of Chinese sea are processed through the software of SeaDAS, the chlorophyll concentration is retrievable by the SeaWiFS/OC4V4 method, and the results are compared between the real collected chlorophyll concentration and the chlorophyll concentration retrieval.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666360","Chlorophyll;SeaWiFS data;concentration retrieval","Carbon dioxide;Information retrieval;Marine pollution;Marine technology;Oceans;Pigmentation;Remote monitoring;Remote sensing;Tides;Water pollution","algebra;biology computing;information retrieval;neural nets","SeaDAS;SeaWiFS;SeaWiFS/OC4V4;algebra;biooptical algorithm;chlorophyll concentration retrieval;neural networks methods;ocean ecological system;oceanic chlorophyll concentration;phytoplankton;water quality","","1","","5","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Web Based Product Price Forecast Using Fuzzy CBR","H. Yuan; J. Ju; Y. Chen; M. Chen","Coll. of Inf. Technol., Shanghai Ocean Univ., Shanghai","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","3","","493","497","A healthy and sustainable development of aquaculture requires an accurate forecast of aquatic product prices. This paper presents an experiment with a Web-based application to perform product price prediction. It integrates three key technologies: automatic data extraction algorithms to retrieve aquatic product prices from various related Websites, attribute-oriented induction algorithms to capture varied time granularity data and case-based reasoning (CBR) as its reasoning logic to deal with a focus on fuzzy matching. Test results of the experiment have shown that the application can successfully extract the web-based data as designed and effectively analyze the data leading to a reliable forecast of aquatic product prices.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.445","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666294","Aquatic products prices;Attribute-oriented induction;Case-based reasoning;Fussy matching","Data analysis;Data mining;Economic forecasting;Flowcharts;Fuzzy logic;Fuzzy systems;Information retrieval;Technology forecasting;Testing;Weather forecasting","Internet;aquaculture;case-based reasoning;sustainable development","Web based product price forecast;aquaculture;automatic data extraction algorithms;case-based reasoning;fuzzy matching;sustainable development","","2","","11","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Semi-supervised learning by disagreement","Z. H. Zhou","National Key Laboratory for Novel Software Technology, Nanjing University, 210093, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","93","93","In real-world applications, assigning labels to examples usually requires human effort and therefore, labeled training examples are expensive; unlabeled training examples, however, are cheap and abundant. As a consequence, semi-supervised learning which attempts to exploit unlabeled data to help improve learning performance has become a very hot topic in machine learning and data mining. In this talk, I will introduce some of our research advances in disagreement-based semi-supervised learning, a paradigm covers a broad range of algorithms and has been successfully applied to many real tasks such as statistical parsing, noun phrase identification, image retrieval, etc.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664785","","Algorithm design and analysis;Application software;Data mining;Humans;Image retrieval;Information retrieval;Laboratories;Machine learning;Machine learning algorithms;Semisupervised learning","data mining;learning (artificial intelligence);pattern classification","data classification;data mining;disagreement-based algorithm;labeled training;machine learning;semisupervised learning","","1","","14","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Comparison between document-based, term-based and hybrid partitioning","A. Abusukhon; M. P. Oakes; M. Talib; A. M. Abdalla","School of Computing and Technology, University of Sunderland, UK","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","90","95","Information retrieval (IR) systems for largescale data collections must build an index in order to provide efficient retrieval that meets the userpsilas needs. In distributed IR systems, query response time is affected by the way in which the data collection is partitioned across nodes. There are three types of collection partitioning; document-based partitioning (called the local index), term-based partitioning (called the global index) and hybrid partitioning. In this paper, we compare the three types of partitioning in terms of average query response time for a system with one broker and six other nodes. Our results showed that within our distributed IR system, the document-based and hybrid partitioning outperformed the term-based partitioning. However, unlike Xi et al. , we did not find that hybrid partitioning was any better than document-based partitioning in terms of average query response time.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664324","Document-based;average query response time;experimental comparison;hybrid partitioning;term-based","Computer science;Data structures;Delay;Indexing;Information retrieval;Optical computing","document handling;information retrieval systems;query processing","data collections;document-based partitioning;hybrid partitioning;information retrieval systems;query response time;term-based partitioning","","0","6","16","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"CCPR 2008 Keynote Speech 3 and Keynote Speech 4","Song-Chun Zhu","Dept. of Stat., Univ. of California, Los Angeles, CA","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","1","Firstly, we consider the space of small image patches, say 7times7 pixels, and show that patches cropped from natural images are distributed in a wide variety of manifolds from low dimensional manifolds for regular textons and image primitives, to high dimensional manifolds for textures. Secondly, we introduce a learning and modeling method which pursues these manifolds by information projection, and derive statistical models, such as the active basis model for the low dimensional manifolds and the MRF models for the high dimensional manifolds. Thirdly we show how these two types of manifolds are integrated in large images to form the primal sketch model in early vision, and how they are mixed to form complex objects in the high level vision. Fourthly we show the transition of these manifolds through information scaling. The objective of this work is to study the structures of the image space, based on which we can understand the connections and transitions of a number of classic models used in computer vision and pattern recognition.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.7","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662960","","Biomedical imaging;Computer vision;Image retrieval;Information retrieval;Pattern recognition;Pixel;Speech;Statistical distributions","computer vision;image texture;statistical analysis","MRF models;active basis model;computer vision;image patches;information projection;pattern recognition;primal sketch model;statistical models;visual manifold learning","","0","","","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Documentation accountability: Approval to archiving","D. L. Gordon; J. Heaton","DocuMedia Learning Group, Inc., 300 East 2650 North, North Ogden, Utah 84414, USA","2008 IEEE AUTOTESTCON","20081031","2008","","","128","132","Knowledge management systems (KMSs) are a mature information technology often used to accumulate policies and procedures in an accessible framework. However, the usefulness of a KMS depends on its capabilities and the users: a KMS is only useful if it contains a certain quantity and quality of information. A good KMS can increase information quantity by making documentation processes faster and can increase information quality by ensuring accountability throughout the testing process. This paper illustrates how the KMS, JARIS, can streamline each test phase, from approval to archiving, by reducing paper documentation and increasing information accountability and accessibility.","1088-7725;10887725","CD-ROM:978-1-4244-2226-5; POD:978-1-4244-2225-8","10.1109/AUTEST.2008.4662598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662598","JARIS;KMS;Knowledge Management System;accountability;documentation","Cities and towns;Databases;Documentation;Electronic equipment testing;Information retrieval;Information technology;Jacobian matrices;Knowledge management;Law;System testing","database management systems;document handling;knowledge management;system documentation","documentation accountability;knowledge management systems","","0","","5","","","8-11 Sept. 2008","","IEEE","IEEE Conference Publications"
"Visualization of Current Core Research Groups of Enterprise Risk Management","P. Zhuang; Y. Li; H. Hou; T. Qu","Sch. of Manage., Dalian Univ. of Technol., Dalian","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","310","314","Through methods of visualization, maps of the core research groups of enterprise risk management (1994-2007) are drawn to identify the intellectual structure of current researches in the field of enterprise risk management. This study is based on bibliographic data retrieved from the Web of Science. The maps of the core research groups of enterprise risk management demonstrate the status of and relationships among 157 most cited authors. The present study also discusses the most cited papers of the most influential authors of each group and the main research fields of group representatives such as Porter Michael, Daniel Kahneman, Harry Markowitz, and Fisher Black. These authors have made great contributions to the development of current enterprise risk management, and the research fields of them deserve the attention of other researchers in the field of enterprise risk management.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666404","author co-citation analysis;enterprise risk management;pathfinder network scaling;visualization","Companies;Conference management;Data visualization;Information retrieval;Knowledge management;Risk analysis;Risk management;Software engineering;Software quality;Technology management","commerce;data visualisation;risk management","bibliographic data;current core research groups;data visualization;enterprise risk management;intellectual structure","","0","","13","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Content-Based Semantic Indexing of Image using Fuzzy Support Vector Machines","J. Li; S. Huang; R. He; K. Qian","Sch. of Electron. & Inf. Eng., Dalian Univ. of Technol., Dalian","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","6","With the increasing amount of multimedia data, content-based image retrieval attracts many researchers of various fields in an effort to automate data analysis and indexing. In this paper, we propose a content-based semantic indexing method which annotates images automatically using concepts and textual description. In order to bridge the ""semantic gap"" between the low-level descriptors and the high-level semantic concepts of an image, we introduce a 3-level pyramid and combine the color, texture and edge features for each level. Fuzzy support vector machine (FSVM) is employed for building the concept model and calculates the likelihood of an image to a model. We index the images with concepts according to the likelihood between an image and the concept model. Experiments show that our method has good accuracy in semantic indexing of images.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662988","","Bridges;Content based retrieval;Data analysis;Feature extraction;Histograms;Image retrieval;Image segmentation;Indexing;Information retrieval;Support vector machines","content-based retrieval;database indexing;fuzzy set theory;image colour analysis;image retrieval;image texture;support vector machines","content-based image retrieval;content-based semantic indexing;data analysis;edge feature;fuzzy support vector machine;image color;image texture;semantic image indexing","","0","","10","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Semi-Supervised Learning Based Relevance Feedback Algorithm in Content-Based Image Retrieval","Z. P. Luo; X. M. Zhang","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou","2008 Chinese Conference on Pattern Recognition","20081031","2008","","","1","4","As a useful solution for address the faultage between image features and semanteme, relevance feedback (RF) became an effective approach to boost image retrieval. In supervised-based machine learning algorithm, insufficient Labeled training data and the unlabeled data in one RF circle can not represent scatter of features space for all irrelevant images, such algorithm used for CBIR did not show a high performance. As a research hot point, semi-supervised, it can utilize unlabeled data to estimate model of RF so that boost the retrieval performance. This paper proposed a new algorithm for RF: make use of expectation maximization (EM) to learn RBF function for RBF neutral network, integrated active learning to void a local value EM learned, and reduce iterations of feedback, as a result this algorithm learned a RF model based on RBF. Experience indicated that: compare to EM and Bayes, efficiency of learner is improved, user's query concept is grasped quickly.","","POD:978-1-4244-2316-3","10.1109/CCPR.2008.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662990","","Computer science;Content based retrieval;Feedback;Image retrieval;Information retrieval;Machine learning algorithms;Radio frequency;Scattering;Semisupervised learning;Training data","content-based retrieval;expectation-maximisation algorithm;feature extraction;image retrieval;learning (artificial intelligence);radial basis function networks;relevance feedback","RBF function;RBF neutral network;active learning;content-based image retrieval;expectation maximization algorithm;feature space;image features;machine learning;relevance feedback algorithm;semanteme;semisupervised learning;unlabeled data;user query","","1","","8","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Image annotation with parametric mixture model based multi-class multi-labeling","Zhiyong Wang; W. C. Siu; D. Feng","School of Information Technologies, University of Sydney, Australia","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","634","639","Image annotation, which labels an image with a set of semantic terms so as to bridge the semantic gap between low level features and high level semantics in visual information retrieval, is generally posed as a classification problem. Recently, multi-label classification has been investigated for image annotation since an image presents rich contents and can be associated with multiple concepts (i.e. labels). In this paper, a parametric mixture model based multi-class multi-labeling approach is proposed to tackle image annotation. Instead of building classifiers to learn individual labels exclusively, we model images with parametric mixture models so that the mixture characteristics of labels can be simultaneously exploited in both training and annotation processes. Our proposed method has been benchmarked with several state-of-the-art methods and achieved promising results.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665153","","Bridges;Content based retrieval;Humans;Image retrieval;Information retrieval;Information technology;Ontologies;Shape;Software libraries;Visual perception","content-based retrieval;image classification;image retrieval","content-based image retrieval systems;high level semantic;image annotation;multiclass multilabeling approach;multilabel classification;parametric mixture model;visual information retrieval","","3","","22","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"3-D mesh representation and retrieval using Isomap manifold","Jung-Shiong Chang; A. C. C. Shih; H. Y. Lin; H. F. Kao; 2. Y. M. Liao; W. H. Fang","Department of Electronic Engineering, National Taiwan University of Science and Technology, No 43, Keelung Road, Section 4, Da-an District, Taipei 10607, Taiwan","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","541","546","We propose a compact 3D object representation scheme that can greatly assist the search/retrieval process in a network environment. A 3D mesh-based object is transformed into a new coordinate frame by using the Isomap (isometric feature mapping) method. During the transformation process, not only the structure of the salient parts of an object will be kept, but also the geometrical relationships will be preserved. From the viewpoint of cognitive psychology, the data distributed on the Isomap manifold can be regarded as a set of significant features of a 3D mesh-based object. To perform efficient matching, we project the Isomap domain 3D object onto two different 2D maps, and the two 2D feature descriptors are used as the basis to measure the degree of similarity between two 3D mesh-based objects. Experiments demonstrate that the proposed method in retrieving similar 3D models is very effective. Most importantly, the proposed 3D mesh retrieval scheme is still valid even if a 3D mesh undergoes a mesh simplification process.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665137","","Computer science;Content based retrieval;Feature extraction;Grid computing;Information retrieval;Information science;Internet;Manifolds;Solid modeling;Spatial databases","image matching;image representation;image retrieval;mesh generation;solid modelling","3D mesh representation;3D mesh retrieval;Isomap manifold;cognitive psychology;feature descriptor;isometric feature mapping;object representation;pattern matching","","0","","13","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"Accelerating Video-Mining Applications Using Many Small, General-Purpose Cores","E. Li; W. Li; X. Tong; J. Li; Y. Chen; T. Wang; P. P. Wang; W. Hu; Y. Du; Y. Zhang; Y. K. Chen","Intel","IEEE Micro","20081028","2008","28","5","8","21","Emerging video-mining applications such as image and video retrieval and indexing will require real-time processing capabilities. A many-core architecture with 64 small, in-order, general-purpose cores as the accelerator can help meet the necessary performance goals and requirements. The key video-mining modules can achieve parallel speedups of 19times to 62times from 64 cores and get an extra 2.3times speedup from 128-bit SIMD vectorization on the proposed architecture.","0272-1732;02721732","","10.1109/MM.2008.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4659271","","Acceleration;Bandwidth;Data mining;Image retrieval;Image segmentation;Indexing;Information retrieval;Internet;Surveillance;Yarn","data mining;parallel architectures;video retrieval","SIMD vectorization;accelerator;image indexing;image retrieval;many-core architecture;real-time processing;video indexing;video retrieval;video-mining","","3","","17","","","Sept.-Oct. 2008","","IEEE","IEEE Journals & Magazines"
"Wireless Multimedia Sensor Networks: Applications and Testbeds","I. F. Akyildiz; T. Melodia; K. R. Chowdhury","Sch. of Electr. & Comput. Eng., Georgia Inst. of Technol., Atlanta, GA","Proceedings of the IEEE","20081031","2008","96","10","1588","1605","The availability of low-cost hardware is enabling the development of wireless multimedia sensor networks (WMSNs), i.e., networks of resource-constrained wireless devices that can retrieve multimedia content such as video and audio streams, still images, and scalar sensor data from the environment. In this paper, ongoing research on <i>prototypes</i> <i>of</i> <i>multimedia</i> <i>sensors</i> and their integration into <i>testbeds</i> <i>for</i> <i>experimental</i> <i>evaluation</i> of algorithms and protocols for WMSNs are described. Furthermore, open research issues and future research directions, both at the device level and at the testbed level, are discussed. This paper is intended to be a resource for researchers interested in advancing the state-of-the-art in experimental research on wireless multimedia sensor networks.","0018-9219;00189219","","10.1109/JPROC.2008.928756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4653057","Distributed smart cameras;experimental testbeds;multimedia sensor networks;video sensor networks;wireless sensor networks","Availability;Content based retrieval;Hardware;Image retrieval;Image sensors;Information retrieval;Prototypes;Streaming media;Testing;Wireless sensor networks","multimedia communication;wireless sensor networks","multimedia content retrieval;resource-constrained wireless devices;wireless multimedia sensor networks","","177","1","33","","20081017","Oct. 2008","","IEEE","IEEE Journals & Magazines"
"A Text Network Representation Model","J. Liu; J. Wang; C. Wang","Beijing Univ. of Posts & Telecommun., Beijing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","150","154","Text representation is the basis of text processing. Most current text representation models ignore the words' inter-relations, which result in the loss of textpsilas structure information. This paper proposed a novel text representation model, which uses lexical network to represent the text and retains the text's structure. According to the different levels of words' inter-relations, co-occurrence network, syntactic network and semantic network are introduced. To evaluate the representation ability of text network representation model, we investigated the applications of text network to two language processing tasks including unsupervised keyword extraction and text classification. The experimental results show how to use it for natural language processing successfully.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666374","","Animals;Fuzzy systems;Indexing;Information retrieval;Natural language processing;Natural languages;Neural networks;Singular value decomposition;Text categorization;Text processing","natural language processing;pattern classification;text analysis","co-occurrence network;language processing tasks;lexical network;semantic network;syntactic network;text classification;text network representation model;unsupervised keyword extraction","","0","","15","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Topological Distance Function in Formal Concept Lattice","L. Zhang; S. Gao; L. Qi","Sch. of Sci., Dalian Fisheries Coll., Dalian","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","5","","570","574","As a formalization of the concept analysis and applications, formal concept analysis has been studied for years since early 1980s, the exploration was made by many scholars in different ways, In [12], we introduce the topology structures induced by the concepts for the first time, the relationship between the topological properties and some mathematical properties are indicated. In the present paper, a distance function was defined with the topological structure, some results were given to manifest the concept, We pave a way to explore concept lattice with topological approach.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666589","Concept Lattices;topological distance","Aquaculture;Artificial intelligence;Data analysis;Educational institutions;Fuzzy systems;Information analysis;Information retrieval;Lattices;Relational databases;Topology","data analysis","formal concept analysis;formal concept lattice;topological distance function","","1","","12","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Using nonnegative matrix factorization and concept lattice reduction to visualizing data","V. Snasel; H. M. Dahwa Abdulla; M. Polovincak","Department of Computer Science, VSB - Technical University of Ostrava, Czech Republic","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","296","301","The large volume of data from the large-scale computing platforms for high-fidelity design and simulations, and instrumentation for gathering scientific as well as business data, and huge information in the web, give us some problems if we want to compute all concepts from huge incidence matrix. In some cases, we do not need to compute all concepts, but only some of them. In this paper, we proposed minimizing incidence matrix by using non-negative matrix factorization (NMF), because non-negative matrix factorization (NMF) is an emerging technique with a wide spectrum of potential applications in biomedical data analysis. Modified matrix has lower dimensions and acts as an input for some known algorithms for lattice construction.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664362","Concept lattice;Formal Concept Analysis;Nonnegative Matrix Factorization","Bioinformatics;Data analysis;Data visualization;Displays;Encoding;Information retrieval;Lattices;Matrix decomposition;Sparse matrices;Text mining","data analysis;data visualisation;matrix decomposition;medical computing","biomedical data analysis;concept lattice reduction;data visualization;large scale computing;lattice construction;nonnegative matrix factorization","","0","","21","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"Dynamic chroma feature vectors with applications to cover song identification","S. Kim; S. Narayanan","Signal Anlaysis and Interpretation Lab. (SAIL), University of Southern California, Los Angeles, USA","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","984","987","A new chroma-based dynamic feature vector is proposed inspired by psychophysical observations that the human auditory system detects reltative pitch changes rather than absolute pitch values. The proposed chroma-based dynamic feature vector describes the relative pitch change intervals. The utility of the proposed feature vector incorporated with a music fingerprint extraction algorithm is experimentally explored within a music cover song identification framework. The results with a classical music database suggest that the proposed biologically plausible dynamic chroma feature vector can be successfully added to the conventional chroma feature vector as a complementary feature; it provides a 5.8% relative performance improvement.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665217","","Auditory system;Change detection algorithms;Fingerprint recognition;Frequency;Humans;Multiple signal classification;Music information retrieval;Psychology;Signal processing;Spatial databases","audio databases;feature extraction;fingerprint identification;hearing;music","absolute pitch values;biologically plausible dynamic chroma feature vector;classical music database;dynamic chroma feature vectors;human auditory system;music cover song identification framework;music fingerprint extraction algorithm;psychophysical observations;relative pitch changes","","7","1","8","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Novel Approach to Naive Bayes Web Page Automatic Classification","Z. He; Z. Liu","Sch. of Comput. Sci. & Technol., Xidian Univ., Xian","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","361","365","In this paper, a novel approach of Web page classification using Naive Bayes (NB) classifier based on independent component analysis (ICA) is proposed. In order to perform the classification, a Web page is firstly represented by a vector of features with different weights, and the weight calculated method is improved. As the number of the features is big, principal component analysis (PCA) which is to select the relevant features will perform in preprocessing section as input for improved ICA algorithm (MFICA). Finally, the output of MFICA is sent to NB classifier for classification to boost the classifierpsilas performance. The experimental evaluation demonstrates that the NB classifier based on ICA model provides acceptable classification accuracy.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.284","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666139","","Data mining;Fuzzy systems;Independent component analysis;Information retrieval;Internet;Neural networks;Niobium;Principal component analysis;Signal processing algorithms;Web pages","Bayes methods;Web sites;independent component analysis;information analysis;principal component analysis","Naive Bayes classifier;Web page automatic classification;independent component analysis;principal component analysis","","2","","12","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Refining Image Annotation Based on Object-Based Semantic Concept Capturing and WordNet Ontology","L. Zheng; M. Jun","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","96","100","This paper presents a novel approach to automatically refining the original annotations of images. An existing image annotation method is used to obtain the candidate annotations for an image in advance. Then, low-level features are extracted automatically from all blocks in the image to construct a suitable multi-feature space. Next, the image is divided into nonoverlapping block-based structures and a block-based structure clustering algorithm to capture the semantic concept of object as accepted annotations is proposed. Based on these accepted annotations, the irrelevant annotations are pruned according to the semantic similarity in WordNet. Experimental results on the typical Corel dataset show that the approach outperforms the existing image annotation refining techniques.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666364","Content-based Image Retrieval;Corel Dataset;Image Annotation;Multi-feature Space;WordNet","Clustering algorithms;Computer science;Content based retrieval;Feature extraction;Fuzzy systems;Humans;Image analysis;Image retrieval;Information retrieval;Ontologies","content-based retrieval;feature extraction;image retrieval;natural language processing;pattern clustering","Corel dataset;WordNet ontology;block-based structure clustering;content-based image retrieval;feature extraction;image annotation refinement;object-based semantic concept capturing;semantic similarity","","0","","9","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Dynamic On-Line Updating Solution for CURE Cubes","L. Zhang; X. g. Hong","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","5","","396","400","CURE is an efficient ROLAP algorithm both on construction time and utility of storage. A new updating method for cubes generated by CURE, dynamic on-line updating solution (DOLUS) is presented here in which dynamic means updating cubes incrementally and on-line guarantees concurrent of updating and query answering except the period of incremental construction in memory. DOLUS takes advantage of original CURE and brings in new writing strategies. After being updated by DOLUS, cubes appear a little different from the original CURE ones, as trivial tuples and common aggregate tuples become less and normal tuples become more. However, the query answering time is at least the same or less. Those are the result of performance tradeoff between query-optimize and storage-optimize.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666557","CURE;Cube;DOLUS;Update","Aggregates;Cats;Computer science;Data warehouses;Databases;Fuzzy systems;Information retrieval;Multidimensional systems;Speech synthesis;Writing","data mining;data warehouses;query processing","CURE cubes;ROLAP algorithm;common aggregate tuples;dynamic online updating solution;normal tuples;online analytical processing;query answering;trivial tuples","","0","","11","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Variation Characteristics of Aerosol Optical Depth at 14 Meteorological Observatories over China during 1961-2005","X. Xu; S. Niu; J. Qiu","Nanjing Univ. of Inf. Sci. & Technol., Nanjing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","5","","665","668","A new method of retrieving aerosol optical depth (AOD) was proposed using daily global and diffuse radiative insolations. After a comparison with daily AOD products of AERONET, it shows that the correlation coefficient between the two AODs exceeded 0.95, and the mean bias error was less than 0.03. Using this retrieval method, AODs at 0.55mum were obtained at 14 meteorological observatories over China during 1961-2005. The analysis shows that, as to the average AOD for all the 14 stations of the 45 years, the mean value is 0.40 and its annual increment is 0.005. As to the seasonal average values, the AODs from high to low occur in order of spring (0.45), summer (0.43), winter (0.37) and autumn (0.34), separately. Over the 14 observatories, the stations of Chengdu in Sichuan Basin has the fastest AOD increasing speed of 0.01 per year, while AODs at Kashi and Geermu station show a slightly downward trend.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666608","aerosol optical depth;diffuse solar radiation;global solar radiation","Aerosols;Information retrieval;Information science;Meteorology;NASA;Observatories;Optical sensors;Pollution measurement;Remote sensing;Solar radiation","aerosols;climate mitigation;environmental science computing;information retrieval;meteorology","AERONET;aerosol optical depth;diffuse radiative insolations;meteorological observatories","","0","","11","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Securing coding based distributed storage in wireless sensor networks","L. Buttyan; L. Czap; I. Vajda","Budapest University of Technology and Economics, Laboratory of Cryptography and Systems Security (CrySyS), Hungary","2008 5th IEEE International Conference on Mobile Ad Hoc and Sensor Systems","20081028","2008","","","821","827","We address the problem of pollution attacks in coding based distributed storage systems proposed for wireless sensor networks. In a pollution attack, the adversary maliciously alters some of the stored encoded packets, which results in the incorrect decoding of a large part of the original data upon retrieval. We propose algorithms to detect and recover from such attacks. In contrast to existing approaches to solve this problem, our approach is not based on adding cryptographic checksums or signatures to the encoded packets. We believe that our proposed algorithms are suitable in practical systems.","2155-6806;21556806","POD:978-1-4244-2574-7","10.1109/MAHSS.2008.4660132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4660132","","Decoding;Digital signatures;Elliptic curve cryptography;Information retrieval;Network coding;Pollution;Public key cryptography;Redundancy;Secure storage;Wireless sensor networks","decoding;encoding;security of data;telecommunication security;wireless sensor networks","distributed storage system;pollution attack;secured coding;stored encoded packet;wireless sensor network","","3","","12","","","Sept. 29 2008-Oct. 2 2008","","IEEE","IEEE Conference Publications"
"Performing operations on graph through multimodal interface: An agent based architecture","N. S. Sreekanth; S. N. Pal; K. G. Girish; A. Arunjith; N. K. Narayanan","C-DAC Bangalore, 68 Electronic City, India","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","74","77","In this paper we discuss about agent based multimodal interface architecture. To illustrate this concept, we present an application to mine information from a graph data structure. This application can be used as a user friendly interface for mining information where graph can be used as data structure for information storage. The application recognizes the gestures, text based input, speech and combination of all of these. Here the various input modalities are implemented as software agents which are independent of each other. There exist MONITOR agents which will synchronize various inputs from the user and act according to it. Users response will be mapped to system vocabulary space with help of a semantic analyzer and results will be passed to MONITOR for further processing.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664321","","Application software;Automatic speech recognition;Computer interfaces;Costs;Data structures;Humans;Information retrieval;Monitoring;Speech recognition;User interfaces","data mining;data structures;gesture recognition;graph theory;mathematics computing;speech recognition;text analysis","agent based architecture;gesture recognition;graph data structure;graph operations;information mining;information storage;multimodal interface architecture;speech recognition;text based input;user friendly interface","","0","","6","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"A Practical Approach for Relevance Measure of Inter-sentence","M. Zhong; Y. Hu; L. Liu; R. Lu","Dept. of Compute Sci. & Eng., Shanghai Jiaotong Univ., Shanghai","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","140","144","Many natural language processing tasks, such as text classification, text clustering, text summarization, and information retrieval etc., cannot miss the step-relevance measure of inter-sentence. However, many of the current NLP system always calculate not the inter-sentence relevance but their similarity. In fact, similarity means differently from relevance. The similarity measure can be acquired by comparing the exterior tokens of inter-sentences, but relevance measure can be obtained only by comparing the interior meaning of the sentences. In this paper, we described a method to explore the quantified conceptual relations of word-pairs by using the definition of a lexical item in modern Chinese standard dictionary, and proposed a practical approach to measure the inter-sentence relevance. The results of the examples show that our approach can solve the problem of how to measure the relevance of two sentences without (or very low) similarity but with a certain relevance. This method is also compatible with the current cosine similarity method.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666372","Natural Language Processing;Quantified Conceptual Relations;Relevance Measure;inter-sentence relevance","Data mining;Dictionaries;Fuzzy systems;Information analysis;Information retrieval;Knowledge engineering;Measurement standards;Mutual information;Natural language processing;Text categorization","natural language processing","cosine similarity method;intersentence relevance measure;natural language processing;quantified conceptual relations;similarity measure","","3","","15","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"An efficient anti-collision algorithm through division transfer of tag ID in RFID systems","Seong Joon Lee; Young Tae Kim; SungSoo Kim; Y. S. Park; YongHwan Kim; Kwang Seon Ahn","Department of Computer Engineering, Kyungpook National University, Daegu, Korea","2008 33rd IEEE Conference on Local Computer Networks (LCN)","20081031","2008","","","574","575","With the wide adoption of radio frequency identification (RFID) system, one of important issues is the anti-collision problem. This means that the reader should be identified all tags within the same range, efficiently, fast. Generally, the tree-based protocols should make the unique ID from the request from the reader and the response from tags. In the result, the traditional methods need the number of considerable query. In this paper, we, on the environment making IDs from the rest of bits except the specified fields of EPC Class 1 Gen. 2 for the similar circumstances that we can easily look at real environment, propose the BSCTTA based method to reduce the number of query.","0742-1303;07421303","CD-ROM:978-1-4244-2413-9; POD:978-1-4244-2412-2","10.1109/LCN.2008.4664243","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664243","Binary Tree;EPC Class1 Generation 2;RFID;anti-collision","Binary trees;Broadcasting;Classification tree analysis;Data mining;Information retrieval;Intrusion detection;Protocols;RFID tags;Radio frequency;Radiofrequency identification","protocols;radiofrequency identification","BSCTTA based method;RFID systems;anticollision algorithm;division transfer;radiofrequency identification system;tag identification;tree-based protocols","","0","","8","","","14-17 Oct. 2008","","IEEE","IEEE Conference Publications"
"A text segmentation based approach to video shot boundary detection","Duy-Dinh Le; Shin'ichi Satoh; Thanh Duc Ngo; Duc Anh Duong","National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Japan 101-8430","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","702","706","Video shot boundary detection is one of the fundamental tasks of video indexing and retrieval applications. Although many methods have been proposed for this task, finding a general and robust shot boundary method that is able to handle the various transition types caused by photo flashes, rapid camera movement and object movement is still challenging. We present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing. This is possible by assuming that each frame is a word and then the shot boundaries are treated as text segment boundaries (e.g. topics). The text segmentation based approaches in natural language processing can be used. The experimental results from various long video sequences have proved the effectiveness of our approach.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665166","","Cameras;Cities and towns;Gunshot detection systems;Indexing;Informatics;Information retrieval;Information technology;Natural language processing;Robustness;Video sequences","image segmentation;image sequences;natural language processing;signal detection;video retrieval","camera movement;natural language processing;object movement;photo flashes;text segmentation based approach;video indexing;video retrieval;video sequences;video shot boundary detection","","1","","10","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"Formal concept analysis in relational contexts","Feng Jiang; Youxin Meng; Yun Liu","College of Information and Science Technology, Qingdao University of Science and Technology, 69#, Songling Road, Laoshan District, Shandong, 266061, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","326","329","Formal concept analysis (FCA) is a method mainly used for the analysis of data, which identifies conceptual structures among data sets. Central to FCA is the notion of formal context. A formal context is usually defined as a binary relation between a set of objects and a set of attributes. But in real world, it is more meaningful to consider the direct relations between objects (or individuals). In this paper, in order to model those relations between individuals in real world, we shall propose a different kind of context - relational context for FCA, which contains a universe U of objects and a binary relation r on U. The definitions of relational concepts in relational contexts and the basic properties about relational contexts and relational concepts are also given.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664730","Formal concept analysis;relational concepts;relational contexts","Context modeling;Data analysis;Data engineering;Data mining;Educational institutions;Information analysis;Information retrieval;Lattices;Relational databases;Rough sets","data analysis;relational databases","conceptual structures;data analysis;formal concept analysis;formal context;relational concepts;relational contexts","","1","","10","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Fine Text Categorization: Using Very Aggressive Feature Selection to Cope with Mass Duplicated Features","L. Dai; J. Hu; S. Wu","Sch. of Comput. Sci., Beijing Inst. of Technol., Beijing","2008 International Conference on Intelligent Computation Technology and Automation (ICICTA)","20081028","2008","2","","984","988","Text categorization is a key issue of text mining. Although there are many studies on this problem, the majority of them are focused on classification of rough categories. In this kind of problem, there are obviously different features that can differentiate one category from others. Only very few researches concerned fine text categorization (FTC) problem which is characterized by many duplicated features across different categories. In this paper, we firstly pointed out that traditional feature selection levels canpsilat be directly used to cope with this problem. In order to improve performance, we performed very aggressive feature selection (VAFS) by firstly removing the common features arbitrarily, and then selecting features with modified CHI-square statistic in a very aggressive manner. At last, Only very few features are used to learnt the underlying concepts of categories. Experimental results shows that VAFS improves performance notabely and rule based algorithms are more suitable than vector based algorithms.","","POD:978-0-7695-3357-5","10.1109/ICICTA.2008.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4659910","SVM;feature selection;fine text categorization;kNN;rough set","Automation;Information retrieval;Information technology;Laboratories;Machine learning algorithms;Partial response channels;Support vector machine classification;Support vector machines;Text categorization;Text mining","data mining;knowledge based systems;statistical analysis;text analysis","aggressive feature selection;fine text categorization;mass duplicated features;rough categories;rule based algorithms;text mining","","0","","15","","","20-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Retrieval Model Based on Bayesian Network for XML Documents","X. Zhang; X. Heng","Comput. Center, Zhangzhou Normal Univ., Zhangzhou","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","91","95","Most recent document standards like XML urge Information Retrieval to design and implement systems to index, retrieve and present documents according to the given document structure. We present a Bayesian model for XML document retrieval. This model is based on Bayesian networks that enable to represent and quantify the relations between the structural components of the document and whose conditional probabilities are learnt from a labeled collection of structured documents - which is composed of documents, queries and their associated assessments. It allows us to focus on free SO (structure only) queries and obtain the relevance of a document to a given structural query by means of an inference process through a complex network of dependences. Some preliminary results on the system implementation are also presented.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666086","Bayesian Network;XML document;structural Retrieval","Bayesian methods;Complex networks;Computer networks;Fuzzy systems;Information retrieval;Network topology;Probability distribution;Standards development;Testing;XML","XML;belief networks;inference mechanisms;query processing","Bayesian network;XML documents;free structure only queries;inference process;retrieval model","","0","","14","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"JCAM: The Joined Clustered Access Method","A. Sleit; W. AlMobaideen; M. Smadi; M. Qatawneh","Department of Computer Science, King Abdulla II School for Information Technology, University of Jordan, Amman, Jordan","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","281","288","Spatial data management has been an active area of intensive research for more than two decades. In order to support objects in a database system, several issues should be taken into consideration including indexing and efficient query processing. Several indexing techniques have been proposed in the literature. Most of the existing indexing mechanisms are designed for spatial selection but may not be efficient for join operations. In this paper, a new structure is proposed to handle join operations between spatial data sets, called the joined clustered access method (JCAM). JCAM is pre-joined index dedicated for answering spatial join queries designed to enhance the response time of spatial join queries by decreasing the number of disk accesses. JCAM is a secondary index used to represent relationships between data sets as a colored-graph. Experiments show that JCAM outperforms the RTJ algorithm which is based on R-tree but requires more construction time.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664360","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664360","Spatial databases;indexing;query processing;spatial join","Computer science;Database systems;Geographic Information Systems;Indexing;Information retrieval;Information technology;Query processing;Spatial databases;Spatial indexes;Technology management","database indexing;graph colouring;query processing;trees (mathematics);visual databases","R-tree algorithm;colored-graph;database system;disk accesses;indexing techniques;joined clustered access method;query processing;spatial data management","","0","","19","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"SPSA based feature relevance estimation for video retrieval","S. Velusamy; S. Bhatnagar; S. V. Basavaraja; V. Sridhar","Applied Research Group, Satyam Computer Services Limited, Indian Institute of Science, Bangalore, India 560012","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","598","603","With the availability of a huge amount of video data on various sources, efficient video retrieval tools are increasingly in demand. Video being a multi-modal data, the perceptions of ldquorelevancerdquo between the user provided query video (in case of Query-By-Example type of video search) and retrieved video clips are subjective in nature. We present an efficient video retrieval method that takes userpsilas feedback on the relevance of retrieved videos and iteratively reformulates the input query feature vectors (QFV) for improved video retrieval. The QFV reformulation is done by a simple, but powerful feature weight optimization method based on Simultaneous Perturbation Stochastic Approximation (SPSA) technique. A video retrieval system with video indexing, searching and relevance feedback (RF) phases is built for demonstrating the performance of the proposed method. The query and database videos are indexed using the conventional video features like color, texture, etc. However, we use the comprehensive and novel methods of feature representations, and a spatio-temporal distance measure to retrieve the top M videos that are similar to the query. In feedback phase, the user activated iterative on the previously retrieved videos is used to reformulate the QFV weights (measure of importance) that reflect the userpsilas preference, automatically. It is our observation that a few iterations of such feedback are generally sufficient for retrieving the desired video clips. The novel application of SPSA based RF for user-oriented feature weights optimization makes the proposed method to be distinct from the existing ones. The experimental results show that the proposed RF based video retrieval exhibit good performance.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665147","","Content based retrieval;Feedback;Indexing;Information retrieval;Machine learning;Optimization methods;Radio frequency;Spatial databases;Visual databases;Weight measurement","approximation theory;feature extraction;iterative methods;optimisation;query processing;relevance feedback;stochastic processes;video retrieval;video signal processing","feature relevance estimation;feature weight optimization;iterative reformulation;query feature vector;relevance feedback;simultaneous perturbation stochastic approximation;user feedback;video indexing;video retrieval system;video searching","","1","","21","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"Study on Topic Evolution Based on Text Mining","J. Wang; X. Geng; K. Gao; L. Li","Sch. of Comput. Eng., Qingdao Technol. Univ., Qingdao","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","509","513","With the development of digital library technology, there are a variety of digital literatures in our life. It is very important to analyze these text for understanding topic evolution. And it is very valuable for the research work and helpful for researchers. This paper investigates this problem, and tries to use text mining technology for studying it. First, we summarize the related works, indicate their weakness, then propose the method for this problem, and present new framework and steps for this problem. Finally, the paper is summarized and some future works are also pointed out.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.417","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666169","","Citation analysis;Civil engineering;Data mining;Explosions;Fuzzy systems;Information retrieval;Knowledge engineering;Software libraries;Text mining;Writing","data mining;digital libraries;text analysis","digital library technology;digital literatures;text mining;topic evolution","","1","","28","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Measuring Taxonomic Similarity between Words Using Restrictive Context Matrices","S. Wang; C. Cao; Y. n. Cao; H. Lu; X. Cao","Key Lab. of Intell. Inf. Process., Chinese Acad. of Sci., Beijing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","4","","193","197","Measuring taxonomic similarity between words plays an important role in many semantic-based applications but still remains a challenging task today. We propose a new method which utilizes restrictive context matrices for this problem. We learn a set of special lexico-syntactic patterns automatically and use them to extract taxonomic related contexts of words from raw text. These restrictive contexts are then transformed into real matrices and similarities between them are calculated to reflect the taxonomic similarities between words. The main contribution of our work is that taxonomic related context of words can be mined, evaluated, and used to measure taxonomic similarities between words. Experimental results on Miller-Charles benchmark dataset achieve a correlation coefficient of 0.856.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666382","restrictive context matrices;taxonomic similarity;text mining","Fuzzy systems;Information processing;Information retrieval;Laboratories;Machine learning;Natural language processing;Ontologies;Robustness;Thesauri;Web search","matrix algebra;word processing","correlation coefficient;lexico-syntactic patterns;restrictive context matrices;taxonomic similarity;words","","0","","17","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Text Classification Based on a Novel Bayesian Hierarchical Model","S. Zhou; K. Li; Y. Liu","Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing","2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery","20081105","2008","2","","218","221","In the text literature, many Bayesian generative models were proposed to represent documents and words in order to process text effectively and accurately. As the most popular one of these models, Latent Dirichlet Allocation Model(LDA) did great job in dimensionality reduction for document classification. In this paper, inspiring by latent Dirichlet allocation model, we propose LDCM or latent Dirichlet category model for text classification rather than dimensionality reduction. LDCM estimate parameters of models by variational inference and use variational parameters to estimate maximum a posteriori of terms. As demonstrated by our experimental results, we report satisfactory categorization performances about our method on various real-world text documents.","","POD:978-0-7695-3305-6","10.1109/FSKD.2008.666","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666111","","Bayesian methods;Computational efficiency;Computer science;Fuzzy systems;Indexing;Information retrieval;Large scale integration;Linear discriminant analysis;Parameter estimation;Text categorization","Bayes methods;data reduction;inference mechanisms;maximum likelihood estimation;pattern classification;text analysis","Bayesian hierarchical generative model;dimensionality reduction;latent Dirichlet allocation model;latent Dirichlet category model;maximum a posteriori estimation;parameter estimation;text classification;text document representation;text processing;variational inference approach","","0","","12","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Scene classification based on rough set method features selection for outdoor images","Q. p. Zeng; S. x. Wu; M. w. Wang","School of Information Engineering, NanChang University, 330031, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","768","771","Scene classification is valuable in image retrieval from databases because an understanding of the scene content can be used for efficient and effective database organization and browsing. a scene classification based on rough set method features selection for outdoor images is developed in this paper, support vector machines and k-nearest neighbors classification model are used, experiments on University of Massachusetts image segmentation database shows that based on rough set method features selection can improve the scene classification performance for outdoor images.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664677","","Content based retrieval;Data engineering;Image databases;Image retrieval;Image segmentation;Information retrieval;Layout;Spatial databases;Support vector machine classification;Support vector machines","feature extraction;image classification;image segmentation;rough set theory;support vector machines;visual databases","University of Massachusetts;database browsing;database organization;image retrieval;image segmentation database;k-nearest neighbors classification model;outdoor images;rough set method feature selection;scene classification;support vector machines","","0","","15","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Large-Scale Data Reengineering: Return from Experience","J. Henrard; D. Roland; A. Cleve; J. L. Hainaut","ReveR S.A., Charleroi","2008 15th Working Conference on Reverse Engineering","20081024","2008","","","305","308","This paper reports on a recent data reengineering project, the goal of which was to migrate a large CODASYL database towards a relational platform. The legacy system, made of one million lines of COBOL code, is in use in a Belgian federal administration. The approach followed combines program transformation, data reverse engineering, data analysis, wrapping and code generation techniques.","1095-1350;10951350","POD:978-0-7695-3429-9","10.1109/WCRE.2008.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4656423","Data reengineering;Data reverse engineering;Program transformation;System migration;Wrapping","Data analysis;Industrial relations;Information retrieval;Intrusion detection;Large-scale systems;Relational databases;Reverse engineering;Wrapping","COBOL;data analysis;program compilers;relational databases;reverse engineering","Belgian federal administration;COBOL code;CODASYL database;code generation;data analysis;data reverse engineering;data wrapping;large-scale data reengineering;program transformation;relational platform","","2","","6","","","15-18 Oct. 2008","","IEEE","IEEE Conference Publications"
"Research on mixture language model-based document clustering","J. Wen; Z. Li","Computer School, National University of Defence Technology, Changsha, 410073 China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","649","652","Language modeling with semantic smoothing is proposed as an effective way to improve the quality of document clustering. However, the existing semantic smoothing model is not effective for partitional clustering because it can not assign fit weight to ldquogeneralrdquo word in a collection. In this paper, inspired by mixture probability model, we put forward a mixture language model for document clustering. The new model can alleviate the effect of ldquogeneralrdquo word, simultaneously, it can integrate the context information and solve the polysemy problems in a document. Based the new model, an EM algorithm for partitional clustering is present. The experimental results show our algorithms are more effective than the previous methods to improve the cluster quality.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664755","","Clustering algorithms;Clustering methods;Context modeling;Frequency;Information retrieval;Partitioning algorithms;Probability;Smoothing methods;Vocabulary","document handling;natural language processing","cluster quality;context information;language modeling;mixture language model-based document clustering;mixture probability model;partitional clustering;polysemy problems;semantic smoothing model","","0","","9","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Highlight scene extraction of sports broadcasts using sports news programs","Yoshiaki Itoh; Shigenobu Sakaki; Kazunori Kojima; Masaaki Ishigame","Faculty of Software and Information Science, Iwate Prefectural University, Sugo 152-52, Takizawa, 020-0193, Japan","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","646","649","This paper proposes a new approach for extracting highlight scenes from sports broadcasts by using sports news programs. In order to extract the highlight scenes from sports broadcasts without fail, we use sports news programs and identify identical or similar sections between sports broadcasts and sports news programs that cover the sports broadcasts. To extract identical or similar sections between two video data sets efficiently, we developed a two-step method that combines relay-CDP and active-search. We evaluated this method from the standpoint of the extraction accuracy of the highlight scenes, and computation time, through experiments using actual broadcast data sets.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665155","","Acoustics;Data mining;Information retrieval;Information science;Layout;Multimedia communication;Relays;Speech;TV broadcasting;Watches","digital video broadcasting;feature extraction","highlight scene extraction;sports broadcasts;sports news programs","","0","","6","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"Rich representation and ranking for photographic image retrieval in ImageCLEF 2007","S. Gao; J. P. Chevallet; J. H. Lim","IPAL French-Singaporean Joint Lab, Institute for Infocomm Research, Singapore 119613","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","553","557","The task of ad hoc photographic image retrieval in ImageCLEF 2007 international benchmark is to retrieve relevant images in the database to the user query formulated as keywords and image examples. This paper presents rich representation and indexing technologies exploited in our system that participated in ImageCLEF 2007. It uses diverse visual content representation, text representation, pseudo-relevance feedback and fusion, which make our system, with mean average precision 0.2833, in the 4th place among 457 automatic runs submitted from 20 participants to photographic ImageCLEF 2007 and in the 2nd place in terms of participants. Our systematic analysis in the paper demonstrates that 1) combing diverse low-level visual features and ranking technologies significantly improves the content-based image retrieval (CBIR) system; 2) cross-modality pseudo-relevance feedback improves the system performance; and 3) fusion of CBIR and TBIR outperforms individual modality based system.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665139","","Content based retrieval;Feedback;Image analysis;Image databases;Image retrieval;Indexing;Information retrieval;Paper technology;Performance analysis;Visual databases","image representation;image retrieval","ImageCLEF 2007 international benchmark;ad hoc photographic image retrieval;content- based image retrieval system;cross-modality pseudo-relevance feedback;diverse visual content representation;text representation","","0","","13","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"APA Labs: An experimental web-based platform for the retrieval and analysis of news articles","W. Kienreich; E. Lex; C. Seifert","Know-Center, Competence Center for Knowledge-Based Applications and Systems, Austria","2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)","20081031","2008","","","58","62","In this paper, we present APA Labs, an experimental, Web-based platform supporting retrieval and analysis in the news archives of the Austrian Press Agency. APA Labs has been designed as a combination of a rich internet application with a modular system of interactive visualizations backed by server-side entity extraction and three-dimensional rendering capability. This paper outlines concepts and implementation details of APA Labs and presents several visualization modules based on research results from the field of Information and Knowledge visualization.","","CD-ROM:978-1-4244-2624-9; POD:978-1-4244-2623-2","10.1109/ICADIWT.2008.4664318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664318","","Business;Data mining;Information analysis;Information retrieval;Internet;Natural languages;Testing;User interfaces;Visualization;Web sites","Web services;information analysis;information retrieval","3D rendering;APA Labs;Austrian Press Agency;Internet;Web services;information analysis;information retrieval;news articles;server-side entity extraction","","2","","15","","","4-6 Aug. 2008","","IEEE","IEEE Conference Publications"
"Blind SNR estimation with empirical characteristic function’s derivative in high-order modulation system","Zhijiang Xu; Kang Wang; Jingyu Hua; Guomin Zhong","College of Information Technology, Zhejiang University of Technology, Hangzhou, China","2008 International Conference on Communications, Circuits and Systems","20081024","2008","","","242","245","In order to retrieve the pre-estimated information from the received signals, it is necessary to estimate the variance of AWGN channel during the initialization of Turbo iterative decoder. Some literature has been devoted to this problem in BPSK/8PSK scenarios, and in this paper, we present another low-complexity blind SNR estimation method based on empirical characteristic functionpsilas derivative. It proves to be effective for both MPSK and MQAM, which alternatively provides a good un-biased estimation at receiver even without the knowledge of modulation type, as we can see in the simulations.","","CD-ROM:978-1-4244-2064-3; POD:978-1-4244-2063-6","10.1109/ICCCAS.2008.4657768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4657768","","AWGN channels;Additive white noise;Algorithm design and analysis;Educational institutions;Educational technology;Gaussian noise;Information retrieval;Iterative decoding;Parity check codes;Signal to noise ratio","AWGN channels;decoding;phase shift keying;quadrature amplitude modulation;turbo codes","AWGN channel;BPSK-8PSK;MPSK;MQAM;Turbo iterative decoder;blind SNR estimation;empirical characteristic function derivative;high-order modulation system;signal to noise ratio","","0","","5","","","25-27 May 2008","","IEEE","IEEE Conference Publications"
"Cost and accuracy sensitive dynamic workflow composition over grid environments","D. Chiu; S. Deshpande; G. Agrawal; Rongxing Li","Department of Computer Science and Engineering, The Ohio State University, Columbus, 43210, USA","2008 9th IEEE/ACM International Conference on Grid Computing","20081031","2008","","","9","16","A myriad of recent activities can be seen towards dynamic workflow composition for processing complex and data intensive problems. Meanwhile, the simultaneous emergence of the grid has marked a compelling movement towards making datasets and services available for ubiquitous access. This development provides new challenges for workflow systems, including heterogeneous data repositories and high processing and access times. But beside these problems lie opportunities for exploration: The gridpsilas magnitude offers many paths towards deriving essentially the same information albeit varying execution times and errors. We discuss a framework for incorporating QoS in a dynamic workflow composition system in a geospatial context. Specific contributions include a novel workflow composition algorithm which employs QoS-aware apriori pruning and an accuracy adjustment scheme to flexibly adapt workflows to given time restrictions. A performance evaluation of our system suggests that our pruning mechanism provides significant efficiency towards workflow composition and that our accuracy adjustment scheme adapts gracefully to time and network limitations.","2152-1085;21521085","CD-ROM:978-1-4244-2579-2; POD:978-1-4244-2578-5","10.1109/GRID.2008.4662777","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4662777","","Computer science;Costs;Data engineering;Delay;Grid computing;Information retrieval;Processor scheduling;Propulsion;Sampling methods;Workflow management software","geophysics computing;grid computing;quality of service;ubiquitous computing;workflow management software","QoS-aware apriori pruning;accuracy adjustment scheme;data intensive problem;dynamic workflow composition system;geospatial context;grid environment;heterogeneous data repository;ubiquitous access","","5","","20","","","Sept. 29 2008-Oct. 1 2008","","IEEE","IEEE Conference Publications"
"Classification of image databases using face detection","S. Sergyan","Budapest Tech/John von Neumann Faculty of Informatics, Hungary","2008 6th International Symposium on Intelligent Systems and Informatics","20081105","2008","","","1","4","During image retrieval in image databases the indexing technique can be used on many ways. The two most frequently used methods are the text-based and the content-based indexing. In case of content-based image retrieval the image classification is significant, and after the classification process the image retrieval can be much efficient than without classification. A possible way of image classification is the decision of that, the image contains human faces or not. In this paper a survey of the recently used face detection algorithms, and a comparative analysis of that is shown. The effectiveness of face detection algorithms in image classification also is shown.","1949-047X;1949047X","POD:978-1-4244-2406-1","10.1109/SISY.2008.4664960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664960","","Algorithm design and analysis;Classification algorithms;Content based retrieval;Face detection;Humans;Image classification;Image databases;Image retrieval;Indexing;Information retrieval","face recognition;image classification;text analysis;visual databases","content-based indexing;face detection;image database classification;image retrieval;indexing technique;text-based methods","","0","","10","","","26-27 Sept. 2008","","IEEE","IEEE Conference Publications"
"Music emotion annotation by machine learning","Wai Ling Cheung; Guojun Lu","Gippsland School of Information Technology, Monash University, Churchill, Victoria 3842, Australia","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","580","585","Music emotion annotation is a task of attaching emotional terms to musical works. As volume of online musical contents expands rapidly in recent years, demands for retrieval by emotion are emerging. Currently, literature on music retrieval using emotional terms is rare. Emotion annotated data are scarce in existing music databases because annotation is still a manual task. Automating music emotion annotation is an essential prerequisite to research in music retrieval by emotion, for without which even sophisticated retrieval methods may not be very useful in a data deficient environment. This paper describes a machine learning approach to annotate music using a large number of emotional terms. We also estimate the training data size requirements for a workable annotation system. Our empirical result shows that 1) the task of music emotion annotation could be modelled using machine learning techniques to support a large number of emotional terms, 2) the combination of sampling method and data-driven detection threshold is highly effective in optimizing the use of existing annotated data in training machine learning models, 3) synonymous relationships enhance the annotation performance and 4) the training data size requirement is within reach for a workable annotation system. Essentially, automatic music emotion annotation enables music retrieval by emotion to be performed as a text retrieval task.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665144","","Australia;Content based retrieval;Databases;Humans;Information technology;Joining processes;Machine learning;Mood;Music information retrieval;Training data","emotion recognition;information retrieval;information retrieval systems;learning (artificial intelligence);music;sampling methods","automatic music emotion annotation system;data-driven detection threshold;machine learning;music database;music retrieval;sampling method;synonymous relationship;text retrieval","","2","","24","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
