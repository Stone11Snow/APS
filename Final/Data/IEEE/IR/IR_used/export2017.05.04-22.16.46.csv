"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6984803,6983838,6981121,6982459,6980994,6982520,6982839,6982909,6984805,6984699,6982456,6980784,6983270,6981053,6982906,6984921,6980905,6982086,6982093,6978948,6981151,6978945,6976325,6976151,6976081,6976108,6976074,6975949,6977239,6975444,6978183,6977236,6975437,6975552,6976691,6978189,6976134,6976153,6976072,6977350,6970191,6974095,6973510,6928922,6973950,6970149,6974831,6969964,6970178,6970146,6973498,6974089,6973666,6973507,6973743,6970144,6974849,6970204,6974856,6972272,6973889,6928952,6973732,6970239,6970182,6974151,6970187,6970200,6970746,6970207,6973960,6970225,6974629,6970208,6970161,6972365,6968553,6968582,6913414,6967187,6967179,6913366,6968484,6968370,6913323,6913322,6913431,6913415,6968434,6913391,6968531,6913407,6968172,6968206,6913356,6968574,6965175,6965078,6965220,6965062",2017/05/04 22:16:46
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"ICFHR 2014 Competition on Handwritten Keyword Spotting (H-KWS 2014)","I. Pratikakis; K. Zagoris; B. Gatos; G. Louloudis; N. Stamatopoulos","Dept. of Electr. & Comput. Eng., Democritus Univ. of Thrace, Xanthi, Greece","2014 14th International Conference on Frontiers in Handwriting Recognition","20141215","2014","","","814","819","H-KWS 2014 is the Handwritten Keyword Spotting Competition organized in conjunction with ICFHR 2014 conference. The main objective of the competition is to record current advances in keyword spotting algorithms using established performance evaluation measures frequently encountered in the information retrieval literature. The competition comprises two distinct tracks, namely, a segmentation-based and a segmentation-free track. Five (5) distinct research groups have participated in the competition with three (3) methods for the segmentation-based track and four (4) methods for the segmentation-free track. The benchmarking datasets that were used in the contest contain both historical and modern documents from multiple writers. In this paper, the contest details are reported including the evaluation measures and the performance of the submitted methods along with a short description of each method.","2167-6445;21676445","Electronic:978-1-4799-4334-0; POD:978-1-4799-7892-2; USB:978-1-4799-4335-7","10.1109/ICFHR.2014.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981121","Benchmarking;Handwritten Documents;Word Spotting","Atmospheric measurements;Educational institutions;Image segmentation;Mathematical model;Particle measurements;Writing","benchmark testing;document image processing;handwritten character recognition;image segmentation;information retrieval;performance evaluation","H-KWS 2014;ICFHR 2014 competition;ICFHR 2014 conference;benchmarking datasets;handwritten keyword spotting competition;historical documents;information retrieval;keyword spotting algorithms;modern documents;performance evaluation measures;segmentation free track;segmentation-based track","","9","","15","","","1-4 Sept. 2014","","IEEE","IEEE Conference Publications"
"Development of an Online Reading Literacy Assessment on Life Information after Mild Stroke","H. Y. Ching; H. P. Hsia; C. K. Chou","Dept. of Grad. Inst. of Meas. & Stat., Nat. Univ. of Tainan, Tainan, Taiwan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","351","354","Back ground and purpose: Reading is the critical foundation of learning. Leaning to read is important for a citizen to participate and development in modern society with internet heavily used. However, it might not be an easy task for aged and cognitive impaired minority groups learn to adapt. The basic demographics of adult literacy will help to construct the amelioration program to promote learning to read. This study aimed to develop the Online Reading Literacy Assessment on Life Information (ORLALI). Methods: According to design of PISA, Retrieving information, interpretation and reflection/evaluation are designed into the ORLALI with 3 domains, 16 items with total score of 18. Pretest will be executed in 100 adults with contents validation and norm establishment. 500 adults will be recruited to validate the psychometric characteristics. 100 stroke patients with mild severity and 100 adults from community learning programs will be matched to explore the difference and the impact of cognitive impairment on literacy. Results: ORLALI will be well designed with good reliability and validity. Adult literacy will be less intact in mild stroke patients with negative correlation to cognitive impairment.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913323","life information;on-line reading literacy;stroke;validity","Aging;Communities;Educational institutions;Hospitals;Nervous system;Reflection;Senior citizens","Internet;computer aided instruction;information retrieval;medical computing;medical disorders;patient rehabilitation","Internet;ORLALI;PISA;adult literacy;aged group;amelioration program;cognitive impaired minority group;cognitive impairment;community learning program;mild stroke patients;online reading literacy assessment on life information;psychometric characteristics;retrieving information","","0","","13","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"A Novel Transcript Mapping Technique for Handwritten Document Images","N. Stamatopoulos; B. Gatos; G. Louloudis","Comput. Intell. Lab., Nat. Center for Sci. Res. &#x201C;Demokritos&#x201D;, Athens, Greece","2014 14th International Conference on Frontiers in Handwriting Recognition","20141215","2014","","","41","46","Transcript mapping refers to the process of aligning meaningful units of a handwritten document image (e.g. Text lines, words, characters) with the corresponding transcription information. It has many applications such as (i) fast generation of ground truth at different granularity levels and (ii) indexing handwritten collections for document retrieval. In this paper, a novel transcript mapping technique is proposed which is guided by the number of words as well as the characters per word of a text line. The proposed method combines the results of a local and a global approach using a scoring algorithm. The efficiency of the proposed method is demonstrated by experimentation conducted on a known, publicly available dataset, achieving word level alignment accuracy of 99.48%.","2167-6445;21676445","Electronic:978-1-4799-4334-0; POD:978-1-4799-7892-2; USB:978-1-4799-4335-7","10.1109/ICFHR.2014.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980994","transcript mapping;word segmentation","Abstracts;Algorithm design and analysis;Computational intelligence;Handwriting recognition;Informatics;Laboratories;Telecommunications","document image processing;handwritten character recognition;indexing;information retrieval","document retrieval;fast ground truth generation;handwritten collections indexing;handwritten document images;scoring algorithm;transcript mapping technique;transcription information;word level alignment accuracy","","1","","15","","","1-4 Sept. 2014","","IEEE","IEEE Conference Publications"
"An Investigation of Junior High School Students' Online Historical-Documents Reading Literacy","Y. R. Liao; P. H. Hung; G. J. Hwang; W. Y. Chang","Dept. of Educ., Nat. Univ. of Tainan, Tainan, Taiwan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","347","350","The purpose of this pilot study was to check the validity issues for an online historical-documents reading literacy assessment (OHDRLA) and an online historical reading attitude questionnaire (OHRAQ). Items of OHDRLA were developed based on PISA 2012 reading aspects and history contents. The former dimension includes the abilities to access and retrieve, integrate and interpret, and reflect and evaluate while the latter one covers two historical reading themes. The sample was drawn from 7th and 8th graders in 4 classes of 2 junior high schools in Taiwan and the total number is 112. The preliminary results revealed that the psychometric quality of OHDRLA and OHRAQ is acceptable and the female students performed better than male students while the difference between grades wasn't statistically significant. The analysis results of correlation pattern not only demonstrated a reasonable validity but also implied the lack of multi-perspective historical thinking teaching in school history classes. In other words, online historical-document reading literacy is reasonably independent from traditional school subjects and the instruction of this innovative construct is urgently needed.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913322","historical-documents;online hostorical reading attitude;online reading literacy","Art;Correlation;Correlation coefficient;Educational institutions;History;Standards","Internet;computer aided instruction;educational institutions;history;information retrieval;teaching","OHDRLA;OHRAQ;Taiwan;correlation pattern analysis;female students;history contents;junior high schools;male students;multiperspective historical thinking teaching;online historical reading attitude questionnaire;online historical-document reading literacy assessment;reading aspects;school history classes","","0","","13","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Audio feature reduction and analysis for automatic music genre classification","B. K. Baniya; J. Lee; Z. N. Li","Department of Computer Science and Engineering, Chonbuk National University, South Korea","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","457","462","Multimedia database retrieval is growing at a fast rate thereby subsequent increase in the popularity of online retrieval system. The large datasets are major challenges for searching, retrieving, and organizing the music content. Therefore, there is a need of robust automatic music genre classification method for organizing these music data into different classes according to the certain viable information. There are two fundamental components to be considered for genre classification namely audio feature extraction and classifier design. In this paper, diverse audio features set have been proposed to characterize the music contents precisely. The feature sets belong to four different groups, i.e. dynamic, rhythm, spectral, and harmony. From the features, five different statistical parameters are considered as representatives, including up to the 4<sup>th</sup> order central moments of each feature, and covariance components. Ultimately, significant numbers of representative attributes are controlled by MRMR algorithm. The algorithm calculates the score level of all feature attributes and orders them. The high score feature attributes are only considered for genre classification. Moreover, we can visualize that which audio features and which of the different statistical parameters derived from them are important for genre classification. Among them, mel frequency cepstral coefficients (MFCCs) have higher scored level than other feature attributes. Furthermore, MRMR does not transform the feature value like as principal component analysis (PCA). Besides these, the comparison has been made based on classification accuracy between two-dimensionality reduction methodologies using support vector machine (SVM). The classification accuracy of MRMR feature reduction set outperforms than PCA. The overall classification is also higher than other existing state-of-the-art of frame base methods.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973950","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973950","MRMR;dimensionality;feature reduction;music genre;statistical parameters","Accuracy;Classification algorithms;Feature extraction;Mel frequency cepstral coefficient;Music;Principal component analysis;Support vector machines","audio signal processing;feature extraction;information retrieval;music;principal component analysis;signal classification;support vector machines","MFCC;MRMR algorithm;Mel frequency cepstral coefficients;PCA;SVM;audio analysis;audio feature reduction;automatic music genre classification;dimensionality reduction methodologies;multimedia database retrieval;music content organization;music content retrieval;music content search;music data organization;online retrieval system;principal component analysis;score feature attributes;statistical parameters;support vector machine","","1","","26","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"GIS geoprocessing services search based on breadth-first reverse share pruning AND/OR tree algorithm","S. Zhang; F. Wang","Tourism College, Hainan University, Haikou, China","2014 10th International Conference on Natural Computation (ICNC)","20141206","2014","","","850","855","GIS geoprocessing service is the inevitable result of the combination of Geographical Information System and Web service technology, which is widely used for the interoperating of geoprocessing operations in distributed platform-independent and language-independent environments. Since function limited single GIS geoprocessing service cannot satisfy the demands of internet users anymore, it is necessary to dynamically mashup those existing GIS geoprocessing services to implement more complex tasks. However, the application of the research for GIS geoprocessing services mashup is still infancy with the following limitations: An efficient search method is not available to help user quickly find the required services within vast GIS geoprocessing services with multiple inputs and multiple outputs. In order to solve the problem mentioned above, Breadth-first Reverse Share Pruning AND/OR Tree algorithm has been proposed in this research. This algorithm proposes a reverse AND/OR tree to simplify the search by converting mesh AND/OR graph to AND/OR tree. This research also has developed a rule for converting complex types of services into a combination of two simple types of services. Furthermore, shared tree has been introduced and search efficiency has been improved by deleting the AND sub-tree.","2157-9555;21579555","Electronic:978-1-4799-5151-2; POD:978-1-4799-5152-9","10.1109/ICNC.2014.6975949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975949","AND/OR tree algorithm;GIS processing service;service discovery","Algorithm design and analysis;Educational institutions;Geographic information systems;Planning;Search problems;Web services","Web services;geographic information systems;information retrieval","AND subtree;GIS geoprocessing services search;Internet users;Web service technology;breadth-first reverse share pruning AND-OR tree algorithm;distributed platform-independent environments;geographical information system;geoprocessing operations;geoprocessing services mashup;language-independent environments","","0","","9","","","19-21 Aug. 2014","","IEEE","IEEE Conference Publications"
"The Archival Acid Test: Evaluating archive performance on advanced HTML and JavaScript","M. Kelly; M. L. Nelson; M. C. Weigle","Old Dominion University, Department of Computer Science, Norfolk, Virginia 23529 USA","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","25","28","When preserving web pages, archival crawlers sometimes produce a result that varies from what an end-user expects. To quantitatively evaluate the degree to which an archival crawler is capable of comprehensively reproducing a web page from the live web into the archives, the crawlers' capabilities must be evaluated. In this paper, we propose a set of metrics to evaluate the capability of archival crawlers and other preservation tools using the Acid Test concept. For a variety of web preservation tools, we examine previous captures within web archives and note the features that produce incomplete or unexpected results. From there, we design the test to produce a quantitative measure of how well each tool performs its task.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970146","Digital Preservation;Web Archiving;Web Crawler","Browsers;Crawlers;HTML;Libraries;Software;Standards;Web pages","Java;Web sites;hypermedia markup languages;information retrieval systems","HTML;JavaScript;Web archives;Web pages;Web preservation tool;acid test concept;archival acid test;archival crawlers;archive performance;preservation tools","","2","","8","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"OnehopMANET: One-Hop Structured P2P over Mobile Ad Hoc Networks","M. A. Mojamed; M. Kolberg","Comput. Sci. & Math., Univ. of Stirling, Stirling, UK","2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies","20141215","2014","","","159","163","There are many common characteristics between P2P (Peer to Peer) overlay networks and MANET (mobile ad hoc networks). Previous work has shown that when used together, the two approaches complement each other and performance synergies can be exploited. While MANET provide wireless connectivity without depending on any pre-existing infrastructure, P2P overlays provide data storage/retrieval functionality. On the other hand, both approaches face common challenges: maintaining connectivity in dynamic and decentralized networks. This paper proposes One hop MANET as a structured P2P over MANET the uses cross-layering with a proactive underlay. Unlike previous work, One hop MANET uses a P2P overlay that is capable of achieving lookups in a single hop. Through simulation we show that this approach offers performance benefits when compared with approaches which employ a multi-hop P2P overlay.","2161-2889;21612889","CD-ROM:978-1-4799-5072-0; Electronic:978-1-4799-5073-7; POD:978-1-4799-5074-4","10.1109/NGMAST.2014.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982909","DHT;EpiChord;MANET;OLSR;P2P","Mobile ad hoc networks;Mobile computing;Overlay networks;Peer-to-peer computing;Routing;Routing protocols","information retrieval;mobile ad hoc networks;overlay networks;peer-to-peer computing;storage management","OnehopMANET;data retrieval functionality;data storage functionality;one-hop structured P2P over mobile ad hoc networks;peer to peer overlay networks;wireless connectivity","","1","","24","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Named entity recognition in Assamese using CRFS and rules","P. Sharma; U. Sharma; J. Kalita","Dept. of Comput. Sci. & Eng., Tezpur Univ., Tezpur, India","2014 International Conference on Asian Language Processing (IALP)","20141204","2014","","","15","18","Named Entity Recognition (NER) is an important task in all Natural Language Processing (NLP) applications. It is the process of identifying and classifying the proper noun into classes such as person, location, organization and miscellaneous. Substantial work has been done in English and other European languages, achieving greater accuracy compared to the Indian Languages. Although NER in Indian languages is a difficult and challenging task and suffers from scarcity of resources, such work has started to appear recently. This paper discusses work on NER in Assamese using both Conditional Random Fields and a Rule-Based approach which gives an F-measure of 90-95% accuracy.","","Electronic:978-1-4799-5330-1; POD:978-1-4799-5331-8; USB:978-1-4799-5329-5","10.1109/IALP.2014.6973498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973498","AS;Assamese;CRF;HMM;IE;ME;MUC;NE;NER;NLP;POS;QA;SVM","Computer science;Educational institutions;Europe;Hidden Markov models;Natural language processing;Organizations;Support vector machines","information retrieval;knowledge based systems;natural language processing;statistical distributions","Assamese language;CRF;NER;NLP;conditional random fields;named entity recognition;natural language processing;rule-based approach","","0","","","","","20-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"Personalised PageRank for making recommendations in digital cultural heritage collections","A. Otegi; E. Agirre; P. Clough","IXA taldea, University of the Basque Country, Donostia, Spain","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","49","52","In this paper we describe the use of Personalised PageRank (PPR) to generate recommendations from a large collection of cultural heritage items. Various methods for computing item-to-item similarities are investigated, together with representing the collection as a network over which random walks can be taken. The network can represent similarity between item metadata, item co-occurrences in search logs, and the similarity of items based on linking them to Wikipedia articles and categories. To evaluate the use of PPR, search logs from Europeana are used to simulate user interactions. PPR on each information source is compared to a standard retrieval-based baseline, resulting in higher performance.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970149","Cultural Heritage;Random Walks;Recommender Systems","Cultural differences;Electronic publishing;Encyclopedias;Europe;Internet;Recommender systems","Web sites;history;information retrieval;meta data;recommender systems;user interfaces","Europeana;PPR;Wikipedia;digital cultural heritage collections;item-to-item similarities;meta data;personalised PageRank;recommendations;retrieval-based baseline;search logs;user interactions","","0","","17","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Document Retrieval Based on Logo Spotting Using Key-Point Matching","V. P. Le; N. Nayef; M. Visani; J. M. Ogier; C. D. Tran","Lab. L3I, La Rochelle Univ., La Rochelle, France","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3056","3061","In this paper, we present an approach to retrieve documents based on logo spotting and recognition. A document retrieval system is proposed inspired from our previous method for logo spotting and recognition. First, the key-points from both the query logo images and a given set of document images are extracted and described by SIFT descriptor, and are matched in the SIFT feature space. They are filtered by the nearest neighbor matching rule based on the two nearest neighbors and are then post-filtered with BRIEF descriptor. Secondly, logo segmentation is performed using spatial density-based clustering, and homography is used to filter the matched key-points as a post processing. Finally, for ranking, we use two measures which are calculated based on the number of matched key-points. Tested on a well-known benchmark database of real world documents containing logos Tobacco-800, our approach achieves better performance than the state-of-the-art methods.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977239","document retrieval;key-point matching;logo recognition;logo spotting","Accuracy;Databases;Feature extraction;Matched filters;Materials requirements planning;Optical filters;Shape","document image processing;feature extraction;filtering theory;image segmentation;information retrieval;pattern clustering;transforms","BRIEF descriptor;SIFT descriptor;SIFT feature space;document retrieval system;filtering method;key-point matching;logo recognition;logo segmentation;logo spotting;nearest neighbor matching rule;query logo images;spatial density-based clustering","","3","","20","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Retrieving Information from a Document Repository for Constructing Assurance Cases","K. Chindamaikul; T. Takai; H. Iida","Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Ikoma, Japan","2014 IEEE International Symposium on Software Reliability Engineering Workshops","20141215","2014","","","198","203","We address the problem of constructing an assurance case by presenting an approach to extract information from a large set of documents. In the proposed approach, document retrieval and formal concept analysis techniques are systematically combined for assisting users to explore relevant information from huge data set and to understand a number of concepts in such data set with the relation among them. We perform an experiment with a data set from an open-source software development project, in order to evaluate the effectiveness of our approach. The experimental results suggest that the proposed approach can be effective in terms of reducing the time and the cost for constructing assurance cases with acceptable confidence level, indicated by some assurance case quality metrics.","","Electronic:978-1-4799-7377-4; POD:978-1-4799-7378-1","10.1109/ISSREW.2014.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6983838","Assurance Case;FCA;Formal Concept Analysis;Rocument Retrieval","Accuracy;Context;Frequency measurement;Lattices;Manuals;Security","document handling;formal concept analysis;information retrieval","assurance case quality metrics;confidence level;document repository;document retrieval;formal concept analysis;information retrieval;open-source software development project","","0","","21","","","3-6 Nov. 2014","","IEEE","IEEE Conference Publications"
"A PubMed Meta Search Engine Based on Biomedical Entity Mining","A. Kanavos; E. Theodoridis; A. Tsakalidis","Comput. Eng. & Inf. Dept., Univ. of Patras, Patras, Greece","2014 25th International Workshop on Database and Expert Systems Applications","20141204","2014","","","82","86","Biomedical knowledge stored in the web is increasing significantly as most of the biomedical research papers are published online. Biomedical entity extraction is a crucial procedure for efficient text analysis and retrieval. PubMed is a very popular indexing engine, concerning life sciences and biomedical research. Being a free database, it accesses primarily the MEDLINE database of references and abstracts on life sciences and biomedical topics. In this work, we propose a metasearch engine over PubMed, which classifies PubMed results according to their specific topic and the extracted Biomedical entities. This method helps researchers to browse and search in the retrieved results. In order to provide more accurate clustering results, we utilize the biomedical ontology, named MeSH as well as RxNorm which is a tool for supporting semantic interoperation between drug terminologies and pharmacy knowledge base systems. Finally, we embed the proposed methodology in an online system.","1529-4188;15294188","Electronic:978-1-4799-5722-4; POD:978-1-4799-7866-3","10.1109/DEXA.2014.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974831","","Abstracts;Clustering algorithms;Clustering methods;Databases;Ontologies;Semantics;Vectors","data mining;information retrieval;medical computing;ontologies (artificial intelligence);search engines;text analysis","MEDLINE database;MeSH;PubMed meta search engine;RxNorm;biomedical entities extraction;biomedical entity mining;biomedical knowledge;biomedical ontology;biomedical research;information retrieval;pharmacy knowledge base system;text analysis","","1","","19","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Improving relation descriptor extraction with word embeddings and cluster features","T. Liu; M. Li","School of Information, Renmin University of China, Beijing, China","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","1271","1275","Relation descriptor is the text string which best describes the pre-defined relation between two entities. Relation descriptor can help people to know the specific semantics between two entities, which is very meaningful for knowledge base construction. Traditional relation descriptor extraction method use nominal features, whose expressibility is limited. Word embeddings via deep learning technology can reflect more syntactic and semantic information of words. In this paper we introduce the word embeddings to relation descriptor extraction problem. In order to obtain word semantic classes, we cluster words based on word embeddings and adopt the word cluster feature. Experimental results have shown that word embeddings feature and word cluster feature can improve the performance of relation descriptor extraction obviously. Furthermore the word cluster feature is more robust than word embeddings feature on the relation descriptor extraction. The best method can save 44% and 33% training data to achieve the same performance as the basic method on two datasets.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974089","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974089","deep learning;relation descriptor extraction;word cluster;word embeddings","Electronic publishing;Encyclopedias;Feature extraction;Internet;Semantics;Training data","feature extraction;information retrieval;learning (artificial intelligence);pattern clustering;text analysis;vocabulary;word processing","deep learning technology;relation descriptor extraction method;semantic information;syntactic information;text string;word cluster features;word embeddings","","0","","16","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"An Enhanced Quantum PageRank Algorithm Integrated with Quantum Search","H. Wang; J. Wu; X. Yang; P. Chen; X. Yi","State Key Lab. of High Performance Comput., Nat. Univ. of Defense Technol., Changsha, China","2014 Eighth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing","20141206","2014","","","74","81","The Google's PageRank algorithm is one of the most famous algorithms in data mining. A quantum version of this algorithm has been proposed in 2012. It is a meaningful step towards the quantum search engine but it can not search solutions. In this paper, we integrate a special operator of quantum search into the quantum PageRank algorithm to make a new quantum algorithm. We called it the Search Rank algorithm. This new algorithm is able to search solutions and rank results according to their importance at the same time. It is the first algorithm possessing this ability as far as we know. And it outperforms all classical algorithms when searching an unsorted database.","","CD-ROM:978-1-4799-4333-3; Electronic:978-1-4799-4331-9; POD:978-1-4799-7891-5","10.1109/IMIS.2014.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975444","quantum PageRank;quantum algorithm;quantum search engine;quantum walk","Algorithm design and analysis;Computers;Google;Heuristic algorithms;Quantum computing;Search engines;Vectors","data mining;information retrieval;quantum computing;search engines","Google PageRank algorithm;data mining;quantum PageRank algorithm;quantum search engine","","0","","15","","","2-4 July 2014","","IEEE","IEEE Conference Publications"
"Revealing Research Themes and their Evolutionary Trends Using Bibliometric Data Based on Strategic Diagrams","H. Han; J. Gui; S. Xu","Inst. of Sci. & Tech. Inf. of China, Beijing, China","2013 International Conference on Information Science and Cloud Computing Companion","20141204","2013","","","653","659","The paper aims to use strategic diagram technique to detect research themes and reveal their evolutionary trends in a scientific field using bibliometric data under practical application. Keywords are selected not only from author-provided and machine-indexed keywords, but also extracted from the full text so as to eliminate the ""indexer effect"". The keywords are then clustered to detect research themes, which are classified into four categories in a strategic diagram to reveal the research situations according to their strategic positions. Moreover, the strategic diagrams based on analysis of temporal dynamics are used to find out the thematic evolution through the similarity index to detect similar themes of adjacent phases, and the provenance and influence indexes to evaluate interactions of similar themes. Experimental results showed that the method is effective and useful in revealing research themes and their evolutionary trends in a scientific field.","","CD-ROM:978-1-4799-1864-5; Electronic:978-1-4799-5245-8; POD:978-1-4799-5246-5","10.1109/ISCC-C.2013.121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973666","co-word analysis;strategic diagram;thematic evolution;theme detection","Density measurement;Indexes;Libraries;Market research;Standards","indexing;information retrieval;natural sciences computing;pattern classification;pattern clustering;text analysis","bibliometric data;evolutionary trends;full text extraction;keyword clustering;machine-indexed keywords;research theme classification;research themes;scientific field;similarity index;strategic diagram technique;temporal dynamics;thematic evolution","","1","","17","","","7-8 Dec. 2013","","IEEE","IEEE Conference Publications"
"The optimized processing system for sci-tech novelty retrieval based on queuing theory","Q. y. Jiang; Liu Ju-hong","Guangzhou University of Traditional Chinese Medicine, China","2014 IEEE Workshop on Advanced Research and Technology in Industry Applications (WARTIA)","20141206","2014","","","578","582","Sci-tech novelty retrieval (STNR) plays an important role in novelty retrieval of literature information in the colleges and universities. It can help experts to confirm novelty of sci-tech projects which are required for application and approval. In this study, we give the basic framework of the system, and build the mathematical models of the optimized processing system for STNR based on queuing theory, and to explore the optimized mode between distribution of STNR processing and the task assignment for STNR staffs. We also simulate the model above with real data, and give a discussion of it. The result shows that, the customers' queue in system model will be blocked and stopped from working when the number of STNR staffs convert from three into five at busy periods, while rapidly lowering when the number of STNR staffs reach six. The customers' queue in system model will be unimpeded and unencumbered as long as the number of STNR staffs is more than three at free periods. The model can be used to build an intelligent and coordinating processing system for sci-tech novelty retrieval.","","DVD:978-1-4799-6988-3; Electronic:978-1-4799-6989-0; POD:978-1-4799-6990-6","10.1109/WARTIA.2014.6976325","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976325","Mathematical model;Optimized Processing System;Queuing Theory;Sci-tech Novelty Retrieval","Conferences;Educational institutions;Industry applications;Mathematical model;Probability distribution;Queueing analysis;Servers","educational institutions;information retrieval;natural sciences computing;queueing theory","STNR processing;STNR staffs;colleges;customer queue;intelligent coordinating processing system;mathematical models;optimized processing system;queuing theory;sci-tech novelty retrieval;sci-tech projects;task assignment;universities","","0","","8","","","29-30 Sept. 2014","","IEEE","IEEE Conference Publications"
"Building a Language Model for Local Coherence in Multi-document Summaries Using a Discourse-Enriched Entity-Based Model","M. L. d. R. C. Jorge; M. S. Dias; T. A. S. Pardo","Interinstitutional Center for Comput. Linguistics (NILC) Inst. of Math. & Comput. Sci., Univ. of Sao Paulo, Sao Paulo, Brazil","2014 Brazilian Conference on Intelligent Systems","20141215","2014","","","44","49","Local Coherence is a very important aspect in multi-document summarization, since good summaries not only condense the most relevant information, but also present it in a well-organized structure. One of the most investigated models for local coherence is the Entity-based model, which has been successfully used, once it facilitates the computational approach for coherence measurement. Particularly, this model was used for the evaluation of local coherence in multi-document summaries, achieving promising results. In order to improve the potential of the Entity-based model, we propose the creation of a language model for multi-document summaries that integrates the Entity-based model with discourse knowledge, mainly from Cross-document Structure Theory. Our results show that this type of information enriches the Entity-based Model by capturing other phenomena that are inherent to multi-document summaries, such as redundancy and complementarily, which improves the performance of the original model.","","Electronic:978-1-4799-5618-0; POD:978-1-4799-7859-5","10.1109/BRACIS.2014.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984805","discourse models;entity-based model;multi-document summarization","Accuracy;Buildings;Coherence;Computational modeling;Proposals;Redundancy;Vectors","computational linguistics;document handling;information retrieval","coherence measurement;cross-document structure theory;discourse-enriched entity-based model;language model;local coherence;multidocument summarization;redundancy","","0","","28","","","18-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"Semantic-structural assessment scheme for integrability in service-oriented applications","A. De Renzis; M. Garriga; A. Flores; A. Cechich; A. Zunino","GIISCo Research Group, Faculty of Informatics UNComa University, Neuquen, Argentina","2014 XL Latin American Computing Conference (CLEI)","20141124","2014","","","1","11","This work improves a novel Service Selection Method for the development of Service-Oriented Applications in the context of the Service-Oriented Computing (SOC) paradigm. We have defined a Semantic-Structural Scheme to assess Web Services on Interface Compatibility exploring the available information from WSDL documents. The structural information involves data types from return, parameters and exceptions. The semantic information concerns identifiers from parameters and operation names. The lexical database WordNet is used as a semantic basis. Two appraisal values were defined: compatibility gap and adaptability gap. The former is centered on functional aspects. The latter explains the adaptation effort to a successful integration. We validated those appraisals values through different experiments with a data-set of 465 real-life Web Services and measured the results using three metrics from the Information Retrieval field.","","Electronic:978-1-4799-6130-6; POD:978-1-4799-6131-3","10.1109/CLEI.2014.6965175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965175","Service Discovery;Service Integration;Service Oriented Applications;Service Selection;Web Services","Appraisal;Databases;Java;Semantics;System-on-chip;Web services","Web services;data integration;feature selection;information retrieval;semantic Web;service-oriented architecture","SOC;Web services;WordNet;data integration;information retrieval;interface compatibility;semantic-structural assessment scheme;service selection method;service-oriented computing","","4","","30","","","15-19 Sept. 2014","","IEEE","IEEE Conference Publications"
"A Hybrid Movie Recommendation Approach via Social Tags","S. Wei; L. Xiao; X. Zheng; D. Chen","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2014 IEEE 11th International Conference on e-Business Engineering","20141211","2014","","","280","285","The social media should be where a large number of netizens contribute, extract, create, and spread news consulting spontaneously, such as the social movie network. It requires frequent operations for users when they face with the vast resources. Personalized recommendation service can effectively solve the problem. However, the accuracy of recommendation service is lower than expected. We put forward a kind of hybrid movie recommendation approach via social tags. According to the user's preference from the social content annotation, e.g. Tags, through a series of the analysis, including the extraction, the normalization and recondition of social tags, we established the mixed recommendation model. Comparing with the existing collaborative filtering algorithms, the experimental results show that the proposed method has increased significantly in recommendation accuracy.","","Electronic:978-1-4799-6563-2; POD:978-1-4799-6564-9","10.1109/ICEBE.2014.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982093","KL;MCA;movie recommendation;personalized;social tags;topic","Collaboration;Correlation;Educational institutions;Equations;Filtering;Media;Motion pictures","entertainment;information retrieval;recommender systems;social networking (online)","hybrid movie recommendation approach;mixed recommendation model;personalized recommendation service;recommendation service;social content annotation;social media;social movie network;social tag extraction;social tag normalization;social tag recondition;user preference","","0","","21","","","5-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"The retrieval research of non-adjacent keywords in Chinese corpus — A case study of “Yi…Jiu…” construction","X. Tan; L. Yang","Institute of Chinese Information Processing Beijing Normal University Beiing, China","2014 International Conference on Asian Language Processing (IALP)","20141204","2014","","","191","194","Corpus Concordancing is a popular research topic. The function of retrieving data from corpus by providing non-adjacent keywords is widely used by users. However, the precision of retrieval results is not very high because the machine can't recognize the relationship of the non-adjacent keywords. To deal with this problem, this paper proposed a rule-based method for the “Yi...Jiu...” construction, which could exclude the unrelated data, even though the data include the keywords. The experiments show that the precision is close to 82%.","","Electronic:978-1-4799-5330-1; POD:978-1-4799-5331-8; USB:978-1-4799-5329-5","10.1109/IALP.2014.6973507","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973507","Corpus;Yi…Jiu…;concordancing;non-adjacent keywords;retrieval","Accuracy;Educational institutions;Electronic mail;Information processing;Legged locomotion;Testing","information retrieval;knowledge based systems;natural language processing;word processing","Chinese corpus;Chinese language;Yi...Jiu... construction;nonadjacent keywords retrieval research;rule-based method","","0","","2","","","20-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"A semantic case based web 2.0 tag hierarchy construction framework","Y. Zhang; K. Gao; B. Zhang; L. Gao","College of Information Science and Engineering, Northeastern University Shenyang, China","2014 11th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20141211","2014","","","616","622","In contrast to tags with no inter-relation, web users are more familiar with concept systems with hierarchies, which could also be leveraged in various information retrieval applications. The construction of tag hierarchies relies on the analysis of tag semantic characteristics, while such characteristics are evidenced by semantic case objects which are co-related to tags. Based on such an observation, a semantic case based tag hierarchy construction framework is proposed, together with a semantic flow analysis based hierarchy construction algorithm. Experiment results show that the proposed framework provides an effective mechanism for studying and comparing available algorithms, and the semantic flow based hierarchy construction algorithm outperforms the other evaluated methods in various evaluation metrics.","","Electronic:978-1-4799-5148-2; POD:978-1-4799-5149-9","10.1109/FSKD.2014.6980905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980905","Web 2.0;concept hierarchy;semantic case;tagging system","Association rules;Dictionaries;Semantics;Standards;Superluminescent diodes;Support vector machines;Vegetation","Internet;information retrieval;semantic Web","Web users;information retrieval applications;semantic case based Web 2.0 tag hierarchy construction framework;semantic case objects;semantic flow analysis based hierarchy construction algorithm;tag semantic characteristics","","1","","11","","","19-21 Aug. 2014","","IEEE","IEEE Conference Publications"
"An Investigation Into Internet Crowdsourcing for Enterprise Software Development","J. Trow; L. Liu; Z. Li","Sch. of Comput. & Math., Univ. of Derby, Derby, UK","2014 IEEE International Conference on Computer and Information Technology","20141215","2014","","","474","481","Recent years have witnessed the continuing development of the Internet from its original communication purpose (e.g., email), content provision (e.g., Web) and software deployment platform (e.g. SaaS) to a software development platform for enterprise. This paper investigated crowd sourcing, in particular its application to the software development sector. By making use of this method developers can be recruited from around the world, resulting in a wide range of expertise and more manageable workload. This paper considers a number of ways which crowd sourcing can be applied to existing software development methods and techniques, as well as exploring and evaluating the benefits and constraints of such methods. The paper used data gathered from the Top Coder platform to assess the skill levels and demographics of the current crowd sourcing user base. This paper also examined a wider range of crowd sourcing platforms to discover which features makes platforms successful and how they can be applied to a software engineering platform. Recommendations are then made as to what should constitute a software engineering specific crowd sourcing platform.","","Electronic:978-1-4799-6239-6; POD:978-1-4799-6240-2","10.1109/CIT.2014.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984699","Internet;crowdsourcing;software development","Accreditation;Crowdsourcing;Market research;Project management;Software;Software engineering","Internet;information retrieval;software engineering","Internet crowdsourcing;Top Coder platform;crowdsourcing user base;enterprise software development;software deployment platform;software development platform;software engineering","","0","","20","","","11-13 Sept. 2014","","IEEE","IEEE Conference Publications"
"Design pattern recommendation based-on a pattern usage hierarchy","N. Sanyawong; E. Nantajeewarawat","School of Information, Computer and Communication Technology, Sirindhorn International Institute of Technology, Thammasat University, Thailand","2014 International Computer Science and Engineering Conference (ICSEC)","20141206","2014","","","134","139","Design patterns for software development provide general reusable solutions to commonly occurring problems. They are useful for developing flexible, reusable and modular software with object-oriented programming. Selecting an appropriate design pattern is however a difficult task, especially for novice designers. In order to apply a pattern to a given problem context, a designer necessarily understand not only a problem domain but also the usage and structure of the pattern. To facilitate pattern selection, we construct a pattern usage hierarchy, based on which a problem-driven framework for recommending design patterns is developed. The characteristics of tasks to be performed in a given problem and examples of pattern usage are used for retrieving user intention and for matching the problem with an appropriate pattern. Results of a subjective evaluation of the framework are reported.","","Electronic:978-1-4799-4963-2; POD:978-1-4799-4962-5","10.1109/ICSEC.2014.6978183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978183","design pattern;recommendation system;software reuse","Computer science;Context;Heuristic algorithms;Pattern matching;Production facilities;Prototypes;Software","information retrieval;object-oriented programming;software architecture;software reusability","design pattern recommendation;general reusable solutions;modular software;object-oriented programming;pattern usage hierarchy;problem-driven framework;software development;software reusability;user intention retrieval","","1","","8","","","July 30 2014-Aug. 1 2014","","IEEE","IEEE Conference Publications"
"Overviewing Information Structure of Review Documents Using Syntax Constraints on Evaluation Descriptions","J. Fukumoto; C. Furuta; R. Yamanishi","Deptment of Media Technol., Ritsumeikan Univ., Kusatsu, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","954","959","This paper describes a method to detect evaluation points from freely written Web review for overviewing review structure. In freely written review, evaluation points and relationships between these points are unclear. We consider that overviewing Web review structure helps us to understand review documents. Based on our experiments, we confirmed that the proposed method detected evaluation points to be presented with high precision without dependence on kinds of evaluation target. Moreover, our proposed method realized to present relationships among evaluation points to be presented referring syntax features that were used to detect evaluation points to be presented.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913431","Detection of Evaluation Points;Information Extraction;Information Structure;Natural language processing;Review analysis","Data mining;Dictionaries;Feature extraction;Recycling;Syntactics;Vehicles;Visualization","Internet;computational linguistics;information retrieval;natural language processing;reviews","Web review documents;evaluation descriptions;evaluation point detection;information extraction;information structure;natural language processing;syntax constraints","","0","","9","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"A Supporting System for Finding Lost Objects for Dementia Patient and Caregiver by Image Recognition","T. Yonesaka; N. Kuwahara; K. Morimoto","Kyoto Inst. of Technol., Kyoto, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","859","862","In this study we propose the system for searching scenes from the video recorded by the wearable camera when people leave their valuable objects. Our proposed system analyses the movement of the hands by using various parameters in order to identify the actions that the patient hides the object and extracts scenes when the patient hides the object. By using this system the dementia patient and the caregiver can easily find the object that the dementia patient hides without a doubt the people around them when he/she develops delusion of being stolen.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913415","","Cameras;Dementia;Feature extraction;Histograms;Image color analysis;Lighting;Skin","feature extraction;image colour analysis;image motion analysis;image recognition;information retrieval;medical disorders;object detection;video cameras;video signal processing;wearable computers","actions identification;caregiver;dementia patient;hands movement;human skin color information;image recognition;lost objects finding;scenes extraction;valuable objects;video scenes searching;wearable camera","","0","","4","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Exploiting label dependency and feature similarity for multi-label classification","P. Nedungadi; H. Haripriya","Amrita CREATE, Amrita University, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","2196","2200","Multi-label classification is an emerging research area in which an object may belong to more than one class simultaneously. Existing methods either consider feature similarity or label similarity for label set prediction. We propose a strategy to combine both k-Nearest Neighbor (kNN) algorithm and multiple regression in an efficient way for multi-label classification. kNN works well in feature space and multiple regression works well for preserving label dependent information with generated models for labels. Our classifier incorporates feature similarity in the feature space and label dependency in the label space for prediction. It has a wide range of applications in various domains such as in information retrieval, query categorization, medical diagnosis and marketing.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968582","kNN;multilabel;multiple rgression","Prediction algorithms","information retrieval;learning (artificial intelligence);pattern classification;regression analysis","feature similarity;information retrieval;k-nearest neighbor;kNN algorithm;label dependency;label set prediction;label space;marketing;medical diagnosis;multilabel classification;multiple regression;query categorization","","0","","17","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Question Classification using syntactic and rule based approach","P. Biswas; A. Sharan; R. Kumar","School of Computer and Systems Sciences, Jawaharlal Nehru University, New Delhi-110067, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1033","1038","Question Classification is a vital component of Question Answering System. In this paper we have proposed a compact and effective method for question classification. Here rather than using a two layered taxonomy of 6 course grain and 50 fine grained categories developed by Li and Roth, 2002, we have classified the questions into three broad categories. We have also studied the syntactic structure of the question and suggest the syntactic patterns and expected answer type for particular category of questions. Using these question Patterns we have also suggested an algorithm for classifying the question into particular category. For experiment purpose we have used Li and Roth data set of 2000 questions. The experimental output shows that even with small set o question categories we can classify the questions with more satisfactory and better result. Hence in brief various contributions through this paper are: - Achieve state of art of question classification using less number of question categories - Communicate an Question classification algorithm which classifies the question into proposed categories which aids to embed the appropriate Answer Extraction Algorithm discussed in our previous work [23]. - Suggest more generic syntactic patterns for Wh questions.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968434","Definition Type Question;Descriptive Type Questions;Factoid Type Questions;Question Pattern;Syntactic Structure","Accuracy;Classification algorithms;Feature extraction;Knowledge discovery;Semantics;Support vector machines;Syntactics","classification;data mining;question answering (information retrieval)","answer extraction algorithm;course grain categories;fine grained categories;question answering system;question categories;question classification;question patterns;rule based approach;syntactic patterns;syntactic structure;two layered taxonomy","","0","","23","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Recognition of Pen-Based Music Notation: The HOMUS Dataset","J. Calvo-Zaragoza; J. Oncina","Dept. of Software & Comput. Syst., Univ. of Alicante, Alicante, Spain","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3038","3043","A profitable way of digitizing a new musical composition is by using a pen-based (online) system, in which the score is created with the sole effort of the composition itself. However, the development of such systems is still largely unexplored. Some studies have been carried out but the use of particular little datasets has led to avoid objective comparisons between different approaches. To solve this situation, this work presents the Handwritten Online Musical Symbols (HOMUS) dataset, which consists of 15200 samples of 32 types of musical symbols from 100 different musicians. Several alternatives of recognition for the two modalities -online, using the strokes drawn by the pen, and offline, using the image generated after drawing the symbol- are also presented. Some experiments are included aimed to draw main conclusions about the recognition of these data. It is expected that this work can establish a binding point in the field of recognition of online handwritten music notation and serve as a baseline for future developments.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.524","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977236","","Error analysis;FCC;Handwriting recognition;Hidden Markov models;Kernel;Music;Support vector machines","handwritten character recognition;image recognition;information retrieval;light pens;music","HOMUS dataset;data recognition;handwritten online musical symbols dataset;image generation;musical composition digitization;online handwritten music notation recognition;online modality recognition;pen-based music notation recognition;symbol drawing","","6","","27","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Full-text based context-rich heterogeneous network mining approach for citation recommendation","X. Liu; Yingying Yu; C. Guo; Y. Sun; L. Gao","School of Informatics and Computing, Indiana University, Bloomington, USA, 47405","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","361","370","Citation relationship between scientific publications has been successfully used for scholarly bibliometrics, information retrieval and data mining tasks, and citation-based recommendation algorithms are well documented. While previous studies investigated citation relations from various viewpoints, most of them share the same assumption that, if paper<sub>1</sub> cites paper<sub>2</sub> (or author<sub>1</sub> cites author<sub>2</sub>), they are connected, regardless of citation importance, sentiment, reason, topic, or motivation. However, this assumption is oversimplified. In this study, we employ an innovative “context-rich heterogeneous network” approach, which paves a new way for citation recommendation task. In the network, we characterize (1) the importance of citation relationships between citing and cited papers, and (2) the topical citation motivation. Unlike earlier studies, the citation information, in this paper, is characterized by citation textual contexts extracted from the full-text citing paper. We also propose algorithm to cope with the situation when large portion of full-text missing information exists in the bibliographic repository. Evaluation results show that, context-rich heterogeneous network can significantly enhance the citation recommendation performance.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970191","Citation Recommendation;Full-text Citation Analysis;Heterogeneous Information Network;Meta-Path","Abstracts;Citation analysis;Context;Data mining;Educational institutions;Focusing;Inference algorithms","citation analysis;data mining;full-text databases;information retrieval;recommender systems","bibliographic repository;citation recommendation performance enhancement;citation relationship;citation textual context extraction;citation-based recommendation algorithms;context-rich heterogeneous network approach;full-text based context-rich heterogeneous network mining approach;full-text citing paper;full-text missing information;scientific publications;topical citation motivation","","1","","30","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Intelligent System for a Personalized Diet of obese patients with Cancer","O. Geman; I. Chiuchisan; A. C. Iuresi; I. Chiuchisan; M. Dimian; A. Bosancu; D. Buliga; M. Covasa","Human Development and Health Department, &#x201C;Stefan cel Mare&#x201D; University of Suceava, Romania","2014 International Conference and Exposition on Electrical and Power Engineering (EPE)","20141204","2014","","","528","531","We have developed a system, called INSPIRED - Intelligent System for a Personalized Cancer Diet to improve the health and quality of life for obese patients with cancer. It is designed for monitoring, alerting, reminding and evaluation of patients as well as storage, access and retrieval of medical and personal data for establishing treatment. Our system provides users (patients or physicians) with personalized dietary plans, rehabilitation and lifestyle information, all tailored to each individual's needs. Obese cancer patients are informed of, and educated about, the role of nutrition as a first and best defense in improving survivability and quality of life. The proposed system analyzes patient data such as vital signs (weight, height, Body Mass Index BMI, blood pressure), physical activity, type of cancer, treatment, side effects and uses the patient's profile to build a custom diet that relies on comprehensive care planning. The Cancer Nutrition Personalized Tips System is based on My SQL (Structured Query Language) architecture that is user friendly and can be expanded to future needs.","","Electronic:978-1-4799-5849-8; POD:978-1-4799-5850-4; USB:978-1-4799-5848-1","10.1109/ICEPE.2014.6969964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969964","Cancer;Intelligent Systems;Nutrition;Obesity;Personalized Diet","Cancer;Diabetes;Obesity;Oncology;Sugar","SQL;cancer;data analysis;health care;information retrieval;knowledge based systems;medical information systems;patient monitoring;patient rehabilitation;patient treatment","BMI;Cancer Nutrition Personalized Tips System;INSPIRED;Intelligent System for a Personalized Cancer Diet;My SQL;Structured Query Language architecture;blood pressure;body mass index;cancer type;comprehensive care planning;custom diet;data access;data retrieval;data storage;health improvement;lifestyle information;medical data;nutrition;obese cancer patients;patient alerting;patient data analysis;patient evaluation;patient height;patient monitoring;patient profile;patient quality of life improvement;patient reminding;patient treatment;patient vital signs;patient weight;personal data;personalized dietary plan;physical activity;physicians;rehabilitation;side effects;survivability","","6","","34","","","16-18 Oct. 2014","","IEEE","IEEE Conference Publications"
"Joint layer based deep learning framework for bilingual machine transliteration","S. P; A. K. M","Center for Excellence in Computational Engineering and Networking, Amrita Vishwa Vidyapeetham, Tamil Nadu, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1737","1743","Between the growth of Internet or World Wide Web (WWW) and the emersion of the social networking site like Friendster, Myspace etc., information society started facing exhilarating challenges in language technology applications such as Machine Translation (MT) and Information Retrieval (IR). Nevertheless, there were researchers working in Machine Translation that deal with real time information for over 50 years since the first computer has come along. Merely, the need for translating data has become larger than before as the world was getting together through social media. Especially, translating proper nouns and technical terms has become openly challenging task in Machine Translation. The Machine transliteration was emerged as a part of information retrieval and machine translation projects to translate the Named Entities based on phoneme and grapheme, hence, those are not registered in the dictionary. Many researchers have used approaches such as conventional Graphical models and also adopted other machine translation techniques for Machine Transliteration. Machine Transliteration was always looked as a Machine Learning Problem. In this paper, we presented a new area of Machine Learning approach termed as a Deep Learning for improving the bilingual machine transliteration task for Tamil and English languages with limited corpus. This technique precedes Artificial Intelligence. The system is built on Deep Belief Network (DBN), a generative graphical model, which has been proved to work well with other Machine Learning problem. We have obtained 79.46% accuracy for English to Tamil transliteration task and 78.4 % for Tamil to English transliteration.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968553","Artificial Intelligence;Computational Linguistics;Deep Belief Networks;Deep Learning;Machine Transliteration;Natural Language Processing;Restricted Boltzmann Machine","Computers;Dictionaries;Joints;Neurons;Support vector machines;Training;Vectors","belief networks;computational linguistics;information retrieval;language translation;natural language processing","DBN;English languages;Friendster;IR;Internet;MT;Myspace;Tamil languages;Tamil-to-English transliteration;World Wide Web;bilingual machine transliteration;computational linguistics;deep belief network;generative graphical model;grapheme;information retrieval;information society;joint layer based deep learning framework;language technology applications;machine learning problem;machine translation;named entities;phoneme;proper nouns;real time information;social media;social networking site;technical terms","","0","","29","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Cost of Tape versus Disk for Archival Storage","J. Inman; G. Grider; H. B. Chen","High-Performance Comput., Los Alamos Nat. Lab., Los Alamos, NM, USA","2014 IEEE 7th International Conference on Cloud Computing","20141204","2014","","","208","215","For archiving large datasets in high-performance computing facilities, tape technology has a long history of providing inexpensive capacity. However, as the memory-size of supercomputers continues to grow geometrically, the cost of tape bandwidth is becoming more important. The projected costs for tape-drives, robotics, and maintenance, are creating challenges for tape-based archives. The advent of erasure-coded object storage, driven by the ""cloud storage"" industry, might make it practical to implement archives using disks, or hybrid disk-and-tape systems. We used linear optimization techniques to investigate when and how this transition might best be made, taking into consideration our significant investment in tape technology. Our models introduce a technique to systematically relax constraints on the relationship between tape-capacity and tape-bandwidth, which governs a trade-off between cost and performance. We ran parameter studies that support some preliminary conclusions about paths forward for archive infrastructure at LANL.","2159-6182;21596182","Electronic:978-1-4799-5063-8; POD:978-1-4799-5064-5","10.1109/CLOUD.2014.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973743","archive;cloud;cost;disk;erasure-code;linear-optimization;tape","Bandwidth;Computational modeling;Equations;Maintenance engineering;Mathematical model;Media;Robots","disc storage;information retrieval systems;optimisation","LANL;archival storage;archive infrastructure;disk;linear optimization techniques;tape technology;tape-bandwidth;tape-capacity","","0","","6","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"An argument for archiving Facebook as a heterogeneous personal store","C. C. Marshall; F. M. Shipman","Microsoft Research, 1065 La Avenida, Mountain View, CA 94043, USA","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","11","20","A decade ago, the locus of activity for our digital belongings-photos, email, videos, documents, and the like-was on our personal computers. Now the situation is different. Not only is personal media born-digital, it may also spend its entire life stored online in social media services and cloud stores, and locally on portable devices. Studies have revealed that most people lack the requisite skills to archive their digital belongings, regardless of where they are stored; furthermore people value the context offered by these large-scale, socially intertwined online stores. So why not archive the contents of a major social media service like Facebook to ensure the permanence of a meaningful portion of peoples' personal digital belongings? Rather than being delighted by this idea, participants in a study of digital ownership have expressed squeamishness about institutional efforts to archive social media: Facebook is not only viewed as private and vulnerable to violations of content ownership, but also as lacking long-term value. However, measures such as data embargoes, aggregation, and permissions mitigate participants' fears and objections to some extent. In this paper, we will use an example of biographical research, coupled with the results of a recent study, to argue that Facebook should be archived by a public institution.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970144","Facebook;Social media;archive;historical research;personal information;social networks","Facebook;Internet;Media;Privacy;Videos","cloud computing;information retrieval systems;social networking (online)","Facebook;archiving system;cloud stores;digital belongings;heterogeneous personal store;personal media born-digital;social media services","","1","","29","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Relationship between Mental States with Strong Emotion Aroused by Music Pieces and Their Feature Values","Y. Takahashi; T. Hochin; H. Nomiya","Grad. Sch. of Inf. Sci., Kyoto Inst. of Technol., Kyoto, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","718","725","This paper discusses the stimulation of the subject's strong emotion in listening music and the relationships between the impression or the strong emotion and acoustic feature values. Impressions of music are classified into five types: ""charity,"" ""nobility,"" ""nostalgia,"" ""passion,"" and ""joy."" First, using fifteen classical music pieces, an impression evaluation experiment is conducted to get the degrees of impression and strong emotion, and others, of the music pieces. Second, the acoustic feature values of the music pieces are extracted. The experimental results are compared with the acoustic feature values. As the result, it is proved that the acoustic feature values are related to the impression of music and the strong emotion. Also, it is suggested that it may be possible to estimate the impression of music by acoustic feature values.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913391","feature values;impression;music;strong emotion","Informatics","information retrieval;multimedia systems;music;psychology","acoustic feature values;mental states;multimedia retrieval system;music impression;subject emotion","","0","","13","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Discovery of Implicit Feature Words of Place Name","S. Hirokawa; T. Nakatoh; H. Nakae; T. Suzuki","Res. Inst. for Inf. Technol., Kyushu Univ., Fukuoka, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","561","566","Individual opinions and experiences are published in Web as CGM (consumer generated media). A tourism blog which a tourist wrote his experience and impression in a certain area is very helpful information for other tourists. However, a user cannot obtain such precious information without knowing the relation of blog articles and concrete place-names. We paid our attention to the hierarchical structure of place-names. In this paper, we propose the method of connecting related words to the place-name which does not appear explicitly in a blog article paying attention to the hierarchical structure of place-names. From from 45,553 blog articles about the Karatsu area in Saga Prefecture, the potential related words about 78 place-names of Saga Prefecture which have not appeared in the blogs were extracted. 4 subjects evaluated that meaningful related words are obtained in 80% or more of the place-names. However, the direct relationships between the place-name and related words was not able to be guessed easily.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913366","","Blogs;Cities and towns;Companies;Educational institutions;Feature extraction;Internet;Search engines","Web sites;information retrieval;travel industry","CGM;Saga Prefecture;consumer generated media;feature word discovery;place name;tourism blog articles;tourism information retrieval","","0","","12","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Implementation of a cloud computing framework for cloud forensics","A. Pătraşcu; V. V. Patriciu","Military Technical Academy, Computer Science Department, Bucharest, Romania","2014 18th International Conference on System Theory, Control and Computing (ICSTCC)","20141215","2014","","","440","445","Cloud computing technologies occupy an important place in today's digital environment as they offer to the user attractive benefits such as file storage and renting virtual machines. In this context, at the datacenter level, we need a unified framework that permits reliable virtual and physical resource management, having in the same time the possibility for digital forensic investigators to access the data. Even though we have ready-to-use solutions that are already applied to the cloud resource allocation part, we lack the software infrastructure needed for conducting a digital forensic investigation. In this paper we will present the foundation of our proposed cloud forensics framework, that aims to resolve and unify into a single entity the two issues mentioned before. We will present in detail the architecture and the modifications needed to be made in order to create a digital forensic compliant framework.","","Electronic:978-1-4799-4601-3; POD:978-1-4799-4600-6","10.1109/ICSTCC.2014.6982456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982456","basic cloud framework;cloud computing;data forensics","Cloud computing;Computer architecture;Databases;Forensics;Virtual machine monitors;Virtual machining","cloud computing;computer centres;digital forensics;information retrieval;resource allocation","cloud computing framework;cloud forensics;cloud resource allocation;data access;datacenter level;digital environment;digital forensic;physical resource management;user attractive benefits;virtual resource management","","0","","14","","","17-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"A rule based bengali stemmer","M. R. Mahmud; M. Afrin; M. A. Razzaque; E. Miller; J. Iwashige","Green Networking Research Group, Dept. of Computer Science and Eng., University of Dhaka, Bangladesh","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","2750","2756","One of the biggest challenges in doing word lookups is to derive the appropriate base word for any given word in Bengali. The basic concept to the solution of the problem is to eliminate inflections from a given word to derive its stem word. Stemmers attempt to reduce a word to its root form using stemming process, which reduces an inflected or derived word to its stem or root form. Existing works in the literature use lookup tables either for stem words or suffixes, increasing the overheads in terms of memory and time. This paper develops a rule-based algorithm that eliminates inflections stepwise without continuously searching for the desired root in the dictionary. To the best of our knowledge, this paper first investigates that, in Bengali morphology, for a large set of inflections, the stems can be computed algorithmically cutting down the inflections step by step. The proposed algorithm is independent of inflected word lengths and our evaluation shows around 88% accuracy.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968484","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968484","Bengali;Inflections;Rule based Stemming;Stem word;Stemmer;Verb-root","Accuracy;Classification algorithms;Colon;Databases;Dictionaries;Informatics;US Department of Transportation","information retrieval;knowledge based systems;natural language processing","Bengali stemmer;information retrieval system;rule-based algorithm;stemming process;word root form","","2","","13","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Generating domain specific ontology for retrieving Hidden Web contents","Manvi; A. Dixit; K. K. Bhatia; B. Wadhwa","Department of Computer Engineering YMCA University of Science & Technology Faridabad, India","2014 International Conference on Information Systems and Computer Networks (ISCON)","20141124","2014","","","66","71","Tremendous information present on the Internet is available only when the user type set of keywords for search for getting the result pages. Those pages are often referred as Hidden Web. The components like hidden Web crawler which wants to retrieve this hidden information has to fill the search interfaces automatically. For automatically filling these types of interfaces precise and relevant information is needed. A database that stores semantic information about objects and their relations may solve this purpose. This database can be defined with the help of Ontology defines common vocabulary. The work presented here mainly focuses on generating domain specific ontology for retrieving hidden Web contents. In this paper a knowledge base of Book domain has created using Protégé. All information stores as knowledge base in form of RDF triples <;subject predicate object>. This Knowledge base may be used in automatically filling up search interfaces for retrieving hidden Web data.","","Electronic:978-1-4799-2981-8; POD:978-1-4799-2982-5","10.1109/ICISCON.2014.6965220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965220","book;domain;hidden web;knowledge base;ontology","Awards activities;Books;Crawlers;Educational institutions;Knowledge based systems;Ontologies;Resource description framework","Web sites;information retrieval;knowledge based systems;ontologies (artificial intelligence);search engines","Protégé;RDF triples;Web pages;automatic search interface filling;book domain;common vocabulary;domain specific ontology generation;hidden Web content retrieval;hidden Web crawler;hidden information retrieval;knowledge base;semantic information storage","","0","","14","","","1-2 March 2014","","IEEE","IEEE Conference Publications"
"An Exclusive WS-Ranking Method for Ranking of Web Blogs Using Webometrics and Sociometrics","M. Pushpalatha; A. V. Kathiravan","Dept. of the Comput. Sci., Padmavani Arts & Sci. Coll. for Women, Salem, India","2014 International Conference on Intelligent Computing Applications","20141124","2014","","","392","396","In recent years, society has moved towards becoming ""information society"", virtual space has become the communication channel and the tool of socialization. While internet usage has grown, the way people are using the internet has also changed. More interactive online technology such as blogs, social networking sites such as Twitter and Facebook and other innovations which are part of greater interactivity and user-generated content that characterize so-called 'Web 2.0' -- i.e. sites allowing users to interact and collaborate with each other in a social media dialogue -- have become more prominent. Information retrieval has become a great challenge in web blogs and social networking web sites. Webometrics is a study of web-based content with primarily quantitative methods for social science research goals using techniques that are not specific to one field of study, which emphasizes the development of applied methods for use in the wider social sciences. This research focuses on developing a ranking algorithm for web blogs using webometrics and sociometrics. Most of the existing ranking algorithms use forward links, back links and weblog data. This paper gives an idea of using centrality measurement to rank web blogs.","","Electronic:978-1-4799-3966-4; POD:978-1-4799-3967-1","10.1109/ICICA.2014.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965078","Centrality;Ranking;Social network;Sociometrics;WS-Rank;Web Impact Factor;Webometrics","Blogs;Computer science;Indexes;Search engines;Social network services;Web pages","Internet;information retrieval;social networking (online)","Internet usage;WS-ranking method;Web 2.0;Web blogs;Web-based content;Webometrics;centrality measurement;information retrieval;information society;interactive online technology;ranking algorithm;social media dialogue;social networking Web sites;social science research goals;sociometrics","","0","","17","","","6-7 March 2014","","IEEE","IEEE Conference Publications"
"Crowd-Sourced Digitisation of Cultural Heritage Assets","H. C. Miles; A. T. Wilson; F. Labrosse; B. Tiddeman; S. Griffiths; B. Edwards; K. Moller; R. Karl; J. C. Roberts","Dept. of Comput. Sci., Aberystwyth Univ., Aberystwyth, UK","2014 International Conference on Cyberworlds","20141215","2014","","","361","368","With the rise of digital content and web-based technologies, archaeologists and heritage organisations are increasingly striving to produce digital records of archaeology and heritage sites. The large numbers and geographical spread of these sites means that it would be too time-consuming for any one team to survey them. To meet this challenge, the Heritage Together project has developed a web platform through which members of the public can upload their own photographs of heritage assets to be processed into 3D models using an automated photogrammetry work flow. The web platform is part of a larger project which aims to capture, create and archive digital heritage assets in conjunction with local communities in Wales, UK, with a focus on megalithic monuments. Heritage Together is a digital community and community-built archive of heritage data, developed to inspire local communities to learn more about their heritage and to help to preserve it.","","CD-ROM:978-1-4799-4678-5; Electronic:978-1-4799-4677-8; POD:978-1-4799-7865-6","10.1109/CW.2014.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980784","archaeology;co-production;photogrammetry","Communities;Data models;Educational institutions;History;Software packages;Solid modeling;Three-dimensional displays","Internet;archaeology;cultural aspects;history;information retrieval systems","3D models;Heritage Together project;Web platform;Web-based technologies;archaeologists;archaeology;archive digital heritage assets;automated photogrammetry work flow;community-built archive;crowd-sourced digitisation;cultural heritage assets;digital community;digital content;digital records;geographical spread;heritage data;heritage organisations;heritage sites;megalithic monuments;photographs","","1","","44","","","6-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Text Retrieval Based on Dyadic Conceptual Projection","S. Alouane-Ksouri; M. Sassi-Hidri; K. Barkaoui","","2014 25th International Workshop on Database and Expert Systems Applications","20141204","2014","","","198","202","This work exploits the use of Triadic Concept Analysis (TCA) for document retrieval to efficiently answer users' queries. The proposed conceptual analysis aims at describing the documents according to three hierarchical levels with a triadic computing model. It is based on normalisation and prototyping, which, by projection, induce a formal dyadic context. This representation has enabled us to visualize triadic concepts associated with the documents, sentences and words through the construction of fuzzy concept lattice. The lattices generated are then used to organize documents in a hierarchical structure to facilitate retrieval process.","1529-4188;15294188","Electronic:978-1-4799-5722-4; POD:978-1-4799-7866-3","10.1109/DEXA.2014.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974849","Cosimilarities;Document Retrieval;Fuzzy clustering;Galois lattice;Triadic Concepts Analysis","Algorithm design and analysis;Clustering algorithms;Computational modeling;Conferences;Context;Lattices;Text analysis","fuzzy set theory;question answering (information retrieval);text analysis","TCA;conceptual analysis;document retrieval;dyadic conceptual projection;formal dyadic context;fuzzy concept lattice;hierarchical levels;normalisation;prototyping;text retrieval;triadic computing model;triadic concept analysis;triadic concept visualization;user query answering","","0","","21","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"The development of object based video contents management technology for broadcasting service","K. Y. Kim; I. G. Jung; W. Ryu","Intelligent Convergence Media Research Department, Electronics & Telecommunications Research Institute","2014 International Conference on Information and Communication Technology Convergence (ICTC)","20141215","2014","","","727","729","In recent years, Many people want to watch their interesting object from their wanted viewing angle when they watch sports or soap opera on TV. Thus, we have developed object based video contents management system for the personalized broadcasting service.","2162-1233;21621233","Electronic:978-1-4799-6786-5; POD:978-1-4799-6787-2; USB:978-1-4799-6785-8","10.1109/ICTC.2014.6983270","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6983270","interesting object;metadata;object based video contents management","Broadcasting;Cameras;Content management;Data mining;Databases;Image segmentation;Multimedia communication","content management;information retrieval;object detection;television broadcasting;video coding","object based video contents management technology;personalized broadcasting service;viewing angle","","0","","4","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"Towards Ontology-Based Question Answering in Vague Domains","P. Alexopoulos; A. Walker; J. M. Gomez-Perez; M. Wallace","iSOCO S.A., Madrid, Spain","2014 9th International Workshop on Semantic and Social Media Adaptation and Personalization","20141211","2014","","","26","31","The rapid growth of the Semantic Web in the last years has led to the emergence of Ontology-Based Question Answering systems, namely systems that exploit the ontological structure of data in order to interpret and answer natural language questions. In this paper, we are interested in question answering scenarios where both semantic data and user questions can be characterized by vagueness and we propose a novel framework that is able to handle this vagueness by means of fuzzy ontologies.","","Electronic:978-1-4799-6814-5; POD:978-1-4799-6815-2","10.1109/SMAP.2014.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978948","Fuzzy Ontologies;Question Answering;Vagueness","Context;Knowledge based systems;Knowledge discovery;Natural languages;Ontologies;Pipelines;Semantics","data structures;fuzzy reasoning;ontologies (artificial intelligence);question answering (information retrieval)","fuzzy ontologies;natural language question answering;natural language question interpretation;ontological data structure;ontology-based question answering systems;semantic Web;semantic data;user questions;vague domains","","0","","24","","","6-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"Great War stories told by the people - Crowdsourced cultural heritage in digital museums","I. Frommholz; D. Graves; H. Liu; A. Kumar; G. Brady","Institute for Research in Applicable Computing, University of Bedfordshire, UK","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","419","420","The increasing interest in the centenary of the Great War 1914-1918 motivates the development of a digital library to capture and access valuable cultural heritage artefacts that would otherwise be lost. We will present a prototype to make available the story of the First World War in the local context of a British town, as told by the people today. The core of our prototype is crowdsourced ingest. To this end we apply latest insights from information interaction and access to foster user engagement. Open standards like CIDOC/CRM facilitate the external provision of our data and the integration of external resources. In the demo we will present our current Great War Stories prototype and how researchers from the humanities as well as digital libraries researchers will be able to benefit from and contribute to the project.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970204","CIDOC;WW1;crowdsourcing;cultural heritage;user engagement and interaction","Cities and towns;Context;Cultural differences;Educational institutions;Libraries;Navigation;Prototypes","history;information retrieval;museums","CIDOC/CRM;First World War;Great War;crowdsourced cultural heritage;digital museums;information access;information interaction;open standards","","0","","6","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Code Tagging as a Social Game","B. Biegel; F. Beck; B. Lesch; S. Diehl","Univ. of Trier, Trier, Germany","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","411","415","Keywords or tags summarize documents on an abstract level and can also be used for describing code fragments. They might be leveraged for retrieving features of a software system, understanding program functionality, or providing additional context. While automatic approaches at best are only able to retrieve information that is already contained in the source code, manual tagging could add valuable extra information from qualified expertise of the developers. However, tagging code is tedious. To make code tagging more fun, we introduce a social gasification approach: developers independently tag code fragments and are rewarded if their solutions conform to the solution of other developers. We implemented the game as a Facebook plug-in. A pilot user study suggests that the game mechanics are motivating and promote the proposition of reasonable tags.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976108","code tagging;crowdsourcing;documentation;gamification;social game","Conferences;Context;Games;Java;Software;Software engineering;Tagging","computer games;document handling;identification technology;information retrieval;social networking (online);source code (software)","Facebook plug-in;code fragments;code tagging;document summarization;information retrieval;keywords;manual tagging;program functionality;social game;software system;source code","","1","","24","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"Taxonomy of E-Learning Challenges and an Insight to Blended Learning","J. Shailaja; R. Sridaran","Fac. of Comput. Studies, National Acad. for Learning, Bangalore, India","2014 International Conference on Intelligent Computing Applications","20141124","2014","","","310","314","The application of information technology in education has the undoubted potential to upsurge the quality of teaching and dexterity in learning. E-learning is rapidly growing from solely training to guarantee its role in the overall learning strategy. It is inclusive of a maximum number of participants with a range of preferences, and needs. Owing to e-learning's brisk development, it is worthy to confer how to improve the performance and expand the application of on-line learning by endowing a systematic classification. The taxonomy provided in the paper can help researchers and developers to meet permissible and regulatory requirements for retrieving specific information within a set timeframe, and for easier study. This paper also lists the potential challenges under each category and as a solution to most common ones, blended learning techniques are proposed.","","Electronic:978-1-4799-3966-4; POD:978-1-4799-3967-1","10.1109/ICICA.2014.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965062","E-learning;blended learning;learning styles;personalized learning","Computers;Electronic learning;Internet;Materials;Real-time systems;Software","computer aided instruction;information retrieval;pattern classification;teaching","blended learning techniques;dexterity;e-learning brisk development;e-learning challenges;information retrieval;information technology;learning strategy;online learning;systematic classification;teaching;training","","0","","42","","","6-7 March 2014","","IEEE","IEEE Conference Publications"
"Keyphrase Extraction Abstracts Instead of Full Papers","S. Popova; V. Danilova","St.-Petersburg State Univ., St. Petersburg, Russia","2014 25th International Workshop on Database and Expert Systems Applications","20141204","2014","","","241","245","In the present paper we consider keyphrase extraction problem from scientific articles. Finding an appropriate solution is important for the organization of fast navigation in databases, indexing, clustering and classification of academic papers. The base collection includes keyphrases selected by the experts for each text (SemEval2010). It is shown that the use of abstracts instead of full texts allows to improve the results obtained by processing full texts or abstracts with introduction and conclusion section. Our approach uses the extraction of keyphrases with linguistic patterns (part of speech-based), patterns are built on the basis of an auxiliary dataset. The use of abstracts in this approach allows to reduce the number of words sequences extracted with patterns, as compared to the use of full texts. It allows to simplify or totally omit the ranking stage. Ranking is usually needed, because out of many keyphrases candidates we have to choose only 10-15. This stage is the most difficult and its effectiveness depends on the number of the selected candidates to keyphrases. The use of abstracts makes it possible to considerably reduce the number of candidate phrases and at the same time yields high recall.","1529-4188;15294188","Electronic:978-1-4799-5722-4; POD:978-1-4799-7866-3","10.1109/DEXA.2014.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974856","abtract processing;indexing;informational retrieval;keyphrase extraction;keyphrase identification","Abstracts;Artificial neural networks;Data mining;Feature extraction;Gold;Pragmatics;Standards","data mining;information retrieval;natural language processing;text analysis","academic paper classification;academic paper clustering;academic paper indexing;keyphrase extraction;linguistic patterns;scientific articles;word sequence extraction","","0","","21","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"NatData: A Platform to Integrate Geospatial Data from Natural Resources of the Brazilian Biomes","C. G. d. N. Macário; A. M. Nakai; L. V. Koenigkan; J. Daltio; C. E. L. d. Fonseca","Embrapa Agric. Inf., Embrapa, Campinas, Brazil","2014 IEEE 10th International Conference on e-Science","20141204","2014","1","","256","262","There are numerous challenges for sustainable agriculture. One of them is to provide an inventory of natural resources, to allow their evaluation for a sustainable use in production systems for food, fiber, essences and energy. The generation and maintenance of this inventory requires efforts of strategic innovation management in order to reduce errors, inconsistencies and unpredictability, replacing them with precise diagnosis, monitoring, early exploration of problems, needs and requirements. Then, it should act as a guide for investment in organization of knowledge and generation of technology flows. This requires an easier access to organized and integrated data about natural resources of different biomes. however, this access is often hampered by a number of reasons, mainly due to their volume and heterogeneity. This paper describes the NatData platform, which is under development at the Brazilian Agricultural Research Corporation (Embrapa). It intends to overcome the challenges, aiming to integrate data from Brazilian natural resources, preserving their semantic and allowing different users to access the data.","","Electronic:978-1-4799-4287-9; POD:978-1-4799-4286-2","10.1109/eScience.2014.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972272","geospatial data integration;heterogeneous data;natural resource information","Biodiversity;Geospatial analysis;Meteorology;Soil;Spatial databases;Standards","agriculture;data integration;geographic information systems;information retrieval;innovation management;inventory management;knowledge management;natural resources;strategic planning;sustainable development","Brazilian Agricultural Research Corporation;Brazilian biomes;Brazilian natural resources;Embrapa;NatData platform;data access;energy;essences;fiber;food;geospatial data integration;inventory generation;inventory maintenance;investment;knowledge organization;natural resources inventory;production systems;strategic innovation management;sustainable agriculture;sustainable use;technology flows generation","","0","","16","","","20-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"Disease-medicine topic model for prescription record mining","S. Park; D. Choi; W. Lee; D. Jung; M. Kim; I. C. Moon","","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","86","93","Analyzing patient records is important for improving the quality of medical services and for understanding each patient's historical diseases. However, the huge size of the data requires statistical analysis procedures. In this paper, we proposed a probabilistic model-the disease-medicine topic model (DMTM)-to explore connected knowledge about diseases and medicines. In the model, diseases and medicines are modeled using generative process. We used the latent Dirichlet allocation, which is one of the most popular topic models, as the baseline model. Then, we compared the qualities of topic representations quantitatively and qualitatively. The comparison results showed that the topics derived from the DMTM are clearer to identify and that specific patterns were found in the diseases and medicines. In the case of topic network analysis, these specific patterns were proved using centrality measurements.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973889","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973889","information retrivial;machine learning;medical mining;text mining;topic modeling","Adaptation models;Analytical models;Biological system modeling;Coherence;Data mining;Diseases;Medical diagnostic imaging","data mining;diseases;information retrieval;learning (artificial intelligence);medical computing;medicine;probability;statistical analysis","DMTM;Dirichlet allocation;disease-medicine topic model;medical services;network analysis;patient record analysis;prescription record mining;probabilistic model;statistical analysis procedures","","1","","19","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Metadata based recommender systems","P. Mittal; A. Jain; A. Majumdar","IIIT-Delhi, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","2659","2664","For building a recommendation system the eCommerce portal gathers the user's ratings on various items in order to determine his/her choice regarding its merchandise. The portal also collects metadata for the user when he/she signs up and becomes a part of the system; therefore the portal has access to information such as user's age, gender, occupation, location, etc. Till date almost all prior studies used the metadata for alleviating the cold-start problem; this information was not used for improving the recommendations. For the first time in this work, we propose a simple neighborhood selection technique by giving importance to the metadata groups for improving the recommendations.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968531","","Accuracy;Collaboration;Electronic mail;Informatics;Motion pictures;Portals;Recommender systems","electronic commerce;information retrieval;meta data;portals;recommender systems","cold-start problem;ecommerce portal;information access;metadata based recommender systems;metadata groups;simple neighborhood selection technique;user age;user gender;user location;user occupation;user ratings","","0","","18","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Extracting Experiences Using Dependency Parsing on Japanese e-Commerce Websites","K. Hagiwara; K. Ono; K. Hatano","Grad. Sch. of Culture & Inf. Sci., Doshisha Univ., Kyotanabe, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","813","818","In recent years, the expansion of e-commerce has led to a rapid increase in the number of customer reviews on websites. In general, the reviews are written by consumers after they have purchased or used the products. However, reviews may not only be written by users who have experience of the products, making it difficult to determine which reviews are useful references when purchasing items. On e-commerce websites, in particular, reviews written by consumers who have actually used or purchased the items are useful to both consumers and shops, so a method of extracting such experiential information is needed. In this paper, we propose a method for extracting reviews that contain useful information using Japanese dependency parsing. Our method extracts rather less information than previous methods, but requires less processing to achieve almost the same accuracy as conventional approaches.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913407","","Data mining;Dictionaries;Educational institutions;Equations;Mathematical model;Sociology;Statistics","Web sites;electronic commerce;grammars;information retrieval;purchasing","Japanese dependency parsing;Japanese e-commerce Web sites;customer reviews;experiential information extraction;purchasing;review extraction","","0","","12","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Annotating Web Service Sections with Combined Classification","G. M. Kapitsaki","Dept. of Comput. Sci., Univ. of Cyprus, Aglantzia, Cyprus","2014 IEEE International Conference on Web Services","20141204","2014","","","622","629","Web services are considered reusable elements that can be exploited stand-alone or as part of wider, generic or domain-specific, applications. With a vast variety of Web Services being offered by service providers, annotation techniques that add tags to services automatically are frequently exploited with the aim of retrieving relevant services faster. Tagging of Web Services at finer levels of granularity can assist in drawing more detailed conclusions, making their use easier. In this paper, we go beyond global Web Service tagging by proposing a classification technique for the annotation of Web Service sections. The process focuses on port type, operation and message sections of the service description. Service information as offered through WSDL and the provider and user descriptions is considered. The initial evaluation results demonstrate the efficiency of the approach in providing annotations at these different service levels.","","Electronic:978-1-4799-5054-6; POD:978-1-4799-5055-3","10.1109/ICWS.2014.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6928952","WSDL;annotation;classification;classifier ensemble;tagging;web services","Data mining;Documentation;Feature extraction;Noise;Semantics;Tagging;Web services","Web services;information retrieval;pattern classification","WSDL;Web service section annotation;combined classification;domain-specific applications;relevant service retrieval;service information","","0","","25","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"SCDA: SLA-Aware Cloud Datacenter Architecture for Efficient Content Storage and Retrieval","D. F. Kassa; K. Nahrstedt","Dept. of Comput. Sci., Univ. of Illinois at Urbana Champaign, Champaign, IL, USA","2014 IEEE 7th International Conference on Cloud Computing","20141204","2014","","","120","127","With the fast growth of (online) content and the need for high quality content services, cloud data centers are increasingly becoming the preferred places to store data and retrieve it from. With a highly variable network traffic and limited resources, efficient server selection and data transfer rate allocation mechanisms become necessary. However, current approaches rely on random server selection schemes and inefficient data transmission rate control mechanisms. In this paper we present SCDA, an efficient server selection, resource allocation and enforcement mechanism with many salient features. SCDA has prioritized rate allocation mechanism to satisfy different service level agreements (SLA)s on throughput and delays. The allocation scheme can achieve max/min fairness. SCDA has a mechanism to detect and hence mitigate SLA violation in realtime. We have implemented SCDA in the NS2 simulator. Extensive experimental results confirm some of the design goals of SCDA to obtain a lower content transfer time and a higher throughput. The design of SCDA can achieve a content transfer time which is about 50% lower than the existing schemes and a throughput which is higher than existing approaches by upto than 60%.","2159-6182;21596182","Electronic:978-1-4799-5063-8; POD:978-1-4799-5064-5","10.1109/CLOUD.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973732","","Artificial neural networks;Equations;Measurement;Monitoring;Quality of service;Resource management;Servers","cloud computing;computer centres;contracts;information retrieval;information storage;resource allocation","SCDA;SLA-aware cloud datacenter architecture;content retrieval;content storage;data transfer rate allocation;server selection;service level agreements","","2","","23","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"Construction of Scholarly n-Gram from Huge Text Data","M. Hwang; H. N. Yeom; M. N. Hwang; H. Jung","Korea Inst. of Sci. & Technol. Inf. (KISTI), Daejeon, South Korea","2014 Eighth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing","20141206","2014","","","31","35","The ultimate goal of this research is to provide n-gram data that is specialized for scholarly utilization. To this end, this paper outlines the construction of a scholarly n-gram through the processing of large text documents. Many researchers, especially non-native English language speakers, find it difficult to construct sentences and paragraphs with appropriate and disambiguated words. One of the methods that can assist them is the provision of n-gram data. A representative n-gram known as Web 1T 5-Gram Version 1, which was constructed by processing virtually all documents retrieved using Google, already exists. However, this data contain unfocused word recommendations, therefore, they are not suitable. Consequently, we are constructing a scholarly n-gram. In this paper, we demonstrate the efficiency of n-gram using Web 1T unigram and introduce and discuss the specifics of our research plan related to scholarly n-gram.","","CD-ROM:978-1-4799-4333-3; Electronic:978-1-4799-4331-9; POD:978-1-4799-7891-5","10.1109/IMIS.2014.4","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975437","context n-gram;personalized n-gram;scholarly n-gram;time-dependent n-gram","Context;Google;Reliability;Semantic Web;Semantics;Text categorization;Time-frequency analysis","Internet;information retrieval;natural language processing;recommender systems;text analysis","English language speakers;Google;document retrieval;n-gram data;text document processing;word disambiguation;word recommendations","","0","","14","","","2-4 July 2014","","IEEE","IEEE Conference Publications"
"Supporting students to find relevant learning resources through social bookmarking and recommendations","E. Popescu; F. E. Buşe","Computers and Information Technology Department, University of Craiova, Craiova, Romania","2014 18th International Conference on System Theory, Control and Computing (ICSTCC)","20141215","2014","","","458","463","The abundance of educational resources available on the Web leads to information overload for the students and the difficulty in finding useful and relevant resources for a specific learning context. The solution that we propose in this paper is a platform called Edu3R (Educational Resources Retrieval and Recommendation), which relies on community filtering: students enrolled in the same course can perform collaborative search through various learning object repositories, bookmark the resources of interest, rate them and share them with peers. The rationale is that resources found and selected by peers are likely to be relevant since the learning community is centered around the same course and the same learning tasks and is relatively homogeneous (classmates generally having common learning backgrounds and completing the same curriculum). Edu3R also relies on social tagging, through which learners annotate resources with meaningful terms that reflect the educational context, provide a personalized classification and facilitate subsequent retrieval. Finally, Edu3R also integrates a collaborative filtering mechanism for recommending learning resources based on student similarity. The paper provides an overview of the system architecture, functionalities and pedagogical rationale, as well as a comparison with similar platforms.","","Electronic:978-1-4799-4601-3; POD:978-1-4799-4600-6","10.1109/ICSTCC.2014.6982459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982459","collaborative filtering;educational resource retrieval;learning objects;social bookmarking;social tagging","Collaboration;Communities;Context;Databases;Filtering;Tagging;Web 2.0","Internet;collaborative filtering;computer aided instruction;educational courses;information retrieval;recommender systems","Edu3R;collaborative search;educational course;educational resources retrieval and recommendation;social bookmarking;social tagging","","0","","20","","","17-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"On the Use of Stack Traces to Improve Text Retrieval-Based Bug Localization","L. Moreno; J. J. Treadway; A. Marcus; W. Shen","Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","151","160","Many bug localization techniques rely on Text Retrieval (TR) models. The most successful approaches have been proven to be the ones combining TR techniques with static analysis, dynamic analysis, and/or software repositories information. Dynamic software analysis and software repositories mining bring a significant overhead, as they require instrumenting and executing the software, and analyzing large amounts of data, respectively. We propose a new static technique, named Lobster (Locating Bugs using Stack Traces and text Retrieval), which is meant to improve TR-based bug localization without the overhead associated with dynamic analysis and repository mining. Specifically, we use the stack traces submitted in a bug report to compute the similarity between their code elements and the source code of a software system. We combine the stack trace based similarity and the textual similarity provided by TR techniques to retrieve code elements relevant to bug reports. We empirically evaluated Lobster using 155 bug reports containing stack traces from 14 open source software systems. We used Lucene, an optimized version of VSM, as baseline of comparison. The results show that, in average, Lobster improves or maintains the effectiveness of Lucene-based bug localization in 82% of the cases.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976081","bug localization;stack traces;static analysis;text retrieval","Conferences;Software maintenance","information retrieval;program debugging;text analysis","TR models;TR techniques;bug localization techniques;dynamic analysis;improve text retrieval;software analysis;software repositories information;software repositories mining;software system;source code;stack traces;static analysis;textual similarity","","4","","29","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"An approach to named entity extraction from historical documents in traditional mongolian script","B. Batjargal; G. Khaltarkhuu; F. Kimura; A. Maeda","Kinugasa Research Organization, Ritsumeikan University, 56-1 Toji-in Kitamachi, Kita-ku, Kyoto, Japan","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","489","490","In this poster, we propose an information extraction method for digitized ancient Mongolian documents by utilizing an ancient-modern dictionary. Named entities such as historical figures and place names will be extracted by employing text mining techniques that aim to reduce the labor-intensive annotation on historical text. The Text Encoding Initiative (TEI) guidelines will be applied to digital text representations that encode the historical figures and place names along with their interpretations, and commentaries.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970239","digital library;historical documents;named entity extraction;traditional Mongolian script","Dictionaries;Educational institutions;Libraries;Text analysis;Visualization","data mining;history;information retrieval;text analysis","TEI guidelines;Text Encoding Initiative;ancient-modern dictionary;digital text representations;digitized ancient Mongolian documents;historical documents;information extraction method;named entity extraction;text mining techniques;traditional Mongolian script","","0","","5","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Offline Hand-Written Musical Symbol Recognition","S. Chanda; D. Das; U. Pal; F. Kimura","Dept. of Comput. Sci. & Media Technol., Gjovik Univ. Coll., Gjovik, Norway","2014 14th International Conference on Frontiers in Handwriting Recognition","20141215","2014","","","405","410","Recognition of offline musical symbols can aid in automatic retrieval of a particular piece of musical notation from a digital repository. Though some work on on-line Musical symbol notations exists, little work has been done on off-line recognition of the symbols. This article proposes a system for offline isolated musical symbol recognition. Efficacy of a texture analysis based feature extraction method is compared with a structural shape descriptor based feature extraction method coupled with a Support Vector Machine (SVM) classifier. Later three different kinds of feature selection techniques were also analyzed to gauge the contribution of each feature in the overall classification process. We compared our results with an existing method and we noted the proposed system exhibited encouraging results and it is better than existing method. The proposed system even worked better when we used MQDF classifier in place of SVM. In a five-fold cross validation experimental framework, considering 3795 music symbols we achieved 97.50% and 98.05% accuracy from SVM and MQDF classifiers, respectively when chain-code histogram features are applied.","2167-6445;21676445","Electronic:978-1-4799-4334-0; POD:978-1-4799-7892-2; USB:978-1-4799-4335-7","10.1109/ICFHR.2014.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981053","Character recognition;MQDF;Musical score;Offline musical symbol recognition;SVM","Accuracy;Classification algorithms;Educational institutions;Feature extraction;Handwriting recognition;Histograms;Support vector machines","feature extraction;feature selection;handwritten character recognition;image classification;image texture;information retrieval;music;support vector machines","MQDF classifier;SVM classifier;automatic musical notation retrieval;chain-code histogram features;digital repository;feature selection technique;offline handwritten musical symbol recognition;offline isolated musical symbol recognition;structural shape descriptor based feature extraction method;support vector machine;texture analysis based feature extraction method","","0","","24","","","1-4 Sept. 2014","","IEEE","IEEE Conference Publications"
"Reviewer Recommender of Pull-Requests in GitHub","Y. Yu; H. Wang; G. Yin; C. X. Ling","Nat. Lab. for Parallel & Distrib. Process., Nat. Univ. of Defense Technol., Changsha, China","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","609","612","Pull-Request (PR) is the primary method for code contributions from thousands of developers in GitHub. To maintain the quality of software projects, PR review is an essential part of distributed software development. Assigning new PRs to appropriate reviewers will make the review process more effective which can reduce the time between the submission of a PR and the actual review of it. However, reviewer assignment is now organized manually in GitHub. To reduce this cost, we propose a reviewer recommender to predict highly relevant reviewers of incoming PRs. Combining information retrieval with social network analyzing, our approach takes full advantage of the textual semantic of PRs and the social relations of developers. We implement an online system to show how the reviewer recommender helps project managers to find potential reviewers from crowds. Our approach can reach a precision of 74% for top-1 recommendation, and a recall of 71% for top-10 recommendation.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976151","Distributed Software Development;Pull-request;Reviewer Recommendation;Social Network Analysis","Communities;Conferences;Semantics;Social network services;Software;Software engineering","distributed processing;information retrieval;recommender systems;social networking (online);software quality;text analysis","GitHub;code contributions;distributed software development;information retrieval;pull-requests;reviewer recommender;social network;software projects quality;textual semantic","","13","","9","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"Nano-media: New nano-photofabric for rapid imprinting of color images and covert data storage","H. Jiang; R. Qarehbaghi; B. Kaminska","School of Engineering Science, Simon Fraser University, 8888 University Drive, Burnaby BC, V5A 1S6 Canada","14th IEEE International Conference on Nanotechnology","20141201","2014","","","608","613","We present the concept of `nano-media' as a novel carrier to imprint and display color images with embedded covert information. The key novelty of the proposed nanoscale technology is (1) the introduction of nano-substrate such as polymer (plastic), paper, glass, metal, or other tissue/fabric and (2) the imprinting processes. Nano-substrate consists of the pixelated nano-structures that are specially designed to display red, green and blue primary colors, and infrared radiation, and can be pre-fabricated on any substrate. The imprinting process activates the pixels according to the desired image that is transferred onto nano-substrate. The effective optical intensity of the pixelated nano-structures is tuned by an intensity control layer (ICL), which is patterned according to the desired color image and covert information. Using this technology, any given full-color image and/or covert data can be embedded on a prefabricated nano-substrate. This new technology makes possible to practically and efficiently use the nano-structures as a visual information display (next generation of holography) and as an high density and long term optical storage medium. In this paper, the concept, the design of the nano-media and the proof-of-concept experimental work are presented. We successfully produced full-color images with 1,270 pixels per inch (PPI) resolution using various ICLs on the fabricated nano-substrate. We also embedded covert information into the nano-media by patterning the intensity of infrared sub-pixels and successfully read the information using an infrared camera device. The texts, QR codes and photos were all tested as the covert information which was retrieved without any loss. The color images and stored data are of very high quality that can be controlled by the imprinting processes.","1944-9399;19449399","Electronic:978-1-4799-5622-7; POD:978-1-4799-5623-4; USB:978-1-4799-4082-0","10.1109/NANO.2014.6968172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968172","","Color;Image color analysis;Integrated optics;Metals;Optical device fabrication;Optical imaging;Substrates","cameras;image colour analysis;information retrieval;materials science computing;nanotechnology;optical storage","ICL;PPI;QR codes;QR photos;data storage;fabric;fabricated nanosubstrate;fullcolor images;glass;infrared camera device;intensity control layer;metal;nanomedia;nanophotofabric;nanoscale technology;nanostructures;paper;pixels per inch;plastic;polymer;rapid imprinting processes;tissue;visual information display","","3","","12","","","18-21 Aug. 2014","","IEEE","IEEE Conference Publications"
"An uniform description solution for devices based on DCON ASCII protocol","N. C. Gaitan","Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University of Suceava, Suceava, Romania","2014 18th International Conference on System Theory, Control and Computing (ICSTCC)","20141215","2014","","","821","825","In the developing process of efficient SCADA systems, there can be problems generated due to the field buses diversity, and the devices connected to this field buses. Furthermore, there can be problems encountered at the integration of new devices in the SCADA systems. An effective solution is to use a method that describes these devices so that there is not required to recompile the software module of the SCADA systems. In this paper, it is presented a solution to describe the capabilities of devices based on DCON ASCII protocol. The solution is based on the Electronic Data Sheet (EDS) files that were extended in order to describe the commands, and the answers used to retrieve information for each device. This solution was integrated into a SCADA system that has a modular architecture.","","Electronic:978-1-4799-4601-3; POD:978-1-4799-4600-6","10.1109/ICSTCC.2014.6982520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982520","DCON protocol;EDS;SCADA;fieldbuses","Computer architecture;Data acquisition;Protocols;SCADA systems;Servers;Software;Standards","SCADA systems;field buses;information retrieval;program compilers;protocols","DCON ASCII protocol;EDS files;SCADA systems;electronic data sheet files;field buse diversity;information retrieval;modular architecture;uniform description solution","","1","","16","","","17-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"Leaning to Train: Linking Financial News Articles to Company Short Names","Y. Xia; H. Lin; R. Lau; Y. Liu; R. Lau","Dept. of Comp. Sci. & Tech., Tsinghua Univ., Beijing, China","2014 IEEE 11th International Conference on e-Business Engineering","20141211","2014","","","240","245","As a special type of named entity, company name is frequently mentioned in financial news articles, leading to significant necessity on company-oriented information retrieval and management. However, company names are usually mentioned with short names, which are sometimes ambiguous. For example, apple refers in some cases to Apple Incorporation while in other cases to a kind of sweet fruit. This motivates our research on linking financial news articles to company short name, which aims to determine whether a mention in an article is short name of a company. The supervised approach requires labor on annotation of news article that mention the specific company short name. It is rather unpractical as new company short names appear constantly. In this work, we propose a self-contained unsupervised learning framework, which relies on probabilistic topic model to collect training data automatically. Experimental results show that the performance is close to the state-of-the-art supervised approach which relies on human-judged gold standard.","","Electronic:978-1-4799-6563-2; POD:978-1-4799-6564-9","10.1109/ICEBE.2014.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982086","Company short name;disambiguation;entity linking","Companies;Data models;Gold;Joining processes;Standards;Support vector machines;Training data","information management;information retrieval;unsupervised learning","Apple Incorporation;company-oriented information management;company-oriented information retrieval;link financial news articles;probabilistic topic model;self-contained unsupervised learning framework;supervised approach","","0","","13","","","5-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"Zeri e LODE. Extracting the Zeri photo archive to linked open data: formalizing the conceptual model","C. M. Gonano; F. Tomasi; F. Mambelli; F. Vitali; S. Peroni","Dept. of Computer Science and Engineering, University of Bologna, Mura Anteo Zamboni 7, 40126 - (Italy)","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","289","298","This paper presents the first steps of a project to convert the notable Italian “Zeri photo archive” to a linked and open dataset. The full project entails the analysis of the records' description model (Scheda F) in order to define a suitable ontology by exploring existing data models, the creation of the RDF triple store, the creation of links to the cloud, and the definition of the user interface for browsing the linked open dataset. This paper presents and discusses the conceptual modeling of the data stored in the Zeri archival database.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970182","CIDOC-CRM;FABIO;FEO;FRBR;OWL 2 DL;PROV-O;RDF;Scheda F","Art;Cultural differences;Data models;Databases;Libraries;Ontologies;Standards","information retrieval systems;ontologies (artificial intelligence);user interfaces;visual databases","Zeri archival database;Zeri e LODE;Zeri photo archive;browsing;description model;linked open data;ontology;user interface","","0","","24","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"A supervised approach to distinguish between keywords and stopwords using probability distribution functions","A. Sharan; S. Siddiqi","School of Computer and Systems Sciences, Jawaharlal Nehru University, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1074","1080","This paper presents a novel probability based approach for distinguishing between keyword and stopword from a text corpus. This has a lot of applications including automatic construction of stopword list. First objective of this paper is to investigate the role of probability distribution for distinguishing between keyword and stopword. Second objective is to compare the performance of probability distributions of various weighting measures for the purpose of identifying keyword and stopword. Main characteristics of our method are that it is corpus base, supervised and computationally very efficient. Being corpus based the method is independent of the language used. However we have tested the approach on a domain specific corpus in Hindi. In Hindi (including many Indian languages), it has a great significance as a standard list of stopwords is not available. The results are encouraging and we are able to achieve 74% accuracy. However as this is a preliminary attempt, there is a great scope for improvement.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968206","Corpus Statistics;Hindi;Keywords;Probability distribution;Stopwords;Term Weighting Measures","Computational modeling;Frequency measurement;Probability distribution;Standards;Testing;Training;Weight measurement","data mining;information retrieval;learning (artificial intelligence);natural language processing;statistical distributions;text analysis","Hindi;Indian language;keyword identification;probability distribution function;stopword identification;supervised approach;term weighting measures","","0","","12","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"A modified aspect model for simulation analysis","M. Goto; K. Minetoma; K. Mikawa; M. Kobayashi; S. Hirasawa","School of Creative Science and Engineering, Waseda University, Tokyo, JAPAN","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","1306","1311","This paper proposes a new latent class model to represent user segments in a marketing model of electric commerce sites. The aspect model proposed by T. Hofmann is well known and is also called the probabilistic latent semantic indexing (PLSI) model. Although the aspect model is one of effective models for information retrieval, it is difficult to interpret the meaning of the probability of latent class in terms of marketing models. It is desirable that the probability of latent class means the size of customer segment for the purpose of marketing research. Through this formulation, the simulation analysis to dissect the several situations become possible by using the estimated model. The impact of the strategy that we contact to the specific customer segment and make effort to increase the number of customers belonging to this segment can be predicted by using the model demonstrating the size of customer segment. This paper proposes a new model whose probability parameter of latent variable means the rate of users with the same preference in market. By applying the proposed model to the data of an internet portal site for job hunting, the effectiveness of our proposal is verified.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974095","","Analytical models;Companies;Data models;Educational institutions;Mathematical model;Portals;Predictive models","Internet;electronic commerce;indexing;information retrieval;marketing;probability","Internet portal site;PLSI model;customer segment size;electric commerce sites;information retrieval;job hunting;marketing model;modified aspect model;probabilistic latent semantic indexing model;probability parameter;simulation analysis","","0","","14","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Trademark retrieval based on phonetic similarity","F. Mohd Anuar; R. Setchi; Y. K. Lai","School of Engineering, Cardiff University, School of Computer Science and Informatics, United Kingdom","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","1642","1647","Trademarks are visual symbols with high reputational value, which requires protection. This paper proposes an algorithm to retrieve phonetically similar trademarks that can be used as a means for supporting trademark examination during the registration process. The algorithm employs a phonology based string similarity algorithm together with a typography mapping and token rearrangement to compute a phonetic similarity between trademarks. The trademark phonetic similarity score is then computed from the employed phonetic similarity algorithm. The proposed algorithm advances the state-of-the-art in trademark retrieval by providing a mechanism to compare trademarks with special characters or symbols phonetically. The proposed algorithm is tested on 1,400 trademarks obtained from real court cases between 1999 and 2012. The proposed algorithm improves the R-precision score by 14% and 17% compared with two state-of-the-art methods.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974151","phonetic algorithm;phonetic similarity;trademark retrieval","Algorithm design and analysis;Databases;Educational institutions;Manuals;Pragmatics;Trademarks;Visualization","information retrieval;speech processing;trademarks","R-precision score improvement;phonetically similar trademark retrieval;phonology based string similarity algorithm;real court cases;registration process;reputational value;token rearrangement;trademark examination;trademark phonetic similarity score;typography mapping;visual symbols","","0","","26","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"An Expansion Method of XML Element Retrieval Techniques into Web Documents","A. Keyaki; J. Miyazaki; K. Hatano","Grad. Sch. of Inf. Sci. & Eng., Tokyo Inst. of Technol., Tokyo, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","853","858","In this paper, we propose a method to expand XML element retrieval techniques into Web documents. XML element retrieval techniques return partial (sub) documents as search results, and are expected to be able to apply to other structured documents, namely, Web documents besides XML documents. The point is that physical document structures of Web documents are literally disorganized because Web documents are generated for not managing data but rendering on a Web browser. As another feature of Web documents, they contain many incomprehensive contents for human readers. To address challenges caused by these features, we propose 1) a reconstruction method of document structures according to logical structures of contents and 2) a filter for removing unimportant content which does not convey useful information to users. Our experimental evaluations showed that our proposed method improved search accuracy compared with both naive XML element retrieval approach and document retrieval approach.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913414","Web documents;XML element retrieval;filter;logical document structure;physical document structure","Containers;Erbium;HTML;Reconstruction algorithms;Sections;Standards;XML","Internet;XML;information retrieval;online front-ends","Web browser;Web document retrieval approach;XML documents;XML element retrieval techniques","","0","","13","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"The Nature of Communications and Emerging Communities on Twitter Following the 2013 Syria Sarin Gas Attacks","Y. Tyshchuk; W. A. Wallace; H. Li; H. Ji; S. E. Kase","Dept. of Ind. & Syst. Eng., Rensselaer Polytech. Inst., Troy, NY, USA","2014 IEEE Joint Intelligence and Security Informatics Conference","20141206","2014","","","41","47","Social media has become an important communication tool especially following an extreme event. Research in social psychology has shown that people engage in gathering and ""milling"" information, and confirmation seeking during the process of forming intent to take action or voice an opinion. Twitter serves as a communications channel where people converge to compile collective intelligence, provide event reporting, and diffuse information. In this paper the investigation of Twitter usage seeks to describe human participation on Twitter following a controversial extreme event -- 2013 Syria sarin gas attack. The methodology employed incorporates Natural Language Processing (NLP) and network analysis to trace human response on Twitter to this event. NLP techniques include Named Entity Recognition (NER) used to extract relevant entities (e.g. countries), Event Extraction (EE) to excerpt relevant events (e.g. conflict, movement, life, etc.), and Stanford Parser to detect actionable verbs discussed by Twitter participants. Network analysis constructs a network based on the Twitter users' communications, detects communities, extracts their leaders and identifies their roles based on structural properties of the networks. Specifically, the research looked at the Twitter data for two days August 22-23, 2013 following the event. The research suggests that (1) there were no immediate polarization of opinions following the event, (2) the primary event of Twitter communication was the conflict and information about the victims of the event, (3) Twitter communities were too sparse to produce substantial amount of social pressure to force an opinion/opinion shift, (4) top community leaders were news sources, political activists, and select individuals, (5) 'individual' leaders political agendas were not revealed.","","CD-ROM:978-1-4799-6363-8; Electronic:978-1-4799-6364-5; POD:978-1-4799-6365-2","10.1109/JISIC.2014.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975552","communities;social media;social network analysis","Communities;Feature extraction;Image edge detection;Media;Natural language processing;Organizations;Twitter","information retrieval;natural language processing;network theory (graphs);social networking (online);terrorism","2013 Syria Sarin gas attack;EE;NER;NLP techniques;Stanford parser;Twitter communication;Twitter communities;event extraction;named entity recognition;natural language processing;network analysis;social media;trace human response","","3","","20","","","24-26 Sept. 2014","","IEEE","IEEE Conference Publications"
"Geo skip list data structure - storing spatial data and efficient search of geographical locations","A. Barewar; M. A. Radke; U. A. Deshpande","Dept. of Computer Science and Engg., VNIT, Nagpur, Maharashtra, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1479","1485","Existing data structures which facilitate storage and retrieval of geographical data are R-trees, R* trees, KD trees etc. Most widely used and accepted structure among these is the R-tree. A drawback with R-trees is that it represents regions as fictitious rectangles which do not correspond to actual geographical regions. Also R-trees do not represent the hierarchy very well. For example New York City belongs to state New York and is in country United States of America and is a part of the North America continent. This kind of information is not brought out naturally by R- trees. Moreover, R-trees have problem of merging and splitting when underflow and overflow condition of a rectangle occurs which increases the complexity of this structure. To overcome these problems, we propose a structure called Geo-skip list which is inspired from the skip list data structure. It is simple, dynamic, partly deterministic and partly randomized data structure. We have compared the results of our structure with those of R-tree and have found improvement in the search efficiency.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968370","complexity;efficiency;geo-skip list;hierarchy;latitude;longitude;skip list;spatial data","Cities and towns;Complexity theory;Continents;Data structures;Filling;Indexes;Spatial databases","computational complexity;data structures;geographic information systems;information retrieval;trees (mathematics)","KD trees;New York City;North America continent;R* trees;R-trees;United States of America;fictitious rectangles;geo skip list data structure;geo-skip list;geographical location search;search efficiency;spatial data storage;structure complexity","","0","","16","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Not all mementos are created equal: Measuring the impact of missing resources","J. F. Brunelle; M. Kelly; H. SalahEldeen; M. C. Weigle; M. L. Nelson","Old Dominion University, Department of Computer Science, Norfolk, Virginia, 23529, USA","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","321","330","Web archives do not capture every resource on every page that they attempt to archive. This results in archived pages missing a portion of their embedded resources. These embedded resources have varying historic, utility, and importance values. The proportion of missing embedded resources does not provide an accurate measure of their impact on the Web page; some embedded resources are more important to the utility of a page than others. We propose a method to measure the relative value of embedded resources and assign a damage rating to archived pages as a way to evaluate archival success. In this paper, we show that Web users' perceptions of damage are not accurately estimated by the proportion of missing embedded resources. The proportion of missing embedded resources is a less accurate estimate of resource damage than a random selection. We propose a damage rating algorithm that provides closer alignment to Web user perception, providing an overall improved agreement with users on memento damage by 17% and an improvement by 51% if the mementos are not similarly damaged. We use our algorithm to measure damage in the Internet Archive, showing that it is getting better at mitigating damage over time (going from 0.16 in 1998 to 0.13 in 2013). However, we show that a greater number of important embedded resources (2.05 per memento on average) are missing over time.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970187","Digital Preservation;HTTP;Memento;TimeMaps;Web Architecture;Web Archiving","Cascading style sheets;Equations;Harmonic analysis;Internet;Mathematical model;Twitter;Web pages","Internet;information retrieval systems","Internet archive;Web user damage perceptions;damage rating algorithm;memento damage;missing embedded resource proportion;resource damage estimation","","3","","28","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"A New Approach to Web Mining: A Search Engine Offering Result of No Assumption","Y. Suzuki; M. Ito; N. Ishii; T. Hara","Coll. of Eng., Chubu Univ., Kasugai, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","531","532","Recently, rapid development in information and communications technology has led to explosive growth in the amount of available information, including substantial volume of data on the Web. One step toward managing and making use of this explosion of information is to enhance search technologies so that they can easily retrieve the necessary data. In this study, we propose a method for providing multifaceted search results and effective Web mining by not only using keywords but also leveraging relationships that include information contained within a resource.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913356","Wikipedia;serendipity;web mining","Databases;Educational institutions;Electronic publishing;Encyclopedias;Internet;Web mining","Internet;data mining;information retrieval","Web mining;information and communication technology;multifaceted search;necessary data retrieval;search engine;search technologies","","0","","4","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Epimenides: An information system offering automated reasoning for the needs of digital preservation","Y. Kargakis; Y. Tzitzikas","Institute of Computer Science, FORTH-ICS, Computer Science Department, University of Crete, Greece","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","411","412","Epimenides is a system that can be used in the context of digital archives and digital libraries for helping archivists in checking whether the archived digital artifacts remain intelligible and functional, and in identifying the consequences of probable losses. A distinctive feature of Epimenides is that it can model also converters and emulators, and the adopted modelling approach enables the automatic reasoning needed for reducing the human effort required for checking whether a task can be performed over a digital object (or digital collection in general).","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970200","","Cognition;Computer science;Computers;Emulation;Resource description framework;Smart phones;Software","digital libraries;digital preservation;inference mechanisms;information retrieval systems","Epimenides;automatic reasoning;converters;digital archives;digital artifacts;digital collection;digital libraries;digital object;digital preservation;emulators;human effort;modelling approach","","0","","1","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"A Slice-Based Estimation Approach for Maintenance Effort","H. W. Alomari; M. L. Collard; J. I. Maletic","Fac. of Inf. Technol., Jerash Univ., Jerash, Jordan","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","81","90","Program slicing is used as a basis for an approach to estimate maintenance effort. A case study of the GNU Linux kernel with over 900 versions spanning 17 years of history is presented. For each version a system dictionary is built using a lightweight slicing approach and encodes the forward decomposition static slice profiles for all variables in all the files in the system. Changes to the system are then modeled at the behavioral level using the difference between the system dictionaries of two versions. The three different granularities of slice (i.e., line, function, and file) are analyzed. We use a direct extension of srcML to represent computed change information. The retrieved information reflects the fact that additional knowledge of the differences can be automatically derived to help maintainers understand code changes. We consider the hypotheses: (1) The structured format helps create traceability links between the changes and other software artifacts. (2) This model is predictive of maintenance effort. The results demonstrate that the approach accurately predicts effort in a scalable manner.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976074","effort estimation;program slicing;software maintenance;software metrics","Dictionaries;Encoding;Estimation;Linux;Maintenance engineering;Open source software","Linux;information retrieval;operating system kernels;program slicing;software maintenance","GNU Linux kernel;computed change information;forward decomposition static slice profiles;information retrieval;lightweight slicing approach;maintenance effort estimation;slice granularities;software artifacts;srcML;structured format;system dictionaries;traceability links","","1","","45","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"CED<sup>2</sup>AR: The Comprehensive Extensible Data Documentation and Access Repository","C. Lagoze; L. Vilhuber; J. Williams; B. Perry; W. C. Block","School of Information, University of Michigan, Ann Arbor, USA","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","267","276","We describe the design, implementation, and deployment of the Comprehensive Extensible Data Documentation and Access Repository (CED<sup>2</sup>AR). This is a metadata repository system that allows researchers to search, browse, access, and cite confidential data and metadata through either a web-based user interface or programmatically through a search API, all the while re-reusing and linking to existing archive and provider generated metadata. CED<sup>2</sup>AR is distinguished from other metadata repository-based applications due to requirements that derive from its social science context. These include the need to cloak confidential data and metadata and manage complex provenance chains.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970178","Metadata;standards","Context;Documentation;Educational institutions;Libraries;Standards;User interfaces;XML","application program interfaces;information retrieval;information retrieval systems;meta data;social sciences;user interfaces","CED<sup>2</sup>AR;Web-based user interface;comprehensive extensible data documentation and access repository;confidential data;metadata repository system;metadata repository-based applications;search API;social science","","1","","43","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Towards a Framework for Supporting Web Search of Complex Objects via Multidimensional Paradigms","A. Cuzzocrea; G. Xu","ICAR, Univ. of Calabria, Cosenza, Italy","2014 14th International Conference on Computational Science and Its Applications","20141206","2014","","","217","220","In this paper we present WebClustCube, an innovative framework for supporting Web search of complex objects via multidimensional paradigms. WebClustCube focuses on the issue of empowering traditional Web search methodologies by means of novel paradigms. In particular, WebClustCube supports the building and the interactive manipulation of OLAP-enabled Web views over complex objects extracted from distributed databases. The data management, OLAP-like support of WebClustCube is provided by ClustCube, a state-of-the-art framework for coupling OLAP methodologies and clustering algorithms with the goal of analyzing and mining of complex database objects. We complement of analytical contribution by means of a case study that clearly shows the potentialities of WebClustCube in the context of next-generation Web search environments.","","Electronic:978-1-4799-4264-0; POD:978-1-4799-4263-3","10.1109/ICCSA.2014.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976691","","Computer architecture;Data mining;Distributed databases;Google;Lattices;Web search","Internet;data mining;distributed databases;information retrieval","CLAP methodologies;OLAP-enabled Web views;Web search methodologies;WebClustCube;clustering algorithms;complex database object analysis;complex database object mining;data management;distributed databases;interactive manipulation;multidimensional paradigms","","0","","20","","","June 30 2014-July 3 2014","","IEEE","IEEE Conference Publications"
"Questcrowd: a location-based question answering system with participation incentives","V. S. K. Pulla; C. S. Jammi; P. Tiwari; M. Gjoka; A. Markopoulou","CalIT2, University of California, Irvine","2013 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","20141204","2013","","","75","76","We present QuestCrowd, a location-based system that uses crowd-sourcing to answer simple day-to-day questions. QuestCrowd supports realtime questions along with questions that can be answered using factual information by people not present at the location. Key design mechanisms that set it apart from similar location-based systems include (i) a reputation system that motivates quality contributors by rewarding high quality answers (ii) a forwarding mechanism that leverages existing social graph relations to increase participation.","","Electronic:978-1-4799-0056-5; POD:978-1-4799-0055-8","10.1109/INFCOMW.2013.6970746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970746","","Androids;Humanoid robots;Knowledge discovery;Search engines;Servers;Social network services;Subscriptions","graph theory;mobile computing;outsourcing;question answering (information retrieval)","QuestCrowd;crowdsourcing;day-to-day questions;forwarding mechanism;location-based question answering system;participation incentives;quality contributors;realtime questions;reputation system;social graph relations","","0","","6","","","14-19 April 2013","","IEEE","IEEE Conference Publications"
"A Cepstral Mean Subtraction based features for Singer Identification","P. G. Radadia; H. A. Patil","Tata Research Development & Design Center (TRDDC) Pune, India","2014 International Conference on Asian Language Processing (IALP)","20141204","2014","","","58","61","Singer IDentification (SID) is a very challenging problem in Music Information Retrieval (MIR) system. Instrumental accompaniments, quality of recording apparatus and other singing voices (in chorus) make SID very difficult and challenging research problem. In this paper, we propose SID system on large database of 500 Hindi (Bollywood) songs using state-of-the-art Mel Frequency Cepstral Coefficients (MFCC) and Cepstral Mean Subtracted (CMS) features. We compare the performance of 3<sup>rd</sup> order polynomial classifier and Gaussian Mixture Model (GMM). With 3<sup>rd</sup> order polynomial classifier, we achieved % SID accuracy of 78 % and 89.5 % (and Equal Error Rate (EER) of 6.75 % and 6.42 %) for MFCC and CMSMFCC, respectively. Furthermore, score-level fusion of MFCC and CMSMFCC reduced EER by 0.95 % than MFCC alone. On the other hand, GMM gave % SID accuracy of 70.75 % for both MFCC and CMSMFCC. Finally, we found that CMS-based features are effective to alleviate album effect in SID problem.","","Electronic:978-1-4799-5330-1; POD:978-1-4799-5331-8; USB:978-1-4799-5329-5","10.1109/IALP.2014.6973510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973510","Cepstral Mean Subtraction;Singer Identification;album effect","Accuracy;Databases;Mel frequency cepstral coefficient;Polynomials;Testing;Training","Gaussian processes;feature extraction;information retrieval systems;music;polynomials;signal classification","CMS feature;Gaussian mixture model;MFCC feature;MIR system;Mel frequency cepstral coefficients;SID;cepstral mean subtraction based features;instrumental accompaniments;music information retrieval system;polynomial classifier;singer identification","","1","","10","","","20-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"On semantic evaluation of text clustering algorithms","S. H. Nguyen; W. Świeboda; H. S. Nguyen","Institute of Mathematics, The University of Warsaw, Banacha 2, 02-097, Warsaw Poland","2014 IEEE International Conference on Granular Computing (GrC)","20141215","2014","","","224","229","In this paper, we investigate the problem of quality analysis of clustering results using semantic annotations given by experts. In previous work we proposed a novel approach to construction of evaluation measure, called SEE (Semantic Evaluation by Exploration), which is an extension of the existing methods such as Rand Index or Normalized Mutual Information. In this paper we present some further extensions as well as some theoretical properties of the of the proposed measure. We illustrate the proposed evaluation method on documents in INFONA document retrieval system. We compare different search result clustering algorithms using the proposed measure.","","Electronic:978-1-4799-5464-3; POD:978-1-4799-5465-0","10.1109/GRC.2014.6982839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982839","","Approximation algorithms;Clustering algorithms;Decision trees;Indexes;Mutual information;Semantics","information retrieval;pattern clustering;text analysis","INFONA document retrieval system;SEE;quality analysis;semantic annotations;semantic evaluation by exploration;text clustering algorithms","","0","","16","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"The SCAPE preservation lifecycle","K. Duretec; A. Kulmukhametov; M. Kraxner; M. Plangg; C. Becker; L. Faria","Vienna University of Technology, Austria","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","425","426","Continuous activities such as preservation monitoring, planning and operations, including the provisioning of access mechanisms or the creation of derivatives through migration, are needed to enable continuous access to content across evolving technological contexts without affecting the authenticity of digital objects. This article describes the SCAPE preservation suite, a loosely coupled set of systems and open APIs that facilitate scalable content profiling, monitoring, planning and workflow execution.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970207","Digital Curation;Digital Preservation;Repositories;Scalability","Context;Decision support systems;Ecosystems;Face;Joining processes;Monitoring;Planning","application program interfaces;information retrieval;monitoring;planning (artificial intelligence)","API;SCAPE preservation lifecycle;access mechanisms;continuous access;digital objects;monitoring;planning;scalable content profiling;workflow execution","","0","","5","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"The ensemble of Naïve Bayes classifiers for hotel searching","J. Srisuan; A. Hanskunatai","Department of Computer Science, Faculty of Science, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand","2014 International Computer Science and Engineering Conference (ICSEC)","20141206","2014","","","168","173","The objective of the paper is to present a new ensemble of Naïve Bayes classifiers model for an application of hotel searching. The dataset were collected from 293 reviews of 15 hotels in Phuket. The main idea of the proposed model is to combine two models of Naïve Bayes classifiers with different feature selection techniques. The output of the searching model is a list of hotel names ranking by hotel probability related to user keywords. The searching performance of the ensemble model was compared with two classical searching methods: Boolean searching and Boyer-Moore searching. The results show that the ensemble of Naïve Bayes classifiers model provides the highest average rank_accuracy. In addition, the proposed model also takes the fastest time in searching when compared with the other techniques.","","Electronic:978-1-4799-4963-2; POD:978-1-4799-4962-5","10.1109/ICSEC.2014.6978189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978189","Ensemble model;Naïve Bayes classifier;hotel searchin;opinion mining","Classification algorithms;Computational modeling;Computer science;Data models;Equations;Mathematical model;Probability","Bayes methods;Boolean functions;hotel industry;information retrieval;pattern classification","Boolean searching;Boyer-Moore searching;Phuket;average rank_accuracy;ensemble model;hotel names;hotel probability;hotel searching;naïve Bayes classifiers;user keywords","","0","","15","","","July 30 2014-Aug. 1 2014","","IEEE","IEEE Conference Publications"
"Data Mining from NoSQL Document-Append Style Storages","R. K. Lomotey; R. Deters","Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada","2014 IEEE International Conference on Web Services","20141204","2014","","","385","392","The modern data economy, which has been described as ""Big Data"", has changed the status quo on digital content creation and storage. While data storage has followed the schema-dictated approach for decades, the recent nature of digital content, which is widely unstructured, creates the need to adopt different storage techniques. Thus, the NoSQL database systems have been proposed to accommodate most of the content being generated today. One of such NoSQL databases that have received significant enterprise adoption is the document-append style storage. The emerging concern and challenge however is that, research and tools that can aid data mining processes from such NoSQL databases is generally lacking. Even though document-append style storages allow data accessibility as Web services and over URL/I, building a corresponding data mining tool deviates from the underlying techniques governing web crawlers. Also, existing data mining tools that have been designed for schema-based storages (e.g., RDBMS) are misfits. Hence, our goal in this work is to design a unique data analytics tool that enables knowledge discovery through information retrieval from document-append style storage. The tool is algorithmically built on the inference-based Apriori, which aids us to achieve optimization of the search duration. Preliminary test results of the proposed tool also show high accuracy in comparison to other approaches that were previously proposed.","","Electronic:978-1-4799-5054-6; POD:978-1-4799-5055-3","10.1109/ICWS.2014.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6928922","Apriori;Bayesian Rule;Big Data;Data mining;NoSQL;Unstructured data","Association rules;Crawlers;Dictionaries;Spatial databases;Standards","Big Data;data analysis;data mining;database management systems;document handling;inference mechanisms;information retrieval","Big Data;NoSQL databases;NoSQL document-append style storages;data analytics tool;data mining;inference-based apriori;information retrieval;knowledge discovery","","2","","17","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"An indexing method of mathematical expression retrieval","X. Tian; S. Yang; X. Li; F. Yang","College of Mathematics & Computer Science, Hebei University, Baoding, China","Proceedings of 2013 3rd International Conference on Computer Science and Network Technology","20141201","2013","","","574","578","As the kernel component of scientific documents, mathematical expressions are becoming a new object of searching engines. Different from normal text, mathematical expressions are composed of various kinds of symbols arranged in nonlinear mode, which results in the limitations of traditional full-text information retrieval used for expression searching. In this paper, we discuss the existing search engine of mathematical expressions and introduce the two-dimensional characteristics of mathematical expressions firstly. Then, a data structure of expressing mathematical formulas is designed which contains not only the symbol code but also the mathematical information among symbols. Finally, the indexing algorithm of mathematical expressions is put forward on the basis of the expression data structure. The experimental result shows the effectiveness of the indexing method proposed in this paper.","","Electronic:978-1-4799-0561-4; POD:978-1-4799-0560-7","10.1109/ICCSNT.2013.6967179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967179","LaTeX;data structure;expression indexing;mathematical expressions retrieval;nonlinear","Data mining;Data structures;Educational institutions;Feature extraction;Indexing;Search engines","data structures;indexing;information retrieval;mathematics computing;search engines","data structure;indexing algorithm;kernel component;mathematical expression retrieval;mathematical information;nonlinear mode;scientific documents;search engine;symbol code;two-dimensional characteristics","","4","","17","","","12-13 Oct. 2013","","IEEE","IEEE Conference Publications"
"Alias extraction by giving entity name using lexical pattern based approach","N. S. Chapke; P. K. Bharne","Department of Computer Engineering, PG student, SSGMCE, Shegaon, India","2014 International Conference on Power, Automation and Communication (INPAC)","20141211","2014","","","141","145","Many celebrities and experts from various fields may have been referred by not only their personal names but also by their aliases. If the person is referred by using their alias then it would be difficult to find the complete information about the same. So it is important to know the aliases to make the search more reliable. Extracting aliases are important in many task such as information extraction, name disambiguation etc. The main purpose of the project is to show the aliases of a given personal name. If the user is new he has to create his profile first. Once created he can successfully search for the aliases by giving two types of input like by giving personal name as an input or by giving one of the alias amongst existing. Admin has the charge of uploading aliases information and he can upload the additional information too if needed. There is possibility that it may extract more aliases so it is important to know which most appropriate aliases are for that ranking function is used. The proposed method gives higher MRR(Mean Reciprocal Rank).","","Electronic:978-1-4799-7169-5; POD:978-1-4799-7170-1","10.1109/INPAC.2014.6981151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981151","Alias;Data Mining;Information extraction;Snippets","Blogs;Computers;Data mining;Engines;Security;Web search","data mining;information retrieval","MRR;alias extraction;data mining;information extraction;mean reciprocal rank;name disambiguation;personal names;ranking function","","0","","7","","","6-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"User's Interest Detection through Eye Tracking for Related Documents Retrieval","J. evcech; M. Bieliková","Fac. of Inf. & Inf. Technol., Slovak Univ. of Technol., Bratislava, Slovakia","2014 9th International Workshop on Semantic and Social Media Adaptation and Personalization","20141211","2014","","","9","13","In multiple studies, various implicit and explicit feedback types were used to quantify document quality and to identify user's interest in document content on both document and sub-document level. In this study we use eye movement data retrieved while reading a document to identify sections, user is most interested in. We describe multiple patterns in eye movement of users reading documents that can be used to identify important document fragments. The identified patterns are used to determine the user's interest in text fragments and to compare effectiveness of extracted document fragments and user created in-text highlights in the task of related document retrieval. Identified eye movement patterns allowed us to extract more important document sections compared to manual annotations with greater precision and consistency. Both types of compared interest indicators achieved similar performance in related document retrieval with the single most important difference: gaze based important section identification do not require active participation of the reader.","","Electronic:978-1-4799-6814-5; POD:978-1-4799-6815-2","10.1109/SMAP.2014.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978945","document retrieval;eye movement patterns;eye tracking;interest indicators;related document retrieval","Computers;Data mining;Data models;Libraries;Manuals;Tracking","digital libraries;feedback;gaze tracking;information retrieval","document fragments;document retrieval;explicit feedback;eye movement data;eye tracking;implicit feedback;interest detection;interest indicators;manual annotations;reading documents;section identification;text fragments","","0","","13","","","6-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"A new parallelization model for detecting temporal bursts in large-scale document streams on a multi-core CPU","K. Tamura; H. Kitakami","Graduate School of Information Sciences, Hiroshima City University, 3-4-1, Ozuka-Higashi, Asa-Minami-Ku, 731-3194, Japan","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","519","524","Burstiness is the simplest but the most robust criterion for detecting topics and events in online documents. Online documents are referred to as document streams because they have a temporal order. Kleinberg's temporal burst detection algorithm is the most successful algorithm for detecting bursty periods related to a topic- or event-related keyword. Kleinberg's temporal burst detection algorithm aims to find certain time periods in which a keyword occurs at a high frequency. In recent times, large-scale online documents are increasingly common on social media. Therefore, speed-up of burst-detection processing is one of the most important issues in this era of big data. In this paper, we propose a novel parallelization model, called the hybrid parallelization model with a hidden I/O thread, to enable the parallel processing of Kleinberg's temporal burst detection algorithm on a multi-core CPU. In a multi-core CPU environment, I/O latency is a critical issue for improving the performance of a parallelization model. To automatically hide the I/O latency, the proposed parallelization model utilizes speculative I/Os. The results of experiments using actual large-scale document streams show that the proposed parallelization model performs well compared with a conventional parallelization model.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973960","Burst detection;Document stream;Multi-core CPU;Parallel processing","Data models;Detection algorithms;Instruction sets;Media;Message systems;Parallel processing;Viterbi algorithm","Big Data;information retrieval;multiprocessing systems;parallel processing;social networking (online)","I/O latency;Kleinberg's temporal burst detection algorithm;big data;burst-detection processing;event-related keyword;hidden I/O thread;hybrid parallelization model;large-scale document streams;multicore CPU environment;online document topic detection;parallel processing;parallelization model;social media;temporal burst detection;topic-related keyword","","0","","21","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"The Organization information integration in the management of a Digital Library System","A. Di Iorio; M. Schaerf","DIAG - Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Via Ariosto 25, 00185, Rome, Italy","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","461","462","The Sapienza Digital Library collects digital resources from the different University's Organizations representing the multidisciplinary Sapienza University's community. The poster presents the pre-ingestion process for creating and aggregating digital resources, under the Organizational Collection conceptualization. The pre-ingestion building process had allowed to automatically provide information about the resources' custody from the origination, until their creation as OAIS Submission Information Package. Whatever system able to provide archival, preservation or dissemination services, could potentially use it, maintaining provenance information.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970225","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970225","Digital Libraries organization;Information integration;Workflow modeling","Buildings;Educational institutions;Information systems;Libraries;Organizations;Standards organizations","digital libraries;information dissemination;information retrieval systems;organisational aspects","OAIS submission information package;Sapienza University;Sapienza digital library;archival services;digital library system;digital resources;dissemination services;organization information integration;organizational collection conceptualization;preservation services","","1","","6","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Performance Evaluation of an IoT Platform","K. Vandikas; V. Tsiatsis","Manage. & Oper. of Complex Syst., Ericsson Res., Stockholm, Sweden","2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies","20141215","2014","","","141","146","The number of Internet of Things (IoT) deployments has grown in an unprecedented rate during the past few years. This expansion has led analysts and individual industrial companies to the prediction that a few tens of billions of devices will be deployed in the next decade in diverse industries such as automotive, utility, health, logistics and home automation. This growth in physical deployments and physical devices fuelled the development of cloud middleware for managing a large number of sensor data streams generated by the individual sensors. In this paper, we describe one such computational middleware, called IoT-Framework, built on open source components. The main objective of this framework is to disseminate the generated raw data streams as well as processed and fused streams to multiple interested parties. The IoT-Framework is using the RabbitMQ publish-subscribe system and the elasticsearch search and storage technology. In this paper we provide preliminary evaluation results on the performance of the combined operation of the two components.","2161-2889;21612889","CD-ROM:978-1-4799-5072-0; Electronic:978-1-4799-5073-7; POD:978-1-4799-5074-4","10.1109/NGMAST.2014.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982906","Internet of Things;RabbitMQ;computation;elasticsearch;engine;evaluation;performance;publish-subscribe","Databases;Java;Middleware;Optimization;Performance evaluation;Publish-subscribe;Throughput","Internet of Things;cloud computing;information retrieval;middleware;public domain software","Internet of things deployments;IoT Platform;IoT-framework;RabbitMQ publish-subscribe system;cloud middleware;elasticsearch search;individual industrial companies;open source components;performance evaluation;physical deployments;physical devices;sensor data streams;storage technology","","3","","27","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Effective personalized mobile search using KNN","K. Swati; A. J. Patankar","D Y Patil COE, Akurdi, University of Pune","2014 International Conference on Data Science & Engineering (ICDSE)","20141204","2014","","","157","160","Effective Personalized Mobile Search Using KNN, implements an architecture to improve user's personalization effectiveness over large set of data maintaining security of the data. User preferences are gathered through clickthrough data. Clickthrough data obtained is sent to the server in encrypted form. Clickthrough data obtained is classified into content concepts and location concepts. To improve classification and minimize processing time, KNN(K Nearest Neighborhood) algorithm is used. Preferences identified(location and content) are merged to provide effective preferences to the user. System make use of four entropies to balance weight between content concepts and location concepts. System implements client server architecture. Role of client is to collect user queries and to maintain them in files for future reference. User preference privacy is ensured through privacy parameters and also through encryption techniques. Server is responsible to carry out the tasks like training, reranking of the search results obtained and the concept extraction. Experiments are carried out on Android based mobile. Results obtained through experiments show that system significantly gives improved results over previous algorithm for the large set of data maintaining security.","","Electronic:978-1-4799-5460-5; POD:978-1-4799-5462-9","10.1109/ICDSE.2014.6974629","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974629","Clickthrough data;concept;location search;mobile search engine;ontology;personalization;user preferences","Androids;Classification algorithms;Mobile communication;Ontologies;Search engines;Servers;Vectors","client-server systems;cryptography;data privacy;information retrieval;mobile computing;pattern classification","Android based mobile;KNN;classification;clickthrough data;client-server architecture;concept extraction;data maintaining security;encryption techniques;k nearest neighborhood;personalized mobile search;user preference privacy","","0","","13","","","26-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Improvement on Wu-manber multi-pattern matching algorithm","L. Zhang; D. Wang; L. He; W. Wang","National Computer Network Emergency, Response Technical Team Coordination Center, Beijing, China","Proceedings of 2013 3rd International Conference on Computer Science and Network Technology","20141201","2013","","","608","611","With development of computer and network technology, string matching are widely used in information retrieval, intrusion detection, network data analysis and other fields. String matching algorithms and experimental analysis of previous studies are set in the pattern scale to tens of thousands of circumstances, for the large-scale pattern set algorithm was not conducted under the in-depth analysis. This paper studies the classic multi-pattern matching algorithm Wu-manber algorithm is proposed under large-scale pattern set algorithm based on Wu-manber three improved algorithms: hash based on the shortest length of the key algorithm, the value of pre-screening algorithm multi-hash, group comparison algorithm. Experiment results show that these improvements can enhance the capability and performance of classic Wu-Manber algorithm.","","Electronic:978-1-4799-0561-4; POD:978-1-4799-0560-7","10.1109/ICCSNT.2013.6967187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967187","multi-hash;pattern matching;pattern set scale;string matching;wu-manber","Algorithm design and analysis;Classification algorithms;Educational institutions;Intrusion detection;Pattern matching;Software algorithms;Vectors","cryptography;data analysis;information retrieval;string matching","Wu-Manber multipattern matching algorithm;computer technology;group comparison algorithm;information retrieval;intrusion detection;network data analysis;network technology;pre-screening algorithm multihash;string matching","","0","","15","","","12-13 Oct. 2013","","IEEE","IEEE Conference Publications"
"vCity Map: Crowdsensing towards visible cities","Y. Tobe; I. Usami; Y. Kobana; J. Takahashi; G. Lopez; N. Thepvilojanapong","Department of Integrated Information Technology, Aoyama Gakuin University, Sagamihara, Kanagawa, Japan","IEEE SENSORS 2014 Proceedings","20141215","2014","","","17","20","Crowdsensing is a powerful system to utilize the activities by people carrying mobile phones embedded many kinds of sensors. We have developed a system called vCity Map which uses crowdsensing to visualize the city environment for two kinds of information: sound and road conditions. For sound, we analyze the sound of passing automobiles. Collecting sound at many places help understand the atmosphere in the urban environment if the sound information is associated with time and place. For road conditions, bicycle riders who carry smartphones automatically upload the information. The acceleration signals obtained by the smartphones are separated into two signals, movement of the users' body and road condition by the combination of Independent Component Analysis (ICA) and Fourier Transform. Both of these two kinds of information is analyzed at a cloud side. Our work differs from the previous work in that analyzed information is mapped into the map and road condition is obtained using ICA.","1930-0395;19300395","Electronic:978-1-4799-0162-3; POD:978-1-4799-0160-9; USB:978-1-4799-0161-6","10.1109/ICSENS.2014.6984921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984921","crowdsensing;independent component analysis;smartphones;sound","Roads;Sensors;Smart phones","cartography;data visualisation;independent component analysis;information retrieval;smart phones","Fourier transform;ICA;city environment visualization;crowdsensing;independent component analysis;mobile phones;road condition;vCity Map system","","2","","10","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Improving Low Quality Stack Overflow Post Detection","L. Ponzanelli; A. Mocci; A. Bacchelli; M. Lanza; D. Fullerton","REVEAL @ Fac. of Inf., Univ. of Lugano, Lugano, Switzerland","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","541","544","Stack Overflow is a popular questions and answers (Q&A) website among software developers. It counts more than two millions of users who actively contribute by asking and answering thousands of questions daily. Identifying and reviewing low quality posts preserves the quality of site's contents and it is crucial to maintain a good user experience. In Stack Overflow the identification of poor quality posts is performed by selected users manually. The system also uses an automated identification system based on textual features. Low quality posts automatically enter a review queue maintained by experienced users. We present an approach to improve the automated system in use at Stack Overflow. It analyzes both the content of a post (e.g., simple textual features and complex readability metrics) and community-related aspects (e.g., popularity of a user in the community). Our approach reduces the size of the review queue effectively and removes misclassified good quality posts.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976134","","Communities;Entropy;Genetic algorithms;Indexes;Measurement;Readability metrics;Software","Web sites;information retrieval","Q&A Website;automated identification system;community related aspects;complex readability metrics;questions and answers;software developers;stack overflow post detection;textual features","","10","","11","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"SurfClipse: Context-Aware Meta-search in the IDE","M. M. Rahman; C. K. Roy","Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","617","620","Despite various debugging supports of the existing IDEs for programming errors and exceptions, software developers often look at web for working solutions or any up-to-date information. Traditional web search does not consider the context of the problems that they search solutions for, and thus it often does not help much in problem solving. In this paper, we propose a context-aware meta search tool, Surf Clipse, that analyzes an encountered exception and its context in the IDE, and recommends not only suitable search queries but also relevant web pages for the exception (and its context). The tool collects results from three popular search engines and a programming Q & A site against the exception in the IDE, refines the results for relevance against the context of the exception, and then ranks them before recommendation. It provides two working modes-interactive and proactive to meet the versatile needs of the developers, and one can browse the result pages using a customized embedded browser provided by the tool.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976153","Context-aware web search;context-relevance;errors and exceptions;meta search","Context;Measurement;Metasearch;Programming;Search engines;Search problems;Web search","online front-ends;query processing;question answering (information retrieval);recommender systems;search engines;ubiquitous computing","IDE;SurfClipse;Web pages;Web search;context-aware meta search tool;customized embedded browser;interactive mode;proactive mode;programming Q&A site;programming errors;programming exceptions;search queries","","0","","6","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"SNAC: The Social Networks and Archival Context project - Towards an archival authority cooperative","R. R. Larson; D. Pitti; A. Turner","School of Information, University of California, Berkeley, USA, 94720-4600","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","427","428","Social Networks and Archival Context (SNAC) is a multi-year research and demonstration project that aims to address the longstanding research challenge of discovering, locating, and using distributed historical resources. It also seeks to redefine traditional online access points for those resources, by exposing information about the people, families, and organizations who created them in addition to their socio-historical contexts. Finally, SNAC endeavors to set the stage for a cooperative program for maintaining names of creators of archival materials, via the Encoded Archival Context - Corporate Bodies, Persons, and Families (EAC-CPF) standard. This demonstration will show the prototype access and search systems for the second phase of SNAC, incorporating over 2 million records derived from Encoded Archival Descriptions (EAD), MARC Archival Records and EAC-CPF records from over 40 repositories and consortia including the Library of Congress, ArchivesHub, Archives nationales, the Bibliothèque nationale de France (BnF), and OCLC World-Cat.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970208","","Context;Educational institutions;Libraries;Materials;Merging;Organizations;Prototypes","information retrieval systems;social networking (online)","Archives nationales;ArchivesHub;Bibliothèque nationale de France;BnF;EAC-CPF standard;Encoded Archival Context Corporate Bodies-Persons-Families standard;Library of Congress;MARC Archival Records;OCLC World-Cat;archival materials;distributed historical resources;online access points;social networks and archival context;sociohistorical contexts","","0","","","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"A robust scheme on proof of data retrievability in cloud","N. S. Chauhan; A. Saxena","Infosys Labs, Infosys Ltd, Hyderabad-500032, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","665","671","In the era of rampant adoption of information technology and social networking, data generation is rapidly outpacing data storage resources. Cloud computing has emerged as cost effective, flexible and scalable alternate to address issue of increasing resource requirements. Though the advantages offered by such services appear attractive, there are certain inherent challenges related to trust and data security. Ensuring data integrity and retrievability of data in cloud is one such challenge. Proof of retrievability (POR) concept tries to establish assurance for cloud customer regarding correctness and completeness of their data. In this paper, we evaluate an already existing POR scheme and propose a new crypto based scheme which helps in reducing the amount of computation and storage at cloud customer side while establishing POR. In our scheme client is not required to store any large set of data locally except a secret key which is required for encryption. Compare to previous scheme, we also avoid the necessity of encrypting entire data at client side, thereby saving client computational resources. The proposed scheme is relevant for large static data such as video files, audio files and social networking data etc.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968574","Proof of retrievability;cloud computing;data integrity;mobile computing;thin clients","Cloud computing;Complexity theory;Encryption;Memory;Servers","cloud computing;cryptography;data integrity;information retrieval;trusted computing","POR;cloud computing;cloud customer;crypto based scheme;data completeness;data correctness;data generation;data integrity;data retrievability;data security;data storage resources;encryption;information technology;proof of retrievability;resource requirements;secret key;social networking;trust","","0","","28","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Extracting Semantic Information from Patent Claims Using Phrasal Structure Annotations","D. S. d. Carvalho; F. M. G. França; P. M. V. Lima","Syst. Eng. & Comput. Sci. Program - COPPE, Univ. Fed. do Rio de Janeiro, Rio de Janeiro, Brazil","2014 Brazilian Conference on Intelligent Systems","20141215","2014","","","31","36","The rapid change of trading values from tangible assets to Intelectual Property has put both businesses and academia in a race to acquire and protect the rights to exploit such property. This is mainly accomplished in the form of patent issuing by the governments, being time consuming and complicated due to the vast amount of documents that need to be analyzed in order to assert the novelty or validity of a patent application. Patent information retrieval research is thus growing quickly to support document analysis across multiple domains and information systems. One of the big challenges in patent analysis is the identification of the elements of innovation (concepts, processes, materials) and the relations between them, in the patent text. This paper presents a method for extracting semantic information from patent claims by using semantic annotations on phrasal structures, abstracting domain ontology information and outputting ontology-friendly structures to achieve generalization. An extraction system built upon the method is briefly evaluated on a document sample from INPI, the Brazilian patent office, a challenging information source.","","Electronic:978-1-4799-5618-0; POD:978-1-4799-7859-5","10.1109/BRACIS.2014.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984803","Machine Learning;Natural Language Processing;Patent Information Extraction;Semantic Relation Extraction;Semantic Segmentation","Data mining;Ontologies;Patents;Semantics;Syntactics;Testing;Training","information retrieval;ontologies (artificial intelligence);patents;text analysis","document analysis;intellectual property;ontology-friendly structure;patent claims;patent information retrieval;phrasal structure annotation;semantic annotation;semantic information","","0","","20","","","18-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"CoMoGen: An Approach to Locate Relevant Task Context by Combining Search and Navigation","K. Kevic; T. Fritz; D. C. Shepherd","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","61","70","Developers spend a substantial amount of time searching and navigating source code to locate the relevant places for performing a change task. While the searching and navigating are highly intertwined and related, most current approaches focus either on search or on navigation support for developers, keeping the two distinct. In this paper, we present an approach called CoMoGen that combines search and navigation by expanding, ranking and visualizing search results with navigation context. In an experimental analysis we found that our approach is able to generate small task-relevant context models that locates more relevant search results than state-of-the-art and state-of-the-practice search approaches. A small, preliminary user study with ten participants further yields promising preliminary findings that CoMoGen supports developers in better understanding and assessing the relevance of search results and in reducing navigation steps.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976072","","Conferences;Navigation;Software maintenance;Visualization","information retrieval;search engines","CoMoGen;relevant task context;search and navigation;task-relevant context model","","0","","53","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"Lend me some sugar: Borrowing rates of neighbouring books as evidence for browsing","D. McKay; W. Smith; S. Chang","University of Melbourne, Parkville, VIC 3010, Australia","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","145","154","There is more to choosing a book than simply keyword searching. Browsing is a fundamental part of the information seeking process, and one that information seekers profess to value, though it has attracted little study. This dearth of research is undoubtedly in part because browsing is nebulous and difficult to quantify. In this paper we use a large circulation dataset from an academic library consortium to examine whether books in the library stacks are loaned in clusters, with a view firstly to confirming the existence of book browsing that has been reported anecdotally, and secondly to quantifying its impact on loan patterns.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970161","Libraries;books;browsing;classification systems;digital libraries;information seeking;log analysis","Australia;Educational institutions;Electronic publishing;Indexes;Libraries;Object recognition;Testing","academic libraries;digital libraries;information retrieval","academic library consortium;borrowing rates;browsing;information seekers;information seeking process;keyword searching;library stacks;loan patterns;neighbouring books","","1","","76","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Dynamic partition and replication algorithm for storage capacity limited distributed social network","P. Lv; Q. Deng","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China","2014 IEEE International Conference on Progress in Informatics and Computing","20141204","2014","","","400","404","Large scale online social networks (OSN) are usually based on distributed storage systems. The data of users are distributed on multiple storage and computing nodes to provide concurrency and redundancy. How to store and access user data efficiently in OSN system with limited storage has practical significance. This paper proposes a dynamic partitioning and replication algorithm, which partitions and replicates user data periodically in line with the frequency of user interaction, in order to improve local access ratio and reduce system communication load. Through experiment on a real-world dataset, this paper testifies that compared with random partitioning and replication, the proposed algorithm could improve local access ratio greatly, and finally reduce access latency.","","CD-ROM:978-1-4799-2031-0; Electronic:978-1-4799-2030-3; POD:978-1-4799-2032-7","10.1109/PIC.2014.6972365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972365","distributed storage system;dynamic partition and replication;online social network;storage capacity limited","Clustering algorithms;Heuristic algorithms;History;Partitioning algorithms;Redundancy;Social network services;Time factors","concurrency control;information retrieval;social networking (online)","OSN system;computing nodes;concurrency;distributed storage systems;dynamic partitioning;large scale online social networks;multiple storage;random partitioning;random replication;real-world dataset;replication algorithm;storage capacity limited distributed social network;system communication load reduction;user data access;user data replication;user data storage;user interaction","","0","","6","","","16-18 May 2014","","IEEE","IEEE Conference Publications"
"Fast Similarity Search Using Multiple Binary Codes","S. Shirakawa","Coll. of Sci. & Eng., Aoyama Gakuin Univ., Sagamihara, Japan","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3714","3719","One of the fast similarity search techniques is a binary hashing method that transforms a real-valued vector into a binary code. The similarity between two binary codes is measured by their Hamming distance. In this method, a hash table is often used for realizing the constant time similarity search. The number of accesses to the hash table, however, increases when the number of bits becomes long. In this paper, we consider the method that does not access the data with long Hamming radius by using multiple binary codes. Then, we propose the learning method of the binary hash functions for multiple binary codes. We conduct the experiment on similarity search utilizing up to 20 million data set, and show that our proposed method achieves a fast similarity search compared with the conventional linear scan and hash table search.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977350","Binary hash;image retrieval;machine learning;similarity search","Binary codes;Computational efficiency;Databases;Hamming distance;Linear programming;Training;Vectors","binary codes;file organisation;information retrieval;learning (artificial intelligence);vectors","Hamming distance;Hamming radius;binary hash functions;binary hashing method;constant time similarity search;fast similarity search techniques;hash table;learning method;multiple binary codes;real-valued vector","","0","","15","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
