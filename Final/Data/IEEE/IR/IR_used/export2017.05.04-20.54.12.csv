"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5414346,5372708,5414228,5414140,5413350,5413065,5412205,5412651,5413629,5413558,5414454,5413556,5412429,5413554,5414506,5412200,5372709,5412373,5414634,5414229,5372704,5372719,5414572,5412347,5413515,5412614,5414313,5413444,5413537,5372777,5413233,5413380,5414011,5414097,5413405,5413982,5413921,5412598,5413408,5414503,5413361,5413815,5342498,5337999,5410051,5408024,5409726,5410708,5406468,5406185,5406948,5405693,5407184,5405860,5405823,5406546,5405705,5406539,5406582,5407487,5407527,5406567,5406445,5403278,5403111,5403104,5402980,5403423,5402975,5403068,5401268,5399293,5402568,5402569,5401297,5401261,5402485,5402558,5402570,5402610,5400020,5401527,5400695,5395052,5395500,5394368,5393605,5393318,5393866,5396008,5393628,5395493,5395068,5395140,5395316,5396065,5397714,5397713,5397711,5397469",2017/05/04 20:54:12
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Rendition-based video editing for public contents authoring","A. Yoshitaka; Yoshiki Deguchi","School of Information Science, Japan Advanced Institute of Science and Technology, 1-1 Nomi, Asahidai, Ishikawa, 923-1292 Japan","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1825","1828","Previous video editing is performed by specifying cutting points in a sequence of video frames and combining the trimmed shots together. In order to emphasize a nonverbal, emotional information of a scene effectively, we need to edit a video sequence so that it follows `film grammar' or cinematography, which is the technique for effective expression of the scene in a film. In this paper, we propose a new framework of rendition-based video editing. Instead of specifying cutting points of a video sequence, an editor specifies the type of emotional expression that he/she likes to emphasize. Consequently, desirable transition of shot duration and shot combination are determined, and video contents are semi-automatically edited so as to follow the film grammar.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413558","","Atmosphere;Cameras;Cinematography;Content based retrieval;Gunshot detection systems;Information retrieval;Information science;Layout;Motion pictures;Video sequences","cinematography;image sequences;video signal processing","cinematography;film grammar;public contents authoring;rendition-based video editing;video frames sequence","","3","","8","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Real-time inference of 3D human poses by assembling local patches","K. Hara","Intelligent Systems Lab, SECOM CO., LTD., Tokyo, 181-8528 Japan","2009 Workshop on Applications of Computer Vision (WACV)","20100202","2009","","","1","8","This paper presents a novel patch-based approach for 3D human body pose estimation from a static silhouette image. Our approach uses a database which contains example patches extracted from different parts of images rendered using a 3D human body model in various poses. Each example patch is represented as a shape context histogram and contains pose parameters of the model that is used to render the image. At the estimation step, example patches in the database that have a similar shape context to patches extracted from the input silhouette image are rapidly retrieved using a modified locality-sensitive hashing algorithm. The pose parameters are then estimated by a probabilistic Hough voting scheme in a hierarchical manner. Our approach is flexible and needs a small number of examples since combinations of local patches can be used to identify previously unseen entire poses. Thus, it is not necessary for every possible pose to be stored in the database. This property significantly reduces computation time. Experiments have shown that our proposed method can handle a variety of unseen articulations and output accurate pose estimations in real time.","1550-5790;15505790","Electronic:978-1-4244-5498-3; POD:978-1-4244-5497-6","10.1109/WACV.2009.5403111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403111","","Assembly;Biological system modeling;Context modeling;Histograms;Humans;Image databases;Image retrieval;Information retrieval;Rendering (computer graphics);Shape","pose estimation;visual databases","3D human body pose estimation;database;local patches;modified locality-sensitive hashing algorithm;probabilistic Hough voting scheme;shape context histogram;static silhouette image","","3","","16","","","7-8 Dec. 2009","","IEEE","IEEE Conference Publications"
"Shape geodesics for boundary-based object recognition and retrieval","K. Nasreddine; A. Benzinou; R. Fablet","ENIB, RESO (EA 3380), 29238 BREST (FRANCE)","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","405","408","In this paper we define a distance between shapes based on geodesics in shape space. The proposed distance, robust to outliers, uses shape matching to compare shapes locally. Multiscale analysis is introduced in order to avoid problems of local and global variabilities. The resulting similarity measure is invariant to translation, rotation and scaling independently of constraints or landmarks, but constraints can be added to the approach formulation when needed. An evaluation of the proposed approach is reported for shape classification and retrieval on a complex benchmark shape database. It demonstrates in both cases that previous work is outperformed.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414454","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414454","Image shape analysis;image matching;object recognition;robustness","Computer vision;Databases;Information retrieval;Level measurement;Object recognition;Robustness;Rotation measurement;Shape measurement;Skeleton;Testing","differential geometry;image matching;image retrieval;object recognition","boundary-based object recognition-retrieval;complex benchmark shape database;multiscale analysis;shape classification;shape geodesics;shape matching;shape retrieval","","1","","19","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Image pre-classification based on saliency map for image retrieval","Z. Liang; H. Fu; Z. Chi; D. Feng","Centre for Multimedia Signal Processing, Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong, China","2009 7th International Conference on Information, Communications and Signal Processing (ICICS)","20100122","2009","","","1","5","In content-based image retrieval, it is helpful to add a pre-classification module to classify a query image into attentive class or non-attentive class. Based on the pre-classification result, a suitable retrieval strategy is adopted for the query image presented. In this paper, we proposed a Multi-Layer Perceptron (MLP) classifier with the features extracted from saliency map to classify both the query image and database images into attentive images and non-attentive classed. A dataset of 1,000 images was selected from the 7,346 Hemera color image database for our experiments. Various features extracted from the saliency map are investigated, including the number and the average size of saliency regions, the variance of the sizes of saliency regions, as well as the sizes of the three most conspicuous saliency regions. The number and average size of saliency regions in the saliency map are shown to be the most discriminative features with which a classification rate of better than 98% can be achieved. To facilitate multi-strategy image retrieval, we define an attentive index between 0 and 1 based on the two most discriminative features to indicate how attentive an image is. Finally, two image retrieval strategies based on the attentive index are proposed, and the corresponding image retrieval performances are evaluated on the 7,346 Hemera color image database with a comparison with the other conventional image retrieval methods.","","Electronic:978-1-4244-4657-5; POD:978-1-4244-4656-8","10.1109/ICICS.2009.5397714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5397714","Image classfication;attentive index;attentive objects;image retrieval;non-attentive objects;saliency map","Color;Content based retrieval;Feature extraction;Image databases;Image retrieval;Indexes;Information retrieval;Multilayer perceptrons;Performance evaluation;Spatial databases","content-based retrieval;feature extraction;image classification;image retrieval;multilayer perceptrons;query formulation;visual databases","attentive images;attentive index;content-based image retrieval;database image classification;features extraction;image preclassification module;multilayer perceptron classifier;nonattentive images;query image classification;saliency map","","2","","11","","","8-10 Dec. 2009","","IEEE","IEEE Conference Publications"
"Query translation from SQL to XPath","P. M. Vidhya; P. Samuel","Department of Computer Science, Cochin University of Science & Technology, India","2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)","20100122","2009","","","1749","1752","Today XML is the de facto standard of data exchange format for the information on the Web. At the same time, database systems are well known for consistent storage, retrieval and manipulation of data. XML querying language (XPath) is used to access XML documents whereas Structured Query Language (SQL) for retrieving and manipulating data in relational database. It may not be possible for users and developers to be familiar with both the query languages easily and quickly. Here, we examine how XML data can be queried using SQL. In this paper, we propose a new concept and framework where SQL statements can be easily transformed to XPath expressions. We use SQL, as it has long been the standard language. Users can access XML database and relational database through the query language SQL using our framework. We present algorithms for translating queries expressed in SQL (SELECT, DELETE, RENAME) to XPath. The procedure provides relational interface to XML database and the experimental results validate the proposed approach.","","Electronic:978-1-4244-5052-7; POD:978-1-4244-5053-4","10.1109/NABIC.2009.5393628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393628","Query Translation;SQL;XML;XML Database;XPath","Books;Computer science;Database languages;Database systems;Information retrieval;Internet;Navigation;Relational databases;Transaction databases;XML","SQL;XML;document handling;electronic data interchange;query processing;relational databases","Structured Query Language;World Wide Web;XML database;XML documents;XML querying language;XPath;data exchange format;data manipulation;data retrieval;data storage;database systems;de facto standard;query translation;relational database","","0","","13","","","9-11 Dec. 2009","","IEEE","IEEE Conference Publications"
"Emotional identity of movies","L. Canini; S. Benini; P. Migliorati; R. Leonardi","DEA-SCL, University of Brescia, Via Branze 38, 25123, Italy","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1821","1824","In the field of multimedia analysis, attempts that lead to an emotional characterization of content have been proposed. In this work we aim at defining the emotional identity of a feature movie by positioning it into an emotional space, as if it was a piece of art. The multimedia content is mapped into a trajectory whose coordinates are connected to filming and cinematographic techniques used by directors to convey emotions. The trajectory evolution over time provides a strong characterization of the movie, by locating different movies into different regions of the emotional space. The ability of this tool in characterizing content has been tested by retrieving emotionally similar movies from a large database, using IMDb genre classification for the evaluation of results.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413556","Emotional identity;Video retrieval","Art;Computer industry;Content based retrieval;Hidden Markov models;Information retrieval;Motion pictures;Multimedia databases;Multimedia systems;Testing;Trajectory","cinematography;emotion recognition;image classification;multimedia computing;video retrieval","IMDb genre classification;cinematographic technique;database;emotional characterization;emotional identity;movies;multimedia analysis;trajectory evolution;video retrieval","","8","","12","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"The application of particle swarm optimization in relevance feedback","Xiangli Xu; Libiao Zhang; Zhezhou Yu; Chunguang Zhou","College of Computer Science and Technology,Jilin University, Changchun, China","2009 International Conference on Future BioMedical Information Engineering (FBIE)","20100205","2009","","","156","159","Particle swarm optimization(PSO) algorithm is applied in relevance feedback(RF) of image retrieval, which is combined with user feedback process effectively, The proposed method makes users' understanding to the retrieval goal become clear gradually, it could search image database effectively and comprehensively, and at the same time it could avoid the contradiction of efficiency and retrieval effect caused by multi-feedback. Experiments show that the proposed algorithm is validity.","2157-9598;21579598","Electronic:978-1-4244-4691-9; POD:978-1-4244-4690-2","10.1109/FBIE.2009.5405860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5405860","image retrieval;particle swarm optimization;relevance feedback","Biomedical engineering;Content based retrieval;Educational technology;Image retrieval;Information retrieval;Knowledge engineering;Negative feedback;Paper technology;Particle swarm optimization;Radio frequency","image retrieval;particle swarm optimisation;relevance feedback;visual databases","PSO algorithm;image database search;image retrieval;particle swarm optimization application;relevance feedback;user feedback process","","0","","11","","","13-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"Implementation of Web Crawler","P. Gupta; K. Johari","Linagay's Univ., India","2009 Second International Conference on Emerging Trends in Engineering & Technology","20100122","2009","","","838","843","The World Wide Web is an interlinked collection of billions of documents formatted using HTML. Ironically the very size of this collection has become an obstacle for information retrieval. The user has to shift through scores of pages to come upon the information he/she desires. Web crawlers are the heart of search engines. Web crawlers continuously keep on crawling the web and find any new web pages that have been added to the web, pages that have been removed from the web. Due to growing and dynamic nature of the web; it has become a challenge to traverse all URLs in the web documents and to handle these URLs. A focused crawler is an agent that targets a particular topic and visits and gathers only relevant web pages. In this dissertation I had worked on design and working of web crawler that can be used for copyright infringement. We will take one seed URL as input and search with a keyword, the searching result is based on keyword and it will fetch the web pages where it will find that keyword. This focused based crawler approach retrieve documents that contain particular keyword from the user's query; we are implementing this using breadth-first search. Now, when we retrieved the web pages we will apply pattern recognition over text. We will give one file as input and apply the pattern recognition algorithms. Here, pattern symbolizes text only and check how much text is available on the web page. The algorithms that I had used for pattern search are Knutt-Morri-Pratt, Boyer-Moore, finite automata algorithm.","2157-0477;21570477","Electronic:978-0-7695-3884-6; POD:978-1-4244-5250-7","10.1109/ICETET.2009.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5395052","","Automata;Crawlers;HTML;Heart;Information retrieval;Pattern recognition;Search engines;Uniform resource locators;Web pages;Web sites","Internet;Web sites;finite automata;hypermedia markup languages;information retrieval;search engines","Boyer-Moore algorithm;HTML;Knutt-Morri-Pratt algorithm;URL;Web crawler;Web pages;World Wide Web;breadth-first search;copyright infringement;finite automata algorithm;information retrieval;pattern recognition algorithms;search engines;web documents","","7","","10","","","16-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"Towards Timbre-Invariant Audio Features for Harmony-Based Music","M. Muller; S. Ewert","Saarland University and the Max-Planck Institut f&#252;r Informatik, Saarbr&#252;cken, Germany","IEEE Transactions on Audio, Speech, and Language Processing","20100208","2010","18","3","649","662","Chroma-based audio features are a well-established tool for analyzing and comparing harmony-based Western music that is based on the equal-tempered scale. By identifying spectral components that differ by a musical octave, chroma features possess a considerable amount of robustness to changes in timbre and instrumentation. In this paper, we describe a novel procedure that further enhances chroma features by significantly boosting the degree of timbre invariance without degrading the features' discriminative power. Our idea is based on the generally accepted observation that the lower mel-frequency cepstral coefficients (MFCCs) are closely related to timbre. Now, instead of keeping the lower coefficients, we discard them and only keep the upper coefficients. Furthermore, using a pitch scale instead of a mel scale allows us to project the remaining coefficients onto the 12 chroma bins. We present a series of experiments to demonstrate that the resulting chroma features outperform various state-of-the art features in the context of music matching and retrieval applications. As a final contribution, we give a detailed analysis of our enhancement procedure revealing the musical meaning of certain pitch-frequency cepstral coefficients.","1558-7916;15587916","","10.1109/TASL.2010.2041394","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5410051","Audio matching;chroma feature;mel-frequency cepstral coefficient (MFCC);music retrieval;pitch feature;timbre-invariance","Art;Boosting;Cepstral analysis;Degradation;Discrete cosine transforms;Instruments;Mel frequency cepstral coefficient;Music information retrieval;Robustness;Timbre","audio signal processing;cepstral analysis;music","audio matching;equal-tempered scale;harmony-based music;mel-frequency cepstral coefficients;pitch feature;timbre-invariant audio features","","30","","39","","","March 2010","","IEEE","IEEE Journals & Magazines"
"A multi-scale learning approach for landmark recognition using mobile devices","T. Chen; Z. Li; K. H. Yap; K. Wu; L. P. Chau","School of Electrical and Electronic Engineering Nanyang Technological University, Singapore","2009 7th International Conference on Information, Communications and Signal Processing (ICICS)","20100122","2009","","","1","4","The growing usage of mobile camera phones has led to proliferation of many mobile applications. Landmark recognition is one of the mobile applications that are gaining more attention in recent years. The main idea of the application is that a user will use a camera phone to capture the image of a landmark or building and then the system will analyze, identify, and inform the user the name of the captured landmark together with its related information. A new mobile landmark recognition method is proposed in this paper: first, a set of multi-scale patches are extracted from the landmark images. Discriminative patches of the images are then selected based on a Gaussian mixture model (GMM). A combination of color, texture and scale-invariant feature transform (SIFT) descriptors are then extracted from the selected patches. They are used to train support vector machine (SVM) classifiers for each category of landmark. Experimental results using a database of 4000 landmark images illustrate the effectiveness of the proposed method.","","Electronic:978-1-4244-4657-5; POD:978-1-4244-4656-8","10.1109/ICICS.2009.5397713","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5397713","Gaussian mixture model;mobile landmark recognition;multi-scale patches;support vector machine","Cameras;Data mining;Image analysis;Information analysis;Information retrieval;Mobile handsets;Navigation;Robustness;Support vector machine classification;Support vector machines","Gaussian processes;feature extraction;image colour analysis;image recognition;image texture;learning (artificial intelligence);mobile computing;mobile handsets;support vector machines","Gaussian mixture model;building image;image color analysis;image texture;images patches;landmark images;landmark recognition;mobile camera phones;multiscale learning approach;multiscale patch extraction;scale-invariant feature transform descriptors;support vector machine classifiers","","7","","15","","","8-10 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Location Based Text Mining Approach for Geospatial Data Mining","C. H. Lee; H. C. Yang; S. H. Wang","Dept. of Electr. Eng., Nat. Kaohsiung Univ. of Appl. Sci., Kaohsiung, Taiwan","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","1172","1175","In this paper, we describe a location based text mining approach to classify texts into various categories based on their geospatial features, with the aims to discovering relationships between documents and zones. We first mapped documents into corresponding zones by adaptive affinity propagation (adaptive AP) clustering technique, and then framed maximize zones by means of simplified fuzzy ARTMAP (SFAM) and support vector machines (SVM) methods. Also, we compared our experimental results with the baseline approaches of self-organizing maps (SOM) and learning vector quantization (LVQ) methods. The preliminary results show that our platform framework has the potential for geospatial data mining.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412429","","Data mining;Information management;Information retrieval;Multimedia databases;Ontologies;Self organizing feature maps;Support vector machine classification;Support vector machines;Text mining;Vector quantization","data mining;fuzzy set theory;geophysics computing;pattern clustering;self-organising feature maps;support vector machines;text analysis","SVM;adaptive AP clustering technique;adaptive affinity propagation;geospatial data mining;geospatial features;learning vector quantization;location based text mining approach;self-organizing maps;simplified fuzzy ARTMAP;support vector machines;text classification","","1","","17","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Gray system theory based study on constructing school education-teaching resources database","Z. Donghong","Shanghai Pudong Institute of Education Development, No. 10, 658 nong, Zaozhuang road, Shanghai, CO 200136 China","2009 IEEE International Conference on Grey Systems and Intelligent Services (GSIS 2009)","20100208","2009","","","998","1002","Constructing school education-teaching resources database will help accumulate education teaching resources which are suitable for the school teaching and learning. In this paper, using the data of 2008 obtained in Pudong New Area education information special supervision, we try to make correlation analysis about dependence on school education-teaching resources database when teacher search for resources, and case of its structure, such as scale, quality, technical specifications, used-time, to find out the aim of constructing school education-teaching resources database.","2166-9430;21669430","Electronic:978-1-4244-4916-3; POD:978-1-4244-4914-9","10.1109/GSIS.2009.5408024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5408024","","Books;Deductive databases;Education;Educational institutions;Error analysis;Information analysis;Information retrieval;Intelligent systems;Mathematics;Quality management","database management systems;educational computing;grey systems;teaching","Pudong New Area education information special supervision;correlation analysis;gray system theory;school education-teaching resources database construction","","0","","10","","","10-12 Nov. 2009","","IEEE","IEEE Conference Publications"
"Optimization on active learning strategy for object category retrieval","D. Gorisse; M. Cord; F. Precioso","ETIS, CNRS/ENSEA/UCP, Univ Cergy-Pontoise, France","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1873","1876","Active learning is a machine learning technique which has attracted a lot of research interest in the content-based image retrieval (CBIR) in recent years. To be effective, an active learning system must be fast and efficient using as few (relevance) feedback iterations as possible. Scalability is the major problem for such an on-line learning method, since the complexity of such methods on a database of size n is in the best case O(n * log(n)). In this article we propose a strategy to overcome this limitation. Our technique exploits ultra fast retrieval methods like Locality Sensitive Hashing (LSH), recently applied for unsupervised image retrieval. Combined with active selection, our method is able to achieve very fast active learning task in very large database. Experiments on VOC2006 database are reported, results are obtained four times faster while preserving the accuracy.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413554","active learning;image retrieval;locality sensitive hashing;relevance feedback;support vector machines","Computational complexity;Feedback;Histograms;Image databases;Image retrieval;Indexes;Information retrieval;Learning systems;Machine learning;Scalability","computational complexity;content-based retrieval;image retrieval;learning (artificial intelligence);relevance feedback","VOC2006 database;active learning strategy;computational complexity;content-based image retrieval;locality sensitive hashing;machine learning technique;object category retrieval;relevance feedback iterations;very large database","","1","","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"J2EE framework perspective for security augmentation","P. K. Verma; N. Singh; R. Katarya","Department of Computer Science & Engineering Jaypee University of Information Technology, Waknaghat, India","TENCON 2009 - 2009 IEEE Region 10 Conference","20100122","2009","","","1","6","The creation of efficient and secure framework is becoming important with the rapid development of internet and World Wide Web (WWW). The objective of this paper is to examine the web based framework to retain the information of any organization. Thus, we propose a new scaffold on the basis of JSP Access Model and Model-View-Controller (MVC), which will assist in providing information regarding users and some indispensable services to several organizations. This framework also provides better security then other frameworks. In turn it supports faster retrieval and processing of data. For the implementation of this framework different approaches of software engineering are being used. In this paper work we discuss this framework with Java programming language, because Java is more popular and secure programming language for web application.","2159-3442;21593442","Electronic:978-1-4244-4547-9; POD:978-1-4244-4546-2","10.1109/TENCON.2009.5396008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5396008","Data Retrieval;Digital Signature;Framework;JSP;Kerberos;Servl et;Web Application","Application software;Computer languages;Data security;Information retrieval;Information security;Internet;Java;Software engineering;Web sites;World Wide Web","Internet;Java;security of data","Internet;J2EE framework;JSP access model;Java programming language;Web based framework;World Wide Web;data processing;data retrieval;model view controller;security augmentation;software engineering","","0","","14","","","23-26 Jan. 2009","","IEEE","IEEE Conference Publications"
"Efficient image retrieval in DCT domain by hypothesis testing","D. He; Z. Gu; N. Cercone","Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","225","228","We consider a hypothesis testing approach to content-based image retrieval (CBIR) using discrete cosine transform (DCT) coefficients restored by partially decoding JPEG images. In order to further decorrelate DC coefficients from an image, a 2 Ã 2 DCT is performed on the sub-image constructed from all the DC coefficients. Assume that each DCT coefficient sequence is emitted from a memoryless source, and all these sources are independent of each other. For each target image we form a hypothesis that its DCT coefficient sequences are emitted from the same sources as the corresponding sequences in the query image. Testing these hypotheses by measuring the log-likelihoods leads to a simple yet efficient scheme that ranks each target image according to the Kullback-Leibler (KL) divergence between the empirical distribution of the DCT coefficient sequences in the query image and that in the target image. Experiments on two image datasets show that our approach achieves consistently better retrieval results than related methods in the literature.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414506","CBIR;DCT;JPEG;KL divergence;hypothesis testing","Content based retrieval;Data mining;Decoding;Discrete cosine transforms;Feature extraction;Image coding;Image retrieval;Information retrieval;Testing;Transform coding","content-based retrieval;decoding;discrete cosine transforms;image coding;image retrieval;image sequences","DCT coefficient sequences;JPEG image decoding;Kullback-Leibler divergence;content-based image retrieval;discrete cosine transform;empirical distribution;log-likelihoods;query image coefficient sequences","","2","","14","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Network and content aware information management","S. Boldyrev; I. Oliver; R. Brown; J. M. Tuupola; A. Palin; A. Lappetelainen","Nokia Research Centre, Ubiquitous Architectures","2009 International Conference for Internet Technology and Secured Transactions, (ICITST)","20100129","2009","","","1","7","The presented approach addresses the problem of query and persistent query (subscription) resolution, taking into consideration distribution across multi-domains, network infrastructure and content management. This approach is particularly suitable for information-centric and cloud computing applications based around a mobile-device infrastructure.","","Electronic:978-1-4244-5648-2; POD:978-1-4244-5647-5","10.1109/ICITST.2009.5402569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402569","","Cameras;Cloud computing;Computer architecture;Content management;Delay;Displays;Information management;Information retrieval;Microphones;Subscriptions","content management;information management;persistent objects;query processing;ubiquitous computing","cloud computing applications;content aware information management;information-centric applications;mobile-device infrastructure;network infrastructure;persistent query resolution","","0","10","16","","","9-12 Nov. 2009","","IEEE","IEEE Conference Publications"
"An Optimal Choice of Morphological Operating Center for Object Image Retrieval","H. Hama; T. T. Zin; P. Tin","Grad. Sch. of Eng., Osaka City Univ., Osaka, Japan","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","298","301","In this paper we introduce a novel and simple schemes to develop an optimal choice of morphological Operating Center (OC) for object image retrieval. A variation of the standard morphological operators which require the choice of an OC is discussed. The proposed method is based on combinations of statistical and dynamic programming techniques in which recursive equations on the basis of dilation by using the principle of optimality and minimizing unnecessary background area of the objects are applied. We also present the application of mathematical morphology with Structuring Elements (SEs) which are elongated in the angular direction. The experimental results show that the optimal choice of OC provides satisfying retrieval results.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412200","","Data mining;Dynamic programming;Feature extraction;Image analysis;Image retrieval;Information retrieval;Lattices;Morphology;Optimal control;Shape","dynamic programming;image retrieval;mathematical morphology;object detection","dilation;dynamic programming techniques;mathematical morphology;morphological Operating Center;object image retrieval;optimality principle;statistical programming techniques;structuring elements","","0","","12","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"A novel approach to image edge enhancement using Artificial Bee Colony optimization algorithm for hybridized smoothening filters","T. R. Benala; S. H. Villa; S. D. Jampala; B. Konathala","Dept. of CSE, ANITS, Visakhapatnam, India","2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)","20100122","2009","","","1071","1076","In this modern era, image transmission and processing plays a major role. It would not be possible to retrieve information from satellite and medical images without the help of image processing techniques. Image edge enhancement is the art of examining images for identifying objects and judging their significance. The proposed work uses the concept of artificial bee colony algorithm which proved to be the most powerful unbiased optimization technique for sampling a large solution space. Because of its unbiased stochastic sampling, it was quickly adapted in image processing and thus for image edge enhancement as well. This paper deals with the techniques that help in improvising the quality of the image edges and in solving various complex image processing tasks such as segmentation, feature extraction, classification and image generation. The edge enhancement is done using hybridized smoothening filters by the artificial bee colony optimization algorithm and compared it with the genetic algorithm.","","Electronic:978-1-4244-5052-7; POD:978-1-4244-5053-4","10.1109/NABIC.2009.5393866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393866","Artificial Bee Colony (ABC) Algorithm;Genetic Algorithm (GA);Image edge enhancement;hybridized smoothening filter;neighbourhood search","Art;Biomedical imaging;Filters;Image communication;Image processing;Image retrieval;Image sampling;Information retrieval;Satellites;Stochastic processes","image enhancement;information retrieval;optimisation;smoothing methods","artificial bee colony optimization algorithm;feature extraction;hybridized smoothening filters;image classification;image edge enhancement;image edge quality;image generation;image processing techniques;image transmission;information retrieval;medical images;satellite images;unbiased optimization technique;unbiased stochastic sampling","","2","","18","","","9-11 Dec. 2009","","IEEE","IEEE Conference Publications"
"Image retrieval for compressed and uncompressed images","V. R. Khapli; A. S. Bhalchandra","K K Wagh Women's Polytechnic, Nashik, India","2009 7th International Conference on Information, Communications and Signal Processing (ICICS)","20100122","2009","","","1","4","To reduce the storage and transmission requirements in image applications, images are compressed while maintaining acceptable visual quality. In this paper, image retrieval using Vector Quantization (VQ) is explored. The VQ technique is tested on uncompressed images (UCID) as well as compressed images (JPG). In order to reduce the retrieval time, the images are converted into thumbnails and the retrieval performance in both the domains is observed. The testing is performed with various thumbnail sizes. Performance is evaluated by using Precision and Recall. It is observed that the retrieval performance using VQ for compressed images remains comparable with that with uncompressed images.","","Electronic:978-1-4244-4657-5; POD:978-1-4244-4656-8","10.1109/ICICS.2009.5397711","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5397711","Vector Quantization;compressed domain image retrieval;compressed domain indexing","Discrete Fourier transforms;Discrete wavelet transforms;Image coding;Image retrieval;Image storage;Indexing;Information retrieval;Pixel;Testing;Vector quantization","image coding;image retrieval;vector quantisation","JPG;UCID;acceptable visual quality;compressed images;image retrieval;retrieval time reduction;storage transmission requirements;thumbnail sizes;uncompressed images;vector quantization","","0","","18","","","8-10 Dec. 2009","","IEEE","IEEE Conference Publications"
"Implementation of web-based medical image retrieval system in Oracle","I. Dimitrovski; P. Guguljanov; S. Loskovska","Faculty of Electrical Engineering and Information Technology in Skopje, Macedonia","2009 2nd International Conference on Adaptive Science & Technology (ICAST)","20100208","2009","","","192","197","The requirement for systems that can stock, represent, and provide efficient retrieval of images is becoming very important in medicine. Content-based Image Retrieval (CBIR) for medical images is a promising approach to address the data management challenges posed by the rapidly increasing volume of medical image data in use. In this paper we present an implemented web-based system for medical image retrieval using the Oracle Multimedia features for image retrieval. The system integrates content-based and text-based retrieval for efficient and more reliable search.","2326-9413;23269413","Electronic:978-1-4244-3523-4; POD:978-1-4244-3522-7","10.1109/ICASTECH.2009.5409726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5409726","CBIR;DICOM;Oracle Multimedia;medicine","Biomedical imaging;Content based retrieval;Image databases;Image retrieval;Image storage;Indexing;Information retrieval;Multimedia systems;Spatial databases;Visual databases","Internet;content-based retrieval;image retrieval;medical computing;multimedia systems","Oracle multimedia;World Wide Web;content-based image retrieval;medical image retrieval system","","5","","13","","","14-16 Jan. 2009","","IEEE","IEEE Conference Publications"
"Efficient image concept indexing by harmonic & arithmetic profiles entropy","H. Glotin; Z. Q. Zhao; S. Ayache","Systems and Information Sciences Lab., UMR CNRS and Univ. Sud-Toulon Var, France","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","277","280","We propose new efficient visual features called Profile Entropy Features (PEF), giving information on the structure of the image content, and defined as the entropy of the distribution of a projection of the pixels. We analyse two simple projection operators (arithmetic or harmonic mean), and two orientations (horizontal and vertical). PEF are fast to compute (10 images per sec. on a PentiumIV) and of small dimension. Moreover, we show on High Level Feature task in TrecVid2008 that PEF performs in average better than the features of the state of the art (usual color features, edge direction, Gabor, and Local Binary Pattern). Moreover, we show on another international image retrieval campaign, the Visual Concept Detection of ImageCLEF2008, that the arithmetic and harmonic projections give complementary informations, yielding to the third best rank system in the official run of this campaign. Other properties of the PEF are discussed.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413350","Content-Based Image Retrieval;Entropy;SVM;Texture;Video Retrieval","Arithmetic;Computer science;Content based retrieval;Entropy;Image retrieval;Image segmentation;Indexing;Information retrieval;Pixel;Reactive power","content-based retrieval;entropy;feature extraction;image retrieval;indexing","TrecVid2008;Visual Concept Detection of ImageCLEF2008;arithmetic profiles entropy;arithmetic projections;harmonic profiles entropy;harmonic projections;high level feature task;image concept indexing;image content;international image retrieval campaign;profile entropy features;projection operators;visual features","","2","","8","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Data retrieval from online social network profiles for social engineering applications","S. Alim; R. Abdul-Rahman; D. Neagu; M. Ridley","Department of Computing, University of Bradford, UK","2009 International Conference for Internet Technology and Secured Transactions, (ICITST)","20100129","2009","","","1","5","With the increased use of online social networking sites, data retrieval from social networking profiles is becoming a major tool for business. What makes social networking profile data different is its semi-structured format. The structure and the presentation of profile data change all the time. In social networking there is a lack of research into automated data retrieval from semi-structured Web pages. Our approach is based on automated retrieval of the profile's attributes and list of top friends from MySpace by examining and extracting the relevant tokens in the parsed HTML code. The tokens were placed into a repository and Breadth First Search algorithm was used. The approach was implemented and tested with a profile which resulted in over 800 top friend profiles and attributes being extracted. This implementation process highlighted that MySpace profile structures vary depending on profile type and the way in which the user has customised the profile.","","Electronic:978-1-4244-5648-2; POD:978-1-4244-5647-5","10.1109/ICITST.2009.5402568","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402568","","Computer networks;Data analysis;Data engineering;Data mining;HTML;Information retrieval;MySpace;Social network services;Web pages;Web sites","Web sites;commerce;information retrieval;social networking (online);tree searching","MySpace;automated data retrieval;breadth first search algorithm;business;online social networking sites;parsed HTML code;semi-structured Web pages;semi-structured format;social engineering applications;social networking profiles","","1","1","19","","","9-12 Nov. 2009","","IEEE","IEEE Conference Publications"
"Commentator's Speech Extraction in Audio Stream of Sports Games","L. Lu; F. Ge; Q. Zhao; Y. Yan","ThinkIT Speech Lab., Chinese Acad. of Sci., Beijing, China","2009 International Conference on Research Challenges in Computer Science","20100129","2009","","","64","67","This paper proposes a method to deal with the problem of extracting commentator's speech in audio stream of live sports games. First, a two-pass metric-based audio segmentation module is developed to segment the audio stream into short ones with homogeneous acoustic features. Then a model-based classification module is adopted to extract the speech segments. For robust audio classification, various audio features have been used in this paper. Finally, a music scene analysis (Music-CASA) method is adopted to remove the speech in the advertisements with minimum loss of commentator's speech. By integrating all the techniques, an average F value of 94.79% is achieved in the commentator's speech extraction task evaluated on eleven games of six kinds of sports.","","Electronic:978-1-4244-5410-5; POD:978-0-7695-3927-0; POD:978-1-4244-5409-9","10.1109/ICRCCS.2009.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401297","","Computer science;Data mining;Image analysis;Information retrieval;Robustness;Speech analysis;Speech recognition;Streaming media;Support vector machines;Technology management","audio signal processing;audio streaming;music;signal classification;speech processing;sport","audio stream;commentator speech extraction;homogeneous acoustic features;live sports games;model-based classification module;music scene analysis method;robust audio classification;speech segments;two-pass metric-based audio segmentation module","","0","","6","","","28-29 Dec. 2009","","IEEE","IEEE Conference Publications"
"Chinese text classification method based on NMF","Lei Zhang; Xuezhi Xiang","Information and Communication Engineering College, Harbin Engineering University, China","2009 International Conference on Test and Measurement","20100217","2009","2","","240","243","Text document classification based on the semantic level is a hot issue in text processing presently. In this paper, a method based on NMF for Chinese text classification is presented. According to NMF, the term-document matrix is decomposed to capture the relation between terms. This method settled effectively the problems of synonym and polysemy. It experimentally shows that, compared with LSI based on SVD, this method has advantages of faster computing speed, less memory occupancy and improvement of classification precision when the dimension reduces markedly.","2157-5592;21575592","Electronic:978-1-4244-4700-8; POD:978-1-4244-4699-5","10.1109/ICTM.2009.5413065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413065","NMF;SVD;text document classification","Dictionaries;Educational institutions;Image retrieval;Indexing;Information retrieval;Matrix decomposition;Surveillance;Testing;Text categorization;Text processing","information retrieval;matrix decomposition;singular value decomposition;text analysis","NMF;SVD;chinese text document classification method;nonnegative matrix factorization;polysemy;semantic level;singular value decomposition;synonym;term-document matrix;text processing","","0","","11","","","5-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Implemented Rank Merging Algorithm for Meta Search Engine","Y. Fu-yong; W. Jin-dong","Coll. of Inf. Sci. & Eng., Yanshan Univ., Qinhuangdao, China","2009 International Conference on Research Challenges in Computer Science","20100129","2009","","","191","193","In order to improve the precision of meta search engine, In the foundation of analysis two kinds traditional merging algorithm of meta search engine, and the disadvantage of two algorithms are given, one kind of new about the results merging method based on the combination of position and snippets/titles is proposed. which integrates these two factors, the related degree between the position information of query results and the query words, the similarity between query results' snippets and the query words. Then take a popular measure for evaluating the effectiveness of search engines to analysis the results, The results of the experiment show that, the average precision of this method is higher than popular component search engines now, and it also proved that result merging in a meta search engine, considering the information of the position and title/snippet of the search results at one time, the accuracy of the meta search engine will be better.","","Electronic:978-1-4244-5410-5; POD:978-0-7695-3927-0; POD:978-1-4244-5409-9","10.1109/ICRCCS.2009.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401261","meta search engine;query words;related degree;results merging","Computer science;Educational institutions;Electronic mail;Information analysis;Information retrieval;Information science;Internet;Merging;Metasearch;Search engines","Internet;merging;query formulation;search engines","meta search engine;position information;position snippets-titles combination;query results snippets;query word;rank merging algorithm;results merging method","","0","","5","","","28-29 Dec. 2009","","IEEE","IEEE Conference Publications"
"Effectively Using Monotonicity Analysis for Paraphrase Identification","D. Uribe","Div. de Posgrado e Investig., Inst. Tecnol. de la Laguna, Cuauhtemoc, Mexico","2009 Eighth Mexican International Conference on Artificial Intelligence","20100217","2009","","","108","113","We analyse in this paper the role of monotonicity for learning to identify sentence-level paraphrasing. Our approach is based in a system architecture which consists of two components. The first component is the features set definition module which takes care of the order of the elements for the analysis of monotonicity as well as the use of semantic heuristics to recognize false paraphrasing. The learning phase is carried out by the second module which makes uses of supervised learning algorithms such as logistic regression and support vector machines for the definition of the classifier model. The results of the experimentation conducted show how the set of features that we propose in this paper leads to decent accuracy. In fact, the results of the experimentation using monotonic and non-monotonic features show how our approach is a plausible alternative to cope with the syntactic and semantic diversity of a data set.","","POD:978-0-7695-3933-1","10.1109/MICAI.2009.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5372709","content vector;monotonicity;paraphrasing","Artificial intelligence;Information retrieval;Logistics;Machine learning;Natural language processing;Search engines;Supervised learning;Support vector machine classification;Support vector machines;Text recognition","learning (artificial intelligence);natural language processing;pattern classification;pattern recognition","classifier model;false paraphrasing recognition;features set definition module;logistic regression;monotonicity analysis;semantic heuristics;sentence-level paraphrasing identification;supervised learning algorithms;support vector machines;system architecture","","0","","13","","","9-13 Nov. 2009","","IEEE","IEEE Conference Publications"
"Hash functions for near duplicate image retrieval","A. Auclair; N. Vincent; L. D. Cohen","Paris Descartes University, LIPADE, France","2009 Workshop on Applications of Computer Vision (WACV)","20100202","2009","","","1","6","This paper proposes new hash functions for indexing local image descriptors. These functions are first applied and evaluated as a range neighbor algorithm. We show that it obtains similar results as several state of the art algorithms. In the context of near duplicate image retrieval, we integrated the proposed hash functions within a bag of words approach. Because most of the other methods use a kmeans-based vocabulary, they require an off-line learning stage and highest performance is obtained when the vocabulary is learned on the searched database. For application where images are often added or removed from the searched dataset, the learning stage must be repeated regularly in order to keep high recalls. We show that our hash functions in a bag of words approach has similar recalls as bag of words with kmeans vocabulary learned on the searched dataset, but our method does not require any learning stage. It is thus very well adapted to near duplicate image retrieval applications where the dataset evolves regularly as there is no need to update the vocabulary to guarantee the best performance.","1550-5790;15505790","Electronic:978-1-4244-5498-3; POD:978-1-4244-5497-6","10.1109/WACV.2009.5403104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403104","","Computer applications;Frequency;Image databases;Image retrieval;Indexing;Information retrieval;Nearest neighbor searches;Search engines;Visual databases;Vocabulary","cryptography;image retrieval","bag-of-words approach;hash function;kmeans vocabulary;near duplicate image retrieval;range neighbor algorithm","","1","","16","","","7-8 Dec. 2009","","IEEE","IEEE Conference Publications"
"File Metadata Management in Embedded Linux","S. Bolognini; N. Corriero; V. Cozza","Dept. of Comput. Sci., Univ. of Bari, Bari, Italy","2009 Fourth International Conference on Embedded and Multimedia Computing","20100202","2009","","","1","6","In embedded Linux systems low power consumption and memory usage are strict constraint. The problem to manage a large quantity of file metadata, that usually represents the most expensive task of such systems, is a task delegated to user space programs, generally, database based. In this work we propose how to deal with metadata at file system level with Hixosfs. Hixosfs is an ext2 based Linux file system, designed to easily cataloging and retrieving e-mails, musical files and logs files according final user selected metadata. The core idea is to move the problem complexity from user space to kernel level to speed up the overall process. The implementation mainly required ext2 file system structure to be extended to store file tags, then they can be accessed and modified directly by system calls. Analysis and comparison works state this approach to be suitable for a large amount of data.","2159-1520;21591520","Electronic:978-1-4244-4996-5; POD:978-1-4244-4995-8","10.1109/EM-COM.2009.5402980","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402980","","Data mining;Databases;Embedded system;Energy consumption;File systems;Kernel;Linux;Memory management;Music information retrieval;Power system management","Linux;embedded systems;file organisation;meta data","Hixosfs;Linux file system;embedded Linux system;ext2 file system structure;file metadata management;file system level;file tags;memory usage;user selected metadata;user space programs","","0","","12","","","10-12 Dec. 2009","","IEEE","IEEE Conference Publications"
"Research on semantic network image retrieval method","Shiqun Yin; Weiling Chen; Xiaotie Qin","Faculty of Computer and Information Science, Southwest University, Chongqing, China 400715","2009 International Conference on Future BioMedical Information Engineering (FBIE)","20100205","2009","","","449","452","As a prominent form of multimedia, image retrieval has become an important project research presently. Nowadays, the development of image search engine mainly bases on two kinds of technique: (1) traditional Text-Based Image Retrieval (TBIR); (2) Content-Based Image Retrieval (CBIR). However, because of the limitation of the Â¿semantic gapÂ¿ bottleneck, they both have limitations. In the light of this, we present an image retrieval method based on semantic network. We create a mapping from low-level image visual features to high-level semantic, and attempt to identify the semantic concept of visual features. We also introduce user feedback, guide search results to the optimal direction, and make it to fit the natural way for humans to understand image. The technology requires the use of the knowledge library for storing semantic networks and mapping. In this paper, the system model, retrieval method and experiments are given. Experimental results indicate that the method have better retrieval efficiency.","2157-9598;21579598","Electronic:978-1-4244-4691-9; POD:978-1-4244-4690-2","10.1109/FBIE.2009.5405823","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5405823","Semantic network;feature extraction;image retrieval;relevance feedback;semantic mapping","Content based retrieval;Data mining;Feedback;HTML;Humans;Image retrieval;Indexing;Information retrieval;Libraries;Search engines","content-based retrieval;image retrieval;search engines;semantic networks","CBIR method;TBIR method;content based image retrieval method;high-level semantic;image search engine;knowledge library;low-level image visual features;semantic networks storage;text based image retrieval method","","1","","13","","","13-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"Against wiretappers without key-security is an intrinsic property of network coding","Z. Cao; Y. Tang; X. Huang","College of Mathematical Sciences, Yangzhou University, Yangzhou, Jiangsu, 225002 P.R.C. China","2009 7th International Conference on Information, Communications and Signal Processing (ICICS)","20100122","2009","","","1","5","Note that network coding allows immediate nodes to mix information from different data flows. On the basis of this observation, we prove that under suitable conditions, communicators can communicate with perfect secrecy over wiretap networks. Our method of secure communication over wiretap networks without keys is fundamentally distinct from cryptographic means. Furthermore, a linear network code with perfect secrecy is available for a given wiretap multicast network provided that the cardinality of the alphabet is larger than a constant. Comparing with other approaches, no network capacity is lost by our method.","","Electronic:978-1-4244-4657-5; POD:978-1-4244-4656-8","10.1109/ICICS.2009.5397469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5397469","","Cryptographic protocols;Cryptography;Data mining;Educational institutions;Information retrieval;Information security;Information theory;Network coding;Routing;Scheduling algorithm","cryptography;multicast communication;network coding;telecommunication security","cryptography;linear network code;network coding;network security;wiretap multicast network","","0","","19","","","8-10 Dec. 2009","","IEEE","IEEE Conference Publications"
"Video Abstraction via Attention Model and On-Line Clustering","Y. n. Li; Z. m. Lu","Shenzhen Grad. Sch., Harbin Inst. of Technol., Shenzhen, China","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","627","630","Video abstraction is an indispensable component in various applications, such as indexing, browsing and retrieval. In this paper, we present a new video abstraction algorithm based on visual attention model and on-line clustering. Representative frames are first selected on shot level. The attention regions in representative frames are detected via attention model. Finally, the visual features of attention regions are clustered in an on-line manner to reduce memory cost. Experimental results demonstrate that the key frames extracted by the proposed algorithm are consistent with the results of human perceptions.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412373","","Biological system modeling;Clustering algorithms;Data mining;Electronic mail;Feature extraction;Gunshot detection systems;Humans;Indexing;Information retrieval;Videoconference","feature extraction;object detection;pattern clustering;video signal processing","human perceptions;keyframe extraction;on-line clustering;representative frame detection;video abstraction algorithm;visual attention model","","0","","8","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Content-based 3D object retrieval using 2D views","T. Napoléon; H. Sahbi","TELECOM ParisTech, CNRS UMR 5141, 46 rue Barrault, 75013 Paris, France","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1437","1440","2D techniques have recently emerged as an important boost for 3D objects content-based retrieval in many real world applications such as photography, art, archeology and geolocalization thanks to its several complementary aspects. We introduce in this paper a new framework for 3D objects content-based retrieval based on a 2D photography approach. A new alignment process that is able to find canonical views consistently through scenes/objects and a new coarse-to-fine description and matching method used for ranking are our contributions. The results are presented through an international benchmarking and showing clearly the good performance of our framework with respect to the other participants.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414634","","Art;Content based retrieval;Data mining;Information retrieval;Photography;Power system harmonics;Principal component analysis;Probes;Shape measurement;Telecommunications","content-based retrieval;image retrieval","2D photography approach;archeology;art;coarse-to-fine description;content-based 3D object retrieval;geolocalization;matching method","","0","","13","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Reliability Based Web Information Ranking System","P. Tin; T. T. Zin; T. Toriu; H. Hama","Grad. Sch. of Eng., Osaka City Univ., Osaka, Japan","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","294","297","In this paper, we propose a reliability based Web information ranking system which enables searching useful and reliable knowledge information. The proposed system will contain subsystems for reliability ranking, information clustering based on reliability. The reliability ranking system will estimate the likelihood that a statement on the Web can be trusted using standards developed by information scientists, and the link structure of associated Web pages. The clustering will cluster relevant and reliable information based on whether or not they can be trusted or not. We test these models on an academic search engine and show how the reliability information ranks can be used as a useful knowledge.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.306","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412205","","Biomedical imaging;Control systems;Explosions;Image retrieval;Influenza;Information retrieval;Knowledge engineering;Reliability engineering;Tin;Web pages","Internet;information retrieval;pattern clustering;reliability;search engines","Web information ranking system;Web pages;academic search engine;information clustering;knowledge information;reliability ranking system","","0","","8","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"A spectral method for context based disambiguation of image annotations","D. Semenovich; A. Sowmya","School of Computer Science and Engineering, University of New South Wales, 2052, Australia","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","789","792","In this work we employ contextual information to improve the quality of image labellings provided by an existing automatic image annotation algorithm in a weakly supervised setting, where each training image is labelled but it is not known which part of the image its labels are referring to. We recast the problem into that of constructing a graph which encodes pairwise consistency of candidate annotations and observe that mutually consistent labels will form a compact cluster in this graph. We recover the clusters using a spectral theory based technique. The results are demonstrated on the Corel5k dataset. With improvements in the range of 25%-55% the performance in some cases approaches the state of the art despite using a very simple base algorithm.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414229","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414229","Image annotation;spectral clustering","Australia;Clustering algorithms;Computer science;Context modeling;Image recognition;Image retrieval;Information retrieval;Labeling;Layout;Machine learning","graph theory;image retrieval;pattern clustering;spectral analysis","Corel5k dataset;automatic image annotation;compact cluster;context based disambiguation;graph;image labelling;image quality;pairwise consistency;spectral method","","0","","15","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Feeding back learning resources repurposing patterns into the “information loop”: opportunities and challenges","D. Giordano; A. Faro; F. Maiorana; C. Pino; C. Spampinato","University of Catania, Dipartimento di Ingegneria Informatica e Telecomunicazioni, Viale A. Doria 6, 95125, Italy","2009 9th International Conference on Information Technology and Applications in Biomedicine","20100122","2009","","","1","6","The paper outlines a model for framing the representation and treatment of information gathered from the reuse and repurposing of learning resources from distributed repositories. The model takes into account as sources of information both static user-edited or automatically generated metadata fields and the emerging, dynamic information clouds that surrounds a learning resource when users comment on it, tags it, or explicitly links it to other learning resources. By coordinating these separate information layers, the advantages that can be achieved are reducing the semantic gap occurring when unanticipated contexts of use are to be described by resorting only to predefined vocabularies; and improvements in the relevance of the retrieved resources after a query. To achieve this ""coordination"" it is proposed that the textual descriptions of the repurposing activity with respect to the intended learning outcomes and pedagogical strategies are fed to a dynamic unsupervised classification method that operates on the above mentioned information spaces, and that supports exploratory search by suggesting associations. It is argued that the proposed analogical retrieval, as opposed to standard query matching, is more fit to tracking the loci of innovation and sustaining the formation of best practices in the community.","2168-2194;21682194","CD-ROM:978-1-4244-5379-5","10.1109/ITAB.2009.5394368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5394368","classification;content sharing;exploratory search;metadata;multimedia analysis and indexing","Back;Clouds;Context modeling;Educational technology;Information resources;Information retrieval;Medical treatment;Paper technology;Semantic Web;Vocabulary","Internet;computer aided instruction;meta data;query processing;semantic Web;unsupervised learning","Web 2.0;analogical retrieval;distributed repositories;dynamic information clouds;dynamic unsupervised classification method;information layers;information loop;learning resources;metadata fields;semantic Web technologies;standard query matching;vocabularies","","5","","20","","","4-7 Nov. 2009","","IEEE","IEEE Conference Publications"
"A Query-Dependent Ranking Approach for Search Engines","L. W. Lee; J. Y. Jiang; C. Wu; S. J. Lee","Dept. of Electr. Eng., Nat. Sun Yat-Sen Univ., Kaohsiung, Taiwan","2009 Second International Workshop on Computer Science and Engineering","20100202","2009","1","","259","263","Ranking model construction is an important topic in Web mining. Recently, many approaches based on the idea of Â¿learning to rankÂ¿ have been proposed for this task and most of them attempt to score all documents of different queries by resorting to a single function. In this paper, we propose a novel framework of query-dependent ranking. A simple similarity measure is used to calculate similarities between queries. An individual ranking model is constructed for each training query with corresponding documents. When a new query is asked, documents retrieved for the new query are ranked according to the scores determined by a ranking model which is combined from the models of similar training queries. A mechanism for determining combining weights is also provided. Experimental results show that this query-dependent ranking approach is more effective than other approaches.","","Electronic:978-0-7695-3881-5; POD:978-1-4244-5285-9","10.1109/WCSE.2009.666","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403423","Query-dependent ranking;model combination;query similarity;ranking model;web mining","Boosting;Computer industry;Computer science;Information retrieval;Machine learning;Search engines;Support vector machine classification;Support vector machines;Training data;Web mining","data mining;document handling;query processing;search engines","Web mining;document processing;query dependent ranking;ranking model;search engine;training query","","5","","18","","","28-30 Oct. 2009","","IEEE","IEEE Conference Publications"
"Very Efficient Balanced Codes","K. A. Schouhamer Immink; J. H. Weber","Nanyang Technological University of Singapore, Singapore","IEEE Journal on Selected Areas in Communications","20100129","2010","28","2","188","192","The prior art construction of sets of balanced codewords by Knuth is attractive for its simplicity and absence of look-up tables, but the redundancy of the balanced codes generated by Knuth's algorithm falls a factor of two short with respect to the minimum required. We present a new construction, which is simple, does not use look-up tables, and is less redundant than Knuth's construction. In the new construction, the user word is modified in the same way as in Knuth's construction, that is by inverting a segment of user symbols. The prefix that indicates which segment has been inverted, however, is encoded in a different, more efficient, way.","0733-8716;07338716","","10.1109/JSAC.2010.100207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402485","Magnetic recording, optical recording, channel capacity, constrained code, dc-free code, balanced code.","Algorithm design and analysis;Art;Channel capacity;Communication channels;Cryptography;Decoding;Information retrieval;Optical recording;Table lookup;Turing machines","codes;table lookup","Knuth algorithm;balanced codewords;look-up tables;user symbols","","17","","8","","","February 2010","","IEEE","IEEE Journals & Magazines"
"Capturing Contextual Relationship for Effective Media Search","G. H. Cha","Dept. of Comput. Eng., Seoul Nat. Univ. of Technol., Seoul, South Korea","2009 Fourth International Conference on Embedded and Multimedia Computing","20100202","2009","","","1","6","One of the central problems regarding media search is the semantic gap between the low-level features computed automatically from media data and the human interpretation of them. This is because the notion of similarity is usually based on high-level abstraction but the low-level features do not sometimes reflect the human perception. In this paper, we assume the semantics of a media is determined by the contextual relationship in a dataset, and introduce the method to capture the contextual information from a large media (especially image) dataset for effective search. Similarity search in an image database based on this contextual information shows encouraging experimental results.","2159-1520;21591520","Electronic:978-1-4244-4996-5; POD:978-1-4244-4995-8","10.1109/EM-COM.2009.5402975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402975","","Data engineering;Euclidean distance;Humans;Image databases;Image retrieval;Information retrieval;Measurement standards;Nearest neighbor searches","image retrieval;query formulation;visual databases","contextual relationship;high-level abstraction;human perception;image database;media search;semantic gap;similarity search","","0","","24","","","10-12 Dec. 2009","","IEEE","IEEE Conference Publications"
"Resource Retrieval Service to Enhance U-Learning Environment","N. Y. Yen; L. R. Chao; Q. Jin; J. Ma; T. K. Shih","Dept. of Comput. Sci. & Inf. Eng., Tamkang Univ., Taipei, Taiwan","Proceedings of the 4th International Conference on Ubiquitous Information Technologies & Applications","20100205","2009","","","1","6","E-Learning makes it possible for learners to study at any time. With the improvement of ubiquitous technologies and corresponding devices, learners can conduct their learning activities without any limitations from the environment. Instructors can utilize various kinds of resources to create more plentiful learning materials for learners. In this situation, instructors or learners have to spend more time on collecting relevant resources for a specific purpose. In our previous works, we utilized the geographical information and RFID (Radio Frequency Identification) to develop an outdoor adventure game to support learning procedures. In this paper, we go further to propose and develop a resource retrieval mechanism to assist learners in collecting relevant learning resources. This mechanism can be regarded as a search procedure. We aim at providing search results in the order of relevant degree based on learners' current geographical information. It can make resource retrieval more efficient in ubiquitous learning environments.","1976-0035;19760035","Electronic:978-1-4244-5130-2; POD:978-1-4244-5131-9","10.1109/ICUT.2009.5405693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5405693","","Collaboration;Computer science;Conducting materials;Electronic learning;Global Positioning System;Information filtering;Information filters;Information retrieval;Pervasive computing;Radiofrequency identification","computer aided instruction;geographic information systems;relevance feedback;ubiquitous computing","e-learning;geographical information;instructors;learners;learning materials;learning resources;resource retrieval service;u-learning environment;ubiquitous technologies","","0","","20","","","20-22 Dec. 2009","","IEEE","IEEE Conference Publications"
"Clustering Hyperlinks for Topic Extraction: An Exploratory Analysis","S. E. G. Villarreal; L. M. Elizalde; A. C. Viveros","Tecnol. de Monterrey, Monterrey, Mexico","2009 Eighth Mexican International Conference on Artificial Intelligence","20100217","2009","","","128","133","In a Web of increasing size and complexity, a key issue is automatic document organization, which includes topic extraction in collections. Since we consider topics as document clusters with semantic properties, we are concerned with exploring suitable clustering techniques for their identification on hyperlinked environments (where we only regard structural information). For this purpose, three algorithms (PDDP, k-means, and graph local clustering) were executed over a document subset of an increasingly popular corpus: Wikipedia. Results were evaluated with unsupervised metrics (cosine similarity, semantic relatedness, Jaccard index) and suggest that promising results can be produced for this particular domain.","","POD:978-0-7695-3933-1","10.1109/MICAI.2009.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5372704","Wikipedia;graph local clustering;k-means;principal direction divisive partitioning;topic detection","Artificial intelligence;Clustering algorithms;Clustering methods;Data mining;Data visualization;Information retrieval;Partitioning algorithms;Semantic Web;Testing;Wikipedia","Web sites;document handling","PDDP;Wikipedia;automatic document organization;clustering techniques;document clusters;graph local clustering;hyperlinked environments;hyperlinks clustering;k means;topic extraction;unsupervised metrics","","0","","21","","","9-13 Nov. 2009","","IEEE","IEEE Conference Publications"
"Image Retrieval Using Sieve Complement Trees","A. P. Palma; R. Harvey; J. M. P. Aguilar; L. R. V. Pérez; A. L. Álvarez","Fac. de Inf., Univ. Autonoma de Queretaro, Queretaro, Mexico","2009 Eighth Mexican International Conference on Artificial Intelligence","20100217","2009","","","47","52","This paper is about scale-space image trees. We introduce here a variant of the sieve algorithm to produce sieve complement trees where not only extremal regions are characterized but also their corresponding complements. Different simplification methods can transform (or prune) the hierarchy into a simpler form where the remaining nodes represent regions that are noticeably different from their neighbourhood, and that are traditionally known in the literature as ""Salient Regions"". Although, the resulting scale-space tree hierarchy, can not strictly be defined as a segmentation, its associated signal (a simplified image of the original), can be used for content based image retrieval (CBIR) similarly to a segmentation. Here, we present the resulting retrieval precision rates of testing our trees into three widely known image datasets. Our results confirm the premise that complementary regions can contribute to improve image retrieval rates.","","POD:978-0-7695-3933-1","10.1109/MICAI.2009.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5372719","complement trees;image retrieval;scale-space;segmentation;sieve algorithm","Artificial intelligence;Content based retrieval;Filters;Histograms;Image retrieval;Image segmentation;Information retrieval;Iterative algorithms;Merging;Testing","content-based retrieval;image retrieval","content based image retrieval;image datasets;salient regions;scale-space image trees;scale-space tree hierarchy;sieve complement trees","","0","","14","","","9-13 Nov. 2009","","IEEE","IEEE Conference Publications"
"Face Recognition by Computers and Humans","R. Chellappa; P. Sinha; P. J. Phillips","University of Maryland, College Park","Computer","20100208","2010","43","2","46","55","This article talks about how the study of how humans perceive faces can be used to help design practical systems for face recognition. Besides applications related to identification and verification-such as access control, law enforcement, ID and licensing, and surveillance-face recognition has also proven useful in applications such as human-computer interaction, virtual reality, database retrieval, multimedia, and computer entertainment. Continuing research into face recognition will provide scientists and engineers with many vital projects, in areas such as homeland security, human-computer interaction, and numerous consumer applications. The areas we are considering pursuing are recognition from unconstrained video sequences, incorporating familiarity into algorithms, modeling effects of aging, and developing biologically plausible models for human face recognition ability.","0018-9162;00189162","","10.1109/MC.2010.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5410708","Biometrics;Face recognition;Homeland security;Human-computer interaction","Access control;Application software;Biological system modeling;Face recognition;Humans;Information retrieval;Law enforcement;Licenses;Multimedia databases;Virtual reality","access control;face recognition;human computer interaction;national security","access control;aging;computer entertainment;database retrieval;face recognition;homeland security;human computer interaction;unconstrained video sequences;virtual reality","","35","2","12","","","Feb. 2010","","IEEE","IEEE Journals & Magazines"
"Fingerprint recognition system performance in the maritime environment","H. Fakourfar; S. Belongie","Department of Electrical and Computer Engineering, USA","2009 Workshop on Applications of Computer Vision (WACV)","20100202","2009","","","1","5","This study assesses the effects of prolonged exposure of fingers to water on the performance of existing fingerprint recognition systems. The dataset used in this research is collected using a high-end, multispectral fingerprint scanner. To perform a data acquisition, we recruited volunteers to contribute their fingerprint samples to the dataset in multiple sessions. Once the dataset is filled with both fingerprints under normal and wrinkled conditions, we use a minutiae-based fingerprint verification system to retrieve the match scores between all combinations of prints. Finally, we use receiver operating characteristic (ROC) curve to measure the behavior of such systems under maritime environment. Using the equal error rate (EER), we successfully quantify the degradation in performance due to water-induced skin pruning, which is approximately 1% reduction in EER.","1550-5790;15505790","Electronic:978-1-4244-5498-3; POD:978-1-4244-5497-6","10.1109/WACV.2009.5403068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403068","","Data acquisition;Degradation;Error analysis;Fingerprint recognition;Fingers;Information retrieval;RAKE receivers;Recruitment;Skin;System performance","fingerprint identification","equal error rate;fingerprint recognition;maritime environment;minutiae-based fingerprint verification system;multispectral fingerprint scanner;receiver operating characteristic curve","","3","","8","","","7-8 Dec. 2009","","IEEE","IEEE Conference Publications"
"Localized Null Space representation for dynamic updating and downdating in image and video databases","X. Chen; D. Schonfeld; A. Khokhar","Department of Electrical and Computer Engineering, University of Illinois at Chicago, USA","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","801","804","Event/object classification and recognition is an extremely challenging problem, particularly when the query or stored data undergo an affine transformation due to camera motion. The complexity of the problem is further compounded when the input or stored data contain only partial information (e.g. due to object occlusion). Most of the existing representation do not allow view invariant representation and dynamic updating and downdating with in a single framework. In this paper, we present a novel robust multi-dimensional Localized Null Space and associated dynamic updating and downdating techniques, thus allowing classification and retrieval in the presence of affine transformations and partial information. We investigate the robustness of Localized Null Space using perturbation analysis. We further determine the optimal segmentation of the data by minimizing a distortion criterion. We demonstrate the effectiveness and robustness of the proposed techniques for motion event classification and retrieval applications by posing different affine transformations of partial queries.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414346","Localized Null Space;affine transformation;merging;partial query;perturbation analysis;splitting;view invariance","Cameras;Image databases;Image recognition;Information retrieval;Merging;Null space;Robustness;Sensor systems and applications;Social network services;Space technology","affine transforms;visual databases","affine transformation;camera motion;distortion criterion;dynamic downdating;dynamic updating;event classification;image databases;localized null space representation;multidimensional localized null space;object classification;partial information;perturbation analysis;video databases;view invariant representation","","0","","5","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"A fast cube-based video shot retrieval using 3D moment-preserving technique","W. K. Huang; C. H. Chung; S. C. Cheng; J. W. Hsieh","Institute of Engineering Science and Technology, National Kaohsiung First University of Science and Technology, Taiwan","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","241","244","In this paper, we describe a novel video shot retrieval where each shot is separated into multiple video cubes. Therefore, every video shot can be represented by a linear combination of video cubes, which are used to calculate the similarity measurements among video shots in terms of video cube similarity. The position of a voxel in a cube is characterized with (x, y, t) 3D coordinates and the spatial-temporal features within video cubes are extracted with a set of analytical formulas derived from the proposed 3D moment-preserving technique. Then, the content of a video cube is approximated by three blocks generated from projecting the cube onto xy, yt and tx planes. Based on the visual patterns of xy, yt, and tx blocks, a fast video shot retrieval scheme is proposed. As compared with other key-frame based representations, the proposed cube-based video retrieval improves the retrieval accuracy without sacrificing the execution speed. Experimental results show the efficiency and effectiveness of the proposed video retrieval.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414572","3D moment-preserving technique;video cube;video indexing;video retrieval;visual pattern","Computer science;Content based retrieval;Data mining;Feature extraction;Histograms;Indexing;Information retrieval;Marine technology;Video sequences;Video sharing","image representation;image segmentation;video retrieval","3D moment-preserving technique;cube-based video retrieval;key-frame based representations;linear combination;multiple video cubes;similarity measurements;spatial-temporal features;video cube similarity;video shot retrieval;visual patterns","","2","","9","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Automatic Position Annotation of Brain CT Axial Slice for Content-Based Image Retrieval","K. Yuan; Z. Tian; J. Zou","Dept. of Biomed. Eng., Tsinghua Univ., Beijing, China","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","315","318","Anatomy position annotation of brain CT axial slice is an important step in content-based image retrieval. In this paper, we provide an efficient approach to automatically estimate the approximate anatomy position of brain CT axial slices in two steps: First, decide whether the input image is encephalic image or nasal cavity image using vote scheme based on the classification results with features extracted by Gabor filter, Sobel operator and gray-level co-occurrence matrix (GLCM) respectively; Second, annotate the approximate anatomy position of encephalic images using nonnegative tensor factorization (NTF). The approach has 99% accuracy in distinguishing between encephalic images and nasal cavity images and over 90% accuracy in automatic position annotation of encephalic images.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412347","","Anatomy;Computed tomography;Content based retrieval;Data mining;Feature extraction;Frequency;Gabor filters;Image retrieval;Information retrieval;Voting","Gabor filters;computerised tomography;content-based retrieval;feature extraction;image classification;image retrieval;matrix decomposition;medical image processing;tensors","Gabor filter;Sobel operator;anatomy position annotation;approximate automatic position annotation;brain CT axial slice;computerised tomography;content-based image retrieval;encephalic image;features extraction;gray-level cooccurrence matrix;image classification;nasal cavity image;nonnegative tensor factorization;vote scheme","","0","","13","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Fuzzy Retrieval System Employing Image Processing for Car Shape","T. Samatsu; K. Tachikawa; Y. Shi","Dept. of Mech. Syst. Eng., Tokai Univ., Kumamoto, Japan","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","1023","1026","This paper proposes a fuzzy retrieval system for purchasing cars employing image processing. This system aims to support such persons who are not good with machines or cars. When they try to purchase a car, they can use this system easily as if they ask casually someone else who knows more about car. Unspecific conditions are expressed by the fuzzy set, and the level matching conditions are expressed by the grade values. To use this more practically, a GUI form with selection menus is developed. In addition, calculating curvature by the car shape using the image processing, and adding an item for selecting a car shape from roundness and sharpness, try to improve usability of this system.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412651","","Fuzzy control;Fuzzy systems;Graphical user interfaces;Image processing;Image retrieval;Industrial engineering;Information retrieval;Shape control;Systems engineering and theory;Usability","automobiles;fuzzy set theory;graphical user interfaces;image processing;information retrieval systems;purchasing","GUI;car shape;fuzzy retrieval system;fuzzy set theory;graphical user interfaces;image processing","","0","","10","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Reversible data hiding for ordered dithered halftone images","B. K. Lien; Wei-Dyi Pei","Dept. of Computer Science and Information Engineering, Fu Jen Catholic Univ., Taiwan","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","4237","4240","A reversible data hiding method is a data hiding technique that hides data into cover media such that the cover media can be recovered distortion-free after the hidden data are retrieved. In this paper, we present a very robust reversible watermarking algorithm for all kinds of ordered dithered halftone images. The proposed method utilizes a new decomposition method to divide the pixels into two groups with very large statistical difference between each other so that the watermark can be decoded without error even under severely degradation. The experimental results show that the halftone image can be completely recovered if the watermarked image is intact and the correct decoding rate is 100% for the print/scan attack and degradation less than 25%.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413515","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413515","data hiding;ordered dither;reversible","Bit error rate;Computer science;Data encapsulation;Decoding;Degradation;Displays;Information retrieval;Noise generators;Robustness;Watermarking","data encapsulation;decoding;image coding;watermarking","decoding rate;image decomposition method;ordered dithered halftone images;reversible data hiding;robust reversible watermarking algorithm","","2","","12","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"A bio-inspired CNN with re-indexing engine for lossless DNA microarray compression and segmentation","S. Battiato; F. Rundo","University of Catania, Dipartimento di Matematica ed Informatica, Italy","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1737","1740","The DNA microarray images allow to analyze the natural gene expressions. In this paper we propose an advanced method to efficiently address the imaging storage as well as the performance of the algorithm used to retrieve information from DNA images. The cellular neural networks (CNNs) based core is able to provide a method to extract foreground (the DNA gene expression information) from DNA images. It is also proposed an innovative method to compress the DNA image by re-organizing the signal data belonging to the background by making use of a novel way to apply the re-indexing techniques to almost Â¿uncorrelatedÂ¿ signal. Experiments confirm how the proposed method outperform previous solution in almost all cases.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413629","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413629","CNNs;DNA microarray;lossless compression;re-indexing","Cellular neural networks;DNA;Engines;Gene expression;Image analysis;Image coding;Image retrieval;Image segmentation;Image storage;Information retrieval","DNA;cellular neural nets;data compression;image coding;image retrieval;image segmentation;indexing;lab-on-a-chip;medical image processing","bioinspired CNN;cellular neural network;image segmentation;imaging storage;information retrieval;lossless DNA microarray image compression;natural gene expression;reindexing engine;signal data reorganizing;uncorrelated signal","","3","","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Field experimentation of the RAMPE interactive auditive information system for the mobility of blind people in public transport : Final evaluation","O. Venard; G. Baudoin; G. Uzan","Universit&#233; Paris-Est Telecoms Department, ESIEE Paris, BP 99, F93162 Noisy le Grand","2009 9th International Conference on Intelligent Transport Systems Telecommunications, (ITST)","20100129","2009","","","558","563","This paper presents the experimentation of a system, developed through the RAMPE research project, intended for the assistance and information of blind or Visual Impaired People (VIP) so that they can increase their mobility and autonomy in public transports. The system is intended to equip bus or tramway stops. It is based either on a simple remote command or on a smart hand-held devices that is a WiFi enabled Personal Digital Assistant (PDA) able to retrieve travelers information. This system has been evaluated by blind People in real environment in the public transport in the city of Lyon in France. Ergonomics data has been collected during the experiment and analyzed, showing the usability of such kind of device by VIP.","","Electronic:978-1-4244-5347-4; POD:978-1-4244-5346-7","10.1109/ITST.2009.5399293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5399293","Real-Time travelers information system;Visually Impaired People;WLAN;assistive device;design for all;pervasive computing","Base stations;Cities and towns;Ergonomics;Information retrieval;Information systems;Personal digital assistants;Radio frequency;Real time systems;Speech synthesis;Telecommunications","audio signal processing;automated highways;ergonomics;handicapped aids;information retrieval;interactive systems;mobile computing;transportation;wireless LAN","RAMPE interactive auditive information system;WiFi;ergonomics data;public transport;remote command;smart handheld devices;travelers information retrieval;visual impaired people","","4","","8","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"Prosima: Protein similarity algorithm","T. Novosád; V. Snášel; A. Abraham; J. Y. Yang","Department of Computer Science, VSB - Technical University of Ostrava, The Czech Republic","2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)","20100122","2009","","","84","91","In this article, we present a novel algorithm for measuring protein similarity based on their three dimensional structure (protein tertiary structure). The PROSIMA algorithm using suffix tress for discovering common parts of main-chains of all proteins appearing in current NCSB protein data bank (PDB). By identifying these common parts we build a vector model and next use classical information retrieval tasks based on the vector model to measure the similarity between proteins - all to all protein similarity. For the calculation of protein similarity we are using tf-idf term weighing schema and cosine similarity measure. The goal of this work to use the whole current PDB database (downloaded on June 2009) of known proteins, not just some kinds of selections of this database, which have been studied in other works. We have chose the SCOP database for verification of precision of our algorithm because it is maintained primarily by humans. The next success of this work is to be able to determine protein SCOP categories of proteins not included in the latest version of the SCOP database (v. 1.75) with nearly 100% precision.","","Electronic:978-1-4244-5052-7; POD:978-1-4244-5053-4","10.1109/NABIC.2009.5393605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393605","","Amino acids;Computer science;Databases;Information retrieval;Lifting equipment;Machine intelligence;Nuclear magnetic resonance;Protein engineering;Sequences;Support vector machines","biology computing;information retrieval;proteins;trees (mathematics);vectors","PROSIMA algorithm;cosine similarity measure;information retrieval;protein similarity algorithm;protein tertiary structure;suffix tress;tf-idf term weighing schema;vector model","","4","","27","","","9-11 Dec. 2009","","IEEE","IEEE Conference Publications"
"Query fusion based on performance analysis","Rong Luo; Yuxi Gong","Institute of Computer Engineering, Qingdao Technological University, 266033, China","2009 2nd International Conference on Power Electronics and Intelligent Transportation System (PEITS)","20100205","2009","2","","101","103","Put the predicting query performance(PQP) into the query fusion and construct a new adaptive information retrieval system(QAAIR) based on performance analysis in the base of analyzing the method of PQP for IR system and expound the main technique. The experiment adopted testing data of TREC Web track show the method can improve the effectiveness of query and overcome the robust of information retrieval.","","Electronic:978-1-4244-4543-1; POD:978-1-4244-4544-8","10.1109/PEITS.2009.5406948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406948","nearest neighborss;performance analysis;query fusion","Adaptive systems;Information analysis;Information retrieval;Intelligent transportation systems;Performance analysis;Power electronics;Power engineering and energy;Robustness;Space technology;Testing","query processing","TREC Web track;adaptive information retrieval system;predicting query performance;query fusion;testing data","","0","","12","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Modeling Music as a Dynamic Texture","L. Barrington; A. B. Chan; G. Lanckriet","Department of Electrical and Computer Engineering, University of California, San Diego","IEEE Transactions on Audio, Speech, and Language Processing","20100208","2010","18","3","602","612","We consider representing a short temporal fragment of musical audio as a <i>dynamic texture</i>, a model of both the timbral and rhythmical qualities of sound, two of the important aspects required for automatic music analysis. The dynamic texture model treats a <i>sequence</i> of audio feature vectors as a sample from a linear dynamical system. We apply this new representation to the task of automatic song segmentation. In particular, we cluster audio fragments, extracted from a song, as samples from a dynamic texture mixture (DTM) model. We show that the DTM model can both accurately cluster coherent segments in music and detect transition boundaries. Moreover, the generative character of the proposed model of music makes it amenable for a wide range of applications besides segmentation. As examples, we use DTM models of songs to suggest possible improvements in other music information retrieval applications such as music annotation and similarity.","1558-7916;15587916","","10.1109/TASL.2009.2036306","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337999","Automatic segmentation;dynamic texture model (DTM);music modeling;music similarity","Bridges;Cepstral analysis;Character generation;Clustering algorithms;Humans;Instruments;Music information retrieval;Testing;Timbre;Vectors","audio signal processing;music","audio fragments;automatic music analysis;automatic song segmentation;dynamic texture;musical audio","","24","","48","","20091117","March 2010","","IEEE","IEEE Journals & Magazines"
"Timestamped Conjunctive Keyword-Searchable Public Key Encryption","Y. C. Chen; G. Horng","Dept. of Comput. Sci. & Eng., Nat. Chung-Hsing Univ., Taichung, Taiwan","2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)","20100217","2009","","","729","732","To realize ubiquitous computing, data should be able to be accessed from anywhere at anytime. However, for security purpose, we need to encrypt the data so that the attackers cannot obtain any information from the server. Nevertheless, the user should be able to use keywords to search and retrieve required data. To this end, we propose a timestamp based conjunctive keyword searchable public key encryption scheme. Our construction is semantically secure against adaptive chosen keyword attacks and off-line guessing attacks, based on the decision Diffie-Hellman assumption.","","Electronic:978-1-4244-5544-7; POD:978-1-4244-5543-0","10.1109/ICICIC.2009.369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412614","","Computer science;Cryptography;Data engineering;Data security;Electronic mail;Information retrieval;Keyword search;Network servers;Public key;Testing","public key cryptography;ubiquitous computing","adaptive chosen keyword attacks;decision Diffie-Hellman assumption;off-line guessing attacks;timestamped conjunctive keyword-searchable public key encryption;ubiquitous computing","","0","","12","","","7-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Web community-based video retrieval method using canonical correlation analysis","Y. Hatakeyama; T. Ogawa; S. Asamizu; M. Haseyama","Graduate School of Information Science and Technology Hokkaido University Sapporo 060-0814, Japan","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","805","808","This paper presents a Web community-based video retrieval method using canonical correlation analysis (CCA). In the proposed method, two novel approaches are introduced into the retrieval scheme of video materials on the Web. First, the CCA is applied to three kinds of video features, visual and audio features of video materials and textual features obtained from Web pages containing those video materials. This approach provides a solution of problems of traditional methods of not being able to calculate similarities between different kinds of video features. Furthermore, from the obtained similarities and link relationships of Web pages, a new adjacency matrix is defined, and link analysis can be applied to this matrix. Then, the Web communities of the video materials whose topics are similar to each other can be automatically extracted based on their features. Therefore, by ranking the video materials in the obtained Web community, accurate video retrieval can be realized.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414313","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414313","Canonical correlation analysis;Link analysis;Video retrieval;Web community extraction","Databases;Educational institutions;Feature extraction;Histograms;Information analysis;Information retrieval;Information science;Materials science and technology;Web and internet services;Web pages","Internet;content-based retrieval;correlation methods;feature extraction;video retrieval","Web community;Web pages;adjacency matrix;audio feature;canonical correlation analysis;link analysis;video feature;video feature extraction;video retrieval method;visual feature","","0","","10","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"On the intelligent content retrieval by means of text relevance modelling","S. Ionita","Department of Electronics and Computers, University of Pitesti, Romania","2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)","20100122","2009","","","433","438","This paper presents some results with application in area of web-based knowledge retrieval. The key issue on the relevant topics retrieving in practice is that the results returned by the actual search engines do not provide fully satisfaction to the user in terms of his or her informational needs. Considering the information utility is correlated to the semantic meaning - that is: if the information has the expected meaning then it can be considered to be useful. A measure of information utility in the contents is given by the relevancy of the search terms. In our study we achieve a preliminary experimental investigation on the set of informational sources, comparing the ranking of the documents by three distinct methods. One is based on a fuzzy logic relevance filter that was proposed as an original method by the author in his previous work. Its outcomes are compared with the answers returned by a popular web search engine and also with the solutions provided by the user. This research aims to improve the technology of intelligent information retrieval to access the relevant e-content.","","Electronic:978-1-4244-5052-7; POD:978-1-4244-5053-4","10.1109/NABIC.2009.5393318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393318","Fuzzy modelling;Information relevance;Web Intelligence","Application software;Content based retrieval;Fuzzy logic;Information analysis;Information retrieval;Knowledge management;Pattern analysis;Search engines;Web pages;Web search","Internet;data mining;fuzzy logic;information filters;information needs;knowledge management;relevance feedback;search engines","Web-based knowledge retrieval;fuzzy logic relevance filter;information utility;informational needs;intelligent content retrieval;knowledge discovery;knowledge management;relevant e-content;search engines;text relevance modelling;user satisfaction","","0","","10","","","9-11 Dec. 2009","","IEEE","IEEE Conference Publications"
"Framework for the Extraction of Clausal Mention Movement Events from the Text Using Its Meaning Representation","S. Sangeetha; R. S. Thakur; M. Arock","Dept. of Comput. Applic., Nat. Inst. of Technol., Tiruchirapalli, India","2009 Second International Conference on Emerging Trends in Engineering & Technology","20100122","2009","","","844","847","Given a text the proposed work is to identify clausal mention movement events in the text. As the existing event extraction systems do not incorporate the meaning of the text, there is a need for event extraction system that takes meaning of the text into account. The proposed work provides a framework for identifying events by considering the text meaning representation (TMR). The framework involves 4 phases, namely, identifying event triggers, event argument, event properties and annotation of event. Event triggers are recognized using statistical methods. Event arguments are identified from text meaning representation of the input text. Event properties are extracted from the outcome of syntactic analysis phase of TMR generating tool as well as TMR. This information is annotated with event extent so that it can be accessed by queries that need information about the events.","2157-0477;21570477","Electronic:978-0-7695-3884-6; POD:978-1-4244-5250-7","10.1109/ICETET.2009.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5395493","","Computer applications;Data mining;Event detection;Filtering;Information retrieval;Logistics;Production;Statistical analysis;Tellurium","information retrieval;text analysis","clausal mention movement event;event annotation;event argument;event extraction system;event properties;event triggers;statistical methods;syntactic analysis;text meaning representation","","0","","10","","","16-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"A New Suffix Tree Similarity Measure and Labeling for Web Search Results Clustering","A. Kale; U. Bharambe; M. SashiKumar","Thadomal Shahani Eng. Coll., P.G. Kher Marg, Bandra, India","2009 Second International Conference on Emerging Trends in Engineering & Technology","20100122","2009","","","856","861","Due to the enormous size of the web and low precision of user queries, finding the right information from the web can be difficult if not impossible. One approach that tries to solve this problem is using clustering techniques for grouping similar documents together in order to facilitate presentation of results in more compact form and enable thematic browsing of the results set. Web search results clustering is an attempt to apply the idea of clustering to document references (snippets) returned by a search engine in response to a query. Thus, it can be perceived as a way of organizing the snippets into set of meaningful thematic groups. This paper introduces a new similarity criterion for merging which is evaluated for search results returned from actual web search engines.","2157-0477;21570477","Electronic:978-0-7695-3884-6; POD:978-1-4244-5250-7","10.1109/ICETET.2009.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5395068","","Clustering algorithms;Educational institutions;Information retrieval;Labeling;Merging;Navigation;Organizing;Search engines;Size measurement;Web search","Internet;information retrieval;pattern clustering;search engines;trees (mathematics)","document references;suffix tree similarity measure;user queries;web search engines;web search results clustering","","1","","34","","","16-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"Web-Based Variant of the Lesk Approach to Word Sense Disambiguation","M. Á. R. Gaona; A. Gelbukh; S. Bandyopadhyay","Center for Comput. Res., Nat. Polytech. Inst., Mexico City, Mexico","2009 Eighth Mexican International Conference on Artificial Intelligence","20100217","2009","","","103","107","Word Sense Disambiguation (WSD) is the task of selecting the meaning of a word based on the context in which the word occurs. The principal statistical WSD approaches are supervised and unsupervised learning. The Lesk method is an example of unsupervised disambiguation. We present a measure for sense assignment useful for the simple Lesk algorithm. We use word co-occurrences of the gloss and the context, which is statistical information retrieved from the Web. In the SemCor data our method always gives an answer. On the Senseval 2 data, our variant of the Lesk method outperformed some other Lesk-based methods.","","POD:978-0-7695-3933-1","10.1109/MICAI.2009.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5372708","Natural Language Processing;Unsupervised disambiguation;Word Sense Disambiguation","Artificial intelligence;Cities and towns;Computer science;Costs;Dictionaries;Information retrieval;Knowledge acquisition;Mice;Testing;Unsupervised learning","Internet;information retrieval;natural language processing;unsupervised learning;word processing","Lesk algorithm;Lesk method;SemCor data;World Wide Web;principal statistical WSD;sense assignment;statistical information retrieval;unsupervised disambiguation;unsupervised learning;word co-occurrences;word sense disambiguation","","5","","27","","","9-13 Nov. 2009","","IEEE","IEEE Conference Publications"
"Retrieval of shoemarks using Harris points and SIFT descriptor","O. Nibouche; A. Bouridane; D. Crookes; M. Gueham; M. Laadjel","ECIT Center, Queen's University of Belfast, Queen's Rd, BT9 3DT, UK","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","2897","2900","In this paper, we suggest a solution for the problem of scene-of-crime shoeprints retrieval based on the use of multi-scale Harris points, which are a set of very distinctive points of interest in an image, combined with SIFT descriptor. We show that such combination can overcome the issue of retrieval of partial prints in the presence of scale and rotation distortions with Gaussian noise perturbation. Excellent results were obtained for synthetic scene images, clearly outperforming published results in the literature.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413444","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413444","Harris points;SIFT descriptor;Shoemark","Feature extraction;Footwear;Gaussian noise;Image databases;Image recognition;Image retrieval;Indexing;Information retrieval;Layout;Spatial databases","Gaussian noise;feature extraction;footwear;image retrieval;perturbation techniques","Gaussian noise perturbation;Harris points;SIFT descriptor;rotation distortions;shoemark retrieval;synthetic scene images","","0","","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Open source software for personal information managers and personal knowledge management","K. M. Khan; U. Naik","Department of Studies in Library and Information Science, Mangalore University, Karnataka, India","2009 International Conference for Internet Technology and Secured Transactions, (ICITST)","20100129","2009","","","1","12","Technology is common in the domain of knowledge distribution, but it rarely enhances the process of knowledge use. Distribution delivers knowledge to the potential user's desktop but cannot dictate what he or she does with it thereafter. It would be interesting to envision technologies that help to manage personal knowledge as it applies to decisions and actions. The viewpoints about knowledge vary from individual, community, society, personnel development or national development. Personal Knowledge Management (PKM) integrates Personal Information Management (PIM), focused on individual skills, with Knowledge Management (KM). KM Software is a subset of Enterprise content management software and which contains a range of software that specialises in the way information is collected, stored and/or accessed. This article focuses on KM skills, PKM and PIM Open Sources Software, Social Personal Management and also highlights the Comparison of knowledge base management software and its use.","","Electronic:978-1-4244-5648-2; POD:978-1-4244-5647-5","10.1109/ICITST.2009.5402558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402558","","Content management;Databases;Information management;Information retrieval;Information science;Knowledge management;Open source software;Personnel;Software libraries;Technology management","content management;human computer interaction;information management;knowledge management;personal information systems;public domain software","enterprise content management software;human-computer interaction;individual skills;knowledge delivery;knowledge distribution;open source software;personal information management;personal knowledge management;social personal management;users desktop","","0","1","13","","","9-12 Nov. 2009","","IEEE","IEEE Conference Publications"
"Robust affine invariant shape image retrieval using the ICA Zernike Moment Shape Descriptor","Ye Mei; D. Androutsos","Department of Electrical and Computer Engineering, Ryerson University, 350 Victoria Street, Toronto, Ontario, Canada M5B 2K3","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1065","1068","In this paper, we proposed a new affine invariant region-based shape descriptor, the ICA Zernike Moment Shape Descriptor (ICAZMSD). Independent Component Analysis (ICA) is first used to turn the original shape into a canonical form, in which the effects of scaling and skewing are eliminated. Next, the properties of the Zernike transform is used to further eliminate the effects of any possible rotation and reflection of the canonical shapes, in extracting the Zernike moments as the affine invariant region-based descriptors. Using the proposed ICAZMSD as shape feature, shape-based image retrieval experiments on a 4000 complex shape image database and a 5600 simple shape image database, show promising retrieval rates of 99.80% and 92.25%, respectively.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413537","Affine Invariant;Independent Component Analysis;Shape Descriptor;Zernike moments","Image databases;Image retrieval;Independent component analysis;Information retrieval;Object recognition;Reflection;Robustness;Shape;Spatial databases;Wheels","affine transforms;content-based retrieval;image retrieval;independent component analysis;shape recognition","ICA Zernike moment shape descriptor;Zernike moments;Zernike transform;affine invariant shape image retrieval;complex shape image database;independent component analysis;invariant region-based shape descriptor;simple shape image database","","2","","6","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Genetic Algorithm Based to Improve HTML Document Retrieval","A. Al-Dallal; R. S. Abdul-Wahab","Sch. of Inf. Syst. Comput. & Math., Brunel Univ., Uxbridge, UK","2009 Second International Conference on Developments in eSystems Engineering","20100122","2009","","","343","348","This paper describes GAHWM, a new evolutionary algorithm that integrates genetic algorithm paradigm with an inverted index model to mine the content of HTML documents for effective Web document retrieval. This method is superior in terms of recall and precision over various real life datasets.","","Electronic:978-1-4244-5402-0; POD:978-1-4244-5401-3","10.1109/DeSE.2009.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5395140","AI;Genetic Algorithm;Inverted Index;Web Mining","Biological cells;Content based retrieval;Data mining;Evolutionary computation;Genetic algorithms;HTML;Information retrieval;Search engines;Web mining;Web pages","Internet;data mining;genetic algorithms;hypermedia markup languages;information retrieval","GAHWM;HTML Web content mining;HTML document retrieval;Web document retrieval;evolutionary algorithm;genetic algorithm;inverted index model","","2","","14","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"iMATCH: Image Matching and Retrieval for Digital Image Libraries","S. N. Talbar; S. L. Varma","Dept. of Electron. & Telecommun., SGGS, Nanded, India","2009 Second International Conference on Emerging Trends in Engineering & Technology","20100122","2009","","","196","201","Content-based image retrieval (CBIR), also known as query by image content (QBIC) and content-based visual information retrieval (CBVIR) is the application of computer vision to the image retrieval problem, that is, the problem of searching for digital images in large databases. It is increasingly evident that an image retrieval system has to be domain specific. In this paper, we present an algorithm for retrieving images with respect to a database consisting of difference class of images. The feature vectors used are DCT coefficient arranged in a typical fashion. Image similarity is computed using k-means clustering followed by the modified chi-square distance measure.","2157-0477;21570477","Electronic:978-0-7695-3884-6; POD:978-1-4244-5250-7","10.1109/ICETET.2009.119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5395500","","Application software;Computer vision;Content based retrieval;Digital images;Image databases;Image matching;Image retrieval;Information retrieval;Software libraries;Spatial databases","content-based retrieval;digital libraries;discrete cosine transforms;image matching;image retrieval;pattern clustering","DCT coefficient;content based image retrieval;content based visual information retrieval;digital image libraries;discrete cosine transform;iMATCH;image matching;k means clustering;large databases;modified chi square distance measure;query by image content","","2","","24","","","16-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"M4WebGIS: A Mobile Agent-Based Middleware for WebGIS","W. Huang; J. Xu","Sch. of Comput. Sci. & Technol., Soochow Univ., Suzhou, China","2009 Second International Workshop on Computer Science and Engineering","20100202","2009","2","","234","237","Geographic information systems (GIS) are now widely used. WebGIS, pushed by keeping increasing information resources, enriches functions and content of GIS under WWW framework. We propose a mobile agent-based middleware for WebGIS, called M4WebGIS, which consists of a group of coordinated agents for users to retrieve geographic information. Function logic of server part, processing logic of client part and underlying operation of system, such as interaction with operating system, network, and database, are designed separately in M4WebGIS to achieve stability. Independence between modules ensures extensibility. Moreover, functions such as map management, user management and data management, make M4WebGIS as an integrated middleware system. M4WebGIS offers functions, such as roaming and zooming in several map layers, spatial information analysis and retrieval, database supporting, real-time event tracking, different systems compatibility supporting, and adding spatial characteristics to Web site. Using M4WebGIS, application developers, data distributors and spatial database engine vendors can add dynamic, data-driven map to their applications. M4WebGIS can be integrated into development environment seamlessly, reducing application system complexity, speeding up development progress of applications, alleviating cost and enhancing maintainability as well. In the distributed environment, M4WebGIS achieves pretty parallel computing, balances network workload, acquires exact geographic information and saves network bandwidth.","","Electronic:978-0-7695-3881-5; POD:978-1-4244-5285-9","10.1109/WCSE.2009.802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403278","GIS;WebGIS;agent;middleware;web application","Geographic Information Systems;Information resources;Information retrieval;Logic design;Middleware;Network servers;Operating systems;Spatial databases;Stability;World Wide Web","Internet;geographic information systems;middleware;mobile agents;parallel processing","M4WebGIS;data management;geographic information system;map management;middleware;mobile agent;parallel computing;user management","","3","","16","","","28-30 Oct. 2009","","IEEE","IEEE Conference Publications"
"An approach on the automatic generation of concept weights for test items","Ziguang Sun; Zengfang Zhang; Meng Wang; Qin Wang","Dept. of Computer Engineering, Guangxi University of Technology, Liuzhou, China","2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)","20100205","2009","2","","92","95","This paper proposes a structure that automatically analyzes the parameters of Chinese test items. This structure utilizes latent semantic analysis (LSA) to analyze the relationships of keywords among all test items in an item bank. It also uses the similarity measure to calculate the similarity degree of keywords. We also propose an algorithm, which is similar to the graph-theoretic algorithm, for keyword clustering. The concept weights of each test item can be generated automatically with the proposed automatic generate concept weights.","","Electronic:978-1-4244-4607-0; POD:978-1-4244-4606-3","10.1109/PACIIA.2009.5406546","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406546","Latent semantic analysis;cluster analysis;concept weights;test items;test sheet","Automatic testing;Clustering algorithms;Computational intelligence;Computer aided instruction;Computer science education;Data mining;Information retrieval;Internet;Matrix decomposition;Space technology","computer aided instruction;graph theory;pattern clustering","Chinese test items;automatic generation;concept weight;graph theoretic algorithm;keyword clustering;keywords similarity degree;latent semantic analysis","","0","","9","","","28-29 Nov. 2009","","IEEE","IEEE Conference Publications"
"Architectural model for a high performance content management system","R. Vasilescu","Polytechnic University of Bucharest, Computer Science University, Hungary","2009 International Conference for Internet Technology and Secured Transactions, (ICITST)","20100129","2009","","","1","6","Usually content management systems are based on core technologies such as database management systems and file systems. Content management is now being regarded as a base technology for other more complex applications which offer a wide range of functionality for accessing and transforming large data volumes. While content management tasks can be easily implemented using the existing database systems, we believe that high performance implementations require specialized processing and architectures. This paper will describe the proposed architecture of a high performance content management system and will present some experimental conclusions from a model implementation. The proposed architecture focuses on the content management specific characteristics identification and describes a new implementation model, aiming at supplying greater performance than conventional ones.","","Electronic:978-1-4244-5648-2; POD:978-1-4244-5647-5","10.1109/ICITST.2009.5402570","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402570","","Application software;Collision mitigation;Computer science;Content based retrieval;Content management;Data security;Database systems;File systems;Information retrieval;Time measurement","content management","architectural model;database management system;file system;high performance content management","","1","","4","","","9-12 Nov. 2009","","IEEE","IEEE Conference Publications"
"CASanDRA: A Framework to Provide Context Acquisition Services ANd Reasoning Algorithms for Ambient Intelligence Applications","A. M. Bernardos; P. Tarrío; J. R. Casar","Univ. Politec. de Madrid, Madrid, Spain","2009 International Conference on Parallel and Distributed Computing, Applications and Technologies","20100217","2009","","","372","377","The development of ambient intelligence (AmI) applications usually implies dealing with complex sensor access and context reasoning tasks, which may significantly slow down the application development cycle when vertically assumed. To face this issue, we present CASanDRA, a middleware which provides easily consumable context information about a given user and his environment, retrieving and fusing data from personal mobile devices and external sensors. The framework is built following a layered service oriented approach. The output data from every CASanDRA's layer are fully accessible through semantic interfaces; this allows AmI applications to retrieve raw context features, aggregated context data and complex `images of context', depending on their information needs. Moreover, different query modes -subscription, event-based, continuous and on-demand- are available. The current `mobile-assisted' version of CASanDRA is composed by a CASanDRA Server, developed on an applications container and hosting the system intelligence, and CASanDRA Lite, a mobile client bundling a set of sensor level acquisition services. How an AmI application may be effortlessly built on CASanDRA is described in the paper through the design of an `Ambient Home Care Monitor'.","2379-5352;23795352","POD:978-0-7695-3914-0","10.1109/PDCAT.2009.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5372777","ambient home care systems;context-aware systems;sensor networks;ubiquitous frameworks","Ambient intelligence;Containers;Context-aware services;Image retrieval;Information retrieval;Intelligent sensors;Intelligent systems;Middleware;Monitoring;Sensor systems and applications","data acquisition;home computing;middleware;mobile computing;mobile handsets;sensor fusion;software architecture","CASanDRA server;ambient home care monitor;ambient intelligence applications;application development cycle;complex sensor access;context acquisition services;context data;context images;context reasoning tasks;data fusion;data retrieval;information needs;layered service oriented approach;middleware;mobile client;mobile-assisted version;personal mobile devices;query modes;reasoning algorithms;sensor level acquisition services;system intelligence","","5","","14","","","8-11 Dec. 2009","","IEEE","IEEE Conference Publications"
"Intelligent Query by Humming System","G. P. Nam; K. R. Park; S. P. Lee; E. C. Lee; M. Y. Kim; K. Kim","Dept. of Electron. Eng., Dongguk Univ., Seoul, South Korea","Proceedings of the 4th International Conference on Ubiquitous Information Technologies & Applications","20100205","2009","","","1","6","This research proposes new system which finds the music by using Query-by-humming (QBH). For finding a stored music, the features of humming data are selected by using G.729 feature extractor. We normalize the extracted features by using mean-shifting, median filtering, average filtering and min-max scaling methods. Then the corresponding music is matched based on dynamic time warping (DTW) algorithm. As experiment, we compared the matching performance by using the database of Roger Jang's Corpus in MIREX.","1976-0035;19760035","Electronic:978-1-4244-5130-2; POD:978-1-4244-5131-9","10.1109/ICUT.2009.5405705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5405705","","Computer science;Content based retrieval;Data mining;Feature extraction;Filtering;Flowcharts;Matched filters;Music information retrieval;Spatial databases;Speech","feature extraction;information filtering;median filters;minimax techniques;music;query processing","G.729 feature extractor;Humming system;MIREX;QBH;average filtering;dynamic time warping algorithm;feature extraction;intelligent query;mean-shifting;median filtering;min-max scaling methods;music","","1","","10","","","20-22 Dec. 2009","","IEEE","IEEE Conference Publications"
"Single Snapshot R-D Unitary Tensor-ESPRIT Using an Augmentation of the Tensor Order","A. Thakre; M. Haardt; K. Giridhar","Electrical Engineering Department, Indian Institute of Technology Madras, India","2009 3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","20100217","2009","","","81","84","Single snapshot R-D unitary tensor-ESPRIT using an augmentation of the tensor order (SS-U-TE-ATO) is a subspace-based parameter estimation technique for R-dimensional (R-D) undamped harmonics using a single snapshot of data. In SS-U-TE-ATO the measurement data is packed into a measurement tensor to which spatial smoothing is applied. We propose the construction of R higher-order tensors from the spatially smoothed tensor by exploiting the inherent structure of the spatially smoothed tensor. In the next step of SS-U-TE-ATO, R enhanced real-valued signal subspace estimates, one for each dimension, are obtained from the R complex-valued higher-order tensors. We show that SS-U-TE-ATO performs significantly better than unitary tensor-ESPRIT (U-TE) directly applied to the spatially smoothed tensor. Moreover, for each dimension, SS-U-TE-ATO is almost insensitive to changes in the number of sensors per subarray provided that the number of subarrays is greater than the number of sources. Thereby we avoid the problem of selecting the optimum subarray size for a given source configuration.","","Electronic:978-1-4244-5180-7; POD:978-1-4244-5179-1","10.1109/CAMSAP.2009.5413233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413233","HOSVD;multidimensional signal processing;multilinear algebra;parameter estimation;undamped harmonics","Algebra;Conferences;MIMO;Multidimensional signal processing;Multidimensional systems;Multiple signal classification;Music information retrieval;Parameter estimation;Smoothing methods;Tensile stress","multidimensional signal processing;parameter estimation;smoothing methods;tensors","ESPRIT;R higher-order tensors;R-D unitary tensor;R-dimensional undamped harmonics;augmentation of the tensor order;single snapshot;spatially smoothed tensor;subspace-based parameter estimation","","2","","11","","","13-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Implementation of unsystematic cyclic codes on DSP 56F8300 hybrid board","G. Deka; S. Kashyap; B. P. Pokhrel; S. Majumder; P. K. Dutta","Dept of ECE, NERIST, Nirjuli,India","2009 4th International Conference on Computers and Devices for Communication (CODEC)","20100205","2009","","","1","4","In this age of information, there is increasing need not only for speed as well as accuracy in the storage, retrieval, and transmission of data. Error correcting codes are a kind of safety net- the mathematical insurance against the vagaries of an imperfect digital world, due to faulty transmission channel, manmade and non-manmade errors, to recover the original data from the corrupted one. Here the approach is to take the unsystematic variant of cyclic code and its implementation in the Motorola DSP 56F8300 hybrid board. This chip has the luxury of having both microcontroller and digital signal processor characteristics on board. Processor ExpertÂ® based IDE was used for this purpose and the implementation has been checked with respect to MATLABÂ® program based output as well as digital TTL gate based hardware. The unsystematic variant has been chosen to eradicate the necessity of the look up tables as required in case of the systematic cyclic codes and on board it has been checked for (3, 1), (7, 4), (15, 11), (31, 26) and (63, 57) codes.","","Electronic:978-81-8465-152-2; POD:978-1-4244-5073-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5407184","DSP 56F8300;Error Correcting Codes;MATLAB®;Processor Expert®","Computer languages;Digital signal processing;Digital signal processing chips;Digital signal processors;Error correction codes;Hardware;Information retrieval;Insurance;Microcontrollers;Safety","cyclic codes;data communication;digital signal processing chips;mathematics computing;table lookup;telecommunication channels","IDE;MATLAB;Motorola DSP 56F8300 hybrid board;Processor Expert;cyclic codes;data retrieval;data storage;data transmission;digital TTL gate based hardware;digital signal processor;error correcting codes;faulty transmission channel;look up tables;microcontroller;non-manmade errors","","0","","14","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Semantic-Based Dynamic Search Engine Design and Implementation for Electronic Medical Records","W. D. Yu; S. K. Yilayavilli","Computer Engineering Department, San Jose State University, (Silicon Valley), California, 95192-0180, USA","2009 11th International Conference on e-Health Networking, Applications and Services (Healthcom)","20100205","2009","","","187","189","Information retrieval activities in many different areas are using popular Web search engines, such as Google, Yahoo!, and Live Search, etc. to obtain initial helpful information. These retrieved information items may not be relevant to the search target in the search engine user's mind. The user in turn has to shortlist the results. These popular Web search engines use first generation search service based on Â¿static keywordsÂ¿, which require the users to type in the exact keywords. This approach clearly puts the users in a critical situation of guessing the exact keyword. The users may want to define their search by using attributes of the search target. This paper is to investigate and design a dynamic, question-answer type of search engine, which enables the search by attributes for more precise and relevant information in electronic medical record (EMR) field.","","Electronic:978-1-4244-5014-5; POD:978-1-4244-5013-8","10.1109/HEALTH.2009.5406185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406185","","Application specific processors;Data mining;Information retrieval;Medical services;Ontologies;Resource description framework;Search engines;Service oriented architecture;Social network services;Web search","medical information systems;search engines;semantic Web","Web search engines;electronic medical records;information retrieval;semantic-based dynamic search engine design","","0","","5","","","16-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"Lidar waveform modeling using a marked point process","C. Mallet; F. Lafarge; F. Bretar; U. Soergel; C. Heipke","Laboratoire MATIS, Institut G&#233;ographique National - Saint-Mand&#233;, FRANCE","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1713","1716","Lidar waveforms are 1D signal consisting of a train of echoes where each of them correspond to a scattering target of the Earth surface. Modeling these echoes with the appropriate parametric function is necessary to retrieve physical information about these objects and characterize their properties. This paper presents a marked point process based model to reconstruct a lidar signal in terms of a set of parametric functions. The model takes into account both a data term which measures the coherence between the models and the waveforms, and a regularizing term which introduces physical knowledge on the reconstructed signal. We search for the best configuration of functions by performing a Reversible Jump Markov Chain Monte Carlo sampler coupled with a simulated annealing. Results are finally presented on different kinds of signals in urban areas.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413380","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413380","3D point cloud;Lidar;Marked point process;RJMCMC;Signal reconstruction;Source modeling","Coherence;Earth;Information retrieval;Laser radar;Monte Carlo methods;Scattering;Signal processing;Simulated annealing;Surface reconstruction;Surface waves","Markov processes;Monte Carlo methods;optical radar;radar signal processing;signal reconstruction;simulated annealing","1D signal;Earth surface;LIDAR signal reconstruction;LIDAR waveform modeling;echoes train;marked point process;parametric functions;physical information;reversible jump Markov chain Monte Carlo sampler;scattering target;simulated annealing","","5","","13","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Boosting object retrieval by estimating pseudo-objects","Kuan-Hung Lin; K. T. Chen; W. H. Hsu; C. J. Lee; T. H. Li","National Taiwan University, Taipei, Taiwan","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","785","788","State-of-the-art object retrieval systems are mostly based on the bag-of-visual-words representation which encodes local appearance information of an image in a feature vector. A search is performed by comparing query object's feature vector with those for database images. However, a database image vector generally carries mixed information of an entire image which may contain multiple objects and background. Search quality is degraded by such noisy (or diluted) feature vectors. We address this issue by introducing the concept of pseudo-objects to approximate candidate objects in database images. A pseudo-object is a subset of proximate feature points in an image with its own feature vector to represent a local area. We investigate effective methods (e.g., Grid, G-means, and GMM-BIC) to estimate pseudo-objects. Experimenting over two consumer photo benchmarks, we demonstrate the proposed methods significantly outperforming other state-of-the-art object retrieval algorithms.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414228","image retrieval;object retrieval;pseudo-object;visual word","Boosting;Computer vision;Content based retrieval;Frequency;Histograms;Image databases;Image retrieval;Information retrieval;Spatial databases;Visual databases","image retrieval;object detection","bag-of-visual-words representation;object retrieval boosting;pseudo-object estimation;search quality","","1","","10","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Retrieving dental radiographs for post-mortem identification","A. Abaza; A. Ross; H. Ammar","West Virginia University, Lane Department of Computer Science and Electrical Engineering, Morgantown, USA, 26506","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","2537","2540","Automating the process of postmortem identification of deceased individuals based on dental characteristics is receiving increased attention. With the large number of victims encountered in mass disasters (e.g., Asian tsunami), automating the identification process would enhance the scalability of this biometric. However, archiving and retrieving dental records from large databases is a challenging task and has received inadequate attention in the literature. This paper concerns itself with the task of efficient fast retrieving dental records from a database in order to assist the forensic expert in identifying deceased individuals in a rapid manner. The proposed method is an appearance-based technique that consolidates the evidence presented by individual teeth in a dental record, i.e., it `moves' from tooth-to-tooth in order to render a record-to-record matching score. The proposed method is shown to reduce the searching time of record-to-record matching by a factor of hundred. Experimental results indicate that the proposed approach requires significantly less time compared to the other approaches suggested in the literature thereby underscoring its relevance in real-time applications.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414011","Automated dental identification system (ADIS);Eigen-teeth;Postmortem Identification;Record Retrieving","Biometrics;Databases;Dentistry;Forensics;Image segmentation;Information retrieval;Principal component analysis;Radiography;Teeth;Tsunami","biometrics (access control);content-based retrieval;image matching;image retrieval;visual databases","appearance-based technique;biometric identification;dental radiographs retrieval;dental records database;dental records retrieval;forensic expert;postmortem identification;record-to-record matching","","4","","14","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Towards Keyword Search over Relational Databases in DHT Networks","J. Yu; J. Guan; J. Xu; S. Zhou","Dept. of Comput. Sci. & Technol., Tongji Univ., Shanghai, China","2009 15th International Conference on Parallel and Distributed Systems","20100122","2009","","","448","455","Recent research has shown that keyword search is a friendly and potentially effective way to retrieve information of interest over relational databases. Existing work has generally focused on implementing keyword search in centralized databases. This paper addresses keyword search over distributed databases. We adopts distributed hash tables (DHTs) - a peer-to-peer inspired overlay network technology - as the infrastructure to implement keyword search over relational databases. For this end, we combine IR-based ranking techniques with a P2P-based indexing strategy, and propose an effective approach. Extensive experiments over real-world datasets show that our approach is effective and efficient.","1521-9097;15219097","Electronic:978-1-4244-5789-2; POD:978-1-4244-5788-5","10.1109/ICPADS.2009.133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5395316","Distributed Hash Tables;Keyword Searching;Peer-to-Peer Networks;Relational Databases","Computer science;Deductive databases;Indexing;Information retrieval;Intelligent networks;Internet;Keyword search;Peer to peer computing;Query processing;Relational databases","cryptography;distributed databases;peer-to-peer computing;query processing;relational databases","DHT networks;IR-based ranking techniques;P2P-based indexing strategy;distributed databases;distributed hash table;information retrieval;keyword search;overlay network technology;peer-to-peer networks;relational database","","0","","29","","","8-11 Dec. 2009","","IEEE","IEEE Conference Publications"
"Application of bilateral filtering and Gaussian Mixture modeling for the retrieval of paintings","M. Luszczkiewicz; B. Smolka","Silesian University of Technology, Department of Automatic Control, Akademicka 16, 44-100 Gliwice, Poland","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","77","80","In this paper we propose a novel approach to the problem of color image indexing and retrieval applied for collections of paintings. The described indexing technique utilizes the Gaussian Mixture Model of the color histogram based on weights provided by the Bilateral Filtering scheme. Thus, the proposed technique considers not only the global distribution of the color image pixels but also takes into account their spatial arrangement. The model parameters serve as signatures which enable fast and efficient retrieval of paintings in large databases. The proposed approach is not only robust to color image distortions introduced by lossy compression artifacts and therefore it is well suited for indexing and retrieval of collections of paintings, but it also provides meaningful results, coherent in their artistic style features.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414097","Color image indexing and retrieval","Color;Filtering;Histograms;Image databases;Image retrieval;Indexing;Information retrieval;Painting;Pixel;Spatial databases","Gaussian processes;content-based retrieval;database indexing;filtering theory;image colour analysis;image retrieval","Gaussian mixture modeling;bilateral filtering;color histogram;color image indexing;lossy compression artifacts;painting retrieval;spatial arrangement","","3","","12","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Key technique research of image retrieval based on combination feature","Y. Yang; L. Wang","Department of Computer Science and Technology, Hebei Normal University of Science and Technology, Qinghuangdao, China","2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)","20100205","2009","2","","69","72","In this paper, we introduce the generalization of feature-based image retrieval, the technology of semantic query and how to use CBIR on web. It research the different methods retrieval the image, including color-shape feature (CS) and color-texture-shape (CTS) feature. Through contrasting CS, CST we found CS and CST enhanced effectively and decreased the storage space and calculation. On the base of the color, texture and shape features, the technology of semantic query is proposed in this paper. The query not only reflect the low-layer physical property of image, but also joined with the high-layer semantic property of image. The retrieval performance is improved efficiently.","","Electronic:978-1-4244-4607-0; POD:978-1-4244-4606-3","10.1109/PACIIA.2009.5406539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406539","Morphology;image database;semantic query","Computer science;Content based retrieval;Histograms;Image databases;Image retrieval;Information retrieval;Multimedia databases;Quantization;Shape;Space technology","Internet;content-based retrieval;image colour analysis;image retrieval;image texture","CBIR;World Wide Web;color-shape feature;color-texture-shape feature;combination feature;feature based image retrieval;semantic query","","0","","8","","","28-29 Nov. 2009","","IEEE","IEEE Conference Publications"
"The retrieval system based on concept extending","M. Zhang; Ming Liu","Department of Computer Science, HuaZhong Normal University, Wuhan CHINA","2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)","20100205","2009","2","","365","368","At present, the retrieval approaches could not match the concept with identical meaning but dissimilar expression. To aim at solving the problem, this paper puts forward a retrieval model based on concept extending. The system model is composed of three levels, which are the query level, the concept extending level, and the retrieval level. In the model, an extending method based on concept is proposed to extend user's query from the concept hierarchy. This paper not only describes its extending algorithm after presenting a concept similarity between words, but also analyzes the merits of the extending method. Moreover, a result ranking method based on concept is proposed, to filter out the results with low scores at the concept level. In addition, the experiment's result shows that the concept extending approach has improved the performance of retrieval system.","","Electronic:978-1-4244-4607-0; POD:978-1-4244-4606-3","10.1109/PACIIA.2009.5406582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406582","concept extending;ranking;similarity","Algorithm design and analysis;Application software;Computational intelligence;Computer industry;Computer science;Content based retrieval;Filters;Fuzzy set theory;Humans;Information retrieval","information filtering;query processing","concept extending;query level;result ranking method;results filtering;retrieval system","","2","","13","","","28-29 Nov. 2009","","IEEE","IEEE Conference Publications"
"Wavelet-based colour texture retrieval using the kullback-leibler divergence between bivariate generalized Gaussian models","G. Verdoolaege; Y. Rosseel; M. Lambrechts; P. Scheunders","Department of Data Analysis, Ghent University, Henri Dunantlaan 1, 9000 Gent, Belgium","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","265","268","We study the retrieval of coloured textures from a database. In a statistical framework we model the heavy-tailed wavelet histograms through a generalized Gaussian distribution (GGD). We choose the Kullback-Leibler divergence (KLD) as a similarity measure and we obtain a closed-form expression for the KLD between two zero-mean bivariate GGDs. This allows us to take into account the rich correlation structure between the colour bands two by two. We show that this results in a considerably improved retrieval rate and, in addition, we demonstrate the superior performance of the bivariate GGD, in comparison with the bivariate Gaussian.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413405","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413405","Kullback-Leibler divergence;colour texture retrieval;multivariate generalized Gaussian distribution","Closed-form solution;Content based retrieval;Discrete wavelet transforms;Gaussian distribution;Histograms;Image databases;Image retrieval;Information retrieval;Wavelet coefficients;Wavelet domain","Gaussian distribution;image colour analysis;image retrieval;image texture;visual databases;wavelet transforms","bivariate generalized gaussian models;heavy-tailed wavelet histograms;kullback-leibler divergence;retrieval rate;wavelet-based colour texture retrieval;zero-mean bivariate generalized gaussian distribution","","10","","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Speech recognition system for embedded real-time applications","O. Cheng; W. Abdulla; Z. Salcic","Department of Electrical and Computer Engineering, University of Auckland, New Zealand","2009 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)","20100205","2009","","","118","122","In this paper, a hardware/software co-processing speech recognizer for embedded applications is proposed. The system mainly consists of a softcore processor and a hardware accelerator. The accelerator is responsible for GMM emission probability calculation, which is the major computational bottleneck. To alleviate the memory bandwidth issue, the hardware accelerator uses double-buffering, which allows parallel operation of data retrieval and GMM computation. The proposed accelerator is synthesized on an Altera Stratix II FPGA device together with a Nios II softcore processor running at 100 MHz. The proposed system is compared with a pure software-based system using test utterances from the Resource Management (RMI) corpus. For a speech utterance length of 2.49 s, the decoding time reduces from 6.64 s to 2.48 s. The real-time factor improves from 2.67 to 1.00. The word accuracy rate of the proposed system on the RM corpus is 93:42%.","2162-7843;21627843","Electronic:978-1-4244-5950-6; POD:978-1-4244-5949-0","10.1109/ISSPIT.2009.5407487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5407487","Embedded application;Field Programmable Gate Arrays;Real-time system;Softcore processor;Speech recognition","Application software;Bandwidth;Concurrent computing;Embedded software;Hardware;Information retrieval;Probability;Real time systems;Speech recognition;Speech synthesis","embedded systems;field programmable gate arrays;hardware-software codesign;speech recognition","Altera Stratix II FPGA device;GMM emission probability calculation;Nios II softcore processor;frequency 100 MHz;hardware accelerator;hardware-software coprocessing;speech recognition system","","2","","12","","","14-17 Dec. 2009","","IEEE","IEEE Conference Publications"
"Large corpus of Iranian music","M. H. Shirali-Shahreza; S. Shirali-Shahreza","Virtual Education Graduate College, Amirkabir University of Technology, Iran","2009 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)","20100205","2009","","","568","573","Digital music is now widely used and a great number of digital music files are available on the Internet. Designing systems that can automatically index, search and retrieve the digital music is one of the active research fields. One of the requirements for design and evaluation of such systems is corpuses of digital music samples. A good corpus is expected to have a number of features such as including a great number of samples, have samples of different artists and also samples with different quality. Additionally, the regional music of different parts of the world uses local musical instruments which results in music that are acoustically different. So, corpuses of regional music are needed for design and evaluation of web scale systems. Considering the above reasons, we created a large corpus of Iranian music. In this paper, we review available public music corpuses and then describe our corpus. Our corpus contains 27496 music tracks of 1355 artists that gathered from the Internet. The lyrics for more than 54% of tracks are also provided. We analyze the different aspects of collected tracks such as their bit rate and sampling rate which are helpful in designing large scale systems.","2162-7843;21627843","Electronic:978-1-4244-5950-6; POD:978-1-4244-5949-0","10.1109/ISSPIT.2009.5407527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5407527","Corpus;Diversity;Iranian Music;Mel Frequency Cepstral Coefficients (MFCC);Music Track","Databases;Educational institutions;Indexing;Internet;Mel frequency cepstral coefficient;Mobile handsets;Music information retrieval;Recommender systems;Search engines;System testing","Internet;music","Internet;Iranian music;Web scale systems;digital music files;local musical instruments","","0","","29","","","14-17 Dec. 2009","","IEEE","IEEE Conference Publications"
"The application of association rules algorithm on web search engine","L. Nan; Z. Chun-Guang; C. Lai-Zhong","College of Computer and Software Shenzhen University, China","2009 International Conference for Internet Technology and Secured Transactions, (ICITST)","20100129","2009","","","1","8","Aiming at the prevalently concerned mining problem about constructing concept search in current Web search engine area, especially applying the Vector Space Model VSM to Web search mining based on the association rules, this paper provides a highly efficient mining algorithm EARS. The EARS algorithm implements the association rules pruning based on VSM via constructing association library and computing similarity. The EARS stores the frequent itemsets via multi-dimensional linked lists and utilizes the recurrence relation among the frequent itemsets in order to effectively obtain the association rules. We verify the extended function of retrieving and querying on the Web and the results of these experiments indicate that our method is effective and feasible.","","Electronic:978-1-4244-5648-2; POD:978-1-4244-5647-5","10.1109/ICITST.2009.5402610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402610","","Association rules;Data mining;Ear;Information retrieval;Itemsets;Libraries;Partitioning algorithms;Search engines;Software algorithms;Web search","data mining;query processing;search engines","EARS;VSM;Web search engine;Web search mining;association library;association rules algorithm;multidimensional linked lists;querying;recurrence relation;retrieving function;vector space model","","1","","8","","","9-12 Nov. 2009","","IEEE","IEEE Conference Publications"
"Region-based color transfer from multi-reference with graph-theoretic region correspondence estimation","Wan-Chien Chiou; C. T. Hsu","Department of Computer Science, National Tsing Hua University, Taiwan","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","501","504","This paper proposes an automatic color transfer method based on multi-reference and graph-theoretic region correspondence estimation. When multiple high-quality reference images are available, our goal is to determine a set of best reference colors for transferring the color characteristics of the target image. Given a target image, we first employ content-based image retrieval technique to obtain a small number of relevant images as its multi-reference. Next, we represent each image in region level and determine the best-matched reference region for each target region. We propose to incorporate both region attribute and spatially adjacent relationships between regions into the region mapping criterion. Finally, we conduct color transfer between the best-matched region pairs in a de-correlated color space. Both subjective and objective measures of our experiments demonstrate that the proposed method outperforms the existing methods.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413982","color transfer;content-based image retrieval;multi-reference;region correspondence","Color;Computational complexity;Computer science;Content based retrieval;Decorrelation;Image quality;Image retrieval;Image segmentation;Information retrieval;Rendering (computer graphics)","content-based retrieval;graph theory;image colour analysis;image fusion;image matching;image retrieval","automatic color transfer method;content based image retrieval technique;decorrelated color space;graph theoretic region;high quality reference images;image representation;multireference region","","2","1","10","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Subspace-based rational interpolation of analytic functions from real or imaginary parts of frequency-response data","H. Akçay; S. Turkay","The Department of Electrical and Electronics Engineering, Anadolu University, Eskisehir 26470, Turkey","Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference","20100129","2009","","","3359","3363","In this paper, construction of analytic functions from evaluations of real or imaginary parts on finite subsets of the unit circle is studied. The points in the subsets are not necessarily uniformly spaced as in the most existing works. An algorithm exactly retrieving finite-dimensional systems from noise-free data is presented. This algorithm is based on a recent frequency-domain subspace algorithm to identify discrete-time power spectra from non-uniformly spaced measurements and inherits consistency and robustness properties of the latter with respect to inaccuracies in data.","0191-2216;01912216","Electronic:978-1-4244-3872-3; POD:978-1-4244-3871-6","10.1109/CDC.2009.5400020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5400020","","Digital signal processing;Frequency measurement;Image analysis;Information retrieval;Interpolation;Mathematics;Noise robustness;Power measurement;Signal processing algorithms;Transfer functions","discrete time systems;interpolation;multidimensional systems;robust control","analytic function;consistency property;discrete-time power spectra;finite subset;finite-dimensional system;frequency-response data;noise-free data;robustness property;subspace-based rational interpolation;unit circle","","0","","12","","","15-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Efficient Time-Bound Access Control Scheme for Dynamic Access Hierarchy","Y. Sui; F. Maino; Y. Guo; K. Wang; X. Zou","Dept. of Comput. & Inf. Sci., Purdue Univ. at IUPUI, Indianapolis, IN, USA","2009 Fifth International Conference on Mobile Ad-hoc and Sensor Networks","20100129","2009","","","279","286","Embedding user subscription time into cryptographic key generation and assignment for hierarchical access control has raised tremendous interest among researchers and practitioners in multicast, broadcast, and secure group communication fields. During the subscription period, a user of a higher class can compute the (time-bound) keys of his/her own class and also derive the keys of all its descendant classes in the access hierarchy. However, after the subscription expires, the user cannot compute/derive the keys. Unfortunately, due to the inclusion of time in the keys, existing schemes either suffer from (colluding) attacks or are only applicable to static access hierarchies. In this paper, we propose a new key generation and assignment scheme for this kind of time-bound hierarchy access control. The new scheme is able not only to prevent colluding attacks but also to support dynamics of access hierarchies in a simple and efficient way.","","Electronic:978-1-4244-5469-3; POD:978-1-4244-5468-6","10.1109/MSN.2009.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401527","Dynamicity;Hierarchical Access Control;Tamper-resistant;Time-bound hierarchical key management","Access control;Broadcasting;Computer networks;Computer science;Cryptography;Information retrieval;Intelligent networks;Mobile computing;Sensor systems;Subscriptions","authorisation","cryptographic key generation;dynamic access hierarchy;efficient time bound access control;embedding user subscription;hierarchical access control;prevent colluding attacks;secure group communication fields;static access hierarchies;user compute keys;user derive keys","","1","","24","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Facial marks: Soft biometric for face recognition","A. K. Jain; U. Park","Department of Computer Science and Engineering, Michigan State University, East Lansing, 48824, USA","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","37","40","We propose to utilize micro features, namely facial marks (e.g., freckles, moles, and scars) to improve face recognition and retrieval performance. Facial marks can be used in three ways: i) to supplement the features in an existing face matcher, ii) to enable fast retrieval from a large database using facial mark based queries, and iii) to enable matching or retrieval from a partial or profile face image with marks. We use Active Appearance Model (AAM) to locate and segment primary facial features (e.g., eyes, nose, and mouth). Then, Laplacian-of-Gaussian (LoG) and morphological operators are used to detect facial marks. Experimental results based on FERET (426 images, 213 subjects) and Mugshot (1,225 images, 671 subjects) databases show that the use of facial marks improves the rank-1 identification accuracy of a state-of-the-art face recognition system from 92.96% to 93.90% and from 91.88% to 93.14%, respectively.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413921","Active Appearance Model;face recognition;facial marks;local features;soft biometrics","Active appearance model;Biometrics;Face detection;Face recognition;Facial features;Image databases;Image retrieval;Image segmentation;Information retrieval;Spatial databases","Gaussian processes;biometrics (access control);face recognition;image matching;image retrieval;image segmentation;visual databases","FERET database;Laplacian-of-Gaussian operator;Mugshot database;active appearance model;face matching;face recognition;facial marks;large database;morphological operator;partial face image retrieval;primary facial features segmentation;profile face image;rank-1 identification accuracy;soft biometric","","30","","12","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Validation of differential light emission analysis on FPGA","J. D. Battista; P. Perdu; J. C. Courrege; B. Rouzeyre; L. Torres","THALES ISS, 18 avenue Edouard Belin, 31401 Toulouse, France","2009 3rd International Conference on Signals, Circuits and Systems (SCS)","20100217","2009","","","1","5","Failure analysis tools and methods can be used for security purposes as well as the security attack techniques can be used in failure analysis. In this paper, we describe the last results obtained concerning light emission techniques and their use to set up a side channel methodology. From a cryptanalyst standpoint, the light emission could be a potential source of leakage. When studying a specific cipher algorithm implemented in a device, by analysing this new kind of leakage it is possible to retrieve secret sensitive data. We made our analyses on an FPGA device, which makes the attack harder to perform than on a standard ASIC. Furthermore, the technique was validated on a device in 0.13 Â¿m technology, resulting in a more complex sample preparation from backside. We will show that, the leakage due to the light emitted during normal operation of a CMOS circuit, can be used to set up an attack based on the well-known DPA technique.","","Electronic:978-1-4244-4398-7; POD:978-1-4244-4397-0","10.1109/ICSCS.2009.5412598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412598","DES cipher;DPA;FPGA;Light emission;Side-channel","Application specific integrated circuits;Costs;Failure analysis;Field programmable gate arrays;Information retrieval;MOSFETs;Microcontrollers;Optical microscopy;Security;Signal analysis","CMOS logic circuits;application specific integrated circuits;failure analysis;field programmable gate arrays;logic design;security of data","ASIC;CMOS circuit;DPA technique;FPGA;cipher algorithm;cryptanalyst standpoint;differential light emission analysis;failure analysis tools;security attack;sensitive data retrieval;side channel methodology","","1","","20","","","6-8 Nov. 2009","","IEEE","IEEE Conference Publications"
"Content-based image retrieval: An application to tattoo images","A. K. Jain; J. E. Lee; R. Jin; N. Gregg","Department of Computer Science & Engineering, Michigan Sate University, East Lansing, 48824, USA","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","2745","2748","Tattoo images on human body have been routinely collected and used in law enforcement to assist in suspect and victim identification. However, the current practice of matching tattoos is based on keywords. Assigning keywords to individual tattoo images is both tedious and subjective. We have developed a content-based image retrieval system for a tattoo image database. The system automatically extracts image features based on the Scale Invariant Feature Transform (SIFT). Side information, i.e., body location of tattoos and tattoo classes, is utilized to improve the retrieval time and retrieval accuracy. Geometrical constraints are also introduced in SIFT keypoint matching to reduce false retrievals. Experimental results on 1,000 queries against an operational database of 63,593 tattoo images show a rank-20 accuracy of 94.2%; the average matching time per query is 2.9 sec. on Intel Core 2, 2.66 GHz, 3 GB RAM processor.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414140","Image retrieval;SIFT;geometric constraints;point matching;tattoo images","Application software;Content based retrieval;Humans;Image databases;Image retrieval;Image storage;Information retrieval;Law enforcement;Skin;Spatial databases","content-based retrieval;feature extraction;image matching;image retrieval;transforms;visual databases","content based image retrieval;geometrical constraints;keypoint matching;keywords assignment;law enforcement;scale invariant feature transform;side information;suspect identification;tattoo image database;tattoo images application;tattoos matching;victim identification","","20","","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Windows and facades retrieval using similarity on graph of contours","J. E. Haugeard; S. Philipp-Foliguet; F. Precioso","ETIS, CNRS, ENSEA, Univ Cergy-Pontoise, 6 avenue du Ponceau, BP 44,F 95014 Cergy Pontoise, France","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","269","272","The development of street-level geoviewers become recently a very active and challenging research topic. In this context, the detection, representation and classification of windows can be beneficial for the identification of the respective facade. In this paper, a novel method for windows and facade retrieval is presented. This method, based on a similarity of graph of contours, introduces a new kernel on graph for inexact graph matching. We design a kernel similarity function for structured sets of contours which will take into account the variations of contour orientation inside a structure set, as well as spatial proximity. Then we are able to extract a window as a sub-graph of the graph of all contours of the facade image and to retrieve similar windows from a database of images of facades.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413408","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413408","Attributed relational graph;facade retrieval;inexact graph matching;kernel on graphs;window extraction","Buildings;Cities and towns;Data mining;Image databases;Image retrieval;Image segmentation;Information retrieval;Kernel;Relational databases;Windows","civil engineering computing;graph theory;image retrieval;visual databases;windows (construction)","contour graph;contour orientation;facades retrieval;image database;inexact graph matching;kernel similarity function;spatial proximity;street-level geoviewers;structure set;windows retrieval","","3","","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"VARMAX-based closed-loop subspace model identification","I. Houtzager; J. W. van Wingerden; M. Verhaegen","Delft Center of Systems and Control, Delft University of Technology, 2628 CD The Netherlands","Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference","20100129","2009","","","3370","3375","In this paper a predictor-based subspace model identification method is presented that relaxes the requirement that the past window has to be large for asymptotical consistent estimates. By utilizing a VARMAX model, a finite description of the input-output relation is formulated. An extended least squares recursion is used to estimate the Markov parameters in the VARMAX model set. Using the Markov parameters the state sequence can be estimated and consequently the system matrices can be recovered. The effectiveness of the proposed method in comparison with an existing method is emphasized with a simulation study on a wind turbine model operating in closed loop.","0191-2216;01912216","Electronic:978-1-4244-3872-3; POD:978-1-4244-3871-6","10.1109/CDC.2009.5400695","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5400695","","Adaptive control;Autoregressive processes;Information retrieval;Least squares approximation;MIMO;Parameter estimation;Predictive models;Recursive estimation;State estimation;Wind turbines","Markov processes;closed loop systems;state estimation","Markov parameters;VARMAX model set;VARMAX-based closed loop subspace model identification;asymptotical consistent estimates;input-output relation;least squares recursion;predictor-based subspace model identification;state sequence estimation;system matrices;wind turbine model","","5","","15","","","15-18 Dec. 2009","","IEEE","IEEE Conference Publications"
"Subspace clustering of images using Ant colony Optimisation","T. Piatrik; E. Izquierdo","Queen Mary, University of London, Department of Electronic Engineering, E1 4NS, UK","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","229","232","Content-based image retrieval can be dramatically improved by providing a good initial clustering of visual data. The problem of image clustering is that most current algorithms are not able to identify individual clusters that exist in different feature subspaces. In this paper, we propose a novel approach for subspace clustering based on Ant Colony Optimisation and its learning mechanism. The proposed algorithm breaks the assumption that all of the clusters in a dataset are found in the same set of dimensions by assigning weights to features according to the local correlations of data along each dimension. Experiment results on real image datasets show the need for feature selection in clustering and the benefits of selecting features locally.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5414503","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5414503","Ant Colony Optimisation;Feature selection;Subspace Clustering","Ant colony optimization;Clustering algorithms;Content based retrieval;Data engineering;Image retrieval;Information retrieval;Learning systems;Shape;Unsupervised learning;Visualization","content-based retrieval;image retrieval;learning (artificial intelligence);optimisation;pattern clustering","ant colony optimisation;content-based image retrieval;feature selection;learning mechanism;real image datasets;subspace image clustering;visual data","","1","","9","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Performance Evaluation of Compressed Inverted Index in Lucene","J. Wan; S. Pan","Grid & Service Comput., Lab. Hangzhou Dianzi Univ., Hangzhou, China","2009 International Conference on Research Challenges in Computer Science","20100129","2009","","","178","181","Inverted index is the most popular index structure in search engine. Applying index compression can reduce storage space on inverted index, and improve the search performance. In this paper, we compare three typical index compression schemes in Lucene-the open source information retrieval system. First, index compression schemes are realized in Lucene. Then we present the comparison results of these compression schemes in compression ratio, decompression speed, and scalability. In different algorithms, the impact caused by whether index file is interleaving has remarkable discrepancies in compression ratio and decompression speed, and the scale of data also influences the algorithm's efficiency.","","Electronic:978-1-4244-5410-5; POD:978-0-7695-3927-0; POD:978-1-4244-5409-9","10.1109/ICRCCS.2009.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401268","index compression;inverted index;lucene;performance evaluation;search engine","Computer science;Frequency;Grid computing;Information retrieval;Interleaved codes;Java;Performance analysis;Scalability;Search engines;Vocabulary","indexing;information retrieval systems;public domain software;search engines","Lucene system;index compression;information retrieval system;inverted index;open source system;search engine","","1","","12","","","28-29 Dec. 2009","","IEEE","IEEE Conference Publications"
"Multi-Modal Mining in Web image retrieval","Ruhan He; Wei Zhan","College of Computer Science, Wuhan University of Science and Engineering, 430073, China","2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)","20100205","2009","2","","425","428","The associations between different modalities of Web images could be very useful for Web image retrieval. In this paper, we investigate the multi-modal associations between two basic modalities of Web images, i.e. keyword and visual feature clusters, by data mining technique. The association rule crosses two modalities, in which the antecedent is a single keyword and the consequent is several visual feature clusters. A customized mining process is provided to mine such special multi-modal association rules. The multi-modal association rules are obtained offline based on the existing inverted file and utilized online to automatically integrate the keyword and visual features for Web image retrieval. The experiments are carried out in a prototype system for Web image retrieval, and the results show the effectiveness of the mined multi-modal association rules.","","Electronic:978-1-4244-4607-0; POD:978-1-4244-4606-3","10.1109/PACIIA.2009.5406567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406567","Association Rule;Multi-Modal Mining;Web Image Retrieval","Association rules;Clustering methods;Computational intelligence;Content based retrieval;Data mining;Delay;Feedback;Image retrieval;Information retrieval;Radio frequency","Internet;data mining;image retrieval;pattern clustering","Web image retrieval;customized mining process;data mining technique;multimodal association rule mining;visual feature clusters","","0","","15","","","28-29 Nov. 2009","","IEEE","IEEE Conference Publications"
"Extraction of numerical strings in Farsi/Arabic documents using structural features","Ali Abedi; Karim Faez; Saeed Mozaffari","Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran","2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)","20100205","2009","1","","245","248","In this paper, we present an approach to separate digits and non-digits for numerical string extraction in Farsi/Arabic handwritten or machine-printed document images. Each connected component is labeled as it belongs to a numerical string or not. For this purpose we introduce a set of features which firstly based on the maximum difference between digits and non-digits in Farsi. Secondly their complexity and extraction time are much less than those features used for connected components recognition. For feature classification, a fuzzy rule-based classifier is utilized. Experimental results show an acceptable detection rate with low false positive rate.","","Electronic:978-1-4244-4607-0; POD:978-1-4244-4606-3","10.1109/PACIIA.2009.5406445","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406445","Farsi/Arabic document analysis;Fuzzy classifier;Numerical string extraction;Structural features","Character recognition;Computational intelligence;Computer industry;Costs;Feature extraction;Image converters;Image retrieval;Information retrieval;Optical character recognition software;Text analysis","document image processing;knowledge based systems","Farsi-Arabic documents;fuzzy rule based classifier;handwritten document image;machine-printed document image;numerical string extraction;structural features","","0","","11","","","28-29 Nov. 2009","","IEEE","IEEE Conference Publications"
"Research on XML-based component library and its application","Linlin Qiu; Yan Peng; Wei Zhang","College of Information Engineering, Capital Normal University, Beijing, China","2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)","20100205","2009","1","","166","169","Component-based software development approach is the main approach to develop new applications at present. How to improve the retrieval efficiency in component libraries becomes an important issue. In this paper, a component library based on XML (extensible markup language) is constructed, in which faceted-based classification mechanism is used to classify components and XML is used to describe components. Furthermore, this component library is designed for components of e-government information platform. The most important parts of this paper are the third and fourth sections, in the third section, we describe the system architecture firstly, and then we present the method which we used to classify and describe components. In the fourth section, we present the method and algorithm that is used to implement component retrieval. Theories and method about tree matching is used to retrieval component, in order to reduce the matching complexity, we build index for XML document which makes the tree matching issues turn to string matching problem. In addition, we adopt a matching algorithm which will compare term strings and level strings at first, and then a component collection that is ordered by the matching degree is returned. All of these are aimed at reduce the time that retrieval takes and improve the recall and precision of retrieval. The experimental results show that the method we adopted in this research is feasible.","","Electronic:978-1-4244-4607-0; POD:978-1-4244-4606-3","10.1109/PACIIA.2009.5406468","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406468","XML;XML index;component library;component retrieval;tree matching","Application software;Computational intelligence;Costs;Electronic government;Electronic mail;Industrial relations;Information retrieval;Scalability;Software libraries;XML","XML;information retrieval;software architecture","XML-based component library;component retrieval;component-based software development approach;e-government information platform;extensible markup language;faceted-based classification mechanism","","1","","8","","","28-29 Nov. 2009","","IEEE","IEEE Conference Publications"
"Intelligent information mining from veterinary clinical records and open source repository","P. Tangtulyangkul; T. S. Hocking; C. C. Fung","School of Information Technology, Murdoch University, Perth, Australia","TENCON 2009 - 2009 IEEE Region 10 Conference","20100122","2009","","","1","6","This paper reports an implementation of an intelligent mining approach from veterinary clinical records and an external source of information. The system retrieves information from a local veterinary clinical database and then complements this information with related records from an external source, OAIster. It utilizes text-mining, Web service technologies and domain knowledge, in order to extract keywords, to retrieve related records from an external source, and to filter the extracted keywords list. This study meets a practical challenge encountered at the School of Veterinary and Biomedical Sciences at Murdoch University. The results indicate that the system can be used to increase the limited knowledge within a local source by complementing it with related records from an external source. Moreover, the system also reduces information overload by only retrieving a set of related information from an external source. Finally, domain knowledge can be used to filter the extracted keywords, in this case, selected medical keywords from the extracted keyword list.","2159-3442;21593442","Electronic:978-1-4244-4547-9; POD:978-1-4244-4546-2","10.1109/TENCON.2009.5396065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5396065","clinical database;information filtering;keyword extraction;query;text-mining;veterinary records;web services","Animals;Data mining;Databases;Hospitals;Information filtering;Information filters;Information retrieval;Information technology;Intelligent systems;Web services","Web services;data mining;information retrieval;medical information systems;veterinary medicine","Web service;clinical database;domain knowledge;intelligent information mining;keyword extraction;open source repository;text-mining;veterinary clinical record","","0","","21","","","23-26 Jan. 2009","","IEEE","IEEE Conference Publications"
"Fusion Coding of Correlated Sources for Storage and Selective Retrieval","S. Ramaswamy; J. Nayak; K. Rose","Dept. of Electrical and Computer Engineering, University of California, Santa Barbara","IEEE Transactions on Signal Processing","20100208","2010","58","3","1722","1731","We focus on a new, potentially important application of source coding directed toward storage and retrieval, termed fusion coding of correlated sources. The task at hand is to efficiently store multiple correlated sources in a database so that, at any point of time in the future, data from a <i>selective subset</i> of sources specified by user can be efficiently retrieved. Only statistical information about future <i>queries</i> is available in advance. A typical application scenario would be in storage of correlated data generated by dense sensor networks, where information from specific regions is requested in the future. We propose a <i>fusion coder</i> (FC) for lossy storage and retrieval, wherein different queries are handled by allowing for selective (compressed) bit retrieval. We derive the properties of an optimal FC and present an iterative algorithm for its design. Since iterative design is initialization-dependent, we present initialization heuristics that help avoid poor local optima. An analysis of design complexity reveals complexity growth with query-set size. We first tackle this problem by exploiting optimality properties of FCs. We also consider quantization of the query-space with decision trees in order to adapt to new queries, unseen during FC design. Experiments conducted on real and synthetic data-sets demonstrate that the proposed FC is able to achieve significantly better tradeoffs than joint compression by vector quantization (VQ), with retrieval speedups reaching 3 ¿¿ and distortion gains of up to 3.5 dB possible.","1053-587X;1053587X","","10.1109/TSP.2009.2037664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342498","Database query processing;multisensor systems;source coding;vector quantization (VQ)","Algorithm design and analysis;Cameras;Databases;Decision trees;Fusion power generation;Information retrieval;Iterative algorithms;Layout;Source coding;Vector quantization","computational complexity;database management systems;encoding;query processing;sensor fusion","complexity growth;compressed bit retrieval;decision trees;dense sensor networks;design complexity;fusion coder;fusion coding;initialization heuristics;iterative algorithm;iterative design;lossy retrieval;lossy storage;multiple correlated sources;optimality properties;query-set size;selective retrieval;source coding;statistical information","","1","","16","","20091201","March 2010","","IEEE","IEEE Journals & Magazines"
"Integrating local feature and global statistics for texture analysis","Y. Xu; SiBin Huang; H. Ji","School of Computer Science & Engineering, South China University of Technology, Guangzhou, 510006, China","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1377","1380","A main challenge for texture analysis is to construct a compact texture descriptor which is not only highly discriminative to intra-class textures, but also robust to inter-class variations, geometric and photometric changes. In this paper, a new texture descriptor is developed by integrating the local affine-invariant texture features and the global viewpoint-invariant statistics. Based on the pixel clustering using two state-of-art robust local texture descriptors (i.e. SIFT and SPIN), the proposed texture descriptor enables impressive invariance to a wide range of environmental changes (e.g. view changes, illumination changes, surface distortions) by characterizing the spatial distribution of pixel sets using multi-fractal analysis. Experiments on some real datasets (publicly available) showed that the proposed texture descriptor achieved better performance than some state-of-art techniques in texture retrieval and texture classification while the computation cost is significantly reduced.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413361","Image texture analysis;feature extraction;image classification;image recognition;pattern recognition","Fractals;Histograms;Image texture analysis;Information retrieval;Lighting;Pixel;Robustness;Shape;Statistical analysis;Surface texture","affine transforms;feature extraction;fractals;image classification;image texture;statistical analysis","compact texture descriptor;geometric change;global viewpoint-invariant statistics;local affine-invariant texture features;multifractal analysis;photometric change;pixel clustering;texture analysis;texture classification;texture retrieval","","1","","8","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Saliency detection for content-aware image resizing","R. Achanta; S. Süsstrunk","School of Computer and Communication Sciences (IC), Ecole Polytechnique F&#233;d&#233;rale de Lausanne (EPFL), Switzerland","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1005","1008","Content aware image re-targeting methods aim to arbitrarily change image aspect ratios while preserving visually prominent features. To determine visual importance of pixels, existing re-targeting schemes mostly rely on grayscale intensity gradient maps. These maps show higher energy only at edges of objects, are sensitive to noise, and may result in deforming salient objects. In this paper, we present a computationally efficient, noise robust re-targeting scheme based on seam carving by using saliency maps that assign higher importance to visually prominent whole regions (and not just edges). This is achieved by computing global saliency of pixels using intensity as well as color features. Our saliency maps easily avoid artifacts that conventional seam carving generates and are more robust in the presence of noise. Also, unlike gradient maps, which may have to be recomputed several times during a seam carving based re-targeting operation, our saliency maps are computed only once independent of the number of seams added or removed.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413815","Content aware image re-targeting;saliency;seam carving","Colored noise;Contracts;Displays;Face detection;Gray-scale;Information retrieval;Noise generators;Noise robustness;Pixel;Videos","gradient methods;image colour analysis","content aware image retargeting methods;deforming salient objects;gradient maps;grayscale intensity gradient maps;image resizing;saliency detection;saliency maps;visually prominent features","","64","7","11","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
