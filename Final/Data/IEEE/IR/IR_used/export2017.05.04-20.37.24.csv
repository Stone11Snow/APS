"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7424034,7424010,7424364,7368090,7414686,7408931,7406307,7405644,7400641,7400046,7395743,7396780,7395713,7395658,7396795,7395119,7355316,7381865,7382300,7379651,7381891,7380313,7382149,7379428,7380594,7377286,7377324,7373889,7372137,7363176,7363188,7364006,7362594,7362337,7362593,7361133,7350013,7359934,7351815,7349895,7349945,7349758,7350541,7102707,7346701,7346650,7340446,7338064,7339147,7336891,7339202,7336923,7338147,7336929,7338523,7339241,7329743,7333094,7335401,7329740,7335353,7331964,7323019,7321530,7152946,7312088,7307457,7302189,7300260,7306771,7254179,7292388,7130638,7288806,7281886,7280376,7277219,7277265,7277303,7275635,7277261,7277284,7277279,7273451,7272605,7263565,7264340,7259395,7248495,7095607,7238500,7237153,7231205,7237171,7230358,7237170,7225389,7226100,7219790,7217959",2017/05/04 20:37:24
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"NLP based intelligent news search engine using information extraction from e-newspapers","M. Kanakaraj; S. S. Kamath","Department of Information Technology, National Institute of Technology Karnataka, Surathkal, Mangalore. India","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","5","Extracting text information from a Web news page is a challenging task as most of the E-News content is provided with support from backend Content Management Systems (CMSs). In this paper, we present a personalized news search engine that focuses on building a repository of news articles by applying efficient extraction of text information from a Web news page from varied e-news portals. The system is based on the concept of Document Object Model(DOM) tree manipulation for extracting text and modifying the Web page structure to exclude irrelevant content like ads and user comments. We also use WordNet, a thesaurus of English language based on psycholinguist studies for matching the extracted content semantically to the title of the Web page. TF-IDF (Term Frequency Inverse Document Frequency) is used for identifying the Web page blocks carrying information relevant to the pages title. In addition to the extraction of information, functionalities to gather related information from different Web news papers and to summarize the gathered information based on user preferences have also been included. We observed that the system was able to achieve good recall and high precision for both generalized and specific queries.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238500","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238500","NLP;Summary generation;Text Extraction;information retrieval;search engine","Data mining;HTML;Noise;Search engines;Semantics;Web pages","Web sites;content management;information retrieval;natural language processing;search engines;text analysis","CMS;DOM tree manipulation;E-News content;English language thesaurus;NLP-based intelligent news search engine;TF-IDF;Web news page;Web news papers;Web page title;WordNet;content management systems;document object model tree manipulation;e-news portals;e-newspapers;generalized queries;information gathering;precision value;psycholinguist studies;recall value;specific queries;term frequency inverse document frequency;text information extraction;user preferences","","0","","12","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Unified inter- and intra-recording duration model for multiple music audio alignment","A. Maezawa; K. Itoyama; K. Yoshii; H. G. Okuno","Yamaha Corporation, Japan","2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","20151130","2015","","","1","5","This paper presents a probabilistic audio-to-audio alignment method that focuses on the relationship among the note durations of different performances of a piece of music. A key issue in probabilistic audio alignment methods is in expressing how interrelated are the durations of notes in the underlying piece of music. Existing studies focus either on the duration of adjacent notes within a recording (intra-recording duration model), or the duration of a given note across different recordings (inter-recording duration model). This paper unifies these approaches through a simple modification to them. Furthermore, the paper extends the unified model, allowing the dynamics of the note duration to change sporadically. Experimental evaluation demonstrated that the proposed models decrease the alignment error.","","Electronic:978-1-4799-7450-4; POD:978-1-4799-7451-1; USB:978-1-4799-7449-8","10.1109/WASPAA.2015.7336929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336929","audio alignment;hierarchical Bayesian model;music information retrieval","Bayes methods;Conferences;Probabilistic logic;Random variables;Signal processing;Switches;Trajectory","audio recording;electronic music","alignment error;intra-recording duration model;note duration;probabilistic audio-to-audio alignment method","","1","","26","","","18-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Prototype of an Augmented Reality Browser for Natural Environment Studies","H. Honda; M. Kasahara; S. Li; K. Takano","Grad. Sch. of Inf. & Comput. Sci., Kanagawa Inst. of Technol., Atsugi, Japan","2015 16th IEEE International Conference on Mobile Data Management","20150914","2015","1","","311","314","Because an augmented reality (AR) user interface (UI) can intuitively display information content to a user, this type of interface has been applied to many systems in various fields. In our previous work, we proposed a mobile learning system with a recommender function for natural environment studies. The construction of a user profile is a major approach for personalizing learning content. However, no method for collecting a user's implicit preferences from his/her browsing behavior on the augmented reality UI has been established. In this study, we present a prototype of an AR browser that allows a user to observe, search, and record in the context of natural environment studies. Through the user's natural environment fieldwork, his/her implicit preferences can be extracted from his/her browsing behavior on the AR browser and leveraged to provide appropriate learning content recommendations. In our demonstration of this concept, we present a prototype of an AR browser for natural environment study that uses smartphone and tablet devices and validates the feasibility of our system.","1551-6245;15516245","Electronic:978-1-4799-9972-9; POD:978-1-4799-9973-6","10.1109/MDM.2015.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7264340","Fieldwork;information retrieval;mobile;personalization;plants and animals","Animals;Browsers;Conferences;Data mining;Information retrieval;Mobile communication;Spatial databases","augmented reality;computer aided instruction;graphical user interfaces;mobile learning;notebook computers;online front-ends;recommender systems;smart phones","AR browser;AR user interface;UI;augmented reality browser;learning content recommendation;mobile learning system;natural environment;smartphone;tablet device","","","","3","","","15-18 June 2015","","IEEE","IEEE Conference Publications"
"A Semi-automatic System to Detect Relevant Learning Content for Each Subject","I. Guitart; J. Moré; J. Duran; J. Conesa; D. Baneres; D. Gañan","Dept. of Comput. Sci., Open Univ. of Catalonia, Barcelona, Spain","2015 International Conference on Intelligent Networking and Collaborative Systems","20151102","2015","","","301","307","Today, the crisis has worsened the panorama for Universities, placing new constraints that require being more sustainable economically. In addition, universities will also have to improve their research and teaching in order to obtain more research funds and attract more students. In this panorama, analytics can be a very useful tool since it allows academics (and university managers) to get a more thorough view of their context, to better understand the environment, and to identify potential improvements. Some analytics have been done under the names of Learning analytics, Academic analytics, Educational Data Mining and etcetera. However, these systems, under our humble opinion, only take into account the small part of data related to the problem, but not contextual data. In order to perform analytics efficiently and reproduce their results easily in other contexts, it is necessary to have as much information as possible about the context. For example, when communication forums are analyzed to see the concepts in which students have more doubts, it is important to analyze also what concepts are taught in the subject. Having access to both sources, more information can be obtained and may help to discover not only the problem (a concept is difficult for students) but also its cause (maybe it is not explained in the materials of the course). The work presented in the paper proposes a novel approach to work in that direction: gathering information from different aspects within subjects. In particular, the paper presents an approach that uses natural language processing techniques to analyze the subject's materials in order to discover which concepts are taught and their importance in the subject. The contribution of the paper is a system that allows obtaining a better understanding of subjects. The results can be used for analyzing the suitability of materials to subjects and to enrich and contextualize other analytical processes.","","Electronic:978-1-4673-7695-2; POD:978-1-4673-7696-9","10.1109/INCoS.2015.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312088","Information retrieval;analytics;eLearning;learning analytics;natural language processing","Context;Data mining;Databases;Education;Measurement;Metadata;Natural language processing","computer aided instruction;further education;natural language processing","academic analytics;educational data mining;learning analytics;learning content detection;natural language processing techniques","","1","","10","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"An Efficient Page Ranking Approach Based on Hybrid Model","L. Rodrigues; S. Jaswal","Comput. Eng., St. Francis Inst. of Technol., Mumbai, India","2015 Second International Conference on Advances in Computing and Communication Engineering","20151026","2015","","","693","696","World is full of information. The World Wide Web serves as major source of getting such information. Due to the changing nature of web plenty of web pages are deleted and added newly. Every time a surfer searches web using the search engine, data should be fresh and relevant. Retrieving efficient, relevant and meaningful information from these large sources of information is very challenging job. Due to the large size of web, corresponding to any query made by a user number of pages are being retrieved so the result should be ordered in the manner that most relevant web pages is on top of the list. In order to get most relevant pages at top and reduce the problem of theme drift we propose a hybrid approach of Enhanced-Ratio Rank and Page level keyword algorithms.","","Electronic:978-1-4799-1734-1; POD:978-1-4799-1735-8","10.1109/ICACCE.2015.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7306771","information retrieval;inlink;keyword;outlink;page level keyword;visit count","Algorithm design and analysis;Databases;Radiation detectors;Search engines;Web mining;Web pages","Internet;query processing;search engines","World Wide Web;enhanced-ratio rank algorithm;information retrieval;page level keyword algorithm;page ranking approach;search engine;user query","","1","","10","","","1-2 May 2015","","IEEE","IEEE Conference Publications"
"Dispersion Based Similarity for Mining Similar Papers in Citation Network","S. Singhal; V. Pudi","Centre for Data Eng., IIIT, Hyderabad, India","2015 IEEE International Conference on Data Mining Workshop (ICDMW)","20160204","2015","","","524","531","Measuring ""similarity"" has been established as afundamental problem and has been widely studied. In thispaper we propose a novel approach for establishing similarityin context of citation network. With the rapidly growing sizeof academic literature, the problem of finding similar researchpapers has become a challenging task. Research papers in acitation network often form communities based on an underlyingconcept. Our research shows that dispersion based similaritymeasure can be used as a strong measure for finding similarpapers based on similar connectivity in those communities andstructural relevance of the citation network. Our results showthat our approach works better than other conventional link-based similarity measures both quantitatively and qualitatively. One of the direct benefits of this research is to support the highlyspecialized information needs of a scholarly researcher workingin a specialized field of research.","","Electronic:978-1-4673-8493-3; POD:978-1-4673-8494-0","10.1109/ICDMW.2015.166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395713","Citation Networks;Graph Mining;Information Retrieval;Link Analysis","Collaboration;Conferences;Context;Couplings;Data mining;Dispersion;Social network services","citation analysis;data mining;network theory (graphs);pattern matching","academic literature;citation network;dispersion based similarity;link-based similarity measures;similar connectivity;similar paper mining","","","","18","","","14-17 Nov. 2015","","IEEE","IEEE Conference Publications"
"Current communication technologies in language processing","J. Mizera-Pietraszko","Institute of Mathematics and Computer Science, Opole University, Opole, Poland","2015 Fourth International Conference on Future Generation Communication Technology (FGCT)","20151026","2015","","","1","6","Even the most cutting-edge communication-mediated technology like satellite navigation for orbit positioning, pedestrian movement recognition systems based on inertial sensors, 5G systems, let alone medical devices for coordination of human organs functionality would not be invented without technologies for language processing as an information source between humans and communication systems. Regardless of the way we communicate that is via emails, website short tweets, video conferencing systems, social networking, blogs, instant messaging through websites or mobile applications, or texting only, we use a language that is processed by computer system. Thus, the keynote paper discusses language processing technologies as the core of any other communication between human beings or human-machine. From the user???s perspective communication technologies simply integrate computer science and linguistics, but that is a very broad scope of knowledge. Technologies of a particular language rely on computational linguistics, natural language processing including also speech processing, information retrieval, knowledge acquisition and machine translation tools.","2377-262X;2377262X","Electronic:978-1-4799-8267-7; POD:978-1-4799-8268-4","10.1109/FGCT.2015.7300260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300260","Computational Linguistics;Computer-Mediated Communication;Information Retrieval;Intelligent Information Systems;Language Processing;Machine Translation","Communication systems;Grammar;Natural language processing;Pragmatics;Semantics;Syntactics","","","","","","23","","","29-31 July 2015","","IEEE","IEEE Conference Publications"
"Sparse Matrix Sparse Vector Multiplication - A Novel Approach","M. Shah","Dept. of Comput. Sci. & Eng., Nirma Univ., India","2015 44th International Conference on Parallel Processing Workshops","20151210","2015","","","67","73","The terabytes of information available on the internet creates a severe demand of scalable information retrieval systems. Sparse Matrix Vector Multiplication (SpMV) is a well-known kernel for such computing applications in science and engineering world. This raises need of designing an efficient SpMV. Researchers are putting their continuous effort to optimize SpMV that deal with wide class of sparse matrix patterns using various compressed storage formats, and algorithm for high performance computing devices like multi-core/many-core processor i.e. GPU. But, they have not focus on optimization of input vector, which is highly sparse for various applications. This paper presents a novel approach - Sparse Matrix Sparse Vector Multiplication (SpMSpV) to utilize sparse input vector efficiently. To demonstrate efficiency of the proposed algorithm, it has been applied to keyword based document search, where sparse matrix is used as index structure of text collection and sparse vector for query keywords. The proposed algorithm is also implemented over Graphical Processing Unit (GPU) to explore high parallelism. Implementation results over CPU and GPU both demonstrate that SpMSpV using Compressed Sparse Column (CSC) sparse format is more efficient for information retrieval applications that use highly sparse input vector.","1530-2016;15302016","Electronic:978-1-4673-7589-4; POD:978-1-4673-7590-0","10.1109/ICPPW.2015.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349895","Information Retrieval;Query Processing;SpMSpV;SpMV;Sparse Matrix;Sparse Vector","Graphics processing units;Indexes;Information retrieval;Optimization;Performance evaluation;Query processing;Sparse matrices","matrix multiplication;query processing;sparse matrices;text analysis;vectors","CSC sparse format;GPU;Internet;SpMSpV;compressed sparse column sparse format;compressed storage formats;computing applications;graphical processing unit;high performance computing devices;information retrieval systems;keyword based document search;multicore-manycore processor;sparse matrix patterns;sparse matrix sparse vector multiplication;sparse vector;text collection","","","","15","","","1-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"Mobile agent for the building of automatic textual reports from web queries","J. G. R. Díaz; N. J. García; M. E. R. Fuentes; J. C. S. Leyva; J. L. S. Martínez; L. A. C. Medrano","Depto. de Sistemas y Computaci&#243;n, I.T. de La Piedad, Av. Tecnol&#243;gico 2000, CP 59310, Mich., Mex","2015 IEEE International Autumn Meeting on Power, Electronics and Computing (ROPEC)","20160201","2015","","","1","6","Traditionally, web searching in order to discover meaningful information is an action that obeys a typical way. A user launches a web query by means of a set of keywords directed toward a web searcher. Thus, it returns a list of web links (URLs) which must be read and then, analyzed by the user for finding out the required information. This way of web searching is normal for devices with broad screens, but for mobile devices with small visual areas is tiresome and cumbersome, especially if we consider the amount of information to be deployed. In this work we present a software agent (a mobile app) for the preparation and deployment of text reports in natural language from a web query. The tool implies the definition of a formal method for the extraction of text fragments from web pages, the development of a library for natural language processing, the design of a software architecture and the development of mobile apps for interfacing with users. Our agent presents small text reports, which ensures more readability and improves searching user experience.","","Electronic:978-1-4673-7121-6; POD:978-1-4673-7122-3","10.1109/ROPEC.2015.7395119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395119","agent;information retrieval;mobile app;report;web searching","Computational modeling;HTML;Internet;Mobile communication;Software;Uniform resource locators;Web search","Internet;data mining;mobile agents;mobile computing;natural language processing;query processing;software architecture;text analysis","URLs;Web links;Web pages;Web queries;Web searching;automatic textual reports;meaningful information discovery;mobile agent;mobile app;natural language processing;software agent;software architecture;text fragment extraction","","","","16","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Personalizing your social computing world: A case study using Twitter","N. Mounota; M. Brayshaw","Department of Computer Science, The University of Hull, Hull, HU6 7RX, UK","2015 Science and Information Conference (SAI)","20150903","2015","","","263","268","Twitter portal has become one of the major sources of social networking. Everyday millions of people send tweets to share their interest and view what other people are showing interests on. People who subscribe to Twitter portal are often overwhelmed not only by the large number of tweets they receive, but also by the fact that a large number of those tweets are irrelevant to their interests. One way to address this is to look to personalize this interaction. In this paper we describe a Smart Tweet Portal (STP) that we have built using an Adaptive Information Retrieval technique to personalize itself to user's interest. This portal filters unwanted tweets and delivers only tweets of user's interests. It employs similar features like that of Twitter (followers, following and number of tweets) as well as some user actions (Retweet, Post, Download and Like). In this way users can create their own highly personal cut on their online social world around them. The portal was evaluated by 12 users. The evaluation showed 91.7% overall user satisfaction for the relevancy of tweets and for displaying tweets of interests, indicating that the described system proved to be useful and user friendly.","","Electronic:978-1-4799-8547-0; POD:978-1-4799-8548-7; USB:978-1-4799-8546-3","10.1109/SAI.2015.7237153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237153","Adaptive Information Retrieval;Smart Tweet Portal;Twitter Portal;context-based;cosine similarity;personalization;social computing","Context;Databases;Filtering;Portals;Testing;Twitter","information filtering;social networking (online)","STP;Twitter;adaptive information retrieval technique;smart tweet portal;social networking;tweet filtering","","0","","19","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Developing a Platform That Supplies Processed Information from Internet Resources and Services","I. Cicekli; N. Suleymanov","Dept. of Comput. Eng., Hacettepe Univ., Ankara, Turkey","2015 Second International Conference on Soft Computing and Machine Intelligence (ISCMI)","20160225","2015","","","116","120","In this paper, a Turkish question answering system that extracts most suitable answers from Internet services and resources is described. During the question-analyzing period of our question answering system, the question class is determined from lexical-morphological properties of the words appearing in the question. In addition, some other properties of the question are predicted and various solution methods are tried in order to get the right answer. Furthermore, to increase the success rate of the system, Wordnet platform is used to find synonym words and other related words of question words. In the information retrieval phase of the system, the system utilizes Tim Berner Lee's semantic web approach, instead of classic search engine approach. Using extracted features of given questions, subject-predicate-object triples are fetched from DBpedia, which extracts structural information from Wikipedia articles. From obtained triples, the final answer is formulated. For searching and getting Turkish equivalent of the information, Wikipedia Search API and Bing Translate API are used.","","Electronic:978-1-4673-9819-0; POD:978-1-4673-9820-6","10.1109/ISCMI.2015.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7414686","Information Retrieval;Natural Language Processing;Question Answering Systems;Semantic Web","Encyclopedias;Knowledge discovery;Search engines;Semantic Web","Web sites;application program interfaces;feature extraction;natural language processing;question answering (information retrieval);search engines;semantic Web","Bing translate API;DBpedia;Internet resource;Internet service;Turkish equivalent;Turkish question answering system;Wikipedia article;Wikipedia search API;Wordnet platform;classic search engine approach;feature extraction;information retrieval phase;lexical-morphological property;processed information;question-analyzing period;semantic Web approach;structural information;subject-predicate-object triple;success rate;synonym word","","","","15","","","23-24 Nov. 2015","","IEEE","IEEE Conference Publications"
"Approaches to Retrieve Verses of the Holy Quran Based on Full Meaning","F. A. O. Najadat; G. G. Kanaan","Adm. Dept., IJASET Sci. Journal, Amman, Jordan","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","310","315","Most information retrieval researchers and specialists in NLP have focused on employing the concepts of the Holy Quran in their field of work as a step towards combining modern technology and the understanding of Quran itself. Retrieving information from the Holy Quran in response to a particular query has been considered to be a very significant field in research and analysis. Many researchers have found special search options to retrieve verses from the Holy Quran such as exact matching of query, query's stem matching, and query's synonyms matching based on certain thesauruses. In this study, the researchers adopt special search options for retrieving verses from the Holy Quran based on single-word queries according to the full meaning of the Quran's verses in addition to the meaning of the search query; in other words, the researchers in this study add the exact matching of search-query as a default search option in order to retrieve the verses that match the search query in a precise form. After that, the researchers also add query's synonyms matching as a search option to give the user the ability to add any synonym that can enhance the retrieval process. The synonyms selection is not based on a thesaurus but it just an additional search option that can aid in enhancing the Information retrieval process. In order to find the Quran verses that are related to the search query without including the word or its synonyms exactly, the researchers add new special search options based on the full meaning of the verses. These new search options are based on special indices for each verse in the Holy Quran about the topic of the verse and the explanation of its full meaning. The researchers select two books of the Holy Quran explanation that gives the full meaning of each verse; ""Tafseer Klmat Al-Quran Tafseer w Bayan"" and ""Tafseer Al- Jalalayn"".","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277265","Indexing;Information Retrieval (IR);Precision;Recall;Stemmers","Indexing;Mathematical model;Search engines;Semantics;Thesauri","humanities;query processing","Holy Quran;NLP;information retrieval;query stem matching;query synonyms matching;verses retrieval","","","","13","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"Phoneme-to-speech dictionary for Indian languages","M. V. Reddy; Margaret Mary T; Hanumanthappa M","Department of Computer Science, Rani Channamma University, Vidyasangam, Belagavi- 591156, India","2015 International Conference on Soft-Computing and Networks Security (ICSNS)","20151008","2015","","","1","4","Phonetics is a multilayered subject of linguistics that focuses on speech. This paper describes how articulatory phonetics is used to generate the phonetic for Kannada using the Unigram statistical approach, to map the elements which are taken from documents. It allows users to enter a source text into either in English or in Natural Language processing with the help of virtual keyboard later it will use bilingual dictionary. the same results are presented for the same.","","Electronic:978-1-4799-1753-2; POD:978-1-4799-1754-9","10.1109/ICSNS.2015.7292388","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7292388","Information Retrieval (IR);Natural Language Processing;Phonetics;Unicode","Acoustics;Dictionaries;Internet;Keyboards;Natural languages;Pragmatics;Speech","computational linguistics;information retrieval;keyboards;natural language processing;speech processing;statistical analysis","English language;Indian language;Kannada language;articulatory phonetics;bilingual dictionary;document handling;element mapping;multilayered linguistics;natural language processing;phoneme-to-speech dictionary;phonetics;source text;unigram statistical approach;virtual keyboard","","","","10","","","25-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"Word detection in recorded speech using textual queries","Ł. Laszko","Cybernetics Faculty, Military University of Technology, ul. Gen. S. Kaliskiego 2, 00-908 Warsaw, Poland","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","849","853","The paper presents unsupervised method for word detection in recorded spoken language signal. The method is based on examining signal similarity of two analyzed media description: registered voice and a word (textual query) synthesized by using Text-to-Speech tools. The descriptions of media were given by a sequence of Mel-Frequency Cepstral Coefficients or Human-Factor Cepstral Coefficients. Dynamic Time Warping algorithm has been applied to provide time alignment of the given media description. The detection involved classification method based on cost function, calculated upon signal similarity and alignment path. Potential false matches were eliminated in the algorithm by comparing costs of the path subsequences to a threshold value. The results of the work could provide incentives to build affordable commercial or non-commercial solutions for specific and multilingual applications.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F341","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321530","Speech processing;audio information retrieval;keyword search;pattern matching;speech analysis","Filter banks;Heuristic algorithms;Hidden Markov models;Mel frequency cepstral coefficient;Speech;Speech recognition","human factors;natural language processing;query processing;signal classification;signal detection;speech synthesis;unsupervised learning","alignment path;classification method;cost function;dynamic time warping algorithm;human-factor cepstral coefficients;media description;mel-frequency cepstral coefficients;recorded spoken language signal;signal similarity;text-to-speech tools;textual query;unsupervised method;word detection","","","","14","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"Multi-space Projection Based Search Engine: Theoretical Model Instantiation and Prototype","A. Hannech; M. Adda; H. Mcheick","Comput. Sci. Dept., Univ. of Quebec At Chicoutimi, Chicoutimi, QC, Canada","2015 26th International Workshop on Database and Expert Systems Applications (DEXA)","20160215","2015","","","281","285","Information Retrieval (IR) is still one of the most important and active research areas in computer science. The most popular applications of IR are Search Engines that help users locate information in the Web. It has to be noted that they have some limitations such as results' relevance and exploration. We propose a Multi-Space Search Engine model that is based on multiple interpretation spaces. To evaluate the effectiveness of the proposed model, we developed a prototype and conducted a comparative study that includes content interpretation, search features and usability. The experiments showed that our prototype performs well when compared to popular search engines with regard to the visibility of interpretations and the navigability of the results.","1529-4188;15294188","Electronic:978-1-4673-7582-5; POD:978-1-4673-7583-2","10.1109/DEXA.2015.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406307","Information retrieval;indexing;search engines;semantic web","Indexing;Java;Prototypes;Search engines;Semantics","content-based retrieval;information retrieval;search engines;semantic Web","IR;World Wide Web;active research areas;computer science;content interpretation;information retrieval;multispace projection based search engines;multispace search engine model;navigability;search features;theoretical model instantiation;usability","","1","","29","","","1-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"A hybrid-architecture retrieval system based on Web Services","Dajie Cong; Ping Shi; Yang Li; Da Pan; Yuan Sha","School of Information Engineering, Communication University of China, Beijing, China","2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20160114","2015","","","2236","2241","In this paper, we design and implement a high quality audio material retrieval system in view of the shortcomings of existing professional audio retrieval platforms. The aim of our system is to provide an integrated audio retrieval solution for audio editing staffs. Firstly, for hybrid architecture, the server of the system described in this paper publishes services by Web Services when realizing B/S logical transaction. And the rich client of C/S calls the advertised services to provide Internet audio retrieval and other functions. Then based on this system architecture, we design the retrieval and the other peripheral modules to achieve overall functions of the system. Finally, some performance tests are done to our system.","","CD-ROM:978-1-4673-7681-5; Electronic:978-1-4673-7682-2; POD:978-1-4673-7683-9","10.1109/FSKD.2015.7382300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382300","Hybrid architecture;Information retrieval;Lucene;Search engines;Web Services","Computer architecture;Indexes;Servers;Simple object access protocol","Web services;information retrieval","B/S logical transaction;Internet audio retrieval;Web services;audio material retrieval system;hybrid architecture;hybrid-architecture retrieval system;integrated audio retrieval;professional audio retrieval platforms","","","","14","","","15-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"A tag-level factor graph model for semantic music discovery","Q. Yan; S. Deng; Q. Tao; L. Dong; Y. Lv","College of Computer and Information, Hohai University, China","2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)","20150903","2015","","","40","44","This paper proposes a semantic music discovery system based on a tag-level factor graph (TFG) model with utilization of tag probability and content similarity in a unified fashion. The content similarities are calculated based on the extracted pitch features while tag probabilities are obtained from our previous auto-tagging system. The TFG model consists of a set of node and edge feature functions, which define the impact of tag probabilities and content similarities on representative degrees of songs. Representative degrees indicate to which extent a song is a representative one given the query tag. The loopy max-product inference algorithm is applied to obtain the values of all representative degrees that maximize the joint probability distribution of the TFG model. Experiment results show the TFG model improves the performance by 5.6% higher in the precision rate at top 3 music and 3.5% higher at both top 5 and 10 music.","","Electronic:978-1-4799-1948-2; POD:978-1-4799-1949-9; USB:978-1-4799-1947-5","10.1109/ChinaSIP.2015.7230358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230358","Content similarity;Factor graph model;Music information retrieval;Tag probability","Computational modeling;Feature extraction;Hidden Markov models;Inference algorithms;Mathematical model;Probabilistic logic;Semantics","content-based retrieval;edge detection;feature extraction;graph theory;inference mechanisms;music;semantic Web;statistical distributions","TFG model;autotagging system;content similarity;edge feature function extraction;joint probability distribution;loopy max-product inference algorithm;node feature function extraction;pitch feature extraction;query tag;semantic music discovery system;song representative degree;tag probability;tag-level factor graph model","","0","","17","","","12-15 July 2015","","IEEE","IEEE Conference Publications"
"On the perceptual relevance of objective source separation measures for singing voice separation","U. Gupta; E. Moore; A. Lerch","School of Electrical and Comp. Eng., Georgia Institute of Technology, Atlanta, GA, USA","2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","20151130","2015","","","1","5","Singing Voice Separation (SVS) is a task which uses audio source separation methods to isolate the vocal component from the background accompaniment for a song mix. This paper discusses the methods of evaluating SVS algorithms, and determines how the current state of the art measures correlate to human perception. A modified ITU-R BS.1543 MUSHRA test is used to get the human perceptual ratings for the outputs of various SVS algorithms, which are correlated with widely used objective measures for source separation quality. The results show that while the objective measures provide a moderate correlation with perceived intelligibility and isolation, they may not adequately assess the overall perceptual quality.","","Electronic:978-1-4799-7450-4; POD:978-1-4799-7451-1; USB:978-1-4799-7449-8","10.1109/WASPAA.2015.7336923","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336923","MUSHRA;Music Information Retrieval;Singing Voice Separation;Source Separation","Correlation;Distortion;Distortion measurement;Instruments;Radio frequency;Signal processing algorithms;Source separation","audio signal processing;information retrieval;music;source separation","1543 MUSHRA test;ITU-R BS;SVS algorithm;audio source separation method;objective source separation;perceptual relevance;singing voice separation","","1","","26","","","18-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Malay document clustering using complete linkage clustering technique with Cosine Coefficient","N. Abd Rahman; Z. Abu Bakar; N. S. S. Zulkefli","Department of Computer Science, Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, Malaysia","2015 IEEE Conference on Open Systems (ICOS)","20160111","2015","","","103","107","Finding useful and relevant information is a very challenging task to the user. The retrieval system usually responded with a long listed documents which are not necessarily relevant to the user's need. Document clustering is a special technique that can sort out the documents effectively so that documents in the same cluster are similar to each other and documents in different cluster are dissimilar to each other. This paper focuses on document clustering for Malay test collection. It consists of 2028 Malay translated Hadith documents from book Sahih Bukhari. This paper presents the results using Complete Linkage Clustering algorithm with Cosine Coefficient on Malay translated Hadith documents. The evaluation of the experiments uses Recall (R), Precision (P) and Effectiveness (E) measure. The experiments is conducted on 100 clusters, 50 clusters and 20 clusters. It shows that the smaller the size of clusters, Recall (R) will increase, but Precision (P) will decrease. Results for Effectiveness (E) measure compared to the non-clustered documents show that applying clustering algorithm will improved the effectiveness of searching process. For this experiment 20 clusters is rather effective compared to the others.","","Electronic:978-1-4673-9434-5; POD:978-1-4673-9435-2; USB:978-1-4673-9433-8","10.1109/ICOS.2015.7377286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377286","Complete Linkage;Cosine Similarity;Document Clustering;Hierarchical Agglomerative Clustering;Malay Information Retrieval","Clustering algorithms;Conferences;Couplings;Indexes;Open systems;Partitioning algorithms;Search engines","document handling;information retrieval;natural language processing;pattern clustering","Malay document clustering;Malay test collection;complete linkage clustering technique;cosine coefficient;information retrieval system;searching process","","","","19","","","24-26 Aug. 2015","","IEEE","IEEE Conference Publications"
"Manipuri morphological generator","H. M. Devi; K. Singh; N. P. Devi","Department of Computer Science, Manipur University, Imphal, India","2015 International Symposium on Advanced Computing and Communication (ISACC)","20160111","2015","","","103","108","The present paper deals with the design and development of a morphological generator for Manipuri language, a Tibeto-Burman language. It is highly agglutinating language. The input of the morphological generator would be the root word which then inflects the word to the morphology of the language and gives the target forms of the word. The Morphological structure of Manipuri Noun is quite complex since it caters to gender, diminutive, numbers, case and number markings etc. Manipuri nouns are broadly classified into 27 categories according to ending characters and phonological factors. Also Manipuri verbs are classified into 15 main categories. The coverage of the system is directly related to the size of the root list.","","DVD:978-1-4673-6706-6; Electronic:978-1-4673-6708-0; POD:978-1-4673-6709-7","10.1109/ISACC.2015.7377324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377324","Information Retrieval;Machine Translation;Morphological Generator;morpho-syntax;morphonemics","Generators;Mood;Proposals","natural languages","Manipuri language;Manipuri morphological generator;Manipuri nouns;Manipuri verbs;Morphological structure;Tibeto-Burman language;agglutinating language;phonological factors;root list","","","","13","","","14-15 Sept. 2015","","IEEE","IEEE Conference Publications"
"The extended longest common substring algorithm for spoken document retrieval","D. Prozorov; A. Yashina","Vyatka State University, Kirov, Russia","2015 9th International Conference on Application of Information and Communication Technologies (AICT)","20151130","2015","","","88","90","The paper considers the spoken document retrieval problem. The proposed method uses a length of the longest common substring (LCS) algorithm for detection of query words. This method based on phoneme recognition of a spoken document. Also this method is compared with a text retrieval methods based on a vector space model. Use of a length of LCS and phoneme recognition improves retrieval effectiveness.","","Electronic:978-1-4673-6856-8; POD:978-1-4673-6857-5","10.1109/ICAICT.2015.7338523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338523","information retrieval;phoneme recognition;spoken document retrieval;the longest common substring","Hidden Markov models;Speech;Speech recognition;Text recognition;Vocabulary;Weight measurement","document handling;query processing;speech processing","LCS;extended longest common substring algorithm;phoneme recognition;query words;retrieval effectiveness;spoken document retrieval;text retrieval methods;vector space model","","","","15","","","14-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Evaluating text features for lyrics-based songwriter prediction","B. Kırmacı; H. Oğul","Department of Computer Engineering, Ba&#x015F;kent University, Ankara, T&#x00FC;rkiye","2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES)","20151123","2015","","","405","409","We offer an automated way of estimating the author of a song using only its lyrics content. To this end, we introduce a complete text classification framework which takes raw lyrics data as input and report estimated songwriter. The performance of the system is evaluated based on its classification and retrieval ability on a large dataset of Turkish songs, which was collected in this study. The results promote the use of such technique as a complementary tool in music information retrieval applications.","","Electronic:978-1-4673-7939-7; POD:978-1-4673-7940-3; USB:978-1-4673-7938-0","10.1109/INES.2015.7329743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7329743","Music information retrieval;authorship attribution;text classification","Accuracy;Computational modeling;Feature extraction;Kernel;Music information retrieval;Support vector machines;Text categorization","information retrieval;music;pattern classification;text analysis","Turkish songs;lyrics-based songwriter prediction;music information retrieval applications;raw lyrics data;retrieval ability;song author estimation;text classification framework;text feature evaluation","","","","37","","","3-5 Sept. 2015","","IEEE","IEEE Conference Publications"
"Recovery Medical Articles Using Semantic Enrichment Method","J. C. d. Araújo; J. M. P. d. Oliveira; L. G. Marques","Fed. Inst. of Goias, Itumbiara, Brazil","2015 11th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","20160208","2015","","","705","711","The low success rate when retrieving information through web searches could be verified virtually in all areas of knowledge, due to the large amount of information available which raises the selection complexity for relevant articles. A query consists in chosen terms to drive the search for related documents. However, if new terms could be added in order to expand the relevance of the search, then there is what is called query semantic enrichment. This paper presents a semantic enrichment model to improve the quality of results for medical articles queries. This model knows the search context by using a repository of articles which is previously subjected to Latent Semantic Analysis and is supported by the National Cancer Institute ontology and the WordNet lexical database. In this way, new terms which are semantically related to the conducted search context, could be proposed to help raising precision when retrieving relevant articles.","","Electronic:978-1-4673-9721-6; POD:978-1-4673-9722-3","10.1109/SITIS.2015.131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400641","Information Retrieval;Latent Semantic Analysis;Medical Articles;Ontology;Semantic Enrichment","Biomedical imaging;Context;Databases;Ontologies;Search problems;Semantics","medical information systems;query processing","National Cancer Institute ontology;WordNet lexical database;article retrieval;latent semantic analysis;medical article recovery;medical articles queries;query semantic enrichment;semantic enrichment model","","","","27","","","23-27 Nov. 2015","","IEEE","IEEE Conference Publications"
"Examining influences of publication dates on citation recommendation systems","Zequn Gao","Department of Machine Intelligence, Peking University, Key Laboratory on Machine Perception, Ministry of Education, Beijing 100871, China","2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20160114","2015","","","1400","1405","Citation recommendation is a research problem that is both interesting and challenging. Recent years, various methods [2] [4] [12] have been put forward. But these methods omit some features, which are also usable.","","CD-ROM:978-1-4673-7681-5; Electronic:978-1-4673-7682-2; POD:978-1-4673-7683-9","10.1109/FSKD.2015.7382149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382149","Digital library;Information retrieval;Recommender Systems;component","Collaboration;Curve fitting;Feature extraction;Filtering;Fitting;Singular value decomposition;Time-frequency analysis","citation analysis;curve fitting;digital libraries;electronic publishing;recommender systems","AAN;Microsoft Academic;citation publication year;curve fitting method;digital library;time-difference-dependent citation recommendation system","","","","26","","","15-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"Rankboost-Based Result Merging","B. Ghansah; S. Wu; N. Ghansah","Sch. of Comput. Sci. & Telecommun. Eng., Jiangsu Univ., Zhenjiang, China","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","907","914","The explosion of searchable text content especially on the web has rendered information to be distributed among many disjoint text information sources (Federated Search). How to merge the results returned by selected sources is a major problem of the Federated Search task. We study the problem of learning to rank a set of objects by combining various sources of ranking. The problem of merging search results arises in several domains, for example combining the results of different verticals and also Meta search applications. This paper presents a supervised learning solution to the result merging problem. Our approach combines multiple sources of evidence to inform the merging decision. We use the Rankboost Method, a boosting approach to machine learning which learns a function that merges results based on information that is readily available: i.e. the ranks, titles, summaries, URLs and click-through data, which are found in the results pages. We combine these evidences by treating result merging as a multiclass machine learning problem. By not downloading additional information such as the full document, we decrease processing cost in terms of bandwidth usage and latency. We compare our results against existing result merging methods which rely on evidence found only in ranked lists, Semi-Supervised Learning (SSL), Sample-Agglomerate Fitting Estimate (SAFE) and CORI. An extensive set of experiments demonstrates that our method is more effective than the baseline result-merging algorithm under a variety of conditions.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363176","Distributed Information retrieval;Information Retrieval;Machine learning;Result merging;rankboost","Classification algorithms;Feature extraction;Merging;Metasearch;Training;Training data","information retrieval;learning (artificial intelligence);merging;search engines;text analysis","Federated Search task;Rankboost-based search result merging;URL;bandwidth usage;click-through data;disjoint text information sources;latency;merging decision;meta search application;multiclass machine learning problem;object rank learning;ranking sources;ranks;searchable text content;summaries;supervised learning;titles","","","","39","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Tracking File's Metadata from Computer Memory Analysis","K. A. Z. Ariffin; A. K. Mahmood; J. Jaafar; S. Shamsuddin","Digital Forensics Dept., CyberSecurity Malaysia, Seri Kembangan, Malaysia","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","975","980","With the advance in technology, the computer storage will become cheaper for the larger sizes. Previously, it allows the user to store more data at a lower cost. In context of digital forensic investigation, the traditional approach such as analysis on the hard disk will become inefficient in handling the huge data that is stored within it. The research on retrieving the open files from computer memory only focused on tracking the Virtual Address Descriptor (VAD) and Object Table. Thus, only the active object's open files can be retrieved from the computer memory. The aim of this paper is to present algorithms to track the metadata of file from the well-known file system for Windows system such as File Allocation Table (FAT) and New Technologies File System (NTFS). The algorithms encompass the signature search to retrieve the boot sector and then capture the metadata about the file from the computer memory. The algorithm will be independent of address translation algorithm and able to capture the information from various file's extension, not limited to .EXE and .DLL.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363188","Algorithms;Digital Forensics;File Systems;Information Retrieval;Memory Analysis","Algorithm design and analysis;Clustering algorithms;Computers;Digital forensics;File systems;Hard disks;Indexes","digital forensics;file organisation;information retrieval;meta data","FAT;NTFS;New Technologies File System;VAD;Windows system;active object open file retrieval;address translation algorithm;boot sector retrieval;computer memory analysis;computer storage;data storage;digital forensic;file allocation table;file extension;file metadata tracking;information capture;object table;open file retrieval;signature search;virtual address descriptor","","","","28","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Deep Learning and Music Adversaries","C. Kereliuk; B. L. Sturm; J. Larsen","DTU Compute, The Technical University of Denmark, Frederiksberg, Denmark","IEEE Transactions on Multimedia","20151026","2015","17","11","2059","2071","An adversary is an agent designed to make a classification system perform in some particular way, e.g., increase the probability of a false negative. Recent work builds adversaries for deep learning systems applied to image object recognition, exploiting the parameters of the system to find the minimal perturbation of the input image such that the system misclassifies it with high confidence. We adapt this approach to construct and deploy an adversary of deep learning systems applied to music content analysis. In our case, however, the system inputs are magnitude spectral frames, which require special care in order to produce valid input audio signals from network- derived perturbations . For two different train-test partitionings of two benchmark datasets, and two different architectures , we find that this adversary is very effective. We find that convolutional architectures are more robust compared to systems based on a majority vote over individually classified audio frames. Furthermore , we experiment with a new system that integrates an adversary into the training loop, but do not find that this improves the resilience of the system to new adversaries.","1520-9210;15209210","","10.1109/TMM.2015.2478068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254179","AEA-MIR content-based processing and music information retrieval;deep learning","Benchmark testing;Computer architecture;Machine learning;Neural networks;Rhythm;Training","audio signal processing;content management;convolution;image classification;information retrieval;learning (artificial intelligence);music;object recognition","audio frame classification;audio signal;classification system;convolutional architecture;deep learning system;image object recognition;magnitude spectral frame;music adversary;music content analysis;network derived perturbation;training loop","","3","","65","","20150910","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"An ontology-based retrieval system for mammographic reports","A. Comelli; L. Agnello; S. Vitabile","Dipartimento di Biopatologia e Biotecnologie Mediche, Universit&#224; degli Studi di Palermo, Italy","2015 IEEE Symposium on Computers and Communication (ISCC)","20160215","2015","","","1001","1006","In healthcare domain it can be useful to compare unstructured free-text clinical reports in order to enable the search for similar and/or relevant clinical cases. In data mining and text analysis tasks, the cosine similarity is usually used for texts comparison purposes. It is usually performed by computing the standard document vector cosine similarity between the two vectors representing the report pair under analysis. In this paper a novel system based on text pre-processing techniques and a modelled medical knowledge, using an improved radiological ontology, is proposed. Medical terms organized in a hierarchical tree can assess semantic similarity relationships between unstructured report concepts. The proposed retrieval system has been tested on a dataset composed of 126 unstructured mammographic reports written in Italian language, randomly extracted from the available reports in the Radiological Information System of the University of Palermo Policlinico Hospital. The ontology is composed of 731 concepts and it has been developed and enhanced with the collaboration of breast imaging expert radiologists. The proposed system computes the cosine similarity exploiting semantic vectors, adding the ""is-a"" and ""equivalent-to"" relationships to the enhanced ontology. It shows great improvements if compared against a classical syntactic method, giving a Sensitivity rise of+45,27%.","","Electronic:978-1-4673-7194-0; POD:978-1-4673-7195-7","10.1109/ISCC.2015.7405644","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405644","Information Retrieval;Mammography Reports;Ontology","Biomedical imaging;Breast;Data mining;Medical services;Ontologies;Semantics;Standards","data mining;health care;hospitals;information retrieval;mammography;natural language processing;ontologies (artificial intelligence);text analysis;trees (mathematics)","Italian language;University of Palermo Policlinico Hospital;classical syntactic method;data mining;equivalent-to relationship;healthcare domain;hierarchical tree;is-a relationship;mammographic reports;medical terms;modelled medical knowledge;ontology-based retrieval system;radiological information system;radiological ontology;report pair;semantic similarity relationships;semantic vectors;standard document vector cosine similarity;text analysis task;text preprocessing technique;unstructured free-text clinical reports","","1","","22","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"Personalized multimedia content retrieval through relevance feedback techniques for enhanced user experience","V. Pouli; S. Kafetzoglou; E. E. Tsiropoulou; A. Dimitriou; S. Papavassiliou","Network Manage. & Optimal Design Lab. (NETMODE) Institute of Communication and Computer Systems (ICCS) National Technical University of Athens (NTUA) Athens, Greece","2015 13th International Conference on Telecommunications (ConTEL)","20150903","2015","","","1","8","Emerging multimedia interactive services inherently call for user-centered design approaches, where the involved high degree of interactivity requires the implementation of efficient and effective information retrieval approaches. In this paper, a multimodal content retrieval framework is introduced that employs personalization along with relevance feedback techniques in order to enhance provided QoE, by retrieving and offering multimedia content tailored to individual users' characteristics and/or preferences. The developed Relevance Feedback mechanism engages the user into assessing the relevance of the initially retrieved results list of the original query, and through one or more iterations to present him with the most relevant result list based on his feedback. Our proposed framework implements a similarity learning scheme to improve multimedia content retrieval, towards increasing user experience. A model for implicit relevance feedback is formulated and a confidence level parameter is introduced to classify the results, based on the Jaccard similarities of the results that did not receive explicit feedback with those that did. This relevance feedback mechanism acts complementary to the personalized search by reranking the initial retrieved set in iterative rounds. The performance and effectiveness of the proposed framework was evaluated and demonstrated through an extensive experimental study, utilizing an interactive multimodal multimedia web-based system, with media files consisting of a set of 3D movies containing audio-visual content with high and low level semantic annotations.","","Electronic:978-1-4799-8972-0; POD:978-1-4799-8973-7","10.1109/ConTEL.2015.7231205","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7231205","information retrieval;multimedia content;personalization;quality of experience;relevance feedback","Media;Motion pictures;Multimedia communication;Quality of service;Semantics;Streaming media;XML","Internet;interactive systems;learning (artificial intelligence);multimedia computing;quality of experience;relevance feedback;user centred design","3D movies;Jaccard similarities;QoE;interactive multimodal multimedia Web-based system;multimedia interactive services;multimodal content retrieval framework;personalized multimedia content retrieval;relevance feedback techniques;similarity learning scheme;user-centered design approaches","","0","","19","","","13-15 July 2015","","IEEE","IEEE Conference Publications"
"Extracting semantic relations between vietnamese legislative documents","H. N. T. Tuyet; T. Hanh; T. H. Cong","Faculty of Information Technology, Posts and Telecommunications Institute of Technology, Ho Chi Minh city, Vietnam","2015 2nd National Foundation for Science and Technology Development Conference on Information and Computer Science (NICS)","20151026","2015","","","191","196","The semantic relations between entities in documents play vital roles in many applications such as information extraction, and information retrieval. The problem of extracting the semantic relations in Vietnamese documents is more difficult because Vietnamese textual analysis tools are in progress. In this paper, we propose an approach based on syntactic dependency feature between provisions in each sentence and the Support Vector Machine classifier to extract the semantic relations between entities in Vietnamese documents. Our results show that syntactic dependency method is more stable and accuracy (F-measure) than the regular expression method especially for long and complex texts of Vietnamese legislative documents.","","CD-ROM:978-1-4673-6638-0; Electronic:978-1-4673-6640-3; POD:978-1-4673-6641-0","10.1109/NICS.2015.7302189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7302189","Dependency Parsing;Information Extraction;Information retrieval;Support Vector Machines","Feature extraction;Information retrieval;Kernel;Pattern matching;Semantics;Support vector machines;Syntactics","information retrieval;natural language processing;pattern classification;support vector machines;text analysis","Vietnamese legislative documents;Vietnamese textual analysis tools;information extraction;information retrieval;semantic relation extraction;support vector machine classifier;syntactic dependency feature","","","","22","","","16-18 Sept. 2015","","IEEE","IEEE Conference Publications"
"A survey of query expansion, query suggestion and query refinement techniques","J. Ooi; Xiuqin Ma; Hongwu Qin; S. C. Liew","Faculty of Computer Systems and Software Engineering, Universiti Malaysia Pahang, Malaysia","2015 4th International Conference on Software Engineering and Computer Systems (ICSECS)","20151123","2015","","","112","117","The ineffectiveness of information retrieval systems often caused by the inaccurate use of keywords in a query. In order to solve the ineffectiveness problem in information retrieval systems, many solutions have been proposed over the years. The most common techniques are revolving around query modification techniques such as query expansion, query refinement, etc. Due to the high similarity in these query modification techniques, people are often confused about their differences. However, few existing survey papers compare their differences. Hence, in this paper, we first briefly discuss the basic technique of query expansion, query suggestion and query refinement, and then make a detailed comparison between these three techniques. We finally show the promising future research trend in the field of query modification.","","Electronic:978-1-4673-6722-6; POD:978-1-4673-6723-3; USB:978-1-4673-6721-9","10.1109/ICSECS.2015.7333094","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7333094","information retrieval;query expansion;query modification;query refinement;query suggestion","Computers;Internet;Measurement;Software engineering;Thesauri;Vocabulary","information retrieval systems;query processing","ineffectiveness problem;information retrieval systems;query expansion technique;query modification techniques;query refinement technique;query suggestion technique","","","","33","","","19-21 Aug. 2015","","IEEE","IEEE Conference Publications"
"MR-VSM: Map Reduce based vector Space Model for user profiling-an empirical study on News data","A. Gautam; P. Bedi","Department of Computer Science, University of Delhi, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","355","360","Velocity of data generation has increased over a period of decade which is expected to further increase exponentially with the passage of time. To mine the useful nuggets of information, satisfying a large community of users it is preferred to capture the interest of the user, i.e., to create a user profile, and then filter the content according to his taste. A user may traverse through a large number of documents, requiring a user profiling technique to support the scalability of growing number of documents. This paper proposes a novel technique of user profiling - Map Reduce based Vector Space Model (MR-VSM). MR-VSM is a technique for user profiling where the user interacts with data rich in text and volume. MR-VSM implements traditional VSM to use Map Reduce, a parallel programming paradigm to increase the computational efficiency and support scalability of documents. It works by parallelizing the task of creating a term-document class of VSM by using TF-IDF to create term vector. For experimental study this paper makes use of the News dataset which is rich in text and volume and is collected from the web using RSS feeds. The proposed system creates user profile by taking into consideration the News item read by the user and creating a term vector for each news item read. Resulting user profile is set of Top-n terms. To test the computational efficiency and scalability of MR-VSM for growing number of news items read by user, MR-VSM is made to run on a cluster of Hadoop for 12,000, 24,000 and 48000 news items. VSM is also run for 1,500 news items to show the computational efficiency of the proposed approach. It is observed that for MR-VSM computational time for user profiling and scalability of news item read by the user are improved with the increase in the number of nodes in a Hadoop cluster.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275635","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275635","Hadoop;Information Retrieval;Map Reduce;User Profiling;Vector Space Model","Computational efficiency;Computational modeling;Databases;Feeds;Filtering;Informatics;Scalability","document handling;information resources;information retrieval;parallel programming;pattern clustering","Hadoop cluster;MR-VSM;Mapreduce based vector space model;RSS feeds;TF-IDF;computational efficiency;data generation;documents scalability;information retrieval;news dataset;news item;parallel programming;term vector;term-document class;top-n terms;user profiling","","","","12","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Twitter mining for traffic events detection","C. Gutiérrez; P. Figuerias; P. Oliveira; R. Costa; R. Jardim-Goncalves","Centre of Technology and Systems Faculdade de Ci&#x00EA;ncias e Tecnologia, Universidade Nova de Lisboa, UNINOVA, Lisboa, Portugal","2015 Science and Information Conference (SAI)","20150903","2015","","","371","378","Nowadays with the proliferation of smartphones and tablets on the market, almost everyone has access to mobile devices that offer better processing capabilities and access to new information and services. The Web is undoubtedly the best tool for sharing content, especially through social networks. One of the most useful information that can be extracted is the geographical one. Current navigation systems lack in several ways to satisfy the need to process and reason upon such volumes of data, namely, to accurately provide information about urban traffic in real-time and the possibility to personalize the information used by such systems. This paper describes an approach to integrate and fuse tweet messages from traffic agencies in UK, with the objective of detecting the geographical focus of traffic events. Tweet messages are considered in this work given its uniqueness, the real time nature of tweets which may be used to quickly detect a traffic event and its simplicity; it only cost 140 characters to generate a message (called “tweet”) for any user. The approach presented here is composed by several steps: tweet classification, event type classification, name entity recognition, geolocation and event tracking. Finally, we do an experimental study on a real dataset composed by traffic related tweet messages to access the accuracy of proposed approach. We present some inaccuracies ranging from lack of geographical information, imprecise and ambiguous toponyms, overlaps and repetitions as well as visualization to our data set in UK. We finally give an outlook into potential corrections. The work presented here is still part of on-going work. Results achieved so far do not address the final conclusions but form the basis for the formalization of a domain knowledge along with the services.","","Electronic:978-1-4799-8547-0; POD:978-1-4799-8548-7; USB:978-1-4799-8546-3","10.1109/SAI.2015.7237170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237170","classification;geo-parsing;information retrieval;machine learning;social networks;traffic events","Data mining;Engines;Event detection;Geology;Real-time systems;Twitter","Internet;data mining;geography;mobile computing;pattern classification;social networking (online);traffic engineering computing","Twitter mining;World Wide Web;content sharing;domain knowledge;event tracking;event type classification;geographical focus detection;geographical information;geolocation;mobile devices;name entity recognition;navigation systems;smartphones;social networks;tablets;traffic events detection;tweet classification;urban traffic","","3","","21","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Populating ConceptNet Knowledge Base with Information Acquired from Japanese Wikipedia","M. Krawczyk; R. Rzepka; K. Araki","Hokkaido Univ., Sapporo, Japan","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","2985","2989","This paper presents a method of acquiring IsA assertions (hyponymy relations), AtLocation assertions (informing of location of objects) and Located Near assertions (informing of neigh boring locations) automatically from Japanese Wikipedia XML dump files. To extract IsA assertions, we use the Hyponymy extraction tool v1.0, which analyses definition, category and hierarchy structures of Wikipedia articles. The tool also produces information-rich taxonomy from which, using our original method, we can extract additional information, in this case AtLocation and Located Near type of assertions. Experiments showed that both methods produce positive results: we were able to acquire 5,866,680 IsA assertions with 99.0% reliability, 131,760 AtLocation assertion pairs with 93.0% reliability and 6,217 Located Near assertion pairs with 99.0% reliability. Our method exceeded the baseline system considering both precision and the number of acquired assertions.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379651","Information Retrieval;Knowledge Acquisition;Pattern Recognition","Cities and towns;Electronic publishing;Encyclopedias;Internet;Knowledge based systems;Reliability","Web sites;information retrieval;knowledge acquisition;knowledge based systems","Atlocation assertion;ConceptNet knowledge base;IsA assertion;Japanese Wikipedia XML dump files;LocatedNear assertion;hyponymy extraction tool v1.0;information-rich taxonomy","","","","14","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Search of web service based on association rule","L. Wang; L. Xu; J. Yu; Y. Xue; G. Zhang; X. Luo","School of Computer Engineering and Science, Shanghai University, China","2015 IEEE 14th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","20150914","2015","","","262","266","The rapid growth of web services need efficiently discovering the desired web services for the users. Web service interfaces are defined with WSDL that is described by a bag of terms. Many similarity metrics are proposed to solve this problem, it is hardly to resolve the problem that only few pairs of terms between two services have high semantic distance, the semantic distance of other terms between two services are low. Using traditional keyword search metrics may acquire a wrong result that these two web services are similar. But semantics of the web services is hardly to exploit. In this work we use association rule to find terms that are often appear together and find the most similar terms. We weaken the weight of the most similar term contained in an association rule and enhance the other terms' weight contained in an association rule to solve the situation above. The experiments show that our approach outperforms some searching methods.","","CD-ROM:978-1-4673-7289-3; Electronic:978-1-4673-7290-9; POD:978-1-4673-7291-6","10.1109/ICCI-CC.2015.7259395","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7259395","association rule;information retrieval;similarity","Education;Weapons","Web services;data mining;search problems","WSDL;Web service interfaces;Web services description language;association rule;keyword search metrics;semantic distance;similarity metrics","","1","","11","","","6-8 July 2015","","IEEE","IEEE Conference Publications"
"Experimental analysis and comparison of multilabel problem transformation methods for multimedia domain","Z. Abdallah; A. El Zaart; M. Oueidat","Department of Mathematics and Computer Sciences, Beirut Arab University, Lebanon","2015 International Conference on Applied Research in Computer Science and Engineering (ICAR)","20151130","2015","","","1","8","Multi-label learning is the term used to express a type of supervised learning that requires classification algorithms to learn from a set of examples; each example can belong to one or multiple labels. The learning task consists of breaking the multi-label classification problem into several single label classification problems. This learning process results in the prediction of new class labels for a new example. Nowadays, the research community pays significant attention for Multi-label classification due to its relevance to many important domains including, video and audio, images and other media, text, and bioinformatics. Among the previously mentioned domains, Multimedia has the greatest part of interest in multi-label learning due to the increasing demand to efficiently access large collections of images and videos and developing applications that are used for indexing, searching and browsing multimedia data. In this paper, we present an analysis and experimental comparison of four multi-label learning methods applied to three multimedia benchmark datasets using five evaluation measures. In the experimental study, each method is applied to all datasets; alternatively, each problem transformation method is applied against all 54 classifiers in order to find the classifier that gives the best performance for each dataset and classification method.","","Electronic:978-1-4673-8542-8; POD:978-1-4673-8543-5","10.1109/ARCSE.2015.7338147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338147","Data mining;Multilabel;Multimedia Information retrieval system;Problem transformation","Accuracy;Birds;Classification algorithms;Measurement;Multimedia communication;Training;Transforms","indexing;information retrieval;learning (artificial intelligence);multimedia computing;pattern classification","classification algorithms;evaluation measures;multilabel classification problem;multilabel learning methods;multilabel problem transformation methods;multimedia data browsing;multimedia data indexing;multimedia data searching;multimedia domain;single label classification problems;supervised learning","","","","21","","","8-9 Oct. 2015","","IEEE","IEEE Conference Publications"
"Constrained region selection method based on configuration space for visualization in scientific dataset search","S. Takeuchi; K. Sugiura; Y. Akahoshi; K. Zettsu","National Institute of Information and Communications Technology, Kyoto 619-0289, Japan","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2191","2200","We consider constrained label placement problem considering touch interface such as smartphone or tablet. For scientific dataset search, the search results are shown on the global map based on spatial information. There spatial region are often unevenly distributed and most of them are overlapped each other. To select non-overlapped regions from overlapped regions can be considered as a combinational optimization problem which is known as NP-hard. Also, the applications for touch interface should be designed considering finger pad size. In this paper, we propose rectangular label placement method in configuration space for scientific dataset search with touch interface. The idea of configuration is often used for path planning for robots to avoid obstacles. The proposed method apply the idea of configuration space to find the un-overlapped regions to show the selectable regions for touch interface. Furthermore, the relevance between search query and each datasets are considered, so that the user can select more relevant datasets from original search results. This method can be applied not only for scientific dataset search system but also any other applications which shows their results in global map. The experimental evaluations show that the proposed method achieves superior performance to the compared methods.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364006","configuration space;information retrieval;label placement problem;scientific data;touch interface","Data visualization;Metadata;Path planning;Robots;Search problems;Spatiotemporal phenomena;Standards","haptic interfaces;information retrieval","NP-hard;combinational optimization problem;configuration space;constrained label placement problem;constrained region selection method;global map;nonoverlapped regions;obstacle avoidance;path planning;rectangular label placement method;robots;scientific dataset search;search query;smart phone;spatial information;spatial region;tablet;touch interface;visualization","","","","36","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Cross-Dataset Validation of Feature Sets in Musical Instrument Classification","P. J. Donnelly; J. W. Sheppard","Dept. of Comput. Sci., Montana State Univ., Bozeman, MT, USA","2015 IEEE International Conference on Data Mining Workshop (ICDMW)","20160204","2015","","","94","101","Automatically identifying the musical instruments present in audio recordings is a complex and difficult task. Although the focus has recently shifted to identifying instruments in a polyphonic setting, the task of identifying solo instruments has not been solved. Most empirical studies recognizing musical instruments use only a single dataset in the experiments, despiteevidence that mapproaches do not generalize from one dataset to another dataset. In this work, we present a method for data driven learning of spectral filters for use in feature extraction from audio recordings of solo musical instruments and discuss the extensibility of this approach to polyphonic mixtures of instruments. We examine four datasets of musical instrument sounds that have 13 instruments in common. We demonstrate cross-dataset validation by showing that a feature extraction scheme learned from one dataset can be used successfully for feature extraction and classification on another dataset.","","Electronic:978-1-4673-8493-3; POD:978-1-4673-8494-0","10.1109/ICDMW.2015.213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395658","binary relevance classification;classification;crossdataset validation;feature extraction;instrument recognition;k-nearest neighbor;machine learning;music;music information retrieval;musical note separation;timbre","Feature extraction;Harmonic analysis;Instruments;Source separation;Standards;Time-frequency analysis;Training","audio recording;classification;feature extraction;learning (artificial intelligence);musical instruments;optical filters","audio recordings;cross-dataset validation;data driven learning;feature extraction;feature sets;musical instrument classification;polyphonic setting;spectral filters","","","","34","","","14-17 Nov. 2015","","IEEE","IEEE Conference Publications"
"Polyphonic pitch detection by matching spectral and autocorrelation peaks","S. Kraft; U. Zölzer","Department of Signal Processing and Communications, Helmut-Schmidt-University, Hamburg, Germany","2015 23rd European Signal Processing Conference (EUSIPCO)","20151228","2015","","","1301","1305","This paper describes a polyphonic multi-pitch detector which selects peaks as pitch candidates in both the spectrum and a multi-channel generalised autocorrelation. A final pitch is detected if a peak in the spectrum has a corresponding peak within the same semitone range in at least one of the autocorrelation channels. The autocorrelation is calculated in octave bands and all pre-processing steps like filtering, whitening and non-linear distortion are applied exclusively in the frequency domain for maximum flexibility in the parametrisation and high computational efficiency. An evaluation with common data sets yields good detection accuracies comparable to state of the art algorithms.","","Electronic:978-0-9928-6263-3; POD:978-1-4799-8851-8","10.1109/EUSIPCO.2015.7362594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362594","autocorrelation;music information retrieval;polyphonic pitch detection;spectral processing","Algorithm design and analysis;Correlation;Europe;Harmonic analysis;Indexes;Signal processing algorithms","audio signal processing;correlation methods;filtering theory;music;signal detection","autocorrelation channel;multichannel generalised autocorrelation;nonlinear distortion;octave band;polyphonic multipitch detector;polyphonic pitch detection;signal filtering;signal whitening;spectral-autocorrelation peak matching","","","","12","","","Aug. 31 2015-Sept. 4 2015","","IEEE","IEEE Conference Publications"
"The Impact of Contrastive Corpora for Term Relevance Measures","L. Lopes; P. Fernandes; R. Granada; R. Vieira","Comput. Sci. Dept., PUCRS Univ., Porto Alegre, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","146","151","Estimate the relevance of extracted terms through indices based on contrastive corpora is acknowledged to be efficient. Unfortunately, there is no ground rules to help practitioners and researchers to choose adequate contrastive corpora. In this paper, we present an extensive analysis of different options of contrastive corpora for seven different target corpora. It is our goal to show that the impact of such choice is not as harmful as feared, and such impact tends to be diminished as the number of contrastive corpora increases.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424010","Information retrieval;Natural language processing;Relevance indices;Term extraction;tf-dcf","Europe;Frequency estimation;Indexes;Information retrieval;Ontologies;Rocks","Internet;text analysis","contrastive corpora;extracted term relevance measures","","","","18","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"Integrating romanized Nepali spellchecker with SMS based decision support system for Nepalese farmers","B. Devkota; B. Adhikar; D. Shrestha","Research Management Unit, Institute of Engineering, WRC, Pokhara, Nepal","2015 9th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)","20160208","2015","","","1","6","Now-a-days the role of Information and Communication Technology (ICT) to develop and strengthen the sector of agriculture has become seemingly promising. ICT can help a farmer to get relevant information regarding different agricultural information like crop, diseases, marketing, etc. Also, studies have depicted that mobile phone penetration in Nepal have increased in the recent years. This have opened a new possibility for implementing SMS (Short Message Service) based information dissemination services in order to reduce information asymmetry prominent in the country due to extreme geography. This work proposes an approach based on simple SMS service for disseminating agricultural knowledge to the needy farmers in a cost effective and easily deployable manner. Here, the farmers can get consultancy expert advices by sending simple queries (in romanized Nepali language) as a SMS to a central knowledge base. But, the end users, may not provide correct spelling in their queires. Therefore, we integrated a domain specific (i.e. romanized Nepali) spell checker for improving robustness of the system. The purposed approach is seemingly promising than other advanced mobile applications because the general farmer community use simple handset with basic features only.","","Electronic:978-1-4673-6744-8; POD:978-1-4673-6745-5","10.1109/SKIMA.2015.7400046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400046","Decision Support System;Information Retrieval and search;Nepali Romanized;Spell Check;mobile technology;wireless technology","Agriculture;Dictionaries;Knowledge based systems;Logic gates;Mobile communication;Mobile handsets;Servers","agriculture;decision support systems;electronic messaging;geography;human computer interaction;information dissemination;mobile computing;mobile handsets;natural language processing;query processing","Nepal;Nepalese farmers;SMS based decision support system;SMS based information dissemination services;agricultural knowledge dissemination;agriculture sector;crop;diseases;extreme geography;handset;information asymmetry reduction;information-and-communication technology;marketing;mobile phone penetration;mobile technology;romanized Nepali language;romanized Nepali spellchecker integration;short message service;wireless technology","","","","16","","","15-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"Metadata-oriented language model in translingual retrieval of digital data","J. Mizera-Pietraszko; J. Tancula","Institute of Mathematics and Computer Science, Opole University, Poland","2015 Tenth International Conference on Digital Information Management (ICDIM)","20160114","2015","","","115","119","Translingual retrieval relies on processing a source language to retrieve digital document content in a target language. From the perspective of successful browsing digital catalogues, probability of retrieving the full text document in a language other than the query language is close to zero owning to the fact that it is not only the library collection, but especially a problem of matching the index terms with the query keywords which are assumed to be their translation equivalents. In addition, hardly any digital library system is incorporated with a translation component. As a result, such a matching is rather coincidental. Our approach to the translingual document retrieval problem is to build a metadata language model that based on a digital document computes such a word sequence which ranks the document collection on the basis of the probability of generating a particular query keyword alignment.","","Electronic:978-1-4673-9152-8; POD:978-1-4673-9153-5","10.1109/ICDIM.2015.7381891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381891","Cross-Language Information Retrieval;Language Modelling;Multilingual Digital Libraries","Adaptation models;Bismuth;Computational modeling;Computers;Indexes;Libraries;Metadata","digital libraries;document handling;information retrieval;meta data;probability;query languages","digital catalogues;digital data;digital document content retrieval;digital library system;library collection;metadata-oriented language model;probability;query language;source language;translingual document retrieval","","","","17","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers","C. Verma; M. Hart; S. Bhatkar; A. Parker-Wood; S. Dey","Department of Electrical and Computer EngineeringMobile Systems Design Laboratory, University of California at San Diego, San Diego, CA, USA","IEEE Access","20160301","2016","4","","204","215","Enterprise knowledge workers have been overwhelmed by the growing rate of incoming data in recent years. In this paper, we present a recommendation system with the goal of helping knowledge workers in discovering useful new content. In particular, our system builds personalized user models based on file activities on enterprise network file servers. Our models use novel features that are derived from file metadata and user collaboration. Through extensive evaluation on real-world enterprise data, we demonstrate the effectiveness of our system with high precision and recall values. Unfortunately, our experiments reveal that per-user models are unable to handle heavy workloads. To address this limitation, we propose a novel optimization technique, active feature-based model selection, that predicts the user models that should be applied on each test file. Such a technique can reduce the classification time per file by as much as 23 times without sacrificing accuracy. We also show how this technique can be extended to improve the scalability exponentially at marginal cost of prediction accuracy, e.g., we can gain 169 times faster performance on an average across all shares by sacrificing 4% of F-score.","2169-3536;21693536","","10.1109/ACCESS.2015.2513000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368090","Enterprise;File systems;Information Retrieval;Information retrieval;Machine Learning;enterprise;file systems;machine learning","Computational modeling;Feature extraction;File systems;Information retrieval;Machine learning;Metadata;Predictive models","feature selection;information retrieval;meta data;optimisation;recommender systems","active feature-based model selection;enterprise knowledge workers;file metadata;information retrieval;novel optimization technique;personalized recommendation systems;personalized user models;user collaboration","","","","24","","20151229","2016","","IEEE","IEEE Journals & Magazines"
"Learning and modelling user interests using user feedback : A novel approach","T. Alloui; I. Boussebough; A. Chaoui","MISC Laboratory, Dept of Computer Science and its Applications, Faculty of NTIC, University Constantine 2 Abdelhamid Mehri Constantine, Algeria","2015 Fifth International Conference on Digital Information Processing and Communications (ICDIPC)","20151112","2015","","","136","140","User profiles and interests have become essential for personalizing information search and retrieval. Indeed, traditional Information Retrieval Systems (IRS) don't integrate the user in the search process. Also, users do not always find what they need after a single query. Instead, they often issue multiple queries, incorporating what they learned from the previous results to iterate and refine how they express their information needs. So we rely on this process to learn the user information needs without asking him explicitly. This is achieved by capturing his judgments on the retrieved results. We consider also, in the construction of the user interests, what he is looking for and what the user doesn't want to find in the future results to build interests that best match his information needs.","","CD-ROM:978-1-4673-6831-5; Electronic:978-1-4673-6832-2; POD:978-1-4673-6833-9","10.1109/ICDIPC.2015.7323019","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7323019","information retrieval systems;user feedback;user information needs;user interests","Buildings;Computer science;Conferences;Reliability;Search engines;Web search","feedback;information needs;information retrieval systems;learning (artificial intelligence)","IRS;information needs;information retrieval system;user feedback;user interest learning;user interest modelling","","","","12","","","7-9 Oct. 2015","","IEEE","IEEE Conference Publications"
"Extracting academic social networks among conference participants","T. Arif; M. Asger; Majid Bashir Malik; R. Ali","Deptt. of Info. Technology, BGSB University, Rajouri, J&K, India","2015 Eighth International Conference on Contemporary Computing (IC3)","20151207","2015","","","42","47","Academics establish relations among them in multitude ways, co-authorship being one of them. In fact co-authorship has the advantage of being the best recorded among all forms of academic collaborations. Co-authored publications appear in the form of research articles, conference and workshop proceedings, technical reports, etc. As per DBLP, one of the major digital libraries, around 55 percent of the publications appear in conference and workshop proceedings. This implies that conference and workshops provide a rich environment for academics to portray their co-authorship based academic social networks. In this paper we extract academic social networks among conference participants, study their collaboration patterns, analyze their evolution over time and use social network analysis metrics to quantify them.","","CD-ROM:978-1-4673-7946-5; Electronic:978-1-4673-7948-9; POD:978-1-4673-7949-6","10.1109/IC3.2015.7346650","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346650","co-authorship;conference participants;contemporary computing;disambiguation;information retrieval;social networks","Collaboration;Computer science;Data mining;Information technology;Measurement;Metadata;Social network services","graph theory;information retrieval;network theory (graphs);social networking (online)","SNA;academic collaboration;academic social network extraction;coauthorship;conference participant;information retrieval;social network analysis","","","","27","","","20-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"Audio retrieval based on manifold ranking and relevance feedback","J. Qin; X. Liu; H. Lin","School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, China and College of Information Engineering, Dalian University, Dalian 116622, China","Tsinghua Science and Technology","20151217","2015","20","6","613","619","An audio information retrieval model based on Manifold Ranking (MR) is proposed, and ranking results are improved using a Relevance Feedback (RF) algorithm. Timbre components are employed as the model???s main feature. To compute timbre similarity, extracting the spectrum features for each frame is necessary; the large set of frames is clustered using a Gaussian Mixture Model (GMM) and expectation maximization. The typical spectra frame from GMM is drawn as data points, and MR assigns each data point a relative ranking score, which is treated as a distance instead of as traditional similarity metrics based on pair-wise distance. Furthermore, the MR algorithm can be easily generalized by adding positive and negative examples from the RF algorithm and improves the final result. Experimental results show that the proposed approach effectively improves the ranking capabilities of existing distance functions.","","","10.1109/TST.2015.7350013","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350013","audio information retrieval; manifold ranking; relevance feedback","Clustering algorithms;Feature extraction;Information retrieval;Manifolds;Radio frequency;Semantics","","","","","","","","","December 2015","","TUP","TUP Journals & Magazines"
"A low-latency, real-time-capable singing voice detection method with LSTM recurrent neural networks","B. Lehner; G. Widmer; S. Bock","Department of Computational Perception, Johannes Kepler University of Linz, Austria","2015 23rd European Signal Processing Conference (EUSIPCO)","20151228","2015","","","21","25","Singing voice detection aims at identifying the regions in a music recording where at least one person sings. This is a challenging problem that cannot be solved without analysing the temporal evolution of the signal. Current state-of-the-art methods combine timbral with temporal characteristics, by summarising various feature values over time, e.g. by computing their variance. This leads to more contextual information, but also to increased latency, which is problematic if our goal is on-line, real-time singing voice detection. To overcome this problem and reduce the necessity to include context in the features themselves, we introduce a method that uses Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN). In experiments on several data sets, the resulting singing voice detector outperforms the state-of-the-art baselines in terms of accuracy, while at the same time drastically reducing latency and increasing the time resolution of the detector.","","Electronic:978-0-9928-6263-3; POD:978-1-4799-8851-8","10.1109/EUSIPCO.2015.7362337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362337","music information retrieval;recurrent neural nets;singing voice detection","Context;Europe;Feature extraction;Recurrent neural networks;Reliability;Signal processing;Training","feature extraction;recurrent neural nets;speech recognition","LSTM-RNN;SVD;long short-term memory recurrent neural network;singing voice detection method","","1","","16","","","Aug. 31 2015-Sept. 4 2015","","IEEE","IEEE Conference Publications"
"Unique Links as Weak Ties","Y. Yamada; D. Ikeda; S. Hirokawa","Interdiscipl. Grad. Sch. of Sci. & Eng., Shimane Univ., Matsue, Japan","2015 IIAI 4th International Congress on Advanced Applied Informatics","20160107","2015","","","132","136","It is important to find suitable partners in order to form successful collaborations between companies and university researchers. We consider finding the partners by calculating the similarity of the documents such as scientific papers and patents. We focus on weak (unique) links of researchers as the local similarity of their documents, instead of strong links as the global similarity of the documents. In the present paper, we propose a system that matches partners using documents such as research papers and patents. Given a query, the proposed system outputs a graph of unique research in retrieved documents. Each node in the graph corresponds to a word with a document frequency of two. Two words connected by an edge occur in the same two documents, and neither word appears in other retrieved documents. The edge is labeled with the names of the researchers involved in the documents in which the two words appear. Experiments are conducted using graphs output by the system.","","Electronic:978-1-4799-9958-3; POD:978-1-4799-9959-0","10.1109/IIAI-AAI.2015.266","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373889","co-occurring word;industry-university cooperation;information retrieval;text mining;weak ties","Biomass;Collaboration;Companies;Databases;Informatics;Information retrieval;Patents","graph theory;groupware;information retrieval","company researchers;document frequency;document retrieval;document similarity;graph;successful collaborations;unique links;university researchers;weak ties","","","","11","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"Using changeset descriptions as a data source to assist feature location","M. Chochlov; M. English; J. Buckley","Department of Computer Science and Information Systems, University of Limerick, Limerick, Ireland","2015 IEEE 15th International Working Conference on Source Code Analysis and Manipulation (SCAM)","20151123","2015","","","51","60","Feature location attempts to assist developers in discovering functionality in source code. Many textual feature location techniques utilize information retrieval and rely on comments and identifiers of source code to describe software entities. An interesting alternative would be to employ the changeset descriptions of the code altered in that changeset as a data source to describe such software entities. To investigate this we implement a technique utilizing changeset descriptions and conduct an empirical study to observe this technique's overall performance. Moreover, we study how the granularity (i.e. file or method level of software entities) and changeset range inclusion (i.e. most recent or all historical changesets) affect such an approach. The results of a preliminary study with Rhino and Mylyn. Tasks systems suggest that the approach could lead to a potentially efficient feature location technique. They also suggest that it is advantageous in terms of the effort to configure the technique at method level granularity and that older changesets from older systems may reduce the effectiveness of the technique.","","Electronic:978-1-4673-7529-0; POD:978-1-4673-7530-6","10.1109/SCAM.2015.7335401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335401","Feature location;information retrieval;software repositories","Computer languages;Engines;Indexing;Information retrieval;Libraries;Software maintenance","information retrieval;software maintenance;source code (software)","data source code;information retrieval;software entity;software repository;textual feature location technique","","","","47","","","27-28 Sept. 2015","","IEEE","IEEE Conference Publications"
"A Semantic-Based Health Advising System Exploiting Web-Based Personal Health Record Services","G. W. Kim; K. W. Park; D. H. Lee","Dept. of Comput. Sci. & Eng., Hanyang Univ., Seoul, South Korea","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","3","","654","655","In recent years, the growing of interest in healthcare has promoted the usage of internet and web-based personal health record (PHR) services as a popular approach to self-healthcare management. However, it remains difficult for ordinary people to identify the relevance of health information to them as individuals by using the Web. Also, despite rapid growth in web-based PHR services, the utilization of PHR data in these services is still at a low level. In this paper, we propose a semantic-based health advising system exploiting web-based PHR services.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273451","Health Advising System;Health Information Retrieval;Healthcare;Personal Health Record","Diseases;Medical diagnostic imaging;Metadata;Recommender systems;Reliability;YouTube","Internet;electronic health records;health care","Internet;PHR services;Web-based personal health record services;self-healthcare management;semantic-based health advising system","","","","3","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Flexible document organization: Comparing fuzzy and possibilistic approaches","T. M. Nogueira; S. O. Rezende; H. A. Camargo","Department of Computer Science, Federal University of Bahia- Brazil","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","8","System flexibility means the ability of a system to manage imprecise and/or uncertain information. A lot of commercially available Information Retrieval Systems (IRS) address this issue at the level of query formulation. Another way to make the flexibility of an IRS possible is by means of the flexible organization of documents. Such organization can be carried out using clustering algorithms by which documents can be automatically organized in multiple clusters simultaneously. Fuzzy and possibilistic clustering algorithms are examples of methods by which documents can belong to more than one cluster simultaneously with different membership degrees. The interpretation of these membership degrees can be used to quantify the compatibility of a document with a particular topic. The topics are represented by clusters and the clusters are identified by one or more descriptors extracted by a proposed method. We aim to investigate if the performance of each clustering algorithm can affect the extraction of meaningful overlapping cluster descriptors. Experiments were carried using well-known collections of documents and the predictive power of the descriptors extracted from both fuzzy and possibilistic document clustering was evaluated. The results prove that descriptors extracted after both fuzzy and possibilistic clustering are effective and can improve the flexible organization of documents.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7338064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338064","documents;flexible organization;fuzzy clustering;information retrieval;possibilistic clustering","Clustering algorithms;Feature extraction;Information retrieval;Mathematical model;Organizations;Phase change materials;Prototypes","document handling;fuzzy set theory;pattern clustering;possibility theory;query processing","IRS;Information Retrieval Systems;document compatibility quantification;flexible-document organization;fuzzy approach;fuzzy clustering algorithms;imprecise-uncertain information management;membership degrees;overlapping cluster descriptors;possibilistic approach;possibilistic clustering algorithms;query formulation","","1","","37","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"LS-AMS: An Adaptive Indexing Structure for Realtime Search on Microblogs","F. Zhao; J. Liu; J. Zhou; H. Jin; L. T. Yang","Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technolgoy, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Big Data","20160129","2015","1","4","125","137","Indexing microblogs for realtime search is challenging, because new microblogs are created at tremendous speed, and user query requests keep constantly changing. To guarantee user obtain complete query results, micro-blogging site maintains huge indices which leads to index fragmentation or extra merging overhead during realtime search. This paper proposes an efficient LogStructured index structure with Adaptive Merging Strategy (LS-AMS) for realtime search on microblogs. LS-AMS structure consists of an inverted index buffer and a sequence of dynamically adjustable index packages with exponentially increasing sizes. These index packages manage their inverted indices using adaptive merging strategy, which can reduce the merging overhead to improve query performance and can adjust the index structure based on environmental factors, such as the arrival rate of query requests and new microblogs. Experimental results show that LS-AMS can greatly improve query performance without increasing the update cost and improve the self-adaptability in dynamic environment.","","","10.1109/TBDATA.2015.2506159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7355316","Adaptive merging;Information retrieval;Microblog index;Realtime search;Structure adjustment;adaptive merging;microblog index;realtime search;structure adjustment","Big data;Computer science;Indexing;Merging;Stability criteria;Twitter","Web sites;indexing;merging;query processing","LS-AMS;adaptive indexing structure;dynamically adjustable index packages;inverted index buffer;log-structured index structure with adaptive merging strategy;microblogs;realtime search;user query requests","","","","29","","20151217","Dec. 1 2015","","IEEE","IEEE Journals & Magazines"
"Retrieval of Semantically Similar Healthcare Questions in Healthcare Forums","Y. Wang; S. Mehrabi; M. R. Mojarad; D. Li; H. Liu","Dept. of Health Sci. Res., Mayo Clinic, Rochester, NY, USA","2015 International Conference on Healthcare Informatics","20151210","2015","","","517","518","Healthcare forums are popular platforms for patients to communicate with other patients who have similar conditions. Retrieving similar post to a user's question is valuable as the question might have been already answered in similar threads. ICHI 2015 organized a challenge with a corpus of ninety-five selected questions and a query set of ten questions from various diabetes related online forums. The task in this challenge is that given the corpus, a system should be developed to generate the most three similar questions for each question in the query set. In order to accomplish the challenge, we utilized Elastic search to built and search an index based on tokens, UMLS concepts, and semantic types, and finally combined the ranking results with LDI, a Latent Dirichlet Allocation (LDA) based ranking method. The experimental results showed that a mean average precision of 0.72 was achieved on the manually created gold standard.","","Electronic:978-1-4673-9548-9; POD:978-1-4673-9549-6","10.1109/ICHI.2015.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349758","healthcare forum;information retrieval;question answering","Gold;Indexes;Medical services;Resource management;Semantics;Standards;Unified modeling language","Internet;health care;query processing;question answering (information retrieval);social networking (online);statistical analysis","LDA based ranking method;LDI;UMLS concepts;diabetes;elastic search;latent Dirichlet allocation based ranking method;mean average precision;online healthcare forums;patient-patient communication;query set;semantically similar healthcare question retrieval","","","","7","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Cooperative Coevolution Framework for Parallel Learning to Rank","S. Wang; Y. Wu; B. J. Gao; K. Wang; H. W. Lauw; J. Ma","Department of Computer Science and Information Systems, University of Jyv&#228;skyl&#228;, Mattilanniemi 2, Jyv&#228;skyl&#228;, Finland","IEEE Transactions on Knowledge and Data Engineering","20151104","2015","27","12","3152","3165","We propose CCRank, the first parallel framework for learning to rank based on evolutionary algorithms (EA), aiming to significantly improve learning efficiency while maintaining accuracy. CCRank is based on cooperative coevolution (CC), a divide-and-conquer framework that has demonstrated high promise in function optimization for problems with large search space and complex structures. Moreover, CC naturally allows parallelization of sub-solutions to the decomposed sub-problems, which can substantially boost learning efficiency. With CCRank, we investigate parallel CC in the context of learning to rank. We implement CCRank with three EA-based learning to rank algorithms for demonstration. Extensive experiments on benchmark datasets in comparison with the state-of-the-art algorithms show the performance gains of CCRank in efficiency and accuracy.","1041-4347;10414347","","10.1109/TKDE.2015.2453952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152946","Cooperative Coevolution;Cooperative coevolution;Genetic Programming;Immune Programming;Information Retrieval;Learning to Rank;genetic programming;immune programming;information retrieval;learning to rank","Cooperative systems;Evolutionary computation;Genetic programming;Information retrieval;Machine learning algorithms;Ranking (statistics);Sociology","divide and conquer methods;evolutionary computation;learning (artificial intelligence)","CC;CCRank;EA;benchmark datasets;complex structures;cooperative coevolution framework;divide-and-conquer framework;evolutionary algorithms;function optimization;learning efficiency;parallel learning to rank;search space","","0","","55","","20150708","Dec. 1 2015","","IEEE","IEEE Journals & Magazines"
"Using beat notation for enhancement of chord sheet music document similarity","C. Wongsaroj; N. Prompoon; A. Surarerks","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20151130","2015","","","911","915","Most sheet music websites provide chord sheet music document that has only simple text. The system should provide music information that is easy to understand and allows users to search and view a document in many aspects. However, music recommendation and searching capability based on music similarity of chord sequences in documents are challenging features for the system. In this paper, we present a notation of beat information to specify chord length in chord sheet music and its approach for the similarity calculation in three levels: chord, sequence, and music. This approach focuses on beat information of chord sequences in a song. Then, music similarity value between two songs can be determined by using the aggregation of chord sequence similarity values. This work emphasizes the significance of the beat information in chord sequences that can improve the effectiveness of similarity measure. By the experimental results, our music similarity measure was improved about 32% higher in precision after beat information was included.","2327-0586;23270586","CD-ROM:978-1-4799-8351-3; Electronic:978-1-4799-8353-7; POD:978-1-4799-8354-4","10.1109/ICSESS.2015.7339202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339202","Beat information;Chord sheet music;Data warehousing;Information retrieval;Music similarity","Data mining;Frequency modulation;Harmonic analysis;Information retrieval;Music;Runtime;Warehousing","document handling;information retrieval;music;recommender systems","chord sequence similarity values;chord sheet music document similarity;music beat notation;music recommendation;music similarity measure;sheet music Web sites","","","","16","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"New approach for automatic medical image annotation using the bag-of-words model","R. Bouslimi; J. Akaichi","Department of Computer Science, High Institute of Management, Bouchoucha city, Le Bardo, Tunis","2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20151130","2015","","","1088","1093","In this paper, we present a new approach for semantic automatic annotation of medical images. Indeed, the proposed approach uses the bag of words model to represent the visual content of the medical image combined with text descriptors based on term frequency-inverse document frequency technique and reduced by latent semantic to extract the co-occurrence between text and visual terms. In a first phase, we are interested in indexing texts and extracting all relevant terms using a thesaurus containing medical subject headings and concepts. In a second phase, medical images are indexed while recovering areas of interest which are invariant to change in scale such as light and tilt. To annotate a new medical image, we use the bag of words model to recover the feature vector. Indeed, we use the vector space model to retrieve similar medical images from the training database. The computation of the relevance value of an image according to a query image is based on the cosine function. To evaluate the performance of our proposed approach, we present an experiment carried out on five types of radiological imaging. The results showed that our approach works efficiently, especially with more images taken from the radiology of the skull.","2327-0586;23270586","CD-ROM:978-1-4799-8351-3; Electronic:978-1-4799-8353-7; POD:978-1-4799-8354-4","10.1109/ICSESS.2015.7339241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339241","Automatic medical image annotation;Bag of words;Feature detection;Information retrieval;Latent semantic;Radiology","Classification algorithms;Computational modeling;Databases;Medical diagnostic imaging;Visualization;Vocabulary","document image processing;feature extraction;image retrieval;indexing;medical image processing;radiology","automatic medical image annotation;bag-of-word model;cosine function;frequency-inverse document frequency technique;indexing text;medical image retrieval;query image;radiological imaging;semantic automatic annotation;text descriptor","","","","30","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Lexical Semantic Relatedness for Twitter Analytics","Y. Feng; H. Fani; E. Bagheri; J. Jovanovic","","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","202","209","Existing work in the semantic relatedness literature has already considered various information sources such as WordNet, Wikipedia and Web search engines to identify the semantic relatedness between two words. We will show that existing semantic relatedness measures might not be directly applicable to microblogging content such as tweets due to i) the informality and short length of microblogging content, which can lead to shift in the meaning of words when used in microblog posts, ii) the presence of non-dictionary words that have their semantics defined/evolved by the Twitter community. Therefore, we propose the Twitter Space Semantic Relatedness (TSSR) technique that relies on the latent relation hypothesis to measure semantic relatedness of words on Twitter. We construct a graph representation of terms in tweets and apply a random walk procedure to produce a stationary distribution for each word, which is the basis for relatedness calculation. Our experiments examine TSSR from three different perspectives and show that TSSR is better suited for Twitter analytics compared to the standard semantic relatedness techniques.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372137","Information Retrieval;Microblogging;Random Walk;Semantic Relatedness;Semantic Similarity;Twitter","Context;Electronic publishing;Encyclopedias;Internet;Semantics;Twitter","graph theory;information retrieval;social networking (online);statistical distributions","TSSR technique;Twitter analytics;Twitter community;Twitter space semantic relatedness technique;Web search engine;Wikipedia;WordNet;graph representation;latent relation hypothesis;lexical semantic relatedness;microblog post;microblogging content;nondictionary word;random walk procedure;relatedness calculation;stationary distribution;tweets","","","","22","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"An experimentation line for underlying graphemic properties acquiring knowledge from text data with Self Organizing Maps","G. Bernard; N. Aliane; O. Manad","Laboratoire d'Informatique Avanc&#x00E9;e de Saint-Denis (LIASD), PARIS 8 University, 2 Rue de la Libert&#x00E9;, France","2015 12th International Conference on Informatics in Control, Automation and Robotics (ICINCO)","20151210","2015","01","","659","666","We present an experimentation line that encompasses various stages for research on graphemes distribution and unsupervised classification. We aim to help close the gap between recent research results showing the abilities of unsupervised learning and clustering algorithms to detect underlying properties of phonemes and the present possibilities of Unicode textual representation. Our procedures need to ensure repeatability and guarantee that no information is implicitely present in the preprocessing of data. Our approach is able to categorize potential graphemes correctly, thus showing that not only phonemic properties are indeed present in textual data, but that they can be automatically retrieved from raw-unicode text data and translated into phonemic representations. By the way, we observe that SOM algorithm copes well with very sparse vectors.","","Electronic:978-9-8975-8149-6; POD:978-1-4673-6944-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350541","Computational Linguistics;Neural Networks;Text Information Retrieval;Unsupervised Knowledge Learning","Computers;Constitution;Context;Handwriting recognition;Neurons;Pragmatics;Self-organizing feature maps","information retrieval;pattern classification;pattern clustering;self-organising feature maps;text analysis;unsupervised learning","SOM algorithm;automatic raw-unicode text data retrieval;clustering algorithms;data preprocessing;grapheme distribution;graphemic properties;knowledge acquisition;phonemic properties;phonemic representations;self organizing maps;sparse vectors;unicode textual representation;unsupervised classification;unsupervised learning","","","","21","","","21-23 July 2015","","IEEE","IEEE Conference Publications"
"A parallel cross-language retrieval system for patent documents","X. Shen; H. Huang; L. Li; Y. Huang","Beijing Engineering Research Center of High Volume Language Information Processing & Cloud Computing Application, Beijing Institute of Technology, Beijing, 100081 China","2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20151130","2015","","","672","676","In order to help people obtain useful information from patent documents in different languages. This paper proposes a cross-language retrieval system to search Chinese and English patent documents simultaneously. This system consists of query translation module, document retrieval module and user interaction module. Query translation module is used to translate query based on bilingual dictionaries. Document retrieval module consists of monolingual retrieval system using standard vector space model. In order to retrieve in highly parallel, we use the MapReduce model to calculate the similarity. User interaction module provides users with interactive mechanism used to improve the retrieval accuracy in the system. It contains two parts: the second translation and relevance feedback. The experimental results show that our system has good performance.","2327-0586;23270586","CD-ROM:978-1-4799-8351-3; Electronic:978-1-4799-8353-7; POD:978-1-4799-8354-4","10.1109/ICSESS.2015.7339147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339147","Hadoop;Patent document;cross-language information retrieval;parallel retrieval","Accuracy;Context;Data processing;Dictionaries;Machine learning algorithms;Patents","dictionaries;natural language processing;parallel processing;patents;query processing;relevance feedback","Chinese patent documents;English patent documents;MapReduce model;bilingual dictionaries;document retrieval module;interactive mechanism;monolingual retrieval system;parallel cross-language retrieval system;patent documents;query translation;query translation module;relevance feedback;user interaction module;vector space model","","","","12","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Text Document Preprocessing and Dimension Reduction Techniques for Text Document Clustering","A. I. Kadhim; Y. N. Cheah; N. H. Ahamed","Sch. of Comput. Sci., Univ. Sains Malaysia, Minden, Malaysia","2014 4th International Conference on Artificial Intelligence with Applications in Engineering and Technology","20151210","2014","","","69","73","Text mining defines generally the process of extracting interesting features (non-trivial) and knowledge from unstructured text documents. Text mining is an interdisciplinary field which depends on information retrieval, data mining, machine learning, parameter statistics and computational linguistics. Standard text mining and retrieval information techniques of text document usually rely on similar categories. An alternative method of retrieving information is clustering documents to preprocess text. The preprocessing steps have a huge effect on the success to extract knowledge. This study implements TF-IDF and singular value decomposition (SVD) dimensionality reduction techniques. The proposed system presents an effective preprocessing and dimensionality reduction techniques which help the document clustering by using k-means algorithm. Finally, the experimental results show that the proposed method enhances the performance of English text document clustering. Simulation results on BBC news and BBC sport datasets show the superiority of the proposed algorithm.","","CD-ROM:978-1-4799-7909-7; Electronic:978-1-4799-7910-3; POD:978-1-4799-7911-0","10.1109/ICAIET.2014.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351815","Text mining; retrieval information; clustering; singular value decomposition; dimension reduction; clustering; k-means","Algorithm design and analysis;Clustering algorithms;Data models;Indexing;Singular value decomposition;Text mining","data mining;data reduction;information retrieval;knowledge acquisition;learning (artificial intelligence);natural language processing;pattern clustering;singular value decomposition;text analysis","BBC news datasets;BBC sport datasets;English text document clustering;SVD dimensionality reduction techniques;TF-IDF;computational linguistics;data mining;dimension reduction techniques;feature extraction process;information retrieval;information retrieval techniques;k-means algorithm;machine learning;parameter statistics;singular value decomposition dimensionality reduction techniques;text document preprocessing;text mining;unstructured text document knowledge extraction","","1","","8","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Building Standard Dataset for Quran Tafseer","M. B. Bashir; M. S. A. Latiff; A. M. Salih","Dept. of Comput. Sci., Shendi Univ., Shendi, Sudan","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","287","291","The growing number of scholars and students of the Quran Tafseer and its science has led to the increase of computer-based researches. Additionally, the evaluation of these researches requires computer-based experiments to be performed with a real Quran Tafseer documents. The available Tafseer documents are in text file or image file and are in Arabic language whereas the majority of the computer programming is in English language. Furthermore, the researchers will have difficulty to compare their research with other researchers. Therefore, the requirement for standard Tafseer dataset is very necessary for the current researches. This paper proposed a Tafseer dataset that will be used by researchers in Quran Tafseer and information processing fields. The dataset is organized in XML format to provide simple access and usage from the computer applications. A computer program is developed to create the dataset in XML structure. By applying the XML language computer applications users will be able to access the dataset and manipulate the content in easily.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277261","Holy Quran; Quran Tafseer; information retrieval ; Tafseer dataset;XML dataset.","Computers;Data mining;HTML;Information retrieval;Metadata;XML","XML;document handling;information retrieval","Arabic language;Quran Tafseer documents;XML format","","","","16","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"A hybrid method for Persian Named Entity Recognition","F. Ahmadi; H. Moradi","Department of Information Technology, Urmia University of Technology, Iran","2015 7th Conference on Information and Knowledge Technology (IKT)","20151005","2015","","","1","7","Named Entity Recognition (NER) is an information extraction subtask that attempts to recognize and categorize named entities in unstructured text into predefined categories such as the names of people, organizations, and locations. Recently, machine learning approaches, such as Hidden Markov Model (HMM) as well as hybrid methods, are frequently used to solve Name Entity Recognition. Since the absence of publicly available data sets for NER in Persian, as our knowledge does not exist any machine learning base Persian NER system. Because of HMM innate weaknesses, in this paper, we have used both Hidden Markov Model and rule-based method to recognize named entities in Persian texts. The combination of rule-based method and machine learning method results in a high accurate recognition. The proposed system in is machine learning section uses from HMM and Viterbi algorithms; and in its rule-based section employs a set of lexical resources and pattern bases for the recognition of named entities including the names of people, locations and organizations. During this study, we annotate our own training and testing data sets to use in the related phases. Our hybrid approach performs on Persian language with 89.73% precision, 82.44% recall, and 85.93% F-measure using an annotated test corpus including 32,606 tokens.","","Electronic:978-1-4673-7485-9; POD:978-1-4673-7486-6","10.1109/IKT.2015.7288806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7288806","Hidden Markov Model;Information Retrieval;Languages and Systems;Named Entity Recognition;Natural Language Processing;Text Processing","Decoding;Hidden Markov models;Markov processes;Organizations","hidden Markov models;knowledge based systems;learning (artificial intelligence);natural language processing;text analysis","F-measure;HMM;Persian language;Persian texts;Viterbi algorithms;hidden Markov model;hybrid Persian named entity recognition method;information extraction subtask;lexical resources;machine learning based Persian NER system;precision;publicly available datasets;recall;rule-based method;unstructured text","","","","18","","","26-28 May 2015","","IEEE","IEEE Conference Publications"
"Combining temporal and content aware features for microblog retrieval","A. N. Chy; M. Z. Ullah; M. Aono","Department of Computer Science & Engineering Toyohashi University of Technology Toyohashi, Aichi, Japan","2015 2nd International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA)","20151123","2015","","","1","6","Microblog, especially Twitter, have become an integral part of our daily life for searching latest news and events information. Due to short length characteristics of tweets, only content-relevance based search result cannot satisfy user's information need. Recent research shows that considering temporal aspects in this regard improve the retrieval performance significantly. In this paper, we propose a method to re-rank the search result based on temporal features, account related features, and Twitter specific features along with textual features of tweets. We also applied a two stage query expansion technique to improve the relevancy of tweets. After automatic feature selection by using LASSO and elastic-net regularization; we applied random forest as a feature ranking method to estimate the importance of selected feature. Then, with that importance score, a weighted ranking model combines the features value to estimate the relevance score. We conducted our experiments based on the TREC Microblog 2011 and 2012 queries over the TREC Tweets2011 collection. Experimental result demonstrates the effectiveness of our method over the baseline in terms of precision@30 (P@30), mean average precision (MAP), and reciprocal-precision (R-Prec) metrics.","","Electronic:978-1-4673-8143-7; POD:978-1-4673-8144-4","10.1109/ICAICTA.2015.7335353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335353","Information retrieval;Twitter;feature selection;microblog search;query expansion;re-ranking","Feature extraction;Radio frequency;Standards;Twitter;Uniform resource locators;Vocabulary","feature selection;information needs;learning (artificial intelligence);query processing;relevance feedback;social networking (online)","LASSO;MAP;P@30;R-Prec metrics;TREC Microblog queries;TREC Tweets2011 collection;Twitter;account related features;automatic feature selection;content aware features;content-relevance based search result;elastic-net regularization;event information;feature ranking method;mean average precision;microblog retrieval;news information;precision@30;query expansion technique;random forest;reciprocal-precision metrics;temporal features;tweet characteristics;tweet textual features;twitter specific features;user information need satisfaction;weighted ranking model","","","","22","","","19-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"Measuring product semantic similarity by exploiting a manufacturing process ontology","G. Bruno","Department of Management and Production Engineering, Politecnico di Torino, Italy","2015 International Conference on Industrial Engineering and Systems Management (IESM)","20160114","2015","","","1251","1257","The retrieval of manufacturing knowledge in companies is critical because product and process knowledge was not actually managed but only documented. Particularly, the identification of similarities between new and past products relied almost exclusively on the memory and the experience of people, and thus it is a time-consuming task. In this paper, a method to allow the automatic identification of past similar products is proposed, so that they can be used to speed up the design of manufacturing of the new product. The similarity is computed by using a semantic model in the form of ontology, which constitutes the hierarchical structure of concepts. A new similarity index is defined based on the portion of overlapping subgraph of concepts existing between two products. The different weight of each node is also considered because more descendants the node has, less specific its semantics information content is. The computation of the similarity measurement will allow the discovering of knowledge from stored data, thus supporting the engineers in searching for past products having similar characteristics with the new one. The potentiality of the proposed index is shown in a motivating example.","","Electronic:978-2-9600-5326-5; POD:978-1-4673-8340-0; USB:978-2-9600-5325-8","10.1109/IESM.2015.7380313","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380313","Information retrieval;knowledge modelling;manufacturing systems;ontology;semantic similarity","Casting;Forging;Machining;Manufacturing processes;Ontologies;Semantics;Welding","manufacturing processes","automatic identification;manufacturing knowledge;manufacturing process ontology;overlapping subgraph;process knowledge;product semantic similarity index;semantic model;semantics information content;similarity measurement;time-consuming task","","2","","21","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Personalized E-Advertisement and Experience: Recommending User Targeted Ads","D. A. Al Qudah; A. I. Cristea; S. H. Bazdarevic; S. Al-Saqqa; A. Rodan; W. Yang","Dept. of Comput. Sci., Univ. of Warwick, Coventry, UK","2015 IEEE 12th International Conference on e-Business Engineering","20151210","2015","","","56","61","Personalized e-advertising is the art of attracting users' attention by correlating to their tastes and interests. The evolving research of adaptive hypermedia with its techniques and theories contributed to the personalization field. This paper reports the case study of ""My Ads"", an adaptive e-advertisement delivery system that is based on a new theoretical framework, to evaluate users' acceptance of personalized ads. The results indicated that the implemented features within the system contributed to an enhanced experience through the exposure to different personalization methods and the appealing ideas of the system.","","Electronic:978-1-4673-8002-7; POD:978-1-4673-8003-4","10.1109/ICEBE.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349945","Adaptive hypermedia;e-advertisement;information retrieval;personalization;user modeling","Adaptation models;Adaptive systems;Advertising;Data models;History;Standards","Internet;advertising data processing;hypermedia;information retrieval","My Ads;e-advertisement delivery system;e-advertisement personalization;hypermedia;information retrieval;user targeted ads recommendation","","","","17","","","23-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"Design of local web content observatory system","G. Tsegaye; S. Atnafu","Department of Computer Science, Addis Ababa University, Addis Ababa, Ethiopia","AFRICON 2015","20151119","2015","","","1","5","The amount of information on the web is growing rapidly. However, considering a particular group or country, it is very difficult to know how much relevant web contents are published and which are in what language and on what specific subject. Knowing the status of local web content of a country or a culture is of critical importance for making a decision on policy and strategy design for the development of the multi-lingual and multi-cultural web. This research work is therefore to design a model for a local web content observatory system that measures the qualitative and quantitative content of different domains. The local web content observatory system consists of six components - the crawler, content extractor, statistical tracker, language identifier, Web document categorizer and report generator. Though the model developed is generic and can be applied to any country or culture, to test and evaluate the system, we have selected all domains hosted under the .et domain. Accordingly about two thousand seed URLs under the .et domain are used and the crawler collected around 263,031 web documents. The accuracy rate measures employed to the language identifier obtained a rate of 98.67%. To demonstrate the effectiveness of the local web content categorizer precision, recall and F-measures test were conducted and an average precision of 91.7%, a recall of 97.2% and an F-measures of 94.25% is obtained for English document and a precision of 91.7%, recall of 87.85% and F-measures of 86.65% obtained for Amharic document. The average accuracy rate of the statistical tracker is 98.72%.","","Electronic:978-1-4799-7498-6; POD:978-1-4799-7499-3","10.1109/AFRCON.2015.7331964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7331964","Crawler;Information Retrieval;Language Identification;Local Web Content Observatory;Web Document Categorization","Accuracy;Crawlers;Observatories;Search engines;Service-oriented architecture;Training;Web pages","Web design;natural language processing;statistical testing",".et domain;English document;F-measures test;URL;Web document categorizer;accuracy rate measures;content extractor;crawler;language identifier;local Web content observatory system design;multicultural Web;multilingual Web;precision;qualitative content;quantitative content;recall;report generator;statistical tracker","","","","12","","","14-17 Sept. 2015","","IEEE","IEEE Conference Publications"
"Voice Search in the Holy Quran","G. Larbi","LaSTIC, UHL, Batna, Algeria","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","413","418","The holy Quran is sacred book of Muslims. The use of this book is very frequent either for reading, for memorization or for the search of a verse of Quran dealing with a particular subject. Muslims find difficulties in the use of this book in his audio format and especially in the search for a verse. For this, and to help Muslims, we focus our work on the problem of finding a verse in the holy Quran. The search will be in voice mode where the user dictates a verse into microphone. The goal is to receive the verse dictated by user from the microphone and compare it with all verses of holy Quran. It returns then the closest verse to the desired one. This goal requires a great work which will be proposed as a doctoral subject. In this paper we propose to acquire the query by playing a verse of the database and to capture it by microphone. This paper presents a new system that identifies an audio subsequence (requested verse of Holy Quran) using basic audio descriptors. Each audio document of corpus (all verses of Holy Quran) is pre-processed before the extraction of a set of basic audio descriptors, which characterize the temporal and the spectral information. Therefore, an audio signal is represented by a sequence of characteristics called in this paper ""audio fingerprint"". The search process is based on a new concept called ""interference wave"". This wave is generated from the content of audio signals, and used to calculate the similarity rate between two audio signals.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277284","Voice search;audio information retrieval;interference wave","Databases;Fingerprint recognition;Fourier transforms;Information retrieval;Interference;Microphones;Speech","acoustic wave interference;audio signal processing;humanities;microphones;query processing;signal processing","Holy Quran;audio descriptors;audio fingerprint;audio format;audio signal content;audio subsequence;interference wave;microphone;muslims;voice search","","","","10","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"CITEX: A new citation index to measure the relative importance of authors and papers in scientific publications","A. Pal; S. Ruj","TCS Innovation Labs., Kolkata, India","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","1256","1261","Evaluating the performance of researchers and measuring the impact of papers written by scientists is the main objective of citation analysis. Various indices and metrics have been proposed for this. In this paper, we propose a new citation index CITEX, which gives normalized scores to authors and papers to determine their rankings. To the best of our knowledge, this is the first citation index which simultaneously assigns scores to both authors and papers. Using these scores, we can get an objective measure of the reputation of an author and the impact of a paper. We model this problem as an iterative computation on a publication graph, whose vertices are authors and papers, and whose edges indicate which author has written which paper. We prove that this iterative computation converges in the limit, by using a powerful theorem from linear algebra. We run this algorithm on several examples, and find that the author and paper scores match closely with what is suggested by our intuition. The algorithm is theoretically sound and runs very fast in practice. We compare this index with several existing metrics and find that CITEX gives far more accurate scores compared to the traditional metrics.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7248495","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7248495","CITATION ANALYSIS;EIGENVALUES AND EIGENVECTORS;GRAPH ALGORITHMS;INFORMATION RETRIEVAL;MATRIX COMPUTATIONS","Algorithm design and analysis;Citation analysis;Collaboration;Eigenvalues and eigenfunctions;Indexes;Measurement;Social network services","citation analysis","CITEX;citation index;iterative computation;linear algebra;objective measure;publication graph;scientific publications","","1","","22","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Latin Music Mood Classification Using Cifras","A. L. Przybysz; R. Corassa; C. L. d. Santos; C. N. Silla","Comput. Music Technol. Lab., Fed. Univ. of Technol. of Parana, Cornelio Procopio, Brazil","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","1682","1686","This article describes the automatic classification of emotions through five novel feature descriptors based on the ""cifras"" of the songs. A ""cifra"" is a document that contains the harmonic structure and harmonic progression a song. In order to evaluate the proposed feature sets, we have created a novel database, namely the Latin Music Cifras Mood Database (LMCMD). This database was created manually by the authors by querying different websites for the ""cifras"" of songs.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379428","Latin music;Music Emotion Classification;Music Information Retrieval","Databases;Emotion recognition;Frequency modulation;Harmonic analysis;Mood;Music;Support vector machines","Web sites;music;pattern classification;query processing;text analysis","LMCMD;Latin music cifras mood database;Latin music mood classification;Web site querying;automatic emotion classification;feature descriptors;harmonic progression;harmonic structure","","","","11","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Jaccard coefficient-based word sense disambiguation using hybrid knowledge resources","S. M. Tyar; T. Win","Department of Information Technology, Yangon Technological University, Yangon, Myanmar","2015 7th International Conference on Information Technology and Electrical Engineering (ICITEE)","20160218","2015","","","147","151","Word Sense Disambiguation (WSD) has become a popular method for solving the ambiguous meaning of the words in Information Retrieval (IR) field area. Under the Natural Language Processing (NLP) community, WSD has been described as the task which able to select the appropriate meaning among the ambiguous meanings to a given word. Among three approaches, supervised based, unsupervised based and knowledge based approaches to WSD, this paper focuses on both supervised based and knowledge based approaches by proposing new Jaccard coefficient-based WSD algorithm to overcome the vocabulary miss match problem. WordNet and corpus external knowledge resources are utilized as the sense repositories by linking up with the new WSD algorithm to consider additional semantic for WSD. According to sample testing, IR system with new WSD algorithm attains more about 20 percent of total accuracy rate than traditional IR system.","","Electronic:978-1-4673-7863-5; POD:978-1-4673-7864-2; USB:978-1-4673-7862-8","10.1109/ICITEED.2015.7408931","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7408931","Jaccard coefficient;WordNet;corpus;information retrieval;word sense disambiguation","Context;Electrical engineering;Information technology;Semantics;Testing;Vocabulary","information retrieval;natural language processing;statistical testing;unsupervised learning","IR system;Jaccard coefficient-based WSD algorithm;Jaccard coefficient-based word sense disambiguation;NLP;WordNet;corpus external knowledge resources;hybrid knowledge resources;information retrieval field area;knowledge based approach;natural language processing community;sense repositories;supervised based approach;unsupervised based approach","","","","13","","","29-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"Music boundary detection using neural networks on spectrograms and self-similarity lag matrices","T. Grill; J. Schluter","Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria","2015 23rd European Signal Processing Conference (EUSIPCO)","20151228","2015","","","1296","1300","The first step of understanding the structure of a music piece is to segment it into formative parts. A recently successful method for finding segment boundaries employs a Convolutional Neural Network (CNN) trained on spectrogram excerpts. While setting a new state of the art, it often misses boundaries defined by non-local musical cues, such as segment repetitions. To account for this, we propose a refined variant of self-similarity lag matrices representing long-term relationships. We then demonstrate different ways of fusing this feature with spectrogram excerpts within a CNN, resulting in a boundary recognition performance superior to the previous state of the art. We assume that the integration of more features in a similar fashion would improve the performance even further.","","Electronic:978-0-9928-6263-3; POD:978-1-4799-8851-8","10.1109/EUSIPCO.2015.7362593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362593","Acoustic signal processing;Feedforward neural networks;Music information retrieval","Context;Convolution;Europe;Kernel;Neural networks;Spectrogram","acoustic signal detection;music;neural nets","boundary recognition performance;convolutional neural network;music boundary detection;music piece segmentation;nonlocal musical cues;segment boundaries;segment repetitions;self-similarity lag matrices;spectrogram excerpts","","","","15","","","Aug. 31 2015-Sept. 4 2015","","IEEE","IEEE Conference Publications"
"Challenges for information access in multi-disciplinary product design and engineering settings","D. Ahlers; M. Mehrpoor; K. Kristensen; J. Krogstie","Department of Computer and Information Science, NTNU - Norwegian University of Science and Technology, Trondheim, Norway","2015 Tenth International Conference on Digital Information Management (ICDIM)","20160114","2015","","","109","114","In any larger engineering setting, there is a huge number of documents that engineers and others need to use and be aware of in their daily work. To improve the handling of this amount of documents, we propose to view it under the angle of a new domain for professional search, thus incorporating search engine knowledge into the process. We examine the use of Information Retrieval (IR), Recommender Systems (RecSys), and Knowledge Management (KM) methods in the engineering domain of Knowledge-based Engineering (KBE). The KBE goal is to capture and reuse knowledge in product and process engineering with a systematic method. Based on previous work in professional search and enterprise search, we explore a combination of methods and aim to identify key issues in their application to KBE. We list detected challenges, discuss information needs and search tasks, then focus on issues to solve for a successful integration of the IR and KBE domain and give a system overview of our approach to build a search and recommendation tool to improve the daily information-seeking workflow of engineers in knowledge-intense disciplines. Our work contributes to bridging the gap between Information Retrieval and engineering support systems.","","Electronic:978-1-4673-9152-8; POD:978-1-4673-9153-5","10.1109/ICDIM.2015.7381865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381865","CAx;Case Study;Enterprise Search;Industry;Information Access;Information Retrieval;Information and Knowledge Management;Manufacturing;Manufacturing design and product lifecycle management","Libraries;Personnel;Semantics","information retrieval;knowledge management;recommender systems;search engines","IR;KBE domain;KM methods;RecSys;engineering settings;engineering support systems;enterprise search;information access;information needs;information retrieval;information-seeking workflow;knowledge management;knowledge-based engineering;knowledge-intense disciplines;multidisciplinary product design;process engineering;professional search;recommendation tool;recommender systems;search engine knowledge","","","","30","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"New paradigm to keyword search: A survey","S. S. Laddha; A. R. Laddha; P. M. Jawandhiya","Government College of Engineering, Aurangabad 431001 (India)","2015 International Conference on Green Computing and Internet of Things (ICGCIoT)","20160114","2015","","","920","923","The total information available on WWW (World Wide Web) is huge and is increasing at lightning speed. Existing web is dominated by Search Engines which are running on keyword based search system which in turn leads to wastage of end user's precious time if he do not know the key terms which are utilized to index preferred correct pages. For example, a user enters the term `Jaguar'. Now current search engines will display results for `Car Jaguar', `Cat Jaguar' and `Operating System Jaguar'. That means it is the overhead on the user to go through the contents of the web pages to get the desired information. The same problem is with image search engines. If query is searched for images of `Tourist places in India', image result set will return number of irrelevant as well relevant images. To solve this problem solution is required where machine will itself separate the result into relevant and irrelevant one and then presenting the relevant ones to the user and Semantic Web is a step towards that. It is web 3.0, an expansion of the current web, web 2.0 , that permits the meaning of information to be specifically described which can be well understood by computer as well as user. Ontology is very important ingredient of Semantic Web. Advantage of using Semantic Web is that it improves the usability & performance of search engine and thereby increases Precision and Recall rate of search engine. This paper tries to identify the major challenges for today's keyword search engines to handle the fast growth of web and support comprehensive user demands in quick time. Then it surveys different search techniques proposed, developed or implemented by researchers.","","Electronic:978-1-4673-7910-6; POD:978-1-4673-7911-3; USB:978-1-4673-7909-0","10.1109/ICGCIoT.2015.7380594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380594","information retrieval;keyword based search;search engine;semantic web search","Indexing;Resource description framework;Search engines;Semantics","Internet;Web sites;query processing;semantic Web","WWW;Web 3.0;World Wide Web;comprehensive user demands;image search engines;keyword based search system;keyword search engines;ontology;precision;recall rate;search engine performance;search engine usability;semantic Web","","","","13","","","8-10 Oct. 2015","","IEEE","IEEE Conference Publications"
"BMExpert: Mining MEDLINE for Finding Experts in Biomedical Domains Based on Language Model","B. Wang; X. Chen; H. Mamitsuka; S. Zhu","Fudan University, Shanghai, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20151208","2015","12","6","1286","1294","With the rapid development of biomedical sciences, a great number of documents have been published to report new scientific findings and advance the process of knowledge discovery. By the end of 2013, the largest biomedical literature database, MEDLINE, has indexed over 23 million abstracts. It is thus not easy for scientific professionals to find experts on a certain topic in the biomedical domain. In contrast to the existing services that use some ad hoc approaches, we developed a novel solution to biomedical expert finding, BMExpert, based on the language model. For finding biomedical experts, who are the most relevant to a specific topic query, BMExpert mines MEDLINE documents by considering three important factors: relevance of documents to the query topic, importance of documents, and associations between documents and experts. The performance of BMExpert was evaluated on a benchmark dataset, which was built by collecting the program committee members of ISMB in the past three years (2012-2014) on 14 different topics. Experimental results show that BMExpert outperformed three existing biomedical expert finding services: JANE, GoPubMed, and eTBLAST, with respect to both MAP (mean average precision) and P@50 (Precision). BMExpert is freely accessed at http://datamining-iip.fudan.edu.cn/service/BMExpert/.","1545-5963;15455963","","10.1109/TCBB.2015.2430338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102707","Biomedical text mining;expert finding;information retrieval;language model","Benchmark testing;Bibliometrics;Bioinformatics;Biological system modeling;Computational modeling;Genomics;Proteins","data mining;medical expert systems;medical information systems;query processing;text analysis","BMExpert;ISMB program committee members;MEDLINE documents;MEDLINE mining;benchmark dataset;biomedical domains;biomedical expert finding services;biomedical literature database;biomedical sciences;knowledge discovery process;language model;query topic","0","1","","18","","20150506","Nov.-Dec. 1 2015","","IEEE","IEEE Journals & Magazines"
"Data Jacket Retrieval Based on Explicit Semantic Analysis","Q. Zhang","Dept. of Syst. Innovation, Univ. of Tokyo, Tokyo, Japan","2015 IEEE International Conference on Data Mining Workshop (ICDMW)","20160204","2015","","","749","752","By using the market of data, we are able to make decision and solve problem for new business based on real-world data to do. When someone needs to find some suitable data employed to ideas that are going to be realized, we can use keywords derived from the ideas as query to search in the market of data. However, sometimes the keywords are not included in the descriptions of data in the database, even for human, it is difficult to choose proper keywords. Therefore, the searching results are usually not satisfying in aspect of either quantity or relevancy. This paper presents two approaches of using Wikipedia-based Explicit Semantic Analysis (ESA) for retrieving relevant data, and compares them with the traditional TF·IDF based full-text retrieval method by experiment.","","Electronic:978-1-4673-8493-3; POD:978-1-4673-8494-0","10.1109/ICDMW.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395743","information retrieval;market of data;semantic analysis","Dictionaries;Electronic publishing;Encyclopedias;Internet;Large scale integration;Semantics","Web sites;commerce;decision making;information retrieval;marketing data processing;problem solving","ESA;Wikipedia;business;data jacket retrieval;decision making;explicit semantic analysis;market of data;problem solving","","","","6","","","14-17 Nov. 2015","","IEEE","IEEE Conference Publications"
"Desire: A Dynamic Approach for Exploratory Search Results Recommendation","L. P. Nanni; V. D. Feltrim","Inf. Dept., State Univ. of Maringa, Maringa, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","288","293","Personalized search aims to capture different users' needs in order to provide them with relevant results considering their individual interests. Therefore, personalized search systems store information about users' preferences and interests to create individualized profiles that can be integrated into the retrieval process. Several approaches have been proposed to dynamically capture the real user interest and achieve such objective. However, works so far have restricted themselves to the results page, failing to explore the possibility of recommending search results while the user navigates through the search space. Thus, we propose DESiRe, a dynamic approach for search results recommendation that is able to present unseen relevant results while the user browses the retrieved search space. Evaluation results showed an overall improvement of 88% for the ranking quality when compared to Google. The recommendation process was equally effective, providing high quality recommendations with a relatively large number of unseen results.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424034","dynamic search results recommendation;exploratory search;information retrieval;personalized search","Adaptation models;Context;Heuristic algorithms;Mathematical model;Search engines;Web search","information retrieval;recommender systems","DESiRe;Google;exploratory search result recommendation;personalized search system;ranking quality;retrieval process;search space;user interest information;user preference information","","","","18","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"An Automated Tagging Approach to Improve Search and Retrieval in a Radio Archive","M. Lycke; M. Matton; L. Overmeire","","SMPTE Motion Imaging Journal","20151203","2015","124","8","25","32","Although a manual process guarantees accurate tagging of archive material, it is very time-consuming. Hence, not all media content in a big broadcast archive can be annotated sufficiently. A more automated tagging process could reduce the amount of unannotated content. This paper describes how speech technology is applied to archived content of one year of the Flemish Radio and Television Network's Radio 1 Dutch news to address the issue described. Different options are discussed and an automated approach is suggested. Techniques such as speech recognition, keyword spotting, and keyword extraction are combined to generate automatic annotations. A search engine prototype was implemented to assess the findability of the radio content. Results from the prototype show that the proposed automated approach can improve annotation and search efficiency significantly while still maintaining high precision. The results and lessons learned and presented are not only valuable to archivists, but to other professional users such as journalists and even end users.","1545-0279;15450279","","10.5594/j18635","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340446","content-based retrieval;information retrieval;search engines;speech recognition","","","","","","","16","","","November/December 2015","","SMPTE","SMPTE Journals & Magazines"
"Inferring microarray relevance by enrichment of chemotherapy resistance-based microRNA sets","K. Açıcı; H. Oğul","Computer Engineering Department, Baskent University, Ankara, Turkey","2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES)","20151123","2015","","","389","393","Inferring relevance between microarray experiments stored in a gene expression repository is a helpful practice for biological data mining and information retrieval studies. In this study, we propose a knowledge-based approach for representing microarray experiment content to be used in such studies. The representation scheme is specifically designed for inferring a disease-associated relevance of microRNA experiments. A group of annotated microRNA sets based on their chemotherapy resistance are used for a statistical enrichment analysis over observed expression data. A query experiment is then represented by a single dimensional vector of these enrichment statistics, instead of raw expression data. According to the results, new representation scheme can provide a better retrieval performance than traditional differential expression-based representation.","","Electronic:978-1-4673-7939-7; POD:978-1-4673-7940-3; USB:978-1-4673-7938-0","10.1109/INES.2015.7329740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7329740","content-based search;gene expression database;information retrieval;microRNA","Chemotherapy;Databases;Diseases;Fingerprint recognition;Immune system;Information retrieval;Measurement","RNA;bioinformatics;data mining;lab-on-a-chip;query processing;statistical analysis","biological data mining;chemotherapy resistance-based microRNA set;gene expression repository;information retrieval;knowledge-based approach;microRNA experiment;query experiment;raw expression data;statistical enrichment analysis","","","","15","","","3-5 Sept. 2015","","IEEE","IEEE Conference Publications"
"TrackInfo: Finding relevant information from high velocity data of social network","M. K. Rahman","Bangladesh Univ. of Eng. & Technol., Dhaka, Bangladesh","2015 International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)","20151029","2015","","","1","6","Social networking sites are becoming popular platforms to share information for different types of media agencies including Newspapers, TV channels, FM radios, etc. Obviously, they hold public pages or accounts in social networks. Sometimes, such media agencies post in online social network (OSN) (Facebook, Twitter, etc.) and ask users' feedback through comments. They also declare some lucrative facilities for a user who give maximum comments to that post or contact directly to the users who give qualitative comments. In case of a live reality shows in TV channels, they ask votes from viewers for a fixed set of candidates within very limited time. As a result, in few minutes, more than 1,000 comments are found in such posts which is really difficult for streaming and analyzing to discover some information at the same time. In this paper, we discuss three new problems of such media agencies, analyze some scenarios and propose novel solution for each of the problem. Though such problems have not been tackled in the literature, we are first to deal with such problems. We have conducted an extensive set of experiments on the collected data from official facebook page of Roger Federer<sup>1</sup> and DhakaFM90.4<sup>2</sup> to evaluate the effectiveness of our proposed approaches.","","Electronic:978-1-4673-6676-2; POD:978-1-4673-6677-9","10.1109/ICEEICT.2015.7307457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307457","Data processing;Information filtering;Information retrieval;Social network services","Cascading style sheets;Sparks","data handling;information filtering;social networking (online)","DhakaFM90.4<sup>2</sup>;FM radio;OSN;TV channel;facebook;high velocity data;information filtering;newspaper;online social network;social networking site","","","","12","","","21-23 May 2015","","IEEE","IEEE Conference Publications"
"Ranking algorithm based on relational topic model","Y. Ding; Shengli Yan; Yang Xiao; Tingting Tao","Department of Computer Science and Technology Harbin Institute of Technology Shenzhen Graduate School, China","2015 International Joint Conference on Neural Networks (IJCNN)","20151001","2015","","","1","8","In this paper a supervised topic model is proposed for rank learning. The original supervised topic model can only learn from positive samples. For rank learning problem, training data have different ranking labels. To solve this issue, we extend the supervised topic model and make it learn from training data with different ranking labels. The experiments show that the proposed topic models can find the hidden relationships among words, and have higher ranking accuracy than word based models. In addition, the supervised topic models have higher ranking accuracy than the unsupervised topic models.","2161-4393;21614393","Electronic:978-1-4799-1960-4; POD:978-1-4799-1961-1","10.1109/IJCNN.2015.7280376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280376","Information Retrieval;Machine Learning;Ranking;Topic Relation Model","Data models;Manganese","information retrieval;learning (artificial intelligence)","information retrieval;machine learning;rank learning problem;ranking algorithm;ranking labels;relational topic model;supervised topic model","","","","19","","","12-17 July 2015","","IEEE","IEEE Conference Publications"
"Affective analysis of musical chords","M. Kukreti","Graduate student, Computer Science, University of Waterloo","2015 Science and Information Conference (SAI)","20150903","2015","","","379","385","Music invokes emotions in humans and hence sentiment extraction in music has been researched for a long time. This paper focuses on 2 research goals (RGs): RG1: Identifying and analyzing emotions associated with different musical chords. RG2: Suggesting a technique to compute Evaluation, Potency and Activity (EPA) [31] values for musical chords. For RG1 a user study is conducted wherein 30 people are asked to name a song under two emotional categories - “Happiness” and “Sadness”. Chord progression of each song is determined using the Chordify Web service and the frequency of occurrence of the chords under the two emotional categories is calculated and the trends are analyzed. For RG2, EPA values for chords are computed by utilizing the results of RG1 to calculate the probability of chord, given an emotion Pr(Chord|Emotion). This data is fed into the proposed formula to determine EPA values associated with different chords. Thereafter, application of these results to existing sentiment extraction models is suggested.","","Electronic:978-1-4799-8547-0; POD:978-1-4799-8548-7; USB:978-1-4799-8546-3","10.1109/SAI.2015.7237171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237171","Affective computing;Computer generated music;Emotion recognition;Music information retrieval;Sentiment analysis","Computational modeling;Databases;Feature extraction;Probabilistic logic;Rhythm;Web services","Web services;emotion recognition;graphical user interfaces;information retrieval;music","Chordify Web service;EPA values;chord occurrence frequency;chord probability;chord progression;emotion analysis;emotion identification;evaluation-potency-and-activity;happiness-emotional category;musical chords;research goals;sadness-emotional category;sentiment extraction models","","0","","31","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Cloud Computing Oriented Retrieval Technology Based on Big Data","W. Xiao-Shu; X. Yao; L. Huan","Dalian Vocational Tech. Coll., Dalian, China","2015 Seventh International Conference on Measuring Technology and Mechatronics Automation","20150914","2015","","","275","278","With the rapid development of cloud computing, the information increase rapidly. Cheap cloud storage and computing power accelerate the development of big data, and make the big data information collection and information retrieval become necessary. More than 50% of the big data is unstructured data, so it is stored in the form of file for the most part. Big data is divided into many blocks what stored in the server with some corresponding metadata of storage on the master server. How to collect the big data web and keywords and retrieve the information are been discussed in this paper.","2157-1473;21571473","CD-ROM:978-1-4673-7142-1; Electronic:978-1-4673-7143-8; POD:978-1-4673-7144-5","10.1109/ICMTMA.2015.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7263565","big data information retrieval;pagerank;web pages index","Big data;Cloud computing;Indexes;Metadata;Search engines;Servers;Web pages","Big Data;cloud computing;information retrieval;meta data","Big Data Web;big data information collection;cloud computing oriented retrieval technology;information retrieval;master server;metadata","","","","9","","","13-14 June 2015","","IEEE","IEEE Conference Publications"
"Notice of Violation of IEEE Publication Principles<BR>Question answering system: A survey","A. Mathur; M. T. U. Haider","Computer Science & Engineering Deptt. National Institute of Technology Patna, India","2015 International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM)","20150827","2015","","","47","57","Notice of Violation of IEEE Publication Principles<BR><BR>""Question Answering System: A Survey,""<BR>by Ashish Mathur and M. T. U. Haider,<BR>in the Proceedings of the International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM), May 2015, pp. 47-57<BR><BR>After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>This paper duplicates the content and figures from the paper cited below. The original content was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.<BR><BR>Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:<BR><BR>""The Question Answering Systems: A Survey""<BR>by Ali Mohamed Nabil Allam and Mohamed Hassan Haggag<BR>in the International Journal of Research and Reviews in Information Sciences (IJRRIS)Vol. 2, No. 3, September 2012, pp. 211-221<BR><BR>Question answering (QA) is new research domain in the field of Information Science comes into focus in last few decades. Question answering systems are pretty much different from web based search engines which works on the principal of Information Retrieval (IR), however QA systems works on the concept of Information Retrieval (IR) as well as Information Extraction (IE). Web based search engines takes user's query in natural language and responds the same with references and URLs of related documents and websites, but they failed when a user wants precise answer for their query. By considering these limitations of search engines people finds that there is a need for such a system which answer the user's query rather responds with references or URLs of related documents. User should be provided - ith the precise answer to their question. They are one step ahead of web search engines which provides relevant documents against users query however QA system provides precise answer. A QA system comprises of three core components question classification, information retrieval and answer extraction module. Answer extraction module distinguishes QA system from web search engines. Question classification module plays an important role in QA since it identifies the type of information user have asked for. Similarly information retrieval is also important, because if none of the retrieved document contains answer sets no further processing can be done.","","CD:978-1-4799-9853-1; Electronic:978-1-4799-9855-5; Paper:978-1-4799-9854-8","10.1109/ICSTM.2015.7225389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225389","Answer Extraction;Information Extraction;Information Retrieval;Natural Language Processing;Question Answering","Data mining;Knowledge discovery;Natural languages;Query processing;Search engines;Taxonomy","Web sites;information science;natural language processing;pattern classification;question answering (information retrieval);search engines","IE;IR;QA;URLs;Web based search engines;Web sites;answer extraction module;information extraction;information retrieval;information science;natural language;question answering system;question classification","","0","","24","","","6-8 May 2015","","IEEE","IEEE Conference Publications"
"Modeling musical rhythmatscale with the music Genome project","M. Prockup; A. F. Ehmann; F. Gouyon; E. M. Schmidt; Y. E. Kim","Drexel University, ECE Dept., 3141 Chestnut Street, Philadelphia, PA 19104","2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","20151130","2015","","","1","5","Musical meter and attributes of the rhythmic feel such as swing, syncopation, and danceability are crucial when defining musical style. However, they have attracted relatively little attention from the Music Information Retrieval (MIR) community and, when addressed, have proven difficult to model from music audio signals. In this paper, we propose a number of audio features for modeling meter and rhythmic feel. These features are first evaluated and compared to timbral features in the common task of ballroom genre classification. These features are then used to learn individual models for a total of nine rhythmic attributes covering meter and feel using an industrial-sized corpus of over one million examples labeled by experts from Pandora® Internet Radio's Music Genome Project®. Linear models are shown to be powerful, representing these attributes with high accuracy at scale.","","Electronic:978-1-4799-7450-4; POD:978-1-4799-7451-1; USB:978-1-4799-7449-8","10.1109/WASPAA.2015.7336891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336891","audio;feature engineering;large-scale machine learning;music information retrieval;rhythm;signal processing","Bioinformatics;Context;Genomics;Multiple signal classification;Rhythm;Transforms","audio signal processing;information retrieval;signal classification","MIR;Pandora Internet Radio Music Genome Project;ballroom genre classification;music audio signal;music genome project;music information retrieval;musical meter;musical rhythm modeling","","","","19","","","18-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Text-mining approach for verifying alignment of information systems curriculum with industry skills","Law Sheng Xun; S. Gottipati; V. Shankararaman","School of Information Systems, Singapore Management University, Singapore","2015 International Conference on Information Technology Based Higher Education and Training (ITHET)","20150824","2015","","","1","6","Managing and developing competencies or skills are vital to professional development of an individual. Many tertiary education institutions are therefore focused on developing curriculum that will help the graduating students acquire skills that are aligned with industry practice. Industry skills frameworks such as Skills Framework for the Information Age (SFIA) define the professionals required for an IT professional. Therefore, mapping the curriculum competencies to the industry skills framework has a dual purpose of aiding the educationists to improve the curriculum, and the students to plan the courses according to their career plan. Existing mapping methods are manual and painstaking processes. In this paper, we present an automated solution based on text analytics techniques to map the curriculum to industry framework and provide a visual based analysis to discover the strengths and weakness of the curriculum. We evaluated our solution model on an undergraduate core curriculum; Bachelor of Science (Information Systems Management) degree program BSc (ISM), offered by the School of Information Systems (SIS), Singapore Management University (SMU) and Skills Framework for the Information Age (SFIA).","","Electronic:978-1-4799-1756-3; POD:978-1-4799-1757-0; USB:978-1-4799-1755-6","10.1109/ITHET.2015.7217959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217959","Curriculum evaluation;analysis;industry skills framework;information retrieval;text analytics;visualization","Business;Computer integrated manufacturing;Industries;Information retrieval;Information systems;Text mining;Visualization","data mining;further education;text analysis","SFIA;industry skills;information systems;skills framework for the information age;tertiary education institutions;text analytics techniques;text-mining approach;undergraduate core curriculum;visual based analysis","","0","","20","","","11-13 June 2015","","IEEE","IEEE Conference Publications"
"A performance comparison between classification techniques with CRM application","D. A. R. Mohamed; M. M. Sakre","Management Information System, Al Shorouk Academy, Cairo, Egypt","2015 SAI Intelligent Systems Conference (IntelliSys)","20151221","2015","","","112","119","Complaints Management (CM) is one of the important elements in Customer Relationship Management (CRM) system of any organization which helps in customer retention for the longest possible period of time. In this research, a system called Complaint Classification System (CCS) is implemented to discuss how Data Mining Techniques (DMT) can be used to classify and direct complaints to the departments responsible for them. This may help to renew the client confidence with the organization. To achieve this, many algorithms are used in classification and are compared to use the most efficient of them in the practical system. The used algorithms are the centroid-based classifier, the Voting k-Nearest Centroid Neighbor (VK-NCN) algorithm, the Weighted k-Nearest Centroid Neighbor (WK-NCN) and the Local Mean K-Nearest Centroid Neighbor (LM-KNCN) algorithm. Centroid-based classifier algorithm is proved to have the best performance during the usage of cosine measure while LM-KNCN algorithm is proved to have the best performance during the usage of Euclidean distance measure.","","Electronic:978-1-4673-7606-8; POD:978-1-4673-7607-5; USB:978-1-4673-7605-1","10.1109/IntelliSys.2015.7361133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361133","Centroid based classifier;Complaints management;Customer relationship management;Customer retention;Data mining;Information retrieval;Local mean k-nearest centroid neighbor;Text classification;Voting k-nearest centroid neighbor;Weighted k-nearest centroid neighbor","Classification algorithms;Companies;Customer relationship management;Euclidean distance;Text categorization;Training","customer relationship management;data mining;pattern classification","CCS;CRM application;DMT;Euclidean distance measure;LM-KNCN;VK-NCN algorithm;WK-NCN;centroid-based classifier algorithm;classification techniques;complaint classification system;complaints management;customer relationship management;customer retention;data mining techniques;local mean k-nearest centroid neighbor;voting k-nearest centroid neighbor;weighted k-nearest centroid neighbor","","","","27","","","10-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Joint Structural Learning to Rank with Deep Linear Feature Learning","X. Zhao; X. Li; Z. Zhang","Department of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Knowledge and Data Engineering","20150909","2015","27","10","2756","2769","Multimedia information retrieval usually involves two key modules including effective feature representation and ranking model construction. Most existing approaches are incapable of well modeling the inherent correlations and interactions between them, resulting in the loss of the latent consensus structure information. To alleviate this problem, we propose a learning to rank approach that simultaneously obtains a set of deep linear features and constructs structure-aware ranking models in a joint learning framework. Specifically, the deep linear feature learning corresponds to a series of matrix factorization tasks in a hierarchical manner, while the learning-to-rank part concentrates on building a ranking model that effectively encodes the intrinsic ranking information by structural SVM learning. Through a joint learning mechanism, the two parts are mutually reinforced in our approach, and meanwhile their underlying interaction relationships are implicitly reflected by solving an alternating optimization problem. Due to the intrinsic correlations among different queries (i.e., similar queries for similar ranking lists), we further formulate the learning-to-rank problem as a multi-task problem, which is associated with a set of mutually related query-specific learning-to-rank subproblems. For computational efficiency and scalability, we design a MapReduce-based parallelization approach to speed up the learning processes. Experimental results demonstrate the efficiency, effectiveness, and scalability of the proposed approach in multimedia information retrieval.","1041-4347;10414347","","10.1109/TKDE.2015.2426707","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095607","Learning to rank;deep feature learning;information retrieval;joint learning;matrix factorization;structural SVM","Correlation;Information retrieval;Joints;Multimedia communication;Optimization;Support vector machines;Training","learning (artificial intelligence);matrix decomposition;multimedia computing;parallel processing;query processing;support vector machines","MapReduce-based parallelization approach;deep linear feature learning;feature representation;intrinsic ranking information;joint learning mechanism;joint structural learning;matrix factorization;multimedia information retrieval;query-specific learning-to-rank subproblem;ranking model construction;structural SVM learning;structure-aware ranking model","","0","","49","","20150427","Oct. 1 2015","","IEEE","IEEE Journals & Magazines"
"An Empirical Study on Structured Dichotomies in Music Genre Classification","T. Arjannikov; J. Z. Zhang","Univ. of Victoria, Victoria, BC, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","493","496","Ensemble learning approaches have been gaining popularity in the non-trivial task of multi-class classification. Some of these, including 1-against-1, 1-against-all, and dichotomy-based methods, are based on decomposing the class space of a multi-class task into a set of binary-class ones. In this work, we investigate whether they could help improve genre classification in music. In particular, we explore various dichotomy structures of binary classifiers in music data. In addition to the existing ones, we propose several strategies to build new binary tree structures. We base our approach on the observation that people find it easy to distinguish between certain classes and difficult between others. In our investigation, we use several base classifiers that are common in the literature and conduct series of empirical experiments on two benchmarking music datasets. We report the initial results of our investigation in this paper.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424364","dichotomy based classification;genre classification;music information retrieval","Benchmark testing;Binary trees;Electronic mail;Feature extraction;Music;Training","learning (artificial intelligence);music;pattern classification;tree data structures","binary classifiers;binary tree structures;dichotomy structures;ensemble learning approaches;music genre classification;structured dichotomies","","","","12","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Leveraging Temporal Query-Term Dependency for Time-Aware Information Access","B. Moulahi; L. Tamine; S. B. Yahia","IRIT, Univ. of Toulouse, Toulouse, France","2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)","20160204","2015","1","","149","156","Incorporating the temporal property of queries into time-aware information access methods has been shown to have a significant positive effect on a large number of search tasks, such as over microblogs and news archive. Recent work on time-aware search mostly rely on time-based relevance models that are built upon the language model framework. However, in this model, query terms are often assumed to be generated independently from each other. In this paper, we observe through a time series analysis that, query terms are temporally dependent and are frequently occurring within similar time periods when they deal with the same topics. In contrast to existing work, we propose a method that naturally extends the effective temporal language model and exploits this dependency at the term granularity level. Moreover, we reframe the task as a rank aggregation problem that fully exploits the temporal features of query terms. Experiments using the large-scale TREC Temporal Summarization 2013 and 2014 standard datasets empirically show that our method leads to significant performance improvements, when compared to state-of-the-art temporal ranking models.","","Electronic:978-1-4673-9618-9; POD:978-1-4673-9619-6","10.1109/WI-IAT.2015.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7396795","Relevance;ranking;temporal information retrieval","Intelligent agents","Internet;document handling;query processing;time series","microblogs;news archive;rank aggregation problem;temporal language model;temporal query-term dependency;term granularity level;time series analysis;time-aware information access;time-aware search;time-based relevance model","","","","23","","","6-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Plugin for concept-assisted search and navigation on PUBMED","T. Joseph; V. G. Saipradeep; S. Kotte; A. Rao; R. Srinivasan","TCS Innovation Labs, Tata Consultancy Services Limited 1, Software Units Layout, Madhapur, Hyderabad, India","2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20151217","2015","","","1712","1714","Introduction: Search of MEDLINE using the PUBMED interface still remains a preferred approach for many scientists, even in the presence of alternatives. While PUBMED provides a rich interface for querying, it does not provide deep analysis of the query results to refine queries and build hypotheses. To provide an improved search experience in PubMed, we have developed a Firefox browser plugin called “TPX plus” that enables concept-assisted search and navigation of the MEDLINE database while remaining in the PubMed website. Some of the features of the plugin include identification and highlighting of biomedical concept types like genes, processes, diseases etc. in the PubMed results page; link-outs to dictionary sources for identified terms; a Concept Explorer to view ranked automatically identified concepts in the results as well as use them for filtering/refining the search; deriving related concepts using a statistical concept-associations network; bookmarking and managing articles, storing notes and sharing comments on articles. Implementation: The core of the plugin is written in JavaScript that uses Web 2.0 technologies such as jQuery, AJAXlJSON and XUL for handling and manipulating content of web pages within the PubMed domain. 'TPX plus' uses the DOM structure of PubMed's search interface for a) building input to Annotation server by extracting appropriate content such as title, abstract text and PubMed ID from the appropriate DOM elements and b) presenting the top ranked biomedical concepts based on their relevance to the search query under concept explorer and c) highlight biomedical concepts for each abstract in the search result under article view in the PubMed's search interface. Conclusion: Its three-pronged nature of relying on PubMed as the basic indexing engine, enhancing PubMed by performing customized offline and on-the-fly analysis of the search results and most importantly being available as a browser plugin allowing use of the- PubMed user-interface makes this plugin an ideal PubMed search assistant for scientists.","","Electronic:978-1-4673-6799-8; POD:978-1-4673-6800-1","10.1109/BIBM.2015.7359934","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359934","PubMed;TPX;biomedical text;information retrieval;plugin;search","Benchmark testing;Bioinformatics;Browsers;Buildings;Cryptography;Navigation","Web sites;indexing;information filtering;medical computing;query processing;user interfaces","AJAXlJSON;Annotation server;Concept Explorer;Firefox browser plugin;JavaScript;MEDLINE database;PUBMED interface;PubMed Web site;PubMed user-interface;TPX plus;Web 2.0 technologies;Web pages;XUL;article bookmarking;article management;biomedical concept type highlighting;biomedical concept type identification;concept-assisted search and navigation;content handling;content manipulation;indexing engine;jQuery;offline analysis;on-the-fly analysis;search filtering;search refining;statistical concept-associations network","","1","","11","","","9-12 Nov. 2015","","IEEE","IEEE Conference Publications"
"Test cases prioritization for software regression testing using analytic hierarchy process","P. Klindee; N. Prompoon","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20150827","2015","","","168","173","Test cases are considered an important asset in the software testing process since they are used to detect defects in the software. In order to produce quality software covering all of the requirements, the test case designer requires much time and effort in designing test cases to cover all requirements and conditions according to the test case structure. This research proposes a method for storing and retrieving of test cases affected by software requirements changes, as well as ranking the retrieved test cases using the AHP method to improve the quality of the ranking. There are to assist system testers in identifying test cases for complete regression testing. An example application of the proposed method will also be presented.","","Electronic:978-1-4799-1966-6; POD:978-1-4799-1967-3","10.1109/JCSSE.2015.7219790","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219790","AHP;Analytical Hierarchy Process;Information Retrieval;Prioritization Technique;Regression Testing;Test Case Prioritization","Analytic hierarchy process;Complexity theory;Computer aided software engineering;Indexes;Software;Software testing","analytic hierarchy process;program testing;software quality","AHP method;analytic hierarchy process method;software quality;software regression testing process;test cases prioritization","","2","","14","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Techniques to Preserve the Integrity of the Electronic Versions of the Nobel Quran","I. M. Alsmadi","Inf. Syst. Dept., Prince Sultan Univ., Riyadh, Saudi Arabia","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","52","56","The ability to control data and information through the Internet can be challenging. Preliminary analysis showed that some literal modification may occur to some words of the Quran in the electronic versions that span the Internet. Such small modifications may not be noticed by public audience. The holly book of Quran includes a unique feature in that its worldwide copies are all identically similar. The 114 Suras and all verses and words in them are preserved in the exact form. As such, we designed and evaluated a model and a tool to preserve the integrity of the wording in the Quran through generating a Meta data related to all letters in the Quran preserving the counts and locations. Such data can be used eventually in the same way CRC or hash algorithms are used in security to check the integrity of a disk and its data file where any small change in the data will result in a different hash value. We conducted several experiments to evaluate the different parameters and challenges that can impact the automatic authentication process of Quranic verses based on information retrieval and hashing algorithms.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277219","Information retrieval;documents automatic evaluation;hashing algorithms;information authentication;search engines;security","Accuracy;Authentication;Encryption;Information retrieval;Internet;Plagiarism","Internet;data integrity;electronic publishing;information retrieval;meta data;security of data","CRC algorithms;Internet;Quranic verse automatic authentication process;Suras;data integrity;electronic Quran;hashing algorithms;information retrieval;meta data","","","","3","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"Palazzo Matrix Model: An approach to simulate the efficient semantic results in search engines","S. Mahaboob Hussain; D. Surya Narayana; P. Kanakam; S. Gupta","Department of CSE, Vishnu Institute of Technology, Bhimavaram, India","2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)","20150827","2015","","","1","6","Searching of data over the web by the users is increasing day to day. Many search engines are feasible in the market to provide services to the users to achieve relevant data and knowledge. But, most of the time the search engines fail to provide the exact information what the users really seek, i.e., losing the relevancy of the retrieved documents for the queries. In recent years, semantic search engines have arrived with considerable research efforts which aim to improve the retrieval process and traditional information search. This paper presents different models to calculate the relevancy of the document retrieved for the given query and also introduce a novel approach Palazzo Matrix Approach to retrieve the most relevant documents that use lemmatization and stemming processes to match terms which are in the given query. Based on this approach, various experiments were conducted to evaluate the effectiveness of search engines using different measures such as precision and recall on multiple as well as single word search queries given by the users to either semantic or keyword based search engines.","","Electronic:978-1-4799-6085-9; POD:978-1-4799-6086-6","10.1109/ICECCT.2015.7226100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226100","information retrieval;lemmatization;palazzo matrix;precision;recall;search engines;stemming","Dictionaries;Engines;Joining processes;TV","Internet;matrix algebra;query processing;search engines","Palazzo matrix model;World Wide Web;document retrieval;predictable documents;query;search engines;semantic results","","1","","16","","","5-7 March 2015","","IEEE","IEEE Conference Publications"
"Privacy preservation and content protection in location based queries","G. Sarath; Megha Lal S. H","Department of Computer Science, Amrita School of Engineering, Kollam, India","2015 Eighth International Conference on Contemporary Computing (IC3)","20151207","2015","","","325","330","Location based services are widely used to access location information such as nearest ATMs and hospitals. These services are accessed by sending location queries containing user's current location to the Location based service(LBS) server. LBS server can retrieve the the current location of user from this query and misuse it, threatening his privacy. In security critical application like defense, protecting location privacy of authorized users is a critical issue. This paper describes the design and implementation of a solution to this privacy problem, which provides location privacy to authorized users and preserve confidentiality of data in LBS server. Our solution is a two stage approach, where first stage is based on Oblivious transfer and second stage is based on Private information Retrieval. Here the whole service area is divided into cells and location information of each cell is stored in the server in encrypted form. The user who wants to retrieve location information will create a clocking region(a subset of service area), containing his current location and generate a query embedding it. Server can only identify the user is somewhere in this clocking region, so user's security can be improved by increasing the size of the clocking region. Even if the server sends the location information of all the cells in the clocking region, user can decrypt service information only for the user's exact location, so confidentiality of server data will be preserved.","","CD-ROM:978-1-4673-7946-5; Electronic:978-1-4673-7948-9; POD:978-1-4673-7949-6","10.1109/IC3.2015.7346701","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346701","Location based query;oblivious transfer;private information retrieval","Cryptography;Information retrieval;Privacy;Protocols;Receivers;Servers","authorisation;data privacy;mobile computing;query processing","ATM;LBS server;authorized user;content protection;data confidentiality;hospital;location based query;location based service server;location information retrieval;location privacy;oblivious transfer;privacy preservation;private information retrieval;security critical application","","","","15","","","20-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"A system for semantic information extraction from mixed soundtracks deploying MARSYAS framework","D. Y. Mohammed; P. J. Duncan; M. M. Al-Maathidi; F. F. Li","School of Computing, Science and Engineering, University of Salford, Salford, Greater Manchester, UK","2015 IEEE 13th International Conference on Industrial Informatics (INDIN)","20151001","2015","","","1084","1089","Ever increasing volumes of media content and the desire to extract information from media archives motivate the studies into semantic audio information mining. Much research in this filed concerns development of bespoke systems, in which sound tracks are exclusively classified and segmented, and a specific type of sound is recognized and analyzed. This approach however is detrimental to the complete extraction of all relevant semantic information and audio scene analysis. The current study addresses the issues of sound tracks with overlapped music, speech and ambient sounds, and explores how MARSYAS (Music Analysis, Retrieval and Synthesis for Audio Signals) can be extended to mixed and overlapped soundtrack applications. The MARSYAS has been adapted to this application by means of adopting additional speech cleaning algorithms. The proposed new system can analyze arbitrary sound tracks and timestamp the occurrence of music and speech, allowing overlaps, in the form of a “sound score” for further recognition methods to extract music score and text information. Validation tests have shown that the new system handles overlapping cases and is therefore capable of extracting more information than other existing methods.","1935-4576;19354576","Electronic:978-1-4799-6649-3; POD:978-1-4799-6650-9; USB:978-1-4799-6648-6","10.1109/INDIN.2015.7281886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281886","Audio information retrieval;classification;feature extraction;machine learning;non-exclusive classification;segmentation;semantic audio","Multiple signal classification;Music;Noise;Semantics;Speech;Speech enhancement;Speech recognition","audio signal processing;information retrieval;music;speech processing;speech recognition","MARSYAS framework;Music Analysis-Retrieval-and-Synthesis for Audio Signals;mixed soundtracks;music score extraction;recognition methods;semantic information extraction;sound score;speech cleaning algorithms;text information extraction;timestamp","","","","23","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Literature Visualization and Similarity Measurement Based on Citation Relations","H. Alfraidi; W. S. Lee; D. Sankoff","Sch. of Electr. Eng. & Comput. Sci., Univ. of Ottawa, Ottawa, ON, Canada","2015 19th International Conference on Information Visualisation","20150921","2015","","","217","222","While similar documents are, traditionally, found using Natural Language Processing, we observe reference/citation information by authors indicates better insight of similarity. Our system is to retrieve publications from Google Scholar and visualize them as a 2D graph using the citation relation, where the nodes represent the documents while the links represent the citation/reference relation between them. We measure the similarity score between each pair of papers based on both the number of paths and the length of each path. More paths and shorter the lengths higher the similarity score. We compared them with another similarity scores from Scurtu's Document Similarity API [1] that uses Natural Language Processing. We use the average of the similarity scores collected from 15 users as a ground truth to determine how good the scores from two methods are. The result shows that our citation network approach gives better results than the ones by Scurtu's.","1550-6037;15506037","Electronic:978-1-4673-7568-9; POD:978-1-4673-7569-6","10.1109/iV.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272605","Citation Network;Information Retrieval;Information Visualization;Similarity Measures","Correlation;Data visualization;Google;Layout;Length measurement;Search engines;Visualization","citation analysis;data visualisation;document handling;natural language processing","2D graph visualization;Google Scholar;Scurtu document similarity API;application program interface;citation information;citation relations;document representation;literature visualization;natural language processing;reference information;similarity measurement;similarity score","","","","18","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Design Concepts of a KnowledgeBase System for Research and Studies in Quran and Its Science","A. Arbaoui; M. Menacer; Y. M. Alginahi","IT Res. Centre for the Holy Quran & its Sci., Taibah Univ., Medina, Saudi Arabia","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","387","390","There is a wealth of research and studies related to Quran and its Sciences that are largely not available online. Usually researchers, in these fields, contact relevant and specific organizations for such information, if they become aware that such journals or proceedings are available/exist through those organizations. Therefore, in most cases thousands of research work tend to be shelved and not properly referenced for online use. This is the main reason why many Quran and Islamic related research works and studies are not well cited, and difficult to search or find online. This research paper presents the design concepts of a customized knowledgebase system that would be used as a knowledge management of research and studies in Quran and its related Sciences, named Quran Research Knowledge Base (QKB). The proposed knowledgebase system provides a mean for information to be collected, organized, and shared for the benefit of researchers as well as organizations, and government agencies. The knowledgebase content is categorized based on Quran and its related sciences research papers, conferences, books, post-graduate thesis and publications, web publishing, products, and other materials. The finalized knowledgebase system is integrated with other systems such as eConferences, online journals and other Virtual Learning systems. The methodology and procedures for populating the knowledgebase with authenticated and accurate content, are also presented.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277279","Knowledge base;data classification;data collection;data extraction;information retrieval;meta data","Collaboration;Media;Metadata;Multimedia communication;Organizations;Search engines","humanities;knowledge based systems","Islamic related research works;QKB;Quran research knowledge base;e-conferences;knowledge management;knowledge-base system;online journals;virtual learning systems","","","","7","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Novel Hierarchical Convolutional Neural Network for Question Answering over Paragraphs","S. Zheng; H. Bao; J. Zhao; J. Zhang; Z. Qi; H. Hao","Inst. of Autom., Beijing, China","2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)","20160204","2015","1","","60","66","The question of classical Factoid Question Answering (FQA) task is always in the form of a single sentence. There also exists another kind of FQA task, whose question is a descriptive paragraph, such as quiz bowl question answering. Recently, some works try to automatically answer paragraph questions by applying machine learning methods. However, these methods neglect the correlation information between sentences in a paragraph and do not take full advantage of answer embedding information. In this paper, we propose a novel Hierarchical Convolutional Neural Network, called HCNN-E, to settle the task by considering ordinal information of sentences in paragraph and the information of answer embeddings. The experimental results on two public datasets demonstrate the effectiveness of proposed method, and the proposed method can achieve approximately 10% - 20% improvements, when comparing with the baselines.","","Electronic:978-1-4673-9618-9; POD:978-1-4673-9619-6","10.1109/WI-IAT.2015.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7396780","Convolutional Neural Network;Information Retrieval;Question Answering;Text Mining","Cities and towns;Computer architecture;Data models;Knowledge discovery;Recurrent neural networks;Semantics","data mining;neural nets;question answering (information retrieval);text analysis","FQA;HCNN-E;descriptive paragraph;factoid question answering;hierarchical convolutional neural network;sentence ordinal information;text mining","","","","34","","","6-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Family of Rank Similarity Measures Based on Maximized Effectiveness Difference","L. Tan; C. L. A. Clarke","School of Computer Science, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Knowledge and Data Engineering","20151005","2015","27","11","2865","2877","Rank similarity measures provide a method for quantifying differences between search engine results without the need for relevance judgments. For example, the providers of a search service might use such measures to estimate the impact of a proposed algorithmic change across a large number of queries-perhaps millions-identifying those queries where the impact is greatest. In this paper, we propose and validate a family of rank similarity measures, each derived from an associated effectiveness measure. Each member of the family is based on the maximization of effectiveness difference under this associated measure. Computing this maximized effectiveness difference (MED) requires the solution of an optimization problem that varies in difficulty, depending on the associated measure. We present solutions for several standard effectiveness measures, including nDCG, AP, and ERR. Through an experimental validation, we show that MED reveals meaningful differences between retrieval runs. Mathematically, MED is a metric, regardless of the associated measure. Prior work has established a number of other desiderata for rank similarity in the context of search, and we demonstrate that MED satisfies these requirements. Unlike previous proposals, MED allows us to directly translate assumptions about user behavior from any established effectiveness measure to create a corresponding rank similarity measure. In addition, MED cleanly accommodates partial relevance judgments, and if complete relevance information is available, it reduces to a simple difference between effectiveness values.","1041-4347;10414347","","10.1109/TKDE.2015.2448541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130638","Search;effectiveness measures;information retrieval;rank similarity;search engines","Correlation;Gain measurement;Mathematical model;Optimization;Search engines;Standards","optimisation;query processing;search engines","AP;ERR;MED;maximized effectiveness difference;nDCG;optimization problem;queries;rank similarity measures;search engine","","1","","42","","20150622","Nov. 1 2015","","IEEE","IEEE Journals & Magazines"
"Advanced Search Feature in Noble Quran","A. Chelli; A. Balla; T. Zerrouki","Ecole Nat. Superiure d'Inf., Algeria","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","681","699","The Quran is a sacred book to all Muslims which contains a variety of information about all aspects of life: Scientific, Social, Historic and Political based knowledge. The Quran is extremely dynamic and consists of a unique structure within a distinctive language. It contains an immense, vast range of information, which can only be extracted in small parts. The printed indexes can't help much since many search processes waste the time and the effort of the researcher. The simple search using exact query does not offer realistic options and still highly inefficient to move toward the thematic search for example. Due to this limitation, the need to find a more practical method to query is evident. Our proposal is to design an information retrieval system that fits to the specific needs of the Quran. But to realize this objective, we must first list and classify all the search features that are possible and helpful, this paper has been written to explain this point. In order to evaluate the proposed list, we have made a survey about the importance of, the need for, and the clarity of each feature. The collection and evaluation of search features is useful to organize them and make easier the discussion, the study, and the implementation.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277303","Search Features; Quran; Query; Arabic; Information Retrieval; Search Engine","Data mining;Indexes;Information technology;Proposals;Search engines;Search problems","information retrieval systems;literature;natural language processing;query processing","Muslims;distinctive language;historic based knowledge;information retrieval system;noble Quran;political based knowledge;printed indexes;query method;sacred book;scientific based knowledge;search features collection;search features evaluation;social based knowledge","","","","","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
