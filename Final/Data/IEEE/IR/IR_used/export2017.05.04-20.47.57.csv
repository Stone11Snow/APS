"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7046050,7044871,7041674,7041717,7041558,7036699,7039611,7033460,7033770,7035959,7033167,7033761,7030588,7023378,7023388,7025187,7021826,7014961,7013152,6999177,7009116,7010811,7001462,7004324,7000277,6998367,6991426,6987729,6984300,6984189,6984316,6517848,6980901,6975936,6976066,6974397,6973703,6928887,6974324,6972100,6970125,6974626,6967112,6866179,6823723,6954258,6775274,6949274,6945717,6947073,6946717,6946812,6748036,6934176,6933548,6930613,6927560,6923751,6923752,6924623,6924642,6911461,6911523,6532281,6916220,6916331,6915441,6906015,6911367,6906789,6565320,6903241,6891820,6893251,6890857,6883114,6840822,6883891,6885421,6885371,6882038,6878830,6876992,6868623,6601708,6859755,6863127,6859768,6863128,6854974,6853679,6853672,6854196,6834820,6849847,6843353,6846921,6847483,6845863,6844186",2017/05/04 20:47:57
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An Indexing Network: Model and Applications","C. Jiang; H. Sun; Z. Ding; P. Wang; M. Zhou","Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20141113","2014","44","12","1633","1648","Internet data are heterogeneous, redundant, disordered, and exponentially growing. Finding the right information from them becomes an ever-challenging issue. Existing technologies such as inverted index and keyword matching can list user webpage matching with given search keywords. They cannot recognize potential relations among webpages to meet some rising user needs, e.g., exploratory search and personalized search. We propose an indexing network model that organizes information in webpages at three levels: words, webpages, and categories, thereby leading to a semantic association graph. Words are used as the description of webpages and categories. Webpage classification is used to gather similar webpages together. Hyperlinks imply the wisdom of the webpage creator, which can help us generate semantic relations among categories. With a clear organizational structure, an indexing network can provide support for many important applications including intelligent information retrieval, recommendation and decision support. In order to provide access to interfaces for the proposed indexing network, an indexing network algebra is defined. Finally, to validate the proposed model, an indexing network is generated based on 30 million webpages and its structure is analyzed. We also give methods to achieve “browsing navigation” and “personalized search” based on the generated network. Results reveal that the use of an indexing network can greatly facilitate exploratory information retrieval and personalized search.","2168-2216;21682216","","10.1109/TSMC.2014.2320695","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823723","Exploratory search;hyperlink;indexing network;webpage application;webpage management","Indexing;Information retrieval;Internet;Recommender systems;Search methods;Semantics;Web pages","Web sites;classification;indexing;information retrieval;text analysis","Internet data;Webpage classification;Webpage creator;Webpages information;browsing navigation;categories;decision support;hyperlinks;indexing network algebra;indexing network model;intelligent information retrieval;inverted index;keyword matching;organizational structure;personalized search;recommendation;search keywords;semantic association graph;semantic relations;user Webpage matching","","2","","45","","20140530","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"An Approach for Document Pre-processing and K Means Algorithm Implementation","G. S.; M. Goswami; B. K.; B. S. Purkayastha","Fac. of Eng., Christ Univ., Bangalore, India","2014 Fourth International Conference on Advances in Computing and Communications","20140929","2014","","","162","166","The web mining is a cutting edge technology, which includes information gathering and classification of information over web. This paper puts forth the concepts of document pre-processing, which is achieved by extraction of keywords from the documents fetched from the web, processing it and generating a term-document matrix, TF-IDF and the different approaches of TF-IDF (term frequency Inverse document frequency) for each respective document. The last step is the clustering of these results through K Means algorithm, by comparing the performance of each approach used. The algorithm is realized on an X64 architecture and coded on Java and Matlab platform. The results are tabulated.","","Electronic:978-1-4799-4363-0; POD:978-1-4799-4362-3","10.1109/ICACC.2014.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906015","K Means clustering;Stop words;augmented;frequency;logarithmic;stemming;term-document matrix;tf-idf","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Data mining;Information retrieval;Java;MATLAB","Internet;Java;classification;data mining;document handling;pattern clustering","Java;Matlab platform;TF-IDF;Web mining;World Wide Web;X64 architecture;cutting edge technology;document preprocessing;information classification;information gathering;k means algorithm implementation;term frequency inverse document frequency;term-document matrix","","0","","9","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"De-identification in natural language processing","V. Vincze; R. Farkas","MTA-SZTE Res. Group on Artificial Intell., Univ. of Szeged Szeged, Szeged, Hungary","2014 37th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20140724","2014","","","1300","1303","Natural language processing (NLP) systems usually require a huge amount of textual data but the publication of such datasets is often hindered by privacy and data protection issues. Here, we discuss the questions of de-identification related to three NLP areas, namely, clinical NLP, NLP for social media and information extraction from resumes. We also illustrate how de-identification is related to named entity recognition and we argue that de-identification tools can be successfully built on named entity recognizers.","","CD-ROM:978-953-233-081-6; Electronic:978-953-233-077-9; POD:978-1-4799-5657-9","10.1109/MIPRO.2014.6859768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6859768","","Databases;Educational institutions;Electronic mail;Informatics;Information retrieval;Media;Natural language processing","data privacy;natural language processing","NLP areas;NLP systems;data protection;information extraction;natural language processing;privacy protection;social media;textual data","","0","","15","","","26-30 May 2014","","IEEE","IEEE Conference Publications"
"Clustering Affective Qualities of Classical Music: Beyond the Valence-Arousal Plane","A. Rodà; S. Canazza; G. De Poli","Department of Information Engineering, University of Padova, Italy","IEEE Transactions on Affective Computing","20141124","2014","5","4","364","376","The important role of the valence and arousal dimensions in representing and recognizing affective qualities in music is well established. There is less evidence for the contribution of secondary dimensions such as potency, tension and energy. In particular, previous studies failed to find significant relations between computable musical features and affective dimensions other than valence and arousal. Here we present two experiments aiming at assessing how musical features, directly computable from complex audio excerpts, are related to secondary emotion dimensions. To this aim, we imposed some constraints on the musical features, namely modality and tempo, of the stimuli.The results show that although arousal and valence dominate for many musical features, it is possible to identify features, in particular Roughness, Loudness, and SpectralFlux, that are significantly related to the potency dimension. As far as we know, this is the first study that gained more insight into the affective potency in the music domain by using real music recordings and a computational approach.","1949-3045;19493045","","10.1109/TAFFC.2014.2343222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6866179","Music;affective dimensions;automated mood analysis;emotions;musical features;potency","Emotion recognition;Music;Music information retrieval;Physiology;Stress;User interfaces","behavioural sciences;music","affective dimensions;affective potency;affective qualities clustering;arousal dimensions;classical music;complex audio excerpts;computable musical features;energy;features identification;loudness;modality;potency dimension;real music recordings;roughness;secondary emotion dimensions;spectral flux;tempo;tension;valence dimensions;valence-arousal plane","","3","","55","","20140725","Oct.-Dec. 1 2014","","IEEE","IEEE Journals & Magazines"
"Ontology Based Heterogeneous Data Integration Framework Facing Mobile Environment","C. Xu; S. Yang; J. Huang; C. Ji","Coll. of Phys. Sci. & Technol., Dalian Univ., Dalian, China","2014 IEEE 12th International Conference on Dependable, Autonomic and Secure Computing","20141106","2014","","","367","371","In the context of cloud computing, Mobile Data Integration Platform is put forward, on this basis, we first study on SORE (Simplied Object Repository) system of heterogeneous data integration based on CORBA. Furthermore, by virtue of the design of Heterogeneous Data Source Wrapper, this paper introduces an ontology based distributed information integration framework(OIIF), it implements uniform semantic query on heterogeneous data and enhances the depth and scope of available information. OIIF is innovation, its study has practical significance.","","CD-ROM:978-1-4799-5078-2; Electronic:978-1-4799-5079-9; POD:978-1-4799-5080-5","10.1109/DASC.2014.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945717","Data Integration;Mobile Cloud Computing;Ontology","Cloud computing;Data integration;Educational institutions;Information retrieval;Mobile communication;Ontologies;Semantics","data integration;distributed object management;mobile computing;ontologies (artificial intelligence)","CORBA;OIIF;SORE;cloud computing;distributed information integration framework;heterogeneous data integration;heterogeneous data source wrapper;mobile data integration platform;ontology;semantic query;simplied object repository system","","0","","14","","","24-27 Aug. 2014","","IEEE","IEEE Conference Publications"
"Information Extraction of Strategic Activities Based on Semi-structured Text","X. Ma; J. e. Guo","Sch. of Manage., Xi'an jiaotong Univ., Xi'an, China","2014 Seventh International Joint Conference on Computational Sciences and Optimization","20141016","2014","","","579","583","The paper constructed the information extraction method to extract description characteristic of execution process from the description text to provide data support for the evaluation of enterprise strategy execution effectiveness. The constructed information extraction method included two stages, i.e., Feature information extraction and information integration. It overcame some weaknesses of the current information extraction technology, such as its mere use for extracting time, address and other named entities. Firstly, the information extraction process of descriptive information is designed through establishing substantial GATE vocabularies and compiling ordinary and special extraction rules to avoid the disadvantages of the identification of GATE in Chinese named entity. Then, rules of integration of description characteristics information are established on the basis of semantic relation, positional relation to structurally represent the process of executing strategic activities.","","Electronic:978-1-4799-5372-1; POD:978-1-4799-5373-8","10.1109/CSO.2014.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6923752","information extraction;information integration;semi-structured text","Authorization;Data mining;Educational institutions;Feature extraction;Information retrieval;Logic gates;Psychology","information retrieval;learning (artificial intelligence);text analysis","Chinese named entity;GATE vocabulary;description text;descriptive information;enterprise strategy execution effectiveness;extraction rules;feature information extraction;information extraction method;information integration;positional relation;semantic relation;semistructured text;strategic activity","","0","","14","","","4-6 July 2014","","IEEE","IEEE Conference Publications"
"Music segment similarity using 2D-Fourier Magnitude Coefficients","O. Nieto; J. P. Bello","Music & Audio Res. Lab., New York Univ., New York, NY, USA","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20140714","2014","","","664","668","Music segmentation is the task of automatically identifying the different segments of a piece. In this work we present a novel approach to cluster the musical segments based on their acoustic similarity by using 2D-Fourier Magnitude Coefficients (2D-FMCs). These coefficients, computed from a chroma representation, significantly simplify the problem of clustering the different segments since they are key transposition and phase shift invariant. We explore various strategies to obtain the 2D-FMC patches that represent entire segments and apply k-means to label them. Finally, we discuss possible ways of estimating k and compare our competitive results with the current state of the art.","1520-6149;15206149","Electronic:978-1-4799-2893-4; POD:978-1-4799-2894-1; USB:978-1-4799-2892-7","10.1109/ICASSP.2014.6853679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6853679","2D-Fourier Transform;Clustering;Music Segmentation","Multiple signal classification;Music;Music information retrieval;Speech;Speech processing;Vectors","Fourier transforms;acoustic signal processing;audio signal processing;learning (artificial intelligence);music;pattern clustering;signal representation","2D-FMC;2D-Fourier magnitude coefficients;acoustic similarity;chroma representation;k-means algorithm;music segment similarity;music segmentation;segment clustering","","2","","24","","","4-9 May 2014","","IEEE","IEEE Conference Publications"
"Using syntactic parsing for geographical names extraction on the example of newspaper articles","A. Arefina","PROMT, Saint-Petersburg, Russia, 199155, 17E Uralskaya str. building 3","2014 International Conference on Computer Technologies in Physical and Engineering Applications (ICCTPEA)","20140908","2014","","","14","14","We consider the problem of geographical names extraction in arbitrary text. We describe a method of extracting geographical names using syntactic information obtained by PROMT syntactic parser. The method performance is evaluated on a newspaper text corpus.","","Electronic:978-1-4799-5317-2; POD:978-1-4799-5318-9; USB:978-1-4799-5316-5","10.1109/ICCTPEA.2014.6893251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893251","","Buildings;Data mining;Electronic mail;Europe;Information retrieval;Semantics;Syntactics","computational linguistics;grammars;information retrieval;text analysis","PROMT syntactic parser;arbitrary text;geographical names extraction;newspaper articles;newspaper text corpus;syntactic information;syntactic parsing","","0","","2","","","June 30 2014-July 4 2014","","IEEE","IEEE Conference Publications"
"PSaD: A Privacy-Preserving Social-Assisted Content Dissemination Scheme in DTNs","L. Guo; C. Zhang; H. Yue; Y. Fang","Department of Electrical and Computer Engineering, University of Florida, Gainesville","IEEE Transactions on Mobile Computing","20141029","2014","13","12","2903","2918","Content dissemination is very useful for many mobile applications, like instant messaging, file sharing, and advertisement broadcast, etc. In real life, for various kinds of time-insensitive contents, such as family photos and video clips, the process of content dissemination forms a delay tolerant networks (DTNs). To improve the data forwarding performance in DTNs, several social-based approaches have been proposed, most of which leverage mobile users' social information, including contact history, moving trajectory, and personal profiles as metrics to design routing schemes. However, although the social-based approaches provide better performance, the revealing of mobile users' information apparently compromises their privacy. Moreover, users' contents may only be shared with a particular group of users rather everyone in the system. In this paper, we propose the PSaD: a Privacy-preserving Social-assisted content Dissemination scheme in DTNs. We apply users' verifiable attributes to establish their social relationships in terms of identical attributes in a privacy-preserving way. Besides, to provide the confidentiality of contents, our approach enables users to encrypt contents before the dissemination process, and only allows users who have particular attributes to decrypt them. By trace-driven simulations and experiments, we show the performance, privacy preservation, and efficiency of our proposed scheme.","1536-1233;15361233","","10.1109/TMC.2014.2308177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6748036","Content dissemination;delay tolerant networks;privacy;social networks","Encryption;Fault tolerance;Information retrieval;Mobile communication;Privacy;Routing;Social network services","computer network security;data privacy;mobile communication;telecommunication network routing","DTN;PSaD;advertisement broadcast;computer networks;content encryption;data forwarding performance;delay tolerant networks;file sharing;instant messaging;mobile applications;mobile user social information;privacy preserving social assisted content dissemination scheme;routing schemes;time insensitive contents","","5","","34","","20140225","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Big Data Processing with Probabilistic Latent Semantic Analysis on MapReduce","Y. Zhao; Y. Chen; Z. Liang; S. Yuan; Y. Li","Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","2014 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20141215","2014","","","162","166","Probabilistic Latent Semantic Analysis (PLSA) is a powerful statistical technique to analyze co-occurrence data, it has wide usage in information processing, ranging from information retrieval, information filtering, text processing automation, to natural language processing, and related areas. However, it has very high time and space complexity to train PLSA model on big data. Researchers have been trying to solve this problem using parallel means. But their approaches only partially reduce the time complexity, the main memory in the compute process still needs to load a large amount of data. In order to solve the scalability problem of data, a parallel method to train PLSA is proposed by adapting the traditional EM algorithm into MapReduce a computing framework for processing vast amounts of data in-parallel on clusters. In this way, the main memory in each computer just needs to load part of the dataset. This method can reduce time and space complexity simultaneously. Results show that this method can deal with large datasets efficiently.","","Electronic:978-1-4799-6236-5; POD:978-1-4799-6237-2","10.1109/CyberC.2014.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984300","MapReduce;Parallelism;Probabilistic Latent Semantic Analysis;Scalablity","Computational modeling;Information retrieval;Load modeling;Mathematical model;Probabilistic logic;Semantics;Training","Big Data;computational complexity;expectation-maximisation algorithm;parallel programming;probability","Big Data processing;EM algorithm;MapReduce;PLSA model training;co-occurrence data analysis;computing framework;data scalability problem;information filtering;information processing;information retrieval;main memory;natural language processing;parallel method;probabilistic latent semantic analysis;space complexity;statistical technique;text processing automation;time complexity","","0","","16","","","13-15 Oct. 2014","","IEEE","IEEE Conference Publications"
"Intelligent question — Answering systems: Review of research","J. Tomljanović; M. Pavlić; M. A. Katić","Polytech. of Rijeka, Rijeka, Croatia","2014 37th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20140724","2014","","","1228","1233","With the development of ICT the need for automated question-answering systems is becoming increasingly important. Question-answering systems are still under development and experimentation. This paper is an overview of the research area that deals with question-answering systems; it explains the concept of question-answering systems and points out the problems that occur during their development. It also refers to a complex assessment techniques that are necessary when designing such systems. The system described is a real system and so are the test results.","","CD-ROM:978-953-233-081-6; Electronic:978-953-233-077-9; POD:978-1-4799-5657-9","10.1109/MIPRO.2014.6859755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6859755","artificial intelligence;question-answering systems;technology assessment question-answering systems","Complexity theory;Context;Encyclopedias;Information retrieval;Internet;Knowledge discovery;Testing","artificial intelligence;question answering (information retrieval)","ICT development;artificial intelligence;complex assessment techniques;intelligent question-answering systems;technology assessment question-answering systems","","2","","28","","","26-30 May 2014","","IEEE","IEEE Conference Publications"
"Proposal of interactive document clustering system based on coordinated multiple views","T. Tonegawa; Y. Takama","Graduate School of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan","2014 IEEE 7th International Workshop on Computational Intelligence and Applications (IWCIA)","20141218","2014","","","19","22","This paper proposes an interactive document clustering system based on coordinated multiple views (CMV). Recently, the amount of documents has become extremely large, which makes it difficult for a user to under-stand relationship between documents and topics mentioned in a set of documents. In order to support a user, interactive clustering is a promising approach. When designing an interactive clustering system, it should be considered that a user has to examine clustering result from various levels such as clusters, documents, and words. The proposed system divides documents into four levels and displays each level in parallel with different views. By designing coordination among those views, a user can understand document information from various levels and perform interactive clustering efficiently.","1883-3977;18833977","Electronic:978-1-4799-4770-6; POD:978-1-4799-4769-0; USB:978-1-4799-6828-2","10.1109/IWCIA.2014.6987729","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987729","coordinated multiple views (CMV);interactive document clustering;visualization","Artificial intelligence;Clustering algorithms;Data visualization;Information retrieval;Prototypes;Text mining","data visualisation;document handling;interactive systems;pattern clustering","CMV;coordinated multiple views;interactive document clustering system","","0","","14","","","7-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"Study on the precision evaluation index in building seismic damage information extraction from remote sensing image","Z. Li; A. Dou; X. Wang","Institute of Earthquake Science, China Earthquake Administration, Beijing, 100036, China","2014 IEEE Geoscience and Remote Sensing Symposium","20141106","2014","","","2862","2865","Precision evaluation is an important step in remote sensing classification. The Kappa is widely used to evaluate the overall accuracy of classification result, but it cannot reflect the classification effect of a certain class. A new precision evaluation index R can apply to evaluate the accuracy of a certain category in classification image. In this paper, we extracted building damage information based on object-oriented method, and discussed the effect and robust of index R and Kappa when different categories of the classification result were involved in precision evaluation. The study shows that the standardized index R can reflect the efficiency of the classification result more stably and it has certain advantages in classification evaluation.","2153-6996;21536996","Electronic:978-1-4799-5775-0; POD:978-1-4799-5314-1; USB:978-1-4799-5774-3","10.1109/IGARSS.2014.6947073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6947073","Kappa;Remote sensing classification;index R;precision evaluation","Accuracy;Buildings;Earthquakes;Indexes;Information retrieval;Remote sensing;Roads","seismology","building damage information;classification evaluation;classification result;evaluation index;object-oriented method;precision evaluation;precision evaluation index;remote sensing classification;remote sensing image;seismic damage information extraction;standardized index","","0","","11","","","13-18 July 2014","","IEEE","IEEE Conference Publications"
"User Interest Modeling for P2P Document Sharing Systems Based on K-Medoids Clustering Algorithm","C. Qin; Z. Yang; H. Liu","Sch. of Econ. & Manage., Xidian Univ., Xi'an, China","2014 Seventh International Joint Conference on Computational Sciences and Optimization","20141016","2014","","","576","578","User interest modeling is an important way for P2P document sharing systems to improve the level of information service such as personalized information retrieval and document recommendation. Based on K-medoids clustering, the paper presents a method of user interest modeling for P2P document sharing systems. Staring from the perspective of the shared document, the proposed approach creates the initial user interest model with k-mediods clustering algorithm. Then, combining with the related results of user's historical queries, the initial user interest model is improved and complete user interest model is obtained.","","Electronic:978-1-4799-5372-1; POD:978-1-4799-5373-8","10.1109/CSO.2014.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6923751","P2P document sharing system;k-medoids clustering algorithm;user interest model","Clustering algorithms;Computational modeling;Educational institutions;Information retrieval;Information services;Peer-to-peer computing;Vectors","pattern clustering;peer-to-peer computing;query processing;user modelling","P2P document sharing systems;document recommendation;information service level;k-mediods clustering algorithm;personalized information retrieval;user historical queries;user interest modeling","","0","","5","","","4-6 July 2014","","IEEE","IEEE Conference Publications"
"Where in the World Is My Information?: Giving People Access to Their Data","K. Evans","Office of the New Zealand Privacy Commissioner","IEEE Security & Privacy","20141015","2014","12","5","78","81","Willis Ware and his committee developed their principles in a world where business and government information systems were very different from today's interconnected and complex environment. They foresaw that the rise of computer information processing capability would place more strain on individual privacy, but they would have been hard-pressed to see just how far that capability would go. We're living in revolutionary times, but the reason for the principles--particularly the right to access information--is as sound and fundamental as it ever was.","1540-7993;15407993","","10.1109/MSP.2014.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6924623","Willis Ware;big data;government;privacy;security","Access control;Authentication;Data mining;Information retrieval;Law;Privacy","data handling;data privacy;information systems","business information systems;computer information processing capability;data access;government information systems;individual privacy;revolutionary times","","0","","","","","Sept.-Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Improving event extraction using online learning strategy","J. Chen","School of Information Science and Engineering, Xiamen university, Xiamen, P.R. China 361005","2014 11th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20141211","2014","","","593","597","The traditional mention-oriented model for event extraction cannot capture information of multiple event types in a sentence. To deal with this problem, we present a novel intensive model for event extraction task. Firstly, the model can filter out non-event sentences automatically by introducing some meaningful language features. Then, the model adopts an online learning strategy for event type ranking, which provides an alternative view of event type identification as multi-label classification so that we can achieve a predicted set of relevant event types for each sentence. The experimental evaluation verified that the model can improve the performance of the event extraction task.","","Electronic:978-1-4799-5148-2; POD:978-1-4799-5149-9","10.1109/FSKD.2014.6980901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980901","","Event detection;Feature extraction;Information retrieval;Machine learning algorithms;Prototypes;Support vector machines;Training","information filtering;learning (artificial intelligence);natural language processing;pattern classification","event extraction;event type identification;event type ranking;intensive model;mention-oriented model;multilabel classification;nonevent sentence filtering;online learning strategy","","0","","23","","","19-21 Aug. 2014","","IEEE","IEEE Conference Publications"
"Multimodal Music and Lyrics Fusion Classifier for Artist Identification","K. Aryafar; A. Shokoufandeh","Comput. Sci. Dept., Drexel Univ., Philadelphia, PA, USA","2014 13th International Conference on Machine Learning and Applications","20150209","2014","","","506","509","Humans interact with each other using different communication modalities including speech, gestures and written documents. In the absence of one modality or presence of a noisy modality, other modalities can benefit precision of systems. HCI systems can also benefit from these multimodal communication models for different machine learning tasks. The provision of multiple modalities is motivated by usability, presence of noise in one modality and non-universality of a single modality. Combining multimodal information introduces new challenges to machine learning such as designing fusion classifiers. In this paper we explore the multimodal fusion of audio and lyrics for music artist identification. We compare our results with a single modality artist classifier and introduce new directions for designing a fusion classifier.","","Electronic:978-1-4799-7415-3; POD:978-1-4799-7416-0; USB:978-1-4799-7414-6","10.1109/ICMLA.2014.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033167","audio;classification;multimodal;sparse methods","Accuracy;Kernel;Mel frequency cepstral coefficient;Music;Music information retrieval;Semantics;Sparse matrices","audio signal processing;human computer interaction;learning (artificial intelligence);music;pattern classification","HCI systems;artist identification;communication modalities;human-computer interaction;machine learning tasks;multimodal communication models;multimodal music lyrics fusion classifier;noisy modality;single modality artist classifier","","1","","19","","","3-6 Dec. 2014","","IEEE","IEEE Conference Publications"
"Search in the universe of big networks and data","E. Gelenbe; O. H. Abdelrahman","Dept. oF Electr. & Electron. Eng., Imperial Coll., London, London, UK","IEEE Network","20140724","2014","28","4","20","25","Searching the Internet for some object characterized by its attributes in the form of data, such as a hotel in a certain city whose price is lower than some amount, is one of our most common activities when we access the web. We discuss this problem in a general setting, and compute the average amount of time and energy it takes to find an object in an infinitely large search space. We consider the use of N search agents that act concurrently in both the case where the search agent knows which way it needs to go to find the object, and the case where the search agent is completely ignorant and may even head away from the object being sought. We show that under mild conditions regarding the randomness of the search and the use of a time-out, the search agent will always find the object in spite of the fact that the search space is infinite. We obtain a formula for the average search time and the average energy expended by N search agents acting concurrently and independent of each other. We see that the time-out itself can be used to minimize the search time and the amount of energy that is consumed to find an object. An approximate formula is derived for the number of search agents that can help us guarantee that an object is found in a given time, and we discuss how the competition between search agents and other agents that try to hide the data object can be used by opposing parties to guarantee their own success.","0890-8044;08908044","","10.1109/MNET.2014.6863127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6863127","","Approximation methods;Computers;Information retrieval;Internet;Probability density function;Search methods;Search problems","Big Data;Internet;information retrieval","Big Data;Internet searching;Web access;average energy;average search time;big networks;data object;infinite search space;search agents;search randomness","","5","","24","","","July-August 2014","","IEEE","IEEE Journals & Magazines"
"An Empirical Study of the Effects of Expert Knowledge on Bug Reports","D. Huo; T. Ding; C. McMillan; M. Gethers","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","1","10","Bug reports are crucial software artifacts for both software maintenance researchers and practitioners. A typical use of bug reports by researchers is to evaluate automated software maintenance tools: a large repository of reports is used as input for a tool, and metrics are calculated from the tool's output. But this process is quite different from practitioners, who distinguish between reports written by experts such as programmers, and reports written by non-experts such as users. Practitioners recognize that the content of a bug report depends on its author's expert knowledge. In this paper, we present an empirical study of the textual difference between bug reports written by experts and non-experts. We find that a significance difference exists, and that this difference has a significant impact on the results from a state-of-the-art feature location tool. Our recommendation is that researchers evaluate maintenance tools using different sets of bug reports for experts and non-experts.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976066","bug reports;empirical study;expert knowledge","Computer bugs;Information retrieval;Maintenance engineering;Measurement;Semantics;Software maintenance","program debugging;software maintenance;software metrics","automated software maintenance tool evaluation;bug report content;empirical analysis;expert knowledge;feature location tool;large-report repository;software artifacts;software maintenance practitioners;software maintenance researchers;software metrics;textual difference","","3","","85","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"Instant Recommendation for Web Services Composition","L. Chen; J. Wu; H. Jian; H. Deng; Z. Wu","College of Computer Science, Zhejiang University, China","IEEE Transactions on Services Computing","20141212","2014","7","4","586","598","Web service composition helps users integrate services to create new large-granularity and value-added composite services. Most recent studies have focused on automatic AI-Planning-based static or dynamic composition at functional- or process-level. However in industry, most business applications are still composed manually or semi-automatically with abundant domain expertise. Consequently, to build a good and reliable composite service is really a time-consuming and professional task. Inspired by the Instant Search of Google, we propose an Instant recommendation approach to provide optimal suggestions while a composition process incrementally proceeds. In our model, we fully utilize the execution log of composite services, and intend to identify appropriate services which have been proved to be more reliable and robust, therefore those services have higher probability to fulfill users' demands. To find the top-k possible composite services in real-time, we adopt the A* search algorithm with various pruning heuristics to dynamically expand the search space efficiently. Experiments on a real-world dataset with 15,959 real Web services crawled from the Internet demonstrate the effectiveness and efficiency of the proposed approach.","1939-1374;19391374","","10.1109/TSC.2013.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517848","<formula formulatype=""inline""><tex Notation=""TeX"">${rm A}^{ast}$</tex></formula>;Bayes;Composite service;instant recommendation","Algorithm design and analysis;Information retrieval;Internet;Quality of service;Time complexity;Web services","Web services;recommender systems;search problems","A* search algorithm;Google Instant Search;Web service composition;business applications;dynamically searched space expansion;execution log;incrementally proceeded composition process;instant recommendation approach;large-granularity value-added composite services;optimal suggestions;pruning heuristics;real Web service crawling;real-world dataset;service integration;top-k possible composite services;user demands","","7","","32","","20130521","Oct.-Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Job Recruitment and Job Seeking Processes: How Technology Can Help","P. Montuschi; V. Gatteschi; F. Lamberti; A. Sanna; C. Demartini","Politecnico di Torino, Italy","IT Professional","20140924","2014","16","5","41","49","This survey of current job search and recruitment tools focuses on applying a computer-based approach to job matchmaking. The authors present a semantic-based software platform, LO-MATCH--developed in the framework of a European project on lifelong learning--that highlights future research directions. There are three related Web extras that provide supplemental material. The first video [http://youtu.be/yi9gNd_9g8E] introduces job matchmaking and the LO-MATCH platform. The second video [http://youtu.be/OGQ26dM_KjQ] shows how semantic technologies can be used in a job matchmaking scenario. The third video [http://youtu.be/l7j-7_5gFVU] demonstrates the LO-MATCH job matchmaking platform.","1520-9202;15209202","","10.1109/MITP.2013.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6565320","Internet/Web technologies;Web platform;computer-supported job matchmaking;data analysis;information technology;learning outcome-based annotation;semantics","Career development;Computational modeling;Information analysis;Information retrieval;Object oriented modeling;Ontologies;Recruitment;Search methods;Semantics","Internet;business data processing;recruitment","European project;LO-MATCH platform;Web extras;computer based approach;job matchmaking;job recruitment process;job search;job seeking processes;recruitment tools","","3","","12","","20130722","Sept.-Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Studying the effects of conflicting tokenization on LSA dimension reduction","M. Fahsi; S. M. Benslimane","Computer Science Departement, EEDIS Laboratory, Djillali Liabes University, Sidi Bel Abbes, Algeria","2014 International Conference on Multimedia Computing and Systems (ICMCS)","20140929","2014","","","542","546","With the growing needs of dimension reduction for term selection and recommendation and the up to date trends in natural language processing modules integrated in existing architectures and multiple semantic web system such as search engine. The existence of multiples tokenization techniques of the same text represents a persistent problem in current semantic search engine practice and create a non-trivial problem the query expansion and their efficiency in general. In this work we try to study the effect of the tokenization technique in context of query expansion terms selection within a statistical latent semantic indexing. Finally we talk about the results from a corpuslinguistic point of view.","","CD-ROM:978-1-4799-3823-0; Electronic:978-1-4799-3824-7; POD:978-1-4799-3825-4","10.1109/ICMCS.2014.6911367","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911367","Dimension Reduction;LSA;Query Expansion;Tokenisation","Context;Indexing;Information retrieval;Large scale integration;Matrix decomposition;Semantics;Vectors","indexing;natural language processing;query processing;search engines;semantic Web;statistical analysis","LSA dimension reduction;conflicting tokenization;multiples tokenization technique;natural language processing module;query expansion;search engine;semantic Web system;statistical latent semantic indexing","","0","","20","","","14-16 April 2014","","IEEE","IEEE Conference Publications"
"Towards a Plug-and-Play B2B Marketing Tool Based on Time-Sensitive Information Extraction","M. Callery; F. H. III; R. Hull; M. Linehan; P. Sukaviriya; R. Vaculin; D. Oppenheim","IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA","2014 IEEE International Conference on Services Computing","20141020","2014","","","821","828","The LARIAT system developed at IBM Research uses information extraction applied to news feeds and other time-sensitive documents, along with historical and enterprise data, to provide a stream for B2B sales leads to different sales teams. This paper overviews the system and discusses lessons learned. LARIAT is contrasted with the IBM infoSage system from almost two decades ago. The experience with LARIAT is used as the basis for the design of a Solution-as-a-Service framework that will enable a richly extensible version of the capability, which could serve multiple B2B companies while affording economies of scale.","","Electronic:978-1-4799-5066-9; POD:978-1-4799-5067-6","10.1109/SCC.2014.111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6930613","AQL;B2B;Information extraction;Marketing;Software-as-a-Service;Solution-as-a-Service;unstructured data","Companies;Data mining;Feeds;Filtering;Information retrieval;Semantics","cloud computing;data mining;economies of scale;information retrieval;marketing data processing;sales management","B2B companies;B2B sales leads;IBM Research;IBM infoSage system;LARIAT system;economies of scale;enterprise data;historical data;news feed;plug-and-play B2B marketing tool;sales teams;solution-as-a-service framework;time-sensitive document;time-sensitive information extraction","","0","","18","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"Latent keyphrase generation by combining contextually similar primitive words","T. Cho; H. Cho; J. Lee; J. H. Lee","Department of Electrical and Computer Engineering Sungkyunkwan University Suwon, Republic of Korea","2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)","20150219","2014","","","600","604","As the number of document resources is continuously increasing, automatically extracting keyphrases from a document becomes one of the main issues in recent days. However, most previous work overlook keyphrases which is nonexistent in the document. Although latent keyphrases do not appear in the document, it can be important because it represents the meaningful concepts or keypoints of the document. We have discovered that the portion of latent keyphrases is more than one fourth of the entire keyphrases. Latent keyphrases also take an important role as much as existential keyphrases in documents. In this paper, we propose an approach to find latent keyphrases of a document in a given document set. The main idea of this approach is to generate keyphrase by choosing primitive words and combining them considering their context in documents. Experiment result shows that latent keyphrase can be extracted by our approach.","","Electronic:978-1-4799-5955-6; POD:978-1-4799-5956-3; USB:978-1-4799-5954-9","10.1109/SCIS-ISIS.2014.7044871","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044871","contextual similiarity;keyphrase generation;neighbor document;primitive word combination","Computational linguistics;Context;Equations;Feature extraction;Information retrieval;Mathematical model;Semantics","feature extraction;feature selection;word processing","document resource;latent keyphrase extraction;latent keyphrase generation;primitive word selection","","1","","20","","","3-6 Dec. 2014","","IEEE","IEEE Conference Publications"
"Supervised low dimensional embedding for multi-label classification","Zi-Jie Chen; Zhi-Feng Hao","School of Medical Business, Guangdong Pharmaceutical University, Guangzhou 510006, China","2014 International Conference on Machine Learning and Cybernetics","20150115","2014","1","","193","199","In multi-label classification, discovering label structures or label correlations when learning can improve predictive performance and time complexity. In this paper, a unified framework is proposed to incorporate the supervised correlation exploration with the predictive model. In the framework, feature mappings to a low-dimensional subspace is obtained through a linear transformation guided by the label information. And a multi-label classifier is simultaneously built on the projected features. The framework leads to a trace optimization problem which can be solved by a generalized eigenvalue problem. Meanwhile, the dual form of the framework is presented to deal with different problems. Experiments on four datasets show that the proposed framework can achieve comparable performance with four other well-known methods, and achieve better performance when label correlations are important. It's also demonstrated that the framework is efficient when the dimensionality is low, and the dual form will be more efficient without extra computational tricks in the small-sample problems.","2160-133X;2160133X","CD-ROM:978-1-4799-4217-6; Electronic:978-1-4799-4215-2; POD:978-1-4799-4214-5","10.1109/ICMLC.2014.7009116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009116","Feature Mapping;Generalized Eigenvalue Problems;Latent Label Correlations;Low-dimensional Subspace;Multi-label Classification;Supervised Correlation Exploration","Abstracts;Classification algorithms;Information retrieval;Measurement;Probabilistic logic","eigenvalues and eigenfunctions;learning (artificial intelligence);optimisation;pattern classification","generalized eigenvalue problem;label correlations;linear transformation;multilabel classification;predictive model;supervised correlation exploration;supervised low dimensional embedding;trace optimization problem","","0","","14","","","13-16 July 2014","","IEEE","IEEE Conference Publications"
"Algorithm Research about Textual Case Retrieval Based on Topic Words","L. Tang; Y. Wang; Y. Zhu; K. Tao; Y. Feng; Y. Guan","Sch. of Geomatics, Liaoning Tech. Univ., Fuxin, China","2013 International Conference on Information Science and Cloud Computing Companion","20141204","2013","","","875","880","Several shortages of Boolean retrieval, such as ignorance of the semantic relations among words and inability to rank the retrieval results in order of importance, are found by analyzing the essence of traditional text retrieval, in view of which an improvement of algorithm optimization based on topic words is proposed. Through enriching topic words to structure keywords library, the semantic distance and similarity of keywords are calculated on the basis of semantic retrieval framework. The improved algorithm is applied in the disaster case retrieval system at last, which retrieval results are then analyzed to detect performance. It is observed that the improved algorithm has a better improvement in retrieval both in precision rate and recall rate.","","CD-ROM:978-1-4799-1864-5; Electronic:978-1-4799-5245-8; POD:978-1-4799-5246-5","10.1109/ISCC-C.2013.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973703","Boolean retrieval;improved algorithm;precision rate;recall rate;semantic distance;topic words","Cognition;Earthquakes;Educational institutions;Electronic mail;Information retrieval;Libraries;Semantics","information retrieval;text analysis","Boolean retrieval;algorithm optimization;disaster case retrieval system;keyword similarity;precision rate;recall rate;semantic distance;semantic relations;semantic retrieval framework;textual case retrieval;topic words","","0","","16","","","7-8 Dec. 2013","","IEEE","IEEE Conference Publications"
"A pairwise approach to simultaneous onset/offset detection for singing voice using correntropy","S. Chang; K. Lee","Music & Audio Res. Group, Seoul Nat. Univ., Seoul, South Korea","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20140714","2014","","","629","633","In this paper, we propose a novel method to search for precise locations of paired note onset and offset in a singing voice signal. In comparison with the existing onset detection algorithms, our approach differs in two key respects. First, we employ Correntropy, a generalized correlation function inspired from Reyni's entropy, as a detection function to capture the instantaneous flux while preserving insensitiveness to outliers. Next, a novel peak picking algorithm is specially designed for this detection function. By calculating the fitness of a pre-defined inverse hyperbolic kernel to a detection function, it is possible to find an onset and its corresponding offset simultaneously. Experimental results show that the proposed method achieves performance significantly better than or comparable to other state-of-the-art techniques for onset detection in singing voice.","1520-6149;15206149","Electronic:978-1-4799-2893-4; POD:978-1-4799-2894-1; USB:978-1-4799-2892-7","10.1109/ICASSP.2014.6853672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6853672","entropy;offset detection;onset detection;pairwise peak picking;singing voice","Correlation;Indexes;Kernel;Multiple signal classification;Music information retrieval;Signal processing;Speech","entropy;speech synthesis","Reyni entropy;correntropy;detection function;generalized correlation function;inverse hyperbolic kernel;onset detection algorithms;onset-offset detection;peak picking algorithm;singing voice signal","","0","","18","","","4-9 May 2014","","IEEE","IEEE Conference Publications"
"A semi-informative aware approach using topic model for medical search","Q. V. Hu; L. He; M. Li; J. X. Huang; E. M. Haacke","Shanghai Key Laboratory of Multidimensional Information Processing","2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20150115","2014","","","320","324","We propose a semi-informative aware approach using the topic model on query expansion problem in the biomedicine domain. the demographics and disease information is applied to semi-structure the topic model as the “known” label, compared to the traditional latent topics in topic modelling. Then, we suggest to select three terms from the top ranked documents to expand the query, based on the assumption in the pseudo relevance feedback method that the top ranked results in the first retrieval around are relevant. After that, we conduct the experiments on the TREC medical records data sets with extensive analysis and discussions. Numerically, we achieve the improvements of 7.41% on MAP, 9.29% on Bpref and 5.60% on P@10 respectively over the strong baselines.","","Electronic:978-1-4799-5669-2; POD:978-1-4799-5670-8","10.1109/BIBM.2014.6999177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6999177","","Biological system modeling;Diseases;Educational institutions;Indexes;Information retrieval;Mathematical model;Numerical models","diseases;electronic health records","Bpref;MAP;P@10;TREC medical records data sets;biomedicine domain;demographics;disease information;extensive analysis;medical search;pseudorelevance feedback method;query expansion problem;semiinformative aware approach;top ranked documents;topic modelling","","0","","14","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Heterogeneous Metric Learning with Content-Based Regularization for Software Artifact Retrieval","L. Wu; L. Du; B. Liu; G. Xu; Y. Ge; Y. Fu; J. Li; Y. Zhou; H. Xiong","Comput. Network Inf. Center, Beijing, China","2014 IEEE International Conference on Data Mining","20150129","2014","","","610","619","The problem of software artifact retrieval has the goal to effectively locate software artifacts, such as a piece of source code, in a large code repository. This problem has been traditionally addressed through the textual query. In other words, information retrieval techniques will be exploited based on the textual similarity between queries and textual representation of software artifacts, which is generated by collecting words from comments, identifiers, and descriptions of programs. However, in addition to these semantic information, there are rich information embedded in source codes themselves. These source codes, if analyzed properly, can be a rich source for enhancing the efforts of software artifact retrieval. To this end, in this paper, we develop a feature extraction method on source codes. Specifically, this method can capture both the inherent information in the source codes and the semantic information hidden in the comments, descriptions, and identifiers of the source codes. Moreover, we design a heterogeneous metric learning approach, which allows to integrate code features and text features into the same latent semantic space. This, in turn, can help to measure the artifact similarity by exploiting the joint power of both code and text features. Finally, extensive experiments on real-world data show that the proposed method can help to improve the performances of software artifact retrieval with a significant margin.","1550-4786;15504786","Electronic:978-1-4799-4302-9; POD:978-1-4799-4301-2","10.1109/ICDM.2014.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7023378","","Electronic mail;Feature extraction;Information retrieval;Measurement;Optimization;Semantics;Software","feature extraction;learning (artificial intelligence);query processing;source code (software);text analysis","artifact similarity;code feature;code repository;content-based regularization;feature extraction method;heterogeneous metric learning approach;information retrieval technique;latent semantic space;semantic information;software artifact retrieval;source code;text feature;textual query;textual representation;textual similarity","","0","","33","","","14-17 Dec. 2014","","IEEE","IEEE Conference Publications"
"A formal method for selecting evaluation metrics for image segmentation","A. A. Taha; A. Hanbury; O. A. J. del Toro","Vienna University of Technology","2014 IEEE International Conference on Image Processing (ICIP)","20150129","2014","","","932","936","Evaluating the quality of segmentations is an important process in image processing, especially in the medical domain. Many evaluation metrics have been used in evaluating segmentation. There exists no formal way to choose the most suitable metric(s) for a particular segmentation task and/or particular data. In this paper we propose a formal method for choosing the most suitable metrics for evaluating the quality of segmentations with respect to ground truth segmentations. The proposed method depends on measuring the bias of metrics towards/against the properties of the the segmentations being evaluated. We firstly demonstrate how metrics can have bias towards/against particular properties and then we propose a general method for ranking metrics according to their overall bias. We finally demonstrate for 3D medical image segmentations that ranking produced using metrics with low overall bias strongly correlate with manual rankings done by an expert.","1522-4880;15224880","Electronic:978-1-4799-5751-4; POD:978-1-4799-5752-1","10.1109/ICIP.2014.7025187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7025187","evaluation metrics;image segmentation;selection","Correlation;Equations;Image segmentation;Information retrieval;Manuals;Sensitivity","image segmentation;medical image processing","3D medical image segmentation;evaluation metric selection;image processing","","1","","20","","","27-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Surviving the upcoming data deluge: A systems and control perspective","M. Sznaier; O. Camps; N. Ozay; C. Lagoa","ECE Dept., Northeastern University, Boston, MA, 02115, USA","53rd IEEE Conference on Decision and Control","20150212","2014","","","1488","1498","Arguably, one of the biggest challenges facing the systems and control community stems from the exponential growth in data collection capabilities, made possible by the development of low cost, ultra low power sensors. These developments have rendered feasible a spectrum of new control applications, ranging from zero emission buildings to reconfigurable, self aware environments, that can profoundly impact society. However, realizing this potential, requires endowing controllers with the ability to timely extract actionable information from the very large data streams generated by the sensors, a goal that challenges the capabilities of existing techniques. The goal of this paper is to show the key role that dynamics can play in accomplishing this task. This is accomplished by establishing a connection, largely unexplored until recently, between the problems of information extraction, manifold embedding and identification of switched systems, and showing that this connection allows for recasting the problem of decision making in “data deluged” scenarios into a tractable convex optimization form.","0191-2216;01912216","CD-ROM:978-1-4799-7745-1; Electronic:978-1-4673-6090-6; POD:978-1-4673-6089-0","10.1109/CDC.2014.7039611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039611","","Educational institutions;Information retrieval;Manifolds;Optimization;Polynomials;Sensors;Time series analysis","convex programming;decision making;identification;information retrieval;time-varying systems","data deluged scenarios;decision making;information extraction;manifold embedding;switched systems identification;tractable convex optimization problem","","2","","40","","","15-17 Dec. 2014","","IEEE","IEEE Conference Publications"
"Similarity measures based on sentence semantic structure for recognizing paraphrase and entailment","X. Y. Liu; Chuan-Lun Ren","North China Institute of Computer Technology, Beijing 100083, China","2013 International Conference on Machine Learning and Cybernetics","20140908","2013","04","","1601","1607","The similarity measure on the sentence level plays an increasingly important role in many applications about text-related areas and natural language processing. In this paper, we employ sentence semantic structures to overcome the difficulty from the variability of natural language expression. We represent a sentence as verb-argument pairs of semantic structures. The similarity between sentences is reflected through the relation between verb-argument pairs. We evaluate the proposed measure on two applications: recognizing paraphrases and entailments. The experimental results show that our method outperforms existing methods in the task of identifying similar sentences.","2160-133X;2160133X","Electronic:978-1-4799-0260-6; POD:978-1-4799-0259-0","10.1109/ICMLC.2013.6890857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6890857","Entailment;Paraphrase;Semantic structure;Similarity measures","Abstracts;Accuracy;Area measurement;Information retrieval;Noise measurement;Semantics;Syntactics","natural language processing","entailment;natural language expression;natural language processing;paraphrase recognition;sentence level;sentence semantic structure;similarity measures;verb-argument pairs","","0","","28","","","14-17 July 2013","","IEEE","IEEE Conference Publications"
"Syntactic open domain Arabic question/answering system for factoid questions","N. S. Fareed; H. M. Mousa; A. B. Elsisi","Computer Science dep., Faculty of Computers and Information, Menofia University, Egypt","2014 9th International Conference on Informatics and Systems","20150212","2014","","","NLP-1","NLP-9","Information Retrieval systems have become a crucial part of any search engine, taking into consideration the increased number of pages and documents added to the World Wide Web every day. Question/Answering systems are specific to retrieve the most accurate answer among several documents; this paper will present an improved methodology and implementation of an open domain Arabic Question Answering System for factoid questions. The proposed system is based on Query Expansion ontology and an Arabic Stemmer. Basically the system mainly depends on AWN as a semantic Query Expansion and Khoja stemmer as a stemming system, to evaluate the system we used 56 translated CLEF and TREC questions, four types of test scenarios are performed. Four evaluation attributes were considered: Accuracy, Mean Reciprocal Rank, Answered Questions and recall; and encouraging results were reached with the proposed system.","","CD-ROM:978-977-403-689-7; Electronic:978-977-403-695-8; POD:978-1-4799-4018-9","10.1109/INFOS.2014.7036699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7036699","Arabic WordNet;Factoid questions;JIRS;Khoja stemmer;Query Expansion;Question/Answering","Computers;Educational institutions;Google;Information retrieval;Knowledge discovery;Natural language processing;Ontologies","natural language processing;ontologies (artificial intelligence);query processing;question answering (information retrieval)","Arabic stemmer;CLEF questions;Khoja stemmer;TREC questions;accuracy attribute;answered questions attribute;factoid questions;information retrieval systems;mean reciprocal rank attribute;open domain Arabic question-answering system;query expansion ontology;recall attribute;search engine","","1","","23","","","15-17 Dec. 2014","","IEEE","IEEE Conference Publications"
"A Web Service for Scholarly Big Data Information Extraction","K. Williams; L. Li; M. Khabsa; J. Wu; P. C. Shih; C. L. Giles","Inf. Sci. & Technol., Comput. Sci. & Eng, Pennsylvania State Univ., University Park, PA, USA","2014 IEEE International Conference on Web Services","20141204","2014","","","105","112","The automatic extraction of metadata and other information from scholarly documents is a common task in academic digital libraries, search engines, and document management systems to allow for the management and categorization of documents and for search to take place. A Web-accessible API can simplify this extraction by providing a single point of operation for extraction that can be incorporated into multiple document workflows without the need for each workflow to implement and support its own extraction functionality. In this paper, we describe CiteSeerExtractor, a RESTful API for scholarly information extraction that exploits the fact that there is duplication in scholarly big data and makes use of a near duplicate matching backend. The backend stores previously extracted metadata and avoids extracting metadata from a document if it has already been extracted before. We describe the design, implementation, and functionality of CiteSeerExtractor and show how the duplicate document matching results in a difference of 8.46% in the time required to extract header and citation information from approximately 3.5 million documents compared to a baseline.","","Electronic:978-1-4799-5054-6; POD:978-1-4799-5055-3","10.1109/ICWS.2014.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6928887","CiteSeerExtractor;Web service;information extraction;scholarly big data","Big data;Data mining;Databases;Hamming distance;Information retrieval;Web servers","Big Data;Web services;application program interfaces;information retrieval;meta data","Big Data information extraction;CiteSeerExtractor;RESTful API;Web service;Web-accessible API;academic digital libraries;automatic metadata extraction;document categorization;document management systems;document workflows;extraction functionality;near duplicate matching backend;search engines","","2","","20","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"Music Genre and Emotion Recognition Using Gaussian Processes","K. Markov; T. Matsui","Div. of Inf. Syst., Univ. of Aizu, Aizu-Wakamatsu, Japan","IEEE Access","20140709","2014","2","","688","697","Gaussian Processes (GPs) are Bayesian nonparametric models that are becoming more and more popular for their superior capabilities to capture highly nonlinear data relationships in various tasks, such as dimensionality reduction, time series analysis, novelty detection, as well as classical regression and classification tasks. In this paper, we investigate the feasibility and applicability of GP models for music genre classification and music emotion estimation. These are two of the main tasks in the music information retrieval (MIR) field. So far, the support vector machine (SVM) has been the dominant model used in MIR systems. Like SVM, GP models are based on kernel functions and Gram matrices; but, in contrast, they produce truly probabilistic outputs with an explicit degree of prediction uncertainty. In addition, there exist algorithms for GP hyperparameter learning-something the SVM framework lacks. In this paper, we built two systems, one for music genre classification and another for music emotion estimation using both SVM and GP models, and compared their performances on two databases of similar size. In all cases, the music audio signal was processed in the same way, and the effects of different feature extraction methods and their various combinations were also investigated. The evaluation experiments clearly showed that in both music genre classification and music emotion estimation tasks the GP performed consistently better than the SVM. The GP achieved a 13.6% relative genre classification error reduction and up to an 11% absolute increase of the coefficient of determination in the emotion estimation task.","2169-3536;21693536","","10.1109/ACCESS.2014.2333095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843353","Gaussian processes;Music genre classification;gaussian processes;music emotion estimation;music genre classification","Acoustic measurement;Analytical models;Bayes methods;Data models;Emotion recognition;Gaussian processes;Information retrieval;Music;Regression analysis;Support vector machines;Time series analysis","Bayes methods;Gaussian processes;audio signal processing;emotion recognition;feature extraction;information retrieval;learning (artificial intelligence);music;nonparametric statistics;pattern classification;support vector machines","Bayesian nonparametric model;GP hyperparameter learning;Gaussian process;MIR system;SVM;degree of prediction uncertainty;feature extraction method;music audio signal processing;music emotion recognition;music genre classification error reduction;music genre recognition;music information retrieval;nonlinear data relationship;support vector machine","","7","","52","","20140625","2014","","IEEE","IEEE Journals & Magazines"
"Research on Multi-document Summarization Based on LDA Topic Model","J. Bian; Z. Jiang; Q. Chen","Sch. of Autom., Beijing Inst. of Technol., Beijing, China","2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics","20141009","2014","2","","113","116","Compared with VSM (Vector Space Model) and graph-ranking models, LDA (Latent Dirichlet Allocation) Model can discover latent topics in the corpus and latent topics are beneficial to use sentence-ranking mechanisms to form a good summary. In the paper, based on LDA Model, a new method of sentence-ranking is proposed. The method combines topic-distribution of each sentence with topic-importance of the corpus together to calculate the posterior probability of the sentence, and then, based on the posterior probability, it selects sentences to form a summary. Topic-distribution of each sentence represents the likelihood of sentence belonging to each topic and topic-importance represents the degree that the topics cover the significant portion of the corpus. The method highlights the latent topics and optimizes the summarization. Experiment results on the dataset DUC2006 show the advantage of the multi-document summarization algorithm proposed in the paper. ROUGE values are improved compared with those methods, such as LexRank, LDA-SIBS, LDA-PGS.","","Electronic:978-1-4799-4955-7; POD:978-1-4799-4954-0","10.1109/IHMSC.2014.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911461","LDA;Multi-document summarization;Topic Model","Data mining;Information retrieval;Probability distribution;Resource management;Semantics;Vectors","information retrieval;probability;text analysis","LDA topic model;ROUGE value;latent dirichlet allocation;latent topic;multidocument summarization;posterior probability;sentence-ranking mechanism;topic-distribution;topic-importance","","1","","10","","","26-27 Aug. 2014","","IEEE","IEEE Conference Publications"
"Scalable Semantic Aware Context Storage","M. L. P. Antunes; D. N. P. Gomes; R. L. A. Aguiar","Inst. de Telecomun., Univ. de Aveiro, Aveiro, Portugal","2014 International Conference on Future Internet of Things and Cloud","20141215","2014","","","152","158","In recent years the Internet has grown by incorporating billions of small devices, collecting real-world information and distributing it though various systems. As the number of such devices grows, it becomes increasingly difficult to manage all these new information sources. Several context representation schemes have tried to standardize this information, however none of them have been widely adopted. Instead of proposing yet another context representation scheme, we discuss an efficient way to deal with this diversity of representation schemes. We define the basic requirements for context storage systems, analyse context organizations models and propose a new context storage solution. Our solution implements an organizational model that improves scalability, semantic extraction and minimizes semantic ambiguity.","","Electronic:978-1-4799-4357-9; POD:978-1-4799-4356-2","10.1109/FiCloud.2014.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984189","Internet of things;M2M;context information","Context;Context modeling;Indexes;Information retrieval;Semantics;Sensors","Internet;Internet of Things;information resources;storage management","Internet;context organization model;context representation scheme;context storage solution;context storage system;information sources;real-world information;scalability;scalable semantic aware context storage;semantic ambiguity;semantic extraction","","2","","23","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"Resource-efficient regular expression matching architecture for text analytics","K. Atasu","IBM Res. - Zurich, Zurich, Switzerland","2014 IEEE 25th International Conference on Application-Specific Systems, Architectures and Processors","20140731","2014","","","1","8","Text analytics systems, such as IBM's SystemT software, rely on regular expressions (regexs) and dictionaries for transforming unstructured data into a structured format. Unlike network intrusion detection systems, text analytics systems compute and report precisely where the specific and sensitive information starts and ends in a text document. Therefore, advanced regex matching functions, such as start-offset reporting, capturing groups, and leftmost match computation are heavily used in text analytics systems. We present a novel regex matching architecture that supports such functions in a resource-efficient way. The resource efficiency is achieved by 1) eliminating state replication, 2) avoiding expensive offset comparison operations in leftmost match computation, and 3) minimizing the number of offset registers. Experiments on regex sets from text analytics and network intrusion detection domains, using an Altera Stratix IV FPGA, show that the proposed architecture achieves a more than threefold reduction of the logic resources used and a more than 1.25-fold increase of the clock frequency with respect to a recently proposed architecture that supports identical features.","1063-6862;10636862","Electronic:978-1-4799-3609-0; POD:978-1-4799-3610-6; USB:978-1-4799-3608-3","10.1109/ASAP.2014.6868623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6868623","","Clocks;Computer architecture;Hardware;Information retrieval;Redundancy;Registers;Vectors","data structures;dictionaries;field programmable gate arrays;text analysis","Altera Stratix IV FPGA;IBM SystemT software;advanced regex matching functions;capturing groups;clock frequency;dictionaries;leftmost match computation;logic resources;network intrusion detection domains;offset registers;resource efficiency;resource-efficient regular expression matching architecture;sensitive information;start-offset reporting;structured format;text analytics;text document;unstructured data","","1","","25","","","18-20 June 2014","","IEEE","IEEE Conference Publications"
"Adapting REST To REAST, Building Smarter Interactions for Personal Web Tasking","J. W. Ng","Software Lab., CAS Res., IBM Canada, Canada","2014 IEEE World Congress on Services","20140922","2014","","","38","47","REpresentational State Transfer (REST) today represents and transfers the data-states of distrib-uted resources. Through hypermedia-based inter-actions among these representations and transfers, the web's original goal of information retrieval is accomplished. However, despite of the fact that the web today has evolved beyond information retrieval into task executions, the original web interaction model built for information browsing has not been enhanced accordingly. This paper proposes a hypermedia-based RESTful model for task expression, delegation and execution through the representations and transfers of action-states of distributed resources, termed as REpresentational Action State Transfer (REAST). The con-tributions of this paper are (1) a representation of hypermedia-based task expressions that enables the building of user-controlled interactive apps, (2) a technique for Resource Oriented Web Auto-mation (ROWA) using a dedicated media type designed for machine processing as well as ma-chine-initiated and machine-executed task expressions within the RESTful HATEOAS constraints, (3) REST-based Resource Oriented Intelligent Agents (ROIA) to act on users' behalf across the web without domain-specificity, and (4) an in-teroperability model for tasks execution involving diversified resources types (e.g., enterprise re-sources and internet of things) working seamlessly together within the RESTful architecture.","2378-3818;23783818","Electronic:978-1-4799-5069-0; POD:978-1-4799-5070-6","10.1109/SERVICES.2014.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6903241","RESTful Architecture;Web Agents;Web Automation;Web services;personal web tasking","Automation;Buildings;Data models;Information retrieval;Programming;Semantics;Servers","Internet of Things;Web sites;hypermedia;information retrieval;open systems;resource allocation;task analysis","Internet of Things;REAST;REST-based resource oriented intelligent agents;RESTful HATEOAS constraints;ROIA;ROWA;Web interaction model;distributed resource data-states;hypermedia-based RESTful model;hypermedia-based interactions;hypermedia-based task expression representation;information browsing;information retrieval;interoperability model;machine processing;machine-executed task expressions;machine-initiated task expressions;personal Web tasking;representational action state transfer;resource oriented Web automation;task expression;user-controlled interactive apps","","2","","21","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"What drives social sentiment? An entropic measure-based clustering approach towards identifying factors that influence social sentiment polarity","D. N. Sotiropoulos; C. D. Kounavis; P. Kourouthanassis; G. M. Giaglis","","IISA 2014, The 5th International Conference on Information, Intelligence, Systems and Applications","20140818","2014","","","361","373","Analyzing the public sentiment over social media streams constitutes an extremely demanding task mainly due to the difficulties that are imposed by the wide spectrum of discussion topics that underlie a given collection of posts. This paper addresses the problem of determining the underlying semantic factors that influence the social sentiment polarity in a given corpus of posts through the utilization of an entropic measure-based clustering approach. Extant studies examine the semantic structure of social network data primarily through topic modeling or sentiment analysis methods. The novelty of our approach lies upon the utilization of a semantically-aware clustering procedure that effectively combines topic modeling and sentiment analysis algorithms. Our approach extends the fundamental assumption behind traditional sentiment analysis methods, according to which sentiment can be associated with low level document features such as words, phrases or sentences. We argue that sentiment can be associated with higher level entities such as the semantic axes that span a given volume of posts, thus performing sentiment analysis at the topic level. Our experimentation provides strong evidence that combining topic modeling and sentiment analysis results by a semantically-aware clustering procedure can reveal the distribution of the overall public sentiment on the underlying semantic axes.","","Electronic:978-1-4799-6171-9; POD:978-1-4799-6172-6","10.1109/IISA.2014.6878830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6878830","Entropic Measure-based Clustering;Sentiment Analysis;Support Vector Machines;Topic Modelling","Abstracts;Information retrieval","information analysis;pattern clustering;social networking (online)","entropic measure-based clustering approach;low level document features;public sentiment;semantic factors;semantically-aware clustering procedure;sentiment analysis algorithms;sentiment analysis methods;social media streams;social network data;social sentiment polarity;topic modeling","","0","","17","","","7-9 July 2014","","IEEE","IEEE Conference Publications"
"Uploader models for video concept detection","B. Merialdo; U. Niaz","Multimedia Commun. Dept., EURECOM, Sophia Antipolis, France","2014 12th International Workshop on Content-Based Multimedia Indexing (CBMI)","20140710","2014","","","1","4","In video indexing, it has been noticed that a simple uploader model was able to improve the MAP of concept detection in the TRECVID Semantic Concept Indexing (SIN) task. In this paper, we explore this idea further by comparing different types of uploader models and different types of score/rank distribution. We evaluate the performance of these combinations on the best SIN 2012 runs, and explore the impact of their parameters. We observe that the improvement is generally lower for the best runs than for the weaker runs. We also observe that tuning the models for each concept independently produces a much more significant improvement.","1949-3983;19493983","Electronic:978-1-4799-3990-9; POD:978-1-4799-3991-6; USB:978-1-4799-3989-3","10.1109/CBMI.2014.6849847","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6849847","Multimedia Indexing;TRECVID;User model","Adaptation models;Correlation;Information retrieval;Semantics;Silicon compounds;Tuning;Visualization","indexing;video signal processing","SIN task;TRECVID semantic concept indexing;score/rank distribution;uploader models;video concept detection;video indexing","","1","","14","","","18-20 June 2014","","IEEE","IEEE Conference Publications"
"Big Data in the Public Cloud","E. Collins","Cloudera","IEEE Cloud Computing","20141015","2014","1","2","13","15","The early innovators in big data infrastructure (Google, Microsoft, Yahoo, and Facebook) were large public cloud companies, but ran on their own private infrastructures. Although the public cloud companies have been developing big data infrastructure since their inception, only more recently have big data workloads been running in the public cloud. This article looks at some of the developments in big data public cloud offerings.","2325-6095;23256095","","10.1109/MCC.2014.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6924642","big data;cloud;cloud computing;data processing;data warehousing;search","Big data;Cloud computing;Data warehouses;Electronic mail;Google;Information retrieval;Market research;Search engines;Social network services","Big Data;cloud computing","Facebook;Google;Microsoft;Yahoo;big data infrastructure;big data workloads;private infrastructures;public cloud companies","","2","","6","","","July 2014","","IEEE","IEEE Journals & Magazines"
"Arabic Text Root Extraction via Morphological Analysis and Linguistic Constraints","A. Alsaad; M. Abbod","Dept. of Electron. & Comput. Eng., Brunel Univ., Uxbridge, UK","2014 UKSim-AMSS 16th International Conference on Computer Modelling and Simulation","20150223","2014","","","125","130","Arabic language is vastly inflected, thus the process of effective Arabic text analysis with correct stem and root extraction is challenging. In this paper we present a linguistic root extraction approach that is composed of two main phases. In the first phase we handle removal of affixes including prefixes, suffixes and infixes. Prefixes and suffixes are removed depending on the length of the word, while checking its morphological pattern after each deduction to remove infixes. In the second phase, the root extraction algorithm is developed further to handle weak, hamzated, eliminated-long-vowel and two-letter geminated words as there is a rationally great amount of irregular Arabic words in texts. Before roots are extracted, they are checked against a predefined list of 3800 triliteral and 900 quad literal roots. Series of experiments has been conducted to improve and test the performance of the proposed algorithm. The obtained results revealed that the roots are extracted correctly has improved comparing with Khoja's stemming algorithm.","","Electronic:978-1-4799-4922-9; POD:978-1-4799-4921-2","10.1109/UKSim.2014.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7046050","Arabic root extraction;data mining;morphological analyser;natural language processing;text mining","Algorithm design and analysis;Information retrieval;Pattern matching;Pragmatics;Testing;Text mining","computational linguistics;data mining;natural language processing;text analysis","Arabic text analysis;Arabic text root extraction;linguistic constraint;morphological analysis;text mining","","2","","15","","","26-28 March 2014","","IEEE","IEEE Conference Publications"
"Overview of positioning technologies from fitness-to-purpose point of view","A. Basiri; E. S. Lohan; Pedro Figueiredo e Silva; P. Peltola; C. Hill; T. Moore","The Nottingham Geospatial Institute, The University of Nottingham, UK","International Conference on Localization and GNSS 2014 (ICL-GNSS 2014)","20141023","2014","","","1","7","Even though Location Based Services (LBSs) are being more and more widely-used and this shows a promising future, there are still many challenges to deal with, such as privacy, reliability, accuracy, cost of service, power consumption and availability. There is still no single low-cost positioning technology which provides position of its users seamlessly indoors and outdoors with an acceptable level of accuracy and low power consumption. For this reason, fitness of positioning service to the purpose of LBS application is an important parameter to be considered when choosing the most suitable positioning technology for an LBS. This should be done for any LBS application, since each application may need different requirements. Some location-based applications, such as location-based advertisements or Location-Based Social Networking (LBSN), do not need very accurate positioning input data, while for some others, e.g. navigation and tracking services, highly-accurate positioning is essential. This paper evaluates different positioning technologies from fitness-to-purpose point of view for two different applications, public transport information and family/friend tracking.","2325-0747;23250747","Electronic:978-1-4799-5123-9; POD:978-1-4799-5124-6","10.1109/ICL-GNSS.2014.6934176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6934176","Fitness-To-Purpose;Location Based Service (LBS);Positioning Technologies","Cameras;Cities and towns;Digital video broadcasting;Information retrieval;Micromechanical devices;Navigation;Security","mobile radio;public transport;radio tracking;radionavigation","LBS application;family tracking;fitness-to-purpose;friend tracking;location based service;positioning technologies;positioning technology;public transport information","","4","","38","","","24-26 June 2014","","IEEE","IEEE Conference Publications"
"Weighted Combination of Q&A Retrieval Models Based on Part-of-Speech of Question Word","D. s. Chang; Y. s. Choi","Dept. of Comput. & Software, Hanyang Univ., Seoul, South Korea","2014 International Conference on Information Science & Applications (ICISA)","20140708","2014","","","1","4","Question and answer archives have become useful information resources with increase of community based question and answer service. For effective question and answering system, it is important to find semantically similar questions and retrieve its answer from the archive for user's question. In this paper, we propose a weighted combination of retrieval models for question and answer archives. In contrast to well-known translation based language model, the proposed model reflects significance of each word in user's question by giving variant weight to the word depending on its part-of-speech. In experiment, our model improves performance considerably when compared to conventional ones.","2162-9048;21629048","Electronic:978-1-4799-4441-5; POD:978-1-4799-4440-8","10.1109/ICISA.2014.6847483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6847483","","Computational modeling;Educational institutions;Estimation;Information retrieval;Probability;Research and development;Smoothing methods","information resources;language translation;question answering (information retrieval)","Q&A retrieval models;answer retrieval;information resources;part-of-speech of question word;question and answer archives;weighted combination","","0","","11","","","6-9 May 2014","","IEEE","IEEE Conference Publications"
"An online audio alignment tool for live musical performance","G. Burloiu","University Politehnica of Bucharest","2014 11th International Symposium on Electronics and Telecommunications (ISETC)","20150115","2014","","","1","4","Alignment of live audio material with a recorded interpretation of the same piece is a growing interest in computer music research. We present an implementation of a modified online dynamic time warping algorithm for live music performance in the form of a new Max/MSP<sup>1</sup> external object. The tool tracks key points in the musician's playing in order to start and finish in time with the incoming audio and maintain temporal synchronization throughout, despite variations or mistakes in the live musician's input. We examine the present algorithm's alignment performance using a representative set of pairs of audio material, and compare the results to existing related algorithms. We demonstrate the applicability of the tool in a real musical situation and propose directions for future development.","","CD-ROM:978-1-4799-7265-4; Electronic:978-1-4799-7267-8; POD:978-1-4799-7268-5","10.1109/ISETC.2014.7010811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010811","MFCCs;Max/MSP;audio alignment;automatic accompaniment;dynamic time warping","Cost function;Heuristic algorithms;Materials;Music;Music information retrieval;Real-time systems;Vectors","audio recording;audio signal processing;music","Max/MSP1 external object;computer music research;live audio material alignment;live music performance;live musical performance;modified online dynamic time warping algorithm;online audio alignment tool;recorded interpretation;temporal synchronization throughout","","0","","16","","","14-15 Nov. 2014","","IEEE","IEEE Conference Publications"
"Anti-Reconnaissance Tools: Detecting Targeted Socialbots","A. Paradise; R. Puzis; A. Shabtai","Dept. of Inf. Syst. Eng., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel","IEEE Internet Computing","20140828","2014","18","5","11","19","Advanced attackers use online social networks to extract useful information about the target organization, including its members and their connections, affiliations, and positions. Socialbots are artificial, machine-operated, social network profiles that connect to real members of an organization, greatly increasing the amount of information an attacker can collect. To connect socialbots, attackers can employ several strategies. The authors' approach hunts socialbots using a carefully chosen monitoring strategy by intelligently selecting organization member profiles and monitoring their activity. Their results demonstrate their method's efficacy-specifically, when attackers know the defense strategy being deployed, the attack they will most likely use is randomly sprayed friend requests, which eventually lead to a low number of connections.","1089-7801;10897801","","10.1109/MIC.2014.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6840822","reconnaissance;social network;socialbots","Information retrieval;Internet;Mathematical model;Online services;Social network services;Targeting","security of data;social networking (online)","activity monitoring;antireconnaissance tools;artificial machine-operated social network profiles;intelligent organization member profile selection;randomly sprayed friend requests;targeted socialbot detection","","4","","20","","20140620","Sept.-Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Concept based document management in cloud storage","M. R. Sumalatha; E. Pugazhendi; D. J. Archana","Dept. of Inf. Technol., Anna Univ., Chennai, India","2013 International Conference on Recent Trends in Information Technology (ICRTIT)","20140626","2013","","","90","96","Cloud computing is one of the most useful environment that provides various information services in which required information can be retrieved through many web-based tools and applications. Now the new surge of interest in cloud computing is accompanied with the exponential growth of data sizes. There is a need to find the desired content quickly and efficiently by simply consulting the index. Thus there arises a question of how to effectively process these immense data sets is becoming increasingly urgent. Our existing system is searching the content through ontology in cloud which practically suffers from maintaining a consistent logic for the input documents given and taking this advantage into consideration we have brought in new concepts called Document Retrieval Algorithm. In this paper we discuss how effectively and efficiently information can be retrieved from cloud taking into account their storage space too, where we store the metadata of file in cloud and not the entire file which holds a lot of space in distributed environment. Thus we bring in the concept of Named Entity Recognition and Universal Word List with Term frequency, which maximizes the information retrieval more effective and efficient and also to bridge the gap between the semantic web and the users which reduces the complexity met by them in information retrieval.","","Electronic:978-1-4799-1024-3; POD:978-1-4799-1023-6","10.1109/ICRTIT.2013.6844186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6844186","Cloud storage;Concept Extraction;Document retrieval;Named entity recognition pronoun","Cloud computing;Databases;Information retrieval;Information technology;Market research;Ontologies;Semantic Web","cloud computing;document handling;indexing;information retrieval;ontologies (artificial intelligence);semantic Web;storage management","Web-based tools;cloud computing;cloud storage;concept based document management;consistent logic;content searching;data sizes;distributed environment;document retrieval algorithm;index;information retrieval;information services;input documents;named entity recognition;ontology;semantic web;term frequency;universal word list","","0","","13","","","25-27 July 2013","","IEEE","IEEE Conference Publications"
"Performance analysis on agriculture ontology using SPARQL query system","A. Khamparia; B. Pandey; V. Pardesi","Department of Computer Science and Engineering, Lovely ProfessionalUniversity, Phagwara, Punjab, India","2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)","20141113","2014","","","1","5","Ontologies are used to represent domain knowledge with help of object, their behaviour and properties. This paper represents web enabled approach on agriculture semantic web using SPARQL and specified tools to increase productivity of farmers. This work focuses on assessment of query optimization tools and results predicted from them to determine the suitability of each method for different users where structured ontologies are used as querying aids for agriculture based dataset.","","Electronic:978-1-4799-4674-7; POD:978-1-4799-4673-0","10.1109/ICDMIC.2014.6954258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954258","DL-Query;Ontograf;RDF;Reasoner;SPARQL;Semantic web;TLX","Agriculture;Diseases;Information retrieval;Knowledge based systems;Ontologies;Resource description framework","SQL;agricultural engineering;agriculture;ontologies (artificial intelligence);query processing;semantic Web","SPARQL query system;Web enabled approach;agriculture based dataset;agriculture ontology;agriculture semantic web;domain knowledge;productivity;query optimization tools;structured ontologies","","0","","11","","","5-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"Single Outdoor Image Depth Map Generation Based on Scene Classification and Object Detection","Y. Ren; J. Liu","Sch. of Inf. Sci. & Eng., Shandong Univ., Jinan, China","2014 7th International Conference on Ubi-Media Computing and Workshops","20141007","2014","","","91","94","Three dimensional television (3DTV) has attracted more and more attention in the area of TV broadcasting. However, the applications are constrained due to the content shortage. It is an economical way by converting monoscopic 2D video to 3D (2D-3D) so as to reuse the existed huge amount of 2D videos materials by using Depth-Image-Based-Rendering (DIBR). In this paper, an efficient framework for extracting depth information from the single image is proposed, which is based on scene classification and object detection. In the proposed scheme, by applying that real similar 3D scenes may have a similar depth map, we construct an image set including many kinds of images (their corresponding depth maps are given) with different scene structures first. The image set is classified into some categories manually. For a certain input image, k-Nearest Neighbor (KNN) algorithm is employed to judge that whether the input image corresponds to outdoor scene or not. Then, the initial depth map is obtained by fusing the depth maps of those images in the category which the input image belongs to, After that, we incorporate the image segmentation results to detect the sky region and the ground region by using color information. Finally, the depth map is obtained by refining the initial depth map using the sky and ground region. Experimental results demonstrate that the proposed scheme can generate smooth and reliable depth maps with satisfied performance.","","CD-ROM:978-1-4799-4267-1; Electronic:978-1-4799-4266-4; POD:978-1-4799-4265-7","10.1109/U-MEDIA.2014.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916331","Scene understanding;depth generation;object recognition","Educational institutions;Estimation;Image color analysis;Image segmentation;Information retrieval;Roads;Three-dimensional displays","image classification;image colour analysis;image fusion;image segmentation;natural scenes;object detection;rendering (computer graphics);television broadcasting;three-dimensional television;video signal processing","2D video materials;3D scenes;3D video;KNN algorithm;TV broadcasting;color information;depth information extracting;depth map fusion;depth maps;depth-image-based-rendering;ground region detection;image segmentation;image set;images depth maps;k-nearest neighbor algorithm;monoscopic 2D video;object detection;scene classification;single outdoor image depth map generation;sky region detection;three-dimensional television","","0","","16","","","12-14 July 2014","","IEEE","IEEE Conference Publications"
"Classification ensemble to improve medical Named Entity Recognition","S. Keretna; C. P. Lim; D. Creighton; K. B. Shaban","Centre for Intelligent Systems Research, Deakin University, Australia","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","2630","2636","An accurate Named Entity Recognition (NER) is important for knowledge discovery in text mining. This paper proposes an ensemble machine learning approach to recognise Named Entities (NEs) from unstructured and informal medical text. Specifically, Conditional Random Field (CRF) and Maximum Entropy (ME) classifiers are applied individually to the test data set from the i2b2 2010 medication challenge. Each classifier is trained using a different set of features. The first set focuses on the contextual features of the data, while the second concentrates on the linguistic features of each word. The results of the two classifiers are then combined. The proposed approach achieves an f-score of 81.8%, showing a considerable improvement over the results from CRF and ME classifiers individually which achieve f-scores of 76% and 66.3% for the same data set, respectively.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974324","Machine learning;biomedical named entity recognition;conditional random field;information extraction;maximum entropy;medical text mining","Context modeling;Entropy;Feature extraction;Information retrieval;Testing;Text recognition;Training","data mining;learning (artificial intelligence);maximum entropy methods;medical information systems;pattern classification;random processes;text analysis","CRF;ME classifiers;NER;classification ensemble;conditional random field;contextual features;ensemble machine learning approach;informal medical text;knowledge discovery;linguistic features;maximum entropy classifiers;medical named entity recognition;text mining;unstructured medical text","","1","","37","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Multi-level Funneling Approach to Data Provenance Reconstruction","A. Aierken; D. B. Davis; Q. Zhang; K. Gupta; A. Wong; H. U. Asuncion","Sch. of Sci., Technol., Eng. & Math., Univ. of Washington Bothell, Bothell, WA, USA","2014 IEEE 10th International Conference on e-Science","20141204","2014","2","","71","74","When data are retrieved from a file storage system or the Internet, is there information about their provenance (i.e., their origin or history)? It is possible that data could have been copied from another source and then transformed. Often, provenance is not readily available for data sets created in the past. Solving such a problem is the motivation behind the 2014 Provenance Reconstruction Challenge. This challenge is aimed at recovering lost provenance for two data sets: one data set (WikiNews articles) in which a list of possible sources has been provided, and another data set (files from GitHub repositories) in which the file sources are not provided. To address this challenge, we present a multi-level funneling approach to provenance reconstruction, a technique that incorporates text processing techniques from different disciplines to approximate the provenance of a given data set. We built three prototypes using this technique and evaluated them using precision and recall metrics. Our preliminary results indicate that our technique is capable of reconstructing some of the lost provenance.","","Electronic:978-1-4799-4287-9; POD:978-1-4799-4286-2","10.1109/eScience.2014.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972100","data provenance reconstruction;longest common subsequence;semantic analysis;similarity metrics;topic modeling;vector space model","Image reconstruction;Information retrieval;Measurement;Natural language processing;Prototypes;Semantics;Vectors","Web sites;data analysis;meta data;text analysis","2014 Provenance Reconstruction Challenge;GitHub repository;Internet;WikiNews articles;data history;data origin;data provenance reconstruction;data retrieval;file sources;file storage system;lost provenance recovery;metadata information;multilevel funneling approach;precision metrics;provenance information;recall metrics;semantic content;text processing technique","","2","","15","","","20-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"A study of intents resolving for service discovery","C. Zheng; W. Shen; H. H. Ghenniwa","Dept. of Electr. & Comput. Eng., Western Univ., London, ON, Canada","Proceedings of the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20140708","2014","","","649","654","Intents is an emerging framework which is employed for service discovery and integration. Currently the main strategy applied in Intents for resolving an intent message is exactly matching which may miss some valuable service candidates for the user. In order to address this issue, techniques in Information Retrieval (IR) are potential alternatives to find the missing services. This paper makes an empirical study of some classic IR techniques on a practical Intents dataset and demonstrates the findings of interest from the experiments which can be employed in designing matching schemes based on similarity.","","Electronic:978-1-4799-3776-9; POD:978-1-4799-3777-6; USB:978-1-4799-3775-2","10.1109/CSCWD.2014.6846921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6846921","Intents;Web services;service discovery","Collaborative work;Conferences;Decision support systems;Handheld computers;IEEE Potentials;Information retrieval","Web services;information retrieval","IR;Web services;information retrieval;intent message;intent resolving;intents dataset;matching schemes;service discovery;service integration","","0","","18","","","21-23 May 2014","","IEEE","IEEE Conference Publications"
"Are the popular users always important for information dissemination in online social networks?","S. Wen; J. Jiang; Y. Xiang; S. Yu; W. Zhou","Deakin University","IEEE Network","20141003","2014","28","5","64","67","This article verifies the importance of popular users in OSNs. The results are counter-intuitive. First, for dissemination speed, a large amount of users can swiftly distribute information to the masses, but they are not highly-connected users. Second, for dissemination scale, many powerful forwarders in OSNs cannot be identified by the degree measure. Furthermore, to control dissemination, popular users cannot capture most bridges of social communities.","0890-8044;08908044","","10.1109/MNET.2014.6915441","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915441","","Computational modeling;Information retrieval;Information services;Online services;Social network services","information dissemination;social networking (online)","OSN;information dissemination;online social networks","","1","","18","","","September-October 2014","","IEEE","IEEE Journals & Magazines"
"An Automated Approach for Interpretation of Statistical Graphics","A. Mahmood; I. S. Bajwa; K. Qazi","Dept. of Comput. Sci. &IT, Islamia Univ. of Bahawalpur, Bahawalpur, Pakistan","2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics","20141009","2014","2","","376","379","Text plays vital role in the analysis of quantitative data as in statistics the data representation is made through different graphical tools such as bar charts, pie charts, line charts, scatter diagram, histograms etc. Statistical graphics are the valuable tool used for visual information representation in multimodal documents. It is often observed that communicative goal of the statistical graphics is not captured by documents accompanying text. To perceive the represented information using statistical graphics is hard-hitting job for novice readers. An approach to automate the process of image classification and information extraction is presented in this paper. This study focuses on the area charts that are important type of statistical graphics used for probability distribution and testing of hypothesis process. Firstly, we have classified the area charts into different classes and then designed architecture for chart image classification and information withdrawal from each class of area chart. The extracted information is represented in the form of natural language summaries using template based approach.","","Electronic:978-1-4799-4955-7; POD:978-1-4799-4954-0","10.1109/IHMSC.2014.192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911523","Natural language processing;Optical character recognition;Statistical graphics;Text detection and extraction;area charts classification and detection","Data mining;Feature extraction;Graphics;Image recognition;Information retrieval;Natural languages;Optical character recognition software","data analysis;data structures;image classification;information retrieval;natural language processing;statistical analysis;statistical distributions;statistical testing;text detection","area charts;chart image classification process;data representation;graphical tools;hypothesis process testing;information extraction process;information withdrawal;multimodal documents;natural language summaries;probability distribution;quantitative data analysis;statistical graphics;template based approach;visual information representation","","0","","10","","","26-27 Aug. 2014","","IEEE","IEEE Conference Publications"
"Semantic ranking based on Computer Science Ontology weight","T. Boonyoung; A. Mingkhwan","Faculty of Information Technology King Mongkut's University of Technology North Bangkok Bangkok, Thailand","Ninth International Conference on Digital Information Management (ICDIM 2014)","20141218","2014","","","86","91","Document Ranking retrieval systems are the top documents ordering and particularly appropriate for user's query. Most existing assigned based on the information retrieval term frequency (tf) that appears in the document. Although the number of times that the term occurrence is more relevant, but not meant for rank documents according to their proximity to user's query. So this paper, we presented a new document semantic ranking process for the semantic ranking that proposes a new weight of query term in the document based on Computer Science Ontology weight. The experimental results show that the new document similarity score between a user's query and the paper suggests that the new measures were effectively ranked.","","Electronic:978-1-4799-5421-6; POD:978-1-4799-5422-3","10.1109/ICDIM.2014.6991426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991426","Computer Science Ontology;Cosine Similarity;Semantic Ranking;Vector Space Model","Computational modeling;Computer science;Decision making;Information retrieval;Ontologies;Semantics;Vectors","computer science;query processing","computer science ontology weight;document ranking retrieval systems;document semantic ranking process;document similarity score;information retrieval term frequency;user query","","0","","15","","","Sept. 29 2014-Oct. 1 2014","","IEEE","IEEE Conference Publications"
"Context storage for M2M scenarios","M. Antunes; D. Gomes; R. Aguiar","Inst. de Telecomun., Univ. de Aveiro, Aveiro, Portugal","2014 IEEE International Conference on Communications (ICC)","20140828","2014","","","3664","3669","As the number of environmental sensors grows, it becomes increasingly difficult to manage, store and process all these sources of information. Several context representation schemes try to standardize this information, however none of them have been widely adopted. Instead of proposing yet another context representation scheme, we discuss efficient ways to deal with this diversity of representation schemes. We defined the basic requirements for flexible context storage systems, proposed an implementation and compared our implementation against two other approaches. Our solution provides more value than the remaining solutions without suffering a significant decrease in performance.","1550-3607;15503607","Electronic:978-1-4799-2003-7; POD:978-1-4799-2005-1; USB:978-1-4799-2004-4","10.1109/ICC.2014.6883891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6883891","Internet of things;M2M;context information","Context;Indexes;Information retrieval;Load modeling;Relational databases;Sensors","mobile computing;storage management","M2M scenarios;context representation schemes;environmental sensors;flexible context storage systems","","5","","23","","","10-14 June 2014","","IEEE","IEEE Conference Publications"
"An effective re-ranking method based on learning to rank for improving audio fingerprinting","C. C. Wang; M. H. Lin; J. S. R. Jang; W. Liou","Dept. of CS, NTHU, Hsinchu, Taiwan, R.O.C.","Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific","20150216","2014","","","1","4","This paper presents an effective re-ranking method that uses learning-to-rank paradigms to improve the accuracy of landmark-based audio fingerprinting (AFP) for audio music retrieval. The re-ranking mechanism is invoked whenever the returned ranking from an AFP system does not have a high enough confidence measure. We propose that use of new features for re-ranking, and employ the popular learning-to-rank paradigms, including pairwise and listwise approaches for modeling the behavior from queries to desired ranking. Experimental results indicate that the proposed re-ranking method can effectively improve the top-1 recognition rate of our AFP system, with only small extra overhead of overall response time.","","Electronic:978-6-1636-1823-8; POD:978-1-4799-4250-3","10.1109/APSIPA.2014.7041558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7041558","","Accuracy;Conferences;Decision support systems;Fingerprint recognition;Indexes;Music information retrieval","audio signal processing;fingerprint identification;information retrieval;music","AFP;audio fingerprinting;audio music retrieval;effective reranking method;learning-to-rank paradigms","","0","","11","","","9-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Ontology supported information extraction for document of evidence-based nursing domain","F. Rocha; E. C. Lopes","Nucleo de Pesquisas em Redes e Comput., Univ. Salvador, Salvador, Brazil","2014 9th Iberian Conference on Information Systems and Technologies (CISTI)","20140814","2014","","","1","6","The increasing amount of information available in electronic media is a strategic resource for the health professional who uses this source to support decision making. However, it is not feasible to analyze a significant number of documents in a short time without the support of a computational tool. The Information Extraction aims to extract from textual documents only the relevant information defined by the user. This information can be mapped and classified in the field of health through ontologies. This paper proposes the design of an information extracting mechanism that, in a hybrid form, can combine: an extractor for textual documents; the construction and use of a domain ontology for evidence-based nursing, aiming to assist in the classification of documents which will be extracted by the extractor and in the representation of this domain with respect to the computational area.","2166-0727;21660727","Electronic:978-9-8998-4343-1; POD:978-1-4799-6111-5","10.1109/CISTI.2014.6876992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876992","evidence-based nursing;information extraction;ontology;text classification","Abstracts;Data mining;Information retrieval;Internet;Media;Medical services;Ontologies","document handling;medical information systems;ontologies (artificial intelligence);patient care;pattern classification","documents classification;domain ontology;evidence-based nursing;evidence-based nursing domain document;information extracting mechanism;ontology supported information extraction;textual documents extraction","","0","","19","","","18-21 June 2014","","IEEE","IEEE Conference Publications"
"Combining Query Terms Extension and Weight Correlative for Expert Finding","C. T. Chuang; K. H. Yang; Y. L. Lin; J. H. Wang","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","323","326","This paper proposes two methods for solving the expert finding problem. In order to enhance the correctness, a C-value method is applied to these methods for query expansion. After query expansion, proposed system calculates correlation between all query terms and experts, and finally outputs a list of experts. The experiment results show that the proposed methods can provide higher precision than the baseline method from 3% to 10%.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927560","C-value;TF-IDF;expert finding;query expension","Correlation;Databases;Educational institutions;Equations;Information retrieval;Mathematical model;Vectors","query processing","C-value method;expert finding problem;query expansion;query term extension;weight correlative","","1","","18","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Spatial big data and wireless networks: experiences, applications, and research challenges","C. Jardak; P. Mähönen; J. Riihijärvi","Siemens Corp., Germany","IEEE Network","20140724","2014","28","4","26","31","In this article we demonstrate that spatial big data can play a key role in many emerging wireless networking applications. We also argue that spatial and spatiotemporal problems have their own very distinct role in the big data context compared to the commonly considered relational problems. We describe three major application scenarios for spatial big data, each imposing specific design and research challenges. We then present our work on developing highly scalable parallel processing frameworks for spatial data in the Hadoop framework using the MapReduce computational model. Our results show that using Hadoop enables highly scalable implementations of algorithms for common spatial data processing problems. However, development of these implementations requires significant specialized knowledge, demonstrating the need for development of more user-friendly alternatives.","0890-8044;08908044","","10.1109/MNET.2014.6863128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6863128","","Big data;Information retrieval;Sensors;Spatial analysis;Spatial databases;Wireless networks;Wireless sensor networks","mobile computing;very large databases;visual databases","Hadoop framework;MapReduce computational model;parallel processing framework;spatial big data;spatial data processing problem;spatio-temporal problem;wireless networks","","13","","16","","","July-August 2014","","IEEE","IEEE Journals & Magazines"
"Evaluation of applicability of modified vector space representation for in-VM malicious activity detection in Cloud","B. Borisaniya; K. Patel; D. Patel","Computer Engineering Department, NIT Surat, India","2014 Annual IEEE India Conference (INDICON)","20150205","2014","","","1","6","Malware writers use increasingly complex evasion mechanisms to ensure the concealment of malware against standard anti-malware suites. To identify malware through its behaviour, rather than its approach is an interesting venue of exploration. System call traces are highly indicative of a process behaviour. However, it is difficult to acquire system calls of all processes running on a physical machine. Fortunately, the same cannot be said for the virtual machines, owing to the advancement of Virtual Machine Introspection (VMI) techniques. This opens up the possibility of utilizing system call information for malicious activity detection. In this paper, we study different representations of system call information and evaluate their applicability for in- VM malicious activity detection in Cloud environment.","2325-940X;2325940X","Electronic:978-1-4799-5364-6; POD:978-1-4799-5365-3","10.1109/INDICON.2014.7030588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030588","Cloud;System call traces;Vector Space Model;Virtual Machine Introspection","Cloud computing;Information retrieval;Kernel;Malware;Testing;Vectors;Virtual machining","cloud computing;invasive software;virtual machines","applicability evaluation;cloud computing;complex evasion mechanisms;in-VM malicious activity detection;malware concealment;malware identification;modified vector space representation;standard antimalware suites;system call information utilization;system call traces;virtual machine introspection techniques","","1","","15","","","11-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Object-oriented approach of information extraction from panchromatic satellite images based on fuzzy logic","N. Gupta; H. S. Bhadauria","CSE Dept., G.B. Pant Engineering College, Pauri Garhwal, Uttarakhand-246194, India","2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)","20141110","2014","","","651","656","This paper presents a fuzzy inference based object oriented classification approach for information extraction from panchromatic satellite images. The main problem concerned with high resolution satellite imagery is diverse composition of spectral resolution in urban mapping. Information extraction form these high resolution images are problematic due to discriminated object boundaries in the land use as well as the multiple resemblances of the different class segments. Satisfying results cannot be obtained with the use of traditional pixel based classifiers which rely on per pixel value analysis. This paper demonstrated the concept of fuzzy logic based object-oriented approach, in order to deal with this problematic situation. The concept of this approach is to determine a suitable threshold of the parameters adopted in the object oriented approach. Establishment of fuzzy membership functions for extraction of various surface objects such as bare soil, roads, water, vegetation, building etc using the provided built-in tools of eCognition software, is the main focus of this study. In this proposed approach, fuzzy logic (rules) is defined for every class based on the specifications mentioned in class hierarchy. Using these fuzzy rules each image object is tested against specifications. Each segment receives a membership value (degree) which acts as class representative. After deffuzification of the results every class is assigned associated segments with high similarity degree, using eCognition software. Improved overall accuracy of the presented system, making this approach feasible and efficient for extracting information from high resolution remotely sensed data.","","CD-ROM:978-1-4799-4237-4; Electronic:978-1-4799-4236-7; POD:978-1-4799-4235-0","10.1109/CONFLUENCE.2014.6949274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949274","classification;eCognition;extraction;fuzzy logic;high resolution;information;object-oriented;satellite images","Fuzzy logic;Image segmentation;Information retrieval;Satellites;Soil;Spatial resolution","feature extraction;fuzzy logic;fuzzy reasoning;geophysical image processing;image classification;image resolution;image retrieval;image segmentation;land use;object-oriented methods;remote sensing","class hierarchy;class segments;deffuzification;eCognition software;fuzzy inference based object oriented classification;fuzzy logic;fuzzy membership functions;fuzzy rules;high resolution remotely sensed data;high resolution satellite imagery;information extraction;land use;membership value;object boundaries;object-oriented approach;panchromatic satellite images;pixel based classifiers;pixel value analysis;similarity degree;spectral resolution;surface objects extraction;urban mapping","","0","","33","","","25-26 Sept. 2014","","IEEE","IEEE Conference Publications"
"New metrics for quantifying data association performance","M. E. Silbert; C. S. Agate","NAVAIR, Patuxent River, MD 20670","17th International Conference on Information Fusion (FUSION)","20141007","2014","","","1","8","Numerous metrics exist for quantifying the performance of information fusion systems. Some metrics focus on estimation accuracy by comparing estimated quantities to the truth. Other metrics assess the accuracy of the estimation uncertainty by determining the consistency of the estimation error covariance. In this paper we define two metrics that quantify the data association algorithm's performance (whether the data are measurements or tracks). We compare the metric to a few existing metrics that quantify the effects of data association and evaluate the new metrics both with some notional examples and with some simulated data run through a track-to-track (T2T) fusion algorithm. Finally, we discuss a direct analogy between the data association problem and the information retrieval problem and reference two metrics in the information retrieval domain that are equivalent to the two metrics proposed in this paper.","","Electronic:978-8-4901-2355-3; POD:978-1-4799-1634-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916220","association performance;fusion performance;incorrect association;missed association;precision;recall;track-to-track association","Algorithm design and analysis;Estimation;Information retrieval;Partitioning algorithms;Probability;Target tracking","estimation theory;information retrieval;sensor fusion","data association;estimation error covariance;estimation uncertainty;information fusion system;information retrieval;track-to-track fusion algorithm","","0","","10","","","7-10 July 2014","","IEEE","IEEE Conference Publications"
"Voting Models for Summary Extraction from Text Documents","Y. J. Kumar; O. S. Goh; M. K. A. Ghani; N. Salim; A. T. Albaham","Fac. of Inf. & Commun. Technol., Univ. Teknikal Malaysia Melaka, Durian Tunggal, Malaysia","2014 International Conference on IT Convergence and Security (ICITCS)","20150126","2014","","","1","4","Electronic information - web pages, text documents, etc. are rapidly expanding due to the exponential growth of the World Wide Web (WWW). Information which are available through online search often provide readers with large collection of texts. Although easy access to online information had made great impact to the people, on the other hand, it has also caused them problem in facing information overload. Providing a solution to digest various information sources is indeed necessary to treat such problem. Especially in the case concerning online text sources, one study which is being actively researched is the field of automatic text summarization. In this paper, we propose the use of voting models, an effective approach in ranking aggregates tasks, to treat text summarization. Here, we will discuss how voting models can be adapted to the task of sentence ranking to generate text summaries.","","Electronic:978-1-4799-6541-0; POD:978-1-4799-6542-7","10.1109/ICITCS.2014.7021826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7021826","","Adaptation models;Aggregates;Communications technology;Computational modeling;Feature extraction;Information retrieval;Mathematical model","Internet;text analysis","World Wide Web;automatic text summarization;electronic information;online search;summary extraction;text documents;voting models","","1","","12","","","28-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Robust anchorperson detection based on audio streams using a hybrid I-vector and DNN system","Y. F. Chang; P. Lin; S. H. Cheng; K. H. Chan; Y. C. Zeng; C. W. Liao; W. T. Chang; Y. C. Wang; Y. Tsao","Research Center for Information Technology Innovation, Academia S&#x00ED;nica, Taipei, Taiwan","Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific","20150216","2014","","","1","4","Anchorperson segment detection enables efficient video content indexing for information retrieval. Anchorperson detection based on audio analysis has gained popularity due to lower computational complexity and satisfactory performance. This paper presents a robust framework using a hybrid I-vector and deep neural network (DNN) system to perform anchorperson detection based on audio streams of video content. The proposed system first applies I-vector to extract speaker identity features from the audio data. With the extracted speaker identity features, a DNN classifier is then used to verify the claimed anchorperson identity. In addition, subspace feature normalization (SFN) is incorporated into the hybrid system for robust feature extraction to compensate the audio mismatch issues caused by recording devices. An anchorperson verification experiment was conducted to evaluate the equal error rate (EER) of the proposed hybrid system. Experimental results demonstrate that the proposed system outperforms the state-of-the-art hybrid I-vector and support vector machine (SVM) system. Moreover, the proposed system was further enhanced by integrating SFN to effectively compensate the audio mismatch issues in anchorperson detection tasks.","","Electronic:978-6-1636-1823-8; POD:978-1-4799-4250-3","10.1109/APSIPA.2014.7041717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7041717","","Abstracts;Decision support systems;Feature extraction;Indexing;Information retrieval;Robustness;Support vector machines","audio signal processing;computational complexity;feature extraction;image classification;learning (artificial intelligence);neural nets;speaker recognition;vectors;video retrieval","DNN classifier;DNN system;SFN;anchorperson verification experiment;audio analysis;audio mismatch issues;audio streams;computational complexity;deep neural network system;equal error rate evaluation;hybrid I-vector;information retrieval;recording devices;robust anchorperson segment detection;speaker identity feature extraction;subspace feature normalization;video content indexing","","0","","21","","","9-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Improving severity prediction on software bug reports using quality indicators","C. Z. Yang; K. Y. Chen; W. C. Kao; C. C. Yang","Department of Computer Science and Engineering, Yuan Ze University, Chungli, Taoyuan 32003, Taiwan","2014 IEEE 5th International Conference on Software Engineering and Service Science","20141023","2014","","","216","219","Recently, research has been conducted to explore the prediction schemes to identify the severity of bug reports. Several text mining approaches have been proposed to facilitate severity prediction. However, these studies mainly focus on the textual information of the bug reports. Other attributes of the bug reports have not been comprehensively discussed. In this paper, we investigate the influences of four quality indicators of bug reports in severity prediction. In an empirical study with the Eclipse dataset, the results show that considering these indicators can further improve the performance of a previous work employing only textual information.","2327-0586;23270586","CD-ROM:978-1-4799-3277-1; Electronic:978-1-4799-3279-5; POD:978-1-4799-3280-1","10.1109/ICSESS.2014.6933548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933548","bug reports;empirical study;performance evaluation;quality indicators;severity prediction","Conferences;Information retrieval;Predictive models;Software;Sun;Text mining","data mining;program debugging;software quality;text analysis","Eclipse dataset;quality indicators;severity prediction;software bug reports;text mining approach;textual information","","0","","11","","","27-29 June 2014","","IEEE","IEEE Conference Publications"
"A comparison of methods for identification of early aspects","S. Ye; C. He","School of Computer Science and Engineering. Wuhan Institute of Technology, Hubei Province Key Laboratory of Intelligent Robot, Wuhan, China","Proceedings of 2013 3rd International Conference on Computer Science and Network Technology","20141201","2013","","","275","279","Aspects are tangled and scattered behaviours across a system. The identification of early aspects helps to separate these behaviours from the requirements and improve modularity in the design and implementation stages. In recent years, many methods for identification of crosscutting concerns have been proposed at the requirements level. This paper analyzes how these well-known Aspect-Oriented Requirements Engineering approaches address crosscutting concern and makes a comparison between these techniques.","","Electronic:978-1-4799-0561-4; POD:978-1-4799-0560-7","10.1109/ICCSNT.2013.6967112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967112","aspects;comparison;crosscutting concerns;requirements","Computer architecture;Conferences;Information retrieval;Petri nets;Software;Unified modeling language","aspect-oriented programming;program diagnostics;systems analysis","aspect-oriented requirements engineering approaches;crosscutting concerns;design modularity;early aspects identification;scattered behaviours;tangled behaviours","","0","","21","","","12-13 Oct. 2013","","IEEE","IEEE Conference Publications"
"Mp-Dissimilarity: A Data Dependent Dissimilarity Measure","S. Aryal; K. M. Ting; G. Haffari; T. Washio","Clayton Sch. of Inf. Technol., Monash Univ., Melbourne, VIC, Australia","2014 IEEE International Conference on Data Mining","20150129","2014","","","707","712","Nearest neighbour search is a core process in many data mining algorithms. Finding reliable closest matches of a query in a high dimensional space is still a challenging task. This is because the effectiveness of many dissimilarity measures, that are based on a geometric model, such as lp-norm, decreases as the number of dimensions increases. In this paper, we examine how the data distribution can be exploited to measure dissimilarity between two instances and propose a new data dependent dissimilarity measure called 'mp-dissimilarity'. Rather than relying on geometric distance, it measures the dissimilarity between two instances in each dimension as a probability mass in a region that encloses the two instances. It deems the two instances in a sparse region to be more similar than two instances in a dense region, though these two pairs of instances have the same geometric distance. Our empirical results show that the proposed dissimilarity measure indeed provides a reliable nearest neighbour search in high dimensional spaces, particularly in sparse data. Mp-dissimilarity produced better task specific performance than lp-norm and cosine distance in classification and information retrieval tasks.","1550-4786;15504786","Electronic:978-1-4799-4302-9; POD:978-1-4799-4301-2","10.1109/ICDM.2014.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7023388","distance measure;lp-norm;mp-dissimilarity","Accuracy;Approximation methods;Data mining;Educational institutions;Electronic mail;Information retrieval;Vectors","data mining;probability;query processing;search problems","cosine distance;data dependent dissimilarity measure;data distribution;data mining algorithms;geometric distance;geometric model;high dimensional space;information retrieval tasks;l<sub>p</sub>-norm;m<sub>p</sub>-dissimilarity measures;nearest neighbour search;probability mass;reliable nearest neighbour search","","0","","12","","","14-17 Dec. 2014","","IEEE","IEEE Conference Publications"
"Cross domain web information extraction with multi-level feature model","Q. Chen; W. Zhu; C. Ju; W. Zhang","School of Computer Engineering and Science, Shanghai University, Shanghai, China","2014 10th International Conference on Natural Computation (ICNC)","20141206","2014","","","780","784","One of the key problems of information extraction is to design a cross domain extraction procedure that can adapt different domain topics and text formats. However, most information extraction methods focus on specific areas or only have limited scalability for semi-structured texts. We argue that the problem of cross domain information extraction is basically introduced by domain related features. For example, the features used for price extraction in e-commerce websites cannot be directly applied in the case of extracting salary for recruiting websites. In worst case, a whole extraction model is required to be implemented despite the fact that there are common characters for price and salary. In this paper we propose a cross domain solution by dismantling domain relevant features into sub-features that are less domain related. The sub-features include composite features (those can be represented with a combination of several other features) and atomic features (features that can't be dismantled). To manage the features effectively we propose a multi-level feature model by organizing the features as well as their relations. With this model, we give an information extraction method that can be quickly shifted when the extraction domain changes.","2157-9555;21579555","Electronic:978-1-4799-5151-2; POD:978-1-4799-5152-9","10.1109/ICNC.2014.6975936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975936","cross domain;information extraction;multi-level feature model","Data mining;Electronic publishing;Encyclopedias;Feature extraction;Information retrieval;Internet","Internet;information retrieval","atomic features;composite features;cross domain Web information extraction;multilevel feature model;sub-features","","0","","23","","","19-21 Aug. 2014","","IEEE","IEEE Conference Publications"
"Personalized indexing for heterogeneous multimedia data","A. Aggoune; A. Bouramoul; M. K. Kholladi","Computer Science Department LabSTIC Laboratory, University 8th may 45 Guelma, Algeria","2014 4th International Symposium ISKO-Maghreb: Concepts and Tools for knowledge Management (ISKO-Maghreb)","20150209","2014","","","1","7","The work presented in this article fall under the scope of multimedia documents coming from a heterogeneous corpus that its aims to improve the quality of semantic search of information. We propose a unified indexing model based on the integration of user profile to the indexing process. The general idea of our proposal is to operate the common concepts between the representation of a document and the definition of a user via his profile, these two elements will be added as additional indexing entities to enrich the heterogeneous corpus database indexes. We believe that these new concepts will enable the improvement of the automatic judging of documents relating to user profile. We have developed IRONTO domain ontology allowing annotation of documents in the field of information retrieval. We will present also the tool developed validating the proposed model. An evaluation phase aims at comparing the execution result according to two indexing modes: one without integration of the user profile and the other with the integration of the user profile using our unified model. The results show that the use of user profile in the process of semantic indexing improves significantly the performance of research in relation to the first indexing mode.","","Electronic:978-1-4799-7508-2; POD:978-1-4799-7509-9","10.1109/ISKO-Maghreb.2014.7033460","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033460","heterogeneous of sources;multimedia document;ontology;personnalization;user profile;semantic indexing","Indexing;Information retrieval;Media;Multimedia communication;Ontologies;Semantics","document handling;indexing;information retrieval;multimedia computing;ontologies (artificial intelligence)","IRONTO domain ontology;automatic judging;heterogeneous corpus database indexes;heterogeneous multimedia data;indexing process;information retrieval;multimedia documents;personalized indexing model;semantic indexing modes;semantic search;user profile","","1","","25","","","9-10 Nov. 2014","","IEEE","IEEE Conference Publications"
"Interscale learning and classification for global HR/VHR image information extraction","L. Gueguen; M. Pesaresi","DigitalGlobe Inc., Image Mining Product Development, 1601 Dry Creek Drive, Longmont, CO 80501, USA","2014 IEEE Geoscience and Remote Sensing Symposium","20141106","2014","","","1481","1484","An interscale learning paradigm for global HR/VHR image information extraction is presented. The paradigm relies on the information matching between a priori global knowledge and features derived from high resolution imagery to perform adaptive high resolution land classification. Unlike traditional machine learning techniques, this strategy avoids the costly collection of local training datasets and the local parameter tuning and it enables the full automation of the information extraction process.","2153-6996;21536996","Electronic:978-1-4799-5775-0; POD:978-1-4799-5314-1; USB:978-1-4799-5774-3","10.1109/IGARSS.2014.6946717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6946717","","Data mining;Feature extraction;Information retrieval;Remote sensing;Spatial resolution;Training","feature extraction;geophysical image processing;geophysical techniques;image classification","adaptive high resolution land classification;global HR-VHR image information extraction;high resolution imagery;information extraction process;interscale classification;interscale learning paradigm;traditional machine learning techniques","","0","","17","","","13-18 July 2014","","IEEE","IEEE Conference Publications"
"A survey on ontology matching techniques","S. Kumar; V. Singh; B. Saini","National Institute of Technology, Kurukshetra, India","2014 International Conference on Computer and Communication Technology (ICCCT)","20150108","2014","","","13","15","Words, sentences, paragraphs and documents is an important component in the data mining application area such as information retrieval, text summarization etc. And finding the similarity value between these components is an important action. Nowaday, there are various matching techniques are present which are very helpful for finding the similarity between the ontology. In this survey paper discusses the existing works on similarity (On text, words etc.) using element-level techniques and structure level techniques.","","Electronic:978-1-4799-6758-2; POD:978-1-4799-6759-9","10.1109/ICCCT.2014.7001462","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001462","Element-Level techniques;Similarity;String-Based similarity;Structure-Level techniques","Conferences;Hamming distance;Information retrieval;Natural language processing;Ontologies;Semantics;Transforms","data mining;ontologies (artificial intelligence);pattern matching","data mining application area;element-level technique;information retrieval;matching techniques;ontology matching technique;similarity value;structure level technique;text summarization","","0","","8","","","26-28 Sept. 2014","","IEEE","IEEE Conference Publications"
"Automatic assessment of affective episodes for daily activities analysis","Y. H. Chiu; K. Y. Huang; H. E. Chiu; W. H. Chen","Dept. of Healthcare Administration and Medical Informatics, Kaohsiung Medical University, Kaohsiung, Taiwan","Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific","20150216","2014","","","1","4","Monitoring health conditions and events of grandparent-headed family is important to increase their quality of life and reduce care burdens. Affective episodes are significant indexes in monitoring behavior changes. In this paper, we propose an information retrieval approach to extract affect words from speech and written text to provide quantitative evidence of physical functions and social interactivity for living support and the health related quality of life assessment. Hidden Markov model with a developed behavior grammar network was adopted to transcribe speech. Combined with written texts, an adjusted term-frequency and a sliding window method were performed to extract and quantify affect words. A quantitative index scored by trigger pair approach was applied to assess affective episodes with time and place. Experimental results and case study revealed that the proposed approach shows encouraging potential in monitoring daily activity and family dialog. Its extension may provide an alternative way to obtain implicit information of emotional expression between a family.","","Electronic:978-6-1636-1823-8; POD:978-1-4799-4250-3","10.1109/APSIPA.2014.7041674","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7041674","","Data mining;Decision support systems;Indexes;Information retrieval;Markov processes;Monitoring;Speech","assisted living;hidden Markov models;information retrieval;medical information systems","affective episodes automatic assessment;behavior grammar network;daily activities analysis;grandparent-headed family;health condition monitoring;health related quality of life assessment;hidden Markov model;information retrieval;sliding window method;social interactivity;term-frequency;trigger pair approach","","0","","10","","","9-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"A fuzzy ERM for extracting and modeling uncertain spatial expressions in text","V. R. Kanagavalli; K. Raja","Sathyabama University, Chennai","International Conference on Information Communication and Embedded Systems (ICICES2014)","20150209","2014","","","1","7","The information and knowledge sharing era is exploding with information that people are continuously sharing over various sources across the globe. This has made the retrieval a difficult task. There are plenty of documents everywhere about anything and everything a human mind can think about. All this information is mostly presented transferred and shared using natural language. The biggest challenge and research area has been to enable machines understand and decipher what has been communicated to it through natural language. There are document classification systems that classifies and groups the documents that are speaking about the same concept. But the same type of classification is not successfully handled if it happens to be based on spatial keywords. This is due to the inherent ambiguity and uncertainty that is associated with the spatial terms found in natural language descriptions. Text documents imply the usage of natural language and as such it yields to explicit vague fuzzy descriptions involving linguistic terms such as near to, far from, to the east of, very close and also implicit vague spatial references. Event reporting in case of disasters or in case of special occasions is also generally done using free form text rather than structured methods since it allows more detailed descriptions to be added in. Much of these afore said text documents acting as an information source and the query posed by the user implicitly have a geographic or spatial reference component present in it. This logically leads to the conclusion by the previous studies that more than 80% of the searches are pertaining to geographic locations. Fuzzy logic is an extension to the Boolean crisp logic to accommodate for the fuzziness of an element belonging to a set. This paper studies the feasibility of fuzzy logic techniques in resolving the spatial uncertainty in text and presents a Fuzzy ERM (Extraction, Resolving and Modeling) architecture for the same.","","Electronic:978-1-4799-3834-6; POD:978-1-4799-3698-4","10.1109/ICICES.2014.7033770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033770","Fuzzy Logic;Granulation;Possibility Theory;Spatial Uncertainty","Educational institutions;Fuzzy logic;Fuzzy sets;Information retrieval;Natural languages;Spatial resolution;Uncertainty","Boolean algebra;fuzzy logic;fuzzy set theory;knowledge management;natural language processing;pattern classification;query processing;text analysis","Boolean crisp logic;disasters;document classification systems;event reporting;explicit vague fuzzy descriptions;fuzzy ERM;fuzzy extraction, resolving and modeling architecture;fuzzy logic;geographic reference component;information sharing era;information source;knowledge sharing era;linguistic terms;natural language descriptions;query;spatial keywords;spatial reference component;text documents;uncertain spatial expression extraction;uncertain spatial expression modelling;vague spatial references","","0","","35","","","27-28 Feb. 2014","","IEEE","IEEE Conference Publications"
"A bootstrapping and MV-RNN mixed method for relation extraction","J. Jianshu; C. Guang; Z. Chunyun","Beijing University of Posts and Telecommunications, Beijing 100876, China","2014 4th IEEE International Conference on Network Infrastructure and Digital Content","20150105","2014","","","117","120","The classical method for information extraction called bootstrapping is widely used for its good performance. But some inevitable weakness such as semantic drift and low recall hinders the improvement of the model. With the repopulation of neural network, some neural network methods also showed their power in relation extraction with the loss of accuracy compared to bootstrapping method. Under this circumstance, we propose a method, which mixed these two methods together and combined their pros together.","2374-0272;23740272","CD-ROM:978-1-4799-5624-1; Electronic:978-1-4799-4734-8; POD:978-1-4799-4733-1","10.1109/ICNIDC.2014.7000277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000277","bootstrapping;neural network;relation extraction","Data mining;Feature extraction;Information retrieval;Neural networks;Semantics;Support vector machine classification;Syntactics","information retrieval;recurrent neural nets;statistical analysis","MV-RNN mixed method;bootstrapping method;information extraction;recurrent neural networks;relation extraction","","0","","10","","","19-21 Sept. 2014","","IEEE","IEEE Conference Publications"
"I-vector based language modeling for spoken document retrieval","K. Y. Chen; H. S. Lee; H. M. Wang; B. Chen; H. H. Chen","Inst. of Inf. Sci., Taipei, Taiwan","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20140714","2014","","","7083","7088","Since more and more multimedia data associated with spoken documents have been made available to the public, spoken document retrieval (SDR) has become an important research subject in the past two decades. The i-vector based framework has been proposed and introduced to language identification (LID) and speaker recognition (SR) tasks recently. The major contribution of the i-vector framework is to reduce a series of acoustic feature vectors of a speech utterance to a low-dimensional vector representation, and then numbers of well-developed postprocessing techniques (such as probabilistic linear discriminative analysis, PLDA) can be readily and effectively used. However, to our best knowledge, there is no research up to date on applying the i-vector framework for SDR or information retrieval (IR). In this paper, we make a step forward to formulate an i-vector based language modeling (IVLM) framework for SDR. Furthermore, we evaluate the proposed IVLM framework with both inductive and transductive learning strategies. We also exploit multi-levels of index features, including word- and subword-level units, in concert with the proposed framework. The results of SDR experiments conducted on the TDT-2 (Topic Detection and Tracking) collection demonstrate the performance merits of our proposed framework when compared to several existing approaches.","1520-6149;15206149","Electronic:978-1-4799-2893-4; POD:978-1-4799-2894-1; USB:978-1-4799-2892-7","10.1109/ICASSP.2014.6854974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6854974","Spoken document retrieval;i-vector;inductive;language modeling;transductive","Context;Indexes;Information retrieval;Probabilistic logic;Semantics;Training;Vectors","information retrieval;learning by example;probability;speaker recognition","IVLM framework;LID;PLDA;SDR;TDT-2 collection;acoustic feature vector;i-vector based framework;i-vector based language modeling framework;inductive learning strategy;information retrieval;language identification;low-dimensional vector representation;multimedia data;postprocessing techniques;probabilistic linear discriminative analysis;speaker recognition task;speech utterance;spoken document retrieval;subword-level unit;topic detection and tracking collection;transductive learning strategy","","4","","35","","","4-9 May 2014","","IEEE","IEEE Conference Publications"
"An Ontology Based Recommendation Mechanism for Lighting System Design","C. J. Hu; C. C. Cheng; H. Y. Wu; N. T. Chao","Green Energy & Environ. Res. Labs., ITRI, Hsinchu, Taiwan","2014 International Symposium on Computer, Consumer and Control","20140630","2014","","","239","243","Lighting system designers increasingly rely on information from building environment and lighting elements, such as the requirements from occupants or documents on lighting elements, to facilitate their development processes. However, most of current systems are unable to assist designer to integrate components into a schematic design for deploying a suitable light system for particular building environment. To address this problem, an ontology based recommendation mechanism is developed for designing lighting system projects. The proposed method was constructed with reusable project analysis and term-based ontology analysis. By examining an ontology-based design for lighting control system, designer can observe ranks of and similarities among alternatives by system requirements or system schemas, iteratively select historical project, and adjust system schemas for developing new projects.","","Electronic:978-1-4799-5277-9; POD:978-1-4799-5278-6","10.1109/IS3C.2014.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6845863","Context Reasoning;Daylight;Inverse Document Frequency (IDF);Knowledge Sharing;Lighting System;Ontology;Recommendation;Smart;Term Frequency (TF)","Algorithm design and analysis;Buildings;Feature extraction;Formal concept analysis;Information retrieval;Lighting;Ontologies","building management systems;electrical engineering computing;lighting control;ontologies (artificial intelligence);recommender systems","building environment;lighting control system;lighting elements;lighting system project design;ontology based recommendation mechanism;reusable project analysis;schematic design;system schemas;term-based ontology analysis","","0","","25","","","10-12 June 2014","","IEEE","IEEE Conference Publications"
"A pilot study on automatic inference rule discovery from Turkish text","G. G. İşgüder-Şahin; E. Adali","Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey","2014 IEEE 8th International Conference on Application of Information and Communication Technologies (AICT)","20150209","2014","","","1","5","In this paper we present a framework for extraction of inference rules from Turkish documents, such as ""A solved B ~ A found a solution to B"". Many natural language processing tasks, such as question answering, information retrieval and machine translation can benefit tremendously from inference rules. Our framework consists of three layers: construction of dependency trees; determining predicates and their complements and finally discovery of inference rules via clustering. We use Silhouette Index (SI) of the clusters as an automatic evaluation metric.","","Electronic:978-1-4799-4119-3; POD:978-1-4799-4118-6","10.1109/ICAICT.2014.7035959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7035959","Turkish;inference rule discovery;information extraction;text mining","Data mining;Educational institutions;Indexes;Information retrieval;Morphology;Semantics;Silicon","data mining;inference mechanisms;natural language processing;pattern clustering;text analysis;trees (mathematics)","SI;Silhouette Index;Turkish documents;Turkish text;automatic inference rule discovery;clustering;dependency tree construction;inference rule extraction;information retrieval;machine translation;natural language processing tasks;question answering","","0","","14","","","15-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Design and implementation of cell-ID location system based on signal monitoring","Hongman Wang; Shi Ma; Zhikui Hong; Wenbin Zheng","Beijing Univ. of Posts & Telecommun., Beijing, China","Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)","20140828","2013","","","2260","2264","In this paper, a Cell-ID location system based on signal monitoring (SM-CLS) is designed and implemented. After the discussion of the problems in the existing Cell-ID location technique, the Cell-ID location technique based on signal monitoring is introduced. With the technique, SM-CLS is designed and implemented. As obtaining Cell-IDs from the signal monitoring system, SM-CLS avoids the interplay between the location-based services and the core network. The disaster warning application proves the practical feasibility of the system at last.","","CD-ROM:978-1-4799-2563-6; Electronic:978-1-4799-2565-0; POD:978-1-4799-2566-7","10.1109/MEC.2013.6885421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6885421","Cell-ID location;distributed;signal monitoring;stream query","Data mining;Databases;Information retrieval;Mobile radio mobility management;Monitoring;Real-time systems;Signal processing","mobility management (mobile radio);signal processing","Cell-ID location system;SM-CLS;disaster warning application;signal monitoring system","","0","","7","","","20-22 Dec. 2013","","IEEE","IEEE Conference Publications"
"Semantic-Based Publish/Subscribe for M2M","M. Antunes; D. Gomes; R. Aguiar","Inst. de Telecomun., Univ. de Aveiro, Aveiro, Portugal","2014 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20141215","2014","","","256","263","The number of connected devices is expected to soar in the coming years, each one of them collects and distributes real-world information though various systems. As the number of such connected devices grows, it becomes increasingly difficult to store and share all these new sources of information. Several context representation schemes try to standardize this information, however none of them have been widely adopted. Publish/subscribe paradigm has proven to be an adequate abstraction for large scale information dissemination, but none of current variations is well suited for context information. In a previous publication we addressed these challenges, however our solution has some drawbacks: poor scalability and semantic extraction. The aim of this paper is twofold. First, we discuss an efficient way to deal with representation schemes diversity and propose a d-dimensional context organization model. Second, we propose a semantic-based publish/subscribe system that is well suited for M2M scenarios. Our evaluation shows that d-dimensional organization model outperforms our previous solution in both speed and space requirements.","","Electronic:978-1-4799-6236-5; POD:978-1-4799-6237-2","10.1109/CyberC.2014.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984316","Internet of things;M2M;context information","Context;Context modeling;Information retrieval;Mathematical model;Organizations;Semantics;Sensors","information dissemination;message passing;middleware","M2M;context information;context representation schemes;d-dimensional context organization model;d-dimensional organization model;information sources;information standardization;large scale information dissemination;real-world information;semantic-based publish/subscribe system","","1","","28","","","13-15 Oct. 2014","","IEEE","IEEE Conference Publications"
"Reducing semantic drift in bootstrapping for entity relation extraction","Chen Sijia; Li Yan; Chen Guang","Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)","20140828","2013","","","1947","1950","This paper presents a novel bootstrapping algorithm for entity relation extraction. Shortest dependency patterns connecting entity pairs in sentences are captured initially and in turn applied to extract new binary relationships. The patterns are evaluated through correlation detection. In addition, we effectively prevent semantic drift by co-training with trigger words. Experiments for slot filling on the Knowledge Base Population (KBP) newspaper corpora show that our enhanced bootstrapping system achieves an 11% F1-score improvement over traditional bootstrapping algorithm.","","CD-ROM:978-1-4799-2563-6; Electronic:978-1-4799-2565-0; POD:978-1-4799-2566-7","10.1109/MEC.2013.6885371","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6885371","bootstrapping;dependency pattern;relation extraction;semantic drift;trigger word","Context;Correlation;Data mining;Information retrieval;Natural language processing;Semantics;Training","entity-relationship modelling;learning (artificial intelligence);semantic networks;text analysis","F1-score improvement;KBP newspaper corpora;binary relationships;bootstrapping algorithm;bootstrapping system;correlation detection;entity pairs;entity relation extraction;knowledge base population newspaper corpora;semantic drift;sentences;shortest dependency patterns;slot filling;trigger words cotraining","","0","","21","","","20-22 Dec. 2013","","IEEE","IEEE Conference Publications"
"Extracting product features from online reviews based on two-level HHMM","X. Wang; Z. Lu","School of Economics and Management, Tongji University, Shanghai, China","2014 Global Summit on Computer & Information Technology (GSCIT)","20141204","2014","","","1","4","With rapid development of E-commerce, obtaining product features from online reviews effectively is both important consumers and product manufacturers. In this paper, we proposed a two-level Hierarchical Hidden Markov Model (HHMM) to extract product features. In HHMM-1, we use segment tags to divide comment text into Feature-Contained Segment and Non-Feature-Contained Segment. Then the product feature in Non-Feature-Contained Segment is further marked and extracted in HHMM-2. The experimental results of online reviews from Amazon show the HHMM method is very effective in product feature extraction.","","Electronic:978-1-4799-5627-2; POD:978-1-4799-5628-9","10.1109/GSCIT.2014.6970125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970125","HHMM;data mining;product feature extraction","Data mining;Educational institutions;Feature extraction;Hidden Markov models;Information retrieval;Maximum likelihood estimation;Training","electronic commerce;feature extraction;hidden Markov models","Amazon;HHMM-1;HHMM-2;e-commerce;nonfeature-contained segment;online reviews;product feature extraction;segment tags;two-level HHMM;two-level hierarchical hidden Markov model","","0","","10","","","14-16 June 2014","","IEEE","IEEE Conference Publications"
"Tonic and scale recognition in Persian audio musical signals","P. Heydarian; L. Jones","London Metropolitan University, UK","2014 12th International Conference on Signal Processing (ICSP)","20150122","2014","","","18","21","This paper proposes methods for computational identification of the tonic and scale in Persian audio musical signals. The chroma, a simplified spectrum is taken as the feature set and Bit-masking and Manhattan distance are used as the classifiers. The results are applicable to various musical traditions in the Mediterranean and the Near East. This approach enables content-based analysis of, and content-based searches of, musical archives.","2164-5221;21645221","CD-ROM:978-1-4799-2187-4; Electronic:978-1-4799-2186-7; POD:978-1-4799-2189-8","10.1109/ICOSP.2014.7014961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014961","Bit-masking;Computational musicology;DSP;Machine Learning;Manhattan distance;Persian scale identification;Pitch Class Profiles;chroma;dastgàh;maqàm;mode;santur;tonic detection","Educational institutions;Histograms;Multiple signal classification;Music information retrieval;Training;Transforms;Tuning","audio signal processing;natural language processing;speech processing","Manhattan distance;Persian audio musical signals;bit-masking;content-based analysis;content-based searches;musical archives;scale recognition;tonic recognition","","0","","11","","","19-23 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Rule-Based Dynamic Decision-Making Stock Trading System Based on Quantum-Inspired Tabu Search Algorithm","Y. H. Chou; S. Y. Kuo; C. Y. Chen; H. C. Chao","Dept. of Comput. Sci. & Inf. Eng., Nat. Chi Nan Univ., Nantou, Taiwan","IEEE Access","20140908","2014","2","","883","896","Heuristic methods or evolutionary algorithms (such as genetic algorithms and genetic programs) are common approaches applied in financial applications, such as trading systems. Determining the best time to buy or sell stocks in a stock market, and thereby maximizing profit with low risks, is an important issue in financial research. Recent studies have used trading rules based on technique analysis to address this problem. This method can determine trading times by analyzing the value of technical indicators. In other words, we can make trading rules by finding the trading value of technique indicators. An example of a trading rule would be, if one technical indicator's value achieves the setting value, then either buy or sell. A combination of trading rules would become a trading strategy. The process of making trading strategies can be formulated as a combinational optimization problem. In this paper, we propose a novel method for applying a trading system. First, the proposed method uses the quantum-inspired Tabu search algorithm to find the optimal composition and combination of trading strategies. Second, this method uses a sliding window to avoid the major problem of over-fitting. The experiment results of earning money show much better performance than other approaches, and the proposed method outperforms the buy and hold method (which is a benchmark in this field).","2169-3536;21693536","","10.1109/ACCESS.2014.2352261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6883114","Tabu search;Trading system;decision making;quantum-inspired algorithm","Decision making;Encoding;Evolutionary computation;Genetic algorithms;Heuristic algorithms;Information analysis;Information retrieval;Search methods;Stock markets;Training","combinatorial mathematics;decision making;econophysics;evolutionary computation;search problems;stock markets","combinational optimization problem;evolutionary algorithm;genetic algorithms;genetic programs;heuristic methods;quantum inspired Tabu search algorithm;rule based dynamic decision making stock trading system;setting value;stock market;technical indicators;trading rules;trading strategy","","1","","32","","20140826","2014","","IEEE","IEEE Journals & Magazines"
"Effective pseudo-relevance feedback for language modeling in extractive speech summarization","S. H. Liu; K. Y. Chen; Y. L. Hsieh; B. Chen; H. M. Wang; H. C. Yen; W. L. Hsu","Inst. of Inf. Sci., Acad. Sinica, Taipei, Taiwan","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20140714","2014","","","3226","3230","Extractive speech summarization, aiming to automatically select an indicative set of sentences from a spoken document so as to concisely represent the most important aspects of the document, has become an active area for research and experimentation. An emerging stream of work is to employ the language modeling (LM) framework along with the Kullback-Leibler divergence measure for extractive speech summarization, which can perform important sentence selection in an unsupervised manner and has shown preliminary success. This paper presents a continuation of such a general line of research and its main contribution is two-fold. First, by virtue of pseudo-relevance feedback, we explore several effective sentence modeling formulations to enhance the sentence models involved in the LM-based summarization framework. Second, the utilities of our summarization methods and several widely-used methods are analyzed and compared extensively, which demonstrates the effectiveness of our methods.","1520-6149;15206149","Electronic:978-1-4799-2893-4; POD:978-1-4799-2894-1; USB:978-1-4799-2892-7","10.1109/ICASSP.2014.6854196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6854196","Kullback-Leibler divergence;Speech summarization;language modeling;pseudo-relevance feedback","Acoustics;Conferences;Decision support systems;Information retrieval;Research and development;Speech;Speech processing","natural language processing;speech processing","Kullback-Leibler divergence measure;effective pseudo-relevance feedback;extractive speech summarization;language modeling;spoken document","","2","","37","","","4-9 May 2014","","IEEE","IEEE Conference Publications"
"Road damage information extraction using high-resolution SAR imagery","C. Fu; Y. Chen; L. Tong; M. Jia; L. Tan; X. Ji","School of Automation, University of Electronic Science and Technology of China, Chengdu 611731, China","2014 IEEE Geoscience and Remote Sensing Symposium","20141106","2014","","","1836","1838","Road is a great part of transportation, emergency response and disaster relief, the monitor and real-time evaluation of the state of road are always important for the rescue works after disaster. SAR has some advantages of all-weather and all-time, which can be well adapted to disaster conditions. Until now the extraction of road damage information has been studied more in optical remote sensing, while less in SAR images. Base on the researches in optical and the studies of road information extraction in SAR, we explored the road damage information extraction in this paper, and proposed a new method of road damage information extraction.","2153-6996;21536996","Electronic:978-1-4799-5775-0; POD:978-1-4799-5314-1; USB:978-1-4799-5774-3","10.1109/IGARSS.2014.6946812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6946812","DMFF;SAR;road damage;road extraction","Earthquakes;Feature extraction;Image edge detection;Indexes;Information retrieval;Roads;Synthetic aperture radar","condition monitoring;disasters;emergency services;feature extraction;geophysical image processing;image resolution;optical images;radar imaging;remote sensing by radar;roads;synthetic aperture radar","disaster relief;emergency response;high-resolution SAR imagery;optical remote sensing;rescue works;road damage information extraction;road state evaluation","","0","","8","","","13-18 July 2014","","IEEE","IEEE Conference Publications"
"Semantic Context-Dependent Weighting for Vector Space Model","T. Nakanishi","Center for Global Commun. (GLOCOM), Int. Univ. of Japan, Minamiuonuma, Japan","2014 IEEE International Conference on Semantic Computing","20140825","2014","","","262","266","In this paper, we represent a dynamic context-dependent weighting method for vector space model. A meaning is relatively decided by a context dynamically. A vector space model, including latent semantic indexing (LSI), etc. relatively measures correlations of each target thing that represents in each vector. However, the vectors of each target thing in almost method of the vector space models are static. It is important to weight each element of each vector by a context. Recently, it is necessary to understand a certain thing by not reading one data but summarizing massive data. Therefore, the vectors in the vector space model create from data set corresponding to represent a certain thing. That is, we should create vectors for the vector space model dynamically corresponding to a context and data distribution. The features of our method are a dynamic calculation of each element of vectors in a vector space model corresponding to a context. Our method reduces a vector dimension corresponding to context by context-depending weighting. Therefore, We can measure correlation with low calculation cost corresponding to context because of dimension deduction.","","Electronic:978-1-4799-4003-5; POD:978-1-4799-4004-2","10.1109/ICSC.2014.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6882038","Semantic computing;context-dependent weighting;correlation;relative semantics;vector space model","Context;Context modeling;Correlation;Information retrieval;Ontologies;Semantics;Vectors","data reduction;indexing;vectors","LSI;data distribution;data set;dimension deduction;dynamic context-dependent weighting method;latent semantic indexing;massive data summarization;semantic context-dependent weighting method;vector dimension;vector space model","","2","","31","","","16-18 June 2014","","IEEE","IEEE Conference Publications"
"Incentive-Driven and Privacy-Preserving Message Dissemination in Large-Scale Mobile Networks","J. Teng; B. Zhang; X. Bai; Z. Yang; D. Xuan","Department of Computer Science and Engineering, The Ohio State University , Columbus, OH, USA","IEEE Transactions on Parallel and Distributed Systems","20141009","2014","25","11","2909","2919","In this paper, we propose a new type of incentive-driven and privacy-preserving systems for large-scale message dissemination in mobile networks. To distribute incentives which encourage forwarding behaviors, such as monetary rewards, we want to keep track of the forwarder list. In our algorithms, we rely on a Probabilistic one-ownership forwarding algorithm to record the list, so that the exchanged messages can be kept short and privacy preserving. More specifically, only one hop of forwarder information, instead of the complete list, is recorded, and the information is updated probabilistically following two ownership flipping models, namely, One-Flip and Always-Flip models. We also use a Bluetooth Service Discovery Protocol (SDP) toolkit to enable fast, configuration-free message exchange. Throughout the paper, we use coupon as a typical type of message to illustrate the core ideas. We have implemented the coupon dissemination system in Java ME. Our experiments on real-world mobile phones, such as Nokia and Samsung phones, and large-scale simulations show that our system is efficient in peer-to-peer message distribution and capable of massive deployment. We believe our key methodology can serve as a general framework for facilitating information propagation on mobile phones, where incentives and privacy protection are both essential.","1045-9219;10459219","","10.1109/TPDS.2013.158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6532281","Message dissemination;coupon;incentive;mobile phone;privacy","Cellular phones;Information retrieval;Large-scale systems;Mobile communication;Privacy;Wireless networks","Bluetooth;Java;data privacy;information dissemination;mobile communication;mobile handsets;peer-to-peer computing;protocols;telecommunication security","Bluetooth service discovery protocol toolkit;Java ME;Probabilistic one-ownership forwarding algorithm;SDP toolkit;always-flip model;configuration-free message exchange;coupon dissemination system;incentive-driven message dissemination;information propagation;large-scale mobile network;one-flip model;peer-to-peer message distribution;privacy protection;privacy-preserving message dissemination;real-world mobile phone","","1","","34","","20130614","Nov. 2014","","IEEE","IEEE Journals & Magazines"
"Triangulation-Based Singer Identification for Duet Music Data Indexing","W. H. Tsai; C. H. Ma","Dept. of Electron. Eng., Nat. Taipei Univ. of Technol., Taipei, Taiwan","2014 IEEE International Congress on Big Data","20140925","2014","","","270","275","This study proposes a system to automatically identify multiple singers in a long audio stream that may have singing voices overlapping in time. The system is of great help in handling the rapid proliferation of music data. To achieve this, an audio stream is segmented into a sequence of consecutive, non-overlapping, fixed-length clips using a sliding window, and then undergoes solo/duet recognition, single singer identification, and duet singer identification. Furthermore, we propose a triangulation-based decision approach to improve the performance of singer identification. The results of the experiment conducted using a database of solo and duet a cappella demonstrate feasibility of the proposed system.","2379-7703;23797703","Electronic:978-1-4799-5057-7; POD:978-1-4799-5058-4","10.1109/BigData.Congress.2014.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906789","Audio stream;Duet recordings;Simultaneous","Accuracy;Databases;Feature extraction;Instruments;Music information retrieval;Testing;Training","audio databases;audio streaming;database indexing;music;speaker recognition","audio stream segmentation;audio stream sequence;cappella;consecutive nonoverlapping fixed-length clips;duet database;duet music data indexing;duet recognition;duet singer identification;singing voices;single singer identification;sliding window;solo database;solo recognition;triangulation-based decision approach;triangulation-based singer identification","","0","","29","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"Identifying top Chinese network buzzwords from social media big data set based on time-distribution features","Y. Tang; T. He; B. Li; X. Hu","School of Computer, Central China Normal University, Wuhan, China","2014 IEEE International Conference on Big Data (Big Data)","20150108","2014","","","924","931","Buzzwords are the main embodiment of Internet culture, which play an important role in public opinion analysis, social focus tracking and language evolution study. At present, questionnaire has been wildly used as a standard method to obtain network buzzwords, which is subjective and costly. In this paper, we will propose a novel algorithm relying on the time-distribution feature of words and a KL-divergence measure to estimate words' popularity so as to figure out buzzwords in a specific period. The time-distribution feature simply states the fact that buzzwords' usage has a sharp increase during a very short period, which is then modeled formally with the KL-divergence measure. Compared with traditional method involving much workforce, the automatic algorithm presented here is clearly more efficient. Moreover, buzzwords identified in this manner will not be affected by individual's subjective opinions, so they can reflect the language usage in practice better. When applying the algorithm to a social media big data set, our experimental results show that the proposed approach can accurately identify buzzwords in a certain period, which is highly coincident with results tagged manually.","","Electronic:978-1-4799-5666-1; POD:978-1-4799-5667-8","10.1109/BigData.2014.7004324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004324","KL divergence;buzzword;language model;time-distribution","Data models;Educational institutions;Information retrieval;Internet;Mathematical model;Probability distribution;Smoothing methods","Big Data;social networking (online);text analysis","Internet culture;KL-divergence measure;buzzword usage;language evolution study;language usage;public opinion analysis;social focus tracking;social media Big Data set;standard method;subjective opinions;time-distribution feature;time-distribution features;time-distribution word feature;top-Chinese network buzzword Identification;word popularity estimation","","0","","19","","","27-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"On the Relationships Among Optimal Symmetric Fix-Free Codes","S. M. H. T. Yazdi; S. A. Savari","Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA","IEEE Transactions on Information Theory","20140710","2014","60","8","4567","4583","Symmetric fix-free codes are prefix condition codes in which each codeword is required to be a palindrome. Their study is motivated by the topic of joint source-channel coding and by some information retrieval problems. Although they have been considered by a few communities they are not well understood. In earlier work, we used a collection of instances of Boolean satisfiability problems as a tool in the generation of all optimal binary symmetric fix-free codes with n codewords and observed that the number of different optimal codelength sequences grows slowly compared with the corresponding number for prefix condition codes. We demonstrate that all optimal symmetric fixfree codes can alternatively be obtained by sequences of codes generated by simple manipulations starting from one particular code. We also discuss simplifications in the process of searching for this set of codes as well as a conjecture, which if correct, together with the other results leads to a relatively fast algorithm which has been implemented in MATLAB to construct all optimal binary symmetric fix-free codes.","0018-9448;00189448","","10.1109/TIT.2014.2330839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834820","Source coding;fix-free codes;minimum-redundancy codes;reversible-variable-length codes","Encoding;Information retrieval;Joints;Lattices;Measurement;Tin;Transforms","combined source-channel coding;variable length codes","MATLAB;codewords;information retrieval problems;joint source-channel coding;optimal codelength sequences;optimal symmetric fix-free codes;palindrome;prefix condition codes;reversible-variable-length codes","","1","","26","","20140613","Aug. 2014","","IEEE","IEEE Journals & Magazines"
"A Zero-Watermarking-Like Steganography and Potential Applications","H. Ishizuka; I. Echizen; K. Iwamura; K. Sakurai","Fac. of Infromation Sci. & Electr. Eng., Kyushu Univ., Fukuoka, Japan","2014 Tenth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20141229","2014","","","459","462","We propose a new steganographic method which is similar to zero-watermarking. In general, digital steganography and digital watermarking, which both embed secret information in host data, have different intended uses. Digital steganography carries embedded secret information through public networks, and the host data serves only as camouflage. Digital watermarking is used to protect host data by embedding secret information. However, the concept of zero-watermarking was proposed in 2001. It does not embed secret information in host data and a result obtained by the interaction of secret information and host data is registered into a certificate authority for protecting the copyright of host data. Our method is also intended to be included in the concept of zero-watermarking broadly. In this paper, we will clarify the difference of zerowatermarking and our method, evaluate the noise immunity of our method, and discuss with various application possibilities.","","Electronic:978-1-4799-5390-5; POD:978-1-4799-5391-2","10.1109/IIH-MSP.2014.121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6998367","probabilistic frequency transform;secret shareing;similar image search;steganography;watermarking","Cryptography;Data mining;Gaussian noise;Information retrieval;PSNR;Watermarking","copyright;security of data;steganography;watermarking","digital steganographic method;digital watermarking;embedded secret information;host data copyright;zero-watermarking","","3","","6","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"Information extraction based on probing algorithm with Bayesian approach","J. Danie Davidson; I. J. Jacob; K. G. Srinivasagam","SCAD College of Engg and Tech, Tirunelveli, India","International Conference on Information Communication and Embedded Systems (ICICES2014)","20150209","2014","","","1","4","Document Annotation is the task of adding metadata information in the document which is useful in information extraction. Document annotation has emerged as a different stream in data mining. Majority of algorithms are concentrated on query workload. This paper uses Probing algorithm with Bayesian approach which identifies the attribute based on query workload, text frequency and content of the previous text annotation such as content value. This method has been implemented in datasets that facilitates data annotation and prioritizes the values of the attributes by ranking scheme. Query cost is also low when compared to other approach. The experimental analysis shows a better performance while comparing with other methods because probability theory provides a principled foundation for such reasoning under uncertainty.","","Electronic:978-1-4799-3834-6; POD:978-1-4799-3698-4","10.1109/ICICES.2014.7033761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033761","Predicate;Probing;Query-cost","Algorithm design and analysis;Bayes methods;Educational institutions;Equations;Information retrieval;Mathematical model;Probes","Bayes methods;data mining;meta data;query processing;text analysis;uncertainty handling","Bayesian approach;data annotation;data mining;document annotation;information extraction;metadata information;probability theory;probing algorithm;query cost;query workload;ranking scheme;reasoning;text annotation;text frequency;uncertainty","","0","","14","","","27-28 Feb. 2014","","IEEE","IEEE Conference Publications"
"A support system for selection of reviewers","J. Protasiewicz","National Information Processing Institute in Poland","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","3062","3065","In this paper we deal with a reviewer assignment problem and as a solution we propose a decision support system which is able to recommend relevant reviewers to evaluate grant proposals as well as manuscripts. The system is composed of a user interface and three modules responsible for data transformation into information and knowledge. Firstly, a data acquisition module collects data concerning researchers. Next, an information retrieval module builds researchers' profiles using various machine learning methods for keyword extraction, information classification and disambiguation. Finally, a recommendation module generates a ranking of potential reviewers based on a cosine similarity measure between researchers' profiles and a problem that has to be reviewed. The system is meant to work autonomously, without any manual adjustment. It is available for free use on the Internet (http://sssr.opi.org.pl)1.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974397","decision support system;machine learning;reviewer assignment problem","Data acquisition;Data mining;Indexes;Information retrieval;Proposals;Vectors","Internet;data acquisition;decision support systems;information retrieval;learning (artificial intelligence);pattern classification;user interfaces","Internet;cosine similarity measure;data acquisition module;data transformation;decision support system;disambiguation;information classification;information retrieval module;keyword extraction;machine learning method;recommendation module;researcher profiles;reviewer assignment problem;user interface","","1","","29","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Social Image Tagging With Diverse Semantics","X. Qian; X. S. Hua; Y. Y. Tang; T. Mei","SMILES Laboratory, School of Electronics and Information Engineering, Xi'an Jiaotong University, Xi'an, China","IEEE Transactions on Cybernetics","20141113","2014","44","12","2493","2508","We have witnessed the popularity of image-sharing websites for sharing personal experiences through photos on the Web. These websites allow users describing the content of their uploaded images with a set of tags. Those user-annotated tags are often noisy and biased. Social image tagging aims at removing noisy tags and suggests new relevant tags. However, most existing tag enrichment approaches predominantly focus on tag relevance and overlook tag diversity problem. How to make the top-ranked tags covering a wide range of semantic is still an opening, yet challenging, issue. In this paper, we propose an approach to retag social images with diverse semantics. Both the relevance of a tag to image as well as its semantic compensations to the already determined tags are fused to determine the final tag list for a given image. Different from existing image tagging approaches, the top-ranked tags are not only highly relevant to the image but also have significant semantic compensations with each other. Experiments show the effectiveness of the proposed approach.","2168-2267;21682267","","10.1109/TCYB.2014.2309593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775274","Image tagging;semantic;social media;tag diversity;tag enrichment;tag relevance","Birds;Cultural differences;Image retrieval;Information retrieval;Semantics;Tagging;Visualization","content-based retrieval;image retrieval;social networking (online)","diverse semantics;image-sharing Web sites;semantic compensation;social image tagging;tag diversity problem;tag enrichment approach;tag relevance;top-ranked tags;user-annotated tags","","14","","93","","20140319","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"A time saving index construction in geospatial searching","A. Joshi; U. Patil","ME Student at (Dept. of Comp) RCPIT Engineering College, Shirpur Dist. Dhule, Maharashtra, India","2014 International Conference on Data Science & Engineering (ICDSE)","20141204","2014","","","140","144","In general, the IR Tree is widely used for indexing in geospatial searching. The traditional internet is gaining a geospatial dimension driven by the emergence of mobile internet. The basic IR-tree with a search algorithm for top-k document facilitates spatial and textual narrowing of the dataset along with relevance computation and ranking of the documents simultaneously. Different weights are adopted by IR-tree on textual and spatial relevances of documents searched at the runtime. Many experiments has been conducted and their results has shown that IR-tree performs the state-of-the art approaches for geospatial searching but at the cost of increased storage overhead along with the hours invested in building IR tree. This paper introduces the concept of semi bulk loading in the data structure to reduce the construction time. The results has shown that with the proposed concept the construction time required for constructing IR-tree is reduced significantly and is capable of excellent performance.","","Electronic:978-1-4799-5460-5; POD:978-1-4799-5462-9","10.1109/ICDSE.2014.6974626","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974626","Geoscopes;Geospatial searching;Location intent;Semi bulk loading","Geospatial analysis;Indexing;Information retrieval;Internet;Loading;Spatial databases","Internet;mobile computing;tree data structures","IR-Tree;IR-tree;Internet;data structure;geospatial dimension driven;geospatial searching;mobile internet;relevance computation;search algorithm;time saving index construction;top-k document facilitates spatial","","0","","17","","","26-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"A fuzzy-ontology-driven method for a personalized query reformulation","H. Baazaoui-Zghal; H. Ben Ghezala","Riadi-GDL Laboratory, ENSI, Manouba University, Tunis, Tunisia","2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20140908","2014","","","1640","1647","Ontologies have proven their utility in the area of Information Retrieval. However, building and updating ontologies manually is a long and tedious task. Moreover, crisp ontologies are not capable to support uncertain information. One interesting solution is to integrate fuzzy logic into ontology to handle vague and imprecise information. This paper presents a method for individual fuzzy ontology building. The key aspects in our proposal are: (1) an automatic building of an individual fuzzy ontology; (2) a query reformulation based, on the one hand, on the weights associated with the concepts and all existing relations in the fuzzy ontology and, on the other hand, on users' preferences, (3) an update of the membership concepts and relations' values after each users search, and (4) the use of the proposed fuzzy ontology and service ontology to individually classify documents by services. Our method has endured a twofold evaluation. Firstly, we have evaluated the impact of the update and the weights' variations on the search results. Secondly, we have studied how the query reformulation has led to a quality results improvement, both in terms of precision and recall.","1098-7584;10987584","CD-ROM:978-1-4799-2073-0; Electronic:978-1-4799-2072-3; POD:978-1-4799-2074-7","10.1109/FUZZ-IEEE.2014.6891820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6891820","Fuzzy ontology;individual ontology;personalization;query reformulation","Buildings;Fuzzy logic;Information retrieval;Integrated circuits;Ontologies;Semantics;Vectors","fuzzy logic;fuzzy set theory;information retrieval;ontologies (artificial intelligence)","crisp ontologies;fuzzy logic;fuzzy ontology-driven method;information retrieval;personalized query reformulation;service ontology","","2","","20","","","6-11 July 2014","","IEEE","IEEE Conference Publications"
"Defined entity extraction based on Indonesian text document","T. Mangasi; A. Erwin; H. P. Ipung","Department of Information Technology, Facutly of Engineering and Information Technology, Swiss German University, Tangerang, Indonesia","2014 International Conference on ICT For Smart Society (ICISS)","20150119","2014","","","61","65","Entity Extraction basically is a part of process to extract document from unstructured metadata text documents. It is important to know whether the words stated in some documents are useful and contains of important information. With the growth of technology including website and internet, some involved in how semantic and technical challenged to make entity extraction much more efficient. In this case there are several tools that complied with existing name finder extraction. OpenNLP plays a good instrument to imply. Extracting entities such as person names, location and organization become terminology to defined the field of entity extraction. In generating the model for training set, Indonesian articles and documents need to be plenty and diverse so those entity easily to know exactly how to differentiate each other entities. There are several problems that necessary to minimize such as accuracy and efficiency. Percentage of word inside training set also need to have more custom and unique sentence. The result shown will be based on training set and the model generated. Mainly whole articles are in Indonesian language and this is not yet created in OpenNLP models.","","Electronic:978-1-4799-6322-5; POD:978-1-4799-6323-2; USB:978-1-4799-6321-8","10.1109/ICTSS.2014.7013152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7013152","Entity Extraction;Entity Models;OpenNLP;Training Set","Data mining;Entropy;Feature extraction;Information retrieval;Natural language processing;Organizations;Training","Internet;natural language processing;text analysis","Indonesian articles;Indonesian language;Indonesian text document extraction;Internet;OpenNLP models;Web site;defined entity extraction;name finder extraction;person names;unstructured metadata text documents","","0","","4","","","24-25 Sept. 2014","","IEEE","IEEE Conference Publications"
"Orness Measure of OWA Operators: A New Approach","A. Kishor; A. K. Singh; N. R. Pal","Dept. of Electron. & Commun., Indian Stat. Inst., Kolkata, India","IEEE Transactions on Fuzzy Systems","20140729","2014","22","4","1039","1045","The ordered weighted averaging (OWA) operators are an extensively used class of aggregation operators. The weight vector that is associated with an OWA can determine the attitudinal characters of the aggregation. One of these characterizing measures is called the orness measure. The aim of this paper is to introduce orness measures in an axiomatic framework and to propose an alternate definition of orness that is based on these axioms. The proposed orness measure satisfies a more generalized set of axioms than Yager's orness measure. We further calculate the maximum Shannon's entropy of the OWA operator corresponding to a fixed value of orness of our proposed measure as well as of Yager's orness. For a given level of orness, the maximum entropy corresponding to the proposed orness measure, is more than that of Yager's. This suggests that the proposed measure is a more plausible one.","1063-6706;10636706","","10.1109/TFUZZ.2013.2282299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601708","Aggregation operators;maximum entropy;ordered weighted averaging (OWA) operator;orness","Entropy;Information retrieval;Open wireless architecture;Optimization;Q measurement;Vectors;Weight measurement","mathematical operators;maximum entropy methods;sensor fusion","Information fusion;OWA operators;Pager orness measure;aggregation operators;attitudinal character determination;axiomatic framework;information aggregation;maximum Shannon entropy;ordered weighted averaging operators","","6","","44","","20130917","Aug. 2014","","IEEE","IEEE Journals & Magazines"
