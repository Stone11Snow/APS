"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5337487,5328834,5337563,5337238,5336954,5336917,5337106,5337538,5327951,5337579,5337610,5337484,5337108,5337137,5328143,5337146,5329188,5328090,5337442,5337421,5337603,5337530,5329125,5337451,5337453,5333564,5333359,5331483,5331427,5332084,5332080,5331626,5333438,5331643,5331325,5331635,5331571,5331631,5331490,5331719,5331527,5331521,5332134,5331422,5334509,5331708,5319151,5326066,5319712,5319718,5190700,5319132,5319346,5319699,5324969,5318970,5190706,5319390,5319138,5326206,5319034,5319247,5326093,5319225,5319299,5319111,5326359,5190637,5190643,5322096,5325345,5319211,5319119,5184910,5321617,5325308,5326369,5313816,5313824,5313756,5313772,5313736,5313728,5313827,5313808,5318701,5313778,5313813,5313740,5313760,5313730,5313787,5313836,5313770,5314049,5313835,5313806,5313768,5313846,5308112",2017/05/04 20:57:05
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A Hybrid Web Service Selection Approach Based on Singular Vector Decomposition","S. L. Pan; Q. J. Mao; Y. X. Zhang","Dept. of Comput. Sci. & Technol., Ningbo Univ., Ningbo, China","2009 Congress on Services - I","20091110","2009","","","724","731","With the number of registered Web services growing, Identifying desired Web service is crucial for Web users. Current keyword based service search are inefficient in two main aspects: poor scalability and lack of semantics. Firstly ,the users are overwhelmed by the huge number of irrelevant services returned. Secondly, the intentions of users and the semantics in Web services are ignored. We propose a hybrid approach of Web service selection that complements logic based reasoning with approximate matching. In particular, the large set of available Web services is first clustered into a set of smaller groups. Then a logic based reasoning with approximate matching based on Ontology is applied, which is followed by a syntactic matching method based on Singular Value Decomposition (SVD). Therefore, service matching is conducted within both syntactic-level and semantic-level.A set experimental results demonstrate that the proposed method outperforms several other alternative methods.","2378-3818;23783818","CD-ROM:978-0-7695-3708-5","10.1109/SERVICES-I.2009.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190706","SVD;Service compose;Web service","Computer science;Impedance matching;Indexing;Information retrieval;Large scale integration;Logic;Ontologies;Scalability;Singular value decomposition;Web services","Web services;formal logic;inference mechanisms;information retrieval;ontologies (artificial intelligence);pattern matching;singular value decomposition","approximate matching;hybrid Web service selection approach;keyword based service search;logic based reasoning;ontology;semantic Web service retrieval;singular vector decomposition;syntactic matching method","","0","","25","","","6-10 July 2009","","IEEE","IEEE Conference Publications"
"Implementation and Research on Key Techniques of Color Image Retrieval System Based on Regions of Interest","M. Ziming; J. Kebin","Sch. of Electron. Inf. & Control Eng., Beijing Univ. of Technol., Beijing, China","2009 WRI World Congress on Software Engineering","20091110","2009","1","","377","381","The method of design and implementation of image retrieval system based on regions of interest (ROI) is introduced in this article: First of all, the system's main function is discussed, which is focused on human-computer interaction and real-time feature extraction. The retrieval system's features are followed by the ROI to the color and spatial information for the ROI extraction, characterization, this regional characteristics matching method achieves a rapid and accurate way to retrieve. The results are showed that the retrieval algorithm is of high accuracy and retrieval recall, the system is made by user-friendly human-computer interaction, with good maintenance and scalability.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319132","human-computer interaction;regions of interest;retrieval algorithm;retrieval system","Buildings;Color;Content based retrieval;Control engineering;Design methodology;Image retrieval;Information retrieval;Internet;Java;User interfaces","content-based retrieval;feature extraction;human computer interaction;image colour analysis;image retrieval;visual databases","color image retrieval system;real-time feature extraction;regions of interest;spatial information;user-friendly human-computer interaction","","0","","8","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"Evaluating the weighted-keyword model to improve clinical question answering","Y. G. Cao; J. Ely; H. Yu","University of Wisconsin-Milwaukee","2009 IEEE International Conference on Bioinformatics and Biomedicine Workshop","20091113","2009","","","331","335","Physicians ask many complex questions during their encounters with patients. Question answering systems provide immediate and direct answers to ad hoc clinical questions, and because these systems might aid in the practice of evidence-based medicine, we are developing the clinical question answering system, AskHERMES, to generate answers to such questions. In this study, we report the evaluation of a new weighted-keyword model for improving our question answering system. As part of this development, a physician manually examined AskHERMES' answers to 20 ad hoc clinical questions created with and without the weighted-keyword model. The results show that the weighted-keyword model improves quality in question answering. AskHERMES can be accessed at http://www.AskHERMES.org.","","POD:978-1-4244-5121-0","10.1109/BIBMW.2009.5332084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332084","","Automatic control;Cardiovascular diseases;Data mining;Frequency;Information retrieval;Libraries;Multimedia systems;Osteoporosis;Speech;Unified modeling language","information retrieval;medical information systems","AskHERMES;Information retrieval systems;ad hoc clinical questions;clinical question answering system;evidence-based medicine;weighted-keyword model","","0","","10","","","1-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Chinese semantic role labeling using CRFs and SVMs","Y. Tan; X. Wang; Y. Chen","Beijing University of Posts and Telecommunications. Beijing 100876, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","5","There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction. In this paper, we present an semantic role labeling (SRL) system for Chinese that exploits many aspects of the rich features of the languages. Finally, we compare system based on CRFs and SVMs. The experiment yields a global SRL FB1 score of 92.89%.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313827","Conditional Random Fields;Semantic Role Labeling;Support Vector Machines;Tracking","Computational linguistics;Data mining;Gold;Information retrieval;Labeling;Natural languages;Performance evaluation;Support vector machines;Teeth;Text recognition","computational linguistics;information retrieval;support vector machines","CRF;Chinese semantic role labeling;SVM;computational linguistics;document retrieval;information extraction;machine translation;question answering","","0","","17","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"A weakly supervised optimize method in latent semantic indexing","D. Ji; D. Guo; D. Cai; Y. Bai","Knowledge Engineering Research Center, Shenyang Institute of Aeronautical Engineering. Shenyang, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","7","Latent Semantic Indexing (LSI) is an effective method in the way of feature extraction, which has been applied to many text learning tasks, such as text clustering and information retrieval. This paper thoroughly analyses the influence of term co-occurrences on the mapping of Latent Semantic Indexing and brings forward a method named pseudo document which strengthens the beneficial term co-occurrences by adding heuristic knowledge to text collection so as to make the mapping of Latent Semantic Indexing more reasonable. The experimental results show that the method named pseudo document can effectively improve the performance of patent retrieval.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313756","Latent Semantic Indexing;Patent Retrieval;Pseudo Document;Term Co-occurrence","Aerospace engineering;Computer aided instruction;Feature extraction;Indexing;Information retrieval;Knowledge engineering;Large scale integration;Least squares approximation;Matrix decomposition;Optimization methods","computational linguistics;feature extraction;indexing;information retrieval;learning (artificial intelligence);text analysis","feature extraction;heuristic knowledge;information retrieval;latent semantic indexing;pseudo document method;term co-occurrence;text clustering;text learning task;weakly supervised optimize method","","0","","12","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Translate Chinese organization names using examples and web","F. Ren; J. Zhu; H. Wang","Northeastern University, Shenyang, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","7","This paper proposes a new approach for translating Chinese organization names that uses example-based method along with Web assistance. It consists of two phases, first, it generates a translation candidate for the input Chinese organization name by an example-based translation method; and secondly, it uses the Web to amend this translation candidate so as to finish such tasks: translation candidate reordering, word selection revising, and adjustment of the use of function words. Experimental results show that our method outperforms competing traditional statistical translation method in the task of translating Chinese ONs.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313760","Chinese organization names translation;examples-based machine translation method;machine translation;named entity translation;web assistant translation method","Appropriate technology;Dictionaries;Flexible structures;Information retrieval;Lab-on-a-chip;Search engines;Text recognition;Training data","Internet;language translation;learning by example;natural language processing","Chinese organization name translation;Web assistance;example based method;translation candidate reordering;word selection revising","","3","","14","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Grid-Based Distributed Computing Environment for Automatic Concept Extraction and Content Supporting Service","C. M. Wang; M. C. Chiang; C. S. Yang","Dept. of Comput. Sci. & Eng., Nat. Sun Yat-sen Univ., Kaohsiung, Taiwan","2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing","20091110","2009","","","161","166","This paper proposes an automatic concept extraction and content supporting service, called ACECSS. The service sends a large number of question items to the word segmentation system of Academia Sinica, Taiwan to split each question item into terms. Then, a database of terms is created, and the sequence relation of terms is found. After that, ACECSS will automatically extract concepts associated with each question item when teachers edit or students read the examination sheet. The concepts can even be sent as queries to a search engine to get more contents to aid learning. In addition, ACECSS is able to automatically rank the relations between the learning contents based on the similarity between the learning contents, the number of times the learning contents are accessed, and voting by the user of the learning contents. Moreover, the computations of similarity are distributed using grid computing technology. As such, the service described herein can aid the users of the service to learn much quicker and better.","","POD:978-1-4244-4902-6","10.1109/UIC-ATC.2009.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319247","","Content based retrieval;Distributed computing;Education;Frequency;Grid computing;Information retrieval;Internet;Search engines;Sheet materials;Voting","computer aided instruction;distance learning;grid computing;query processing;search engines;word processing","ACECSS;automatic concept extraction;content supporting service;grid-based distributed computing;learning aids;queries;search engine;word segmentation system","","4","","15","","","7-9 July 2009","","IEEE","IEEE Conference Publications"
"DOCINER: A Document Indexation Tool for Learning Objects","S. Niwattanakul; M. Eboueya; P. Martin","Sch. of Inf. Technol., Suranaree Univ. of Technol., Nakhon Ratchasima, Thailand","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","859","863","In this paper, we present a method we implemented to help a user index documents (and, in particular, learning objects) according to a given set of concepts (terms referring to domains or topics). The user first associates keywords to the concepts. Our method uses such associations to suggest simple rules for indexing a document by concepts according to the keywords this document contains. Then, our system uses those rules to perform the indexation of documents.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331643","document indexation;formal concept analysis","Animation;Computer network management;Data mining;Databases;Indexing;Information retrieval;Information technology;Network servers;Ontologies;Standards development","computer aided instruction;indexing;text analysis","DOCINER;document indexation tool;keywords;learning objects","","0","","30","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"A hybrid approach for Arabic multi-word term extraction","I. Bounhas; Y. Slimani","Department of Computer Science, Faculty of Sciences of Tunis, University of Tunis, 1060, Tunis, Tunisia","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","8","Building a domain model from a specialized corpus requires identifying candidate terms. It also includes identifying semantic relations between terms. Once this model is constructed it can be used for many tasks of information retrieval. In this process, multi-word terms have a great importance. In the one hand they constitute domain relevant candidate terms. On the other hand syntactic relations that link their constituents can be used to infer semantic relations between terms. In this paper we propose to extract mutli-word terms from Arabic specialized corpora. The proposed approach uses linguistic rules based on morphological features and POS (Part Of Speech) tags to parse documents and retrieve candidate terms. Statistical measures are used to deal with ambiguities generated by the linguistic tools and to rank candidate terms according to their relevance. We present experiments on a corpus from the environment domain. We report high quality results that are confirm the targets set for the precision metric.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313728","Arabic language processing;morpho-syntactic parsing;multi-word terms;terminology extraction","Bellows;Books;Buildings;Computer science;Data mining;Information retrieval;Ontologies;Speech;Terminology","information retrieval;natural language processing","Arabic multiword term extraction;Arabic specialized corpora;domain model;information retrieval;linguistic rules;multiword terms;part of speech tags;semantic relation;syntactic relation","","7","","16","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Exploitation of ontological resources for scientific literature analysis: Searching genes and related diseases","A. Jimeno-Yepes; R. Berlanga-Llavori; D. Rebholz-Schuhmann","European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, U.K.","2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20091113","2009","","","7073","7078","Ontological resources such as controlled vocabularies, taxonomies and ontologies from the OBO foundry are used to represent biomedical domain knowledge. The development of such resources is a time consuming task. Once they are finished they contribute to standardization of information representation, interoperability of IT solutions, literature analysis and knowledge discovery. Text mining comprises IT solutions for information retrieval (IR) and information extraction (IE). IR technology exploits ontological resources to select documents that fit best to the processed query, for example, through indexing of the literature content with concept ids or through disambiguation of terms in the query. IE solutions make use of the ontological labels to identify concepts in the text. The text passages that denote conceptual entries are then used either to annotate named entities or to relate the named entities to each other. For knowledge discovery (KD) solutions the identified concepts in the scientific literature are used to relate entities to each other, e.g. to identify gene-disease relations based on shared molecular functions.","1094-687X;1094687X","CD-ROM:978-1-4244-3296-7","10.1109/IEMBS.2009.5333359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5333359","","Diseases;Foundries;Information analysis;Information representation;Information retrieval;Ontologies;Standardization;Taxonomy;Text mining;Vocabulary","data mining;diseases;genetics;indexing;information retrieval systems;medical information systems;ontologies (artificial intelligence);vocabulary","concept ids;conceptual entries;diseases;genes;indexing;information extraction;information retrieval;knowledge discovery;ontological labels;ontological resources;query;scientific literature analysis;shared molecular functions;taxonomies;text mining;text passages;vocabularies","0","0","","51","","","3-6 Sept. 2009","","IEEE","IEEE Conference Publications"
"db4OWL: An Alternative Approach to Organizing and Storing Semantic Data","A. Batzios; P. A. Mitkas","Philips Applied Technologies","IEEE Internet Computing","20091106","2009","13","6","48","55","The complex structure of semantic data still poses a challenge in storing, querying, and organizing Web information. Although researchers have proposed various semantic database system approaches over the years, it seems that most systems have tried to provide industrial-strength scalability too soon. Consequently, most semantic databases still rely on the relational model of storing data and still use SQL-like query languages for data retrieval. The db4OWL semantic database prototype addresses many of the shortcomings of current systems and features native OWL-querying as well as the ability to store and query multiple ontologies concurrently.","1089-7801;10897801","","10.1109/MIC.2009.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5318701","OWL database;OWL querying;RDF;semantic database;semantic storage","Database languages;Database systems;Industrial relations;Information retrieval;Ontologies;Organizing;Prototypes;Relational databases;Scalability;Spatial databases","SQL;data models;knowledge representation languages;ontologies (artificial intelligence);query processing;relational databases;semantic Web","SQL-like query language;Web information querying;data retrieval;db4OWL querying;industrial-strength scalability;relational model;semantic data organization;semantic data storing;semantic database system approach","","0","","9","","","Nov.-Dec. 2009","","IEEE","IEEE Journals & Magazines"
"A fast retrieval algorithm for the earth mover's distance using EMD lower bounds and the priority queue","M. Shishibori; D. Koizumi; K. Kita","The University of Tokushima, Tokushima, Japan","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","6","Earth mover's distance (EMD) is a distance measure between two distributions, and has been widely used in multimedia information retrieval systems, especially content-based image retrieval systems. When the EMD is applied to image problems based on color or texture, the EMD reflects the human perceptual similarities. Its computations, however, is too expensive to use in large-scale databases. In order to achieve the efficient computation of the EMD during query processing, we have developed ldquofastEMDrdquo, a library for high-speed feature-based similarity retrievals in large databases. This paper introduces techniques that are used in the implementation of the fastEMD and demonstrates the efficiency in extensive experiments.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313772","Content-based Image Retrieval;Earth Mover's Distance;Lower Bounds","Content based retrieval;Earth;Humans;Image databases;Image retrieval;Information retrieval;Large-scale systems;Multimedia databases;Multimedia systems;Spatial databases","content-based retrieval;data structures;feature extraction;image colour analysis;image retrieval;image texture;linear programming;multimedia databases;very large databases","CBIR;EMD lower bound;content-based image retrieval system;earth mover distance measure;fastEMD library;high-speed feature-based similarity retrieval;human perceptual similarity;image color;image texture;information retrieval algorithm;large-scale multimedia database;linear programming problem;multimedia information retrieval system;priority queue;query processing","","0","","8","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Construction and Application of SOTER-LUCC Database in Fujian Province","Z. q. Chen; J. f. Chen","Coll. of Geogr. Sci., Fujian Normal Univ., Fuzhou, China","2009 WRI World Congress on Software Engineering","20091110","2009","3","","181","184","Soil and terrain digital database (SOTER) recognizes the regional land according to terrain, rock, and soil providing a comprehensive framework for the data storage and retrieval. Currently SOTER has been authorized and become one of hotspots in the studies of soil and sustainable use of land. Combining SOTER and LUCC, taking SOTER units as the frame of LUCC information, constructing SOTER-LUCC database will provide more abundant and reliable data sources and can be used for a wide range of applications at different scales. Backed by the technology of ldquo3Srdquo, the study builds the SOTER-LUCC database in a moderate scale in Fujian province which has been applied in the assessment of the relative sensitivity of ecosystem to acid deposition and the suitable sites selection for Euphoria Longan in Fujian province and turned out to be feasible.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319390","3S;Fujian province;LUCC;SOTER","Application software;Ecosystems;Geographic Information Systems;Information retrieval;Memory;Software engineering;Soil;Spatial databases;Temperature;Terrain mapping","ecology;geographic information systems;land use planning;regional planning;rocks;soil;sustainable development;terrain mapping","3S technology;Euphoria Longan;Fujian province;GIS;SOTER-LUCC database;acid deposition;data retrieval;data storage;ecosystem;regional land recognition;relative sensitivity;rock;site selection;soil and terrain digital database;sustainable land use","","0","","12","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"Global Feature Properties by Image Modifications and Variations","J. Jeong; C. Park; B. Jeon","Sch. of Inf. & Commun. Eng., Sungkyunkwan Univ., Suwon, South Korea","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1611","1614","In this paper, we examine the properties of some typical instance of global image features to provide clues to image retrieval by efficient selection of them as content. It is performed by calculating the feature difference between images including variously transformed images. Image data might be caused image variations by typical modification or deterioration originated from image collection process. We intend to classify the transformed images as identical group and investigate the appropriate kind of feature which is robust against the image variation and difference measuring method distinguishable from other group. The result can be applied for image identification against environmental modifications or identical photographic image grouping working with local feature.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331325","global feature;image identification;photographic image grouping;typical modification","Brightness;Content based retrieval;Feature extraction;Histograms;Image reconstruction;Image retrieval;Image storage;Information retrieval;Robustness;Testing","feature extraction;image retrieval","environmental modifications;global image feature properties;identical photographic image grouping;image collection process;image identification;image modifications;image retrieval;image transformation;image variations","","0","","5","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Using Local Latent Semantic Indexing with Pseudo Relevance Feedback in Web Image Retrieval","R. He; Y. Zhu; W. Zhan","Coll. of Comput. Sci., Wuhan Univ. of Sci. & Eng., Wuhan, China","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1354","1357","Latent Semantic Indexing (LSI) and Relevance Feedback (RF) have been shown to be extremely useful in information retrieval respectively. But at the context of Web image retrieval, LSI is limited for the Single Value Decomposition (SVD) computation cost to large dataset while RF is confused with the reluctance of interaction for most Web users. In this paper, a Pseudo Relevance Feedback approach based on Local Latent Semantic Indexing (PRF-LLSI) is proposed, which integrating the LSI and RF, and making use of the benefit of them while solving the limitation of them. The Local LSI (LLSI) method performs a low-dimensional SVD on the local region of initial retrieved results. Both keywords and image contents of the Web images are computed by LLSI to re-rank the initial retrieval results automatically. The PRF-LLSI contribute to the following: (1) Local LSI resolves the heavy computation cost of LSI; (2) Pseudo Relevance Feedback doesn't need the user's interaction; (3) LLSI combine the textual and visual features, which improves the precision of the system. The experiments are done in our VAST (VisuAl & SemanTic image search) system, and the results show the effectiveness of the proposed method.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331483","Local Latent Semantic Indexing (LLSI);Pseudo-Relevance Feedback (PRF);Web Image Retrieval","Computational efficiency;Content based retrieval;Feedback;Image retrieval;Indexing;Information retrieval;Large scale integration;Radio frequency;Search engines;Web search","Internet;image retrieval;indexing;relevance feedback;singular value decomposition","VAST;Web image retrieval;information retrieval;local latent semantic indexing;pseudo relevance feedback;single value decomposition;textual features;visual & semantic image search system;visual features","","0","","26","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Research on Automatic Extraction of Web Metadata","H. Changxia; L. Xiaoxing","Comput. & Inf. Eng. Dept., Shijiazhuang Railway Inst., Shijiazhuang, China","2009 WRI World Congress on Software Engineering","20091110","2009","1","","449","452","Traditional Web retrieval system is based on whole-length search of keyword, which would bring large results, but users can't find the answer that they need quickly. This paper presents a model of information retrieval based on media data, to improve the web information retrieval efficiency and precision in specific fields. The result shows that the method based on metadata is effective for the task of web text information retrieval.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319151","association rule;chinese lexical analysis;metadata;subject expansion","Content based retrieval;Databases;Electronic mail;Information resources;Information retrieval;Rail transportation;Railway engineering;Search engines;Web pages;Web search","Internet;information retrieval;meta data","Web metadata;Web text information retrieval;automatic extraction;information retrieval","","0","","5","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"Sentence Similarity Computation Based on POS and Semantic Nets","M. C. Lee; J. W. Zhang; W. X. Lee; H. Y. Ye","Dept. of Comput. & Commun. Eng., Ming Chuan Univ., Taoyuan, Taiwan","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","907","912","This paper presents a novel sentence similarity computation algorithm. The proposed algorithm is based on the concepts of part-of-speech (POS) and the WordNet semantic nets. Unlike other related researches that focused only on short sentences, our algorithm is applicable to short (4-5 words), medium (8-12 words), and even long sentences (over 12 words). The experiment demonstrates that the proposed algorithm has outstanding performance in handling with long sentences with complex syntax. The significance of this research lies in the semantic similarity extracting of word sets with different part-of-speeches.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331635","","Buildings;Data mining;Information analysis;Information retrieval;Matrix decomposition;Natural language processing;Natural languages;Singular value decomposition;Sparse matrices;Support vector machines","natural language processing;semantic networks;speech processing;word processing","WordNet semantic nets;natural language processing;part-of-speech;semantic similarity word sets extraction;sentence similarity computation algorithm","","2","","12","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Literature Characterization and Similarity Retrieval Based on Hierarchical Clustering","P. Li","Sch. of Inf., Linyi Normal Univ., Linyi, China","2009 WRI World Congress on Software Engineering","20091110","2009","1","","397","400","The growing number of literature in journals database raises a new and challenging search problem: locating desired literature. Traditional keyword search is insufficient: the specific literature users require is possibly not captured. We introduce a new algorithm of hierarchical clustering. With this algorithm, we cluster the keywords into a concept tree, then we turn every literature into an induced tree. We propose a new method for theses retrieval, which based on concept similarity. This method improves in recall and precision.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319138","Hierarchical clustering;Journals database;Literature Characterization;Similarity search","Association rules;Binary trees;Clustering algorithms;Databases;Filtering algorithms;Information retrieval;Keyword search;Search engines;Search problems;Software engineering","information retrieval;literature","concept tree;hierarchical clustering;journals database;keywords;literature characterization;similarity retrieval","","0","","5","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"Combining Shape and Color for Retrieval of 3D Models","C. R. Ruiz Jr; R. Cabredo; L. J. Monteverde; Z. Huang","Coll. of Comput. Studies, De La Salle Univ., Manila, Philippines","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1295","1300","Current research on the retrieval systems for 3D models focuses on using the shape of the models to facilitate search and retrieval. This paper explores the possibility of augmenting the existing 3D shape-based similarity measures by combining shape and color. First, a new descriptor was developed based on the D2 shape descriptor. In our method, Npairs of faces are randomly chosen from a 3D model, with probability proportional to the area of the face. The ratio of the smaller area over the larger area is computed and its frequency stored, generating a frequency distribution of Nratios which is stored as the second dimension of a 2D array,while the first dimension contains the frequency distribution of distances of randomly generated point pairs (the D2distribution). Second, this research introduces the use of the color features of a 3D model in combination with the shape features to determine similarity. The research involves the study and adoption of an existing 2D color-based similarity measure for 3D models. The analysis of the results is based on the precision and recall of both approaches.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331571","3D models;color retrieval;shape database;shape retrieval;similarity measures","Airplanes;Biological system modeling;Databases;Educational institutions;Electronic mail;Frequency;Hardware;Information retrieval;Internet;Shape measurement","image processing;image retrieval;solid modelling","3D model color features;3D model retrieval system;3D model shape features;D2 shape descriptor;frequency distribution","","1","","13","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Position encryption of extended surfaces for subpixel localization of small-sized fields of observation","J. A. Galeano Zea; P. Sandoz; L. Robert","Institut FEMTO-ST, D&#233;partement d'Optique PM Duffieux, UMR CNRS Universit&#233; de Franche-Comt&#233; 6174, F-25030 Besan&#231;on cedex, France","2009 International Symposium on Optomechatronic Technologies","20091110","2009","","","22","27","A vision system is used for measuring in-plane target position, displacement and orientation. An encrypted pseudo-periodic pattern fixed on the target forms a phase reference. Absolute position is determined with subpixel accuracy by phase computations from any local view of a small zone of the pattern. Method principle is presented and performances are characterized. The capability to resolve position on depth ranges larger than the lens depth of focus is demonstrated. The method is applied to position referencing of live cell culture boxes and could be used as visual control sensor in other applications.","","POD:978-1-4244-4209-6","10.1109/ISOT.2009.5326093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326093","","Automatic control;Cryptography;Displacement measurement;Focusing;Image reconstruction;Information retrieval;Lenses;Machine vision;Position measurement;Telephony","image processing;position measurement","absolute position;encrypted pseudo-periodic pattern;in-plane target position;live cell culture boxes;phase computations;phase reference;position encryption;position referencing;subpixel localization;vision system;visual control sensor","","0","","6","","","21-23 Sept. 2009","","IEEE","IEEE Conference Publications"
"Comparison of visual and vibration displays for finding spatial memory in Intelligent Space","M. Niitsuma; H. Hashimoto","Department of Precision Mechanics, Chuo University, Tokyo 112-8551, Japan","RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication","20091110","2009","","","587","592","We have proposed the spatial memory which is a human interface to operate iSpace agents such as mobile robots, computer displays, etc. Spatial memory enables users to store computerized information ranging from digital files and commands for robots in real space by assigning digital information to a three-dimensional position. Users can retrieve the information by pointing the locations using their own bodies directly. The accessed information will be delivered to a suitable iSpace agent who should execute it. We named information arranged into real space ldquoSpatial-Knowledge-Tagrdquo (SKT). In order to encourage people to share useful information via spatial memory, they need to retrieve pre-arranged SKTs which are arranged by somebody. In this paper, firstly we show possibility of finding SKTs through seeing other users' actions, but not using any display to show locations and content types of SKT. Then, we present two kinds of displays to show users locations and content types of SKTs. Specifically, one is a visualization using computer graphics (we call ldquographical displayrdquo), the other is a display using vibration (we call ldquovibration displayrdquo). Experiments to compare the efficiency of the methods to find SKTs are shown.","1944-9445;19449445","CD-ROM:978-1-4244-5081-7","10.1109/ROMAN.2009.5326206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326206","","Computer displays;Humans;Information retrieval;Intelligent actuators;Intelligent agent;Intelligent networks;Intelligent robots;Intelligent sensors;Mobile robots;Orbital robotics","human computer interaction;intelligent networks;user interfaces","3D position;computer graphics;computerized information storage;digital file;human interface;iSpace agent;information retrieval;intelligent space;robots command;spatial knowledge tag;spatial memory;vibration display;visual display","","0","","16","","","Sept. 27 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"Constant Time Stereo Matching","M. H. Ju; H. B. Kang","Dept. of Comput. Eng. & Dept. of Media Eng., Catholic Univ. of Korea, Bucheon, South Korea","2009 13th International Machine Vision and Image Processing Conference","20091110","2009","","","13","17","Typically, local methods for stereo matching are fast but have relatively low degree of accuracy while global ones, though costly, achieve a higher degree of accuracy in retrieving disparity information. Recently, however, some local methods such as those based on segmentation or adaptive weights are suggested to possibly achieve more accuracy than global ones in retrieving disparity information. The problem for these newly suggested local methods is that they cannot be easily adopted since they may require more computational costs which increase in proportion to the window size they use. To reduce the computational costs, therefore, we propose in this paper the stereo matching method that use domain weight and range weight similar to those in the bilateral filter. Our proposed method shows constant time O(1) for the stereo matching. Our experiments spend constant time for computation regardless of the window size but our experimental results show that the accuracy of generated depth map is as good as the ones suggested by recent methods.","","POD:978-1-4244-4875-3","10.1109/IMVIP.2009.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319346","Bilateral Filtering;Constant time;Stereo matching","Computational efficiency;Computer vision;Costs;Histograms;Image processing;Information retrieval;Machine vision;Matched filters;Noise generators;Shape","image matching;information retrieval;stereo image processing","disparity information retrieval;stereo image matching","","7","1","10","","","2-4 Sept. 2009","","IEEE","IEEE Conference Publications"
"Mining Sequential Patterns for Image Classification in Ubiquitous Multimedia Systems","M. Y. Lin; S. C. Hsueh; M. H. Chen; H. Y. Hsu","Dept. of IECS, Feng Chia Univ., Taichung, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","303","306","Image classification is an important technique for effective content-based multimedia retrieval. Many classifiers have been proposed while frequent patterns based approaches have received many attentions in recent years. In this paper, we proposed an image classification approach utilizing sequential patterns discovered from distinct classes. The image is segmented and low-level features are extracted as a sequence of feature-sets. Sequence-rules are collected from each class and conflict rules are resolved by rule pruning. Useful rules are then selected to form the prediction rules. Four prediction heuristics are provided to raise the prediction accuracy of the image classifier. Experimental results using synthetic datasets show that the proposed algorithm may reach an accuracy of 78%. Effective image classification thus can be achieved by mining sequential patterns for the construction of the rule-based sequence classifier.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337487","data mining;image classification;sequence classifier;sequential pattern","Accuracy;Association rules;Content based retrieval;Data mining;Feature extraction;IEC;Image classification;Image retrieval;Information retrieval;Multimedia systems","content-based retrieval;feature extraction;image classification;image retrieval;image segmentation;image sequences;knowledge based systems;multimedia systems;ubiquitous computing","content-based multimedia retrieval;image classification;image segmentation;low-level feature extraction;rule pruning;rule-based sequence classifier;sequential pattern mining;ubiquitous multimedia systems","","2","","18","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Searching semantically similar questions from a large community-based question archive","M. Liu; Y. Liu; Q. Yang","National Laboratory of Pattern Recognition Institute of Automation Chinese Academy of Sciences, Beijing 100080, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","8","This paper provides a novel and totally statistical method to search similar questions from a large question archive for a given queried question. Firstly, a word relevance model is trained based on the whole question archive which is made up of millions of natural language questions proposed by users on the Web. The word relevance model is utilized to find most semantically related words to a specific word. Secondly, in order to find semantically similar questions for a queried question, each non-stop word in a question is expanded with the help of word relevance model and represented as a word vector. Elements of the vector include the word itself and some semantically related words to it. Elements of the word vector are weighted by combining both classical IR term weighting method and word transformation probability learned from the relevance model. Then the question is mapped to a question vector as the normalized center of the word vectors representing these words contained in it. The problem of question retrieval can be solved by comparing the similarity between question vectors. The method is actually a simple question expansion based Kernel approach. Experimental results indicate the proposed method outperforms the baseline methods such as Vector Space Model (VSM) and Language Model for Information Retrieval (LMIR).","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313808","","Automation;Databases;Information retrieval;Kernel;Laboratories;Natural languages;Pattern recognition;Search engines;Statistical analysis;Web search","information needs;query formulation;statistical analysis","classical IR term weighting method;community based question archive;language model;large question archive;natural language question;question expansion based Kernel approach;semantically related word;similar question searching;statistical method;vector space model;word relevance model;word transformation probability;word vector","","1","","18","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Optimizing Wireless Channels through a Push-Based System","A. S. Al-Mogren","Riyadh Coll. of Technol., Riyadh, Saudi Arabia","2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing","20091110","2009","","","268","272","Dissemination techniques may be used to enable users to get the needed data efficiently. In this paper, I describe an architecture designed to provide a flexible access to data in a multi-channel dissemination-based network. I show how a suitable system fits in the overall telecommunication network. In addition, I show the consistency of the system design and provide analytical study for the space and time overhead.","","POD:978-1-4244-4902-6","10.1109/UIC-ATC.2009.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319225","Multi-channel;dissemination architecture;mobility;transaction management;wireless network","Computer architecture;Conferences;Distributed computing;Educational institutions;Information retrieval;Mobile computing;Pervasive computing;Telecommunication computing;Transaction databases;Wireless networks","information dissemination;mobile computing;optimisation;wireless channels","data dissemination;multichannel dissemination-based network;optimization;push-based system;wireless channels","","0","","9","","","7-9 July 2009","","IEEE","IEEE Conference Publications"
"MagicNET: Security System for Development, Validation and Adoption of Mobile Agents","M. A. Shibli; S. Muftic; A. Giambruno; A. Lioy","Dept. of Comput. & Syst. Sci., R. Inst. of Technol., Stockholm, Sweden","2009 Third International Conference on Network and System Security","20091110","2009","","","389","396","Current research in the area of mobile agents' security mainly deals with protection and security for agents and agents' runtime platforms. Mobile agent systems usually do not provide an extensive security methodology for the entire agent's life cycle, from agent's creation to its deployment and execution. In this paper we propose a comprehensive secure system for deployment of mobile agents. The system provides methodology that spans a number of phases in agent's lifetime: it starts from agent creation and ends with agent's execution. It addresses classification, validation, publishing, discovery, adoption, authentication and authorization of agents. Our system is based on secure web services and uses RBAC XACML policies and SAML protocol.","","POD:978-1-4244-5087-9","10.1109/NSS.2009.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319299","Mobile agents Adoption;Mobile agents deployment;Trusted Mobile Agents","Access control;Authorization;Computer networks;Computer science;Computer security;Information retrieval;Information security;Mobile agents;Protection;Runtime","Web services;authorisation;mobile agents;protocols","RBAC XACML policies;SAML protocol;agent adoption;agent authentication;agent authorization;agent classification;agent discovery;agent publishing;agent validation;magicNET;mobile agent systems;security system;web services","","3","","27","","","19-21 Oct. 2009","","IEEE","IEEE Conference Publications"
"KeyOnto: A Hybrid Knowledge Retrieval Model in Law Semantic Web","B. Fan; G. Liu; T. Liu; H. Hu; X. Du","Key Lab. of Data Eng. & Knowledge Eng., MOE, Beijing, China","2009 Fourth ChinaGrid Annual Conference","20091117","2009","","","179","184","This paper proposes a hybrid knowledge retrieval model KeyOnto, which combines ontology based knowledge retrieval model with traditional Vector Space Model (VSM). KeyOnto model makes use of domain ontology to organize and structure knowledge resources. Documents and queries are represented by concepts and term vectors respectively. Furthermore, ontology based query expansion called K2CM, is introduced to get expanded concepts of a query. Domain specific terms are used to form a term vector for queries and documents. Basing on these vectors, we can evaluate term similarity and concept similarity respectively, and integrate them together. Domain specific thesaurus is used to assist knowledge retrieval. Experiments show that compared with each single model, KeyOnto model improves precision of query result.","1949-131X;1949131X","POD:978-0-7695-3818-1","10.1109/ChinaGrid.2009.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5328834","Knowledge Retrieval;Ontology;Query Expansion;Vector Space Model","Computer displays;Helium;Indexing;Information retrieval;Internet;Laboratories;Natural languages;Ontologies;Semantic Web;Thesauri","law;ontologies (artificial intelligence);query processing;semantic Web","KeyOnto model;domain ontology;hybrid knowledge retrieval model;law semantic Web;ontology based query expansion;vector space model","","1","","16","","","21-22 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Effective Web Content-Based Image Retrieval Algorithm by Using SIFT Feature","Z. Wang; K. Jia; P. Liu","Coll. of Electron. Inf. & Control Eng., Beijing Univ. of Technol., Beijing, China","2009 WRI World Congress on Software Engineering","20091110","2009","1","","291","295","This paper provides an effective Web content-based image retrieval algorithm by using SIFT (scale invariant feature transform) feature. Different from other existing text-based Web image search engines, this algorithm can be applied to content-based Web image search engine effectively. SIFT descriptors, which are invariant to image scaling and transformation and rotation, and partially invariant to illumination changes and affine, present the local features of an image. Therefore, feature keypoints saved as XML files can be extracted more accurately by using SIFT than by color, texture, shape and spatial relations feature. To decrease unavailable features matching, a dynamic probability function replaces the original fixed value to determine the similarity distance of ROI (Region of interest) and database from Web training images. The experimental results show that this method improves the stability and precision of image retrieval.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.420","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319111","Content-based image retrieval;ROI(Region Of Interest);SIFT(Scale Invariant Feature Transform);feature matching","Content based retrieval;Digital cameras;Feature extraction;Image databases;Image retrieval;Information retrieval;Lighting;Shape;Software algorithms;Spatial databases","Internet;XML;content-based retrieval;feature extraction;image matching;image retrieval;probability;search engines;text analysis","SIFT feature;Web content-based image retrieval algorithm;XML;dynamic probability function;feature matching;illumination change;image rotation;image scaling;image transformation;local feature extraction;scale invariant feature transform;text-based Web image search engine","","2","","10","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"Volume Image Segmentaton by Dual Multi-Scale Morphological Reconstructions","J. J. Chen; C. R. Su","Dept. of Electr. Eng., Nat. Taiwan Univ. of Sci. & Technol., Taipei, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","511","514","Performing image preprocessing for specific targets, e.g., foreground (FG) segmentation and feature extraction, on the scale of databases is challenging. For volume image FG segmentation, we proposed to utilize dual multi-scale graylevel morphological open/close by reconstruction to simulate background (BG) gray-level variational mesh to identify FG regions. It is developed from a global perspective on image FG/BG gray-levels and is carried out with regular operations. To evaluate FG segmentation performance, the probability of coherent segmentation labeling, normalized probability random index, with ground-truth ones is computed for comparisons. For assessing the segmentation capability in dealing with volume images, content-based image retrieval is carried out for performance evaluations. Experiments showed that the proposed FG segmentation method outperforms previous ones with 21% PRI improvement and also improves the retrieval precision-recall performance up to 31%.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.295","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337563","Content-Based Image Retrieval;Image Database;Image Segmentation;Morphological Reconstructions","Content based retrieval;Image color analysis;Image databases;Image reconstruction;Image retrieval;Image segmentation;Information retrieval;Performance evaluation;Shape;Signal processing algorithms","content-based retrieval;feature extraction;image reconstruction;image retrieval;image segmentation;mathematical morphology;probability;random processes","FG segmentation;content-based image retrieval;dual multiscale graylevel morphological reconstruction;feature extraction;foreground segmentation;image preprocessing;image segmentation;probability random index","","0","","9","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"QoS compromise in data gathering for WSN","J. Z. Sun","Academy of Finland, Department of Electrical and Information Engineering, University of Oulu, 90014, Finland","2009 6th Annual International Mobile and Ubiquitous Systems: Networking & Services, MobiQuitous","20091110","2009","","","1","2","The problem of adaptive determination of data granularity for QoS-constraint query execution is addressed. An application specifies QoS requirements with a query. Then, each node can choose the optimum data granularity for local data collection and transmission. The proposed algorithm is in a distributed fashion, and executed at each local sensor node.","","POD:978-963-9799-59-2","10.4108/ICST.MOBIQUITOUS2009.7027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326359","QoS;data gathering;wireless sensor networks","Data communication;Data engineering;Energy dissipation;Energy efficiency;Information retrieval;Query processing;Relays;Sampling methods;Sun;Wireless sensor networks","quality of service;wireless sensor networks","QoS compromise;QoS-constraint query execution;data gathering;data granularity;wireless sensor network","","1","","5","","","13-16 July 2009","","IEEE","IEEE Conference Publications"
"Analysis about event annotation and information structure in sudden events discourse","E. Yang; Q. Zeng; D. Zhu","Institute of Applied Linguistics Beijing Language and Culture University Beijing, CA 100083, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","5","This paper attempts to analyze the setup about the sudden event discourses. All the analysis is based on a large scale of events annotation. Paper gives an overview of events annotations. The event words, event arguments and event attributes are all necessary to annotate. It also does some analysis on the information structure of the texts and defines two information chains from the perspective of researchers. The article also performs a statistical analysis between the content which can be easily identified by the computer and which can not Anyway, all the research are just to lay the foundation for Information Extraction.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313778","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313778","Event annotation;Event attribute;Main information chain;Secondary information chain","Data mining;Earthquakes;Guidelines;Information analysis;Information retrieval;Large-scale systems;Scattering;Statistical analysis","information retrieval;statistical analysis;text analysis","event annotation;information extraction;information structure;statistical analysis;sudden event discourse;text analysis","","0","","10","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"An Arabic question-answering system for factoid questions","W. Brini; M. Ellouze; S. Mesfar; L. H. Belguith","LARIS- MIRACL, FSEGS - University of Sfax, Tunisia","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","7","In this paper, we propose an Arabic Question-Answering (Q-A) system called QASAL (Question-Answering system for Arabic Language). QASAL accepts as an input a natural language question written in Modern Standard Arabic (MSA) and generates as an output the most efficient and appropriate answer. The proposed system is composed of three modules: A question analysis module, a passage retrieval module and an answer extraction module. To process these three modules we use the NooJ Platform which represents a linguistic development environment.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313730","Arabic language;Natural language processing;Question-Answering system;factoid questions","Character generation;Data mining;Information retrieval;Intersymbol interference;Knowledge engineering;Natural language processing;Natural languages;Performance analysis;Search engines;Web pages","natural language processing;search engines","NooJ platform;QASAL system;Question-Answering system for Arabic Language;answer extraction module;factoid questions;modern standard Arabic;natural language question;passage retrieval module;question analysis module","","1","","14","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"A New Upgrade to SQLf: Towards a Standard in Fuzzy Databases","C. Gonzalez; M. Goncalves; L. Tineo","Dept. de Comput., Univ. Simon Bolivar, Caracas, Venezuela","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","442","446","One remarkable fuzzy set based extension to SQL is SQLf. It allows fuzzy conditions in any place where SQL allows a Boolean one. At present time SQLf development is not up to date with SQL standard. Latest SQLf revision was with the SQL:1999 standard.New features of SQL:2003 standard have not been yet extended to the fuzzy case in SQLf. In this paper, we make a contribution towards a standard in Fuzzy Databases, upgrading SQLf according SQL:2003 standard, proposing these new fuzzy features: fuzzy table storage,fuzzy multiset data type and fuzzy merge statement.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337238","Flexible Querying;Fuzzy Database;SQLf","Boolean functions;Fuzzy logic;Fuzzy set theory;Fuzzy sets;Fuzzy systems;Hybrid intelligent systems;Information retrieval;Relational databases;Spatial databases;Standards development","SQL;fuzzy logic;relational databases","SQLf extension;fuzzy database;fuzzy merge statement feature;fuzzy multiset data type feature;fuzzy set SQL extension;fuzzy table storage feature","","3","","18","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Towards an Efficient Integration of Spatial Join Queries and IR-style Keyword Search","D. Chen; Y. Guo; L. Liu","Coll. of Comput. Sci. & Technol., Donghua Univ., Shanghai, China","2009 WRI World Congress on Software Engineering","20091110","2009","2","","16","20","Recently, with the amount of available textual data in spatial databases growing rapidly, more and more applications are required to support both spatial joins and keyword-based text information retrieval. In this paper, we discuss a new type of query, called as SJIRKS, which efficiently integrates spatial join on spatial data and IR-style keyword search on textual data. In particular, the proposed SJ-IRKS queries return users with the most interesting spatial object pairs by adapting state-of-the-art information retrieval (IR) relevance ranking strategies. For answering SJ-IRKS queries efficiently, we present a pipeline algorithm named PL*SJ-IRKS which outputs the results in an incremental way. The experimental results show that our proposed algorithm has superior performance and excellent scalability.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319718","","Application software;Cities and towns;Computer science;Database systems;Educational institutions;Information retrieval;Keyword search;Roads;Software engineering;Spatial databases","information retrieval;query processing;visual databases","IR-style keyword search;PL*SJ-IRKS pipeline algorithm;SJIRKS;relevance ranking strategies;spatial databases;spatial join queries;text information retrieval","","0","","8","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"DMRC: Distortion-minimizing rate control for Wireless Multimedia Sensor Networks","S. Pudlewski; T. Melodia","Wireless Networks and Embedded Systems Laboratory, Department of Electrical Engineering, State University of New York (SUNY) at Buffalo, USA","2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems","20091117","2009","","","563","572","The availability of inexpensive CMOS cameras and microphones that can ubiquitously capture multimedia content from the environment is fostering the development of Wireless Multimedia Sensor Networks (WMSNs), i.e., distributed systems of wirelessly networked devices that can retrieve video and audio streams, still images, and scalar sensor data. WMSNs require the sensor network paradigm to be re-thought in view of the need for mechanisms to deliver multimedia content with a pre-defined level of quality of service (QoS). A new rate control scheme for WMSNs is introduced in this paper with a two-fold objective: i) maximize the video quality of each individual video stream; ii) maintain fairness in video quality between different video streams. The rate control scheme is based on both analytical and empirical models and consists of a new cross-layer control algorithm that jointly regulates the end-to-end data rate, the video quality, and the strength of the channel coding at the physical layer. The end-to-end data rate is regulated to avoid congestion while maintaining fairness in the domain of video quality rather than data rate. Once the end-to-end data rate has been determined, the sender adjusts the video encoder rate and the channel encoder rate based on the overall rate and the current channel quality, with the objective of minimizing the distortion of the received video. Simulations show that the proposed algorithm considerably improves the received video quality without sacrificing fairness.","2155-6806;21556806","POD:978-1-4244-5114-2","10.1109/MOBHOC.2009.5336954","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336954","","CMOS image sensors;Cameras;Information retrieval;Microphones;Multimedia systems;Quality of service;Rate distortion theory;Sensor systems;Streaming media;Wireless sensor networks","channel coding;distortion;multimedia communication;quality of service;telecommunication congestion control;video coding;video streaming;wireless channels;wireless sensor networks","DMRC;channel coding;congestion avoidance;cross-layer control algorithm;distortion-minimizing rate control;quality of service;video encoder;video quality;video streaming;wireless multimedia sensor network","","4","","38","","","12-15 Oct. 2009","","IEEE","IEEE Conference Publications"
"An information arrangement technique for a text classification and summarization based on a summarization frame","S. Tsuchiya; E. Yoshimura; H. Watabe","Dept. of Information and Computer Science, Doshisha University, Kyo-Tanabe, Kyoto, Japan","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","5","In this paper, the purpose is to arrange information to understand at one view. The proposed summarization frame technology is a system to hierarchically arrange and classify information by targeting content and level of importance in sentences. Moreover, the technique in which the Concept Base, the Degree of Association Algorithm, the Time Judgment system and the Place judgment system are used to understand content of sentences is proposed. The Concept Base generates semantics from a certain word, and the Degree of Association Algorithm uses the results of the semantics expansion to express the relationship between one word and another as a numeric value. Only needed information like the number of strokes limitation etc. can be easily extracted by hierarchically arranging information in the document summary. Moreover, the speed-up of the retrieval can be expected by narrowing the retrieval object in information retrieval. An answer matched to TPO can be expected to be achieved in a QA system. Sentences are classified according to the content. Each classification is classified into a more detailed field. Important keywords are extracted from the sentences classified into the field. Moreover, the extracted keywords are classified into common and peculiar word for the sentences in the field. In addition, sentences of each field hierarchize sentences to three stages according to the importance of the content. In addition, the sentences of each field are hierarchized at three levels according to the importance of the content.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313816","Concept Base;Degree of Association;document classification;information arrangement;summarization","Computer science;Data mining;Databases;Dictionaries;Humans;Information retrieval;Large-scale systems;Text categorization","classification;information retrieval;text analysis","Place judgment system;Time Judgment system;information arrangement technique;information classification;information retrieval;keyword extraction;summarization frame technology;text classification","","0","","7","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Requirements for evidential value for the assessment of the trustworthiness of digital records over time","J. Ma; H. Abie; T. Skramstad; M. Nygard","Department of Computer and Information Science, Norwegian University of Science and Technology, Trondheim, Norway","2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems","20091117","2009","","","796","803","The issue of trust in the management of digital records has been a topic of research for a number of years. During this time most researchers have concentrated on the nature and meaning of the record itself, rather than the potential use of the record as evidence of the originators' origins, functions, and activities. Through a comparison of trust in the real world and trust in the digital world, we demonstrate the importance of evidential value in the assessment of the trustworthiness of a record. In this paper we investigate, identify and specify the requirements for evidential value, based on our life cycle model of the record. Finally, we show briefly how these requirements can be used in the assessment of the trustworthiness of records in long-term storage.","2155-6806;21556806","POD:978-1-4244-5114-2","10.1109/MOBHOC.2009.5336917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336917","","Banking;Digital cameras;Information retrieval;Information science;Information technology;Internet;Microcomputers;Packaging;Project management;Technology management","digital libraries;formal specification;records management;security of data","digital record management;evidential value;life cycle model;long-term storage;requirements specification;trustworthiness assessment","","0","","28","","","12-15 Oct. 2009","","IEEE","IEEE Conference Publications"
"Existence Dependency-Based Domain Modeling for Improving Stateless Process Enactment","R. Haesen; M. Snoeck; W. Lemahieu; S. Poelmans","Dept. of Decision Sci. & Inf. Manage., Katholieke Univ., Leuven, Belgium","2009 Congress on Services - I","20091110","2009","","","515","521","In a process-enabled service oriented architecture, a process engine typically stores the state of the process instances during enactment. As an alternative, stateless process enactment entails that process state is derived from the state of business objects, which are organized in a domain model. The business objects are referred to in pre- and post-conditions of activities, which determine when the activity is enabled and completed, respectively. Despite the fact that the latter approach has multiple benefits compared with the former, the repeated state (re)calculations deteriorate performance and the formulation of clear conditions is not self-evident if typical domain modeling techniques (e.g. UML or ER) are adopted. In this paper we show that by adopting a specific domain modeling technique, which is based on the notion of existence dependency between the business objects, the performance and comprehensibility issues can proficiently be dealt with. We illustrate the technique using a real-world case from the insurance domain and analyze the emerging duality between process modeling and domain modeling.","2378-3818;23783818","CD-ROM:978-0-7695-3708-5","10.1109/SERVICES-I.2009.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190637","","Coherence;Engines;Erbium;Humans;Information management;Information retrieval;Inspection;Insurance;Service oriented architecture;Unified modeling language","Unified Modeling Language;Web services;business data processing;entity-relationship modelling;graph theory;object-oriented programming;software architecture","ER modeling technique;UML modeling technique;business object;business process modeling;existence dependency graph;insurance domain model;post-condition activity;pre-condition activity;process engine;process-enabled service oriented architecture;specific domain modeling technique;stateless process enactment","","0","","14","","","6-10 July 2009","","IEEE","IEEE Conference Publications"
"The Research of Using Jena in the Semantic-Based Online Learning Intelligent Behavior Analysis System","L. Shi; L. Fan; Z. Meng","Dept. of Educ. Technol., Capital Normal Univ., Beijing, China","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","926","929","With the online learning appears diversity and complexity, analyzing the behavior of online learning is significance. In this paper, we introduce Jena, the semantic development and reasoning tool, which can use internal reasoners, import external reasoners and define new rules to complete the key steps of the Semantic analysis. We used Jena to create and to update ontology model, to reason and to query learners' behavior, also base on the analysis result to evaluate and to guide learners' learning. The main parts of the article describe functional running diagram of the system and Jena's role in the system, then introduce some schema of the Jena we used to create the model and to complete the reasoning needed in the system, finally give an example to illustrate the reasoning function of the system.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331631","Jena;OWL;SPASQL;learner model;reasoner","Data mining;Database languages;Engines;Information analysis;Information retrieval;Intelligent systems;OWL;Ontologies;Resource description framework;XML","behavioural sciences computing;inference mechanisms;intelligent tutoring systems;ontologies (artificial intelligence);semantic Web","Jena;functional running diagram;ontology model;semantic development;semantic reasoning;semantic-based online learning intelligent behavior analysis system","","1","","9","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Web Services Based Multi-data Centers Knowledge Sharing for Autonomic Problem Determination and Remediation","H. Chan; T. Kwok","IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA","2009 Congress on Services - I","20091110","2009","","","30","37","With the proliferation of Web services as a business solution to enterprise application integration, rapid utilization of information and software functions from heterogeneous sources becomes possible. However, most autonomic problem and remediation systems focus on and are confined only to the environment and knowledge of the data centers they are managing, limiting their knowledge bases and therefore their ability to effectively and accurately determine these problems and suggest a solution. In this paper, we propose and describe a Web services based system that enables the mutual sharing of knowledge among data centers and external entities. We also show how a collective practice for information sharing and distributing tasks into manageable pieces, managed by an intelligent mediator and accessible via Web services, can improve problem determination.","2378-3818;23783818","CD-ROM:978-0-7695-3708-5","10.1109/SERVICES-I.2009.133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190643","","Application software;Environmental management;Hardware;Information analysis;Information retrieval;Knowledge management;Learning;Network servers;Resource virtualization;Web services","Web services;business data processing;computer centres;knowledge management","Web services;autonomic problem determination;business solution;enterprise application integration;multidata centers knowledge sharing;remediation systems;software functions","","0","","17","","","6-10 July 2009","","IEEE","IEEE Conference Publications"
"Investigating and annotating the role of citation in biomedical full-text articles","H. Yu; S. Agarwal; N. Frid","University of Wisconsin-Milwaukee","2009 IEEE International Conference on Bioinformatics and Biomedicine Workshop","20091113","2009","","","308","313","Citations are ubiquitous in scientific articles and play important roles for representing the semantic content of a full-text biomedical article. In this work, we manually examined full-text biomedical articles to analyze the semantic content of citations in full-text biomedical articles. After developing a citation relation schema and annotation guideline, our pilot annotation results show an overall agreement of 0.71, and here we report on the research challenges and the lessons we've learned while trying to overcome them. Our work is a first step toward automatic citation classification in full-text biomedical articles, which may contribute to many text mining tasks, including information retrieval, extraction, summarization, and question answering.","","POD:978-1-4244-5121-0","10.1109/BIBMW.2009.5332080","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332080","","Biomedical measurements;Citation analysis;Data mining;Guidelines;Indexing;Information retrieval;Irrigation;Machinery;Proteins;Text mining","citation analysis;full-text databases;medical information systems;text analysis","automatic citation classification;full-text biomedical articles;information extraction;information retrieval;information summarization;question answering;scientific articles;semantic content representing;text mining","","1","","38","","","1-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Automatic generation of narrative content for digital games","M. F. Caropreso; D. Inkpen; S. Khan; F. Keshtkar","School of Information Technology and Engineering, University of Ottawa, Ottawa, ON, K1N6N5, Canada","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","8","Interactive simulation games used for training usually require a large amount of coherent narrative content. An effective and efficient solution to the narrative content creation problem is to use Natural Language Generation (NLG) systems. The use of NLG systems, however, requires sophisticated linguistic and sometimes programming knowledge. For this reason, NLG systems are typically not accessible to the game designers who write narrative content. We have designed and implemented a visual environment for creating and modifying NLG templates that requires no programming knowledge, and can operate with a minimum of linguistic knowledge. It allows specifying templates with any number of variables and dependencies between them. It automatically generates all the sentences that follow the created template. It uses SimpleNLG to provide the linguistic background knowledge. We tested the performance of our system in the context of an interactive simulation game.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313787","","Context modeling;Displays;Information processing;Information retrieval;Information technology;Java;Layout;Natural languages;Robotics and automation;System testing","computer based training;computer games;digital simulation;interactive systems;natural language processing","NLG system;digital game;interactive simulation game;linguistic knowledge;narrative content automatic generation;narrative content creation problem;natural language generation system;visual environment","","0","","13","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Layer-Based Media Integration for Mobile Mixed-Reality Applications","R. Lee; Y. J. Kwon; K. Sumiya","Sch. of Human Sci. & Environ., Univ. of Hyogo, Himeji, Japan","2009 Third International Conference on Next Generation Mobile Applications, Services and Technologies","20091117","2009","","","58","63","Rapidly evolving and widely-used smart phones provide many novel applications and services, making it possible to gather information from any location. Recent advances in technology have introduced many useful functions to assist users of outdoor mobile devices by sensing nearby conditions, such as the user's current location and even the user's slightest motions. Among these growing capabilities and their potential applications, the development of new mobile mixed-reality applications will need to consider various integration forms to be beneficial in both mobile device applications and services. In this paper, a layer-based media integration model for mobile mixed-reality applications is proposed to help developers gather diverse resources in a unified form, i.e., media, sensing, and even internal processing controls. In particular, to make it possible to identify and look for relevant information about real-world geospatial objects of interests in a very intuitive and direct manner by simply pointing towards an object, an object-identification layer is introduced. For each identified object, various types of services can be naturally integrated with the layer-based model; to take a snapshot or to jump to a related Web page, or to collaborate with the popular touch control. The authors address an integration model that will significantly simplify mixed-reality application development work to establish a relationship between a geospatial object, its graphic image on a project screen, and user interaction. The improved simplicity, advantages, and new capabilities of the proposed model are also validated with two implemented applications, ldquoautomatic tagging camerardquo and ldquotouch-based mixed-reality Web searchrdquo based on the layer model.","2161-2889;21612889","POD:978-0-7695-3786-3","10.1109/NGMAST.2009.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337106","Layer-based Integration;Mobile Mixed-Reality","Cameras;Databases;Displays;Engines;Humans;Information retrieval;Mobile handsets;Object detection;Telecommunications;Virtual reality","graphical user interfaces;human computer interaction;mobile computing;virtual reality","automatic tagging camera;graphic image;graphical user interface;layer-based media integration;mobile mixed-reality application;object-identification layer;project screen;real-world geospatial object;smart phone;touch-based mixed-reality Web search;user interaction","","2","1","12","","","15-18 Sept. 2009","","IEEE","IEEE Conference Publications"
"A method for stemming and eliminating common words for Persian text summarization","M. Berenjkoob; R. Mehri; H. Khosravi; M. A. Nematbakhsh","Department of Computer, Engineering. University of Isfahan., Isfahan, Iran","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","6","With high increasing documents and electronic texts in Persian language, the use of fast methods to achieve texts through huge sets of documents is highly crucial. Persian text summarization which shows the main concept of a text in minimum size is an effective solution. One of the steps in Persian text summarization is to stem and eliminate common words. The aim of this research is to stem words from Persian documents to make their use more efficient in text summarization, the present method is to eliminate words and stem keywords. The compound of existing techniques in the words network was used to create a Persian database using the Dehkhoda dictionary. The algorithm used for summarization is based on statistical techniques. In this method each sentence is given an important weight, sentences with higher weight are used for summarization. By comparing the results of other algorithms on Persian texts we concluded that our technique extracts the root of the existing words with more precision.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313836","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313836","Database;Text Summarization;common words;stemming","Data mining;Databases;Dictionaries;Frequency measurement;Information retrieval;Natural language processing;Ontologies;Statistical analysis;Text recognition","natural language processing;statistical analysis;text analysis","Dehkhoda dictionary;Persian language;Persian text summarization;common words elimination;common words stemming;statistical technique","","0","","14","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Mining Generalized Actionable Rules Using Concept Hierarchies","L. S. Tsay; S. Im","Sch. of Technol., North Carolina A&T State Univ., Greensboro, NC, USA","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","2016","2023","A series of mining actionable rule methods have been proposed from various aspects, but the existing models do not incorporate the concept of hierarchy/taxonomy into the mining process and restrict the terms used to build actionable rules to atomic concepts. In order to resolve this problem, an integrated framework for extracting multiple-level actionable rules with ontology support is proposed so more generalized knowledge from data can be extracted. This type of generalized rules will contain not only the attribute values contained in data, but also some concepts encoded in a given taxonomy. Obtaining generalized actionable rules are a necessity since they provide a more general view of the domain. The proposed framework is based on a breadth-first top-downward model to be developed by extending the existing single-level actionable rule discovery methods. This framework can improve the quality of the extracted actionable rules in terms of their interestingness and understandability.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331490","Action Rule;Concept Hierarchy;Reclassification Rule","Association rules;Data mining;Databases;Information retrieval;Ontologies;Profitability;Taxonomy","data mining;ontologies (artificial intelligence)","atomic concepts;breadth-first top-downward model;concept hierarchy;generalized actionable rule mining;knowledge extraction;multiple-level actionable rules extraction;ontology support;single-level actionable rule discovery methods;taxonomy","","0","","26","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Answer generation for Chinese cuisine QA system","L. Xia; Z. Teng; F. Ren","Faculty of Engineering, The University of Tokushima, Tokushima, 770-8506, Japan","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","6","In this paper, we propose an approach on answer generation for cooking question answering system. We first review previous work of question analysis. Then, we give annotation scheme for knowledge database. Finally, we present the answer planning based approach for generate an exact answer in natural language. An evaluation has been conducted on natural language questions and the result shows that the system can satisfy user's demand.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313813","QA system;annotation;answer generation (AG);answer planning;domain knowledge","Data mining;Databases;Information retrieval;Intelligent agent;Knowledge engineering;Natural languages;Pipelines;Taxonomy;Weather forecasting;Web search","information retrieval;knowledge based systems;natural language processing","Chinese cuisine QA system;annotation scheme;answer generation;answer planning based approach;cooking question answering system;knowledge database;natural language","","0","","14","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Mode content analysis of the RF output of a gyrotron based on the astigmatic Gaussian beam of higher order","S. Jawla; I. Pagonakis; J. P. Hogge; S. Alberti; T. Goodman; T. M. Tran","Centre de Recherche en Physique des Plasmas, Association EURATOM-Conf&#233;d&#233;ration Suisse, Ecole Polytechnique F&#233;d&#233;rale de Lausanne, CH-1015, Lausanne, Switzerland","2009 34th International Conference on Infrared, Millimeter, and Terahertz Waves","20091110","2009","","","1","2","An efficient intermodal decomposition technique is developed for an accurate reconstruction of the RF field obeying a paraxial approximation such as the output of a gyrotron. This method requires complete RF beam information i.e. its amplitude, measured using infrared thermography technique, and phase, which is calculated by an accurate phase retrieval method using complete scalar diffraction integral. The complex RF field evaluated at several positions along the direction of propagation is then used in our modal decomposition method which is based on minimizing the error between the original field and the optimized field. The minimization method is implemented such that it evaluates the optimized field by calculating the beam parameters and the complex coefficient of each mode simultaneously. During the beam propagation, after phase retrieval method, it is observed that in several cases the output RF beam cannot be analyzed using simple Gaussian beam equation and therefore, we extended our method to a more general case of astigmatic Gaussian beam of higher order modes rotating along the optic axis of propagation.","2162-2027;21622027","POD:978-1-4244-5416-7","10.1109/ICIMW.2009.5324969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5324969","","Diffraction;Gyrotrons;Information retrieval;Mirrors;Optical distortion;Optical propagation;Optical waveguides;Optimization methods;Plasma measurements;Radio frequency","","","","1","","2","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Unknown place name detection base on YamCha for Japanese guidance QA system","Y. Liu; F. Ren","Graduate School of Advanced, Technology and Science, The University of Tokushima, Tokushima, Japan","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","5","We perform a research about Japanese sightseeing guidance question answering (QA) system. In this domain Web information retrieval approach is always being used. However for the Web information retrieval, Japanese unknown place word detection needs to be considered. Some famous places are known very well, such as ""Kinkaku-ji"", it can be recognized by morphological analysis. However, the recognition rate of Japanese complex place is so poor. Therefore, we proposed an approach of the Japanese unknown place word detection. We use YamCha, a tool based on support vector machines (SVMs). The goal is that we want to recognize the unknown sightseeing spots word from user's question. In the experiment of Japanese place word detection we have got excellent precision and recalling rates.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313824","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313824","Japanese sightseeing place word detection;Support Vector Machine;YamCha","Data mining;Earth Observing System;Information retrieval;Natural languages;Silicon compounds;Support vector machine classification;Support vector machines;Training data","Internet;information retrieval;natural language processing;support vector machines","Japanese sightseeing guidance QA system;Japanese unknown place name detection;SVM;Web information retrieval approach;YamCha tool;morphological analysis;question answering system;support vector machine;unknown sightseeing spot word recognition rate","","1","","11","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Video Retrieval Algorithm Based on Spatio-temporal Feature Curves and Key Frames","X. Chen; K. Jia; Z. Deng","Coll. of Electron. Inf. & Control Eng., Beijing Univ. of Technol., Beijing, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1078","1081","Present video retrieval methods have many problems. To solve these problems, a new video retrieval algorithm base on the combination of video spatio-temporal feature curves and key frames is proposed in this paper. In this new algorithm, the feature curves are extracted from the video, and then two videos' feature curves are compared to determine whether they have the same content or not. In the comparing process, to solve the problems of brightness offset in all frames and abrupt intense disturbance, the paper uses Grads comparison method and Exception Factor. To improve retrieval precision for videos like films, a method based on clips and key frames is added after spatio-temporal feature curves based retrieval. The new algorithm can largely reduce the data amount of video retrieval. Experimental results show the effectiveness and robustness of the algorithm.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337538","","Brightness;Control engineering;Educational institutions;Feature extraction;Image retrieval;Information retrieval;Robustness;Signal processing algorithms;Video signal processing;Videoconference","feature extraction;video retrieval;video signal processing","feature curves extraction;spatio-temporal feature curves;video feature curves;video retrieval algorithm;video retrieval precision","","0","","5","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Research of Massive Internet Text Data Real-Time Loading and Index System","W. Han; Y. Jia; S. Yang","Comput. Sch., Nat. Univ. of Defense Technol., Changsha, China","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","960","965","With rapid development of the Internet and communication technology, massive text data has been accumulated in Internet, including text data on network pages, emails, instant messengers and etc. Requirements on increasing data volume, real-time data-loading and creating text indexes pose enormous challenges to data-loading techniques. This paper presents a data loading system in real time, text-loader that is used in ITSR (Internet text data real-time storage and retrieval system). Text-loader consists of an efficient algorithm for bulk data loading and exchange partition mechanism, increasing text index creation algorithm, optimized parallelism, and guidelines for system tuning. Performance studies show the positive effects of these techniques with loading speed of every Cluster, increasing from 220 million records per day to 1.2 billion per day, and achieving the top loading speed of 6TB data when 10 Clusters are in parallel. This framework offers a promising approach for loading other large and complex text databases.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.414","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331626","data loading;exchange partition;massive data;parallel schedule;text index","Clustering algorithms;Computer networks;IP networks;Indexes;Information retrieval;Internet;Optimization methods;Partitioning algorithms;Real time systems;Relational databases","information networks;information retrieval","Internet text data real-time storage;index system;real-time data-loading;retrieval system","","0","","11","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"An ontology-based question answering method with the use of textual entailment","S. Ou; D. Mekhaldi; C. Orasan","Research Group in Computational Linguistics, University of Wolverhampton, Wolverhampton, UK","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","8","This paper presents a new method for ontology-based Question Answering (QA) with the use of textual entailment. In this method, a set of question patterns, called hypothesis questions, was automatically produced from a domain ontology, along with their corresponding SPARQL query templates for answer retrieval. Then the QA task was reduced to the problem of looking for the hypothesis question that was entailed by a user question and taking its corresponding query template to produce a complete query for retrieving the answers from underlying knowledge bases. An entailment engine was used to discover the entailed hypothesis questions with the help of question classification. An evaluation was carried out to assess the accuracy of the QA method, and the results revealed that most of the user questions (65%) can be correctly answered with a semantic entailment engine enhanced by the domain ontology.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313770","Domain ontology;pattern generation;question answering;text entailment","Computational linguistics;Databases;Engines;Information management;Information retrieval;Motion pictures;Ontologies;Pattern matching;Pattern recognition;Text recognition","knowledge based systems;ontologies (artificial intelligence);pattern classification;query processing","answer retrieval;ontology-based question answering method;query template;question classification;textual entailment engine","","0","","17","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Data extraction from Web forums based on similarity of page layout","Y. Wang; B. Li; C. Lin","Information Processing Dept, Information Technology Institute, Zhengzhou, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","5","Web forums contain a wealth of information resources. Forum data can be widely used in areas such as Internet community mining, information retrieval and public opinion analysis and so on. This paper solves the problems of what should be extracted and how to extract from the Web forums. Aimed at the limitation of current methods to extract data from Web forums, an automated method is proposed to extract metadata from Web forum pages. The method processes in two steps. We firstly recognizes the topic-block by making full use of the special layout of the Web forum pages, then extract metadata from the topic-block by making use of statistical regularity of the metadata, the whole process done without manual work. Experimental results show that this method performs well both in adjustability and accuracy.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313736","data extraction;similarity;web forum","Data mining;Databases;Discussion forums;HTML;Information analysis;Information processing;Information resources;Information retrieval;Information technology;Visual effects","Internet;Web sites;data mining;information retrieval","Internet community mining;Web forum pages;data extraction;information resources;information retrieval;page layout similarity;public opinion analysis","","0","","10","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Signature-Based Hybrid Spill-Tree for Indexing High-Dimensional Data","H. J. Lee; J. W. Chang","Dept. of Eng., Chonbuk Nat. Univ., Jeonju, South Korea","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","1","","287","292","Because video data, especially UCC (User Create Content), has recently attracted much interest, high-dimensional indexing schemes are required to support the content-based retrieval of video data. However, most high-dimensional indexing schemes, except Hybrid Spill-Tree, are not efficient in terms of retrieval performance because they are weak in either retrieval accuracy or retrieval time. Therefore, we, in this paper, propose a new efficient high-dimensional indexing scheme to support the content-based retrieval of a large amount of video data. For this, we extend Hybrid Spill-tree by using a newly designed clustering technique and by adopting a signature technique. In addition, we provide both an insertion algorithm and a k-NN search algorithm for our high-dimensional indexing scheme. Finally, we show that our signature-based high-dimensional indexing scheme achieves better retrieval performance than M-Tree and Hybrid Spill-Tree.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5327951","Contents-Based Retireval;High-Dimensional Indexing;Hybrid Spill-Tree","Animation;Clustering algorithms;Content based retrieval;Data engineering;Indexing;Information retrieval;Information technology;Internet;Performance analysis;Videoconference","content-based retrieval;digital signatures;indexing;tree searching;trees (mathematics);video signal processing","content-based retrieval;high-dimensional data indexing;hybrid spill-tree;insertion algorithm;k-NN search algorithm;signature-based high-dimensional indexing scheme;user create content;video data","","0","","7","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Scoring Function for Retrieving Photo Sets with Broad Topic Coverage","S. Lee; J. Park","Web Eng. Lab., Seoul Nat. Univ., Seoul, South Korea","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1577","1580","As a storage-unit of user created Web objects, the set has become an emerging challenge in the retrieval. Set search requires relevant sets to meet the information need of users, whereas traditional information retrieval focuses on finding relevant Web objects. This paper proposes a new approach to measure relevance of sets with respect to a user query by their topic coverage. The main idea of the proposed approach is to prefer the set which covers as many different query-related topics as possible. The problem domain of this paper is photo sets of the Flickr.com, which are collections of photos. The experimental result shows that our algorithm outperforms the previous collection selection algorithm.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331427","Collection Selection;Ranking algorithm;Set search","Content management;Energy management;Frequency;Information retrieval;Large-scale systems;Navigation;Noise robustness;Terminology;Videos;Web services","image retrieval","broad topic coverage;information retrieval;photo set retrieval;scoring function;set search;user query","","0","","12","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Static-Discovery Dynamic-Selection (SDDS) Approach to Web Service Discovery","A. Pahlevan; H. A. Müller","Dept. of Comput. Sci., Univ. of Victoria, Victoria, BC, Canada","2009 Congress on Services - I","20091110","2009","","","769","772","Supporting dynamic attributes is critical in high quality Web service discovery. Presently, the methods used for service discovery assume that the world is static and, therefore, do not support attributes that are dynamic in nature. It is important to note that a service is characterized by both static and dynamic attributes. High quality Web service discovery requires detailed service context models describing both static and dynamic features. Our approach to high quality service discovery aims to overcome the limitations of existing methods by considering dynamic attributes and employing context-aware information retrieval techniques.","2378-3818;23783818","CD-ROM:978-0-7695-3708-5","10.1109/SERVICES-I.2009.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190700","","Availability;Computer science;Context modeling;Context-aware services;Databases;Information retrieval;Protocols;Scalability;Unicast;Web services","Web services;information retrieval;software architecture;ubiquitous computing","Web service discovery;context aware techniques;detailed service context models;information retrieval techniques;static-discovery dynamic-selection approach","","2","","13","","","6-10 July 2009","","IEEE","IEEE Conference Publications"
"An Ontology-Based System for Semantic Query over Heterogeneous Databases","D. Chen; L. Li; R. Wang","Sch. of Econ., Wuhan Univ. of Technol., Wuhan, China","2009 WRI World Congress on Software Engineering","20091110","2009","2","","50","53","With an exponential growth in the amount of information available in diverse domains, the traditional information retrieval (IR) approaches which based on keywords can not meet the semantic needs of users. Semantic query, as an application of semantic Web, has shown significant potential in improving the performance of IR. However, many current semantic query engines focus only on the ontology query, while in real world lots of data is stored in heterogeneous relational databases, not ontologies. So how to use semantic query to search the real information in databases has become an issue. In this paper, we explore a novel semantic search approach based on ontology, which uses SPARQL to query the Global Ontology, and realizes the final search of information in the heterogeneous relational databases through a series of query rewrite. A prototype system named 'OSEQ' has been implemented in light of this approach. And it is illustrated by a case study in the e-commerce domain.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319712","SPARQL;heterogeneous databases;ontology;semantic query","Artificial intelligence;Data mining;Information retrieval;Navigation;Ontologies;Prototypes;Relational databases;Search engines;Semantic Web;Software engineering","distributed databases;electronic commerce;information retrieval;ontologies (artificial intelligence);query languages;relational databases;semantic Web","OSEQ;SPARQL;e-commerce;exponential growth;global ontology query;heterogeneous relational databases;information retrieval;keywords;query rewrite;semantic Web;semantic query","","1","","12","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"TPS data collection and data mining","I. Williams; S. Moran","EADS North America Test and Services, Irvine, CA, USA","2009 IEEE AUTOTESTCON","20091106","2009","","","155","160","This paper discusses tools and techniques for TPS data collection and near real-time data processing and visualization using commercial, off-the-shelf products such as Microsoftreg SQL Serverreg database software and Visual Studioreg development system. Examples will be shown on how to add simple data collection and processing methods to the unit under test (UUT) test process using. NET programming languages.","1088-7725;10887725","POD:978-1-4244-4980-4","10.1109/AUTEST.2009.5314049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5314049","","Data analysis;Data engineering;Data mining;Database systems;Information retrieval;North America;Software testing;Software tools;System testing;Visual databases","data mining;network operating systems;program testing;program visualisation",".NET programming language;Microsoftreg SQL serverreg database software;TPS data collection;Visual Studioreg development system;commercial product;data mining;data visualization;off-the-shelf product;real-time data processing;unit under test process","","1","","4","","","14-17 Sept. 2009","","IEEE","IEEE Conference Publications"
"Construction of Ancient-Modern Word Dictionary from Parallel Corpus of Ancient Writings and Their Translations in Modern Language","F. Kimura; A. Maeda","Coll. of Inf. Sci. & Eng., Ritsumeikan Univ., Kusatsu, Japan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1126","1129","Recently, an increasing number of ancient documents are being digitized in text form, but it is difficult to apply natural language processing techniques to these documents because the language resources for ancient languages, such as archaic dictionaries that have sufficient vocabularies, are scarce. In this paper, we propose a method for constructing an ancient modern Japanese dictionary using parallel corpus of ancient writings and their translations in modern language. The parallel corpus consists of document pairs in the same language but in ancient and modern versions. From this corpus, we try to acquire equivalent pairs of archaic and modern word by analyzing the frequencies of word occurrences in a sentence in ancient language and its corresponding modern language translation. We conducted an experiment of calculating similarities of occurrence frequencies of archaic and modern words.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.329","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337579","","Dictionaries;Educational institutions;Frequency estimation;Information retrieval;Information science;Natural language processing;Natural languages;Search engines;Signal processing;Writing","dictionaries;natural language processing;word processing","ancient documents;ancient languages;ancient writings;ancient- modern Japanese dictionary;ancient-modern word dictionary;modern language translations;natural language processing techniques;parallel corpus","","0","","3","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Histogram Descriptor Based on Co-occurrence Matrix and its Application in Cloud Image Indexing and Retrieval","Q. Li; W. Lu","Sch. of Comput. & Inf. Technol., Beijing Jiaotong Univ., Beijing, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","450","454","It becomes an emergent challenge how to retrieve the cloud image from a gigantic cloud image database because of the fast accumulation of digital cloud images in meteorological area. This paper puts forward the histogram descriptor based on gray level co-occurrence matrices to depict the texture characteristics of cloud images, and then applies the histogram descriptor in content-based cloud image retrieval. Our experiment results shows that the proposed histogram descriptor outperforms the state-of-the-art texture features, such as Gabor, local binary pattern and moment descriptor of gray level co-occurrence matrix.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337610","co-occurrence matrix;ground-based cloud image retrieval;histogram","Clouds;Content based retrieval;Filter bank;Histograms;Image retrieval;Indexing;Information retrieval;Meteorology;Pixel;Statistics","content-based retrieval;image retrieval;image texture;visual databases","cloud image indexing;content-based cloud image retrieval;digital cloud images;gigantic cloud image database;gray level cooccurrence matrices;histogram descriptor","","1","","7","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Using Instant Messaging and Annotation Services to Improve Undergraduate Programming Courses in Web-Based Collaborative Learning","Y. F. Lan; Y. C. Jiang","Dept. of Inf. Manage., Nat. Formosa Univ., Huwei, Taiwan","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","236","241","The purpose of this study was to investigate how to improve the collaborative learning to encourage learners' participation in learning activities through CSCL. In addition,this study further to explore the differences of learning achievement from different collaborative learning environment.This study designed an efficient computer-supported collaborative learning (CSCL) mechanism and to develop instant messaging combined with the annotation services as support learning tool. Experimental results demonstrated that different collaborative learning environment have no statistically significant difference on learning achievements. It is notable that our purposed the mechanism can improve interaction between peers, and can encourage learners' participation in collaborative learning activities.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331719","Annotation services;Collaborative learning;Instant messaging","Collaborative tools;Collaborative work;Education;Electronic learning;Information management;Information retrieval;Information technology;Problem-solving;Programming profession;Space technology","Internet;computer aided instruction;computer science education;electronic messaging;programming","Web-based collaborative learning;annotation services;collaborative learning environment;computer-supported collaborative learning;instant messaging;learning activities;undergraduate programming courses","","2","","19","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Ontology-Based Measure of Semantic Similarity between Concepts","S. Bin; F. Liying; Y. Jianzhuo; W. Pu; Z. Zhongcheng","Coll. of Electron. Inf. & Control Eng., Beijing Univ. of Technol., Beijing, China","2009 WRI World Congress on Software Engineering","20091110","2009","2","","109","112","Semantic similarity between concepts plays an important role in knowledge sharing, Web mining and semantic sense understanding. We proposed a new measure which combines the graph-based measure and information content-based measure. The measure take the condition into account that there is another ancestor concept whose information content is nearly the same with which of the nearest common ancestor (NCA). The measure constructs the concept tree by Wordnet and computes the path length of the two concepts in the concept graph, local density and the connect power of the edge, and then integrates them with edge weight and information content. The result indicates the measure perform well in the experiment.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319699","information content;ontology;semantic similarity;wordnet","Educational institutions;Humans;Information retrieval;Joining processes;Knowledge engineering;Length measurement;Ontologies;Software engineering;Software measurement;Tree graphs","data mining;information retrieval;ontologies (artificial intelligence);semantic Web;text analysis;trees (mathematics)","NCA;Web mining;Wordnet;concept graph;concept tree;edge weight;graph-based measure;information content-based measure;information retrieval;knowledge sharing;local density;nearest common ancestor concept;ontology;path length computation;semantic sense understanding;semantic similarity","","4","","13","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"A Fast Image Retrieval Method Using Multi-Feature Dimension Technique","K. L. Hung; Y. C. Tsay","Dept. of Inf. Manage., Chaoyang Univ. of Technol., Wufeng, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","290","294","For querying an image, the most commonly-used method uses low-level features. Of the low-level features, the color feature is the simplest and easiest to understand. Yet, using the color feature alone will not yield a good query result. For example, there may be external factors which cause an alteration in color intensity. To solve these types of problems, in this paper, we propose a multi-feature method composed of saturation, brightness, and frequency to build a three-dimensional space using these features. Then we apply fuzzy theory to color intensity. In this way, our image querying will not fail from an alteration in color intensity. Further experiments have demonstrated that this method is not only effective but is also highly accurate.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337484","image retrieval;multi-feature dimension","Brightness;Content based retrieval;Frequency;Image databases;Image retrieval;Image segmentation;Information retrieval;Lungs;Pixel;Signal processing","fuzzy set theory;image colour analysis;image retrieval","brightness;fast image retrieval method;frequency;fuzzy theory;image querying;multi-feature dimension technique;saturation;three-dimensional space","","0","","10","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Wireless sensor network gateway","L. d. T. Steenkamp; S. Kaplan; R. H. Wilkinson","Center for Instrumentation Research, Department of Electrical Engineering, Cape Peninsula University of Technology, PO Box 652, 8000, South Africa","AFRICON 2009","20091103","2009","","","1","6","Using wireless sensor networks is an effective way of gathering data and also opens up new sensing opportunities. Wireless sensor networks can be more useful if the data can be effectively retrieved from the sensor network. This paper describes the development of a gateway node for a wireless sensor network, implemented in TinyOS, using the AT91RM9200 ARM evaluation kit from Atmel. This node enables the user to remotely retrieve data from-, manage- and configure the network.","2153-0025;21530025","POD:978-1-4244-3918-8","10.1109/AFRCON.2009.5308112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5308112","","Application software;Cities and towns;Communication standards;Information retrieval;Memory;Radio link;Radio transceivers;Remote monitoring;Wireless communication;Wireless sensor networks","internetworking;microprocessor chips;operating systems (computers);wireless sensor networks","AT91RM9200 ARM evaluation kit;Atmel;TinyOS;wireless sensor network gateway","","6","","15","","","23-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Framework of Business Intelligence-Driven Data Mining for E-business","Y. Hang; S. Fong","Dept. of Comput. & Inf. Sci., Univ. of Macau, Macau, China","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1964","1970","This paper proposes a data mining methodology called Business Intelligence-driven Data Mining (BIdDM). It combines knowledge-driven data mining and method-driven data mining, and fills the gap between business intelligence knowledge and existent various data mining methods in e-Business. BIdDM contains two processes: a construction process of a four-layer framework and a data mining process. A methodology is established in setting up the four-layer framework, which is an important part in BIdDM. A case study of B2C e-Shop is provided to illustrate the use of BIdDM.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331527","BI-driven Data Mining;Business intelligence;Data mining","Bismuth;Computer networks;Data mining;Databases;Delta modulation;Information representation;Information retrieval;Information science;Internet;Knowledge representation","competitive intelligence;data mining;electronic commerce","business intelligence-driven data mining;e-business;knowledge-driven data mining;method-driven data mining","","4","","22","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"A method and application of automatic term extraction using conditional random fields","W. Fu; L. Li","CISTR, Beijing University of Posts and Telecommunications, P.R.C., 100876","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","5","A conditional random fields (CRF) based method and application of automatic term extraction was proposed in this paper according to the theory of ldquoInformation -Knowledge - Intelligencerdquo transformation. A CRF model was created by training the different fields of the corpus segmented and tagged. Using the model trained by CRF, the documents in a given field were automatically tagged and the terms in the field was automatically extracted with a certain way. On this basis, this method was used in automatic text summarization system to enhance the rate of the excellent summary. The experimental results showed that this method had a relatively high recall rate and accuracy, could effectively increase the performance of automatic summarization system.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313740","Automatic Term Extraction;Automatic Text Summarization;Conditional Random Fields","Data mining;Entropy;Graphical models;Hidden Markov models;Information processing;Information retrieval;Machine intelligence;Random variables;Standardization;Terminology","information retrieval;random processes;text analysis","automatic term extraction;automatic text summarization system;conditional random;information-knowledge-intelligence transformation","","0","","15","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Automatic Cluster Number Selection Using a Split and Merge K-Means Approach","M. Muhr; M. Granitzer","Knowledge Relationship Discovery, Know-Center Graz, Graz, Austria","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","363","367","The k-means method is a simple and fast clustering technique that exhibits the problem of specifying the optimal number of clusters preliminarily. We address the problem of cluster number selection by using a k-means approach that exploits local changes of internal validity indices to split or merge clusters. Our split and merge k-means issues criterion functions to select clusters to be split or merged and fitness assessments on cluster structure changes. Experiments on standard test data sets show that this approach selects an accurate number of clusters with reasonable runtime and accuracy.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337108","cluster number selection;k-means;split and merge;validity indices","Clustering algorithms;Clustering methods;Databases;Expert systems;Information retrieval;Knowledge management;Large-scale systems;Navigation;Runtime;Testing","pattern clustering;statistical analysis","automatic cluster number selection;internal validity indices;split and merge k-means approach;standard test data","","1","","14","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Federated Databases as a Basis for Infrastructure Supporting Epidemiological Research","R. Fomkin; M. Stenbeck; J. E. Litton","Dept. of Med. Epidemiology & Biostat., Karolinska Institutet, Stockholm, Sweden","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","313","317","Data on the Swedish population are stored in many registers located in different authorities. These data are crucial for epidemiological and other register-based research. We are developing an infrastructure to support research on the data from Swedish registers. In the infrastructure each organization or authority should keep its own control on all accesses to its data. The infrastructure should allow only authorized access to data. The effort for scientists to perform their analyses on the data should be insignificant. We propose to base the infrastructure on federated databases. This enables secure and only authorized data access, efficient and scalable data extractions, integration with statistical and other tools, and autonomy to data sources. We are investigating the feasibility of our approach by developing a pilot infrastructure for epidemiological research on cervical cancer. In this paper we identify challenges of applying federated databases for accessing sensitive and personal data by scientists.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337137","database infrastructure;database integration;epidemiological research;federated database;register-based research","Cervical cancer;Data analysis;Data mining;Database systems;Information retrieval;Medical expert systems;Performance analysis;Proposals;Protection;Statistics","authorisation;database management systems;medical information systems","Swedish population;Swedish registers;access control;authorized data access;cervical cancer;epidemiological research;federated databases;register-based research","","1","","12","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Receiver assistant congestion control in high speed and lossy networks","K. Shi; Y. Shu; O. Yang; J. Luo","Department of Computer Science, Tianjin University, 300072, China","2009 16th IEEE-NPSS Real Time Conference","20091110","2009","","","91","95","Many applications require fast data transfer in high speed wireless networks. A representative example is that EAST experiment data are retrieved by some physics researchers using the TCP (transmission control protocol). However, due to the limitation in its conservative congestion control algorithm, TCP can not effectively utilize the network capacity. Furthermore, TCP assumes that every packet loss is caused by network congestion and invokes congestion control and avoidance. TCP's blind congestion control aggravates the performance degradation in high speed and lossy wireless networks. In this paper, we propose a receiver assistant congestion control mechanism (RACC), in which the sender still performs loss-based control, while the receiver performs delay-based control. The receiver measures the network bandwidth based on the interpacket delay gaps, and computes an appropriate congestion window size according to the measured bandwidth and then feedbacks the value to the sender. The sender adjusts the congestion window size based on the value informed by the receiver and the AIMD (additive-increase multiplicative-decrease) mechanism. By integrating the loss-based and delay-based congestion controls, our mechanism can mitigate the effect of wireless losses, alleviate the timeout effect, and therefore make better use of network bandwidth. The simulation results in various scenarios show that our mechanism can have better performance than conventional TCP in high speed and lossy wireless environment.","","POD:978-1-4244-4454-0","10.1109/RTC.2009.5322096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5322096","","Bandwidth;Computer networks;Degradation;Delay;Information retrieval;Performance loss;Physics;Protocols;Size measurement;Wireless networks","delays;radio networks;telecommunication congestion control;transport protocols","AIMD;RACC;TCP blind congestion control;additive-increase multiplicative-decrease;congestion window size;delay-based congestion control;high speed wireless network;interpacket delay gap;loss-based congestion control;lossy wireless network;receiver assistant congestion control algorithm;transmission control protocol","","1","","10","","","10-15 May 2009","","IEEE","IEEE Conference Publications"
"Temporal Specification and Deductive Verification of a Distributed Component Model and Its Environment","A. Basso; A. Bolotov; V. Getov","Sch. of Electron. & Comput. Sci., Univ. of Westminster, London, UK","2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement","20091110","2009","","","379","386","In this paper we investigate the formalisation of distributed and long-running stateful systems using our normative temporal specification framework. We analyse aspects of a component-oriented Grid system, and the benefits of having a logic-based tool to perform automated and safe dynamic reconfiguration of its components. We describe which parts of this Grid system are involved in the reconfiguration process and detail the translation procedure into a state-based formal specification. Subsequently, we apply deductive verification to test whether dynamic reconfiguration can be performed. Finally, we analyse the procedure required to update our model for reconfiguration and justify the validity and the advantages of our methodology.","","POD:978-0-7695-3758-0","10.1109/SSIRI.2009.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5325345","Automated Reconfiguration;Deductive Reasoning;Formal Specification;Grid Component Model;Grid IDE","Architecture description languages;Computer science;Conferences;Formal specifications;Information retrieval;Logic;Monitoring;Performance analysis;Runtime;Testing","distributed object management;formal specification;grid computing;object-oriented programming;program verification","Grid Component model;automated dynamic reconfiguration;component-oriented Grid system;deductive verification;distributed component model;distributed stateful systems;logic-based tool;long-running stateful systems;model-based validation;model-based verification;normative temporal specification;safe dynamic reconfiguration;state-based formal specification","","0","","26","","","8-10 July 2009","","IEEE","IEEE Conference Publications"
"A Conceptual Model for Combining Enhanced OLAP and Data Mining Systems","M. Usman; S. Asghar; S. Fong","Shaheed Zulfikar AH Bhutto Inst. of Sci. & Technol., Islamabad, Pakistan","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1958","1963","Online Analytical Processing (OLAP) was widely used to visualize complex data for efficient, interactive and meaningful analysis. Its power comes in visualizing huge operational data for interactive analysis. On the other hand, data mining techniques (DM) are strong at detecting patterns and mining knowledge from historical data. OLAP and DM is believed to be able to complement each other to analyze large data sets in decision support systems. Some recent researches have shown the benefits of combining OLAP with Data Mining. In this paper, we reviewed the coupling of OLAP and data mining in the literature and identified their limitations. We proposed a conceptual model that overcomes the existing limitations, and provides a way for combining enhanced OLAP with data mining systems. Furthermore, the proposed model offers directions to improving cube construction time and visualization over the data cube.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331521","Data Mining;Enhanced OLAP;Performance Enhancement;Visualization Techniques","Data analysis;Data mining;Data visualization;Decision support systems;Delta modulation;Information analysis;Information retrieval;Multidimensional systems;Performance analysis;Power system modeling","data mining;data visualisation;decision support systems","complex data visualization;data cube construction time;data mining systems;decision support systems;enhanced OLAP;interactive analysis;knowledge mining;online analytical processing;pattern detection","","4","","32","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"CGM: A biomedical text categorization approach using concept graph mining","S. Bleik; M. Song; A. Smalter; J. Huan; G. Lushington","Department of Information Systems, New Jersey Institute of Technology","2009 IEEE International Conference on Bioinformatics and Biomedicine Workshop","20091113","2009","","","38","43","Text Categorization is used to organize and manage biomedical text databases that are growing at an exponential rate. Feature representations for documents are a crucial factor for the performance of text categorization. Most of the successful existing techniques use a vector representation based on key entities extracted from the text. In this paper we investigate a new direction where we represent a document as a graph. In this representation we identify high level concepts and build a rich graph structure that contains additional concepts and relationships. We then use graph kernel techniques to perform text categorization. The results show a significant improvement in accuracy when compared to categorization based on only the extracted concepts.","","POD:978-1-4244-5121-0","10.1109/BIBMW.2009.5332134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332134","","Data mining;Engineering management;Information retrieval;Kernel;Management information systems;Spatial databases;Technology management;Text categorization;Unified modeling language;User-generated content","data mining;medical computing;text analysis","biomedical text categorization approach;biomedical text databases;concept graph mining;graph kernel techniques","","1","","23","","","1-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Group Aware Semantic Matchmaker for Grid Resource Discovery","B. K. R.; S. M. S. Bhanu","Dept. of IT, Amrita Sch. of Eng., Coimbatore, India","2009 International Conference on Advances in Recent Technologies in Communication and Computing","20091117","2009","","","777","779","In large-scale grid environments, resource discovery is made challenging by a potentially large number of resources and users and considerable heterogeneity in resource types and user requests. Resource discovery is further complicated by the dynamic variation of the number of shared resources in the system, shared resource characteristics such as availability and CPU load which vary with the time. To achieve high precision resource discovery, resources must be given well defined meaning carried by semantic information added to resource descriptions. Ontologies increasingly gain importance for grid computing to semantically describe resources and to support an improved interoperability between applications. It allows customization of the service discovery process as it provides a selection of service matches. In this paper, a framework for resource discovery based on group aware semantics is proposed. The resources are grouped according to the services offered by them and whenever there is a request for a resource the best match is returned by matchmaking locally or by forwarding the requests to the neighbor matchmakers. A flat, decentralized model is implemented so that it will thwart single point failure and increase scalability.","","POD:978-1-4244-5104-3","10.1109/ARTCom.2009.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5328143","Grid;Matchmaking;Ontology;Resource Discovery","Availability;Central Processing Unit;Communications technology;Grid computing;Information retrieval;Large-scale systems;Ontologies;Operating systems;Quality of service;Scalability","grid computing;groupware;ontologies (artificial intelligence);open systems","CPU load;application interoperability;decentralized model;grid computing;grid resource discovery;group aware semantic matchmaker;ontologies","","0","","9","","","27-28 Oct. 2009","","IEEE","IEEE Conference Publications"
"Ranking Method for Optimizing Precision/Recall of Content-Based Image Retrieval","J. Zhang; L. Ye","Sch. of Comput. Sci. & Software Eng., Univ. of Wollongong, Wollongong, NSW, Australia","2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing","20091110","2009","","","356","361","The ranking method is a key element of content-based image retrieval (CBIR) system, which can affect the final retrieval performance. In the literature, previous ranking methods based on either distance or probability do not explicitly relate to precision and recall, which are normally used to evaluate the performance of CBIR systems. In this paper, a novel ranking method based on relative density is proposed to improve the probability based approach by ranking images in the class. The proposed method can achieve optimal precision and recall. The experiments conducted on a large photographic collection show significant improvements of retrieval performance.","","POD:978-1-4244-4902-6","10.1109/UIC-ATC.2009.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319211","Content-based image retrieval;performance evaluation;ranking method","Australia;Computer science;Conferences;Content based retrieval;Image retrieval;Image sequences;Information retrieval;Optimization methods;Pervasive computing;Software engineering","content-based retrieval;image retrieval;optimisation","CBIR systems;content-based image retrieval;large photographic collection;optimal precision;optimal recall;optimization;ranking method","","0","","13","","","7-9 July 2009","","IEEE","IEEE Conference Publications"
"An Efficient Encoding and Labeling Based Upon Continued Fraction for Dynamic XML Data","Y. Jiang; Z. m. Zeng; D. Z. Zhang","Dept. of Comput. Sci., Xiamen Univ., Xiamen, China","2009 WRI World Congress on Software Engineering","20091110","2009","1","","324","328","In order to efficiently determine ancestor-descendant relationships between any two random XML nodes and the document-order between the nodes and to avoid re-labeling for updates, much research about labeling schemes has been conducted. In this paper we present a new efficient XML encoding and labeling scheme for dynamic XML document called CFE (Continued Fraction-based Encoding) which labels nodes with continued fractions. CFE has three important properties which form the foundations of this paper: (1) CFE supports that codes can be inserted between any two consecutive CFE codes with the orders kept and without re-encoding the existing nodes; (2) CFE is orthogonal to specific labeling schemes, thus it can be applied broadly to different labeling schemes or other applications to efficiently process the updates; (3) Moreover, CFE supports all structural relationships query in XPath. The experimental results show that CFE provides fairly reasonable XML query processing performance while completely avoiding re-labeling for updates.","","POD:978-0-7695-3570-8","10.1109/WCSE.2009.150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319119","","Computer science;Costs;Database languages;Encoding;Information retrieval;Labeling;Query processing;Radio access networks;Software engineering;XML","XML;encoding;query processing","XML labeling scheme;XPath;ancestor-descendant relationship;continued fraction;dynamic XML data encoding;random XML node;structural relationship query","","0","","19","","","19-21 May 2009","","IEEE","IEEE Conference Publications"
"A Comparative Study of Global and Local Feature Representations in Image Database Categorization","C. F. Tsai; W. C. Lin","Dept. of Inf. Manage., Nat. Central Univ., Chungli, Taiwan","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","1563","1566","Content-based image retrieval systems can automatically extract visual content of images which allow users to query images by their low-level features (such as color and texture). However, users usually prefer querying images based on high-level concepts such as keywords. Classifying images into a number of categories (or image classification) facilitates search in image databases. However, the classification performance is heavily dependent on the use of features. In general, there are three feature representation methods, which are global, block-based, and region-based features. As related work only considers using one of these three methods, this paper aims at comparing each of these methods and their combinations by using a standard classifier (i.e. k-nearest neighbor) over thirty categories. The experimental results show that the combined global and block-based feature representation performs the best. In addition, larger numbers of training examples produce higher classification accuracy.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331422","Multimedia databases;content-based image retrieval;feature representation;image classification","Content based retrieval;Humans;Image classification;Image databases;Image retrieval;Indexing;Information management;Information retrieval;Multimedia databases;Vocabulary","content-based retrieval;feature extraction;image classification;image representation;image retrieval;visual databases","block-based feature representation;content-based image retrieval systems;global feature representations;image classification;image database categorization;image query;keywords;local feature representations;low-level features;standard classifier","","1","","14","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Towards Optimal Indexing for Relevance Feedback in Large Image Databases<formula formulatype=""inline""><tex Notation=""TeX"">$^+$</tex> </formula>","S. Ramaswamy; K. Rose","Signal Compression Lab., Univ. of California, Santa Barbara, CA, USA","IEEE Transactions on Image Processing","20091110","2009","18","12","2780","2789","Motivated by the need to efficiently leverage user relevance feedback in content-based retrieval from image databases, we propose a fast, clustering-based indexing technique for exact nearest-neighbor search that adapts to the Mahalanobis distance with a varying weight matrix. We derive a basic property of point-to-hyperplane Mahalanobis distance, which enables efficient recalculation of such distances as the Mahalanobis weight matrix is varied. This property is exploited to recalculate bounds on query-cluster distances via projection on known separating hyperplanes (available from the underlying clustering procedure), to effectively eliminate noncompetitive clusters from the search and to retrieve clusters in increasing order of (the appropriate) distance from the query. We compare performance with an existing variant of VA-File indexing designed for relevance feedback, and observe considerable gains.","1057-7149;10577149","","10.1109/TIP.2009.2028929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5184910","CBIR;image database;index;relevance feedback;similarity search","Biomedical imaging;Content based retrieval;Feedback;Image databases;Image retrieval;Image storage;Indexing;Information retrieval;Multimedia databases;Search engines","database indexing;image retrieval;relevance feedback;visual databases","Mahalanobis distance;VA-File indexing;content-based retrieval;indexing;large image databases;relevance feedback","","10","","42","","20090731","Dec. 2009","","IEEE","IEEE Journals & Magazines"
"TMS for Multimodal Information Processing","B. R. Barricelli; M. Padula; P. L. Scala","Dipt. di Inf. e Comun., Univ. degli Studi di Milano, Milan, Italy","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","295","299","Many working processes are complex and composed by heterogeneous atomic tasks, e.g. editing, assembling data from different sources (as databases or laboratory's devices) with texts, images or learning objects, or submitting them to processing components to retrieve information, to render them, re-format, submit to computations, and other types of information processing. All these complex processes are extremely difficult to be modeled and automatized without having a flexible, multimodular evolutionary system in place. Support to information from different modalities increases the performance of a computer system originally designed for a task with a unimodular nature. In this paper, we discuss the idea of task management system (TMS) as a component based system which offers a virtual workbench to search, acquire, describe and assemble computational agents performing single autonomous tasks into working processes. We sustain that TMS is a cutting edge platform to develop SW solutions for problems related to workflow automatization and design. The architecture we propose follows the conceptual track of the TMS to allow composition and arrangement of atomic modules into a complex system: a core configuration of the system can be extended with a set of task/components, chunks of activities which are considered basic to working flow composition. The workflow designer selects the relevant chunks from system repositories, drags them into a working system area and assembles them into a working process. Complex activities could be formally described, implemented and applied with a consequent advantage for personnel re-organization toward more conceptual activities.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337146","","Assembly systems;Computer architecture;Databases;Electronic mail;Expert systems;Image retrieval;Information processing;Information retrieval;Rendering (computer graphics);US Department of Transportation","Web services;object-oriented programming;workflow management software","complex processes;complex system;component based system;computational agents;heterogeneous atomic tasks;multimodal information processing;multimodular evolutionary system;task management system;virtual workbench;workflow automatization;workflow design","","0","","18","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Iterative integration of visual insights during patent search and analysis","S. Koch; H. Bosch; M. Giereth; T. Ertl","Visualization and Interactive Systems Group, Universit&#228;t Stuttgart, Germany","2009 IEEE Symposium on Visual Analytics Science and Technology","20091113","2009","","","203","210","Patents are an important economic factor in todays globalized markets. Therefore, the analysis of patent information has become an inevitable task for a variety of interest groups. The retrieval of relevant patent information is an integral part of almost every patent analysis scenario. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. With `PatViz', a new system for interactive analysis of patent information has been developed to leverage iterative query refinement. PatViz supports users in building complex queries visually and in exploring patent result sets interactively. Thereby, the visual query module introduces an abstraction layer that provides uniform access to different retrieval systems and relieves users of the burden to learn different complex query languages. By establishing an integrated environment it allows for interactive reintegration of insights gained from visual result set exploration into the visual query representation. We expect that the approach we have taken is also suitable to improve iterative query refinement in other Visual Analytics systems.","","POD:978-1-4244-5283-5","10.1109/VAST.2009.5333564","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5333564","Patent retrieval;information visualization;multiple coordinated views;visual analytics","Companies;Database languages;Environmental economics;Information analysis;Information retrieval;Intellectual property;Interactive systems;Iterative methods;Visual analytics;Visualization","information analysis;information retrieval;patents","PatViz;complex query languages;economic factor;globalized markets;interactive analysis;iterative integration;iterative query refinement;patent document retrieval;patent information analysis;patent information retrieval;patent material;patent search;visual analytics system;visual insight;visual query module;visual query representation","","9","","23","","","12-13 Oct. 2009","","IEEE","IEEE Conference Publications"
"Combining Vector Space Model and Category Hierarchy Model for TV Content Similarity Measure","Z. Yu; X. Zhou","Sch. of Comput. Sci., Northwestern Polytech. Univ., Xi'an, China","2009 Third International Conference on Multimedia and Ubiquitous Engineering","20091110","2009","","","130","136","In this paper, we propose a new approach for TV content similarity measure, which combines both vector space model and category hierarchy model. The hybrid measure proposed here makes the most of TV metadata information and takes advantage of the two similarity measurements. It measures TV content similarity from the semantic level other than the physical level. Furthermore, we propose an adaptive strategy for setting the combination parameters. The experimental results showed that using the combining approach proposed here is superior to using either similarity measure alone for example-based retrieval of TV content.","","POD:978-0-7695-3658-3","10.1109/MUE.2009.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319034","","Bayesian methods;Computer science;Content based retrieval;Databases;Extraterrestrial measurements;Fuzzy logic;Hidden Markov models;Information retrieval;Large-scale systems;TV","XML;content-based retrieval;encoding;meta data;television broadcasting;vectors","TV content broadcasting;TV content example-based retrieval;TV content similarity measurement;TV metadata information;XML encoding;adaptive combination parameter strategy;category hierarchy model;document retrieval;physical level;semantic level;vector space model","","2","","24","","","4-6 June 2009","","IEEE","IEEE Conference Publications"
"A Probabilistic Model for Automatic Image Annotation and Retrieval","Z. Li; H. Ma; Z. Shi; Z. Shi","Key Lab. of Intell. Inf. Process., Chinese Acad. of Sci., Beijing, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","1","","14","19","Automatic image annotation has become an important and challenging problem due to the existence of the semantic gap. In this paper, we present an approach based on probabilistic latent semantic analysis (PLSA) to achieve the task. In order to model training data precisely, an image is firstly represented as a bag of visual words, then a probabilistic structure with two PLSA models is employed to capture semantic information from visual and textual modalities respectively. Furthermore, an adaptive asymmetric learning approach is proposed to fuse the aspects of these two models. For each image document, the distribution over aspects of different models is fused by multiplying different weights, which are determined by the entropy of the feature distribution. Consequently, the two models are linked with the same distribution over all aspects. This structure can predict semantic annotation well for an unseen image because it associates visual and textual modalities properly. We compare our approach with several previous approaches on a standard Corel dataset. The experimental results show that our approach performs more effectively and accurately.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329188","PLSA;adaptive asymmetric learning;aspect model;automatic image annotation;image retrieval","Computers;Feature extraction;Fuses;Image databases;Image retrieval;Indexing;Information processing;Information retrieval;Laboratories;Spatial databases","image retrieval;learning (artificial intelligence);probability;semantic networks","adaptive asymmetric learning approach;automatic image annotation;automatic image retrieval;bag of visual words;probabilistic latent semantic analysis;semantic gap;standard Corel dataset","","1","","19","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Midas touch - chunking information on a robotic user interface using spatial and functional metaphor","S. C. Kim; S. Koo; D. S. Kwon","Human Robot Interaction Research Center, Mechanical Engineering Department, KAIST, Daejeon, Korea","RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication","20091110","2009","","","967","972","In this paper, a robotic user interface (RUI) as an information management system is described. There have been numerous studies regarding 2D- or 3D-based GUIs that attempt to overcome the disadvantages of a hierarchal structure in information handling. Here, the GUI system is extended to RUI in a technique that enhances its capacity to store and recall by exploiting a spatial/functional association between semantic categories and body parts. A robot resembling a bear was implemented for the evaluation of this association. Experimental results revealed that information can be clustered on a specific body part with statistical significance. Information storage and retrieval becomes easier because there is no need for maintenance or memorization of a location in which specific information is stored. In addition, the fact that a robotic interface can be used in parallel with an existing desktop-based system enhances work efficiency.","1944-9445;19449445","CD-ROM:978-1-4244-5081-7","10.1109/ROMAN.2009.5326066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326066","","Displays;Ecosystems;Encoding;Graphical user interfaces;Human robot interaction;Information management;Information retrieval;Layout;Mechanical engineering;User interfaces","graphical user interfaces;human-robot interaction;information management;information retrieval","2D-based GUI;3D-based GUI;Midas touch;desktop-based system;functional metaphor;information management system;information retrieval;information storage;robotic user interface;spatial metaphor;statistical significance","","0","","24","","","Sept. 27 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"The picture superiority effect in encoding and retrieval processes during Japanese learning for Chinese bilinguals","L. Mi; X. Liu; F. Ren","Department of Information Science and Intelligent Systems, The University of Tokushima, 770-8506, Tokushima, Japan","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","8","In order to investigate the picture superiority effect, we compared the ERP between picture combined word (picture-word) and pure word (word) at study and test phase. During encoding, the FN400 was more negative and lasted longer for picture-words than for words. The late positive component (LPC) was more positive and distributed broadly for words compared to picture-words. During retrieval, the old picture-word elicited remarkably FN400 familiarity effect and parietal old/new effect compared to the old word. We suggested that simultaneous image and verbal encoding of picture-word elicited better and faster recollection compared to word during the memory test. Our findings also demonstrated that the picture superiority effect was related to the ability of pictures enhancing encoding and facilitating recollection.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313835","ERP;encoding;familiarity;picture superiority effect;recognition memory;recollection;retrieval","Electrodes;Encoding;Enterprise resource planning;Image coding;Image retrieval;Information retrieval;Information science;Intelligent systems;Linear predictive coding;Natural languages","image coding;image retrieval;natural language processing","Chinese bilinguals;FN400;Japanese learning;event-related potentials;image encoding process;late positive component;picture superiority effect;retrieval process;verbal encoding","","0","","16","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"A slice-based data acquisition system for long duration discharges of EAST","Y. Liu; J. Luo; G. Li","ShenZhen University, College of Physics Science & Technology, China","2009 16th IEEE-NPSS Real Time Conference","20091110","2009","","","431","433","Pulse of up to 1000 seconds with 0.5 MA plasma current is the main objective of EAST (Experimental Advanced Superconducting Tokamak) discharge experiments. For long duration discharge, real-time diagnostics is indispensable. To meet the requirement, a slice-based data acquisition system for long duration discharge has been designed and developed. This paper gives an overview of this system. The slice-based data acquisition system is based on time slice mechanism, which divides continuous experimental data into slices. And the time slice of data are transferred, stored, published in real-time while collecting data. Moreover, the introduction of multi-stage storage and time window greatly enhanced the speed of mass data access. The slice-based data acquisition system has been reliably operated in the EAST experimental campaigns.","","POD:978-1-4244-4454-0","10.1109/RTC.2009.5321617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5321617","data acquisition;fusion reactors","Data acquisition;Data visualization;Electronic mail;Information retrieval;Network servers;Nuclear and plasma sciences;Optical buffering;Physics;Plasma diagnostics;Real time systems","Tokamak devices;data acquisition;fusion reactor operation;plasma diagnostics;real-time systems","EAST discharge experiments;Experimental Advanced Superconducting Tokamak;current 0.5 MA;long duration discharges;multistage storage;plasma current;real-time data;real-time diagnostics;slice-based data acquisition system;time 1000 s;time slice mechanism;time window","","0","","7","","","10-15 May 2009","","IEEE","IEEE Conference Publications"
"Context-aware life-logging for persons with mild dementia","B. Kikhia; J. Hallberg; K. Synnes; Z. u. H. Sani","Department of Computer Science and Electrical Engineering, Lule&#229; University of Technology, Sweden. 971 87 Lule&#229;, Sweden","2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20091113","2009","","","6183","6186","The demands of introducing technology to support independent living is increasing. This is true also for persons suffering from mild dementia who may have difficulties remembering important information, such as activities, numbers, names, objects, faces, and so on. This paper presents a context-aware life-logging system, called MemoryLane, which can support independent living and improve quality of life for persons with mild dementia. The system offers both real time support as well as possibilities to rehearse and recall activities for building episodic memory. This paper also presents a mobile client to be used in MemoryLane, as well as an evaluation of the importance of different data for the purpose of memory recollection.","1094-687X;1094687X","CD-ROM:978-1-4244-3296-7","10.1109/IEMBS.2009.5334509","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5334509","","Computer science;Context-aware services;Dementia;Digital recording;Information retrieval;Navigation;Real time systems;Safety;Senior citizens;USA Councils","handicapped aids;medical computing;medical disorders;neurophysiology;real-time systems;ubiquitous computing","MemoryLane;context-aware life-logging;episodic memory;memory aids;memory recollection;memory rehabilitation;mild dementia;real time support","1","3","","10","","","3-6 Sept. 2009","","IEEE","IEEE Conference Publications"
"Towards the relationship between Semantic Web and NLP","R. Guo; F. Ren","College of Mathematics & Information Science, Hebei Normal University, Shijiazhuang, Hebei, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","8","With the development of Semantic the Web technology, the NLP technology has much broader prospects. This article analyses the fusion degrees between the two technologies based on the survey of relations of them. We explain the relationship between Semantic Web and NLP in two aspects. One is NLP how to support Semantic Web development in Ontology Learning, Ontology Query and Multilingual Ontology Mapping. The other is Semantic Web technologies how to improve NLP results in Information Extraction and Word Sense Disambiguation. We also propose some research challenges for the cooperation between Semantic Web and NLP.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313806","NLP;Ontology;Semantic Web","Data mining;Educational institutions;Information retrieval;Information science;Mathematics;Natural language processing;OWL;Ontologies;Resource description framework;Semantic Web","natural language processing;ontologies (artificial intelligence);semantic Web","information extraction;multilingual ontology mapping;natural language processing;ontology learning;ontology query;semantic Web development;semantic Web technology;word sense disambiguation","","1","","70","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Solving Over-constrained Problems Using Network Analysis","M. Schubert; A. Felfernig; M. Mandl","Appl. Software Eng., IST Graz Univ. of Technol., Graz, Austria","2009 International Conference on Adaptive and Intelligent Systems","20091117","2009","","","9","14","Requirements for which no recommendation can be calculated are unsatisfactory for the user. The detection and resolution of conflicts between those requirements and the product assortment is an important functionality to successfully guide the user to a solution. In this paper we introduce a new approach how to identify minimal conflict sets in over constrained problems through network analysis. Conflict sets offer the information which constraints (requirements) need to be changed to retrieve a solution. Random constrained problems are used to evaluate our approach and compare it to existing conflict detection algorithms. A major result of this evaluation is that our approach is superior in settings typical for knowledge-based recommendation problems.","","POD:978-0-7695-3827-3","10.1109/ICAIS.2009.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5328090","Explanations;Recommender Systems","Adaptive systems;Algorithm design and analysis;Databases;Detection algorithms;Information retrieval;Intelligent networks;Intelligent systems;Portable computers;Recommender systems;Software engineering","constraint handling;constraint theory;knowledge based systems;network analysis;operations research","conflict detection algorithm;constraint satisfaction problem;knowledge-based recommendation problem;minimal conflict sets identification;network analysis;over constrained problems;recommender system","","0","","10","","","24-26 Sept. 2009","","IEEE","IEEE Conference Publications"
"Visual knowledge exploration and discovery from different points of view","A. S. Dadzie; D. Petrelli","Dept. of Information Studies, The University of Sheffield, UK","2009 IEEE Symposium on Visual Analytics Science and Technology","20091113","2009","","","227","228","Complex scenario analysis requires the exploration of multiple hypotheses and supporting evidence for each argument posed. Knowledge-intensive organisations typically analyse large amounts of inter-related, heterogeneous data to retrieve the knowledge this contains and use it to support effective decision-making. We demonstrate the use of interactive graph visualisation to support hierarchical, task-driven, hypothesis investigation. The visual investigative analysis is guided by task and domain ontologies used to capture the structure of the investigation process and the experience gained and knowledge created in previous, related investigations.","","POD:978-1-4244-5283-5","10.1109/VAST.2009.5333438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5333438","H.5.2 [Information Interfaces and Presentation]: User Interfaces—Graphical user interfaces (GUI);K.6.1 [Management of Computing and Information Systems]: Project and People Management—Life Cycle","Assembly systems;Bicycles;Computer science;Decision making;Failure analysis;Information analysis;Information retrieval;Ontologies;Project management;Visualization","data mining;data visualisation;decision making;information retrieval;ontologies (artificial intelligence)","decision making;domain ontologies;heterogeneous data analysis;interactive graph visualisation;knowledge retrieval;knowledge-intensive organisations;visual knowledge discovery;visual knowledge exploration","","0","","6","","","12-13 Oct. 2009","","IEEE","IEEE Conference Publications"
"Chinese maximal noun phrase parsing based on cascaded conditional random fields","D. Cai; X. Liu; Q. Zhou; N. Ye","Knowledge Engineering Research, Center, Shenyang Institute of Aeronautical Engineering, Shenyang, Liaoning, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","7","This paper proposes an approach for Chinese maximal noun phrase parsing based on cascaded conditional random fields. In this approach, the parse tree of Chinese maximal noun phrase is constructed layer by layer. The Chinese chunks are first recognized by the lower conditional random fields model, then the result is passed as input to the higher model for recognition of phrases, the process of recognizing phrases is continued until no new phrases are discovered. Post-processing rules are constructed between the lower and higher models to modify the erroneous recognition of Chinese chunks, and finally the phrase structure tree of the Chinese maximal noun phrase is constructed. In open test, our Chinese maximal noun phrase parser achieves F1-score of 92.02%.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313768","Cascaded Conditional Random Fields;Conditional Random Fields;Maximal Noun Phrase;phrase structure tree","Aerospace engineering;Computer aided instruction;Information retrieval;Knowledge engineering;Natural language processing;Performance analysis;Testing","grammars;natural languages;random processes;trees (mathematics)","Chinese maximal noun phrase parsing;cascaded conditional random fields;phrase structure tree;phrases recognition","","1","","14","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"DAR: Distributed Adaptive Service Replication for MANETs","A. Ahmed; K. Yasumoto; N. Shibata; T. Kitani; M. Ito","Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol. (NAIST), Ikoma, Japan","2009 IEEE International Conference on Wireless and Mobile Computing, Networking and Communications","20091110","2009","","","91","97","Mobile ad hoc networks (MANETs) can be used to provide mobile users temporary infrastructure to use services such as database retrieval service when traditional infrastructure-based networks are unavailable in infrastructure-less situations (e.g. after a destructive disaster like an earthquake). The challenging task in such dynamic environments is how we can improve the service availability. An effective strategy is replicating a service at some nodes distributed across the network. However, service replication can considerably impact the system energy consumption. Since mobile devices have a limited amount of battery, a dynamic and efficient service replication is necessary to support such environments. In this paper, we propose a distributed service replication scheme for achieving high service availability with reasonable energy consumption for MANETs. The proposed method called distributed adaptive service replication (DAR) divides the whole network into disjoint zones of at most 2-hops in diameter and builds a dynamic replication mechanism which puts replicas only in zones with high service demand. Through simulations, we have confirmed that our approach can achieve higher service availability and lower energy consumption than an existing method.","2160-4886;21604886","POD:978-0-7695-3841-9","10.1109/WiMob.2009.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5325308","Energy consumption;MANET;Service availability;Service replication","Availability;Batteries;Computer networks;Distributed computing;Energy consumption;Information retrieval;Mobile ad hoc networks;Mobile computing;Multimedia databases;Service oriented architecture","ad hoc networks;mobile radio","database retrieval service;distributed adaptive service replication;dynamic replication mechanism;infrastructure-based networks;mobile ad hoc networks","","2","","18","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"SIFT-Based Image Retrieval Combining the Distance Measure of Global Image and Sub-Image","B. Li; X. Kong; Z. Wang; H. Fu","Sch. of Electron. & Inf., Dalian Univ. of Technol., Dalian, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","706","709","This paper presents a similarity match method based on global image and local sub-image using the SIFT features of digital images, and applies our algorithm to Content-Based Image Retrieval. In order to make the SIFT-based image retrieval results better, the most fundamental improvement comes in two areas. One is the introduction of the distance between the matched keypoints, and the shorter the distance between the matched keypoints, the lower the similarity measure. The other is that the image is partitioned off into sub-images, which reduces the mismatched keypoints. Experiments demonstrate effectiveness of the proposed approach compared with the traditional SIFT-based image retrieval and reveal it as a good option to image retrieval.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337442","CBIR;SIFT;Similarity match;Similarity measure;sub-image;the distance measure","Content based retrieval;Data mining;Digital images;Digital signal processing;Feature extraction;Image databases;Image retrieval;Information retrieval;Paper technology;Signal processing algorithms","content-based retrieval;feature extraction;image retrieval","SIFT-based image retrieval;content-based image retrieval;digital images;distance measure;global image;local sub-image;scale invariant feature transform;similarity match method;similarity measure","","3","","10","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Incomplete Information of Decision Support System for Planting Material Selection","M. N. B. M. Salleh; N. B. M. Nawi; P. Boursier","Univ. Tun Hussein Onn Malaysia, Johor, Malaysia","2009 Fifth International Joint Conference on INC, IMS and IDC","20091113","2009","","","315","319","Incomplete information introduces uncertainty into decision modeling evaluation, since it is no longer obvious which objects should be retrieved. In agriculture environment where ecological databases are distributed on several information servers, the informative features such as planting material, weather and fertilizer should be exploited in optimal way with supported informative and relevant requirements derived from the expert. Many real-world data sets which have missing values attempt to impute some values, while many statistical and learning methods simply deleting directly the missing values. However, we measure the degree of uncertainty to rank objects for presentation to a user and measure the observed value into fuzzy representation to generate simple and comprehensible decision rule sets as `information'.","","POD:978-1-4244-5209-5","10.1109/NCM.2009.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331708","Decision tree;entropy;uncertainty","Agriculture;Biological system modeling;Decision support systems;Distributed databases;Fertilizers;Fuzzy sets;Information retrieval;Learning systems;Spatial databases;Uncertainty","agriculture;decision support systems;decision trees;fuzzy set theory","agriculture environment;decision modeling evaluation;decision rule sets;decision support system;ecological databases;fertilizer;fuzzy representation;incomplete information;information servers;missing values;planting material selection;weather","","0","","9","","","25-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"A feature-enhanced smoothing method for LDA model applied to text classification","D. Liu; W. Xu; J. Hu","PRIS Lab, BUPT., BeiJing, China","2009 International Conference on Natural Language Processing and Knowledge Engineering","20091106","2009","","","1","7","Latent Dirichlet Allocation (LDA) is a generative model employing the symmetry Dirichlet distribution as prior of the topic-words' distributions to implement model smoothing. When LDA is applied to text classification, smoothing is essential to classification performance. In this paper, we propose a feature-enhanced smoothing method in the idea that words not appeared in the training corpus can help to improve the classification performance. The key point is fully considering the relativity between the new document and training corpus, and enhancing the document's class feature by regarding the words not appeared in the training corpus. Evaluations on 20newsgroups show feature-enhanced smoothing can significantly improve the performance in Bi-class text classification.","","POD:978-1-4244-4538-7","10.1109/NLPKE.2009.5313846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313846","Data-Driven Strategy;Latent Dirichlet Allocation;Text classification;feature-enhanced;smoothing","Information entropy;Information retrieval;Laplace equations;Linear discriminant analysis;Maximum likelihood estimation;Probability distribution;Random variables;Smoothing methods;Text categorization;Vocabulary","pattern classification;text analysis","Dirichlet distribution;LDA model;classification performance;feature-enhanced smoothing method;latent Dirichlet allocation;model smoothing;text classification;topic-words distributions;training corpus","","3","","7","","","24-27 Sept. 2009","","IEEE","IEEE Conference Publications"
"Vehicle Retrieval Using Eigen Color and Multiple Instance Learning","S. Y. Chen; J. W. Hsieh; J. C. Wu; Y. S. Chen","Dept. of Electr. Eng., Yuan Ze Univ., Chungli, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","657","660","This paper presents a novel approach for retrieving images from databases using eigen color and the concept of multiple instance learning. Usually, vehicles have various colors and shapes under different viewpoints, weathers, and lighting conditions. All the variations will increase many difficulties and challenges in selecting a general feature to describe vehicles. Thus, traditional methods to retrieve vehicles require their orientations or colors being fixed. To tackle this problem, this paper proposes a novel vehicle retrieval system for effectively retrieving vehicles from databases no matter what orientations and colors they are. First of all, this paper proposes a novel color transform model, which is global and does not need to be re-estimated for any new vehicles or new images, to extract different regions of interest (or vehicle analogues) from databases. Then, to more accurately locate desired vehicle images, this paper uses the MIL (multiple-instance learning) method to learn specific visual properties of vehicles from query images. However, the MIL technique requires the positive training data being strongly positive and the negative ones being strongly negative. This requirement is too constrained in real cases and will lead to lots of false detection. This problem can be easily tackled if an eigen color transform is introduced. The extra consideration ""eigen color"" will add more capabilities to the MIL learner for capturing the embedded concept more accurately. Furthermore, during the learning process, since no time-consuming optimization process is involved, all the desired visual concept can be obtained immediately and adapted to different user's requests. Experimental results reveal the feasibility and high accuracy of the proposed approach in vehicle retrieval system.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.304","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337421","Eigen Color;Multiple Instance Learning;Vehicle Retrieval;vehicle detection","Color;Content based retrieval;Image databases;Image retrieval;Information retrieval;Multimedia databases;Spatial databases;Support vector machines;Vehicles;Visual databases","eigenvalues and eigenfunctions;image colour analysis;image retrieval;learning (artificial intelligence)","eigen color transform;multiple instance learning;vehicle retrieval system","","3","","14","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Retrieval System for Ballet Steps Using Three-dimensional Motion Data","T. Matsuoka; A. Soga; K. Fujita","Ryukoku Univ., Otsu, Japan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1144","1147","The purpose of this research is to develop a system for supporting dance. We have developed a database system for fundamental steps of classical ballet to manage and to utilize 3-dimensional motion data. First, we archived 543 fundamental steps obtained by motion capture systems, then constructed a 3-dimensional motion database for them. A user can search for a fundamental step and preview its motion by 3-dimensional CG. In order to retrieve motions, two approaches are applied; the first one is based on the classification of fundamental ballet motions, and the second one is based on the characteristics of 3-dimensional motion data, which are evaluated by calculating the sum of each position or rotation data along the axis. As a result of an evaluation, we confirmed that the approach using the characteristics of 3-dimensional data is valid for objective retrieval of motions.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337603","database;motion;retrieval","Character generation;Costs;Database systems;Information retrieval;Leg;Libraries;Multimedia databases;Multimedia systems;Signal processing;User interfaces","content-based retrieval;database management systems;image retrieval","ballet steps;content-based retrieval;database system;motion capture systems;motion objective retrieval;retrieval system;three-dimensional motion data","","1","","8","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Blind Clustering of Music Recordings Based on Audio Fingerprinting","W. H. Tsai; W. C. Hsieh","Dept. of Electron. Eng., Nat. Taipei Univ. of Technol., Taipei, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1086","1089","Although multiple music recordings may sound identical to a human listener, the underlying representations of sound may differ due to the variations in their audio encoding and/or transmission methods. In contrast to the existing audio-fingerprinting techniques, which establishes the fingerprint of each source music to identify unknown, ldquodistortedrdquo audio clips, this paper proposes an unsupervised clustering framework to identify unknown, ldquodistortedrdquo audio clips derived from the same source music. By grouping together audio data derived from the same music, the human effort required to label music data can be dramatically reduced. This work develops methods to measure the similarities between audio clips and use hierarchical agglomerative clustering to group together audio clips that are similar to one another. Also proposed is a method based on the Rand Index to determine the optimal number of clusters automatically in relation to the number of source music recordings.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337530","Rand index;audio fingerprinting;clustering","Acoustic signal processing;Acoustical engineering;Audio recording;Distortion measurement;Encoding;Fingerprint recognition;Humans;Libraries;Multiple signal classification;Music information retrieval","audio coding;music;pattern clustering","audio clips;audio encoding;audio transmission methods;audio-fingerprinting techniques;hierarchical agglomerative clustering;music recording blind clustering;source music recordings;unsupervised clustering framework","","1","","12","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"UPS: Unified Protocol Stack for wireless sensor networks","C. H. Feng; I. Demirkol; W. B. Heinzelman","Department of Electrical and Computer Engineering, University of Rochester, NY, USA","2009 6th Annual International Mobile and Ubiquitous Systems: Networking & Services, MobiQuitous","20091110","2009","","","1","2","In this paper, we propose a complete protocol stack framework called UPS (Unified Protocol Stack) as a solution for incorporating different protocols within WSNs through enabling the co-existence of multiple modules in same stack layer as well as providing unified access to cross-layer data.","","POD:978-963-9799-59-2","10.4108/ICST.MOBIQUITOUS2009.6991","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326369","","Access protocols;Information retrieval;Multicast protocols;Open systems;Packet switching;Telecommunication traffic;Traffic control;Uninterruptible power systems;Wireless application protocol;Wireless sensor networks","protocols;wireless sensor networks","UPS;unified protocol stack;wireless sensor network","","1","","2","","","13-16 July 2009","","IEEE","IEEE Conference Publications"
"Efficient Image Feature Combination with Hierarchical Scheme for Content-Based Image Management System","J. Jeong; H. Jeon; C. Hwang; B. Jeon","Sch. of Inf. & Commun. Eng., Sungkyunkwan Univ., Suwon, South Korea","2009 Third International Conference on Multimedia and Ubiquitous Engineering","20091110","2009","","","539","545","This paper proposes efficient image feature combinations based on local descriptor and hierarchical indexing scheme obtained by clustering with global descriptor for content-based image management system such as image identification and identical image grouping. As features for the image retrieval, we consider both global feature which has general information of overall image for fast image retrieval and local feature which is based on feature points and has high matching accuracy for fine matching of images. The developed local feature is invariant to image scale and rotation, addition of noise, and change in illumination, thus, it sufficiently performs reliable matching between different views of scene across affine transformation. The method works with global feature among image clusters of database in advance and do fine searching only among image data in the cluster with local feature. In order to decrease computation time, we apply conventional clustering methods to group images similar in their characteristics together so that search can be made in a hierarchical manner by fine matching within partial database of candidate images. It can overcome the drawback of exhaustive matching time between similar images by using only local descriptor.","","POD:978-0-7695-3658-3","10.1109/MUE.2009.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5318970","","Conference management;Content based retrieval;Content management;Engineering management;Feature extraction;Histograms;Image databases;Image retrieval;Information retrieval;Layout","affine transforms;content-based retrieval;database indexing;feature extraction;image matching;image retrieval;pattern clustering;visual databases","affine transformation;content-based image management system;global descriptor;global feature;hierarchical indexing scheme;identical image grouping;image feature combination;image identification;image matching;image retrieval;image rotation;image scale;local descriptor;local feature;pattern clustering","","1","","15","","","4-6 June 2009","","IEEE","IEEE Conference Publications"
"Collective Intelligence-Based Web Page Search: Combining Folksonomy and Link-Based Ranking Strategy","T. Zhang; B. Lee; S. Kang; H. Kim; J. Kim","Sch. of Comput. Sci., Univ. of Seoul, Seoul, South Korea","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","2","","166","171","With the exponentially growing amount of information available on the Internet, retrieving web pages of interest has become increasingly difficult. While several web page recommender systems have been developed, it is still difficult to search related information which reflects users' preference. In this paper, we propose a new type of web page search which is based on the collective intelligence. It combines folksonomy and link-based ranking evaluation scheme so as to accommodate users' preferences. We implemented the prototype system and demonstrate the feasibility of the proposed web page search scheme.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329125","Collective Intelligence;Folksonomy;Link-Based Web Search;Ranking Strategy","Computer science;Information retrieval;Information science;Information technology;Internet;Prototypes;Recommender systems;Statistics;Web pages;Web search","Internet;information filtering","Folksonomy;Internet;Web page recommender systems;Web page retrieval;collective intelligence;intelligence-based Web page search;link-based ranking strategy","","3","","15","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A GeoTagging Scheme Using Image Steganography and GPS Information Authentication","M. Y. Wu; C. C. Hsu; J. H. Lee","Dept. of Inf. Manage., Chang Jung Univ., Tainan, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1245","1248","Geotagging, in which digital photos are labelled with the location where they were taken, becomes more popular today. Users can browse the photos on digital map and make the Web photo sharing and management even more conveniently. However, lacking the function of authentication and the way to deal with the situation that information within the EXIF area being falsified, the content of the photo might be inconsistent to the location it has been displayed on map. In this paper, a framework using image steganography and GPS information authentication is proposed for the problem described. By means of embedding GPS information as well as the authentication information into the image, the consistency of photo content and location can be assured. Furthermore, this scheme can be applied to authenticate that a user has ever visited a certain place.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337451","GPS information;geotagging;image authentication;image steganograpy","Authentication;Cameras;Cellular phones;Data encapsulation;Discrete cosine transforms;Global Positioning System;Information management;Information retrieval;Steganography;Web services","Global Positioning System;Web services;digital photography;geographic information systems;image coding;message authentication;steganography","EXIF area;GPS information authentication;Web photo sharing;Web service;digital map;digital photo;exchangeable image file format;geotagging scheme;image steganography;location information","","1","","10","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"A New Feature Integration Approach and Its Application to 3D Model Retrieval","J. L. Shih; C. H. Lee; C. H. Chou; Y. C. Chang","Dept. of Comput. Sci. & Inf. Eng., Chung Hua Univ., Hsinchu, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1026","1029","In recent years, advanced techniques on digitization and visualization of 3D models have made 3D models as plentiful as images and video. The rapid generation of 3D models has made the development of efficient 3D model retrieval systems become urgently. In this paper, we will propose a feature integration approach in which a weighted distance method is developed to combine the distance evaluated by each individual one of the descriptors. The weight associated with each feature descriptor can be automatically determined according to the retrieval result using each individual feature descriptor. Experiments conducted on the Princeton Shape Benchmark (PSB) database have shown that the proposed feature integration approach provides a promising retrieval result.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337453","3D model retieval;feature integration","Content based retrieval;Frequency;Histograms;Information retrieval;Multimedia databases;Multimedia systems;Sampling methods;Shape;Subspace constraints;Visualization","data visualisation;solid modelling;video retrieval","3D model retrieval;data visualization;feature integration approach;princeton shape benchmark database;weighted distance method","","0","","15","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
