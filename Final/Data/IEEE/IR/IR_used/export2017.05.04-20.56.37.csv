"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5349070,5350040,5350202,5349409,5349874,5349526,5349906,5348465,5348518,5348434,5346030,5343973,5346682,5346105,5346032,5346135,5346493,5344513,5346694,5348468,5345936,5344024,5346610,5344369,5344041,5346121,5344579,5345483,5345653,5344407,5346321,5345394,5345537,5346038,5348519,5348410,5344154,5345904,5346527,5346783,5344033,5346236,5347780,5344079,5346507,5345637,5341513,5341521,5342921,5340946,5342132,5341756,5341676,5341910,5340949,5340927,5342131,5340931,5340914,5341051,5342826,5340929,5341673,5342009,5342007,5342997,5340335,5340275,5339948,5337432,5329078,5336041,5329120,5337606,5337401,5337111,5328931,5337190,5328545,5329146,5336040,5337038,5327810,5337566,5328928,5337277,5337350,5337096,5329386,5337079,5337523,5337480,5337204,5329113,5337231,5337327,5329118,5337305,5337374,5329378",2017/05/04 20:56:37
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Body Motion Analysis for Similarity Retrieval of Motion Data and Its Evaluation","W. Choi; T. Ono; K. Hachimura","Kinugasa Res. Organ., Ritsumeikan Univ., Kusatsu, Japan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1177","1180","With the spread of motion capture systems, body motion data has been obtained without effort and quantity of its data has been increasing. We need an efficient method for target motion retrieval. In this paper, we propose the method of analyzing motion data in advance, and express the construction of movement with indexed labels for reducing similar-motion retrieval. The posture of each frame is distinguished into the pattern of the indexed labels, and we therefore try to index each motion data. Firstly, we reduce the number of dimensions of motion data with PCA (Principal Components Analysis) and do clustering. Next, a trained dictionary is consisted of the indexed motion data. Finally, SVM (Support Vector Machine) distinguishes the test data by using the dictionary. In this research, we made the trained dictionary from the movement of radio gymnastics, and then carried out an evaluation of discrimination by using break dance movement as test data. As a result, we could use the motion data with indexes, and obtained a good retrieval result in this experiment.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337523","Machine Learning;Motion Data;Similarity Retrieval","Dictionaries;Gravity;Information retrieval;Legged locomotion;Motion analysis;Multimedia systems;Principal component analysis;Signal processing;Support vector machines;Testing","image motion analysis;image retrieval;principal component analysis;support vector machines","SVM;body motion analysis;break dance movement;motion capture systems;motion data indexing;motion data similarity retrieval;principal components analysis;radio gymnastics;support vector machine","","1","","6","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Unifying semantic and content-based approaches for retrieval of environmental sounds","G. Wichern; H. Thornburg; A. Spanias","Arts, Media and Engineering, Arizona State University, Tempe, 85281 USA","2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics","20091204","2009","","","13","16","Creating a database of user-contributed recordings allows sounds to be linked not only by the semantic tags and labels applied to them, but also to other sounds with similar acoustic characteristics. Of paramount importance in navigating these databases are the problems of retrieving similar sounds using text or sound-based queries, and automatically annotating unlabeled sounds. We propose an integrated system, which can be used for text-based retrieval of unlabeled audio, content-based query-by-example, and automatic annotation. To this end, we introduce an ontological framework where sounds are connected to each other based on a measure of perceptual similarity, while words and sounds are connected by optimizing link weights given user preference data. Results on a freely available database of environmental sounds contributed and labeled by non-expert users, demonstrate effective average precision scores for both the text-based retrieval and annotation tasks.","1931-1168;19311168","POD:978-1-4244-3678-1","10.1109/ASPAA.2009.5346493","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346493","Acoustic signal analysis;Clustering methods;Database query processing;Hidden Markov models","Acoustic applications;Audio databases;Conferences;Content based retrieval;Hidden Markov models;Information retrieval;Internet;Music information retrieval;Navigation;Ontologies","acoustic signal processing;audio databases;audio signal processing;content-based retrieval;hidden Markov models;ontologies (artificial intelligence);optimisation;query processing;text analysis","acoustic signal analysis;audio database creation;automatic annotation;content-based query-by-example;content-based retrieval;environmental sound-based query;hidden Markov model;integrated system;link weight optimization;ontological framework;perceptual similarity measure;text-based retrieval;unifying semantic tag approach;unlabeled audio;user preference data;user-contributed recording","","3","","16","","","18-21 Oct. 2009","","IEEE","IEEE Conference Publications"
"Research on the retrieval process of teaching video resources based on content","F. Haiguang; W. Zhenyu; L. Jing; J. Baocong","Department of Educational Technology, Capital Normal University, Beijing","2009 2nd IEEE International Conference on Broadband Network & Multimedia Technology","20091204","2009","","","472","476","The application of video resources has become extensive, and the demand to the video retrieval is growing intensely. How to access the video clips expected quickly and accurately from the massive video database has become the key issue in the development of the video information retrieval. The existing retrieval process based on keywords is no longer meeting the needs of users. Thus, video retrieval systems based on content have been proposed and become a hotspot of this field. This paper researches on teaching video retrieval process based on content, explores the search process and the key technologies for teaching video resources retrieval, which is applied in the ldquoCourse Review Platform on Basic Educationrdquo.","","POD:978-1-4244-4590-5","10.1109/ICBNMT.2009.5348518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5348518","matching algorithm;retrieval process;teaching video resource;video content retrieval","Authentication;Content based retrieval;Content management;Data mining;Education;Educational institutions;Educational technology;Feedback;Information retrieval;Spatial databases","content-based retrieval;teaching;video databases;video retrieval","content based retrieval;search process;video information retrieval;video resources","","1","","8","","","18-20 Oct. 2009","","IEEE","IEEE Conference Publications"
"Factored translation model in English-to-Thai translation","P. Porkaew; A. Takhom; T. Supnithi","Human Language Technology Laboratory, National Electronics and Computer Technology, Thailand Science Park, Klong Nueng, Klong Luang, Pathumthani, Thailand","2009 Eighth International Symposium on Natural Language Processing","20091201","2009","","","143","146","The objective of this paper is to find an appropriate combination of English factors to support English-to-Thai translation task. There are four English factors those are surface, lemma, part-of-speech (POS) and combinatory categorical grammar (CCG). Various combinations of those factors were trained to build the most efficient model for translation. We test the accuracy using the BLEU score. The result shows that the factored model which consists of lemma and CCG produce the highest accuracy at 24.21% (1.05% superior than baseline). In future work, we will extend this work to Thai-to-English translation.","","POD:978-1-4244-4138-9","10.1109/SNLP.2009.5340929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340929","","Bayesian methods;Humans;Information retrieval;Information technology;Internet;Natural language processing;Natural languages;Probability;Surface-mount technology;Testing","grammars;language translation;natural language processing","BLEU score;English factors;English-to-Thai translation task;Thai-to-English translation;combinatory categorical grammar;factored translation model;lemma;part-of-speech","","0","","15","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Novel Mutual Authentication Based on Data Embedding Technique","C. C. Lin; P. H. Chiang","Dept. of Comput. Sci. & Inf. Manage., Providence Univ., Taichung, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","274","277","This paper presents a novel approach for retrieving images from databases using eigen color and the concept of multiple instance learning. Usually, vehicles have various colors and shapes under different viewpoints, weathers, and lighting conditions. All the variations will increase many difficulties and challenges in selecting a general feature to describe vehicles. Thus, traditional methods to retrieve vehicles require their orientations or colors being fixed. To tackle this problem, this paper proposes a novel vehicle retrieval system for effectively retrieving vehicles from databases no matter what orientations and colors they are. First of all, this paper proposes a novel color transform model, which is global and does not need to be re-estimated for any new vehicles or new images, to extract different regions of interest (or vehicle analogues) from databases. Then, to more accurately locate desired vehicle images, this paper uses the MIL (multiple-instance learning) method to learn specific visual properties of vehicles from query images. However, the MIL technique requires the positive training data being strongly positive and the negative ones being strongly negative. This requirement is too constrained in real cases and will lead to lots of false detection. This problem can be easily tackled if an eigen color transform is introduced. The extra consideration ldquoeigen colorrdquo will add more capabilities to the MIL learner for capturing the embedded concept more accurately. Furthermore, during the learning process, since no time-consuming optimization process is involved, all the desired visual concept can be obtained immediately and adapted to different user's requests. Experimental results reveal the feasibility and high accuracy of the proposed approach in vehicle retrieval system.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.305","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337480","Data embedding;Mutual authentication;Phishing","Authentication;Data mining;Image databases;Image retrieval;Information retrieval;Shape;Spatial databases;Training data;Vehicles;Visual databases","image retrieval;message authentication","data embedding technique;image retrieval;multiple instance learning;multiple-instance learning;mutual authentication;vehicle retrieval system","","0","","4","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"NFC at the workplace — Simplify enterprise work flows with NFC","J. Miiller; V. Borovskiy; O. Panchenko; A. Bog; A. Zeier","Hasso Plattner Institute for IT Systems Engineering Prof.-Dr.-Helmert-Str. 2-3 14482 Potsdam, Germany","2009 16th International Conference on Industrial Engineering and Engineering Management","20091204","2009","","","1539","1542","In our contribution, we present the results of our research on the use of Near Field Communication (NFC) for user authentication and document control. To show our results, we present two different scenarios and a combination of them. In the first scenario, NFC tags are embedded in documents of an office environment. This includes customer invoices which are archived or kept in paper form as well as contracts with business partner which might change over time. Once certain paper document needs to be changed, it is moved close to the NFC reader, which will invoke a database lookup to get the digital version of the document. The second scenario is mainly intended for attorneys, tax consultants or, in general, for each situation that involves the need for a copy of (highly) classified documents. If somebody considers copying a classified document, he needs to have the proper access rights, which are stored in a database that can be referenced by the NFC tag. The third scenario involves both, authentication and digitization of documents. In order to copy a document, the proper access rights and the digital version of the document is stored in a protected, centralized data storage container.","","POD:978-1-4244-3671-2","10.1109/ICIEEM.2009.5344369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344369","Near-field Communication;Process Optimization;Secure Work Place","Authentication;Cryptography;Data engineering;Databases;Employment;Hardware;Information retrieval;Information security;Permission;Protection","document handling;mobile computing;mobile radio;security of data;workflow management software","data storage container;database lookup;document control;documents digitization;near field communication;user authentication","","0","","3","","","21-23 Oct. 2009","","IEEE","IEEE Conference Publications"
"A mobile spontaneous semantic P2P system","T. Schwotzer","University of Applied Sciences for Technology and Economics Berlin / Germany (HTW Berlin","2009 IEEE International Conference on Communications Technology and Applications","20091208","2009","","","977","981","The WWW is often used as synonym for the Internet. In the last 20 years the Web became the Internet application. And it evolves. There is the Web 2.0 mobile Web, semantic Web. Though, a noteworthy number of data are sent over short distances, the mobile Web is usually based on a public land mobile network. This is a tremendous was of resource and adds unnecessarily entities which can fail. Spontaneous networks are an alternative. This paper give a brief overview of the shark framework. It is a framework for building cross-platform semantic P2P systems in mobile spontaneous networks but also in the traditional fixed Internet.","","POD:978-1-4244-4816-6","10.1109/ICCOMTA.2009.5349070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349070","Android;J2ME;Objective-C;P2P;Semantic Web;Topic Maps;distributed mobile systems;spontaneous networks","Application software;HTML;ISO standards;Information retrieval;Internet;Local area networks;Mobile communication;Semantic Web;Social network services;World Wide Web","Internet;mobile computing;peer-to-peer computing;semantic Web","Internet;WWW;Web 2.0 mobile Web;World Wide Web;mobile spontaneous semantic P2P system;peer-to-peer computing;public land mobile network;semantic Web;shark framework","","1","1","9","","","16-18 Oct. 2009","","IEEE","IEEE Conference Publications"
"Web Video Data Clustering and Recognition Using Histograms of Phoneme Symbols","Y. Yaguchi; Y. Sakai; K. Yoshida; R. Oka","Univ. of Aizu, Aizu-Wakamatsu, Japan","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","2","","306","311","The clustering and recognition of Web video content play an important role in multimedia information retrieval. This paper proposes a method for both clustering and recognizing Web video content using a histogram of phoneme symbols (HoPS). HoPS contains information about speech and sound intervals. In this study, three experiments were conducted.The first experiment allocated HoPS feature of video intervals in a 3D space using PCA and quantification method IV (Q-IV). The second experiment applied the k-nearest neighbor (k-NN) method to analyze the difficulties in clustering. The third experiment recognized unknown video intervals by using the distance between HoPS of the query and a category average. The accuracy of the recognition results were 44.3% and 36.9% using the Mahalanobis distance and the correlation distance for the category average of training data, respectively.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329078","Multimedia data mining;Phoneme recognition;Video content clustering","Content based retrieval;Data mining;Histograms;Image processing;Information retrieval;Principal component analysis;Speech processing;Video sharing;Videoconference;YouTube","information retrieval;multimedia systems;pattern clustering;principal component analysis","Mahalanobis distance;PCA;Web video content clustering;Web video content recognition;Web video data clustering;Web video data recognition;k-nearest neighbor method;multimedia information retrieval;phoneme symbols histograms","","1","","22","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Method of Building Chinese Basic Semantic Lexicon Based on Word Similarity","Y. Zhu; Z. Wen; P. Wang; Z. Peng","Inst. of Comput. & Commun., Hunan Univ. of Technol., Zhuzhou, China","2009 Chinese Conference on Pattern Recognition","20091204","2009","","","1","4","Identification of sentiment orientation in Chinese words is essential for getting sentiment comprehension of Chinese text, and building a basic semantic lexicon with Chinese emotional words will provide a core subset for identifying emotional words in a special area. It can not only help to identify and enlarge semantic lexicon in corpus effectively but also improve classification efficiency. On the basis of the similarity of Chinese words, the paper has proposed a method of calculating sentiment weight of Chinese emotional words. In addition, a dictionary with basic Chinese emotional words has been constructed based on the HowNet semantic lexicon. By utilizing the dictionary together with TF-IDF, we have done experiments to identify sentiment orientation in Chinese text and have got satisfying classification result.","","POD:978-1-4244-4199-0","10.1109/CCPR.2009.5344041","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344041","","Dictionaries;Information filtering;Information filters;Information retrieval;Natural language processing;Recommender systems;Testing","natural language processing;text analysis","Chinese basic semantic lexicon;Chinese emotional words;Chinese text;Chinese words;HowNet semantic lexicon;dictionary;sentiment comprehension;sentiment orientation identification;word similarity","","0","","11","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
"Image Retrieval in Multimedia Databases: A Survey","Y. Alemu; J. b. Koh; M. Ikram; D. K. Kim","Dept. of Comput. Eng., Ajou Univ., Suwon, South Korea","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","681","689","In the past decades the advancement in the area of database management systems shifts towards multimedia. Multimedia information is very expressive, self explanatory, narrative, etc. Now a day the development of digital media, advanced network infrastructure and the easily available consumer electronics makes the multimedia revolution to run in an alarming rate. Inline with the advancement of database technology that incorporates multimedia data, an open question that always rose in the technology is how to retrieve/search images in the multimedia databases. There are a huge number of research works focusing on the searching mechanisms in image databases for efficient retrieval and tried to give supplementary suggestions on the overall systems. The growing of digital medias (digital camera, digital video, digital TV, e-book, cell phones, etc.) gave rise to the revolution of very large multimedia databases, in which the need of efficient storage, organization and retrieval of multimedia contents came into question. Among the multimedia data, this survey paper focuses on the different methods (approaches) and their evaluation techniques used by many of recent research works on image retrieval system. Many researchers develop and use lots of approaches towards image retrieval. This paper, in general, classified image retrieval into text based and content based, including the newly growing ontology based image retrieval system as one focus. We address, in this paper, the challenges, techniques and evaluation methods used in image retrieval systems through a detailed look of most recent works.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337432","database;image retrieval;multimedia","Consumer electronics;Content based retrieval;Database systems;Digital TV;Digital cameras;Image databases;Image retrieval;Information retrieval;Multimedia databases;Multimedia systems","content-based retrieval;image retrieval;multimedia databases;ontologies (artificial intelligence)","advanced network infrastructure;consumer electronics;content based image retrieval;database management systems;digital media;image databases;multimedia databases;ontology;searching mechanisms;text based image retrieval","","8","","29","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Name Disambiguation Using Semantic Association Clustering","H. Jin; L. Huang; P. Yuan","Services Comput. Technol. & Syst. Lab., Huazhong Univ. of Sci. & Technol., Wuhan, China","2009 IEEE International Conference on e-Business Engineering","20091201","2009","","","42","48","Due to homonyms, abbreviations, etc., name ambiguity is widely available in Web and e-document. For example, when integrating heterogeneous literature databases, because there are different name specifications, different authors may be thought of as the same author, and vice versa. Therefore, name ambiguity makes data robust even dirty and lowers the precision of information retrieval. In this paper, we present an approach, named as semantic association based name disambiguation method (SAND), to solve person name ambiguity. The basic idea of SAND is to explore the semantic association of name entities and cluster name entities according to their associations. Finally, the name entities in the same group are considered as the same entities. We test SAND using data from CitesSeer, DBLP and Libra. The test results show that SAND is an effective approach to solve the problem of name ambiguity.","","POD:978-0-7695-3842-6","10.1109/ICEBE.2009.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342132","clusting;name disambiguation;semantic association","Bibliographies;Clustering algorithms;Computer science;Couplings;Databases;Frequency;Grid computing;Information retrieval;Robustness;Testing","Web sites;document handling;information retrieval;pattern clustering","CitesSeer;DBLP;Libra;SAND;Website;e-document;heterogeneous literature database;information retrieval;name specification;semantic association clustering;semantic association-based name disambiguation method","","3","","19","","","21-23 Oct. 2009","","IEEE","IEEE Conference Publications"
"Hypotheses Generation Pertaining to Ayurveda Using Automated Vocabulary Generation and Transitive Text Mining","H. G. G. Vaka; S. Mukhopadhyay","Dept. of Comput. & Inf. Sci., Indiana Univ.-Purdue Univ. Indianapolis, Indianapolis, IN, USA","2009 International Conference on Network-Based Information Systems","20091208","2009","","","200","205","Automated extraction of knowledge from voluminous documents is a vast research area. Text mining is a promising approach for extracting knowledge from unstructured textual documents. The objective of this paper is to mine documents pertaining to Ayurveda, which are retrieved from PubMed into a databank, and find novel transitive associations among biological objects. This paper discusses the extraction of biological objects from the databank using an Automated Vocabulary Discovery (AVD) algorithm. A text-mining process is described for finding transitive (novel) associations among the extracted biological objects. The text mining algorithm, in addition to identifying novel associations (termed hypotheses), also assigns a numerical significance score to them. The expectation is that those with higher score have greater likelihood of being true than those with lower scores. Experimental results as well as their validation results are presented, demonstrating that the method has the potential to predict novel and interesting true associations.","2157-0418;21570418","POD:978-1-4244-4746-6","10.1109/NBiS.2009.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5350040","Ayurveda;automated vocabulary discovery;breadth first search;text mining;transitive closure","Abstracts;Computer networks;Data mining;Databases;Diseases;Information retrieval;Information science;Information systems;Text mining;Vocabulary","data mining;medical information systems;text analysis;vocabulary","Ayurveda;PubMed;automated knowledge extraction;automated vocabulary discovery algorithm;automated vocabulary generation;biological objects;databank;mine documents;novel associations;transitive associations;transitive text mining;unstructured textual documents;voluminous documents","","0","","14","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"Negative Database for Data Security","A. Patel; N. Sharma; M. Eirinaki","Comput. Eng. Dept., San Jose State Univ., San Jose, CA, USA","2009 International Conference on Computing, Engineering and Information","20091117","2009","","","67","70","Data security is a major issue in any Web-based application. There have been approaches to handle intruders in any system, however, these approaches are not fully trustable; evidently data is not totally protected. Real world databases have information that needs to be securely stored. The approach of generating negative database could help solve such problem. A negative database can be defined as a database that contains huge amount of data consisting of counterfeit data along with the real data. Intruders may be able to get access to such databases, but, as they try to extract information, they will retrieve data sets that would include both the actual and the negative data. In this paper we present our approach towards implementing the concept of negative database to help prevent data theft from malicious users and provide efficient data retrieval for all valid users.","","POD:978-0-7695-3538-8","10.1109/ICC.2009.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5328931","Database;Negative;Security","Application software;Counterfeiting;Cryptography;Data engineering;Data mining;Data security;Database systems;Information retrieval;Information security;Protection","database management systems;information retrieval;security of data","Web-based application;data retrieval;data security;information extraction;negative database","","2","","6","","","2-4 April 2009","","IEEE","IEEE Conference Publications"
"Content-Based Image Retrieval Using Gabor Filtering","T. Barbu","Inst. of Comput. Sci., Romanian Acad., Iasi, Romania","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","236","240","This paper provides a content-based digital image retrieval system. Our CBIR system uses the query by example technique and the relevance feedback. A Gabor filter based image feature extraction is proposed first. Thus, 3D image feature vectors using even-symmetric 2D Gabor filters are computed for the images of a large collection and for the input image. At each step an input image is selected, from the output set obtained in the previous step, and the most similar images from the collection are retrieved.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337204","Gabor filter;content-based image retrieval;feature extraction;image query;relevance feedback","Application software;Content based retrieval;Digital images;Feature extraction;Feedback;Gabor filters;Image databases;Image retrieval;Information retrieval;Shape","Gabor filters;content-based retrieval;feature extraction;image retrieval;relevance feedback","3D image feature vector;CBIR system;content-based digital image retrieval system;even-symmetric 2D Gabor filter;image feature extraction;query by example technique;relevance feedback","","7","","15","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"An Ontology-Driven Paradigm for Component Representation and Retrieval","Y. Peng; C. Peng; J. Huang; K. Huang","Sch. of Mechatron. Eng. & Autom., Nat. Univ. of Defense Technol., Changsha, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","2","","187","192","Component-based software reuse is an important research topic in software engineering and is the basis of software product line. Many methods for representation and retrieval of components have been proposed and most of them are faceted-based or specification-based. There is no a uniform formulism for component representation and retrieval. In order to solve this problem, an ontology-based representation model for component and the retrieval algorithm based on this model are proposed. The key factors of component reuse are discussed and it is pointed out that component reuse is the reuse of knowledge about component. Component ontology is employed to represent the knowledge about component. Domain-specific terms are used to represent component by importing domain ontology into component ontology. Component retrieving algorithm is implemented by ontology query and reasoning. The model is used in a large scale distributed simulation system and the fact revealed that component ontology is flexible enough for component reuse and efficiency of retrieving algorithm is gratifying.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329113","component reuse;componnet representation and retrieval;ontology;software engineering","Automation;Computer industry;Context;Information retrieval;Information technology;Large-scale systems;Mechatronics;Ontologies;Software engineering;Tides","ontologies (artificial intelligence);software reusability","component representation;component retrieval;component-based software reuse;knowledge reuse;large scale distributed simulation system;ontology query;ontology-based representation model;ontology-driven paradigm;software engineering;software product line","","3","","14","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Improving research paper searching with social tagging — A preliminary investigation","P. Jomsri; S. Sanguansintukul; W. Choochaiwattana","Department of Mathematics, Faculty of Science, Chulalongkorn University, Bangkok, Thailand","2009 Eighth International Symposium on Natural Language Processing","20091201","2009","","","152","156","The WWW provides an efficient way to store and share information. Search engines and social bookmarking systems are important tools for Web resource discovery. This study investigated three different indexing approaches applied to CiteULike - a social bookmarking system for tagging academic research papers. The indexing approaches here are known as: Tag only; Title with Abstract; and Tag, Title with Abstract. These three indexing approaches were evaluated using mean values of normalized discount cumulative gain (NDCG). The preliminary results illustrated that indexing using ""Tag, Title, with Abstract"" performed the best. The initial evaluation on our implementation implied that these designs might improve the accuracy and efficiency of Web resource searching on social bookmarking system, not only in academics but also in other domains.","","POD:978-1-4244-4138-9","10.1109/SNLP.2009.5340927","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340927","","Data mining;Filtering algorithms;Indexing;Information retrieval;Internet;Libraries;Natural language processing;Navigation;Search engines;Tagging","Internet;indexing;information retrieval;search engines;social networking (online)","CiteULike;Web resource discovery;Web resource searching;World Wide Web;normalized discount cumulative gain;research paper searching;search engines;social bookmarking systems;social tagging","","1","1","16","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"Modeling Trajectories: A Spatio-Temporal Data Type Approach","A. Frihida; D. Zheni; H. B. Ghezala; C. Claramunt","Ecole Nat. d'Ing. de Tunis, Univ. Tunis El Manar, Tunis, Tunisia","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","447","451","Retrieving and analyzing trajectories favor the study of human behaviors in space and time. Although time geography has long proposed a conceptual framework for the interpretation of trajectory data, there is still a need for database and semantic models that support representation and manipulation. In fact, the concept of trajectory is rarely addressed as a sui generis data type that can be embedded in a database structure. This paper introduces an algebraic spatio-temporal trajectory data type (STT) for the representation of object trajectory. The STT is an abstract data type endowed with a set of operations designed as a way to cover the syntax and semantics of a given trajectory. It is considered as a data structure that can be used for the design and implementation of spatio-temporal databases.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337231","Time Geography;abstract data type modeling;moving objects databases;spatio-temporal databases;spatio-temporal trajectory modeling;temporal GIS","Data structures;Database systems;Expert systems;Geographic Information Systems;Geography;History;Humans;Information retrieval;Spatial databases;Spatiotemporal phenomena","abstract data types;temporal databases;visual databases","abstract data type;algebraic spatio-temporal trajectory data type approach;conceptual framework;data structure;human behavior;object trajectory representation;semantic model;spatio-temporal database;sui generis data type;time geography;trajectory analysis;trajectory data interpretation;trajectory modeling;trajectory retrieval","","1","","18","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Region-Based Segmentation versus Edge Detection","H. G. Kaganami; Z. Beiji","Sch. of Inf. Sci. & Eng., Central South Univ., Changsha, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1217","1221","This paper, we will review the main approaches of partitioning an image into regions by using gray values in order to reach a correct interpretation of the image. We mainly compare the region-based segmentation with the boundary estimation using edge detection. Image segmentation is an important step for many image processing and computer vision algorithms while an edge can be described informally as the boundary between adjacent parts of an image. A formal definition is elusive, but edge detection is nonetheless a useful and ubiquitous image processing task. After comparing we have come to a conclusion that the edge detection has advantage of not necessarily needing closed boundaries and also its computation is based on difference. The region-segmentation in spite of improving multi-spectral images has the drawback of being applied only on closed boundaries. To reach the result of edge detection we have used the technique of performance metrics and Canny edge detection. We have applied Canny ground truth to acquire more features via displaying more details.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337327","edge detection;gray values;region-based segmentation","Cells (biology);Computer vision;Image edge detection;Image processing;Image retrieval;Image segmentation;Information retrieval;Layout;Measurement;Signal processing algorithms","computer vision;edge detection;image representation;image segmentation","Canny edge detection;Canny ground truth;boundary estimation;computer vision algorithms;edge detection;gray values;image processing;image segmentation;multi-spectral images;performance metrics;region-based segmentation;ubiquitous image processing","","7","","12","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"A study of online transaction platform based on interactive search engine","Q. Li; T. Yang","Department of Technical Economy and Management, China Three Gorges University, Yichang, China","2009 16th International Conference on Industrial Engineering and Engineering Management","20091204","2009","","","627","632","Online transaction becomes a main way of e-commerce at present. Information discovery and price discovery in e-commerce are realized in the platform mainly. This thesis presents an online transaction platform of interactive search after analyzing the research status of interactive search engine to solve the problem that buyers are hard to search seller information in this platform, bring the initiative of the sellers in principal part of trade into full play about using transaction platform, improving search efficiency and enhance VAS ability in transaction platform. The system has been implemented with .net technology and runs in campus network. Interactive search can be fulfilled using embedded search engine rather than using SQL trigger mechanism to raise search efficiency.","","POD:978-1-4244-3671-2","10.1109/ICIEEM.2009.5344513","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344513","Interactive;online transaction;search engine;transaction platform","Costs;Data mining;Electronic mail;Engineering management;Forward contracts;Information retrieval;Internet;Search engines;Telephony;Web pages","Internet;electronic commerce;embedded systems;information retrieval;interactive systems;pricing;search engines;transaction processing","Internet;SQL trigger mechanism;VAS;e-commerce;embedded search engine;information discovery;interactive search engine;online transaction platform;price discovery;seller information","","0","","10","","","21-23 Oct. 2009","","IEEE","IEEE Conference Publications"
"Web Forum Sentiment Analysis Based on Topics","L. Shi; B. Sun; L. Kong; Y. Zhang","Dept. of Machine Intell., Peking Univ., Beijing, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","2","","148","153","As Web forum has become an enormous collection of highly valuable opinions and commentaries, more and more researchers express strong interests on it. However, most of them pay attention to the forum reviews rather than the posts themselves. In this paper we focus on recognizing the diversified opinions of different threads on the same topic from Chinese Web forums. First, we congregate the Web forum threads on the same topic into a cluster. In order to further distinguish different opinions for a topic, we propose a sentiment classification algorithm based on a probability word-list, which is constructed by us using a propagation method on the word graph with a seed set. Experimental results on a real data set show that our algorithm performs well with both high precision and efficiency, much better than traditional methods such as SVM and naive Bayes.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329118","Chinese web forum;sentiment analysis;topic detection","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Entropy;Information analysis;Information retrieval;Information technology;Machine intelligence;Sun;Yarn","Web sites;classification;probability","Web forum;forum review;probability word-list;propagation method;sentiment analysis;sentiment classification;threads;word graph","","4","1","24","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Research on Knowledge Extraction and Visualization in Knowledge Retrieve","C. YongYue; X. HuoSong","Dept. of Inf. Manage. & Inf. Syst., Wuhan Univ. of Sci. & Eng., Wuhan, China","2009 International Conference on Intelligent Human-Machine Systems and Cybernetics","20091117","2009","2","","66","69","In order to adapt to the development tendency of knowledge organization and resolve the problem about the low efficiency of information retrieve, knowledge retrieve as a new retrieval theory is proposed. Based on the knowledge organization, it realizes the intelligent retrieve of knowledge correlation and concept semantic retrieve. It synthetically applies many new theories and technologies, such as the information science, artificial intelligence, cognitive science and linguistics. This paper mainly discusses the realizing mechanism of knowledge retrieve based on knowledge extraction and visualization technology.","","POD:978-0-7695-3752-8","10.1109/IHMSC.2009.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336041","knowledge extraction;knowledge retrieve;visualization","Artificial intelligence;Data mining;Information analysis;Information management;Information retrieval;Man machine systems;Management information systems;Natural language processing;Natural languages;Visualization","data visualisation;information retrieval;knowledge acquisition","artificial intelligence;cognitive science;concept semantic retrieval;information retrieval;information science;knowledge correlation;knowledge extraction;knowledge organization;knowledge retrieval;knowledge visualization;linguistics","","1","","9","","","26-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"Fast palmprint retrieval using principal lines","W. Jia; Y. H. Zhu; L. F. Liu; D. S. Huang","Hefei Institute of Intelligent Machines, CAS, Hefei, China","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","4118","4123","In this paper, we propose a novel palmprint retrieval scheme based on principal lines. In the proposed scheme, the principal lines are firstly extracted by the modified finite radon transform. And then, a lot of key points located in three principal lines i.e. heart line, life line and head line are detected. Finally, the palmprints are retrieved by several key points' position and direction. The results of experiments conducted on PolyU palmprint database show that the proposed scheme is feasible and has high accurate retrieval rate with fast speed.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346694","biometric;palmprint;principal lines;retrieval","Biometrics;Cybernetics;Data mining;Discrete wavelet transforms;Error analysis;Feature extraction;Geometry;Information retrieval;Spatial databases;USA Councils","Radon transforms;biometrics (access control);feature extraction;information retrieval;security of data","PolyU palmprint database;fast palmprint retrieval;head line detection;heart line detection;life line detection;modified finite radon transform;principal line extraction","","0","","15","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Preventing False Positives in Content-Based Phishing Detection","S. Nakayama; I. Echizen; H. Yoshiura","Grad. Sch. of Human Commun., Univ. of Electro-Commun., Chofu, Japan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","48","51","Content-based phishing detection extracts keywords from a target Web page, uses these keywords to retrieve the corresponding legitimate site, and detects phishing when the domain of the target page does not match that of the retrieved site. It often misidentifies a legitimate target site as a phishing site, however, because the extracted keywords do not charecterize the legitimate site with sufficient accuracy. Two methods are described for extracting keywords: domain keyword extraction, which extracts keywords from not only the page on the browser but also from pages linked from this page, and time-invariant keyword extraction, which extracts keywords from the page and previous versions of the page. Experiments using 172 legitimate sites demonstrated a reduction in the false detection rate from 14.0% to 7.6%, while experiments using 172 phishing sites demonstrated no change in the rate of overlooking phishing pages.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337305","Internet;network;phishing;security","Content based retrieval;Data mining;HTML;Humans;IP networks;Informatics;Information retrieval;National security;Signal processing;Web pages","Web sites;computer crime;content-based retrieval;unsolicited e-mail","Web page;content-based phishing detection;domain keyword extraction;false positives prevention;legitimate site;phishing sites;time-invariant keyword extraction","","4","","6","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Efficient Web Page Main Text Extraction towards Online News Analysis","B. Zhou; Y. Xiong; W. Liu","Hewlett-Packard Labs. China, Beijing, China","2009 IEEE International Conference on e-Business Engineering","20091201","2009","","","37","41","We propose a simple approach to fast extract the main text content from Web pages, especially online news pages. Most existing approaches need to construct the DOM tree structure from the HTML source of the Web page first, and then, extract the important content by pruning/merge the DOM branches/sub-trees. Such DOM tree processing tasks are very time-consuming. Our solution processes the HTML source as a paragraphed text string directly and extracts the main text content by only analyzing the word count of text paragraphs. Compared with the existing DOM based approaches, the proposed approach is simple and fast, but not loses the accuracy. The proposed solution can be applied into practical applications with critical requirement on the efficiency, such as online news analysis. The experimental results show that our solution can efficiently and effectively extract the news content from online news pages for further analysis.","","POD:978-0-7695-3842-6","10.1109/ICEBE.2009.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342131","Web content analysis;Web information extraction","Content based retrieval;Data mining;HTML;Image segmentation;Information analysis;Information retrieval;Navigation;Tree data structures;Web pages;Web sites","Web sites;hypermedia markup languages;information retrieval;text analysis;tree data structures","DOM tree structure;HTML source;Web page;main text content extraction;online news analysis;paragraphed text string;pruning","","5","","12","","","21-23 Oct. 2009","","IEEE","IEEE Conference Publications"
"DSNotify - Detecting and Fixing Broken Links in Linked Data Sets","B. Haslhofer; N. Popitsch","Dept. of Distrib. & Multimedia Syst., Univ. of Vienna, Vienna, Austria","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","89","93","The Linking Open Data (LOD) initiative has motivated numerous institutions to publish their data on the Web and to interlink them with those of other data sources. But since LOD sources are subject to change, links between resources can break and lead to processing errors in applications that consume linked data. The current practice is to ignore this problem and leave it to the applications what to do when broken links are detected. We believe, however, that LOD data sources should provide the highest possible degree of link integrity in order to relieve applications from this issue, similar to databases that provide mechanisms to preserve referential integrity in their data. As a possible solution, we propose DSNotify, an add-on for LOD sources that detects broken links and assists the data source in fixing them, e.g., when resources were moved to other Web locations.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337374","data quality;semantic web;web of data","Clouds;Distributed databases;Expert systems;Humans;Joining processes;Libraries;Multimedia databases;Multimedia systems;Music information retrieval;Wikipedia","data integrity;database management systems;semantic Web","DSNotify;broken links;data integrity;data source;linked data sets;linking open data initiative","","3","","13","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Combining weights into scores: A linear transform approach","S. Y. Sung; T. Hu","Department of Computer Science, South Texas College, McAllen, USA","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","2636","2641","Ranking has been widely used in many applications. A ranking scheme usually employs a scoring rule that assigns a final numerical value to every object to be ranked. A scoring rule normally involves the use of one to many scores, and it gives more weight to the scores that are more important. In this paper, we give a scheme that can combine weights into scores in a natural way and compare our scheme to the formula given by Fagin. Also given are some additional properties that are desirable for weighted scoring rules. Finally, we discuss other interesting issues on weighted scoring rules.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346121","linear transform;ranking;scoring rule;weighted method","Application software;Computer science;Cybernetics;Educational institutions;Image databases;Image retrieval;Information retrieval;Multimedia databases;Sorting;USA Councils","query processing;transforms","Fagin formula;k-nearest neighbour query;linear transform approach;ranking scheme;weighted scoring rule","","0","","20","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Using semantic annotation for ontology based decision support in product family design","S. Chong; J. Lim; Y. Liu; W. B. Lee","Department of Industrial and Systems Engineering The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong SAR, China","2009 16th International Conference on Industrial Engineering and Engineering Management","20091204","2009","","","321","325","Developing product family is one of the most promising approaches in the mass customization paradigm. In the product family perspective, the understanding of product family metrics and modeling is crucial for decision support and analysis. Most of the current product family modeling representation is meant solely for physical product configuration. Therefore, the current product family modeling approaches is not adequate to support various decision making at different product family design issues. An integrated knowledge framework that is able to support decision making in all aspects of interest would be highly desirable. This paper presents a conceptual framework of using semantic annotation for ontology based decision support in product family design. Together with a new commonality analysis based on a semantically annotated product family ontology, the framework illustrates the merits of using semantic annotation in assisting ontology based analysis and decision making in product family design. A case study involving a product family of digital camera is also presented to demonstrate our concepts and approach.","","POD:978-1-4244-3671-2","10.1109/ICIEEM.2009.5344579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344579","Conformance Cost;Internal And External Failure Cost;Non Conformance Cost;Total Quality Cost","Bills of materials;Costs;Data mining;Decision making;Design engineering;Information retrieval;Mass customization;Object oriented modeling;Ontologies;Product design","decision making;mass production;ontologies (artificial intelligence);product customisation;product design","commonality analysis;decision analysis;decision making;family ontology;integrated knowledge framework;mass customization paradigm;ontology based analysis;ontology based decision support;physical product configuration;product family design;product family metrics;product family modeling representation;product family perspective;semantic annotation","","1","","20","","","21-23 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Multilingual Patent Text-Mining Approach for Computing Relatedness Evaluation of Patent Documents","C. H. Lee; H. C. Yang; C. H. Wu; Y. J. Li","Dept. of Electr. Eng., Nat. Kaohsiung Univ. of Appl. Sci., Kaohsiung, Taiwan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","612","615","This paper describes our work on developing a language-independent technique for discovery of implicit knowledge about patents from multilingual patent information sources. Traditional techniques of multi- and cross-language patent retrieval are mostly based on the process of translation. One major problem of those is that it is difficult to find related patents produced from other countries in a stand-alone patent information system. In this paper, we present a novel system platform to support locating similar and relevant multilingual patent documents. The platform is developed using a multilingual vector space based on the latent semantic indexing (LSI) model, and utilizing collected professional Chinese-English parallel corpora for training the system model. These multilingual patent documents can then be mapped into the semantic vector space for evaluating their similarity by means of text clustering techniques. The preliminary results show that our platform framework has potential for retrieval and relatedness evaluation of multilingual patent documents.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337401","Latent semantic indexing;Multilingual patent retrieval;Neural networks;Text clustering;Text mining","Dictionaries;Indexing;Information management;Information processing;Information retrieval;Information systems;Large scale integration;Multimedia computing;Signal processing;Text mining","data mining;indexing;information retrieval;patents;pattern clustering;text analysis","language-independent technique;latent semantic indexing model;multilingual patent documents;multilingual patent information sources;multilingual patent text-mining approach;multilingual vector space;text clustering techniques","","0","","19","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Kernel Based Spatiogram Tracking Using Improved Similarity Measure","N. He; J. Cao; L. Song","Comput. Sch., Wuhan Univ., Wuhan, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","1","","124","127","Spatiogram were generalization of histograms, which can harvest spatial information of images. In this paper, we address the object tracking problem using spatiogram as feature descriptor. We use an improved spatiogram similarity measure which is recently proposed. Based on the measure, we derive a kernel tracking algorithm utilizing mean shift procedure. We test our tracking algorithm on several datasets. Experiment show better tracking result compared with the previously proposed kernel based spatiogram tracking algorithm.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329378","computer vision;mean shift;spatiogram;tracking","Computer vision;Distance measurement;Histograms;Image retrieval;Information retrieval;Information technology;Kernel;Target tracking;Taylor series;Testing","computer vision;image processing;object detection","feature descriptor;improved similarity measure;kernel based spatiogram tracking algorithm;kernel tracking algorithm;mean shift procedure;object tracking problem","","1","","11","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Architecture for context-aware multiparty delivery in mobile heterogeneous networks","J. Antoniou; C. Christophorou; C. Janneteau; M. Kellil; S. Sargento; A. Neto; F. C. Pinto; N. F. Carapeto; J. Simoes","University of Cyprus, P.O. Box 20537, 75 Kallipoleos Str., 1678 Nicosia CYPRUS","2009 International Conference on Ultra Modern Telecommunications & Workshops","20091204","2009","","","1","6","Future networks are envisioned to satisfy the user needs and improve their quality of experience. This requires the networks to support context-aware information, where context of the user, session, network and environment will greatly influence the way the session is delivered: new approaches are required to deal with the overall context information and network reaction to constantly context changes. This paper presents a context-aware architecture that provides delivery of multiparty services in heterogeneous and mobile environments. The architecture, its elements and functionalities are described through a specific application to a context-driven use case scenario. We show that this architecture is able to provide personalized and multiparty services to the users, addressing their characteristics and preferences, and optimizing network support while mobility and heterogeneous environments are in place.","2157-0221;21570221","POD:978-1-4244-3942-3","10.1109/ICUMT.2009.5345483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345483","architecture;context-aware;heterogeneous;heterogeneous networks;multicast","Cities and towns;Computer aided software engineering;Context awareness;Context-aware services;Fans;Informatics;Information retrieval;Laboratories;Legged locomotion;Watches","multicast communication;optimisation;ubiquitous computing","context aware information;context driven use case scenario;mobile heterogeneous networks;multiparty delivery;multiparty services;optimizing network","","5","","8","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Describing Web Topics Meticulously through Word Graph Analysis","B. Sun; L. Shi; L. Kong; Y. Zhang","Dept. of Machine Intell., Peking Univ., Beijing, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","2","","142","147","Topic description is as important as topic detection. In this paper, we propose a novel method to describe Web topics with topic words. Under the assumption that representative words exist in important sentences and have high probability of occurrence with other representative words, two graphs are built, one of which represents the relationship for sentences, the other for words. Considering a topic cluster contains a set of different Web pages, sentence clusters are also introduced. Experimental results on a real data set show that our method achieves excellent performance in both high precision and efficiency, especially when real Web data contain mass of noises.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329146","","Broadcasting;Data mining;Frequency;Information analysis;Information retrieval;Information technology;Machine intelligence;Noise reduction;Sun;Web pages","Internet;content management;data mining;graph theory;information retrieval","Web pages;Web topics;noise;sentence clusters;topic cluster;topic description;topic detection;topic words;word graph analysis","","1","","22","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Multilevel logic transmission using disparate intensity levels of white light and programmable controllers","R. Sharma; A. Chahar; N. Paliwal; A. Narula; V. Jindal","Jaypee University of Information Technology, Waknaghat, Solan, 173215, HP, INDIA","2009 International Conference on Ultra Modern Telecommunications & Workshops","20091204","2009","","","1","5","This paper analyzes the transmission of a multilevel logic information by assigning a distinct level of Intensity of white light to a specific Byte. The criterion for allocation of Intensities is fed into the programmable transmitter controller. The receiver employs a Photocell to detect the transmitted intensity of white light emitted by an LED. The information at the receiving end is retrieved and processed by the programmable receiver controller. The technique discussed takes into consideration the channel's behavior and the involvement of noise excursions, thus settling for a unique Look up Table at the receiving end. The programmability of the transmitter and receiver controllers allows adjustment according to the variation in channel's behavior. The paper uses a normal dust free channel opaque in nature, thus providing a cost effective alternative to Optical Fibers and a loss effective alternative to Copper Wires for short length communication systems.","2157-0221;21570221","POD:978-1-4244-3942-3","10.1109/ICUMT.2009.5345653","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345653","","Communication system control;Costs;Information analysis;Information retrieval;Light emitting diodes;Logic;Optical noise;Optical receivers;Optical transmitters;Programmable control","data communication;light emitting diodes;light transmission;multivalued logic;optical fibres;photoelectric devices;programmable controllers","LED;copper wires;look up table;multilevel logic transmission;optical fibers;photocell;programmable receiver controller;programmable transmitter controller;short length communication systems;white light","","0","","10","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Development of surgical operation data interchange model using XML and relational database","W. Paoin; P. Boonchai-Apisit","Department of Computer and Communication Technology, Dhurakij Pundit University, Laksi, Bangkok 10210, Thailand","2009 Eighth International Symposium on Natural Language Processing","20091201","2009","","","132","136","This research was focused on development of a surgical operation data interchange model using XML and relational database and development of a Web application to store, retrieve and transfer operative note data between database and XML file. In system analysis phase, surgeon requirement were collected using Delphi method, 27 expert surgeons for 9 specialty groups were selected. Three rounds of questionnaire were sent to experts asking for opinion on important of operative note data elements and suggestion to add new data elements. In system design phase, database design was done using entity-relationship (ER diagram) and normalization. XML format for operative data was designed using document type declaration - DTD and XML schema. Interchange model was designed using context diagram, dataflow diagram, system flowchart and process specification. A Web application was developed using PHP, database created in MySQL, files transfer in XML, PDF and HTML format. Majority of 27 expert surgeons agreed that all items in original operative note and additional items suggested to be included during this research are important. Inter-quartile range between expert opinion varied from 0 to 2. Most of them agreed that detail of procedures and difficulty found during operation are 2 items that should be defined specific fields in database table. All testing for process of storing operative note data into relational database, creation of operative note in XML format file from Web application, conversion of operative note content between XML format file VS relational database and transformation of operative note XML format file into portable document format - PDF and hypertext markup language format - HTML format revealed no difficulty nor major error. This suggest that development products comprised of XML schema, database model, an interchange model and a web application developed in this research can be used as a prototype of model and program to store, retrieve and transfer operat- ive note data between hospitals in Thailand. Data interchange could be in offline mode using diskette, CD-ROM or USB drive or online mode using internet or intranet network.","","POD:978-1-4244-4138-9","10.1109/SNLP.2009.5340931","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340931","","Context modeling;Erbium;Flowcharts;HTML;Information retrieval;Relational databases;Surgery;Surges;System analysis and design;XML","XML;electronic data interchange;information retrieval;medical information systems;relational databases","Delphi method;HTML format;MySQL;PDF format;PHP;Web application;XML file;context diagram;dataflow diagram;document type declaration;entity-relationship;hypertext markup language format;process specification;relational database;surgical operation data interchange model;system flowchart","","0","","16","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"Scheduling and manpower allocation for hotel banquet functions","L. S. Soh","School of Engineering, Republic Polytechnic, Singapore","2009 16th International Conference on Industrial Engineering and Engineering Management","20091204","2009","","","1398","1402","Hotel banquet functions usually employ part-time workers as waiters and waitresses. These functions often end beyond the scheduled duration. In addition, there is also either a shortage or excess of workers for majority of the banquet functions, resulting in significant losses to the hotel not only in monetary terms, but also to the reputation of the hotel. In this paper, the Six Sigma methodology was employed to help a hotel understand their current situation and come out with solutions to address these problems. The systematic approach allowed all their banquet functions to end within a stipulated duration and controlled the labor cost with no out-of-control situations. The process capability was also vastly improved as a result. All the recommendations were summarized into a Visual Basic .Net program for easy use by the banquet supervisor, allowing him to retrieve the required information and perform scheduling and manpower allocation automatically.","","POD:978-1-4244-3671-2","10.1109/ICIEEM.2009.5344407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344407","DMAIC;Six Sigma;Six Sigma for service","Automatic control;Collaborative work;Control charts;Control systems;Cost function;Information retrieval;Job shop scheduling;Manufacturing;Six sigma;Visual BASIC","","","","0","","9","","","21-23 Oct. 2009","","IEEE","IEEE Conference Publications"
"Research on Knowledge Acquisition in the Intelligent Retrieve","C. YongYue; X. HuoSong","Dept. of Inf. Manage. & Inf. Syst., Wuhan Univ. of Sci. & Eng., Wuhan, China","2009 International Conference on Intelligent Human-Machine Systems and Cybernetics","20091117","2009","2","","78","81","Knowledge Acquisition is the research hotspot in Knowledge Engineering. Its application is very wide in the intelligent system. It can be realized through the manual, semi-automatic and automatic patterns. This paper mainly discusses the realization principles of Knowledge Acquisition and its application in Intelligent Retrieve.","","POD:978-0-7695-3752-8","10.1109/IHMSC.2009.145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5336040","Information Extraction;Intelligent Retrieve;Knowledge Acquisition","Artificial intelligence;Data mining;Dictionaries;Expert systems;Indexing;Information retrieval;Knowledge acquisition;Knowledge engineering;Natural language processing;Natural languages","information retrieval;knowledge acquisition","automatic patterns;intelligent retrieve;intelligent system;knowledge acquisition;knowledge engineering;manual patterns;semi-automatic patterns","","0","","9","","","26-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"STRank: A SiteRank algorithm using semantic relevance and time frequency","H. Guo; Q. Chen; X. Wang; Z. Wang; Y. Wu","Dept. of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, P.R. China","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","4876","4881","Most of the researches on Web information processing are concentrated on the Web pages and the hyperlinks among them. One of the important facts that a Web page is just one building block of the whole Website had been ignored. But the situation is gradually changed in recent years for the needs of Website reputation calculation, the high level Website structure mining etc. It causes the Website ranking become one of the hot research topics and various site ranking algorithms, such as SiteRank, AggregateRank etc., had been proposed. But most of existing Website ranking algorithm just take use of Website link graphs and the content of Websites are usually not put into consideration. It is obviously not enough for a reliable ranking of Websites. To address this issue, this paper introduces two content based features, i.e., semantic relevance and time frequency and proposes a new STRank algorithm based on these two features. We firstly conduct a series of experiments to verify the feasibility of these two factors in site ranking task. Then the semantic relevance is applied in the calculation of transition probability, and the updating frequency of sites is combined into the ranking task. Since traditional Kendall's Â¿ distance and Spearman's footrule distance is not appropriate for the evaluation of site ranking, we make some modifications accordingly to evaluate Website ranking algorithms. Finally, our experiments show that the STRank algorithm outperforms existing approaches on both effectiveness and efficiency.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346321","STRank;semantic relevance;site ranking;time frequency;updating frequency","Algorithm design and analysis;Computer science;Cybernetics;Information processing;Information retrieval;Search engines;Space technology;Time frequency analysis;USA Councils;Web pages","Web sites;data mining;graph theory;probability;search engines","Kendall's Â¿ distance;STRank;SiteRank algorithm;Spearman's footrule distance;Web information processing;Web pages;Web site link graphs;Web site ranking;Web site reputation calculation;Web site structure mining;content based features;hyperlinks;semantic relevance;time frequency;transition probability","","3","","17","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Thai personal named entity extraction without using word segmentation or POS tagging","P. Sutheebanjard; W. Premchaiswadi","Graduate School of Information Technology, Siam University 235 Petchkasem Road, Phasi-charoen, Bangkok 10163, Thailand","2009 Eighth International Symposium on Natural Language Processing","20091201","2009","","","221","226","Named entity (NE) extraction for Thai language is a difficult and time consuming task because sentences in Thai language are composed of a series of words formed by a stream of characters. Moreover, there are no delimiters (blank space) to show word boundaries. Currently, most named entity extraction methods for Thai language are associated with word segmentation and part of speech (POS) tagging processes. The accuracy of named entity extraction is mostly affected the efficiency of those processes. At present, it is still lack of suitable methods for identifying the boundary of word for Thai sentence. Therefore this paper proposes the method to extract Thai personal named entity without using word segmentation or POS tagging. The proposed method is composed of 3 steps. Firstly, pre-processing, this process is used to remove non alphabet such as parenthesizes and numerical. Then, personal named entity is extracted by using contextual environment, front and rear, of personal name. Finally, post-processing, a simple rule base is employed to identify personal names. The training corpus of 900 political news articles and the test corpus of 100 political news, 100 financial news and 100 sport news articles were used in the experiments. The results showed that the F-measures in political and financial domain are 91.442% and 91.720% respectively which are nearly the same. However, the proposed scheme used neither word segmentation nor POS tagging process that can significantly reduce the effort and speed up the process in building the training corpus.","","POD:978-1-4244-4138-9","10.1109/SNLP.2009.5340914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340914","","Data mining;Entropy;Feature extraction;Guidelines;Information retrieval;Natural language processing;Natural languages;Tagging;Testing;Text recognition","information retrieval;learning (artificial intelligence);natural language processing;text analysis","POS tagging;Thai personal named entity extraction;blank space;contextual environment;financial news article;machine learning;part of speech;political news article;rule base;sport news article;text analysis;word boundary identification;word segmentation","","4","","9","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Selective Update Propagation Based on Degree of Data Update in Peer-to-Peer Networks","T. Watanabe; A. Kanzaki; T. Hara; S. Nishio","Dept. of Multimedia Eng., Osaka Univ., Osaka, Japan","2009 International Conference on Network-Based Information Systems","20091208","2009","","","52","59","In a P2P network, it is common that data items are replicated on multiple peers for improving data availability. In such an environment, when a data item is updated on a particular peer, the update should be immediately propagated to other peers holding its replicas. However, in some applications, some replica holders do not need the update when the degree of change in the update is small. In this paper, we propose two update propagation strategies considering the degree of change in data update in P2P networks. Our proposed strategies reduce the load for propagating data update by suppressing the update propagation to replica holders which do not need to receive the update. Moreover, we verify the effectiveness of our strategies by simulation experiments.","2157-0418;21570418","POD:978-1-4244-4746-6","10.1109/NBiS.2009.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5350202","P2P;replication;update","Data engineering;Fault tolerance;File systems;Information retrieval;Information science;Information systems;Load management;Multimedia systems;Network servers;Peer to peer computing","peer-to-peer computing;replicated databases","P2P network;peer-to-peer networks;propagation strategies;selective update propagation","","1","","9","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"BioCLink: A Probabilistic Approach for Improving Genomics Search with Citation Links","X. Yin; X. Huang; Z. Li","Coll. of Comput. Sci. & Eng., Beihang Univ., Beijing, China","2009 IEEE International Conference on Bioinformatics and Biomedicine","20091201","2009","","","375","378","Combination of multiple evidences has been shown to be effective in genomics literature retrieval. Citation information is an intuitive evidence for facilitating literature retrieval. Previous research on citation analysis has demonstrated that useful linkage information can be extracted from the citation graph. However, the question of how the combination of citation evidence and content evidence should be done to maximize retrieval accuracy still remains largely unanswered. In this paper, we propose BioCLink, a new probabilistic approach that integrates citation evidence into content-based weighting function for improving genomics literature retrieval performance. Based on findings of our previous study, a strategy for modeling citation evidence is proposed. BioCLink provides the combination of content and citation evidences with a theoretical support. Moreover, exhaustiveparameter tuning can be avoided using BioCLink. Extensive experiments on TREC 2006 and 2007 Genomics collections demonstrate the advantages and effectiveness of our proposed methods.","","POD:978-0-7695-3885-3","10.1109/BIBM.2009.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341756","citation link analysis;genomics literature retrieval;probabilistic model","Bioinformatics;Biomedical engineering;Citation analysis;Computer science;Content based retrieval;Couplings;Educational institutions;Genomics;Information retrieval;Information technology","bioinformatics;citation analysis;content-based retrieval;genomics","BioCLink;citation analysis;citation graph;citation links;content-based weighting function;genomics literature retrieval;genomics search;information citation;linkage information","","0","","16","","","1-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Building deep dependency structure from partial parses","H. Faili","Department of Electrical and Computer Enginering, University of Tehran, Tehran, Iran","2009 14th International CSI Computer Conference","20091208","2009","","","247","252","Increasing the domain of locality by using tree-adjoining-grammars (TAG) encourages some researchers to use it as a modeling formalism in their language application. But parsing with a rich grammar like TAG faces two main obstacles: low parsing speed and a lot of ambiguous syntactical parses. We uses an idea of the shallow parsing based on a statistical approach in TAG formalism, named supertagging, which enhanced the standard POS tags in order to employ the syntactical information about the sentence. In this paper, an error-driven method in order to approaching a full parse from the partial parses based on TAG formalism is presented. These partial parses are basically resulted from supertagger which is followed by a simple heuristic based light parser named light weight dependency analyzer (LDA). Like other error driven methods, the process of generation the deep parses can be divided into two different phases: error detection and error correction, which in each phase, different completion heuristics applied on the partial parses. The experiments on Penn Treebank show considerable improvements in the parsing time and disambiguation process.","","POD:978-1-4244-4261-4","10.1109/CSICC.2009.5349409","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349409","","Application software;Buildings;Error correction;Information retrieval;Linear discriminant analysis;Natural languages;Phase detection;Speech;State-space methods;Technical Activities Guide -TAG","grammars;natural language processing;text analysis","Penn Treebank;ambiguous syntactical parses;deep dependency structure;error correction;error detection;error-driven method;light weight dependency analyzer;partial parses;syntactical information;tree-adjoining-grammars","","1","","13","","","20-21 Oct. 2009","","IEEE","IEEE Conference Publications"
"Web document retrieval using manifold learning and ACO algorithm","W. Ziqiang; S. Xia","School of Information Science and Engineering, Henan University of Technology, Zhengzhou","2009 2nd IEEE International Conference on Broadband Network & Multimedia Technology","20091204","2009","","","152","155","To efficiently deal with high dimensionality and precision problems in document retrieval, a novel document retrieval algorithm based on manifold learning and ant colony optimization(ACO) algorithm is proposed. The high-dimensional document data are first projected into lower-dimensional feature space with neighborhood preserving embedding (NPE) algorithm, the ACO algorithm is then applied to retrieve relevant documents in the reduced lower-dimensionality document feature space. Extensive experiments on real-world data set demonstrate the effectiveness of the proposed algorithm.","","POD:978-1-4244-4590-5","10.1109/ICBNMT.2009.5348468","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5348468","Document retrieval;ant colony optimization(ACO);manifold learning;neighborhood preserving embedding(NPE)","Ant colony optimization;Feedback;Information retrieval;Large scale integration;Linear discriminant analysis;Manifolds;Pattern recognition;Scattering;Space technology;Sun","Internet;document handling;information retrieval;learning (artificial intelligence);optimisation","ACO algorithm;NPE algorithm;Web document retrieval algorithm;ant colony optimization;high-dimensional document data;lower-dimensional feature space;manifold learning;neighborhood preserving embedding","","0","","9","","","18-20 Oct. 2009","","IEEE","IEEE Conference Publications"
"Neural Network Based Text Detection in Videos Using Local Binary Patterns","J. Ye; L. L. Huang; X. Hao","Sch. of Autom. Sci. & Electr. Eng., Beihang Univ., Beijing, China","2009 Chinese Conference on Pattern Recognition","20091204","2009","","","1","5","The detection of texts in video images is an important task towards automatic content-based information indexing and retrieval system. In this paper, we propose a texture-based method for text detection in complex video images. Taking advantage of the desirable characteristic of gray-scale invariance of local binary patterns (LBP), we apply a modified LBP operator to extract feature of texts. A polynomial neural network (PNN) is employed to make classification. The PNN is trained with large quantities of samples collected using a bootstrap strategy. In addition, post-processing procedure including verification and integration is performed to refine the detected results. The effectiveness of the proposed method is demonstrated by experimental results.","","POD:978-1-4244-4199-0","10.1109/CCPR.2009.5343973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5343973","","Content based retrieval;Data mining;Feature extraction;Gray-scale;Image retrieval;Indexing;Information retrieval;Neural networks;Polynomials;Videos","content-based retrieval;database indexing;feature extraction;image classification;image texture;information retrieval systems;learning (artificial intelligence);neural nets;object detection;polynomials;text analysis;video retrieval","CBIR system;LBP operator;PNN training;automatic content-based information indexing and retrieval system;bootstrap strategy;feature extraction;gray-scale invariance;image sample;local binary pattern;numerical analysis;polynomial neural network-based text detection;post-processing procedure;texture-based method;video image classification","","2","","13","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
"An Evolutionary Algorithm for Automatic Composition of Information-gathering Web Services in Mashups","T. Fischer; F. Bakalov; B. König-Ries; A. Nauerz; M. Welsch","Friedrich-Schiller Univ. of Jena, Jena, Germany","2009 Seventh IEEE European Conference on Web Services","20091201","2009","","","39","48","The idea behind mashups is to provide a mechanism that allows for more or less spontaneous combination of existing Web applications. Users shall thus be enabled to combine data and services according to their needs.However, existing mashup frameworks require some programming knowledge, hence are not suitable for non-expert users. In this paper, we present a system that builds on existing semantic Web research to achieve an automatic, ad-hoc generation of mashups thus eliminating the need for programmer involvement. At the core of our approach, there is an evolutionary algorithm that automatically composes different information Web services based on semantic service descriptions. The information that has been retrieved from the invoked Web services is automatically transformed into a semantic representation and presented as a mashup to the users of the system.","","POD:978-0-7695-3854-9","10.1109/ECOWS.2009.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341673","Evolutionary Algorithms;Semantic Web Services;Web Service Composition","Cities and towns;Corporate acquisitions;Evolutionary computation;Financial management;Information retrieval;Mashups;Programming profession;Research and development;Semantic Web;Web services","Web services;evolutionary computation;ontologies (artificial intelligence);semantic Web","evolutionary algorithm;information gathering Web service composition;mashup framework;ontology;semantic Web;semantic representation;semantic service description","","1","","53","","","9-11 Nov. 2009","","IEEE","IEEE Conference Publications"
"A Proposal for a Semantic Intelligent Document Repository Architecture","A. Rodriguez; R. Colomo; J. M. Gomez; G. Alor-Hernandez; R. Posada-Gomez; U. Juarez-Martinez; J. E. L. Gayo; K. Vidyasankar","Comput. Sci. Dept., Univ. Carlos III de Madrid, Leganes, Spain","2009 Electronics, Robotics and Automotive Mechanics Conference (CERMA)","20091201","2009","","","69","75","The processing of high amount of documents is a highly complex challenge, which becomes even more complicated when the goal is to extract the semantically relevant data within the documents. The large-scale processing of immense repositories of knowledge requires techniques which perform information extraction to facilitate the subsequent classification and indexing of texts. Having this into account, we propose the use of Dublin Core metadata for the classification of Software Engineering publications. Based on the information obtained from Dublin Core, we present a global repository that is populated automatically, which takes the form of an ontology which represents the distinct areas of Software Engineering knowledge inspired by SWEBOK (Software Engineering Body of Knowledge). Finally, the process of the classification of texts within the ontology is carried out in three steps: keyword analysis, processing of the document. We believe our proposal based on a linguistic text classification method, heuristics, and subsequently the intersection of the three techniques mentioned, generating more precise search results in response to user queries.","","POD:978-0-7695-3799-3","10.1109/CERMA.2009.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342009","Ontologies;semantic Web.","Computer science;Data mining;Information retrieval;Intelligent robots;Internet;Ontologies;Proposals;Software engineering;Support vector machine classification;Support vector machines","database indexing;ontologies (artificial intelligence);software engineering;text analysis","Dublin core metadata;document processing;global repository;information extraction;keyword analysis;linguistic text classification method;ontology;semantic intelligent document repository architecture;software engineering knowledge;software engineering publication;text indexing","","0","","30","","","22-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Practical location-based routing in vehicular ad hoc networks","Zhi Li; Y. Zhu; M. Li","Department of Computer Science and Engineering, Shanghai Jiao Tong University, China","2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems","20091117","2009","","","900","905","Rapid advancement in wireless communication has made it possible to develop vehicular ad hoc networks, in which a vehicle can communicate with other vehicles via a wireless, multi-hop fashion. A variety of appealing real-world applications can be enabled by VANETs, such as driving safety and urban monitoring. Many location based routing algorithms have been proposed for data delivery in VANETs. Most of them assume that accurate location information is available when needed. In practice, however, such assumption is unrealistic. It incurs considerable cost to retrieve location information. In addition, a vehicle is on the fast move over time, and a location previously obtained may become invalid after certain time. This paper proposes a routing algorithm that is based on a practical location information model. To solve the problem of location inaccuracy and vehicle mobility, we devise a location predictor which estimates the possible location of a vehicle by using history information. Based on the greedy forwarding strategy, the proposed routing differentiates packets in terms of closeness to destination and jump distance. We evaluate the performance of the proposed algorithms with a large real trace of taxi motion in Shanghai. Trace-driven simulation results demonstrate that data delivery performance is improved.","2155-6806;21556806","POD:978-1-4244-5114-2","10.1109/MOBHOC.2009.5337038","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337038","Routing Protocol;Vehicular Ad Hoc Networks","Ad hoc networks;Costs;History;Information retrieval;Monitoring;Routing;Safety;Spread spectrum communication;Vehicles;Wireless communication","ad hoc networks;greedy algorithms;mobile radio;road vehicles;telecommunication network routing","MANET;Shanghai taxi motion;VANET;data delivery performance;driving safety;greedy forwarding strategy;location information model;location information retrieval;location predictor;location-based routing algorithm;trace-driven simulation;urban monitoring;vehicle mobility;vehicular ad hoc network;wireless multihop communication","","3","","14","","","12-15 Oct. 2009","","IEEE","IEEE Conference Publications"
"The impact of cross-functional teams on operational performance after the implementation of intelligent information systems","R. Santa; W. K. D. Pun","Charles Darwin University, Darwin NT 0909 Australia","2009 IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications","20091201","2009","","","544","548","This study examines cross-functional teams and their impact in line with operational performance and system effectiveness after the implementation of intelligent information and retrieval systems in organisations. Multiple regression analysis was used to determine the structural relationships and look for the phenomenon of cross-functional teams, operational effectiveness, and system effectiveness in the betterment of operational performance. Preliminary findings suggest that the quality and speed from operational effectiveness and the quality of information and quality of the services from systems effectiveness are the two key factors for cross-functional teams to enhance operational performance.","","POD:978-1-4244-4901-9","10.1109/IDAACS.2009.5342921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342921","Intelligent Information Systems;Operational Effectiveness;Systems Effectiveness","Australia;Cultural differences;Human resource management;Information retrieval;Information systems;Innovation management;Intelligent systems;Management training;Technological innovation;Technology management","information retrieval systems;information systems;innovation management;regression analysis;team working","cross-functional team;information quality;information retrieval system;innovation management;intelligent information system;multiple regression analysis;operational performance;structural relationship;system effectiveness","","0","","28","","","21-23 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Metadata Registry to Facilitate the Search and Retrieval of Electrocardiograms","S. Yuan; D. Wei; W. Xu; W. Shen","Biomed. Inf. Technol. Lab., Univ. of Aizu, Aizu-Wakamatsu, Japan","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","1","","269","273","Sequential electrocardiograms (ECGs) are very useful for personalized diagnosis. It is therefore very useful to search various electrocardiographs or ECG management systems connected to the Internet for a particular patient's ECGs. This is an interesting but not completely solved problem. In this paper, we present an experimental study of our metadata registry aimed at facilitating the search for and retrieval of a patient's ECGs via the Internet. The metadata registry was developed based on the ebXML registry methodology and Web service technique. An assessment test in an experimental scenario shows that it is feasible to apply the metadata registry to discovering and retrieving a patient's ECGs resident in a number of emulated electrocardiographs placed in the Internet. This study demonstrates a useful framework for ECG sharing through the Internet.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5327810","ebXML;electrocardiogram;registry;retrieval;search;web service","Biomedical computing;DICOM;Databases;Electrocardiography;Hospitals;Information retrieval;Information technology;Internet;Picture archiving and communication systems;Web services","Web services;electrocardiography;information retrieval;medical information systems;meta data","ECG management systems;Internet;Web service technique;ebXML registry methodology;metadata registry;sequential electrocardiograms","","0","","9","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Relevance Judgments for Web Services Retrieval - A Methodology and Test Collection for SWS Discovery Evaluation","U. Küster; B. König-Ries","Inst. of Comput. Sci., Friedrich-Schiller Univ. Jena, Jena, Germany","2009 Seventh IEEE European Conference on Web Services","20091201","2009","","","17","26","Semantic web services (SWS) promise to take service oriented computing to a new level by allowing to automatically locate and use functionality exposed as web services. At the core of SWS are solutions to the problem of SWS discovery, i.e., the problem of comparing semantic goal descriptions with semantic offer descriptions to determine services relevant to a given request. A plethora of different approaches to this problem have been proposed, but their comparative evaluation is challenging.While the evaluation setups from the information retrieval (IR) community provided a natural starting point to SWS discovery evaluation, the applicability of their assumptions have not been sufficiently discussed so far. This paper discusses the differences between traditional IR and SWS discovery and the resulting fundamental problems. It proposes a methodology and experimental setup for SWS discovery evaluation that addresses these problems. An initial realistic service test collection is presented and issues related to the central notion of relevance in the context of service discovery are examined. In particular the consistency of relevance judgments using three different relevance scales is experimentally investigated and the consequences on the evaluation methodology are discussed.","","POD:978-0-7695-3854-9","10.1109/ECOWS.2009.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341676","Evaluation;Relevance Judgments;Semantic Web Services;Service Discovery and Matchmaking","Application software;Automatic testing;Computer science;Computer vision;Context-aware services;History;Information retrieval;Libraries;Semantic Web;Web services","Web services;information retrieval;semantic Web","SWS discovery evaluation;Web services retrieval;information retrieval;realistic service test collection;semantic Web service;semantic goal description;semantic offer description;service discovery context;service oriented computing","","1","","17","","","9-11 Nov. 2009","","IEEE","IEEE Conference Publications"
"Decision Model for a System to Start Communicating with a Human Using HMM","M. Murakami; M. Yamagiwa; M. Uehara; S. Ushiyama; K. Shirai","Fac. of Inf. Sci. & Arts, Toyo Univ., Toyo, Japan","2009 International Conference on Network-Based Information Systems","20091208","2009","","","618","622","The purpose of this paper is to develop a robot that actively communicates with a human, and explicitly extracts information from the human mind that is rarely expressed as verbal information. The spoken dialogue system for information collection must independently decide whether it may or may not start communicating with a human. In this paper, we assume that the system begins to communicate with a human sitting and working at a desk, analyze the relationship between his behavioral pattern and the decisions made by the other humans, i.e., whether or not to communicate with the former, and construct the decision model for the system to start communicating with the human using hidden Markov model.","2157-0418;21570418","POD:978-1-4244-4746-6","10.1109/NBiS.2009.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349874","","Data mining;Hidden Markov models;Humans;Information retrieval;Mood;Motion pictures;Pattern analysis;Robots;Wearable sensors;Web sites","decision theory;hidden Markov models;human-robot interaction;interactive systems","decision model;hidden Markov model;information collection;robot;spoken dialogue system","","0","","7","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"Toward new peering strategies for push-pull based P2P streaming systems","A. Ouali; B. Kerhervey; B. Jaumardz","ECE Dept., Concordia University, Montreal, Canada","2009 International Conference on Ultra Modern Telecommunications & Workshops","20091204","2009","","","1","8","Recently, several mesh-based P2P live streaming systems are adopting a push-pull mechanism instead of the classical pull mechanism. A push-pull mechanism is more efficient in terms of overhead and leads to much better playback delay performance because it eliminates the need of the three steps of pull content retrieval: buffer map broadcast, data request and data sending. Thus, using the pull mechanism is not the best way to evaluate the performance of peering strategies especially the ones targeting playback delay minimization. We propose to revisit the peering strategies with a focus on playback delay minimization. Such strategies will benefit from the push-pull mechanism as the pull part is used mainly at the beginning of the session or to recover lost content. We believe that making the right decisions about node relationships will boost the performance of P2P systems. We propose new peering strategies that are compared, through simulations, with some recent strategies. Results show that one of the proposed strategies outperforms significantly the existing ones with respect to the playback delay experienced by participating nodes.","2157-0221;21570221","POD:978-1-4244-3942-3","10.1109/ICUMT.2009.5345394","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345394","Live Streaming;P2P;Peering Strategies;Playback Delay","Bandwidth;Broadcasting;Content based retrieval;Costs;Delay;Information retrieval;Internet;Peer to peer computing;Streaming media;Web server","content-based retrieval;minimisation;peer-to-peer computing;video streaming","buffer map broadcast;data request;data sending;mesh-based P2P live streaming systems;peering strategies;playback delay minimization;pull content retrieval;push-pull based P2P streaming systems","","1","","17","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Extracting spatial semantics in association rules for ocean image retrieval","L. J. Kao; Y. P. Huang; F. E. Sandnes","Department of Multimedia and Game, Science, Taipei College of Maritime, Technology, Taipei, 11174 Taiwan","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","2924","2929","Several research institutions and governmental departments provide ocean images for research purposes. For example, Argo, a worldwide ocean research organization, produces ocean salinity and temperature images and researchers can download those images from the Internet. One may build an image system to store ocean images and retrieve them later for further research, for example, to predict future salinity or temperature variation. Image retrieval technology is therefore important. This paper describes an ocean image retrieval system based on content-based image retrieval. Currently, content-based image retrieval technology does not exploit high-level semantics, and it is hard to obtain predictive information from retrieved images. Our improvement involves a spatial reference method that is used to help get the spatial relationships between objects for a certain image. This allows the spatial semantics between the query image and images in database to be considered. Spatial association rules are also mined and are subsequently used as a basis for retrieving additional images. As the spatial semantics in both the query image and spatial association rules, the retrieved images are more accurate. The experimental results verify that the system effectively predicts the occurrence of salinity or temperature variations.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346105","content-based image retrieval;ocean salinity and temperature images;spatial association rules mining","Association rules;Content based retrieval;Image databases;Image retrieval;Information retrieval;Internet;Marine technology;Ocean salinity;Ocean temperature;Spatial databases","Internet;content-based retrieval;data mining;geophysics computing;image retrieval;ocean temperature;oceanographic techniques","Internet;content-based image retrieval;ocean image retrieval;ocean salinity;ocean temperature image;spatial association rule mining;spatial reference method;spatial semantics extraction","","0","","12","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Dissimilarity algorithm on conceptual graphs to mine text outliers","S. S. Kamaruddin; A. R. Hamdan; A. A. Bakar; F. M. Nor","Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, 43600 Bangi Selangor, Malaysia","2009 2nd Conference on Data Mining and Optimization","20091201","2009","","","46","52","The graphical text representation method such as Conceptual Graphs (CGs) attempts to capture the structure and semantics of documents. As such, they are the preferred text representation approach for a wide range of problems namely in natural language processing, information retrieval and text mining. In a number of these applications, it is necessary to measure the dissimilarity (or similarity) between knowledge represented in the CGs. In this paper, we would like to present a dissimilarity algorithm to detect outliers from a collection of text represented with Conceptual Graph Interchange Format (CGIF). In order to avoid the NP-complete problem of graph matching algorithm, we introduce the use of a standard CG in the dissimilarity computation. We evaluate our method in the context of analyzing real world financial statements for identifying outlying performance indicators. For evaluation purposes, we compare the proposed dissimilarity function with a dice-coefficient similarity function used in a related previous work. Experimental results indicate that our method outperforms the existing method and correlates better to human judgements. In Comparison to other text outlier detection method, this approach managed to capture the semantics of documents through the use of CGs and is convenient to detect outliers through a simple dissimilarity function. Furthermore, our proposed algorithm retains a linear complexity with the increasing number of CGs.","2155-6938;21556938","POD:978-1-4244-4944-6","10.1109/DMO.2009.5341910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341910","Conceptual graphs;dissimilarity algorithm;outlier detection;text mining;text outliers","Character generation;Data mining;Humans;Information retrieval;Information science;NP-complete problem;Natural language processing;Optimization methods;Performance analysis;Text mining","data mining;document handling;graph theory;information retrieval;natural language processing;optimisation","NP-complete problem;conceptual graph interchange format;conceptual graphs;dice-coefficient similarity function;dissimilarity algorithm;graph matching;graphical text representation;information retrieval;natural language processing;text mining;text outliers","","1","","33","","","27-28 Oct. 2009","","IEEE","IEEE Conference Publications"
"Evaluation of P2P overlays for AoI management in Distributed Virtual Environments","C. Bettinger; R. Oechsle; M. Esch; H. Schloss; P. Sturm","Trier University of Applied Sciences, Department of Computer Science, D-54293, Germany","2009 International Conference on Ultra Modern Telecommunications & Workshops","20091204","2009","","","1","6","Client/Server-based DVE approaches incur scalability and load balancing problems while addressing massive number of users. In order to mitigate these problems P2P overlays are proposed for content provision and management issues instead. However, content provision and management in a distributed manner is much more complicated and requires an exhaustive study of overlay network properties. In order to investigate which kinds of overlay networks suit the requirements stated by DVEs at best, we have performed a comparative evaluation of the deterministic DHT-based Tapestry overlay and the nondeterministic prefix-tree-based P-Grid overlay considering their data location performance and construction cost. In this paper we discuss these evaluation results and exemplarily show how AoI management and content provision can be realized by using the P-Grid overlay.","2157-0221;21570221","POD:978-1-4244-3942-3","10.1109/ICUMT.2009.5345537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345537","AoI Management;P2P Overlays","Avatars;Content management;Environmental management;Information retrieval;Load management;Scalability;Spine;Surges;Technology management;Virtual environment","grid computing;peer-to-peer computing","AoI management;P2P overlays;content management;content provision;data location performance;distributed virtual environments;load balancing problems;overlay network;prefix-tree-based P-grid overlay","","0","","21","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Exploiting text content in image search by semi-supervised learning techniques","C. Shen; Y. Yang; B. Wang","School of Software and Electronics, Peking University, Beijing 100871, China","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","5063","5067","Along with the explosive growth of the Web, Web image search has become a more and more popular application which helps users digest the large amount of online visual information. Previous research mainly exploits visual information between images while rarely uses the text information surrounding the images on the Web pages. In this paper, we consider the relevance feedback as a machine learning problem. We proposed a novel relevance feedback framework for Web image search, which exploit both text and image modalities information with semi-supervised learning techniques. In each round of relevance feedbacks, the framework trains two classifiers for the two modalities by using the feedback information collected from the user. Then, it uses the unlabeled search result to improve these two classifiers. Finally, the ranked results list produced by image and text modality classifiers are combined to get the final rank. Experiments demonstrate the promise of the proposed framework.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346038","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346038","Web image search;co-training;relevance feedback;semi-supervised learning","Computers;Content based retrieval;Cybernetics;Explosives;Feedback;Image retrieval;Information retrieval;Machine learning algorithms;Semisupervised learning;Web pages","Internet;classification;image classification;image retrieval;learning (artificial intelligence);relevance feedback;text analysis","Web image search;image modality classifier;machine learning problem;online visual information;relevance feedback;semisupervised learning technique;text content exploiting;text modality classifier","","0","","15","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Improved shape description using radon transform and application in phytoplankton identification","K. Lin; Y. Chenhui; G. Yahui","School of Information Science and Technology, Xiamen University, Xiamen","2009 2nd IEEE International Conference on Broadband Network & Multimedia Technology","20091204","2009","","","477","481","An improved shape description using Radon transform is presented. As shown in the experiments for MPEG-7 shape database, the improved Radon composite features descriptor not only has rotation, scaling and translation invariance (RST), but also has better performance in image retrieval than Radon composite features (RCFs) and some well-known approaches such as Zernike moments and Gabor Filters. Phytoplankton is as one of important indication to the ocean ecosystem, the application of the improved Radon composite features in phytoplankton identification system is also shown in this paper.","","POD:978-1-4244-4590-5","10.1109/ICBNMT.2009.5348519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5348519","Image retrieval;Invariance;Phytoplankton identification;Radon transform;Shape","Algae;Ecosystems;Image recognition;Image retrieval;Information retrieval;Information science;Oceans;Sea measurements;Shape measurement;Silicon compounds","Gabor filters;Zernike polynomials;ecology;feature extraction;geophysics computing;image classification;image retrieval;microorganisms;oceanographic techniques;remote sensing","Gabor Filters;MPEG-7 shape database;RCF;RST;Zernike moment;feature extraction;image classification;image retrieval method;ocean ecosystem;phytoplankton identification;phytoplankton shape description;radon composite feature;radon transform;rotation, scaling and translation invariance;shape image","","0","","14","","","18-20 Oct. 2009","","IEEE","IEEE Conference Publications"
"Trojan detection using MIB-based IDS / IPS system","C. Pattinson; K. Hajdarevic","Innovation North Faculty, Leeds Metropolitan University, Leeds, UK","2009 XXII International Symposium on Information, Communication and Automation Technologies","20091204","2009","","","1","5","Identifying and detecting Trojans (malicious software installed and run on a host, without the acquiescence of the host's owner) is a major element in delivering computer security. As with any computer application, installation of a Trojan leaves a ldquofootprintrdquo on the systems resources. However, detection is non-trivial: the detector must be able to recognize the symptoms against a background of a range of other (ldquosaferdquo) activities, which also consume system resources. Furthermore, such detection activity should be at least resource neutral (in other words, the resources consumed by the detection process should not be more than the resources saved in detection). Therefore, we wished to explore the potential of an economical approach that explicitly takes into account resources used. In order to achieve our aim, we explore the possibility of making use of the existing widely deployed management information database (the MIB) as the basis for detecting attempts to install Trojan software on networked systems. We identify the characteristics of typical attacks in respect of the impact they have on particular MIB objects, and propose a decision-tree based algorithm which can detect Trojan activity. We identify the likely effectiveness of this system, with particular reference to the need for such information to be gathered in a timely manner.","","POD:978-1-4244-4220-1","10.1109/ICAT.2009.5348410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5348410","Anomaly detection;Management Information Base;Network security;Trojan attacks","Application software;Costs;Data processing;Data security;Gain control;Information management;Information retrieval;Intrusion detection;Resource management;Technological innovation","database management systems;decision trees;invasive software","MIB-based IDS-IPS system;Trojan detection;computer security;decision-tree based algorithm;intrusion detection system;intrusion prevention system;management information database","","1","","6","","","29-31 Oct. 2009","","IEEE","IEEE Conference Publications"
"Study of Thangka Image Retrieval and Multimedia Presentation Management System","W. Wang","Sch. of Comput. Sci. & Inf. Eng., Northwest Univ. for Nat., Lanzhou, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","981","984","Thangka is integral part of Tibetan painting art, is also a bright pearl in the treasure house of world culture as well as a valuable cultural heritage of the world. Thangka's digital works are meaningful and valuable, since in today's fast-growing information age, multimedia data is becoming more and more common in people's daily applications, however this data is nearly useless if there is no computer-aided browsing, searching, and retrieving mechanism to obtain the desired contents. And it involves many research content such as database management system, feature extraction and presentation, content-based image retrieval, semantic-based image retrieval and search engines of Thangka image and so on. In this paper, the characteristics of Thangka image, content-based image retrieval (CBIR) system for Thangka is introduced, and a semantic-based image retrieval and multimedia presentation management system model for Thangka image is also proposed.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337190","Thangka;content-based image retrieval (CBIR);semantic-based image retrieval","Application software;Art;Content based retrieval;Cultural differences;Database systems;Image retrieval;Information retrieval;Multimedia databases;Multimedia systems;Painting","content-based retrieval;feature extraction;image retrieval;search engines;visual databases","Thangka;Tibetan painting art;computer aided browsing;content-based image retrieval;cultural heritage;database management system;feature extraction;feature presentation;information age;multimedia data;multimedia presentation management system;search engines;semantic based image retrieval","","2","","9","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Fast Audio Retrieval Method Based on Negativity Judgment","Z. Guibin; L. Miao; H. Jiqing; Z. Tieran","Sch. of Comput. Sci. & Technol., Harbin Inst. of Technol., Harbin, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","1156","1159","A novel audio retrieval method based on negativity judgment is proposed. The foundation is that the similar audio feature vectors should be near after a transform procedure but which is a necessary condition but not sufficient condition to judge whether two audio segments are similar or not. So, it is reasonable to exclude audio vectors that can't meet the necessary condition for similarity judgment from retrieval matching, which can speed up retrieval effectively. In the paper, an audio feature vector quantization method called weighted self-similarity and an index method based on the idea of negativity judgment for Euclidean distance is introduced. Experimental results show that the method can search at a high speed.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337566","audio retrieval;negativity judgment;weighted self-similarity","Computer science;Content based retrieval;Euclidean distance;Indexing;Information retrieval;Multidimensional systems;Signal processing;Sufficient conditions;Vector quantization;World Wide Web","audio coding;information retrieval;vector quantisation","audio feature vector;audio feature vector quantization method;audio retrieval method;euclidean distance;index method;negativity judgment;retrieval matching;weighted self-similarity method","","0","","6","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"Monotonicity Analysis for Paraphrase Detection","D. Uribe","Div. de Posgrado e Investig., Inst. Tecnol. de la Laguna, Mexico City, Mexico","2009 Electronics, Robotics and Automotive Mechanics Conference (CERMA)","20091201","2009","","","82","87","In this paper, we analyse the role of monotonicity for the recognition of paraphrasing pairs. Our approach is based in a system architecture which consists of two components. The first component is the alignment module which takes care of the order of the elements for the analysis of monotonicity. The semantic analysis is carried out by the second module which relies on the combination of semantic information provided by the analysis of lexical relationships, and the use of semantic heuristics to recognize false paraphrasing. The results of the experimentation conducted show how lexical coupling without false monotonicity assumption leads to higher accuracy. Moreover, the results of the experimentation using monotonic alignment techniques suggest that the MSR corpus might be a data set without a substantial syntactic diversity.","","POD:978-0-7695-3799-3","10.1109/CERMA.2009.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342007","alignment;monotonicity;paraphrasing;semantic heuristics","Automotive engineering;Event detection;Information analysis;Information retrieval;Natural language processing;Proposals;Robots;Search engines;Supervised learning;Text recognition","speech recognition","MSR corpus;monotonicity analysis;paraphrase detection;paraphrasing pairs recognition;system architecture","","0","","13","","","22-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Creating and visualizing fuzzy document classification","J. Gelernter; D. Cao; R. Lu; E. Fink; J. G. Carbonell","School of Computer Science, Carnegie Mellon University, 5000 Forbes Ave., Pittsburgh, PA 15213, U.S.A.","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","672","679","Fuzzy classification ranks items by degree rather than assigning them either within or without of a category. The novelty of our work is in integrating fuzzy classification algorithms with an interface to visualize fuzzy results. An advantage of our algorithms' `fuzziness' is that it provides additional information per retrieved result that helps in deciding whether to drill down to the document or skip it. An advantage of our interface is that it allows users to visualize those differences quickly. We have created a prototype that allows the retrieval of journal articles by content word or by ontology-supported browse categories that can be selected independently or in tandem. Journal articles in our digital library pertain to paleontology, but techniques demonstrated viable in indexing and ranking paleo-journal literature should apply to other knowledge domains with little modification.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346682","classification;fuzzy match;fuzzy retrieval systems;graphical user interfaces;information visualization;relevance;retrieval model","Automatic testing;Computer science;Cybernetics;Data visualization;Fuzzy systems;Information retrieval;Ontologies;Text categorization;USA Councils;Uncertainty","data visualisation;digital libraries;fuzzy set theory;graphical user interfaces;indexing;information retrieval;pattern classification","digital library;fuzzy classification algorithms;fuzzy document classification visualization;graphical user interfaces;information retrieval;ontology-supported browse categories;paleo-journal ranking;paleontology;user interface","","2","","21","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Retrieve Space Principal Component Analysis Based on the Image Retrieve Principle","Z. b. Guo; Y. y. Yan","Sch. of Inf. Eng., Yangzhou Univ., Yangzhou, China","2009 Chinese Conference on Pattern Recognition","20091204","2009","","","1","5","Principal component analysis is the well-known method in pattern recognition, but classical principal component analysis extract some features that keep maximal scatter and the algorithm doesn't use the classificatory information of samples. Therefore, extracted features aren't very efficient to classification based on classical principal component analysis. Based on the image retrieve principle, the paper presents a kind of retrieve space principal component analysis (RS-PCA). Then, a supervised retrieve space principal component analysis (SRS-PCA) using classificatory information are developed according to RS-PCA. The algorithm makes the extracted features more effective and the recognition precision is increased. The experiments resulted on ORL and Yale face database demonstrate that the proposed algorithm has more powerful and excellent performance than classical principal component analysis.","","POD:978-1-4244-4199-0","10.1109/CCPR.2009.5344154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344154","","Data mining;Face recognition;Feature extraction;Image retrieval;Information retrieval;Pattern recognition;Principal component analysis;Scattering;Space technology;Spatial databases","feature extraction;image retrieval;principal component analysis","SRS-PCA;classificatory information;feature extraction;image retrieve principle;principal component analysis;supervised retrieve space","","1","","9","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
"Constructing a Facet-Based and Personalized Just-in-Time Web Information Recommendation Application in a Multi-agent Environment","K. Yang; Z. Shi","Key Lab. of Intell. Inf. Process., Chinese Acad. of Sci., Beijing, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","2","","154","159","High precision is vital to the success of just-in-time information retrieval system. This paper attempts to improve it from two aspects: better understanding the user's current need and providing a highly relevant information source. For the former, an algorithm that can model a user's need in current context based on his behavior automatically is proposed, and for the latter, a mechanism is provided for the user to choose the information source he need by organizing all Web resources involved in a faceted way. All the algorithms and functions are encapsulated in several agents to constitute a multi-agent just-in-time Web information recommending application that help people write, and all these agent are constructed and managed by a multi-agent system middleware named ldquoMAGErdquo.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329120","facet;just-in-time;multi-agent;personalization;recommenda- tion","Application software;Computers;Containers;Face;Information processing;Information resources;Information retrieval;Information technology;Middleware;Multiagent systems","Internet;information filtering;just-in-time;middleware;multi-agent systems","MAGE middleware;facet-based Web information recommendation;just-in-time information retrieval system;multiagent system middleware;personalized just-in-time Web information recommendation","","0","","11","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"An efficient k-means algorithm integrated with Jaccard distance measure for document clustering","M. U. S. Shameem; R. Ferdous","Dept. of Computer Science and Engineering, University of Development Alternative (UODA), Dhaka, Bangladesh","2009 First Asian Himalayas International Conference on Internet","20091124","2009","","","1","6","Document Clustering is a widely studied problem in Text Categorization. It is the process of partitioning or grouping a given set of documents into disjoint clusters where documents in the same cluster are similar. K-means, one of the simplest unsupervised learning algorithms, solves the well known clustering problem following a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters) fixed a priori. The main idea is to define k centroids, one for each cluster. This clustering algorithm uses an iterative procedure which converges to one of numerous local minima. We have found that these iterative techniques are especially sensitive to initial starting conditions of the centroid of each cluster and the more the distance among the cluster centroid the better the clustering performance. In simple K-means algorithm the way to initialize the centroid is not specified and one popular way to start is to randomly choose k points of the samples as k centroids but this process does not guarantee to choose the maximum dissimilar documents as the centroid point for k-cluster. In this paper we proposed a modified k-means algorithm which uses Jaccard distance measure for computing the most dissimilar k documents as centroids for k clusters. Our experimental results demonstrate that our proposed K-means algorithm with Jaccard distance measure for computing the centroid improves the clustering performance of the simple K-means algorithm.","1089-7801;10897801","POD:978-1-4244-4569-1","10.1109/AHICI.2009.5340335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340335","Document Clustering;Entropy;F1-Measure;K-Means algorithm;Precission;Recall","Clustering algorithms;Computer science;Entropy;Information retrieval;Iterative algorithms;Iterative methods;Measurement techniques;Partitioning algorithms;Text categorization;Unsupervised learning","pattern clustering;statistics;text analysis;unsupervised learning","Jaccard distance measure;document clustering;k-means algorithm;text categorization;unsupervised learning algorithms","","7","","7","","","3-5 Nov. 2009","","IEEE","IEEE Conference Publications"
"Towards a method for evaluating naturalness in conversational dialog systems","V. Hung; M. Elvir; A. Gonzalez; R. DeMara","Intelligent Systems Laboratory, University of Central Florida, Orlando, Florida","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","1236","1241","The evaluation of conversational dialog systems has remained a controversial topic, as it is challenging to quantitatively assess how well a conversation agent performs, or how much better one is compared to another. Furthermore, one of the hurdles which remains elusive in this quandary is the definition of naturalness, as demonstrated by how well a dialog system can maintain a natural conversation flow devoid of perceived awkwardness. As a step towards defining the dimensions of effectiveness and naturalness in a dialog system, this paper identifies existing evaluation practices which are then expanded to develop a more suitable assessment vehicle. This method is then applied to the LifeLike virtual avatar project.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5345904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345904","artificial intelligence;dialog systems;humancomputer interaction;software evaluation","Avatars;Cybernetics;Humans;Information retrieval;Intelligent agent;Intelligent systems;Performance evaluation;Production systems;USA Councils;User interfaces","avatars;interactive systems;multi-agent systems;software maintenance","LifeLike virtual avatar project;controversial topic;conversation agent;conversational dialog systems;human computer interaction;software evaluation","","1","","26","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A survey on Chinese word segmentation technology","L. Qun","Institute of Computing Technology, Chinese Academy of Sciences, China","2009 Eighth International Symposium on Natural Language Processing","20091201","2009","","","4","4","Summary form only given. This talk gives a comprehensive introduction on Chinese word segmentation (CWS) technologies. The problem and difficulty of CWS will be introduced firstly. Then various CWS methods will be given, which include dictionary-based CWS, generative CWS models, discriminative CWS models, and unsupervised CWS methods. Applications of CWS in information retrieval and machine translation will also be discussed.","","POD:978-1-4244-4138-9","10.1109/SNLP.2009.5340949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340949","","Computers;Information retrieval;Natural language processing","information retrieval;language translation;natural language processing;word processing","Chinese word segmentation technology;dictionary-based Chinese word segmentation;information retrieval;machine translation;unsupervised Chinese word segmentation method","","1","","","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"An automatic indexing technique for Thai texts using frequent max substring","T. Chumwatana; K. W. Wong; H. Xie","School of Information Technology Murdoch University, South St, Murdoch Western Australia 6150","2009 Eighth International Symposium on Natural Language Processing","20091201","2009","","","67","72","Thai language is considered as a non-segmented language where words are a string of symbols without explicit word boundaries, and also the structure of written Thai language is highly ambiguous. This problem causes an indexing technique has become a main issue in Thai text retrieval. To construct an inverted index for Thai texts, an index terms extraction technique is usually required to segment texts into index term schemes. Although index terms can be specified manually by experts, this process is very time consuming and labor-intensive. Word segmentation is one of the many techniques that are used to automatically extract index terms from Thai texts. However, most of the word segmentation techniques require linguistic knowledge and the preparation of these approaches is time consuming. An n-gram based approach is another automatic index terms extraction method that is often used as indexing technique for Asian languages including Thai. This approach is language independent which does not require any linguistic knowledge or dictionary. Although the n-gram approach out performs many indexing techniques for Asian languages in term of retrieval effectiveness, the disadvantage of n-gram approach is it suffers from large storage space and long retrieval time. In this paper we present the frequent max substring mining to extract index terms from Thai texts. Our method is language-independent and it does not rely on any dictionary or language grammatical knowledge. Frequent max substring mining is based on text mining that describes a process of discovering useful information or knowledge from unstructured texts. This approach uses the analysis of frequent max substring sets to extract all long and frequently-occurred substrings. We aim to employ the frequent max substring mining algorithm to address the drawback of n-gram based approach by keeping only frequent max substrings to reduce disk space requirement for storing index terms and to reduce the retrieval time in or- der to deal with the rapid growth of Thai texts.","","POD:978-1-4244-4138-9","10.1109/SNLP.2009.5340946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340946","","Data mining;Dictionaries;Frequency;Information retrieval;Machine assisted indexing;Machine learning;Natural language processing;Natural languages;Text mining","data mining;indexing;information retrieval;natural language processing;text analysis","Asian language;Thai text retrieval;automatic indexing technique;dictionary;frequent max substring mining;index term extraction technique;knowledge discovery;language-independent method;linguistic knowledge;n-gram based approach;nonsegmented language;text mining;text segmentation;word segmentation","","3","","30","","","20-22 Oct. 2009","","IEEE","IEEE Conference Publications"
"An interactive evolutionary approach for content based image retrieval","M. Arevalillo-Herráez; F. J. Ferri; S. Moreno-Picot","Departament d'Inform&#224;tica, Universitat de Val&#232;ncia, Dr Moliner, 50 46100 Burjassot, Spain","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","120","125","Content based image retrieval (CBIR) systems aim to provide a means to find pictures in large repositories without using any other information except its contents usually as low-level descriptors. Since these descriptors do not exactly match the high level semantics of the image, assessing perceptual similarity between two pictures using only their feature vectors is not a trivial task. In fact, the ability of a system to induce high level semantic concepts from the feature vector of an image is one of the aspects which most influences its performance. This paper describes a CBIR algorithm which combines relevance feedback, evolutionary computation concepts and ad-hoc strategies in an attempt to fill the existing gap between the high level semantic content of the images and the information provided by the low level descriptors.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346135","","Computational modeling;Content based retrieval;Cybernetics;Evolutionary computation;Feedback;Genetic algorithms;Genetic mutations;Image retrieval;Information retrieval;Support vector machines","content-based retrieval;evolutionary computation;feature extraction;image representation;image retrieval;relevance feedback","CBIR system;ad-hoc strategy;content based image retrieval;feature vector;high level semantic content;interactive evolutionary approach;perceptual similarity;relevance feedback","","2","","25","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Evaluation of Persian text based on Huffman data compression","O. Jalilian; A. T. Haghighat; A. Rezvanian","Islamic Azad University, Hamedan branch, Iran","2009 XXII International Symposium on Information, Communication and Automation Technologies","20091204","2009","","","1","5","According to the growth of information sources in recent years along the Web, many of Web servers have been dedicated to the information sources storage. Until yet many methods are presented for storing and transforming information on the Web in the case of paralleling or processing. But one of the researcher's challenges in derivation and restoring data in data mining and information retrievals are to face to this huge amount of information for storing. One of the solutions of this problem is compression of information resources. Notice that the published statistics, Persian language is one of the oldest and the most diffused languages all around the world and Web and also according to its kind of alphabets and variety along the Persian texts, an evaluation on compression for Persian texts will be useful. First of all in this paper variety difficulties and huge amount of information on the Web, general aspects of Huffman compression methods are introduced, and also some features of Persian language. The state of choosing Persian texts collections has been investigated and the result of tests in compare with some experimental datasets form Persian, English and Arabic were shown. The experimental results are given at the end of paper.","","POD:978-1-4244-4220-1","10.1109/ICAT.2009.5348434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5348434","Data mining;Huffman data compression;Persian language;Persian texts compression;Persian web;Text compression;component","Data compression;Data mining;Huffman coding;Image coding;Information resources;Information retrieval;Natural languages;Statistics;Testing;Web server","Huffman codes;Internet;data compression;natural language processing;statistical analysis;text analysis","Huffman data compression;Persian language;Persian text evaluation;Web server;data mining;information retrieval;information source;statistics","","2","","14","","","29-31 Oct. 2009","","IEEE","IEEE Conference Publications"
"An Image Index Algorithm Based on Hierarchical Clustering","T. Yang; H. Xu","Sch. of Comput. & Inf. Technol., Beijing Jiaotong Univ., Beijing, China","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","459","462","Along with the rapid development of multimedia technology and network technology, building an indexing structure in image information retrieval becomes a very challenging issue. In this paper, we analyze a cluster-based index approach-CLIMB, and also propose a novel idea of this index structure which called CBC-Tree. The clustering information is saved to the index file and also B+ tree is used to retrieve the last level of CBC-Tree. While combining the retrieval ability of B+ tree and CBC-Tree together, the efficiency of image retrieval is improved. Our experiment results show that the improved indexing structure is efficient.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337606","","Clustering algorithms;Clustering methods;Image retrieval;Indexing;Information retrieval;Information technology;Intelligent networks;Intelligent structures;Partitioning algorithms;Signal processing algorithms","database indexing;image retrieval;pattern clustering;tree data structures;visual databases","B+ tree;CBC-tree structure;CLIMB;hierarchical clustering;image index algorithm;image information retrieval;multimedia technology;network technology","","0","","13","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"An integrated intelligent system for estimating and updating a large-size matrix","T. Yu","Centre of Integrated Sustainability Analysis, Physics Building A28, University of Sydney, NSW 2006, Australia","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","3066","3070","This paper presents an integrated intelligent system being capable of automatically estimating and updating a large-size matrix. In the theoretical economics, the input-output model of economics uses a matrix representation of a nation's (or a region's) economy to predict the effect of changes in one industry on others and by consumers, government, and foreign suppliers on the economy. The system in this paper aims to estimate the large-size input-output model and consists of a series of components with the purposes of data retrieval, data integration, data analysis, and quality checking. This unique system is able to interpret and follow users' XML-based query scripts, retrieve data from various sources and integrate them for the following data mining components. The data mining component is based on a unique modelling algorithm which constructs the matrix from the historical data and the spatial data simultaneously. This unique data analysis algorithm runs over the parallel computer to enable the system to estimate a matrix of the size up to 3700-by-3700. The result demonstrates the acceptable accuracy by comparing a part of the multipliers with the corresponding multipliers calculated by the matrix constructed by the surveys.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5345936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345936","","Australia;Data analysis;Data mining;Economic forecasting;Government;Industrial economics;Information retrieval;Intelligent structures;Intelligent systems;Predictive models","XML;data analysis;data mining;economics;information retrieval;matrix algebra","XML-based query scripts;data analysis;data integration;data mining;data retrieval;input-output economics model;integrated intelligent system;large-size matrix estimation;matrix representation;quality checking","","0","","6","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"PADMA Database: Pathogen Associated Drosophila MicroArray Database","A. Kawaguchi; A. Mondal; N. Montesdeoca; S. Govind; M. J. Lee","Comput. Sci. Dept., City Coll. of New York, New York, NY, USA","2009 International Conference on Computing, Engineering and Information","20091117","2009","","","63","66","We present the development of new database, called PADMA, for easy retrieval of genes whose expression is altered by parasitoid infections. The database also houses gene expression data sets from Drosophila blood cells after immune activation. The PADMA system will allow a user to compare genes whose expression is altered after infection by a single or multiple pathogens. Such capability is not publicly available to the Drosophila research community. The PADMA system is currently being tested in-house for public release. We describe the motivation for this research and a detailed account on the design of the database to promote data sharing among users and applications in the context of genome biology.","","POD:978-0-7695-3538-8","10.1109/ICC.2009.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5328928","biology data-warehouse;biology database;drosophila gene data;drosophila microarray;gene database","Bioinformatics;Blood;Cells (biology);Databases;Gene expression;Genomics;Immune system;Information retrieval;Pathogens;System testing","genomics;information retrieval;medical information systems","Drosophila blood cells;PADMA database;data retrieval;data sharing;gene expression;genome biology;pathogen associated Drosophila microarray database","","0","","13","","","2-4 April 2009","","IEEE","IEEE Conference Publications"
"The Role of Clustering in Search Computing","A. Campi; S. Ronchi","Dipt. di Elettron. e Inf., Politec. di Milano, Milan, Italy","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","432","436","This paper proposes a novel language in order to explore the results retrieved by several internet search services and search engines that cluster retrieved documents. The goal of this work, rooted in the new context of Search Computing, is to offer users a tool to discover relevant hidden relationships between clustered documents. When the same query is submitted to distinct search services, they may produce partially overlapped clustered results, where clusters identified by distinct labels collect some common documents. Moreover, clusters with similar labels, but containing distinct documents, may be produced as well. In such a situation, it may be useful to compare, combine, and rank the cluster contents, to filter out relevant documents. The proposed language is composed of several operators that can be used in order to combine groups of clusters.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337277","","Databases;Expert systems;Filters;Hospitals;Information retrieval;Proposals;Search engines;Visualization;Web and internet services;Web pages","Internet;document handling;information retrieval;search engines","Internet search service;document clustering;document retrieval;search computing;search engines","","1","","14","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Learning to rank for web image retrieval based on genetic programming","L. Piji; M. Jun","School of Computer Science & Technology Shandong University, Jinan, 250101, China","2009 2nd IEEE International Conference on Broadband Network & Multimedia Technology","20091204","2009","","","137","142","Ranking is a crucial task in information retrieval systems. This paper proposes a novel ranking model named WIRank, which employs a layered genetic programming architecture to automatically generate an effective ranking function, by combining various types of evidences in Web image retrieval, including text information, image-based features and link structure analysis. This paper also introduces a new significant feature to represent images: Temporal information, which is rarely utilized in the current information retrieval systems and applications. The experimental results show that the proposed algorithms are capable of learning effective ranking functions for Web image retrieval. Significant improvement in relevancy obtained, in comparison to some other well-known ranking techniques, in terms of MAP, NDCG@n and D@n.","","POD:978-1-4244-4590-5","10.1109/ICBNMT.2009.5348465","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5348465","Web image retrieval;genetic programming;graph theory;ranking function;temporal information","Computer science;Content based retrieval;Genetic mutations;Genetic programming;Image analysis;Image retrieval;Information analysis;Information retrieval;Machine learning;Search engines","Internet;genetic algorithms;graph theory;image retrieval;text analysis","WIRank;Web image retrieval;genetic programming;graph theory;image-based feature;information retrieval system;link structure analysis;ranking;temporal information;text information","","0","","10","","","18-20 Oct. 2009","","IEEE","IEEE Conference Publications"
"Factorial Scaled Hidden Markov Model for polyphonic audio representation and source separation","A. Ozerov; C. Févotte; M. Charbit","Institut Telecom, Telecom ParisTech, CNRS LTCI, 37-39, rue Dareau, 75014, France","2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics","20091204","2009","","","121","124","We present a new probabilistic model for polyphonic audio termed factorial scaled hidden Markov model (FS-HMM), which generalizes several existing models, notably the Gaussian scaled mixture model and the Itakura-Saito nonnegative matrix factorization (NMF) model. We describe two expectation-maximization (EM) algorithms for maximum likelihood estimation, which differ by the choice of complete data set. The second EM algorithm, based on a reduced complete data set and multiplicative updates inspired from NMF methodology, exhibits much faster convergence. We consider the FS-HMM in different configurations for the difficult problem of speech/music separation from a single channel and report satisfying results.","1931-1168;19311168","POD:978-1-4244-3678-1","10.1109/ASPAA.2009.5346527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346527","Factorial hidden Markov model;Gaussian scaled mixture models;audio source separation;expectation-maximization algorithm;nonnegative matrix factorization","Acoustic signal processing;Conferences;Convergence;Hidden Markov models;Maximum likelihood estimation;Music information retrieval;Signal processing algorithms;Source separation;Speech;Telecommunications","audio signal processing;expectation-maximisation algorithm;hidden Markov models;signal representation;source separation","Gaussian scaled mixture model;Itakura-Saito nonnegative matrix factorization model;expectation-maximization algorithm;factorial scaled hidden Markov model;maximum likelihood estimation;polyphonic audio;polyphonic audio representation;source separation;speech-music separation","","33","2","12","","","18-21 Oct. 2009","","IEEE","IEEE Conference Publications"
"Dominant Color Embedded Markov Chain Model for Object Image Retrieval","T. T. Zin; P. Tin; T. Toriu; H. Hama","Grad. Sch. of Eng., Osaka City Univ., Osaka, Japan","2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20091117","2009","","","186","189","This paper proposes a new and compact method for object image retrieval fusing Dominant Colors (DCs) and embedded Markov chain concepts. This proposed method uses combined color-texture features which are characterized in terms of their spatial interaction or interrelationship properties, modeled by means of a set of embedded Markov chains, each associated with a major spatial direction. Specifically, DCs are extracted from the object image, which are encountered pixelwise along a given direction to form an embedded Markov chain. Normalizing the resultant Markov chains over all specified directions, the corresponding stationary distribution is derived and served as Markov Feature-Vector (MFV). We then employ the chi square distance between the feature vectors in comparing similarity of images. The MFV involves spatial structure information of both within and between dominant color regions. Moreover, it keeps simplicity, compactness, efficiency, and robustness. We conduct experiments using a comprehensive set of images including both within and between dominant color regions. Moreover, it keeps simplicity, compactness, efficiency, and robustness. We conduct experiments using a comprehensive set of images including deformable shapes. Experimental results show that the proposed method can retrieve an important number of correct images with very high accuracy while the mismatch ratio remains constant.deformable shapes. Experimental results show that the proposed method can retrieve an important number of correct images with very high accuracy while the mismatch ratio remains constant.","","POD:978-1-4244-4717-6","10.1109/IIH-MSP.2009.281","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337350","","Color;Content based retrieval;Distributed control;Histograms;Image databases;Image retrieval;Indexing;Information retrieval;Shape;Spatial databases","Markov processes;image retrieval;image texture","Markov feature-vector;chi square distance;combined color-texture features;dominant color embedded Markov chain model;image similarity;mismatch ratio;object image retrieval fusing dominant colors;spatial interaction","","3","","14","","","12-14 Sept. 2009","","IEEE","IEEE Conference Publications"
"A linear hashing enabling efficient retrieval for range queries","K. Higuchi; T. Tsuji","Graduate School of Engineering, University of Fukui, Fukui-shi, Japan","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","4557","4562","For efficient retrieval of data, design of the data structuring is important. Tree structures and hash tables are popular data structures. A hash table is a simple data structure and it can be retrieved very fast for an exact match query. But for a range query, the hashing scheme is necessary to search much more data blocks than other data structures. In this paper, in order to overcome this problem, the order-preserving linear hashing scheme is proposed. This hashing scheme is based on linear hashing which uses specific hash function enabling efficient retrieval for range queries. By comparing the proposed hashing scheme with the traditional linear hashing scheme, our scheme proves to provide better retrieval time for range queries.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346783","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346783","dynamic hashing;linear hashing;range query","Cybernetics;Data engineering;Data structures;Delay;Design engineering;Dynamic range;Information retrieval;Tree data structures;USA Councils;Upper bound","file organisation;query formulation;tree data structures","hash table;match query;order preserving linear hashing scheme;range query;tree data structure design","","0","","10","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Interoperability of SCADA system applications with Web services","A. Lipnickas; R. Rutkauskas; R. Cerkauskas","Department of Control Technology, Kaunas University of Technology, Student&#191; str. 48-105, Kaunas, Lithuania","2009 IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications","20091201","2009","","","196","200","This paper describes the methodic of three-tier client-server architecture implementation for Web service creation. Data from SCADA system application are dynamically loaded to database by implementing ODBC method. For acceleration of data retrieving the parameters from SCADA application are transmitted to procedure that is stored in DB server. This stored procedure exports SCADA data to XML. DB interacts with Web server in XML. SOAP protocol is used for messaging with Web service client browser. The sequence of programming steps for interoperability with concrete Web service, which visualizes data, is shown.","","POD:978-1-4244-4901-9","10.1109/IDAACS.2009.5342997","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342997","SCADA;SOAP;Web services;XML;automation","Acceleration;Concrete;Databases;Information retrieval;SCADA systems;Service oriented architecture;Simple object access protocol;Web server;Web services;XML","SCADA systems;Web services;client-server systems;control engineering computing;open systems;protocols","SCADA system;SOAP protocol;Web server;Web service client browser;XML;data retrieval;data visualization;interoperability;supervisory control and data acquisition systems;three-tier client-server architecture","","2","","7","","","21-23 Sept. 2009","","IEEE","IEEE Conference Publications"
"An Architecture for Finding Entities on the Web","G. Demartini; C. S. Firan; M. Georgescu; T. Iofciu; R. Krestel; W. Nejdl","L3S Res. Center, Univ. of Hanover, Hanover, Germany","2009 Latin American Web Congress","20091201","2009","","","230","237","Recent progress in research fields such as information extraction and information retrieval enables the creation of systems providing better search experiences to Web users. For example, systems that retrieve entities instead of just documents have been built. In this paper we present an approach for large-scale entity retrieval using Web collections as underlying corpus. We propose an architecture for entity extraction and entity ranking starting from Web documents. This is obtained (1) using an existing Web document index and (2) creating an entity centric index. We describe advantages and feasibility of our approach using state-of-the-art tools.","","Paper:978-0-7695-3856-3","10.1109/LA-WEB.2009.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341521","entity retrieval;natural language processing;web search","Data mining;Erbium;Image retrieval;Information retrieval;Natural language processing;Search engines;Service oriented architecture;Web pages;Web search;Wikipedia","Internet;document handling;information retrieval","Web collections;Web document index;Web documents;World Wide Web;entity centric index;entity extraction;entity ranking;information extraction;information retrieval;large-scale entity retrieval","","0","","24","","","9-11 Nov. 2009","","IEEE","IEEE Conference Publications"
"Religious Portrait Thangka Image Retrieval Based on Gesture Feature","J. Qian; W. Wang","Inf. Technol. Inst., Northwest Univ. for Nat., Lanzhou, China","2009 Chinese Conference on Pattern Recognition","20091204","2009","","","1","5","This paper proposed a novel method for religious portrait Thangka image retrieval based on gesture feature. Firstly, adopt the method of TPLR (two point locate rule) which we propose to annotate gesture of images that will be saved to image database, extract gesture features which are represented in a quintuple vector to store in characteristic library; Secondly, the same task such as gesture annotation, feature extraction, in the process of image retrieval to be treated to the retrieved image, then compute similarity between sample image and the image of image database using the algorithm this paper presented; Finally, we apply the method of ITFA (interval threshold filter algorithm) to obtain the final retrieval result. The experiments show that the proposed algorithm can retrieve the similar images well and efficient.","","POD:978-1-4244-4199-0","10.1109/CCPR.2009.5344033","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344033","","Art;Content based retrieval;Feature extraction;Filters;History;Image databases;Image retrieval;Information retrieval;Painting;Shape","feature extraction;filtering theory;gesture recognition;image retrieval;image segmentation","ITFA;TPLR;gesture feature extraction;image annotation;image database;interval threshold filter algorithm;quintuple vector;religious portrait Thangka image retrieval;two point locate rule","","3","","9","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
"Providing adaptive support in computer supported collaboration environments","Kinshuk; Y. Sakurai; K. Takada; S. Graf; A. Zarypolla; S. Tsuruta","School of Computing and Information Systems, Athabasca University Alberta, Canada","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","1304","1309","Many misunderstandings can occur during remote interaction due to different user domain competency levels, different cognitive capacity of users as well as different user backgrounds. In this paper, we propose an adaptive keyword/summary presentation approach that aims at identifying potential misunderstandings of individual users and provide these users with effective and personalized content of the current discussion. Our approach is developed for virtual worlds and tested and implemented based on the Wonderland Project. In order to evaluate our approach, a practical scenario has been designed and tested, which demonstrates how the system enriches the cyberspace for collaboration by making adaptive use of keyword/summary presentation.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346236","Adaptive;collaboration;cyberspace;keyword/summary;misunderstandings","Avatars;Biosensors;Collaborative tools;Collaborative work;Cybernetics;Information retrieval;Information systems;International collaboration;Remote monitoring;USA Councils","groupware;personal information systems;user interfaces;virtual reality","Wonderland Project;adaptive keyword-summary presentation approach;computer supported collaboration environments;virtual worlds","","5","","9","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Toward Automating Requirements Satisfaction Assessment","E. A. Holbrook; J. H. Hayes; A. Dekhtyar","","2009 17th IEEE International Requirements Engineering Conference","20091117","2009","","","149","158","This paper introduces the automation of satisfaction assessment: the process of determining the satisfaction mapping of natural language textual requirements to natural language design elements. Satisfaction assessment is useful because it assists in discovering unsatisfied requirements early in the lifecycle when such issues can be corrected with lower cost and impact than later. We define the basic terms and concepts for this process and explore the feasibility of developing baseline methods for its automation. This paper describes the satisfaction assessment approach algorithmically and then evaluates the effectiveness of two proposed information retrieval (IR) methods in two industrial studies - one based on a large dataset including a complete requirements specification and design specification for a NASA science instrument, and one based on a smaller dataset for an open source project management dataset. We found that both approaches have merit, and that the more sophisticated approach outperformed the simpler approach in terms of overall accuracy of the results.","1090-705X;1090705X","POD:978-0-7695-3761-0","10.1109/RE.2009.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5328545","Design;Requirements;Satisfaction Assessment;Traceability","Algorithm design and analysis;Costs;Defense industry;Design automation;Design engineering;Frequency;Information retrieval;NASA;Natural languages;Software systems","customer satisfaction;formal specification;formal verification;natural languages;project management;software development management;systems analysis;text analysis","IR method;NASA science instrument;customer satisfaction mapping;design specification;information retrieval method;natural language design element;natural language textual requirements;open source project management dataset;requirements satisfaction assessment automation;requirements specification;software lifecycle","","6","","42","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Relevant document retrieval using a spoken document","A. Ito; Y. Uno; R. Masumura; M. Ito; S. Makino","Graduate School of Engineering, Tohoku University, Sendai, 980-8579 Japan","2009 9th International Symposium on Communications and Information Technology","20091201","2009","","","1483","1488","In this paper, we proposed a method of retrieving documents from the world wide Web using a spoken document as a ldquokey.rdquo This method can be viewed as a speech version of an ordinary relevant document retrieval, where a text document is used as a query of retrieval. Basically the retrieval is based on an automatic transcription of a spoken document using a speech recognizer. The difficult point of this task is that the automatic transcription contains many recognition errors, therefore we cannot trust keywords extracted from the automatic transcription using conventional method such as tfmiddotidf. To solve this problem, we developed three methods. The first one is to measure relevance of a keyword to the spoken document by using Web documents retrieved using a Web search engine by specifying the keyword as a query. The second one is to compose a query from the selected keywords so that words derive from misrecognitions are excluded and similar words are gathered. The third one is to measure relevance of a downloaded Web document to the spoken document. The experimental results suggest that the proposed methods are promising for retrieving relevant documents of a spoken document.","","POD:978-1-4244-4521-9","10.1109/ISCIT.2009.5341051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341051","","Automatic speech recognition;Databases;Indium tin oxide;Information retrieval;Internet;Search engines;Speech recognition;Vocabulary;Web search;Web sites","Internet;information retrieval;search engines","Web search engine;automatic transcription;relevant document retrieval;speech recognizer;spoken document;text document;world wide Web","","3","","20","","","28-30 Sept. 2009","","IEEE","IEEE Conference Publications"
"Collection-Relative Representations: A Unifying View to Retrieval Models","B. Stein; M. Anderka","Fac. of Media, Media Syst., Bauhaus-Univ. Weimar, Weimar, Germany","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","383","387","Various retrieval models have been developed and analyzed so far, but less research aims to an integration of the different models within a common framework. This paper introduces the idea of collection-relative retrieval models, a paradigm where several important retrieval models fit in. Our unifying view helps to better understand retrieval models, and it can be considered as a step towards a common theoretical framework for text retrieval. Collection-relative retrieval models employ a so-called index collection. We present an evaluation that shows how particular characteristics of the underlying index collection affect the retrieval performance of a collection-relative model. Based on such insights tailored index collections can be constructed in order to address specialized retrieval tasks.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337096","Collection-Relative Representations;Retrieval Models","Databases;Expert systems;Guidelines;Heart;Humans;Indexing;Information retrieval;Runtime;Size control;Wikipedia","information retrieval","collection-relative retrieval models;index collection;text retrieval","","0","","14","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"An Unsupervised Approach for the Emergence of Ontologies from Personomies in Tagging-Based Systems","C. A. M. Basso; J. M. P. Ferreira; S. R. P. d. Silva","Dept. de Inf., Univ. Estadual de Maringa, Maringa, Brazil","2009 Latin American Web Congress","20091201","2009","","","193","200","Tagging-based systems are becoming a widely used tool as they are considered simple and quick to categorize resources. However, due to the free vocabulary used for tagging, and also because of its plane structure, there are some drawbacks inherent to this kind of system, mainly when users do the information retrieval. This paper presents a proposal for the emergence of ontologies from tagging-based systems, seeking to reduce information overload, thus minimizing the cognitive effort of users when processing information retrieval.","","Paper:978-0-7695-3856-3","10.1109/LA-WEB.2009.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5341513","Ontology emergence;Personomies;Tagging","Chaos;Information retrieval;Ontologies;Organizing;Proposals;Tag clouds;Tagging;Taxonomy;Vocabulary;Web sites","information retrieval;ontologies (artificial intelligence)","information retrieval;ontologies;personomies;tagging-based systems;vocabulary","","1","","14","","","9-11 Nov. 2009","","IEEE","IEEE Conference Publications"
"A scalable peer-to-peer video-on-demand system with asynchronous transfer","Z. Peng; G. Cheng; Z. Yang; J. Chen","Dept. of Electronics and Information Engineering Huazhong University of Science & Technology Wuhan, Hubei, China","2009 Fourth International Conference on Communications and Networking in China","20091120","2009","","","1","6","Providing Video-on-Demand (VoD) service over the Internet remains to be challenging due to the diversity of client requests and the requirement of high bandwidth. Based on the requirements of high-quality video application, in this paper, we present an unstructured Peer-to-Peer (P2P) VoD system with asynchronous data transfer among peers and centralized directory service. Some new algorithms for choosing supplying peers, caching video data and reducing the workload of centralized server are introduced to relax well-known limitations with asynchronous transfer and centralized directory service. Moreover, a simple incentive is developed to ensure fair share of peer resources. Packet-level simulations show the benefits of the proposed system in terms of playback continuity, launch delay and server stress.","","CD-ROM:978-1-4244-4337-6","10.1109/CHINACOM.2009.5339948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5339948","","Bandwidth;Delay;Information retrieval;Peer to peer computing;Streaming media;Stress;Video recording;Video sharing;Web and internet services;Web server","Internet;client-server systems;peer-to-peer computing;video on demand","Internet;asynchronous data transfer;centralized directory service;centralized server;client requests;fair share;launch delay;packet-level simulations;peer-to-peer video-on-demand system;server stress;video data caching","","0","","11","","","26-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"A collaborative personalized affective video retrieval system","M. Soleymani; J. Davis; T. Pun","Computer Vision and Multimedia Laboratory, Computer Science Department, University of Geneva, Battelle Campus, Building A, Rte. De Drize 7, CH - 1227 Carouge, Geneva, Switzerland","2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops","20091208","2009","","","1","2","In this demonstration, a collaborative personalized affective video retrieval is introduced. A dataset of 155 video clips extracted from Hollywood movies were annotated by the emotion felt by participants. More than 1300 annotations from 40 participants were gathered in a database to be used for affective retrieval system. The retrieval system is able to retrieve videos based on emotional keyword query as well as arousal and valence query. The user's personal profile (gender, age, cultural background) was employed to improve the collaborative filtering in retrieval.","2156-8103;21568103","POD:978-1-4244-4800-5","10.1109/ACII.2009.5349526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349526","","Collaboration;Computer vision;Content based retrieval;Cultural differences;Filtering;Information retrieval;Internet;Motion pictures;Multimedia databases;Multimedia systems","filtering theory;video retrieval","Hollywood movies;collaborative filtering;collaborative personalized affective video retrieval system;emotional keyword query","","6","1","7","","","10-12 Sept. 2009","","IEEE","IEEE Conference Publications"
"Order-based localization scheme in ad hoc sensor networks","Y. H. Chen; S. Y. Yuan; C. H. Ho; S. Y. Kuo","Department of Electrical Engineering National Taiwan University, Taipei, Taiwan","2009 First Asian Himalayas International Conference on Internet","20091124","2009","","","1","5","Most monitoring or tracking applications require the localization information in wireless sensor network. The DV-Hop provides a basic scheme to retrieve the localization without GPS information. DV-Hop scheme only uses the localizations of the reference nodes and the hop-count, so the fundamental estimation may cause the larger error than range-based schemes. The proposed scheme uses the neighbor information to improve the accuracy in the distance estimation. A node finds the orders of its neighbors, and the orders means how close of them. The proposed analysis model reveals the probability distribution of the distance with different orders. According to the analysis model, a node retrieves the distance, called order distance, to provide the approximate location. The simulation results show our scheme outperforms than the DV-Hop in the location accuracy. For example, the average error distance is 1.09 in our scheme and 1.4 in DV-Hop with the average node density 9.42.","1089-7801;10897801","POD:978-1-4244-4569-1","10.1109/AHICI.2009.5340275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5340275","DV-Hop;ad hoc sensor networks;order distance;order-based localization scheme","Communication industry;Global Positioning System;Hardware;Information retrieval;Monitoring;Probability distribution;Sensor phenomena and characterization;Smoothing methods;Time difference of arrival;Wireless sensor networks","ad hoc networks;probability;wireless sensor networks","DV-Hop scheme;ad hoc sensor network;order distance;order-based localization;probability distribution;wireless sensor network","","0","","12","","","3-5 Nov. 2009","","IEEE","IEEE Conference Publications"
"On feature selection in environmental sound recognition","D. Mitrović; M. Zeppelzauer; H. Eidenberger","Vienna University of Technology, Institute of Software Technology and Interactive Systems, Favoritenstrasse 9-11, A-1040, Austria","2009 International Symposium ELMAR","20091201","2009","","","201","204","Given a broad set of content-based audio features, we employ principal component analysis for the composition of an optimal feature set for environmental sounds. We select features based on quantitative data analysis (factor analysis) and conduct retrieval experiments to evaluate the quality of the feature combinations. Retrieval results show that statistical data analysis gives useful hints for feature selection. The experiments show the importance of feature selection in environmental sound recognition.","1334-2630;13342630","POD:978-953-7044-10-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342826","Environtmental Sound Recognition;Feature Selection;Statistical Data Analysis","Cepstral analysis;Data analysis;Fourier transforms;Frequency;Information retrieval;Linear predictive coding;Music information retrieval;Principal component analysis;Spatial databases;Speech recognition","audio signal processing;data analysis;feature extraction;principal component analysis","audio retrieval;content-based audio features;environmental sound recognition;feature combinations;feature selection;optimal feature set;principal component analysis;quantitative data analysis","","0","1","5","","","28-30 Sept. 2009","","IEEE","IEEE Conference Publications"
"A Client-Server Architecture for Context-Aware Search Application","F. Gui; M. Guillen; N. Rishe; A. Barreto; J. Andrian; M. Adjouadi","Center for Adv. Technol. & Educ., Florida Int. Univ., Miami, FL, USA","2009 International Conference on Network-Based Information Systems","20091208","2009","","","539","546","This paper develops a client-side context-aware search application which is built on the context-aware infrastructure. A context-aware architecture is designed to collect the mobile user's context information, derive mobile user's current context, distribute user context among context-aware applications, and support the context-aware applications. The context acquisition is centralized at the context server to ensure the reusability of context information among mobile devices, while context reasoning remains at the application level. Algorithms are proposed to consider the user context profiles. By promoting feedback on the dynamics of the system, prior user selection is now saved for further analysis expediting a subsequent search. A software-based proxy is set up at the client side which includes the context reasoning component. Implementation of such a proxy supports that the context applications are able to derive the user context profiles. To meet the practical demands required of a testing environment, a software simulation using Yahoo search API is provided as a means to evaluate the effectiveness of the design approach in a realistic way. The integration of user context into Yahoo search engines proves how context-aware searches can meet user demands for tailored services and products in and around the user's environment.","2157-0418;21570418","POD:978-1-4244-4746-6","10.1109/NBiS.2009.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349906","Context Awareness;Context Server;Mobile Search;Personalized Search;User Profile","Algorithm design and analysis;Application software;Computer architecture;Computer networks;Context awareness;Context-aware services;Information retrieval;Mobile computing;Network servers;Web search","client-server systems;digital simulation;mobile computing;program testing;search engines;software architecture;software reusability","Yahoo search API;Yahoo search engines;client-server architecture;client-side context-aware search application;context information reusability;context reasoning component;context server;mobile devices;software simulation;software-based proxy;testing environment;user context profiles","","5","2","17","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"Research on Optimize Technology in Latent Semantic Indexing Based on Semantic Block","D. Cai; D. Guo; D. Ji","Knowledge Eng. Res. Center, Shenyang Inst. of Aeronaut. Eng., Shenyang, China","2009 Chinese Conference on Pattern Recognition","20091204","2009","","","1","5","Latent semantic indexing (LSI) is an effective method in the way of dimensionality reduction, which has been applied to many text learning mission, such as text categorization, information retrieval. This paper sufficiently analyses influence of text window toward mapping of latent semantic indexing and bring forward a latent semantic analysis method based on the semantic block which strengthen the term co-occurrences' precise in the text window so as to rationalize mapping of latent semantic indexing. The experimental result shows that this method which is applied to text categorization improves categorization precise in effect.","","POD:978-1-4244-4199-0","10.1109/CCPR.2009.5344024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344024","","Aerospace engineering;Computer interfaces;Delay;Humans;Indexing;Information retrieval;Knowledge engineering;Large scale integration;Text categorization;Tree graphs","data reduction;indexing;text analysis","dimensionality reduction;latent semantic indexing;semantic block;text categorization;text learning;text window","","1","","11","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
"An advanced location based service (A-LBS) on mobile social network","D. Fengyu; G. Xuerong","School of telecommunication education Beijing University of Posts and Telecommunications, Beijing","2009 2nd IEEE International Conference on Broadband Network & Multimedia Technology","20091204","2009","","","740","743","Advances in the innovation about service pattern, and the rapidly growing number of mobile personal devices result in the fast growth of Mobile Social Network Service (MSNS). This paper just analyzes and compares the existing MSNS applications, and proposes the concept of MSNS. In this paper we also concentrate on the realization of the interaction method between the three-dimensional virtual world of the Internet and the human real world, and this service pattern is named as ldquoA-LBSrdquo. The implement of the system platform make users have a possibility to experience the similarly real life in the virtual world. Besides, the application of new technologies, such as Geographic Information System, is also one of the innovation points in the industry of MSNS. Finally, the initial stage of interaction platform has already been proposed and implemented.","","POD:978-1-4244-4590-5","10.1109/ICBNMT.2009.5347780","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5347780","Geographic Information System;Mobile Social Network Service;three-dimensional platform","Displays;Geographic Information Systems;Global Positioning System;Humans;Information retrieval;Land use planning;Resource management;Social network services;Technological innovation;Web and internet services","mobile computing;mobility management (mobile radio)","3D virtual world;Internet;advanced location based service;geographic information system;interaction platform;mobile personal device;mobile social network service pattern","","4","","6","","","18-20 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Video Retrieval Algorithm Based on Affective Features","L. Zhaoming; W. Xiangming; L. Xinqi; Z. Wei","Sch. of Inf. & Telecommun., BUPT, Beijing, China","2009 Ninth IEEE International Conference on Computer and Information Technology","20091117","2009","1","","134","138","One important but often overlooked aspect of human interpretation of multimedia data is the affective information. Affective labels of video content can be extracted automatically from multimedia data streams. These can then be used for content-based retrieval and browsing. In this paper we propose an approach to retrieve the video clips which are similar to the given query in emotion from the video database. We adopt fuzzy representation of video emotion to bridge the semantic gap. Then, we use the cosine measure to compute the similarity between the query video clip and each video clip in database. Ten video clips in database with the highest similarity are output and submitted to the user. And our experiment indicates that the algorithm works well.","","POD:978-0-7695-3836-5","10.1109/CIT.2009.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5329386","cosine measure;emotion types;emotion-based video retrieval;fuzzy representation;sementic gap","Bridges;Content based retrieval;Data mining;Databases;Humans;Indexing;Information retrieval;Layout;Motion pictures;Streaming media","content-based retrieval;fuzzy set theory;query processing;video retrieval","affective features;content-based retrieval;fuzzy representation;multimedia data streams;query video clip;video content;video retrieval algorithm","","0","","16","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Image Retrieval Using Discriminant Embedding and LS-SVM","Z. Wang; X. Sun","Sch. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou, China","2009 Chinese Conference on Pattern Recognition","20091204","2009","","","1","5","To efficiently deal with the curse of dimensionality in the content-based image retrieval (CBIR) system, a novel image retrieval algorithm is proposed by combination of local discriminant embedding (LDE) and least square SVM (LS-SVM) in this paper. LDE aims to achieve good discriminating performance by integrating the local geometrical structure and class relations between image data. LS-SVM classifier is used to classify the retrieved image into relevant or irrelevant image based on extracted low-level visual features. Experimental results on real-world image collection demonstrate that the proposed algorithm performs much better than other related image retrieval algorithms.","","POD:978-1-4244-4199-0","10.1109/CCPR.2009.5344079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5344079","","Content based retrieval;Image retrieval;Information retrieval;Least squares methods;Negative feedback;Principal component analysis;Radio frequency;Search engines;Support vector machine classification;Support vector machines","content-based retrieval;feature extraction;image classification;image retrieval;least squares approximations;support vector machines","CBIR system;LS-SVM classifier;content-based image retrieval;image classification;least square SVM;local discriminant embedding;local geometrical structure;visual feature extraction","","0","","10","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
"Instance-Based Data Management -- Is it Useful for Biodiversity Informatics Applications?","J. Parsons","Fac. of Bus. Adm., Memorial Univ. of Newfoundland, St. John's, NL, Canada","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","355","359","Traditional data models explicitly or implicitly assume that data are organized according to a single, ""correct"" classification scheme. However, there is increasing recognition that biological and other phenomena can be classified in multiple ways to accommodate varying perspectives. In this context, we review an approach to instance-based data modeling that might be useful for managing biodiversity-related data. We examine how data can be represented to support multiple classifications, and highlight a novel SQL-like query language to support information retrieval in instance-based databases. We conclude by speculating briefly on the potential use of this model to support the data requirements of biodiversity applications.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337111","classification;data modeling;query language","Biodiversity;Bioinformatics;Biological system modeling;Data models;Database languages;Expert systems;Humans;Informatics;Information retrieval;Relational databases","biology computing;classification;data models;database management systems;information retrieval;query languages","SQL-like query language;biodiversity informatics applications;biodiversity-related data;biological classification;data models;information retrieval;instance-based data management;instance-based data modeling;instance-based databases","","1","","16","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Study on feature selection in finance text categorization","C. Sun; X. Wang; J. Xu","Department of Computer Science and Technology, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","5077","5082","Document genre information is one of the most distinguishing features in information retrieval, which brings order to the search results. What the genre classification concerned is not the topic but the genre of document. In this paper, two different feature sets were employed: bag of words which are derived by feature selection method and structural features which are selected manually and subjectively. And a comparative study on feature selection in genre classification of Chinese finance text is presented. In empirical results with classifiers on the real world corpora, we find that those manual labeled features can improve the performance clearly.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346030","Feature Selection;Genre Classification;Text Categorization","Computer science;Cybernetics;Feature extraction;Finance;IEEE news;Information retrieval;Search engines;Sun;Text categorization;World Wide Web","classification;financial data processing;information retrieval;text analysis","document genre information;feature selection;finance text categorization;information retrieval;structural feature","","0","","16","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Note detection with dynamic bayesian networks as a postanalysis step for NMF-based multiple pitch estimation techniques","S. A. Raczyński; N. Ono; S. Sagayama","The University of Tokyo, Graduate School of Information Science and Technology, 7-3-1, Hongo, Bunkyo-ku, 113-8656 Japan","2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics","20091204","2009","","","49","52","In this paper we present a method for detecting note events in the note activity matrix obtained with Nonnegative Matrix Factorization, currently the most common method for multipitch analysis. Postprocessing of this matrix is usually neglected by other authors, who use a simple thresholding, often paired with additional heuristics. We propose a theoretically-grounded probabilistic model and obtain very promising results due to the fact that it was able to capture basic musicological information. The biggest advantage of our approach is that it can be extended without much effort to include various information about musical signals, such as principles of tonality and rhythm.","1931-1168;19311168","POD:978-1-4244-3678-1","10.1109/ASPAA.2009.5346507","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346507","Dynamic Bayesian Networks;Nonnegative Matrix Factorization;multipitch analysis;note detection","Acoustic signal processing;Bayesian methods;Conferences;Event detection;Hidden Markov models;Information analysis;Matrix decomposition;Music information retrieval;Signal analysis;Vectors","acoustic signal processing;estimation theory;matrix decomposition;musical acoustics","dynamic Bayesian network;multipitch analysis;multiple pitch estimation technique;musical signal;musicological information;nonnegative matrix factorization;note activity matrix;note detection;rhythm;theoretically-grounded probabilistic model;tonality","","0","","13","","","18-21 Oct. 2009","","IEEE","IEEE Conference Publications"
"Fuzzy object retrieval by using histogram of fuzzy Allen relations","N. Salamat; E. h. Zahzah","MIA laboratory, University of La Rochelle, Avenue M. Crepeau, La Rochelle 17042, France","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","3854","3859","Relative position of object description are widely used in event understanding and computer vision tasks especially in object recognition. Use of low level features cannot give satisfactory results when high level concepts is not easily expressible in low level contents. Mostly researchers are concentrating on spatio- temporal relationship between objects or regions of an object in images. Object retrieval which is taken into account the relative position of objects in images become important. In such a case classical Allen relations are used. Searched object can take various shapes and scale according to shooting. Fuzzy methods have the ability to compensate the imprecise informations and vagueness. In this paper fuzzy histograms of Allen relations are used for object retrieval. Fuzzy histograms of Allen relations are the quantitative representation of relative object position. For this purpose Matsakis's [9] algorithm for fuzzification of line segments is refined. This representation is affine invariant. Query is made by example and only corresponding relative relation between objects is considered. Results are analyzed by a well known receiver operating characteristic curve (ROC)method.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346610","Fuzzy Allen Relations;Histogram Comparison;Object Retrieval;Quantitative Representation","Content based retrieval;Fuzzy systems;Histograms;Image databases;Image retrieval;Image storage;Information retrieval;Laboratories;Layout;Shape","computer vision;content-based retrieval;fuzzy set theory;image retrieval;object recognition;statistical analysis","Content-based image retrieval;computer vision;fuzzy Allen relation;fuzzy object retrieval;histogram analysis;object position;object recognition;quantitative representation;spatio-temporal relationship","","0","","15","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Flexible Data Warehousing Approach for One-Stop Querying on Heterogeneous Personal Information","M. Zhong; M. Liu","Sch. of Comput., Wuhan Univ., Wuhan, China","2009 20th International Workshop on Database and Expert Systems Application","20091117","2009","","","412","416","This paper presents a flexible data warehousing approach which allows one-stop querying on entire personal information residing at heterogeneous data sources. Different from previous work that requires expensive and error-prone semantic integration, our approach aims to construct personal dataspaces for users. In our approach, personal data are uniformly represented in a single data model proposed in this paper, and stored in a data warehousing system based on a storage model corresponding to the data model. Then, users are enabled to easily retrieve all their personal information by using keywords or a semi-structured query language.","1529-4188;15294188","POD:978-0-7695-3763-4","10.1109/DEXA.2009.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337079","data warehouse;dataspace;keyword proximity search;personal information management;semi-structured search","Application software;Computer errors;Data models;Database languages;Electronic mail;Expert systems;Information retrieval;Search engines;Warehousing;Web pages","data models;data warehouses;personal information systems;query processing","data model;error-prone semantic integration;flexible data warehousing approach;heterogeneous personal information;one-stop querying;personal dataspaces;personal information retrieval;semi-structured query language;storage model","","0","","12","","","Aug. 31 2009-Sept. 4 2009","","IEEE","IEEE Conference Publications"
"Efficient entropy-based features selection for image retrieval","T. W. Chang; Y. P. Huang; F. E. Sandnes","Department of Computer Science and Information Engineering, De Lin Institute of Technology, Tucheng, Taipei County, 236 Taiwan","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","2941","2946","Information retrieval systems should provide users quick access to desired information. There are no established ways for inexperienced users to explicitly express queries for retrieving images from ecological databases. This study proposes an entropy-based feature selection strategy for finding images of interest from databases. Six visual features are used to represent birds, and hence used to formulate search queries. The proposed method is tested on a real world bird database and the experimental results demonstrate the effectiveness of the presented work.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346032","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346032","content-based image retrieval;entropy;feature selection","Birds;Content based retrieval;Cybernetics;Feature extraction;Image databases;Image retrieval;Information retrieval;Ontologies;Spatial databases;Visual databases","entropy;image retrieval;query processing","birds;ecological databases;entropy;features selection;image retrieval;information retrieval systems;queries","","3","","15","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Neighbor-Based Detection Scheme for wireless sensor networks against node replication attacks","L. C. Ko; H. Y. Chen; G. R. Lin","Industrial Technology Research Institute (ITRI), Hsinchu, Taiwan, R.O.C.","2009 International Conference on Ultra Modern Telecommunications & Workshops","20091204","2009","","","1","6","Most of sensor network applications rely on deploying large amount of sensor nodes in unattended areas, leaving sensor nods suffer from node capture attacks in which the adversary compromises the node and retrieves secret information from the node. Moreover, the adversary can launch node replication attacks or clone attacks by loading secret information into several replicated nodes and rejoining these nodes to execute malicious behaviors or subvert underlying protocols. In this paper we propose a neighbor-based detection scheme (NBDS) to counteract node replication attacks. Compare with previous distributed schemes that periodically detect replicated nodes, NBDS not only provides near real-time detection but also achieves lower communication and memory costs. Further, the probability of detecting replicated nodes in NBDS is much higher than previous schemes.","2157-0221;21570221","POD:978-1-4244-3942-3","10.1109/ICUMT.2009.5345637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345637","Distributed detection;Node clone attacks;Node replication attacks;WSN security","Broadcasting;Cloning;Costs;Information retrieval;Phase detection;Protocols;Routing;Security;Temperature sensors;Wireless sensor networks","protocols;telecommunication security;wireless sensor networks","neighbor-based detection scheme;node replication attacks;wireless sensor networks","","5","","21","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
