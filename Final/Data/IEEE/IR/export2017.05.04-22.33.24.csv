"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5712030,5545401,5711740,5707266,5707258,5706654,5708732,5708628,5706749,5708414,5709160,5707167,5706588,5709184,5709328,5708462,5709365,5708464,5706846,5708901,5708875,5708446,5708738,5708728,5707040,5708438,5698391,5706211,5705844,5705787,5706190,5704879,5705886,5704958,5703845,5703948,5703796,5704074,5703848,5704116,5704399,5704337,5704097,5703835,5704085,5703905,5701888,5704405,5700854,5700853,5700851,5700880,5692921,5694005,5693897,5693322,5694008,5693916,5696223,5693213,5696512,5694493,5694059,5693409,5693529,5695466,5696360,5698491,5693432,5693978,5693321,5694475,5695480,5699426,5698490,5693370,5694085,5693299,5689588,5687655,5688932,5689532,5689627,5687724,5689665,5692734,5610728,5662276,5663510,5687201,5663525,5688008,5663511,5662318,5687468,5662647,5687428,5475278,5687963,5663519",2017/05/04 22:33:24
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Profit of extending standard relational databases with the Intelligent Cluster Index (ICIx)","S. Leuoth; A. Adam; W. Benn","Dimensio informatics GmbH, Development Division 09111 Chemnitz, Germany","2010 11th International Conference on Control Automation Robotics & Vision","20110204","2010","","","1198","1205","In this paper, we present a strategy to reduce the processing time needed for selection operations with many attributes in standard database systems. These problems mostly occur in data mining, data analysis, information retrieval, and applications with high combinatorial complexity. In these systems, standard indexes do not gain a satisfying performance. Currently, this problem is tackled using more computing power or special solutions instead of standard databases. Our approach is to interpret the queries as high-dimensional point or range queries. Thus, we provide a “real” solution to answering complex queries rather than merely postponing the problems using technical methods. We show the benefit of multidimensional data structures. This benefit can be transferred to a lot of applications (e.g. Business Intelligence, Bill Of Materials Explosion, DNA Sequence Search), not only advanced applications of database systems like GIS, CAD, or multimedia. Finally, a very small sample data set is used to show the profit of our approach and we present possible integration points of the ICIx into standard relational database.","","Electronic:978-1-4244-7815-6; POD:978-1-4244-7814-9","10.1109/ICARCV.2010.5707266","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5707266","Content-Based Indexing;ICIx;Multi-Dimensional Index;Query Processing","Indexing;Relational databases;Time factors;Transforms","data structures;pattern clustering;query processing;question answering (information retrieval);relational databases","combinatorial complexity;complex query answering;data analysis;data mining;information retrieval;intelligent cluster index;multidimensional data structures;query processing;standard relational database","","0","","32","","","7-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"A hybrid computational model for spoken language understanding","G. Huang; M. J. Er","School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore","2010 11th International Conference on Control Automation Robotics & Vision","20110204","2010","","","2078","2083","This paper shows that the integration of statistical and connectionist methods can greatly enhance human-computer interaction through speech. The research approach is inspired by recent advances in high performance automatic speech recognition (ASR) systems and neurocognitive researches of natural language understanding (NLU). And a modest hybrid computational model is proposed and implemented to achieve intelligent spoken language understanding (SLU) in an information retrieval system.","","Electronic:978-1-4244-7815-6; POD:978-1-4244-7814-9","10.1109/ICARCV.2010.5707258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5707258","Human-computer interaction;natural language understanding;speech recognition;spoken language understanding","Acoustics;Computational modeling;Hidden Markov models;Semantics;Speech;Speech recognition;Syntactics","cognitive systems;human computer interaction;information retrieval;natural language processing;speech recognition;statistical analysis","automatic speech recognition system;human computer interaction;hybrid computational model;information retrieval system;intelligent spoken language understanding;natural language understanding;neurocognitive research;statistical methods","","0","","27","","","7-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"Anubis: An attestation protocol for distributed context-aware applications","S. Buthpitiya; F. T. Sun; H. T. Cheng; P. Tague; M. Griss; A. K. Dey","Department of Electrical and Computer Engineering, Carnegie Mellon University, 5000 Forbes Ave., Pittsburgh, PA, USA","2010 Sixth International Conference on Intelligent Sensors, Sensor Networks and Information Processing","20110204","2010","","","251","256","Sharing sensitive context information among multiple distributed components in mobile environments introduces major security concerns. The distributed sensing, processing and actuating components of these applications can be compromised and modified or impersonated to extract private and confidential information or to inject false information. In this paper we present the Anubis protocol for remote code attestation and access control of distributed components using remote execution of trusted code. Our Anubis protocol leverages previous work in the fields of wireless sensor networks and secure web-browsing. Anubis allows new components to be introduced to the environment without updating existing components. Our implementation of Anubis in Android G1 based applications shows that the protocol introduces manageable overhead (less than 600 ms latency and 35 kB packet overhead) which does not significantly impact the user experience.","","Electronic:978-1-4244-7177-5; POD:978-1-4244-7174-4","10.1109/ISSNIP.2010.5706749","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706749","","Authentication;Computational modeling;Context;Protocols;Public key;Servers","authorisation;cryptographic protocols;information retrieval;mobile computing;operating systems (computers);peer-to-peer computing;wireless sensor networks","Android Gl based application;Anubis protocol;access control;attestation protocol;confidential information extraction;distributed context-aware application;distributed sensing;private information extraction;remote code attestation;secure Web-browsing;sensitive context information sharing;wireless sensor networks","","1","","17","","","7-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"A general search method based on social communities in P2P networks","Mo Hai; Shuhang Guo","School of Information, Central University of Finance and Economics, Beijing, China","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","1","","547","551","With the increase of the amount of information stored in P2P networks, how to search the information satisfying users' needs efficiently becomes very important. Current researches on search algorithms focus on increasing search efficiency(measured by the length of routing path) or decreasing search cost(measured by the number of messages) at the cost of sacrificing the recall rate. However, there is no work which increases search efficiency, decreases search cost and increase the recall rate. In this paper, we propose a general search method which can be applied in both unstructured P2P networks and structured P2P networks. In this method, social communities are formed dynamically on top of P2P overlay networks. Each social community is made up of peers who share similar characteristics, such as interests, search behavior, etc. These characteristics are dynamic, so the social communities will change as any peer's characteristics have changed. In this method, a search request is forwarded by taking use of the social communities. Simulation results show our proposed method achieves a higher search efficiency, a lower search cost and a higher recall rate compared with traditional search algorithms.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687468","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687468","P2P networks;search cost;search efficiency;social community","Biological system modeling;Communities;Educational institutions;Floods;Lead;Peer to peer computing;Robustness","information retrieval;peer-to-peer computing","P2P networks;decreasing search cost;general search method;increasing search efficiency;search algorithms;search request;social communities","","0","","22","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"The humidity retrievals using BP neural network algorithm based on mexihat or morlet wavelet function in clear-sky","J. He; S. Zhang; Y. Huang; Zhang Yu; F. Sun","Center for space science and applied research, Chinese academy of sciences, Beijing, 100190, China","Proceedings of the 9th International Symposium on Antennas, Propagation and EM Theory","20110120","2010","","","502","504","The paper presents three algorithms to retrieve the humidity profiles from the observing datasets of FENGYUN-3A (FY-3A) satellite microwave humidity sensor. Compared to widely used algorithm-BP artificial neural network (BP-ANN), the algorithms of ANN based on morelet and mexihat function can avoid the conditions of easily getting stuck in local minima and reaching convergence with long time. Especially, the BP-ANN with mexihat function can decrease the training time and improve the humidity retrievals.","","Electronic:978-1-4244-6908-6; POD:978-1-4244-6906-2","10.1109/ISAPE.2010.5696512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5696512","back-propagation neural network;humidity profile;mexihat wavelet function;microwave humidity sensor;morlet wavelet function","","backpropagation;geophysics computing;humidity sensors;information retrieval;neural nets;wavelet transforms","BP neural network algorithm;FENGYUN-3A;Mexihat wavelet function;Morlet wavelet function;humidity retrievals;satellite microwave humidity sensor","","1","","14","","","Nov. 29 2010-Dec. 2 2010","","IEEE","IEEE Conference Publications"
"A Browser/Server Product Data Management System","S. Yong","Sch. of Mech. Eng., Shenyang Ligong Univ., Shenyang, China","2010 Asia-Pacific Conference on Power Electronics and Design","20110113","2010","","","43","46","In this paper, a design of a browser/server product data management (BSPDM) is presented. It is aimed at achieving the goal of e-Manufacturing by providing an effective tool for product database management through the Internet utilizing Java EE technologies. The BSPDM mainly uses Servlets and JSP to handle user inputs and manage and retrieve product data from the database through the JDBC driver, with the server components stored on a web server system called Tomcat. Within this environment, all parties involved in product design and manufacture can access the log-in page with the given URL after a successful identity authorization. Consequently, these users can create, search and/or manipulate the desired engineering data through the enabled BSPDM. The BSPDM developed in this work has been experimentally developed.","","Electronic:978-1-4244-7080-8; POD:978-1-4244-7079-2","10.1109/APPED.2010.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662647","Java EE;Product Data Management;concurrent engineering","","Internet;Java;authorisation;database management systems;file servers;information retrieval;online front-ends;product design;production engineering computing","Internet;JSP;Java EE technologies;Tomcat;URL;Web server system;browser-server product data management system;e-manufacturing;identity authorization;product data retrieval;product database management;product design;product manufacture","","0","","5","","","30-31 May 2010","","IEEE","IEEE Conference Publications"
"Mining and Composition of Emergent Collectives in Mixed Service-Oriented Systems","D. Schall; F. Skopik","Distrib. Syst. Group, Vienna Univ. of Technol., Vienna, Austria","2010 IEEE 12th Conference on Commerce and Enterprise Computing","20110204","2010","","","212","219","Complex service-oriented systems typically span interactions between people and services. Compositions in such systems demand for flexible interaction models. In this work we introduce an approach for discovering experts based on their dynamically changing skills and interests. We discuss human provided services and an approach for managing user preferences and network structures. Experts offer their skills and capabilities as human provided services that can be requested on demand. Our main contributions center around an expert discovery method based on the concept of hubs and authorities in Web-based environments. The presented discovery and interaction approach takes trust-relations and link properties in social networks into account to estimate the hub-expertise of users. Furthermore, we show how our approach supports flexible interactions in mixed service-oriented systems.","2378-1963;23781963","Electronic:978-0-7695-4228-7; POD:978-1-4244-8433-1","10.1109/CEC.2010.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708414","ExpertHITS;emergent collectives;expert discovery;hubs and authorities;mixed service-oriented systems","Collaboration;Communities;Context;Humans;Measurement;Receivers;Social network services","Internet;data mining;expert systems;information retrieval;service-oriented architecture;social networking (online)","Web-based environment;emergent collective composition;emergent collective mining;expert discovery method;interaction model;mixed service-oriented system;social networks","","2","","23","","","10-12 Nov. 2010","","IEEE","IEEE Conference Publications"
"Automatic extraction of usable information from unstructured resumes to aid search","S. K. Kopparapu","TCS Innovation Labs - Mumbai, Tata Consultancy Services, Thane (West), Maharastra 400 601, INDIA","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","1","","99","103","This paper describes a system for automated resume information extraction to support rapid resume search and management. The system is capable of extracting several important informative fields from a free format resume using a set of natural language processing (NLP) techniques. We describe a working system, for automatic resume management. The system is capable of extracting six major fields of information as defined by HR-XML. Experimental results carried out on a large number of resumes show that the proposed system can handle a large variety of resumes in different document formats with a precision of 91% and a recall of 88%.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687428","component;natural language processing;resume manager","Electronic mail;Organizations;Variable speed drives;Writing","document handling;information retrieval;management information systems;natural language processing","HR-XML;automated usable information extraction;document format;free format resume;natural language processing technique;unstructured resume","","1","1","9","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Multi-dimensional Mass Estimation and Mass-based Clustering","K. M. Ting; J. R. Wells","Gippsland Sch. of Inf. Technol., Monash Univ., Clayton, VIC, Australia","2010 IEEE International Conference on Data Mining","20110120","2010","","","511","520","Mass estimation, an alternative to density estimation, has been shown recently to be an effective base modelling mechanism for three data mining tasks of regression, information retrieval and anomaly detection. This paper advances this work in two directions. First, we generalise the previously proposed one-dimensional mass estimation to multidimensional mass estimation, and significantly reduce the time complexity to O(ψh) from O(ψ<sup>h</sup>)-making it feasible for a full range of generic problems. Second, we introduce the first clustering method based on mass-it is unique because it does not employ any distance or density measure. The structure of the new mass model enables different parts of a cluster to be identified and merged without expensive evaluations. The characteristics of the new clustering method are: (i) it can identify arbitrary-shape clusters; (ii) it is significantly faster than existing density-based or distance-based methods; and (iii) it is noise-tolerant.","1550-4786;15504786","Electronic:978-0-7695-4256-0; POD:978-1-4244-9131-5","10.1109/ICDM.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694005","Mass estimation;mass-based clustering","Clustering methods;Complexity theory;Data mining;Data models;Equations;Estimation;Runtime","computational complexity;data mining;information retrieval;pattern clustering","anomaly detection;arbitrary-shape cluster;base modelling mechanism;data mining task;density estimation;density-based method;distance-based method;information retrieval;mass-based clustering;multidimensional mass estimation;one dimensional mass estimation;time complexity","","3","","13","","","13-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Simultaneous speech recognition and speaker identification","T. Herbig; F. Gerl; W. Minker","Nuance Communications Aachen GmbH, Ulm, Germany","2010 IEEE Spoken Language Technology Workshop","20110124","2010","","","218","222","In this paper we present a self-learning speech controlled system comprising speech recognition, speaker identification and speaker adaptation for a small number of users, e.g. five recurring speakers. A compact representation of speech and speaker characteristics is discussed. It is combined with a technique for efficient information retrieval to capture individual speech characteristics allowing robust speaker identification with limited training data. Speech recognition is enhanced by applying speaker specific profiles which are incrementally adapted. However, the computational load and memory consumption are essential design parameters for an embedded system. Such a personalization of human-computer interfaces represents an important research issue. In this paper in-car applications such as speech controlled navigation, hands-free telephony or infotainment systems are investigated. Results for a subset of the SPEECON database are presented. They validate the benefit of the unified modeling of speech and speaker characteristics.","","Electronic:978-1-4244-7902-3; POD:978-1-4244-7904-7; USB:978-1-4244-7902-3; USB:978-1-5090-5693-4","10.1109/SLT.2010.5700854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5700854","speaker adaptation","","database management systems;information retrieval;speech recognition","SPEECON database;computational load;information retrieval;memory consumption;self learning speech controlled system;speaker adaptation;speaker identification;speech characteristics;speech recognition","","2","","16","","","12-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"iHelp: An Intelligent Online Helpdesk System","D. Wang; T. Li; S. Zhu; Y. Gong","School of Computing and Information Sciences, Florida International University, Miami, FL, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20110113","2011","41","1","173","182","Due to the importance of high-quality customer service, many companies use intelligent helpdesk systems (e.g., case-based systems) to improve customer service quality. However, these systems face two challenges: 1) Case retrieval measures: most case-based systems use traditional keyword-matching-based ranking schemes for case retrieval and have difficulty to capture the semantic meanings of cases and 2) result representation: most case-based systems return a list of past cases ranked by their relevance to a new request, and customers have to go through the list and examine the cases one by one to identify their desired cases. To address these challenges, we develop iHelp, an intelligent online helpdesk system, to automatically find problem-solution patterns from the past customer-representative interactions. When a new customer request arrives, iHelp searches and ranks the past cases based on their semantic relevance to the request, groups the relevant cases into different clusters using a mixture language model and symmetric matrix factorization, and summarizes each case cluster to generate recommended solutions. Case and user studies have been conducted to show the full functionality and the effectiveness of iHelp.","1083-4419;10834419","","10.1109/TSMCB.2010.2049352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5475278","Case clustering;case summarization;intelligent helpdesk;semantic similarity","","Internet;case-based reasoning;customer services;help systems;information resources;information retrieval;matrix decomposition;semantic networks;technical support services","case based system;case retrieval;customer request;customer service quality;customer-representative interactions;iHelp;intelligent online helpdesk;keyword matching based ranking;mixture language model;semantic relevance;symmetric matrix factorization","","10","","40","","20100601","Feb. 2011","","IEEE","IEEE Journals & Magazines"
"Minimizing influence of ontology evolution in ontology-based data access system","Funian Tang; Rongnian Tang","School of Information System and Management, National University of Defense Technology, Changsha, China","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","1","","10","14","Nowadays, many organizations face the problem of how to accessing the legacy data by means of flexible mechanism. As a powerful and efficient solution to this problem, ontology-based data access (OBDA) technology enables people to utilize data from heterogeneous sources through a well-defined ontology. However, under the dynamic environment, the ontology which acts as concept view in an OBDA application may be changed and modified to meet users' needs. Furthermore, the changes occurred during ontology evolution process may be propagated across the whole system. In order to minimize the influence of ontology evolution in OBDA system, we present a solution to control the impact of change propagation from ontology evolution, namely ICOE method. The experiment illustrate that this method is helpful in managing an OBDA system.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687963","Data access;Mappings;Ontology;Semantic Web","Artificial neural networks","information retrieval;minimisation;ontologies (artificial intelligence);semantic Web","change propagation;dynamic environment;flexible mechanism;ontology based data access system;ontology evolution process","","0","","11","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Information System Management of Inspectional Files after the Completion of Engineer Procure Construct","Y. Liu; R. Jin; X. Liu; S. Wu; W. Jiang","Dept. of Building Eng., Tongji Univ., Shanghai, China","2010 Second WRI Global Congress on Intelligent Systems","20110204","2010","2","","185","189","Information System Management of Inspectional Files after the Completion of Project Total Contracting Items is an important project information portal in BLM technological management based on network platform. All the project information belonging to different participators can be collected automatically via PIP, as well as the establishment of data archiving of files from Engineer Procure Construct and that for urban construction archives.","2155-6083;21556083","Electronic:978-0-7695-4304-8; POD:978-1-4244-9247-3","10.1109/GCIS.2010.255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5709160","Information System Management;Inspectional Files after Project Completion;Project Total Contracting Items","Buildings;Contracts;Electronic mail;Information filtering;Information systems;Project management","civil engineering computing;engineering information systems;file organisation;information management;information retrieval systems;project management","BLM technological management;engineer procure construct completion;file data archiving;information system management;inspectional files;project information portal;project total contracting items;urban construction archive","","0","","11","","","16-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Searching for Historical Events on a Large-Scale Web Archive","L. Huang; W. Lin; X. Li","Internet Res. & Eng. Center, Peking Univ., Shenzhen, China","2010 Sixth International Conference on Semantics, Knowledge and Grids","20110113","2010","","","259","266","Finding knowledge on the Web has long been a hot research issue. Today the Web has become a popular medium for publishing news and opinion articles, which are important carriers of human knowledge, especially of social knowledge. Developing techniques of automatically collecting and analysing these articles on a large scale is thus desirable. In this paper we propose techniques for searching for events on the Web, and our techniques have been tested on a large scale web archive. Given an event, or a news topic cared by many people, the purpose of this paper is to find out near-all news stories related to it. First, a novel domain-independent approach of extracting news stories from web pages is proposed which is based on anchor text and is applicable to most websites. Experiments show our approach performs good and is better than another approach we have found. Second, a domain-based method of representing events is proposed in which hundreds of keywords are used to represent an event and compose the query expression. This situation of retrieval is different from most search engines' in that the number of keywords is large. We then propose several retrieval algorithms based on BM25 for the method. Evaluation show that these algorithms perform better than unmodified BM25 in our situation and the best one is chosen as the algorithm of our system. Finally an experimental system has been built on a collection of 2 billion web pages and the running performance is reported, which shows the effectiveness of our approaches.","","Electronic:978-0-7695-4189-1; POD:978-1-4244-8125-5","10.1109/SKG.2010.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663519","Domain;Historical Event;Knowledge Finding;News Extraction;Web Mining","","Internet;Web sites;history;information retrieval systems;query processing","BM25;Web page;anchor text;domain independent approach;event search;historical event;human knowledge;knowledge search;large scale Web archive;news story extraction;query expression;retrieval algorithm;search engine;social knowledge","","0","","25","","","1-3 Nov. 2010","","IEEE","IEEE Conference Publications"
"Influencing Factors of Usage in Virtual Communities with Real-Name System: An Empirical Research","W. Fengyan; A. Shizhong; S. Kang","Sch. of Econ. & Manage., Xidian Univ., Xian, China","2010 3rd International Conference on Information Management, Innovation Management and Industrial Engineering","20110120","2010","1","","662","665","On the basis of extant literatures, we built a conceptual model of the relationship between perceived quality, trust, extrinsic motivation, intrinsic motivation and usage in the virtual communities with real-name system, and proposed some hypotheses about them. To test the hypotheses, we designed a questionnaire, and collected data from the members who use virtual communities with real-name system. We used SPSS15.0 and AMOS 16.0 to analyze the collected data. We found that perceived quality, trust, extrinsic motivation and intrinsic motivation all significantly influence usage. Additionally, perceived quality has a positive correlation with trust.","2155-1456;21551456","Electronic:978-0-7695-4279-9; POD:978-1-4244-8829-2","10.1109/ICIII.2010.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694493","Real-Name System;Usage;Virtual Community;influencing factors","","data analysis;question answering (information retrieval);virtual reality","AMOS 16.0;SPSS15.0;correlation;data analysis;data collection;questionnaire;real name system;virtual community","","0","","15","","","26-28 Nov. 2010","","IEEE","IEEE Conference Publications"
"Out-of-vocabulary term detection by n-gram array with distance from continuous syllable recognition results","K. Iwami; Y. Fujii; K. Yamamoto; S. Nakagawa","Department of Computer Science and Engineering, Toyohashi University of Technology, Japan","2010 IEEE Spoken Language Technology Workshop","20110124","2010","","","212","217","For spoken document retrieval, it is very important to consider Out-of-Vocabulary (OOV) and mis-recognition of spoken words. Therefore, sub-word unit based recognition and retrieval methods have been proposed. This paper describes a Japanese spoken document retrieval system that is robust for considering OOV words and mis-recognition of sub-units. To solve the problem of OOV keywords and mis-recognized words, we used individual syllables as sub-word unit in continuous speech recognition and an n-gram sequence of syllables as a retrieval unit. We propose an n-gram indexing/retrieval method with distance in a syllable lattice for attacking OOV, recognition errors, and high speed retrieval. We applied this method to academic lecture presentation database of 44 hours, and 60% of the OOV words were detected in less than 2.5 milliseconds.","","Electronic:978-1-4244-7902-3; POD:978-1-4244-7904-7; USB:978-1-4244-7902-3; USB:978-1-5090-5693-4","10.1109/SLT.2010.5700853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5700853","Out-of-Vocabulary;mis-recognition;n-gram;spoken term retrieval;syllable recognition","","document handling;indexing;information retrieval;speech recognition","Japanese spoken document retrieval system;continuous syllable recognition;n-gram array;n-gram indexing-retrieval method;out-of-vocabulary term detection","","4","","16","","","12-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Chinese question classification in community question answering","Y. Lei; Y. Jiang","Department of Computer Science, Xiamen University, Xiamen, P. R. China","2010 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)","20110204","2010","","","1","6","Community Question Answering (CQA) has become a popular and effective mean for seeking information on the Web. It is now possible and effective to post a question asked in natural language on a popular community Question Answering (QA) portal, and to rely on other users to provide answers. These online collaborative services are attracting users and questions at an explosive rate, while how to correctly categorize a given question is the first problem that a community QA system must dispose. Question classification plays a crucial important role in the community QA System because categorizing a given question correctly is beneficial to obtain accurate answers quickly. In this paper, we present a classifier based on the Support Vector Machine (SVM) machine learning algorithm, and develop a variety of lexical and semantic features for this task. Our experimental results, obtained from a large scale evaluation over thousands of real questions, show the feasibility and effectiveness of our approach.","2163-2871;21632871","Electronic:978-1-4244-9801-7; POD:978-1-4244-9802-4","10.1109/SOCA.2010.5707167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5707167","Community Question Answering;Feature Extraction;Question Classification;Support Vector Machine","Accuracy;Classification algorithms;Communities;Correlation;Feature extraction;Semantics;Support vector machines","Internet;classification;learning (artificial intelligence);natural language processing;portals;question answering (information retrieval);support vector machines","Chinese question classification;SVM machine learning algorithm;World Wide Web;community question answering portal;lexical features;natural language;online collaborative services;semantic features;support vector machine","","0","","16","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"SOA context-aware mobile data model for emergency situation","W. Romsaiyud; W. Premchaiswadi","Graduate School of Information Technology, Siam University, Bangkok, Thailand","2010 Eighth International Conference on ICT and Knowledge Engineering","20110120","2010","","","93","97","At present, the number of mobile device users are increasing as a result of many factors such as today's efficiency of mobile data exchange, the collaboration and support from several business services such as bank system, retail marketing, healthcare, emergency service and etc. Emergency situation is a crisis that needs rapid information retrieval in real time from heterogeneous data source. The appropriate data from multiple data models needs to be chosen for responding in sudden time. However, mobile devices have limitation on memory, battery life time and downlink/uplink bandwidth. Therefore, this paper presents a mSOA (mobile Service Oriented Architecture) data model for emergency environments that based on many factors such as emergency location, emergency type, approximate time when the emergency happened, the patient information and etc.","2157-0981;21570981","Electronic:978-1-4244-9876-5; POD:978-1-4244-9874-1","10.1109/ICTKE.2010.5692921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5692921","context-aware mobile application;context-awareness;mobile service oriented architecture (mSOA)","Accidents;Hospitals;Mobile communication;Mobile computing;Mobile handsets;Service oriented architecture","electronic data interchange;emergency services;information retrieval;mobile computing;mobile handsets;service-oriented architecture","SOA context aware mobile data model;bank system;battery life time;business service;downlink-uplink bandwidth;emergency service;emergency situation;healthcare;heterogeneous data source;information retrieval;mSOA data model;mobile data exchange;mobile device;mobile service oriented architecture;retail marketing","","2","","15","","","24-25 Nov. 2010","","IEEE","IEEE Conference Publications"
"Search-based short-text classification","K. Wei; R. Zhang; X. Xu","National Computer System Engineering Research, Beijing, 100083, P. R. China","5th International Conference on Pervasive Computing and Applications","20110128","2010","","","297","301","Since the traditional classification algorithm does not work well in the case of short-text classification, we propose a search-based method employing Na'iveBayes classification algorithm. This paper describes the whole process, including the classification algorithms, training and the evaluation. The results indicate that the classifier has better performance comparing with other methods.","","Electronic:978-1-4244-9143-8; POD:978-1-4244-9144-5","10.1109/ICPCA.2010.5704116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704116","NarveBayes;search engine;short text;text classification","","Bayes methods;classification;information retrieval;text analysis","Na'iveBayes classification algorithm;search-based method;search-based short-text classification","","0","","9","","","1-3 Dec. 2010","","IEEE","IEEE Conference Publications"
"The imminent convergence of the technology trio: Demystifying the super potential of 4G, CDN and cloud computing","N. Ramachnadran; P. Sivaprakasam","Computer Centre, Indian Institue of Management, Kozhikode, India","2010 IEEE International Conference on Computational Intelligence and Computing Research","20110131","2010","","","1","4","Fourth Generation (4G) is the evolving mobile technology, supporting up to 1 Gbit/s bandwidth for fixed gadgets and 100 Mbit/s for mobiles, and is reported to be more secure than 3G and 4G. Also supports IPv6 in addition to many added features. Content Delivery Networks (CDN) is the technology deployed for good quality as well as speedy access to the content as it overcomes flash crowd, denial of services etc. Cloud Computing is the evolving technology, which allows for increased efficiency in computing by centralizing storage, memory, processing and bandwidth. In addition, the users can gain access to their applications from anywhere through connected devices. Convergence of these three technologies will be a milestone and a path-breaking revolution in information and communication technology. A logical forecast of the technology suggests that it will certainly change the present scenario, so much so that the usage of laptops and tablet PCs will considerably reduce and even the usage of desktops will drastically come down. This paper aims at unleashing the potential of these technologies in detail and portrays the impact of their convergence.","","Electronic:978-1-4244-5967-4; POD:978-1-4244-5965-0","10.1109/ICCIC.2010.5705787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5705787","4G;CDN;Cloud Computing;DNS redirection;MIMO;OFDM;URL rewriting","Bandwidth;Cloud computing;Content distribution networks;Convergence;Mobile communication;Servers;Software","4G mobile communication;IP networks;cloud computing;convergence;information retrieval;mobile computing","CDN technology;IPv6;bit rate 1 Gbit/s;bit rate 100 Mbit/s;cloud computing;content access;content delivery network;fourth generation technology;imminent convergence;logical technology forecast;mobile technology;technology trio","","1","","13","","","28-29 Dec. 2010","","IEEE","IEEE Conference Publications"
"Semantics for Music Analysis through Linked Data: How Country is My Country?","K. R. Page; B. Fields; B. J. Nagel; G. O'Neill; D. C. D. Roure; T. Crawford","Sch. of Electron. & Comput. Sci., Univ. of Southampton, Southampton, UK","2010 IEEE Sixth International Conference on e-Science","20110120","2010","","","41","48","We present a proof-of-concept system that demonstrates the utility of linked data for enhancing the application of Music Information Retrieval (MIR) workflows, both when curating collections of music signal data for analysis, and publishing results that can be simply and readily correlated to these, and other, collection sets and Linked Data sources. The system includes: linked data implementations of a signal repository, collection builder, and results explorer, an extension to the my Experiment workflow sharing environment to include Meandre workflows, and support within my Experiment and Meandre to retrieve and persist resources from the linked data repositories. By way of example we gather and publish RDF describing signal collections derived from the country of an artist. Genre analysis over these collections and integration of collection and result metadata enables us to ask: ""how country is my country?"".","","Electronic:978-0-7695-4290-4; POD:978-1-4244-8957-2","10.1109/eScience.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693897","MIR;linked data;music analysis;semantic web;workflow","Algorithm design and analysis;Data models;Multiple signal classification;Ontologies;Prototypes;Resource description framework","audio signal processing;data analysis;information retrieval;music;peer-to-peer computing;semantic Web","Meandre workflow;RDF publishing;collection builder;genre analysis;linked data repository;metadata;music analysis;music information retrieval;music signal data;myExperiment;proof-of-concept system;signal repository;workflow sharing environment","","3","","20","","","7-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"Cluster-based query expansion using language modeling in the biomedical domain","X. Xu; X. Hu","College of Information Science and Technology, Drexel University, Philadelphia, PA 19104, USA","2010 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20110128","2010","","","185","188","Several techniques have been developed, such as query expansion, cluster-based retrieval and dimensionality reduction to resolve low search precision and low search recall issues. Of these techniques, this paper proposed cluster-based query expansion using language modeling. Through our experiments in TREC genomic track ad-hoc retrieval task, we explore and demonstrate clusters that are created based on the whole collection or the initially returned document results of the original query can be utilized to perform query expansion and eventually improve the overall effectiveness and performance of information retrieval system in the biomedical domain.","","Electronic:978-1-4244-8304-4; POD:978-1-4244-8303-7","10.1109/BIBMW.2010.5703796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703796","Cluster;Informational Retrieval;Language Modeling;Pseudo-feedback;Query Drift;Query Expansion;TREC","","bioinformatics;genomics;information retrieval systems;query languages","TREC genomic track adhoc retrieval task;biomedical domain;cluster-based query expansion;cluster-based retrieval;information retrieval system;language modeling","","1","","12","","","18-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Efficient Probabilistic Latent Semantic Analysis with Sparsity Control","S. Liu; C. Xia; X. Jiang","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2010 IEEE International Conference on Data Mining","20110120","2010","","","905","910","Probabilistic latent semantic analysis is a topic modeling technique to discover the hidden structure in binary and count data. As a mixture model, it performs a probabilistic mixture decomposition on the co-occurrence matrix, which produces two matrices assigned with probabilistic explanations. However, the factorized matrices may be rather smooth, which means we may obtain global feature and topic representations rather than expected local ones. To resolve this problem, one of the solutions is to revise the decomposition process with considerations of sparsity. In this paper, we present an approach that provides direct control over sparsity during the expectation maximization process. Furthermore, by using the log penalty function as sparsity measurement instead of the widely used L2 norm, we can approximate the re-estimation of parameters in linear time, as same as original PLSA does, while many other approaches require much more time. Experiments on face databases are reported to show visual representations on obtaining local features, and detailed improvements in clustering tasks compared with the original process.","1550-4786;15504786","Electronic:978-0-7695-4256-0; POD:978-1-4244-9131-5","10.1109/ICDM.2010.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694059","data-adaptive representations;opic model;plsa;sparsity;unsupervised learning","","information retrieval;learning (artificial intelligence);matrix decomposition;sparse matrices;visual databases","cooccurrence matrix;expectation maximization process;factorized matrices;probabilistic latent semantic analysis;probabilistic mixture decomposition;sparsity control;topic modeling","","2","","17","","","13-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Combination of Ontology Model and Semantic Link Network in Web Resource Retrieval","S. t. Sun; D. s. Liu; G. q. Li; W. y. Yu; L. Pang","Key Lab. of Digital Earth, Chinese Acad. of Sci., Beijing, China","2010 Sixth International Conference on Semantics, Knowledge and Grids","20110113","2010","","","285","288","Ontology Model and Semantic Link Network (SLN) are two important semantic data models in Semantic Web. Ontology Model can describe network resource in concept space, while SLN can describe various links and relations between network resources. Combination of Ontology Model and SLN can help to improve the effect of network resource retrieval, but data transfer and exchange between ontological knowledge base and SLN knowledge base are needed. This paper presents semantic relationship tree (SRT) to realize the information transfer from Ontology Model to SLN, and also gives an example of network resource retrieval based on ontology knowledge base and SLN knowledge base.","","Electronic:978-0-7695-4189-1; POD:978-1-4244-8125-5","10.1109/SKG.2010.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663525","ontological model;semantic data model;semantic link network;semantic relationship tree","","Web services;electronic data interchange;information retrieval;ontologies (artificial intelligence);semantic Web","Web resource retrieval;data exchange;data transfer;ontology;semantic Web;semantic data models;semantic link network;semantic relationship tree","","1","","9","","","1-3 Nov. 2010","","IEEE","IEEE Conference Publications"
"A framework for semantic Web Services annotation and discovery based on ontology","Yang Liu; Zhiqing Shao","Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai, China","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","2","","1034","1039","In order to achieve the automatic discovery of Web Services to composition, business processes and workflows, it is necessary to take advantage of semantic information. A couple of approaches have been proposed to achieve automatic annotation and retrieval of Web Services based on similarity or logical reasoning. A key difference between our method and existing methods is that we separated the annotation process from the description documents of services, which can express the semantic explicitly for reusing separately. Meanwhile, we proposed a framework for Web Services discovery automatically based on this annotation method. Finally, we presented the performance for the framework.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5688008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5688008","annotation;ontology;semantic Web service;service retrieval","Ontologies;Silicon","Web services;information retrieval;ontologies (artificial intelligence);semantic Web","automatic annotation;business processes;document description;logical reasoning;ontology;semantic information;semantic web services annotation;web services retrieval","","1","","22","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Intelligent Digital Photo Management System Using Ontology and SWRL","Y. Chai; T. Xia; J. Zhu; H. Li","Sch. of Inf., Central Univ. of Finance & Econ., Beijing, China","2010 International Conference on Computational Intelligence and Security","20110120","2010","","","18","22","The number of digital photos in the personal computer is exploding. Existing photo annotation and management systems suffer from some problems (some among them are quite serious), which discussed at the beginning of the full paper. Aiming at these problems, this paper proposed a solution based on ontology. First of all, the Family Album ontology is built to organize the domain knowledge and provide formal, explicit and conceptual annotation. Then we annotate preliminary semantic information for digital photos by automated extraction of semantic concepts from file titles, photo description texts, EXIF metadata and visual features of images etc.. Furthermore, the SWRL (Semantic Web Rule Language) rules are written and executed to extend previous semantic annotations and support knowledge inference. Finally, an Onto Album prototype system is developed for verifying the validity of the proposed approach. Experimental results show that the proposed approach is very effective and promising.","","Electronic:978-0-7695-4297-3; POD:978-1-4244-9114-8","10.1109/CIS.2010.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5696223","SWRL rules;digital photo;intelligent retrieval;ontology","","digital photography;inference mechanisms;information retrieval;information retrieval systems;knowledge representation languages;ontologies (artificial intelligence);semantic Web","EXIF metadata;SWRL rules;automated extraction;conceptual annotation;digital photos;domain knowledge;explicit annotation;family album ontology;file titles;formal annotation;intelligent digital photo management system;knowledge inference;onto album prototype system;personal computer;photo annotation;photo description texts;photo management systems;preliminary semantic information;semantic Web rule language rules;semantic annotations;semantic concepts;visual features","","3","","10","","","11-14 Dec. 2010","","IEEE","IEEE Conference Publications"
"Global analysis of miRNA target genes in colon rectal cancer","M. Pradhan; L. Ledford; Y. Pandit; M. Palakal","School of Informatics, Indiana University-Purdue University, Indianapolis, IN 46202","2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20110204","2010","","","341","345","In this paper we present a global analysis of colon rectal cancer genes and their associated miRNAs. Significant genes in colon cancer were obtained by mining the literature and cancer related miRNAs were obtained from miRbase. Five different features were used to analyze to obtain a global gene-miRNA profile. By combining the topological features along with miRNA-gene associations and gene propensity measures, we identified a set of genes and modules that are significant in CRC. The proposed methodology identified 123 significant modules of miRNA-genes that can be further studied for understanding the disease and marker discovery.","","Electronic:978-1-4244-8307-5; POD:978-1-4244-8306-8","10.1109/BIBM.2010.5706588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706588","Literature Mining;Networks;miRNA","Asynchronous transfer mode;Bioinformatics;Breast cancer;Colon;Gene expression;Humans","bioinformatics;biological tissues;cancer;data mining;database management systems;genetics;genomics;information retrieval;macromolecules","colon rectal cancer;disease;gene expression;gene propensity;literature mining;miRNA target genes;miRbase;topological features","","1","","20","","","18-21 Dec. 2010","","IEEE","IEEE Conference Publications"
"Knowledge File System -- A Principled Approach to Personal Information Management","K. Chang; I. W. T. Perdana; B. Ramadhana; K. Sethuraman; T. V. Le; N. Chachra","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","2010 IEEE International Conference on Data Mining Workshops","20110120","2010","","","1037","1044","The Knowledge File System (KFS) is a smart virtual file system that sits between the operating system and the file system. Its primary functionality is to automatically organize files in a transparent and seamless manner so as to facilitate easy retrieval. Think of the KFS as a personal assistant, who can file every one of you documents into multiple appropriate folders, so that when it comes time for you to retrieve a file, you can easily find it among any of the folders that are likely to contain it. Technically, KFS analyzes each file and hard links (which are simply pointers to a physical file on POSIX file systems) it to multiple destination directories (categories). The actual classification can be based on a combination of file content analysis, file usage analysis, and manually configured rules. Since the KFS organizes files using the familiar file/folder metaphor, it enjoys 3 key advantages against desktop search based solutions such as Google's Desktop Search, namely 1) usability, 2) portability, and 3) compatibility. The KFS has been prototyped using the FUSE (File system in User space) framework on Linux. Apache Lucerne was used to provide traditional desktop search capability in the KFS. A machine learning text classifier was used as the KFS content classifier, complimenting the customizable rule-based KFS classification framework. Lastly, an embedded database is used to log all file access to support file-usage classification.","2375-9232;23759232","Electronic:978-0-7695-4257-7; POD:978-1-4244-9244-2","10.1109/ICDMW.2010.119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693409","classification;indexing;personal information management;search engine;virtual file system","","Linux;file organisation;information management;information retrieval;knowledge based systems;learning (artificial intelligence);pattern classification;personal information systems;search engines","Apache Lucene;FUSE;Google desktop search;Linux;content classifier;destination directory;embedded database;file access;file content analysis;file retrieval;file usage analysis;folder metaphor;knowledge file system;machine learning text classifier;multiple appropriate folder;operating system;personal assistant;personal information management;rule based KFS classification;smart virtual file system","","0","","19","","","13-13 Dec. 2010","","IEEE","IEEE Conference Publications"
"Alpha-Numerical Sequences Extraction in Handwritten Documents","S. Thomas; C. Chatelain; L. Heutte; T. Paquet","LITIS, Univ. de Rouen, St. Etienne du Rouvray, France","2010 12th International Conference on Frontiers in Handwriting Recognition","20110120","2010","","","232","237","In this paper, we introduce an alpha-numerical sequences extraction system (keywords, numerical fields or alpha-numerical sequences) in unconstrained handwritten documents. Contrary to most of the approaches presented in the literature, our system relies on a global handwriting line model describing two kinds of information : i) the relevant information and ii) the irrelevant information represented by a shallow parsing model. The shallow parsing of isolated text lines allows quick information extraction in any document while rejecting at the same time irrelevant information. Results on a public french incoming mails database show the efficiency of the approach.","","Electronic:978-0-7695-4221-8; POD:978-1-4244-8353-2","10.1109/ICFHR.2010.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693529","","","feature extraction;handwriting recognition;information retrieval","alpha numerical sequences extraction;handwriting line model;handwritten documents;information extraction;irrelevant information representation;isolated text lines;literature;shallow parsing model","","3","","19","","","16-18 Nov. 2010","","IEEE","IEEE Conference Publications"
"The Research and Implementation of Parallel Web Crawler in Cluster","M. Wu; J. Lai","Sch. of Comput. Sci., Southwest Petro Univ., Chengdu, China","2010 International Conference on Computational and Information Sciences","20110204","2010","","","704","708","As the foundational component of web information acquisition, web crawler has been always the research hotspot in academia and industry, recently the parallel web crawler is the main research direction. In view of the shortage of the center-like dynamic assignment and distributed static assignment which are adopted by current parallel web crawler, this paper presents a parallel web crawler based on the cluster environment, which adopts the dynamic assignment structure, introduces the distributed controller pattern, eliminates the problem of single point failure in the central controller, and enhances system's concurrent capability. In addition, it uses the URL dynamic assignment technology, and realizes dynamic balance among components according to their real-time condition.","","Electronic:978-0-7695-4270-6; POD:978-1-4244-8814-8","10.1109/ICCIS.2010.175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5709184","Cluster;Dynamic assignment;Parallelism;Web crawler","Control systems;Crawlers;Databases;Internet;Process control;Protocols;Web pages","Internet;information retrieval","URL dynamic assignment technology;Web information acquisition;center-like dynamic assignment structure;cluster environment;distributed controller pattern;distributed static assignment;parallel Web crawler","","3","","7","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Discovering and Exploiting Cumulative Cues for Informational Web Search","Y. C. Liu; W. H. Wen; W. G. Teng","Dept. of Eng. Sci., Nat. Cheng Kung Univ., Tainan, Taiwan","2010 International Conference on Technologies and Applications of Artificial Intelligence","20110120","2010","","","286","292","<div style=""font-variant: small-caps; font-size: .9em;"">First Page of the Article</div><img class=""img-abs-container"" style=""width: 95%; border: 1px solid #808080;"" src=""/xploreAssets/images/absImages/05695466.png"" border=""0"">","2376-6816;23766816","Electronic:978-0-7695-4253-9; POD:978-1-4244-8668-7","10.1109/TAAI.2010.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5695466","","","cloud computing;information retrieval","cloud computing;information collection;informational Web search;search engines","","0","","17","","","18-20 Nov. 2010","","IEEE","IEEE Conference Publications"
"Bridging Folksonomies and Domain Ontologies: Getting Out Non-taxonomic Relations","C. Trabelsi; A. B. Jrad; S. B. Yahia","Dept. of Comput. Sci., Fac. of Sci. of Tunis, Tunis, Tunisia","2010 IEEE International Conference on Data Mining Workshops","20110120","2010","","","369","379","Social bookmarking tools are rapidly emerging on the Web as it can be witnessed by the overwhelming number of participants. In such spaces, users annotate resources by means of any keyword or tag that they find relevant, giving raise to lightweight conceptual structures aka folksonomies. In this respect, needless to mention that ontologies can be of benefit for enhancing information retrieval metrics. In this paper, we introduce a novel approach for ontology learning from a folksonomy, which provide shared vocabularies and semantic relations between tags. The main thrust of the introduced approach stands in putting the focus on the discovery of nontaxonomic relationships. The latter are often neglected, even though they are of paramount importance from a semantic point of view. The discovery process heavily relies on triadic concepts to discover and select related tags and to extract and label non-taxonomically relationships between related tags and external sources for tags filtering and non-taxonomic relationships extraction. In addition, we also discuss a new approach to evaluate obtained relations in an automatic way against WordNet repository and presents promising results for a real world folksonomy.","2375-9232;23759232","Electronic:978-0-7695-4257-7; POD:978-1-4244-9244-2","10.1109/ICDMW.2010.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693322","Association rule;Conceptual Knowledge Discovery;Data Mining;Folksonomy;Ontology;Triadic Concept","","data mining;identification technology;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);semantic Web;vocabulary","WordNet repository;data mining;discovery process;domain ontology;information retrieval metrics;lightweight conceptual structure;nontaxonomic relation;ontology learning;semantic relation;shared vocabulary;social bookmarking tool;tag filtering;triadic concept","","7","","25","","","13-13 Dec. 2010","","IEEE","IEEE Conference Publications"
"Detecting spam comments with malicious users' behavioral characteristics","Qianqian Wang; Bin Liang; Wenchang Shi; Zhaohui Liang; Wei Sun","Key Laboratory of Data Engineering and Knowledge Engineering, MOE, School of Information, Renmin University of China, Beijing, China","2010 IEEE International Conference on Information Theory and Information Security","20110117","2010","","","563","567","In recent years, the spread of spam comments has become a main obstacle which limits the development of commercialized social networks. This paper analyzes the differences of behavioral characteristics between normal users and malicious users. Based on these characteristics, we propose several heuristic methods to detect spam comments. These methods evaluate comments from three perspectives, including time-frequency characteristic of comments, text similarity of comments and the number of target domains each user's comments refer to. In our collected dataset, our experimental results indicate the accuracy of our detection strategy I (strategy for high accuracy) and strategy II (strategy for wide coverage) are 100% and 92.6%, respectively. The preliminary evaluation of the proposed detection methods shows promising result.","","Electronic:978-1-4244-6943-7; POD:978-1-4244-6942-0","10.1109/ICITIS.2010.5689532","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5689532","commercialized social network;spam comment;spam detection","Accuracy;Books;Commercialization;Conferences;Filtering;Time series analysis;Unsolicited electronic mail","information retrieval;social networking (online);unsolicited e-mail","commercialized social network;heuristic method;malicious user behavioral characteristic;spam comment detection;text similarity;time-frequency characteristic","","2","","15","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"The technology of music retrieval by humming and its application in internet music search system","Yunfeng Dong; Bei Qi","Computing Center, Shandong Institute of Light Industry, Jinan, China","2010 IEEE International Conference on Information Theory and Information Security","20110117","2010","","","50","53","This paper applied the technology of music retrieval by humming into music retrieval by humming, proposed a complete framework of humming retrieval. We has proposed a new energy-based note segmentation algorithm and a new approximate matching algorithm-similarity matching. Based on the note segmentation and pitch extraction, we use the characteristics of algorithms to achieve core functions of internet music search system. The author did experiments on the system of internet music search by humming, and got the result that the algorithms' comprehensive efficiency is superior, on the two standard of the query hit ratio and query speed. The framework, which we proposed, is applicable to the internet music search.","","Electronic:978-1-4244-6943-7; POD:978-1-4244-6942-0","10.1109/ICITIS.2010.5689627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5689627","Dynamic Time Wrapping;Large-scale music library;Query by humming;Similarity matching algorithm","Computer applications;Educational institutions;Face recognition;Feature extraction;Gabor filters;Information science;Principal component analysis","Internet;feature extraction;information retrieval;music;pattern matching","Internet music search system;approximate matching algorithm;energy based note segmentation;humming retrieval;music retrieval;pitch extraction;similarity matching","","0","","5","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Co-operative mobile and static agents for distributed communication systems for data mining applications","P. T. Kavitha; T. Sasipraba","Sathyabama University, Chennai","INTERACT-2010","20110131","2010","","","108","110","A mobile agent is a program that can travel during execution from one system to another system in a massive network. Mobile agent interacts with static agents and other resources to perform its task autonomously. Mobile agents are particularly attractive in distributed information retrieval applications. This paper discusses about how to parallelize the incremental algorithm for mining distributed dynamic datasets. This minimizes communication overhead between distributed systems and the central system. In this distributed approach, we use static agents at each distributed local system which are capable of generating local model (each static agent has a summary of its own database) as well as the global model (carries the summary of the entire data base) of the frequent item sets. This ability permits our system to generate high contrast frequent item sets, which allow us to examine how the data is positioned over different systems. Using the capabilities of the mobile agent, the knowledge could be retrieved from the local systems to the central system for making the communication process better and easier between the distributed systems.","","Electronic:978-1-4244-9006-6; POD:978-1-4244-9004-2","10.1109/INTERACT.2010.5706211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706211","","Association rules;Conferences;Decision making;Distributed databases;Heuristic algorithms;Mobile agents","data mining;distributed processing;information retrieval;mobile agents","central system;cooperative mobile agents;cooperative static agents;data mining;distributed communication systems;distributed dynamic dataset mining;distributed information retrieval;incremental algorithm","","0","","10","","","3-5 Dec. 2010","","IEEE","IEEE Conference Publications"
"Multidimensional Data Model Research for Data Mart Based Analysis System of Drilling Fluid","L. Jian; W. Bing; X. Bihua; L. Dachun","Sch. of Comput. Sci., Southwest Pet. Univ., Chengdu, China","2010 Second WRI Global Congress on Intelligent Systems","20110204","2010","1","","149","152","For the sake of complex analysis requirements of drilling fluid analysis system, this paper proposes a multidimensional data model and implement the solution of data mart due to the analyzing weaknesses of conventional information system. Since the database system is only applied to undertake the daily manipulating application of raw data, and supports simple works of search and statistic, however, the data mart which is enable users to retrieval and exchange raw business data from homologous source databases, setups multidimensional data model for providing a considerable analysis circumstance to decision-makers that fills users' complex analysis requirements. This paper has taken “drilling fluid efficiency analysis” as a typical case, and illustrated the method of data mart implementation through applying multidimensional data model.","2155-6083;21556083","Electronic:978-0-7695-4304-8; POD:978-1-4244-9247-3","10.1109/GCIS.2010.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708732","Data Mart;Dimension Tables;Fact Tables;Multi-Analysis;Multidimensional Data Model;drilling fluid","Data models;Data warehouses;Databases;Drilling;Fluids;Servers;Web pages","business data processing;data models;data warehouses;decision making;electronic data interchange;information retrieval;oil drilling","data manipulation;data mart based analysis;database system;decision maker;drilling fluid analysis system;information system;multidimensional data model research;raw business data exchange;raw business data retrieval","","1","","8","","","16-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"A reversible encryption technique for storing weld piece related information during digital archiving of industrial radiographs","P. Nandhini; S. E. Roslin; N. M. Nandhitha","Department of Electronic Sciences, Sathyabama University, Chennai 600 119, India","INTERACT-2010","20110131","2010","","","39","41","Archival of digital radiographs is the growing need in weld industries. However in addition to radiographs, the information about the weld piece must also be stored for future documentation. However the information about the radiographs may be confidential and should not be stored as such. Also matching the radiographs with the corresponding radiographs is also a major area of concern. Hence it necessitates an effective encryption technique that hides the information about the weld piece in the radiograph itself. The proposed technique involves hiding the nature of the weld defect in the radiographs. The paper also proposes an extraction technique to effectively extract the signature image.","","Electronic:978-1-4244-9006-6; POD:978-1-4244-9004-2","10.1109/INTERACT.2010.5706190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706190","Radiographs;embedding;extraction;nature of defect;watermarking","Data mining;Encryption;Radiography;Slag;Watermarking;Welding","cryptography;image watermarking;information retrieval systems;radiography;welding","digital archiving;digital watermarking;documentation;industrial radiograph;reversible encryption technique;signature image;weld piece","","0","","7","","","3-5 Dec. 2010","","IEEE","IEEE Conference Publications"
"Graph-Based Answer Passage Ranking for Question Answering","X. Li; E. Chen","Sch. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China","2010 International Conference on Computational Intelligence and Security","20110120","2010","","","634","638","Passage retrieval of Question Answering (QA) systems aims to find the text segments or sentences that may contain the exact answers for the given question. Previous studies on passage retrieval are mostly utilized a single function to calculate the relevance scores of passages. However, some research has proved that the relations between passages can be utilized to improve the accuracy of relevance evaluation. Hence, a passage retrieval method based on passage-passage graph model is proposed. A KNN-based question expansion method is proposed and then the candidate answer passages are retrieved based on the expanded question model. The passage graph is constructed based on the similarities between the candidate answer passages. Finally, a graph-based ranking model is utilized to re-calculate the relevance scores of the answer passages and the ranking parameter is trained using the learning method. Experiment results show that our method can significantly increase the MRR and TRDR performances compared to the baseline methods.","","Electronic:978-0-7695-4297-3; POD:978-1-4244-9114-8","10.1109/CIS.2010.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5696360","Passage retrieval;graph model;question answering;question similarity;ranking","","graph theory;question answering (information retrieval)","KNN-based question expansion method;expanded question model;graph-based answer passage ranking;k-nearest neighbors based method;learning method;passage retrieval method;passage-passage graph model;question answering systems;relevance evaluation","","0","1","18","","","11-14 Dec. 2010","","IEEE","IEEE Conference Publications"
"Efficient data selection for spoken document retrieval based on prior confidence estimation using speech and context independent models","S. Kobashikawa; T. Asami; Y. Yamaguchi; H. Masataki; S. Takahashi","NTT Cyber Space Labs., NTT Corp., Tokyo, Japan","2010 IEEE Spoken Language Technology Workshop","20110124","2010","","","200","205","This paper proposes an efficient speech sample selection technique that can identify those samples that will be well recognized. Conventional confidence measures can identify well-recognized speech samples, but they require speech recognition to estimate confidence scores. Speech samples with low confidence should not undergo recognition since they yield speech documents that will eventually be rejected. The proposed technique can select the samples that will justify the application of speech recognition. It is based on rapid prior confidence estimation by using speech and context independent models to calculate acoustic likelihood values on a frame-by-frame basis. Tests show that the proposed confidence estimation technique is over 50 times faster than the conventional posterior confidence measure while maintaining equivalent data selection performance for speech recognition and spoken document retrieval.","","Electronic:978-1-4244-7902-3; POD:978-1-4244-7904-7; USB:978-1-4244-7902-3; USB:978-1-5090-5693-4","10.1109/SLT.2010.5700851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5700851","confidence measure;data selection;speech recognition;spoken document retrieval","","document handling;information retrieval;speech recognition","acoustic likelihood values;confidence estimation;context independent model;data selection;speech independent model;speech recognition;speech sample selection technique;spoken document retrieval","","0","","19","","","12-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Representing clinical documents to support automatic retrieval of evidence from the Cochrane Library","D. O'Sullivan; W. Michalowski; M. Michalowski; S. Wilk; K. Farion","School of Engineering and Applied Science, Aston University, UK","2010 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20110128","2010","","","461","466","The overall aim of our research is to develop a clinical information retrieval system that retrieves systematic reviews and underlying clinical studies from the Cochrane Library to support physician decision making. We believe that in order to accomplish this goal we need to develop a mechanism for effectively representing documents that will be retrieved by the application. Therefore, as a first step in developing the retrieval application we have developed a methodology that semi-automatically generates high quality indices and applies them as descriptors to documents from The Cochrane Library. In this paper we present a description and implementation of the automatic indexing methodology and an evaluation that demonstrates that enhanced document representation results in the retrieval of relevant documents for clinical queries. We argue that the evaluation of information retrieval applications should also include an evaluation of the quality of the representation of documents that may be retrieved.","","Electronic:978-1-4244-8304-4; POD:978-1-4244-8303-7","10.1109/BIBMW.2010.5703845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703845","","","bioinformatics;decision making;information retrieval;medical information systems","Cochrane Library;automatic indexing methodology;automatic retrieval;clinical documents;clinical information retrieval system;enhanced document representation;physician decision making;semiautomatically generation","","0","","12","","","18-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Similarity searches of medical image data in peer-to-peer systems","A. Charisi; V. Megalooikonomou","Department of Computer Engineering and Informatics, University of Patras, Greece","Proceedings of the 10th IEEE International Conference on Information Technology and Applications in Biomedicine","20110117","2010","","","1","4","The objective of this study is to effectively perform content-based medical image retrieval in distributed systems. We present a method that constructs a distributed index over a peer-to-peer network. Considering the network bandwidth limitations and other restrictions that are associated with the handling of medical data, we do not further distribute images between the participant peers in the network. We distribute only feature vectors, extracted from each image from which only a low resolution image can be obtained. The images are processed locally at each site. For the index distribution, we develop our own hash function that is based on multi-resolution analysis of the images using the wavelet transform and on a set of reference images that is known to each node in the network. To evaluate our method and demonstrate its applicability, we performed similarity searches on a brain image dataset. We also compared the performance of the distributed system to that of the centralized one.","2168-2194;21682194","Electronic:978-1-4244-6561-3; POD:978-1-4244-6559-0","10.1109/ITAB.2010.5687724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687724","","Biomedical imaging;Brain;Facsimile;Image resolution;Telemedicine","biomedical engineering;brain;cryptography;data handling;information retrieval;medical computing;neurophysiology;peer-to-peer computing;visual databases","brain image dataset;content based medical image retrieval;distributed index;distributed systems;feature vectors;hash function;low resolution image;medical data handling;medical image data;multiresolution analysis;network bandwidth limitations;peer to peer network;peer-to-peer systems;similarity search","","0","","7","","","3-5 Nov. 2010","","IEEE","IEEE Conference Publications"
"Combining implicit measures and information foraging theory to improve web search","Wenjun Hou; Jingjing Yang","Laboratory of Human-Computer Interaction and Multimedia, Beijing University of Posts and Telecommunications, China","2010 3rd IEEE International Conference on Broadband Network and Multimedia Technology (IC-BNMT)","20110131","2010","","","112","116","The massive distributed, dynamical and evolutionary characteristics of World Wide Web inspire us study it drawing on the Information Foraging Theory which assumes that people prefer yield more useful information per unit cost. Understanding the value of implicit measures is also important to help World Wide Web users search more effectively. Borrowing idea from information foraging theory we propose a method to estimate the Web page information gain based on the implicit measures analysis. We developed an experimental search platform to record the URLs of the pages be browsed, the time spent reading, the time spent scrolling and the number of links be clicked. We analyzed these data using multiple linear regression modeling and obtained a regression function which could be used in calculating the information profitability of the Web pages. Then we regrouped the Web pages searched out by the descending order of the Web page information profitability. We also reported experimental data to show that the search results be regrouped can increase searching efficiency. The findings suggest that the combination of information foraging theory and implicit measures analysis support effective Web-search interaction for everyone.","","Electronic:978-1-4244-6772-3; POD:978-1-4244-6769-3","10.1109/ICBNMT.2010.5704879","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704879","Information Foraging Theory;implicit measures;information profitability","Gain measurement;Information filters;Search problems;Web search;World Wide Web","Internet;data analysis;information retrieval;online front-ends;profitability;regression analysis","URL;Web page information gain;Web page information profitability;Web search;information foraging theory;multiple linear regression modeling;world Wide web","","0","","10","","","26-28 Oct. 2010","","IEEE","IEEE Conference Publications"
"A Method of Text Feature Extraction Based on Weighted Scatter Difference","L. Haifeng; S. Zhan; Y. Zeqing; Z. Xueren","Inst. of Sci., PLA Univ. of Sci. & Technol., Nanjing, China","2010 Second WRI Global Congress on Intelligent Systems","20110204","2010","3","","83","86","Feature reduction is one of the core technologies of automatic text categorization. As for the scatter difference criterion, poor categorization effect is made when the between-class distance is small and the class density is high. In order to solve this problem, a weighted method based on the sample distribution is shown in the paper, which will make the between-class and within-class scatter matrixes with poor scatter be weighted, to enhance the categorization ability after dimensional reduction and to improve the dimensional reduction effect of linear feature extraction method based on scatter difference. The following experiment tells us that this method is superior to the original maximum scatter difference method in precision rate and recall rate.","2155-6083;21556083","Electronic:978-0-7695-4304-8; POD:978-1-4244-9247-3","10.1109/GCIS.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5709328","feature extraction;feature reduction;scatter difference;text classification","Covariance matrix;Feature extraction;Imaging;Support vector machine classification;Text categorization;Training;Vectors","feature extraction;information retrieval;text analysis","automatic text categorization;core technologies;feature reduction;text feature extraction method;weighted scatter difference","","0","","6","","","16-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Integrating DBMSs as a Read-Only Execution Layer into Hadoop","M. An; Y. Wang; W. Wang; N. Sun","Key Lab. of Comput. Syst. & Archit., Grad. Univ. of Chinese Acad. of Sci., Beijing, China","2010 International Conference on Parallel and Distributed Computing, Applications and Technologies","20110128","2010","","","17","26","To obtain the efficiency of DBMS, HadoopDB combines Hadoop and DBMS, and claims the superiority over Hadoop in terms of performance. However, the approach of HadoopDB is simply putting Map Reduce onto unmodified single-machined DBMSs which has several obvious weaknesses. In essence, HadoopDB is a parallel DBMS with fault tolerance, which incurs unnecessary overhead due to the DBMS legacy. Instead of augmenting DBMS with Hadoop techniques, we propose a new system architecture integrating modified DBMS engines as a read-only execution layer into Hadoop, where DBMS plays a role of providing efficient read-only operators rather than managing the data. Besides the obtained efficiency from DBMS engine, there are other advantages. The modified DBMS engine is able to directly process data from the HDFS (Hadoop Distributed File System) files at the block level, which means that the data replication can be handled by HDFS naturally, and the block-level parallelism is easily achieved. The global index access mechanism is added according to the Map Reduce paradigm. The data loading speed is also guaranteed by directly writing the data into HDFS with simplified logic. Experiments show that our system outperforms both original Hadoop and HadoopDB styled system.","2379-5352;23795352","Electronic:978-0-7695-4287-4; POD:978-1-4244-9110-0","10.1109/PDCAT.2010.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704399","Hadoop;database;global index access;large-scale data processing","Engines;Fault tolerance;Fault tolerant systems;Indexes;Loading;Parallel processing","data handling;fault tolerant computing;information retrieval;parallel databases;software architecture","DBMS engine;HDFS;Hadoop distributed file system;HadoopDB;MapReduce;block-level parallelism;data processing;database management system;fault tolerance;index access;parallel DBMS;read-only execution layer;single-machined DBMS;system architecture","","2","","17","","","8-11 Dec. 2010","","IEEE","IEEE Conference Publications"
"Information acquisition strategies for Bayesian network-based decision support","R. Johansson; C. Mårtenson","Informatics Research Centre, University of Sko&#x00A8;vde","2010 13th International Conference on Information Fusion","20110210","2010","","","1","8","Determining how to utilize information acquisition resources optimally is a difficult task in the intelligence domain. Nevertheless, an intelligence analyst can expect little or no support for this from software tools today. In this paper, we describe a proof of concept implementation of a resource allocation mechanism for an intelligence analysis support system. The system uses a Bayesian network to structure intelligence requests, and the goal is to minimize the uncertainty of a variable of interest. A number of allocation strategies are discussed and evaluated through simulations.","","Electronic:978-0-9824438-1-1","10.1109/ICIF.2010.5712030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5712030","Bayesian networks;decision support tool;information acquisition","Analytical models;Bayesian methods;Biological system modeling;Entropy;Knowledge engineering;Sensors;Uncertainty","belief networks;decision support systems;information retrieval;resource allocation","Bayesian network-based decision support;information acquisition resources;information acquisition strategies;intelligence analysis support system;resource allocation","","0","","7","","","26-29 July 2010","","IEEE","IEEE Conference Publications"
"Functionalities for Blog Conversation: An Investigation about the Use of Quote and Reply","A. de Miranda Marques; M. Pimentel; S. Siqueira","Dept. de Inf. Aplic., Univ. Fed. do Estado do Rio de Janeiro, Rio de Janeiro, Brazil","2010 Brazilian Symposium on Collaborative Systems - Simposio Brasileiro de Sistemas Colaborativos","20110120","2010","","","9","16","The blog is featured as a communication system for dissemination of information and expression of opinions. Is the blog a system suitable for collaboration? The research presented in this paper investigates the use of citation and response to enable a conversation on the blog. From analysis of the discourse structuring and the possibilities of relationship among participants, were developed some research questions that guided the research on the citation functionality and response functionality. To investigate the research questions, we performed a case study explanatory using the blog as a support method for Project-based Collaborative Learning. Explanatory case study, citation functionality and response functionality were varied between the stages of the dynamics so that they could observe the influence of each functionality in the conversation among students. As a result of the study, we observed that the citation functionality was hardly used by bloggers because of usability problems and the lack of culture usage and the response functionality was used moderately. There is a preference among bloggers to use the response functionality to replicate the comments received from readers. It was not possible to infer in this research whether it's better to make available both features: the quote and the reply, only one or none (only the comment for a post).","2326-2826;23262826","Electronic:978-0-7695-4239-3; POD:978-1-4244-8445-4","10.1109/SBSC.2010.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5698491","blogs;citation functionality;discourse structuring;relationship among participants;response functionality","","Web sites;groupware;information dissemination;learning (artificial intelligence);question answering (information retrieval)","Blog conversation;information dissemination;project-based collaborative learning;quote functionality;reply functionality;research question","","0","","22","","","5-8 Oct. 2010","","IEEE","IEEE Conference Publications"
"Direct and latent modeling techniques for computing spoken document similarity","T. J. Hazen","MIT Lincoln Laboratory, Lexington, Massachusetts, USA","2010 IEEE Spoken Language Technology Workshop","20110124","2010","","","366","371","Document similarity measures are required for a variety of data organization and retrieval tasks including document clustering, document link detection, and query-by-example document retrieval. In this paper we examine existing and novel document similarity measures for use with spoken document collections processed with automatic speech recognition (ASR) technology. We compare direct vector space approaches using the cosine similarity measure applied to feature vectors constructed with various forms of term frequency inverse document frequency (TF-IDF) normalization against latent topic modeling approaches based on latent Dirichlet allocation (LDA). In document link detection experiments on the Fisher Corpus, we find that an approach that applies bagging to models derived from LDA substantially outperforms the direct vector space approach.","","Electronic:978-1-4244-7902-3; POD:978-1-4244-7904-7; USB:978-1-4244-7902-3; USB:978-1-5090-5693-4","10.1109/SLT.2010.5700880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5700880","document link detection;document similarity;latent topic modeling","","document handling;file organisation;information retrieval;speech recognition","Fisher corpus;automatic speech recognition technology;data organization;direct modeling techniques;document link detection experiments;latent Dirichlet allocation;latent modeling techniques;query-by-example document retrieval;spoken document similarity computing;term frequency inverse document frequency normalization","","7","","14","","","12-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Search results presentation and interface design: A comparative evaluation study of five web search engines in Arabic language","W. Tawileh; T. Mandl; J. Griesbaum","Institute of Information Science, University of Hildesheim, Hildesheim, Germany","2010 10th International Conference on Intelligent Systems Design and Applications","20110113","2010","","","592","597","An evaluation study performed in Arabic language on the five web search engines Araby, Ayna, Google, MSN and Yahoo aimed to compare how good these search engines can satisfy the information needs of native Arab users on the internet in their mother tongue. The top ten search results for fifty randomly selected search queries and the descriptions of these results in the search results list were evaluated by independent jurors on a web information retrieval basis. Comparing the relevance of results descriptions presented by each search engine and the relevance of the search results themselves, a big difference was found between search results and their descriptions for all tested engines. Six usability aspects of the tested search engines where also evaluated from the jurors' perspective. Google reached the higher usability evaluation score followed by Yahoo then MSN. The two native Arabic search engines Araby and Ayna seemed to be less accepted by participated Arab internet users.","2164-7143;21647143","Electronic:978-1-4244-8136-1; POD:978-1-4244-8134-7","10.1109/ISDA.2010.5687201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687201","Arabic;Web information retireval;evaluation;interface design;results description;search engines;usability test","","Internet;information retrieval;search engines","Arabic language;Araby;Ayna;Google;Internet;MSN;Yahoo;interface design;native Arab users;usability test;web information retrieval basis;web search engines","","1","","16","","","Nov. 29 2010-Dec. 1 2010","","IEEE","IEEE Conference Publications"
"Reviewer Profiling Using Sparse Matrix Regression","E. E. Papalexakis; N. D. Sidiropoulos; M. N. Garofalakis","Dept. of ECE, Tech. Univ. of Crete, Chania, Greece","2010 IEEE International Conference on Data Mining Workshops","20110120","2010","","","1214","1219","Thousands of scientific conferences happen every year, and each involves a laborious scientific peer review process conducted by one or more busy scientists serving as Technical/Scientific Program Committee (TPC) chair(s). The chair(s) must match submitted papers to their reviewer pool in such a way that i) each paper is reviewed by experts in its subject matter, and ii) no reviewer is overloaded with reviews or under-utilized. Towards this end, seasoned TPC chairs know the value of reviewer and paper profiling: summarizing the expertise/interests of each reviewer and the subject matter of each paper using judiciously chosen domain-specific keywords. An automated profiling algorithm is proposed for this purpose, which starts from generic/noisy reviewer profiles extracted using Google Scholar and derives custom conference-centric reviewer and paper profiles. Each reviewer is expert on few sub-topics, whereas the pool of reviewers and the conference may collectively need many more keywords for appropriate specificity. Exploiting this sparsity, we propose a sparse matrix factorization approach in lieu of classical SVD-based LSI or NMF-type approaches. We illustrate the merits of our approach using real conference data, and expert scoring of the assignments by a seasoned TPC chair in the area.","2375-9232;23759232","Electronic:978-0-7695-4257-7; POD:978-1-4244-9244-2","10.1109/ICDMW.2010.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693432","Reviewer profiling;lasso;latent semantic indexing;non-negative matrix factorization;singular value decomposition;sparse regression;text mining","","information retrieval;regression analysis;scientific information systems;search engines;singular value decomposition;sparse matrices;text analysis","Google scholar;TPC chair;automated profiling algorithm;custom conference-centric reviewer;domain-specific keyword;expert review;generic reviewer profile extraction;noisy reviewer profile extraction;paper profiling;reviewer profiling;scientific peer review process;singular value decomposition;sparse matrix factorization;sparse matrix regression;technical-scientific program committee","","4","","9","","","13-13 Dec. 2010","","IEEE","IEEE Conference Publications"
"Solely Tag-Based Music Genre Classification","C. Zhen; J. Xu","Comput. Sci. Dept., Renmin Univ. of China, Beijing, China","2010 International Conference on Web Information Systems and Mining","20110113","2010","1","","20","24","As a fundamental and critical component of music information retrieval (MIR) systems, automatically classifying music by genre is a challenging problem. The approaches depending on low-level audio features may not be able to obtain satisfactory results. In recent years, the social tags have emerged as an important way to provide information about resources on the Web. In this paper we are interested in another aspect, namely how perform automatic music genre classification solely depending on the available tag data. Two classification methods based on the social tags (including music-tag and artist-tag) which crawled from Last. fm are developed in our work. The first one, we use the generative probabilistic model Latent Dirichlet Allocation (LDA) to analyze the music-tag. Then, we can compute the probability of every tag belonging to each music genre. The starting point of the second method is that music's artist is often associated with music genres more closely. Therefore, we can calculate the similarity between the artist-tags to infer which genre the music belongs to. At last, our experimental results demonstrate the benefit of using tags for accurate music genre classification.","","Electronic:978-0-7695-4224-9; POD:978-1-4244-8438-6","10.1109/WISM.2010.152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662276","LDA;artist tag;music genre classification;music tag","","Internet;classification;information retrieval;information retrieval systems;music;probability","Web;latent Dirichlet allocation;music information retrieval systems;social tags;solely tag-based music genre classification","","0","","13","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Service of Searching and Ranking in a Semantic-Based Expert Information System","L. Yang; Z. Hu; J. Long","Central South Univ., Changsha, China","2010 IEEE Asia-Pacific Services Computing Conference","20110204","2010","","","609","614","Selecting professional and authoritative experts to evaluate projects is an essential process in order to assure the quality of projects. In this paper, we present a semantic-based expert information system, which search for expert information based on semantic and knowledge reasoning, and rank the search results according to the scientific capability of experts. We design software architecture for semantic-based information service system (Esoogle). Expert information ontology is defined to store the information of experts, and reasoning rules are defined for semantic-based reasoning. Assessment model based on TOPSIS is built to estimate the scientific capability for ranking. Applications show Esoogle improves the recall and precision of semantic-based searching service compared to the traditional systems and ranking service is helpful for the users to select suitable experts quickly.","","Electronic:978-0-7695-4305-5; POD:978-1-4244-9396-8","10.1109/APSCC.2010.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708628","TOPSIS;expert information service;ontology;ranking;semantic;semantic-based search","Cognition;Engines;Information systems;OWL;Ontologies;Semantics","expert systems;inference mechanisms;information retrieval;information retrieval systems;information storage;ontologies (artificial intelligence);project management;semantic Web;software architecture","Esoogle;TOPSIS;assessment model;authoritative experts;expert information ontology;expert scientific capability;information storage;knowledge reasoning;professional experts;project evaluation;project quality;ranking service;reasoning rules;semantic reasoning;semantic-based expert information system;semantic-based information service system;semantic-based reasoning;semantic-based searching service;software architecture","","2","","25","","","6-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"TissueWiki<sup>Mobile</sup>: An integrative protein expression image browser for pathological knowledge sharing and annotation on a mobile device","C. Cheng; T. H. Stokes; S. Hang; M. D. Wang","Electrical and Computer Engineering, Georgia Institute of Technology, USA","2010 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20110128","2010","","","473","480","Doctors need fast and convenient access to medical data. This motivates the use of mobile devices for knowledge retrieval and sharing. We have developed TissueWiki<sup>Mobile</sup> on the Apple iPhone and iPad to seamlessly access TissueWiki, an enormous repository of medical histology images. TissueWiki is a three terabyte database of antibody information and histology images from the Human Protein Atlas (HPA). Using TissueWiki<sup>Mobile</sup>, users are capable of extracting knowledge from protein expression, adding annotations to highlight regions of interest on images, and sharing their professional insight. By providing an intuitive human computer interface, users can efficiently operate TissueWiki<sup>Mobile</sup> to access important biomedical data without losing mobility. TissueWiki<sup>Mobile</sup> furnishes the health community a ubiquitous way to collaborate and share their expert opinions not only on the performance of various antibodies stains but also on histology image annotation.","","Electronic:978-1-4244-8304-4; POD:978-1-4244-8303-7","10.1109/BIBMW.2010.5703848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703848","histological image;image annotation;knowledge sharing;mobile medical device","","PACS;bioinformatics;biomedical equipment;file servers;information retrieval;knowledge acquisition;mobile handsets;molecular biophysics;online front-ends;proteins","Apple iPhone;PACS;Picture Archiving and Communication System;TissueWiki;antibody information;antibody stain;digital medical imaging;histology image annotation;human protein atlas;iPad;integrative protein expression image browser;knowledge extraction;knowledge retrieval;knowledge sharing;medical data access;medical histology images;memory size 3 TByte;mobile device;pathological knowledge sharing;protein expression;three terabyte database","","0","","25","","","18-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Stability analysis for ranking algorithms","Wei Gao; Yungang Zhang; Li Liang; Youming Xia","Department of Information, Yunnan Normal University, Kunming, China","2010 IEEE International Conference on Information Theory and Information Security","20110117","2010","","","973","976","In this paper, the stability of ranking algorithms is studied by adopting a strategy which adjusts the sample set by deleting one or two element from it. Relationship between uniform loss stability and uniform score stability is investigated. A sufficient condition for uniform score stability is given. The result of our work shows that if a uniform score stability ranking algorithm use γ ranking loss, then it has uniform loss stability; also, if for any x, a kernel function K(x, x) has a limited upper bound, then the ranking algorithm which minimizes the regularization empirical l-error will have good uniform score stability.","","Electronic:978-1-4244-6943-7; POD:978-1-4244-6942-0","10.1109/ICITIS.2010.5689665","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5689665","RKHS;ranking;ranking loss function;uniform loss stability;uniform score stability","Algorithm design and analysis;Kernel;Machine learning algorithms;Manganese;Stability analysis;Thermal stability;Training","algorithm theory;information retrieval;search engines","ranking algorithm stability;uniform loss stability;uniform score stability","","1","","14","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Simulation-Based Evaluation of Resource Allocation Strategies for Archival Management Workflow: The Macau Case","V. I. Chan; Y. W. Si","Fac. of Sci. & Technol., Univ. of Macau, Macau, China","2010 IEEE 7th International Conference on E-Business Engineering","20110128","2010","","","338","344","Workflow management systems are widely adopted for implementing business processes. Archival workflow is a precise representation of the archival process, reflecting the formal coordination mechanisms between archival activities and manual processes with respect to the specific requirements of the local governing body. Understanding key performance indicators of archival processes is considered as one of the crucial factors for the government organizations. Process Simulation enables detailed analysis of such performance indicators without actually deploying the processes. In this paper, we analyze a number of resource allocation strategies for the existing workflow model from Macau Historical Archives using Colored Petri Nets models. Based on these models, the strengths and the weaknesses of each resource assignment schemes are evaluated against a number of performance indicators.","","Electronic:978-0-7695-4227-0; POD:978-1-4244-8386-0","10.1109/ICEBE.2010.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704337","archival management workflow;process simulation;resource assignment","Analytical models;Appraisal;Computational modeling;Government;Resource management","Petri nets;business data processing;information retrieval systems;resource allocation;workflow management software","Macau historical archives;archival management workflow;business processes;colored Petri nets models;formal coordination mechanisms;government organizations;resource allocation strategies;simulation-based evaluation;workflow management systems","","0","","22","","","10-12 Nov. 2010","","IEEE","IEEE Conference Publications"
"Data Replication and Power Consumption in Data Grids","S. V. Vrbsky; M. Lei; K. Smith; J. Byrd","Dept. of Comput. Sci., Univ. of Alabama, Tuscaloosa, AL, USA","2010 IEEE Second International Conference on Cloud Computing Technology and Science","20110204","2010","","","288","295","While data grids can provide the ability to solve large-scale applications which require the processing of large amounts of data, they have been recognized as extremely energy inefficient. Computing elements can be located far away from the data storage elements. A common solution to improve availability and file access time in such environments is to replicate the data, resulting in the creation of copies of data files at many different sites. The energy efficiency of the data centers storing this data is one of the biggest issues in data intensive computing. Since power is needed to transmit, store and cool the data, we propose to minimize the amount of data transmitted and stored by utilizing smart replication strategies that are data aware. In this paper we present a new data replication approach, called the sliding window replica strategy (SWIN), that is not only data aware, but is also energy efficient. We measure the performance of SWIN and existing replica strategies on our Sage green cluster to study the power consumption of the strategies. Results from this study have implications beyond our cluster to the management of data in clouds.","","Electronic:978-0-7695-4302-4; POD:978-1-4244-9405-7","10.1109/CloudCom.2010.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708462","data cluster;data grid;data intensive computing;data replication;power consumption;sliding window protocol","Availability;Cooling;Data models;Distributed databases;Energy efficiency;Green products;Servers","file organisation;grid computing;information retrieval;pattern clustering","SWIN;Sage green cluster;data center;data grid power consumption;data intensive computing;data management;data processing;data replication;data storage element;file access;sliding window replica strategy","","10","","23","","","Nov. 30 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Improved Consistent Sampling, Weighted Minhash and L1 Sketching","S. Ioffe","Google Inc., Mountain View, CA, USA","2010 IEEE International Conference on Data Mining","20110120","2010","","","246","255","We propose a new Consistent Weighted Sampling method, where the probability of drawing identical samples for a pair of inputs is equal to their Jaccard similarity. Our method takes deterministic constant time per non-zero weight, improving on the best previous approach which takes expected constant time. The samples can be used as Weighted Minhash for efficient retrieval and compression (sketching) under Jaccard or L1 metric. A method is presented for using simple data statistics to reduce the running time of hash computation by two orders of magnitude. We compare our method with the random projection method and show that it has better characteristics for retrieval under L1. We present a novel method of mapping hashes to short bit-strings, apply it to Weighted Minhash, and achieve more accurate distance estimates from sketches than existing methods, as long as the inputs are sufficiently distinct. We show how to choose the optimal number of bits per hash for sketching, and demonstrate experimental results which agree with the theoretical analysis.","1550-4786;15504786","Electronic:978-0-7695-4256-0; POD:978-1-4244-9131-5","10.1109/ICDM.2010.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693978","Compression;Hashing;Minhash;Retrieval;Sampling;Sketching","","cryptography;data compression;file organisation;information retrieval;pattern matching;sampling methods","Jaccard similarity;L1 sketching;bit string;consistent weighted sampling method;data statistics;deterministic constant time;hash computation;random projection method;running time reduction;sample compression;sample retrieval;weighted Minhash","","9","11","13","","","13-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"The technique of IMS Sh interface and its NGN LBS application","Jih-Wei Tsai; Chao-Chun Huang; Chih-Sheng Chang; Chung-Shih Tang; Chin-Ywu Twu","Broadband Network Technology Lab., Telecommunication Laboratories, Chunghwa Telecom Co., Ltd. Taiwan, R.O.C.","2010 IEEE 12th International Conference on Communication Technology","20110117","2010","","","599","602","In this paper, the technique of IP Multimedia Subsystem (IMS) Sh interface (Diameter) is introduced. The architecture for service provision of IMS is shown. The messages and user data on the Sh interface are presented. Then the Location-Based Services (LBS) in the IMS/NGN Network of Chunghwa Telecom Labs. of Taiwan, R.O.C. are illustrated. At first, the location information is obtained by PANI SIP header for the caller and by TLS/SSL (https) to the Connectivity Session Location and Repository Function (CLF) via outbound for the callee. Next, an alternative way of it is by Sh interface to look up the related data of IMS user identity from the Home Subscriber Server (HSS). Because it is via inbound and in the IMS core network only; moreover, it is better in retrieving any specified location information regardless session case of the caller or callee. Hence it is an efficient application for the fixed User Equipment (UE).","","Electronic:978-1-4244-6871-3; POD:978-1-4244-6868-3","10.1109/ICCT.2010.5688932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5688932","Diameter;IMS/NGN;Location-Based Service;Sh Interface","Authentication;Geographic Information Systems;IP networks;Multimedia communication;Quantum cascade lasers;Subscriptions;Syntactics","IP networks;information retrieval;mobile computing;multimedia systems;next generation networks;signalling protocols","CLF;Chunghwa telecom labs;HSS;IMS Sh interface;IP multimedia subsystem Sh interface;NGN LBS application;PANI SIP header;TLS-SSL;connectivity session location and repository function;home subscriber server;location information retrieval;location-based services;next generation network;session initialization protocol","","0","","9","","","11-14 Nov. 2010","","IEEE","IEEE Conference Publications"
"Ranking-Based Emotion Recognition for Music Organization and Retrieval","Y. H. Yang; H. H. Chen","Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan","IEEE Transactions on Audio, Speech, and Language Processing","20110210","2011","19","4","762","774","Determining the emotion of a song that best characterizes the affective content of the song is a challenging issue due to the difficulty of collecting reliable ground truth data and the semantic gap between human's perception and the music signal of the song. To address this issue, we represent an emotion as a point in the Cartesian space with valence and arousal as the dimensions and determine the coordinates of a song by the relative emotion of the song with respect to other songs. We also develop an RBF-ListNet algorithm to optimize the ranking-based objective function of our approach. The cognitive load of annotation, the accuracy of emotion recognition, and the subjective quality of the proposed approach are extensively evaluated. Experimental results show that this ranking-based approach simplifies emotion annotation and enhances the reliability of the ground truth. The performance of our algorithm for valence recognition reaches 0.326 in Gamma statistic.","1558-7916;15587916","","10.1109/TASL.2010.2064164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5545401","Arousal;learning-to-rank;music emotion recognition;music emotion tournament;ranking;rating;valence","","audio signal processing;cognitive systems;emotion recognition;information retrieval;music;radial basis function networks","Cartesian space;RBF-ListNet algorithm;emotion annotation;gamma statistic;human perception;music organization;music retrieval;music signal;radial basis function;ranking-based emotion recognition;ranking-based objective function optimization","","37","","67","","20100809","May 2011","","IEEE","IEEE Journals & Magazines"
"RnR: Extracting Rationale from Online Reviews and Ratings","D. A. Rahayu; S. Krishnaswamy; O. Alahakoon; C. Labbe","Centre for Distrib. Syst. & Software Eng., Monash Univ., Melbourne, VIC, Australia","2010 IEEE International Conference on Data Mining Workshops","20110120","2010","","","358","368","Review mining is a part of web mining which focuses on getting main information from user review. State of the art review mining systems focus on identifying semantic orientation of reviews and providing sentences or feature scores. There has been little focus on understanding the rationale for the ratings that are provided. This paper presents our proposed RnR system for extracting rationale from online reviews and ratings. We have implemented the system for evaluation on online reviews for hotels from TripAdvisor.com and present extensive experimental evaluation that demonstrates the improved computational performance of our approach and the accuracy in terms of identifying the rationale. This RnR system is available for testing from http://rnrsystem.com/RnRSystem.","2375-9232;23759232","Electronic:978-0-7695-4257-7; POD:978-1-4244-9244-2","10.1109/ICDMW.2010.167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693321","Review mining;ontology;ratings;rationale","","Web sites;data mining;information retrieval systems;relevance feedback;reviews","RnR system;online ratings rationale extraction;online reviews rationale extraction;user review mining systems;web mining","","0","","19","","","13-13 Dec. 2010","","IEEE","IEEE Conference Publications"
"Despeckling Synthetic Aperture Radar images with cloud computing using graphics processing units","M. Kseneman; D. Gleich; A. Chowdhury","Margento R & D d.o.o., Gosposvetska cesta 84, Maribor, Slovenia","5th International Conference on Pervasive Computing and Applications","20110128","2010","","","195","200","This paper presents the implementation of Synthetic Aperture Radar (SAR) image enhancement and information extraction techniques using multicore Graphic Processing Units (GPUs) connected into a cloud computing environment. The Bayesian approach to SAR image despeckling and information extraction is presented. The first order Bayesian inference is used to estimate a maximum a posteriori (MAP) estimate. A prior is modeled using Gauss-Markov Random Fields (GMRF). The second order Bayesian inference is used to find the best model parameters, which represent texture information in SAR images. The algorithm is rewritten in matrix form to fully exploit GPUs computing power. GMRF on GPU give good results for despeckling and information extraction, but this algorithm is also very computationally demanding. This paper presents the implementation of the MAP estimator and evidence maximization using GPUs. The image is divided into subblocks and each subblock has as many threads as there are pixels inside the subblock. The estimation of MAP solution and its corresponding model is computed separately in each thread in the sub-block The GPUs implementation of the model-based despeckling is about 95-times faster as the implementation of the same algorithm on multicore CPUs on a development system. The whole cloud computing environment has proven to be fast and robust.","","Electronic:978-1-4244-9143-8; POD:978-1-4244-9144-5","10.1109/ICPCA.2010.5704097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704097","Bayesian inference;Cloud Data Computing;GPU;SAR;speckle reduction","","Bayes methods;Gaussian processes;Markov processes;cloud computing;computer graphic equipment;coprocessors;image texture;inference mechanisms;information retrieval;multiprocessing systems;optimisation;radar imaging;random processes;synthetic aperture radar","GPU computing power;Gauss-Markov random fields;MAP estimator;cloud computing;evidence maximization;image despeckling;information extraction techniques;maximum a posteriori estimate;multicore CPU;multicore graphic processing unit;second order Bayesian inference;synthetic aperture radar image enhancement;texture information","","1","","9","","","1-3 Dec. 2010","","IEEE","IEEE Conference Publications"
"Network security and management","B. Singh","Computer Science, University of Lucknow, Lucknow-226 007","2010 IEEE International Conference on Computational Intelligence and Computing Research","20110131","2010","","","1","6","In the past few years government and military organizations have widely adopted LAN, WAN and Internet to take advantage of advancement in technology. Computers are integral part of everyday operations. Organizations depend on them. A computer failure will have a critical impact on the organization. The term “Security” brings to mind all shorts of issues that refer to data protection and prevention of unauthorised access. The common motives for computer crimes could be lure for money, revenge, terrorism, fun, recognition or curiosity. Information systems can be attacked by outsiders who may penetrate a computer system or by insiders who are authorised to use the resources but misuse their authorization. An attacker may disrupt the information system of an organization (active attack) or gain access to its sensitive information (passive attack). Although no direct damage is done in a passive attack, any leak in information could have drastic repercussions for the organization. In simple words, security can be defined as: protecting information system from intended access. The goal of network management is to provide users with a quality of service. To meet this goal, network services plan involve strategic and technical planning of engineering, operations and maintenance of the network. The field of network security and management is constantly undergoing changes in technology, applications and hence the need for continually changing skills set on the part of academics. We will try to cover the various points with respect to organizational structure, policies and techniques of network security and management. Impact of various factors including management has been discussed on network security.","","Electronic:978-1-4244-5967-4; POD:978-1-4244-5965-0","10.1109/ICCIC.2010.5705886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5705886","","","authorisation;computer crime;computer network management;computer network security;information retrieval;information systems;strategic planning;telecommunication network planning","computer crimes;data protection;information access;information system security;network maintenance;network management;network security;network service plan;quality of service;strategic planning;technical planning;unauthorised access","","0","","","","","28-29 Dec. 2010","","IEEE","IEEE Conference Publications"
"Content based mammogram image retrieval based on the multiclass visual problem","F. Siyahjani; E. Fatemizadeh","Biomedical Signal and Image Processing Lab (BiSIPL), School of Electrical Engineering, Sharif University of Technology, Iran","2010 17th Iranian Conference of Biomedical Engineering (ICBME)","20110131","2010","","","1","4","Since expertise elicited from past resolved cases plays an important role in medical application and images acquired from various cases have a great contribution to diagnosis of the abnormalities, Content based medical image retrieval has become an active research area for many scientists, In this article we proposed a new framework to retrieve visually similar images from a large database, in which visual relevance is regarded as much as the semantic category similarity, we used optimized wavelet transform as the multi-resolution analysis of the images and extracted various statistical SGLDM features from different resolutions then after reducing feature space we used error correcting codes in order to untwist the existing multiclass visual problem introduced in preceding parts of the article, we implemented proposed algorithm on the 1000 mammograms provided by the DDSM database which consist of 2500 studies and their annotations provided by specialists.","","Electronic:978-1-4244-7484-4; POD:978-1-4244-7483-7","10.1109/ICBME.2010.5704958","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704958","CBIR;ECOC;lifting scheme;relevant;visual-similarity","","diagnostic radiography;error correction codes;information retrieval;mammography;medical image processing;visual databases;wavelet transforms","content based mammogram image retrieval;error correcting codes;large image database;mammograms;multiclass visual problem;multiresolution image analysis;optimized wavelet transform;semantic category similarity;statistical SGLDM features;visually similar image retrieval","","1","","9","","","3-4 Nov. 2010","","IEEE","IEEE Conference Publications"
"Intelligent Scheme Design of High-Rise Structure for K-Means-Based Case Retrieval","S. Zhang; C. Wang; S. Liu","Sch. of Civil Eng., Harbin Inst. of Technol., Harbin, China","2010 Second WRI Global Congress on Intelligent Systems","20110204","2010","3","","241","244","In the basic idea of k-means clustering algorithm and its criterion function, step process, the cluster analysis theory and method into intelligent design of high-rise structure was introduced in this paper, the high-rise structure of intelligent design case retrieval method based on the K-Means clustering analysis method was established, and by the given engineering application, the process of clustering results and their spatial distribution, the evaluation function J<sub>W</sub> with the curves of the increase in the number of iterations and J<sub>W</sub> monotonically decreasing curve with k( the number of clusters k changes from 2 to 10) were obtained, the weaknesses of the method were pointed out, and the further improvement was given. Practice shows that: k-means cluster analysis method can be effectively used to design case retrieval system in high-rise structures intelligent scheme, and has opened up new ways for the high-rise building intelligent design.","2155-6083;21556083","Electronic:978-0-7695-4304-8; POD:978-1-4244-9247-3","10.1109/GCIS.2010.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5709365","case retrieval;cluster analysis;high-rise building;k-means algorithm;structural intelligent scheme design","Algorithm design and analysis;Artificial intelligence;Buildings;Classification algorithms;Clustering algorithms;Design methodology;Electron tubes","information retrieval;pattern clustering;structural engineering computing","case retrieval method;evaluation function;intelligent scheme design;k-means clustering algorithm;spatial distribution","","0","","5","","","16-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Using Global Behavior Modeling to Improve QoS in Cloud Data Storage Services","J. Montes; B. Nicolae; G. Antoniu; A. Sanchez; M. S. Perez","Univ. Politec. de Madrid, Madrid, Spain","2010 IEEE Second International Conference on Cloud Computing Technology and Science","20110204","2010","","","304","311","The cloud computing model aims to make large-scale data-intensive computing affordable even for users with limited financial resources, that cannot invest into expensive infrastructures necesssary to run them. In this context, MapReduce is emerging as a highly scalable programming paradigm that enables high-throughput data-intensive processing as a cloud service. Its performance is highly dependent on the underlying storage service, responsible to efficiently support massively parallel data accesses by guaranteeing a high throughput under heavy access concurrency. In this context, quality of service plays a crucial role: the storage service needs to sustain a stable throughput for each individual accesss, in addition to achieving a high aggregated throughput under concurrency. In this paper we propose a technique to address this problem using component monitoring, application-side feedback and behavior pattern analysis to automatically infer useful knowledge about the causes of poor quality of service and provide an easy way to reason in about potential improvements. We apply our proposal to Blob Seer, a representative data storage service specifically designed to achieve high aggregated throughputs and show through extensive experimentation substantial improvements in the stability of individual data read accesses under MapReduce workloads.","","Electronic:978-0-7695-4302-4; POD:978-1-4244-9405-7","10.1109/CloudCom.2010.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708464","","Computational modeling;Context;Data models;Monitoring;Quality of service;Stability analysis;Throughput","behavioural sciences computing;cloud computing;file organisation;information retrieval;parallel processing;quality of service","MapReduce;QoS;cloud computing;data storage services;financial resources;global behavior modeling;parallel data access;pattern analysis;quality of service;scalable programming","","2","","27","","","Nov. 30 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Machine science in biomedicine: Practicalities, pitfalls and potential","T. W. Kelsey; W. H. B. Wallace","School of Computer Science, University of St Andrews, United Kingdom","2010 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20110128","2010","","","399","404","Machine Science, or Data-driven Research, is a new and interesting scientific methodology that uses advanced computational techniques to identify, retrieve, classify and analyse data in order to generate hypotheses and develop models. In this paper we describe three recent biomedical Machine Science studies, and use these to assess the current state of the art with specific emphasis on data mining, data assessment, costs, limitations, skills and tool support.","","Electronic:978-1-4244-8304-4; POD:978-1-4244-8303-7","10.1109/BIBMW.2010.5703835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703835","Biomedical computing;Data acquisition;Modeling;Text recognition","","bioinformatics;data acquisition;data analysis;data mining;information retrieval","biomedical Machine Science;computational techniques;data analysis;data assessment;data classification;data identification;data mining;data retrieval;data-driven research","","1","","15","","","18-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Hot keyword identification for extracting web public opinion","Z. Fang; Y. Ning; T. Zhu","National Computer System Engineering Research Institute of China, Beijing 100083, China","5th International Conference on Pervasive Computing and Applications","20110128","2010","","","116","121","Internet is becoming an increasingly important platform for ordinary life and work. It is expected that keyword extraction can help people quickly find hot spots on the web, since keywords in a document provide important information about the content of the document. In this paper, we propose to use text clustering method based on semi-supervised learning to get focuses of social topics in a large amount of text. We develop a novel keyword extraction method named NATF-PDF, which is based on TFPDF algorithm, combined with supervised learning theory for keyword extraction. We compare its performance with TFIDF in comparison, and the results show that our method get better accuracy and recall ratio.","","Electronic:978-1-4244-9143-8; POD:978-1-4244-9144-5","10.1109/ICPCA.2010.5704085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704085","Clustering;Keyword Extraction;NATF-PDF;Semi-supervised learning","","Internet;information retrieval;learning (artificial intelligence);text analysis","Internet;NATF-PDF;TFPDF algorithm;Web public opinion extraction;hot keyword identification;keyword extraction method;semi-supervised learning;supervised learning theory;text clustering method","","0","","13","","","1-3 Dec. 2010","","IEEE","IEEE Conference Publications"
"Research on the Hierarchical Sentence Template and its Application in the Automatic Answering System","S. Kai; G. Huan-Tong; W. Li-Xin","Coll. of Comput. & Software, Nanjing Univ. of Inf. Sci. & Technol., Nanjing, China","2010 3rd International Conference on Information Management, Innovation Management and Industrial Engineering","20110120","2010","1","","588","591","In the online automatic answering system, the interpretation of the question sentence is an important part. The interpretation process has a few drawbacks if only splitting words or the simple sentence template is used. This paper presents a new method to interpret the question sentence. This method creates hierarchical sentence template to interpret the sentence from level to level. It's more flexible than the traditional method. In practice, experimental result shows that our method has a good effect and it improves the accuracy of question interpretation, meanwhile, it reduces the number of the sentence template.","2155-1456;21551456","Electronic:978-0-7695-4279-9; POD:978-1-4244-8829-2","10.1109/ICIII.2010.146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694475","automatic answering system;hierarchical sentence template;sentence template function;traditional sentence template","","question answering (information retrieval);word processing","hierarchical sentence template;online automatic answering system;question interpretation;question sentence;splitting words","","0","","12","","","26-28 Nov. 2010","","IEEE","IEEE Conference Publications"
"A New Mixed Index Method for XML Documents Updating","S. Q. Chen","Sch. of Public Adm., Fuzhou Univ., Fuzhou, China","2010 International Symposium on Computational Intelligence and Design","20110117","2010","2","","64","67","Traditional mixed index method combines the inverted file with a structure index and implements the retrieval of both context and structure. However, it is neither efficient nor supports for xml documents updating. This study presents a novel mixed index method to overcome these disadvantages. It can be used to optimize the query of path expression, decrease the number of update operations, accelerate the process of real-time update and shorten the response time. Experiments show that our strategy is effective and efficient.","","Electronic:978-0-7695-4198-3; POD:978-1-4244-8094-4","10.1109/ISCID.2010.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5692734","Structural Abstract;XML documents updating;mixed index","","XML;document handling;indexing;information retrieval","XML documents updating;mixed index method;structural abstract","","0","","8","","","29-31 Oct. 2010","","IEEE","IEEE Conference Publications"
"Study on the principle of treatment, medicine and formula of Chinese Medicine in congestive heart failure based on literature review and data mining technology","R. j. Luo; L. Teng; J. c. He; H. Wang; X. b. Cao; Y. h. Hu","Shanghai University of Traditional Chinese Medicine, 201203, China","2010 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20110128","2010","","","758","762","The authors review literature of Traditional Chinese Medicine on congestive heart failure treatment from 2005 to 2010 of CNKI database and analyze the common principle of treatment and prescription of Traditional Chinese Medicine by combining computer retrieval with artificially retrieval. The result of this study reflect the principle of treatment and law of taking medicine basically, hope to provide some ideas for clinical practice.","","Electronic:978-1-4244-8304-4; POD:978-1-4244-8303-7","10.1109/BIBMW.2010.5703905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703905","Chinese medicine;congestive heart failure;medicine and formula;principle of treatment","","bioinformatics;cardiology;data mining;diseases;information retrieval;patient treatment;reviews","CNKI database;Traditional Chinese Medicine;artificial retrieval;computer retrieval;congestive heart failure;data mining;literature review;patient treatment","","1","","15","","","18-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Periodic Topic Mining from Massive Amounts of Data","K. Ishida","Hiroshima Inst. of Technol., Hiroshima, Japan","2010 International Conference on Technologies and Applications of Artificial Intelligence","20110120","2010","","","379","386","Social media keeps growing and providing us with rich sources of information to understand our everyday lives, customs, and culture in the form of periodic topics. This paper proposes a method of detecting periodic topics based on autocorrelation using the time series of the document frequencies of keywords. To deal with the massive amount of data collected from social media, this method is implemented using Hadoop, which is an open-source framework for distributed processing and data storage. The implementation is evaluated in comparison with a relational database management system. Using this method, this paper analyzes blogs, news sites, and spam as information sources which serve as social and cultural indicators. Data is collected from Japanese blogs and news sites, and spam blogs are then separated from legitimate blogs using a spam filtering system. Distribution periods of keywords within each information source and weekly keywords are then extracted, and the characteristics of each information source are illustrated in terms of distribution and keywords. The results obtained using this extraction method indicate that periodic blog topics tend to be TV programs, hobbies, and social events; periodic news topics tend to be political and economic events; and periodic topics in spam tend to be automatically copied-and-pasted e-mail newsletters and affiliate offers.","2376-6816;23766816","Electronic:978-0-7695-4253-9; POD:978-1-4244-8668-7","10.1109/TAAI.2010.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5695480","Auto-correlation;Huge Data;Periodic Topic Mining;Social Media;Time-Series Analysis","","Web sites;data mining;distributed processing;information retrieval;time series;unsolicited e-mail","Hadoop;Japanese blogs;autocorrelation;data storage;distributed processing;document keyword frequencies;information sources;news sites;open-source framework;periodic topic mining;relational database management system;social media;spam filtering system;time series","","0","","14","","","18-20 Nov. 2010","","IEEE","IEEE Conference Publications"
"Toward Ontology-Guided Knowledge-Driven XML Query Relaxation","J. Hill; J. Torson; B. Guo; Z. Chen","Dept. of Comput. Sci., Univ. of Nebraska at Omaha, Omaha, NE, USA","2010 Second International Conference on Computational Intelligence, Modelling and Simulation","20110128","2010","","","448","453","Recently ontologies have drawn much attention from research communities. However, the advantage of using ontologies for knowledge-driven intelligent query answering is yet to be fully explored. In this paper, we examine the use of ontologies for guiding XML query relaxation and propose a practical approach which incorporates WordNet ontology with free software Qexo. Rather than reinventing the wheel, we take advantage of assembling publicly available tools to make query relaxation easy to implement. We present a methodology for XML query relaxation, and report experimental results to show the feasibility of the proposed approach. Our research indicates the importance of incorporating ontologies into the study of intelligent query answering.","2166-8523;21668523","Electronic:978-0-7695-4262-1; POD:978-1-4244-8652-6","10.1109/CIMSiM.2010.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5701888","Query relaxation;WordNet;XML;intelligent query answering;ontology","","XML;ontologies (artificial intelligence);query processing;question answering (information retrieval)","Qexo;WordNet ontology;knowledge-driven intelligent query answering;ontology-guided knowledge-driven XML query relaxation","","3","","12","","","28-30 Sept. 2010","","IEEE","IEEE Conference Publications"
"Annotating educational content by questions created by learners","M. Unčík; M. Bieliková","Institution of Informatics and Software Engineering, Faculty of Informatics and Information Technologies, Slovak University of Technology, Ilkovi &#x010D;ova 3, 842 16 Bratislava, Slovakia","2010 Fifth International Workshop Semantic Media Adaptation and Personalization","20110204","2010","","","13","18","Several approaches to educational web-based content enrichment have been devised. Annotations in form of comments and other types of remarks obviously supply these approaches. Annotations allow enriching the educational materials mainly by retaining key information or comments; they can support visual search and also collaboration. In this paper we present a method for an acquisition of new educational content created by learners. It is based on collaborative questions creation. We let the students to enrich educational materials with questions related to the selected text. We believe that this helps them to learn more effectively. It facilitates a collaboration and explicit rating to gain new quality content. This kind of annotations can be considered also as a source of semantics of the selected text and used for adaptation. To evaluate proposed method we experimented in domain of learning programming. We implemented the method within an existing web-based educational framework ALEF and provided several experiments.","","Electronic:978-1-4244-8602-1; POD:978-1-4244-8603-8; USB:978-1-4244-8601-4","10.1109/SMAP.2010.5706846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706846","","Collaboration;Context;Manuals;Materials;Programming profession;Semantics;Web pages","Internet;content management;courseware;groupware;question answering (information retrieval);text analysis","ALEF;Web based educational framework;collaborative question creation;educational Web based content annotation;educational content acquisition;educational materials;learning programming;quality content;visual search","","0","","12","","","9-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"Compute and data management strategies for grid deployment of high throughput protein structure studies","I. Stokes-Rees; P. Sliz","Dept. of Biological Chemistry and Molecular Pharmacology, Harvard Medical School, Boston, MA 02115","2010 3rd Workshop on Many-Task Computing on Grids and Supercomputers","20110120","2010","","","1","6","The study of macromolecular protein structures at an atomic resolution is the source of many data and compute intensive challenges, from simulation, to image processing, to model building. We have developed a general platform for the secure deployment of structural biology computational tasks and workflows into a federated grid which maximizes robustness, ease of use, and performance, while minimizing data movement. This platform leverages several existing grid technologies for security and web-based data access, adding protocols for VO, user, task, workflow, and individual job data staging. We present the strategies used to deploy and maintain tens of GB of data and applications to a significant portion of the US Open Science Grid, and the workflow management mechanisms to optimize task execution, both for performance and correctness. Significant observations are made about real operating conditions in a grid environment from automated analysis of hundreds of thousands of jobs over extended periods. We specifically focus on one novel application which harnesses the capacity of national cyberinfrastructure to dramatically accelerate the process of protein structure determination. This workflow requires 20 - 50 thousand hours to compute with 1e5 tasks, requiring tens of GB of input data, and producing commensurate output. We demonstrate the success of our platform through the successful completion of this workflow in half a day using Open Science Grid.","2151-1683;21511683","Electronic:978-1-4244-9705-8; POD:978-1-4244-9704-1","10.1109/MTAGS.2010.5699426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5699426","","","Internet;biology computing;data visualisation;grid computing;information retrieval;molecular biophysics;proteins;security of data;workflow management software","US open science grid;Web-based data access;atomic resolution;cyberinfrastructure;data management;data security;grid deployment;high throughput protein structure study;image processing;individual job data staging;macromolecular protein structure;protocol;structural biology computational task;workflow management","","1","","15","","","15-15 Nov. 2010","","IEEE","IEEE Conference Publications"
"Hierarchical medical image annotation using SVM-based approaches","I. F. Amaral; F. Coelho; J. F. P. da Costa; J. S. Cardoso","INESC Porto, Faculdade de Ci&#x00EA;ncias, Universidade do Porto, Portugal","Proceedings of the 10th IEEE International Conference on Information Technology and Applications in Biomedicine","20110117","2010","","","1","5","Automatic image annotation or image classification can be an important step when searching for images from a database. Common approaches to medical image annotation with the Image Retrieval for Medical Applications (IRMA) code make poor or no use of its hierarchical nature, where different dense sampled pixel based information methods outperform global image descriptors. In this work we address the problem of hierarchical medical image annotation by building a Content Based Image Retrieval (CBIR) system aiming to explore the combination of three different methods using Support Vector Machines (SVMs): first we concatenate global image descriptors with an interest points Bag-of-Words (BoW) to build a feature vector; second, we perform an initial annotation of the data using two known methods, disregarding the hierarchy of the IRMA code, and a third that takes the hierarchy into consideration by classifying consecutively its instances; finally, we make use of pairwise majority voting between methods by simply summing strings in order to produce a final annotation. Our results show that although almost all fusion methods result in an improvement over standalone classifications, none clearly outperforms each other. Nevertheless, these are quite competitive when compared with related works using an identical database.","2168-2194;21682194","Electronic:978-1-4244-6561-3; POD:978-1-4244-6559-0","10.1109/ITAB.2010.5687655","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687655","","Biomedical imaging;Databases;Kernel;MONOS devices;Manuals;Picture archiving and communication systems","data handling;image classification;information retrieval systems;medical image processing;query processing;support vector machines;visual databases","CBIR system;IRMA code;Image Retrieval for Medical Applications;SVM-based approaches;automatic image annotation;automatic image classification;content based image retrieval system;feature vector;global image descriptor concatenation;hierarchical medical image annotation;image database searching;interest points bag of words;pixel based information methods;support vector machines","","4","","22","","","3-5 Nov. 2010","","IEEE","IEEE Conference Publications"
"Detecting Duplicate Bug Report Using Character N-Gram-Based Features","A. Sureka; P. Jalote","Indraprastha Inst. of Inf. Technol. (IIIT), New Delhi, India","2010 Asia Pacific Software Engineering Conference","20110120","2010","","","366","374","We present an approach to identify duplicate bug reports expressed in free-form text. Duplicate reports needs to be identified to avoid a situation where duplicate reports get assigned to multiple developers. Also, duplicate reports can contain complementary information which can be useful for bug fixing. Automatic identification of duplicate reports (from thousands of existing reports in a bug repository) can increase the productivity of a Triager by reducing the amount of time a Triager spends in searching for duplicate bug reports of any incoming report. The proposed method uses character N-gram-based model for the task of duplicate bug report detection. Previous approaches are word-based whereas this study investigates the usefulness of low-level features based on characters which have certain inherent advantages (such as natural-language independence, robustness towards noisy data and effective handling of domain specific term variations) over word-based features for the problem of duplicate bug report detection. The proposed solution is evaluated on a publicly-available dataset consisting of more than 200 thousand bug reports from the open-source Eclipse project. The dataset consists of ground-truth (pre-annotated dataset having bug reports tagged as duplicate by the Triager). Empirical results and evaluation metrics quantifying retrieval performance indicate that the approach is effective.","1530-1362;15301362","Electronic:978-0-7695-4266-9; POD:978-1-4244-8831-5","10.1109/APSEC.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693213","Bug Report Analysis;Duplicate Bug Detection;Maintenance;Software Engineering Task Automation;Software Testing;Text Classification","","information retrieval;program debugging;program testing;public domain software;software maintenance;text analysis","Triager;automatic identification;character n-gram based features;duplicate bug report detection;evaluation metrics;free form text;ground truth;low-level features;open source Eclipse project;publicly available dataset;retrieval performance","","24","","17","","","Nov. 30 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Multi-view Clustering of Visual Words Using Canonical Correlation Analysis for Human Action Recognition","B. Saghafi; D. Rajan","Centre For Multimedia & Network Technol., Nanyang Technol. Univ., Singapore, Singapore","2010 Ninth International Conference on Machine Learning and Applications","20110204","2010","","","661","666","In this paper we propose a novel approach for introducing semantic relations into the bag-of-words framework for recognizing human actions. We represent visual words in two different views: the original features and the document co-occurrence representation. The latter view conveys semantic relations but is large, sparse and noisy. We use canonical correlation analysis between the two views to find a subspace in which the words are more semantically distributed. We apply k-means clustering in the computed space to find semantically meaningful clusters and use them as the semantic visual vocabulary. Incorporating the semantic visual vocabulary the features are quantized to form more discriminative histograms. Eventually the histograms are classified using an SVM classifier. We have tested our approach on KTH action dataset and achieved promising results.","","Electronic:978-0-7695-4300-0; POD:978-1-4244-9211-4","10.1109/ICMLA.2010.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708901","Bag-of-words;Canonical Correlation Analysis;Clustering;Human Action Recognition;Multi-view","Accuracy;Correlation;Feature extraction;Histograms;Semantics;Visualization;Vocabulary","correlation methods;gesture recognition;information retrieval;natural language processing;pattern clustering;support vector machines;vocabulary","KTH action dataset;SVM classifier;bag of word;canonical correlation analysis;discriminative histogram;document cooccurrence representation;human action recognition;k-means clustering;semantic visual vocabulary","","0","","22","","","12-14 Dec. 2010","","IEEE","IEEE Conference Publications"
"Question-unanswered: Research and Development of InterVIU System to Support Chat-based Interviews","R. R. Nunes; M. Pimentel","Dept. de Engenharias, Univ. de Tras-os-Montes e Alto Douro (UTAD), Vila Real, Portugal","2010 Brazilian Symposium on Collaborative Systems - Simposio Brasileiro de Sistemas Colaborativos","20110120","2010","","","1","8","In the research presented in this paper, the use of computational systems for the interviews is investigated. Exploratory Case Studies had been carried through to identify the problems that occur when the technique interview is carried through by chat. Amongst the identified problems, question-without-reply it was the chosen problem to be investigated in this research. It was proposed solution “list of questions”: to isolate messages by interviewing other messages chat, becoming explicit to the respondent which messages still need to be answered. The InterVIU system was developed for interviews, and the solution was implemented through the mechanism “area of questions”. A study was carried through pilot to identify the functionality problems, of usability and bugs in the system. To evaluate the proposed solution, a study of confirmatory case was performed. In the session where the InterVIU was used, the respondent could answer all the questions, an indication of that the solution is adjusted. From the register's analysis of the interview session, the answers to a questionnaire and the participant's comments, it could be concluded that the list of questions is useful for monitoring the interview.","2326-2826;23262826","Electronic:978-0-7695-4239-3; POD:978-1-4244-8445-4","10.1109/SBSC.2010.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5698490","CSCW;Chat based systems;InterVIU system;interview systems","","groupware;interactive systems;question answering (information retrieval)","InterVIU system;chat based interview system","","0","","20","","","5-8 Oct. 2010","","IEEE","IEEE Conference Publications"
"A System for De-identifying Medical Message Board Text","A. Benton; S. Hill; L. Ungar; A. Chung; C. Leonard; C. Freeman; J. H. Holmes","Sch. of Med., Univ. of Pennsylvania, Philadelphia, PA, USA","2010 Ninth International Conference on Machine Learning and Applications","20110204","2010","","","485","490","There are millions of public posts to medical message boards by users seeking support and information on a wide range of medical conditions. It has been shown that these posts can be used to gain a greater understanding of patients' experiences and concerns. As investigators continue to explore large corpora of medical discussion board data for research purposes, protecting the privacy of the members of these online communities becomes an important challenge that needs to be met. Extant entity recognition methods used for more structured text are not sufficient because message posts present additional challenges: the posts contain many typographical errors, larger variety of possible names, terms and abbreviations specific to Internet posts or a particular message board, and mentions of the authors' personal lives. The main contribution of this paper is a system to de-identify the authors of discussion board posts automatically, taking into account the aforementioned challenges. We demonstrate our system on two different message board corpora, one on breast cancer and another on arthritis. We show that our approach significantly outperforms other publicly available de-identification systems, which have been tuned for more structured text like operative reports, pathology reports and discharge summaries. Our software will be available for download as open source code in the near future.","","Electronic:978-0-7695-4300-0; POD:978-1-4244-9211-4","10.1109/ICMLA.2010.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708875","conditional random field;de-identification;message boards;named entity recognition;natural language processing;privacy","Arthritis;Discharges;Drugs;Electronic mail;Support vector machine classification;Training","Internet;cancer;data privacy;information needs;information retrieval;medical computing;natural language processing;text analysis","Internet post;arthritis;author personal life;breast cancer;discharge summary;entity recognition;information seeking;medical condition;medical discussion board data;medical message board text deidentification;online community;operative report;pathology report;patient concerns;patient experiences;privacy protection;structured text;support seeking;typographical error","","0","","16","","","12-14 Dec. 2010","","IEEE","IEEE Conference Publications"
"Weighted Feature Subset Non-negative Matrix Factorization and Its Applications to Document Understanding","D. Wang; T. Li; C. Ding","Sch. of Comput. & Inf. Sci., Florida Int. Univ., Miami, FL, USA","2010 IEEE International Conference on Data Mining","20110120","2010","","","541","550","Keyword (Feature) selection enhances and improves many Information Retrieval (IR) tasks such as document categorization, automatic topic discovery, etc. The problem of keyword selection is usually solved using supervised algorithms. In this paper, we propose an unsupervised approach that combines keyword selection and document clustering (topic discovery) together. The proposed approach extends non-negative matrix factorization (NMF) by incorporating a weight matrix to indicate the importance of the keywords. The proposed approach is further extended to a weighted version in which each document is also assigned a weight to assess its importance in the cluster. This work considers both theoretical and empirical weighted feature subset selection for NMF and draws the connection between unsupervised feature selection and data clustering. We apply our proposed approaches to various document understanding tasks including document clustering, summarization, and visualization. Experimental results demonstrate the effectiveness of our approach for these tasks.","1550-4786;15504786","Electronic:978-0-7695-4256-0; POD:978-1-4244-9131-5","10.1109/ICDM.2010.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694008","Non-negative matrix factorization;feature selection;weighted feature subset non-negative matrix factorization","","document handling;information retrieval;matrix decomposition;pattern clustering;unsupervised learning","data clustering;document clustering;information retrieval;keyword selection;nonnegative matrix factorization;unsupervised feature selection;weighted feature subset selection","","7","","43","","","13-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Researches on Semantic Annotation and Retrieval of 3D Models Based on User Feedback","T. Lu; S. Huang; P. Wu; Y. Jia","Coll. of Comput. Sci. & Technol., Harbin Eng. Univ., Harbin, China","2010 Sixth International Conference on Semantics, Knowledge and Grids","20110113","2010","","","211","218","As an important part of multimedia retrieval, researches on 3D model retrieval concentrate on the shape-based retrieval method. It is a promising way to improve retrieval performance by adopting semantic information. At present, semantics of an object is usually represented by several keywords. However, acquiring each 3D model's semantics is very difficult and expensive. To solve the problem, the paper proposes to describe a 3D model's semantics based on its relationship with the semantics of the others, and states an automatic semantic annotation based on noisy user feedbacks. The paper first analyzes the semantic relationship reflected by user feedbacks. Then, the semantic relationship is treated as one 3D model's semantic property and is adopted in clustering to detect semantic groups that is named as semantic community. Thirdly, based on the semantic community, the semantics for models is automatically and efficiently annotated based on semantic keywords of a few 3D models. Finally, a retrieval mechanism with long-term semantic learning ability is proposed. The experiments performed on Princeton Shape Benchmark show that the proposed method achieves good performance not only in semantic clustering and annotation but also in semantic retrieval.","","Electronic:978-0-7695-4189-1; POD:978-1-4244-8125-5","10.1109/SKG.2010.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663510","","","feedback;information retrieval;learning (artificial intelligence);multimedia systems;solid modelling","3D model retrieval;multimedia retrieval;semantic annotation;semantic information;semantic learning;shape-based retrieval;user feedback","","0","","13","","","1-3 Nov. 2010","","IEEE","IEEE Conference Publications"
"Analysis of algorithms used to compute term discrimination values","K. P. Pushpalatha; G. Raju","School of Computer Sciences, Mahatma Gandhi University, Kottayam, Kerala, India","2010 IEEE International Conference on Computational Intelligence and Computing Research","20110131","2010","","","1","6","Now-a-days all most all areas of life uses internet and search engines for getting relevant and useful information about various topics. Large index data bases are to be used in automatic document search and retrieval from large document collections. Term weighting schemes are very good in identifying and selecting good indexing terms. But it is possible to generate more efficient indexing terms using term discrimination values based on term weighting measures. The sum of similarity coefficients, between pairs of documents for each term, determines the document space density for a collection of documents. The terms, whose inclusion or elimination to/from documents in a collection, makes a large change in the document space density. This change constitutes the difference between the pair of documents, and in turn provides for discrimination measure. An efficient search index can be created using such good discriminating terms so that the precision and recall rates can be improved. This paper presents a study and analysis of a set of algorithms that compute and use term discrimination values (TDV) to identify good discriminators, and in turn to create good search index. It is recognized that there is a crucial relationship between term frequencies and discrimination values. Also discrimination values depend on the type of measure used to determine the similarity coefficients.","","Electronic:978-1-4244-5967-4; POD:978-1-4244-5965-0","10.1109/ICCIC.2010.5705844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5705844","TDV;Text mining;discrimination value model;search index","Algorithm design and analysis;Approximation algorithms;Classification algorithms;Clustering algorithms;Complexity theory;Indexes;Vocabulary","Internet;data mining;database indexing;information retrieval;search engines","Internet;automatic document search;document collection;document pair;document retrieval;document space density;indexing term;large index database;search engine;search index;similarity coefficient;term discrimination value","","1","","10","","","28-29 Dec. 2010","","IEEE","IEEE Conference Publications"
"Mining molecular interactions from scientific literature using cloud computing","F. Nazareno; K. H. Lee; W. S. Cho","Department of Bio and Information Technology, Chungbuk National University, Cheongju City, South Korea","2010 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20110128","2010","","","864","865","Biomedical entities such as proteins and nucleic acids and its corresponding interactions is considered as one of the fundamental building block in understanding biological processes of organisms. Majority of this information is stored in an overwhelming amount of scientific literatures. Written in unstructured text format, this collection also employs natural language. Additionally, the demands for such extraction and analysis over a huge amount of biomedical abstracts and full texts requires effective means of data management and high performance computing systems. A key in efficiently acquiring this information involves an intelligent and effective system of information extraction using techniques in natural language processing, information retrieval and knowledge management. With this regard, we developed a straight-forward biomolecular mining system that recognizes the biological named entities, simple heuristic pattern rules in identifying molecular interactions and utilization of high performance cloud computing technology.","","Electronic:978-1-4244-8304-4; POD:978-1-4244-8303-7","10.1109/BIBMW.2010.5703948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703948","biological named entities;cloud computing;natural language processing;text mining","","bioinformatics;cloud computing;data mining;database management systems;information retrieval;knowledge management;molecular biophysics;proteins","biomedical abstracts;biomolecular mining system;cloud computing;data management;full texts;heuristic pattern rules;high performance computing systems;information extraction;information retrieval;knowledge management;molecular interactions;natural language processing;nucleic acids;proteins;scientific literature","","1","","8","","","18-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Identity attributes quantitative analysis and the development of a metrics model using text mining techniques and information theory","J. Phiri; Tiejun Zhao","Machine Intelligence and Natural Language Processing Group, School of Computer Science, Harbin Institute of Technology, China","2010 IEEE International Conference on Information Theory and Information Security","20110117","2010","","","390","393","Term weighting has been applied to quantify and rank text data in information retrieval. Shannon's information theory called entropy is another area that is used to quantify information. In this paper, term weighting and entropy are used to compose an identity attribute metric model. A set of application forms are used to form a sample space of identity attributes and three corpora are used to generate the required statistics used to compose an identity attribute metric model. The composed metric model has application in point based authentication systems, such as banking, immigration and implementing intelligent authentication systems.","","Electronic:978-1-4244-6943-7; POD:978-1-4244-6942-0","10.1109/ICITIS.2010.5689588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5689588","Entropy;Identity Attributes;Metrics;Multimode Authentication;Term Weight","Authentication;Color;Entropy;Information theory;Measurement;Text mining","data mining;entropy;information retrieval","Shannon information theory;entropy;identity attribute metric model;identity attribute quantitative analysis;information retrieval;point based authentication system;rank text data;term weighting;text mining technique","","3","","18","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"A relevance-novelty combined model for genomics search result diversification","X. Yin; Z. Li; J. X. Huang; X. Hu","College of Computer Science and Engineering, Beihang University, Beijing, China","2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20110204","2010","","","692","695","Traditional retrieval models assume that the relevance of a document is independent of the relevance of other documents. However, this assumption may result in high redundancy and low diversity in a ranked list. In order to provide comprehensive and diverse answers to fulfill biologists' information need, we propose a relevance-novelty combined model, named RelNov model, based on the framework of an undirected graphical model. Experiments conducted on the TREC 2006 and 2007 Genomics collections show that the proposed approach is effective in promoting both diversity and relevance of retrieval ranked lists.","","Electronic:978-1-4244-8307-5; POD:978-1-4244-8306-8","10.1109/BIBM.2010.5706654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706654","Diversity;Genomics Search;Graphical Model","Bioinformatics;Biological system modeling;Genomics;Graphical models;Mathematical model;Redundancy","bioinformatics;document handling;genomics;information retrieval;natural language processing","RelNov model;TREC 2006 Genomics collection;TREC 2007 Genomics collection;document relevance;genomics search result diversification;relevance novelty combined model;retrieval models;undirected graphical model","","0","","15","","","18-21 Dec. 2010","","IEEE","IEEE Conference Publications"
"Concept Based Search Using LSI and Automatic Keyphrase Extraction","R. Rodrigues; K. Asnani","Dept. of Inf. Technol. (M.E.), Padre Conceicao Coll. of Eng., Verna, India","2010 3rd International Conference on Emerging Trends in Engineering and Technology","20110131","2010","","","573","577","Classic information retrieval model might lead to poor retrieval due to unrelated documents that might be included in the answer set or missed relevant documents that do not contain at least one index term. Retrieval based on index terms is vague and noisy. The user information need is more related to concepts and ideas than to index terms. Latent Semantic Indexing (LSI) model is a concept-based retrieval method which overcomes many of the problems evident in today's popular word-based retrieval systems. Most retrieval systems match words in the user's queries with words in the text of documents in the corpus, whereas LSI model performs the match based on the concepts. In order to perform concept mapping, Singular Value Decomposition (SVD) is used. Also key phrases are an important means of document summarization, clustering and topic search. Key phrases give high level description of document contents that indeed makes it easy for perspective readers to decide whether or not it is relevant to them. In this paper, we first develop an automatic key phrase extraction model for extracting key phrases from documents and then use these key phrases as a corpus on which conceptual search will be performed using LSI.","2157-0477;21570477","Electronic:978-0-7695-4246-1; POD:978-1-4244-8481-2","10.1109/ICETET.2010.100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5698391","Keyphrases;Latent Semantic Indexing;Retrieval models;Singular Value Decomposition","","indexing;information needs;information retrieval;singular value decomposition","LSI;automatic keyphrase extraction;concept based search;concept-based retrieval method;document clustering;document summarization;information need;information retrieval model;latent semantic indexing model;singular value decomposition","","0","1","15","","","19-21 Nov. 2010","","IEEE","IEEE Conference Publications"
"SubSift Web Services and Workflows for Profiling and Comparing Scientists and Their Published Works","S. Price; P. A. Flach; S. Spiegler; C. Bailey; N. Rogers","Inst. for Learning & Res. Technol., Univ. of Bristol, Bristol, UK","2010 IEEE Sixth International Conference on e-Science","20110120","2010","","","182","189","Scientific researchers, laboratories and organisations can be profiled and compared by analysing their published works, including documents ranging from academic papers to web sites, blog posts and Twitter feeds. This paper describes how the vector space model from information retrieval, more normally associated with full text search, has been employed in the open source Sub Sift software to support workflows to profile and compare such collections of documents. Sub Sift was originally designed to match submitted conference or journal papers to potential peer reviewers based on the similarity between the paper's abstract and the reviewer's publications as found in online bibliographic databases. The software is implemented as a family of Restful web services that, composed into a re-usable workflow, have already been used to support several major data mining conferences. Alternative workflows and service compositions are now enabling other interesting applications.","","Electronic:978-0-7695-4290-4; POD:978-1-4244-8957-2","10.1109/eScience.2010.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693916","","","Web services;bibliographic systems;information retrieval;text analysis","SubSift Web services;Twitter;Web sites;blog posts;data mining;information retrieval;online bibliographic databases;text search;vector space model","","0","","15","","","7-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"Cost-Sensitive Feature Selection Based on the Set Covering Machine","R. Santos-Rodriguez; D. Garcia-Garcia","Dept. of Signal Theor. & Commun., Univ. Carlos III de Madrid, Legane&#x0301;s, Spain","2010 IEEE International Conference on Data Mining Workshops","20110120","2010","","","740","746","This paper describes how to make use of the cost information related to the extraction of each feature in a feature selection algorithm. For instance, in medical diagnosis, the different tests a patient might take during the diagnosis process can have different associated costs. The main idea is to change the feature selection framework in order to get low-cost subsets of informative features. This work proposes a way to introduce this information in a well-known machine learning algorithm, the Set Covering Machine.","2375-9232;23759232","Electronic:978-0-7695-4257-7; POD:978-1-4244-9244-2","10.1109/ICDMW.2010.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693370","Cost-sensitive learning;Feature selection;Set Covering Machine","","decision making;information retrieval;learning (artificial intelligence);patient diagnosis","cost-sensitive feature selection algorithm;feature extraction;information extraction;machine learning algorithm;patient diagnosis process;set covering machine","","1","","8","","","13-13 Dec. 2010","","IEEE","IEEE Conference Publications"
"A System for Mining Temporal Physiological Data Streams for Advanced Prognostic Decision Support","J. Sun; D. Sow; J. Hu; S. Ebadollahi","T.J. Watson Res. Center, IBM, Hawthorne, NY, USA","2010 IEEE International Conference on Data Mining","20110120","2010","","","1061","1066","We present a mining system that can predict the future health status of the patient using the temporal trajectories of health status of a set of similar patients. The main novelties of this system are its use of stream processing technology for handling the incoming physiological time series data and incorporating domain knowledge in learning the similarity metric between patients represented by their temporal data. The proposed approach and system were tested using the MIMIC II database, which consists of physiological waveforms, and accompanying clinical data obtained for ICU patients. The study was carried out on 1500 patients from this database. In the experiments we report the efficiency and throughput of the stream processing unit for feature extraction, the effectiveness of the supervised similarity measure both in the context of classification and retrieval tasks compared to unsupervised approaches, and the accuracy of the temporal projections of the patient data.","1550-4786;15504786","Electronic:978-0-7695-4256-0; POD:978-1-4244-9131-5","10.1109/ICDM.2010.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694085","Patient similarity;Physiological streams","","data mining;feature extraction;information retrieval;learning (artificial intelligence);medical administrative data processing;patient monitoring;time series","ICU patient;MIMIC II database;advanced prognostic decision support;classification task;clinical data;feature extraction;patient health status;physiological time series data;retrieval task;supervised similarity measure;temporal physiological data stream mining","","7","","19","","","13-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"A framework for high level semantic annotation using trusted object annotated dataset","Irfanullah; N. Aslam; J. Loo; M. Loomes; Roohullah","School of Engineering and Information Sciences, Middlesex University, London, NW4 4BT, UK","The 10th IEEE International Symposium on Signal Processing and Information Technology","20110210","2010","","","491","495","Dramatic expansion and eminence of the multimedia data from the last decades, culminates to a trouble in managing, accessing and annotating the data. The high level semantic annotation (HLS) of resources in general and multimedia resources in particular, is a resilient job. The Progression in automatic annotation mechanisms have not been able to comprehend with adequately accurate results. To outfit multimedia (e.g. image/video) retrieval capabilities, digital libraries have hung on manual annotation of images. Providing a track to enact high level semantic annotation automatically would be more worthwhile, efficient and scalable with magnifying image collections. This paper intent to equip the high level semantic annotation for images, and consequently, contributes to 1) calculating semantic intensity (SI) of each object in the image depicting the dominancy factor, (2) image similarity on the bases on metadata tag with the images, and (3) clustering approach based on the image similarity to tag set of images with a high level semantic description with their calculated similarity values. The experiment on a portion of randomly selected images from LabelMe database manifests stimulating outcomes.","2162-7843;21627843","Electronic:978-1-4244-9991-5; POD:978-1-4244-9992-2","10.1109/ISSPIT.2010.5711740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5711740","High Level Semantics;Image Annotation;Image Similarity;Semantic Intensity","Purification;Redundancy;Silicon","digital libraries;information retrieval;meta data;multimedia databases;pattern clustering;semantic Web;visual databases","LabelMe database;automatic annotation;clustering;digital libraries;high level semantic annotation;image similarity;metadata tag;multimedia data;multimedia resources;multimedia retrieval;semantic intensity;trusted object annotated dataset","","0","","14","","","15-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"CloudView: Describe and Maintain Resource View in Cloud","D. Zhou; L. Zhong; T. Wo; J. Kang","Sch. of Comput. Sci. & Eng., Beihang Univ., Beijing, China","2010 IEEE Second International Conference on Cloud Computing Technology and Science","20110204","2010","","","151","158","Resource view is the user defined table to provide specific view on resource status in cloud computing environment. It provides a convenient way to retrieve resource data for applications at infrastructure, platform and service layers. But the description and maintenance of these diverse resource views are inconvenient and dramatically difficult due to massive, heterogeneous and dynamic characteristics of the cloud resources involved. In this paper we present a resource view description scheme RQL and the corresponding system Cloud View to address these difficulties. RQL provides users a scheme to specify the data processing flow from resource raw data collected to resource view data objected. By constructing data processing a cyclic graph based on view definitions and using basic routines, view maintenance mechanism update user defined resource views automatically and periodically. Cloud View use a centralized scheduler to distribute maintenance jobs to a set of scalable worker nodes. It leverages distributed key-value database to store view data. Compared to related resource monitoring and discovering systems, Cloud View is flexible in application oriented view description and maintenance. Experiments show it updates typical user defined views with desired performance.","","Electronic:978-0-7695-4302-4; POD:978-1-4244-9405-7","10.1109/CloudCom.2010.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708446","cloud computing;information service;resource view maintenance","Cloud computing;Data processing;Distributed databases;Maintenance engineering;Monitoring;Protocols;Software","cloud computing;information retrieval","CloudView;cloud computing;data processing acyclic graph;distributed key value database;resource data retrieval;resource monitoring;resource view description scheme;resource view maintenance","","3","1","24","","","Nov. 30 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Distributed Popularity Based Replica Placement in Data Grid Environments","M. Shorfuzzaman; P. Graham; R. Eskicioglu","Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada","2010 International Conference on Parallel and Distributed Computing, Applications and Technologies","20110128","2010","","","66","77","Data grids support distributed data-intensive applications that need to access massive datasets stored around the world. Ensuring efficient access to such datasets is hindered by the high latencies of wide-area networks. To speed up access, files can be replicated so a user can access a nearby replica. Replication also provides improved availability, decreased bandwidth use, increased fault tolerance, and improved scalability. Since a grid environment is dynamic, resource availability, network latency, and user requests may change. To address these issues a dynamic replica placement strategy that adapts to changing behaviour is needed. In this paper, we introduce a highly distributed replica placement algorithm for hierarchical data grids. Our algorithm exploits data access histories to identify popular files and determines optimal replication locations to improve access performance by minimizing replication overhead (access and update) assuming a given traffic pattern. The problem is formulated using dynamic programming. We evaluate our algorithm using the OptorSim simulator and find that it offers shorter execution time and reduced bandwidth consumption compared to other dynamic replica placement methods.","2379-5352;23795352","Electronic:978-0-7695-4287-4; POD:978-1-4244-9110-0","10.1109/PDCAT.2010.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704405","data grids;distributed algorithms;dynamic programming;file popularity;replication","Bandwidth;Cost function;Data models;Dynamic programming;Heuristic algorithms;Peer to peer computing;Servers","dynamic programming;grid computing;information retrieval;minimisation;replicated databases","OptorSim simulator;bandwidth consumption;data access;data grid environment;distributed data-intensive applications;distributed replica placement algorithm;dynamic programming;hierarchical data grids;optimal replication locations;replication overhead;traffic pattern;wide area networks","","5","","24","","","8-11 Dec. 2010","","IEEE","IEEE Conference Publications"
"Parallelizing an Information Theoretic Co-clustering Algorithm Using a Cloud Middleware","V. Ramanathan; W. Ma; V. T. Ravi; T. Liu; G. Agrawal","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2010 IEEE International Conference on Data Mining Workshops","20110120","2010","","","186","193","The emerging cloud environments are well suited for storage and analysis of large datasets, since they can allow on-demand access to resources. However, developing high-performance implementations of data analysis tasks is a challenging problem. In our prior work, we have developed a middleware called FREERIDE (FRamework for Rapid Implementation of Data mining Engines). FREERIDE is based upon the observation that the processing structure of a large number of data mining algorithms involves generalized reductions. FREERIDE offers a high-level interface and implements both distributed memory and shared memory parallelization. In this paper, we consider a challenging new data mining algorithm, information theoretic co-clustering, and parallelize it using the FREERIDE middleware. We show how the main processing loops of row clustering and column clustering of the Co-clustering algorithm can essentially be fit into a generalized reduction structure. We achieve good parallel efficiency, with a speedup of nearly 21 on 32 cores.","2375-9232;23759232","Electronic:978-0-7695-4257-7; POD:978-1-4244-9244-2","10.1109/ICDMW.2010.100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693299","Co-clustering;Parallel Data Mining","","cloud computing;data analysis;data mining;information retrieval;middleware;parallel algorithms;pattern clustering","cloud middleware;data analysis;data mining algorithm;data storage;generalized reduction structure;information theoretic co-clustering algorithm;on-demand resource access;parallel algorithm","","2","","12","","","13-13 Dec. 2010","","IEEE","IEEE Conference Publications"
"The Application of ""3S"" Technology in Underground Pipeline Emergency Management","S. Ping; Z. Wei; X. Tao","Beijing Res. Center of Urban Syst. Eng., Beijing, China","2010 Second WRI Global Congress on Intelligent Systems","20110204","2010","1","","175","179","At present, urban underground pipeline is inadequate in base material, the information management system is incomplete, establishing and perfecting underground pipeline information system is an important means to realize the modernization management of underground pipeline. Based on the function of “3S” technology, it builds underground pipeline emergency management supporting system, with the thorough research of data acquisition and extration, space data management and analysis, making the data processing model concrete, providing scientific basis for strengthening emergency management of underground pipeline.","2155-6083;21556083","Electronic:978-0-7695-4304-8; POD:978-1-4244-9247-3","10.1109/GCIS.2010.244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708738","3S technology;emergency management;system designation;urban underground pipeline","Accidents;Decision support systems;Geographic Information Systems;Global Positioning System;Monitoring;Pipelines;Spatial databases","data acquisition;data analysis;decision support systems;emergency services;information retrieval;pipelines;town and country planning","3S technology;data acquisition;data analysis;data extraction;data processing model;management decision support system;space data management;underground pipeline emergency management","","0","","6","","","16-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Mapping Relational Databases into Ontologies through a Graph-based Formal Model","S. Yang; J. Wu","IT Dept., Chinese Acad. of Sci., Chengdu, China","2010 Sixth International Conference on Semantics, Knowledge and Grids","20110113","2010","","","219","226","One of key issues of the Semantic Web applications is the lack of semantic data (ontologies). Although the vast majority of data are stored in the popular relational databases, they are still not easily available for many next generation Web applications. Therefore, one of core challenges of Semantic Web is whether these applications can automatically retrieve semantic information from the existed relational databases. This paper proposes a middle graph-based formal model language, W-graph, a bridge between relational databases and ontologies, which abstracts semantic information from relational database instances semi-automatically and then generates an OWL ontology automatically. This method not only maps relational database schemata to ontologies, but also populates ontologies with data stored in databases. Moreover, a proof of semantic preserving on the mapping is provided, and a case study and an implemented prototype tool are also reported.","","Electronic:978-0-7695-4189-1; POD:978-1-4244-8125-5","10.1109/SKG.2010.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663511","graph-based formal model;ontology;relational database;semantic interoperability;semantic web","","graphs;information retrieval;knowledge representation languages;ontologies (artificial intelligence);relational databases;semantic Web","OWL ontology;W-graph;graph based formal model language;mapping relational database;next generation Web application;semantic Web application;semantic information retrieval","","2","","15","","","1-3 Nov. 2010","","IEEE","IEEE Conference Publications"
"Spatial Topology Retrieval: A Visual Approach for Encoding and Indexing Spatial Topology in an Architectural Design Case Library","C. J. Lin; M. L. Chiu","Dept. of Interior Design, Tainan Univ. of Technol., Tainan, Taiwan","2010 Second WRI Global Congress on Intelligent Systems","20110204","2010","1","","125","132","This paper aims to develop a visual tool named Spatial Topology Retrieval (STR) for integrating a physical-based spatial allocation tool, which offers a visual interactive interface for architectural space layout in the early design stage, into an online case library of architectural design, which is based on rational database technology with ontology-based authoring tools of metadata of case features. STR provides the case library with a tool for indexing and retrieving the plane views of a given architectural design case.","2155-6083;21556083","Electronic:978-0-7695-4304-8; POD:978-1-4244-9247-3","10.1109/GCIS.2010.254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708728","Architectural design;case library;implicit knowledge;knowledge representation;spatial topology","Floors;Indexing;Layout;Libraries;Semantics;Topology;Visualization","architectural CAD;authoring systems;data visualisation;indexing;information retrieval;meta data;ontologies (artificial intelligence);topology","STR;architectural design case library;architectural space layout;meta data;ontology based authoring tool;physical based spatial allocation tool;rational database technology;spatial topology indexing;spatial topology retrieval;visual approach;visual interactive interface;visual tool","","0","","23","","","16-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Information-theoretic analysis of function computation on streams","K. Viswanathan","HP Labs, Palo Alto, CA, USA","2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton)","20110204","2010","","","1147","1152","We consider the problem of determining the memory required to compute functions of data streams. A streaming system with memory constraint has to observe a collection of sources X<sub>1</sub>;X<sub>2</sub>;...;X<sub>m</sub> sequentially, store synopses of the sources in memory, and compute a function of the sources based on the synopses. We are interested in the memory requirement, the number of bits of memory required to compute the function. In an earlier work, we established a correspondence between this problem and a functional source coding problem in cascade/line networks, and for the latter we derived inner and outer bounds on the rate region. In particular we showed that the outer bounds are achievable for all functions and a certain classes of distributions on the sources. In this paper we extend the class of distributions for which the outer bounds are achieved. By virtue of the correspondence between the two problems, this also characterizes the memory requirement for the associated streaming computation problem.","","Electronic:978-1-4244-8216-0; POD:978-1-4244-8215-3","10.1109/ALLERTON.2010.5707040","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5707040","","Joints;Markov processes;Memory management;Protocols;Random variables;Robustness;Source coding","information retrieval;information theory;storage management","associated streaming computation problem;cascade/line networks;data streams;function computation;functional source coding problem;information-theoretic analysis","","4","","11","","","Sept. 29 2010-Oct. 1 2010","","IEEE","IEEE Conference Publications"
"Fine-Grained Data Access Control Systems with User Accountability in Cloud Computing","J. Li; G. Zhao; X. Chen; D. Xie; C. Rong; W. Li; L. Tang; Y. Tang","Sch. of Comput. Sci. & Educ. Softwar, Guangzhou Univ., Guangzhou, China","2010 IEEE Second International Conference on Cloud Computing Technology and Science","20110204","2010","","","89","96","Cloud computing is an emerging computing paradigm in which IT resources and capacities are provided as services over the Internet. Promising as it is, this paradigm also brings forth new challenges for data security and access control when users outsource sensitive data for sharing on cloud servers, which are likely outside of the same trust domain of data owners. To maintain the confidentiality of, sensitive user data against untrusted servers, existing work usually apply cryptographic methods by disclosing data decryption keys only to authorized users. However, in doing so, these solutions inevitably introduce heavy computation overhead on the data owner for key distribution and data management when fine-grained data access control is desired, and thus do not scale well. In this paper, we present a way to implement, scalable and fine-grained access control systems based on attribute-based encryption (ABE). For the purpose of secure access control in cloud computing, the prevention of illegal key sharing among colluding users is missing from the existing access control systems based on ABE. This paper addresses this challenging open issue by defining and enforcing access policies based on data attributes and implementing user accountability by using traitor tracing. Furthermore, both the user grant and revocation are efficiently supported by using the broadcast encryption technique. Extensive analysis shows that the proposed scheme is highly efficient and provably secure under existing security models.","","Electronic:978-0-7695-4302-4; POD:978-1-4244-9405-7","10.1109/CloudCom.2010.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708438","Accountability;Attribute-based encryption;Fine-grained access control","Access control;Cloud computing;Encryption;Servers","Web services;access control;cloud computing;cryptography;information retrieval","attribute based encryption;cloud computing;data security;fine grained data access control system;secure access control;user accountability","","17","","21","","","Nov. 30 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Training Surrogate Sensors in Musical Gesture Acquisition Systems","A. Tindale; A. Kapur; G. Tzanetakis","department of Computer Science, the department of Electrical Engineering, and the faculty of music, University of Victoria, Victoria, Canada","IEEE Transactions on Multimedia","20110117","2011","13","1","50","59","Capturing the gestures of music performers is a common task in interactive electroacoustic music. The captured gestures can be mapped to sounds, synthesis algorithms, visuals, etc., or used for music transcription. Two of the most common approaches for acquiring musical gestures are: 1) “hyper-instruments” which are “traditional” musical instruments enhanced with sensors for directly detecting the gestures and 2) “indirect acquisition” in which the only sensor is a microphone capturing the audio signal. Hyper-instruments require invasive modification of existing instruments which is frequently undesirable. However, they provide relatively straightforward and reliable sensor measurements. On the other hand, indirect acquisition approaches typically require sophisticated signal processing and possibly machine learning algorithms in order to extract the relevant information from the audio signal. The idea of using direct sensor(s) to train a machine learning model for indirect acquisition is proposed in this paper. The resulting trained “surrogate” sensor can then be used in place of the original direct invasive sensor(s) that were used for training. That way, the instrument can be used unmodified in performance while still providing the gesture information that a hyper-instrument would provide. In addition, using this approach, large amounts of training data can be collected with minimum effort. Experimental results supporting this idea are provided in two detection contexts: 1) strike position on a drum surface and 2) strum direction on a sitar.","1520-9210;15209210","","10.1109/TMM.2010.2089786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5610728","Gesture recognition;machine learning;new interfaces for musical expression;surrogate sensors;virtual sensors","Context;Feature extraction;Instruments;Machine learning;Music;Sensors;Training","audio signal processing;gesture recognition;information retrieval;learning (artificial intelligence);microphones;musical instruments;sensors","audio signal;direct invasive sensor;gesture information;indirect acquisition approach;information extraction;interactive electroacoustic music;machine learning;musical gesture acquisition system;signal processing;surrogate sensor;training data","","4","","35","","20101028","Feb. 2011","","IEEE","IEEE Journals & Magazines"
"Research and Implementation of Chinese Patent Information Gathering System Based on Domain Ontology","H. Wu; Y. Li","Inst. of Sci. & Tech. Inf., Shandong Univ. of Technol., Zibo, China","2010 International Conference on Web Information Systems and Mining","20110113","2010","1","","237","241","Traditional information gathering systems are mostly keyword-based that are lack of semantic comprehension and analysis ability and can't guarantee the comprehensiveness and accuracy of information gathering. This paper proposes Chinese patent information gathering model based on domain ontology, which can visualize ontology concept semantic map related to user gathering requirements on the information gathering interface. Users can select more related and professional domain concept to user gathering subjects from ontology concept semantic map, the system may automatically carry out semantic inference and extension to the selected domain concept, and form the normative expansive semantic gathering expression to gather patent information from the related web pages. In order to verify feasibility and effectiveness of the model, this paper selects clothing domain, develops Chinese clothing domain ontology, implements the patent information gathering system based on clothing domain ontology. Experiment results show that the model can greatly improve the comprehensiveness and accuracy of information gathering.","","Electronic:978-0-7695-4224-9; POD:978-1-4244-8438-6","10.1109/WISM.2010.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662318","domain ontology;information gathering;model;ontology construction;patent;semantic expansion","","Web sites;clothing;inference mechanisms;information retrieval;information retrieval systems;ontologies (artificial intelligence);patents;semantic networks;user interfaces","Chinese clothing domain ontology;Chinese patent information gathering system;Web pages;analysis ability;information gathering accuracy;information gathering comprehensiveness;information gathering interface;keyword-based information gathering system;normative expansive semantic gathering expression;professional domain concept;selected domain concept;semantic comprehension;semantic inference;user gathering requirements;user gathering subjects;visualize ontology concept semantic map","","1","","21","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Information technology and health care: A scenario of biofeedback","Y. Cao; N. Wang; H. Peng; Q. Liu; W. Cao","Department of Cardiovascular Medicine, Gansu Provincial Hospital, Lanzhou, China","5th International Conference on Pervasive Computing and Applications","20110128","2010","","","50","55","Medical Informatics is the scientific field that deals with the storage, retrieval and optimal use of information and data in medicine. It is often called healthcare informatics or biomedicai informatics, and forms part of the wider domain of eHealth. The end objective of biomedicai informatics is the coalescing of data, knowledge, and the tools necessary to apply that data and knowledge in the decision-making process, at the time and place that a decision needs to be made. Ubiquitous healthcare is an emerging field of technology that uses a large number of environmental and patient sensors and actuators to monitor and improve patients' physical and mental condition. Biofeedback is a training technique in which people are taught to improve their health and performance by using signals from their own bodies. Based on above, we pick up electrical signals from the brain(EEG) and translates the signals into a form that people can detect, by which we improve the brain function and mental condition. Moreover, a scenario of ubiquitous mental healthcare system has been established.","","Electronic:978-1-4244-9143-8; POD:978-1-4244-9144-5","10.1109/ICPCA.2010.5704074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704074","Healthcare;Informatics;biofeedback","","bioinformatics;decision making;health care;information retrieval;medical information systems;ubiquitous computing","EEG;biofeedback;biomedicai informatics;decision-making process;healthcare informatics;information retrieval;information storage;information technology;information usage;ubiquitous mental healthcare system","","1","","29","","","1-3 Dec. 2010","","IEEE","IEEE Conference Publications"
