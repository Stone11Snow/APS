"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6256173,6256398,6254293,6254338,6252543,6252618,6252626,6250457,6252765,6249844,6252435,6252553,6250000,6252781,6249300,6248085,6246064,6246145,6246966,6247101,6245774,6245779,6246944,6246074,6246795,6246092,6245653,6244636,6244703,6241666,6243965,6240673,6240907,6240835,6240805,6239781,6240464,6240504,6240436,6240365,6239742,6239234,6239734,6236404,6236607,6235411,6237198,6237456,6234301,6233217,6234190,6234315,6233716,6234292,6233970,6233810,6233722,6233735,6234021,6234068,6234518,6234114,6233253,6233411,6234230,6233240,6233946,6233932,6233241,6232939,6234637,6233418,6233404,6232125,6228171,6227664,6228185,6229817,6228380,6228266,6228163,6228131,6228657,6228207,6228187,6229401,6228074,6227966,6228183,6228226,6228140,6225472,6224842,6224929,6225810,6226945,6225474,6225478,6226787,6227034",2017/05/04 22:27:00
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Computing approximate joins of relations based on entity chains","B. Liu","Department of Computer Science, Jinan University, Guangzhou, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1627","1631","Because of data inconsistencies among multiple databases, it is not always possible to get exact query answers from them. The paper proposes the method based on entity chains for approximate join queries on multiple relations, and designs extended SQL query language to implement the main procedures. An entity chain consists of the entities belonging to different relations with the same or approximate linkage attribute values, and is computed by analyzing similarity of linkage attributes in different relations. Entity chains provide facilities for approximate joins, and can be used to improve efficiency of computing approximate joins on multiple relations in information systems.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233722","approximate join;database;entity chain;multi-relations","Algorithm design and analysis;Approximation algorithms;Cleaning;Couplings;Database systems","SQL;approximation theory;entity-relationship modelling;question answering (information retrieval)","data inconsistency;entity chain;extended SQL query language;information system;linkage attribute value approximation;query answering;query approximation","","0","","11","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"A rule-based ontology reasoning for scientific effects retrieval","J. Ma; Q. Zhang; J. Zhang; J. Zhang","Hebei University of Technology, Tianjin 300401, China","2012 IEEE International Conference on Management of Innovation & Technology (ICMIT)","20120628","2012","","","232","237","Scientific effects, which are knowledge of scientific principles, can be used to transform inputs to outputs and achieve corresponding functions. How to manage and make full use of them to support the conceptual design is an important task. Many papers focused on the expression and retrieval of function ontology, few related to the reasoning rules on the function expansion with attributes of function and flow. This paper proposed a rule-based ontology reasoning for scientific effects retrieval with expanding 5 groups reasoning rules based on Jena reasoning engine. A proto type software is developed. The experiment results demonstrated that the rule-based ontology reasoning can greatly widen the solution space and increase opportunities for product innovation.","","Electronic:978-1-4673-0110-7; POD:978-1-4673-0108-4","10.1109/ICMIT.2012.6225810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6225810","Jena;function ontology;reasoning rules;scientific effect","Cognition;Educational institutions;Materials;Ontologies;Semantics;Software;Technological innovation","inference mechanisms;information retrieval;innovation management;knowledge based systems;ontologies (artificial intelligence);product development;production engineering computing;prototypes;scientific information systems","Jena reasoning engine;conceptual design;function ontology expression;function ontology retrieval;product innovation;prototype software development;rule-based ontology reasoning;scientific effect retrieval","","0","","31","","","11-13 June 2012","","IEEE","IEEE Conference Publications"
"A Strategic Question Inquiry System for fuzzy decision of elevators street","M. Katoh; T. Ozeki; J. Sawaki","Dept. of Mechanical Engineering, Faculty of Engineering, Osaka Institute of Technology, Japan","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","287","291","This paper presents a Strategic Question and Inquiry System (SQIS) as a Decision Support System (DSS) on elevators street for correction of knowledge on Failure Mode Effect Analysis (FMEA) and Action Mode Effect Analysis (AMEA). Then, an example of a numerical experiment for the concept demonstration of the fuzzy decision making is shown. The application to double-deck and multi-car elevator was discussed.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233735","DSS;Eligibility;FMEA;Fuzzy Decision;SIS","Analytical models;Conferences;Decision making;Decision support systems;Elevators;Floors;Fuzzy sets","decision making;decision support systems;fuzzy set theory;lifts;question answering (information retrieval);reliability","AMEA;DSS;FMEA;SQIS;action mode effect analysis;decision support system;double-deck elevator;elevator street;failure mode effect analysis;fuzzy decision making;knowledge correction;multicar elevator;strategic question and inquiry system","","0","","18","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Tools for grading students' exercises for Microsoft Access applications","N. Majstorović; Ž. Širanović; K. Kavran","Polytechnicum Zagrabiense/INRO, Zagreb, Croatia","2012 Proceedings of the 35th International Convention MIPRO","20120716","2012","","","1290","1292","This paper describes the teacher's tools for automated grading of students' exercises in Microsoft Access skill and knowledge. The method requires teachers to build etalon sample of Microsoft Access database which satisfies all the requirements expected to be done by the students. This etalon is processed by Distiller Utility to extract information about database objects and its properties into decision-support database. The Property Browser allows the teachers to assign score points for correct value settings of arbitrary property for each database table, form, report or their fields, sections or controls. Finally, the Grader Utility is to perform inspection of collected student's databases and report their results. Flexible parameterized exercise description is also generated with RTF memos included. Some degree of robustness is accomplished in grading accuracy for text and numeric values. The development is in the direction to port decision-support database from Microsoft Access to Microsoft SQL server, Property Browser as ASP.NET application and includes Queries and Entity Relationship support.","","DVD:978-953-233-072-4; Electronic:978-953-233-068-7; POD:978-1-4673-2577-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240835","","Accuracy;Browsers;Databases;Education;Inspection;Programming;Servers","computer science education;database machines;educational administrative data processing;information retrieval","ASP.NET application;Distiller Utility;Entity Relationship support;Grader Utility;Microsoft Access applications;Microsoft Access database;Microsoft Access knowledge;Microsoft Access skill;Microsoft SQL server;Property Browser;Queries;automated student exercise grading;database objects;database table;decision-support database;grading student exercise tools;information extraction;teacher tools","","0","","8","","","21-25 May 2012","","IEEE","IEEE Conference Publications"
"Multivariate input vector space reconstruction and its application","J. Xi; Zhang Lei; Y. Niu; Su Ronghui; L. Jiang","School of Automation, Shenyang Aerospace University, 110136, China","2012 24th Chinese Control and Decision Conference (CCDC)","20120719","2012","","","3994","3997","This paper was concentrated on the reconstruction of multivariate input vector space. Based on evaluating the nonlinear correlation degree between observed variables and output variables, the input variables were selected if the evaluation was strong. Then, C-C method was used to reconstruct an initial input vector space. Finally, FastICA method was expanded to extract the effective independent information and reduce the dimension of initial input vector. Simulation results showed the effectiveness of the reconstructed input vector.","1948-9439;19489439","Electronic:978-1-4577-2074-1; POD:978-1-4577-2073-4","10.1109/CCDC.2012.6244636","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6244636","FastICA;Input vector space reconstruction;Nonlinear correlation degree","Correlation;Input variables;Predictive models;Simulation;Space vehicles;Time series analysis;Vectors","independent component analysis;information retrieval;vectors","C-C method;FastICA method;independent component analysis;independent information extraction;input variables;multivariate input vector space reconstruction;nonlinear correlation degree;observed variables;output variables","","0","","7","","","23-25 May 2012","","IEEE","IEEE Conference Publications"
"A Lean and Sustainable User Access System for a University Microfabrication Laboratory","A. Roth; J. Lee","","2012 19th Biennial University/Government/Industry, Micro/Nano Symposium (UGIM)","20120723","2012","","","1","1","Summary form only given. The objective of this project is to develop a user access system for the Microscale Process Engineering Laboratory (MPEL) at San Jose State University (SJSU). The system implements hardware/software locks that limit tool use to authorized users only. The MPEL at SJSU is a 5,000 sq. ft. instructional facility that is also used for research projects and industry collaboration. Based on the size of the facility and its support infrastructure, it is critical that the user access system be very lean and sustainable for the limited staffing available. In addition to the interlock system, the necessary system functions include a database with user information and authorization levels that can easily be modified by the lab managers. Preventing unauthorized tool use, or any use in the case of a tool that is down, will help maintain user safety and prevent tool damage. Individual user and tool hours are logged to add user accountability, budget tracking, and improve tool maintenance. This project evaluates trade-offs between having a centralized master computer that communicates with ""child"" computers stationed at each major functional area of the lab and having independent computers located separately at each functional area. Each option has benefits and costs related to expense, sustainability and usability. The implemented system will provide SJSU's MPEL with a lean and sustainable user access system that will improve safety, maintainability and quality.","0749-6877;07496877","Electronic:978-1-4577-1752-9; POD:978-1-4577-1751-2; USB:978-1-4577-1750-5","10.1109/UGIM.2012.6247101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6247101","","Collaboration;Computers;Educational institutions;Hardware;Industries;Safety;Software","authorisation;budgeting;information retrieval;laboratories;sustainable development","MPEL;Microscale Process Engineering Laboratory;SJSU;SJSU MPEL;San Jose State University;budget tracking;centralized master computer;child computers;hardware-software locks;independent computers;individual tool;individual user;industry collaboration;instructional facility;interlock system;lab managers;limited staffing;research projects;sustainability costs;sustainable user access system;system functions;tool damage prevention;tool down time;unauthorized tool use prevention;usability costs;user accountability;user information;user safety maintain;users authorization","","0","","","","","9-10 July 2012","","IEEE","IEEE Conference Publications"
"Research on media player based on Android","S. Jin; H. Li; Y. Liu","Faculty of Information Engineering, Zhengzhou University, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","2326","2329","Introduced the hierarchy and application components of Android platform. In view of its built-in media player has many limits, the paper designs a media player that based on file browser way to manage the media library. When it is started, the media player can scan the storage equipment stably and quickly and then will save the scanned lyric files to database. With the playing song, the media player can retrieve its lyric file quickly according to the music name, and then display the lyric synchronously.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234021","Android;Android simulator;application;media player","Androids;Humanoid robots;Libraries;Linux;Media;Multimedia communication;Smart phones","information retrieval;multimedia systems;music;operating system kernels","Android;database;file browser;lyric file retrieval;media library;media player;music name;scanned lyric file saving;song playing;storage equipment scanning;synchronous display","","0","","5","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Extraction of thesaurus and project structure from Linux kernel source tree","A. Y. Sokolov; I. R. Golovko; E. A. Cherkashin","Irkutsk State Technical University, Russia","2012 Proceedings of the 35th International Convention MIPRO","20120716","2012","","","1088","1092","The paper deals with the problem of automatic extraction of a software project structure and its ontology from revision control system network of the project source code. The aim of the investigation is to determine the correlation between the project structure and ontology terms of the project domain, i.e., to answer the question about possibility to describe the structure of the project with terms of the ontology. If it will be true then a modification of the ontology can be interpreted as modification of the project structure.","","DVD:978-953-233-072-4; Electronic:978-953-233-068-7; POD:978-1-4673-2577-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240805","","Indexes;Kernel;Linux;Ontologies;Thesauri;Unified modeling language","Linux;information retrieval;ontologies (artificial intelligence);operating system kernels;project management;software maintenance;thesauri;tree data structures","Linux kernel source tree;automatic software project structure extraction;instrumental software development technologies evolution;ontology terms;project source code;revision control system network;thesaurus extraction","","0","","5","","","21-25 May 2012","","IEEE","IEEE Conference Publications"
"GazeCloud: A Thumbnail Extraction Method Using Gaze Log Data for Video Life-Log","Y. Ishiguro; J. Rekimoto","Univ. of Tokyo, Tokyo, Japan","2012 16th International Symposium on Wearable Computers","20120723","2012","","","72","75","We propose a method for information extraction and presentation using recorded eye gaze data, i.e., life-log video data. We call our method Gaze Cloud, which essentially uses gaze information for the generation of thumbnail images. One of the usages of wearable computing, personal life-logs are becoming increasingly possible. However, an aspect that needs to be addressed is information retrieval through different browsing methods. It is also well known that human memory recall is aided by effective presentation of information. Our propose method Gaze Cloud calculates the importance of information from gaze data that is consequently used for the generation of thumbnail images. This method performs the calculation using the eye gaze duration and hot spot information. Additionally, we construct a prototype daily-use wearable eye tracker system.","1550-4816;15504816","Electronic:978-0-7695-4697-1; POD:978-1-4673-1583-8","10.1109/ISWC.2012.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246145","","Acceleration;Cameras;Data mining;Data visualization;Humans;Tag clouds;USA Councils","information retrieval;video recording;video signal processing;wearable computers","GazeCloud;browsing methods;daily-use wearable eye tracker system;gaze information;gaze log data;human memory recall;information extraction;information presentation;information retrieval;life-log video data;personal life-logs;recorded eye gaze data;thumbnail extraction method;video life-log;wearable computing","","2","","14","","","18-22 June 2012","","IEEE","IEEE Conference Publications"
"Hamiltonian-Based Clustering: Algorithms for Static and Dynamic Clustering in Data Mining and Image Processing","D. Casagrande; M. Sassano; A. Astolfi","Dept of Electrical, Managerial, and Mech Eng, University of Udine","IEEE Control Systems","20120719","2012","32","4","74","91","The large amount of data available for analysis and management raises the need for defining, determining, and extracting meaningful information from the data. Hence in scientific, engineering, and economics studies, the practice of clustering data arises naturally when sets of data have to be divided into subgroups with the aim of possibly deducting common features for data belonging to the same subgroup. For instance, the innovation scoreboard [1] (see Figure 1) allows for the classification of the countries into four main clusters corresponding to the level of innovation defining the “leaders,” the “followers,” the “trailing,” and the “catching up” countries. Many other disciplines may require or take advantage of a clustering of data, from market research [2] to gene expression analysis [3], from biology to image processing [4][7]. Therefore, several clustering techniques have been developed (for details see “Review of Clustering Algorithms”).","1066-033X;1066033X","","10.1109/MCS.2012.2196321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6244703","","Clustering algorithms;Data mining;Feature extraction;Gene expressoin;Marketresearch;Technological innovation","data analysis;data mining;image processing;information retrieval;pattern clustering","Hamiltonian-based clustering;biology;data analysis;data clustering;data management;data mining;dynamic clustering;gene expression analysis;image processing;information extraction;innovation scoreboard;market research;static clustering","","4","","20","","","Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Mining Knowledge from Data: An Information Network Analysis Approach","J. Han; Y. Sun; X. Yan; P. S. Yu","Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","1214","1217","Most objects and data in the real world are interconnected, forming complex, heterogeneous but often semistructured information networks. However, many database researchers consider a database merely as a data repository that supports storage and retrieval rather than an information-rich, inter-related and multi-typed information network that supports comprehensive data analysis, whereas many network researchers focus on homogeneous networks. Departing from both, we view interconnected, semi-structured datasets as heterogeneous, information-rich networks and study how to uncover hidden knowledge in such networks. For example, a university database can be viewed as a heterogeneous information network, where objects of multiple types, such as students, professors, courses, departments, and multiple typed relationships, such as teach and advise are intertwined together, providing abundant information. In this tutorial, we present an organized picture on mining heterogeneous information networks and introduce a set of interesting, effective and scalable network mining methods. The topics to be covered include (i) database as an information network, (ii) mining information networks: clustering, classification, ranking, similarity search, and meta path-guided analysis, (iii) construction of quality, informative networks by data mining, (iv) trend and evolution analysis in heterogeneous information networks, and (v) research frontiers. We show that heterogeneous information networks are informative, and link analysis on such networks is powerful at uncovering critical knowledge hidden in large semi-structured datasets. Finally, we also present a few promising research directions.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228171","","Cleaning;Data mining;Databases;Ontologies;Semantics;Sun","data analysis;data mining;database management systems;information networks;information retrieval systems","comprehensive data analysis;data mining;data repository;data retrieval;data storage;database researchers;information network analysis;knowledge mining;link analysis;semistructured information networks","","2","","32","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"Case study: Analysis of the direct sales force performance - Clients reach by geographical area in telecommunication industry","M. Velić; I. Padavić; Z. Lovrić","Initium Futuri Ltd., Zagreb, Croatia","2012 Proceedings of the 35th International Convention MIPRO","20120716","2012","","","1601","1606","In today's every-day changing economy, direct sales is of big importance both as a sales and customer satisfaction tool but also as an information retrieval process. In direct sale business there is a problem of geographical deployment of the salesmen and thus utilization of the complete clients population dispersed geographically. In this paper we analyze those parameters on the example from the Croatian market. Problems are identified and possible improvements by utilizing some of the travelling salesmen problem solutions are analyzed.","","DVD:978-953-233-072-4; Electronic:978-953-233-068-7; POD:978-1-4673-2577-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240907","","Cities and towns;Customer relationship management;Marketing and sales;Search problems;Software;Traveling salesman problems","customer satisfaction;geographic information systems;information retrieval;telecommunication industry;travelling salesman problems","Croatian market;complete clients population;customer satisfaction tool;direct sales force performance;every-day changing economy;geographical area;geographical deployment;information retrieval;telecommunication industry;travelling salesmen problem solutions","","0","","28","","","21-25 May 2012","","IEEE","IEEE Conference Publications"
"A user survey on search ranking algorithm for social networking sites","Khuan Yew Lee; J. L. Hong","School of Computing and IT, Taylor's University, Malaysia","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","995","999","Social networks need to manage and control the drift of insane amount of information by filtering and ranking everything in order to ensure they are right there for users' viewing pleasure. However, the realization of social networks ranking is currently dictated by fairly straightforward optimization algorithms. Hence, there is a need for a newly enhanced and improved ranking algorithm to be formulated since users have been occasionally seeing what they should not. In this paper, we conduct a user survey to gain a deeper insight on user needs for ranking algorithm. The outcome of the user survey is useful for the development of accurate and efficient ranking algorithm.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234068","Search Ranking;Social Network;User Survey","Algorithm design and analysis;Collaboration;Educational institutions;Facebook;Feeds;Filtering","information filtering;information retrieval;optimisation;social networking (online)","fairly straightforward optimization algorithms;information filtering;search ranking algorithm;social networking sites","","0","","25","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"A Classification of Questions Using SVM and Semantic Similarity Analysis","J. Xu; Y. Zhou; Y. Wang","Sch. of Comput. Sci., Zhongyuan Univ. of Technol., Zhengzhou, China","2012 Sixth International Conference on Internet Computing for Science and Engineering","20120716","2012","","","31","34","Question classification is an important part in the question answering system. The results of the question classification determine the quality of the question answering system. In this paper, a question classification algorithm based on SVM and question semantic similarity is proposed, it is applied in a real-world on-line interactive question answering system in tourism domain. In the two level question classification method, Support Vector Machine model is adopted to train a classifier on coarse categories, question semantic similarity model is used to classify the question into sub-categories. The use of concept of domain terms construction will improve the feature expression of Support Vector Machine and question semantic similarity. The experimental result show that the accuracy of the classification algorithm is up to 91.49%.","2330-9857;23309857","Electronic:978-0-7695-4705-3; POD:978-1-4673-1683-5","10.1109/ICICSE.2012.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239781","SVM;lexical feature;question classification;question semantic similarity","Accuracy;Classification algorithms;Feature extraction;Semantics;Support vector machines;Training;Vectors","interactive systems;pattern classification;question answering (information retrieval);support vector machines;travel industry","SVM;classifier;domain terms construction;feature expression;online interactive question answering system;question classification algorithm;question semantic similarity analysis;support vector machine model;tourism domain","","3","","7","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
"Research and design of a vertical search engine for educational resources","Lei Shao; Jianwei Li; Xuerong Gou","School of Network Education, Beijing University of Posts and Telecommunications, 100876, China","2011 International Conference on Advanced Intelligence and Awareness Internet (AIAI 2011)","20120709","2011","","","159","163","With computer and network technology developing, the educational resources on the Internet are also growing exponentially. To locate useful resources from the mass and diverse information is crucial. When using general search engine to search information in a specific field, the results usually cover all fields which can't provide accurate retrieval service for users. However, powerful vertical search engine can meet users' information needs more precisely. This paper describes a vertical search engine on the resources in educational field based on Lucene. Three parts of the system are detailed in this paper, identification of search results metadata, analysis and indexing of all formats of resources and improvement of Lucene ranking algorithm.","","Electronic:978-1-84919-471-6","10.1049/cp.2011.1448","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233217","Lucene;educational resource;ranking;vertical search","","Internet;educational technology;indexing;information retrieval;search engines","Internet;Lucene ranking algorithm;educational resources;indexing;search results metadata;vertical search engine","","0","","","","","28-30 Oct. 2011","","IET","IET Conference Publications"
"Efficient Top-k Keyword Search in Graphs with Polynomial Delay","M. Kargar; A. An","Dept. of Comput. Sci. & Eng., York Univ., Toronto, ON, Canada","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","1269","1272","A system for efficient keyword search in graphs is demonstrated. The system has two components, a search through only the nodes containing the input keywords for a set of nodes that are close to each other and together cover the input keywords and an exploration for finding how these nodes are related to each other. The system generates all or top-k answers in polynomial delay. Answers are presented to the user according to a ranking criterion so that the answers with nodes closer to each other are presented before the ones with nodes farther away from each other. In addition, the set of answers produced by our system is duplication free. The system uses two methods for presenting the final answer to the user. The presentation methods reveal relationships among the nodes in an answer through a tree or a multi-center graph. We will show that each method has its own advantages and disadvantages. The system is demonstrated using two challenging datasets, very large DBLP and highly cyclic Mondial. Challenges and difficulties in implementing an efficient keyword search system are also demonstrated.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228185","","Approximation algorithms;Communities;Delay;Indexes;Keyword search;Polynomials","approximation theory;information retrieval;polynomials;tree data structures;trees (mathematics)","Mondial;approximation algorithm;data structure;duplication free;information extraction;multicenter graph;polynomial delay;presentation methods;ranking criterion;top-k keyword search system;very large DBLP","","3","","6","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"Thwarting traffic analysis: A signal processing perspective","A. Mishra; P. Venkitasubramaniam","ECE Department, Lehigh University, USA","2012 IEEE 7th Sensor Array and Multichannel Signal Processing Workshop (SAM)","20120730","2012","","","169","172","Traffic analysis, where eavesdroppers retrieve networking information such as source-destination pairs and paths of data flow, severely compromises user privacy and can equip an adversary to launch more powerful network attacks. Anonymous communication, where users exchange information without revealing the communicating parties is essential in any data network. Chaum Mixing, where relay nodes or proxy servers use cryptographic and batching strategies to mask source identities, is a well technique to provide anonymous communication on the Internet. The mathematical analysis of Chaum mixes and the design of mixing strategies have utilized an information theoretic measure of anonymity based on Shannon entropy. In this work, a statistical signal processing framework is proposed to study optimal mixing strategies and the achievable anonymity. Using the detection time of an adversary as a metric, the maximum achievable anonymity of a mix is characterized as a function of its available memory and the allowed rate of dummy transmissions. It is shown that, in the absence of dummy transmissions, the maximum allowable time for anonymous transmission increases quadratically with the buffer size, and for a fixed buffer size, the system approaches perfect unobservability at a rate inversely proportional to the rate of dummy transmissions.","1551-2282;15512282","Electronic:978-1-4673-1071-0; POD:978-1-4673-1070-3","10.1109/SAM.2012.6250457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6250457","","Conferences;Delay;Internet;Privacy;Signal processing","Internet;computer network security;cryptography;entropy;information retrieval;mathematical analysis;signal detection;statistical analysis;telecommunication traffic","Chaum mixing strategy;Internet;Shannon entropy;anonymous communication;anonymous transmission;batching strategy;cryptographic strategy;data flow path;data network;dummy transmissions;fixed buffer size;information theoretic measure;mathematical analysis;network attacks;network information retrieval;optimal mixing strategy;proxy servers;relay nodes;source-destination pairs;statistical signal processing framework;thwarting traffic analysis;user privacy","","1","","13","","","17-20 June 2012","","IEEE","IEEE Conference Publications"
"Developing a plug-in tool to make OneNote an E-textbook","J. Cristy; J. G. Tront","Virginia Tech, Blacksburg, VA, USA","2012 Second International Workshop on Developing Tools as Plug-Ins (TOPI)","20120702","2012","","","84","85","E-textbooks encourage the user to perform all of the operations typically performed with a hardcopy text in addition to some functions not possible with paper books. This project works to implement an e-textbook with as much capability as possible using software tools that are already in place. Because Microsoft OneNote already implements some of the desired functions of e-textbooks, it is a suitable software foundation for this work. This paper will detail the implementation of the e-textbook plug-in for OneNote and Windows. Specifically, it will discuss the methods of harnessing the built-in capabilities of OneNote such as page content creation and modification, specialized controls creation, and interaction with other programs.","2327-0748;23270748","Electronic:978-1-4673-1820-4; POD:978-1-4673-1819-8","10.1109/TOPI.2012.6229817","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6229817","Education;OneNote;e-Textbook;eTextbook","Browsers;Consumer electronics;Internet;Libraries;Navigation;Portable document format;Web search","Internet;content management;information retrieval;text editing;word processing","E-textbook;Microsoft OneNote;Web function;Web search;Windows;hardcopy text;page content creation;page content modification;plug-in tool development;program interaction;software tool;specialized control creation","","1","","8","","","3-3 June 2012","","IEEE","IEEE Conference Publications"
"Digital Archives of Poem Manuscripts and Historical Data of Mr. Chang Lai Yulian","B. C. Y. Wen; H. C. Chang; S. L. Chiu; K. A. Wang; P. C. Chan","Language Center, Central Taiwan Univ. of Sci. & Technol., Taichung, Taiwan","2012 International Symposium on Computer, Consumer and Control","20120702","2012","","","602","605","Mr. Chang Lai Yulian (1901-1961) was a master of poetry and dedicated his life to the agricultural development and education of his hometown-the Dakeng Jungongliao District, Taichung County. On December 1st 2008, the Chang Lai Family donated all Mr. Chang Lai Yulian's manuscripts, a total of 893 manuscripts in 432 volumes, to the institution of his residence-XCentral Taiwan University of Science and Technology Library for permanent archiving. The family wishes to preserve Mr. Chang Lai Yulian's works through the Digital Archive Program and pass down the cultural assets of Taiwan to the generations to come. The Digital Archive will enable the general public to share and appreciate the beauty of the poems generic from Taiwan over the Internet.","","Electronic:978-0-7695-4655-1; POD:978-1-4673-0767-3","10.1109/IS3C.2012.157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228380","Chang Lai Yulian;Digital Archives;Li Society;Metadata","Computer science;Cultural differences;Databases;Educational institutions;Internet;Sorting","Internet;academic libraries;educational institutions;history;information retrieval systems;literature","Central Taiwan University of Science and Technology Library;Dakeng Jungongliao District;Internet;Mr. Chang Lai Yulian;Poem Manuscripts;Taichung County;Taiwan;agricultural development;cultural assets;digital archive program;education;historical data","","0","","10","","","4-6 June 2012","","IEEE","IEEE Conference Publications"
"Experience and recommendations for distributed software development","P. Carlson; Nan Xiao","Human-Computer Interaction, Iowa State University, Ames, USA","2012 Second International Workshop on Collaborative Teaching of Globally Distributed Software Development (CTGDSD)","20120628","2012","","","21","24","The following position paper outlines a software development course project for a semester long class on distributed software development. The developed application was an Android based facial recognition application which returned the name and contact information of people in a picture. Students from Iowa State University in the US, Jilin University in China, and the Federal Universidade da Bahia in Brazil participated. Challenges and solutions that were part of the development process as well as recommendations for future classes are provided.","","Electronic:978-1-4673-1818-1; POD:978-1-4673-1817-4","10.1109/CTGDSD.2012.6226945","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226945","Android;distributed software development;remote collaboration","Collaboration;Documentation;Educational institutions;Programming;Servers;Smart phones;Software","computer aided instruction;computer science education;educational courses;face recognition;groupware;information retrieval;operating systems (computers);software engineering","Android based facial recognition application;Federal Universidade da Bahia;Iowa State University;Jilin University;contact information;distributed software development;name information;software development course project","","2","","10","","","9-9 June 2012","","IEEE","IEEE Conference Publications"
"Combining N-gram retrieval with weights propagation on massive RDF graphs","H. Hu; X. Du","Key Labs of Data Engineering and Knowledge Engineering, Ministry of Education, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1181","1185","N-gram approach takes the position information into account additionally and thus can offer higher accuracy in query answering than keyword based approaches and is widely used in IR and NLP. However, in large-scale RDF graphs, URIs instead of documents are the ranking and querying units; URIs are usually much shorter than documents, and different URIs are interlinked into a massive network. One shot n-gram querying is usually not good for the RDF data in many cases. In this paper, we present a hybrid framework which combines the n-gram retrieval with link analysis based weight propagation. The idea is to exploit the link structures in the RDF data graphs and propagate the one shot n-gram score weights along with these links. Large scale experiments using MapReduce on Billion Triples Challenge dataset show the hybrid framework achieves an 80.3% improvement in relevance scores over mere n-gram retrieval.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233970","Linked Data;MapReduce;N-gram;RDF Graphs","Conferences;Educational institutions;Indexes;Legged locomotion;Resource description framework;Semantics;USA Councils","data structures;graph theory;information retrieval","Billion Triples Challenge dataset;MapReduce;N-gram retrieval;RDF data graphs;large-scale RDF graphs;massive RDF graphs;weights propagation","","0","","12","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Multimedia Processing and Applications: Based on Visualizing RIA Navigation On-Demand Service","C. W. Hwang","Lan-Yang Inst. of Technol., Taiwan","2012 International Symposium on Computer, Consumer and Control","20120702","2012","","","137","140","When facing the "" overabundant"" of semantic web information, in this paper, the researcher proposes the hierarchical classification and visualizing RIA (Rich Internet Application) navigation system: Concept Map (CM) + Semantic Structure (SS) + the Knowledge on Demand (KOD) service. The aim of the Multimedia processing and empirical applications testing, was to investigating the utility and usability of this visualizing navigation strategy in web design, into whether it enables the user to retrieve and construct their personal knowledge or not. Furthermore, based on the segment markets theory in the Marketing model, to propose a User Interface (UI) classification strategy and formulate a set of hypermedia design principles for further UI strategy & e-learning resources in semantic web content. These research findings: (1) Irrespective of whether the simple declarative knowledge or the complex declarative knowledge model is used, the ""CM + SS + KOD navigation system"" has a better cognition effect than the ""Non CM + SS + KOD navigation system"". However, for the ""No web design experience user"", the navigation system does not have an obvious cognition effect. (2) The essential of classification in semantic web design: Different groups of user have a diversity of preference needs and different cognitive styles in the CM + SS + KOD navigation system.","","Electronic:978-0-7695-4655-1; POD:978-1-4673-0767-3","10.1109/IS3C.2012.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228266","Concept Map (CM);Knowledge on Demand (KOD);Multimedia information web design;Semantic Structure (SS);cognition navigation;visualizing navigation","Cognition;Knowledge engineering;Multimedia communication;Navigation;Semantics;Visualization;Web design","cognition;computer aided instruction;data visualisation;hypermedia;information retrieval;multimedia computing;pattern classification;semantic Web;user interfaces","CM;KOD;RIA navigation system;SS;UI strategy;Web design;cognition effect;cognitive style;concept map;declarative knowledge;e-learning resource;hierarchical classification;hypermedia design principle;knowledge on demand;knowledge retrieval;marketing model;multimedia processing;on-demand service visualization;rich Internet application;segment market theory;semantic Web information;semantic structure;user interface;user preference diversity","","0","","10","","","4-6 June 2012","","IEEE","IEEE Conference Publications"
"Reducing Uncertainty of Low-Sampling-Rate Trajectories","K. Zheng; Y. Zheng; X. Xie; X. Zhou","Sch. of Inf. Technol. & Electr. Eng., Univ. of Queensland, Brisbane, QLD, Australia","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","1144","1155","The increasing availability of GPS-embedded mobile devices has given rise to a new spectrum of location-based services, which have accumulated a huge collection of location trajectories. In practice, a large portion of these trajectories are of low-sampling-rate. For instance, the time interval between consecutive GPS points of some trajectories can be several minutes or even hours. With such a low sampling rate, most details of their movement are lost, which makes them difficult to process effectively. In this work, we investigate how to reduce the uncertainty in such kind of trajectories. Specifically, given a low-sampling-rate trajectory, we aim to infer its possible routes. The methodology adopted in our work is to take full advantage of the rich information extracted from the historical trajectories. We propose a systematic solution, History based Route Inference System (HRIS), which covers a series of novel algorithms that can derive the travel pattern from historical data and incorporate it into the route inference process. To validate the effectiveness of the system, we apply our solution to the map-matching problem which is an important application scenario of this work, and conduct extensive experiments on a real taxi trajectory dataset. The experiment results demonstrate that HRIS can achieve higher accuracy than the existing map-matching algorithms for low-sampling-rate trajectories.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228163","","Artificial neural networks;Educational institutions;Global Positioning System;Inference algorithms;Roads;Trajectory;Uncertainty","Global Positioning System;inference mechanisms;information retrieval;mobile computing;sampling methods;traffic engineering computing;trees (mathematics);uncertainty handling","GPS-embedded mobile devices;HRIS;consecutive GPS points;historical data;historical trajectories;history-based route inference system;information extraction;location trajectories;location-based services;low-sampling-rate trajectories;map-matching problem;taxi trajectory dataset;time interval;travel patterns;uncertainty reduction","","33","1","32","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"Examining the impact of stemming on clustering Turkish texts","V. Tunali; T. T. Bilgin","Faculty of Engineering, Maltepe University, Istanbul, Turkey","2012 International Symposium on Innovations in Intelligent Systems and Applications","20120723","2012","","","1","4","Preprocessing is an important step in information retrieval and text mining. In this study, we examined the impact of stemming on clustering Turkish texts. We used two datasets compiled from web sites of Turkish news agencies, and performed extensive experiments. We empirically show that there is no significant evidence that stemming always improves the quality of clustering for texts in Turkish. However, when stemming is used, dimensionality of the document-term matrix dramatically decreases without inversely affecting the clustering performance. As a result, it is highly recommended to apply stemming for clustering Turkish texts.","","Electronic:978-1-4673-1448-0; POD:978-1-4673-1446-6","10.1109/INISTA.2012.6246966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246966","data mining;document clustering;preprocessing;stemming;text mining","Clustering algorithms;Educational institutions;Entropy;Text mining;Web sites","Web sites;data mining;information retrieval;pattern clustering;text analysis","Turkish news agencies;Turkish text clustering;Web sites;document-term matrix dimensionality reduction;information retrieval;stemming impact;text clustering quality;text mining","","2","","14","","","2-4 July 2012","","IEEE","IEEE Conference Publications"
"Subjects on objects in contexts: Using GICA method to quantify epistemological subjectivity","T. Honkela; J. Raitio; K. Lagus; I. T. Nieminen; N. Honkela; M. Pantzar","Aalto University School of Science, Dep't of Information and Computer Science, P.O.Box 15400, FI-00076, Finland","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","9","A substantial amount of subjectivity is involved in how people use language and conceptualize the world. Computational methods and formal representations of knowledge usually neglect this kind of individual variation. We have developed a novel method, Grounded Intersubjective Concept Analysis (GICA), for the analysis and visualization of individual differences in language use and conceptualization. The GICA method first employs a conceptual survey or a text mining step to elicit from varied groups of individuals the particular ways in which terms and associated concepts are used among the individuals. The subsequent analysis and visualization reveals potential underlying groupings of subjects, objects and contexts. One way of viewing the GICA method is to compare it with the traditional word space models. In the word space models, such as latent semantic analysis (LSA), statistical analysis of word-context matrices reveals latent information. A common approach is to analyze term-document matrices in the analysis. The GICA method extends the basic idea of the traditional term-document matrix analysis to include a third dimension of different individuals. This leads to a formation of a third-order tensor of size subjects × objects × contexts. Through flattening into a matrix, these subject-object-context (SOC) tensors can again be analyzed using various computational methods including principal component analysis (PCA), singular value decomposition (SVD), independent component analysis (ICA) or any existing or future method suitable for analyzing high-dimensional data sets. In order to demonstrate the use of the GICA method, we present the results of two case studies. In the first case, GICA of health-related concepts is conducted. In the second one, the State of the Union addresses by US presidents are analyzed. In these case studies, we apply multidimensional scaling (MDS), the self-organizing map (SOM) and Neighborhood Retrieval Visualizer (NeRV) a- specific data analysis methods within the overall GICA method. The GICA method can be used, for instance, to support education of heterogeneous audiences, public planning processes and participatory design, conflict resolution, environmental problem solving, interprofessional and interdisciplinary communication, product development processes, mergers of organizations, and building enhanced knowledge representations in semantic web.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252765","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252765","","Color;Context;Educational institutions;Electronic mail;Humans;Pragmatics;Tensile stress","data analysis;data mining;data visualisation;independent component analysis;information retrieval;knowledge representation;principal component analysis;self-organising feature maps;semantic Web;singular value decomposition;text analysis","(ICA);GICA method;MDS;NeRV;PCA;SOC;SVD;conflict resolution;data analysis methods;environmental problem solving;epistemological subjectivity quantification;formal knowledge representations;grounded intersubjective concept analysis;independent component analysis;latent semantic analysis;multidimensional scaling;neighborhood retrieval visualizer;participatory design;principal component analysis;product development processes;public planning processes;self-organizing map;semantic Web;singular value decomposition;statistical analysis;subject-object-context tensors;term-document matrix analysis;text mining step;visualization;word space models;word-context matrices","","1","1","22","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Making Research Data Available in Australia","A. Burton; D. Groenewegen; C. Love; A. Treloar; R. Wilkinson","Australian National Data Service","IEEE Intelligent Systems","20120711","2012","27","3","40","43","Governmental and private initiatives in Australia are trying to make public-sector data and research data more available and of increased value for more purposes. Data is becoming more freely and openly available in the Commonwealth of Australia as a result of initiatives that span the public sector as well as the research and innovations sector. At the national level, the Commonwealth's Gov 2.0 agenda has resulted in the Declaration of Open Government, “built on better access to and use of government-held information.”In the research sector, a National Collaborative Research Infrastructure Strategy (NCRIS; http://ncris.innovation.gov.au) has operated on the assumption that research data is an integral part of research infrastructure. The Australian National Data Service (ANDS) has been funded by the Commonwealth Government to create the infrastructure to enable Australian researchers to easily publish, discover, access, and use research data.","1541-1672;15411672","","10.1109/MIS.2012.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6237456","ANDS;ARDC;Australia;Australian National Data Service;Australian Research Data Commons;data;infrastructure;open data;research data","Australia;Data processing;Database systems;Government policies;Information services;Open systems;Research initiatives","Internet;government data processing;information retrieval","Australian National Data Service;Commonwealth of Australia;Gov 2.0 agenda;NCRIS;National Collaborative Research Infrastructure Strategy;data access;government-held information;governmental initiatives;innovations sector;open government;private initiatives;public-sector data;research data;research infrastructure","","2","","5","","","May-June 2012","","IEEE","IEEE Journals & Magazines"
"A new algorithm based on centroid for text categorization","C. Shen; B. Wu","School of Computer Science, Beijing University of Posts and Telecommunications, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1265","1269","Text categorization is a hot topic and a key technology in data mining and information retrieval, so that it received wide attention recently. Centroid-based algorithm is an effective and robust approach. However it often suffers from the inductive bias or model misfit. In order to solve this problem, many researchers have put forward a number of improvement strategies which makes the centroid-based algorithm have a better performance. The paper proposed a novel approach to adjust the centroids which is called Weighted Margin adjusted Centroid based Algorithm (WMCA). Then it presented a lot of experimental comparison with some other algorithms by using 5 different public corpuses. The results showed that the WMCA algorithm has the best performance.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234190","WMCA;centroid;margin;text categorization","Classification algorithms;Educational institutions;Machine learning;Support vector machines;Text categorization;Training;Vectors","data mining;information retrieval;pattern classification;text analysis","WMCA algorithm;data mining;inductive bias;information retrieval;model misfit;text categorization;text classification;weighted margin adjusted centroid based algorithm","","0","","16","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"3D model retrieval method based on area distributions","L. j. Jiang; X. f. Chen; G. y. Zhang","School of Mechatronics Engineering, Harbin Institute of Technology, China","2012 8th International Conference on Natural Computation","20120709","2012","","","515","518","Large numbers of 3D model have been used in the product design and 3D artifact, but problems have occurred that attribute data was incomplete; the search method was inaccurate based on attributes. Consequently, the search engines could not provide effective search service. This paper proposes an area distributions based on method outlying with 3D system. According to this method, we first summarize the total area and average area of the vertex of the 3D model, then normalize the list of the area distributions list and Fourier transform the list; last, get the final area distributions list model, and map the search of the model to compare the area distributions list. Experiments have been conducted for comparing and evaluating the proposed algorithm utilizing the Engineering Shape Benchmark (ESB) database. The experiential results show that the proposed technique has effectively reflected the similarity among engineering models, and the match result of the extremely similar model is accurate and the retrieval performance has been significantly improved compared with traditional shape distribution method.","2157-9555;21579555","Electronic:978-1-4577-2133-5; POD:978-1-4577-2130-4","10.1109/ICNC.2012.6234518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234518","Fourier transform;area distributions;engineering model retrieval","Computational modeling;Fourier transforms;Mathematical model;Shape;Solid modeling;Tin;Vectors","CAD;Fourier transforms;information retrieval;search engines","3D model retrieval method;3D model vertex;ESB database;Engineering Shape Benchmark database;Fourier transform;area distribution list normalization;attribute data;average area;engineering model retrieval;search engines;search mapping;total area","","0","","10","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"A novel algorithm for technical articles classification based on gene selection","R. Kilany; R. Ammar; S. Rajasekaran","Comput. Sci. &amp; Eng. Dept., Univ. of Connecticut, Storrs, CT, USA","2012 IEEE Symposium on Computers and Communications (ISCC)","20120726","2012","","","000234","000238","Research in science and engineering has resulted in the generation of voluminous datasets. For instance, biological databases such as PubMed now have millions of articles. Given this growth in data, the problem of retrieving information relevant to a specific topic has become a big challenge. In this paper we focus on the problem of retrieving articles pertaining to a given topic from among a huge collection of articles. In particular, we investigate the problem of classifying articles. Though numerous techniques and tools are available for documents classification, a shortcoming in them is that they take too much time. In this paper we present generic computational techniques that can classify articles efficiently. Our algorithms are based on algorithms that have been proposed for a related problem called gene selection. Gene selection is the problem of identifying a minimum set of genes that are responsible for certain events (for example the presence of cancer). Even though gene selection was originally proposed for biological data analysis, the technique itself is generic. For example, `genes' can be thought of as generic variable. A typical tool that we envision will take as input a set of keywords (that characterize the information of interest) and will develop a learner that will identify a small subset of the keywords that are capable of classifying papers into two types. A paper is of the first type if it has information of interest and a paper is of the second type if the paper does not have information of interest. Experiments show that the new algorithm obtains a higher classification accuracy using a smaller number of selected keywords when compared to one of the best algorithms reported in the literature.","1530-1346;15301346","Electronic:978-1-4673-2713-8; POD:978-1-4673-2712-1; USB:978-1-4673-2711-4","10.1109/ISCC.2012.6249300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249300","Data Minimg;SVM;document classification;text categorization","Accuracy;Algorithm design and analysis;Classification algorithms;Correlation;Kernel;Support vector machines;Training","data mining;information retrieval;learning (artificial intelligence);pattern classification;support vector machines;text analysis","article collection;article retrieval;data growth;document classification;gene selection;generic computational technique;generic variable;information characterization;information retrieval;keyword selection;keyword subset identification;learning;paper classification;technical article classification;text mining;voluminous dataset","","0","","32","","","1-4 July 2012","","IEEE","IEEE Conference Publications"
"Building a dictionary of image fragments","Z. Liao; A. Farhadi; Y. Wang; I. Endres; D. Forsyth","Department of Computer Science, University of Illinois at Urbana-Champaign","2012 IEEE Conference on Computer Vision and Pattern Recognition","20120726","2012","","","3442","3449","We show how to build large dictionaries of meaningful image fragments. These fragments could represent objects, objects in a local context, or parts of scenes. Our fragments operate as region-based exemplars, and we show how they can be used for image classification, to localize objects, and to compose new images. While each of these activities has been demonstrated before, each has required manually extracted fragments. Because our method for fragment extraction is automatic it can operate at a large scale. Our method uses recent advances in generic object detection techniques, together with discriminative tests to obtain good, clean fragment sets with extensive diversity. Our fragments are organized by the tags of the source images to build a semantically organized fragment table. A good set of fragment exemplars describes only the object, rather than object+context. Context could help identify an object; but it could also contribute noise, because other objects might appear in the same context. We show a slight improvement in classification performance by two standard exemplar matching methods using our fragment dictionary over such methods using image exemplars. This suggests that knowing the support of an exemplar is valuable. Furthermore, we demonstrate our automatically built fragment dictionary is capable of good localization. Finally, our fragment dictionary supports a keyword based fragment search system, which allows artists to get the fragments they need to make image collages.","1063-6919;10636919","Electronic:978-1-4673-1228-8; POD:978-1-4673-1226-4; USB:978-1-4673-1227-1","10.1109/CVPR.2012.6248085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6248085","","Buildings;Context;Dictionaries;Image segmentation;Proposals;Standards;Training","dictionaries;feature extraction;image classification;image matching;information retrieval;object detection","automatically built fragment dictionary;classification performance;discriminative tests;fragment exemplars;fragment extraction;generic object detection techniques;image classification;image collages;image exemplars;image fragments dictionary;keyword based fragment search system;object identification;object localization;object+context;region-based exemplars;semantically organized fragment table;source images;standard exemplar matching methods","","4","","13","","","16-21 June 2012","","IEEE","IEEE Conference Publications"
"Ontology-based knowledge retrieval system and evaluation mechanism","F. Yang; M. Lu","Library of Second Military Medical University, Shanghai 200433, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","2944","2948","Ontology-based knowledge retrieval is one of the mainstreams of the development of information retrieval field. The evaluation mechanism is an important way to improve the efficiency of knowledge retrieval, and to enhance the user satisfaction. This paper evaluates the efficiency of knowledge retrieval models, and advances the corresponding rules and the assessment mechanisms.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234301","Knowledge Retrieval;Ontology;evaluation mechanism","Accuracy;Cognition;Libraries;Ontologies;Semantics","information retrieval;ontologies (artificial intelligence)","assessment mechanisms;evaluation mechanism;information retrieval field development;ontology-based knowledge retrieval system;user satisfaction enhancement","","0","","10","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"An Efficient Trie-based Method for Approximate Entity Extraction with Edit-Distance Constraints","D. Deng; G. Li; J. Feng","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","762","773","Dictionary-based entity extraction has attracted much attention from the database community recently, which locates sub strings in a document into predefined entities (e.g., person names or locations). To improve extraction recall, a recent trend is to provide approximate matching between sub strings of the document and entities by tolerating minor errors. In this paper we study dictionary-based approximate entity extraction with edit-distance constraints. Existing methods have several limitations. First, they need to tune many parameters to achieve high performance. Second, they are inefficient for large edit-distance thresholds. We propose a trie-based method to address these problems. We first partition each entity into a set of segments, and then use a trie structure to index segments. To extract similar entities, we search segments from the document, and extend the matching segments in both entities and the document to find similar pairs. We develop an extension-based method to efficiently find similar string pairs by extending the matching segments. We optimize our partition scheme and select the best partition strategy to improve the extraction performance. Experimental results show that our method achieves much higher performance compared with state-of-the-art studies.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228131","","Complexity theory;Dictionaries;Heuristic algorithms;Indexes;Partitioning algorithms;Search problems;Strontium","approximation theory;dictionaries;indexing;information retrieval;search problems;string matching;tree data structures","approximate matching;database community;dictionary-based approximate entity extraction;document substring;edit-distance constraints;edit-distance thresholds;entity partitioning;entity substring;error tolerance;extension-based method;extraction performance improvement;partition scheme optimization;segment indexing;segment matching;segment search;trie-based method","","2","1","29","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"fp-Sparql: An RDF fuzzy retrieval mechanism supporting user preference","H. Wang; Z. M. Ma; J. Cheng","Sch. of Inf. Sci. &amp; Eng., Northeastern Univ., Shenyang, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","443","447","RDF fuzzy retrieval is an important module for realizing intelligent retrieval of Web semantics. In this paper, Zadeh's type-II fuzzy set theory, as well as the concepts of α-cut set and linguistic variable is adopted to put forward the RDF fuzzy retrieval mechanism supporting user preference, which extends SPARQL language for further realizing fuzzy and preferred expression. Moreover, ordered sub-domain table of linguistic values is constructed, to realize the projection from the fuzzy values to relayed sub-domains in the table, so as to figure out the interval of membership. On this basis, it will then be converted into the standard SPARQL by drawing support from the defuzzification rules, so as to achieve fuzzy retrieval operations. In order to test the ideology proposed in this paper, the fp-SPARQL (fuzzy and preference SPARQL) retrieval system is developed. The system has extended univ_Bench main body, with plenty of retrieval instances constructed. On this basis, visual methods will be employed to realize a fuzzy and preferred retrieval on RDF. According to the result of this experiment, our method has improved the performance of RDF fuzzy retrieval, and correspondingly, users' satisfaction rate on the retrieval results is also enhanced. Besides, the retrieval method complies with users' habit, endowing the system with higher flexibility nature.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234114","fp-SPARQL;fuzzy retrieval;linguistic variable;type-II fuzzy set theory","Educational institutions;Pragmatics;Remuneration;Resource description framework;Semantics;Standards","Internet;fuzzy set theory;information retrieval;user interfaces","RDF fuzzy retrieval mechanism;SPARQL language;Web semantics;Zadeh type-II fuzzy set theory;fp-SPARQL;intelligent retrieval;univ_Bench main body;user preference","","2","","8","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Implementation of 3D model retrieval feature extraction","Xuan Liu; Haisheng Li; Shan Peng; Qiang Cai","College of Computer and Information Engineering, Beijing Technology and Business University, 100048, China","2011 International Conference on Advanced Intelligence and Awareness Internet (AIAI 2011)","20120709","2011","","","367","371","This paper mainly realizes the key-steps of 3D model retrieval, which are model preprocessing, feature extraction and similarity measure. Firstly, area weighted and random point projection to deal with translation and scale normalization of 3D model is employed. Secondly, feature extraction of 3D models is analyzed by studying the algorithm based on the content. The two algorithms based on shape histogram, Osada algorithm and the Ankerst algorithm are realized in this paper. The result of two algorithms are compared based on 100 models. We found that Osada algorithm is better than Ankerst algorithm. For Ankerst algorithm, using quadratic distance to calculate similarity is better than the way using Euclidean distance.","","Electronic:978-1-84919-471-6","10.1049/cp.2011.1492","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233253","3D model retrieval;feature extraction;shape histogram;similarity","","feature extraction;information retrieval;solid modelling;statistical analysis","3D model retrieval;Ankerst algorithm;Euclidean distance;Osada algorithm;area weighted projection;feature extraction;model preprocessing;quadratic distance;random point projection;scale normalization;shape histogram;similarity measure;translation normalization","","0","","","","","28-30 Oct. 2011","","IET","IET Conference Publications"
"Study and Modeling of the Server Application for Monitoring Embedded Systems of Vehicle Fleet in Agribusiness","D. Mezzalira; L. C. Trevelin","Comput. Dept., Fed. Univ. of Sao Carlos, Sao Carlos, Brazil","2012 Second Brazilian Conference on Critical Embedded Systems","20120702","2012","","","100","105","The management of multiple systems such as machine tools, vehicles, aircraft, among others, results in a very intense flow of data between the server and embedded systems, using wired and/or radio frequency structures, demanding performance and interest in real time systems. The objective of this study is to propose a low cost scalable architecture for embedded applications, using pools of personal computers for high performance storage, retrieval and processing of information through the study of traces and real solutions for companies operating in this niche market.","","Electronic:978-0-7695-4728-2; POD:978-1-4673-1912-6","10.1109/CBSEC.2012.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227664","Distributed Systems;Embedded Systems;Performance;Queuing Systems;Simulation","Companies;Computer architecture;Embedded systems;Hardware;Monitoring;Servers;Vehicles","agricultural machinery;agriculture;client-server systems;competitive intelligence;enterprise resource planning;information retrieval;information storage;production engineering computing;queueing theory;vehicles","agribusiness;aircraft;business intelligence;data flow;embedded application;embedded system monitoring;enterprise resource planning;information processing;information retrieval;information storage;low cost scalable architecture;machine tools;multiple system management;personal computer;queueing theory;radio frequency structures;real time system;server application;sugarcane sector;vehicle fleet;wired structures","","1","","12","","","20-25 May 2012","","IEEE","IEEE Conference Publications"
"Person name extraction from Modern Standard Arabic or Colloquial text","O. H. Zayed; S. R. El-Beltagy","Center for Informatics Science, Nile University, Cairo, Egypt","2012 8th International Conference on Informatics and Systems (INFOS)","20120712","2012","","","NLP-44","NLP-48","Person Name extraction from Arabic text is a challenging task. While most existing Arabic texts are written in Modern Standard Arabic Text (MSA) the volume of Arabic Colloquial text is increasing progressively with the wide spread use of social media examples of which are Facebook, Google Moderator and Twitter. Previous work addressed extracting persons' names from MSA text only and especially from news articles. Previous work also relied on a lot of resources such as gazetteers for places, organizations, verbs, and person names. In this paper we introduce a system for extracting persons' names from any type of Arabic text whether it is MSA or Colloquial using very few resources. In our system, Natural Language Processing (NLP) is integrated with a limited set of dictionaries to extract a person's name from Arabic text. The paper also presents the results of evaluating the system on two datasets, one for MSA and the other for Colloquial Arabic. The results achieved were found to be satisfactory in terms of precision, recall and f-measure.","","Electronic:978-977-403-506-7; POD:978-1-4673-0828-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6236607","Modem Standard Arabic;colloquial Arabic;named entity recognition;natural language processing (NLP);social media","Computers;Dictionaries;Educational institutions;Grammar;Informatics;Natural language processing;Standards","information retrieval;natural language processing;social networking (online);text analysis;text detection","Arabic colloquial text;Facebook;Google;MSA;Moderator;NLP;Twitter;datasets;dictionaries;f-measure;modern standard Arabic text;natural language processing;person name extraction;precision;recall;social media","","0","","13","","","14-16 May 2012","","IEEE","IEEE Conference Publications"
"Integration framework for NASA NextGen Volumetric Cockpit Situation Display with haptic feedback","J. Robles; M. Sguerri; R. C. Rorie; K. P. Vu; T. Z. Strybel; P. Marayong","Department of Computer Engineering and Computer Science, California State University, Long Beach, USA","2012 IEEE International Conference on Robotics and Automation","20120628","2012","","","1032","1037","In this paper, we present a framework for the integration of force feedback information in a NASA NextGen Volumetric Cockpit Situation Display (CSD). With the current CSD, the user retrieves operational information solely through visual displays and interacts with the CSD tools through using a mouse. The advanced capabilities of the CSD may require complex manipulation of information which may be difficult to perform with input devices found in today's cockpits. Performance with the CSD could benefit from a new user input device and enhanced user feedback modalities that can be operated safely, effectively, and intuitively in a cockpit environment. In this work, we investigate the addition of force feedback in two key CSD tasks: object selection and route manipulation. Different force feedback models were applied to communicate guidance commands, such as collision avoidance and target contact. We also discuss the development of a GUI-based software interface to allow the integration of a haptic device for the CSD. A preliminary user study was conducted on a testbed system using the Novint Falcon force-feedback device. A full experiment, assessing the effectiveness and usability of the feedback model in the CSD, will be performed in the next phase of our research.","1050-4729;10504729","Electronic:978-1-4673-1405-3; POD:978-1-4673-1403-9; USB:978-1-4673-1404-6","10.1109/ICRA.2012.6224842","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6224842","","Aircraft;Atmospheric modeling;Data mining;Force;Force feedback;Software","aerospace computing;aircraft displays;computer displays;force feedback;graphical user interfaces;haptic interfaces;information retrieval;mouse controllers (computers);user interface management systems","CSD;GUI-based software interface development;NASA NextGen volumetric cockpit situation display;National Aeronautics and Space Administration;Novint Falcon force-feedback device;force feedback information;guidance command communication;haptic device integration;haptic feedback;integration framework;mouse;object selection;operational information retrieval;route manipulation;testbed system;user feedback modalities;user input device;visual displays","","1","","18","","","14-18 May 2012","","IEEE","IEEE Conference Publications"
"A comparison of recommender systems for mashup composition","P. Cremonesi; M. Picozzi; M. Matera","DEI- Politecnico di Milano, Italy","2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE)","20120709","2012","","","54","58","Web mashups are a new generation of applications created by composing contents and functions available through Web services and APIs. A central activity in mashup development is the retrieval and selection of components to be included in the composition. The adoption of recommender systems can alleviate some of the difficulties arising in this activity. Based on the results of an empirical study, this paper tries to shed light on the application of recommender systems to the mashup composition domain, and discusses the performance of different recommendation systems when applied to a very large collection of mashups and mashup components.","2327-0934;23270934","Electronic:978-1-4673-1759-7; POD:978-1-4673-1758-0","10.1109/RSSE.2012.6233411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233411","APIs;Recommender systems;Web mashups","Accuracy;Collaboration;Mashups;Matrix decomposition;Measurement;Prediction algorithms;Recommender systems","Web services;application program interfaces;information retrieval;recommender systems","API;Web mashups;Web services;component retrieval;component selection;mashup composition domain;mashup development;recommendation systems;recommender systems","","4","","20","","","4-4 June 2012","","IEEE","IEEE Conference Publications"
"Similarity search plug-in: Clone detection meets internet-scale code search","I. Keivanloo; C. Forbes; J. Rilling","Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada","2012 4th International Workshop on Search-Driven Development: Users, Infrastructure, Tools, and Evaluation (SUITE)","20120628","2012","","","21","22","This paper presents an Eclipse plug-in that provides source code similarity search over source code available on the Internet. We show how our Linked Data repository (SeCold) and scalable clone search approach (SeClone) can provide the enabling technology for an open Internet-scale similarity search service.","","Electronic:978-1-4673-1848-8; POD:978-1-4673-1847-1","10.1109/SUITE.2012.6225474","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6225474","Linked Data;clone detection;source code search","Cloning;Impedance matching;Real time systems;Semantic Web;Software engineering;Time factors","Internet;information retrieval;software engineering","Eclipse plug-in;Internet-scale code search;clone detection;linked data repository;open Internet-scale similarity search service;scalable clone search approach;similarity search plug-in;source code similarity search","","3","","7","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"Creation of Virtual Reality space based on Internet of Things","O. Kodym","Institute of Economics and Control Systems, Faculty of Mining and Geology, V&#x0160;B - Technical University of Ostrava, Czech Republic","Proceedings of the 13th International Carpathian Control Conference (ICCC)","20120702","2012","","","296","299","The speed of information technology development is ever increasing. The appropriate information can be easily provided for and often it can be visually presented. The access to relative information, documents, etc., takes advantage of Hyperlinks, often supported by the Internet of things. The paper deals with a technology that makes data interpretation much easier for the users. It is of no consequence for them, where and in what form the information is stored. The user's access to information does not imply knowledge of a specific program, X, or knowledge that his piece of information is in file, Y. All such knowledge is Hyperlink comprised by unified GUI (Graphic User Interface) with the final goal of VRE (Virtual Reality Environment) interpretation. The Internet of Things implies new possibilities to designing and implementing of distributed and hierarchical information systems.","","Electronic:978-1-4577-1868-7; POD:978-1-4577-1867-0","10.1109/CarpathianCC.2012.6228657","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228657","Database;Internet of Things;Technological Process;Virtual Reality","Imaging;Information systems;Internet;Process control;Servers;Solid modeling;Virtual reality","Internet;distributed processing;document handling;graphical user interfaces;information retrieval;virtual reality","Internet of things-based virtual reality space;VRE interpretation;data interpretation;documents access;graphic user interface;hyperlink knowledge;information technology development;specific program;unified GUI;user information access","","1","","10","","","28-31 May 2012","","IEEE","IEEE Conference Publications"
"Mobile message-aware enhancement using fuzzy lattice reasoning","G. Al-Sultany; M. Li; M. Ponraj; H. Al-Raweshidy","School of Engineering and Design, Brunel University, Uxbridge, UB8 3PH, UK","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1594","1597","Developing service discovery, information retrieval and context-aware to adapt to user everywhere/anytime and attain the ambient intelligence arise the issue of handling misclassification, imperfect reasoning and estimation with respect to the current context. To deal with this issue, we propose the use of Fuzzy set theory with the purpose of inferring and reasoning that adopt fuzzy lattice classifier for decision making. It is applied on top of SOIM framework to increase the accuracy of the classification process with clearer decisions.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234315","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234315","Fuzzy lattice reasoning;Semantic reasoning;Similarity Degree","Cognition;Context;Decision making;Lattices;Mobile communication;Ontologies;Semantics","decision making;fuzzy reasoning;fuzzy set theory;information retrieval;mobile computing;pattern classification","SOIM framework;ambient intelligence;context awareness;decision making;fuzzy inference;fuzzy lattice classifier;fuzzy lattice reasoning;fuzzy set theory;information retrieval;misclassification handling;mobile message-aware enhancement;service discovery","","0","","17","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Communities of Yahoo! Answers and Baidu Zhidao: Complementing or competing?","B. Li; M. R. Lyu; I. King","Chinese Univ. of Hong Kong, Hong Kong, China","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","8","Community Question Answering (CQA) attracts increasing volume of research on question retrieval, high quality content discovery and experts finding. However, few studies are focused on community per se of CQA services and also provide an in-depth analysis of them. This paper aims to enrich our knowledge on two of these CQA services, namely Yahoo! Answers and Baidu Zhidao through reviewing their communities, comparing similarities and differences of the two communities, together with analyzing their influence on solving questions. Six data sets are employed for comparative analysis. In this paper: (1) We analyze the social network structures of Yahoo! Answers and Baidu Zhidao; (2) We compare the the social community characteristics of top contributors; (3) We reveal the behaviors of users in different categories in these two portals; (4) We reveal temporal trends of these characteristics; (5) We find that the community of Yahoo! Answers and Baidu Zhidao complement each other in efficiency and effectiveness of answering questions.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252435","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252435","Baidu Zhidao;Community question answering;Yahoo! Answers;community;comparative analysis","","question answering (information retrieval);social networking (online)","Baidu Zhidao;CQA services;Yahoo! Answers;community question answering;comparative analysis;content discovery;data sets;expert finding;question retrieval;social community characteristics;social network structures;user behavior","","2","","33","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Natural language neural network and its application to question-answering system","T. Sagara; M. Hagiwara","Graduate School of Science and Technology, Keio University, Yokohama, Japan","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","7","This paper proposes a novel neural network to treat natural language. Most of the conventional neural networks can only process sentences consisted of a few words, and their applications are very simple such as metaphor understanding. The proposed network can process many complicated sentences and can be used as an associative memory and a question-answering system. The proposed network is composed of 3 layers and one network: Sentence Layer, Knowledge Layer, Deep Case Layer and Dictionary Network. The input sentences are divided into knowledge units and stored in the Knowledge Layer. The Deep Case Layer play an important role to process the knowledge units properly. The Dictionary Network also plays an important role as a knowledge based. We have carried out several experiments and they have shown that the proposed neural network has superior performances as an associative memory and a question-answering system. Especially as a question-answering system, the performance is very close to the elaborated system based on artificial intelligence.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252553","","Algorithm design and analysis;Dictionaries;Programmable logic arrays;Reliability","content-addressable storage;knowledge based systems;natural language processing;neural nets;question answering (information retrieval)","artificial intelligence;associative memory;deep case layer;dictionary network;knowledge based system;knowledge layer;knowledge units;metaphor understanding;natural language neural network;question-answering system;sentence layer","","1","","29","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"A generalized framework for opening doors and drawers in kitchen environments","T. Rühr; J. Sturm; D. Pangercic; M. Beetz; D. Cremers","Intelligent Autonomous Systems group, Computer Science Department, Technische Universit&#x00E4;t M&#x00FC;nchen, Germany","2012 IEEE International Conference on Robotics and Automation","20120628","2012","","","3852","3858","In this paper, we present a generalized framework for robustly operating previously unknown cabinets in kitchen environments. Our framework consists of the following four components: (1) a module for detecting both Lambertian and non-Lambertian (i.e. specular) handles, (2) a module for opening and closing novel cabinets using impedance control and for learning their kinematic models, (3) a module for storing and retrieving information about these objects in the map, and (4) a module for reliably operating cabinets of which the kinematic model is known. The presented work is the result of a collaboration of three PR2 beta sites. We rigorously evaluated our approach on 29 cabinets in five real kitchens located at our institutions. These kitchens contained 13 drawers, 12 doors, 2 refrigerators and 2 dishwashers. We evaluated the overall performance of detecting the handle of a novel cabinet, operating it and storing its model in a semantic map. We found that our approach was successful in 51.9% of all 104 trials. With this work, we contribute a well-tested building block of open-source software for future robotic service applications.","1050-4729;10504729","Electronic:978-1-4673-1405-3; POD:978-1-4673-1403-9; USB:978-1-4673-1404-6","10.1109/ICRA.2012.6224929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6224929","","Grippers;Kinematics;Robot kinematics;Robot sensing systems;Solid modeling;Trajectory","SLAM (robots);domestic appliances;information retrieval;learning (artificial intelligence);manipulator kinematics;mobile robots;object detection;public domain software;robot vision;service robots","Lambertian handle detection;PR2 beta sites;cabinet closing;door opening;drawer opening;impedance control;information retrieval;information strorage;kinematic models;kitchen environments;mobile manipulation robots;nonLambertian handle detection;open-source software;robotic service applications;semantic map","","23","","19","","","14-18 May 2012","","IEEE","IEEE Conference Publications"
"The Credit Suisse Meta-data Warehouse","C. Jossen; L. Blunschi; M. Mori; D. Kossmann; K. Stockinger","Credit Suisse AG, Zu&#x0308;rich, Switzerland","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","1382","1393","This paper describes the meta-data warehouse of Credit Suisse that is productive since 2009. Like most other large organizations, Credit Suisse has a complex application landscape and several data warehouses in order to meet the information needs of its users. The problem addressed by the meta-data warehouse is to increase the agility and flexibility of the organization with regards to changes such as the development of a new business process, a new business analytics report, or the implementation of a new regulatory requirement. The meta-data warehouse supports these changes by providing services to search for information items in the data warehouses and to extract the lineage of information items. One difficulty in the design of such a meta-data warehouse is that there is no standard or well-known meta-data model that can be used to support such search services. Instead, the meta-data structures need to be flexible themselves and evolve with the changing IT landscape. This paper describes the current data structures and implementation of the Credit Suisse meta-data warehouse and shows how its services help to increase the flexibility of the whole organization. A series of example meta-data structures, use cases, and screenshots are given in order to illustrate the concepts used and the lessons learned based on feedback of real business and IT users within Credit Suisse.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228207","","Data models;Data warehouses;Databases;Organizations;Resource description framework;Standards organizations","data warehouses;feedback;information retrieval;meta data;organisational aspects","Credit Suisse;IT landscape;business analytics;business process;feedback;information item extraction;meta data structure;meta data warehouse;organization agility;organization flexibility","","0","1","17","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"Towards automated education demand-offer information monitoring: The information extraction","P. Rudzajs","Department of Systems Theory and Design, Riga Technical University, Riga, Latvia","2012 Sixth International Conference on Research Challenges in Information Science (RCIS)","20120716","2012","","","1","2","Dynamically changing work environment in knowledge economy causes the changes in knowledge requirements for labor. Therefore it becomes more and more important to be constantly aware of what education is currently demanded and what education is currently offered. The IT solution is vital to process various information sources, extract education information, and provide analysis mechanisms in automated manner. The education information extraction is detailed in this paper in the context of Education demand and offer information monitoring system by providing the workflow for semi-automatic skills extraction from the university course descriptions using developed term suggestion method.","2151-1349;21511349","Electronic:978-1-4577-1938-7; POD:978-1-4577-1936-3; USB:978-1-4577-1937-0","10.1109/RCIS.2012.6240464","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240464","education information;information extraction;monitoring system","Data mining;Dictionaries;Educational institutions;Measurement;Monitoring","computerised monitoring;educational administrative data processing;educational courses;educational institutions;information retrieval","IT solution;automated education demand-offer information monitoring system;education information extraction;information sources;knowledge economy;semiautomatic skills extraction;term suggestion method;university course descriptions","","0","","3","","","16-18 May 2012","","IEEE","IEEE Conference Publications"
"Leveraging clone detection for Internet-scale source code search","I. Keivanloo","Ambient Software Evolution Group (ASEG), Concordia University, Montreal, Canada","2012 20th IEEE International Conference on Program Comprehension (ICPC)","20120716","2012","","","277","280","Different approaches to search for source code on the Internet exist. In this paper, we propose techniques that support a special type of Internet-scale code search using two novel syntactical and semantic clone search and detection methods. The syntactical search focuses on providing a scalable real-time engine, while the semantic clone detection is being used to enrich our knowledge base during the offline processing step.","1092-8138;10928138","Electronic:978-1-4673-1216-5; POD:978-1-4673-1213-4; USB:978-1-4673-1215-8","10.1109/ICPC.2012.6240504","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240504","Semantic Web;clone detection;code search","Cloning;Conferences;Real time systems;Search engines;Semantic Web;Semantics;Software","Internet;information retrieval;knowledge based systems;source coding","Internet-scale source code search;clone detection;knowledge base;real-time engine;semantic clone search-detection method;syntactical clone search-detection method","","0","","23","","","11-13 June 2012","","IEEE","IEEE Conference Publications"
"Search by example in TouchDevelop: Code search made easy","M. Akhin; N. Tillmann; M. Fähndrich; J. de Halleux; M. Moskal","Saint Petersburg State Polytechnical University, Russia","2012 4th International Workshop on Search-Driven Development: Users, Infrastructure, Tools, and Evaluation (SUITE)","20120628","2012","","","5","8","Code search has always been essential to software development; it is the cornerstone of activities such as program comprehension and maintenance. Traditionally, code search required learning of complex query languages with very steep learning curves. In contrast, programming environments for mobile devices targeting novice programmers are becoming popular and code search is becoming increasingly important. Yet, dedicated code query languages present a learning barrier for novice programmers. In this paper we consider “search-by-example” as a way of dealing with this problem. Given a query code snippet, we find all similar snippets in the codebase and present them to the user. This problem is a special instance of the clone detection problem, and, by using relevant techniques, we can perform precise code search with little to no configuration and completely agnostic of code formatting, variable renamings, etc. These properties make “search-by-example” very easy to use by inexperienced programmers. We built a prototype of our approach in TouchDevelop, a novel mobile app development environment for Windows Phone. We will use it as a testing ground for future evaluation.","","Electronic:978-1-4673-1848-8; POD:978-1-4673-1847-1","10.1109/SUITE.2012.6225478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6225478","clone detection;code search;mobile programming;novice developer","Cloning;Programming;Search problems;Software;USA Councils;Vectors;Vegetation","information retrieval;mobile computing;mobile handsets;query languages;software maintenance","TouchDevelop;Windows phone;code formatting;code query languages;code search;complex query languages;learning curves;mobile app development environment;mobile devices;program comprehension;program maintenance;query code snippet;software development","","0","","14","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"Question trunks and focus extraction based on question dependency syntax conversion","Y. Liu; Z. Yu; C. Mao; J. Guo; Y. Xian","The School of Information Engineering and Automation, Kunming University of Science and Technology, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","959","963","For the problems of extracting question trunks and focus extraction completely by conventional dependency syntax parsing, this paper presents a method of question trunks and focus extraction oriented to question dependency syntax conversion with the characteristics of the questions. The method defines a number of combining rules of question dependency relations. According to the rules, we do merger, conversion and removal to parts component of question syntax, and extract the question trunks and focus based on question dependency syntactic structure. The experimental results show that the proposed method of question trunks and focus extraction based on dependency syntax conversion achieved good results.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234230","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234230","Question Dependency Syntax Conversion;Question Dependency Syntax Parsing;Question Focus Extraction;Question Sentences Analysis;Question Trunks Extraction","Accuracy;Buildings;Data mining;Educational institutions;Layout;Speech;Syntactics","grammars;natural language processing;question answering (information retrieval)","Chinese question;dependency syntax parsing;focus extraction;question dependency syntactic structure;question dependency syntax conversion;question trunk extraction","","0","","7","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"AutoDict: Automated Dictionary Discovery","F. Chiang; P. Andritsos; E. Zhu; R. J. Miller","Dept. of Comput. Sci., Univ. of Toronto, Toronto, ON, Canada","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","1277","1280","An attribute dictionary is a set of attributes together with a set of common values of each attribute. Such dictionaries are valuable in understanding unstructured or loosely structured textual descriptions of entity collections, such as product catalogs. Dictionaries provide the supervised data for learning product or entity descriptions. In this demonstration, we will present AutoDict, a system that analyzes input data records, and discovers high quality dictionaries using information theoretic techniques. To the best of our knowledge, AutoDict is the first end-to-end system for building attribute dictionaries. Our demonstration will showcase the different information analysis and extraction features within AutoDict, and highlight the process of generating high quality attribute dictionaries.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228187","","Data mining;Data models;Dictionaries;Frequency measurement;Hidden Markov models;TV;Tagging","cataloguing;dictionaries;information retrieval;text analysis","AutoDict;attribute dictionary;automated dictionary discovery;data record;end-to-end system;entity collection;entity description;high quality dictionaries;information analysis;information extraction;information theoretic technique;learning product;loosely structured textual description;product catalog;unstructured textual description","","2","","11","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"Curriculum design tools: Using information modelling for course transformation and mapping","G. Dafoulas; B. Barn; Y. Zheng","Sch. of Eng. &amp; Inf. Sci., Middlesex Univ., London, UK","2012 International Conference on Information Technology Based Higher Education and Training (ITHET)","20120723","2012","","","1","5","There is a plethora of international courses for applicants to choose from. Recent economic developments have triggered the proliferation of alternative studying modes and educational provision around the globe. There is an increasing focus on course pathways leading to more complex study modes and possibly a combination of academic provision and employer focused professional development. It is evident that such changes are likely to affect the way course information is created, shared and communicated. As the boundaries of higher education are no longer constrained from national boarders more education providers offer international courses. The Bologna process provides the means for attempting alignment of courses with respect to the level of study, learning effort and topics. However being able to match course documentation and provide accurate course profiles still requires the involvement of experienced academics with certain skills in curriculum design and documentation. The Join Information Systems Committee (JISC) has funded for the past few years several projects in the UK, using the XCRI-CAP information mode for modeling course data for advertising purposes. The standardized model deals with exchanging course related information for course advertising profiles (XCRI-CAP). This paper describes the creation of a series of tools assisting curriculum design and development through the semantic interpretation of course data. More specifically the project team achieved the semantic mapping of course documentation elements, making it possible to transform document based curriculum information into XCRI-CAP field data. Subsequently the set of tools provide the visual interpretation of course documentation structure and the ability to compare and contrast curriculum documents. This paper describes the development, use and evaluation of the MUSKET-toolkit, a series of tools used for the transformation of document based curriculum documentation. The JISC funded proje- t produced a series of tools that are used for (i) mapping curriculum document components to field of an XML-based information model, (ii) transforming semi-structured documents used for curriculum design to a format suitable for extracting course related information and (iii) aligning descriptions of different courses based on semantic similarity algorithm. The paper provides a detailed discussion of the key issues associated with the range of curriculum description formats used in the education sector and emphasizes the lack of a consistent standardized approach for retrieving course related information. The benefits of such approaches could be used for `intelligent' searches of curriculum content, analysis of course content, retrieval of specific course description components and alignment of course documentation from different education providers. The scope of the paper is to increase awareness of the possibilities and applications available when course data existing in traditional curriculum documentation can be transformed into an information model that is independent of course management systems, curriculum development processes and course structures.","","Electronic:978-1-4673-2334-5; POD:978-1-4673-2332-1","10.1109/ITHET.2012.6246064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246064","","Documentation;Educational institutions;Industries;Semantics;Standards;Training","XML;educational courses;further education;information retrieval","Bologna process;JISC;Join Information Systems Committee;MUSKET-toolkit;UK;XCRI-CAP information mode;XML-based information model;academic provision;complex study modes;course content analysis;course data modelling;course data semantic interpretation;course description component retrieval;course documentation alignment;course documentation element semantic mapping;course management systems;course mapping;course profiles;course related information extraction;course related information retrieval;course structures;course transformation;curriculum content;curriculum description formats;curriculum design tools;curriculum development process;curriculum document component mapping;document based curriculum documentation transformation;document based curriculum information;employer focused professional development;exchanging course related information for course advertising profiles;higher education;information modelling;intelligent search;international courses;semantic similarity algorithm;semistructured document transformation","","1","","6","","","21-23 June 2012","","IEEE","IEEE Conference Publications"
"A portable multi-channel behavioral state and physiological signal monitoring system","C. P. Young; D. W. Chang; S. F. Liang; F. Z. Shaw","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","2012 IEEE International Instrumentation and Measurement Technology Conference Proceedings","20120702","2012","","","2687","2691","Acquisition of a variety of physiological signals is essential for monitoring and investigation of some specific diseases. Many medical instruments have been well developed and deployed in medical institutes, but many of them are bulky and clumsy for daily recording of subjects' activity. A distributed multi-channel physiological data monitoring system was developed for integrating versatile sensor modules attached in different parts of body. The physiological signals are acquired and processed, and the raw or preprocessed data are then transmitted through wireless communications to a backend server and storage for long-term recording and study. Time synchronization is critical for data fusion and therefore more accurate state discrimination can be achieved. Ubiquitous data access is fundamental, so a smart mobile device in a virtual computing environment will help on this requirement.","1091-5281;10915281","Electronic:978-1-4577-1772-7; POD:978-1-4577-1773-4","10.1109/I2MTC.2012.6229401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6229401","distributed;physiological;synchronization;virtual computing;wireless","Clocks;Data acquisition;Delay;Monitoring;Servers;Sleep;Synchronization","biomedical equipment;body sensor networks;data acquisition;data recording;electro-oculography;electrocardiography;electroencephalography;electromyography;information retrieval;intelligent sensors;medical signal processing;patient monitoring;portable instruments;sensor fusion;synchronisation;wearable computers","ECG;EEG;EMG;EOG;body sensor network;data fusion;data processing;diseases;integrating versatile sensor modules;long-term recording;medical institutes;medical instruments;multichannel physiological data monitoring system;patient monitoring;physiological signal acquisition;physiological signal monitoring system;portable multichannel behavioral state;signal processing;smart mobile device;subject activity recording;synchronization;ubiquitous data access;virtual computing environment;wireless communications","","0","","11","","","13-16 May 2012","","IEEE","IEEE Conference Publications"
"ICT adoption by the Malaysian high courts: Exploring the security risks involved","Z. Hamin; M. B. Othman; A. M. Mohamad","Accounting Research Institute, HiCoE and Faculty of Law Universiti Teknologi MARA, Shah Alam, Selangor, Malaysia","2012 International Conference on Innovation Management and Technology Research","20120712","2012","","","285","289","It is a truism that the information and communication technologies (ICT) have changed the way people engage in all aspects of their lives, including how the judiciary functions. The ICT applications adopted by the courts are varied including access to legal materials, high technology information and evidence display systems, electronic filing, foreign language translation, multimedia court records, information and evidence retrieval, audio conferencing, video conferencing and the public's access to court information via the worldwide web. Drawn from an ongoing research, this paper aims to highlight that the growing adoption of ICT by the courts in many jurisdictions in fact raises several issues of security risks. This paper begins by illustrating the concept of courtroom technology and the current technical applications available in the Malaysian courts. The examination of the emergence of non-legal risks closely connected to security and the legal risk raised by courtroom technology is mediated through the understanding of several basic security control requirements involving authentication, non-repudiation, confidentiality, data integrity and privacy encroachment. The paper contends that despite the common notion that law will always lag behind technology, the courts would need to understand these legal and non-legal security risks and manage them in the most efficient and effective manner if judicial business were to be continually advanced by the ICT.","","Electronic:978-1-4673-0654-6; POD:978-1-4673-0655-3","10.1109/ICIMTR.2012.6236404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6236404","Security risks;courtroom technology;e-Court;e-Justice;information and communication technology","Business;Context;Internet;Law;Privacy;Security","Internet;data privacy;information retrieval;multimedia computing;public administration;risk analysis;security of data;teleconferencing;video communication","ICT adoption;Malaysian high courts;Worldwide Web;audio conferencing;courtroom technology;data integrity;electronic filing;evidence display systems;evidence retrieval;foreign language translation;information and communication technologies;information retrieval;judiciary;legal materials;legal risk;multimedia court records;nonlegal risks;privacy encroachment;security risks;video conferencing","","1","","54","","","21-22 May 2012","","IEEE","IEEE Conference Publications"
"A multi-level hierarchical index structure for supporting efficient similarity search on tag sets","J. L. Koh; N. Shongwe; C. W. Cho","Department of Computer Science and Information Engineering, National Taiwan Normal University, Taipei, Taiwan","2012 Sixth International Conference on Research Challenges in Information Science (RCIS)","20120716","2012","","","1","12","Social communication websites has been an emerging type of a Web service that helps users to share their resources. For providing efficient similarity search of tag set in a social tagging system, we propose a multi-level hierarchical index structure to group similar tag sets. Not only the algorithms of similarity searches of tag sets, but also the algorithms of deletion and updating of tag sets by using the constructed index structure are provided. Furthermore, we define a modified hamming distance function on tag sets, which consider the semantically relatedness when comparing the members for evaluating the similarity of two tag sets. This function is more applicable to evaluate the similarity search of two tag sets. A systematic performance study is performed to verify the effectiveness and the efficiency of the proposed strategies. The experiment results show that the proposed MHIB approach further improves the pruning effect of the previous work which constructs a two-level index structure. Especially, the MHIB approach is well scalable with respect to the three parameters when using either the hamming distance or the modified hamming distance for similarity measure. Although the insertion operation of the MHIB approach requires higher cost than the naïve method, with the assistant of the constructed inverted list of clusters, it performs faster than the previous work. Besides, the cost of performing deletion operation by using the MHIB approach is much less than the other two approaches and so is the update operation.","2151-1349;21511349","Electronic:978-1-4577-1938-7; POD:978-1-4577-1936-3; USB:978-1-4577-1937-0","10.1109/RCIS.2012.6240436","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240436","Social tagging;index structure;similarity search","Hamming distance;Indexing;Search problems;Tagging;Transaction databases;Upper bound","Web services;information retrieval;resource allocation;social networking (online)","MHIB approach;Web service;efficient similarity search;modified hamming distance function;multilevel hierarchical index structure;resource sharing;similar tag set grouping;social communication Web sites;social tagging system;tag sets deletion;two-level index structure","","0","","18","","","16-18 May 2012","","IEEE","IEEE Conference Publications"
"A new framework to design distributed query system","Yangming Zhao; Sheng Wang; Huacheng Cai; Xiong Wang","School of Communication and Information Engineering, University of Electronic Science and Technology of China, Chengdu, China","2011 International Conference on Advanced Intelligence and Awareness Internet (AIAI 2011)","20120709","2011","","","270","274","This paper proposes a new framework to design query systems which could be used in DNS systems. An efficient ILP model, which is able to take network layer information into count, is formulated to design such query systems. By simulation, we demonstrate that query system in our framework can relax unnecessary constraint and trade off between query delay and storage cost.","","Electronic:978-1-84919-471-6","10.1049/cp.2011.1471","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233240","ILP (Integrate Linear Programming);query system design;system availability","","distributed processing;information retrieval systems;linear programming;query processing","DNS systems;ILP model;distributed query system design;domain name server;integrated linear programming;network layer information;query delay;storage cost","","0","","","","","28-30 Oct. 2011","","IET","IET Conference Publications"
"Ingredient matching to determine the nutritional properties of Internet-sourced recipes","M. Müller; M. Harvey; D. Elsweiler; S. Mika","Artificial Intelligence, University of Erlangen-Nuremberg, Germany","2012 6th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops","20120716","2012","","","73","80","To utilise the vast recipe databases on the Internet in intelligent nutritional assistance or recommender systems, it is important to have accurate nutritional data for recipes. Unfortunately, most online recipes have no such data available or have data of suspect quality. In this paper we present a system that automatically calculates the nutritional value of recipes sourced from the Internet. This is a challenging problem for several reasons, including lack of formulaic structure in ingredient descriptions, ingredient synonymy, brand names, and unspecific quantities being assigned. We present a system that exploits linguistic properties of ingredient descriptions and nutritional knowledge modelled as rules to estimate the nutritional content of recipes. We evaluate the system on a large Internet sourced recipe database (23.5k recipes) and examine performance in terms of ability to recognise ingredients and error in nutritional values against values established by human experts. Our results show that our system can match all of the ingredients for 91% of recipes in the collection and generate nutritional values within a 10% error bound from human assessors for calorie, protein and carbohydrate values. We show that the error is less than that between multiple human assessors and also less than the error reported for different standard measures of estimating nutritional intake.","2153-1633;21531633","Electronic:978-1-936968-43-5; POD:978-1-4673-1483-1; USB:978-1-936968-43-5","10.4108/icst.pervasivehealth.2012.248681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240365","Health;Lifestyle;Prevention;Recommender Systems","Chaos;Humans","Internet;humanities;information filtering;information retrieval systems;proteins;recommender systems","brand names;calorie values;carbohydrate values;ingredient descriptions;ingredient matching;ingredient recognition;ingredient synonymy;intelligent nutritional assistance;large Internet sourced recipe database;linguistic properties;nutritional content;nutritional data;nutritional intake estimation;nutritional knowledge;nutritional properties determination;nutritional value;online recipes;protein values;recommender systems","","0","","24","","","21-24 May 2012","","IEEE","IEEE Conference Publications"
"The feasibility research of cloud storage based on Global File System","K. Cheng; N. Wang","College of Computer Science, Chongqing University of Posts and Telecommunications, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","2507","2510","Cloud storage is the extension and development based on the cloud computing, which should not only provide the conventional file access just like POSIX, but also must be able to support the massive data management and the public service support functions. GFS (Global File System) is a solution for massively parallel computing and cloud storage, and its high availability and good scalability can assure the data that it can be more secure and reliable stored and more efficiently scheduled. In this paper we test the GFS environment, and study the file system recovery when node damage happening, and compare the GFS with ext3, NFS system in read and write performance. The experiment result and the practical system performance shows, GFS can provide effective support for the cloud storage, and provide good storage and calculation for cloud computing.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233946","Cloud Storage;File system recovery;GFS;Read and write performance","Cloud computing;Computer architecture;Educational institutions;File systems;Linux;Servers;Storage area networks","cloud computing;information retrieval;parallel processing;reliability;security of data;storage management","GFS environment;cloud storage;feasibility research;file access;file system recovery;global file system;massive data management;massively parallel computing;node damage;public service support functions;read performance;reliable data storage;scalability;secure data storage;write performance","","0","","7","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Requirements gathering for assistive technology that includes low vision and sighted users","S. Ludi; A. Canter; L. Ellis; A. Shrestha","Department of Software Engineering, Department of Computer Science, Rochester Institute of Technology, USA","2012 First International Workshop on Usability and Accessibility Focused Requirements Engineering (UsARE)","20120628","2012","","","25","31","Accessibility often concerns compatibility with third-party software in order to meet the needs of users who are disabled. The AccessLecture project seeks to transform the Apple iPad into a tool to make Math and Science class more accessible to visually impaired students. Accessing lecture material during lecture is a challenge to low vision students, in terms of the limited options that can be costly or can allow access only upon the completion of the lecture. This paper presents the techniques used to help the team gather the needs and tasks of math/science instructors and visually impaired students. The analysis of the environment, user groups and the tasks related to the course lecture were modeled in order to ascertain domain knowledge and to specify the system's requirements.","","Electronic:978-1-4673-1846-4; POD:978-1-4673-1845-7","10.1109/UsARE.2012.6226787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226787","Accessibility;elicitation;visually impaired","Computer science;Educational institutions;Interviews;Materials;Prototypes;Visualization","computer aided instruction;distance learning;handicapped aids;information retrieval;mathematics computing;natural sciences computing;smart phones","AccessLecture project;Apple iPad;assistive technology;course lecture;domain knowledge;lecture completion;lecture material access;math class;math-science instructors;requirements gathering;science class;sighted users;system requirements;third-party software;visually impaired students","","3","","15","","","4-4 June 2012","","IEEE","IEEE Conference Publications"
"CI-Rank: Ranking Keyword Search Results Based on Collective Importance","X. Yu; H. Shi","Sch. of Comput. Sci. & Technol., Shandong Univ. Jinan, Jinan, China","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","78","89","Keyword search over databases, popularized by keyword search in WWW, allows ordinary users to access database information without the knowledge of structured query languages and database schemas. Most of the previous studies in this area use IR-style ranking, which fail to consider the importance of the query answers. In this paper, we propose CI-RANK, a new approach for keyword search in databases, which considers the importance of individual nodes in a query answer and the cohesiveness of the result structure in a balanced way. CI-RANK is built upon a carefully designed model call Random Walk with Message Passing that helps capture the relationships between different nodes in the query answer. We develop a branch and bound algorithm to support the efficient generation of top-k query answers. Indexing methods are also introduced to further speed up the run-time processing of queries. Extensive experiments conducted on two real data sets with a real user query log confirm the effectiveness and efficiency of CI-RANK.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228074","","Algorithm design and analysis;Computational modeling;Databases;Educational institutions;Keyword search;Message passing;Motion pictures","database management systems;indexing;query formulation;question answering (information retrieval);random processes;tree searching","CI-Rank;IR-style ranking;branch-and-bound algorithm;collective importance;database information;database schema;indexing method;keyword search;message passing;random walk;real user query log;structured query language;top-k query answer","","1","","19","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"GUI reverse engineering with machine learning","I. C. Morgado; A. C. R. Paiva; J. P. Faria; R. Camacho","Department of Informatics Engineering, Faculty of Engineering, University of Porto, rua Dr. Roberto Frias, 4200-465 Porto, Portugal","2012 First International Workshop on Realizing AI Synergies in Software Engineering (RAISE)","20120702","2012","","","27","31","This paper proposes a new approach to reduce the effort of building formal models representative of the structure and behaviour of Graphical User Interfaces (GUI). The main goal is to automatically extract the GUI model with a dynamic reverse engineering process, consisting in an exploration phase, that extracts information by interacting with the GUI, and in a model generation phase that, making use of machine learning techniques, uses the extracted information of the first step to generate a state-machine model of the GUI, including guard conditions to remove ambiguity in transitions.","","Electronic:978-1-4673-1753-5; POD:978-1-4673-1752-8","10.1109/RAISE.2012.6227966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227966","Inductive Logic Programming;Machine Learning;Model-Based Testing;Reverse Engineering","Buildings;Data mining;Encoding;Graphical user interfaces;Logic programming;Machine learning;Reverse engineering","finite state machines;graphical user interfaces;inductive logic programming;information retrieval;learning (artificial intelligence);reverse engineering","GUI model;GUI reverse engineering;dynamic reverse engineering process;exploration phase;formal models;graphical user interfaces;inductive logic programming;information extraction;machine learning techniques;model-based testing;state-machine model generation","","2","1","21","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"Extracting design information from natural language specifications","I. G. Harris","Center for Embedded Computer Systems, University of California Irvine","DAC Design Automation Conference 2012","20120719","2012","","","1252","1253","Natural language specifications are the first concrete behavioral description which is the basis for any manually generated formal behavioral model. Natural language is preferred as the initial description method mainly because it is much simpler for a designer to use than existing hardware description languages. The focus of this project is the extraction of behavioral information from a natural language specification to generate a formal behavioral description with clear and unambiguous semantics. In the initial effort presented here, we employ semantic parsing to identify key information describing bus transactions in the natural language specification. The identified information is used to generate Verilog tasks which embody bus transactions. To our knowledge, the work presented here is the first attempt to generate simulatable Verilog from natural language descriptions.","0738-100X;0738100X","Electronic:978-1-4503-1199-1; POD:978-1-4503-1199-1","10.1145/2228360.2228591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6241666","Behavioral Modeling;Natural Language Processing;Synthesis","Data mining;Grammar;Hardware design languages;Integrated circuit modeling;Natural languages;Semantics;Syntactics","grammars;hardware description languages;information retrieval;integrated circuit design;natural language processing","Verilog;behavioral information extraction;bus transactions;design information extraction;formal behavioral description;hardware description languages;natural language descriptions;natural language specifications;semantic parsing","","5","","5","","","3-7 June 2012","","IEEE","IEEE Conference Publications"
"Automated EA-type question generation from annotated texts","L. Bednarik; L. Kovács","University of Miskolc/Department of Information Technology, Hungary","2012 7th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI)","20120730","2012","","","191","195","The field of automated question generation is an active investigated area within the development of e-learning systems. The paper gives first an overview of the main methods and then the architecture of the proposed system is presented in details. The novelty of the proposed application lies in the target language Hungarian and in the application of soft computing methods for generation of semi-synonyms as no free thesaurus is available for the target language. The last part of the paper shows an example process of test generation.","","Electronic:978-1-4673-1014-7; POD:978-1-4673-1013-0; USB:978-1-4673-1012-3","10.1109/SACI.2012.6250000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6250000","","Artificial neural networks;Semantics;Software;Thesauri","Internet;computer aided instruction;information retrieval;natural languages;text analysis","Hungarian language;annotated texts;automated EA-type question generation;e-learning systems;semisynonym generation;soft computing methods;test generation process","","2","","21","","","24-26 May 2012","","IEEE","IEEE Conference Publications"
"Asking the Right Questions in Crowd Data Sourcing","R. Boim; O. Greenshpan; T. Milo; S. Novgorodov; N. Polyzotis; W. C. Tan","","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","1261","1264","Crowd-based data sourcing is a new and powerful data procurement paradigm that engages Web users to collectively contribute information. In this work, we target the problem of gathering data from the crowd in an economical and principled fashion. We present Ask It!, a system that allows interactive data sourcing applications to effectively determine which questions should be directed to which users for reducing the uncertainty about the collected data. Ask It! uses a set of novel algorithms for minimizing the number of probing (questions) required from the different users. We demonstrate the challenge and our solution in the context of a multiple-choice question game played by the ICDE'12 attendees, targeted to gather information on the conference's publications, authors and colleagues.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228183","","Databases;Entropy;Games;Measurement;Optimization;Probes;Uncertainty","Internet;data analysis;question answering (information retrieval)","Ask It!;Web users;crowd-based data sourcing;data procurement paradigm;interactive data sourcing applications;multiple-choice question game","","11","","16","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"Comparing textural features for music genre classification","Y. M. G. Costa; L. S. Oliveira; A. L. Koerich; F. Gouyon","State University of Maring&#x00E1;, Brazil","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","6","In this paper we compare two different textural feature sets for automatic music genre classification. The idea is to convert the audio signal into spectrograms and then extract features from this visual representation. Two textural descriptors are explored in this work: the Gray Level Co-Occurrence Matrix (GLCM) and Local Binary Patterns (LBP). Besides, two different strategies of extracting features are considered: a global approach where the features are extracted from the entire spectrogram image and then classified by a single classifier; a local approach where the spectrogram image is split into several zones which are classified independently and final decision is then obtained by combining all the partial results. The database used in our experiments was the Latin Music Database, which contains music pieces categorized into 10 musical genres, and has been used for MIREX (Music Information Retrieval Evaluation eXchange) competitions. After a comprehensive series of experiments we show that the SVM classifier trained with LBP is able to achieve a recognition rate of 80%. This rate not only outperforms the GLCM by a fair margin but also is slightly better than the results reported in the literature.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252626","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252626","","Databases;Feature extraction;Multiple signal classification;Spectrogram;Support vector machines;Vectors;Visualization","data visualisation;image texture;information retrieval;music;pattern classification;support vector machines","GLCM;LBP;Latin music database;MIREX;SVM classifier;audio signal;automatic music genre classification;gray level cooccurrence matrix;local binary patterns;music information retrieval evaluation exchange;spectrogram image;spectrograms;textural descriptors;textural feature sets;visual representation","","6","","23","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Structural similarity computation based on extended edge matching method","T. Yang; J. Wei; B. Fan; X. Wang; H. Zhang","College of Information Technical Science, Nankai University, Tianjin, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1201","1205","Similarity measurement of hierarchically structured data is crucial in the data mining, database and information retrieval communities. In this paper, we propose an extended edge matching method for better evaluating structural similarity between XML(eXtensible Markup Language) documents. The proposed method not only generates edges between parent nodes and child nodes, but also generates topological edges between ancestor nodes and descendant nodes. Furthermore, complete, topological and repeated matchings are distinguished in the process of edge matching. When one edge matches another, the method can identify the type of matching, and assign proper weight to it. Experiments demonstrated that the proposed method generated better similarity results and clustering results in comparison with some existing methods.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233716","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233716","","Clustering algorithms;Complexity theory;Data mining;Educational institutions;Image edge detection;Pattern matching;XML","XML;data mining;edge detection;information retrieval;pattern clustering;pattern matching;topology","XML documents;child nodes;data mining;database retrieval communities;eXtensible markup language documents;extended edge matching method;information retrieval communities;parent nodes;similarity measurement;structural similarity computation;topological edges generation","","0","","31","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Flash™ applications for learning C programming language","C. T. García; L. D. Gómez; L. C. Cepeda; C. G. Cena; B. A. Hadithi","Dep. of Electronics, Automatics and Industrial Computing, UPM (Polytechnics University of Madrid), Madrid, Spain","2012 Technologies Applied to Electronics Teaching (TAEE)","20120712","2012","","","77","81","This article presents a set of resources for helping to learn and teach the C programming language. This language is used on the subject “Informatica” (computing), in the Degree in Electronics and Automatics Engineering at the Polytechnic University of Madrid. The resources presented are interactive animations, that students can use to analyze, on a dynamic way, the behaviour of common programming structures on the C language. These resources are easily embedded on web pages, so students can access and use these animations through Internet.","","Electronic:978-1-4673-2486-1; POD:978-1-4673-2485-4","10.1109/TAEE.2012.6235411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6235411","C programming language;internet teaching resources","Animation;Computer languages;Flexible printed circuits;Internet;Programming;User interfaces;Web sites","C language;Internet;computer animation;computer science education;courseware;information retrieval;interactive systems","C programming language learning;C programming language teaching;Flash applications;Informatica;Internet;Web pages;interactive animations;programming structures;resource access;resource set","","0","","6","","","13-15 June 2012","","IEEE","IEEE Conference Publications"
"Extracting local information for identifying differentially expressed pathways","H. Q. Wang; Z. Wang; C. H. Zheng","Hefei Institutes of Physical Science, Chinese Academy of Sciences, 230031, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1109","1113","This paper proposes to extract local information in a gene set for identifying differentially expressed (DE) gene pathways. DE pathways are more meaningful than a single DE gene to understanding a biological process, and identifying DE pathways has drawn more and more attentions recently. Current methods are mainly based on the identification of single DE genes, and do not concern correlations between genes. We propose to extract local correlations in a pathway of interest by randomly sampling multiple gene subsets from it and using a logistic regression model to measure how the local correlation pattern in each subset predicts phenotypic labels. The differential expression significance of the pathway is finally assessed by combining the p-values of the subsets predicting phenotypic labels to a combinative one. The proposed method referred to as locLR is evaluated on three simulation data sets and a real-world data, and is shown to be more powerful for identifying DE pathways than the previous methods.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233932","gene expression;logistic regression;pathways;pvalue","Accuracy;Bioinformatics;Data mining;Data models;Gene expression;Sensitivity","biology computing;genetics;information retrieval;random processes;regression analysis","DE pathway;biological process;correlation pattern;differentially expressed pathway identification;gene set analysis;information extraction;logistic regression model;p-values;phenotypic label;random sampling","","0","","25","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Extracting Information from Scientific Papers in the Cloud","P. koda; S. perka; P. Smr","IT4Innovations Centre of Excellence, Brno Univ. of Technol., Brno, Czech Republic","2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems","20120723","2012","","","775","780","This paper deals with a system for extracting information from scientific papers. We analyze drawbacks of an existing implementation running on the N1 Grid Engine. Reasons for moving extraction to the Cloud are presented next. The architecture of the Cloud port is discussed and the links to the API and the platform developed within the mOSCAIC project are elaborated.","","Electronic:978-0-7695-4687-2; POD:978-1-4673-1233-2","10.1109/CISIS.2012.176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6245774","Cloud;N1GE;information extraction;mOSAIC","Computers;Data mining;Databases;Dictionaries;Educational institutions;Engines;Portable document format","application program interfaces;cloud computing;grid computing;information retrieval;scientific information systems;software architecture","API;N1 grid engine;cloud port architecture;information extraction;mOSCAIC project;scientific papers","","0","","","","","4-6 July 2012","","IEEE","IEEE Conference Publications"
"A Semantic Web Browser for Novice Users","Y. Kim; S. Yoo; S. Park","Comput. Sci. Educ., Korea Univ., Seoul, South Korea","2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems","20120723","2012","","","806","809","The Semantic Web is an extension of the Web where information is represented in a machine-process able way. Users can access the information on the Semantic Web using a Web browser such as Explorer or Safari. However, since the information is typically represented in RDF (Resource Description Framework), it is not always easy to understand what the information means. While existing Semantic Web browsers can help users understand the information on the Semantic Web, users need to have some knowledge on RDF and XML which is a base representation format for RDF. In this paper, we propose a simple Semantic Web browser for novice users. Using our system, users can easily access the information on the Semantic Web without technical knowledge on RDF. They can navigate among the set of RDF files freely and the system shows the structure of the corresponding information intuitively using circles and arrows.","","Electronic:978-0-7695-4687-2; POD:978-1-4673-1233-2","10.1109/CISIS.2012.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6245779","Semantic Web;Semantic Web browser","Browsers;Navigation;OWL;Ontologies;Resource description framework","XML;data structures;information retrieval;online front-ends;semantic Web;user interfaces","RDF files;RDF representation;Web extension;XML;base representation format;information access;machine-processable way;novice users;resource description framework;semantic Web browser;technical knowledge","","0","","20","","","4-6 July 2012","","IEEE","IEEE Conference Publications"
"External semantic annotation of web-databases","B. Dönz; D. Bruckner","Institute of Computer Technology, Technical University of Vienna, Austria","2012 IEEE International Symposium on Industrial Electronics","20120712","2012","","","841","845","This paper presents a new solution for making existing web-databases accessible for semantic agents. Instead of adding semantic annotations to a page itself or publishing the content separately, the elements of a web-page are annotated and published in an external file, maybe even on an external site. A semantic agent can use these annotations like an instruction manual to find out how to interpret the page's content and how to access databases such as product catalogues, price lists or technical specifications for components. Since these annotations can be published separately from the actual page, anyone can annotate any website and make it accessible for semantic agents.","2163-5137;21635137","Electronic:978-1-4673-0158-9; POD:978-1-4673-0159-6; USB:978-1-4673-0157-2","10.1109/ISIE.2012.6237198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6237198","","Data mining;Databases;Ontologies;Semantic Web;Semantics;Vocabulary","Internet;database management systems;information retrieval;multi-agent systems;software agents","Web database access;Web page;Web site;external file;instruction manual;page content;semantic agents;semantic annotations","","1","","21","","","28-31 May 2012","","IEEE","IEEE Conference Publications"
"Finding suitable programs: Semantic search with incomplete and lightweight specifications","K. T. Stolee","Department of Computer Science and Engineering, University of Nebraska - Lincoln, Lincoln, NE, USA, 68508","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","1571","1574","Finding suitable code for reuse is a common task for programmers. Two general approaches dominate the code search literature: syntactic and semantic. While queries for syntactic search are easy to compose, the results are often vague or irrelevant. On the other hand, a semantic search may return relevant results, but current techniques require developers to write specifications by hand, are costly as potentially matching code need to be executed to verify congruence with the specifications, or only return exact matches. In this work, we propose an approach for semantic search in which programmers specify lightweight, incomplete specifications and an SMT solver automatically identifies programs from a repository, encoded as constraints, that match the specifications. The repository of programs is automatically encoded offline so the search for matching programs is efficient. The program encodings cover various levels of abstraction to enable partial matches when no or few exact matches exists. We instantiate this approach on a subset of the Yahoo! Pipes mashup language, and plan to extend our techniques to more traditional programming languages as the research progresses.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227034","SMT solvers;code reuse;constraints;program composition;semantic search","Concrete;Encoding;Lattices;Mashups;Semantics;Syntactics","formal specification;information retrieval;programming languages;search engines","SMT solver;Yahoo Pipes mashup language;abstraction level;code search literature;incomplete specifications;lightweight specifications;matching program searching;program encodings;program repository;programming languages;semantic approach;semantic search;suitable code finding;suitable program finding;syntactic approach","","2","","19","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Grid Clustering Algorithm with Simple Leaping Search Technique","C. F. Tsai; J. H. Zhang","Dept. of Manage. Inf. Syst., Nat. Pingtung Univ. of Sci. & Technol., Pingtung, Taiwan","2012 International Symposium on Computer, Consumer and Control","20120702","2012","","","938","941","Data mining is a critical data analysis technique for extracting hidden information from large databases for business or industrial applications. As the size of organizational databases increase, finding information and knowledge efficiently is essential. In the past, numerous clustering algorithms based on grid-clustering schemes have been proposed. This study proposes, simple-leaping search (SLS), a new grid-based clustering algorithm that partitions the space by the number of grids. It then sequentially searches odd columns of all grids according to the minimal point set at each grid. Based on whether the grid is useful or useless, different neighbor grids are searched. Experimental results show that the SLS clustering algorithm performs better than other clustering algorithms such as DBSCAN, IDBSCAN and GOD-CS.","","Electronic:978-0-7695-4655-1; POD:978-1-4673-0767-3","10.1109/IS3C.2012.244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228226","data clustering;data mining;large database","Algorithm design and analysis;Clustering algorithms;Data mining;Noise;Partitioning algorithms;Spatial databases","data mining;database management systems;grid computing;information retrieval;pattern clustering","GOD-CS;IDBSCAN;critical data analysis technique;data mining;grid clustering algorithm;hidden information extraction;simple-leaping search","","1","","8","","","4-6 June 2012","","IEEE","IEEE Conference Publications"
"An optimized features extraction algorithm on VSM","K. Fang; J. Wang","College of Information Science and Technology, Hunan Agricultural University, Changsha, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1471","1473","VSM (Vector Space Model) is one of the important methods for describing documents. However, in the process of information representation, features are always high dimensional. So feature extraction technologies have to be used to reduce dimensions. At present, there are lots of feature extraction algorithms, in which TF-IDF,TF-IDF-IG are used widely in practice. However, as the two didn't consider the influence of text categories and the structure of HTML sufficiently, which greatly affects the accuracy and applicability of the algorithms. To this issue, we proposed an optimized feature extraction algorithm. Meanwhile, we introduced a modifying factor into the novel algorithm to avoid the data imbalance problem which results from magnitude of categories. Through the experiment, the proposed algorithm was compared with the TF-IDF and TF-IDF-IG. We found that the precision and recall of the new algorithm are separately increased more than 10.4% and 13.8% than TF-IDF, and 4.6% and 2.9% than TF-IDF-IG, which shows the novel algorithm has better precision and recall.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233810","TF-IDF;TF-IDF-IG;features extraction","Algorithm design and analysis;Classification algorithms;Educational institutions;Feature extraction;HTML;Information processing;Text categorization","document handling;feature extraction;information retrieval;vectors","TF-IDF algorithm;TF-IDF-IG algorithm;VSM;data imbalance problem avoidance;dimension reduction;documents representation;information representation process;information retrieval;optimized feature extraction algorithm;vector space model","","0","","8","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Optimizing Statistical Information Extraction Programs over Evolving Text","F. Chen; X. Feng; C. Re; M. Wang","HP Labs. China, China","2012 IEEE 28th International Conference on Data Engineering","20120702","2012","","","870","881","Statistical information extraction (IE) programs are increasingly used to build real-world IE systems such as Alibaba, CiteSeer, Kylin, and YAGO. Current statistical IE approaches consider the text corpora underlying the extraction program to be static. However, many real-world text corpora are dynamic (documents are inserted, modified, and removed). As the corpus evolves, and IE programs must be applied repeatedly to consecutive corpus snapshots to keep extracted information up to date. Applying IE from scratch to each snapshot may be inefficient: a pair of consecutive snapshots may change very little, but unaware of this, the program must run again from scratch. In this paper, we present CRFlex, a system that efficiently executes such repeated statistical IE, by recycling previous IE results to enable incremental update. As the first step, CRFlex focuses on statistical IE programs which use a leading statistical model, Conditional Random Fields (CRFs). We show how to model properties of the CRF inference algorithms for incremental update and how to exploit them to correctly recycle previous inference results. Then we show how to efficiently capture and store intermediate results of IE programs for subsequent recycling. We find that there is a tradeoff between the I/O cost spent on reading and writing intermediate results, and CPU cost we can save from recycling those intermediate results. Therefore we present a cost-based solution to determine the most efficient recycling approach for any given CRF-based IE program and an evolving corpus. We conduct extensive experiments with CRF-based IE programs for 3 IE tasks over a real-world data set to demonstrate the utility of our approach.","1063-6382;10636382","Electronic:978-0-7695-4747-3; POD:978-1-4673-0042-1","10.1109/ICDE.2012.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228140","","Context;Data mining;Feature extraction;Labeling;Recycling;Vectors;Viterbi algorithm","information retrieval;input-output programs;statistical analysis;text analysis","CRFlex;I/O cost;IE programs;conditional random fields;evolving text;real-world IE systems;statistical information extraction programs;text corpora","","5","","29","","","1-5 April 2012","","IEEE","IEEE Conference Publications"
"The research of Chinese word segmentation strategy in educational resources search engine based on lucene","Man Yang; Jianwei Li; Xuerong Gou","Institute of Educational Technology, Beijing University of Posts and Telecommunications, 100876, China","2011 International Conference on Advanced Intelligence and Awareness Internet (AIAI 2011)","20120709","2011","","","136","140","With the development of education informatization, educational resources on the network increasingly rich, for an effective retrieval of educational resources, to retrieve more targeted results, by studying the Chinese word segmentation module based on lucene and the existing Chinese word segmentation algorithm for educational resources features, proposed strategy to improve the Chinese word segmentation lay the foundation for the establishment of professional education search engine.","","Electronic:978-1-84919-471-6","10.1049/cp.2011.1443","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233241","Chinese word segmentation;educational resources;lucene;search engine","","information retrieval;natural language processing;search engines;software libraries;word processing","Chinese word segmentation algorithm;Lucene;education informatization;educational resource retrieval;professional education search engine","","0","","","","","28-30 Oct. 2011","","IET","IET Conference Publications"
"Association rule based acquisition of hyponym and hypernym relation from a Turkish corpus","T. Yildiz; S. Yildirim","Computer Science, Istanbul Bilgi University, Istanbul, Turkey","2012 International Symposium on Innovations in Intelligent Systems and Applications","20120723","2012","","","1","5","In this paper, we propose a method for the automatic acquisition of hypernym/hyponymy relations from a Turkish raw text. Once the model has extracted prospective hyponyms by using lexico-syntactic patterns, an Apriori algorithm is applied to eliminate faulty hyponyms and increase precision. We show that a model based on a particular lexico-syntactic pattern and association rules for Turkish language can successfully retrieve many is-a relation with high precision.","","Electronic:978-1-4673-1448-0; POD:978-1-4673-1446-6","10.1109/INISTA.2012.6246944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246944","Apriori algorithm;hypernym/hyponym;lexicon","Association rules;Computational linguistics;Databases;Dictionaries;Reliability;Semantics","data mining;feature extraction;information retrieval;natural language processing;text analysis","Turkish corpus;Turkish language;Turkish raw text;apriori algorithm;association rule based acquisition;automatic hypernym-hyponym relations acquisition;faulty hyponym elimination;hyponym extraction;lexico-syntactic patterns","","1","","39","","","2-4 July 2012","","IEEE","IEEE Conference Publications"
"Towards lyrics spotting in the SyncGlobal project","C. Dittmar; P. Mercado; H. Grossmann; E. Cano","Fraunhofer Institute for Digital Media Technology, Ehrenbergstrasse 31, 98693 Ilmenau, Germany","2012 3rd International Workshop on Cognitive Information Processing (CIP)","20120709","2012","","","1","6","With music markets shifting, the use of music in video productions has become increasingly important. Our novel research project “SyncGlobal“ addresses this global music licensing opportunity. Our goal is to find the best acoustic or semantic matches to any video sequence from large-scale intercultural music catalogs with minimal human effort. One important aspect is the retrieval of music excerpts given a semantic query, where one requirement is the ability to search for certain words or phrases inside songs, that match the theme of the corresponding video production. Consequently, here we present our approach towards spotting of lyrics in music recordings. It is based on statistical analysis of sub-sequence dynamic time warping for a capella singing voice recordings. We present algorithm details accompanied by illustrative examples for this approach.","2327-1671;23271671","Electronic:978-1-4673-1878-5; POD:978-1-4673-1877-8","10.1109/CIP.2012.6232939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6232939","","Conferences;Information processing;Semantics;Speech;Speech processing;Testing;Vectors","information retrieval;music;statistical analysis;video recording","SyncGlobal project;capella singing voice recording;global music licensing;large-scale intercultural music catalog;lyrics spotting;music market;music recordings;music retrieval;semantic query;statistical analysis;subsequence dynamic time warping;video production;video sequence","","2","","14","","","28-30 May 2012","","IEEE","IEEE Conference Publications"
"Decision tree models for developing molecular classifiers for cancer diagnosis","A. Floares; A. Birlutiu","Artificial Intelligence Department, SAIA & OncoPredict & Cancer Institute, Cluj-Napoca, Romania","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","7","The aim of this study is to propose a methodology for developing intelligent systems for cancer diagnosis and evaluate it on bladder cancer. Owing to recent advances in high-throughput experiments, large data repositories are now freely available for use. However, the process of extracting information from these data and transforming it into clinically useful knowledge needs to be improved. Consequently, the research focus is shifting from merely data production towards developing methods to manage and analyze it. In this study, we build classification models that are able to discriminate between normal and cancer samples based on the molecular biomarkers discovered. We focus on transparent and interpretable models for data analysis. We built molecular classifiers using decision tree models in combination with boosting and cross-validation to distinguish between normal and malign samples. The approach is designed to avoid overfitting and overoptimistic results. We perform experimental evaluation on a data set related to the urothelial carcinoma of the bladder. We identify a set of tumor microRNAs biomarkers, which integrated in an ensemble of decision tree classifiers, can discriminate between normal and cancer samples with the best published accuracy.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252781","","Accuracy;Biomarkers;Bladder;Cancer;Decision trees;Robustness;Training","RNA;cancer;classification;decision trees;health care;information needs;information retrieval;medical computing;patient diagnosis","bladder cancer;cancer diagnosis;classification models;data production;decision tree classifiers;decision tree models;high-throughput experiments;information extraction;intelligent systems;knowledge needs;large data repositories;molecular biomarkers;molecular classifiers;tumor microRNAs biomarkers","","3","","27","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Automatic labeling of software requirements clusters","N. Niu; S. Reddivari; A. Mahmoud; T. Bhowmik; S. Xu","Department of Computer Science and Engineering, Mississippi State University, 39762, USA","2012 4th International Workshop on Search-Driven Development: Users, Infrastructure, Tools, and Evaluation (SUITE)","20120628","2012","","","17","20","Clustering is of great practical value in retrieving reusable requirements artifacts from the ever-growing software project repositories. Despite the development of automated cluster labeling techniques in information retrieval, little is understood about automatic labeling of requirements clusters. In this paper, we review the literature on cluster labeling, and conduct an experiment to evaluate how automated methods perform in labeling requirements clusters. The results show that differential labeling outperforms cluster-internal labeling, and that hybrid method does not necessarily lead to the labels best matching human judgment. Our work sheds light on improving automated ways to support search-driven development.","","Electronic:978-1-4673-1848-8; POD:978-1-4673-1847-1","10.1109/SUITE.2012.6225472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6225472","clustering;labeling;requirements;software reuse","Clustering algorithms;Humans;Labeling;Manuals;Software;Web search","information retrieval;pattern clustering;software engineering;software reusability","automated cluster labeling techniques;automatic labeling;differential labeling;information retrieval;software project repositories;software requirements clusters","","4","","29","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"A family of adaptive penalty schemes for steady-state genetic algorithms","A. C. C. Lemonge; H. J. C. Barbosa; H. S. Bernardino","Univ. Federal de Juiz de Fora, Campus Universit&#x00E1;rio, MG, Brazil, CEP 36036-330","2012 IEEE Congress on Evolutionary Computation","20120802","2012","","","1","8","Real world engineering optimization problems are often subject to constraints which are complex implicit functions of the design variables. Frequently, such constrained problems are replaced by unconstrained ones by means of penalty functions. A family of adaptive penalty schemes for steady-state genetic algorithms is proposed here. For each constraint, a penalty parameter is adaptively computed along the run according to information extracted from the current population, such as the existence of feasible individuals and the level of violation of each constraint. The performance of each variant in the family is examined using test problems from the evolutionary computation as well as mechanical and structural optimization literature.","1089-778X;1089778X","Electronic:978-1-4673-1509-8; POD:978-1-4673-1510-4","10.1109/CEC.2012.6256173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6256173","","Benchmark testing;Electronic mail;Evolutionary computation;Genetic algorithms;Optimization;Shafts;Steady-state","genetic algorithms;information retrieval","adaptive penalty scheme;design variables;evolutionary computation;information extraction;mechanical optimization;penalty parameter;real world engineering optimization problem;steady-state genetic algorithm;structural optimization literature","","0","","24","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"A practical scheme for resource and knowledge discovery in reproductive design education","M. Imai; Y. Moritoh; Y. Imai","Department of Management Information, Kagawa Junior College, 1-10 Utazu-cho, Ayautagun, 769-0201 Japan","2012 International Conference on Information Technology Based Higher Education and Training (ITHET)","20120723","2012","","","1","6","Design education is one of the most creative topics and themes in Higher Educations and Trainings. Students of the design education course also need to learn both of knowledge and techniques, the former is necessary to design some objects and the latter are essential to utilize tools as well as equipments. It is important to provide not only knowledge but also techniques in efficient and effective ways. One of the most attractive approaches to design in Ecological and/or Recycling methods is to utilize and discover reproductive tools and resources. It is a good way to create some reproductive objects. Especially, some furnitures are worth enough to be reused and reproduced in the above ways. This paper focuses how to utilized recycling resources and useful knowledge for design education. And it also presents a practical scheme to utilize Resources, Knowledge and Techniques for Design Education in order to retrieve and discover in the network environment. The paper challenges to visualize practical scheme for design process by means of comparison between usual steps in the normal design education and special steps using Internet and network community. And it summaries to be important for design education to visualize scheme for resources and knowledge discovery through network environment.","","Electronic:978-1-4673-2334-5; POD:978-1-4673-2332-1","10.1109/ITHET.2012.6246074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246074","Ecological and Recycling methods for Design;Utilization of Network Community for Retrieving and Discovering;Visualization of Design Education","Communities;Education;Knowledge engineering;Materials;Proposals;Recycling;Social network services","data mining;data visualisation;design engineering;ecology;educational courses;further education;information retrieval;recycling;resource allocation","data visualisation;design education course;ecological method;higher education;knowledge discovery;knowledge retrieval;network environment;recycled resource utilisaion;recycling method;recycling methods;reproductive design education;resource discovery","","0","","8","","","21-23 June 2012","","IEEE","IEEE Conference Publications"
"Analysis on IOT communication protocol","Z. Liu; B. Xi; Y. Yuan","School of Management, Harbin Institute of Technology, Harbin, Heilongjiang Province, China","2012 IEEE International Conference on Information and Automation","20120723","2012","","","126","130","The IOT technology has developed rapidly and applied in almost every field in recent years. However, there are still many problems remaining during the development, especially lacking of unified communication protocol and relative technology standards. This paper presents a procedure of universal IOT communication, which describes UID registration, cancellation procedure, UID search procedure and UID information search procedure in details. Relative factors for setting up unified standard are analyzed from data status and data timeliness perspectives. The paper can provide a reference for the establishment of IOT communication protocol standards.","","Electronic:978-1-4673-2237-9; POD:978-1-4673-2238-6","10.1109/ICInfA.2012.6246795","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246795","Communication Protocol;IOT;Standard","IEEE Xplore;Portable document format","Internet;data analysis;information retrieval;protocols;telecommunication standards","IOT;UID information search procedure;UID registration;communication protocol standard;data analysis;data timeliness;technology standard","","0","","9","","","6-8 June 2012","","IEEE","IEEE Conference Publications"
"StreamCars: A new flexible architecture for driver assistance systems","A. Bolles; H. J. Appelrath; D. Geesen; M. Grawunder; M. Hannibal; J. Jacobi; F. Köster; D. Nicklas","OFFIS - Institut f&#x00FC;r Informatik","2012 IEEE Intelligent Vehicles Symposium","20120705","2012","","","252","257","One of the main challenges in the development of traffic systems is to assure safety for all road users. Hence, especially expensive vehicles are equipped with advanced driver assistance systems (ADAS) that use data about the vehicle and information about objects in the proximity of the vehicle to execute the assistance function. These objects have to be detected by sensors and they have to be tracked over multiple scans to keep the object's state up-to-date. Usually, such ADAS are developed as proprietary systems that are tailored for the specific assistance function and the specific sensors in use. Indeed, that leads to a very efficient system. However, changing system properties, e. g. an exchange of sensors, is very expensive. In this case, very often at least some parts of the system code have to be reimplemented. To solve this problem of bad maintainability which arises especially during the development of new assistance functions in this work a new architecture for ADAS is presented. The relevant information for the assistance function is no longer provided by hard coded, predefined processes, but by flexible continuous operator plans in a datastream management system. These operator plans build up a dynamic context model of the vehicle's environment. The context model is kept up-to-date by object tracking operators in these operator plans and is then used as a data source to extract information for different assistance functions. This extraction is also done by operator plans that produce only relevant information and discard other information.","1931-0587;19310587","Electronic:978-1-4673-2118-1; POD:978-1-4673-2119-8","10.1109/IVS.2012.6232125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6232125","","Context;Context modeling;Data models;Data processing;Mathematical model;Sensors;Vehicles","driver information systems;information retrieval;object tracking;road safety","ADAS;StreamCars;advanced driver assistance systems;datastream management system;different assistance functions;dynamic context model;flexible architecture;information extraction;object tracking operators;road user safety;system code;traffic systems;vehicle environment","","5","","18","","","3-7 June 2012","","IEEE","IEEE Conference Publications"
"Automatic extraction of non-textual information in web document and their classification","M. Zachariasova; R. Hudec; M. Benco; P. Kamencay","Deparment of Telecommunications and Multimedia, University of Zilina, Slovakia","2012 35th International Conference on Telecommunications and Signal Processing (TSP)","20120802","2012","","","753","757","This paper deals with research in the area of automatic extraction of textual and non-textual information and their classification. The main idea is to create a robust method for extraction of image and textual segments to obtain short web document. Thus, developed method consist of two data types extractions, where both image and text data extraction are using Document Object Model tree. Extracted objects are saved in separate databases followed the images analysis that define and describe image object from semantic point of view. Moreover, the semantic description of all modal objects are utilized to short web document creation. To accurate object classification, the fast and powerful hybrid segmentation algorithm based on Mean Shift and Believe Propagation principles are mentioned in this paper, too. Likewise, the image segmentation algorithm was integrated with SIFT descriptor. Finally, in order to obtain a semantic description of objects in static image, the SVM classification is used. The developed method was tested on real unsegmented and segmented images, too.","","Electronic:978-1-4673-1118-2; POD:978-1-4673-1117-5","10.1109/TSP.2012.6256398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6256398","DOM;SIFT descriptor;SVM classification;extraction images;segmentation","Algorithm design and analysis;Data mining;Image segmentation;Semantics;Support vector machines;Testing;Training","feature extraction;image classification;image retrieval;image segmentation;information retrieval;support vector machines;text analysis;text detection;trees (mathematics)","SIFT descriptor;SVM classification;Web document;automatic nontextual information extraction;automatic textual information extraction;believe propagation principles;databases;document object model tree;hybrid segmentation algorithm;image extraction;image segmentation algorithm;images analysis;information classification;mean shift principles;object classification;object semantic description;segmented images;static image;text data extraction;textual segment extraction;unsegmented images","","1","","21","","","3-4 July 2012","","IEEE","IEEE Conference Publications"
"Forensics investigation challenges in cloud computing environments","M. Damshenas; A. Dehghantanha; R. Mahmoud; S. bin Shamsuddin","Faculty of Computer Science and Information Technology, University Putra Malaysia, Malaysia","Proceedings Title: 2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec)","20120723","2012","","","190","194","Cloud computing discusses about sharing any imaginable entity such as process units, storage devices or software. The provided service is utterly economical and expandable. Cloud computing attractive benefits entice huge interest of both business owners and cyber thefts. Consequently, the “computer forensic investigation” step into the play to find evidences against criminals. As a result of the new technology and methods used in cloud computing, the forensic investigation techniques face different types of issues while inspecting the case. The most profound challenges are difficulties to deal with different rulings obliged on variety of data saved in different locations, limited access to obtain evidences from cloud and even the issue of seizing the physical evidence for the sake of integrity validation or evidence presentation. This paper suggests a simple yet very useful solution to conquer the aforementioned issues in forensic investigation of cloud systems. Utilizing TPM in hypervisor, implementing multi-factor authentication and updating the cloud service provider policy to provide persistent storage devices are some of the recommended solutions. Utilizing the proposed solutions, the cloud service will be compatible to the current digital forensic investigation practices; alongside it brings the great advantage of being investigable and consequently the trust of the client.","","Electronic:978-1-4673-1426-8; POD:978-1-4673-1425-1","10.1109/CyberSec.2012.6246092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246092","cloud computing;forensic challenges;forensics investigation;security;virtualization","Cloud computing;Computational modeling;Computers;Digital forensics;IEEE Xplore;Media","Web services;cloud computing;computer forensics;information retrieval;trusted computing","TPM;business owner;cloud computing;cloud service provider policy;computer forensic investigation;cyber theft;data access;digital forensic investigation;entity sharing;hypervisor;multifactor authentication;trusted computing","","12","","","","","26-28 June 2012","","IEEE","IEEE Conference Publications"
"Search result clustering for Thai Twitter based on Suffix Tree Clustering","S. Thaiprayoon; A. Kongthon; P. Palingoon; C. Haruechaiyasak","Speech and Audio Technology Laboratory (SPT), National Electronics and Computer Technology Center (NECTEC), Thailand Science Park, Klong Luang, Pathumthani 12120, Thailand","2012 9th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology","20120802","2012","","","1","4","Today Twitter has become a popular online medium for posting and sharing news and events. Generally, many Twitter posts or “tweets” refer to the same topics or events. Searching on Twitter could return a long list of search results. To solve the problem, we propose an approach for clustering the Twitter search results based on the Suffix Tree Clustering (STC) algorithm. However, two main drawbacks of original STC are some of the returned cluster labels are unmeaningful and it is unable to create hierarchical structure. In this paper, we present a new approach called Suffix Tree Clustering with Label Merging (STC-LM). The key idea of the STC-LM is to merge partially overlapped cluster labels and then create two-level label structure. We performed experiments by using Thai Twitter posts from 12 topics such as flooding, traffic and entertainment. The performance based on the F1 measure is equal to 70%, an improvement of 9% from the baseline method.","","Electronic:978-1-4673-2025-2; POD:978-1-4673-2026-9","10.1109/ECTICon.2012.6254293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6254293","Suffix tree clustering;Thai Twitter;search result clustering","Clustering algorithms;Filtering;Floods;Merging;Organizations;Search problems;Twitter","information retrieval;pattern clustering;social networking (online);trees (mathematics)","F1 measure;STC algorithm;STC-LM;Thai Twitter;Twitter posts;baseline method;cluster labels;hierarchical structure;search result clustering;suffix tree clustering with label merging;tweets;two-level label structure","","1","","20","","","16-18 May 2012","","IEEE","IEEE Conference Publications"
"Integrating awareness in user oriented route recommendation system","B. Chakraborty","Faculty of Software and Information Science, Iwate Prefectural University, Takizawamura, 020-0193, JAPAN","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","5","Development of recommendation systems are now gaining importance in variety of fields ranging from multimedia content on web sites to travel guides or online product buying to help and guide users in finding out relevant information from the vast pool of information generated everyday. The research in the area of information retrieval, data mining, marketing or e-commerce shows that integration of contextual information into recommendation system would further improve the efficiency and capability of recommendation system for individual users. In this work the conceptual framework of an user oriented pedestrian navigation system with the capability of integrating context awareness in route recommendation is proposed. A very small pilot study is undertaken to measure the effectiveness of the recommendation system with incorporation of context awareness.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252543","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252543","","Biological cells;Conferences;Context;Context-aware services;Mobile communication;Navigation;Roads","Web sites;data mining;electronic commerce;information retrieval;recommender systems;traffic information systems;ubiquitous computing","Web sites;context awareness;data mining;e-commerce;information retrieval;marketing;multimedia content;product buying;travel guides;user oriented pedestrian navigation system;user oriented route recommendation system","","1","","20","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Generating transcriptions for romanized Thai persons' names","A. Suchato; C. Kittikool; P. Punyabukkana","Spoken Language Systems Research Group, Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, 10330, Thailand","2012 9th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology","20120802","2012","","","1","4","A transcription of each word can either be produced by rules, statistical models, or retrieved from dictionary. However, the lack of standards and the variation of how a Thai person romanizes his or her name pose transcription a challenging task. Although the dictionary-based approach seems to produce the most accurate result, a letter-to-sound conversion module is necessary for unknown names. We propose an approach to transcribe romanized Thai person names into Thai sounds which considers the popularity of usage. The romanized Thai names are parsed into sequences of grams, utilizing the Gram lexicon, built from a corpus of more than 130,000 names. The results show 90 and 93% mean opinion score of acceptability when the transcriptions are generated from all possible sequences with unweighted and weighted Thai grams respectively. When longest-match model is used, the acceptability levels are 70 and 75% for unweighted and weighted Thai grams.","","Electronic:978-1-4673-2025-2; POD:978-1-4673-2026-9","10.1109/ECTICon.2012.6254338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6254338","Romanization;Thai names;Transcription","Accuracy;Audio systems;Computers;Educational institutions;Equations;Mathematical model;Training","dictionaries;information retrieval;natural language processing;speech synthesis;statistical analysis","Thai sounds;dictionary-based approach;gram lexicon;gram sequences;letter-to-sound conversion module;mean opinion score;name pose transcription;romanized Thai persons names;statistical models;text-to-speech system;transcription generation;unweighted Thai grams;weighted Thai grams","","0","","8","","","16-18 May 2012","","IEEE","IEEE Conference Publications"
"Analyzing user click paths in a Wikipedia navigation game","D. Helic","Knowledge Management Institute, Graz University of Technology, Austria","2012 Proceedings of the 35th International Convention MIPRO","20120716","2012","","","374","379","Due to the enormous success of Web search technology navigation became only a second-class information seeking strategy on the Web. However, numerous studies highlight the importance of navigation as an alternative information retrieval technique to search. These studies provide evidences that the most efficient information finding occurs in the settings where search and navigation seamlessly integrate and complement each other. Recently, the research community has also recognized the importance of understanding the human navigation behavior since the knowledge on how users navigate helps in designing optimal navigation structures. In this paper we try to gain more insight in how users navigate towards a known target page in Wikipedia. To that end, we conduct an initial analysis of user click paths from a Wikipedia navigation game. In addition, we compare the structure of Wikipedia navigational paths with the structure of search paths in social networks and routing paths in general complex networks.","","DVD:978-953-233-072-4; Electronic:978-953-233-068-7; POD:978-1-4673-2577-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240673","","Electronic publishing;Encyclopedias;Games;Humans;Internet;Navigation","Internet;Web sites;computer games;information retrieval","Web search technology navigation;Wikipedia navigation game;complex networks;human navigation behavior;information retrieval technique;optimal navigation structures;search paths;second class information seeking strategy;social networks;user click path analysis","","0","","34","","","21-25 May 2012","","IEEE","IEEE Conference Publications"
"Intelligent Interface Architectures for Folksonomy Driven Structure Network","M. D. Mas","","2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems","20120723","2012","","","519","525","The folksonomy is the result of free personal information or assignment of tags to an object (determined by the URI) in order to find them. The practice of tagging is done in a collective environment. Folksonomies are self constructed, based on co-occurrence of definitions, rather than a hierarchical structure of the data. The downside of this was that a few sites and applications are able to successfully exploit the sharing of bookmarks. The need for tools that are able to resolve the ambiguity of the definitions is becoming urgent as the need of simple instruments for their visualization, editing and exploitation in web applications still hinders their diffusion and wide adoption. An intelligent interactive interface design for folksonomies should consider the contextual design and inquiry based on a concurrent interaction for a perceptual user interfaces. To represent folksonomies a new concept structure called "" Folksodriven"" is used in this paper. While it is presented the Folks driven Structure Network (FSN) to resolve the ambiguity of definitions of folksonomy tags suggestions for the user. On this base a Human-Computer Interactive (HCI) systems is developed for the visualization, navigation, updating and maintenance of folksonomies Knowledge Bases - the FSN - through the web. System functionalities as well as its internal architecture will be introduced.","","Electronic:978-0-7695-4687-2; POD:978-1-4673-1233-2","10.1109/CISIS.2012.158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6245653","Folksonomy;Human Computer Interactive systems (HCI);Information Architecture;Interface design;Network;Ontology;Semantic Web","Information architecture;Labeling;Maintenance engineering;Marine vehicles;Navigation;Ontologies;Visualization","data visualisation;groupware;human computer interaction;information retrieval;interactive systems;semantic Web;user interfaces","Folksodriven Structure Network;Folksodriven structure;HCI system;URI;Web application;bookmark sharing;collaborative environment;collective environment;concurrent interaction;contextual design;definition ambiguity;definition cooccurrence;editing;folksonomy driven structure network;folksonomy knowledge base;folksonomy tags;free personal information;human-computer interactive system;inquiry;intelligent interactive interface design;intelligent interface architecture;knowledge base maintenance;knowledge base navigation;knowledge base update;knowledge base visualization;perceptual user interface;semantic Web;tag assignment","","1","","24","","","4-6 July 2012","","IEEE","IEEE Conference Publications"
"Extract summarization using Concept-Obtained and Hybrid Parallel Genetic Algorithm","M. Wang; X. Tang","Department of Computer Engineering, GuangXi University of Technology, LiuZhou, china","2012 8th International Conference on Natural Computation","20120709","2012","","","662","664","This paper proposes a special Chinese automatic summarization method based on Concept-Obtained and Hybrid Parallel Genetic Algorithm. The idea of our approach is to obtain concepts of words using HowNet as tool, and use concepts as feature, not words. We construct conceptual vector space model and use Hybrid Parallel Genetic Algorithm to form summary of documents. The automatic evaluation of document's summaries with n-gram score shows the system's effectiveness and feasibility.","2157-9555;21579555","Electronic:978-1-4577-2133-5; POD:978-1-4577-2130-4","10.1109/ICNC.2012.6234637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234637","Concept-Obtained;Hybrid Parallel Genetic Algorithm;Summarization","Biological cells;Clustering algorithms;Educational institutions;Encoding;Genetic algorithms;Internet;Vectors","Internet;genetic algorithms;information retrieval;natural languages;parallel algorithms;text analysis","Chinese automatic summarization method;HowNet;Internet;automatic document summary evaluation;concept-obtained genetic algorithm;conceptual vector space model;extract summarization;hybrid parallel genetic algorithm;n-gram score;text documents","","1","","6","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Context-based recommendation to support problem solving in software development","J. Cordeiro; B. Antunes; P. Gomes","Centre for Informatics and Systems of the University of Coimbra, Portugal","2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE)","20120709","2012","","","85","89","During the software development process, developers are often faced with problem solving situations. For instance, it is common the occurrence of exceptions, that originate stack traces in the Console View of the IDE. These situations motivate the developer to use the Web to search for information. However, there is a gap between the IDE and the Web, requiring developers to spend significant time searching for relevant information and navigating through web pages in a Web browser. We propose to process the information of exception stack traces and retrieve question-answering web resources to help developers. We developed a tool that integrates recommendation of question/answer web resources in Eclipse, according to the context of these exception stack traces. The results of a preliminary experimentation are promising, showing that our approach performs better than a simple keyword-based approach.","2327-0934;23270934","Electronic:978-1-4673-1759-7; POD:978-1-4673-1758-0","10.1109/RSSE.2012.6233418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233418","Context Modelling;Problem Solving;Recommendation Systems;Software Development","Context;Data mining;Problem-solving;Programming;Search engines;Servers;Software","Web sites;online front-ends;question answering (information retrieval);recommender systems;software development management","Console View;Eclipse;IDE;Web browser;Web pages;context-based recommendation;exception occurrence;exception stack traces;information searching;keyword-based approach;problem solving;question-answering Web resources retrieval;software development process","","15","","8","","","4-4 June 2012","","IEEE","IEEE Conference Publications"
"Harnessing Stack Overflow for the IDE","A. Bacchelli; L. Ponzanelli; M. Lanza","REVEAL @ Faculty of Informatics - University of Lugano, Switzerland","2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE)","20120709","2012","","","26","30","Developers often consult online tutorials and message boards to find solutions to their programming issues. Among the many online resources, Question & Answer websites are gaining popularity. This is no wonder if we consider a case like Stack Overflow, where more than 92% questions on expert topics are answered in a median time of 11 minutes. This new resource has scarcely been acknowledged by any Integrated Development Environment (IDE): Even though developers spend a large part of their working time in IDEs, and the usage of Q&A services has dramatically increased, developers can only use such resources using external applications. We introduce Seahawk, an Eclipse plugin to integrate Stack Overflow crowd knowledge in the IDE. It allows developers to seamlessly access Stack Overflow data, thus obtaining answers without switching the context. We present our preliminary work on Seahawk: It allows users to (1) retrieve Q&A from Stack Overflow, (2) link relevant discussions to any source code in Eclipse, and (3) attach explanative comments to the links.","2327-0934;23270934","Electronic:978-1-4673-1759-7; POD:978-1-4673-1758-0","10.1109/RSSE.2012.6233404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233404","Q&A websites;Seahawk;Stack Overflow","Context;Databases;Engines;Joining processes;Knowledge engineering;Programming;Software engineering","Web sites;question answering (information retrieval);software development management;storage management","Eclipse plugin;IDE;Seahawk;integrated development environment;message boards;online resources;online tutorial;question & answer Web site;stack overflow crowd knowledge","","15","","17","","","4-4 June 2012","","IEEE","IEEE Conference Publications"
"Impact of cyberspace on human rights and democracy","V. Fanchiotti; J. P. Pierini","Faculty of Law, University of Genova, Italy","2012 4th International Conference on Cyber Conflict (CYCON 2012)","20120719","2012","","","1","12","This paper focuses on the asserted `boundlessness' of cyberspace in order to examine how and to what extent jurisdiction, in its various meaning and forms (jurisdiction to prescribe, to adjudicate and to execute), over activities taking place in the cyberspace may be asserted and even exercised, based on traditional jurisdictional links and also on new trends. The paper also examines conflicts of law in civilian (mainly tort laws and laws on the protection of rights of the personality as well as intellectual property) and criminal matters. Determining what set of rules applies to a certain fact or situation implies a reference to those rules establishing where such a fact or situation has legally taken place and is to be localised (locus commissi delicti), and a reference to main criteria including those focusing on the conduct, the localisation of the hardware, the effect, the access to the informatics system, the accessibility of the information and future trends. The paper further highlights that the enforcement of activities in cyberspace appears to be affected by an assimilation to traditional forms of investigative activities, such as search or inspection or even the interception of communication or data flow, which are to a certain degree misleading in respect of the specific means employed. A specific reference to the role of providers in enforcement activities is also included. The second part of the paper deals with the traditional human rights relevant to cyberspace and to the broader concept of `right to access' cyberspace, as well as the uncertainties derived from the fact that a plurality of state and non-state actors may limit and interfere with human rights in cyberspace. The paper specifically deals with the commercial dimension of cyberspace and with eventual corporate liability for human rights violation (multinational corporations violating rights to privacy in connection with or on behalf of states or enforcing censorship) based on US legisla- ion and also taking into consideration European trends. The paper finally highlights the supportive role to the protection of human rights of regulatory bodies enforcing fair-trade and anti-trust regulations, and the multinational dimension of free trade in promoting human rights, by eventually considering restrictions in cyberspace and censorship as restrictions to trade under WTO agreements.","2325-5366;23255366","Electronic:978-9949-9040-9-9; POD:978-1-4673-1270-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6243965","WTO;antitrust;censorship;conduct;effects;enforcement;fair-trade;jurisdiction","Computer crime;Computers;Cyberspace;Internet;Law;Servers","computer network security;criminal law;digital rights management;information retrieval;legislation;uncertainty handling","US legislation;WTO agreement;antitrust regulation;civilian law;criminal matter;cyberspace;democracy;enforcement activity;eventual corporate liability;hardware localisation;human right protection;human right violation;informatics system;information accessibility;jurisdiction;jurisdictional link;uncertainty handling","","0","","23","","","5-8 June 2012","","IEEE","IEEE Conference Publications"
"Efficient knowledge representation in intelligent human-robot co-operation","A. R. Várkonyi-Kóczy; B. Tusor","Institute of Mechatronics and Vehicle Engineering, &#x00D3;buda University, Budapest, Hungary","2012 IEEE 16th International Conference on Intelligent Engineering Systems (INES)","20120730","2012","","","25","30","With the spreading of intelligent machines, manmachine co-operation has become an important research area. Today, intelligent robots collaborating with humans usually have to be able to store, retrieve, and update information about their environment, interpret and execute commands, offer existing and gain/learn new services. In these processes, the efficient knowledge representation and storage are of key importance. In this paper, a new graph based knowledge storage and representation form is introduced which distinguishes between theoretical knowledge and linkage-possibilities among virtual tools and their real-word embodiments. The proposed modular structure makes easy to store, retrieve, modify, and extend theoretical and practical knowledge, to interpret commands and to associate them with physical means and actions, to adapt to changes, learn and build in new knowledge. These aspects are especially important when the robots are involved in human-robot communication, as well.","1543-9259;15439259","Electronic:978-1-4673-2695-7; POD:978-1-4673-2694-0; USB:978-1-4673-2693-3","10.1109/INES.2012.6249844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249844","","Abstracts;Dictionaries;Humans;Knowledge based systems;Knowledge representation;Robots","control engineering computing;graph theory;human-robot interaction;information retrieval;information storage;intelligent robots;knowledge representation","command interpretation;graph based knowledge;human-robot cooperation;information retrieval;information storage;information update;intelligent machine;intelligent robot;knowledge representation;knowledge storage;man-machine cooperation;real-word embodiment","","0","","12","","","13-15 June 2012","","IEEE","IEEE Conference Publications"
"Keyword extraction using backpropagation neural networks and rule extraction","A. Azcarraga; M. D. Liu; R. Setiono","College of Computer Studies, De La Salle University, 2401 Taft Avenue, Manila 1004. Philippines","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","7","Keyword extraction is vital for Knowledge Management System, Information Retrieval System, and Digital Libraries as well as for general browsing of the web. Keywords are often the basis of document processing methods such as clustering and retrieval since processing all the words in the document can be slow. Common models for automating the process of keyword extraction are usually done by using several statistics-based methods such as Bayesian, K-Nearest Neighbor, and Expectation-Maximization. These models are limited by word-related features that can be used since adding more features will make the models more complex and difficult to comprehend. In this research, a Neural Network, specifically a backpropagation network, will be used in generalizing the relationship of the title and the content of articles in the archive by following word features other than TF-IDF, such as position of word in the sentence, paragraph, or in the entire document, and formats such as heading, and other attributes defined beforehand. In order to explain how the backpropagation network works, a rule extraction method will be used to extract symbolic data from the resulting backpropagation network. The rules extracted can then be transformed into decision trees performing almost as accurate as the network plus the benefit of being in an easily comprehensible format.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252618","Backpropagation;document analysis;keyword extraction;rule extraction","Abstracts;Accuracy;Backpropagation;Data mining;Feature extraction;Neural networks;Training","backpropagation;digital libraries;document handling;feature extraction;information retrieval;knowledge management;neural nets;statistical analysis","TF-IDF;Web browsing;backpropagation network;backpropagation networks;decision trees;digital libraries;document processing methods;information retrieval system;keyword extraction;knowledge management system;neural network;process automation;rule extraction method;statistics-based methods;symbolic data extraction;word-related features","","3","","15","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Selection of Sporting Goods with Vague Set","J. Tao; S. Yang","Dept. of Phys. Educ., Zhengzhou Normal Univ., Zhengzhou, China","2012 Sixth International Conference on Internet Computing for Science and Engineering","20120716","2012","","","167","170","As a sunrise industry, sporting goods industry is rapid growth in E-commerce. Information overload become an important issue in this situation. Recommendation system is a good way to solve this problem. In order to find a recommendation strategy for sporting goods in E-commerce, Vague Sets, Gaussian function and characteristics of uncertainty were used to represent sporting goods features with Vague value in this paper. On this basis, the general steps of recommendation strategy with Vague Sets were given, in order to get a new idea and method to decision-maker. Finally, recommender formula is given, which will be conducive to the work of the actual recommendation strategy.","2330-9857;23309857","Electronic:978-0-7695-4705-3; POD:978-1-4673-1683-5","10.1109/ICICSE.2012.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239742","Recommendation strategy;Similarity;Sporting Goods;Vague Sets","Adaptive filters;Companies;Industries;Packaging;Recommender systems;Uncertainty","Gaussian processes;consumer behaviour;decision making;electronic commerce;fuzzy set theory;information retrieval;recommender systems;sports equipment;sportswear","Gaussian function;customer preference;decision making;e-commerce;fuzzy sets;information overload;marketing;recommendation strategy;recommendation system;recommender formula;sporting goods feature;sporting goods industry;sporting goods selection;sunrise industry;uncertainty characteristics;vague set;vague value","","0","","15","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
"Research of the conceptual representing of documents based on light ontology","H. Wang; Y. Guo; J. Li; X. Shi","School of information, Xi'an University of Finance and Economics, 710100, Shaanxi, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1646","1649","The traditional method of presenting a document in an Information Retrieval(IR) system is based on terms. As the the new words appear dramatically in the Internet era, this kind of method draws back the IR system's performance. This paper puts forward an approach by using the concepts of the ontology to present the documents. Constructing the Word-Concept(W-C) model and Concept-Document(C-D) model, we compute the relevance of word-word , word-concept and concept-document. They are used to determine which page is most relevant to the query. It is proofed to be more effective than prevenient.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234292","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234292","","Computational modeling;Educational institutions;Indexing;Ontologies;Resource description framework;Semantics;Symmetric matrices","Internet;document handling;information retrieval systems;ontologies (artificial intelligence)","C-D model;Internet;W-C model;concept-document relevance;conceptual document represention;information retrieval system;light ontology;word-concept model;word-concept relevance;word-word relevance","","0","","10","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Two-person interaction detection using body-pose features and multiple instance learning","K. Yun; J. Honorio; D. Chattopadhyay; T. L. Berg; D. Samaras","Stony Brook University, Stony Brook, NY 11794, USA","2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","20120716","2012","","","28","35","Human activity recognition has potential to impact a wide range of applications from surveillance to human computer interfaces to content based video retrieval. Recently, the rapid development of inexpensive depth sensors (e.g. Microsoft Kinect) provides adequate accuracy for real-time full-body human tracking for activity recognition applications. In this paper, we create a complex human activity dataset depicting two person interactions, including synchronized video, depth and motion capture data. Moreover, we use our dataset to evaluate various features typically used for indexing and retrieval of motion capture data, in the context of real-time detection of interaction activities via Support Vector Machines (SVMs). Experimentally, we find that the geometric relational features based on distance between all pairs of joints outperforms other feature choices. For whole sequence classification, we also explore techniques related to Multiple Instance Learning (MIL) in which the sequence is represented by a bag of body-pose features. We find that the MIL based classifier outperforms SVMs when the sequences extend temporally around the interaction of interest.","2160-7508;21607508","Electronic:978-1-4673-1612-5; POD:978-1-4673-1611-8; USB:978-1-4673-1610-1","10.1109/CVPRW.2012.6239234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239234","","Feature extraction;Humans;Joints;Real time systems;Sensors;Tracking","feature extraction;image classification;image motion analysis;image sensors;image sequences;information retrieval;learning (artificial intelligence);object tracking;pose estimation;support vector machines;synchronisation;video signal processing;video surveillance","MIL based classifier;SVM;body-pose features;complex human activity dataset;content based video retrieval;depth capture data;geometric relational features;human activity recognition;human computer interfaces;inexpensive depth sensors;motion capture data indexing;motion capture data retrieval;multiple instance learning;real-time full-body human tracking;real-time interaction activity detection;sequence classification;sequence representation;support vector machines;two-person interaction detection;video surveillance;video synchronization","","33","","37","","","16-21 June 2012","","IEEE","IEEE Conference Publications"
"A SVM-based Image Classification Method in Document System of Personnel Archives","J. Chen; L. Han; Z. Xiong; N. Sun; G. Gao; Q. Li","Sch. of Comput. & Inf. Sci., Southwest Univ., Chongqing, China","2012 Sixth International Conference on Internet Computing for Science and Engineering","20120716","2012","","","131","134","Information technology has deeply penetrated into the personnel archives management to improve its security, privacy and high efficiency. This paper comes up with a method to solve problems about image classification. It combines SVM with Huffman tree to construct a classifier HFM-SVM. Constructing HFM-SVM, it extracts paragraph and local pixel features of archive document images as training samples and test data and can classify all of personnel archive documents into five classes such as ID cards, application forms and labor contracts and so on. Comparing with multiple classifiers, the experimental results show that HFM-SVM does better in automatically fast and accurate classification of personnel archive document images.","2330-9857;23309857","Electronic:978-0-7695-4705-3; POD:978-1-4673-1683-5","10.1109/ICICSE.2012.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239734","Huffman tree;Local pixel feature;Paragraph feature;Personnel Archives;Support vector machine","Binary trees;Classification algorithms;Feature extraction;Image classification;Personnel;Support vector machines;Training","Huffman codes;data privacy;document image processing;feature extraction;image classification;information retrieval systems;security of data;support vector machines","HFM-SVM construction;Huffman tree;SVM-based image classification;archive document images;classifier construction;information technology;local pixel feature extraction;paragraph extraction;personnel archive document classification;personnel archive management;privacy improvement;security improvement;support vector machine;test data;training samples","","0","","8","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
