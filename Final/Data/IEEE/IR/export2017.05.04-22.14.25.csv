"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7129446,7129177,7129546,7129796,7129560,7124655,7103313,7123716,7120655,7119533,7120646,7120501,7120585,7120691,7118407,7119036,6994780,7116857,6940294,7042773,7106438,7113093,7113351,7113374,7113087,7111779,7113184,7113373,7113286,7113391,7111264,6951432,7021960,7113293,7111660,7006338,7112009,6905790,7107603,7105568,7106930,7107430,7106169,7107611,7106971,7105597,7107527,7106369,6847139,7102611,7064777,6945905,7100428,7100511,7100235,7100351,7099135,7100247,7096238,7098002,7097474,7096153,7095851,7097877,7096024,7095854,7097991,7095369,7094388,7092993,7092967,7091212,7092805,7091297,7083905,7084866,7087122,7087030,7087107,7087015,7083906,7087325,7076613,7063924,7064067,7081544,7081997,7081568,7082016,7064243,7081545,7081855,7081542,7079359,7077272,7079762,7079950,7079614,7079294,7077528",2017/05/04 22:14:25
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Discrimination of melodic patterns in indian classical music","K. K. Ganguli; P. Rao","Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai 400076, India","2015 Twenty First National Conference on Communications (NCC)","20150416","2015","","","1","6","The melodic phrases of a raga are an important cue to its identity. Artists, however, incorporate considerable creative variation within a raga phrase during performance while still preserving its identity in the ears of the listeners. It is of interest therefore to explore the boundaries of this categorization of phrase identity, given the space of musical variations in the tonal interval and duration dimensions. Such an endeavor can help better model musical similarity for music retrieval and pedagogy applications. In this work, we carry out melodic shape manipulations on a selected prominent phrase of raga Deshkar to study the subjective responses of musicians in comparison with non-musicians in terms of perceived discrimination of the controlled variations. A method is presented for deriving musically consistent synthetic stimuli for listening. Subjective responses on the discrimination and identification tasks are presented along with a discussion on possible perceptual mechanisms at play.","","Electronic:978-1-4799-6619-6; POD:978-1-4799-6620-2","10.1109/NCC.2015.7084866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7084866","","Ear;Harmonic analysis;Shape;Speech;Standards;Timbre","feature selection;information retrieval;music;pattern classification","Indian classical music;melodic pattern discrimination;music retrieval;musically consistent synthetic stimuli;phrase selection;raga Deshkar","","0","","17","","","Feb. 27 2015-March 1 2015","","IEEE","IEEE Conference Publications"
"Search Results Clustering Algorithm Based on the Suffix Tree","D. Wang; L. Liu; J. Dong; J. Zheng","Sch. of Math. & Comput. Sci., Ningxia Univ., Yinchuan, China","2015 2nd International Conference on Information Science and Control Engineering","20150611","2015","","","456","460","The STC algorithm clusters the documents based on shared phrases and it is a linear time algorithm. Directed against the insufficiency of the existing STC algorithm such as the quality of clustering results and the screening of the clustering labels, the paper improves STC algorithm, respectively perfecting the choice of the base cluster, the similarity calculation formula used to merge the base clusters and the scoring function for the clustering labels. Finally entropy is taken as the evaluation criterion for the clustering results. Compared with the original algorithm there are a better effect which is attested by experiments and more readability, descriptive and distinguishable clustering labels.","","Electronic:978-1-4673-6850-6; POD:978-1-4673-6851-3","10.1109/ICISCE.2015.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120646","clustering algorithm;document clustering;search result clustering;suffix tree","Algorithm design and analysis;Bismuth;Clustering algorithms;Data mining;Entropy;Mathematical model;Search engines","computational complexity;document handling;information retrieval;pattern clustering;trees (mathematics)","STC algorithm;base cluster merging;clustering labels;descriptive clustering labels;distinguishable clustering labels;entropy;linear time algorithm;scoring function;search result clustering algorithm;shared phrases;similarity calculation formula;suffix tree","","0","","12","","","24-26 April 2015","","IEEE","IEEE Conference Publications"
"Developing a community-based worldwide urban morphology and materials database (WUDAPT) using remote sensing and crowdsourcing for improved urban climate modelling","L. See; C. Perger; M. Duerauer; S. Fritz; B. Bechtel; J. Ching; P. Alexander; G. Mills; M. Foley; M. O'Connor; I. Stewart; J. Feddema; V. Masson","International Institute for Applied Systems Analysis, Laxenburg, Austria","2015 Joint Urban Remote Sensing Event (JURSE)","20150611","2015","","","1","4","This paper outlines the WUDAPT (World Urban Database and Access Portal Tools) concept and highlights progress to date in developing this database for cities around the world. The next steps in the WUDAPT project are outlined, both in the immediate and longer term. Ultimately the goal is to provide an open access resource on urban morphology, materials and metabolism for all major cities that can be used for many different applications, in particular for climate and weather modelling, and urban climate change studies.","2334-0932;23340932","Electronic:978-1-4799-6652-3; POD:978-1-4799-6653-0","10.1109/JURSE.2015.7120501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120501","","Buildings;Cities and towns;Data collection;Databases;Meteorology;Remote sensing;Urban areas","Web sites;atmospheric temperature;climatology;data acquisition;geophysics computing;information retrieval;meteorology;online front-ends;portals;remote sensing;thermal pollution","WUDAPT concept outline;WUDAPT project development;WUDAPT project progress;World Urban Database and Access Portal Tool;community-based urban materials database;community-based urban morphology;crowdsourcing;open access resource application;remote sensing;urban climate change studies;urban climate modelling;urban materials database development;urban materials database progress;urban materials open access resource;urban metabolism open access resource;urban morphology open access resource;urban weather modelling;wordlwide urban materials database;worldwide urban morphology","","2","","19","","","March 30 2015-April 1 2015","","IEEE","IEEE Conference Publications"
"Exploring Stock Market Using Twitter Trust Network","Y. Ruan; L. Alfantoukh; A. Durresi","Indiana Univ. Purdue Univ. at Indianapolis, Indianapolis, IN, USA","2015 IEEE 29th International Conference on Advanced Information Networking and Applications","20150430","2015","","","428","433","As social networks are becoming more and more popular, more and more data are available from them. Researchers are now trying to extract useful information from these big data. One possible usage of social media is to investigate stock market. There are two major events to measure in stock market - price change and trade volume. In this paper, we firstly use our trust framework to build up trust network among Twitter users in a stock market group. We compare trust information extracted from Twitter group with Dow Jones Industrial Average (DJIA) get from Yahoo! Finance. Our results show that by taking trust information into account, they are more correlated than just counting the number of tweets. Also it shows us that trade volume is stronger correlated than price change.","1550-445X;1550445X","Electronic:978-1-4799-7905-9; POD:978-1-4799-7906-6","10.1109/AINA.2015.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7098002","","Correlation;Fluctuations;Mathematical model;Mood;Sentiment analysis;Stock markets;Twitter","Big Data;information retrieval;social networking (online);stock markets","Dow Jones Industrial Average;Twitter trust network;Yahoo!Finance;big data;price change;social networks;stock market group;trade volume;trust information extraction","","0","","20","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Distributed Randomized PageRank Algorithm Based on Stochastic Approximation","J. Lei; H. F. Chen","Key Lab. of Syst. & Control, Acad. of Math. & Syst. Sci., Beijing, China","IEEE Transactions on Automatic Control","20150521","2015","60","6","1641","1646","A distributed randomized PageRank algorithm based on stochastic approximation (SA) is proposed to estimate the importance scores of web pages. Compared with the existing methods, the algorithm given here has wider applications in the sense that it can deal with a larger class of randomizations. The strong consistency of the estimates is proved, and the robustness of the PageRank value is analyzed as well. Numerical examples are given to verify the obtained theoretic results.","0018-9286;00189286","","10.1109/TAC.2014.2359311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6905790","Distributed randomized PageRank algorithm;stochastic approximation;strong consistency","Convergence;Damping;Random variables;Robustness;Tin;Vectors;Web pages","approximation theory;distributed algorithms;information retrieval;randomised algorithms","SA;Web pages;distributed randomized PageRank algorithm;importance scores;stochastic approximation","","0","","19","","20140919","June 2015","","IEEE","IEEE Journals & Magazines"
"Combining Relevance Language Modeling and Clarity Measure for Extractive Speech Summarization","S. H. Liu; K. Y. Chen; B. Chen; H. M. Wang; H. C. Yen; W. L. Hsu","Graduate Institute of Electrical Engineering, National Taiwan University, Taipei, Taiwan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150410","2015","23","6","957","969","Extractive speech summarization, which purports to select an indicative set of sentences from a spoken document so as to succinctly represent the most important aspects of the document, has garnered much research over the years. In this paper, we cast extractive speech summarization as an ad-hoc information retrieval (IR) problem and investigate various language modeling (LM) methods for important sentence selection. The main contributions of this paper are four-fold. First, we explore a novel sentence modeling paradigm built on top of the notion of relevance, where the relationship between a candidate summary sentence and a spoken document to be summarized is discovered through different granularities of context for relevance modeling. Second, not only lexical but also topical cues inherent in the spoken document are exploited for sentence modeling. Third, we propose a novel clarity measure for use in important sentence selection, which can help quantify the thematic specificity of each individual sentence that is deemed to be a crucial indicator orthogonal to the relevance measure provided by the LM-based methods. Fourth, in an attempt to lessen summarization performance degradation caused by imperfect speech recognition, we investigate making use of different levels of index features for LM-based sentence modeling, including words, subword-level units, and their combination. Experiments on broadcast news summarization seem to demonstrate the performance merits of our methods when compared to several existing well-developed and/or state-of-the-art methods.","2329-9290;23299290","","10.1109/TASLP.2015.2414820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063924","Clarity measure;KL divergence;language modeling;relevance modeling;speech summarization","Context modeling;IEEE transactions;Semantics;Speech;Speech processing;Speech recognition;Vectors","feature selection;information retrieval;natural language processing;speech processing;text analysis","IR;LM;clarity measure;extractive speech summarization;information retrieval;relevance language modelling;sentence selection","","4","","55","","20150319","June 2015","","IEEE","IEEE Journals & Magazines"
"Combination of phone N-grams for a MPEG-7-based spoken document retrieval system","N. Moreau; Hyoung-Gook Kim; T. Sikora","Department of Communication Systems, Technical University of Berlin, Einsteinufer 17, D-10587, Germany (Europe)","2004 12th European Signal Processing Conference","20150406","2004","","","549","552","In this paper, we present a phone-based approach of spoken document retrieval (SDR), developed in the framework of the emerging MPEG-7 standard. The audio part of MPEG-7 aims at standardizing the indexing of audio documents. It encloses a SpokenContent tool that provides a description framework of the semantic content of speech signals. In the context of MPEG-7, we propose an indexing and retrieval method that uses phonetic information only and a vector space IR model. Different strategies based on the use of phone N-gram indexing terms are experimented.","","POD:978-320-0001-65-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079762","","Abstracts;Films;Indexing;Lattices;Transform coding","information retrieval;speech processing","MPEG-7-based spoken document retrieval system;SpokenContent tool;audio documents;phone N-gram indexing terms;phone N-grams combination;phonetic information;semantic content;space IR model;speech signals","","0","","10","","","6-10 Sept. 2004","","IEEE","IEEE Conference Publications"
"Combining Syntactic Information with HMM for Term Extraction","H. S. Pan; J. Y. Zhao","Tongfang Knowledge Network Technol. (Beijing) Co. Ltd., Beijing, China","2015 2nd International Conference on Information Science and Control Engineering","20150611","2015","","","170","173","Aiming at the problem of Chinese thesaurus construction, we propose a method of using HMM to extract new terms from academic literature to expand automatically entry-words for Chinese thesaurus. This method converts the new terms extraction problem to a sequence labelling problem. It uses HMM fully integrated lexical information and syntactic information of new terms, as well as local context information, to learn automatically from the artificial corpus and obtain new terms extraction model. When new terms were extracted, Iturbi algorithm is used to extract automatically new terms from texts. Then this method receives these new terms as candidate entry-words. Eventually, we add content features filter conditions and frequency filter conditions for further selection. Experiment results show that the method has a good performance on terms extraction, and plays an important supporting role on expanding automatically entry-words for thesaurus.","","Electronic:978-1-4673-6850-6; POD:978-1-4673-6851-3","10.1109/ICISCE.2015.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120585","HMM;Viterbi;syntactic analysis;term extraction","Accuracy;Context;Data mining;Feature extraction;Hidden Markov models;Syntactics;Thesauri","hidden Markov models;information retrieval;natural language processing;text analysis;thesauri","Chinese thesaurus construction;HMM fully integrated lexical information;Viterbi algorithm;artificial corpus;automatic entry-words;candidate entry-words;content features filter conditions;frequency filter conditions;hidden Markov models;local context information;sequence labelling problem;syntactic information;term extraction model;term extraction problem","","0","","7","","","24-26 April 2015","","IEEE","IEEE Conference Publications"
"PSP-Auto: A DHT-based data storage and retrieval system for automation","J. Skodzik; P. Danielis; V. Altmann; E. Bjoern Schweissguth; D. Timmermann","University of Rostock, Institute of Applied Microelectronics and Computer Engineering, 18051, Germany","2015 Annual IEEE Systems Conference (SysCon) Proceedings","20150604","2015","","","853","858","In the field of automation, reliability is a key aspect to enable resilient systems. Especially, in areas with extreme conditions a reliable monitoring is necessary such as factory, volcano, or laboratory monitoring. These are environments where devices could be stressed uncommonly high and thus more devices could fail in a shorter time period in the worst case. Centralized monitoring systems, which work in real-time for security reasons, contain a single point of failure in the form of a central control instance. Additionally, if the central instance fails no data is available any more as the central instance usually works as the only data sink in the system. Furthermore, with an increasing number of devices this system does not scale well. As the number of devices and their performance will prospectively increase, a new approach is necessary to handle these large-scale systems. Therefore, in this paper a Peer-to-Peer-based data storage and retrieval system for scenarios with real-time requirements called PSP-Auto is presented, which bases on the Peer-to-Peer network Kad. A prototype has been developed to derive performance results for a large-scale simulation of the PSP-Auto system. The results show a high resilience whereby data recovery can still be ensured at 100 % even if each device fails up to eight times a day.","","Electronic:978-1-4799-5927-3; POD:978-1-4799-5928-0; USB:978-1-4799-5926-6","10.1109/SYSCON.2015.7116857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116857","","Automation;Monitoring;Peer-to-peer computing;Performance evaluation;Prototypes;Real-time systems;Reliability","information retrieval;peer-to-peer computing","DHT;PSP-Auto;automation;centralized monitoring system;data retrieval system;data storage;large-scale system;peer-to-peer network Kad","","0","","21","","","13-16 April 2015","","IEEE","IEEE Conference Publications"
"An Extension to Jab Ref for Extraction and Processing of Scholarly Articles","S. Amjad; H. Mukhtar; M. Malik","Nat. Univ. of Sci. & Technol., Islamabad, Pakistan","2014 12th International Conference on Frontiers of Information Technology","20150608","2014","","","245","250","Effective management of bibliographic information and citations of relevant work in an appropriate manner is considered as an integral part of all scholarly articles. To ease the process of literature management and to facilitate researchers, several reference managers have been developed offering different features. Almost all reference managers support extraction of metadata from articles but unfortunately very few provide facility of extraction of full-text from articles, their sub sections search and parsing of citations. Being a researcher, management of references is one of the most complicated aspects. Thus to smooth the progress of researchers, scholarly articles organizer is introduced in this paper as an extension of already developed open source reference manager Jab Ref. The proposed extension of Jab Ref basically performs the management, organization and processing of academic papers. And it has the special features of content reading, metadata extraction, citation parsing, relevant Bib TeX entry fetching and linking of In-Cite and Out-Cite information. Keeping in view the fact that scholarly objects basically represent research output in the form of metadata, parsed contents and citations. Accompanying Bib TeX entries with scholarly objects is really important because it can be easily handled by the end-users and can be read automatically by many repositories and several other tools. Thus the key inspiration behind the designing of the proposed add-on is to enhance the functionality of Jab Ref by reducing the complexities involve in handling academic literature and simplifying the process.","","Electronic:978-1-4799-7505-1; POD:978-1-4799-7506-8","10.1109/FIT.2014.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118407","BibTeX;Citation Parsing;Information Extraction;Reference Management","Data mining;Databases;Feature extraction;Joining processes;Libraries;Open source software;Portable document format","bibliographic systems;citation analysis;information retrieval;meta data;public domain software","Jab Ref;bibliographic information extraction;citation management;metadata extraction;open source reference manager","","0","","20","","","17-19 Dec. 2014","","IEEE","IEEE Conference Publications"
"The Database Platform Design of Collection and Citation","W. Xiaodan; Tian; Yongmei; L. Sun; G. Yu","Libr. of Harbin Inst. of Technol., Harbin Inst. of Technol., Harbin, China","2015 2nd International Conference on Information Science and Control Engineering","20150611","2015","","","497","499","Through the analysis of the Collection and Citation of Scientific and Technological Dissertations of Harbin Institute of Technology Library, The retrieval server currently included in the phenomenon of low efficiency and repetitive work, so the Database Platform of the Collection and Citation was designed. The database platform will save the HIT expert information of collection and citation, which based on the Web of Science and EI search systems. When the experts need to submit the certification report, it directly retrieves the information of database platform. In order to improve the work efficiency, reduce duplication of work.","","Electronic:978-1-4673-6850-6; POD:978-1-4673-6851-3","10.1109/ICISCE.2015.115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120655","citation;collectiont;database platform;database retrieving","Certification;Data processing;Electronic mail;Indexes;Libraries;Standards","citation analysis;database management systems;information retrieval","EI search systems;Scientific and Technological Dissertations of Harbin Institute of Technology Library;Web of Science;citation;database platform design;retrieval server","","0","","4","","","24-26 April 2015","","IEEE","IEEE Conference Publications"
"Indexing and matching trajectories under inconsistent sampling rates","S. Ranu; Deepak P; A. D. Telang; P. Deshpande; S. Raghavan","Dept. of CSE, IIT Madras, Chennai, India","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","999","1010","Quantifying the similarity between two trajectories is a fundamental operation in analysis of spatio-temporal databases. While a number of distance functions exist, the recent shift in the dynamics of the trajectory generation procedure violates one of their core assumptions; a consistent and uniform sampling rate. In this paper, we formulate a robust distance function called Edit Distance with Projections (EDwP) to match trajectories under inconsistent and variable sampling rates through dynamic interpolation. This is achieved by deploying the idea of projections that goes beyond matching only the sampled points while aligning trajectories. To enable efficient trajectory retrievals using EDwP, we design an index structure called TrajTree. TrajTree derives its pruning power by employing the unique combination of bounding boxes with Lipschitz embedding. Extensive experiments on real trajectory databases demonstrate EDwP to be up to 5 times more accurate than the state-of-the-art distance functions. Additionally, TrajTree increases the efficiency of trajectory retrievals by up to an order of magnitude over existing techniques.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113351","","Indexing;Interpolation;Measurement;Robustness;Trajectory","database management systems;indexing;information retrieval;interpolation","EDwP;consistent sampling rate;distance functions;dynamic interpolation;edit distance with projections;inconsistent sampling rates;indexing trajectories;matching trajectories;real trajectory databases;spatio temporal databases;trajectory generation procedure;uniform sampling rate","","5","","22","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Ensemble methods for opinion mining","A. Onan; S. Korukoğlu","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Celal Bayar &#x00DC;niversitesi, Manisa, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","212","215","Opinion mining is an emerging field which uses computer science methods to extract subjective information, such as opinion, emotion, and attitude inherent in opinion holder's text. One of the major issues in opinion mining is to enhance the predictive performance of classification algorithm. Ensemble methods used for opinion mining aim to obtain robust classification models by combining decisions obtained by multiple classifier training, rather than depending on a single classifier. In this study, the comparative performance of opinion mining datasets on Bagging, Dagging, Random Subspace and Adaboost ensemble methods with five different classifiers and six different data representation schemes are presented. The experimental results indicate that ensemble methods can be used for building efficient opinion mining classification methods.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7129796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129796","ensemble methods;opinion mining;sentiment analysis","Bagging;Classification algorithms;Computational modeling;Computer science;Data mining;Sentiment analysis;Support vector machines","data mining;data structures;information retrieval;learning (artificial intelligence);pattern classification;text analysis","Adaboost ensemble method;bagging;classification algorithm predictive performance;dagging;data representation scheme;ensemble method;multiple classifier training;opinion holder text;opinion mining classification method;random subspace;robust classification model;subjective information extraction","","1","","17","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Adaptive Post Recognition","P. Berger; P. Hennig; D. Petrick; M. Pursche; C. Meinel","Hasso-Plattner-Institute University of Potsdam, Germany","2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)","20150423","2014","","","1","8","Blogs, news portal and discussion forums are of high interest for today's social interaction research. But the automatic information extraction from the raw html page of those media channels is still a well-known problem. We introduce a novel approach to infer website templates based on the syndication format of blogs and news portals, called feeds. In comparison to related approaches that infer templates by clustering generic pages, we do not rely on a manual annotated training set. Instead, we use the feeds and their linked articles as training set to identify characteristic XPaths. Those paths identify the exact article content and article properties like title, author and publishing date. Further, we can use those paths to detect article pages that are no longer linked from feeds. We show the precision gain by comparing the article content extraction with an alternative approach e.g. boilerplate.","","Electronic:978-1-4799-5877-1; POD:978-1-4799-5878-8; USB:978-1-4799-5876-4","10.1109/ASONAM.2014.7092993","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092993","","Blogs;Containers;Data mining;Feeds;HTML;Web pages;XML","Web sites;hypermedia markup languages;information retrieval;pattern clustering;portals","Website template;adaptive post recognition;article page detection;automatic information extraction;blogs;characteristic XPath identification;discussion forum;feeds;generic page clustering;media channels;news portal;raw HTML page;social interaction research;syndication format;training set","","0","","16","","","17-20 Aug. 2014","","IEEE","IEEE Conference Publications"
"Multimedia Analysis and Access of Ancient Maya Epigraphy: Tools to support scholars on Maya hieroglyphics","R. Hu; G. Can; C. Pallan Gayol; G. Krempel; J. Spotak; G. Vail; S. Marchand-Maillet; J. M. Odobez; D. Gatica-Perez","Idiap Res. Inst., Martigny, Switzerland","IEEE Signal Processing Magazine","20150615","2015","32","4","75","84","This article presents an integrated framework for multimedia access and analysis of ancient Maya epigraphic resources, which is developed as an interdisciplinary effort involving epigraphers (someone who deciphers ancient inscriptions) and computer scientists. Our work includes several contributions: a definition of consistent conventions to generate high-quality representations of Maya hieroglyphs from the three most valuable ancient codices, which currently reside in European museums and institutions; a digital repository system for glyph annotation and management; as well as automatic glyph retrieval and classification methods. We study the combination of statistical Maya language models and shape representation within a hieroglyph retrieval system, the impact of applying language models extracted from different hieroglyphic resources on various data types, and the effect of shape representation choices for glyph classification. A novel Maya hieroglyph data set is given, which can be used for shape analysis benchmarks, and also to study the ancient Maya writing system.","1053-5888;10535888","","10.1109/MSP.2015.2411291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123716","","Art;Computational modeling;Context awareness;Histograms;Multimedia communication;Visualization","computational linguistics;history;information retrieval;multimedia systems;museums;natural language processing;pattern classification","European institution;European museums;Maya hieroglyphics;ancient Maya epigraphic resources;ancient Maya writing system;automatic glyph classification method;automatic glyph retrieval method;data type;digital repository system;epigraphers;glyph annotation;hieroglyph retrieval system;hieroglyphic resource;multimedia access;multimedia analysis;shape analysis benchmarks;shape representation;statistical Maya language model;valuable ancient codices","","2","","27","","","July 2015","","IEEE","IEEE Journals & Magazines"
"Relational User Attribute Inference in Social Media","Q. Fang; J. Sang; C. Xu; M. S. Hossain","National Lab of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, P. R. China","IEEE Transactions on Multimedia","20150615","2015","17","7","1031","1044","Nowadays, more and more people are engaged in social media to generate multimedia information, i.e, creating text and photo profiles and posting multimedia messages. Such multimodal social networking activities reveal multiple user attributes such as age, gender, and personal interest. Inferring user attributes is important for user profiling, retrieval, and personalization. Existing work is devoted to inferring user attributes independently and ignores the dependency relations between attributes. In this work, we investigate the problem of relational user attribute inference by exploring the relations between user attributes and extracting both lexical and visual features from online user-generated content. We systematically study six types of user attributes: gender, age, relationship, occupation, interest, and emotional orientation. In view of methodology, we propose a relational latent SVM (LSVM) model to combine a rich set of user features, attribute inference, and attribute relations in a unified framework. In the model, one attribute is selected as the target attribute and others are selected as the auxiliary attributes to assist the target attribute inference. The model infers user attributes and attribute relations simultaneously. Extensive experiments conducted on a collected dataset from Google+ with full attribute annotations demonstrate the effectiveness of the proposed approach in user attribute inference and attribute-based user retrieval.","1520-9210;15209210","","10.1109/TMM.2015.2430819","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103313","Attribute relation;latent SVM (LSVM);user attribute inference","Correlation;Feature extraction;Media;Multimedia communication;Social network services;Support vector machines;Visualization","feature extraction;information retrieval;multimedia systems;social networking (online);support vector machines;text analysis","Google+;LSVM;attribute-based user retrieval;auxiliary attributes;emotional orientation;lexical feature extraction;multimedia information;multimedia messages;multimodal social networking activities;online user-generated content;personalization;relational latent SVM;relational user attribute inference;social media;target attribute;target attribute inference;user age;user features;user gender;user interest;user occupation;user profiling;user relationship;visual feature extraction","","9","","43","","20150507","July 2015","","IEEE","IEEE Journals & Magazines"
"A solution which can support privacy protection and fuzzy search quickly under cloud computing environment","L. Xue; R. Wuling; J. Guoxin; Y. Jie","Information Institute, Zhejiang Gongshang University, Hangzhou, China","Proceedings of 2nd International Conference on Information Technology and Electronic Commerce","20150514","2014","","","43","46","With the rapid development and widely-use of cloud computing, nowadays more and more users store data in the cloud storages. Some users, especially enterprise users, who have more privacy requirements, urgently need a solution where the cloud storage can be encrypted and retrieved rapidly and also open to internal staff only. However, to protect the privacy of data, the data must be encrypted when it is uploaded. This will greatly reduce the efficiency of retrieval. On the basis of the above, the author proposes a solution which can provide privacy protection and rapid fuzzy search under cloud computing environment. This solution can provide a more reasonable and efficient data storage and retrieval services to the user's data.","","CD-ROM:978-1-4799-5298-4; Electronic:978-1-4799-5299-1; POD:978-1-4799-5300-4","10.1109/ICITEC.2014.7105568","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105568","Cloud;computing;fuzzy;privacy;search","Approximation methods;Cloud computing;Encryption;Privacy;Servers","cloud computing;cryptography;data privacy;information retrieval;storage management","cloud computing environment;cloud storage;data storage;fuzzy search;privacy protection","","0","","13","","","20-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"A dissection of pseudorandom number generators","Ankur; Divyanjali; T. Bhardwaj","AIM&ACT, Banasthali Vidyapith, Tonk, India","2015 2nd International Conference on Signal Processing and Integrated Networks (SPIN)","20150427","2015","","","318","323","Security over the network has become the most challenging issue with the day by day increase in use of internet and other such services provided by network. The secure transmission, storage and access of data or information are the key issues for security. To understand and implement security one needs to first know in deep the concept of pseudorandom numbers because they play a major role in internet security. Pseudo-random number generators are used to generate these numbers which can be then used as keys or in any other form. In this paper we have presented various pseudorandom number generators that are used for security purpose to generate the encryption keys, SSL connection, database security etc. There is a need to understand how and for what purpose these pseudorandom number generators can be used. We also elaborate some of the limitations of the same.","","Electronic:978-1-4799-5991-4; POD:978-1-4799-5992-1","10.1109/SPIN.2015.7095369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095369","Inversive Congruential Generator;Lagged Fibonacci Generator;Linear Congruential Generator;Pseudorandom generators;Random numbers","Computers;Correlation;Cryptography;Generators;NIST;Signal processing","Internet;cryptography;data communication;information retrieval;random number generation","Internet security;SSL connection;data access;data storage;encryption keys;pseudorandom number generators;secure transmission","","0","","19","","","19-20 Feb. 2015","","IEEE","IEEE Conference Publications"
"CacheSIM: A Web Cache Simulator Tool Based on Coloured Petri Nets and Java Programming","C. Gomes Furtado Junior; J. Marques Soares; G. Cordeiro Barroso","Inst. Fed. do Ceara (IFCE), Fortaleza, Brazil","IEEE Latin America Transactions","20150522","2015","13","5","1511","1519","Efficient policies should be applied in order to decrease the document retrieval time on distributed systems, the network traffic, admission and content replacement for cache systems. Usually, proposed simulators that aim to select better policies have limitation. As an example, it's difficult to create scenarios with multiple cache systems. Besides, frequently those simulators present a lack of extensibility resources for both custom policies as to include new mechanisms for measuring performance. To address these issues, we developed CacheSIM. It is an extensible platform for simulating distributed cache systems. Using CacheSIM, we can conceive different scenarios based on a hierarchical Coloured Petri Net (CPN) model. We are able to define one replacement policy of fifteen available and one admission policy of two possible ones. Moreover, we can program custom policies and choose them. This paper presents the architecture and native resources of CacheSIM. We have evaluated its extensibility by including two replacement policies based on semantics found in works of the state of the art. We reproduced scenarios and results of those works, as well as we compared to those obtained using native policies. Thus, we can demonstrate the potential of CacheSIM as a simulation tool.","1548-0992;15480992","","10.1109/TLA.2015.7112009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7112009","Admission Policy;Coloured Petri Nets;Extensibility;Replacement Policy;Web Caches","Computational modeling;Internet;Java;Monitoring;Petri nets;Semantics;World Wide Web","Internet;Java;Petri nets;cache storage;information retrieval","CacheSIM;Java programming;Web cache simulator tool;distributed cache system;document retrieval;hierarchical CPN model;hierarchical coloured Petri Net model;network traffic;program custom policy","","0","","","","","May 2015","","IEEE","IEEE Journals & Magazines"
"Tactics of twitter data extraction for opinion mining","R. Chatterjee; M. Goyal","Department of Computer Science and Engineering, Manav Rachna College of Engineering (MRCE), Faridabad, INDIA","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","761","766","Opinion mining deals with the determination of people's sentiments over the social web as positive, negative or neutral. Microblogs such as twitter serves as a rich source for opinion mining and sentiment analysis as opinions are shared by millions of users. In our paper, we have analyzed the various methods available through which the twitter data can be extracted. We have provided an overall picture of how each method is different from another for extracting tweets. We have chosen Windows 10 as a keyword to compare the opinions as extracted by different sentiment tools.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100351","APIs;Opinion Mining;Sentiment;Tweet","Blogs;Cameras;Data mining;Media;Programming;Sentiment analysis;Twitter","data mining;information retrieval;social networking (online)","Microblogs;Twitter data extraction;opinion mining;people sentiment determination;social Web","","0","","8","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficient data retrieval for large-scale smart city applications through applied Bayesian inference","J. M. Koh; M. Sak; H. X. Tan; H. Liang; F. Folianto; T. Quek","NUS High Sch. of Math. & Sci., Singapore, Singapore","2015 IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)","20150514","2015","","","1","6","Recent years have witnessed the proliferation of worldwide efforts towards developing technologies for enabling smart cities, to improve the quality of life for citizens. These smart city solutions are typically deployed across large spatial regions over long time scales, generating massive volumes of data. An efficient way of data retrieval is thus required, for post-processing of the data - such as for analytical and visualization purposes. In this paper, we propose a data prefetching and caching algorithm based on Bayesian inference, for the retrieval of data in large-scale smart city applications. A brute-force approach is used to determine the optimal weight correction factor in the proposed prefetching algorithm. We evaluate the optimized Bayesian prefetching algorithm against the Naïve and Random prefetch baselines, using both simulated and actual data usage patterns. Results show that the Bayesian approach can achieve up to 48.4% reductions in actual user-perceived application delays during data retrieval.","","Electronic:978-1-4799-8055-0; POD:978-1-4799-8056-7","10.1109/ISSNIP.2015.7106930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106930","","Algorithm design and analysis;Bayes methods;Cities and towns;Delays;Heuristic algorithms;Prediction algorithms;Prefetching","data handling;inference mechanisms;information retrieval;town and country planning","Bayesian inference;Naïve prefetch baselines;Random prefetch baselines;brute force approach;data caching algorithm;data prefetching algorithm;data retrieval;data volumes;large-scale smart city applications;optimal weight correction factor;quality of life;smart cities;spatial regions","","1","","10","","","7-9 April 2015","","IEEE","IEEE Conference Publications"
"Towards a web-scale data management ecosystem demonstrated by SAP HANA","F. Faerber; J. Dees; M. Weidner; S. Baeuerle; W. Lehner","SAP SE, Walldorf, Germany","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","1259","1267","Over the years, data management has diversified and moved into multiple directions, mainly caused by a significant growth in the application space with different usage patterns, a massive change in the underlying hardware characteristics, and-last but not least-growing data volumes to be processed. A solution matching these constraints has to cope with a multidimensional problem space including techniques dealing with a large number of domain-specific data types, data and consistency models, deployment scenarios, and processing, storage, and communication infrastructures on a hardware level. Specialized database engines are available and are positioned in the market optimizing a particular dimension on the one hand while relaxing other aspects (e.g. web-scale deployment with relaxed consistency). Today it is common sense, that there is no single engine which can handle all the different dimensions equally well and therefore we have very good reasons to tackle this problem and optimize the dimensions with specialized approaches in a first step. However, we argue for a second step (reflecting in our opinion on the even harder problem) of a deep integration of individual engines into a single coherent and consistent data management ecosystem providing not only shared components but also a common understanding of the overall business semantics. More specifically, a data management ecosystem provides common “infrastructure” for software and data life cycle management, backup/recovery, replication and high availability, accounting and monitoring, and many other operational topics, where administrators and users expect a harmonized experience. More importantly from an application perspective however, customer experience teaches us to provide a consistent business view across all different components and the ability to seamlessly combine different capabilities. For example, within recent customer-based Internet of Things scenarios, a huge potential exists i- combining graph-processing functionality with temporal and geospatial information and keywords extracted from high-throughput twitter streams. Using SAP HANA as the running example, we want to demonstrate what moving a set of individual engines and infra-structural components towards a holistic but also flexible data management ecosystem could look like. Although there are some solutions for some problems already visible on the horizon, we encourage the database research community in general to focus more on the Big Picture providing a holistic/integrated approach to efficiently deal with different types of data, with different access methods, and different consistency requirements-research in this field would push the envelope far beyond the traditional notion of data management.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113374","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113374","","Biological system modeling;Business;Data models;Databases;Ecosystems;Engines;Planning","Internet;Internet of Things;data handling;database management systems;information retrieval;social networking (online);software management","SAP HANA;Web-scale data management ecosystem;application space;backup;business semantics;coherent data management ecosystem;communication infrastructures;consistency model;consistent data management ecosystem;customer-based Internet of Things scenarios;data life cycle management;data model;database engines;deployment scenarios;domain-specific data types;geospatial information extraction;graph- processing functionality;high-throughput Twitter streams;keyword extraction;multidimensional problem space;recovery;replication;software management;temporal information extraction;usage patterns","","0","","16","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Data Community-Oriented Object-Level Retrieval System Implementation","N. Liu; J. Yang; G. Li; L. Li","Dalian Maritime Univ., Dalian, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","1","","11","14","To overcome the problems about consequence discontinuities and consequence sorting dissatisfaction of relational database-based key word retrieval, a novel data community-oriented object-level retrieval system is designed and implemented, which is based on data graph. The combination of each keyword nodes that center nodes can reach determines a community. Some corresponding adjustments are carried out by comparing the cost from the central node to each keyword nodes. The implementation of the retrieval system not only makes the retrieval consequences contained more information, but also makes the structure more clearly. The retrieval system achieves a comprehensive, coherent, orderly retrieval for relevant information.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064067","data community;data graph;object-level retrieval;relational database","Communities;Joining processes;Motion pictures;Quantization (signal);Relational databases;Sorting","information retrieval;relational databases","center node;consequence discontinuities;consequence sorting dissatisfaction;data community oriented object level retrieval system;data graph;keyword node;relational database-based keyword retrieval","","0","","8","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"ISO/IEC/IEEE International Standard - Systems and software engineering - Engineering and management of websites for systems, software, and services information","","","ISO/IEC/ IEEE 23026 First edition 2015-05-15","20150601","2015","","","1","54","This standard defines system engineering and management requirements for the life cycle of websites, including strategy, design, engineering, testing and validation, and management and sustainment for Intranet and Extranet environments. The goal of this standard is to improve the usability of informational websites and ease of maintenance of managed Web operations in terms of locating relevant and timely information, applying information security management, facilitating ease of use, and providing for consistent and efficient development and maintenance practices. .It applies to those using web technology to present information and communications technology (ICT) information, such as user documentation for systems and software, life-cycle documentation for systems and software engineering projects, and documentation of policies, plans, and procedures for IT service management. This standard provides requirements for website owners and website providers, managers responsible for establishing guidelines for website development and operations, for software developers and operations and maintenance staff who may be external or internal to the website owner's organization. It applies to websites for public access and for limited access, such as for users, customers, and subscribers seeking information on IT products and services. It includes increased emphasis on the human factors concerns for making information easily retrievable and usable for the intended audience. It focuses on vendor- and product-independent considerations.","","","10.1109/IEEESTD.2015.7106438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106438","23026;webmaster;website engineering;website management","IEC Standards;IEEE Standards;Information management;Software engineering;Systems engineering and theory;Websites;iSO Standards","IEC standards;IEEE standards;ISO standards;Web sites;computer network management;computer network security;extranets;human factors;information retrieval;intranets;software development management;systems engineering","Extranet environment;ICT;ISO/IEC/IEEE 23026;Intranet environments;Web operations management;Website development;human factors;information and communications technology;information retrieval;information security management;management requirements;software developer;software engineering;systems engineering","","0","","","","","May 15 2015","","IEEE","IEEE Standards"
"World-wide online monitoring interface of the ATLAS experiment","S. Kolos; E. Alexandrov; R. Hauser; M. Mineev; A. Salnikov","University of California, Irvine, USA","2014 19th IEEE-NPSS Real Time Conference","20150430","2014","","","1","5","The ATLAS[1] collaboration accounts for more than 3000 members located all over the world. The efficiency of the experiment can be improved allowing system experts not present on site to follow the ATLAS operations in real-time, spotting potential problems which otherwise may remain unattended for a non-negligible time. Taking into account the wide geographical spread of the ATLAS collaboration, the solution of this problem is to have all monitoring information with minimal access latency available world-wide. We have implemented a framework which defines a standard approach for retrieving arbitrary monitoring information from the ATLAS private network via HTTP. An information request is made by specifying one of the predefined URLs with some optional parameters refining data which has to be shipped back in XML format. The framework takes care of receiving, parsing and forwarding such requests to the appropriate plugins. The plugins retrieve the requested data and convert it to XML (or optionally to JSON) format before giving it back to the framework, which forwards it to the original requester. The list of data types which can be retrieved is fairly complete and includes raw physics event samples, operational statistics, application logs, configuration parameters, data quality assessment results and histograms for the current data taking session as well as for the previous ones. In addition to the traditional request-response information access, the latest version of the framework offers asynchronous data access where it initiates data transmission towards clients only when requested data has changed, reducing the network load and simplifying the development of end-user interfaces. This paper presents the architecture of the ATLAS world-wide framework and summarizes the experience of its usage during the first ATLAS data taking period. It also describes new recently developed plugins as part of the preparation of the second round of the experiment operations plann- d to start in early 2015.","","Electronic:978-1-4799-3659-5; POD:978-1-4799-3660-1","10.1109/RTC.2014.7097474","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097474","","Browsers;Graphical user interfaces;Histograms;Information services;Monitoring;Servers;XML","Internet;Java;XML;client-server systems;computerised monitoring;graphical user interfaces;information retrieval;physical instrumentation control","ATLAS Experiment;ATLAS collaboration;ATLAS private network;XML format;arbitrary monitoring information;asynchronous data access;configuration parameters;data quality assessment;data transmission;end-user interfaces;experiment efficiency;minimal access latency;physics event samples;request-response information access;world-wide online monitoring interface","","0","","9","","","26-30 May 2014","","IEEE","IEEE Conference Publications"
"Towards a Practical and Efficient Search over Encrypted Data in the Cloud","M. Strizhov","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA","2015 IEEE International Conference on Cloud Engineering","20150423","2015","","","496","498","Searchable encryption allows a client to encrypt its document collection in such a way that the encrypted collection can still be searched. The most immediate application of searchable encryption is privacy / confidentiality preserving cloud storage, where it enables a client to securely outsource its document collection to an untrusted cloud provider without sacrificing the ability to search over it. Our research focuses on developing a novel searchable encryption framework that allows the cloud server to perform multi-keyword ranked search as well as substring search incorporating position information. We present some advances that we have accomplished in this area. We then layout our planned research work and a timeline to accomplish this.","","Electronic:978-1-4799-8218-9; POD:978-1-4799-8219-6","10.1109/IC2E.2015.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092967","cloud computing;ranked search;searchable symmetric encryption;substring position search","Encryption;Frequency measurement;Indexes;Search problems;Servers","cloud computing;cryptography;data privacy;document handling;file servers;information retrieval;storage management","cloud server;document collection;encrypted data;multikeyword ranked search;position information;privacy/confidentiality preserving cloud storage;searchable encryption;substring search;untrusted cloud provider","","0","","19","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Enabling Scientific Collaboration and Discovery Through the Use of Data Standardization","S. H. Myers; B. M. Huhman","Dahlgren Division, Naval Surface Warfare Center, Dahlgren, VA, USA","IEEE Transactions on Plasma Science","20150506","2015","43","5","1190","1193","The Railgun Data Format Standard (RDFS) provides a flexible format for the archival of electromagnetic railgun (EMRG) laboratory test data. This effort utilizes the hierarchical data format version 5 for the data model and file format, as well as extensible markup language for data structure and data type encapsulation. The RDFS was developed through a collaborative effort within the Office of Naval Research (ONR) EMRG program, including members from the Naval Surface Warfare Center Dahlgren, the Naval Research Laboratory, and the Institute for Advanced Technology. The intent behind the RDFS is to facilitate collaborative data sharing among EMRG researchers through the standardization of EMRG test data archives. The structure of the RDFS is discussed, along with details on its implementation and use within the ONR EMRG community.","0093-3813;00933813","","10.1109/TPS.2015.2405256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064777","Data management;data models;railguns;standardization;standardization.","Collaboration;Data models;Laboratories;Railguns;Resource description framework;Standards","data structures;information retrieval systems;laboratory techniques;military computing;railguns;records management;standardisation","EMRG laboratory test data;EMRG test data archives;Institute for Advanced Technology;Naval Research Laboratory;Naval Surface Warfare Center Dahlgren;ONR EMRG community;ONR EMRG program;Office of Naval Research;RDFS;collaborative data sharing;data model;data standardization;data structure;data type encapsulation;electromagnetic railgun laboratory test data;file format;hierarchical data format version 5;markup language;railgun data format standard;scientific collaboration","","0","","14","","20150320","May 2015","","IEEE","IEEE Journals & Magazines"
"General Multi-key Searchable Encryption","J. Yang; C. Fu; N. Shen; Z. Liu; C. Jia; J. Li","Coll. of Comput. & Control Eng., Nankai Univ., Tianjin, China","2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops","20150430","2015","","","89","95","We analysis outsourced server with multi-users and classify the data sharing into two main types. We focus on the data sharing between users in Searchable Encryption and the corresponding security goal. Then we present a general scheme for Searchable Encryption in which the cipher text can be generated from parameter by authorized users. With the concept of homomorphism and one-way function, we construct a general model to illustrate and fulfill the goals involved. We also promote such a model to a general Multi-Key Searchable Encryption which enables only a single submission for the retrievals in the documents encrypted by different keys. We also give two concrete examples to illustrate the feasibility and security in such a general model.","","Electronic:978-1-4799-1775-4; POD:978-1-4799-1776-1","10.1109/WAINA.2015.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096153","Homomorphism;Multi-key;Searchable Encryption","Access control;Concrete;Data models;Encryption;Servers","cryptography;file servers;information retrieval;outsourcing;security of data","authorized users;ciphertext;data sharing classification;document encryption;multikey searchable encryption;one-way function;outsourced server analysis","","0","","23","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Frequent itemset mining for Big Data in social media using ClustBigFIM algorithm","S. Gole; B. Tidke","Department of Computer Engg, Flora Institute of Technology, Pune, Maharashtra, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","6","Tremendous amount of data is getting explored through IOT (Internet of Things) from variety of sources such as sensor network, social media feed, internet applications, called as Big Data. Big Data cannot be handled by conventional tools and techniques. Social networks are becoming dominant in communications over internet. The Big Data mining is essential in order to extract value from massive amount of data which could give better insights using efficient techniques. Association Rule mining and frequent itemset mining are popular techniques for data mining which needs entire dataset into main memory for processing, but large datasets do not fit into main memory. To overcome this limitation MapReduce is used for parallel processing of Big Data having features such as high scalability and robustness which helps to handle problem of large datasets. Proposed novel method, ClustBigFIM works on MapReduce framework for mining large datasets; ClustBigFIM is modified BigFIM algorithm providing scalability and speed in order to extract meaningful information from large datasets in the form of associations, emerging patterns, sequential patterns, correlations and other significant data mining tasks which gives better insight to make effective business decisions in competitive environment using faster and efficient parallel processing platform.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087122","Association Rule Mining;Big Data;Clustering;Frequent Itemset Mining;Hadoop;MapReduce","Algorithm design and analysis;Association rules;Big data;Itemsets;Scalability","Big Data;Internet of Things;data mining;information retrieval;parallel processing;social networking (online)","Big Data mining;ClustBigFIM;IOT;Internet applications;Internet of Things;MapReduce framework;association rule mining;business decisions;competitive environment;emerging patterns;frequent itemset mining;information extraction;large datasets;parallel processing;sensor network;sequential patterns;social media feed","","2","","40","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"A new algorithm for fast search of the k nearest patterns","R. Gil-Pita; M. Rosa-Zurera; R. Vicen-Bueno; F. L. Ferreras","Department of Signal Theory and Communications, University of Alcal&#x00E1;, Escuela Polit&#x00E9;cnica Superior, 28805, Alcal&#x00E1; de Henares, Spain","2007 15th European Signal Processing Conference","20150504","2007","","","1887","1891","The computational cost associated to the k-nearest neighbor classifier depends on the amount of available patterns, which makes this method impractical in many real-time applications. This fact makes interesting the study of fast algorithms for finding the k-nearest patterns, like, for example, the kLAESA algorithm. In this paper we propose a novel algorithm for finding the k-nearest patterns, denominated k-tuned approximating and eliminating search algorithm (kTAESA). The algorithm is used to implement kNN classifiers, which are applied to three databases from the UCI machine learning benchmark repository. Results are compared with those achieved by the exhaustive search, the kAESA and the kLAESA algorithms, in terms of number of distances to evaluate, number of simple operations (sums, comparisons and products) needed to classify each pattern, and amount of required memory. Results demonstrate the best performance of the proposal, mainly when the number of operations is considered.","","POD:978-839-2134-04-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7099135","","Approximation algorithms;Classification algorithms;Databases;Diabetes;Memory management;Signal processing algorithms;Training","information retrieval;learning (artificial intelligence);pattern classification;search problems","UCI machine learning benchmark repository;k-nearest pattern classifier;k-tuned approximating and eliminating search algorithm;kLAESA algorithm;kNN classifier","","0","","7","","","3-7 Sept. 2007","","IEEE","IEEE Conference Publications"
"Investigating sensor data retrieval schemes for multi-sensor passive RFID tags","Y. Su; A. Wickramasinghe; D. C. Ranasinghe","Auto-ID Lab, The University of Adelaide, Adelaide SA 5005, Australia","2015 IEEE International Conference on RFID (RFID)","20150601","2015","","","158","165","Measuring multiple physical quantities are increasingly being demanded in commercial, biomedical and generally in ubiquitous applications. Although the recent emergence of passive sensor enabled RFID tags (sensor tags) provide new opportunities for these types of applications mainly due to the extended operational life and the small form factor, the energy harvesting nature of sensor tags hinders the use of multiple sensors in a single platform because of the requirement of additional energy to operate multiple sensors and subsequent reduction in the throughput. In this paper, we propose three, fast and energy efficient multi-sensor data retrieval approaches to obtain sensor data from sensor tags. We implemented a sensor tag with two sensors, an accelerometer and a barometer. Our extensive experiments on power consumption, operational range and throughput using the developed sensor tag revealed that, the proposed approaches can successfully be used for multi-sensor data retrieval and indicates that they can effectively be used in a range of real-world ubiquitous sensing applications such as fall prevention and food safety monitoring.","2374-0221;23740221","Electronic:978-1-4799-1937-6; POD:978-1-4799-1938-3; USB:978-1-4799-1936-9","10.1109/RFID.2015.7113087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113087","","Accelerometers;Delays;Monitoring;Power demand;Radiofrequency identification;Schedules;Throughput","information retrieval;radiofrequency identification;telecommunication computing;ubiquitous computing","accelerometer;energy harvesting;investigating sensor data retrieval schemes;multiple physical quantities;multiple sensors;multisensor passive RFID tags;passive sensor;sensor tags hinders;single platform;ubiquitous applications;ubiquitous sensing applications","","3","","19","","","15-17 April 2015","","IEEE","IEEE Conference Publications"
"A summarizer system based on a semantic analysis of web documents","A. Florence; V. Padmadas","Thadomal Shahani Engineering College, Mumbai, India","2015 International Conference on Technologies for Sustainable Development (ICTSD)","20150430","2015","","","1","6","The availability of web and search engines has made the search easier nowadays. Information overload is one of the major problems which require algorithms and tools for faster access. Electronic documents are one of the major sources of information for business and academic information. In order to fully utilizing these on-line documents effectively, it is crucial to be able to extract the summary of these documents. Summarization system will be one of the solutions to the above problem. This project proposes a summarizer system which will be able to perform summarization of multiple documents. The input text documents are analyzed through a parser which parses the input documents and generates parse tree for each sentence. RDF triples are extracted from each sentence by analyzing the typed dependencies generated from the parser in the form of subject, verb and object. Semantic distance is computed between each pair of sentences and a matrix containing the semantic distance for sentences are computed. The measure adopted to compute semantic distance is Wu and Palmer distance. A clustering algorithm is applied to the extracted subject, verb and object space and the extracted RDF triples are grouped into clusters. The important sentences are selected for final summary are extracted using sentence selection algorithm.","","Electronic:978-1-4799-8187-8; POD:978-1-4799-8188-5","10.1109/ICTSD.2015.7095851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095851","NLP;RDF;Semantic analysis;Summarization;parse tree","Algorithm design and analysis;Clustering algorithms;Fires;Resource description framework;Semantics;Sustainable development;Text analysis","document handling;information analysis;information retrieval systems;pattern clustering","RDF triples;Web documents;Wu-Palmer distance;academic information;business information;clustering algorithm;document extraction;electronic documents;information overload;resource description framework;search engines;semantic analysis;semantic distance;sentence selection algorithm;summarizer system","","1","","18","","","4-6 Feb. 2015","","IEEE","IEEE Conference Publications"
"An axiomatic inspection of the behavior of topic models with data aggregation","V. Deolalikar","","2014 IEEE International Conference on Big Data (Big Data)","20150525","2014","","","1","5","Topic modeling has various applications in organizing and retrieving textual data in document collections. In enterprises, such collections are often distributed across various sites, and collaboratively aggregated at the time of processing. Therefore, the problem of topic modeling over aggregations of data is important. We study the behavior of a standard topic modeling technique-hierarchical Dirichlet process (HDP)-as the underlying data is aggregated. We formulate three axioms that reflect the assumptions that users frequently make when dealing with aggregated data. We empirically demonstrate that HDP does not necessarily satisfy these axioms. We discuss the ramifications of this on applications in enterprise settings.","","Electronic:978-1-4799-5666-1; POD:978-1-4799-5667-8","10.1109/BigData.2014.7111660","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7111660","","Analytical models;Computational modeling;Data mining;Data models;Distributed databases;Information management;Standards","document handling;information retrieval","HDP;axiomatic inspection;data aggregation;document collections;enterprise settings;hierarchical dirichlet process;standard topic modeling technique;textual data retrieval;topic model behavior","","0","","","","","27-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Language modeling structures in audio transcription for retrieval of historical speeches","M. Kurimo; B. Zhou; R. Huang; J. H. L. Hansen","Neural Networks Research Centre, Helsinki University of Technology, Finland","2004 12th European Signal Processing Conference","20150406","2004","","","557","560","In this paper we apply speech recognition for automatic transcript generation for spoken document retrieval. The transcripts are used to compute an index for an archive of historical speeches and to provide the index, speech, and transcripts available for query based retrieval and browsing. In addition to acoustic variability, the task is challenging, because it covers a broad spectrum of different speaking styles and use of language. Language modeling is important for speech recognition to determine the prior probabilities of the compared word and sentence candidates in decoding. Various large text corpora are available in electronic format for language model training, but the open question is what and how should we include to improve the audio transcripts of this task. In this work we compare large overall language models to focused ones trained on selected subsets of the data, and to combinations between both. With respect to the potential index terms, improvements were obtained for transcripts that did not fit well to the scope of the large overall language model.","","POD:978-320-0001-65-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079950","","Abstracts;Adaptation models;Indexes;Optical imaging;Scholarships;Speech;Training","information retrieval;probability;speech recognition","acoustic variability;audio transcription;automatic transcript generation;historical speeches;language modeling structures;large text corpora;query based retrieval;speech recognition;spoken document retrieval","","0","","14","","","6-10 Sept. 2004","","IEEE","IEEE Conference Publications"
"Knowledge Sharing in the Online Social Network of Yahoo! Answers and Its Implications","H. Shen; Z. Li; J. Liu; J. E. Grant","Department of Electrical and Computer Engineering, Clemson University, Clemson, SC","IEEE Transactions on Computers","20150508","2015","64","6","1715","1728","Question and Answer (Q&A) websites such as Yahoo! Answers provide a platform where users can post questions and receive answers. These systems take advantage of the collective intelligence of users to find information. In this paper, we analyze the online social network (OSN) in Yahoo! Answers. Based on a large amount of our collected data, we studied the OSN's structural properties, which reveals strikingly distinct properties such as low link symmetry and weak correlation between indegree and outdegree. After studying the knowledge base and behaviors of the users, we find that a small number of top contributors answer most of the questions in the system. Also, each top contributor focuses only on a few knowledge categories. In addition, the knowledge categories of the users are highly clustered. We also study the knowledge base in a user's social network, which reveals that the members in a user's social network share only a few knowledge categories. Based on the findings, we provide guidance in the design of spammer detection algorithms and distributed Q&A systems. We also propose a friendship-knowledge oriented Q&A framework that synergistically combines current OSN-based Q&A and web Q&A. We believe that the results presented in this paper are crucial in understanding the collective intelligence in the web Q&A OSNs and lay a cornerstone for the evolution of next-generation Q&A systems.","0018-9340;00189340","","10.1109/TC.2014.2322598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6847139","Yahoo! Answers;collective intelligence;online social networks;question and answer platforms;user behavior","Correlation;Facebook;Fans;Knowledge based systems;Knowledge engineering;Twitter","question answering (information retrieval);social networking (online);unsolicited e-mail","OSN-based Q&A;Web Q&A;Yahoo! answers;distributed Q&A systems;friendship knowledge oriented Q&A framework;knowledge base;knowledge category;next generation Q&A system;online social network;question and answer system;spammer detection algorithm;user behavior;user social network sharing","","1","","46","","20140701","June 1 2015","","IEEE","IEEE Journals & Magazines"
"Design and interaction music search by humming on beatme online","A. S. D. Martha; A. I. Wuryandari; Y. Priyana","School of Electrical Engineering and Informatics Bandung Institute of Technology, Indonesia","2014 IEEE 4th International Conference on System Engineering and Technology (ICSET)","20150601","2014","4","","1","6","Enjoy the music has become a necessity. Following advances in technology where audio equipment is becoming more affordable, and an abundance of work of the musicians. Beatme Online is an online music communication medium that connects various devices into a cloud system which is manifested in the form of a website. Beatme Online is designed to be able to accommodate all musical activities through the Internet. Through the integration of online applications that have been designed Beatme previously, is also designed to enable users to enjoy music anywhere and anytime. In Beatme Online, all users are artists with different levels (masters, professional, amateur), so the user can have the album, song, or genre respectively. Beatme Hum Melody Search is designed to try to translate humming into playlists that are similar to a given humming, so it can be helpful when the user wants to enjoy the music but having problems forgetting the title song, singer, or album, and only remember the melody.","","CD-ROM:978-1-4799-7188-6; Electronic:978-1-4799-7189-3; POD:978-1-4799-7190-9","10.1109/ICSEngT.2014.7111779","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7111779","humming;interaction;music;online;social media;websites","Hardware;Libraries;Microphones;Music;Servers;Software;Time-frequency analysis","cloud computing;human computer interaction;information retrieval;music;social networking (online)","Beatme Hum Melody Search;Beatme Online;Internet;Website;audio equipment;cloud system;humming translation;music search design;music search interaction;online music communication medium;social media","","0","","12","","","24-25 Nov. 2014","","IEEE","IEEE Conference Publications"
"MAS a scalable framework for research effort evaluation by unsupervised machine learning-Hybrid plagiarism model","S. V. Shinde; S. Z. Gawali; D. M. Thakore","Information Technology, B.V.D.U.s College of Engineering, Pune, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","5","In the era of web new information is upcoming day by day. Researches add their work for their research domains. Detecting of originality of research work is in hype. In Academic sector students researchers bring in innovative ideas, algorithms stating that their work outperforms prior research. They may implement NULL Hypothesis or alternative Hypothesis, detecting their effort is a challenge. By means of plagiarism detectors such academic efforts can be evaluated or graded. This reflects the essence of research in the field of Plagiarized content detection and grading. Some of our research issue highlights to technical scenario to design an algorithm which is adaptable to changing nature of dataset. The dataset grows, as new research work is added in due course of time. Data extraction from unstructured information is challenging, as no standard pattern is yet defined. Such patterns vary from research to research and are domain specific. A document in question i.e plagiarized or not? Is a join of one or more sentences that originate by the authors research or referenced from previous publications. Authors to prove originality use paraphrasing which may have semantic similarity, also some of the contents act as metaphor for upcoming research work. It is complex task point out such an activity. Methodology states that a document in question is a join of sentences, whereas each sentence is a join of terms. Thus we conclude by fork and join operations; plagiarism detection is possible in effective way. Document in question is split to produce a sentence vector. A term vector is generated by forking sentence to terms for each sentence in sentence vector. Mapper is implemented that maps term to sentence and sentence to source document. To enhance the accuracy of the model a Multi Agent Based System MAS frame is recommended to adapt varying similarity functions. Achieve parallelism in system and adaptability of new similarity measures as well remove one which are not sui- able any more to the task.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087030","Cosine similarity;Document in Question;EMA;Inverted Index;MAS;Mapper;PMA;SMA;Sentence vector;Term Vector;Unsupervised Learning;WEMA;WPMA;WSMA;fork;join","Accuracy;Algorithm design and analysis;Classification algorithms;Data mining;Plagiarism;Semantics;Silicon","Internet;information retrieval;multi-agent systems;text analysis;unsupervised learning","MAS;MAS frame;NULL hypothesis;academic sector student researchers;alternative hypothesis;data extraction;innovative ideas;multiagent based system frame;paraphrasing;plagiarism detection;plagiarism detectors;plagiarized content detection;plagiarized content grading;research effort evaluation;scalable framework;semantic similarity;sentence vector;similarity functions;unstructured information;unsupervised machine learning-hybrid plagiarism model","","0","","22","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Full-Space Local Topology Extraction for Cross-Modal Retrieval","L. Zhang; Y. Zhang; R. Hong; Q. Tian","Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Image Processing","20150413","2015","24","7","2212","2224","With the ever increasing availability of various kinds of multimedia data, cross-modal retrieval, which enables information retrieval from various types of data given various types of query, has become a research hotspot. Hashing-based techniques have been developed to solve this problem, however, most previous works cannot capture the shared underlying structure of real-world multimodal data, which degrades their retrieval performances. In this paper, we propose a novel hashing method based on the extraction of the common manifold structure shared among different feature spaces. To faithfully represent the common structure, two kinds of local topology information are exploited in our method. Local angles are incorporated within the extraction of local topology of each feature space, which is then used to learn a common intermediate subspace. After heterogeneous features being embedded into this subspace, local similarities are exploited to extract the local topology between different feature spaces, and learn compact Hamming embeddings to facilitate cross-modal retrieval. The proposed method is referred to as full-space local topology extraction for hashing. Extensive comparisons with other state-of-the-art methods on three benchmark multimedia data sets demonstrate the superiority of our proposed method in terms of retrieval recall and search accuracy.","1057-7149;10577149","","10.1109/TIP.2015.2419074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7076613","Cross-Modal Retrieval;Cross-modal retrieval;Hashing;Intermediate Subspace;Local Topology Extracting;hashing;intermediate subspace;local topology extracting","Accuracy;Availability;Data mining;Feature extraction;Manifolds;Multimedia communication;Topology","feature extraction;file organisation;information retrieval","common manifold structure extraction;compact Hamming embeddings;cross-modal retrieval;full-space local topology extraction;hashing method;information retrieval;local angles;local topology information;retrieval recall;search accuracy","","4","","44","","20150401","July 2015","","IEEE","IEEE Journals & Magazines"
"Multi-group multi-way relaying with multi-stage non-regenerative relay stations","S. N. Islam; S. Durrani","Research School of Engineering, CECS, The Australian National University (ANU), Canberra 2601 ACT, Australia","2015 22nd International Conference on Telecommunications (ICT)","20150618","2015","","","43","47","In this paper, we propose a signal transmission model for multi-group multi-way (MGMW) relaying which allows complete information exchange among users belonging to different user groups, with applications such as file sharing among users separated by large distances. We achieve this through the use of multi-stage non-regenerative relay stations (RSs). The groups of multiple users are connected to the nearest RS stages which are again connected via RSs at the next nearest stage and so on. The RSs at each stage obtain messages from user groups connected through the next RS stage by subtracting information extracted from the previous RS stage. We formulate the achievable sum rate of such a network and investigate the impact of system parameters on it. We show that increasing the number of users per group, while keeping a smaller number of user groups, improves the sum rate.","","Electronic:978-1-4799-8078-9; POD:978-1-4799-8079-6","10.1109/ICT.2015.7124655","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7124655","multi-group multi-way relaying;nonregenerative relaying;sum rate","Array signal processing;Indexes;Network coding;Protocols;Relay networks (telecommunications);Signal to noise ratio","information retrieval;peer-to-peer computing;relay networks (telecommunication);signal processing","MGMW relaying;file sharing;information exchange;information extraction subtraction;multigroup multiway relaying;multistage nonregenerative relay stations;signal transmission model;sum rate improvement;system parameters","","0","","21","","","27-29 April 2015","","IEEE","IEEE Conference Publications"
"Sparse Linear Integration of Content and Context Modalities for Semantic Concept Retrieval","Q. Zhu; M. L. Shyu","Department of Electrical and Computer Engineering, University of Miami, Coral Gables, FL, USA","IEEE Transactions on Emerging Topics in Computing","20150604","2015","3","2","152","160","The semantic gap between low-level visual features and high-level semantics is a well-known challenge in content-based multimedia information retrieval. With the rapid popularization of social media, which allows users to assign tags to describe images and videos, attention is naturally drawn to take advantage of these metadata in order to bridge the semantic gap. This paper proposes a sparse linear integration (SLI) model that focuses on integrating visual content and its associated metadata, which are referred to as the content and the context modalities, respectively, for semantic concept retrieval. An optimization problem is formulated to approximate an instance using a sparse linear combination of other instances and minimize the difference between them. The prediction score of a concept for a test instance measures how well it can be reconstructed by the positive instances of that concept. Two benchmark image data sets and their associated tags are used to evaluate the SLI model. Experimental results show promising performance by comparing with the approaches based on a single modality and approaches based on popular fusion methods.","2168-6750;21686750","","10.1109/TETC.2014.2384992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6994780","Semantic concept retrieval;multimodal integration;semantic concept retrieval;sparse linear methods","Context;Equations;Feature extraction;Mathematical model;Semantics;Videos;Visualization","content-based retrieval;information retrieval;meta data;multimedia computing;social networking (online)","SLI model;content modalities;content-based multimedia information retrieval;context modalities;high-level semantics;low-level visual features;metadata;optimization problem;semantic concept retrieval;social media popularization;sparse linear integration model","","6","","37","","20141222","June 2015","","IEEE","IEEE Journals & Magazines"
"Drum transcription from multichannel recordings with non-negative matrix factorization","D. S. Alves; J. Paulus; J. Fonseca","Dept. of Electr. Eng., New Univ. of Lisbon, Lisbon, Portugal","2009 17th European Signal Processing Conference","20150406","2009","","","894","898","Automatic drum transcription enables handling symbolic data instead of plain acoustic information in music information retrieval applications. Usually the input to the transcription system is single-channel audio, and as a result the proposed solutions are designed for this kind of input. However, in studio environment the multichannel recording of the drums is often available. This paper proposes an extension to a non-negative matrix factorization drum transcription method to handle multichannel data. The method creates spectral templates for all target drums from all available channels, and in transcription estimates time-varying gains for each of them so that the sum approximates the recorded signal. Sound event onsets are detected from the estimated gains. The system is evaluated with multichannel data from a publicly available data set, and compared with other methods. The results suggest that the use of multiple channels instead of a single-channel mix improves the transcription result.","","POD:978-161-7388-76-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7077272","","Acoustics;Materials;Microphones;Source separation;Spectrogram;Target tracking","information retrieval;matrix decomposition;music;signal classification;source separation","drum transcription;estimated gains;multichannel data;multichannel recordings;music information retrieval applications;nonnegative matrix factorization;plain acoustic information;single-channel audio;sound event onsets;spectral templates;symbolic data;time-varying gains","","0","","","","","24-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"Semantic analysis technique of logics retrieval for software testing from specification documents","S. Masuda; F. Iwama; N. Hosokawa; T. Matsuodani; K. Tsuda","IBM Research - Tokyo Toyosu, Tokyo, Japan","2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","20150514","2015","","","1","6","Software testing often targets natural language specification documents. Creating test cases depends on engineer skills, then automation of creating test cases from natural language specification is important. Logics retrieval is a required technique to automate creating test cases, because once logics are retrieved we can transform them into decision tables and also create test cases from the decision tables. Furthermore, Japanese language structure is different from English. If we target Japanese natural language, a new technique is also required. We propose a Semantic Analysis Technique of Logics Retrieval for Software Testing from Japanese Public Sector's Specification Documents. This technique is a new logics retrieval from harmonization between natural language processing technique and software testing. Applying the analysis technique to total 25 files, 1,218 pages and a million double bytes characters, the precision reached 0.93 to 0.97 and recall reached 0.65 to 0.79.","","Electronic:978-1-4799-1885-0; POD:978-1-4799-1886-7","10.1109/ICSTW.2015.7107430","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107430","Japanese language;logics retrieval;natural language processing;semantic analysis;test case","Natural language processing;SONOS devices;Semantics;Software;Software testing","decision tables;document handling;information retrieval;natural language processing;program testing","Japanese language structure;Japanese public sector specification documents;decision tables;logics retrieval;natural language processing technique;natural language specification documents;semantic analysis technique;software testing","","2","","18","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Single-trial identification of failed memory retrieval","E. Noh; M. V. Mollison; T. Curran; V. R. de Sa","Department of Electrical & Computer Engineering, UCSD","2014 48th Asilomar Conference on Signals, Systems and Computers","20150427","2014","","","21","25","We show that it is possible to distinguish unsuccessful from successful retrieval of study items based on single-trial EEG recorded during the test phase of 3 separate recognition memory experiments. The overall classification accuracy across all 34 classification problems was 58.4 %. The classification accuracy monotonically increased to 68.03 % by only classifying trials with high classifier confidence levels. The likelihood of remembering a study item for trials with the 10% highest and lowest classifier outputs were 0.80 and 0.45 respectively. This suggests that the classifier outputs are reflecting the level of retrieval during the test phase. These findings combined with previous single-trial results predicting subsequent memory from EEG recorded during and prior to memory encoding will provide a basis for a passive brain-computer interface (BCI) system for improving memory.","","CD-ROM:978-1-4799-8295-0; Electronic:978-1-4799-8297-4; POD:978-1-4799-8298-1","10.1109/ACSSC.2014.7094388","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7094388","","Accuracy;Brain;Electroencephalography;Encoding;Image coding;Image color analysis;Memory management","brain-computer interfaces;electroencephalography;information retrieval;signal classification","BCI system;classification problem;classifier confidence levels;classifier outputs;failed memory retrieval;overall classification accuracy;passive brain-computer interface system;recognition memory experiments;single-trial EEG recording;single-trial identification;study item retrieval","","0","","15","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Information system of agricultural field experimentation in India","S. K. Sarkar; O. P. Khanduri","ICAR-Indian Agricultural Statistics Research Institute, New Delhi, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","1151","1155","Creation and maintenance of a computerized information system that not only manages agricultural field experiments data efficiently but also provides its statistical analysis is essential for researchers, planners and farmers. Generally data created by the researchers is collected, processed and stored in different physical locations and is poorly disseminated. Data is usually retained at the level of each physical entity for organizational use. An adequate analysis of agricultural field experiments and interpretation of results over time and space seems to be lacking to effectively use it for agricultural policy planning and other purposes. An attempt has been made by creating a computerised Agricultural Field Experiments Information System (AFEIS) at ICAR-Indian Agricultural Statistics Research Institute (IASRI). This system has been aimed at addressing this urgent need by establishing a single, centralized data storage and retrieval system for agricultural field experimental data generated in the country. Development of this system will help the agricultural research workers, planners as well as the farmers to a great extant in this direction.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100428","AFEIS","Agriculture;Computers;Databases;Information systems;Servers;Software;Statistical analysis","agriculture;information retrieval;information storage;information systems","India;agricultural field experimentation;agricultural policy planning;data retrieval system;data storage;information system","","0","","5","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Retrieving abstract information from multi-party conversations","S. Ranathunga","Department of Computer Science and Engineering, University of Moratuwa Katubedda, Sri Lanka","2014 14th International Conference on Advances in ICT for Emerging Regions (ICTer)","20150416","2014","","","221","227","This paper presents the use of dialog acts and addressee information in extracting domain-specific abstract information from multi-party conversations. Identification of dialog acts and addressee information is done in a domain-independent manner. This information is then used with a domain-specific rule set for identifying abstract information in chat conversations. To retrieve abstract information from a conversation in a new domain, the only requirement is to define a new rule set. This eliminates the need of domain-specific corpora. This paper also presents an improved version of a commonly used addressee recognition algorithm.","","CD-ROM:978-1-4799-7729-1; Electronic:978-1-4799-7732-1; POD:978-1-4799-7733-8","10.1109/ICTER.2014.7083905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7083905","addressee recognition;dialog act recognition;natural language processing","Boolean functions;Data structures;Noise measurement","abstracting;information retrieval;interactive systems;learning (artificial intelligence)","abstract information retrieval;addressee information;addressee recognition algorithm;chat conversations;dialog acts;domain-specific abstract information;domain-specific rule set;machine learning;multiparty conversations;rule-based algorithms","","0","","20","","","10-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Human Aided Text Summarizer ""SAAR"" Using Reinforcement Learning","C. Prakash; A. Shukla","Indian Inst. of Inf. Technol. & Manage. Gwalior, Gwalior, India","2014 International Conference on Soft Computing and Machine Intelligence","20150406","2014","","","83","87","Due to information revolution, huge amount of data is available over internet but retrieving correct and relevant data is not an easy task. The information retrieval from search engines is still far greater than that a user can handle and manage. Thus there is need of presenting the information in an abstract way so that one can easily infer the meaning without reading the whole document. In this paper, Human aided text summarizer ""SAAR"" is being proposed for single document. From the document, a term-sentence matrix is generated. The entries in the matrix are weight from Reinforcement Learning. Thus generated summary is shown to the user and if the user approve it then it is the final summary, otherwise new summary is generated as per the user feedback in form of keywords. Results of experiments on DUC2006 documents indicate that the performance of the proposed approach compares very favorably with other approaches in terms of precision, recall, and F-score.","","Electronic:978-1-4673-6751-6; POD:978-1-4799-7879-3","10.1109/ISCMI.2014.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079359","Automated Text Summarization;Human Aided Text summarizer ""Saar"";abstractive summarization technique;information gain;single document;text summarization","Abstracts;Hidden Markov models;Learning (artificial intelligence);Pragmatics;Search engines;Vectors","Internet;information retrieval;learning (artificial intelligence);matrix algebra;search engines;text analysis","Internet;SAAR;human aided text summarizer;information retrieval;information revolution;reinforcement learning;search engines;term-sentence matrix","","0","","16","","","26-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Extraction of reported speeches from Arabic Lebanese newspapers","M. Al-Hajj; G. Mourad","Center for Language Sci. & Commun., Lebanese Univ., Beirut, Lebanon","2015 Fifth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)","20150601","2015","","","125","128","This paper presents ongoing work on the extraction of Arabic reported speech, made by Lebanese politicians, from Arabic Lebanese newspapers. This work is part of a functional system for extraction, presentation and archiving of reported speech made by Lebanese politicians, which constitutes a valuable resource for political analysts, press agents, company researchers and political actors. The system automatically identifies about 280 reported speeches per day from about 1,000 newspaper articles, together with their referents, all are correctly identified as reported speech but only about 200 are correctly referred to their referents. The correctly identified reported speeches that refer to the correctly identified referents are then submitted to a web-based application, which is publicly accessible at http://citations-explorer.com/lpc/.","","CD-ROM:978-1-4799-4130-8; Electronic:978-1-4799-4129-2; POD:978-1-4799-4128-5","10.1109/DICTAP.2015.7113184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113184","Arabic Language Processing;Contextual Exploration","Companies;Data mining;Internet;Manuals;Pragmatics;Presses;Speech","Internet;information retrieval;natural language processing;speech processing","Arabic Lebanese newspapers;Arabic reported speech extraction;Lebanese politicians;Web-based application;company researchers;functional system;newspaper articles;political actors;political analysts;press agents;reported speech archiving;reported speech presentation","","0","","","","","April 29 2015-May 1 2015","","IEEE","IEEE Conference Publications"
"SmartQ: A question and answer system for supplying high-quality and trustworthy answers","Y. Lin; H. Shen","Department of Electrical and Computer Engineering, Clemson University, South Carolina 29631, USA","2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS)","20150430","2014","","","744","751","Question and Answer (Q&A) systems aggregate the collected intelligence of all users to provide satisfying answers for questions. A well-developed Q&A system should incorporate features such as high question response rate, high answer quality, a spam-free environment for users. Previous works use reputation systems to achieve the goals. However, these reputation systems evaluate a user with an overall rating for all questions the user has answered regardless of the question categories, thus the reputation score does not accurately reflect the user's ability to answer a question in a specific category. We propose SmartQ: a reputation based Q&A System. SmartQ employs a category and theme based reputation management system to evaluate users' willingness and capability to answer various kinds of questions. The reputation system facilitates the forwarding of a question to favorable experts, which improves the question response rate and answer quality. Also, SmartQ incorporates a lightweight spammer detection method to identify potential spammers. Our trace-driven simulation on PeerSim demonstrates the effectiveness of SmartQ in providing a good user experience. We then develop a real application of SmartQ and deploy it for use in a student group in Clemson University. The user feedback shows that SmartQ can provide high-quality answers for users in a community.","1521-9097;15219097","Electronic:978-1-4799-7615-7; POD:978-1-4799-7616-4","10.1109/PADSW.2014.7097877","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097877","Question and answer system;Real application;question category;reputation system;spammer detection","Aggregates;Communities;Delays;Fans;IEEE Potentials;Mathematical model;Social network services","question answering (information retrieval);trusted computing","Clemson University;PeerSim;SmartQ;high-quality answers;lightweight spammer detection method;question and answer system;reputation based Q&A system;reputation score;spam-free environment;theme based reputation management system;trace-driven simulation;trustworthy answers;user experience;user willingness evaluation","","0","","29","","","16-19 Dec. 2014","","IEEE","IEEE Conference Publications"
"Migrated Question Prediction on StackExchange","S. Lal; D. Correa; A. Sureka","JIIT, Noida, India","2014 21st Asia-Pacific Software Engineering Conference","20150423","2014","2","","35","38","Stack Exchange (SE) is a network of popular Community based Question and Answering (CQA) websites. Each SE Q&A website is created to address questions on specific user interest or domain. However, often users post questions on SE websites that do not match the domain of the website. Such questions are considered as Off-topic for the origin site. Off-topic questions must be detected and migrated to more appropriate On-Topic site in SE network. Off-topic questions are migrated manually to other sites by moderators or experts users (through a voting process). The process of migrating questions from one site to other is known as Question Migration. We study migrated questions on SE Q&A website. We identify several distinguishing features of migrated questions and propose a machine learning based framework to predict migrating questions. Effectiveness of proposed model is tested on five SE Q&A sites. Experimental results demonstrate that the proposed model is effective (maximum accuracy of 73%) in predicting migrating questions.","1530-1362;15301362","Electronic:978-1-4799-7426-9; POD:978-1-4799-7427-6","10.1109/APSEC.2014.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091212","Mining Software Repositories;Mining User Generated Content;Question Migration Detection;Stack Overflow","Accuracy;Communities;Image edge detection;Manuals;Market research;Predictive models;Uniform resource locators","Internet;Web sites;learning (artificial intelligence);question answering (information retrieval)","Community based Question and Answering Web site;SE Q&A Web site;StackExchange;machine learning;migrated question prediction","","0","","3","","","1-4 Dec. 2014","","IEEE","IEEE Conference Publications"
"Lightweight ICT Approaches to Hydro-Meteorological Data Issues","A. Quarati; A. Clematis; G. Paschina; A. Parodi; T. Bedrina","IMATI, Genoa, Italy","2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing","20150423","2015","","","759","763","Earth science disciplines have imaginary borders. Earth systems are connected and work integrally. Therefore for geosciences researchers it is critical to find, analyze and publish data across domains. Unfortunately, while searching for and accessing enormous amount of heterogeneous data, scientists and professionals often tackle various types of obstacles that hinder their daily activity. Based on a survey on international initiatives in the field of Hydro-Meteorological research, the paper presents a lightweight approach to answer weather-data issues related to data accessing and retrieving, as well as it briefly describe the OGC proposal to cope with interoperability requirements and introduces a technical solution to deal with high volumes of Hydro-Meteorological sensor data.","1066-6192;10666192","Electronic:978-1-4799-8491-6; POD:978-1-4799-8492-3","10.1109/PDP.2015.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092805","Hadoop/MapReduce;Hydro-Meteorological Data;georeferenced mashup;interoperability data issues;sensors data","Data visualization;Humidity;Interoperability;Mashups;Real-time systems;Standards","Web services;data analysis;geographic information systems;geophysics computing;information retrieval;meteorology;open systems;publishing","Earth science disciplines;Earth systems;ICT approach;OGC proposal;data accessing;data analysis;data publishing;data retrieving;hydro-meteorological data issues;interoperability requirements;weather Web services;weather-data issues","","0","","15","","","4-6 March 2015","","IEEE","IEEE Conference Publications"
"Modeling Web Attachment Storage for Web Applications","V. Jain; A. Kolambkar","Center for Dev. of Adv. Comput., Mumbai, India","2014 21st Asia-Pacific Software Engineering Conference","20150423","2014","1","","98","102","Web application performance plays vital role in application usability and adaptability to its intended users. There are many factors, which attributes towards overall performance enhancements. One of them is that how efficiently a web application under peak load stores or retrieves the web-attached documents. In this paper, we have described a document storage and retrieval technique for improving web application performance. A technique suggested for the document storage purpose is based on the verification of results performed with various types and sizes of document attachments. Applying the suggested technique has shown an overall performance improvement for applications with web attachments.","1530-1362;15301362","Electronic:978-1-4799-7426-9; POD:978-1-4799-7427-6","10.1109/APSEC.2014.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091297","Document Attachments;Document Storage;Performance;Performance Modeling;Performance Technique;Reliability;Web Application Modeling;Web Application Performance;Web Attachments;Web Document Attachment;Web Performance;Web Service Performance","Computational modeling;Conferences;Performance evaluation;Testing;Web servers","Internet;information retrieval;storage management","Web attachment storage;application adaptability;application usability;document retrieval technique;document storage technique","","0","","17","","","1-4 Dec. 2014","","IEEE","IEEE Conference Publications"
"Recommender Systems Using Category Correlations Based on WordNet Similarity","S. M. Choi; D. J. Cho; Y. S. Han; K. L. Man; Y. Sun","Dept. of Comput. Sci., Yonsei Univ., Seoul, South Korea","2015 International Conference on Platform Technology and Service","20150406","2015","","","5","6","Recently, many internet users are not only information consumers but also information providers. There is lots of information on the Web and most people can search information what they want through the Web. One problem of the large number of data in the Web is that we often spend most of our time to find a correct result from search results. Thus, people start looking for a better system that can suggest relevant information instead of letting users go through all search results: We call such systems recommendation systems. Conventional recommendation systems are based on collaborative filtering (CF) approaches. The CF approaches have two problems: sparsity and cold-start. Some researchers have studied to alleviate the problems in CF approaches. One of them is the recommendation algorithm based on category correlations. In this study, researchers utilize genre information in movie domain as category. They have drawn genre correlations using genre counting method. This approach can alleviate the user-side cold-start problems, however, there exists one problem that extensions of the approach are less likely. If a domain has singular category, then we cannot apply previous approaches. It means that we cannot draw category correlations. Because of this reason, we propose a novel approach that can draw category correlations for not only multiple categories but also singular one. We utilize word similarities provided by WordNet.","","CD-ROM:978-1-4799-1887-4; Electronic:978-1-4799-1888-1; POD:978-1-4799-1889-8","10.1109/PlatCon.2015.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079614","","Collaboration;Correlation;Databases;Filtering;Fuzzy systems;Internet;Motion pictures","Internet;entertainment;information retrieval;recommender systems","Internet;Web;WordNet similarity;category correlations;genre counting method;genre information;information consumers;information providers;movie domain;recommendation algorithm;recommendation systems;user-side cold-start problems","","0","","7","","","26-28 Jan. 2015","","IEEE","IEEE Conference Publications"
"Adaptive physical layer security using code bank of sequences for CDMA","P. Pillai; S. Kharat; C. Warty; S. Nema; S. Spinsante","Dept. of Electronics and Communication, Usha Mittal Institute of Technology, SNDT Womens University, Mumbai, India","2015 IEEE Aerospace Conference","20150608","2015","","","1","6","Wireless security is an important concern in todays technological world. Wireless devices are used to access data and private applications. From broadband to Wi-Fi, 3G to LTE Advanced, WiMAX to satellite communication every network demands on-the-air security from attacks. Tapping or Jamming attacks leak the secret data, while Service Disruption Attacks affecting QoS (Quality of Service) are relatively easy to perform. In CDMA, the channel and antenna dependent attacks are quite critical to avoid because of its wide bandwidth usage. The critical exchange of time and frequency parameters makes the physical layer elements vulnerable to security related attacks. In order to enable data security and secrecy, there is need of signal protection at the physical layer of CDMA system. Gold codes, M-sequences, OVSF and De-Bruijn sequences were used individually in wireless systems for scrambling purposes in previous proposals. These codes have their own advantages and disadvantages, when channel bandwidth and noise conditions change. This paper proposes a system which would select scrambling codes from a bank of all these mentioned codes depending upon the Signal to Noise Ratio (SNR) or Channel State Information (CSI). This code bank technique is shown as a highly practical solution in selection of proper code for mitigation of attacks and hence, to provide security at the physical layer of CDMA.","1095-323X;1095323X","Electronic:978-1-4799-5380-6; POD:978-1-4799-5381-3; USB:978-1-4799-5378-3","10.1109/AERO.2015.7119036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119036","CDMA system;Code bank;Physical layer security;Wireless attacks","Error probability;Gold;Multiaccess communication;Receivers;Security;Signal to noise ratio","Gold codes;code division multiple access;information retrieval;m-sequences;quality of service;security of data;telecommunication security;wireless channels","3G-LTE Advanced;CDMA;CSI;De-Bruijn sequences;Gold codes;OVSF;QoS;SNR;WiMAX-satellite communication;broadband-Wi-Fi;channel bandwidth;channel state information;code bank;data access;data secrecy;data security;jamming attacks;m-sequences;noise conditions;on-the-air security;quality of service;service disruption attacks;signal protection;signal to noise ratio;tapping attacks;wide bandwidth usage;wireless devices;wireless security","","1","","12","","","7-14 March 2015","","IEEE","IEEE Conference Publications"
"Smartphone's popularity measurement by investigating Twitter profiles","B. Shahzad; E. Alwagait","College of Computer & Information Sciences, King Saud University, Riyadh, Saudi Arabia","2013 Third World Congress on Information and Communication Technologies (WICT 2013)","20150601","2013","","","347","350","Social media has obtained significant importance in the recent years and is being effectively used for the propagation of information and obtaining the user feedback. This paper reviews the popularity of the two leading smartphone brands, Apple and Samsung. By considering their Twitter profile, the comparisons have been made on the location, number of followers and language and a continental assessment has been presented. The data retrieval was made possible by developing an API that crawled data of the required Twitter accounts. The paper presents the results of this experimental review.","","Electronic:978-1-4799-3230-6; POD:978-1-5090-0010-4","10.1109/WICT.2013.7113093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113093","Mobile Technology;Samsung vs. Apple;Smartphone Popularity","Australia;Blogs;Data visualization;Lead;Twitter","application program interfaces;information retrieval;smart phones;social networking (online)","API;Apple smart phone;Samsung smart phone;Twitter accounts;Twitter profiles;continental assessment factor;data crawling;data retrieval;follower number factor;information propagation;language factor;location factor;smart phone popularity measurement;social media;user feedback","","1","","13","","","15-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Oracle Database In-Memory: A dual format in-memory database","T. Lahiri; S. Chavan; M. Colgan; D. Das; A. Ganesh; M. Gleeson; S. Hase; A. Holloway; J. Kamp; T. H. Lee; J. Loaiza; N. Macnaughton; V. Marwah; N. Mukherjee; A. Mullick; S. Muthulingam; V. Raja; M. Roth; E. Soylemez; M. Zait","Server Technologies, Oracle America, 400 Oracle Parkway, Redwood Shores, CA 94065, USA","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","1253","1258","The Oracle Database In-Memory Option allows Oracle to function as the industry-first dual-format in-memory database. Row formats are ideal for OLTP workloads which typically use indexes to limit their data access to a small set of rows, while column formats are better suited for Analytic operations which typically examine a small number of columns from a large number of rows. Since no single data format is ideal for all types of workloads, our approach was to allow data to be simultaneously maintained in both formats with strict transactional consistency between them.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113373","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113373","","Acceleration;Buffer storage;Indexes;Memory management;Optimization;Servers","data mining;database indexing;information retrieval;storage management;transaction processing","OLTP workload;Oracle database in-memory;analytic operation;column format;data access;dual format in-memory database;index;row format;transactional consistency","","1","","11","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Some issues of mood classification for Chinese popular music","J. Zhang; X. Huang; L. Yang; Y. Xu","School of Computing, Communication University of China, Beijing, China","2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)","20150625","2015","","","1193","1198","Music mood can express inherent emotional meaning of a music clip. It's used in music recommendation, music information retrieval, and music classification. In this paper, we follow the Thayer's emotion plane, and extract three different features sets to apply the Chinese popular music mood-detection. We find that the distribution of music moods is quite different from west popular music. Moreover, some feature extract tools which are developed for west popular music aren't suitable for Chinese popular music. In our experiment, we show that the valence dimension is harder to classification (best average precision: 64%) than arousal dimension (best average precision: 86%). Finally the support vector machine, k-nearest neighbors and Naïve Bayes algorithm are used to classifier the music mood. The performance of `exuberance' mood is totally satisfactory, while the `depression' and `contentment' mood are hard to distinguish.","0840-7789;08407789","Electronic:978-1-4799-5829-0; POD:978-1-4799-5830-6; USB:978-1-4799-5828-3","10.1109/CCECE.2015.7129446","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129446","","Feature extraction;Mood;Multiple signal classification;Rhythm;Timbre","Bayes methods;emotion recognition;feature extraction;information retrieval;music;pattern classification;recommender systems;support vector machines","Chinese popular music;Chinese popular music mood-detection;Naive Bayes algorithm;Thayer's emotion plane;contentment mood;depression mood;feature set extraction;k-nearest neighbors;mood classification issues;music classification;music clip emotional meaning;music information retrieval;music mood;music recommendation;support vector machine","","1","","29","","","3-6 May 2015","","IEEE","IEEE Conference Publications"
"The Research of TV Program Category Preference Based on TagPageRank Algorithm","X. Wang; F. L. Yin; J. P. Chai; B. B. Zhang","Inf. Eng. Sch., Commun. Univ. of China, Beijing, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","2","","319","323","Aiming to solve the problem of information overload caused by rich resources of TV programs, This paper put forward attraction index of TV programs and analyze user preference to program category, so as to fully tap the potential information of TV users and provide personalized service. Attraction index of TV programs combines Uses and Gratification Theory and China TV program Tagging System, and come true through Tag PageRank algorithm. The analysis of simulation based on the TV user rating data verify the feasibility of the algorithm.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081997","TagPageRank algorithm;Uses and Gratification Theory;attraction index of TV programs;flat tagging system;user preference to program category","Algorithm design and analysis;Analytical models;Media;Standards;Switches;TV;Tagging","information retrieval;telecommunication computing;television broadcasting","China TV program tagging system;TV program category preference;TV programs attraction index;TV user rating data;TagPageRank algorithm;information overload;personalized service;simulation analysis;television program;user preference;uses and gratification theory","","0","","8","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Using Multi-Locators to Increase the Robustness of Web Test Cases","M. Leotta; A. Stocco; F. Ricca; P. Tonella","Dipt. di Inf., Univ. di Genova, Genoa, Italy","2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)","20150507","2015","","","1","10","The main reason for the fragility of web test cases is the inability of web element locators to work correctly when the web page DOM evolves. Web elements locators are used in web test cases to identify all the GUI objects to operate upon and eventually to retrieve web page content that is compared against some oracle in order to decide whether the test case has passed or not. Hence, web element locators play an extremely important role in web testing and when a web element locator gets broken developers have to spend substantial time and effort to repair it. While algorithms exist to produce robust web element locators to be used in web test scripts, no algorithm is perfect and different algorithms are exposed to different fragilities when the software evolves. Based on such observation, we propose a new type of locator, named multi-locator, which selects the best locator among a candidate set of locators produced by different algorithms. Such selection is based on a voting procedure that assigns different voting weights to different locator generation algorithms. Experimental results obtained on six web applications, for which a subsequent release was available, show that the multi-locator is more robust than the single locators (about -30% of broken locators w.r.t. the most robust kind of single locator) and that the execution overhead required by the multiple queries done with different locators is negligible (2-3% at most).","2159-4848;21594848","Electronic:978-1-4799-7125-1; POD:978-1-4799-7126-8","10.1109/ICST.2015.7102611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102611","","Maintenance engineering;Navigation;Robustness;Software;Software algorithms;Testing;Web pages","Internet;graphical user interfaces;information retrieval;program testing","GUI object;Web element locator;Web page DOM;Web page content retrieval;Web test case;locator generation algorithm;software testing;voting procedure","","7","","22","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"A wearable and ubiquitous NFC wallet","A. E. Al-Chalabi; S. Essa; H. Shahzad; I. Damaj","","2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)","20150625","2015","","","152","157","Technology that is able to integrate the multitude of accounts into one safe, convenient, and wearable pass is an attractive modern setup. Such a technology would be required to have the ability to customize, and unify this information into a convenient and secure system. Since all of a user's accounts are stored in a single device, the act of carrying around copious amounts of smartcards becomes obsolete. The following prototype has three main elements: the wearable technology, a smart reader, and a web-based phone application. The wearable technology is the access point for the user, the readers retrieve the required information, while the application allows the user to modify the information they wish to store. NFC Wallet is ubiquitous; the software is web-enabled so that the user can control it using smart phones, tablets, laptops and other computing devices. The system provides a true pervasive computing experience. This paper presents the organization, architecture, hardware/software interface design, evaluation and analysis of the proposed system.","0840-7789;08407789","Electronic:978-1-4799-5829-0; POD:978-1-4799-5830-6; USB:978-1-4799-5828-3","10.1109/CCECE.2015.7129177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129177","","Databases;Firewalls (computing);Google;Logic gates;Servers;Smart phones","Internet;information retrieval;near-field communication;smart cards;ubiquitous computing","Web-based phone application;Web-enabled software;computing devices;hardware-software interface design;information retrieval;laptops;pervasive computing experience;smart reader;smartcards;tablets;ubiquitous NFC wallet;wearable NFC wallet;wearable technology","","1","","11","","","3-6 May 2015","","IEEE","IEEE Conference Publications"
"Analysis of visual perceptual patterns on screen using eyetracker technology","M. Malčík; E. Mechlová; Z. Sikorová; A. Mentel","VSB - Technical University of Ostrava, Czech Republic","2014 IEEE 12th IEEE International Conference on Emerging eLearning Technologies and Applications (ICETA)","20150514","2014","","","311","317","According to current researches, individual differences in eye movement patterns may be related to different ways of text processing, to comprehension difficulties, etc. They also depend on the nature of the text. Particular question is how reading takes place in case of using figurative (visual) language, e.g. in case of metaphors, irony, or fixed phrases (phraseologisms). Based on other researches, it is evident that the development level of executive functions of each individual is strongly tied to their sociocultural background, especially to the parenting style of their family; on the other hand, differences in executive function significantly affect a person's performance at school. The notable part for the aim of this paper, however, is the direct link between executive functions and eye movement, i.e. on the basis of eye tracking it is possible to make direct, unaltered conclusions on executive functions [1]. Electronic screens on laptop and tablet computers and smartphones are being used for reading text, often while multitasking [14]. The question arises whether reading from a screen is as effective as the reading from textbooks. One of the aims of the paper is to verify the visual patterns of information retrieval from screen for problem comprehension and solving using eyetracking technology.","","CD-ROM:978-1-4799-7738-3; Electronic:978-1-4799-7740-6; POD:978-1-4799-7741-3","10.1109/ICETA.2014.7107603","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107603","eyetracking;learning style;perceptual patterns;reading literacy","Art;Conferences;Electronic learning;Testing;Tracking;Visualization","computer aided instruction;computer literacy;gaze tracking;information retrieval;screens (display)","electronic screens;executive functions;eye movement patterns;eye tracker technology;figurative language;information retrieval;laptop;reading literacy;smartphones;sociocultural background;tablet computers;text processing;visual perceptual pattern analysis","","1","","15","","","4-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Criteria and technique to choose a good ρ parameter for the D-index","Y. Hanyf; H. Silkan; H. Labani","Universit&#x00E9; Chouaib Doukkali, Facult&#x00E9; des Sciences, Laboratoire LAMAPI, El Jadida","2015 Intelligent Systems and Computer Vision (ISCV)","20150514","2015","","","1","6","D-index is among the most efficient similarity search indexes, its performance dramatically depends on the choice of the ρ parameter. Although the importance of this parameter, there are no techniques or criteria proposed to choose an adequate ρ value. In this paper, we propose a criteria and a technique that ensure a good choice of ρ, and we use this technique to modify the original D-index to make it able to choose an adequate value of ρ. The experiments show that the modified D-index is more efficient when the exclusion set is small and the comparison between original and modified D-index proves that the modified D-index presents a good improvement in terms of the search cost.","","Electronic:978-1-4799-7511-2; POD:978-1-4799-7512-9","10.1109/ISACV.2015.7106169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106169","D-index;Index structures;Metric Access Methods;Metric space;Multimedia retrieval","Computational efficiency;Extraterrestrial measurements;Indexes;Partitioning algorithms;Search problems","database indexing;information retrieval;multimedia databases","modified D-index;multimedia retrieval;similarity search indexes","","0","","12","","","25-26 March 2015","","IEEE","IEEE Conference Publications"
"A Reading Answering System Model for Vietnamese Language","S. T. Pham; D. T. Nguyen","Dept. of Inf. Sci. & Eng., Vietnam Nat. Univ. - Ho Chi Minh City, Ho Chi Minh City, Vietnam","2014 8th Asia Modelling Symposium","20150406","2014","","","170","174","Based on our previous researches for building a Reading Answering System Model (RASM) which can read many simple news titles of ICTNEWS (http://ictnews.vn/) to answer related Vietnamese questions. The construction of RASM is based on an approach of computational semantics. In this paper we focus on introducing our approach to build the RASM, the general architecture, and functional operations of RASM. In particular, we present new experimental results to evaluate the performance of our system in practice. We tested the system on 8 datasets composing 403 Vietnamese testing questions, and a vocabulary of 1142 lexicons. In experiments, the precision of our system is 66.63%.","2376-1164;23761164","Electronic:978-1-4799-6487-1; POD:978-1-4799-6488-8","10.1109/AMS.2014.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079294","Computational Semantics;Question Answering System;Reading Answering System;Semantic Representation","Cities and towns;Computational modeling;Computer architecture;Natural language processing;Semantics;Syntactics;Testing","natural language processing;question answering (information retrieval)","ICTNEWS;RASM;Vietnamese language;Vietnamese questions;functional operations;reading answering system model","","1","","11","","","23-25 Sept. 2014","","IEEE","IEEE Conference Publications"
"Modeling Multi-topic Information Diffusion in Social Networks Using Latent Dirichlet Allocation and Hawkes Processes","J. C. L. Pinto; T. Chahed","Inst. Mines-Telecom, Telecom SudParis, E&#x0301;vry, France","2014 Tenth International Conference on Signal-Image Technology and Internet-Based Systems","20150409","2014","","","339","346","We present in this paper a framework to model information diffusion in social networks based on linear multivariate Hawkes processes and the latent Dirichlet allocation topic model. Our model exploits the effective broadcasting times of information by users and a fuzzy scheme of information dissemination, where users broadcast information as a mixture of different latent topics, guaranteeing thus a more realistic view of the information diffusion process. The proposed model takes into consideration not only interactions between users but also interactions between topics, which provides a deeper analysis of influences in social networks. We provide an estimation algorithm based on nonnegative matrix factorization techniques, which are coupled together with a modified collapsed Gibbs sampler and a modified variational Bayes method. This allows a more data-driven estimation of hidden influences in social networks.","","Electronic:978-1-4799-7978-3; POD:978-1-4799-7979-0","10.1109/SITIS.2014.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081568","Hawkes Processes;Latent Dirichlet Allocation;Nonnegative Matrix Factorization;Social Networks","Bayes methods;Broadcasting;Estimation;Kernel;Random variables;Resource management;Social network services","Bayes methods;fuzzy set theory;information retrieval;matrix decomposition;social networking (online)","broadcasting;collapsed Gibbs sampler;data-driven estimation;fuzzy scheme;information dissemination;latent Dirichlet allocation topic model;linear multivariate Hawkes process;multitopic information diffusion;nonnegative matrix factorization technique;social network;variational Bayes method","","0","","48","","","23-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"What Can Pictures Tell Us About Web Pages? Improving Document Search Using Images","S. Rodriguez-Vaamonde; L. Torresani; A. W. Fitzgibbon","Tecnalia, Zamudio, Bizkaia, Spain","IEEE Transactions on Pattern Analysis and Machine Intelligence","20150505","2015","37","6","1274","1285","Traditional Web search engines do not use the images in the HTML pages to find relevant documents for a given query. Instead, they typically operate by computing a measure of agreement between the keywords provided by the user and only the text portion of each page. In this paper we study whether the content of the pictures appearing in a Web page can be used to enrich the semantic description of an HTML document and consequently boost the performance of a keyword-based search engine. We present a Web-scalable system that exploits a pure text-based search engine to find an initial set of candidate documents for a given query. Then, the candidate set is reranked using visual information extracted from the images contained in the pages. The resulting system retains the computational efficiency of traditional text-based search engines with only a small additional storage cost needed to encode the visual information. We test our approach on one of the TREC Million Query Track benchmarks where we show that the exploitation of visual content yields improvement in accuracies for two distinct text-based search engines, including the system with the best reported performance on this benchmark. We further validate our approach by collecting document relevance judgements on our search results using Amazon Mechanical Turk. The results of this experiment confirm the improvement in accuracy produced by our image-based reranker over a pure text-based system.","0162-8828;01628828","","10.1109/TPAMI.2014.2366761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945905","Image Content;Multimedia Search;Ranking;Web Pages;Web Search;document ranking;multimedia search;search engines","Accuracy;Image recognition;Search engines;Training;Vectors;Visualization;Web pages","Web sites;hypermedia markup languages;information retrieval;search engines;text analysis","Amazon Mechanical Turk;HTML document;TREC Million Query Track benchmarks;Web pages;Web search engines;Web-scalable system;candidate set reranking;computational efficiency;document searching;image-based reranker;keyword-based search engine;semantic description;text-based search engines","","2","","32","","20141104","June 1 2015","","IEEE","IEEE Journals & Magazines"
"The 3D Model Retrieval Based on Local Features","L. Huo; X. Lv; K. Zhang; Z. Li","Beijing Key Lab. of Internet Culture & Digital Dissemination Res., Beijing Inf. Sci. & Technol. Univ., Beijing, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","2","","400","403","When using global features for 3D model retrieval, we ignore the local similarity of 3D model. To solve this problem, we propose a 3D model retrieval method based on local features. First, calculate the normal of each vertex, get the normal projection of each vertex and identify salient points according to the SURF feature of the projection. Extract the local feature around the salient points obtained, and use the local feature to update the global similarity. The experimental results show that this method can effectively improve the 3D model retrieval precision.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7082016","3D model retrieval;Local feature;SURF;salient point","Analytical models;Computational modeling;Feature extraction;Marine animals;Shape;Solid modeling;Three-dimensional displays","feature extraction;information retrieval","3D model retrieval;SURF feature;local feature extraction;salient points","","0","","9","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Business Intelligence &amp; Geo Tracking - A Novel Mining Technique to Identify Alerts and Pattern Analysis","M. V. Kamal; D. Vasumathi","Univ. of Pet. & Energy Studies, Dehradun, India","2014 2nd International Symposium on Computational and Business Intelligence","20150611","2014","","","53","57","Web mining plays vital role in day-to-day applications to improve intelligence of web in the context of business must be able to identify useful business intelligence. To achieve our model in web engineering, we are using mining techniques for next generation business intelligence development. In this research our approach identifies the weblogs error reports using comprehensive algorithms, applies the mining techniques to detect noisy and integrates the different models, finally our information patterns satisfies the need of client inputs. For web engineering retrieval system, list of web log bugs and web architecture, the system uses mining techniques to explore valuable web data patterns in order to meet better projects inputs and higher quality web systems that delivered on time. Our research uses association and machine learning applied to web architecture model pertaining to source code mining implementation tools improves software debugging business rules for novel projects and also presents strategies for efficient study text, graph mining. Presents the Geo Tracking system to identify messages from terrorist or threat persons and also from hackers detects the negative rates and improves the high positive which increases the quality of Government Private and Public sectors.","","Electronic:978-1-4799-7552-5; POD:978-1-4799-7553-2","10.1109/ISCBI.2014.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119533","Business Intelligence;Geo-Tracking;Pattern Analysis;Text Mining;Web mining","Business;Databases;Text mining;Web mining;Web pages","Web sites;competitive intelligence;data integration;data mining;government data processing;information retrieval;learning (artificial intelligence);program debugging;source code (software);terrorism","Web architecture;Web architecture model;Web data patterns;Web engineering retrieval;Web logs error reports;Web mining;business intelligence development;client inputs;geo tracking system;government private sectors;government public sectors;graph mining;hackers;information pattern;machine learning;software debugging business rules;source code mining implementation tools;terrorist","","0","","6","","","7-8 Dec. 2014","","IEEE","IEEE Conference Publications"
"Examination of the theta index during solving IT issues","J. Depešová; H. Noga; M. P. Silarska; K. Pytel","Department of Technology and Information Technology, UKF, Nitra, Slovakia","2014 IEEE 12th IEEE International Conference on Emerging eLearning Technologies and Applications (ICETA)","20150514","2014","","","361","366","The theta waves are formed in the thalamus and in the limbic system. It seems, it is linked with a data retrieval from the memory along with ability to impulse control. These waves dominate in EEG scan from 6 months of life till the age of 6-7. At elderly people the dominance of these waves can be related to drowsiness and excluding from discussion and fully awareness of environment. In the theta state person can think very creatively because it's related with the hypnologic state of mind. These waves can be also observed during visualization. The theta state lies on the edge of our consciousness. In Biofeedback, they are associated with the deepest level of meditation. The Theta is also considered as entrance to memory and learning ability. [1-4] Theta meditation increase creativity and allow learning faster. Theta reduce stress level, unlock the understanding, and other none physical senses. It also helps to release the endorphins, strengthening the immune system.","","CD-ROM:978-1-4799-7738-3; Electronic:978-1-4799-7740-6; POD:978-1-4799-7741-3","10.1109/ICETA.2014.7107611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107611","","Biological control systems;Biomedical monitoring;Electroencephalography;Indexes;Pediatrics;Rhythm;Training","behavioural sciences computing;electroencephalography;geriatrics;information retrieval;medical disorders;neurophysiology","EEG scan;IT issues;biofeedback;consciousness;data retrieval;elderly people;hypnologic state;immune system;impulse control;learning ability;meditation;memory ability;theta index examination;visualization","","0","","19","","","4-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"A data mining approach to predict users' Next question in QA system","R. Madaan; A. K. Sharma; A. Dixit","Department of Computer Engineering, Y.M.C.A.U.S.T, Faridabad, Haryana, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","211","215","In a Question Answering system, the user submits a question and waits for the answer as the response. If the system is capable of predicting the user's future interest as the next question, its performance will improve greatly. This paper predicts users' future questions based on the current interaction records of the user with the system. Their current interactions with the system show what they are interested in. These interaction records are maintained in the form of Questions log from which the user sessions are extracted. Based on the user sessions, the system predicts the next question for which the user may become interested in near future. A sample Questions Log is selected for the purpose of performing experiments. The model of Association rule mining is applied to predict the future question of the user.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100247","A-priori algorithm;Association rule mining;Data mining;QA system;Search engines","Association rules;Computer architecture;Itemsets;Knowledge discovery;Search engines","data mining;human computer interaction;question answering (information retrieval)","QA system;association rule mining;data mining;question answering system;questions log;user interaction records;users next question prediction","","0","","11","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Improving Retrieval Efficacy of Homology Searches Using the False Discovery Rate","H. D. Carroll; A. C. Williams; A. G. Davis; J. L. Spouge","Department of Computer Science, Middle Tennessee State University, Murfreesboro, TN","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20150602","2015","12","3","531","537","Over the past few decades, discovery based on sequence homology has become a widely accepted practice. Consequently, comparative accuracy of retrieval algorithms (e.g., BLAST) has been rigorously studied for improvement. Unlike most components of retrieval algorithms, the E-value threshold criterion has yet to be thoroughly investigated. An investigation of the threshold is important as it exclusively dictates which sequences are declared relevant and irrelevant. In this paper, we introduce the false discovery rate (FDR) statistic as a replacement for the uniform threshold criterion in order to improve efficacy in retrieval systems. Using NCBI's BLAST and PSI-BLAST software packages, we demonstrate the applicability of such a replacement in both non-iterative (BLAST<sub>FDR</sub>) and iterative (PSI-BLAST<sub>FDR</sub>) homology searches. For each application, we performed an evaluation of retrieval efficacy with five different multiple testing methods on a large training database. For each algorithm, we choose the best performing method, Benjamini-Hochberg, as the default statistic. As measured by the threshold average precision, BLAST<sub>FDR</sub> yielded 14.1 percent better retrieval performance than BLAST on a large (5,161 queries) test database and PSI-BLAST<sub>FDR</sub> attained 11.8 percent better retrieval performance than PSI-BLAST. The C++ source code specific to BLASTFDR and PSI-BLASTFDR and instructions are available at http://www.cs.mtsu.edu/~hcarroll/blast_fdr/.","1545-5963;15455963","","10.1109/TCBB.2014.2366112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6940294","Homology search;false discovery rate;retrieval efficacy;uniform E-value thresholding","Bioinformatics;Computational biology;Databases;Histograms;Testing;Training","C++ language;bioinformatics;information retrieval;iterative methods;molecular configurations;proteins;query formulation;software packages","++ source code;BLAST software package;Benjamini-Hochberg method;E-value threshold criterion;FDR statistic;PSI-BLAST software package;false discovery rate;homology searches;iterative homology searches;noniterative homology searches;retrieval algorithms;retrieval efficacy;sequence homology;threshold average precision;uniform threshold criterion","0","0","","17","","20141030","May-June 1 2015","","IEEE","IEEE Journals & Magazines"
"Chronic Disease Management System Design Based on Cloud Storage Architecture","Y. Tu; Y. Huang; F. Yi","Dept. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou, China","2015 2nd International Conference on Information Science and Control Engineering","20150611","2015","","","654","658","Traditional Chinese medical (TCM) management system for chronic disease is designed based on distributed storage architecture. The system composed of three modules, namely, medical records collection module, information storage and processing module, and chronic disease education module. Among them, the patient information recorded in the collection module may come from three different information collection devices: computer, image acquisition, and cell-phone. Cloud storage technology is applied to integrate these records to a comprehensive chronic disease information management database. In the information processing module, statistical analysis, early warning assessment and patient guidance algorithms are designed for implementing active medical service, treatment program management, real-time monitoring and other functions. The chronic disease education module is a website, which provide chronic disease health knowledge to patient and help them achieve self-management.","","Electronic:978-1-4673-6850-6; POD:978-1-4673-6851-3","10.1109/ICISCE.2015.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120691","Traditional Chinese Medicine;chronic disease management system;cloud storage architecture","Cloud computing;Data mining;Diseases;Medical diagnostic imaging;Mobile communication","Web sites;biomedical education;cloud computing;diseases;information retrieval systems;medical information systems;statistical analysis;storage management","TCM management system;Traditional Chinese medical management system;active medical service;chronic disease education module;chronic disease health knowledge;chronic disease information management database;chronic disease management system design;cloud storage architecture;cloud storage technology;distributed storage architecture;early warning assessment;early warning assessment algorithms;information processing module;information storage module;medical record collection module;patient guidance algorithms;real-time monitoring;statistical analysis;treatment program management","","1","","8","","","24-26 April 2015","","IEEE","IEEE Conference Publications"
"Entity Resolution with crowd errors","V. Verroios; H. Garcia-Molina","Stanford University, USA","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","219","230","Given a set of records, an Entity Resolution (ER) algorithm finds records that refer to the same real-world entity. Humans can often determine if two records refer to the same entity, and hence we study the problem of selecting questions to ask error-prone humans. We give a Maximum Likelihood formulation for the problem of finding the “most beneficial” questions to ask next. Our theoretical results lead to a lightweight and practical algorithm, bDENSE, for selecting questions to ask humans. Our experimental results show that bDENSE can more quickly reach an accurate outcome, compared to two approaches proposed recently. Moreover, through our experimental evaluation, we identify the strengths and weaknesses of all three approaches.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113286","","Erbium","data handling;maximum likelihood estimation;question answering (information retrieval);records management","bDENSE;computer algorithms;crowd errors;entity resolution algorithm;error-prone humans;maximum likelihood formulation;question selection;record detection;record finding;strength identification;weakness identification","","5","","25","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"A review: FPGA based word matching stage of BLASTN","S. R. Bhalekar; P. G. Chilveri","Department of E&TC, Smt. Kashibai Navale College of Engineering, Vadgaon(BK), Pune, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","4","Molecular Biologists use Basic Local Alignment Search Tool (BLAST) as one of the most popular sequences analysis tool. BLAST is a design used to efficiently find similar regions between the two sequences that have biological significance. As the size of genome sequences is increasing rapidly, the computation time of BLAST is continuously increasing to perform a complete genomic database search. Hence there is a need to accelerate this search process. In this paper, a new approach is proposed to scan the genomic sequence databases of Deoxyribonucleic Acid (DNA) using field programmable gate array (FPGA) based hardware. To accelerate the word matching stage of BLASTN, specifically designed for DNA sequences, and to derive its efficient architecture, a reconfigurable architecture is proposed.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087107","BLASTN;Bloom Filter;DNA sequences;Genomic Sequence analysis;reconfigurable computing","Acceleration;Bioinformatics;DNA;Databases;Field programmable gate arrays;Genomics;Matched filters","bioinformatics;database management systems;field programmable gate arrays;genomics;information retrieval;reconfigurable architectures","BLASTN;DNA sequences;FPGA based word matching stage;basic local alignment search tool;computation time;deoxyribonucleic acid;field programmable gate array;genome sequences;genomic database search;genomic sequence database scanning;reconfigurable architecture;sequences analysis tool;similar region finding","","0","","13","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Conversation Analysis on Social Networking Sites","R. Belkaroui; R. Faiz; A. Elkhlifi","LARODEC, Univ. of Tunis, Bardo, Tunisia","2014 Tenth International Conference on Signal-Image Technology and Internet-Based Systems","20150409","2014","","","172","178","With the explosion of Web 2.0, people are becoming more communicative through expansion of services and multi-platform applications such as micro blogs, forums and social networks which establishes social and collaborative backgrounds. These services can be seen as very large information repository containing millions of text messages usually organized into complex networks involving users interacting with each other at specific times. Several works focused only to retrieve separate tweets or those sharing same hash tags, but, it is not powerful enough if the goal of the search is to retrieve relevant tweets based on content. In addition, finding good results concerning the given subjects needs to consider the entire context. However, context can be derived from user interactions. In this work, we propose a new method to retrieval conversation on micro blogging sites. It's based on content analysis and content enrichment. The goal of our method is to present a more informative result compared to conventional search engine. To valid our method, we developed the TCOND system (Twitter Conversation Detector) which offers an alternative, results to keyword search on twitter and Google. We have evaluated our method on collected social network corpus related to specific subjects, and we obtained good results.","","Electronic:978-1-4799-7978-3; POD:978-1-4799-7979-0","10.1109/SITIS.2014.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081544","Conversation retrieval;Social Network;Twitter;social media;user interactions","Electronic mail;Feature extraction;Google;Servers;Twitter","information analysis;information retrieval;social networking (online);user interfaces","TCOND system;Twitter conversation detector;content analysis;conversation retrieval;information repository;social networking site;user interaction","","0","","24","","","23-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"CROWN: A Context-aware RecOmmender for Web News","S. Wang; B. Zou; C. Li; K. Zhao; Q. Liu; H. Chen","Key Lab of Data Engineering and Knowledge Engineering of MOE, Renmin University of China, Beijing, China","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","1420","1423","It is popular for most people to read news online since the web sites can provide access to news articles from millions of sources around the world. For these news web sites, the key challenge is to help users find related news articles to read. In this paper, we present a system called CROWN (Context-aware RecOmmender for Web News) to do Chinese news recommendation. By recommendation, the system can retrieve personalized fresh and relevant news articles to mobile users according to their particular context. Differing from existing mobile news applications which employ rather simple strategies for news recommendation, CROWN integrates the contextual information in prediction by modeling the data as a tensor. Such context information usually includes the time, the location, etc. This demo paper presents the implementation of the whole procedure of news recommendation in the system of CROWN. Experimental results on a large corpus of newly-published Chinese web news show its performance is satisfactory.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113391","","Context;Context modeling;Data models;Mobile communication;Predictive models;Tensile stress;Tin","Web sites;information retrieval;mobile computing;recommender systems","CROWN;Chinese news recommendation;Web sites;context-aware recommender for Web news;contextual information;mobile users;personalized fresh news article retrieval;relevant news retrieval","","0","","8","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Ranking retrieved data through advance search mechanism over distributed cloud: A review","S. P. Shende; C. M. Mankar; R. P. Shende","Computer Engineering Department, S.S.G.M.C.E, Shegaon, University of Amravati, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","4","Research in peer-to-peer file sharing systems has targeted on try the planning constraints encountered in distributed systems, whereas very little attention has been dedicated to the user experience: these systems continually assume the user is aware of the concerning the file they're looking out. Nevertheless average users seldom even apprehend that file exists. File sharing systems that do take into account the user expertise and permit users to go looking for files by their name, usually gift centralized management and that they show many severe vulnerabilities, that build the system unreliable and insecure. The aim of this method is to style a additional complete distributed file sharing system that's not solely trustable, ascendable and secure, however additionally leverages the user's psychological feature employment. We tend to gift a technique that by mining a file's info designates relevant keywords for the file mechanically. These keywords area unit later utilized for the file search and retrieval. Our system provides smart style principals from previous distributed file sharing systems to supply a trustable, scalable, secure and novel distributed file sharing system that a mean user might utilize for file search. Search engines usually include a crawler that traverses the net retrieving documents and a hunt frontend that provides the program to the non inheritable info. The evolution of search engines nowadays is fast by provision additional search capabilities like a hunt for data moreover as search inside the content text. linguistics internet standards have provided strategies for augmenting files with data.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087015","Cloud computing;distributed system;hygiene factor;lookup problem;search engine","Cloud computing;Computational modeling;Computers;Peer-to-peer computing;Public key;Search engines","cloud computing;data mining;information retrieval;peer-to-peer computing;search engines;text analysis","advance search mechanism;centralized management;content text;crawler;distributed cloud;distributed file sharing systems;distributed systems;document retrieval;file mining;file retrieval;file search;linguistics Internet standards;peer-to-peer file sharing systems;planning constraints;retrieved data ranking;search capabilities;search engines;user psychological feature employment","","0","","9","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Smart web content bookmarking with ANN based key phrase extraction algorithm","B. M. T. Kumarika; N. G. J. Dias","Department of Statistics and Computer Science, University of Kelaniya, Sri Lanka","2014 14th International Conference on Advances in ICT for Emerging Regions (ICTer)","20150416","2014","","","228","234","This paper introduces a smart web content bookmarking tool which gives the ability of bookmarking only a selected text other than bookmarking whole pages and keeping a set of links relevant to those pages for later reference. This novel concept helps to collect most important text and paragraphs into one place for the ease of use. The major component of this research is the use of an artificial neural network (ANN) with author identified parameters especially applicable in the domain of small textual contents to extract the key idea of the selected text and to organize bookmarked contents under this system suggested meaningful names. Key phrases are an important mean of document summarization and the manual assignment of key phrases to documents is very laborious. The purpose of this neural network approach is to automate this extraction process and bookmark a selected paragraph with extracted key idea using the developed key phrase extraction method with artificial intelligence. The front end of Smart Web Content Bookmark is developed as a browser extension so that the web users can extend their browsers with it to experience the efficient and meaningful bookmarking method in web.","","CD-ROM:978-1-4799-7729-1; Electronic:978-1-4799-7732-1; POD:978-1-4799-7733-8","10.1109/ICTER.2014.7083906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7083906","Artificial Neural Network;Bookmarks;Key Phrase Extraction","","Internet;information retrieval;neural nets","ANN based key phrase extraction algorithm;artificial intelligence;artificial neural network;author identified parameters;document summarization;feature extraction process;key phrase assignment;key phrase extraction method;smart Web content bookmarking","","0","","20","","","10-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Extractive Broadcast News Summarization Leveraging Recurrent Neural Network Language Modeling Techniques","K. Y. Chen; S. H. Liu; B. Chen; H. M. Wang; E. E. Jan; W. L. Hsu; H. H. Chen","National Taiwan University, Taipei, Taiwan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150601","2015","23","8","1322","1334","Extractive text or speech summarization manages to select a set of salient sentences from an original document and concatenate them to form a summary, enabling users to better browse through and understand the content of the document. A recent stream of research on extractive summarization is to employ the language modeling (LM) approach for important sentence selection, which has proven to be effective for performing speech summarization in an unsupervised fashion. However, one of the major challenges facing the LM approach is how to formulate the sentence models and accurately estimate their parameters for each sentence in the document to be summarized. In view of this, our work in this paper explores a novel use of recurrent neural network language modeling (RNNLM) framework for extractive broadcast news summarization. On top of such a framework, the deduced sentence models are able to render not only word usage cues but also long-span structural information of word co-occurrence relationships within broadcast news documents, getting around the need for the strict bag-of-words assumption. Furthermore, different model complexities and combinations are extensively analyzed and compared. Experimental results demonstrate the performance merits of our summarization methods when compared to several well-studied state-of-the-art unsupervised methods.","2329-9290;23299290","","10.1109/TASLP.2015.2432578","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7111264","Language modeling;long-span structural information;recurrent neural network;speech summarization","Data models;IEEE transactions;Recurrent neural networks;Speech;Speech processing;Speech recognition;Training","electronic publishing;information retrieval;natural language processing;recurrent neural nets;speech processing;text analysis;unsupervised learning","LM approach;RNNLM framework;bag-of-words assumption;extractive broadcast news summarization;extractive text summarization;important sentence selection;long-span structural information;recurrent neural network language modeling techniques;sentence models;speech summarization;word co-occurrence relationships","","2","","57","","20150521","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Wavelet based optimized polynomial threshold function for ECG signal denoising","H. Tulsani; R. Gupta","Electronics and Communication Department, Maharaja Agrasen Institute of Technology, Delhi - 110086, INDIA","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","1563","1566","The Electrocardiogram (ECG) signal is a bio-signal which provides shows the electrical activity of the heart and provides information about the heart's condition. Data retrieval from ECG signal becomes a tough task when the signal is corrupted with noise. In this paper, denoising of ECG signal in wavelet domain using a polynomial based threshold function is proposed. The coefficients of the function are optimized using artificial bee colony (ABC) algorithm. The proposed function is compared with three existing functions, hard, soft and non-negative garrote threshold function. The performance parameters used are output signal to noise ratio, mean square error and cross correlation coefficient. Performance is compared for two different ECG signals.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100511","ABC algorithm;ECG signal;denoising;thresholding;wavelets","Decision support systems;Handheld computers","correlation methods;electrocardiography;information retrieval;mean square error methods;medical signal processing;optimisation;signal denoising;wavelet transforms","ABC algorithm;ECG signal denoising;artificial bee colony algorithm;cross-correlation coefficient;data retrieval;electrocardiogram signal denoising;heart electrical activity;mean square error;signal to noise ratio;wavelet based optimized polynomial threshold function","","0","","11","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Sensorem - an efficient mobile platform for wireless sensor network visualisation","J. M. Koh; M. Sak; H. X. Tan; H. Liang; F. Folianto; T. Quek","NUS High Sch. of Math. & Sci., Singapore, Singapore","2015 IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)","20150514","2015","","","1","2","We design and implement an Android application, Sensorem, for efficient retrieval and visualization of wireless sensor network (WSN) data. In light of data distribution and visualization being important developmental keystones of smart cities, we seek to enhance sensor data accessibility by developing a user-friendly mobile application (Sensorem) for meaningful visualization of sensor data, targeted at maintenance personnel. Sensor selection can be made with reference to geographical location through an embedded Google Map fragment, as well as a sensor list with sensors in order of WSN node ID. Sensor data is presented through interactive graphs, and graph overlaying functions are offered for easy comparison of data trends. We also employ a Bayesian prefetch algorithm and caching mechanisms to minimize sensor data access latency, such that the app system is able to cope with network and back-end bottlenecks.","","Electronic:978-1-4799-8055-0; POD:978-1-4799-8056-7","10.1109/ISSNIP.2015.7106971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106971","","Cities and towns;Data visualization;Libraries;Mobile communication;Prefetching;Servers;Wireless sensor networks","Bayes methods;cache storage;data visualisation;geographic information systems;graph theory;information retrieval;mobile computing;sensor fusion;smart cities;smart phones;wireless sensor networks","Android application;Bayesian prefetch algorithm;Sensorem;WSN data;WSN node ID;caching mechanisms;embedded Google Map fragment;geographical location;graph overlaying functions;interactive graphs;maintenance personnel;mobile platform;sensor data access latency;sensor data accessibility;smart cities;user-friendly mobile application;wireless sensor network data retrieval;wireless sensor network data visualization","","1","1","4","","","7-9 April 2015","","IEEE","IEEE Conference Publications"
"E-Testing question development technologies and strategies","M. Gusev; S. Ristov; G. Armenski","Ss. Cyril and Methodius University, 1000 Skopje, Macedonia","2015 IEEE Global Engineering Education Conference (EDUCON)","20150430","2015","","","552","560","Advanced learning technologies integrate questions as a very relevant function in building e-Testing systems and especially in intelligent tutoring systems. Therefore, a huge challenge is the generation of a necessary and relevant assessment content. The existing efforts to realize open source learning materials and establishment of massive open online courses introduce another challenge for realization of a sophisticated system and appropriate knowledge database with huge number of questions reflecting all relevant knowledge items (learning objectives). In this paper we present the experience in realization of a real e-Testing system by building two variations: the first with standard graphical interface, and the other with an enhanced media interaction supporting interactive images. We present several question generation strategies for conventional approach using multiple-choice questions and also for the system with interactive images. These techniques can be used to develop a large set of questions and assessment content.","2165-9559;21659559","Electronic:978-1-4799-1908-6; POD:978-1-4799-1909-3","10.1109/EDUCON.2015.7096024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096024","Question database;eAssessment;eTesting;interactive image;knowledge evaluation","Complexity theory;Conferences;Databases;Engineering education;Image resolution;Navigation;Testing","computer aided instruction;graphical user interfaces;information retrieval;multimedia systems","assessment content;e-testing question development;e-testing system;electronic testing;graphical interface;intelligent tutoring system;knowledge database;knowledge items;learning objectives;learning technology;massive open online courses;media interaction;multiple-choice question;open source learning material;question generation strategy","","1","","20","","","18-20 March 2015","","IEEE","IEEE Conference Publications"
"Electronic recording system-heart disease prediction system","S. Shaikh; A. Sawant; S. Paradkar; K. Patil","Dept. of Comput. Eng., Don Bosco Inst. of Technol., Mumbai, India","2015 International Conference on Technologies for Sustainable Development (ICTSD)","20150430","2015","","","1","5","In medical field there is a growing need for development of software to be used for practical applications rather than only in research field. Doctors need not only to know the main symptoms in a patient but also the other factors in life and surrounding that lead to disease in the patient. For collecting all the necessary information about the patient the doctors needs to spend a lot of time with the patient asking necessary questions to get the important details. The doctor needs to document all the data for further use and needs to keep track of all the patient details and remedies. The proposed system is intended to develop an Intelligent System using data mining modeling technique, namely, Naive Bayes. It is implemented as Java application in which user answers the predefined questions. It retrieves hidden data from stored database and compares the user values with trained data set. It can answer complex queries for diagnosing heart disease and thus assist healthcare practitioners to make intelligent clinical decisions which traditional decision support systems cannot.","","Electronic:978-1-4799-8187-8; POD:978-1-4799-8188-5","10.1109/ICTSD.2015.7095854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095854","Data Mining;Heart disease;Naïve Bayes;Prediction;Remedy","Data collection;Data mining;Databases;Diseases;Heart;Pattern matching","Java;belief networks;cardiovascular system;data mining;decision support systems;diseases;health care;information retrieval;medical information systems;patient diagnosis","Intelligent System;Java application;Naive Bayes;complex queries;data mining modeling technique;electronic recording system;healthcare practitioners;heart disease diagnosis;heart disease prediction system;hidden data retrieval;intelligent clinical decisions;medical field;research field;software;traditional decision support systems;trained data set;user values","","3","","4","","","4-6 Feb. 2015","","IEEE","IEEE Conference Publications"
"A fast proof generating system for verifying cloud search","G. Wang","School of Software, Shanghai Jiao Tong University, Shanghai, China","Proceedings of 2nd International Conference on Information Technology and Electronic Commerce","20150514","2014","","","184","187","With the developing of network and hardware, cloud computing is playing a more important role in business and daily usage. The need of searching cloud data is growing increasingly. And the need to proof the correctness of cloud searching has also grown. Previous work has proposed many useful theories on verifiable computing, such as probabilistically checkable proofs, authHashtable, but an efficient and scalable system is rare. We design and implement a fast proof generating system for verifying cloud search based on RSA accumulators, nonmember-ship witnesses. The system is efficient and scalable. Evaluation on real datasets shows that our system can speed up the proof generation time and our system can handle datasets with size around 100GB.","","CD-ROM:978-1-4799-5298-4; Electronic:978-1-4799-5299-1; POD:978-1-4799-5300-4","10.1109/ICITEC.2014.7105597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105597","Cloud Computing;Document Search;Parallel processing;Performance evaluation;Verifiable Computing","Electronic publishing;Encyclopedias;Indexes;Servers;Silicon;Vegetation","cloud computing;information retrieval;public key cryptography","RSA accumulators;cloud computing;cloud search verification;nonmember-ship witnesses;proof generating system;proof generation time","","0","","10","","","20-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Content Information Extraction of Theme Web Pages Based on Tag Information","J. Wang; J. Wu; Y. Zhang; G. He","Sch. of Manage., Capital Normal Univ., Beijing, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","1","","501","504","In order to extract the content information of Theme Web Pages more accurately, this paper proposes a self-learning method based on the tag information by calculating the information quantity of various tag indicators. This method predefines several tag information indexes and coefficients index to calculate a variety of tag information quantity of the web pages in turn, and then the candidate content of Web pages is in the tag with the most information quantity. To improve the versatility of the method, we add the adaptive and adjustable coefficient weight in calculation formulas of tag information quantity. With the increasing of data be processed, tag collections, index value and the information quantity results are added into the learning database to adjust the weight of coefficient factor. Experimental results show that the accuracy of this extraction method with adaptive and adjustable coefficient weights can reach more than 99 percent recall rate. Also, this method does not depend on the specific structure and style of the web page and has good versatility.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064243","Content Information Extraction;DOM Tree;Tag information quantity;Theme Web pages","Accuracy;Data mining;Feature extraction;Indexes;Web pages","Internet;information retrieval;learning (artificial intelligence)","coefficients index;content information extraction;information indexes;information quantity;self-learning method;tag collections;tag indicators;tag information;theme Web pages","","0","","14","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Multi-directional detection of scratches in digitized images","E. Ardizzone; H. Dindo; G. Mazzola; M. Scriminaci; M. Vitali","Dipartimento di Ingegneria Informatica (DINFO) - Universit&#x00E0; degli Studi di Palermo, Viale delle Scienze, building 6, 90128, Italy","2009 17th European Signal Processing Conference","20150406","2009","","","248","252","Line scratches are common defects in old archived videos. Many printed images suffer of a similar problem, in most cases due to improper handling or inaccurate preservation of the support. Once an image is digitized, its defects become part of that image. Many state-of-the-art papers deal with long, thin, vertical lines in old movie frames, by exploiting both spatial and temporal information. In this paper we present a method that consistently modifies and extends our previous proposed algorithm, to detect line scratches in digitized still images. Our method is able to detect scratches regardless of their orientation, and to draw their contour by labeling the pixels belonging to them.","","POD:978-161-7388-76-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7077528","","Abstracts;Buildings;Image color analysis;Image segmentation;Motion pictures;Subspace constraints","image resolution;information retrieval systems;object detection;video signal processing","Line scratches;digitized images;improper support handling;inaccurate support preservation;multidirectional scratch detection;old archived videos;old movie frames;pixel labeling;spatial information;temporal information","","0","","7","","","24-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"Dynamic Time Warping for Music Retrieval Using Time Series Modeling of Musical Emotions","J. J. Deng; C. H. C. Leung","Department of Computer Science, Hong Kong Baptist University, Hong Kong","IEEE Transactions on Affective Computing","20150601","2015","6","2","137","151","Musical signals have rich temporal information not only at the physical level but at the emotion level. The listeners may wish to find music excerpts that have similar sequence patterns of musical emotions with given excerpts. Most state-of-the-art systems for emotion-based music retrieval concentrate on static analysis of musical emotions, and ignore dynamic analysis and modeling of musical emotions overtime. This paper presents a novel approach to perform music retrieval based on time-varying musical emotion dynamics. A three-dimensional musical emotion model-Resonance-Arousal-Valence (RAV)-is used, and emotions of a piece of music are represented by musical emotion dynamics in a time series. A multiple dynamic textures (MDT) model is proposed to model music and emotion dynamics overtime, and expectation maximization (EM) algorithm along with Kalman filtering and smoothing is used to estimate model parameters. Two smoothing methods-Rauch-Tung-Striebel (RTS) and minimum-variance smoothing (MVS)-to robust model are investigated and compared to find an optimal solution to enhance prediction. To find similar sequence patterns of musical emotions, subsequence dynamic time warping (DTW) for emotion dynamics matching is presented. Experimental results demonstrate the benefits of MDT to predict time-varying musical emotions, and our proposed method for music retrieval based on emotion dynamics outperforms retrieval methods based on acoustic features.","1949-3045;19493045","","10.1109/TAFFC.2015.2404352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042773","EM algorithm;Kalman filter and smoother;Musical emotion;dynamic time warping;multiple dynamic textures","Analytical models;Heuristic algorithms;Kalman filters;Multiple signal classification;Music;Smoothing methods;Time series analysis","Kalman filters;acoustic signal processing;emotion recognition;expectation-maximisation algorithm;information retrieval;music;parameter estimation;smoothing methods;time series","DTW;EM algorithm;Kalman filtering;MDT;MVS;RAV;RTS smoothing methods;Rauch-Tung-Striebel smoothing methods;dynamic analysis;emotion dynamics matching;emotion level;emotion-based music retrieval;expectation maximization;minimum-variance smoothing;multiple dynamic textures model;musical emotions;musical signals;parameters estimation;physical level;resonance-arousal-valence;sequence patterns;static analysis;subsequence dynamic time warping;three-dimensional musical emotion model;time series modeling;time-varying musical emotion dynamics","","3","","58","","20150216","April-June 1 2015","","IEEE","IEEE Journals & Magazines"
"Privacy Threats from Social Networking Service Aggregators","O. Jaafor; B. Birregah; C. Perez; M. Lemercier","Charles Delaunay Inst., Univ. of Technol. of Troyes, Troyes, France","2014 Fifth Cybercrime and Trustworthy Computing Conference","20150416","2014","","","30","37","Social networking services (SNS) have increased in popularity over the last decade. They have become major platforms for e-commerce, personal branding, socialization and information. The success of social networking services like Facebook and Twitter as well as LinkedIn, LiveJournal andFoursquare and the variety of their usages leads their users to create a set of profiles on different SNS. Recently, social networking service aggregators have proposed centralizing the multiple social networking profiles of a given user in order to facilitate his interactions with social networking services. Such aggregators allow the messages received by a profile over multiple SNS to be retrieved, edited and posted with much less effort. Despite their obvious advantages, we highlight in this paper the risk of potential data leaks due to the inexperienced use of such tools. For this purpose, we provide a classification of online SNS and present their specificities with regard to the publicly exposed data of a user. Based on this classification, we investigate the possible insecure use of aggregators with an inappropriate set of SNS, which could lead to rendering sensitive data accessible to people it wasn't intended for. We present a decision tree approach for identifying a possible data leak based on the three following criteria: opinion, interest and location. We finally show the result of this approach on popular social networking aggregators.","","Electronic:978-1-4799-8825-9; POD:978-1-4799-8826-6","10.1109/CTC.2014.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087325","Social networking service;decision tree algorithm;social aggregators;social network classification;social networking based data disclosure","Data privacy;Decision trees;Facebook;PROM;Privacy;Twitter","data privacy;decision trees;information retrieval;pattern classification;security of data;social networking (online)","Facebook;Foursquare;LinkedIn;LiveJournal;SNS;Twitter;decision tree approach;e-commerce;interest criteria;location criteria;multiple social networking profiles;online SNS classification;opinion criteria;personal branding;possible data leak identification;privacy threats;social networking service aggregators;socialization","","2","","16","","","24-25 Nov. 2014","","IEEE","IEEE Conference Publications"
"Does Summarization Help Stock Prediction? A News Impact Analysis","X. Li; H. Xie; Y. Song; S. Zhu; Q. Li; F. L. Wang","City University of Hong Kong","IEEE Intelligent Systems","20150522","2015","30","3","26","34","The authors study the problem of how news summarization can help stock price prediction, proposing a generic stock price prediction framework to enable the use of different external signals to predict stock prices. Experiments were conducted on five years of Hong Kong Stock Exchange data, with news reported by Finet; evaluations were performed at individual stock, sector index, and market index levels. The authors' results show that prediction based on news article summarization can effectively outperform prediction based on full-length articles on both validation and independent testing sets.","1541-1672;15411672","","10.1109/MIS.2015.1","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006338","artificial intelligence;intelligent systems;news summarization;predictive analytics;stock prediction","Investments;Predictive models;Stock market","information retrieval;stock markets;text analysis","information retrieval;news impact analysis;news summarization;stock price prediction framework","","7","","8","","20150112","May-June 2015","","IEEE","IEEE Journals & Magazines"
"Gist of Text Extraction","K. Mahmoudi; S. Faïz","Lab. LTSIRS, ENIT, Tunis, Tunisia","2014 Tenth International Conference on Signal-Image Technology and Internet-Based Systems","20150409","2014","","","179","186","The amount of spatial information we are managing is continuously in growth. Such information is increasingly used in most economic sectors by having a direct impact on productivity. Geographic information system (GIS) stores spatial data in geographic databases (GDB). Typically, such databases do not store all the data and details needed to sustain decision makers, since this entails a high cost of data processing and maintenance. In front to this situation, new technologies were proposed to pursue the relevant and timely information. Concretely, this is accomplished through data enrichment. In this context, we propose an approach to enrich the semantic aspect of the GDB. The objective is to save time in retrieving and updating the data to reflect the current state of geographic entities.","","Electronic:978-1-4799-7978-3; POD:978-1-4799-7979-0","10.1109/SITIS.2014.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081545","GIS;RST analysis;data enrichment;segmentation;topic identification","Data processing;Filtering;Geographic information systems;Satellites;Semantics;Spatial databases","data mining;geographic information systems;information retrieval","GDB;GIS;data enrichment;geographic databases;geographic information system;semantic aspect;spatial information;text extraction","","0","","21","","","23-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"SemTree: An index for supporting semantic retrieval of documents","F. Amato; A. De Santo; F. Gargiulo; V. Moscato; F. Persia; A. Picariello; S. R. Poccia","Dipartimento di Ingegneria Elettrica e Tecnologie dellInformazione, University of Naples &#x201C;Federico II&#x201D;, via Claudio 21, 80125, Italy","2015 31st IEEE International Conference on Data Engineering Workshops","20150622","2015","","","62","67","In this paper, we propose SemTree, a novel semantic index for supporting retrieval of information from huge amount of document collections, assuming that semantics of a document can be effectively expressed by a set of 〈subject, predicate, object〉 statements as in the RDF model. A distributed version of KD-Tree has been then adopted for providing a scalable solution to the document indexing, leveraging the mapping of triples in a vectorial space. We investigate the feasibility of our approach in a real case study, considering the problem of finding inconsistencies in documents related to software requirements and report some preliminary experimental results.","","Electronic:978-1-4799-8442-8; POD:978-1-4799-8443-5","10.1109/ICDEW.2015.7129546","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129546","","Complexity theory;Computational modeling;Partitioning algorithms","formal specification;formal verification;indexing;information retrieval;semantic networks;systems analysis;trees (mathematics);vectors","KD-Tree;RDF model;SemTree;document indexing;document retrieval;semantic index;software requirement;vectorial space","","0","","13","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"A new approach to ranking algorithm - Custom Personalized Searching","Anjali; A. Sadhwani; N. Saxena","Department of Information Technology, SRMGPC Lucknow, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","130","133","WWW is a huge collection of information and most of the time people are engaged with it in order to retrieve different types of information. People want to get accurate and appropriate data at the top of search results in a user friendly manner. People also want to get a personal space over the internet when they are browsing on web, from this arises a need of personalization of the search history. Thus there is a need of a highly efficient and effective ranking algorithm that provides search results according to user preferences. In this paper we have proposed a new approach which we call CUSTOM PERSONALISED SEARCHING. In this approach first we will use Page Rank algorithm, then social signals to rank the pages then we provide personalization by creating individual search history for each user on the browser and here we have also focused on the search results to get customized according to the user demand. We have also focused on parameters like page authority and domain authority.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100235","Customization;Domain Authority;Page Authority;Page Rank;Personalization;Search history;Social Signals","Algorithm design and analysis;Google;History;Internet;Search engines;Time-frequency analysis;Web pages","Internet;information retrieval;online front-ends","Internet;Page Rank algorithm;Web browsing;custom personalized searching;domain authority;information retrieval;page authority;ranking algorithm","","0","","13","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"TripPlanner: Personalized Trip Planning Leveraging Heterogeneous Crowdsourced Digital Footprints","C. Chen; D. Zhang; B. Guo; X. Ma; G. Pan; Z. Wu","Key Lab. of Dependable Service Comput. in Cyber Phys. Soc., Chongqing Univ., Chongqing, China","IEEE Transactions on Intelligent Transportation Systems","20150601","2015","16","3","1259","1273","Planning an itinerary before traveling to a city is one of the most important travel preparation activities. In this paper, we propose a novel framework called TripPlanner, leveraging a combination of location-based social network (i.e., LBSN) and taxi GPS digital footprints to achieve personalized, interactive, and traffic-aware trip planning. First, we construct a dynamic point-of-interest network model by extracting relevant information from crowdsourced LBSN and taxi GPS traces. Then, we propose a two-phase approach for personalized trip planning. In the route search phase, TripPlanner works interactively with users to generate candidate routes with specified venues. In the route augmentation phase, TripPlanner applies heuristic algorithms to add user's preferred venues iteratively to the candidate routes, with the objective of maximizing the route score while satisfying both the venue visiting time and total travel time constraints. To validate the efficiency and effectiveness of the proposed approach, extensive empirical studies were performed on two real-world data sets from the city of San Francisco, which contain more than 391 900 passenger delivery trips generated by 536 taxis in a month and 110 214 check-ins left by 15 680 Foursquare users in six months.","1524-9050;15249050","","10.1109/TITS.2014.2357835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6951432","Crowdsourcing;digital footprints;personalization;traffic aware;trip planning","Data models;Global Positioning System;Planning;Search problems;Time factors;Urban areas","Global Positioning System;information retrieval;social networking (online);travel industry","San Francisco;TripPlanner;crowdsourced LBSN;dynamic point-of-interest network model;heterogeneous crowdsourced digital footprints;heuristic algorithms;information extraction;interactive trip planning;itinerary planning;location-based social network;personalized trip planning;route augmentation phase;route score maximization;route search phase;taxi GPS digital footprints;taxi GPS traces;total travel time constraints;traffic-aware trip planning;travel preparation activities;two-phase approach","","6","","42","","20141110","June 2015","","IEEE","IEEE Journals & Magazines"
"NIRMAL: Automatic identification of software relevant tweets leveraging language model","A. Sharma; Y. Tian; D. Lo","School of Information Systems, Singapore Management University, Singapore","2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","20150409","2015","","","449","458","Twitter is one of the most widely used social media platforms today. It enables users to share and view short 140-character messages called “tweets”. About 284 million active users generate close to 500 million tweets per day. Such rapid generation of user generated content in large magnitudes results in the problem of information overload. Users who are interested in information related to a particular domain have limited means to filter out irrelevant tweets and tend to get lost in the huge amount of data they encounter. A recent study by Singer et al. found that software developers use Twitter to stay aware of industry trends, to learn from others, and to network with other developers. However, Singer et al. also reported that developers often find Twitter streams to contain too much noise which is a barrier to the adoption of Twitter. In this paper, to help developers cope with noise, we propose a novel approach named NIRMAL, which automatically identifies software relevant tweets from a collection or stream of tweets. Our approach is based on language modeling which learns a statistical model based on a training corpus (i.e., set of documents). We make use of a subset of posts from StackOverflow, a programming question and answer site, as a training corpus to learn a language model. A corpus of tweets was then used to test the effectiveness of the trained language model. The tweets were sorted based on the rank the model assigned to each of the individual tweets. The top 200 tweets were then manually analyzed to verify whether they are software related or not, and then an accuracy score was calculated. The results show that decent accuracy scores can be achieved by various variants of NIRMAL, which indicates that NIRMAL can effectively identify software related tweets from a huge corpus of tweets.","1534-5351;15345351","Electronic:978-1-4799-8469-5; POD:978-1-4799-8470-1","10.1109/SANER.2015.7081855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081855","","Computational modeling;Market research;Mathematical model;Software;Support vector machines;Training;Twitter","information filtering;natural language processing;question answering (information retrieval);social networking (online);statistical analysis","NIRMAL framework;StackOverflow;Twitter adoption barrier;Twitter streams;accuracy scores;automatic software relevant tweet identification;information overload;irrelevant tweet filtering;language model learning;language model leveraging;programming question-and-answer site;short-character message sharing;short-character message view;social media platforms;statistical model;training corpus;tweet analysis;tweet collection;tweet sorting;tweet stream;user generated content generation","","4","","30","","","2-6 March 2015","","IEEE","IEEE Conference Publications"
"O-Bin: Oblivious Binning for Encrypted Data over Cloud","M. Ahmad; Z. Pervez; B. H. Kang; S. Lee","Dept. of Comput. Eng., Kyung Hee Univ., Yongin, South Korea","2015 IEEE 29th International Conference on Advanced Information Networking and Applications","20150430","2015","","","352","357","In recent years, the data growth rate has been observed growing at a staggering rate. Considering data search as a primitive operation and to optimize this process on large volume of data, various solution have been evolved over a period of time. Other than finding the precise similarity, these algorithms aim to find the approximate similarities and arrange them into bins. Locality sensitive hashing (LSH) is one such algorithm that discovers probable similarities prior calculating the exact similarity thus enhance the overall search process in high dimensional search space. Realizing same strategy for encrypted data and that too in public cloud introduces few challenges to be resolved before probable similarity discovery. To address these issues and to formalize a similar strategy like LSH, in this paper we have formalized a technique O-Bin that is designed to work over encrypted data in cloud. By exploiting existing cryptographic primitives, O-Bin preserves the data privacy during the similarity discovery for the binning process. Our experimental evaluation for O-Bin produces results similar to LSH for encrypted data.","1550-445X;1550445X","Electronic:978-1-4799-7905-9; POD:978-1-4799-7906-6","10.1109/AINA.2015.206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097991","Binning;Cloud;Security and Privacy;Similarity discovery","Cloud computing;Data privacy;Encryption;Outsourcing;Servers","cloud computing;cryptography;data privacy;information retrieval","LSH;O-Bin;approximate similarities;cryptographic primitives;data growth rate;data privacy;data search;encrypted data;high dimensional search space;locality sensitive hashing;oblivious binning process;probable similarity discovery;public cloud;search process","","0","","14","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"<italic>Why so many people</italic>? Explaining Nonhabitual Transport Overcrowding With Internet Data","F. C. Pereira; F. Rodrigues; E. Polisciuc; M. Ben-Akiva","Singapore-MIT Alliance for Res. & Technol., Singapore, Singapore","IEEE Transactions on Intelligent Transportation Systems","20150601","2015","16","3","1370","1379","Public transport smartcard data can be used for detection of large crowds. By comparing statistics on habitual behavior (e.g., average by time of day), one can specifically identify nonhabitual crowds, which are often very problematic for transport systems. While habitual overcrowding (e.g., peak hour) is well understood both by traffic managers and travelers, nonhabitual overcrowding hotspots can become even more disruptive and unpleasant because they are generally unexpected. By quickly understanding such cases, a transport manager can react and mitigate transport system disruptions. We propose a probabilistic data analysis model that breaks each nonhabitual overcrowding hotspot into a set of explanatory components. The potential explanatory components are initially retrieved from social networks and special events websites and then processed through text-analysis techniques. Finally, for each such component, the probabilistic model estimates a specific share in the total overcrowding counts. We first validate with synthetic data and then test our model with real data from the public transport system (EZLink) of Singapore, focused on three case study areas. We demonstrate that it is able to generate explanations that are intuitively plausible and consistent both locally (correlation coefficient, i.e., CC, from 85% to 99% for the three areas) and globally (CC from 41.2% to 83.9%). This model is directly applicable to any other domain sensitive to crowd formation due to large social events (e.g., communications, water, energy, waste).","1524-9050;15249050","","10.1109/TITS.2014.2368119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7021960","Information extraction;machine learning;smartcards;special events;travel demand modeling;web mining","Bayes methods;Data models;Facebook;Google;Intelligent transportation systems;Internet;Predictive models","Internet;behavioural sciences computing;data analysis;information retrieval;probability;public transport;smart cards;social networking (online);text analysis;traffic engineering computing","Internet data;Web sites;correlation coefficient;crowd formation;habitual behavior;nonhabitual transport overcrowding hotspot;probabilistic data analysis;probabilistic model;public transport smart card data;public transport system;social events;social networks;text-analysis techniques;traffic managers","","1","","26","","20150126","June 2015","","IEEE","IEEE Journals & Magazines"
"CEDAR: Efficient Reasoning for the Semantic Web","S. Amir; H. Aït-Kaci","Dept. Inf., Univ. Claude Bernard Lyon 1, Villeurbanne, France","2014 Tenth International Conference on Signal-Image Technology and Internet-Based Systems","20150409","2014","","","157","163","We present a new version of CEDAR, a taxonomic reasoner for large-scale ontologies. This extended version provides fuller support for TBox reasoning, checking consistency, and retrieving instances. CEDAR is built on top of the OSF formalism and based on an entirely new architecture which includes several optimization techniques. Using OSF graph structures, we define a bidirectional mapping between OSF structure and the Resource Description Framework (RDF) allowing a translation from OSF queries into SPARQL for retrieving instances. Experiments were carried out using very large ontologies. The results achieved by CEDAR were compared to those obtained by well-known Semantic Web reasoners such as FaCT++, Pellet, HermiT, TrOWL, and Racer Pro. CEDAR performs on a par with the best systems for concept classification and several orders of magnitude more efficiently in terms of response time for Boolean query-answering.","","Electronic:978-1-4799-7978-3; POD:978-1-4799-7979-0","10.1109/SITIS.2014.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081542","Binary Encoding;Ontology Classification;Query Answering","Binary codes;Cognition;Encoding;Ontologies;Resource description framework;Taxonomy","graph theory;ontologies (artificial intelligence);pattern classification;question answering (information retrieval);semantic Web","Boolean query-answering;CEDAR;OSF formalism;OSF graph structures;OSF queries;RDF;SPARQL;TBox reasoning;bidirectional mapping;concept classification;consistency checking;instance retrieval;large-scale ontologies;optimization techniques;resource description framework;semantic Web;taxonomic reasoner","","2","1","18","","","23-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"POP: A Passenger-Oriented Partners matching system","X. Duan; C. Jin; X. Wang","Shanghai Key Laboratory of Trustworthy Computing, Institute for Data Science and Engineering, East China Normal University, China","2015 31st IEEE International Conference on Data Engineering Workshops","20150622","2015","","","117","118","Sharing one taxi by more than one person is treated promising, since it enables us to take a taxi in rush-hour more conveniently. Hence, we develop POP, a prototype system to find appropriate partners to share a taxi with a given passenger. The framework of POP includes two phases, namely offline preprocessing and online matching. During the offline preprocessing phase, it constructs an R-tree index for road network to speedup data access and computes average travel time for each road segment based on history trajectory data, while during the online matching, it tries to find appropriate partners to a given passenger which aims to save time as much as possible. We also propose a simple pricing method to allocate fee between passengers.","","Electronic:978-1-4799-8442-8; POD:978-1-4799-8443-5","10.1109/ICDEW.2015.7129560","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129560","","Cities and towns;History;Indexes;Prototypes;Resource management;Roads;Vehicles","information retrieval;intelligent transportation systems;pattern matching;pricing;road vehicles;trees (mathematics)","POP;R-tree index;data access;history trajectory data;offline preprocessing phase;online matching;passenger-oriented partners matching system;pricing method;prototype system;road network;road segment;rush-hour;taxi sharing","","1","","4","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Automatic localization and segmentation of optic disc in fundus image using morphology and level set","T. Yu; Y. Ma; W. Li","School of Information Science and Engineering, Lanzhou University, Lanzhou, China","2015 9th International Symposium on Medical Information and Communication Technology (ISMICT)","20150514","2015","","","195","199","Optic disc (OD) localization and segmentation are important in developing systems for automated diagnosis of various serious ophthalmic pathologies. This paper presents a new, fast and robust methodology for fully automatic localization and segmentation of the optic disc in fundus images. This methodology locates the OD with a morphological approach based on the combination of vessel convergence and intensity. The boundary of the OD is extracted by using distance regularized narrowband level set evolution (DRLSE). This algorithm has been validated on three public databases. The location procedure has a high success rate of 99.52% in the cases averagely and the segmentation method improves the sensitivity and specificity to 99.92% and 96.49% respectively. The results confirm the superiority of the proposed method over the conventional ways.","2326-828X;2326828X","Electronic:978-1-4799-8072-7; POD:978-1-4799-8073-4","10.1109/ISMICT.2015.7107527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107527","Diabetic retinopathy;fundus mage;level set segmentation;mathematical morphology;optic disc (OD) segmentation","Biomedical optical imaging;Convergence;Databases;Image segmentation;Level set;Optical filters;Optical imaging","biomedical optical imaging;eye;image segmentation;information retrieval systems;mathematical morphology;medical image processing;patient diagnosis;spatial variables measurement","DRLSE technique;OD boundary extraction;OD location procedure selectivity;OD location procedure sensitivity;OD location procedure success rate;automated diagnostic system development;distance regularized narrowband level set evolution;fast OD localization methodology;fully automatic OD localization;fully automatic OD segmentation;fully automatic optic disc localization;fully automatic optic disc segmentation;fundus image OD localization;fundus image OD segmentation;fundus image optic disc localization;fundus image optic disc segmentation;level set-based OD localization;level set-based optic disc localization;morphological OD localization approach;morphological optic disc localization approach;morphology set-based OD localization;morphology set-based optic disc localization;optic disc boundary extraction;optic disc location procedure selectivity;optic disc location procedure sensitivity;optic disc location procedure success rate;public database-validated algorithm;robust OD localization methodology;segmentation method-improved procedure selectivity;segmentation method-improved procedure sensitivity;serious ophthalmic pathology diagnosis;vessel convergence-intensity combination","","0","","19","","","24-26 March 2015","","IEEE","IEEE Conference Publications"
"INMO: A Web Architecture For Real Estate Search Systems","L. Martinez; J. Contreras; R. Mendoza; P. Torres","Corp. Univ. Rafael Nunez, Cartagena, Colombia","IEEE Latin America Transactions","20150513","2015","13","4","1148","1152","This paper describes the development of a real estate electronic marketplace based on platform J2EE. A novel real estate search method based on Google Maps APIs is included. We explain the approach we propose on a prototypical implementation exhibiting the described functionality.","1548-0992;15480992","","10.1109/TLA.2015.7106369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106369","Google Maps;J2EE;geo localization;information systems;marketplace;real estate;software architecture","Customer relationship management;Decision support systems;Google;Java;Service-oriented architecture;Silicon","Internet;application program interfaces;electronic commerce;information retrieval;information retrieval systems;real estate data processing;software architecture","Google Maps API;INMO;J2EE;Web architecture;geo localization;information systems;real estate electronic marketplace;real estate search systems;software architecture","","0","","","","","April 2015","","IEEE","IEEE Journals & Magazines"
"SkillsRec: A Novel Semantic Analysis Driven Learner Skills Mining and Filtering Approach for Personal Learning Environments Based on Teacher Guidance","Z. A. Shaikh; D. Gillet; S. A. Khoja","Sch. of Eng., Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland","2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops","20150430","2015","","","570","576","This paper presents SkillsRec - a novel teacher guidance based learner skills mining and filtering approach that identifies learner skills for Personal Learning Environment (PLE) based learning scenarios using Latent Semantic Analysis (LSA) technique. Skills Rec is developed on PLE design and development principles of the guided PLEs model [1]. Skills Rec takes teacher competencies/roles [2] and learner interests as input, melds them using LSA, and returns learner skills for the PLE-based learning as output. We compare learner-skill similarity scores of the Skills Rec with those generated through conventional Information Retrieval (IR) and Keywords Matching (KM) techniques. The aim is to report Skills Rec gains over conventional IR techniques. Based on Skills Rec results, this paper also provides top N=8 user-user recommendations most likely to be similar for a given active learner as a testing data.","","Electronic:978-1-4799-1775-4; POD:978-1-4799-1776-1","10.1109/WAINA.2015.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096238","Latent Semantic Analysis;Personal Learning Environment;guided PLEs Model;learner skills;teacher guidance","Analytical models;Computational modeling;Data analysis;Data models;Filtering;Organizations;Semantics","data mining;information retrieval;learning management systems;pattern matching","IR;KM techniques;LSA technique;PLE-based learning;SkillsRec;information retrieval;keywords matching techniques;latent semantic analysis;personal learning environments;semantic analysis driven learner skills filtering approach;semantic analysis driven learner skills mining approach;teacher guidance;teacher guidance based learner skills filtering approach;teacher guidance based learner skills mining approach","","0","","22","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Efficient and scalable trie-based algorithms for computing set containment relations","Y. Luo; G. H. L. Fletcher; J. Hidders; P. De Bra","Eindhoven University of Technology, The Netherlands","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","303","314","Computing containment relations between massive collections of sets is a fundamental operation in data management, for example in graph analytics and data mining applications. Motivated by recent hardware trends, in this paper we present two novel solutions for computing set-containment joins over massive sets: the Patricia Trie-based Signature Join (PTSJ) and PRETTI+, a Patricia trie enhanced extension of the state-of-the-art PRETTI join. The compact trie structure not only enables efficient use of main-memory, but also significantly boosts the performance of both approaches. By carefully analyzing the algorithms and conducting extensive experiments with various synthetic and real-world datasets, we show that, in many practical cases, our algorithms are an order of magnitude faster than the state-of-the-art.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113293","","Algorithm design and analysis;Data mining;Data structures;Estimation;Hardware;Indexes;Market research","data analysis;data structures;information retrieval;storage management","PRETTI join;PRETTI+;PTSJ;Patricia trie-based signature join;computing set containment relation;data management;data mining;graph analytics;scalable trie-based algorithm","","1","","32","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
