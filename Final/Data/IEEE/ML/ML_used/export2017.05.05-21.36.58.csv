"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7889570,7888422,7888414,7886093,7885992,7885729,7886565,7864411,7886119,7886107,7886263,7886278,7883368,7883348,7883046,7883399,7792573,7883038,7885351,7884147,7884170,7883081,7884678,7883389,7883517,7885096,7460959,7884988,7883816,7880179,7881501,7881426,7880255,7880169,7880246,7881726,7881613,7880242,7881575,7881396,7881563,7881611,7881511,7881502,7881381,7835283,7881500,7880607,7877074,7877424,7877614,7877974,7877461,7877199,7877360,7877720,7878753,7779068,7298418,7347363,7879356,7876324,7876731,7876369,7876241,7876155,7876349,7876767,7876376,7565530,7875411,7872790,7872727,7873099,7872882,7872829,7872884,7873601,7849149,7872653,7874186,7873354,7871019,7869875,7871015,7869126,7870220,7869052,7869874,7870205,7869900,7869895,7870644,7337368,7870697,7384415,7500052,7866185,7866183,7866773",2017/05/05 21:36:58
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Online Bimanual Manipulation Using Surface Electromyography and Incremental Learning","I. Strazzulla; M. Nowak; M. Controzzi; C. Cipriani; C. Castellini","Biorobotics Institute, Scuola Superiore Sant&#x0027;Anna, Pontedera, Italy","IEEE Transactions on Neural Systems and Rehabilitation Engineering","20170322","2017","25","3","227","234","The paradigm of simultaneous and proportional myocontrol of hand prostheses is gaining momentum in the rehabilitation robotics community. As opposed to the traditional surface electromyography classification schema, in simultaneous and proportional control the desired force/torque at each degree of freedom of the hand/wrist is predicted in real-time, giving to the individual a more natural experience, reducing the cognitive effort and improving his dexterity in daily-life activities. In this study we apply such an approach in a realistic manipulation scenario, using 10 non-linear incremental regression machines to predict the desired torques for each motor of two robotic hands. The prediction is enforced using two sets of surface electromyography electrodes and an incremental, non-linear machine learning technique called Incremental Ridge Regression with Random Fourier Features. Nine able-bodied subjects were engaged in a functional test with the aim to evaluate the performance of the system. The robotic hands were mounted on two hand/wrist orthopedic splints worn by healthy subjects and controlled online. An average completion rate of more than 95% was achieved in single-handed tasks and 84% in bimanual tasks. On average, 5 min of retraining were necessary on a total session duration of about 1 h and 40 min. This work sets a beginning in the study of bimanual manipulation with prostheses and will be carried on through experiments in unilateral and bilateral upper limb amputees thus increasing its scientific value.","1534-4320;15344320","","10.1109/TNSRE.2016.2554884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460959","Adaptive systems;machine learning;rehabilitation robotics","Electrodes;Electromyography;Indexes;Proportional control;Robot sensing systems;Training","Fourier analysis;biomedical electrodes;dexterous manipulators;electromyography;force control;learning (artificial intelligence);medical robotics;medical signal processing;orthopaedics;patient rehabilitation;prosthetics;regression analysis;signal classification;torque control","able-bodied subjects;average completion rate;bilateral upper limb amputees;bimanual manipulation;bimanual tasks;cognitive effort;daily-life activities;degree-of-freedom;dexterity;force-torque;hand prostheses;hand-wrist orthopedic splints;incremental learning;incremental nonlinear machine learning;incremental ridge regression;natural experience;nonlinear incremental regression machines;online bimanual manipulation;proportional myocontrol;random Fourier features;realistic manipulation scenario;rehabilitation robotics community;robotic hands;simultaneous myocontrol;single handed tasks;surface electromyography electrodes;time 5 min to 1.40 h;total session duration;traditional surface electromyography classification schema;unilateral upper limb amputees","","","","","","20160427","March 2017","","IEEE","IEEE Journals & Magazines"
"Adaptive sequential learning","C. Wilson; V. Veeravalli","Google","2016 50th Asilomar Conference on Signals, Systems and Computers","20170306","2016","","","326","330","A framework for learning a sequence of slowly changing tasks, where the parameters of the learning algorithm are obtained by minimizing a loss function to a desired accuracy using optimization algorithms such as stochastic gradient descent (SGD) is considered. The tasks change slowly in the sense that the optimum values of the learning algorithm parameters change at a bounded rate. An adaptive sequential learning algorithm is developed to solve such a slowly varying sequence of tasks. The adaptive sequential learning algorithm is extended to handle cross validation and a cost based approach to selecting the number of samples used to compute approximate solutions. Experiments with synthetic and real data are used to validate theoretical results.","","DVD:978-1-5386-3952-8; Electronic:978-1-5386-3954-2; POD:978-1-5386-3955-9","10.1109/ACSSC.2016.7869052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869052","adaptive algorithms;gradient methods;machine learning;stochastic optimization","Adaptation models;Advertising;Approximation algorithms;Complexity theory;Data models;Google;Optimization","learning (artificial intelligence);optimisation","SGD;adaptive sequential learning algorithm;cross validation;optimization algorithms;real data;stochastic gradient descent;synthetic data","","","","","","","6-9 Nov. 2016","","IEEE","IEEE Conference Publications"
"Relation discovery of mobile network alarms with sequential pattern mining","M. Lozonavu; M. Vlachou-Konchylaki; V. Huang","Ericsson AB, Stockholm, Sweden","2017 International Conference on Computing, Networking and Communications (ICNC)","20170313","2017","","","363","367","In telecommunication network systems, there are a large number of interconnected components which also contain many subcomponents. Heavy rain, thunder or other factors can cause mal-function of the components or disconnections between the components which trigger alarms. Because of the interconnection of elements, triggered alarms may propagate to other components. This creates harsh challenges to network operators when it comes to root cause analysis. We address this issue by proposing a method on utilizing network alarms for automatic relation discovery between network nodes. By understanding how network elements or network problems are related to each other, a network operator can easily correlate the alarm events and treat clustered groups of alarms instead of specific events. In this study, we use the temporal and spatial aspects of alarm events to cluster network elements. Our results demonstrate that by analyzing the network alarms, a relationship graph showing the connections between different network elements and network problems can be automatically generated. Such relationship graphs can help network operators mining node dependencies and discovering insights within their network.","","Electronic:978-1-5090-4588-4; POD:978-1-5090-4589-1","10.1109/ICCNC.2017.7876155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876155","Machine Learning;NOC;Network Management;OSS;Sequential Pattern Mining","Correlation;Databases;Mobile communication;Mobile computing;Peer-to-peer computing;Wireless communication","alarm systems;data mining;graph theory;pattern clustering;telecommunication network management","alarm events;automatic relation discovery;clustered alarm groups;interconnected components;mobile network alarms;network management;network operators;relationship graph;root cause analysis;sequential pattern mining;telecommunication network systems;triggered alarms","","","","","","","26-29 Jan. 2017","","IEEE","IEEE Conference Publications"
"Ensemble Learning From Synthetically Mixed Training Data for Quantifying Urban Land Cover With Support Vector Regression","A. Okujeni; S. van der Linden; S. Suess; P. Hostert","Geography Department, Humboldt-Universit&#x00E4;t zu Berlin, Unter den Linden 6, Berlin, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20170323","2017","10","4","1640","1650","Generating synthetically mixed data from library spectra provides a direct means to train empirical regression models for subpixel mapping. In order to best represent the subpixel composition of image data, the generation of synthetic mixtures must incorporate a multitude of mixing possibilities. This can lead to an excessive amount of training samples. We show that increasing mixing complexity in the training set improves model performance when quantifying urban land cover with support vector regression (SVR). To cope with the challenging increase in the number of training samples, we propose the use of ensemble learning based on bootstrap aggregation from synthetically mixed training data. The workflow is tested on simulated spaceborne imaging spectrometer data acquired over Berlin, Germany. Comparisons to SVR without bagging and multiple endmember spectral mixture analysis reveal the usefulness of the methodology for quantitative urban mapping.","1939-1404;19391404","","10.1109/JSTARS.2016.2634859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792573","Ensemble learning;hyperspectral;imaging spectrometry;machine learning;subpixel mapping;support vector regression (SVR);urban remote sensing","Data models;Imaging;Libraries;Remote sensing;Support vector machines;Training;Training data","land cover;regression analysis;remote sensing by radar;set theory;spaceborne radar;support vector machines;terrain mapping","Berlin;Germany;SVR;bootstrap aggregation;empirical regression model;ensemble learning;image data;multiple endmember spectral mixture analysis;quantitative urban mapping methodology;spaceborne imaging spectrometer data;subpixel composition;support vector regression;synthetic mixture generation;synthetically mixed training data;training sample;urban land cover","","","","","","20161221","April 2017","","IEEE","IEEE Journals & Magazines"
"Bag-of-Concepts Document Representation for Bayesian Text Classification","M. Mouriño-García; R. Pérez-Rodríguez; L. Anido-Rifón; M. Gómez-Carballa","Dept. of Telematics Eng., Univ. of Vigo, Vigo, Spain","2016 IEEE International Conference on Computer and Information Technology (CIT)","20170313","2016","","","281","288","The classification of text documents into a number of pre-defined categories has many application scenarios, for example the classification of news items into thematic sections. Documents to be classified are commonly represented by a bag-of-words feature vector. The bag-of-words model cannot handle two language phenomena: synonymy and polysemy, besides, dimensions of feature vectors are orthogonal. In order to effectively address those problems, some researchers adopt a bag-of-concepts representation of documents-understanding concept as ""unit of meaning'"". This paper reports a comprehensive experimental evaluation of the efficiency of a bag-of-concepts representation for Bayesian text classification, tackling synonymy and polysemy, and exploiting semantic relatedness between concepts to alleviate the problem of orthogonality-following an approach that we call semantic expansion. Results of experiments performed on three corpora widely used as benchmarks-Reuters, OHSUMED, and 20Newsgroups-show that: the efficiency of the bag-of-concepts approach is very dependent on the capacity of the semantic annotator for extracting concepts and on the characteristics of particular corpora, peaking on OHSUMED, and that it performs especially well when the number of training samples is small. In particular, for the shorter training sequence bag-of-concepts outperforms bag-of-words by 43.67% in OHSUMED and 22.44% in 20Newsgroups. This work provides useful insights to researchers that aim at applying bag-of-concepts representations, for example for organizing scientific articles in accordance with their thematic.","","Electronic:978-1-5090-4314-9; POD:978-1-5090-4315-6","10.1109/CIT.2016.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876349","bag-of-concepts;bag-of-words;document representation;information retrieval;machine learning;text classification","Bayes methods;Electronic publishing;Encyclopedias;Internet;Semantics;Text categorization","Bayes methods;information retrieval;learning (artificial intelligence);pattern classification;text analysis","20Newsgroups benchmark;Bayesian text document classification;OHSUMED benchmark;Reuters benchmark;bag-of-concepts document representation;bag-of-words feature vector;orthogonality problem;polysemy;scientific article organization;semantic annotator;semantic expansion;semantic relatedness;synonymy;training sequence bag-of-concepts;unit-of-meaning","","","","","","","8-10 Dec. 2016","","IEEE","IEEE Conference Publications"
"Behavior Analysis Based SMS Spammer Detection in Mobile Communication Networks","Z. Bin; Z. Gang; F. Yunbo; Z. Xiaolu; J. Weiqiang; D. Jing; G. Jiafeng","China Mobile Commun. Corp., China","2016 IEEE First International Conference on Data Science in Cyberspace (DSC)","20170302","2016","","","538","543","In a communication network, automatic short message service (SMS) spammer detection is a big challenge for a telecommunication operator nowadays, especially with the development of the rich communication services (RCS). Three main problems exist in the areas of research and real practice. They are (1) the whole-volume content based SMS spam detection techniques cannot be easily used on the side of network due to the issue of user privacy, (2) traditional ways to filter the spam according to the combination of key words and sending frequency can be easily bypassed by adding the interference words, (3) Most of them result in a great deal of manual review after the automatic filtering due to a low precision rate. To make up the aforementioned gaps, we study the user behavior characteristics. A two-dimensional visualized result indicates that any combination of two user behavior attributes cannot distinguish the abnormal users from the whole set by splitting the 2-dimensional space. Thus, the integration of multiple user behavior attributes is exploited to train the classifier in a labeled set by machine learning algorithms, respectively, including decision tree, random forest, supported vector machine (SVM), logistic regression, and self-organized feature mapping (SOM). The performance comparison indicates that random forest is a good choice to balance the tradeoff of the precision rate and the recall rate, and in an acceptable time. The experimental result shows the proposed method without the knowledge of SMS content has a significant improvement in terms of precision rate and recall rate compared with the traditional method using the combination of key words and sending frequency used in most of existing networks.","","Electronic:978-1-5090-1192-6; POD:978-1-5090-1193-3","10.1109/DSC.2016.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866183","Behavior Analysis;SMS spammer;communication network;machine learning","Electronic mail;Filtering;Machine learning algorithms;Mobile communication;Social network services;Support vector machines;Training","decision trees;electronic messaging;mobile computing;mobile radio;regression analysis;self-organising feature maps;support vector machines;unsolicited e-mail","RCS;SOM;SVM;automatic SMS spammer detection;automatic short message service spammer detection;decision tree;interference words;logistic regression;machine learning algorithms;multiple user behavior attributes;random forest;rich communication services;self-organized feature mapping;sending frequency;supported vector machine;telecommunication operator;two-dimensional visualized result;user behavior characteristics;whole-volume content based SMS spam detection techniques","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"An overview of Next Generation Technologies and its applications","R. Mukhi; M. Lakhani","Computer Engineering Department, Marwadi Education Foundation Group of Institution, Rajkot, Gujarat, India","2016 International Conference on Automatic Control and Dynamic Optimization Techniques (ICACDOT)","20170316","2016","","","389","393","The term Next Generation Technology has been often used by IT enthusiasts. Many see next generation technologies as one of the solution vectors for the global challenges of the 21<sup>st</sup> century. However, a small research has shed light on this term and specified its characteristics and meaning of it. Next generation technologies are critical to solve large problems faced by this world. Therefore, this paper aims to highlight the benefits of Next Generation Technology. The primary aim of this research paper was to highlight the importance of Next Generation Technology, to create awareness about its working principles and advantages and to inform its disadvantages. We have included the following concepts of the Next Generation Technology along with its implementing technology: Augmented Reality and Virtual Reality, Artificial Intelligence and Machine Learning, Autonomous Driving, Internet of Things, Modular Smartphones.","","Electronic:978-1-5090-2080-5; POD:978-1-5090-2081-2","10.1109/ICACDOT.2016.7877614","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877614","artificial intelligence;augmented reality;autonomous driving;internet of things;machine learning;modular smartphones;next generation technology;virtual reality","Artificial intelligence;Augmented reality;Automobiles;Computers;Next generation networking;Security","augmented reality;learning (artificial intelligence);smart phones","IT enthusiasts;Internet of Things;artificial intelligence;augmented reality;autonomous driving;machine learning;modular smartphones;next generation technologies;solution vectors;virtual reality","","","","","","","9-10 Sept. 2016","","IEEE","IEEE Conference Publications"
"Using logistic regression method to classify tweets into the selected topics","S. T. Indra; L. Wikarsa; R. Turang","Faculty of Engineering","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","385","390","Topics about health, music, sport, and technology are widely discussed in social network sites, especially in Twitter. Sharing information about those topics can enrich one's knowledge as well as increase the awareness of the current trends pertinent to the area of interests. Hence, this research aims to develop a web-based application that can classify tweets of netizens into these four categories of topics using one of machine learning methods called Logistic Regression. There are four main processes applied in this application that are fetching tweets, preprocessing, text feature extraction and machine learning. There are 1800 labeled tweets for each topic used as training data. Several processes were done in the pre-processing phase, including removal of URLs, punctuation, and stop words, tokenization, and stemming. Later, the application automatically converted the pre-processed tweets into set of features vector using Bag of Words. The set of features vector was applied to the Logistic Regression algorithm for the classification task. The trained classifier was then evaluated using 1800 tweets with 450 for each topic. Using Confusion Matrix, the results showed the accuracy of tweets classification into the selected topics is 92% which is considered very high.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872727","Twitter;health;logistic regression;machine learning;music;sport;technology;text classification;topic analysis","Feature extraction;Learning systems;Logistics;Mathematical model;Training;Twitter","Internet;classification;feature extraction;learning (artificial intelligence);regression analysis;social networking (online);text analysis;vectors","Twitter;URL;Web-based application;bag of words;feature vector;information sharing;logistic regression method;machine learning;selected topics;social network sites;text feature extraction;tweet classification","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Radio transformer networks: Attention models for learning to synchronize in wireless systems","T. J. O'Shea; L. Pemula; D. Batra; T. C. Clancy","Virginia Tech, Arlington, VA","2016 50th Asilomar Conference on Signals, Systems and Computers","20170306","2016","","","662","666","We introduce learned attention models into the radio machine learning domain for the task of modulation recognition by leveraging spatial transformer networks and introducing new radio domain appropriate transformations. This attention model allows the network to learn a localization network capable of synchronizing and normalizing a radio signal blindly with zero knowledge of the signal's structure based on optimization of the network for classification accuracy, sparse representation, and regularization. Using this architecture we are able to outperform our prior results in accuracy vs signal to noise ratio against an identical system without attention, however we believe such an attention model has implication far beyond the task of modulation recognition.","","DVD:978-1-5386-3952-8; Electronic:978-1-5386-3954-2; POD:978-1-5386-3955-9","10.1109/ACSSC.2016.7869126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869126","Attention Models;Cognitive Radio;Con-volutional Autoencoders;Deep Learning;Machine Learning;Neural Networks;Radio Transformer Networks;Radio communications;RadioML;Signal Processing;Software Radio;Spatial Transformer Networks;Synchronization","Convolution;Modulation;Neural networks;Signal to noise ratio;Synchronization;Training;Transforms","modulation;optimisation;radio networks","attention models;classification accuracy;modulation recognition;radio machine learning domain;radio signal;radio transformer networks;sparse representation;wireless systems","","","","","","","6-9 Nov. 2016","","IEEE","IEEE Conference Publications"
"Application identification via network traffic classification","B. Yamansavascilar; M. A. Guvensan; A. G. Yavuz; M. E. Karsligil","Department of Computer Engineering, Y&#x0131;ld&#x0131;z Technical University, Istanbul, TURKEY","2017 International Conference on Computing, Networking and Communications (ICNC)","20170313","2017","","","843","848","Recent developments in Internet technology have led to an increased importance of network traffic classification. In this study, we used machine-learning methods for the identification of applications using network traffic classification. Contrary to existing studies, which classify applications into categories like FTP, Instant Messaging, etc., we tried to identify popular end-user applications such as Facebook, Twitter, Skype and many more individually. We are motivated by the fact that individual identification of applications is of high importance for network security, QoS enforcement, and trend analysis. For our tests, we used UNB ISCX Network Traffic dataset and our internal dataset, consisting of 14 and 13 well-known applications respectively. In our experiments, we evaluated four classification algorithms, namely J48, Random Forest, k-NN, and Bayes Net. With the complete set of 111 features, k-NN gave the best result for the ISCX Dataset as 93.94% of accuracy using the value of k as 1, and Random Forest gave the best result for the internal dataset as 90.87% of accuracy. During the course of this study, the initial numbers of features were successfully reduced to two sets of 12 features specific to each dataset without a compromise to the success. Moreover, we observed a 2% increase in the success rate for the internal dataset. We believe that individual application identification by applying machine-learning methods is a viable solution and currently we are investigating a two-tier approach to make it more resilient to in category confusion.","","Electronic:978-1-5090-4588-4; POD:978-1-5090-4589-1","10.1109/ICCNC.2017.7876241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876241","Application-based;Machine Learning;Network Traffic Classification","Classification algorithms;IP networks;Instant messaging;Learning systems;Payloads;Telecommunication traffic","Bayes methods;Internet;learning (artificial intelligence);pattern classification;telecommunication computing;telecommunication traffic","Bayes Net;Internet technology;J48;QoS enforcement;Random Forest;UNB ISCX Network Traffic dataset;application identification;classification algorithms;end-user applications;k-NN;machine-learning methods;network security;network traffic classification;trend analysis;two-tier approach","","","","","","","26-29 Jan. 2017","","IEEE","IEEE Conference Publications"
"Design and Implementation of a Communication-Optimal Classifier for Distributed Kernel Support Vector Machines","Y. You; J. Demmel; K. Czechowski; L. Song; R. Vuduc","Computer Science Division, UC Berkeley, CA","IEEE Transactions on Parallel and Distributed Systems","20170310","2017","28","4","974","988","We consider the problem of how to design and implement communication-efficient versions of parallel kernel support vector machines, a widely used classifier in statistical machine learning, for distributed memory clusters and supercomputers. The main computational bottleneck is the training phase, in which a statistical model is built from an input data set. Prior to our study, the parallel isoefficiency of a state-of-the-art implementation scaled as W = Ω(P<sup>3</sup>), where W is the problem size and P the number of processors; this scaling is worse than even a one-dimensional block row dense matrix vector multiplication, which has W = Ω(P<sup>2</sup>). This study considers a series of algorithmic refinements, leading ultimately to a Communication-Avoiding SVM method that improves the isoefficiency to nearly W = Ω(P). We evaluate these methods on 96 to 1,536 processors, and show average speedups of 3 - 16x (7× on average) over Dis-SMO, and a 95 percent weak-scaling efficiency on six real-world datasets, with only modest losses in overall classification accuracy. The source code can be downloaded at [1].","1045-9219;10459219","","10.1109/TPDS.2016.2608823","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565530","Distributed memory algorithms;communication-avoidance;statistical machine learning","Data models;Kernel;Optimization;Partitioning algorithms;Program processors;Support vector machines;Training","distributed memory systems;learning (artificial intelligence);parallel machines;pattern classification;statistical analysis;support vector machines","Dis-SMO;algorithmic refinements;classification accuracy;communication-avoiding SVM method;communication-optimal classifier design;distributed kernel support vector machines;distributed memory clusters;parallel isoefficiency;parallel kernel support vector machines;statistical machine learning;supercomputers","","","","","","20160913","April 1 2017","","IEEE","IEEE Journals & Magazines"
"FALCON: Feature Driven Selective Classification for Energy-Efficient Image Recognition","P. Panda; A. Ankit; P. Wijesinghe; K. Roy","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, 47907 USA (e-mail: pandap@purdue.edu)","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2017","PP","99","1","1","Machine-learning algorithms have shown outstanding image recognition/classification performance for computer vision applications. However, the compute and energy requirement for implementing such classifier models for large-scale problems is quite high. In this paper, we propose Feature Driven Selective Classification (FALCON) inspired by the biological visual attention mechanism in the brain to optimize the energy-efficiency of machine-learning classifiers. We use the consensus in the characteristic features (color/texture) across images in a dataset to decompose the original classification problem and construct a tree of classifiers (nodes) with a generic-to-specific transition in the classification hierarchy. The initial nodes of the tree separate the instances based on feature information and selectively enable the latter nodes to perform object specific classification. The proposed methodology allows selective activation of only those branches and nodes of the classification tree that are relevant to the input while keeping the remaining nodes idle. Additionally, we propose a programmable and scalable Neuromorphic Engine (NeuE) that utilizes arrays of specialized neural computational elements to execute the FALCON based classifier models for diverse datasets. The structure of FALCON facilitates the reuse of nodes while scaling up from small classification problems to larger ones thus allowing us to construct classifier implementations that are significantly more efficient. We evaluate our approach for a 12- object classification task on the Caltech101 dataset and 10-object task on CIFAR-10 dataset by constructing FALCON models on the NeuE platform in 45nm technology. Our results demonstrate up to 3.66x improvement in energy-efficiency for no loss in output quality, and even higher improvements of up to 5.91x with 3.9% accuracy loss compared to an optimised baseline network. In addition, FALCON shows an improvement in training time of up to 1.96x as compared to- the traditional classification approach.","0278-0070;02780070","","10.1109/TCAD.2017.2681075","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875411","Energy-Efficient Classification;Hierarchical Feature Learning;Machine Learning;Neuromorphic Hardware;Selective Activation","Computational modeling;Hardware;Image color analysis;Neuromorphics;Training;Visualization","","","","","","","","20170310","","","IEEE","IEEE Early Access Articles"
"Prospective Fall-Risk Prediction Models for Older Adults based on Wearable Sensors","J. Howcroft; J. Kofman; E. Lemaire","Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada N2L 3G1. She is currently with Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada K1S 5B6.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2017","PP","99","1","1","Wearable sensors can provide quantitative, gait-based assessments that can translate to point-of-care environments. This investigation generated elderly fall-risk predictive models based on wearable-sensor-derived gait data and prospective fall occurrence; and identified the optimal sensor type, location, and combination for single and dual-task walking. 75 individuals who reported six month prospective fall occurrence (75.2 ± 6.6 years; 47 non-fallers, 28 fallers) walked 7.62 m under single-task and dual-task conditions while wearing pressure-sensing insoles and tri-axial accelerometers at the head, pelvis, and left and right shanks. Fall-risk classification models were assessed for all sensor combinations and three model types: neural network, naïve Bayesian, and support vector machine. The best performing model used a neural network, dual-task gait data, and input parameters from head, pelvis, and left shank accelerometers (accuracy = 57%, sensitivity = 43%, specificity = 65%). The best single-sensor model used a neural network, dual-task gait data, and pelvis accelerometer parameters (accuracy = 54%, sensitivity = 35%, specificity = 67%). Single-task and dual-task gait assessments provided similar fall-risk model performance. Fall-risk predictive models developed for point-of-care environments should use multi-sensor dual-task gait assessment with the pelvis location considered if assessment is limited to a single sensor.","1534-4320;15344320","","10.1109/TNSRE.2017.2687100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886263","Accelerometer;artificial intelligence;classifiers;fall risk;machine learning;pressure-sensing insole","Accelerometers;Artificial neural networks;Data models;Legged locomotion;Pelvis;Predictive models","","","","","","","","20170324","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Household Load Forecasting – A Novel Pooling Deep RNN","H. Shi; M. Xu; R. Li","","IEEE Transactions on Smart Grid","","2017","PP","99","1","1","The key challenge for household load forecasting lies in the high volatility and uncertainty of load profiles. Traditional methods tend to avoid such uncertainty by load aggregation (to offset uncertainties), customer classification (to cluster uncertainties) and spectral analysis (to filter out uncertainties). This paper, for the first time, aims to directly learn the uncertainty by applying a new breed of machine learning algorithms – deep learning. However simply adding layers in neural networks will cap the forecasting performance due to the occurrence of overfitting. A novel pooling-based deep recurrent neural network (PDRNN) is proposed in this paper which batches a group of customers’ load profiles into a pool of inputs. Essentially the model could address the over-fitting issue by increasing data diversity and volume. This work reports the first attempts to develop a bespoke deep learning application for household load forecasting and achieved preliminary success. The developed method is implemented on Tensorflow deep learning platform and tested on 920 smart metered customers from Ireland. Compared with the state-of-art techniques in household load forecasting, the proposed method outperforms ARIMA by 19.5%, SVR by 13.1% and classical deep RNN by 6.5% in terms of RMSE.","1949-3053;19493053","","10.1109/TSG.2017.2686012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885096","big data;deep learning;load forecasting;long short-term memory;machine learning;neural network;smart meter","Computer architecture;Forecasting;Load forecasting;Machine learning;Neural networks;Training;Uncertainty","","","","","","","","20170322","","","IEEE","IEEE Early Access Articles"
"Sentiment mining: An approach for Bengali and Tamil tweets","S. S. Prasad; J. Kumar; D. K. Prabhakar; S. Tripathi","Department of Computer Science & Engineering, Indian Institute of Technology (ISM), Dhanbad, India","2016 Ninth International Conference on Contemporary Computing (IC3)","20170320","2016","","","1","4","This paper presents a proposed work for extracting the sentiments from tweets in Indian Language. We proposed a system that deal with the goal to extract the sentiments from Bengali & Tamil tweets. Our aim is to classify a given Bengali or Tamil tweets into three sentiment classes namely positive, negative or neutral. In recent time, Twitter gain much attention to NLP researchers as it is most widely used platform that allows the user to share there opinion in form of tweets. The proposed methodology used unigram and bi-gram models along with different supervised machine learning techniques. We also consider the use of features generated from lexical resources such as Wordnets and Emoticons Tagger.","","CD:978-1-5090-3249-5; Electronic:978-1-5090-3251-8; POD:978-1-5090-3252-5","10.1109/IC3.2016.7880246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880246","Information Retrieval;Machine learning;Natural Language Processing;Polarity Identification;Sentiment Mining","Decision trees;Feature extraction;Sentiment analysis;Tagging;Thumb;Twitter","data mining;learning (artificial intelligence);sentiment analysis;social networking (online)","Bengali tweets;Indian Language;NLP;Tamil tweets;Twitter;bi-gram models;sentiment mining;supervised machine learning;unigram models","","","","","","","11-13 Aug. 2016","","IEEE","IEEE Conference Publications"
"Decision Trees for the Detection of Skin Lesion Patterns in Lower Limbs Ulcers","J. L. Seixas; R. G. Mantovani","Comput. Sci. Dept., State Univ. of Parana, Apucarana, Brazil","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","677","681","Misleading diagnosis of skin diseases can result in complications during the healing process. Skin images provide important information for the medical staff for information storage and exchange, to trying to prevent this misdiagnosis from happening. For such, a good segmentation process is needed. The segmentation of these images is already being used and has been an effective tool for skin diseases recognition. This paper presents a method for targeting seeds for region growing algorithms, as several of region growing algorithms have good clustering results, but are sensitive to seed. Machine learning were use to create the seed for segmentation of medical images of skin ulcers in the lower limbs. For machine learning, decision tree algorithms were used, which bring a more intuitive approach. The results were compared with gold standard obtained with the help of experts, the results were good and opened paths that can be followed for further work since, even though good results, they can still be improved.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881426","Image segmentation;decision trees;machine learning;seed","Decision trees;Image color analysis;Image segmentation;Lesions;Medical diagnostic imaging;Skin","decision trees;diseases;image recognition;image segmentation;learning (artificial intelligence);medical image processing;object detection;skin","decision tree algorithms;information exchange;information storage;lower limbs ulcers;machine learning;medical image segmentation process;region growing algorithms;skin disease diagnosis;skin disease recognition;skin images;skin lesion pattern detection","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Simulators as Drivers of Cutting Edge Research","M. A. Raja; S. Ali; A. Mahmood","Dept. of Comput. Sci., Namal Coll., Mianwali, Pakistan","2016 7th International Conference on Intelligent Systems, Modelling and Simulation (ISMS)","20170316","2016","","","114","119","Undertaking engineering research can be compounding for beginning graduate students and thwarting even for seasoned researchers. With a wealth of academic literature and a myriad of software development and open-source computing tools available online, the life of a researcher should have become much easier. However, the overwhelming body of knowledge, that is increasing rapidly by the day, quite frequently often confuses a researcher about things that should be done. It is normal to find beginning graduate students who are clueless about how they should conduct their research. Similarly, part of the onus shifts to the academic supervisors too. They are equally oblivious about delivering worthwhile problems and adequate supervision to their students. This position paper is written in this wake. The motive is to highlight important ideas about how good research should be conducted in today's multidisciplinary academic world. A particular intention is to highlight the importance of employing domain-specific simulators for successful research. More specifically, it is argued that in order to conduct good quality research in various scientific and academic disciplines, it is not only important, rather inevitable to employ simulators for conducting cutting-edge research. It is hoped that taking heed from this paper would lead to better research and make research a more fulfilling and enjoyable experience for the researcher.","2166-0670;21660670","Electronic:978-1-5090-0665-6; POD:978-1-5090-0666-3","10.1109/ISMS.2016.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877199","Simulators;machine learning;software integration","Algorithm design and analysis;Communication networks;Computational modeling;Computer science;Machine learning algorithms;Software;Vehicle routing","integrated software;research initiatives;software engineering","academic supervisors;cutting edge research;domain-specific simulators;drivers;engineering research;graduate students;multidisciplinary academic world;open source computing tools;quality research;software development","","","","","","","25-27 Jan. 2016","","IEEE","IEEE Conference Publications"
"Partial Knowledge Data-driven Event Detection for Power Distribution Networks","Y. Zhou; R. Arghandeh; C. J. Spanos","Electrical Engineering Computer Sciences, University of California, Berkeley, 94720 CA USA (e-mail: yxzhou@berkeley.edu)","IEEE Transactions on Smart Grid","","2017","PP","99","1","1","The power system has been incorporating increasing amount of unconventional generations and loads such as distributed renewable resources, electric vehicles, and controllable loads. The induced dynamic and stochastic power flow require high-resolution monitoring technology and agile decision support techniques for system diagnosis and control. This paper discusses the application of micro-phasor measurement unit (PMU) data for power distribution network event detection. A novel datadriven event detection method, namely Hidden Structure Semi- Supervised Machine (HS<formula> <tex>$^{3}$</tex> </formula>M), is established. HS<formula> <tex>$^{3}$</tex> </formula>M only requires partial expert knowledge: it combines unlabeled data and partly labeled data in a large margin learning objective to bridge the gap between supervised learning, semi-supervised learning, and learning with hidden structures. To optimize the non-convex learning objective, a novel global optimization algorithm, namely Parametric Dual Optimization Procedure (PDOP), is established through its equivalence to a concave programming. Finally, the proposed method is validated on an actual distribution feeder with installed PMUs, and the result justifies the effectiveness of the learning-based event detection framework, as well as its potential to serve as one","1949-3053;19493053","","10.1109/TSG.2017.2681962","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876731","Distribution;Event Detection;Machine Learning;Phasor Measurement Unit","Event detection;Indexes;Monitoring;Power measurement;Power system dynamics;Voltage measurement","","","","","","","","20170313","","","IEEE","IEEE Early Access Articles"
"A Methodology for Full-System Power Modeling in Heterogeneous Data Centers","M. Canuto; R. Bosch; M. Macias; J. Guitart","Barcelona Supercomput. Center (BSC), Barcelona, Spain","2016 IEEE/ACM 9th International Conference on Utility and Cloud Computing (UCC)","20170320","2016","","","20","29","The need for energy-awareness in current data centers has encouraged the use of power modeling to estimate their power consumption. However, existing models present noticeable limitations, which make them application-dependent, platform-dependent, inaccurate, or computationally complex. In this paper, we propose a platform-and application-agnostic methodology for full-system power modeling in heterogeneous data centers that overcomes those limitations. It derives a single model per platform, which works with high accuracy for heterogeneous applications with different patterns of resource usage and energy consumption, by systematically selecting a minimum set of resource usage indicators and extracting complex relations among them that capture the impact on energy consumption of all the resources in the system. We demonstrate our methodology by generating power models for heterogeneous platforms with very different power consumption profiles. Our validation experiments with real Cloud applications show that such models provide high accuracy (around 5% of average estimation error).","","Electronic:978-1-4503-4616-0; POD:978-1-5090-4467-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881611","Energy awareness;Machine learning;Power modeling","Biological system modeling;Computational modeling;Data models;Power demand;Power measurement;Radiation detectors;Training","cloud computing;computer centres;estimation theory;power aware computing;power consumption","application agnostic methodology;cloud applications;energy awareness;full-system power modeling;heterogeneous data centers;platform agnostic methodology;power consumption estimation","","","","","","","6-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Short-term load forecasting in smart grid: A combined CNN and K-means clustering approach","Xishuang Dong; Lijun Qian; Lei Huang","Center of Excellence in Research and Education for Big Military Data Intelligence, Prairie View A&M University, Texas A&M University System, 77446, USA","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","119","125","Although many methods are available to forecast short-term electricity load based on small scale data sets, they may not be able to accommodate large data sets as electricity load data becomes bigger and more complex in recent years. In this paper, a novel machine learning model combining convolutional neural network with K-means clustering is proposed for short-term load forecasting with improved scalability. The large data set is clustered into subsets using K-means algorithm, then the obtained subsets are used to train the convolutional neural network. A real-world power industry data set containing more than 1.4 million of load records is used in this study and the experimental results demonstrate the effectiveness of the proposed method.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881726","Big Data Analytics;Convolutional Neural Network;Machine Learning;Short-term Load Forecasting","Data models;Forecasting;Load forecasting;Load modeling;Predictive models;Testing;Training","learning (artificial intelligence);load forecasting;neural nets;pattern clustering;power engineering computing;smart power grids","CNN;K-means algorithm;K-means clustering approach;convolutional neural network;machine learning model;short-term load forecasting;smart grid","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"The power of big data and algorithms for advertising and customer communication","N. Neumann","Institute for Choice, University of South Australia, Sydney, Australia","2016 International Workshop on Big Data and Information Security (IWBIS)","20170309","2016","","","13","14","Leveraging customer data in scale and often in real time has led to a new field called programmatic commerce - the use of data, automation and analytics to improve customer experiences and company performances. In particular in advertising and marketing, programmatic applications have become very popular because they allow personalization/ micro-targeting as well as easier media planning due to the rise of automated buying processes. In this review study, we will discuss the development of the new field around advertising and marketing technology and summarize present research efforts. In addition, some industry case studies will be shared to illustrate the power of the latest big-data and machine-learning applications for driving business outcomes.","","Electronic:978-1-5090-3477-2; POD:978-1-5090-3478-9; USB:978-1-5090-3476-5","10.1109/IWBIS.2016.7872882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872882","advertising technology;machine learning;online advertising;targeting","Advertising;Automation;Companies;Industries;Media;Real-time systems","Big Data;advertising data processing;electronic commerce;learning (artificial intelligence)","Big Data;automated buying processes;company performances;customer communication;customer data;customer experiences;data use;machine learning;marketing;media planning;microtargeting;online advertising;personalization;programmatic applications;programmatic commerce","","","","","","","18-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Development of semi-supervised named entity recognition to discover new tourism places","K. E. Saputro; S. S. Kusumawardani; S. Fauziati","Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia","2016 2nd International Conference on Science and Technology-Computer (ICST)","20170316","2016","","","124","128","Tourism information needs are increasing in line with tourism that has been a primary need for some people. This has an impact on the growth of the tourism information provider. The amount of available information sometimes makes tourist confuse to the information that they needed. Currently, the search systems only rely on indexing web pages so that the information obtained by the tourist is still unfavorable because it only shows a web page with keywords that exist on the article. A support system to recognize tourism places on the web pages is required to produce better information presentation. In this study, the recognition system based on Yet Another Two Stage Idea (YATSI) Semi-Supervised Learning with the Naïve Bayes classifier is used to address the problem. Results obtained by classifying candidate entities on a hundred web pages demonstrate 74% precision with 70% recall.","","Electronic:978-1-5090-4357-6; POD:978-1-5090-4358-3; Paper:978-1-5090-4356-9","10.1109/ICSTC.2016.7877360","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877360","information retrieval;machine learning;naïve bayes;named entity recognition;semi-supervised learning;tourism destinations","Classification algorithms;Dictionaries;Machine learning algorithms;Prediction algorithms;Supervised learning;Urban areas;Web pages","Bayes methods;Internet;indexing;information needs;information retrieval;learning (artificial intelligence);pattern classification;travel industry","Naïve Bayes classifier;VATSI semisupervised learning;Web pages;indexing;information presentation;search systems;semisupervised named entity recognition;support system;tourism information needs;tourism information provider;tourism place recognition;vet another two stage idea semisupervised learning","","","","","","","27-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"On the Anatomy of the Dynamic Behavior of Polymorphic Viruses","A. Cabrera; R. A. Calix","Coll. of Technol., Purdue Univ. Northwest, Hammond, IN, USA","2016 International Conference on Collaboration Technologies and Systems (CTS)","20170306","2016","","","424","429","The sophistication of novel strains of polymorphic viruses, such as Stuxnet, has increased over the last decade. Traditional tools such as anti-virus, firewalls, intrusion detection/prevention systems, etc. may be incapable of detecting such strains. As a result, new methods need to be introduced in order to detect this family of malware. Combining dynamic malware analysis techniques with machine learning tools can prove useful in the progression of developing an effective and efficient classifier. This paper explores the use of dynamic analysis of malware and machine learning to create a classifier for polymorphic virus detection.","","Electronic:978-1-5090-2300-4; POD:978-1-5090-2301-1","10.1109/CTS.2016.0081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871019","S-Stuxnet;dynamic malware analysis;emulators;machine learning;malware detection","Algorithm design and analysis;Feature extraction;Machine learning algorithms;Malware;Strain;Viruses (medical)","computer viruses;learning (artificial intelligence);pattern classification","classifier;machine learning;malware analysis techniques;polymorphic virus detection","","","","","","","Oct. 31 2016-Nov. 4 2016","","IEEE","IEEE Conference Publications"
"Detecting Android malware with intensive feature engineering","Manzhi Yang; QiaoYan Wen","State Key Laboratory of Networking and Switching Technology, BUPT, Beijing, China","2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20170323","2016","","","157","161","Nowadays, the amount of the application in Android App Market has grown fast, and the android malwares have been introduced fast into that market, too. In this paper, we use static analysis of a given android application with intensive feature engineering which we focus on different sources and different levels. It means that we not only extract features from the executable file classes.dex but also from the other android resource files such as manifest of the application, more over we expand features at different levels of abstraction of the APK application, rather than using more features at the single level. Finally, we combine these different feature sets into one feature set which is used by the classifiers for training/testing. Our method is compared against other Android malware code detection and found to be more efficient in terms of detection accuracy and false alarm rate.","","Electronic:978-1-4673-9904-3; POD:978-1-4673-9905-0","10.1109/ICSESS.2016.7883038","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883038","Android;Data Classification;Machine Learning;Malware Detection;feature engineering","HTML","Android (operating system);invasive software;program diagnostics","APK application;Android app market;intensive feature engineering;malware code detection;malware detection;static analysis","","","","","","","26-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Robustness Analysis of a Memristive Crossbar PUF Against Modeling Attacks","M. Uddin; M. B. Majumder; G. S. Rose","Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN, 37996 (e-mail: muddin6@vols.utk.edu).","IEEE Transactions on Nanotechnology","","2017","PP","99","1","1","In the greater context of computer security, hardware security issues such as integrated circuit counterfeiting, cloning, reverse engineering and piracy have emerged as critical issues due in part to an increasingly globalized supply chain. To help combat hardware security vulnerabilities, a wide range of security primitives have emerged in recent years. A popular example are physical unclonable functions (PUFs) which leverage process variations to provide unique signatures or fingerprints that can be used for authentication or secret key generation. Nanoelectronic technologies, such as the memristor technologies considered here, provide an excellent opportunity to engineer dense, energy-efficient PUF circuits with desirable statistical properties. Here we specifically focus on the design considerations of a memristive crossbar based PUF that generates response bits as a function of variable memristor switching time. In addition to describing the operation of the crossbar PUF, we also consider its resilience to two specific machine learning attacks, specifically through the use of linear regression and support vector machines. Two circuit design modifications for the crossbar PUF are provided to improve the resilience to machine learning attacks: XORing of response bits and internal column swapping. We show that the design modifications lead to a reduction in the likelihood of successful attack to about 50% (near ideal) even given 5,000 iterations for the attack itself. We also provide power estimates and performance considerations for the crossbar PUF based on three specific memristive material stacks: hafniumoxide, tantalum-oxide and titanium-oxide.","1536-125X;1536125X","","10.1109/TNANO.2017.2677882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870644","PUF;Physically unclonable function;RRAM;ReRAM;emerging nanotechnology;hardware security;machine learning attack;memristor;memristor PUF;modeling attack;transition metal-oxide","Integrated circuit modeling;Mathematical model;Memristors;Resistance;Support vector machines;Switches;Threshold voltage","","","","","","","","20170303","","","IEEE","IEEE Early Access Articles"
"Writer identification using a probabilistic model of handwritten digits and approximate Bayesian computation","A. Ahmadian; K. Fouladi; B. N. Araabi","Machine Learning and Computational Modeling Lab, Control and Intelligent Processing Center of Excellence, School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran","2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS)","20170306","2016","","","1","6","Writer identification is a classification problem where the classes correspond to a group of writers and the data points are their handwriting samples. This paper proposes an approach to offline text-sensitive writer identification on the basis of a probabilistic generative model of isolated handwritten digits. The model parameters are learned separately for each writer, and the writer of query samples is identified via Bayes decision rule. We deal with a scenario where just a few handwritten instances of a certain Latin digit exist as the training set for each writer. To handle the data sparseness problem, the parameters are learned in a fully Bayesian fashion instead of point estimators through a Markov chain Monte Carlo sampling algorithm. In addition, the hyperparameters are obtained from a background set which contains samples from various writers. Due to computational concerns, an explicit likelihood function is not defined in the model. Instead, the ideas of approximate Bayesian computation have been used in performing inference. Experimental results support the key ideas of the proposed approach.","","Electronic:978-1-5090-5820-4; POD:978-1-5090-5821-1","10.1109/ICSPIS.2016.7869875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869875","Approximate Bayesian Computation;Bayesian Estimation;Bayesian Network;Generative Model;Image Processing;Machine Learning;Markov Chain Monte Carlo Sampling;Writer Identification","Approximation algorithms;Bayes methods;Computational modeling;Hidden Markov models;Probabilistic logic;Splines (mathematics);Training","Bayes methods;Markov processes;Monte Carlo methods;decision theory;handwritten character recognition;image classification;image sampling;learning (artificial intelligence)","Bayes decision rule;Latin digit;approximate Bayesian computation;classification problem;data sparseness problem handling;explicit likelihood function;handwriting samples;isolated handwritten digits;model parameter learning;offline text-sensitive writer identification;probabilistic generative model;query samples","","","","","","","14-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Automatic Classification of Player Complaints in Social Games","K. Balcı; A. A. Salah","Department of Computer Engineering, Bo&#287;azi&#231;i University, Istanbul, Turkey","IEEE Transactions on Computational Intelligence and AI in Games","20170315","2017","9","1","103","108","Artificial intelligence and machine learning techniques are not only useful for creating plausible behaviors for interactive game elements, but also for the analysis of the players to provide a better gaming environment. In this paper, we propose a novel framework for automatic classification of player complaints in a social gaming platform. We use features that describe both parties of the complaint (namely, the accuser and the suspect), as well as interaction features of the game itself. The proposed classification approach, based on gradient boosting machines, is tested on the COPA Database of 100 000 unique users and 800 000 individual games. We advance the state of the art in this challenging problem.","1943-068X;1943068X","","10.1109/TCIAIG.2015.2490339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298418","Abusive behavior;chat analysis;in-game aggression;machine learning;online social games;sociability","Boosting;Communication channels;Companies;Computers;Databases;Games","behavioural sciences computing;classification;computer games;gradient methods;interactive systems;learning (artificial intelligence);social sciences computing","COPA database;artificial intelligence;automatic classification;gradient boosting machines;interactive game elements;machine learning;plausible behaviors;player complaints;social games","","","","","","20151014","March 2017","","IEEE","IEEE Journals & Magazines"
"Predicting Cloud Resource Utilization","M. Borkowski; S. Schulte; C. Hochreiner","Distrib. Syst. Group, Tech. Univ. Wien, Vienna, Austria","2016 IEEE/ACM 9th International Conference on Utility and Cloud Computing (UCC)","20170320","2016","","","37","42","A major challenge in Cloud computing is resource provisioning for computational tasks. Not surprisingly, previous work has established a number of solutions to provide Cloud resources in an efficient manner. However, in order to realize a holistic resource provisioning model, a prediction of the future resource consumption of upcoming computational tasks is necessary. Nevertheless, the topic of prediction of Cloud resource utilization is still in its infancy stage. In this paper, we present an approach for predicting Cloud resource utilization on a per-task and per-resource level. For this, we apply machine learning-based prediction models. Based on extensive evaluation, we show that we can reduce the prediction error by 20% in a typical case, and improvements above 89% are among the best cases.","","Electronic:978-1-4503-4616-0; POD:978-1-5090-4467-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881613","Cloud computing;Machine Learning;Resource usage;Usage prediction","Cloud computing;Computational modeling;Data models;Measurement;Predictive models;Resource management;Training","cloud computing;learning (artificial intelligence);resource allocation","cloud computing;cloud resource utilization prediction;computational tasks;machine learning;per resource level;per task level;resource provisioning","","","","","","","6-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Improving Execution Concurrency of Large-scale Matrix Multiplication on Distributed Data-parallel Platforms","R. Gu; Y. Tang; C. Tian; H. Zhou; G. Li; X. Zheng; Y. Huang","","IEEE Transactions on Parallel and Distributed Systems","","2017","PP","99","1","1","Matrix multiplication is a dominant but very time-consuming operation in many big data analytic applications. Thus its performance optimization is an important and fundamental research issue. The performance of large-scale matrix multiplication on distributed dataparallel platforms is determined by both computation and IO costs. For existing matrix multiplication execution strategies, when the execution concurrency scales up above a threshold, their execution performance deteriorates quickly because the increase of IO cost outweighs the decrease of computation cost. This paper presents a novel parallel execution strategy CRMM (Concurrent Replication-based Matrix Multiplication) along with a parallel algorithm, Marlin, for large-scale matrix multiplication on data-parallel platforms. The CRMM strategy exploits higher execution concurrency for sub-block matrix multiplication with the same IO cost. To further improve the performance of Marlin, we also propose a number of novel system-level optimizations, including increasing the concurrency of local data exchange by calling native library in batch, reducing the overhead of block matrix transformation, and reducing disk heavy shuffle operations by exploiting the semantics of matrix computation. We have implemented Marlin as a library along with a set of related matrix operations on Spark and also contributed Marlin to the open-source community. For large-sized matrix multiplication, Marlin outperforms existing systems including Spark MLlib, SystemML and SciDB, with about 1:29<formula> <tex>$times$</tex> </formula>, 3:53<formula> <tex>$times$</tex> </formula> and 2:21<formula> <tex>$times$</tex> </formula> speedup on average, respectively. The evaluation upon a real-world DNN workload also indicates that Marlin outperforms above systems by about 12:8<formula> <tex>$times$</tex> </formula>, 5:1<formula> <tex>$times$</tex> </formula> and 27:2<formula> <tex>$times$</tex> </formula> speedup, respectively.","1045-9219;10459219","","10.1109/TPDS.2017.2686384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884988","Data-parallel algorithms;Machine learning library;Parallel matrix multiplication","Big Data;Concurrent computing;Libraries;Machine learning algorithms;Optimization;Sparks;Training","","","","","","","","20170322","","","IEEE","IEEE Early Access Articles"
"Classification of Expert-Novice Level of Mobile Game Players Using Electroencephalography","S. M. Anwar; S. M. U. Saeed; M. Majid","Dept. of Software Eng., Univ. of Eng. & Technol., Taxila, Pakistan","2016 International Conference on Frontiers of Information Technology (FIT)","20170302","2016","","","315","318","An exponential increase has been observed in number of mobile game players in last five years. An increasing number of researches have been emerged that assesses the cognitive aspects of video game players. This creates a need to classify the expert-novice level of a player. A novel approach to classify players expert-novice level is to use machine learning algorithm by considering recorded electroencephalography (EEG) signals of player while playing mobile games. In this research work, EEG signals of ten mobile game players is recorded by commercially available 14 channel EMOTIV headset. After preprocessing stage, a feature vector is created in such a way that from each channel, thirteen morphological features are extracted. The extracted features are used to train three different classification algorithms. The Naive Bayes performed with an accuracy of 89:89%. From results, it is evident that EEG can be used to classify the expert-novice level of a player using machine algorithms. These results can be useful in the development of new and interesting entertainment and educational mobile games taking into account the player's cognition using EEG.","","Electronic:978-1-5090-5300-1; POD:978-1-5090-5301-8","10.1109/FIT.2016.064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866773","Brain Computer Interface;EEG;Machine Learning;Mobile Game;Wearable Sensors","Classification algorithms;Electroencephalography;Feature extraction;Games;Land mobile radio;Machine learning algorithms;Support vector machines","Bayes methods;cognitive systems;computer aided instruction;computer games;electroencephalography;feature extraction;learning (artificial intelligence);mobile computing;signal classification;vectors","EEG signals;cognitive aspects;educational mobile games;electroencephalography signals;expert novice level classification;feature extraction;feature vector;machine learning;mobile game players;naive Bayes;video game players","","","","","","","19-21 Dec. 2016","","IEEE","IEEE Conference Publications"
"A modulation classification method in cognitive radios system using stacked denoising sparse autoencoder","X. Zhu; T. Fujii","Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, 182-8585 Japan","2017 IEEE Radio and Wireless Symposium (RWS)","20170327","2017","","","218","220","This paper proposes a modulation classification method based on Stacked Denoising Sparse Autoencoder (SDAE). This method can extract modulation features automatically, and classify input signals based on the features it extracts. The scenarios of rapid classification and high accuracy classification are considered. In the rapid classification scenario, a long symbols sequence is not attainable for this scenario. Moreover, expert features are not necessary for this scenario, simplifying the modulation classification procedure and rendering rapid classification more achievable. In addition, in the high accuracy classification scenario, the higher cumulants are used as expert features due to its advantage over other tries at noise resistance. Moreover, we use complex symbols rather than pulse shaped complex signals as network input, which simplifies the network topology and saves the calculation overhead. The results of the average classification accuracy and the execution time are presented, indicating significant performance advantages over the other methods.","","Electronic:978-1-5090-3446-8; POD:978-1-5090-3447-5","10.1109/RWS.2017.7885992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885992","cognitive radio;machine learning;modulation classification","Cognitive radio;Feature extraction;Manganese;Modulation;Noise reduction;Resistance;Training","cognitive radio;modulation;signal denoising","SDAE;cognitive radio system;complex symbols;feature extraction;modulation classification method;network topology;stacked denoising sparse autoencoder","","","","","","","15-18 Jan. 2017","","IEEE","IEEE Conference Publications"
"A Parallel Bi-Perceptron Approach and Its Application to Data Classification","D. R. Liou; Y. E. Chen; C. Y. Liou","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1152","1157","Since the kernel function in support vector machine is arbitrary, it carries no physical meaning in practical applications. This work presents a bi-perceptron network that works in real physical space. All network parameters can be obtained in a constructive way without training. It is a divide-and-conquer way with perfect performance. We show how to operate this network to classify records.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881511","classification;machine learning;neural network;perceptron;text categorization","Computational intelligence;Decision support systems;Handheld computers;Scientific computing","learning (artificial intelligence);multilayer perceptrons;pattern classification;support vector machines","bi-perceptron network;data classification;divide-and-conquer approach;kernel function;parallel bi-perceptron approach;records classification;support vector machine","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Content Coding of Psychotherapy Transcripts Using Labeled Topic Models","G. Gaut; M. Steyvers; Z. E. Imel; D. C. Atkins; P. Smyth","Department of Cognitive Science, University of California Irvine, Irvine, CA, USA","IEEE Journal of Biomedical and Health Informatics","20170303","2017","21","2","476","487","Psychotherapy represents a broad class of medical interventions received by millions of patients each year. Unlike most medical treatments, its primary mechanisms are linguistic; i.e., the treatment relies directly on a conversation between a patient and provider. However, the evaluation of patient-provider conversation suffers from critical shortcomings, including intensive labor requirements, coder error, nonstandardized coding systems, and inability to scale up to larger data sets. To overcome these shortcomings, psychotherapy analysis needs a reliable and scalable method for summarizing the content of treatment encounters. We used a publicly available psychotherapy corpus from Alexander Street press comprising a large collection of transcripts of patient-provider conversations to compare coding performance for two machine learning methods. We used the labeled latent Dirichlet allocation (L-LDA) model to learn associations between text and codes, to predict codes in psychotherapy sessions, and to localize specific passages of within-session text representative of a session code. We compared the L-LDA model to a baseline lasso regression model using predictive accuracy and model generalizability (measured by calculating the area under the curve (AUC) from the receiver operating characteristic curve). The L-LDA model outperforms the lasso logistic regression model at predicting session-level codes with average AUC scores of 0.79, and 0.70, respectively. For fine-grained level coding, L-LDA and logistic regression are able to identify specific talk-turns representative of symptom codes. However, model performance for talk-turn identification is not yet as reliable as human coders. We conclude that the L-LDA model has the potential to be an objective, scalable method for accurate automated coding of psychotherapy sessions that perform better than comparable discriminative methods at session-level coding and can also predict fine-grained codes.","2168-2194;21682194","","10.1109/JBHI.2015.2503985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337368","Clinical communication;conversation analysis;labeled latent Dirichlet allocation (L-LDA);machine learning;multilabel document classification","Computational modeling;Encoding;Informatics;Logistics;Medical treatment;Predictive models;Resource management","biomedical communication;encoding;learning (artificial intelligence);medical computing;patient treatment;psychology;regression analysis;text analysis","Alexander Street press;L-LDA model;area under-the curve;average AUC scores;baseline lasso regression model;content coding;data sets;fine-grained level coding;labeled latent Dirichlet allocation;labeled topic models;lasso logistic regression model;machine learning;medical interventions;medical treatments;nonstandardized coding systems;patient-provider conversation;psychotherapy corpus;psychotherapy transcripts;session-level codes;specific talk-turns representative;symptom codes;talk-turn identification;text-code associations;within-session text","","","","","","20151125","March 2017","","IEEE","IEEE Journals & Magazines"
"From Prediction to Action: Improving User Experience with Data-Driven Resource Allocation","Y. Bao; H. Wu; X. Liu","","IEEE Journal on Selected Areas in Communications","","2017","PP","99","1","1","Driven by the desire for better user experience and enabled by improved data storage and processing, much recent work has studied user experience prediction in cellular networks. In this paper, moving beyond the prediction-only approach, we propose a data-driven resource allocation framework that uses data-generated prediction models to explicitly guide resource allocation for user experience improvement. In a closed-loop fashion, it further leverages and verifies the causal relation that often exists between certain feature values (e.g., bandwidth) and user experience in computer networks. As a case study, we consider how to reduce the number of user complaints in cellular networks. Our approach consists of three components: we train a logistic regression classifier to predict user experience, utilize the trained likelihood as the objective function to allocate network resource, and then evaluate user experience with allocated resource to (in)validate and adjust the original model. We design a DualHet algorithm to tackle the problem of multi-dimensional resource optimization with heterogeneous users. Numerical simulations based on both synthetic and real network datasets demonstrate the effectiveness of the proposed algorithms. In particular, the simulations based on real data demonstrate up to 2x performance improvement compared with the baseline algorithm.","0733-8716;07338716","","10.1109/JSAC.2017.2680918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876767","Data-driven networking;machine learning;non-convex optimization;resource allocation","Cellular networks;Computational modeling;Data models;Logistics;Predictive models;Resource management","","","","","","","","20170313","","","IEEE","IEEE Early Access Articles"
"Recurrent neural networks for very short term energy resource planning in a microgrid","E. Corsetti; A. Guagliardi; C. Sandroni","RSE - Materials and Generation Technologies Dpt., via Rubattino 54, Milan, Italy","Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MedPower 2016)","20170323","2016","","","1","9","In power system control the prediction of photovoltaic generation (PV) supports more and more the operational planning of the transmission and distribution grids, up to microgrids. Especially during the intra-day operation the lack of reliable PV production forecast can lead to expensive resource planning while recovering errors. In this paper we propose a method to estimate PV production based on recurrent neural networks for very short time intervals, i.e. up to 4 hours ahead. This method is applied the on-line operational planning of a microgrid but can be generalized. The prediction model can run in single and multi-steps ahead modes. The model takes as input past measures of PV production and sun global irradiance, and predicts the future PV production. The paper proposes two different models for multisteps ahead mode: the iterative, where the single step mode is iterated as far as to cover the whole prediction interval, and the direct, where the set of next steps is estimated in one shot.","","","10.1049/cp.2016.0997","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885351","machine learning;multistep time series prediction;photovoltaic power forecast;recurrent neural networks","","distributed power generation;power distribution planning;power engineering computing;recurrent neural nets","PV production;microgrid;online operational planning;photovoltaic generation prediction;power system control;recurrent neural networks;sun global irradiance;transmission grids;very short term energy resource planning","","","","","","","6-9 Nov. 2016","","IET","IET Conference Publications"
"BigExplorer: A configuration recommendation system for big data platform","C. C. Yeh; J. Zhou; S. A. Chang; X. Y. Lin; Y. Sun; S. K. Huang","Department of Computer Science","2016 Conference on Technologies and Applications of Artificial Intelligence (TAAI)","20170320","2016","","","228","234","With the complexity big data platform architectures, data engineer provides the infrastructure with computation and storage resource for data scientist and data analyst. With those supports, data scientists can focus their domain problem and design the intelligence module (e.g., prepare the data, select/train/tune the machine learning modules and validate the result). However, there is still a gap between system engineer team and data scientists/engineers team. For system engineers, they don't have any knowledge about the application domain and the propose of the analytic program. For data scientists/engineers, they don't know the configuration of the computation system, file system and database. Some application performance issues are related with system configurations. Data scientist and data engineer do not have information and knowledge about the system properties. In this paper, we propose a configuration layer with the current big data platform (i.e., Hadoop) and build a configuration recommendation system to collect data, pre-process data. Based on the processed data, we use semi-automatic feature engineer to provide features for data engineers and build the performance model with three different machine learning algorithms (i.e., random forest, gradient boosting machine and support vector regression). With the same two benchmarks (i.e., wordcount and terasort), our recommended configuration archives remarkable improvement than rule of thumb configuration and better than their improvements.","","Electronic:978-1-5090-5732-0; POD:978-1-5090-5733-7","10.1109/TAAI.2016.7880179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880179","big data platform;configuration optimization;machine learning","Benchmark testing;Big Data;Computer architecture;Data models;Machine learning algorithms;Optimization;Support vector machines","Big Data;learning (artificial intelligence);recommender systems","Big Data platform;BigExplorer system;computation resource;configuration layer;configuration recommendation system;data analyst;data engineer;data scientist;intelligence module;machine learning algorithms;machine learning modules;storage resource","","","","","","","25-27 Nov. 2016","","IEEE","IEEE Conference Publications"
"Logger4u: Predicting debugging statements in the source code","S. Saini; N. Sardana; S. Lal","Department of Computer Science, Jaypee Institute of Information Technology, Noida","2016 Ninth International Conference on Contemporary Computing (IC3)","20170320","2016","","","1","7","Software logging is an essential programming practice that saves important runtime information that can be used later by software developers for troubleshooting, debugging and monitoring the software. Even though software logging has numerous benefits this practice is underutilized because of lack of any formal guiding principles to developers for making strategic and efficient logging decisions. Logging should be optimized because too much logging can cause performance overheads; sparse logging can leave out vital information that might give clues to developers about the real issues. In absence of any formal guidelines developers rely solely on their domain knowledge and experience while making logging decisions. In order to lessen this effort of making decisions we have proposed a machine learning based framework, Logger4u for if-block logging prediction. We extract and use 28 distinctive static features from the source code helpful in making well informed logging decisions. We use Support Vector Machine (two variants, 1 linear and 1 RBF kernel based) models, Multilayer Perceptron with back propagation model and Random forest model in our work. Our approach gives encouraging results for if-block logging task. The accuracy achieved by the Linear SVM, MLP, Random Forest and kernel SVM are 73.05%, 74.62%, 79.84% and 81.22% respectively","","CD:978-1-5090-3249-5; Electronic:978-1-5090-3251-8; POD:978-1-5090-3252-5","10.1109/IC3.2016.7880255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880255","Logging;Machine Learning;Multilayer Perceptron Principal Component Analysis;Random Forest;Software Debugging;Support Vector Machine","Containers;Feature extraction;Kernel;Multilayer perceptrons;Neurons;Support vector machines","backpropagation;feature extraction;multilayer perceptrons;program debugging;random processes;source code (software);support vector machines;system monitoring","Logger4u;backpropagation model;decision making;feature extraction;if-block logging prediction;logging decisions;machine learning based framework;multilayer perceptron;random forest model;software debugging statements;software logging;software monitoring;software troubleshooting;source code;sparse logging;support vector machine","","","","","","","11-13 Aug. 2016","","IEEE","IEEE Conference Publications"
"Neighborhood Features Help Detecting Non-Technical Losses in Big Data Sets","P. Glauner; J. A. Meira; L. Dolberg; R. State; F. Bettinger; Y. Rangoni","Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg City, Luxembourg","2016 IEEE/ACM 3rd International Conference on Big Data Computing Applications and Technologies (BDCAT)","20170316","2016","","","253","261","Electricity theft occurs around the world in both developed and developing countries and may range up to 40% of the total electricity distributed. More generally, electricity theft belongs to non-technical losses (NTL), which occur during the distribution of electricity in power grids. In this paper, we build features from the neighborhood of customers. We first split the area in which the customers are located into grids of different sizes. For each grid cell we then compute the proportion of inspected customers and the proportion of NTL found among the inspected customers. We then analyze the distributions of features generated and show why they are useful to predict NTL. In addition, we compute features from the consumption time series of customers. We also use master data features of customers, such as their customer class and voltage of their connection. We compute these features for a Big Data base of 31M meter readings, 700K customers and 400K inspection results. We then use these features to train four machine learning algorithms that are particularly suitable for Big Data sets because of their parallelizable structure: logistic regression, k-nearest neighbors, linear support vector machine and random forest. Using the neighborhood features instead of only analyzing the time series has resulted in appreciable results for Big Data sets for varying NTL proportions of 1%-90%. This work can therefore be deployed to a wide range of different regions.","","Electronic:978-1-4503-4617-7; POD:978-1-5090-4468-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877074","Data mining;electricity theft detection;feature engineering;feature selection;machine learning;non-technical losses;time series classification","Big Data;Feature extraction;Inspection;Meter reading;Reliability;Time series analysis;Urban areas","Big Data;data mining;learning (artificial intelligence);power distribution;power engineering computing;power grids;random processes;regression analysis;support vector machines;time series","big data sets;customer consumption time series;customer master data features;electricity distribution;electricity theft;k-nearest neighbors;linear support vector machine;logistic regression;machine learning algorithms;nontechnical losses;power grids;random forest","","","","","","","6-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Linguistic features based personality recognition using social media data","D. Sewwandi; K. Perera; S. Sandaruwan; O. Lakchani; A. Nugaliyadde; S. Thelijjagoda","Department of Information Technology, Sri Lanka Institute of Information Technology Malabe","2017 6th National Conference on Technology and Management (NCTM)","20170309","2017","","","63","68","Social media has become a prominent platform for opinions and thoughts. This stated that the characteristics of a person can be assessed through social media status updates. The purpose of this research article is to provide a web application in order to detect one's personality using linguistic feature analysis. The personality of a person has classified according to Eysenck's Three Factor personality model. The proposed technique is based on ontology based text classification, linguistic feature-vector matrix using LIWC (Linguistic Inquiry and Word Count) features including semantic analysis using supervised machine learning algorithms and questionnaire based personality detection. This is vital for HR management system when recruiting and promoting employees, R&D Psychologists can use the dynamic ontology for storage purposes and all the other API users including universities and sports clubs. According to the test results the proposed system is in an accuracy level of 91%, when tested with a real world personality detection questionnaire based application, and results demonstrate that the proposed technique can detect the personality of a person with considerable accuracy and a speed.","","CD:978-1-5090-4728-4; Electronic:978-1-5090-4729-1; POD:978-1-5090-4730-7","10.1109/NCTM.2017.7872829","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872829","Eysenck's Three Factor model;LIWC (Linguistic Inquiry and Word Count) features;Machine Learning Algorithms;Ontology;Semantic Analysis","Decision support systems","Internet;behavioural sciences computing;data analysis;feature extraction;learning (artificial intelligence);linguistics;ontologies (artificial intelligence);pattern classification;psychology;social networking (online);text analysis","HR management system;LIWC feature;Web application;behavioral pattern analysis;linguistic feature analysis;linguistic feature-vector matrix;linguistic inquiry and word count;ontology based text classification;personality classification;personality detection;personality recognition;semantic analysis;social media data;supervised machine learning algorithm","","","","","","","27-27 Jan. 2017","","IEEE","IEEE Conference Publications"
"Email Spam filtering using BPNN classification algorithm","S. K. Tuteja; N. Bogiri","Dept. of Computer Engineering, K.J. College of Engineering and Management Research, Pune, India","2016 International Conference on Automatic Control and Dynamic Optimization Techniques (ICACDOT)","20170316","2016","","","915","919","Millions of people use email correspondence for communication across the globe and it is a critically vital application for many businesses. Considerable amount of unsolicited mail flows into user's mail boxes on a daily basis. A major negative aspect since the past decade has been bulk spam or phishing mail. Besides such unsolicited spam emails being wearisome for many email users, it also puts pressure on the IT infrastructure of organizations and costs businesses billions of dollars in lost efficiency. Increasing need of effectively filtering spam has become vital. We thus use BPNN filtering algorithm i.e. Artificial Neural Network Feed forward with Back Propagation, which is based on text classification to classify significant emails from unsolicited ones.","","Electronic:978-1-5090-2080-5; POD:978-1-5090-2081-2","10.1109/ICACDOT.2016.7877720","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877720","Spam email detection;feature selection;machine learning","Clustering algorithms;Feature extraction;Neural networks;Neurons;Training;Unsolicited electronic mail","backpropagation;business data processing;computer crime;e-mail filters;feature selection;feedforward neural nets;pattern classification;unsolicited e-mail","BPNN classification;BPNN filtering algorithm;artificial feedforward neural network;bulk spam;email spam filtering;feature selection;machine learning;phishing mail;unsolicited mail","","","","","","","9-10 Sept. 2016","","IEEE","IEEE Conference Publications"
"Retinal layer delineation through learning of tissue photon interaction in optical coherence tomography","S. P. K. Karri; N. Garai; D. Nawn; S. Ghosh; D. Chakraborty; J. Chatterjee","IIT Kharagpur, Kharagpur, India 721302","2016 IEEE Students&#8217; Technology Symposium (TechSym)","20170309","2016","","","46","51","Optical coherence tomography (OCT) is widely used in Ophthalmology for visualizing retinal layers and cornea width profiles which are indexed to various pathologies. Image processing algorithms have been deployed to automatically delineate various layers for autonomous width profiles computation. Classical OCT segmentation algorithms are anchored around gradient and its derivatives. Such pixel information can vary from subject to subject so prior approximations of different layers are imposed in the name of regularization. Regularization restrains the generalization capability of the model which is crucial for segmentation in pathological subjects. The presented approach aims to model signal interactions with a tissue type through back scattered signal characteristics. During prediction phase, given an unknown interaction, the model estimates the probability of signal being backscattered from a tissue type. Sensor's ballistic models are employed to estimate the uncompressed signal statistics. These models have been experimented and evaluated on 5000 AMD (age-related macular degeneration) and 5000 normal B-scans from Duke OCT dataset. With two percent training data the delineation results are comparable to graph based approaches. The anterior retina, retinal pigment epithelium (RPE) and posterior retina are identified with sensitivity of 0.87, 0.84 and 0.91 respectively.","","Electronic:978-1-5090-5163-2; POD:978-1-5090-5164-9","10.1109/TechSym.2016.7872653","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872653","Optical Coherence Tomography;image segmentation;machine learning;tissue characterization","Attenuation;Computational modeling;Image segmentation;Photonics;Predictive models;Retina;Speckle","biological tissues;biomedical optical imaging;data compression;diseases;eye;image classification;image coding;image segmentation;medical image processing;optical tomography;pigments","Duke OCT dataset;age-related macular degeneration;anterior retina;autonomous width profile computation;backscattered signal characteristics;classical OCT segmentation algorithms;cornea width profiles;generalization capability;graph based approaches;image processing algorithms;normal B-scans;ophthalmology;optical coherence tomography;pathological subject segmentation;pathologies;pixel information;posterior retina;retinal layer delineation;retinal layer visualization;retinal pigment epithelium;sensor ballistic models;signal interactions;tissue photon interaction learning;tissue type;uncompressed signal statistics","","","","","","","Sept. 30 2016-Oct. 2 2016","","IEEE","IEEE Conference Publications"
"Automatic Classification of Source Code Archives by Programming Language: A Deep Learning Approach","J. Reyes; D. Ramírez; J. Paciello","Fac. Politec., Univ. Nac. de Asuncion, San Lorenzo, Paraguay","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","514","519","This paper proposes the use of a Deep Learning technique, the Long Short-Term Memory (LSTM) recurrent neural network, for the automatic classification of source code archives by programming language. Experiments show that this simple recurrent neural network architecture gives promising results in accuracy compared to the Naive Bayes classifier, currently used by Linguist, one of the most popular programming language classifiers.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881396","classification;deep learning;lstm;machine learning","Computer architecture;Computer languages;Logic gates;Machine learning;Microprocessors;Recurrent neural networks","learning (artificial intelligence);programming languages;recurrent neural nets;source code (software)","LSTM;Naive Bayes classifier;automatic classification;deep learning approach;linguist;long short-term memory;programming language classifiers;recurrent neural network architecture;source code archives","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"AnRAD: A Neuromorphic Anomaly Detection Framework for Massive Concurrent Data Streams","Q. Chen; R. Luley; Q. Wu; M. Bishop; R. W. Linderman; Q. Qiu","Department of Electrical Engineering and Computer Science, Syracuse University, NY 13224 USA during the time of the work.","IEEE Transactions on Neural Networks and Learning Systems","","2017","PP","99","1","15","The evolution of high performance computing technologies has enabled the large-scale implementation of neuromorphic models and pushed the research in computational intelligence into a new era. Among the machine learning applications, unsupervised detection of anomalous streams is especially challenging due to the requirements of detection accuracy and real-time performance. Designing a computing framework that harnesses the growing computing power of the multicore systems while maintaining high sensitivity and specificity to the anomalies is an urgent research topic. In this paper, we propose anomaly recognition and detection (AnRAD), a bioinspired detection framework that performs probabilistic inferences. We analyze the feature dependency and develop a self-structuring method that learns an efficient confabulation network using unlabeled data. This network is capable of fast incremental learning, which continuously refines the knowledge base using streaming data. Compared with several existing anomaly detection approaches, our method provides competitive detection quality. Furthermore, we exploit the massive parallel structure of the AnRAD framework. Our implementations of the detection algorithm on the graphic processing unit and the Xeon Phi coprocessor both obtain substantial speedups over the sequential implementation on general-purpose microprocessor. The framework provides real-time service to concurrent data streams within diversified knowledge contexts, and can be applied to large problems with multiple local patterns. Experimental results demonstrate high computing performance and memory efficiency. For vehicle behavior detection, the framework is able to monitor up to 16,000 vehicles (data streams) and their interactions in real time with a single commodity coprocessor, and uses less than 0.2 ms for one testing subject. Finally, the detection network is ported to our spiking neural network simulator to show the potential of adapting to the emerging neur- morphic architectures.","2162-237X;2162237X","","10.1109/TNNLS.2017.2676110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880607","Anomaly detection;general purpose graphics processing unit (GPGPU);heterogeneous systems;machine learning;neuromorphic computing.","Computational modeling;Computer architecture;Feature extraction;Neuromorphics;Neurons;Real-time systems;Testing","","","","","","","","20170317","","","IEEE","IEEE Early Access Articles"
"Co-Ranking Authors in Heterogeneous News Networks","L. Mookiah; W. Eberle","Dept. of Comput. Sci., Tennessee Technol. Univ., Cookeville, TN, USA","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1095","1100","Expert Finding has been a widely studied area of research. However, most of the work in this area has focused solely on analyzing networks representing people in academia. In this work, we will present an approach for two types of heterogeneous news sources (i.e., Traditional Network Sources (TNS) and Policy Network Sources (PNS)) for experts on a set of topics. Our overall objective is to discover who are the expert journalists and policy analysts on specific topics. This work is based on our intuition that the PNS and TNS could complement each other, thus leveraging information for the learning task. We propose a probabilistic generative model named Context-based Latent Dirichlet Allocation (CBLDA) that performs the task of co-ranking authors in the heterogeneous networks of TNS and PNS. We will demonstrate that our proposed approach outperforms baselines in terms of precision, mean average precision, and discounted cumulative gain.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0209","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881502","Computational journalism;Information mining and applications;Machine learning algorithms;Unsupervised learning","Context;Feeds;Heterogeneous networks;Integrated circuits;Oils;Voting","information retrieval;statistical analysis;unsupervised learning","CBLDA;PNS;TNS;context-based latent Dirichlet allocation;expert finding;expert journalists;heterogeneous news networks;networks analysis;policy analysts;policy network sources;probabilistic generative model;traditional network sources","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Determining smartphone's placement through material detection, using multiple features produced in sound echoes","T. Hasegawa; S. Hirahashi; M. Koshino","Division of Healthcare Informatics, Faculty of Healthcare, Tokyo Healthcare University, Tokyo, JP. (e-mail: t-hasegawa@thcu.ac.jp).","IEEE Access","","2017","PP","99","1","1","This study proposes a system to determine the placement of a smartphone by using the acoustic properties of the surface materials nearby. Detecting the surrounding materials allows the smartphone to change its notification method automatically, based on situational factors. Researchers have studied how to recognize the position in which smartphones are worn while walking, using accelerometer data; however, it is difficult to identify a smartphone’s position while stationary, because the accelerometer value does not change significantly when the smartphone is put down. In this study, we developed a method to recognize surface materials close to a smartphone, using echoes; this method is based on the assumption that echoes of a selected frequency will differ in their properties, depending on the smartphone’s placement and the surface materials nearby. Through our experiment, we found that our proposed method can classify 12 kinds of placement with 82.1% accuracy.","2169-3536;21693536","","10.1109/ACCESS.2017.2687467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886278","Smartphone;context-awareness;machine learning;material detection.","Accelerometers;Feature extraction;Frequency measurement;Harmonic analysis;Legged locomotion;Vibrations;White noise","","","","","","","","20170324","","","IEEE","IEEE Early Access Articles"
"A comparison of some methods for training hidden Markov models on sequences with missing observations","A. Popov; T. Gultyaeva; V. Uvarov","Department of Applied Mathematics and Computer Science, Novosibirsk State Technical University, Novosibirsk, Russia","2016 11th International Forum on Strategic Technology (IFOST)","20170323","2016","","","431","435","The three approaches to the problem of hidden Markov models training on sequences with missing observations are discussed: marginalization of missing observations, gluing of available parts of the sequence and training on the multisequence formed from the available parts of the sequence. The training performance of the three approaches is evaluated for various numbers of gaps in training sequences. The results were compared to the standard imputation method based on the mode (the most frequent value) of nearest observations. The marginalization approach showed the best training accuracy. The multisequence approach demonstrated a very poor performance hence it is considered inapplicable. Both the marginalization method and the gluing method performed better than the mode imputation method. The dependence of training accuracy on the position of gaps in training sequence was investigated. It has been found that the biggest decrease in training accuracy is achieved when the gap is situated at the beginning or in the middle of the sequence while the lowest decrease is observed when it is situated at the end.","","Electronic:978-1-5090-0855-1; POD:978-1-4673-8812-2","10.1109/IFOST.2016.7884147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884147","Baum-Welch algorithm;hidden Markov models;incomplete data;machine learning;missing observations;sequence recognition","Algorithm design and analysis;Computer science;Hidden Markov models;Information and communication technology;Speech recognition;Standards;Training","hidden Markov models;learning (artificial intelligence);pattern classification","gluing method;hidden Markov model training;missing observation marginalization;missing observation sequence;most-frequent value;multisequence approach;training accuracy;training sequences","","","","","","","1-3 June 2016","","IEEE","IEEE Conference Publications"
"A Behavioral Biometrics User Authentication Study Using Motion Data from Android Smartphones","J. Maghsoudi; C. C. Tappert","Seidenberg Sch. of CSIS, Pace Univ., Pleasantville, NJ, USA","2016 European Intelligence and Security Informatics Conference (EISIC)","20170306","2016","","","184","187","This study examined the behavioral biometrics of smartphone motion to determine potential authentication accuracies on Android phones. The study used machine learning algorithms to analyze data from the accelerometer and gyroscope sensors. Android smartphone data were captured from sixty different individuals, resulting in a large collection of datasets for training and testing. The data were filtered by removing noise and segmented into motion intervals prior to feature extraction. The classification algorithms employed in the study were Multilayer Perception, k-Nearest Neighbor, Support Vector Machines, and Naïve Bayes. Authentication accuracies achieved ranged from 81% to over 97%.","","CD:978-1-5090-2856-6; Electronic:978-1-5090-2857-3; POD:978-1-5090-2858-0","10.1109/EISIC.2016.047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870220","Behavioral biometrics;Weka;accelerometer;gyroscope;machine learning;smartphone sensors;user authentication","Accelerometers;Authentication;Biometrics (access control);Gyroscopes;Sensors;Smart phones;Support vector machines","Android (operating system);Bayes methods;biometrics (access control);data analysis;feature extraction;learning (artificial intelligence);multilayer perceptrons;pattern classification;security of data;smart phones;support vector machines","Android smartphones;Naïve Bayes;accelerometer;behavioral biometrics user authentication;data analysis;feature extraction;gyroscope sensors;k-nearest neighbor classification;machine learning;multilayer perception;smartphone motion data;support vector machines","","","","","","","17-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Big Data for Industry 4.0: A Conceptual Framework","M. O. Gokalp; K. Kayabay; M. A. Akyol; P. E. Eren; A. Koçyiğit","Inf. Inst., Middle East Tech. Univ., Ankara, Turkey","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","431","434","Exponential growth in data volume originating from Internet of Things sources and information services drives the industry to develop new models and distributed tools to handle big data. In order to achieve strategic advantages, effective use of these tools and integrating results to their business processes are critical for enterprises. While there is an abundance of tools available in the market, they are underutilized by organizations due to their complexities. Deployment and usage of big data analysis tools require technical expertise which most of the organizations don't yet possess. Recently, the trend in the IT industry is towards developing prebuilt libraries and dataflow based programming models to abstract users from low-level complexities of these tools. After briefly analyzing trends in the literature and industry, this paper presents a conceptual framework which offers a higher level of abstraction to increase adoption of big data techniques as part of Industry 4.0 vision in future enterprises.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0088","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881381","Industry 4.0;big data;data flow based programming languages;data mining;machine learning","Big Data;Business;Data mining;Data models;Industries;Programming;Visualization","Big Data;DP industry;Internet of Things;data analysis;programming;software houses","IT industry;Internet of Things sources;abstract users;big data analysis tools;business processes;conceptual framework;data volume;dataflow based programming;distributed tools;enterprises;industry 4.0 vision;information services;libraries","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"An Android Malware Detection Approach Using Bayesian Inference","C. H. Liu; Z. J. Zhang; S. D. Wang","Grad. Inst. of Electr. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2016 IEEE International Conference on Computer and Information Technology (CIT)","20170313","2016","","","476","483","Android malware detection has been a popularre search topic due to non-negligible amount of malware targeting the Android operating system. In particular, the naive Bayes generative classifier is a common technique widely adopted in many papers. However, we found that the naive Bayes classifier performs badly in Contagio Malware Dump dataset, which could result from the assumption that no feature dependency exists. In this paper, we propose a lightweight method for Android malware detection, which improves the performance of Bayesian classification on the Contagio Malware Dump data set. It performs static analysis to gather malicious features from an application, and applies principal component analysis to reduce the dependencies among them. With the hidden naive Bayes model, we can infer the identityof the application. In an evaluation with 15,573 normal applications and 3,150 malicious samples, our work detects94.5% of the malware with a false positive rate of 1.0%.The experiment also shows that our approach is feasible on smart phones.","","Electronic:978-1-5090-4314-9; POD:978-1-5090-4315-6","10.1109/CIT.2016.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876376","Android Malware Detection;Bayesian Inference;Machine Learning;Static Analysis","Androids;Bayes methods;Humanoid robots;Malware;Mathematical model;Permission;Principal component analysis","Android (operating system);Bayes methods;invasive software;pattern classification;principal component analysis;program diagnostics;smart phones","Android malware detection approach;Android operating system;Bayesian classification;Bayesian inference;Contagio Malware Dump dataset;false positive rate;hidden naive Bayes model;malicious features;naive Bayes generative classifier;performance improvement;principal component analysis;smart phones;static analysis","","","","","","","8-10 Dec. 2016","","IEEE","IEEE Conference Publications"
"Polarity classification on web-based reviews using Support Vector Machine","R. S. C. da Rocha; L. Forero; H. de Mello; M. Kohler; M. Vellasco","Department of Informatics, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Brazil","2016 IEEE Latin American Conference on Computational Intelligence (LA-CCI)","20170327","2016","","","1","6","This paper presents a hybrid filter-wrapper approach to sentiment polarity classification. It is a two-phase feature selection method that differs from other approaches in a main aspect: an initial preprocessing step with typical data mining filters. After applying such filters, a wrapper-based feature selection method, which integrates the genetic algorithm and the support vector machine classifier, is used for sentiment analysis on the Internet Movie Database (IMDb) reviews. We show that this approach improves the classification accuracy compared to other methods, including those such preprocessing techniques are applied separately to the database.","","Electronic:978-1-5090-5105-2; POD:978-1-5090-5106-9; USB:978-1-5090-5104-5","10.1109/LA-CCI.2016.7885729","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885729","filter;machine learning;preprocessing techniques;sentiment analysis;support vector machine;text mining;wrapper","Databases;Filtering algorithms;Information filtering;Sentiment analysis;Support vector machines;Text mining","Internet;data mining;feature selection;genetic algorithms;information filtering;pattern classification;sentiment analysis;support vector machines","IMDb reviews;Internet Movie Database;Web-based review;data mining filter;genetic algorithm;hybrid filter-wrapper approach;sentiment analysis;sentiment polarity classification;support vector machine classifier;two-phase feature selection method","","","","","","","2-4 Nov. 2016","","IEEE","IEEE Conference Publications"
"A Real Time EEG Analysis System","J. Garza; Y. Li; Y. Chang; H. Lin","Dept. of Comput. Sci. & Eng., Technol. Univ. of Houston-Downtown, Houston, TX, USA","2016 IEEE First International Conference on Data Science in Cyberspace (DSC)","20170302","2016","","","550","555","Electroencephalographic (EEG) data modeling is useful for developing applications in the areas of healthcare, as well as in the design of brain-computer interface (BCI). We built a system for brain state modeling, which includes a web server that can process uploaded electroencephalographic (EEG) data, store the data in a local database, and perform data analysis on the stored EEG data. This paper introduces a mobile application that is able to interact with the web server to render selected data and display analysis results from the web server. We aim to build an efficient self-adjusting brain wave modeling system that can seamlessly capture and analyze EEG brainwave data. The platform provides user friendly interface with secure data storage and analytics capabilities for wave analysis, statistical analysis, and categorical classification using a number of well-established machine learning algorithms. We also present a systematic method to understand how the variation of raw data sets used in training models affects the accuracy of machine learning algorithms, and then analyze the performance of machine learning algorithms under various computational implementations. Overall, the study describes a successfully built incorporated data analysis platform, and provides preliminary insights into the performance of common machine learning algorithms on the brain wave data sets.","","Electronic:978-1-5090-1192-6; POD:978-1-5090-1193-3","10.1109/DSC.2016.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866185","Biomedical Informatics;Data Mining;Human-centered computing;Machine Learning;Ubiquitous and mobile computing;electroencephalography (EEG)","Brain models;Electroencephalography;Machine learning algorithms;Mobile applications;Web servers","brain-computer interfaces;electroencephalography;health care;learning (artificial intelligence);medical signal processing;mobile computing;statistical analysis","BCI;Web server;brain state modeling;brain-computer interface;categorical classification;electroencephalographic data modeling;healthcare;machine learning algorithms;mobile application;real time EEG analysis system;statistical analysis;user friendly interface;wave analysis","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Only-One-Victor Pattern Learning in Computer Go","J. Wang; C. Xiao; T. Zhu; C. H. Hsueh; W. J. Tseng; I. C. Wu","College of Information Science and Engineering, Shenyang, China","IEEE Transactions on Computational Intelligence and AI in Games","20170315","2017","9","1","88","102","Automatically acquiring domain knowledge from professional game records, a kind of pattern learning, is an attractive and challenging issue in computer Go. This paper proposes a supervised learning method, by introducing a new generalized Bradley-Terry model, named Only-One-Victor, to learn patterns from game records. Basically, our algorithm applies the same idea with Elo rating algorithm, which considers each move in game records as a group of move patterns, and the selected move as the winner of a kind of competition among all groups on current board. However, being different from the generalized Bradley-Terry model for group competition used in Elo rating algorithm, Only-One-Victor model in our work simulates the process of making selection from a set of possible candidates by considering such process as a group of independent pairwise comparisons. We use a graph theory model to prove the correctness of Only-One-Victor model. In addition, we also apply the Minorization-Maximization (MM) to solve the optimization task. Therefore, our algorithm still enjoys many computational advantages of Elo rating algorithm, such as the scalability with high dimensional feature space. With the training set containing 115,832 moves and the same feature setting, the results of our experiments show that Only-One-Victor outperforms Elo rating, a well-known best supervised pattern learning method.","1943-068X;1943068X","","10.1109/TCIAIG.2015.2504108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347363","AI;Go;computer games;machine learning;only-one-victor","Computational modeling;Computers;Estimation;Games;Learning (artificial intelligence);Machine learning algorithms;Supervised learning","computer games;graph theory;learning (artificial intelligence);optimisation","Elo rating algorithm;computer Go;domain knowledge;generalized Bradley-Terry model;graph theory;group competition;minorization-maximization;only-one-Victor model;optimization task;professional game records;supervised pattern learning","","","","","","20151204","March 2017","","IEEE","IEEE Journals & Magazines"
"Modification of optimum-path forest using Markov cluster process algorithm","H. Bostani; M. Sheikhan","Department of Computer Engineering, Islamic Azad University, South Tehran Branch, Tehran, Iran","2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS)","20170306","2016","","","1","5","Optimum-path forest (OPF) is a novel supervised graph-based classifier which reduces the classification problem into partitioning of vertices in a graph derived from the data samples. One of the main processes in OPF is identifying the optimum set of key samples named prototypes. This process is based on creating a minimum spanning tree on a complete weighted graph which is derived from the training samples; hence, it is much time-consuming for large-scale problems. In this study, for overcoming this limitation, the process of finding the prototypes in traditional OPF is modified by using Markov cluster (MCL) algorithm. The graph partitioning in MCL is based on finding key samples named attractors, which attract other related samples; so the obtained attractors can be selected as prototypes for generating optimum-path trees. Experiments on public benchmark datasets show that the speed of proposed modified OPF is improved considerably as compared to the traditional OPF.","","Electronic:978-1-5090-5820-4; POD:978-1-5090-5821-1","10.1109/ICSPIS.2016.7869874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869874","Markov cluster process;Optimum-path forest;supervised machine learning","Classification algorithms;Clustering algorithms;Markov processes;Optimized production technology;Partitioning algorithms;Prototypes;Training","Markov processes;learning (artificial intelligence);pattern classification;pattern clustering;trees (mathematics)","Markov cluster process;OPF;classification problem reduction;large-scale problems;minimum spanning tree;optimum path forest modification;supervised graph-based classifier;weighted graph","","","","","","","14-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Quantum Computing in Big Data Analytics: A Survey","T. A. Shaikh; R. Ali","Dept. of Comput. Eng., Aligarh Muslim Univ., Aligarh, India","2016 IEEE International Conference on Computer and Information Technology (CIT)","20170313","2016","","","112","115","Big Data is a term which denotes data that is beyond storage capacity and processing capabilities of classical computer and getting some insight from large amount of data is a very big challenge at hand. Quantum Computing comes to rescue by offering a lot of promises in information processing systems, particularly in Big Data Analytics. In this paper, we have reviewed the available literature on Big Data Analytics using Quantum Computing for Machine Learning and its current state of the art. We categorized the Quantum Machine learning in different subfields depending upon the logic of their learning followed by a review in each technique. Quantum Walks used to construct Quantum Artificial Neural Networks, which exponentially speed-up the quantum machine learning algorithm is discussed. Quantum Supervised and Unsupervised machine learning and its benefits are compared with that of Classical counterpart. The limitations of some of the existing Machine learning techniques and tools are enunciated, and the significance of Quantum computing in Big Data Analytics is incorporated. Being in its infancy as a totally new field, Quantum computing comes up with a lot of open challenges as well. The challenges, promises, future directions and techniques of the Quantum Computing in Machine Learning are also highlighted.","","Electronic:978-1-5090-4314-9; POD:978-1-5090-4315-6","10.1109/CIT.2016.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876324","Big Data Analytics;Machine Learning;Quantum Artificial Intelligence;Quantum Clustering;Quantum Computing;Qubits","Big data;Computers;Logic gates;Machine learning algorithms;Quantum computing;Quantum mechanics;Support vector machines","Big Data;data analysis;learning (artificial intelligence);neural nets;quantum computing","Big Data analytics;information processing systems;quantum artificial neural networks;quantum computing;quantum unsupervised machine learning;quantum walks","","","","","","","8-10 Dec. 2016","","IEEE","IEEE Conference Publications"
"Islanding Detection of Hybrid Distributed Generation under Reduced Non-detection Zone","Q. Cui; K. El-Arroudi; G. Joos","Department of Electrical and Computer Engineering, McGill University, Montreal, QC, H3A 0E9 Canada.(email:qiushi.cui@mail.mcgill.ca)","IEEE Transactions on Smart Grid","","2017","PP","99","1","1","Future distribution systems are faced with more challenges on islanding detection due to the increasing penetration level of inverter-based distributed generators (DGs). Different DG technologies, inverter control as well as other advanced inverter functions such as fault ride through are challenging the capability of islanding detection schemes. On the other hand, for multiple feeders network, topological change of feeders and islanding at adjacent feeder increase the vulnerability of islanding detection devices. Furthermore, available islanding detection schemes are suffering from notable non-detection zones (NDZs) under reduced power mismatches. Therefore, to mitigate these issues, this paper proposes an effective methodology for building decision trees (DTs) based intelligent relay (IR). This methodology utilizes the NDZ boundaries of existing standard relays and applies a comprehensive training/testing strategy, which effectively reduces the NDZ while maintaining a superior dependability and security performance. To validate the applicability of the proposed methodology, the hardware-in-the-loop simulations are realized by programming the generated IR logics into a real commercial relay.","1949-3053;19493053","","10.1109/TSG.2017.2679101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873354","Distribution systems;decision tree;distributed generators;hardware-in-the-loop simulation;islanding detection;machine learning;non-detection zone","Decision trees;Inverters;Islanding;Reactive power;Relays;Standards;Time-frequency analysis","","","","","","","","20170307","","","IEEE","IEEE Early Access Articles"
"Toward letter recognition system: Determination of best wavelet and best rhythm using EEG","S. Wahed; M. Rana; S. M. K. Hasan; M. Ahmad","Department of Electrical and Electronic Engineering, Khulna University of Engineering & Technology (KUET), Khulna, Bangladesh","2016 3rd International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)","20170309","2016","","","1","4","The paper describes the application of different wavelet analysis together with machine learning algorithm for the recognition of English alphabet from EEG signal. Decision making was executed in two stages. At first important features such as maximum, minimum, delta value, moment, kurtosis, skew, median, mean and standard deviation at different sub-bands are computed using the wavelet functions - Daubechies 8, Coiflet 6, Biorthogonal 4.4, Symlet 4. Finally, a learning-based algorithm like support Vector Machine (SVM) classifier is implemented for classifying letters. From the analysis, Daubechies 8 is found the most suitable candidate among the wavelet families in this proposed research for accurate recognition of different letters. So the focus of this work is to recognize different letters through SVM classifier. In this analysis, among different rhythms of EEG signal delta rhythm shows best performance in recognizing letters and the recognition rate is 80%.","","Electronic:978-1-5090-2906-8; POD:978-1-5090-2907-5","10.1109/CEEICT.2016.7873099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873099","Discrete Wavelet Transform (DWT);Electroencephalography (EEG);Letter recognition;feature extraction;machine learning","Electrodes;Electroencephalography;Feature extraction;Rhythm;Support vector machines;Time-frequency analysis;Wavelet analysis","character recognition;decision making;discrete wavelet transforms;electroencephalography;feature extraction;learning (artificial intelligence);pattern classification;signal classification;support vector machines","Biorthogonal 4.4;Coiflet 6;Daubechies 8;EEG signal delta rhythm;English alphabet recognition;SVM classifier;Symlet 4;best rhythm determination;best wavelet determination;decision making;discrete wavelet transform;feature extraction;learning-based algorithm;letter classification;letter recognition system;machine learning algorithm;support vector machine classifier;wavelet analysis;wavelet functions","","","","","","","22-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"GitHub, Technical Debt, Code Formatting, and More","J. C. Carver; J. Cabot; R. Capilla; H. Muccini","University of Alabama","IEEE Software","20170328","2017","34","2","105","107","This issue's column reports on papers from the 19th International Conference on Model Driven Engineering Languages and Systems, the 2016 ACM SIGPLAN International Conference on Software Language Engineering, the 12th International ACM SIGSOFT Conference on the Quality of Software Architectures, and the 13th Working IEEE/IFIP Conference on Software Architecture. Topics discussed include GitHub and open source, technical debt in model-driven engineering, a universal code formatter, assuring architectural quality, and continuous architecting.","0740-7459;07407459","","10.1109/MS.2017.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888414","AADL;AQAF;Architecture Analysis and Design Language;Architecture Quality Assurance Framework;CAFFEA;Continuous Architecture Framework for Embedded and Agile Software Development;GitHub;UML;architectural quality;code formatting;code smells;continuous architecting;machine learning;model-driven engineering;open source;software development;software engineering;technical debt","","","","","","","","","","Mar.-Apr. 2017","","IEEE","IEEE Journals & Magazines"
"STT-RAM Buffer Design for Precision-Tunable General-Purpose Neural Network Accelerator","L. Song; Y. Wang; Y. Han; H. Li; Y. Cheng; X. Li","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20170320","2017","25","4","1285","1296","Multilevel spin toque transfer RAM (STT-RAM) is a suitable storage device for energy-efficient neural network accelerators (NNAs), which relies on large-capacity on-chip memory to support brain-inspired large-scale learning models from conventional artificial neural networks to current popular deep convolutional neural networks. In this paper, we investigate the application of multilevel STT-RAM to general-purpose NNAs. First, the error-resilience feature of neural networks is leveraged to tolerate the read/write reliability issue in multilevel cell STT-RAM using approximate computing. The induced read/write failures at the expense of higher storage density can be effectively masked by a wide spectrum of NN applications with intrinsic forgiveness. Second, we present a precision-tunable STT-RAM buffer for the popular general-purpose NNA. The targeted STT-RAM memory design is able to transform between multiple working modes and adaptable to meet the varying quality constraint of approximate applications. Lastly, the reconfigurable STT-RAM buffer not only enables precision scaling in NNA but also provides adaptiveness to the demand for different learning models with distinct working-set sizes. Particularly, we demonstrate the concept of capacity/precision-tunable STT-RAM memory with the emerging reconfigurable deep NNA and elaborate on the data mapping and storage mode switching policy in STT-RAM memory to achieve the best energy efficiency of approximate computing.","1063-8210;10638210","","10.1109/TVLSI.2016.2644279","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835283","Approximate computing;machine learning;neural network;spin toque transfer RAM (STT-RAM)","Approximate computing;Artificial neural networks;Biological neural networks;Computational modeling;Computer architecture;Microprocessors;Random access memory","buffer circuits;energy conservation;integrated circuit reliability;neural nets;random-access storage","approximate computing;brain-inspired large-scale learning models;capacity-precision-tunable STT-RAM memory;conventional artificial neural networks;data mapping;deep convolutional neural networks;energy-efficient neural network accelerators;error-resilience feature;induced read-write failures;large-capacity on-chip memory;multilevel STT-RAM buffer design;multilevel spin toque transfer RAM;precision scaling;precision-tunable general-purpose;read-write reliability issue;reconfigurable deep NNA;storage mode switching policy","","","","","","20170126","April 2017","","IEEE","IEEE Journals & Magazines"
"Medical warning system based on Internet of Things using fog computing","I. Azimi; A. Anzanpour; A. M. Rahmani; P. Liljeberg; T. Salakoski","Department of Information Technology, University of Turku, Finland","2016 International Workshop on Big Data and Information Security (IWBIS)","20170309","2016","","","19","24","Remote patient monitoring is essential for many patients that are suffering from acute diseases such as different heart conditions. Continuous health monitoring can provide medical services that consider the current medical state of the patient and to predict or early-detect future potentially critical situations. In this regard, Internet of Things as a multidisciplinary paradigm can provide profound impacts. However, the current IoT-based systems may encounter difficulties to provide continuous and real time patient monitoring due to issues in data analytics. In this paper, we introduce a new IoT-based approach to offer smart medical warning in personalized patient monitoring. The proposed approach consider local computing paradigm enabled by machine learning algorithms and automate management of system components in computing section. The proposed system is evaluated via a case study concerning continuous patient monitoring to early-detect patient deterioration via arrhythmia in ECG signal.","","Electronic:978-1-5090-3477-2; POD:978-1-5090-3478-9; USB:978-1-5090-3476-5","10.1109/IWBIS.2016.7872884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872884","Autonomic computing;Fog Comouting;Internet of Things;Patient monitoring;machine learning","Biomedical monitoring;Cloud computing;Computer architecture;Electrocardiography;Logic gates;Patient monitoring","Internet of Things;alarm systems;data analysis;diseases;electrocardiography;learning (artificial intelligence);medical signal processing;patient monitoring;real-time systems","ECG signal;Internet of Things;IoT-based systems;acute diseases;continuous health monitoring;data analytics;fog computing;machine learning;medical warning system;real time patient monitoring;remote patient monitoring","","","","","","","18-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Skin Segmentation Algorithm Based on Stacked Autoencoders","Y. Lei; W. Yuan; H. Wang; Y. Wenhu; W. Bo","Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, China","IEEE Transactions on Multimedia","20170315","2017","19","4","740","749","A good skin detector that is capable of capturing skin tones under different conditions is important for human-machine interaction applications. In a general situation, skin detectors, such as skin probability maps or Gaussian mixture models, achieve acceptable skin segmentation results. However, the false positive rate increases significantly when the skin tones are in shadow or when skin-like background objects are under similar illumination. In this paper, we propose a novel skin feature learning algorithm based on stacked autoencoders, which are deep neural networks. To overcome the problems encountered in skin segmentation that are caused by different ethnicities and varying illumination conditions, the stacked autoencoders are utilized to learn more discriminative representations of the skin area in both the RGB color space and the HSV color space. Unlike traditional machine learning methods, instead of predicting each pixel individually, our algorithm utilizes blocks to learn the representations and detect the skin areas. The algorithm exploits the learning ability of deep neural networks to learn high-level representations of skin tones. Experiments on test images show that the proposed algorithm achieves acceptable results on several publicly available data sets. To reduce the difficulty of detecting skin pixels in these data sets, the ground truths of these data sets are commonly focused on foreground skin area detection. Our skin detector is also able to detect background areas, as shown in our experiments.","1520-9210;15209210","","10.1109/TMM.2016.2638204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779068","Color space;machine learning;skin detection;stacked autoencoders","Detectors;Histograms;Image color analysis;Image segmentation;Lighting;Skin;Training","feature extraction;human computer interaction;image coding;image colour analysis;image representation;image segmentation;learning (artificial intelligence);neural nets;skin","HSV color space;RGB color space;deep neural networks;discriminative representations;human-machine interaction applications;machine learning methods;skin detector;skin feature learning algorithm;skin segmentation algorithm;skin tones;stacked autoencoders","","","","","","20161209","April 2017","","IEEE","IEEE Journals & Magazines"
"Autonomous learning approach to characterizing motion behavior","R. Anil; H. Khanna; A. S. Keshavamurthy; R. Khanna; A. Haswarey","","2017 IEEE Topical Conference on Wireless Sensors and Sensor Networks (WiSNet)","20170316","2017","","","49","52","Unattended falls can lead to serious medical issues among the elderly, especially when motor functions may become inactive. Motion sensors like accelerometer can aid in automatic characterization and classification of human motion. Un-Classified motion can be accounted for anomaly that when reported to the online knowledge builder can correct the existing model or estimate additional classes into that model. In this paper we develop an alert system using low power Intel Quark D1000 MCU that characterizes the motion behavior using Logistic Model Trees (LMT) and estimates an anomaly in motion behavior while augmenting the model using online learning. The goal is to build a useability model where an unclassified behavior (corresponding to accelerometer data) can be logged and upon additional intervention can be re-evaluated for re-classification. This will lead to autodetecting un-desired motion activities (like falls) and avoid false positives to activities of daily life.","","Electronic:978-1-5090-3461-1; POD:978-1-5090-3462-8","10.1109/WISNET.2017.7878753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7878753","Body Sensors;Fall Detection;Machine Learning","Acceleration;Accelerometers;Data models;Logistics;Mathematical model;Monitoring;Training","accelerometers;assisted living;biomechanics;expert systems;geriatrics;medical signal processing;motion measurement;patient monitoring;signal classification","Logistic Model Trees;alert system;autonomous learning;human motion characterization;human motion classification;low power Intel Quark D1000 MCU;motion anomaly;motion behavior;motion sensors;motor functions;online learning","","","","","","","15-18 Jan. 2017","","IEEE","IEEE Conference Publications"
"Multiple regularizations deep learning for paddy growth stages classification from LANDSAT-8","I. H. Ikasari; V. Ayumi; M. I. Fanany; S. Mulyono","Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, University of Indonesia, Depok, Indonesia 16424","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","512","517","This study uses remote sensing technology that can provide information about the condition of the earth's surface area, fast, and spatially. The study area was in Karawang District, lying in the Northern part of West Java-Indonesia. We address a paddy growth stages classification using LANDSAT 8 image data obtained from multi-sensor remote sensing image taken in October 2015 to August 2016. This study pursues a fast and accurate classification of paddy growth stages by employing multiple regularizations learning on some deep learning methods such as DNN (Deep Neural Networks) and 1-D CNN (1-D Convolutional Neural Networks). The used regularizations are Fast Dropout, Dropout, and Batch Normalization. To evaluate the effectiveness, we also compared our method with other machine learning methods such as (Logistic Regression, SVM, Random Forest, and XGBoost). The data used are seven bands of LANDSAT-8 spectral data samples that correspond to paddy growth stages data obtained from i-Sky (eye in the sky) Innovation system. The growth stages are determined based on paddy crop phenology profile from time series of LANDSAT-8 images. The classification results show that MLP using multiple regularization Dropout and Batch Normalization achieves the highest accuracy for this dataset.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872790","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872790","Classification;Deep Learning;Fast Dropout Training;LANDSAT 8;Machine Learning;Paddy Growth Stage;Remote Sensing","Biological neural networks;Earth;Indexes;Remote sensing;Satellites;Training","convolution;crops;image classification;image fusion;learning (artificial intelligence);neural nets;remote sensing;time series","1D CNN;1D convolutional neural networks;DNN;Indonesia;Karawang District;LANDSAT-8 image time series;LANDSAT-8 spectral data samples;West Java;batch normalization;deep neural networks;fast dropout regularizations;i-Sky Innovation system;multiple regularization deep learning;multisensor remote sensing image;paddy crop phenology profile;paddy growth stage classification","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"But I did not Mean It!—Intent Classification of Racist Posts on Tumblr","S. Agarwal; A. Sureka","Indraprastha Inst. of Inf. Technol., New Delhi, India","2016 European Intelligence and Security Informatics Conference (EISIC)","20170306","2016","","","124","127","Research shows that many like-minded people use popular microblogging Web sites for posting hateful speech against various religions and race. Automatic identification of racist and hate promoting posts is required for building social media intelligence and security informatics based solutions. However, just keyword spotting based techniques cannot be used to accurately identify the intent of a post. In this paper, we address the challenge of the presence of ambiguity in such posts. We conduct our study on Tumblr microblogging Web site and develop a cascaded ensemble learning classifier for identifying the posts having racist or radicalized intent. We train our model by identifying various semantic, sentiment and linguistic features from free-form text. Our experimental results shows that the proposed approach is effective and the social tendencies, language cues and personality traits of a narrative are discriminatory features for classifying the posts with racist intent.","","CD:978-1-5090-2856-6; Electronic:978-1-5090-2857-3; POD:978-1-5090-2858-0","10.1109/EISIC.2016.032","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870205","Intelligence and Security Informatics;Intent Classification;Machine Learning;Mining User Generated Content;Semantic Analysis;Sentiment and Tone Analysis;Social Media Analytics;Text Classification;Tumblr","Data mining;Feature extraction;Radio frequency;Semantics;Tagging;Taxonomy;Writing","data mining;learning (artificial intelligence);sentiment analysis;social networking (online)","Tumblr microblogging Web site;automatic hate promoting post identification;automatic racist post identification;cascaded ensemble learning classifier;free-form text;hateful speech;intent classification;language cues;linguistic features;personality traits;radicalized intent;security informatic-based solutions;semantic features;sentiment features;social media intelligence;social tendencies","","","","","","","17-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Accurate and early prediction of user lifespan in an online video-on-demand system","Y. Wang; Y. Guo; Y. Chen","School of Electrical and Information Engineering, Beijing Jiaotong University, Beijing, China","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","969","974","Online video on demand (VoD) service is prevailing. Prediction of user lifespan in a VoD system benefits the service providers to characterize churn risk of users and manage to retain them. A systematical study on this problem is desired but absent in literature. We address this problem based on a large-scale dataset of user watching behavior from PPTV, one of the largest online VoD systems in China. The dataset is measured for 27 weeks and involves more than 10 million users. We analyze user watching behavior and preference in their lifespans and have some interesting observations. During user lifespans, unlike some user activity metrics such as the visiting frequency, the number of views and the finishing ratio that vary following inverted U-shaped curves, a user's preference for popular video contents, named the Popular Video Preference (PVP), decreases with time. As many users left the system very quickly, e.g. after only one week, it is necessary to make early prediction of whether a user will have a long lifespan based on short instead of long behavior history. We propose to apply machine learning methods to make this prediction based on user first-week behavior records. Experimental results show that the most relevant feature is the visit frequency; the PVP feature helps to improve the F1-score of prediction by 8.8% and reaches 0.74 at the best. Our proposed model and the PVP metric are helpful for VoD service providers to predict user lifespan and take measures to retain users at their early stage in the system.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7877974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877974","Data mining;Lifespan;Machine learning;User behavior analysis;Video","Correlation;Finishing;History;Learning systems;Measurement;Smart phones;TV","behavioural sciences;learning (artificial intelligence);prediction theory;telecommunication computing;video on demand","China;F1-score;PPTV;PVP;VoD service;inverted U-shaped curves;machine learning methods;online video-on-demand system;popular video contents;popular video preference;user lifespan prediction;user watching behavior","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"A New Rate Control Scheme For Video Coding Based On Region Of Interest","Z. Zhang; T. Jing; J. Han; Y. Xu; F. Zhang","School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China (e-mail: zhwzhang@bjtu.edu.cn).","IEEE Access","","2017","PP","99","1","1","The quality fluctuation of video is significant in human visual system, and thus, many rate control schemes are widely developed in the area of video communication. In recent years, researchers show more interests in region of interest (ROI) based encoding, and it is widely applied in the latest video codecs such as HEVC and VP9. This paper presents a new rate control scheme for ROI mode coding based on DCT coefficient model and Radial Basis Function Neuron Network (RBFNN). A new R-D model is proposed by classifying blocks into different depth, ROI groups, etc. Then, rate and distortion are described based on Laplacian distribution model using mathematical ways. A machine learning approach is induced to enhance the accuracy of the distortion estimation. By utilizing the new R-D model, a new rate control scheme is designed for ROI mode coding from the group of picture (GOP) layer to coding unit (CU) layer. By comparisons with other rate control approaches, the proposed one has a better result in terms of visual quality, R-D performance, and bitrate accuracy, etc. Hence, it outperforms the conventional schemes especially for sequences with obvious ROI details.","2169-3536;21693536","","10.1109/ACCESS.2017.2676125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874186","HEVC;Machine learning;Radial Basis Function Neuron Network;Region of interest;VP9;Video coding;rate control","Computational modeling;Copper;Discrete cosine transforms;Distortion;Encoding;Video coding","","","","","","","","20170308","","","IEEE","IEEE Early Access Articles"
"FOREPOST: A Tool for Detecting Performance Problems with Feedback-Driven Learning Software Testing","Q. Luo; D. Poshyvanyk; A. Nair; M. Grechanik","Coll. of William & Mary Williamsburg, Williamsburg, VA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","20170323","2016","","","593","596","A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster to find performance problems in applications automatically. We present a novel tool, FOREPOST, for finding performance problems in applications automatically using black-box software testing. In this paper, we demonstrate how FOREPOST extracts rules from execution traces of applications by using machine learning algorithms, and then uses these rules to select test input data automatically to steer applications towards computationally intensive paths and to find performance problems. FOREPOST is available in our online appendix (http://www.cs.wm.edu/semeru/data/ICSE16-FOREPOST), which contains the tool, source code and demo video.","","Electronic:978-1-4503-4205-6; POD:978-1-5090-2245-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883348","Performance testing;black-box testing;machine learning","Binary codes;Databases;Insurance;Measurement;Software testing;Uniform resource locators","learning (artificial intelligence);program testing","FOREPOST;black-box software testing;feedback-driven learning software testing;machine learning algorithms;performance testing","","","","","","","14-22 May 2016","","IEEE","IEEE Conference Publications"
"Comprehensive analysis of various rough set tools for data mining","S. Gupta; S. Garhwal","Dept. of Computer Science and Engineering, Thapar University, Punjab, India","2016 2nd International Conference on Next Generation Computing Technologies (NGCT)","20170316","2016","","","468","474","Rough set theory is a present day scientific way to deal with imperfect information. Rough sets have been prescribed for a wide assortment of uses. Unequivocally, the rough set methodology is by all accounts basic and critical for Artificial Intelligence and subjective sciences, especially in data mining, knowledge discovery, machine learning, expert systems and pattern acknowledgment. In this paper, we examine data mining programming frameworks inside of the system of rough sets against a few perspectives, for example, the technical specifications and specializations alongside its constraints. By studying the analysis, the decision and choice of tools can be made simple.","","DVD:978-1-5090-3256-3; Electronic:978-1-5090-3257-0; POD:978-1-5090-3258-7","10.1109/NGCT.2016.7877461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877461","data mining;general public license;machine learning;open source;rough set;rough set theory","Data mining;Instruments;Java;Licenses;Programming;Rough sets;Software","data mining;expert systems;rough set theory","artificial intelligence;data mining programming frameworks;expert systems;knowledge discovery;machine learning;pattern acknowledgment;rough set tools;subjective sciences;technical specializations;technical specifications","","","","","","","14-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Range clustering: An algorithm for empirical evaluation of classical clustering algorithms","N. Arora; S. Jain; S. K. Verma","Department of Computer Science, Jaypee Institute of Information Technology, Sector - 128, Noida, Uttar Pradesh, India","2016 Ninth International Conference on Contemporary Computing (IC3)","20170320","2016","","","1","4","Cluster analysis is a principal method in analytics domain of data mining. The algorithm used for clustering directly influences the results obtained from applying the clustering algorithm (clusters). Data clustering is done in order to identify the patterns and trends not identifiable from just looking at the data. Clustering may be supervised (if the machine training data set is available) or unsupervised (if the machine training data set is not available). Unsupervised clustering is usually done using k-Means Algorithm (using any distance, the most common being Euclidean and Manhattan Distance). The drawback of k-means algorithm for a large set are the rigorous calculations that need to be done to cluster a data set into multiple data subsets for every single iteration, thereby limiting its efficiency and use for large data sets. We propose a range based single pass clustering algorithm that clusters data on the basis of the range which it falls in, where the ranges are calculated using simple arithmetic mean between two values. The proposed algorithm is compared against the standard k-means algorithm (using Euclidean Distance and Manhattan Distance).","","CD:978-1-5090-3249-5; Electronic:978-1-5090-3251-8; POD:978-1-5090-3252-5","10.1109/IC3.2016.7880242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880242","Clustering;Empirical;Evaluation;Range Clustering;Supervised Machine Learning;Unsupervised Machine Learning;k-Means Algorithm","Algorithm design and analysis;Clustering algorithms;Euclidean distance;Information technology;Machine learning algorithms;Partitioning algorithms;Standards","data mining;learning (artificial intelligence);pattern clustering;statistical analysis","classical clustering algorithms;cluster analysis;data clustering;data mining;k-means algorithm;machine training data set;pattern identification;range clustering;supervised clustering","","","","","","","11-13 Aug. 2016","","IEEE","IEEE Conference Publications"
"Wearable Medical Sensor-based System Design: A Survey","A. Mosenia; S. SUR-KOLAY; A. Raghunathan; N. Jha","Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA.(email:arsalan@princeton.edu)","IEEE Transactions on Multi-Scale Computing Systems","","2017","PP","99","1","1","Wearable medical sensors (WMSs) are garnering ever-increasing attention from both the scientific community and the industry. Driven by technological advances in sensing, wireless communication, and machine learning, WMS-based systems have begun transforming our daily lives. Although WMSs were initially developed to enable low-cost solutions for continuous health monitoring, the applications of WMS-based systems now range far beyond health care. Several research efforts have proposed the use of such systems in diverse application domains, e.g., education, human-computer interaction, and security. Even though the number of such research studies has grown drastically in the last few years, the potential challenges associated with their design, development, and implementation are neither well-studied nor well-recognized. This article discusses various services, applications, and systems that have been developed based on WMSs and sheds light on their design goals and challenges. We first provide a brief history of WMSs and discuss how their market is growing. We then discuss the scope of applications of WMS-based systems. Next, we describe the architecture of a typical WMS-based system and the components that constitute such a system, and their limitations. Thereafter, we suggest a list of desirable design goals that WMS-based systems should satisfy. Finally, we discuss various research directions related to WMSs and how previous research studies have attempted to address the limitations of the components used in WMS-based systems and satisfy the desirable design goals.","","","10.1109/TMSCS.2017.2675888","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870697","Education;health care;human-computer interaction;machine learning;security;wearable medical sensor;wireless communication","Automation;Biomedical monitoring;Drugs;Human computer interaction;Monitoring;Sensors","","","","","","","","20170303","","","IEEE","IEEE Early Access Articles"
"k-Nearest Neighbours classification based Sybil attack detection in Vehicular networks","P. Gu; R. Khatoun; Y. Begriche; A. Serhrouchni","LTCI, CNRS, TELECOM ParisTech, Universit&#x00E9; Paris-Saclay, 75013, France","2017 Third International Conference on Mobile and Secure Services (MobiSecServ)","20170327","2017","","","1","6","In Vehicular networks, privacy, especially the vehicles' location privacy is highly concerned. Several pseudonymous based privacy protection mechanisms have been established and standardized in the past few years by IEEE and ETSI. However, vehicular networks are still vulnerable to Sybil attack. In this paper, a Sybil attack detection method based on k-Nearest Neighbours (kNN) classification algorithm is proposed. In this method, vehicles are classified based on the similarity in their driving patterns. Furthermore, the kNN methods' high runtime complexity issue is also optimized. The simulation results show that our detection method can reach a high detection rate while keeping error rate low.","","Electronic:978-1-5090-3632-5; POD:978-1-5090-3633-2","10.1109/MOBISECSERV.2017.7886565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886565","Intrusion detection;Machine Learning;Sybil Attack;Vehicle Driving Pattern;Vehicular Networking","Ad hoc networks;Eigenvalues and eigenfunctions;Peer-to-peer computing;Privacy;Symmetric matrices;Transmitters;Wireless sensor networks","computational complexity;data privacy;intelligent transportation systems;pattern classification;road vehicles;traffic engineering computing","ETSI;IEEE;Sybil attack detection;Sybil attack vulnerability;driving pattern similarity;k-nearest neighbours classification;kNN classification algorithm;pseudonymous based privacy protection mechanism;runtime complexity optimization;vehicle classification;vehicle location privacy;vehicular network","","","","","","","11-12 Feb. 2017","","IEEE","IEEE Conference Publications"
"A model of spike neuron oriented to hardware implementation","A. V. Gavrilov; V. M. Kangler; M. Katomin; K. Panchenko","Dept. of Computer Engineering, Novosibirsk State Technical University, Novosibirsk, Russia","2016 11th International Forum on Strategic Technology (IFOST)","20170323","2016","","","521","525","One of most perspective and popular area of neural networks is neuromorphic computing dealing with development of brain-like spike neural networks oriented on hardware implementation. Such neural networks will provide replacement of computers with Von Neumann architecture in such fields as computer vision and control of autonomous robots. In this paper we suggest one model of spike integrate and fire neuron for development of such neural networks. This model is distinguished by simple arithmetic operations, providing, short-long controlled memory of integrated input signals and controlled refractory period for output. Proposed model will provide simple hardware implementation.","","Electronic:978-1-5090-0855-1; POD:978-1-4673-8812-2","10.1109/IFOST.2016.7884170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884170","Machine Learning;Neural Networks;Neuromorphic Computing;Neuron","Biological neural networks;Biological system modeling;Computational modeling;Frequency modulation;Neuromorphics;Neurons;Robot sensing systems","algebra;neural nets","Von Neumann architecture;autonomous robot control;brain-like spike neural networks;computer vision;controlled refractory period;hardware implementation;integrated input signals;neuromorphic computing;short-long controlled memory;simple arithmetic operation;spike integrate and fire neuron;spike neuron","","","","","","","1-3 June 2016","","IEEE","IEEE Conference Publications"
"An Automatic Digital Audio Authentication/Forensics System","Z. Ali; M. Imran; M. Alsulaiman","Department of Computer Engineering, Digital Speech Processing Group, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Access","20170327","2017","5","","2994","3007","With the continuous rise in ingenious forgery, a wide range of digital audio authentication applications are emerging as a preventive and detective control in real-world circumstances, such as forged evidence, breach of copyright protection, and unauthorized data access. To investigate and verify, this paper presents a novel automatic authentication system that differentiates between the forged and original audio. The design philosophy of the proposed system is primarily based on three psychoacoustic principles of hearing, which are implemented to simulate the human sound perception system. Moreover, the proposed system is able to classify between the audio of different environments recorded with the same microphone. To authenticate the audio and environment classification, the computed features based on the psychoacoustic principles of hearing are dangled to the Gaussian mixture model to make automatic decisions. It is worth mentioning that the proposed system authenticates an unknown speaker irrespective of the audio content i.e., independent of narrator and text. To evaluate the performance of the proposed system, audios in multi-environments are forged in such a way that a human cannot recognize them. Subjective evaluation by three human evaluators is performed to verify the quality of the generated forged audio. The proposed system provides a classification accuracy of 99.2% ± 2.6. Furthermore, the obtained accuracy for the other scenarios, such as text-dependent and text-independent audio authentication, is 100% by using the proposed system.","2169-3536;21693536","","10.1109/ACCESS.2017.2672681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7864411","Digital audio authentication;audio forensics;forgery;human psychoacoustic principles;machine learning algorithm","Auditory system;Authentication;Databases;Forgery;Microphones;Psychoacoustics;Splicing","Gaussian processes;digital forensics;hearing;mixture models;speaker recognition","Gaussian mixture model;automatic authentication system;copyright protection breach;digital audio authentication applications;forged audio;forged evidence;hearing;human sound perception system;ingenious forgery;psychoacoustic principles;text-independent audio authentication;unauthorized data access","","","","","","20170224","2017","","IEEE","IEEE Journals & Magazines"
"Applying an ensemble learning method for improving multi-label classification performance","A. Mahdavi-Shahri; M. Houshmand; M. Yaghoobi; M. Jalali","Department of Computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran","2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS)","20170306","2016","","","1","6","In recent years, multi-label classification problem has become a controversial issue. In this kind of classification, each sample is associated with a set of class labels. Ensemble approaches are supervised learning algorithms in which an operator takes a number of learning algorithms, namely base-level algorithms and combines their outcomes to make an estimation. The simplest form of ensemble learning is to train the base-level algorithms on random subsets of data and then let them vote for the most popular classifications or average the predictions of the base-level algorithms. In this study, an ensemble learning method is proposed for improving multi-label classification evaluation criteria. We have compared our method with well-known base-level algorithms on some data sets. Experiment results show the proposed approach outperforms the base well-known classifiers for the multi-label classification problem.","","Electronic:978-1-5090-5820-4; POD:978-1-5090-5821-1","10.1109/ICSPIS.2016.7869900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869900","Ensemble learning;Machine learning;Multi-label Classification;Single-label classification","Classification algorithms;Correlation;Learning systems;Loss measurement;Prediction algorithms;Training","estimation theory;learning (artificial intelligence);pattern classification","base-level algorithms;class labels;ensemble learning method;estimation;multilabel classification performance;supervised learning algorithms","","","","","","","14-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Cancer Classification Based on Microarray Gene Expression Data Using Deep Learning","P. Guillen; J. Ebalunode","Center for Adv. Comput. & Data Syst., Univ. of Houston, Houston, TX, USA","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1403","1405","The classification of cancer is a major research topic in Medicine. Cancer microarray data normally contains a small number of samples, which have a large number of gene expression levels as features, however, makes the classification quite challenging. Using a deep learning algorithm based on multilayer perceptron, we show that classification performance at least as good as published results can be obtained for cancer classification.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0270","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881563","cancer;classification;deep learning;machine learning;microarray gene expression","Cancer;Computer architecture;Gene expression;Machine learning;Multilayer perceptrons;Training;Tumors","bioinformatics;cancer;genetics;multilayer perceptrons;pattern classification","cancer classification;deep learning algorithm;microarray gene expression data;multilayer perceptron","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Comprehensive Analysis of Network Traffic Data","Y. Miao; Z. Ruan; L. Pan; J. Zhang; Y. Xiang; Y. Wang","Sch. of Inf. Technol., Deakin Univ., Geelong, VIC, Australia","2016 IEEE International Conference on Computer and Information Technology (CIT)","20170313","2016","","","423","430","With the large volume of network traffic flow, it is necessary to preprocess raw data before classification to gain the accurate results speedily. Feature selection is an essential approach in preprocessing phase. The Principal Component Analysis (PCA) is recognized as an effective and efficient method. In this paper, we classify network traffic by using the PCA technique together with six machine learning algorithms - Naive Bayes, Decision Tree, 1-Nearest Neighbor (NN), Random Forest, Support Vector Machine (SVM) and H2O. We analyze the impact of PCA through classifying the data set by each algorithm with and without PCA. Experiments are set out by varying the size of input data sets, and the performances are measured from two metrics including overall accuracy and F-measure. The computational time is also considered in analysis phase. Our results show that Random Forest and NN are the top two algorithms among the six. Specifically, both of them behave well in classification under the most cases of input sets regardless of applying PCA. Lastly, PCA significantly boosts NN algorithms in terms of classification accuracy and shortens the classification time for Random Forest.","","Electronic:978-1-5090-4314-9; POD:978-1-5090-4315-6","10.1109/CIT.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876369","Data Analytics;Machine Learning;Network Traffic Classification;Performance","Artificial neural networks;Decision trees;Feature extraction;Machine learning algorithms;Principal component analysis;Servers;Support vector machines","Bayes methods;decision trees;feature selection;learning (artificial intelligence);principal component analysis;support vector machines","1-nearest neighbor;NN algorithms;Naive Bayes;PCA;Random Forest;SVM;decision tree;feature selection;machine learning algorithms;network traffic data;network traffic flow;principal component analysis;raw data;support vector machine","","","","","","","8-10 Dec. 2016","","IEEE","IEEE Conference Publications"
"Predicting usefulness of Yelp reviews with localized linear regression models","Ruhui Shen; Jialiang Shen; Yuhong Li; Haohan Wang","School of Computer and Science, Beijing University of Posts and Telecommunications, China","2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20170323","2016","","","189","192","Many websites such as Yelp provide platform for users to write reviews about places they have visited. But not all reviews are equally useful. However, it generally takes from several weeks to months to receive feedback about “usefulness” of review from online community. So there is a need to automatically predict the “usefulness” of review. In this paper, we are trying to solve the specific question “How many `useful' votes a Yelp review will receive?” by using bag-of-words, linguistic, geographical, statistical, popularity and other qualitative features extracted from user, business and review information provided by Yelp. We use state-of-the-art machine learning algorithms for regression to predict required numeric value of `usefulness' of review. We further gained performance improvement by introducing a batch mode localized weighted regression model. This localized regression approach resulted into RMSLE of 0.47769, which is better than traditional methods.","","Electronic:978-1-4673-9904-3; POD:978-1-4673-9905-0","10.1109/ICSESS.2016.7883046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883046","linear regression;localized model;machine learning","Data mining;Fitting","Web sites;computational linguistics;learning (artificial intelligence);regression analysis","Websites;Yelp reviews;bag-of-words;batch mode localized weighted regression model;geographical features;linguistic features;localized linear regression models;machine learning algorithms;online community;popularity;statistical features;usefulness prediction","","","","","","","26-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Continuous Validation for Data Analytics Systems","M. Staples; L. Zhu; J. Grundy","Data61, NICTA, Eveleigh, NSW, Australia","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","20170323","2016","","","769","772","From a future history of 2025: Continuous development is common for build/test (continuous integration) and operations (devOps). This trend continues through the lifecycle, into what we call `devUsage': continuous usage validation. In addition to ensuring systems meet user needs, organisations continuously validate their legal and ethical use. The rise of end-user programming and multi-sided platforms exacerbate validation challenges. A separate trend is the specialisation of software engineering for technical domains, including data analytics. This domain has specific validation challenges. We must validate the accuracy of statistical models, but also whether they have illegal or unethical biases. Usage needs addressed by machine learning are sometimes not specifiable in the traditional sense, and statistical models are often `black boxes'. We describe future research to investigate solutions to these devUsage challenges for data analytics systems. We will adapt risk management and governance frameworks previously used for software product qualities, use social network communities for input from aligned stakeholder groups, and perform cross-validation using autonomic experimentation, cyber-physical data streams, and online discursive feedback.","","Electronic:978-1-4503-4205-6; POD:978-1-5090-2245-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883399","continuous development;data analytics;devOps;ethics;governance;machine learning;software validation","Data analysis;Data models;Law;Market research;Software engineering;Stakeholders","data analysis;learning (artificial intelligence);program verification;risk management;statistical analysis","autonomic experimentation;black boxes;continuous usage validation;cyber-physical data streams;data analytics systems;devUsage;end-user programming;governance frameworks;machine learning;multisided platforms;online discursive feedback;risk management;social network community;software engineering;software product quality;statistical models","","","","","","","14-22 May 2016","","IEEE","IEEE Conference Publications"
"Sentiment analysis on Chinese movie review with distributed keyword vector representation","C. H. Chu; C. A. Wang; Y. C. Chang; Y. W. Wu; Y. L. Hsieh; W. L. Hsu","Institute of Information Science, Academia Sinica, Taipei City, Taiwan","2016 Conference on Technologies and Applications of Artificial Intelligence (TAAI)","20170320","2016","","","84","89","In the area of national language processing, performing machine learning technique on customer or movie review for sentiment analysis has been? frequently tried. While methods such as support vector machine (SVM) were much favored in the 2000s, recently there is a steadily rising percentage of implementation with vector representation and artificial neural network. In this article we present an approach to implement word embedding method to conduct sentiment analysis on movie review from a renowned bulletin board system forum in Taiwan. After performing log-likelihood ratio (LLR) on the corpus and selecting the top 10000 most related keywords as representative vectors for different sentiments, we use these vectors as the sentiment classifier for the testing set. We achieved results that are not only comparable to traditional methods like Naïve Bayes and SVM, but also outperform Latent Dirichlet Allocation, TF-IDF and its variant. It also tops the original LLR with a substantial margin.","","Electronic:978-1-5090-5732-0; POD:978-1-5090-5733-7","10.1109/TAAI.2016.7880169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880169","LLR;TF-IDF;machine learning;sentiment analysis;word embedding","Motion pictures;Semantics;Sentiment analysis;Support vector machines;Testing;Training;Urban areas","information analysis;learning (artificial intelligence);natural language processing;support vector machines","Chinese movie review;LLR;Taiwan;bulletin board system forum;distributed keyword vector representation;latent Dirichlet allocation;log-likelihood ratio;machine learning technique;national language processing;sentiment analysis;support vector machine;word embedding method","","","","","","","25-27 Nov. 2016","","IEEE","IEEE Conference Publications"
"Detecting high risk taxpayers using data mining techniques","M. S. Rad; A. Shahbahrami","Islamic Azad University, Rasht Branch Faculty of Engineering, Rasht, Iran","2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS)","20170306","2016","","","1","5","Risk refers to a set of events that lead to loss but risk from the tax perspective refers to the taxpayers' behaviors that may lead to negligence from the public property by the taxpayers due to tax evasion. Such actions cause unusual volatilities in the amounts envisaged in the government budgeting. The fiscal and financial transactions outside the scope of the precautionary bound and failure to achieve the expected revenues of the country. One of the most important types of tax risks is concealing the information on buying, selling and contracts that in case of being uncovered in the financial sector it leads to the issuance of amendments to taxpayers. But if it is uncovered in the due course, it leads to the non-fulfillment of tax collection and thus negative financial waves at the national level and ultimately leads to detrimental financial impact to the financial framework of states and countries. The main purpose of this paper is to analyze, design and implement a system to extract high risk taxpayers and provide a model to forecast the amount of tax assessment notification of the taxpayers for the coming years so that it would play the role of the assistance system for the tax experts to issue the assessment notifications with realistic amounts during the assessment and tax audit to prevent major errors in the tax assessment. To extract high risk taxpayers using the variance and the mean standard deviation the suspicious financial behavior is detected and then the previously supervised data that exist in the tax base as amendment forms are used to classify the taxpayers and also the job coefficient field is used and high risk occupations are identified and classified. One of the strongest and best practices in this field is the use of statistical and financial calculations in time domain. The main feature is the amount of taxable income based on which the purchasing, sales, revenue and profit can be calculated. By studying the volatilities and noise detecti- n in the amounts paid by taxpayers during the past years and also creating linear regression analysis it has been possible to discover the risk levels and forecast of the tax assessment notification for the coming years. Also using this technique tax assessment notification error tolerance of the previous years is obtained. Finally the high risk taxpayer detection system known as HTS is provided with the best and quickest manner possible.","","Electronic:978-1-5090-5820-4; POD:978-1-5090-5821-1","10.1109/ICSPIS.2016.7869895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869895","Data mining;artificial neural networks;big data;machine learning;task risk assessment;tax fraud detection","Data mining;Finance;Linear regression;Mathematical model;Neural networks;Risk management;Standards","classification;data mining;feature extraction;financial data processing;fraud;government data processing;regression analysis;risk management;taxation","amount forecasting;data mining techniques;financial transactions;fiscal transactions;fraud detection;government budgeting;high risk taxpayer detection;linear regression analysis;mean standard deviation;public property negligence;suspicious financial behavior detection;tax assessment notification error tolerance;tax collection;tax evasion;tax experts assistance system;taxable income;taxpayer behavior;taxpayer classification","","","","","","","14-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Engagement dynamics and sensitivity analysis of YouTube videos","W. Hoiles; A. Aprem; V. Krishnamurthy","","IEEE Transactions on Knowledge and Data Engineering","","2017","PP","99","1","1","YouTube, with millions of content creators, has become the preferred destination for watching videos online. Through the Partner program, YouTube allows content creators to monetize their popular videos. Of significant importance for content creators is which meta-level features (e.g. title, tag, thumbnail) are most sensitive for promoting video popularity. The popularity of videos also depends on the social dynamics, i.e. the interaction of the content creators (or channels) with YouTube users. Using real-world data consisting of about 6 million videos spread over 25 thousand channels, we empirically examine the sensitivity of YouTube meta-level features and social dynamics. The key meta-level features that impact the view counts of a video include: first day view count , number of subscribers, contrast of the video thumbnail, Google hits, number of keywords, video category, title length, and number of upper-case letters in the title respectively and illustrate that these meta-level features can be used to estimate the popularity of a video. In addition, optimizing the meta-level features after a video is posted increases the popularity of videos. In the context of social dynamics, we discover that there is a causal relationship between views to a channel and the associated number of subscribers. Additionally, insights into the effects of scheduling and video playthrough in a channel are also provided. Our findings provide a useful understanding of user engagement in YouTube.","1041-4347;10414347","","10.1109/TKDE.2017.2682858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879356","Granger causality;YouTube;channel dynamics;machine learning;metadata, user engagement;popularity prediction;sensitivity analysis;social media","Learning systems;Neurons;Sensitivity analysis;Videos;YouTube","","","","","","","","20170315","","","IEEE","IEEE Early Access Articles"
"Sentiment based music play system","V. Patchava; P. Jain; R. R. Lomte; Shakthi Priya G; H. B. Kandala","Department of ECE, RGUKT-Nuzvid, Andhra Pradesh, India","2015 International Conference on Smart Sensors and Systems (IC-SSS)","20170309","2015","","","1","5","Most of us hear music to experience emotions. Music can soothe your bad mood. Music systems available at present times allow you to play selected songs and recommends songs in genres based on your tastes or tastes of users similar to others. Since such music systems are not designed with the emotions evoked in mind, music listeners cannot completely rely on such systems and do not enjoy listening to songs on the station or website. In this paper, we demonstrate a sentiment based music system. Our raspberry pi based system, in conjunction with a speaker and a microphone plays songs on the basis of the mood in the room. The captured background voices are converted to text and their sentiment is determined using machine learning based classification problem. We use a naïve Bayesian classifier for this classification. Songs with similar sentiments are determined using the tempo of the song in BPM (Bits per Minute).","","CD:978-1-4673-9327-0; Electronic:978-1-4673-9328-7; POD:978-1-4673-9329-4","10.1109/SMARTSENS.2015.7873601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873601","Raspberry Pi;machine learning;mood;music system;sentiment analysis;tempo","Bayes methods;Lifting equipment;Microphones;Mood;Sentiment analysis;Training;Universal Serial Bus","Bayes methods;electronic music;learning (artificial intelligence);microphones","Bayesian classifier;machine learning based classification problem;microphone;raspberry pi based system;sentiment based music system;speaker","","","","","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Sentiment analysis for short Chinese text based on character-level methods","Y. An; X. Tang; B. Xie","School of Software Engineering, Shanghai Jiao Tong University, Shanghai, China","2017 9th International Conference on Knowledge and Smart Technology (KST)","20170327","2017","","","78","82","To date, analyzing the sentiment of user-generated reviews is an important way to get timely feedbacks from customers. In order to solve the task, many semantics methods and machine learning algorithms are applied. However, most of them are based on word-level features. Segmenting a sentence into words is a much harder process in tonal languages, like Chinese and Thai, than the others, like English. Thus in this paper, we propose several methods only based on character-level features to avoid the problem. We collect reviews of three different kinds of products from the Internet as data sets, and test our methods to show the effectiveness.","","Electronic:978-1-4673-9077-4; POD:978-1-4673-9078-1","10.1109/KST.2017.7886093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886093","character-level features;deep learning;machine learning;sentiment analysis","Convolution;Feature extraction;Neural networks;Niobium;Sentiment analysis;Support vector machines;Training","Internet;learning (artificial intelligence);sentiment analysis","Chinese text;English;Internet;Thai;character-level features;character-level methods;customers;data sets;machine learning algorithms;semantics methods;sentiment analysis;tonal languages;user-generated reviews;word-level features","","","","","","","1-4 Feb. 2017","","IEEE","IEEE Conference Publications"
"Incremental Self-Evolving Framework for Agent-Based Simulation","D. O. Kang; J. W. Bae; E. Paik","Electron. & Telecommun. Res. Inst., Daejeon, South Korea","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1428","1429","This paper presents a self-evolving scheme of an agent-based simulation to improve agent simulation models to fit real world data in an incremental way without human intervention by machine learning techniques. The proposed method can solve problems of traditional optimization methods of the agent-based simulation by the incremental optimization of agent simulation models. In this paper, we introduce requirements, the structure and internal functions of the self-evolving agent-based simulation framework for social simulation.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0282","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881575","agent;incremental;machine learning;self-evolving;simulation","Analytical models;Computational modeling;Data assimilation;Data models;Evolutionary computation;Mathematical model;Optimization","learning (artificial intelligence);multi-agent systems","agent simulation models;agent-based simulation;incremental optimization;incremental self-evolving framework;machine learning techniques;social simulation","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Real time sentiment analysis of tweets using Naive Bayes","A. Goel; J. Gautam; S. Kumar","JSS Academy of Technical Education, Noida, India","2016 2nd International Conference on Next Generation Computing Technologies (NGCT)","20170316","2016","","","257","261","Twitter<sup>1</sup> is a micro-blogging website which provides platform for people to share and express their views about topics, happenings, products and other services. Tweets can be classified into different classes based on their relevance with the topic searched. Various Machine Learning algorithms are currently employed in classification of tweets into positive and negative classes based on their sentiments, such as Baseline, Naive Bayes Classifier, Support Vector Machine etc. This paper contains implementation of Naive Bayes using sentiment140 training data using Twitter database and propose a method to improve classification. Use of SentiWordNet along with Naive Bayes can improve accuracy of classification of tweets, by providing positivity, negativity and objectivity score of words present in tweets. For actual implementation of this system python with NLTK and python-Twitter APIs are used.","","DVD:978-1-5090-3256-3; Electronic:978-1-5090-3257-0; POD:978-1-5090-3258-7","10.1109/NGCT.2016.7877424","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877424","Machine Learning;NLTK;Python;SentiWordNet;Sentiment Analysis;Twitter","Databases;Motion pictures;Sentiment analysis;Tagging;Training;Training data;Twitter","information analysis;learning (artificial intelligence);pattern classification;social networking (online)","NLTK API;Python-Twitter API;SentiWordNet;Twitter;application program interfaces;machine learning algorithms;microblogging website;naive Bayes classifier;negativity score;objectivity score;positivity score;realtime sentiment analysis;support vector machine;tweets classification","","","","","","","14-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Discovering Important Source Code Terms","P. Rodeghero","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","20170323","2016","","","671","673","Terms in source code have become extremely important in Software Engineering research. These ``important' terms are typically used as input to research tools. Therefore, the quality of the output of these tools will depend on the quality of the term extraction technique. Currently, there is no definitive best technique for predicting the importance of terms during program comprehension. In my work, I perform a literature review of several techniques. I then propose a unified importance prediction model based on a machine learning algorithm. I evaluate my model in a field study involving professional programmers, as well as a standard 10-fold synthetic study. I found that my model predicts the top quartile of most-important source code terms with approximately 50% precision and recall, outperforming tf/idf and other popular techniques. Furthermore, I found that, during actual program comprehension tasks, the predictions from my model help programmers equivalent to a real set of most-important terms.","","Electronic:978-1-4503-4205-6; POD:978-1-5090-2245-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883368","importance;machine learning;source code terms","Conferences;Gaze tracking;Machine learning algorithms;Measurement;Predictive models;Software;Software engineering","learning (artificial intelligence);reverse engineering;software engineering;source code (software)","machine learning algorithm;professional programmers;program comprehension;software engineering research;source code;standard 10-fold synthetic study;term extraction;unified importance prediction model","","","","","","","14-22 May 2016","","IEEE","IEEE Conference Publications"
"Predicting return reversal through a two-stage method","S. Zhao; Yunhai Tong; Xiangfeng Meng; Xianglin Yang; S. Tan","School of Electronics Engineering and Computer Science, Peking University, Key Laboratory of Machine Perception (Ministry of Education), Beijing, China","2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20170323","2016","","","341","344","In the stock market, return reversal happens when investors sell overbought stocks and buy oversold stocks, making the trends of the stocks' prices reverse. While existing studies mainly focused on developing theories to explain the cause of return reversal, we aim at predicting return reversal by proposing a two-stage method in this paper. In the first stage, we employ dynamical Bayesian factor graph (DBFG) to select key factors correlating with return reversal closely from a comprehensive set of economic factors. In the second stage, we input the key factors into artificial neural network (ANN), support vector machine (SVM) and hidden Markov model (HMM) respectively, to accomplish the prediction of return reversal. Through extensive experiments on the US stock market, we establish that the key factors influencing return reversal generally change from year to year, yet factors related to the economic theory of liquidity effect consistently emerge as part of the key factors. Besides, DBFG-ANN achieves the most accurate prediction among the models, leading to precisions above 60%.","","Electronic:978-1-4673-9904-3; POD:978-1-4673-9905-0","10.1109/ICSESS.2016.7883081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883081","machine learning methods;prediction;return reversal;stock market","Biological system modeling;Fluctuations;Hidden Markov models;Lead;Predictive models;Support vector machines;Two dimensional displays","Bayes methods;graph theory;hidden Markov models;neural nets;stock markets;support vector machines","DBFG;US stock market;artificial neural network;dynamical Bayesian factor graph;hidden Markov model;liquidity effect economic theory;overbought stocks;oversold stocks;return reversal prediction;support vector machine;two-stage method","","","","","","","26-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Two improvements to detect duplicates in Stack Overflow","Y. Mizobuchi; K. Takayama","Fujitsu Laboratories LTD., Kawasaki, Japan","2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)","20170323","2017","","","563","564","Stack Overflow is one of the most popular question-and-answer sites for programmers. However, there are a great number of duplicate questions that are expected to be detected automatically in a short time. In this paper, we introduce two approaches to improve the detection accuracy: splitting body into different types of data and using word-embedding to treat word ambiguities that are not contained in the general corpuses. The evaluation shows that these approaches improve the accuracy compared with the traditional method.","","Electronic:978-1-5090-5501-2; POD:978-1-5090-5502-9","10.1109/SANER.2017.7884678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884678","Stack Overflow;duplicate question;information retrieval;machine learning;word-embedding","Computational modeling;Conferences;Data mining;Feature extraction;HTML;Mathematical model;Software","Internet;Web sites;computer aided instruction;computer science education;programming;training","programmers;question-and-answer sites;stack overflow;word ambiguities;word-embedding","","","","","","","20-24 Feb. 2017","","IEEE","IEEE Conference Publications"
"When to Release in Open Source Project?","Z. Li; L. Huang","Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","20170323","2016","","","737","739","As a rapidly growing number of open source projects adopt distributed version control systems, it becomes more crucial and challenging for release managers to oversee the software development, testing, deployment, and support during the software development life cycle. Manual monitoring and control of the lengthy commit history has been extremely tedious and effort consuming. This paper proposes an automated approach based on chronological commit logs to recommend release candidates for release managers by casting release tagging into a structured learning problem. It predicts whether a commit can be identified as a potential release point leveraging Conditional Random Fields (CRFs) model fueled by automatic feature extraction. Experiments on two open source datasets demonstrate promising results.","","Electronic:978-1-4503-4205-6; POD:978-1-5090-2245-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883389","CRFs;machine learning;release tagging","Conferences;History;Rails;Software;Tagging;Testing;Training","data handling;feature extraction;software libraries","CRF model;automatic feature extraction;chronological commit logs;conditional random fields;distributed version control systems;monitoring;open source datasets;open source projects;software development life cycle;structured learning problem;tagging","","","","","","","14-22 May 2016","","IEEE","IEEE Conference Publications"
"Remote Health Monitoring Outcome Success Prediction Using Baseline and First Month Intervention Data","N. Alshurafa; C. Sideris; M. Pourhomayoun; H. Kalantarian; M. Sarrafzadeh; J. A. Eastwood","Department of Preventive Medicine, Northwestern University, Chicago, IL, USA","IEEE Journal of Biomedical and Health Informatics","20170303","2017","21","2","507","514","Remote health monitoring (RHM) systems are becoming more widely adopted by clinicians and hospitals to remotely monitor and communicate with patients while optimizing clinician time, decreasing hospital costs, and improving quality of care. In the Women's heart health study (WHHS), we developed Wanda-cardiovascular disease (CVD), where participants received healthy lifestyle education followed by six months of technology support and reinforcement. Wanda-CVD is a smartphone-based RHM system designed to assist participants in reducing identified CVD risk factors through wireless coaching using feedback and prompts as social support. Many participants benefitted from this RHM system. In response to the variance in participants' success, we developed a framework to identify classification schemes that predicted successful and unsuccessful participants. We analyzed both contextual baseline features and data from the first month of intervention such as activity, blood pressure, and questionnaire responses transmitted through the smartphone. A prediction tool can aid clinicians and scientists in identifying participants who may optimally benefit from the RHM system. Targeting therapies could potentially save healthcare costs, clinician, and participant time and resources. Our classification scheme yields RHM outcome success predictions with an F-measure of 91.9%, and identifies behaviors during the first month of intervention that help determine outcome success. We also show an improvement in prediction by using intervention-based smartphone data. Results from the WHHS study demonstrates that factors such as the variation in first month intervention response to the consumption of nuts, beans, and seeds in the diet help predict patient RHM protocol outcome success in a group of young Black women ages 25-45.","2168-2194;21682194","","10.1109/JBHI.2016.2518673","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7384415","Remote health monitoring;machine learning;outcome success;prediction and modeling","Atmospheric measurements;Biomedical monitoring;Blood pressure;Heart;Monitoring;Wireless communication","blood pressure measurement;cardiovascular system;learning (artificial intelligence);medical diagnostic computing;patient care;patient diagnosis;patient monitoring;smart phones","CVD risk factors;F-measure;Wanda-CVD;Wanda-cardiovascular disease;age 25 yr to 45 yr;baseline intervention data;blood pressure;classification schemes;clinician time;contextual baseline features;first month intervention data;healthy lifestyle education;hospital costs;intervention-based smartphone data;quality-of-care;questionnaire responses;remote health monitoring systems;smartphone-based RHM system;social support;success prediction;wireless coaching","","","","","","20160118","March 2017","","IEEE","IEEE Journals & Magazines"
"Network Coding as a Performance Booster for Concurrent Multi-Path Transfer of Data in Multi-Hop Wireless Networks","N. Arianpoo; I. Aydin; V. C. M. Leung","Department of Electrical Engineering, University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Mobile Computing","20170303","2017","16","4","1047","1058","The emerging use of multi-homed wireless devices along with simultaneous multi-path data transfer offers tremendous potentials to improve the capacity of multi-hop wireless networks. The use of simultaneous data transfer over separate disjoint paths in multi-hop wireless networks to increase network capacity is a less explored subject, mainly because of the challenges it triggers for the reliable transport layer protocols. Reliable transport layer protocols generally use packet sequence number as a mean to ensure delivery. As such, the out-of-order packet arrival in reliable transport layer protocols triggers receiver buffer blocking that causes throughput degradation and prevents the reliable multi-path transport layer protocol to realize its vast potential. This paper focuses on integrating network coding with a reliable multi-path transport layer protocol to resolve the receiver buffer blocking problem. We propose an adaptive network coding mechanism to desensitize the receiver against packet reordering and consequently eliminate the receiver buffer blocking problem. Our state-of-the-art network coding scheme uses a combination of Q-learning and logistic regression for rare data events to control the number of redundant packets based on the network dynamics. We confirmed the veracity of our proposed scheme by a queuing theory based mathematical model. Moreover, the effectiveness of the proposed scheme is demonstrated through simulations and testbed experiments.","1536-1233;15361233","","10.1109/TMC.2016.2585106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7500052","Machine learning;Markov processes;SCTP-CMT;algorithm/protocol design and analysis;coding and information theory;wireless","Data transfer;Encoding;Network coding;Protocols;Receivers;Reliability;Spread spectrum communication","adaptive codes;multipath channels;network coding;queueing theory;regression analysis;transport protocols;wireless channels","Q-learning;adaptive network coding;concurrent multipath data transfer;logistic regression;multihomed wireless devices;multihop wireless networks;multipath transport layer protocol;network capacity;network dynamics;out-of-order packet arrival;packet sequence number;performance booster;queuing theory;receiver buffer blocking problem;redundant packet control","","","","","","20160627","April 1 2017","","IEEE","IEEE Journals & Magazines"
"University ranking prediction system by analyzing influential global performance indicators","A. Tabassum; M. Hasan; S. Ahmed; R. Tasmin; D. M. Abdullah; T. Musharrat","Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology","2017 9th International Conference on Knowledge and Smart Technology (KST)","20170327","2017","","","126","131","In this research, we present a technique of developing university ranking prediction system by analyzing global university performance indicators. Here, we consider standardized dataset of Times higher education world university rankings. Firstly, we perform country wise university ranking data analysis to observe the variation of performance indicators to find out the top influential features. To build the proposed prediction model, we split the ranking dataset into training and test data. Then, based on score of previous years we generate predicted score for each influential feature using our proposed outlier detection and rank score calculation algorithm. Later on, all the universities are ranked globally based on the predicted total score. Then, we evaluate the prediction system accuracy based on ROC curve, recall, number of matched rank against rank deviation. Finally it is justified that our proposed university ranking prediction system is well suited to assess the upcoming global university ranking.","","Electronic:978-1-4673-9077-4; POD:978-1-4673-9078-1","10.1109/KST.2017.7886119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886119","Computational Intelligence;Data Analysis;Global University Ranking;Machine Learning;Prediction System","Algorithm design and analysis;Data analysis;Government;Industries;Prediction algorithms;Training","data analysis;educational administrative data processing;educational institutions;further education","Times higher education world university rankings;country wise university ranking data analysis;global university performance indicators;outlier detection;rank score calculation algorithm;university ranking prediction system","","","","","","","1-4 Feb. 2017","","IEEE","IEEE Conference Publications"
"Hooked on Springs: Using Virtualized Damped Harmonic Oscillators to Explore Complex Search Spaces","J. Kundert-Gibbs; W. D. Potter","Inst. For Artificial Intell., Univ. of Georgia, Athens, GA, USA","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1083","1088","A new search engine, based on Hooke's Law, is proposed and applied to both the Multiple Subscriber Equipment (MSE) deployment and Schaffer's F6 equation problems. A virtualized Damped Simple Harmonic Oscillator is constructed using a system with multiple oscillating. The VHO search engine is constructed to converge on an optimal or near-optimal solution, and then, due to damping, come to rest, at which point the search stops. For the MSE problem, the engine finds the optimal solution 90 to nearly 100% of the time (depending on settings) and does so efficiently. For Schaffer's F6, the engine produces more variable fitness levels than a reference Genetic Algorithm (GA) search engine, but has found two solutions better than the GA.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881500","AI;artificial intelligence;machine learning;search;simple harmonic oscillator","Dynamic range;Force;Genetic algorithms;Harmonic analysis;Oscillators;Search engines;Springs","damping;harmonic oscillators;mechanical engineering computing;search engines;springs (mechanical)","GA search engine;Hooke law;MSE deployment;Schaffer F6 equation problems;Springs;VHO search engine;genetic algorithm;multiple subscriber equipment;virtualized damped harmonic oscillators","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Analysis of a Payload-based Network Intrusion Detection System Using Pattern Recognition Processors","I. M. Iqbal; R. A. Calix","Dept. of Comput. Inf. Technol. & Graphics, Purdue Univ. Calumet, Hammond, IN, USA","2016 International Conference on Collaboration Technologies and Systems (CTS)","20170306","2016","","","398","403","Intrusion detection systems are a necessary tool to protect computer networks from cyber-attacks. Analyzing the payload of a packet can help in identifying strings that can help to detect attacks. Machine learning can be used to train models based on feature extraction of packet payloads. One important issue is that payload based intrusion detection systems may be too slow for standard processing approaches. Analyzing payloads has advantages over analyzing the standard headers of a packet. However, this approach is more resource intensive. The purpose of this study is to analyze the speed and accuracy performance of a payload based network intrusion detection system using pattern recognition processor with a unigram feature extraction approach. Results of the study are presented and discussed.","","Electronic:978-1-5090-2300-4; POD:978-1-5090-2301-1","10.1109/CTS.2016.0077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871015","IDS;Machine learning;intrusion detection;pattern recognition processor;payload processing","Feature extraction;Intrusion detection;Machine learning algorithms;Pattern recognition;Payloads;Program processors;Training","computer network security;learning (artificial intelligence);pattern recognition","attack detection;computer network protection;cyber-attacks;feature extraction;machine learning;packet payload analysis;packet payloads;pattern recognition processors;payload-based network intrusion detection system analysis;unigram feature extraction approach","","","","","","","Oct. 31 2016-Nov. 4 2016","","IEEE","IEEE Conference Publications"
"Topology-Aware Prediction of Virtual Network Function Resource Requirements","R. Mijumbi; S. Hasija; S. Davy; A. Davy; B. Jennings; R. Boutaba","Bell Labs CTO, Nokia, Dublin, Ireland","IEEE Transactions on Network and Service Management","20170309","2017","14","1","106","120","Network functions virtualization (NFV) continues to gain attention as a paradigm shift in the way telecommunications services are deployed and managed. By separating network function from traditional middleboxes, NFV is expected to lead to reduced capital expenditure and operating expenditure, and to more agile services. However, one of the main challenges to achieving these objectives is how physical resources can be efficiently, autonomously, and dynamically allocated to virtualized network function (VNF) whose resource requirements ebb and flow. In this paper, we propose a graph neural network-based algorithm which exploits VNF forwarding graph topology information to predict future resource requirements for each VNF component (VNFC). The topology information of each VNFC is derived from combining its past resource utilization as well as the modeled effect on the same from VNFCs in its neighborhood. Our proposal has been evaluated using a deployment of a virtualized IP multimedia subsystem, and real VoIP traffic traces, with results showing an average prediction accuracy of 90%, compared to 85% obtained while using traditional feed-forward neural networks. Moreover, compared to a scenario where resources are allocated manually and/or statically, our technique reduces the average number of dropped calls by at least 27% and improves call setup latency by over 29%.","1932-4537;19324537","","10.1109/TNSM.2017.2666781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849149","Network functions virtualisation;dynamic resource allocation;graph neural networks;machine learning;prediction;topology-awareness;virtual network functions","Dynamic scheduling;Multimedia communication;Neural networks;Proposals;Reliability;Resource management;Topology","computer networks;graph theory;learning (artificial intelligence);neural nets;resource allocation;telecommunication computing;virtualisation","NFV;VNFC;graph neural network;machine learning;middleboxes;network functions virtualization;resource requirements;resource utilization;topology-aware prediction;virtualized network function component","","","","","","20170209","March 2017","","IEEE","IEEE Journals & Magazines"
"A Multi-Objective Genetic Local Search Algorithm for Optimal Feature Subset Selection","D. Tian","Leeds Sustainability Inst., Leeds Beckett Univ., Leeds, UK","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1089","1094","Feature selection algorithms select the most relevant features of a data set to improve the classification performance of the machine learning classifiers trained using the data set. This paper proposes a feature selection algorithm called ultiobjective genetic local search (MOGLS) which integrates a 3-objective genetic algorithm with a local search heuristic to find feature subsets with the maximum prediction accuracy, the smallest sizes and the minimum redundancy. The performance of MOGLS is compared with 4 algorithms: a wrapper genetic algorithm, correlation-based feature selection, mutual information ranking and C4.5 on 8 datasets from the UCI machine learning repository. MOGLS performs better than or as good as the 4 algorithms on the 8 datasets.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881501","Fuzzy and rough data analysis;Genetic algorithms;Machine learning technologies;Metaheuristic optimization algorithms;Multi-objective evolutionary algorithms","Genetic algorithms;Genetics;Machine learning algorithms;Prediction algorithms;Sociology;Statistics;Training","feature selection;genetic algorithms;pattern classification;search problems","C4.5;MOGLS;UCI machine learning repository;classification;correlation-based feature selection;feature subset selection;multiobjective genetic local search algorithm;mutual information ranking;wrapper genetic algorithm","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction","Y. Chen; Q. Chen; Mingqian Zhao; S. Boyer; K. Veeramachaneni; H. Qu","Hong Kong University of Science and Technology, China","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","20170323","2016","","","111","120","Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.","","Electronic:978-1-5090-5661-3; POD:978-1-5090-5662-0","10.1109/VAST.2016.7883517","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883517","Visualization in education;design studies;machine learning;time series data","Data models;Data visualization;Education;Feature extraction;Predictive models;Visual analytics","courseware;educational courses","DropoutSeer;MOOC;dropout behavior;dropout reasoning;education experts;heterogeneous data;learner activity logs;learning patterns;massive open online courses;open access education;predictive modeling;predictive models;statistical models;visual analytics system","","","","","","","23-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Statistical Anomaly Detection in Human Dynamics Monitoring Using a Hierarchical Dirichlet Process Hidden Markov Model","T. Fuse; K. Kamiya","Department of Civil Engineering, The University of Tokyo, Tokyo 113-8656, Japan.","IEEE Transactions on Intelligent Transportation Systems","","2017","PP","99","1","10","Understanding of human dynamics has drawn attention to various areas. The wide spread of positioning technologies, such as GPS facilitates location information to be obtained with high spatio-temporal resolution as well as at low costs. By collecting individual location information in real time, monitoring of human dynamics has recently become possible and is expected to the area of dynamic traffic control. In this monitoring, detecting anomalous states of human dynamics become important. This research aims to define an anomaly detection problem of the human dynamics monitoring with time-series gridded population data and develop an anomaly detection method for this problem. According to the result of a review we have conducted, we discussed the characteristics of the anomaly detection in human dynamics monitoring and categorized our problem to a semi-supervised anomaly detection problem that detects contextual anomalies behind time-series data. We developed an anomaly detection method based on a sticky hierarchical Dirichlet process hidden Markov model, which is able to estimate the number of latent states according to the input data. Results of the experiment with synthetic data showed that our proposed method has good fundamental performance with respect to the detection rate. Through the experiments with real gridded population data, anomalies were detected when and where an actual social event had occurred.","1524-9050;15249050","","10.1109/TITS.2017.2674684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883816","Anomaly detection;hidden Markov models;human dynamics;machine learning;nonparametric Bayes.","Bayes methods;Hidden Markov models;Monitoring;Sociology;State-space methods;Statistics;Vehicle dynamics","","","","","","","","20170321","","","IEEE","IEEE Early Access Articles"
"Are They Paying Attention? A Model-Based Method to Identify Individuals' Mental States","T. Zhang; R. Fruchter; M. Frank","Stanford University","Computer","20170328","2017","50","3","40","49","In a global economy, online meeting participants often have different backgrounds, making it difficult to know their mental and physical states. The Mental Motion State Model, trained by applying the Gaussian mixture model to electroencephalogram data, can indicate degrees of engagement and fatigue levels, providing a feedback channel for self-regulation.","0018-9162;00189162","","10.1109/MC.2017.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888422","Internet technologies;QoL technologies;collaborative work;distributed work;machine learning algorithms;mental motion states;personal communication models;predictive technology;quality-of-life technologies;teamwork","Brain modeling;Collaboration;Data models;Electroencephalography;Gaussian distribution;Machine learning;Quality of service;Switches;Teamwork","Gaussian processes;behavioural sciences computing;cognition;electroencephalography;learning (artificial intelligence);medical signal processing;mixture models;psychology","Gaussian mixture model;electroencephalogram data;engagement levels;fatigue levels;individual mental states;mental motion state model training;online meeting participants","","","","","","","Mar. 2017","","IEEE","IEEE Journals & Magazines"
"Events Discovery Assistant: A Semi-Supervised Spatio-Temporal and Semantic Model for Discovering First World War Events","M. Nassar; N. Apostolopoulos","Center for Digital Syst., Freie Univ. Berlin, Berlin, Germany","2017 IEEE 11th International Conference on Semantic Computing (ICSC)","20170330","2017","","","401","406","The present paper proposes a dynamic semantic search interface for discovering First World War events. A semi-automated knowledge retrieval algorithm was designed to automatically extract historical events from unstructured scholar texts and define their ontology-based semantic relevance, as well as, their spatial and temporal information. The interface is called ""Events Discovery Assistant"" and is able to improvise with the continuously growing historical contents. Based on semantic web technologies, the interface allow users to query events related to First World War specific (ontology-based) topic(s) and explore their evolved spatial and temporal patterns.","","Electronic:978-1-5090-4284-5; POD:978-1-5090-4285-2","10.1109/ICSC.2017.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889570","Algorithm;Digital Humanity;Event Discovery;First World War;Machine Learning;Search Engine;Semantic Web Technologies","Data mining;Electronic publishing;Encyclopedias;Internet;Libraries;Semantics","history;information retrieval;ontologies (artificial intelligence);semantic Web","Events Discovery Assistant;First World War event discovery;dynamic semantic search interface;historical events;ontology-based semantic relevance;semantic Web technologies;semantic model;semiautomated knowledge retrieval algorithm;semisupervised spatiotemporal model","","","","","","","Jan. 30 2017-Feb. 1 2017","","IEEE","IEEE Conference Publications"
"Multiclass support vector machine for classification spatial data from satellite image","K. Tangthaikwan; N. Keeratipranon; A. Agsornintara","Department of Computer, Faculty of Liberal Arts and Science, Kamphaeng Saen Campus, Kasetsart University, Nakonpathom, Thailand","2017 9th International Conference on Knowledge and Smart Technology (KST)","20170327","2017","","","111","115","This paper presents a method for the classification of Landsat Multi-Spectral Scanner (MSS) satellite images to identify the areas of land use. The image is pre-processed and classified using Support Vector Machine (SVM) with the Radial Basis Function (RBF) Kernel as it is an efficient supervised-classification technique. In this research, pixel - base classification method is performed according to the value of spectral pixels with Multi-Spectral Scanner satellite image and used data corresponds to a 3×3 square neighborhoods. The research work consists of two main stages. At the first stage, the optimal parameter, sigma value of RBF kernel, for SVM is studied. At the second stage, the obtained classification result is compared with other classification methods. In this study, sigma value, a parameter of RBF kernel, is varied between 1.0 and 2.0. The sigma value at 1.7 lead to the best classification result which has over 90% accuracy. The result from this SVM method has a higher accuracy compared to other methods.","","Electronic:978-1-4673-9077-4; POD:978-1-4673-9078-1","10.1109/KST.2017.7886107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886107","Landsat Multi-Spectral Scanner;Machine Learning;Satellite Images;Support Vector Machine","Agriculture;Earth;Kernel;Remote sensing;Satellites;Soil;Support vector machines","geophysical image processing;image classification;land use;radial basis function networks;support vector machines","Landsat multispectral scanner satellite image classification;RBF kernel sigma value;land use;multiclass support vector machine;pixel-base classification;radial basis function kernel;spatial data classification;spectral pixels;supervised-classification technique","","","","","","","1-4 Feb. 2017","","IEEE","IEEE Conference Publications"
