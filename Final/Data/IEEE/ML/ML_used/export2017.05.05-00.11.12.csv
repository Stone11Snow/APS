"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6786135,6786173,6786125,6784616,6786086,6786099,6784596,6784588,6784644,6786138,6786102,6786073,6784583,6784629,6784650,6784618,6784590,6786140,6786075,6784578,6784620,6784580,6786092,6786108,6784607,6784626,6786159,6786165,6786090,6786106,6784640,6786128,6784647,6784653,6784624,6784602,6786124,6786157,6786085,6786098,6786151,6784658,6786163,6786131,6786137,6786088,6786101,6786104,6784634,6784631,6784582,6784649,6786126,6784617,6784597,6784589,6784645,6786139,6786074,6784651,6784619,6786141,6784579,6786143,6786109,6786166,6786107,6784625,6786158,6786119,6786152,6784659,6786164,6786089,6786105,6784635,6784639,6784652,6784622,6786144,6786167,6786170,6786120,6786153,6784599,6784623,6786111,6786171,6786121,6786112,6786122,6786155,6786113,6786123,6786156,6786114,6786115,6786116,6786117,6661945",2017/05/05 00:11:12
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Covariate shift approach for invariant texture classification","A. Hassan; A. Shaukat","Dept. of Comput. Eng., Nat. Univ. of Sci. & Technol. (NUST), Islamabad, Pakistan","2013 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)","20131114","2013","","","1","6","This paper deals with rotation and scale invariant texture classification problem at the machine learning level by modelling these variations in the texture data as a covariate shift. Covariate shift between the training and testing data is minimised by estimating importance weights for the training data which are then incorporated in a standard machine learning algorithm like support vector machines. The effectiveness of these importance weighted support vector machines (IW-SVM) are tested on the Brodatz dataset. The comparative classification results with several other state of the art methodologies demonstrate the effectiveness of the proposed covariate shift approach for rotation and scale invariant texture classification.","1551-2541;15512541","Electronic:978-1-4799-1180-6; POD:978-1-4799-1179-0; USB:978-1-4799-1178-3","10.1109/MLSP.2013.6661945","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6661945","Machine learning;covariate shift;importance weighting and support vector machines","Accuracy;Standards;Support vector machines;Testing;Training;Training data;Vectors","covariance analysis;image classification;image texture;learning (artificial intelligence);support vector machines","Brodatz dataset;IW-SVM;comparative classification;covariate shift approach;importance weighted support vector machines;machine learning algorithm;machine learning level;rotation invariant texture classification;scale invariant texture classification;state of the art methodology;testing data;texture data;training data","","0","","13","","","22-25 Sept. 2013","","IEEE","IEEE Conference Publications"
"Clustering Based Classification in Data Mining Method Recommendation","O. KazíK; K. Peková; J. míd; R. Neruda","Fac. of Math. & Phys., Charles Univ., Prague, Czech Republic","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","356","361","With the growing amount of data available in today's world, the emphasis is laid on the automatic configuration of data analysis - metal earning. This paper elaborates one of the metal earning sub problems, the data mining method recommendation. Based on a metric over the data features called metadata, we have proposed a solution exploiting clustering of datasets. The agglomerative algorithm is used to construct clustering over the metadata, and the average methods' performance is computed in each cluster. The ranking of data mining methods is then deduced from the classification of a dataset to a particular cluster. The recommendation algorithm, which is implemented within our data mining multi-agent system, has been tested in various configurations, and the results of these experiments have been compared.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786135","Metalearning;clustering;data mining;method recommendation","Clustering algorithms;Data mining;Entropy;Error analysis;Measurement;Training","data analysis;data mining;learning (artificial intelligence);meta data;pattern classification;pattern clustering;recommender systems","agglomerative algorithm;clustering based classification;data mining method recommendation;data mining multiagent system;dataset classification;metadata;metalearning subproblem","","1","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Scenario Based Functional Regression Testing Using Petri Net Models","F. Ahmad; Z. H. Qaisar","Fac. of Inf. Technol., Univ. of Central Punjab, Lahore, Pakistan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","572","577","Software testing lies in the validation which ensures that the implementation satisfies the client's requirements. There are several techniques on software testing some are implementation based while others are model based. We have proposed the Petri net model based testing technique for testing the software. Although UML is the de-facto standard for the software development however most of the UML diagrams supports static behavior while Petri nets supports dynamic behavior i.e. we can represent concurrent behavior of objects in case of object oriented paradigm. In our case we have also selected object oriented paradigm as it is well established paradigm and provides ease in development and it is more realistic. We have proposed a regression based testing technique using Petri nets. Regression testing technique is applied on the Delta version i.e. changed version of the software. Our technique has efficient mechanism of reducing the test suite for the delta version on the basis of analysis of the baseline version. Petri net models are used in this paper for analyzing the baseline and delta version.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786173","Petri nets;change analysis;change identification;formal methods;model based testing;software testing;test suite;test suite reduction","Analytical models;Computational modeling;Object oriented modeling;Petri nets;Software;Testing;Unified modeling language","Petri nets;object-oriented methods;program testing;program verification","Delta version;Petri net models;baseline version analysis;object-oriented paradigm;scenario-based functional regression testing;software development;software testing;software validation;test suite reduction","","0","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Unsupervised Video Summarization via Dynamic Modeling-Based Hierarchical Clustering","K. M. Mahmoud; N. M. Ghanem; M. A. Ismail","Comput. & Syst. Eng. Dept., Alexandria Univ., Alexandria, Egypt","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","303","308","Mining the video data using unsupervised learning techniques can reveal important information regarding the internal visual content of large video databases. One of these information is the video summary which is a sequence of still pictures that represent the content of a video in such a way that the respective target group is rapidly provided with concise information about the content, while the essential message of the original video is preserved. In this paper, an enhanced method for generating static video summaries is presented. This method utilizes a modified dynamic modeling-based hierarchical clustering algorithm that depends on the temporal order and sequential nature of the video to fasten the clustering process. Video summaries generated by our method are compared with summaries generated by others found in the literature and the ground truth summaries. Experimental results indicate that the video summaries generated by the proposed method have a higher quality than others.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786125","Clustering;Dynamic Modeling;Key Frames Extraction;Video Summarization","Clustering algorithms;Color;Feature extraction;Heuristic algorithms;Histograms;Image color analysis;Partitioning algorithms","data mining;feature extraction;image sequences;pattern clustering;unsupervised learning;video signal processing","clustering process;dynamic modeling-based hierarchical clustering algorithm;static video summaries;unsupervised learning techniques;unsupervised video summarization;video content;video data mining;video databases;visual content","","3","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Coordinated Reinforcement Learning Agents in a Multi-agent Virtual Environment","W. Sause","Grad. Sch. of Comput. & Inf. Sci., Nova Southeastern Univ., Fort Lauderdale, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","227","230","This research presents a framework for coordinating multiple intelligent agents within a single virtual environment. Coordination is accomplished via a ""next available agent"" scheme while learning is achieved through the use of the Q-learning and Sarsa temporal difference reinforcement learning algorithms. To assess the effectiveness of each learning algorithm, experiments were conducted that measured an agent's ability to learn tasks in a static and dynamic environment while using both a fixed (FEP) and variable (VEP) ϵ-greedy probability rate. Results show that Sarsa, on average, outperformed Q-learning in almost all experiments. Overall, VEP resulted in higher percentages of successes and optimal successes than FEP, and showed convergence to the optimal policy when measuring the average number of time steps per episode.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784616","Reinforcement learning;intelligent agents;virtual environments","Convergence;Educational institutions;Heuristic algorithms;Intelligent agents;Learning (artificial intelligence);Time measurement;Virtual environments","convergence;greedy algorithms;learning (artificial intelligence);multi-agent systems;probability","FEP;Q-learning algorithm;Sarsa temporal difference reinforcement learning algorithm;VEP;agent task learning ability measurement;convergence;coordinated reinforcement learning agents;dynamic environment;fixed ϵ-greedy probability rate;multiagent virtual environment;multiple intelligent agent coordination;next-available agent scheme;optimal policy;static environment;variable ϵ-greedy probability rate","","0","","6","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Empirical Study on Wrapper-Based Feature Selection for Software Engineering Data","H. Wang; T. M. Khoshgoftaar; A. Napolitano","Western Kentucky Univ., Bowling Green, KY, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","84","89","Software metrics give valuable information for understanding and predicting the quality of software modules, and thus it is important to select the right software metrics for building software quality classification models. In this paper we focus on wrapper-based feature (metric) selection techniques, which evaluate the merit of feature subsets based on the performance of classification models. We seek to understand the relationship between the internal learner used inside wrappers and the external learner for building the final classification model. We perform experiments using four consecutive releases of a very large telecommunications system, which include 42 software metrics (and with defect data collected for every program module). Our results demonstrate that (1) the best performance is never found when the internal and external learner match, (2)the best performance is usually found by using NB (Naïve Bayes) inside the wrapper unless SVM (Support Vector Machine) is external learner, (3) LR (Logistic Regression) is often the best learner to use for building classification models regardless of which learner was used inside the wrapper.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786086","learner;software quality prediction model;wrapper-based feature selection","Buildings;Data models;Measurement;Niobium;Software quality;Support vector machines","Bayes methods;feature selection;pattern classification;regression analysis;software metrics;software quality;support vector machines","LR;NB;SVM;external learner;internal learner;logistic regression;naive Bayes;software engineering data;software metrics;software quality classification models;support vector machine;telecommunications system;wrapper-based feature selection technique","","0","","24","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Use of a Feedforward Neural Network for Predicting the Development Duration of Software Projects","C. López-Martín; A. Chavoya; M. E. Meda-Campaña","Inf. Syst. Dept., Univ. de Guadalajara, Guadalajara, Mexico","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","156","159","Context: In the software engineering field, only 20 percent of software projects finish on time relative to their original plan. A software project can be classified as a new development, an enhanced development or a re-development. Goal: To propose a feed forward neural network (FFNN) for predicting the duration of new software development projects. Hypothesis: The accuracy of duration prediction for an FFNN is statistically better than the accuracy obtained from a statistical regression (SR) when an adjusted function points (AFPs) value, obtained from new software development projects, is used as the independent variable. Method: A sample obtained from the International Software Benchmarking Standards Group (ISBSG) Release 11 corresponding to new development projects was used. The accuracy of the FFNN was compared against that of an SR model. The criteria for evaluating the accuracy of these two models were the Mean Magnitude of Relative Error (MMRE) and an ANOVA statistical test. Results: Prediction accuracy of an FFNN was statistically better than that of an SR model at the 90% confidence level. Conclusion: An FFNN could be applied for predicting the duration of new software development projects when AFPs were used as independent variable.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786099","ISBSG;feedforward neural network;software engineering;software project duration prediction","Accuracy;Neural networks;Neurons;Predictive models;Software;Software engineering;Training","feedforward neural nets;project management;regression analysis;software development management","AFP value;ANOVA statistical test;FFNN;ISBSG Release 11;International Software Benchmarking Standards Group;MMRE;SR model;adjusted function points;feedforward neural network;independent variable;mean magnitude of relative error;new software development projects;software engineering;software project development duration prediction;statistical regression","","4","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Learning Decision Trees from Uncertain Data with an Evidential EM Approach","N. Sutton-Charani; S. Destercke; T. Denoeux","Univ. Technol. de Compi`egne, Compiegne, France","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","111","116","In real world applications, data are often uncertain or imperfect. In most classification approaches, they are transformed into precise data. However, this uncertainty is an information in itself which should be part of the learning process. Data uncertainty can take several forms: probabilities, (fuzzy)sets of possible values, expert assessments, etc. We therefore need a flexible and generic enough model to represent and treat this uncertainty, such as belief functions. Decision trees are well known classifiers which are usually learned from precise datasets. In this paper we propose a methodology to learn decision trees from uncertain data in the belief function framework. In the proposed method, the tree parameters are estimated through the maximization of an evidential likelihood function computed from belief functions, using the recently proposed E<sup>2</sup>M algorithm that extends the classical EM. Some promising experiments compare the obtained trees with classical CART decision trees.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784596","algorithm EM;belief functions;classification;decision trees","Accuracy;Data models;Decision trees;Mathematical model;Prediction algorithms;Probabilistic logic;Uncertainty","belief networks;decision trees;expectation-maximisation algorithm;expert systems;fuzzy set theory;learning (artificial intelligence);probability","CART decision trees;E2M algorithm;belief function framework;belief functions;data uncertainty;evidential EM approach;evidential likelihood function;expert assessments;fuzzy sets;learning decision trees;probability;tree parameters","","1","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Approximate l-Fold Cross-Validation with Least Squares SVM and Kernel Ridge Regression","R. E. Edwards; H. Zhang; L. E. Parker; J. R. New","Electr. Eng. & Comput. Sci., Univ. of Tennessee, Knoxville, TN, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","58","64","Kernel methods have difficulties scaling to large modern data sets. The scalability issues are based on computational and memory requirements for working with a large matrix. These requirements have been addressed over the years by using low-rank kernel approximations or by improving the solvers' scalability. However, Least Squares Support Vector Machines (LS-SVM), a popular SVM variant, and Kernel Ridge Regression still have several scalability issues. In particular, the O(n^3) computational complexity for solving a single model, and the overall computational complexity associated with tuning hyper parameters are still major problems. We address these problems by introducing an O(nlog n) approximate l-fold cross-validation method that uses a multi-level circulant matrix to approximate the kernel. In addition, we prove our algorithm's computational complexity and present empirical runtimes on data sets with approximately one million data points. We also validate our approximate method's effectiveness at selecting hyper parameters on real world and standard benchmark data sets. Lastly, we provide experimental results on using a multi level circulant kernel approximation to solve LS-SVM problems with hyper parameters selected using our method.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784588","","Approximation algorithms;Computational complexity;Kernel;Least squares approximations;Runtime;Support vector machines","approximation theory;computational complexity;data handling;least squares approximations;matrix algebra;regression analysis;support vector machines","LS-SVM;approximate l-fold cross-validation;computational complexity;computational requirements;hyper parameter tuning;kernel methods;kernel ridge regression;least squares SVM;least squares support vector machines;low-rank kernel approximations;memory requirements;multilevel circulant kernel approximation;multilevel circulant matrix;real world benchmark data sets;scalability issues;standard benchmark data sets","","1","","22","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Empirical Evaluation of Profile Characteristics for Gender Classification on Twitter","J. S. Alowibdi; U. A. Buy; P. Yu","Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","365","369","Online Social Networks (OSNs) provide reliable communication among users from different countries. The volume of texts generated by OSNs is huge and highly informative. Gender classification can serve commercial organizations for advertising, law enforcement for legal investigation, and others for social reasons. Here we explore profile characteristics for gender classification on Twitter. Unlike existing approaches to gender classification that depend heavily on posted text such as tweets, here we study the relative strengths of different characteristics extracted from Twitter profiles (e.g., first name and background color in a user's profile page). Our goal is to evaluate profile characteristics with respect to their predictive accuracy and computational complexity. In addition, we provide a novel technique to reduce the number of features of text-based profile characteristics from the order of millions to a few thousands and, in some cases, to only 40 features. We prove the validity of our approach by examining different classifiers over a large dataset of Twitter profiles.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784644","Color-based features;color quantization;language independence;phonemes as features;profile characteristics;social networks","Accuracy;Color;Image color analysis;Niobium;Quantization (signal);Sorting;Twitter","computational complexity;computer mediated communication;gender issues;pattern classification;social networking (online)","OSN;Twitter profiles;background color;commercial organizations;computational complexity;gender classification;informative texts;legal investigation;online social networks;profile characteristics;text-based profile characteristics;user profile page","","9","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Improved Helper-Objective Optimization Strategy for Job-Shop Scheduling Problem","I. Petrova; A. Buzdalova; M. Buzdalov","St. Petersburg Nat. Res. Univ. of Inf. Technol., Mech. & Opt., St. Petersburg, Russia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","374","377","A single-objective optimization problem can be solved more efficiently by introducing some helper-objectives and running a multi-objective evolutionary algorithm. But what objectives should be used at each optimization stage? This paper describes a new method of adaptive helper-objectives selection in multi-objective evolutionary algorithms. The proposed method is applied to the Job-Shop scheduling problem and compared with the previously known approach, which was specially developed for the Job-Shop problem. A comparison with the previously proposed method of adaptive helper-objective selection based on reinforcement learning is performed as well.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786138","adaptive selection;helper-objectives;job-shop problem;multi-objective optimization","Evolutionary computation;Learning (artificial intelligence);Optimization;Radiation detectors;Schedules;Sociology;Statistics","evolutionary computation;job shop scheduling;learning (artificial intelligence)","improved helper objective optimization strategy;job shop scheduling problem;multi objective evolutionary algorithm;reinforcement learning;single objective optimization problem","","1","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Preprocessing in Fuzzy Time Series to Improve the Forecasting Accuracy","F. J. J. D. Santos; H. D. A. Camargo","Comput. Dept., Fed. Univ. of Sao Carlos, Sao Carlos, Brazil","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","170","173","The preprocessing in fuzzy time series has an important role to improve the forecast accuracy. The definitions of domain, number of linguistic terms and of the membership function to each fuzzy set, has direct influence in the forecast results. Thus, this paper has the focus on definition of these parameters, before of performing the prediction. The experimental results in enrollments time series show that, when the forecast is performed after proposed preprocessing, the accuracy rate is improved.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786102","forecasting;fuzzy time series;preprocessing","Accuracy;Computational modeling;Forecasting;Fuzzy sets;Pragmatics;Predictive models;Time series analysis","forecasting theory;fuzzy set theory;time series","forecast accuracy;forecasting accuracy;fuzzy set;fuzzy time series preprocessing;linguistic terms","","0","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Generalized Flexible Fuzzy Inference Systems","E. Lughofer; C. Cernuda; M. Pratama","Dept. of Knowledge-Based Math. Syst., Johannes Kepler Univ. of Linz, Linz, Austria","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","1","7","In this paper, we propose a new variant for incremental, evolving fuzzy systems extraction from data data streams, termed as GEN-FLEXFIS (short for Generalized Flexible Fuzzy Inference Systems). It builds upon the FLEXFIS methodology (published by the authors before) and extends it for generalized Takagi-Sugeno (TS) fuzzy systems, which implement generalized rotated rules in arbitrary position, employing a high-dimensional kernel rather than a connection of one-dimensional components (fuzzy sets) with t-norms. The extension includes the development of the evolving clustering learning engine, termed as eVQ-A, to extract ellipsoidal clusters in arbitrary position. Furthermore, a new merging concept based on a combined adjacency-homogenuity relation between two clusters (rules) is proposed in order to prune unnecessary rules and to keep the complexity of the generalized TS fuzzy systems low. Equipped with a new projection concept for high-dimensional kernels onto one-dimensional fuzzy sets, the new approach also provides equivalent conventional TS fuzzy systems, thus maintaining interpretability when inferring new query samples. GEN-FLEXFIS will be evaluated based on high-dimensional real-world data (streaming) sets in terms of accuracy versus final model complexity, compared with conventional FLEXFIS and other well-known (evolving) fuzzy systems approaches.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786073","GEN-FLEXFIS;combined adjacency-homogenuity relation;data stream regression;generalized Takagi-Sugeno (TS) fuzzy systems;projection concept;rule merging","Approximation methods;Complexity theory;Covariance matrices;Ellipsoids;Fuzzy systems;Merging;Vectors","computational complexity;fuzzy reasoning;fuzzy set theory;fuzzy systems;learning (artificial intelligence);merging;pattern clustering","FLEXFIS methodology;GEN-FLEXFIS;combined adjacency-homogenuity relation;data streams;eVQ-A;ellipsoidal clusters extraction;evolving clustering learning engine;evolving fuzzy systems extraction;generalized TS fuzzy systems;generalized Takagi-Sugeno fuzzy systems;generalized flexible fuzzy inference systems;generalized rotated rules;high-dimensional kernel;incremental fuzzy systems extraction;merging concept;model complexity;one-dimensional fuzzy sets;projection concept;query samples","","1","","28","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Improving Software Quality Estimation by Combining Boosting and Feature Selection","K. Gao; T. Khoshgoftaar; A. Napolitano","Eastern Connecticut State Univ., CT, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","27","33","The predictive accuracy of a classification modelis often affected by the quality of training data. However, there are two problems which may affect the quality of the training data: high dimensionality (too many independent attributes in a dataset) and class imbalance (many more instances of one class than the other class in a binary-classification problem). In this study, we present an iterative feature selection approach working with an ensemble learning method to solve both of these problems. The iterative feature selection approach samples the dataset k times and applies feature ranking to each sampled dataset, the k different rankings are then aggregated to create a single feature ranking. The ensemble learning method used is RUSBoost, in which random under sampling(RUS) is integrated into a boosting algorithm. The main purpose of this paper is to investigate the impact of feature selection as well as the RUSBoost approach on the classification performance in the context of software quality prediction. In the experiment, we explore six rankers, each used along with RUS in the iterative feature selection process. Following feature selection, models are built either using a plain learner or byusing the RUSBoost algorithm. We also examine the case of no feature selection and use this as the baseline for comparisons. The experimental results demonstrate that with the exception of one learner, feature selection combined with boosting provides better classification performance than when either is applied alone or when neither are applied.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784583","Data Sampling;Feature Selection;Performance Metric;RUSBoost;Software Quality Classification","Boosting;Data models;Iterative methods;Measurement;Predictive models;Radio frequency;Software algorithms","iterative methods;learning (artificial intelligence);software metrics;software quality","RUSBoost;binary-classification problem;boosting algorithm;class imbalance;classification model;ensemble learning;feature ranking;iterative feature selection;software quality estimation;software quality prediction","","0","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Segmental Analysis and Evaluation of User Focused Search Process","C. Hendahewa; C. Shah","Dept. of Comput. Sci., Rutgers Univ., Piscataway, NJ, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","291","294","In general, IR systems assist searchers by predicting or assuming what could be useful for their information needs by providing query suggestions or pseudo-relevance feedback. Most of these approaches are based on analyzing information objects (documents, queries) seen or used in the past and then proposing other related objects that may be relevant. Such approaches often ignore the underlying process of information seeking that guides how a searcher performs during information seeking episode, thus forgoing opportunities for making process-based recommendations. In order to address this, we propose a search process-based analysis of discovering different segments, which leads to analyzing different search action based features and evaluating the search performance for each stage. Further, we propose a query recommendation strategy to improve the search performance of each low performing user for each stage, which shows that the proposed overall model yields effective search performance improvements above 90% in most cases. This could lead to better recommendations and optimizations within each segment in order to enhance the overall search performance of a user.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784629","Evaluation;Exploratory search;Sequence Analysis;Time Series Analysis","Educational institutions;Logistics;Predictive models;Recommender systems;Search problems;Time measurement;Time series analysis","information filtering;information retrieval system evaluation;performance evaluation;query formulation;query processing;relevance feedback;time series","IR systems;information objects;information retrieval systems;information seeking;pseudorelevance feedback;query recommendation strategy;query suggestions;search process-based analysis;time series analysis;user focused search process;user search performance evaluation","","1","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Learning the Dynamic Process of Inhibition and Task Switching in Robotics Cognitive Control","M. Menna; M. Gianni; F. Pirri","Perception & Cognitive Robot. Lab. DIIAG, Univ. of Rome, Rome, Italy","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","392","397","Modeling cognitive control is a major issue in robot control, and it is about deciding when a task cannot succeed and a new task need to be initiated. These decisions are induced by incoming stimuli alerting of events taking place while the robot is executing its duties. To learn cognitive control we address the human inspired mechanisms that govern cognitive control and that have been widely studied in neuroscience, namely, shifting and inhibition. Shifting and inhibition are, in fact, executive cognitive functions responding selectively to stimuli, so as to switch from one activity to a more compelling one or to inhibit inappropriate urges and preserve focus on the current task. In an autonomous system these cognitive skills are crucial to assess a well-regulated reactive behavior, which is of particular relevance in critical circumstances. In this paper we illustrate a new method developed for learning shifting and inhibition, based on Gaussian Processes, and using examples provided by skilled operators. We finally show that the learning method is promising and can be seen as a new view for modeling robot reactive and proactive behaviors.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784650","Gaussian Processes;Robot Cognitive Control;Task Switching","Batteries;Logistics;Process control;Robots;Switches;Vectors","Gaussian processes;intelligent robots;mobile robots","Gaussian processes;autonomous system;cognitive control learning;cognitive skills;dynamic process learning;executive cognitive functions;human inspired mechanisms;inhibition process;mobile robots;neuroscience;robot cognitive control modeling;robot proactive behavior modeling;robot reactive behavior modeling;shifting process;skilled operators;task switching","","0","","23","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Applications of Class-Conditional Conformal Predictor in Multi-class Classification","F. Shi; C. S. Ong; C. Leckie","Victoria Res. Lab., Nat. ICT Australia, Brisbane, VIC, Australia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","235","239","In many prediction problems, it is beneficial to obtain confidence estimates for the classification output. We consider the problem of estimating confidence sets in multiclass classification of real life datasets. Building on the theory of conformal predictors, we derive a class-conditional conformal predictor. This allows us to calibrate the confidence estimates in a class specific fashion, resulting in a more precise control of the prediction error rate for each class. We show that the class-conditional conformal predictor is asymptotically valid, and demonstrate that it indeed provides better calibration and efficiency on benchmark digit recognition datasets. In addition, we apply the class-conditional conformal predictor to a biological dataset for predicting localizations of proteins in order to demonstrate its performance in bioinformatics applications.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784618","","Accuracy;Calibration;Error analysis;Iterative closest point algorithm;Proteins;Support vector machines;Training","bioinformatics;calibration;data handling;learning (artificial intelligence);pattern classification;proteins;support vector machines","benchmark digit recognition datasets;bioinformatics;biological dataset;calibration;class-conditional conformal predictor;multiclass classification;proteins;real life datasets","","0","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Kernel SODA: A Feature Reduction Technique Using Kernel Based Analysis","Y. Yu; T. Mckelvey; S. Y. Kung","Signals & Syst., Chalmers Univ. of Technol., Gothenburg, Sweden","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","72","78","A feature extraction technique called Successively Orthogonal Discriminant Analysis (SODA) has been recently proposed to overcome the limitation of Linear Discriminant Analysis (LDA), whose objective is to find a projection vector such that the projected values of data from both classes have maximum class separability. However, in LDA, only one such vector can be found due to the rank deficiency for binary classification problems. On the other hand, as a feature extraction technique, the proposed algorithm SODA attempts to obtain a transformation matrix instead of a vector. In this paper, the kernel version of SODA is presented in both intrinsic space and empirical space. To obtain the solution without sacrificing numerical efficiency, we propose a relaxed formulation and data selection for large scale computations. Simulations are conducted on 5 data sets from UCI database to verify and evaluated the new approach.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784590","Discriminant Analysis;Feature extraction;Kernel;SODA;big data","Covariance matrices;Feature extraction;Kernel;Principal component analysis;Training;Training data;Vectors","data analysis;feature extraction","LDA;UCI database;binary classification problems;feature extraction technique;feature reduction technique;kernel SODA;kernel based analysis;linear discriminant analysis;maximum class separability;orthogonal discriminant analysis;transformation matrix","","1","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Multiagent Approach to Ambulance Allocation Based on Social Welfare and Local Search","D. Shaft; R. Cohen","Cheriton Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","384","389","During a mass casualty incident, there will be many victims who need to be driven in an ambulance to a hospital. Reasoning about which patients to assign to which hospitals can be viewed as a multiagent resource allocation issue. The approach taken in this paper is to view this as a constraint satisfaction problem that should also be sensitive to a chosen social welfare metric. Our proposed algorithm employing local search is presented and then implemented in a series of simulations which experiment with different social welfare functions. The initial state used in the search is identified as a factor in the results. Moreover, a global view of the scenario helps to decide the appropriate strategies. We conclude with a discussion of next steps for multiagent resource allocation problems during mass casualty incidents. In short, we offer a more reasoned approach for ambulance allocation that may provide guidance for effective healthcare delivery.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786140","ambulance scheduling;intelligent health decision support systems;optimized utilization of resources;social welfare","Cost function;Educational institutions;Hospitals;Injuries;Resource management;Search problems","constraint satisfaction problems;emergency management;emergency services;hospitals;multi-agent systems;resource allocation;search problems","ambulance allocation;constraint satisfaction problem;healthcare delivery;hospital;local search;mass casualty incident;multiagent resource allocation problems;patients;social welfare functions;social welfare metric","","0","","10","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Evolving Dynamic Forecasting Model for Foreign Currency Exchange Rates Using Plastic Neural Networks","G. M. Khan; D. Nayab; S. A. Mahmud; H. Zafar","Electr. Eng. Dept., Univ. of Eng. & Technol. Peshawar, Peshawar, Pakistan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","15","20","This work explores developmental plasticity in neural networks for forecasting the trends in the daily foreign currency exchange rates. With this work we achieved an efficient artificial neural network (ANN) based dynamic prediction model that make use of the trends in the historical daily prices of the foreign currency to predict the future daily rates while modifying its structure with the trends. The plasticity in ANN is explored to achieve a prediction model that is computationally robust and efficient. The system performance analysis prove that the prediction model proposed is efficient, computationally cost effective and unique in terms of its least dependency on the amount of previous data required for the future prediction. The prediction model achieved accuracy as high as 98.852 percent, in predicting a single day's data from ten days data history, over a span of 1000 days (3 years). Further exploration demonstrated that when the problem domain for the network was changed to predict daily currency prices for multiple chunks of days a much better accuracy was achieved. This performance proved the robustness of the model proposed in this work for a modified problem domain.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786075","Cartesian Genetic Programming;Developmental Plasticity;Neuro Evolution;Plastic Neural Networks (ANNs);Prediction Model","Artificial neural networks;Computational modeling;Forecasting;Hidden Markov models;Predictive models;Solid modeling;Time series analysis","computational complexity;exchange rates;financial data processing;forecasting theory;neural nets;pricing","ANN plasticity;artificial neural network;computationally cost effective prediction model;daily foreign currency exchange rates;developmental plasticity;dynamic prediction model;evolving dynamic forecasting model;future daily rates prediction;historical daily prices trends;plastic neural networks;system performance analysis","","0","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Keynotes - Volume 1","","","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","xvii","xix","Provides an abstract for each of the keynote presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784578","","","","","","0","","","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Application of Neural Networks Based SANARX Model for Identification and Control Liquid Level Tank System","J. Belikov; S. Nõmm; E. Petlenkov; K. Vassiljeva","Inst. of Cybern., Tallinn Univ. of Technol., Tallinn, Estonia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","246","251","This paper is devoted to application of artificial Neural Network based Simplified Additive Autoregressive exogenous model for identification and control of a liquid level tank system consisting of three water reservoirs. A specific restricted connectivity structure of the neural network is trained on input-output data set to identify a nonlinear dynamic single-input single-output model of the liquid level tank system. Parameters of the identified neural network based model can be used to design a dynamic controller for the system. The designed neural network based controller is verified on mathematical model inMATLAB/Simulink environment and applied to the real-time control of the plant. The goal of the control algorithm is to track the desired level of liquid in the upper tank. Experimental result have shown a very good performance of the proposed technique. The designed nonlinear controller is capable of tracking the desired water level for all set points with high degree of accuracy, maximally fast and without significant overshoot.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784620","","Artificial neural networks;Biological neural networks;Liquids;Mathematical model;Output feedback","autoregressive processes;level control;mathematics computing;neurocontrollers;nonlinear control systems;reservoirs;tanks (containers)","MATLAB/Simulink environment;SANARX model;artificial neural network;dynamic controller;liquid level tank system control;liquid level tank system identification;mathematical model;neural network based controller;neural network based model;neural networks;nonlinear controller;nonlinear dynamic single-input single-output model;plant control;simplified additive autoregressive exogenous model;water reservoirs","","1","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Empirical Comparison of Spectral Learning Methods for Classification","A. Drake; D. Ventura","Comput. Sci. Dept., Brigham Young Univ., Provo, UT, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","9","14","In this paper, we explore the problem of how to learn spectral (e.g., Fourier) models for classification problems. Specifically, we consider two sub-problems of spectral learning: (1) how to select the basis functions that will be included in the model and (2) how to assign coefficients to the selected basis functions. Interestingly, empirical results suggest that the most commonly used approach does not perform as well in practice as other approaches, while a method for assigning coefficients based on finding an optimal linear combination of low-order basis functions usually outperforms other approaches.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784580","","Accuracy;Correlation;Equations;Heart;Single photon emission computed tomography;Training;Training data","Fourier transforms;learning (artificial intelligence);pattern classification","Fourier model;classification problem;low-order basis function;optimal linear combination;spectral learning method","","2","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Fuzzy Model Tree for Early Effort Estimation","M. Azzeh; A. B. Nassif","Dept. of Software Eng., Appl. Sci. Univ., Amman, Jordan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","117","121","Use Case Points (UCP) is a well-known method to estimate the project size, based on Use Case diagram, at early phases of software development. Although the Use Case diagram is widely accepted as a de-facto model for analyzing object oriented software requirements over the world, UCP method did not take sufficient amount of attention because, as yet, there is no consensus on how to produce software effort from UCP. This paper aims to study the potential of using Fuzzy Model Tree to derive effort estimates based on UCP size measure using a dataset collected for that purpose. The proposed approach has been validated against Tree boost model, Multiple Linear Regression and classical effort estimation based on the UCP model. The obtained results are promising and show better performance than those obtained by classical UCP, Multiple Linear Regression and slightly better than those obtained by Tree boost model.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786092","Effort Estimation;Fuzzy Modelling;Model tree;Use Case Points","Estimation;Mathematical model;Object oriented modeling;Predictive models;Regression tree analysis;Software;Training","fuzzy set theory;object-oriented methods;regression analysis;software engineering;trees (mathematics)","UCP method;early effort estimation;fuzzy model tree;multiple linear regression;object oriented software requirements;project size estimation;software development;tree boost model;use case diagram;use case points method","","1","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Approach to Control of Hybrid Renewable Power System on the Basis of AE-Method Using Genetic Algorithm","V. Ten; B. Matkarimov; N. Isembergenov","Nazarbayev Univ., Astana, Kazakhstan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","199","202","A hybrid renewable power system test site located at Nazarbayev University is described and a problem statement is formulated. Uncertain disturbances from a consumer grid side are considered and a control approach based on the method of additional equilibria is proposed. For automatic adjustment the controller and control plant parameters, a genetic algorithm is proposed. Results from a MATLAB simulation of the designed control system are presented.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786108","Additional Equilibria;Control Systems;Genetic Algorithm;Hybrid Renewable Energy Sources","Control systems;Genetic algorithms;Hybrid power systems;MATLAB;Power system stability;Voltage control;Wind turbines","genetic algorithms;power grids;power system control;power system faults","AE-method;MATLAB;Nazarbayev University;additional equilibria;automatic adjustment;consumer grid side disturbance;control plant parameters;genetic algorithm;hybrid renewable power system control","","1","","8","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Variable-Length Protein Sequence Motif Extraction Using Hierarchically-Clustered Hidden Markov Models","C. Hudson; B. Chen","Dept. of Comput. Sci., Univ. of Central Arkansas, Conway, AR, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","173","178","Primary sequence motif extraction from protein amino sequences is a field of growing importance in bioinformatics due to its relevance to both sequential and structural analysis. Many approaches for motif extraction include two limitations: a reliance on discovering an existing, known protein homologue to perform motif extraction or structural analysis, and an assumed motif length. This work would propose the Hierarchically Clustered-Hidden Markov Model approach, which represents the behavior and structure of proteins in terms of a Hidden Markov Model chain and hierarchically clusters each chain by minimizing distance between two given chain's structure and behavior. It is well known that HMM can be utilized for clustering purpose, however, methods for clustering on Hidden Markov Models themselves are rarely studied. In this paper, we proposed a hierarchical clustering based algorithm for HMMs to discover protein sequence motifs that transcend family boundaries with no assumption on the length of the motif. This paper carefully examines the effectiveness of this approach for motif extraction on 2, 593 proteins that share no more than 25% sequence identity. Many interesting motifs are generated. Three example motifs generated by the HC-HMM approach are analyzed and visualized with their tertiary structure.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784607","Bioinformatics;Hidden Markov Model;Hierarchical Clustering;Sequential Motif","Amino acids;Data mining;Data models;Databases;Hidden Markov models;Mathematical model;Proteins","bioinformatics;hidden Markov models;proteins","bioinformatics;distance minimization;hierarchically-clustered hidden Markov models;primary sequence motif extraction;protein amino sequences;protein homologue;protein sequence motifs discovery;sequential analysis;structural analysis;tertiary structure;variable-length protein sequence motif extraction","","0","","16","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Computed Data-Geometry Based Supervised and Semi-supervised Learning in High Dimensional Data","E. P. Chou; F. Hsieh; J. Capitanio","Dept. of Stat., Univ. of California, Davis, Davis, CA, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","277","282","In most high dimensional settings, constructing supervised or semi-supervised learning rules has been facing various critically difficult issues, such as no visualizing tools for empirical guidance, no valid distance measures, and no suitable variable selection methods for proper discrimination among data nodes. We attempt to alleviate all of these difficulties by computing data-geometry via a recently developed computational algorithm called Data Cloud geometry (DCG). The computed geometry is represented by a hierarchy of clusters providing a base for developing a divide-and-conquer version of a learning approach. We demonstrate the advantages of taking posteriori geometric information into learning rules construction by evaluating its performance with many illustrated examples and several real data sets compared to the performance resulting from the majority of commonly used techniques.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784626","Data Cloud Geometry;High Dimensional Data;Semi-supervised learning","Clustering algorithms;Educational institutions;Geometry;Logistics;Semisupervised learning;Supervised learning;Support vector machines","computational geometry;divide and conquer methods;learning (artificial intelligence)","computational algorithm;computed data-geometry;data cloud geometry;divide-and-conquer version;high dimensional data;posteriori geometric information;semisupervised learning;supervised learning","","0","","13","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"SksOpen: Efficient Indexing, Querying, and Visualization of Geo-spatial Big Data","Y. Lu; M. Zhang; S. Witherspoon; Y. Yesha; Y. Yesha; N. Rishe","Sch. of Comput. & Inf. Sci., Florida Int. Univ., Miami, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","495","500","With the fast growing use of web-based map services, the performance of indexing and querying of location-based data is becoming a critical quality of service aspect. Spatial indexing is typically time-consuming and is not available to end-users. To address this challenge, we have developed and open-sourced an Online Indexing and Querying System for Big Geospatial Data, sksOpen. Integrated with the TerraFly Geospatial database [1], TerraFly sksOpen is an efficient indexing and query engine for processing Top-k Spatial Boolean Queries. Further, we provide ergonomic visualization of query results on interactive maps to facilitate the user's data analysis.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786159","data visualization;spatial databases;spatial index","Algorithm design and analysis;Data visualization;Geospatial analysis;Indexing;Loading;Spatial databases","Internet;data visualisation;database indexing;geographic information systems;query processing;visual databases","TerraFly Geospatial database;TerraFly sksOpen;Web-based map services;critical quality of service;geospatial big data indexing;geospatial big data querying;geospatial big data visualization;location-based data;top-k spatial Boolean queries","","1","","38","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic Binding Point and Surface Helix Angle Measurement in Historic Weft-Faced Compound Weave Figured Silks","N. Patel; M. Flynn; A. Semenov; J. Galliker","Dept. of Comput. Sci. & Eng., Oakland Univ., Rochester, MI, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","529","534","Structural analysis of textiles using image processing has been explored by many researchers. Topics have ranged from quality control for modern textiles to investigation of historical weaving processes. Our research concerns analysis of ancient weft-faced compound weave figured silks dated between AD 600-1200. The complex draw looms used to weave these silks included a pattern harness to memorize pattern selection sequences. The capability to store work for later use is important in both historical and technical terms. Specifically we are interested in devising nondestructive characterization methods to measure attributes including binding point distance and yarn helix angle. We describe some of the challenges involved in selecting computer vision algorithms appropriate for automated measurement processes.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786165","Ciratefi;Hough Transform;Template Matching;Textile Image Analysis;Textile Image Processing","Correlation;Fabrics;Transforms;Weaving;Yarn","angular measurement;computer vision;image sequences;production engineering computing;quality control;textiles;weaving;yarn","automatic binding point measurement;computer vision algorithms;image processing;nondestructive characterization methods;pattern harness;pattern selection sequences;quality control;surface helix angle measurement;textile structural analysis;weaving processes;weft-faced compound weave figured silks;yarn helix angle","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Worst-Case Execution Time Test Generation for Augmenting Path Maximum Flow Algorithms Using Genetic Algorithms","V. Arkhipov; M. Buzdalov; A. Shalyto","St. Petersburg Nat. Res. Univ. of Inf. Technol., Mech. & Opt., St. Petersburg, Russia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","108","111","Worst-case execution time tests can be tricky to create for various computer science algorithms. To reduce the amount of human effort, authors suggest using search-based optimization techniques, such as genetic algorithms. This paper addresses difficult test generation for several maximum flow algorithms from the augmenting path family. The presented results show that the genetic approach is reasonably good for the well-studied algorithms and superior for the capacity scaling algorithms. Moreover, tests which are generated against one algorithm seem to be hard for other algorithms of this family.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786090","genetic algorithms;maximum flow;performance;test generation;worst-case execution time","Algorithm design and analysis;Generators;Genetic algorithms;Genetics;Optimization;Software algorithms;Wheels","computer science;genetic algorithms;program testing;search problems;software engineering","augmenting path maximum flow algorithms;computer science algorithms;genetic algorithms;search based optimization techniques;worst case execution time test generation","","2","","10","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Permeability Parametrization Using Higher Order Singular Value Decomposition (HOSVD)","S. Afra; E. Gildin","Dept. of Electr. Eng., Texas A&M Univ., College Station, TX, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","188","193","Model reduction is of highly interest in many science and engineering fields where the order of original system is such high that makes it difficult to work with. In fact, model reduction or parametrization defined as reducing the dimensionality of original model to a lower one to make a costly efficient model. In addition, in all history matching problem, in order to reduce the ill-posed ness of the problem, it is necessary to de-correlate the parameters. Proper orthogonal decomposition (POD) as an optimal transformation is widely used in parameterization. To obtain the bases for POD, it is necessary to vectorize the original replicates. Therefore, the higher order statistical information is lost due to slicing the replicates. Another approach that deals with the replicates as they are, is high order singular value decomposition (HOSVD). In the present work permeability maps dimension is reduced using HOSVD image compression method. Unknown permeability maps are also estimated using HOSVD and results of both parts compared to those of SVD.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786106","High Order SVD;Parameter estimation;Parameterization;Permeability","Computational modeling;History;Mathematical model;Permeability;Principal component analysis;Reservoirs;Tensile stress","data compression;image coding;permeability;reduced order systems;singular value decomposition;statistical analysis","HOSVD image compression method;higher order singular value decomposition;higher order statistical information;model dimensionality;model reduction;permeability map dimensions;permeability parametrization;proper orthogonal decomposition","","4","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Movie Recommendation Using Unrated Data","D. Nie; L. Hong; T. Zhu","Inst. of Psychol., Univ. of Chinese Acad. of Sci., Beijing, China","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","344","347","Model based movie recommender systems have been thoroughly investigated in the past few years, and they rely on rating data. In this paper, we take into account unrateddata of genre information to improve the performance of movie recommendation. We propose a novel method to measure users' preference on movie genres, and use Pearson Correlation Coefficient(PCC) to compute the user similarity. A matrix factorization framework is introduced for genre preference regularization. Experimental results on Movie Lens data set demonstrate that the approach performs well. Our method can also be used to increase the genre diversity of recommendations to some extent.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784640","diversity;genre preference regularization;matrix factorization","Accuracy;Collaboration;Frequency measurement;Ground penetrating radar;Matrix decomposition;Motion pictures;Recommender systems","entertainment;matrix decomposition;recommender systems","MovieLens data set;PCC;Pearson correlation coefficient;genre information;genre preference regularization;matrix factorization framework;model-based movie recommender systems;movie recommendation performance improvement;rating data;unrated data;user preference measurement;user similarity","","1","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Multimodal Approach to Song-Level Style Identification in Pop/Rock Using Similarity Metrics","C. H. Chuan","Sch. of Comput., Univ. of North Florida, Jacksonville, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","321","324","This paper presents a multimodal approach to style identification in pop/rock music. Considering the intuitive feelings of similarity from the listener's perspective, this study focuses on features that are computed using similarity metrics for melodies, harmonies, and audio signals for style identification. Support vector machine is used as a binary classifier to determine if two songs are created by the same artist given their similarity distances in the three aspects. Experiments are conducted using songs of four well-known pop/rock bands from 6 albums. The preliminary result shows that the approach achieves the best result in correct rate of 85% using only seven similarity metrics.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786128","Gaussian mixture models;melodic contour;music similarity;n-grams;style","Feature extraction;Measurement;Music;Music information retrieval;Rocks;Support vector machines","Gaussian processes;audio signals;music;pattern classification;support vector machines","Gaussian mixture models;audio signals;binary classifier;harmonies;intuitive similarity feelings;melodies;multimodal approach;pop music;rock music;similarity distances;similarity metrics;song-level style identification;support vector machine","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Protein Local Tertiary Structure Prediction Using the Adaptively-Branching FGK-DF Model","B. Chen; C. Hudson; A. Crawford; M. Kim","Dept. of Comput. Sci., Univ. of Central Arkansas, Conway, AR, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","378","381","For the past twenty years, protein tertiary structure research has been given much attention. Unfortunately, each approach has significant shortcomings, such as necessary time, capital, or restrictions imposed by the method, limiting the resolution or novelty of produced tertiary structures. This work proposes the Adaptively-Branching Fuzzy Greedy K-means-Decision Forest (FGK-DF) model, which utilizes conserved sequential and structural motifs that transcend protein family boundaries, to predict the local tertiary structure of proteins with unknown structures.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784647","Adaptive Branch;Decision Forest;FGK Model","Adaptation models;Decision trees;Hidden Markov models;Predictive models;Proteins;Training;Vegetation","biology computing;fuzzy set theory;greedy algorithms;molecular biophysics;proteins","adaptively-branching FGK-DF model;adaptively-branching fuzzy greedy k-means-decision forest model;conserved sequential motif;produced tertiary structures;protein family boundary;protein local tertiary structure prediction;protein tertiary structure research;structural motif","","0","","13","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Online Processing of Social Media Data for Emergency Management","D. Pohl; A. Bouchachia; H. Hellwagner","Inst. of Inf. Technol., Alpen-Adria-Univ. Klagenfurt, Klagenfurt, Austria","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","408","413","Social media offers an opportunity for emergency management to identify issues that need immediate reaction. To support the effective use of social media, an analysis approach is needed to identify crisis-related hotspots. We consider in this investigation the analysis of social media (i.e., Twitter, Flickr and YouTube) to support emergency management by identifying sub-events. Sub-events are significant hotspots that are of importance for emergency management tasks. Aiming at sub-event detection, recognition and tracking, the data is processed online in real-time. We introduce an incremental feature selection mechanism to identify meaningful terms and use an online clustering algorithm to uncover sub-events on-the-fly. Initial experiments are based on tweets enriched with Flickr and YouTube data collected during Hurricane Sandy. They show the potential of the proposed approach to monitor sub-events for real-world emergency situations.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784653","Crisis Management;Online Clustering;Sub-Event Detection","Clustering algorithms;Feature extraction;Hurricanes;Internet;Media;Twitter;YouTube","emergency management;feature selection;pattern clustering;social networking (online)","Flickr;Hurricane Sandy;Twitter;YouTube;crisis-related hotspot identification;data processing;emergency management;incremental feature selection mechanism;online clustering algorithm;social media data;subevent identification;tweets","","0","","24","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Ordered Segment for Classification of Big Data","A. Fatholahzadeh","UMI GT, Supelec, Metz, France","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","268","272","This paper presents a new, simple, and efficient data structure, namely, the ordered segment (OS): a mono dimensional string array that we have been using in our classification of big data. The essential idea in construction of OS is to make use of the redundancies that abound user-data. OS enables us to performs efficient retrieval, insertions and deletions of data. The theoretical and experimental observations show that the method presented is more practical than existing ones considering the use of dynamic string sets for the classifications of huge user-files.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784624","Big Data;Information retrieval;Learning from text and multimedia","Automata;Data structures;Decision trees;Learning automata;Syntactics;Time complexity;Transducers","Big Data;data structures;pattern classification","OS;big data classification;data deletion;data insertion;data retrieval;data structure;mono dimensional string array;ordered segment","","0","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Fast Multi-component Latent Variable Regression Framework for Quantitative Analysis of Surface-Enhanced Raman Spectra","S. Li; J. O. Nyagilo; D. P. Dave; B. Zhang; X. Wu; J. Gao","Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","147","152","Surface-enhanced Raman spectroscopy (SERS) has been a routine method for the quantitative analysis of Nano-tags or biomarkers. The multivariate calibration (MC) model is normally used to reduce the bias from the inherent instability of Raman signals. To solve the more variables than observations, ill-conditioned problem within the MC model, latent variable regression (LVR) methods are usually used. In order to decide the optimized number of latent variables (LVs) used in the model, cross-validation methods are commonly used to test every possible number, and the one gives the minimum estimated error is returned as the optimized number. In this paper we present a new multi-component LVR together with a cross-validation framework to accelerate the time-consuming processes of optimizing number of LVs. It reduces the growth rate of the algorithms from O(k^2) to O(k), where k is the possible numbers of LVs. Experimental results show the estimated results of the two frameworks are equivalent and the running time of our new framework is evidently reduced.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784602","Quantitative analysis;continuum regression;fast latent variable regression;partial least squares (PLS);surface-enhanced Raman spectra (SERS)","Algorithm design and analysis;Equations;Linear programming;Mathematical model;Raman scattering;Testing;Vectors","Raman spectroscopy;calibration;regression analysis;surface enhanced Raman scattering","Raman signals;biomarkers;cross-validation methods;fast multicomponent latent variable regression framework;growth rate;ill-conditioned problem;inherent instability;latent variable regression methods;minimum estimated error;multivariate calibration model;nanotags;optimized number;quantitative analysis;routine method;running time;surface-enhanced Raman spectra;surface-enhanced Raman spectroscopy;time-consuming processes","","0","","15","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Two-Level Clustering towards Unsupervised Discovery of Acoustic Classes","C. G. Pons; X. Anguera; X. Binefa","Dept. of Inf. & Commun. Technol., Univ. Pompeu Fabra, Barcelona, Spain","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","299","302","In this paper we focus on unsupervised discovering of acoustic classes suitable for use in pattern recognition applications. Our approach is based on a two-level clustering of an initial acoustic segmentation of the audio data in order to allow for discovery and correct modeling of complex acoustic classes. Initially, in a first-level, the acoustic space is densely clustered in order to provide a first layer of acoustic variance reduction. In a second-level clustering we use the acoustic segmentation to infer a smaller number of super-clusters taking advantage of the intra-segment relationships between the first-level clusters. In this paper we compare three possible clustering methods to obtain super-clusters as sub-sets or linear combinations of first-level clusters. Results indicate that the proposed two-level approach improves the balance between Purity and inverse Purity evaluation measures while significantly improving the stability of the transcriptions obtained when using the resulting models to transcribe the same acoustic events in different spoken utterances.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786124","clustering;query by example;zero resources","Acoustic measurements;Acoustics;Clustering algorithms;Data models;Hidden Markov models;Probabilistic logic;Speech","learning (artificial intelligence);pattern clustering;set theory","acoustic classes;audio data acoustic segmentation;first-level clusters;intrasegment relationships;linear combinations;pattern recognition;purity and inverse purity evaluation;subsets;transcriptions stability;two-level clustering;unsupervised discovery","","0","","13","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Epidemiological Data Analysis in TerraFly Geo-spatial Cloud","H. Wang; Y. Lu; Y. Guang; E. Edrosa; M. Zhang; R. Camarca; Y. Yesha; T. Lucic; N. Rishe","Sch. of Comput. & Inf. Sci., Florida Int. Univ., Miami, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","485","490","GIS systems and online services are growing at a very fast pace, however, there are few online services for the analysis of geospatial epidemiology and their functionality is limited. We present a geospatial epidemiology analysis system on the TerraFly Geo-spatial Cloud platform. The system provides comprehensive spatial analysis methods and visualization. In this system, the user is not required to program in order to employ the functionality. All the datasets are stored in the Geo-spatial Cloud. This system is accessible at http://terrafly.fiu.edu/GeoCloud/. The system API algorithms adapted to geospatial epidemiology. The application utilizes the GeoCloud distributed storage system for the Big Data to be analyzed, it utilizes an interactive mapping API to display results.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786157","Big Data;GIS;geospatial epidemiology;visualization","Algorithm design and analysis;Cancer;Data visualization;Diseases;Geospatial analysis;Lungs;Spatial databases","Big Data;application program interfaces;cloud computing;data analysis;data visualisation;epidemics;geographic information systems;medical computing","Big Data analysis;GIS;GeoCloud distributed storage system;TerraFly geo-spatial cloud platform;epidemiological data analysis;geospatial epidemiology analysis system;interactive mapping API;spatial analysis methods;spatial visualization;system API algorithms","","1","","22","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Identifying Effective Test Cases through K-Means Clustering for Enhancing Regression Testing","Y. Pang; X. Xue; A. S. Namin","Dept. of Math. & Stat., Texas Tech Univ., Lubbock, TX, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","78","83","Testing is the most time consuming and expensive process in the software development life cycle. In order to reduce the cost of regression testing, we propose a test case classification methodology based on k-means clustering with the purpose of classifying test cases into two groups of effective and non-effective test cases. The clustering strategy is based on Hamming distances measured over the differences between coverage information obtained for current and the previous releases of the program under test. Our empirical study shows that the clustering-based test case classification can identify effective test cases with high recall ratio and considerable accuracy percentage. The paper also investigates and compares the performance of the proposed clustering-based approach with various factors including coverage criteria and the weights factor used in measuring distances.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786085","k-means clustering;regression testing;test case classification","Accuracy;Classification algorithms;Clustering algorithms;Hamming distance;Measurement;Software;Testing","pattern classification;product life cycle management;program testing;regression analysis;statistical testing","Hamming distances;clustering-based test case classification methodology;effective test case identification;k-means clustering strategy;regression testing cost reduction;software development life cycle;software testing","","3","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Very Short Term Load Forecasting Using Cartesian Genetic Programming Evolved Recurrent Neural Networks (CGPRNN)","G. M. Khan; F. Zafari; S. A. Mahmud","Dept. of Electr. Eng., Univ. of Eng. & Technol., Peshawar, Pakistan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","152","155","Forecasting the electrical load requirements is an important research objective for maintaining a balance between the demand and generation of electricity. This paper utilizes a neuro-evolutionary technique known as Cartesian Genetic Programming evolved Recurrent Neural Network (CGPRNN) to develop a load forecasting model for very short term of half an hour. The network is trained using historical data of one month on half hourly basis to predict the next half hour load based on the 12 and 24 hours data history. The results demonstrate that CGPRNN is superior to other networks in very short term load forecasting in terms of its accuracy achieving 99.57 percent. The model was developed and evaluated on the data collected from the UK Grid station.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786098","Cartesian Genetic Program (CGP);Cartesian Genetic Programming evolved Recurrent Neural Network (CGPRNN);Very Short Term Load forecast (VSTLF)","Forecasting;Genetic programming;Load forecasting;Load modeling;Predictive models;Recurrent neural networks","demand side management;genetic algorithms;load forecasting;power engineering computing;recurrent neural nets","CGPRNN;UK Grid station;cartesian genetic programming evolved recurrent neural networks;electricity demand;electricity generation;load forecasting model;neuroevolutionary technique","","2","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Recommending Messages to Users in Social Networks: A Cross-Site Study","R. Cohen; N. Sardana; K. Rahim; D. Y. Lam; M. Li; O. Maccarthy; E. Woo; J. Zhang; G. Guo","Cheriton Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","445","450","In this paper we produce an algorithm for presenting messages to users in social networks that integrates reasoning about the message, the author, the recipient and the social network. Our proposed model was derived on the basis of immersion within three different existing social networking environments, that of Courser a, Reddit, and medical self-help groups such as PatientsLikeMe. We first present three models, each of which is designed to perform well within the context of one specific social network. From here we derive a generalized model which can be effective regardless of social network context. We conclude with a discussion of possible directions for future research, with an emphasis on promoting the use of trust modeling and user modeling, in a view to exploring additional networks and include as well a comparison to competing models within the artificial intelligence literature. Our aim is to offer insights into coping with the massive amount of information that currently resides within our social networks.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786151","Recommending Messages;Social Networks;Trust Modeling","Communities;Medical services;Message systems;Proposals;Reliability;Social network services;Training","inference mechanisms;recommender systems;social networking (online);trusted computing","Coursera;PatientsLikeMe;Reddit;artificial intelligence;generalized model;medical self-help groups;message recommendation;reasoning;social network users;social networking environments;trust modeling;user modeling","","0","","10","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Classifier Ensembling Approach for Imbalanced Social Link Prediction","J. Hurtado; N. Taweewitchakreeya; X. Kong; X. Zhu","Dept. of Comput. & Electr. Eng. & Comput. Sci., Florida Atlantic Univ., Boca Raton, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","436","439","Supervised learning is a commonly used tool for link prediction in social networks, where data imbalance is a major challenge because only a small portion of nodes may have social connections. In this paper, we propose to use a k-nearest neighbor sampling and a random sampling combined approach to address data imbalance issue for social link prediction. In our solution, we use two sampling approaches to generate multiple copies of the network data, and then use a number of similarity link prediction measures to generate independent variable (features) as training data. For each copy of the sampled data, we train a classifier and use a classifier ensemble for final link prediction. Experimental results on a co-authorship network validate the performance of the proposed design.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784658","classification;co-authorship network;data imbalance;link prediction","Accuracy;Couplings;Data models;Decision trees;Logistics;Prediction algorithms;Training data","learning (artificial intelligence);pattern classification;sampling methods;social networking (online)","classifier ensembling approach;coauthorship network;data imbalance;final link prediction;imbalanced social link prediction;random sampling combined approach;sampling approaches;social connections;social networks;supervised learning","","1","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Weak Segmentations and Ensemble Learning to Predict Semantic Ratings of Lung Nodules","E. Smith; P. Stein; J. Furst; D. S. Raicu","Dept. of Inf. & Comput. Sci., Univ. of Hawaii at Manoa, Honolulu, HI, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","519","524","Computer-aided diagnosis (CAD) can be used as ""second readers"" in the imaging diagnostic process. Typically to create a CAD system, the region of interest (ROI) has to be first detected and then delineated. This can be done either manually or automatically. Given that manually delineating ROIs is a time consuming and costly process, we propose a CAD system based on multiple computer-derived weak segmentations (WSCAD) and show that its diagnosis performance is at least as good as the predictions developed using manual radiologist segmentations. The proposed CAD system extracts a set of image features from the weak segmentations and uses them in an ensemble of classification algorithms to predict semantic ratings such as malignancy. These automated results are compared against a reference truth based on ratings and segmentations provided by radiologists to determine if it is necessary to obtain manual radiologist segmentations in order to develop a CAD. By developing a pair of CADs using the Lung Image Database Consortium (LIDC) data, we show that WSCADs are at least as accurate in predicting semantic ratings as CADs based on radiologist segmentation.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786163","classification;computer aided diagnosis;crowdsourcing;ensemble learning;lung cancer;segmentation","Accuracy;Cancer;Design automation;Feature extraction;Image segmentation;Lungs;Semantics","feature extraction;image classification;image segmentation;learning (artificial intelligence);lung;medical image processing;object detection;radiology","LIDC;Lung Image Database Consortium;ROI detection;WSCAD;computer aided diagnosis;diagnosis performance;ensemble learning;image classification algorithm;image feature extraction;imaging diagnostic process;lung nodules;manual ROI delineation;manual radiologist segmentation;multiple computer-derived weak segmentation;region of interest;semantic ratings prediction","","1","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Incorporating Game-Theoretic Rough Sets in Web-Based Medical Decision Support Systems","J. Yao; N. Azam","Dept. of Comput. Sci., Univ. of Regina, Regina, SK, Canada","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","335","338","Web-based support systems (WSS) assist human activities with the modern Web technology. An important branch of WSS is Web-based decision support systems that provide intelligent support for decision making tasks. We focus on decision making in Web-based medical decision support systems (WMDSS) that can provide support for making diagnosis and treatment decisions. The use of game-theoretic rough set (GTRS) component in WMDSS is explored and investigated for this purpose. The GTRS is a recent development in rough sets that takes advantages from data analysis capabilities of rough sets complimented with decision analysis abilities of game theory. The GTRS may be used to obtain rough sets based three-way or ternary decisions by determining a pair of threshold values. Demonstrative example suggests that the GTRS may be considered as an alternative decision making model and component in building WMDSS for providing decision support.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786131","Game-thoeretic rough sets;decision support;probabilistic rough sets;rough sets;web-based support systems","Databases;Decision making;Decision support systems;Games;Medical diagnostic imaging;Probabilistic logic;Rough sets","Internet;data analysis;decision support systems;game theory;medical computing;rough set theory","GTRS component;WMDSS;WSS;Web technology;Web-based medical decision support systems;data analysis capabilities;decision analysis abilities;decision making model;diagnosis decision making;game-theoretic rough sets;intelligent support;treatment decision making","","2","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Advanced Pattern Recognition Approach for Fault Diagnosis of Wind Turbines","H. Toubakh; M. Sayed-Mouchaweh; E. Duviella","Inst. Mines-Telecom, Mines-Douai, France","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","368","373","The production of maximum amount of electrical power from wind requires the improvement of wind turbine reliability. The life duration and the good functioning of the wind turbine depend heavily on the reliability of its blades. Thus, a critical task is to detect and isolate faults, as fast as possible, and regain optimal functioning in the shortest time. In this paper, a pattern recognition approach is proposed for fault diagnosis of a wind turbine, in particular the pitch system composed of actuators and sensors. To achieve this task, feature and decision spaces have been defined. The aim of the pitch system is to adjust the pitch angle of a blade in order to optimize the generated electrical power according to the wind speed. Thus, a fault in the pitch system can reduce the wind turbine performance. Pitch system fault diagnosis is a challenging task because the pitch system feedback compensates the effect of the fault in the pitch actuator. In addition, the observation of the pitch actuator performance is very hard due to the strong variability of the wind speed. A wind turbine simulator is used to validate the performance of the proposed approach.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786137","fault diagnosis;pattern recognition;wind turbines","Actuators;Benchmark testing;Blades;Fault diagnosis;Feature extraction;Sensors;Wind turbines","blades;electric actuators;electric sensing devices;fault diagnosis;pattern recognition;power system reliability;wind turbines","blades;fault detection;fault isolation;pattern recognition approach;pitch actuator;pitch system fault diagnosis;sensors;wind turbine reliability;wind turbine simulator","","5","","13","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Class Diagram Retrieval Using Genetic Algorithm","H. O. Salami; M. Ahmed","Inf. & Comput. Sci. Dept., King Fahd Univ. of Pet. & Miner., Dhahran, Saudi Arabia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","96","101","Reuse of software results in many gains such as reduced development time and overall cost, especially when it takes place in the early stages of software development. Retrieval is a crucial activity during software reuse. This work focuses on the retrieval of UML class diagrams using Genetic Algorithm (GA). It builds on our earlier work by describing a GA for determining class diagram similarity based on classifier features. Experimental results show that our newly proposed technique results in the retrieval of the most similar class diagrams from a repository.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786088","UML class diagram;genetic algorithm;software retrieval;software reuse","Biological cells;Genetic algorithms;Sociology;Software;Statistics;Support vector machine classification;Unified modeling language","Unified Modeling Language;genetic algorithms;pattern classification;software reusability","GA;UML class diagram retrieval;class diagram similarity;classifier features;genetic algorithm;overall cost reduction;repository;software development time reduction;software reuse;unified modeling language","","2","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"DroidMLN: A Markov Logic Network Approach to Detect Android Malware","M. Rahman","Dept. of Electr. Eng. & Comput. Sci., Syracuse Univ., Syracuse, NY, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","166","169","Traditional data mining mechanisms with their robustly defined classification techniques have certain limitations to express to what extent the class labels of the test data hold. This problem leads to the fact that a false positive or false negative data point has no quantitative value to express to what degree it is false/true. This situation becomes much severe when it comes to the problem of Malware detection for a growing business market like Android applications. To address the need for a more fine grained model to measure the fitness of the classification we used Markov Logic Network for the first time to detect Android Malwares.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786101","API;Android;Malware;Markov Logic Network","Accuracy;Androids;Humanoid robots;Malware;Markov random fields;Training","Android (operating system);invasive software;pattern classification;probabilistic logic","Android malware detection;DroidMLN;Markov logic network;classification","","1","","8","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Selective Sampling Designs to Improve the Performance of Classification Methods","S. Ghorbani; M. C. Desmarais","Comput. & Software Eng. Dept., Polytech., Montreal, QC, Canada","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","178","181","Selective Sampling design refers to the situation where a study has a fixed number of observations but can decide to allocate them differently among the variables during the data gathering phase, such that some variables will have a greater ratio of missing values than others. In particular, we can decide to allocate more, or less missing values to uncertain variables: those for which the relative frequency is closer to 50% (higher uncertainty), or further from 50% (lower certainty). The main objective of the study is to investigate how a Selective Sampling process helps improve the performance of classification methods. This study specifically asks: ""Can Selective Sampling affect the performance of the classification methods?"" We focus on the three different classification models of Naïve Bayes, Logistic Regression and Tree Augmented Naive Bayes (TAN) for binary datasets. Three different schemes of sampling are defined: 1-Uniform (random samples) as a baseline, 2-Most Uncertain (higher sampling rate of uncertain items) and 3-Least Uncertain (lower sampling rate of uncertain items). We investigate the impacts of these different schemes on the performance of the three models on 11 different datasets. The results from 100 fold cross-validation show that Selective Sampling in all of the datasets improves the prediction performance of the TAN model and, in more than half of the datasets (54.6%), brings a higher prediction performance to Naïve Bayes and Logistic Regression classifiers.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786104","Classification;Planned Missing Data Design;Selective Sampling","Computational modeling;Entropy;Logistics;Niobium;Predictive models;Testing;Training","Bayes methods;data handling;pattern classification;performance evaluation;regression analysis;sampling methods","Naïve Bayes classifier;TAN model;binary datasets;classification method performance improvement;data gathering phase;least uncertain scheme;logistic regression classifier;most uncertain scheme;random samples;relative frequency;sampling rate;selective sampling designs;tree augmented Naive Bayes classifier;uncertain items;uncertain variables;uniform scheme","","0","","8","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Discriminative Apprenticeship Learning with Both Preference and Non-preference Behavior","D. Luo; Y. Wang; X. Wu","Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","315","320","Considering that expert's demonstrations are usually sub optimal and failed demonstrations often have some useful guidance, in this paper, a Discriminative Apprenticeship Learning algorithm is proposed, where the apprentice is taught with the join of failed attempts to acquire the ability that could discriminate the preference and non-preference cases so that to actively take a corresponding action. Since robot usually encounters changing environments, generalization ability is taken into account in the algorithm through which the reward function is recovered under the evaluation of generalization error. The problem of the representation error is also analyzed and involved in the algorithm. To ensure performance of the algorithm, theoretical guarantee is presented. Experiments on a simple car-driving robot and the comparison with a variety of inverse reinforcement learning methods are performed, which illustrate the proposed method is an effective and promising alternative.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784634","Discriminative apprenticeship learning;Inverse reinforcement learning;Preference and non-preference","Indium phosphide;Learning (artificial intelligence);Robots;Training;Training data;Trajectory;Vectors","learning (artificial intelligence);robots","car-driving robot;changing environments;discriminative apprenticeship learning;generalization ability;generalization error;nonpreference behavior;preference behavior;reinforcement learning methods;reward function","","0","","11","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Adversarial Spam Detection Using the Randomized Hough Transform-Support Vector Machine","D. Debarr; H. Sun; H. Wechsler","Comput. Sci. Dept., George Mason Univ., Fairfax, VA, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","299","304","In public e-mail systems, it is possible to solicit annotation help from users to train spam detection models. For example, we can occasionally ask a selected user to annotate whether a randomly selected message destined for their inbox is spam or not spam. Unfortunately, it is also possible that the user being solicited is an internal threat and has malicious intent. Similar to an adversary, such a user may want to introduce noise: to confuse the spam classifier into believing a spam message is not spam (to ensure delivery of similar messages), or to confuse the spam classifier into believing a non-spam message is spam (to prevent delivery of similar messages). Inspired by the Randomized Hough Transform (RHT), a set of Support Vector Machines (SVMs) is trained from randomly chosen data subsets to vote to identify training examples that have been mislabeled. The labels for messages which on the average appear on the wrong side of the decision boundary are flipped and a final SVM model is trained using the modified labels. Two data sets are used for evaluating the proposed RHT-SVM method: the TREC 2007 Spam Track data and the CEAS 2008 Spam data. To preserve the time ordered nature of the data stream, for each of the data sets, the first 10% of the messages are used for training, and the remaining 90% of the messages are used for evaluation. Separate adversarial experiments are conducted for flipping spam labels and non-spam labels. For 10 iterations, labels are flipped for a randomly selected subset of 5% of the training data and the final RHT-SVM is evaluated on the test set. Performance of the RHT-SVM is compared to the performance of the state of the art Reject On Negative Impact (RONI) algorithm. RHT-SVM shows an average 9.3% increase in the F measure compared to RONI (99.0% versus 90.6%), as well as significant improvements in other evaluation metrics. The flip sensitivity for RHT-SVM is 95.9% and the flip specificity is 99.0%. It also takes over 90% less time- to complete the RHT-SVM experiments compared to the RONI experiments (20 minutes per experiment instead of 360 minutes).","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784631","Adversarial Label Noise;Adversarial Learning;Spam Detection;Support Vector Machines","Kernel;Noise;Support vector machines;Training;Training data;Transforms;Unsolicited electronic mail","Hough transforms;pattern classification;security of data;support vector machines;unsolicited e-mail","CEAS 2008 spam data;RHT-SVM;RONI;TREC 2007 spam track data;adversarial spam detection;internal threat;malicious intent;nonspam labels;nonspam message;public e-mail systems;randomized Hough transform-support vector machine;randomly selected message;reject on negative impact algorithm;spam classifier;spam labels","","1","","19","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Locally Linear Minimum Spanning Trees for Manifold Learning","C. A. Quintero; F. Lozano","Fac. de Ing. Electron., Univ. Santo Tomas, Bogota, Colombia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","21","26","Graph-based manifold learning techniques have become of paramount importance when researchers have been faced to nonlinear data. These techniques have allowed them to discover relations that usual approaches such as PCA and MDS were incapable of. However, properties such as non-uniform sampling, varied topological substructures and highly curved manifolds still represent a challenge to these methods. We propose a graph building framework that strives at capturing the topological structures hidden in the data by means of a locality linear characterization combined with a MST-based noise model. We propose two algorithms under such framework that show improved performance over usual approaches.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784582","","Approximation algorithms;Buildings;Clustering algorithms;Data models;Manifolds;Noise;Principal component analysis","data analysis;learning (artificial intelligence);trees (mathematics)","MST-based noise model;graph building framework;graph-based manifold learning;locally linear minimum spanning trees;nonlinear data","","0","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Evolutionary Content Pre-fetching in Mobile Networks","O. K. Shoukry; M. B. Fayek","Cairo Univ., Cairo, Egypt","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","386","391","Recently, an increasing number of smart phone users are eagerly using the cellular network in extensive data applications. In particular, multimedia downloads generated by Internet-capable smart phones and other portable devices (such as iPad) have been widely recognized as the major source for strains in cellular networks, to a degree where service quality for all users is significantly impacted. Lately, patterns in both the content consumption as well as the Wi-Fi access by the users were alleged to be available. In this paper we introduce a technique to schedule the content for prefetching based on mobile usage patterns. This technique utilizes both a content profile as well as a bandwidth profile to schedule content for prefetching. Users can then use the cached version of the content in order to achieve a better user experience and reduce the peak-to-average ratio in mobile networks, especially during peak hours of the day. An experiment using real users traces was conducted and the results after applying the proposed evolutionary scheduling algorithm show that up to 70 percent of the user content requests can be fulfilled i.e. the content was successfully cached before request.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784649","Evolutionary algorithms;behavioral Models;content pre-fetching;memetic algorithms;mobile users;pattern mining;scheduling;traffic offloading","Bandwidth;Batteries;IEEE 802.11 Standards;Mobile communication;Schedules;Scheduling;Smart phones","Internet;cache storage;evolutionary computation;human factors;mobile computing;quality of experience;quality of service;scheduling;smart phones;telecommunication traffic;wireless LAN","Internet-capable smart phones;Wi-Fi access;bandwidth profile;cached content version;cellular network;content consumption;content profile;content scheduling;evolutionary content prefetching;evolutionary scheduling algorithm;mobile networks;mobile usage patterns;multimedia downloads;peak-to-average ratio;portable devices;service quality;user experience","","0","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Can We Minimize the Influence Due to Gender and Race in Age Estimation?","X. Wang; V. Ly; G. Lu; C. Kambhamettu","Dept. of Comput. & Inf. Sci., Univ. of Delaware, Newark, DE, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","309","314","Automatic human age estimation has attracted a great deal of interest in the past few years. Although many advancements have been made by researchers, there are still many challenges: such as age estimation across different image acquisition methods, different expressions, gender and races. The influence due to race and gender seems to be the most common issue, because collecting a large amount of face images with comprehensive racial diversities seems impractical. The performance will degrade when estimating face images of races that differ from the training set. In this work, we present a new scheme to mitigate the influences of race and gender in the problem of age estimation. Our system will contribute a robust solution to solve the problem of age estimation across races and genders. This study is essential for developing a practical age estimation system (with mixture of races and gender.) To evaluate the performance of the proposed algorithm, we run comprehensive experiments on one widely used big database - MORPH-II, which contains more than 55, 000 images. On an average, an improvement of more than 20% has been achieved using the proposed scheme.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786126","Age estimation;correlation learning;discriminative mapping;support vector regression","Aging;Correlation;Estimation;Face;Feature extraction;Testing;Training","age issues;face recognition;gender issues","MORPH-II database;automatic human age estimation;face image estimation;gender influence;image acquisition methods;racial diversities","","9","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Natural Image Segmentation Based on Precise Edge Detection","W. Feng; Y. Guo; X. Shi; Y. Hou","","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","231","234","Based on a new variational-based model within the fuzzy framework, we propose a new solution to the problem of multi-region segmentation of natural images. The advantages of our model is: by introducing the PCA features and modeling regions by Gaussian distribution, the proposed model can partition texture images better than classical variational-based segmentation models. We use the Berkeley database(BSDS300) as sample source and compare this model with some other well-known models such as the level-set model and the fuzzy region competition model. Comprehensive experiments have proven that the proposed model has better segmentation performance and faster speed.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784617","Gaussian mixture models;Natural image segmentation;PCA;Variational model","Hidden Markov models;Image color analysis;Image edge detection;Image segmentation;Lighting;Numerical models;Principal component analysis","Gaussian distribution;edge detection;image segmentation;natural scenes;principal component analysis","BSDS300;Berkeley database;Gaussian distribution;PCA features;fuzzy framework;fuzzy region competition model;level-set model;multiregion segmentation;natural image segmentation;precise edge detection;texture images;variational-based model","","1","","10","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Sequential Testing Procedure for Multiple Change-Point Detection in a Stream of Pneumatic Door Signatures","N. Cheifetz; A. Samé; P. Aknin; E. D. Verdalle; D. Chenu","GRETTIA, Univ. Paris-Est, Noisy-le-Grand, France","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","117","122","The conventional change-point detection problem aims to detect distribution changes at some unknown time point in a sequence of multivariate observations. Such problem is hardly addressed when the data are functional and both the pre-change and post-change distributions are unknown. In this paper, we propose an online sequential procedure based on a Generalized Likelihood Ratio (GLR) testing to address these issues. This procedure aims to minimize the expected detection delay subject to a false alarm constraint, and is designed to detect multiple change-points in a stream of multivariate curves. The methodology relies upon a specific multivariate regression model that takes into account prior information about the curve segmentation. This generative model can be fitted using a dedicated Expectation-Maximization (EM) algorithm presented in a semi-supervised framework. The monitoring strategy is applied to a sequence of real data collected from a door system operating in a transit bus. The experimental results allow to highlight the effectiveness of the proposed approach.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784597","Change-point detection;EM algorithm;curve segmentation;finite mixture models;semi-supervision;sequential hypothesis testing","Covariance matrices;Data models;Logistics;Mathematical model;Polynomials;Testing","expectation-maximisation algorithm;regression analysis;statistical distributions;statistical testing","EM algorithm;GLR testing;conventional change-point detection problem;curve segmentation;distribution change detection;door system;expectation-maximization algorithm;expected detection delay;false alarm constraint;generalized likelihood ratio testing;generative model;monitoring strategy;multiple change-point detection;multivariate curve;multivariate observation;multivariate regression model;online sequential procedure;pneumatic door signatures;post-change distribution;pre-change distribution;semisupervised framework;sequential testing procedure","","1","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Multi-modal Tree-Based SVM Classification","C. Freeman; D. Kulic; O. Basir","Dept. of Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","65","71","This paper presents a method for designing binary trees for SVM classification. The proposed algorithm, multi-modal binary tree (MBT) tolerates misclassification in the upper nodes of the tree, allowing points to be classified in either output regardless of the initial specified class groupings. MBT can separate classes that are inseparable with a single classifier by using a piecewise division. The algorithm also incorporates feature selection for the individual classifiers in the system. Classification results on several artificial and real data sets show that the proposed algorithm performs well compared to existing methods for multi-class SVM classification, and although the classifiers are larger, the time required to classify a point is smaller.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784589","classification algorithms;supervised learning;support vector machines","Accuracy;Binary trees;Cancer;Decision trees;Noise;Support vector machines;Training","feature selection;pattern classification;support vector machines;tree data structures","binary trees design;feature selection;multiclass SVM classification;multimodal binary tree;multimodal tree-based SVM classification;piecewise division;support vector machines","","0","","28","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Determining Potential Yeast Longevity Genes via PPI Networks and Microarray Data Clustering Analysis","B. Chen; R. Doolabh; F. Tang","Dept. of Comput. Sci., Univ. of Central Arkansas, Conway, AR, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","370","373","Identification of genes involved in lifespan extension is a pre-requisite for studying aging and age-dependent diseases. So far, very few genes have been identified that relate to longevity. The process of analyzing each single gene one at a time can be a very long and expensive process. It is known that approximately 10% of 6000 yeast genes are lifespan related genes, however, less than 100 genes are identified as longevity genes. The interconnection of multiple genes and the time-dependent protein-protein interactions make researchers use systems biology as a first tool to predict genes potentially involved in aging. In this study, we combined analyses of protein-protein interaction data and micro array data to predict longevity genes. A dataset of all 6000 yeast genes was utilized and a protein-protein interaction ratio was used to narrow the dataset. Next, a hierarchical clustering algorithm was created to group the resulting data. From these clusters, conclusion of 6 highly possible longevity genes was drawn based on the amount of longevity genes in each cluster. Based on our latest information, one of our predicted genes is identified as a longevity gene. Wet lab experiments are applied to our predicted genes for supporting the findings.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784645","Clustering;PPI;yeast longevity genes","Aging;Algorithm design and analysis;Bioinformatics;Clustering algorithms;Partitioning algorithms;Proteins","biology computing;diseases;genetics;pattern classification;proteins","age-dependent disease;aging disease;genes identification;hierarchical clustering algorithm;lifespan extension;micro array data;microarray data clustering analysis;ppi networks;predicted genes;protein-protein interaction data;protein-protein interaction ratio;systems biology;time-dependent protein-protein interactions;yeast genes;yeast longevity genes","","0","","11","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Evolving Hybrid Neural Fuzzy Network for System Modeling and Time Series Forecasting","R. Rosa; F. Gomide; R. Ballini","Sch. of Electr. & Comput. Eng., Univ. of Campinas, Campinas, Brazil","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","378","383","This paper introduces an evolving hybrid fuzzy neural network-based modeling approach using neurons based on uninorms and sigmoidal activation functions in a feed forward structure. The evolving neural network simultaneously adapts its structure and updates its weights using a stream of data. Currently, learning from data streams is a challenging and important issue because often traditional learning methods are impracticable to handle nonstationary and dynamic environments from where data come from. Uninorm-based neurons generalize fuzzy neurons models based on triangular norms and co norms. Uninorms increase the flexibility and generality of fuzzy neurons because they can modify their processing capabilities by adjusting their identity elements. In addition to structural plasticity induced by evolving network structures, identity elements adjustment adds functional plasticity in neural network processing. A recursive procedure to granulate the input space and uncover the evolving neural network structure, and an extreme learning-based algorithm to learn network weights are developed to train the neural network. Computational results show that the evolving neural fuzzy network is competitive when compared with representative methods of the current state of the art in evolving modeling.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786139","clouds;evolving systems;extreme learning;hybrid neural fuzzy systems;unineurons","Adaptation models;Biological neural networks;Forecasting;Fuzzy neural networks;Neurons;Time series analysis","data analysis;feedforward neural nets;fuzzy neural nets;learning (artificial intelligence);time series","data stream;evolving hybrid fuzzy neural network-based modeling approach;evolving network structures;extreme learning-based algorithm;feedforward structure;functional plasticity;fuzzy neuron models;input space;network weight learning;neural network processing;neural network training;recursive procedure;sigmoidal activation functions;structural plasticity;system modeling;time series forecasting;triangular conorms;uninorm-based neurons;weight update","","4","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Design of Chaos-Based Communication System with Use of the Derivative-Free Nonlinear Kalman Filter","G. G. Rigatos","Unit of Ind. Autom., Ind. Syst. Inst., Rion Patras, Greece","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","8","14","A chaos-based communication system is designed in which extraction of the information signal at the receiver is performed with the use of a nonlinear filtering method of improved efficiency (Derivative-free nonlinear Kalman Filter). In the transmitter's side the source of information undergoes modulation (encryption) using as carrier a chaotic signal generated by the Duffing oscillator. The modulated signal is transmitted through a communication channel and at the receiver's side demodulation takes place, by exploiting the estimation provided for the state vector of the chaotic oscillator by the Derivative-free nonlinear Kalman Filter. The proposed filtering method has improved performance over the Extended Kalman Filter and reduces significantly transmission errors.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786074","Derivative-free nonlinear Kalman Filter;chaotic communication system;chaotic oscillators;differential flatness theory;synchronization","Chaotic communication;Estimation;Kalman filters;Modulation;Oscillators;Receivers","Kalman filters;chaotic communication;demodulation;nonlinear filters;oscillators;receivers;telecommunication channels;transmitters","Duffing oscillator;chaos-based communication system design;chaotic oscillator;communication channel;demodulation;derivative-free nonlinear Kalman filter;encryption;information signal extraction;modulation;nonlinear filtering method;receiver;transmitter","","1","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Scalable Expert Selection When Learning from Noisy Labelers","C. Wolley; M. Quafafou","LSIS, Aix-Marseille Univ., Marseille, France","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","398","401","In a supervised learning context, various methods have been proposed to learning from different labelers. Very recently, the problem has shifted towards ranking and filtering low-quality annotators, and estimating the consensus labels based only on the remaining experts, i.e, annotators that provide high quality annotations. In this paper, we propose a novel approach to address this issue. Our solution is based on a probabilistic method where a combination of two metrics, a probabilistic score and an entropy measure, are integrated in order to iteratively select the experts and estimate the labels based only on the selected annotators.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784651","Supervised Learning;experts selection;multiple annotators","Computational modeling;Entropy;Heart;Labeling;Probabilistic logic;Sensitivity;Supervised learning","entropy;learning (artificial intelligence);pattern classification;probability","classification;consensus label estimation;entropy measure;low-quality annotator filtering;low-quality annotator ranking;noisy labelers;probabilistic score;scalable expert selection;supervised learning","","0","","11","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Affect Detection and Classification from the Non-stationary Physiological Data","O. Alzoubi; D. Fossati; S. D'mello; R. A. Calvo","Comput. Sci., Carnegie Mellon Univ. in Qatar, Doha, Qatar","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","240","245","Affect detection from physiological signals has received a great deal of attention recently. One arising challenge is that physiological measures are expected to exhibit considerable variations or non-stationarities over multiple days/sessions recordings. These variations pose challenges to effectively classify affective sates from future physiological data. The present study collects affective physiological data (electrocardiogram (ECG), electromyogram (EMG), skin conductivity (SC), and respiration (RSP)) from four participants over five sessions each. The study provides insights on how diagnostic physiological features of affect change over time. We compare the classification performance of two feature sets, pooled features (obtained from pooled day data) and day-specific features using an up datable classifier ensemble algorithm. The study also provides an analysis on the performance of individual physiological channels for affect detection. Our results show that using pooled feature set for affect detection is more accurate than using day-specific features. The corrugator and zygomatic facial EMGs were more reliable measures for detecting valence than arousal compared to ECG, RSP and SC over the span of multi-session recordings. It is also found that corrugator EMG features and a fusion of features from all physiological channels have the highest affect detection accuracy for both valence and arousal.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784619","Affect;Non-Stationary;classifier ensembles;emotion;physiological","Accuracy;Classification algorithms;Electrocardiography;Electromyography;Feature extraction;Physiology;Training","electrocardiography;electromyography;learning (artificial intelligence);medical signal detection;medical signal processing;physiology;signal classification","ECG;RSP;SC;affect classification;affect detection;affective states classification;arousal;classifier ensemble algorithm;corrugator EMG features;day-specific features;electrocardiogram;electromyogram;nonstationary physiological data;physiological measures;physiological signals;pooled features;respiration;skin conductivity;valence detection","","0","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Comprehension Approach for Formalizing Privacy Rules of HIPAA for Decision Support","I. Khan; M. Alwarsh; J. I. Khan","Dept. of Comput. Sci., Int. Islamic Univ. (IIU), Islamabad, Pakistan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","390","395","In this paper we explore automated verification of electronic medical record (EMR) transaction for compliance with a regulatory regimen such as HIPAA. We present an approach based on modeling the conceptual space of HIPAA. The clauses of HIPAA legal text is then converted into a disambiguated decision tree (DDT) rules precisely identifying the allowed, dis-allowed and prescribed actions per work flow request type. Given any EMR query the DT then enables one not only to verify the compliance as well as provide complete release guidance as prescribed by HIPAA, generate explanation and audit.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786141","HIPAA;Logical Rules Set;Privacy Rules","Authorization;Decision trees;Human immunodeficiency virus;Law;Semantics","data privacy;decision support systems;decision trees;electronic health records;formal verification;health care;law;query processing;text analysis","DDT;EMR query;HIPAA;Portability-and-Accountability Act;US health care system efficiency improvement;allowed action-per-work flow request type;automated electronic medical record transaction verification;computer assisted intelligent verification;decision support;disallowed action-per-work flow request type;disambiguated decision tree rules;legal text conversion;medical information exchange;prescribed action-per-work flow request type;privacy rule formalization;regulatory regimen","","1","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Ecosembles: A Rapidly Deployable Image Classification System Using Feature-Views","A. Rosebrock; T. Oates; J. Caban","","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","1","8","Constructing an image classification system using strong, local invariant descriptors is both time consuming and tedious, requiring many experimentations and parameter tunings to obtain an adequately performing model. Furthermore training a system in a given domain and then migrating the model to a separate domain will likely yield poor performance. As the recent Boston Marathon attacks demonstrated, large, unstructured image databases from traffic cameras, security systems, law enforcement officials, and citizens can be quickly amassed for authorities to review, however, reviewing each and every image is a expensive undertaking, in terms of both time and human intervention. Inherently, reviewing crime scene images is a classification task. For example, authorities may want to know if a given image contains a suspect, a suspicious package, or if there are injured people in the photo. Given an emergency situation, these classifications will be needed as quickly and accurately as possible. In this work we present a rapidly deployable image classification system using ""feature-views"", which each view consists of a set of weak, global features. These weak global descriptors are computationally simple to extract, intuitive to understand, and require substantially less parameter tuning than their local invariant counterparts. We demonstrate that by combining weak features with ensemble methods we are able to outperform current state-of-the-art methods or achieve comparable accuracy with much less effort and domain knowledge. Finally we provide both theoretical and empirical justification for our ensemble framework that can be used to construct rapidly deployable image classification systems called ""Ecosembles"".","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784579","ensemble methods;feature extraction and selection;supervised learning","Accuracy;Birds;Feature extraction;Histograms;Probability distribution;Training;Vectors","Bayes methods;feature extraction;image classification;statistical distributions;visual databases","ecosembles;ensemble methods;feature extraction;feature-views;image classification system;image databases;parameter tuning","","0","","35","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Contrasting Undersampled Boosting with Internal and External Feature Selection for Patient Response Datasets","T. M. Khoshgoftaar; D. J. Dittman; R. Wald; A. Napolitano","Florida Atlantic Univ., Boca Raton, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","404","410","Class imbalance (where one class has many more instances than the other class(es)) and high dimensionality (large number of features per instance) are two prevalent problems that are frequently present in patient response datasets. In addition to these problems, these datasets are notoriously difficult to build effective models from. This paper introduces a new hybrid boosting algorithm named SelectRUSBoost which combines data sampling and feature selection with every iteration of boosting. We test SelectRUSBoost along with RUSBoost combined with external feature selection on a set of five patient response datasets. In addition to the datasets we also utilize two classifiers, three filter-based feature selection techniques, and four feature subset sizes. Our results show that SelectRUSBoost will, with few exceptions, outperform RUSBoost combined with external feature selection. Also, the feature selection technique information gain outperformed the other techniques for all combinations of boosting approach, classifier, and feature subset size, and in addition for this feature selection technique SelectRUSBoost always (without exception) outperformed RUSBoost combined with external selection. Statistical analysis confirmed that SelectRUSBoost gives better performance than RUSBoost combined with external selection. This is the first work which utilizes SelectRUSBoost in a bioinformatics study.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786143","Bioinformatics;Boosting;Class Imbalance;Feature Selection;High Dimensionality;Patient Response","Bioinformatics;Boosting;Buildings;DNA;Data models;Logistics;Stability analysis","bioinformatics;data mining;feature selection;learning (artificial intelligence);patient treatment;pattern classification;sampling methods","RUSBoost;SelectRUSBoost;bioinformatics;class imbalance;data sampling;feature classifier;feature subset size;filter-based feature selection technique;hybrid boosting algorithm;iteration method;patient response datasets;undersampled boosting","","2","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Price Forecasting in the Spanish Day-Ahead Electricity Market Using Preconditioned Wind Power Information","C. Geidel; H. Zareipour","Dept. of Electr. Eng. & Comput. Sci., Tech. Univ. Berlin, Berlin, Germany","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","203","210","In this paper, short-term electricity price forecasting using residual demand under predefined wind power generation conditions is performed. Residual demand is defined as the total electricity demand subtracted by hard to predict renewable energy sources. Focus of this paper lies on wind power generation as the main renewable energy source. First, the long-term influence of wind power on the electricity market price is investigated. Second, the short-term dependency between electricity market price and wind power generation is examined by applying the similar day method to the Spanish day-ahead market as well as data association mining. Third, a novel method of how to use wind power information is introduced.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786109","Price forecasting;residual demand;wind power","Data mining;Electricity;Electricity supply industry;Forecasting;Pragmatics;Support vector machines;Wind power generation","data mining;demand side management;power markets;wind power","Spanish day-ahead electricity market;data association mining;electricity demand;preconditioned wind power information;renewable energy source;residual demand;short-term electricity price forecasting;wind power generation","","0","","21","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"The Estimation of Students' Academic Success by Data Mining Methods","H. Göker; H. I. Bülbül; E. Irmak","Inst. of Informatic, Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","535","539","Data mining is a process of getting out useful information from data stacks. One of the most common application areas is to use classification of algorithms that estimate the future events by past experiences. In this context, in order to predict future events, a data warehouse is created by using the background of students which includes demographic, personal, school, and course information of students. On this data warehouse by using classification algorithms, new applications which can make inferences for the future could be developed. Aims of this study are to create student data warehouse which can be used data mining algorithms, to improve an early warning system that may estimate students' the future academic successes for students and also for their families and to find out primary factors affecting their academic success.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786166","classification;data mining;data warehouse;feature selection;naive bayes;weka","Classification algorithms;Data mining;Data preprocessing;Data warehouses;Databases;Educational institutions","data mining;data warehouses;educational administrative data processing;educational courses;inference mechanisms;pattern classification","algorithm classification;course information;data mining methods;data stacks;demographic information;early warning system improvement;future event prediction;personal information;school information;student background;student data warehouse;students academic success estimation","","1","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Quality Classification of Green Pellet Nuclear Fuels Using Radial Basis Function Neural Networks","B. Kusumoputro; A. Faqih; D. Sutarya; Lina","Dept. Electr. Eng., Univ. Indonesia, Depok, Indonesia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","194","198","Total quality classification process is necessary to be continously conducted along the pellet fabrication processes to minimize the number of rejected of the green pellets. This cylindrical uranium dioxide pellets, as the main fuel element in the Light Water Nuclear Reactor, should shows uniform shape, uniform quality and a high density profile. The quality of green pellets is conventionally monitored through a laboratory measurement of the physical pellets characteristics followed by a graphical chart classification technique, however, this technique is difficult to use and shows low accuracy and time consuming. In this paper, a Radial Basis Function neural networks is develop by studied and modified the weight initialization on its neural structure, and applied for automation of classifying the pellets quality. It is proved from the experiments that the Radial Basis Function neural networks shows a comparable classification rate with that of best-tune Back Propagation neural networks, however, the computational cost is reduced significantly.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786107","RBF NN;classification of green pellets;nuclear fuel cells;weight initialization","Artificial neural networks;Computational efficiency;Fabrication;Neurons;Nuclear fuels;Vectors","computational complexity;fission reactor fuel preparation;fuel processing;pattern classification;production engineering computing;quality control;radial basis function networks;uranium compounds","back propagation neural networks;classification rate;computational cost reduction;cylindrical uranium dioxide pellets;graphical chart classification technique;green pellet nuclear fuel quality classification;laboratory measurement;light water nuclear reactor;pellet fabrication processes;physical pellets characteristics;radial basis function neural networks;total quality classification process","","0","","10","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Indicative Support Vector Clustering with Its Application on Anomaly Detection","H. Xiao; C. Eckert","Comput. Sci. Dept., Tech. Univ. of Munich, Garching, Germany","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","273","276","In many learning scenarios, supervised learning is hardly applicable due to the unavailability of a complete set of data labels, while unsupervised model overlooks valuable user feedback in an interactive system setting. In this paper, a novel semi-supervised support vector clustering algorithm is presented, where a small number of user indicated labels are available as supervised information. We apply the clustering algorithm in the anomaly detection area, and show that the given labels significantly improve the recognition of anomalies. Moreover, the partially labeled data proliferates the information without extra computation but strengthening the robustness to anomalies.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784625","anomaly detection;semi-supervised learning;support vector clustering","Bandwidth;Clustering algorithms;Clustering methods;Kernel;Robustness;Static VAr compensators;Support vector machines","interactive systems;learning (artificial intelligence);pattern clustering;security of data;support vector machines","anomaly detection;data labels;indicative support vector clustering;interactive system setting;semisupervised support vector clustering algorithm;supervised learning;unsupervised model;valuable user feedback","","0","","9","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Hybrid Method for Fast SVM Training in Applications Involving Large Volumes of Data","M. A. Wani","","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","491","494","One of the problems of training a Support Vector Machine (SVM) for applications involving large volumes of data is how to solve the constrained quadratic programming issue. The optimization process suffers from the problem of large memory requirement and computation time. In this paper we propose a hybrid genetic algorithm based SVM that addresses the large memory requirement and computation time problem. The system operates in two main stages. During first stage it obtains a subset of features using genetic algorithm and during second stage it uses genetic algorithm to train the SVM using subset of features. The proposed system is tested on gene expression profile data sets. The experiment results show that the proposed hybrid system is efficient from memory and time computational point of views without compromising classification accuracy results.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.195","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786158","Fast Training of SVM;Genetic Algorithm;Hybrid Approach for Training;Support Vector Machines;Training with Large Volumes of Data","Accuracy;Biological cells;Classification algorithms;Genetic algorithms;Memory management;Support vector machines;Training","biology computing;genetic algorithms;quadratic programming;support vector machines","constrained quadratic programming issue;fast SVM training;gene expression profile data sets;hybrid genetic algorithm;optimization process;support vector machine","","0","","6","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Predicting Next Location of Twitter Users for Surveillance","S. Gunduz; U. Yavanoglu; S. Sagiroglu","Dept. of Comput. Eng., Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","267","273","In this study a novel approach that uses location based social networks for next location prediction in the field of technical surveillance and digital forensics is proposed. With the help of proposed methodology, search area for the potential criminals will be narrowed so that the spent time, money and effort by the law enforcement officers will be minimized. After collecting enough past location information for Foursquare users, the whole data is trained by means of Artificial Neural Networks. After training process, predicting the next location of the wanted personis carried out. Prediction process is made region-based, so it is tried to predict the region of the potential criminals' next geographical location. The experimental results have shown that the proposed approach and developed system might achieve the prediction goal with only 3% error rate, and proposed methodology can be used by law enforcement officers for forensic surveillance and similar criminal acts.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786119","Digital Forensics;Information Security;Location Based Social Networks;Location Prediction;Social Networks;Technical Surveillance","Artificial neural networks;Law enforcement;Prediction algorithms;Predictive models;Social network services;Surveillance;Training","Internet;digital forensics;law;neural nets;social networking (online);video surveillance","artificial neural networks;digital forensics;foursquare users;geographical location;law enforcement officers;predicting next location;social networks;technical surveillance;twitter users","","2","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Massive GIS Database System with Autonomic Resource Management","Y. Lu; M. Zhao; G. Zhao; L. Wang; N. Rishe","Sch. of Comput. & Inf. Sci., NSF Ind.-Univ. Cooperative Res. Centers, Miami, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","451","456","GIS application hosts are becoming more and more complicated. Thus, their management is more time consuming, and reliability decreases with the complexity of GIS applications increasing. We have designed, implemented, and evaluated, a virtualized whole Large Scale Distributed Spatial Data Visualization System for optimizing maintainability and performance when handling large amount of GIS data. We employ the virtual machines (VMs) technique, load balance cluster techniques, and autonomic resource management to improve the system's performance. The proposed system was prototyped on TerraFly [1], a production web map service, and evaluated using actual TerraFly workloads. The results show that the virtual TerraFly system has both good performance and much better maintainability. Our experiments show that the proposed Virtual TerraFly Geo-database system has doubled the reliability, and saved 20-30% computing resources cost compared to current static peak-load physical machine node allocations.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786152","Database Systems;GIS;maintainability;performance","Data visualization;Database systems;Resource management;Servers;Spatial databases;Virtual machining","Web services;cartography;data handling;data visualisation;distributed databases;geographic information systems;resource allocation;software maintenance;software performance evaluation;virtual machines;virtualisation;visual databases","GIS application hosts;GIS data handling;VM;World Wide Web;actual TerraFly workloads;autonomic resource management;large scale distributed spatial data visualization system;load balance cluster techniques;massive GIS database system;production Web map service;system performance improvement;virtual TerraFly geo-database system;virtual machines technique","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Phrase Based Topic Modeling for Semantic Information Processing in Biomedicine","Z. Yu; T. R. Johnson; R. Kavuluru","Dept. of Biostat., Univ. of Kentucky, Lexington, KY, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","440","445","Given that unstructured data is increasing exponentially everyday, extracting and understanding the information, themes, and relationships from large collections of documents is increasingly important to researchers in many disciplines including biomedicine. Latent Dirichlet Allocation (LDA) is an unsupervised topic modeling technique based on the ""bag-of-words"" assumption that has been applied extensively to unveil hidden semantic themes within large sets of textual documents. Recently, it was extended using the ""bag-of-n-grams"" paradigm to account for word order. In this paper, we present an alternative phrase based LDA model to move from a bag of words or n-grams paradigm to a ""bag-of-key-phrases"" setting by applying a key phrase extraction technique, the C-value method, to further explore latent themes. We evaluate our approach by using a phrase intrusion user study and demonstrate that our model can help LDA generate better and more interpretable topics than those generated using the bag-of-n-grams approach. Given topic models essentially are statistical tools, an important problem in topic modeling is that of visualizing and interacting with the models to understand and extract new information from a collection. To evaluate our phrase based modeling approach in this context, we incorporate it in an open source interactive topic browser. Qualitative evaluations of this browser with biomedical experts demonstrate that our approach can aid biomedical researchers gain better and faster understanding of their document collections.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784659","topic models;visual processing;word intrusion","Biological system modeling;Browsers;Computational modeling;Context;Context modeling;Pain;Semantics","biology computing;information retrieval;medicine;statistical analysis;text analysis","C-value method;bag-of-n-grams paradigm;bag-of-words assumption;biomedicine;document collections;key phrase extraction technique;latent Dirichlet allocation;open source interactive topic browser;phrase based topic modeling;phrase intrusion user study;semantic information processing;statistical tools;textual documents;unsupervised topic modeling technique","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Visual Speech Detection Using an Unsupervised Learning Framework","R. Ahmad; S. P. Raza; H. Malik","ECE Dept., Univ. of Michigan - Dearborn, Dearborn, MI, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","525","528","This paper presents an unsupervised learning framework for visual speech detection. Bimodal GMM is used to model visual features, i.e., mouth region intensity, which varies during speech. Variation in the mouth region intensity is used for visual speech and non-speech classification. The GMM parameters are estimated using the EM algorithm. Performance of the proposed algorithm is evaluated using a dataset consisting of 14 video clips containing almost 20, 000 frames. Performance of the proposed algorithm is also compared with existing state-of-the-art. Experimental results show that the proposed method achieves high detection and low false alarm rates.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786164","Expectation Maximization (EM);Gaussian Mixture Model (GMM);Unsupervised Learning;Voice Activity Detection (VAD)","Cavity resonators;Signal processing algorithms;Speech;Teeth;Video sequences;Visualization","Gaussian processes;expectation-maximisation algorithm;feature extraction;image classification;learning (artificial intelligence);mixture models;video signal processing","EM algorithm;Gaussian mixture model;bimodal GMM parameter estimation;detection rates;expectation maximization algorithm;false alarm rates;mouth region intensity;performance evaluation;unsupervised learning framework;video clips;visual feature modelling;visual nonspeech classification;visual speech classification;visual speech detection","","0","","8","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Objective Re-weighting to Guide an Interactive Search Based Software Testing System","B. Marculescu; R. Feldt; R. Torkar","Sch. of Comput., Blekinge Inst. of Technol., Karlskrona, Sweden","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","102","107","Even hardware-focused industries today develop products where software is both a large and important component. Engineers tasked with developing and integrating these products do not always have a software engineering background. To ensure quality, tools are needed that automate and support software testing while allowing these domain specialists to leverage their knowledge and experience. Search-based testing could be a key aspect in creating an automated tool for supporting testing activities. However, domain specific quality criteria and trade-offs make it difficult to develop a general fitness function a priori, so interaction between domain specialists and such a tool would be critical to its success. In this paper we present a system for interactive search-based software testing and investigate a way for domain specialists to guide the search by dynamically re-weighting quality goals. Our empirical investigation shows that objective re-weighting can help a human domain specialist interactively guide the search, without requiring specialized knowledge of the system and without sacrificing population diversity.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786089","embedded software;industrial experience;interactive search based software engineering;search based software testing;user centered","Context;Search problems;Sociology;Software;Software engineering;Software testing","automatic testing;interactive systems;program testing;software quality","automated testing tool;human domain specialist;interactive search- based software testing;objective reweighting;population diversity;quality goals;software engineering background","","2","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Pairwise Clustering by Minimizing the Error of Unsupervised Nearest Neighbor Classification","Y. Yang; X. Chu; T. S. Huang","Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","182","187","Pair wise clustering methods, including the popular graph cut based approaches such as normalized cut, partition the data space into clusters by the pair wise affinity between data points. The success of pair wise clustering largely depends on the pair wise affinity function defined over data points coming from different clusters. Interpreting the pair wise affinity in a probabilistic framework, we build the relationship between pair wise clustering and unsupervised classification by learning the soft Nearest Neighbor (NN) classifier from unlabeled data, and search for the optimal partition of the data points by minimizing the generalization error of the learned classifier associated with the data partitions. Modeling the underlying distribution of the data by non-parametric kernel density estimation, the asymptotic generalization error of the unsupervised soft NN classification involves only the pair wise affinity between data points. Moreover, such error rate reduces to the well-known kernel form of graph cut in case of uniform data distribution, which provides another understanding of the kernel similarity used in Laplacian Eigenmaps [1] which also assumes uniform distribution. By minimizing the generalization error bound, we propose a new clustering algorithm. Our algorithm efficiently partition the data by inference in a pair wise MRF model. Experimental results demonstrate the effectiveness of our method.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786105","Kernel Density Estimation;Nearest Neighbor Classifier;Pairwise Clustering","Bandwidth;Clustering algorithms;Clustering methods;Data models;Kernel;Labeling;Training","generalisation (artificial intelligence);graph theory;inference mechanisms;minimisation;nonparametric statistics;pattern classification;pattern clustering;statistical distributions;unsupervised learning","Laplacian eigenmaps;asymptotic generalization error minimization;data points partition;data space partition;error rate;graph cut based approach;inference mechanism;kernel similarity;learning;nonparametric kernel density estimation;pairwise MRF model;pairwise affinity function;pairwise clustering method;uniform data distribution modeling;unsupervised nearest neighbor classification;unsupervised soft NN classification","","0","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"BEMI Bicluster Ensemble Using Mutual Information","G. Aggarwal; N. Gupta","Dept. of Comput. Sci., Univ. of Delhi, New Delhi, India","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","321","324","Biclustering solutions generally depend upon various parameters like number of biclusters and random initialisations. Ensemble techniques have been used to eliminate the impact of such parameters on the output. In this paper, we present a novel ensemble technique for biclustering solutions using mutual information. Unlike the existing approaches, the proposed technique does not require the biclusters to be aligned. As a result, it does away with the requirement that all the biclustering solutions generate the same number of biclusters. Moreover, most of the existing approaches require the user to specify the number of output biclusters. Our approach determines the number of well separated biclusters from the input solutions itself. Experiments performed on synthetic and real datasets show that our approach improves upon the biclustering error over the input solutions as well as the ensemble techniques of hanczar et al.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784635","Bicluster Ensemble;Biclustering;Mutual information","Algorithm design and analysis;Bagging;Bioinformatics;Data mining;Gene expression;Mutual information;Noise","pattern clustering","BEMI;bicluster ensemble technique;biclustering error;biclustering solutions;mutual information;output biclusters;random initializations","","1","","24","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Event Causality Identification Using Conditional Random Field in Geriatric Care Domain","S. Mehrabi; A. Krishnan; E. Tinsley; J. Sligh; N. Crohn; H. Bush; J. Depasquale; J. Bandos; M. Palakal","Sch. of Inf. & Comput., Indiana Univ., Indianapolis, IN, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","339","343","Event extraction is a key step in many text-mining applications such as question-answering, information extraction and summarization systems. In this study we used conditional random field (CRF) to extract causal events from PubMed articles related to Geriatric care. Abstracts of geriatric care domain were manually reviewed and categorized into 42 different sub domains. There are a total of 19, 677 sentences in the collected abstracts from PubMed, out of which 2, 856 sentences were selected and manually annotated with cause and effect events. The data set was then divided into training (2, 520), validation (252) and test (84) sentence sets. Features such as tokens, token categories, affixes, part of speech and shallow parser were used as inputs to the CRF model. A window of features before and after each token was used to determine its causal event label using CRF. A window of four features had the best performance with 84.6% precision, 87% recall, 85% and F-measure.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784639","conditional random fields;event extraction;natural language processing","Abstracts;Data models;Geriatrics;Hidden Markov models;Natural language processing;Training;Unified modeling language","data mining;geriatrics;health care;information retrieval;text analysis","PubMed articles;causal event extraction;conditional random field;event causality identification;geriatric care domain;text mining","","1","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Incorporating Categorical Information for Enhanced Probabilistic Trajectory Prediction","J. Wiest; F. Kunz; U. Kreßel; K. Dietmayer","Inst. of Meas., Control & Microtechnol. Ulm Univ., Ulm, Germany","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","402","407","Advanced Driver Assistance Systems (ADAS) have witnessed a steady increase in complexity during the last few years. Many of these systems could benefit from a reliable long-term prediction of the vehicle's trajectory, for instance the prediction of a turning maneuver at an intersection. The application of probabilistic trajectory prediction provides knowledge of the probability and the uncertainty of the predicted trajectories, allowing a subsequent probabilistic treatment. In this contribution this is achieved by approximating a motion model through a probability density function (pdf) and inferring its parameters with previously observed motion patterns during a training procedure. Predictions can be obtained by calculating statistical parameters of the conditional probability density function (cpdf), for instance the mean and the variance. A common way to obtain the required cpdf is to approximate a joint pdf over the input and output variables and calculate the conditioning. Since the distribution over the input data space is not needed, this can be very wasteful of resources. Therefore in this contribution a novel approach for probabilistic trajectory prediction is proposed which directly approximates the cpdf using Hierarchical Mixture of Experts. Furthermore, the hierarchical structure of the model is exploited to incorporate optional knowledge in terms of categorical information (e.g., turn signal or map information) without the need to directly increase the input parameter space regarding all model components.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784652","Conditional Density Estimation;Hierarchical Mixture of Experts;Trajectory Prediction","Chebyshev approximation;Predictive models;Probabilistic logic;Trajectory;Vectors;Vehicles","approximation theory;driver information systems;probability","ADAS;CPDF;advanced driver assistance systems;categorical information;conditional probability density function;enhanced probabilistic trajectory prediction;hierarchical structure;joint PDF approximation;motion model approximation;probabilistic treatment;statistical parameters;training procedure;turning maneuver prediction;vehicle trajectory prediction","","4","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"On the Behaviour of Scalarization Methods for the Engagement of a Wet Clutch","T. Brys; K. V. Moffaert; K. V. Vaerenbergh; A. Nowé","AI Lab., VUB, Brussels, Belgium","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","258","263","Many industrial problems are inherently multi-objective, and require special attention to find different trade-off solutions. Typical multi-objective approaches calculate a scalarization of the different objectives and subsequently optimize the problem using a single-objective optimization method. Several scalarization techniques are known in the literature, and each has its own advantages and drawbacks. In this paper, we explore various of these scalarization techniques in the context of an industrial application, namely the engagement of a wet clutch using reinforcement learning. We analyse the approximate Pareto front obtainable by each technique, and discuss the causes of the differences observed. Finally, we show how a simple search algorithm can help explore the parameter space of the scalarization techniques, to efficiently identify possible trade-off solutions.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784622","Multi-objective;reinforcement learning;scalarization","Chebyshev approximation;Friction;Learning (artificial intelligence);Optimization;Pistons;Shafts;Torque","Pareto optimisation;clutches;learning (artificial intelligence);mechanical engineering computing;search problems","approximate Pareto front;industrial application;multiobjective approaches;reinforcement learning;scalarization methods;search algorithm;single-objective optimization method;trade-off solutions;wet clutch engagement","","3","","14","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Gene Expression Profile Classification Using Random Projection and Sparse Representation","X. Hang","Dept. of Electr. & Comput. Eng., California State Univ., Northridge, Northridge, CA, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","411","414","A new gene expression profile classification scheme is developed in this study. Random projection is used for feature selection, and classification is formulated into a problem as finding sparse representations of test samples with respect to training samples. The sparse representation is computed by the l<sub>1</sub>-regularized least square method. To investigate its performance, the proposed method is applied to three tumor gene expression datasets and compared with the combination of support vector machine (SVM) and two popular gene selection methods. The experimental results have shown that the performance of the proposed method is comparable with or better than those of SVM. In addition, the proposed method is more efficient than SVM as it has no need of model selection.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786144","Gene expression;Random projection;Sparse representation","Cancer;Classification algorithms;Face recognition;Gene expression;Support vector machines;Training;Tumors","biology computing;feature selection;least squares approximations;pattern classification;support vector machines","SVM;feature selection;gene expression profile classification;l<sub>1</sub>-regularized least square method;random projection;sparse representation;support vector machine;tumor gene expression datasets","","0","","23","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"The Determination of Socio-economic Factors Affecting Student Success by Data Mining Methods","V. Atalay; S. Üstün; S. Bülbül","Inst. of Informatic, Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","540","542","The success of socio-economic level on students is a fact. The economic level and conditions combined with the student's potential make itself felt at the ultimate level. In this research, it was established that success and socio-economic factors which can attract the attention are effectively observed on particularly female students. It was ensured that a real and sound socio-economic criteria for success be determined by evaluating success and failure at terminal points. Decision trees and chi-square test were used in the implementation.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786167","Data Mining;Decision Tree;IBM Moduler;Navie Bayes","Cities and towns;Data mining;Decision trees;Economics;Educational institutions;Heating","data mining;decision trees;socio-economic effects;statistical testing","chi-square test;data mining method;decision tree;female students;socio-economic factors determination;student potential;student success","","0","","27","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Hindi Language Graphical User Interface to Database Management System","M. Dua; S. Kumar; Z. S. Virk","Dept. of Comput. Eng., NIT kurukshetra, Kurukshetra, India","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","555","559","Database management systems have been widely used for storing and retrieving data. However, databases are hard to use since their interface is rigid in cooperating with users. Large number of e-governance applications like weather forecasting, agriculture, banking, railways etc. use database. For the people who are comfortable with Hindi language require these applications to accept a Hindi sentence as a query, process it and after execution provide result to the user in Hindi language. In this paper, we discuss the architecture of system to convert a Hindi sentence into equivalent SQL query. To make data retrieval easy for common person, in the developed system, the user can input query in Hindi language and get the result in same language. The users have no need to learn any formal query language like SQL to access the database.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786170","DBMS (Database Management System);HLIDBMS (Hindi Language Interface to Database Management System);NL (Natural Language);NLIDB (Natural Language Interface to Database);NLP (Natural Language Processing);SQL (Structured Query Language)","","SQL;database management systems;graphical user interfaces;natural language processing;query processing;storage management","Hindi language graphical user interface;Hindi sentence;SQL query;agriculture;banking;data retrieval;data storage;database management systems;e-governance applications;formal query language;railways;system architecture;weather forecasting","","3","","19","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Google Penguin: Evasion in Non-English Languages and a New Classifier","A. Alarifi; M. Alsaleh; A. Al-Salman; A. Alswayed; A. Alkhaledi","Comput. Res. Inst., King Abdulaziz City for Sci. & Technol., Riyadh, Saudi Arabia","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","274","280","Web spam techniques aim to mislead search engines so that web spam pages get ranked higher than they deserve. This leads to misleading search results as spam pages might appear in search results although the content of these spam pages might not be related to the search terms. Despite the effort of search engines to deploy various techniques to detect and filter out web spam pages from being listed in their search results, spammers continue to develop new tactics to evade search engines detection mechanisms. In this paper, we study the effectiveness and accuracy of newly developed anti-spamming techniques in Google search engine. Focusing on Arabic spam pages, our study results show that Google anti-spamming techniques are ineffective against spam pages with Arabic content. We explore various types of web spam detection features to obtain an appropriate set of detection features that yield a reasonable detection accuracy. In order to build and evaluate our classifier, we collect and manually label a dataset of Arabic web pages, including both benign and spam pages. We believe this Arabic web spam corpus helps researchers in conducting sound measurement studies. We also develop a browser plug-in that utilizes our classifier and warns the user about web spam pages before accessing them, upon clicking on a search term. The plug-in has also the ability to filter out search engine results.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786120","Content spam;Link spam;Search engine spam;Spamdexing;Web spam","Browsers;Feature extraction;Google;Market research;Search engines;Unsolicited electronic mail;Web pages","Internet;natural language processing;search engines;unsolicited e-mail","Arabic Web spam corpus;Arabic spam pages;Google penguin;Google search engine;Web spam detection;Web spam pages;Web spam techniques;new classifier;non english languages;search engines detection mechanisms;search terms","","2","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Comparison of Stability for Different Families of Filter-Based and Wrapper-Based Feature Selection","R. Wald; T. Khoshgoftaar; A. Napolitano","Florida Atlantic Univ., Boca Raton, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","457","464","Due to the prevalence of high dimensionality(having a large number of independent attributes), feature selection techniques (which reduce the feature subset to amore manageable size) have become quite popular. These reduced feature subsets can help improve the performance of classification models and can also inform researchers about which features are most relevant for the problem at hand. For this latter problem, it is often most important that the features chosen are consistent even in the face of changes(perturbations) to the dataset. While previous studies have considered the problem of finding so-called ""stable"" feature selection techniques, none has examined stability across all three major categories of feature selection technique: filter-based feature rankers (which use statistical measures to assign scores to each feature), filter-based subset evaluators (which also employ statistical approaches, but consider whole feature subsets at a time), and wrapper-based subset evaluation (which also considers whole subsets, but which builds classification models to evaluate these subsets). In the present study, we use two datasets from the domain of Twitter profile mining to compare the stability of five filter-based rankers, two filter-based subset evaluators, and five wrapper-based subset evaluators. We find that the rankers are most stable, followed by the filter-based subset evaluators, with the wrappers being the least stable. We also show that the relative performance among the techniques within each group is consistent across dataset and perturbation level. However, the relative stability of the two datasets does vary between the groups, showing that the effects are more complex than simply ""one group is always more stable than another group"".","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786153","Stability;filter-based feature selection;wrapper-based feature selection","Buildings;Feature extraction;Indexes;Measurement;Stability criteria;Twitter","data mining;feature selection;information filters;pattern classification;social networking (online);statistical analysis","Twitter profile mining;classification model performance improvement;feature subset reduction;filter-based feature rankers;filter-based feature selection;filter-based subset evaluators;high-dimensional data;perturbation level;relative stability analysis;score assignment;statistical measures;wrapper-based feature selection;wrapper-based subset evaluation","","2","","28","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"eQTL Mapping Study via Regularized Sparse Canonical Correlation Analysis","M. Kang; S. Li; D. Kim; C. Liu; B. Zhang; X. Wu; J. Gao","Dept. of Comput. Sci. & Eng., Univ. of Texas at Arlington, Arlington, TX, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","129","134","While genome-wide association studies (GWAS) have focused on discovering genetic loci mapped to a disease, expression quantitative trait loci (eQTL) studies combine micro array data and provide a powerful approach. Micro arrays allow one to measure thousands of gene expressions simultaneously and the advances in eQTL studies enable one to capture the insight of the genetic architecture of gene expression. A number of multivariate methods have been recently proposed to identify genetic loci which are linked to gene expression taking into account joint effects and relationships between the units rather than the single locus alone independently. However, the previous research has limitations, such as the lack of supporting the cis/tran-eQTL model into being accepted as a general genetics model. We propose a novel regularized eQTL association mapping detection (Reg-AMADE) method. We have focused on the following three problems. First, we need to take into account co-expressed genes without using clustering or partitioning techniques, as well as detecting linkage disequilibrium and the joint effect of multiple genetic markers. Secondly, we need to build a regularized model to support the cis- and trans-eQTL model observed in most association studies. Lastly, we need to discover the significant genes underlying within diseases rather than a common component. We also propose a new simulation experiment method that implements practical situations so that the results can be evaluated in the true sense instead of the assessment with random samples generated from multivariate normal distributions that most research has mainly used. The power to detect both the joint effect and grouping effect of SNPs and gene expressions is assessed in the simulation study.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784599","Sparse Canonical Correlation Analysis;eQTL","Bioinformatics;Biological cells;Correlation;Diseases;Gene expression;Genomics","diseases;genetics;genomics;lab-on-a-chip","GWAS;Reg-AMADE method;association mapping detection;cis-eQTL model;co-expressed genes;disease;eQTL mapping;expression quantitative trait loci;gene expression;genetic loci;genome-wide association studies;linkage disequilibrium;micro array data;multiple genetic markers;regularized sparse canonical correlation analysis;trans-eQTL model","","0","","19","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Random Forest Classification for Hippocampal Segmentation in 3D MR Images","R. Maglietta; N. Amoroso; S. Bruno; A. Chincarini; G. Frisoni; P. Inglese; S. Tangaro; A. Tateo; R. Bellotti","Ist. di Studi sui Sist. Intelligenti per l'Autom., Consiglio Naz. delle Ric., Bari, Italy","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","264","267","Main goal of this paper is a detailed analysis of the performances of Random Forest algorithm in the field of automated hippocampal segmentation using 3D MR Images. Fifty-six T1-weighted whole brain MR images were included in the study, together with the related manually segmented bilateral hippocampi (mask). Firstly, the relationship between manual and automated segmentations of hippocampus was explored using a number of standard metrics. For left (right) hemisphere the Dice's coefficient obtained by RF was 70.6% (68.4%). The structural complexity of 3D MR images is twofold. The amount of voxels per image is huge and the numbers of hippocampus and background voxels are strongly imbalanced. In order to overcome these two limitations, we propose two simple strategies: one consists of filtering the input data using the logical OR of the masks of training images, followed by the RF classification task, the other is constituted by learning the RF classifier plane by plane. Using both strategies, the segmentation performances of RF improve significantly and Dice's coefficients increases up to 79.1% (77.4%) for left (right) sides.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784623","MR Images;Random Forest;hippocampal segmentation","Hippocampus;Image segmentation;Magnetic resonance imaging;Manuals;Radio frequency;Three-dimensional displays;Training","biomedical MRI;image classification;image segmentation;medical image processing","3D MR images;Dice coefficient;RF classification task;T1-weighted whole brain MR images;hippocampal segmentation;hippocampus;manually segmented bilateral hippocampi;random forest classification","","2","","20","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Intelligent Tool for ANN Based Power Factor Correction","O. Sesveren; R. Bayindir","Project for Promoting LifeLong Learning in Turkey, Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","218","223","This paper describes a case study of a power factor correction technique based on the Artificial Neural Network (ANN). In order to accelerate the training process of ANNs, four learning algorithm, Incremental Back Propagation (IBP), Batch Back Propagation (BBP), Resilient Back Propagation (RBP), and Quick Back Propagation (QBP), were modeled and software that has a graphic user interface was developed. Using the developed software, the training actions of ANNs can be performed according to the inputs. Results show that the developed software can be used as a visual educational tool for training power factor correction using a synchronous motor.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786111","Artificial neural network;Power factor correction;artificial intelligence;synchronous motor","Artificial neural networks;Power factor correction;Reactive power;Software;Synchronous motors;Topology;Training","computer aided instruction;electric machine analysis computing;graphical user interfaces;learning (artificial intelligence);neural nets;power engineering education;power factor correction;synchronous motors","ANN based power factor correction technique;BBP;IBP;QBP;RBP;artificial neural network;batch back propagation;graphic user interface;incremental back propagation;intelligent tool;learning algorithm;quick back propagation;resilient back propagation;synchronous motor;training process;visual educational tool","","0","","34","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Improving the Transcription of Academic Lectures for Information Retrieval","A. Mbogho; S. Marquard","Dept. of Comput. Sci., Univ. of Cape Town, Cape Town, South Africa","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","560","567","Recording university lectures through lecture capture systems is increasingly common, generating large amounts of audio and video data. Transcribing recordings greatly enhances their usefulness by making them easy to search. However, the number of recordings accumulates rapidly, rendering manual transcription impractical. Automatic transcription, on the other hand, suffers from low levels of accuracy, partly due to the special language of academic disciplines, which standard language models do not cover. This paper looks into the use of Wikipedia to dynamically adapt language models for scholarly speech. We propose Ranked Word Correct Rate as a new metric better aligned with the goals of improving transcript search ability and specialist word recognition. The study shows that, while overall transcription accuracy may remain low, targeted language modelling can substantially improve search ability, an important goal in its own right.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786171","","Accuracy;Adaptation models;Crawlers;Electronic publishing;Encyclopedias;Internet","Web sites;educational technology;further education;information retrieval","Wikipedia;academic disciplines;academic lecture transcription;audio data;automatic transcription;information retrieval;lecture capture systems;ranked word correct rate;search ability;standard language models;university lectures;video data;word recognition","","0","","22","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Intelligent Approach for Identifying Political Views over Social Networks","U. Yavanoglu; M. Colak; B. Caglar; S. Cakir; O. Milletsever; S. Sagiroglu","Dept. of Comput. Eng., Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","281","287","Many social network sites have been develop rapidly in recent years. Millions of people are becoming to members of these sites because of facilities provided by these networks. Thousands of people share hundred of comments, news, articles, pictures and videos to support ideas. Recent events have shown that. Users are well and quickly organized for events, demonstrations, boycotts, etc. through social networking sites accounts especially using Twitter accounts. This paper presents an intelligent solution by analysing users' information to clarify if they are supporters or anti-supporters to an event this anaylsis is based on written words or characters on tweets of Twitter accounts. The proposed method presented in this work achieves the task with 90% accuracy within test tweets. Even if the privacy concern is a hot topic in social networks, this sort of solution should provide clear vision to the users and might be used for crime analysing and predicting crime, boycotts, demonstration, events, etc.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786121","data mining;forensic;intelligent;neural network;political views;security;social network","Artificial neural networks;Data mining;Media;Training;Twitter","data mining;politics;social networking (online)","Twitter accounts;characters;data mining;intelligent approach;political views identification;social networks;user information analysis;written words","","1","","18","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Intelligent Decision Support System for Energy Investments","U. Yavanoglu; O. Kaplan; G. Tanis; H. Atli; O. Milletsever; U. Inal","Dept. of Comput. Eng., Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","224","231","In this study, Turkey's energy data were examined and decision support system was formed for Turkey. Energy is an important need for the economic development of the country. The energy requirements are increased due to population growth of Turkey. It was decided that this study is done after these requirements and Turkey energy policy were evaluated. 3 topics were discussed for the system. Natural gas, export, and transmission line length are estimated. Artificial neural network is used for energy estimation. In trainings, the energy data of Turkey Electricity Distribution Company are used. The results show that average success is 99%. This decision support system will contribute to Turkey Electricity Distribution Company.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786112","artificial neural network(ANN);energy forecast;export estimation;natural gas estimation;tranmission line length estimation","Artificial neural networks;Electricity;Natural gas;Power transmission lines;Predictive models;Production;Training","decision support systems;electricity supply industry;international trade;investment;neural nets;power transmission lines","Turkey Electricity Distribution Company;Turkey energy data;Turkey energy policy;artificial neural network;economic development;energy estimation;export estimation;intelligent decision support system;natural gas estimation;trainings;tranmission line length estimation","","1","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A New Approach to Detecting Content Anomalies in Wikipedia","D. Sinanc; U. Yavanoglu","Dept. of Comput., Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","288","293","The rapid growth of the web has caused to availability of data effective if its content is well organized. Despite the fact that Wikipedia is the biggest encyclopedia on the web, its quality is suspect due to its Open Editing Schemas (OES). In this study, zoology and botany pages are selected in English Wikipedia and their html contents are converted to text then Artificial Neural Network (ANN) is used for classification to prevent disinformation or misinformation. After the train phase, some irrelevant words added in the content about politics or terrorism in proportion to the size of the text. By the time unsuitable content is added in a page until the moderators' intervention, the proposed system realized the error via wrong categorization. The results have shown that, when words number 2% of the content is added anomaly rate begins to cross the 50% border.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786122","artificial neural networks;class mapping;data mining;open editing schemas;web classification","Artificial neural networks;Electronic publishing;Encyclopedias;Internet;Web pages","Internet;Web sites;botany;data mining;hypermedia markup languages;neural nets;pattern classification;text analysis;text editing;zoology","ANN;English Wikipedia;HTML contents;OES;Web mining techniques;anomaly rate;artificial neural network;botany pages;content anomaly detection;encyclopedia;open editing schemas;politics;terrorism;text classification;train phase;wrong categorization;zoology pages","","0","","19","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Constrained Motion Particle Swarm Optimization and Support Vector Regression for Non-linear Time Series Regression and Prediction Applications","N. I. Sapankevych; R. Sankar","Raytheon Co., St. Petersburg, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","473","477","Support Vector Regression (SVR) has been applied to many non-linear time series prediction applications [1]. There are many challenges associated with the use of SVR for non-linear time series prediction, including the selection of free parameters associated with SVR training. To optimize SVR free parameters, many different approaches have been investigated, including Particle Swarm Optimization (PSO). This paper proposes a new approach, termed Constrained Motion Particle Swarm Optimization (CMPSO), which selects SVR free parameters and solves the SVR quadratic programming (QP) problem simultaneously. To benchmark the performance of CMPSO, Mackey-Glass non-linear time series data is used for validation. Results show CMPSO performance is consistent with other time series prediction methodologies, and in some cases superior.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786155","Particle Swarm Optimization;Support Vector Regression;Time Series Regression and Prediction","Benchmark testing;Equations;Kernel;Optimization;Particle swarm optimization;Support vector machines;Time series analysis","nonlinear estimation;particle swarm optimisation;quadratic programming;regression analysis;support vector machines;time series","CMPSO;Mackey-Glass nonlinear time series data;SVR free parameter selection;SVR quadratic programming problem;SVR training;constrained motion particle swarm optimization;nonlinear time series prediction application;nonlinear time series regression application;support vector regression","","1","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Operation Planning of Hydroelectric Systems: Application of Genetic Algorithms and Differential Evolution","P. C. B. Rampazzo; A. Yamakami; F. O. D. França","Fed. Univ. of Uberlandia, Uberlandia, Brazil","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","232","237","The Operation Planning of Hydroelectric Systems is a large, dynamic, stochastic, interconnected and nonlinear optimization problem. In this model, the minimization of penalized thermal complementation is considered as the objective function with the water discharge of hydroelectric plants at each period as the decision variables. An adaptation of two Evolutionary Metaheuristics, the Genetic Algorithm and the Differential Evolution, are proposed in this paper to solve this problem. These methods consider a set of solutions in order to perform exploration and exploitation of the search space allowing them to find several good quality solutions that can serve as alternatives to a given scenario. Tests performed with the Brazilian Subsystems and compared to one of the current used approaches show that the evolutionary methods can improve current solutions and can also bring the benefit of alternative solutions.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786113","Differential Evolution;Genetic Algorithms;Hydropower Systems Operation Planning","Genetic algorithms;Mathematical model;Planning;Reservoirs;Sociology;Statistics","genetic algorithms;hydroelectric power stations;power generation planning","Brazilian subsystems;differential evolution;dynamical system;evolutionary metaheuristics;genetic algorithm;hydroelectric system operation planning;interconnected system;large-scale system;nonlinear optimization problem;stochastic system","","0","","19","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Riemannian Stopping Criterion for Unsupervised Phonetic Segmentation","C. G. Pons; X. Anguera; X. Binefa","Dept. of Inf. & Commun. Technol., Univ. Pompeu Fabra, Barcelona, Spain","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","294","298","With the availability of large and heterogeneous corpora of untranscribed speech we have recently seen regained interest for algorithms to perform automatic segmentation of such data into acoustically homogeneous or phonetic units. In this paper, we face the problem of phonetic segmentation under a hierarchical clustering (HC) framework. Concretely, we focus on the task of automatically estimating the optimum number of segments in speech data. For this purpose we present aRiemannian stopping criterion that is able to automatically stop the HC processing when it is close to the underlying number of phonetic segments while providing a lower variance(robust) estimation of the optimal number of segments. We test the proposed criterion using TIMIT data and show that it outperforms previous approaches obtaining a significantly lower over/under-segmentation variance by 46, 1% relative and average improvement of 0:14 compared to a previously proposed approach. We also show that the proposed method is robust in automatically finding the correct number of segments under data source variations.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786123","Riemannian estimator;cluster count estimation;hierarchical clustering;speech segmentation;unsupervised learning","Acoustic measurements;Acoustics;Clustering algorithms;Covariance matrices;Estimation;Robustness;Speech","acoustic signal processing;learning (artificial intelligence);pattern clustering;speech processing","HC framework;Riemannian stopping criterion;TIMIT data;acoustically homogeneous units;acoustically phonetic units;automatic data segmentation;data source variations;hierarchical clustering framework;large-heterogeneous corpora;optimal segment number;over-segmentation variance;robust variance estimation;speech data;under-segmentation variance;unsupervised phonetic segmentation;untranscribed speech","","0","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Survey of Data Cleansing and Monitoring for Large-Scale Battery Backup Installations","L. A. Pachano; T. M. Khoshgoftaar; R. Wald","Florida Atlantic Univ., Boca Raton, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","478","484","A continuous supply of electrical power is necessary for many areas of modern life, including industry, healthcare, and telecommunications. Therefore, battery backup systems, which can provide power in the event of emergencies, have become extremely important for many types of industries. Due to the importance of these systems, they are often installed and maintained by large firms dedicated to this task, but such firms then must monitor a huge number of such systems. Handling this Big Data problem requires facing two challenges: dealing with potentially noisy and erroneous data in a fashion which preserves the important information and may even help point towards repairable failures in the monitoring systems, and using the cleansed data to build models of the battery systems which will allow for prediction of their state. In this work, we survey the scope of progress in these two areas, presenting papers which have looked at the data cleansing and battery monitoring problems in the context of battery backup installations. We also consider the work which has yet been performed, areas which retain the potential for future research.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786156","Battery Backup Systems;Data Cleansing;Remote Monitoring","Batteries;Battery charge measurement;Integrated circuit modeling;Monitoring;Noise;System-on-chip;Voltage control","Big Data;back-up procedures;battery management systems;power aware computing;power supply circuits;system monitoring;system recovery","Big Data problem handling;battery backup system;battery monitoring problem;continuous electrical power supply;data cleansing;data monitoring;large-scale battery backup installations;repairable failure","","0","","19","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Artificial Neural Networks Controller Algorithm Developed for a Brushless DC Motor","I. Colak; M. Sahin; Z. Esen","Renewable Energy Res. Group - GURER, Gazi Univ., Ankara, Turkey","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","238","242","Brush less DC Motors are often preferred due to their high power/volume ratio in electrical vehicles with space constraint and need of high power and space technologies. So that, modeling, simulation and controlling of Brush less DC (BLDC) Motors should be developed for these applications. In this study, the modelling and simulation studies for a BLDC motor in MATLAB/Simulink and a controller design in the structure of ANN based control system with PID compensator are presented. Developed control algorithm is converted to C code which can be understood by standard compilers with Simulink/Target Language Compiler plugin and this code is compiled and embedded to DSPIC MCU. Simulation and test results are compared and good correlation is found between them.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786114","Brushless DC Motor;MATLAB/Simulink;Neural Networks Controller;Simulink/Target Language Compiler;dsPIC","Artificial neural networks;Brushless DC motors;Integrated circuit modeling;Mathematical model;Software packages","C language;brushless DC motors;compensation;control engineering computing;control system synthesis;machine control;neurocontrollers;program compilers;three-term control","ANN based control system;BLDC;C code;DSPIC MCU;MATLAB/Simulink;PID compensator;Simulink/Target language compiler plugin;artificial neural networks controller algorithm;brushless DC motor;controller design;power-volume ratio;space constraint","","0","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Neural Network Approach to Multi-step-ahead, Short-Term Wind Speed Forecasting","J. L. Cardenas-Barrera; J. Meng; E. Castillo-Guerra; L. Chang","Center for Studies on Electron. & Inf. Technol., Univ. Central &#x201C;Marta Abreu&#x201D; de Las Villas, Santa Clara, Cuba","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","243","248","This paper presents a novel neural network-based approach to short-term, multi-step-ahead wind speed forecasting. The methodology combines predictions from a set of feed forward neural networks whose inputs comprehend a set of 11 explanatory variables related to past averages of wind speed, direction, temperature and time of the day, and their outputs represent estimates of specific wind speed averages. Forecast horizons range from 30 minutes up to 6:30 hours ahead with 30 minutes time steps. Final forecasts at specific horizons are combinations of corresponding neural network predictions. Data used in the experiments are telemetric measurements of weather variables from five wind farms in eastern Canada, covering the period from November 2011 to April 2013. Results show that the methodology is effective and outperforms established reference models particularly at longer horizons. The method performed consistently across sites leading up to more than 60% improvement over persistence and 50 % over a more realistic MA-based reference.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786115","neural networks;short-term forecasting;wind power;wind speed forecasting","Accuracy;Forecasting;Predictive models;Training;Wind forecasting;Wind power generation;Wind speed","feedforward neural nets;geophysics computing;weather forecasting;wind power;wind power plants","day time;eastern Canada;explanatory variables;feedforward neural network-based approach;horizon forecasting;multistep-ahead short-term wind speed forecasting;telemetric measurements;weather variables;wind direction;wind farms;wind temperature","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Evaluation Study on Circuit Parameter Conditions of Neural Network Controlled DC-DC Converter","H. Maruta; M. Motomura; F. Kurokawa","Grad. Sch. of Eng., Nagasaki Univ., Nagasaki, Japan","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","249","254","This study aims to evaluate the behavior of neural network control method for digitally controlled dc-dc converters when the circuit parameter condition varies from which is in the training of the neural network. Learning based methods, which include the neural network control, are constructed and tuned using the training data to control given plants. They can provide the effective control since they are tuned as the dedicated one, however, they have difficulties when the parameters of components in the plant are changed from original ones, which are used to obtain the training data. Therefore, they may lose the effectivity in control if the the parameters in plant are changed. In the case of controlling dc-dc converters, the circuit parameter condition such as capacitance, reactor and so forth, are varied in the case that the specification of the circuit design is changed. Moreover they are changed by the environmental condition such as temperature, aging degradation and so forth. In this study, we study the effectivity of neural network control method for dc-dc converters when the circuit parameters are changed from the ones which are used in the training. When the circuit parameters are changed from original one, we evaluate that whether the neural network can control without any tuning, such as re-training of the neural network. From evaluation results, we confirm that the neural network control can work effectively even in such situation and it reveals that the neural network control has the robustness against the change of the circuit parameter condition.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786116","digitally controlled dcdc converter;neural network","Aging;Degradation;Neural networks;PD control;Table lookup;Training;Transient analysis","DC-DC power convertors;digital control;neural nets;power control;three-term control","circuit parameter conditions;digitally controlled DC DC converters;learning based methods;neural network controlled DC DC converter","","0","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Comparative Analysis of Cryptographic Algorithms and Transformation Functions for Biometric Data","I. D. L. O. Filho; O. G. R. Santiago; A. M. P. Canuto; B. R. C. Bedregal","Dept. of Inf., State Univ. of RN, Natal, Brazil","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","255","260","Currently, there is a concern about the security of biometric data in the identification systems, mainly due to the increase of fraudulent attacks in these systems. Therefore, in this paper, we propose a comparative analysis of traditional cryptographic algorithms and transformation functions to be used as biometric template protection methods in the identification systems. In this sense, we aim to contribute with new approaches to the area of information security systems. Our goal is to analyse the increase of the biometric dataset security as well as the performance of these protected dataset in the biometric-based identification systems. In this comparative analysis, we apply well-elaborated structures, called ensemble systems, as the pattern recognition structure. These systems are applied to unprotected and protected biometric dataset to measure the performance of the template protection methods and traditional cryptographic algorithms used in this work. As a result of this comparative analysis, we intend identify which methods have a good trade-off between security and accuracy.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786117","Ensemble systems;cryptosystems;trasnformation functions","Accuracy;Algorithm design and analysis;Bioinformatics;Cryptography;Standards;Support vector machines","biometrics (access control);cryptography","biometric dataset security;biometric template protection methods;biometric-based identification systems;cryptographic algorithms;ensemble systems;fraudulent attacks;information security systems;pattern recognition structure;transformation functions","","0","","24","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
