"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6620165,6618276,6617419,6617852,6617837,6618986,6613658,6578595,6609469,6606717,6610168,6608456,6608572,6609745,6604237,6602331,6603572,6603563,6602048,6603233,6597112,6597216,6597246,6595390,6588784,6521335,6583806,6582713,6579446,6578683,6579473,6578779,6575505,6574616,6573030,6336689,6567848,6563955,6560660,6555726,6556173,6557161,6557774,6558164,6551067,6551092,6531635,6549501,6550464,6550604,6547421,6548824,6542402,6544913,6493458,6531578,6531459,6530367,6520895,6515707,6526056,6524365,6523768,6524993,6484166,6519900,6497431,6513558,6512800,6511639,6509745,6510197,6510235,6510198,6507027,6497311,6505359,6506611,6505841,6505311,6503193,6505088,6495171,6495004,6494687,6405375,6493192,6405356,6493047,6249686,6481145,6483403,6480260,6479991,6481040,6375514,6461419,6472453,6471891,6423821",2017/05/04 23:36:26
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Machine learning based IP traffic classfication","Z. C. Tayşi̇; M. E. Karsligi̇l; A. G. Yavuz; R. Şahi̇n; T. Yilmaz; H. Demi̇rel","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Ak&#x0131;ll&#x0131; Sistemler Laboratuar&#x0131;, Y&#x0131;ld&#x0131;z Teknik &#x00DC;niversitesi, &#x0130;stanbul, T&#x00DC;RK&#x0130;YE","2013 21st Signal Processing and Communications Applications Conference (SIU)","20130613","2013","","","1","4","Nowadays several topics such as improving the quality of service, bandwidth utilization, and creation of different service packages, have gained importance due to widespread use of Internet. It is crucial to identify and classify protocols and applications communicating through the network in order to perform these tasks. There are three types of systems to classify protocols and applications communicating through the network, namely, port-based, payload-based and machine learning based. In this work, we focused on Instant Messaging (IM), Peer-to-peer (P2P), Social Networks, Video and Voice-over-IP (VoIP) classes which have higher importance for the Internet Service Providers. We evaluated the performance of our system with several classifiers. Random Forest classifier has had the highest success rate among others.","","Electronic:978-1-4673-5563-6; POD:978-1-4673-5562-9","10.1109/SIU.2013.6531459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531459","Classification;IP Flow;IP packet;Internet traffic;Peer-to-Peer;Random Forest;SVM;k-NN","IP networks;Instant messaging;Ports (Computers);Postal services;Protocols;Support vector machines","IP networks;Internet telephony;learning (artificial intelligence);peer-to-peer computing;quality of service","Internet service providers;P2P;VoIP;bandwidth utilization;classify protocols;instant messaging;machine learning based IP traffic classification;peer-to-peer;quality of service;random forest classifier;service package;social networks;video;voice-over-IP","","0","","13","","","24-26 April 2013","","IEEE","IEEE Conference Publications"
"Disease insights through analysis: Using machine learning to provide feedback in the MONARCA system","M. Frost; J. E. Bardram; A. Doryab","Pervasive Interaction Technology Lab, IT University of Copenhagen, Denmark","2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops","20130722","2013","","","315","316","There is currently a growing interest in personal health technologies using data collection strategies to develop context-aware systems. The insights from this data could help patients and clinicians monitor and manage mental illness. We describe our approach to support the data analysis and feedback to clinicians and patients through extending the MONARCA Self-Assessment System.","2153-1633;21531633","Electronic:978-1-936968-80-0; POD:978-1-4799-0296-5; USB:978-1-936968-79-4","10.4108/icst.pervasivehealth.2013.252071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6563955","","","data analysis;diseases;health care;learning (artificial intelligence);medical computing;mobile computing;operating systems (computers)","MONARCA Android application;MONARCA self-assessment system;context-aware system;data analysis;data collection strategy;data feedback;disease insight;machine learning;mental illness management;personal health technology","","0","","7","","","5-8 May 2013","","IEEE","IEEE Conference Publications"
"Improving network security using machine learning techniques","S. Akbar; J. A. Chandulal; K. N. Rao; G. S. Kumar","Department of Computer Science and Engineering, SVIET, Nandamuru, Andhra Pradesh, India","2012 IEEE International Conference on Computational Intelligence and Computing Research","20130502","2012","","","1","5","Discovery of malicious correlations in computer networks has been an emergent problem motivating extensive research in computer science to develop improved intrusion detecting systems (IDS). In this manuscript, we present a machine learning approach known as Decision Tree (C4.5) Algorithm and Genetic Algorithm, to classify such risky/attack type of connections. The algorithm obtains into consideration dissimilar features in network connections and to create a classification rule set. Every rule in rule set recognizes a particular attack type. For this research, we implement a GA, C.45 and educated it on the KDD Cup 99 data set to create a rule set that can be functional to the IDS to recognize and categorize dissimilar varieties of assault links. During our study, we have developed a rule set contain of six rules to classify six dissimilar attack type of connections that fall into 4 modules namely DoS, U2R, root to local and probing attacks. The rule produces works with 93.70% correctness for detecting the denial of service type of attack connections, and with significant accuracy for detecting the root to local, user to root and probe connections. Results from our experiment have given hopeful results towards applying enhanced genetic algorithm for NIDS.","","Electronic:978-1-4673-1344-5; POD:978-1-4673-1342-1","10.1109/ICCIC.2012.6510197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6510197","C4.5 Algorithm;Computer networks;Data mining;Genetic Algorithm;Intrusion Detection;KDDCup-p99","","computer network security;decision trees;genetic algorithms;learning (artificial intelligence);pattern classification","C4.5 algorithm;DoS;IDS;KDD Cup 99 data set;NIDS;U2R;assault links;classification rule set;decision tree algorithm;denial of service;genetic algorithm;intrusion detecting systems;machine learning techniques;malicious correlation dicovery;network security;probing attacks;root-local attack","","0","","10","","","18-20 Dec. 2012","","IEEE","IEEE Conference Publications"
"A 48.6-to-105.2µW machine-learning assisted cardiac sensor SoC for mobile healthcare monitoring","S. Y. Hsu; Y. Ho; P. Y. Chang; P. Y. Hsu; C. Y. Yu; Y. Tseng; T. Z. Yang; T. F. Yang; R. J. Chen; C. Su; C. Y. Lee","Dept. of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan","2013 Symposium on VLSI Circuits","20130815","2013","","","C252","C253","A machine-learning (ML) assisted cardiac sensor SoC (CS-SoC) is designed for healthcare monitoring with mobile devices. The architecture realizes the cardiac signal acquisition with versatile feature extractions and classifications, enabling higher order analysis over traditional DSPs. Besides, the dynamic standby controller further suppresses the leakage power dissipation. Implemented in 90nm CMOS, the CS-SoC dissipates 48.6/105.2μW at 0.5-1.0V for real-time arrhythmia/myocardial infarction syndrome detection with 95.8/99% accuracy.","2158-5601;21585601","Electronic:978-4-86348-348-4; POD:978-1-4673-5531-5","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578683","","Clocks;Computer architecture;Feature extraction;Medical services;Monitoring;Program processors;System-on-chip","CMOS integrated circuits;cardiology;health care;learning (artificial intelligence);medical signal processing;system-on-chip","CMOS;CS-SoC;arrhythmia infarction syndrome detection;cardiac sensor SoC;cardiac signal acquisition;dynamic standby controller;feature classification;feature extraction;leakage power dissipation;machine-learning;mobile device;mobile healthcare monitoring;myocardial infarction syndrome detection;power 48.6 muW to 105.2 muW;size 90 nm;voltage 0.5 V to 1.0 V","","2","","8","","","12-14 June 2013","","IEEE","IEEE Conference Publications"
"Online Learning Control Using Adaptive Critic Designs With Sparse Kernel Machines","X. Xu; Z. Hou; C. Lian; H. He","College of Mechatronics and Automation, National University of Defense Technology, Changsha, China","IEEE Transactions on Neural Networks and Learning Systems","20130311","2013","24","5","762","775","In the past decade, adaptive critic designs (ACDs), including heuristic dynamic programming (HDP), dual heuristic programming (DHP), and their action-dependent ones, have been widely studied to realize online learning control of dynamical systems. However, because neural networks with manually designed features are commonly used to deal with continuous state and action spaces, the generalization capability and learning efficiency of previous ACDs still need to be improved. In this paper, a novel framework of ACDs with sparse kernel machines is presented by integrating kernel methods into the critic of ACDs. To improve the generalization capability as well as the computational efficiency of kernel machines, a sparsification method based on the approximately linear dependence analysis is used. Using the sparse kernel machines, two kernel-based ACD algorithms, that is, kernel HDP (KHDP) and kernel DHP (KDHP), are proposed and their performance is analyzed both theoretically and empirically. Because of the representation learning and generalization capability of sparse kernel machines, KHDP and KDHP can obtain much better performance than previous HDP and DHP with manually designed neural networks. Simulation and experimental results of two nonlinear control problems, that is, a continuous-action inverted pendulum problem and a ball and plate control problem, demonstrate the effectiveness of the proposed kernel ACD methods.","2162-237X;2162237X","","10.1109/TNNLS.2012.2236354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461419","Adaptive critic designs;Markov decision processes;approximate dynamic programming;kernel machines;learning control;reinforcement learning","Approximation algorithms;Approximation methods;Dictionaries;Kernel;Learning systems;Machine learning;Vectors","adaptive control;approximation theory;dynamic programming;generalisation (artificial intelligence);heuristic programming;learning (artificial intelligence);learning systems;nonlinear control systems;sparse matrices","KDHP;KHDP;adaptive critic designs;approximately linear dependence analysis;ball-and-plate control problem;computational efficiency improvement;continuous action space;continuous state space;continuous-action inverted pendulum problem;dual-heuristic programming;dynamical system online learning control;generalization capability improvement;heuristic dynamic programming;kernel DHP;kernel HDP;kernel-based ACD algorithms;learning efficiency improvement;nonlinear control problems;representation learning;sparse kernel machines;sparsification method","1","47","","48","","20130213","May 2013","","IEEE","IEEE Journals & Magazines"
"Using Multiclass Machine Learning Methods to Classify Malicious Behaviors Aimed at Web Systems","K. Goseva-Popstojanova; G. Anastasovski; R. Pantev","Lane Dept. of Comput. Sci. & Electr. Eng., West Virginia Univ., Morgantown, WV, USA","2012 IEEE 23rd International Symposium on Software Reliability Engineering","20130404","2012","","","81","90","The number of vulnerabilities and attacks on Web systems show an increasing trend and tend to dominate on the Internet. Furthermore, due to their popularity and users ability to create content, Web 2.0 applications have become particularly attractive targets. These trends clearly illustrate the need for better understanding of malicious cyber activities based on both qualitative and quantitative analysis. This paper is focused on multiclass classification of malicious Web activities using three supervised machine learning methods: J48, PART, and Support Vector Machines (SVM). The empirical analysis is based on data collected in duration of nine months by a high interaction honey pot consisting of a three-tier Web system, which included Web 2.0 applications (i.e., a blog and wiki). Our results show that supervised learning methods can be used to efficiently distinguish among multiple vulnerability scan and attack classes, with high recall and precision values for all but several very small classes. For our dataset, decision tree based methods J48 and PART perform slightly better than SVM in terms of overall accuracy and weighted recall. Additionally, J48 and PART require less than half of the features (i.e., session attributes) used by SVM, as well as they execute much faster. Therefore, they seem to be clear methods of choice.","1071-9458;10719458","Electronic:978-0-7695-4888-3; POD:978-1-4673-4638-2","10.1109/ISSRE.2012.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405356","Web 2.0 security;attacks;empirical study;multiclass classification;vulnerability scans","Accuracy;Blogs;Electronic publishing;Information services;Internet;Learning systems;Support vector machines","Internet;learning (artificial intelligence);pattern classification;security of data;support vector machines","Internet;J48;PART;SVM;Web 2.0 applications;attack classes;high-interaction honeypot;malicious behavior classification;malicious cyber activities;multiclass machine learning methods;multiclass malicious Web activities classification;qualitative analysis;quantitative analysis;supervised machine learning methods;support vector machines;three-tier Web system","","4","","34","","","27-30 Nov. 2012","","IEEE","IEEE Conference Publications"
"Automotive diagnosis typo correction using domain knowledge and machine learning","Y. Huang; Y. L. Murphey; Y. Ge","Electrical and Computer Engineering, University of Michigan - Dearborn, 4901 Evergreen Rd., 48128, USA","2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)","20130916","2013","","","267","274","Text description of engineering diagnoses recorded during and after vehicle repair process plays an important role in root cause analyzing and vehicle maintenance. The fact that such text is unstructured, lack of grammar, has a lot of spelling errors and a large amount of self-invented domain specific terminologies introduces challenges and difficulties for automatic information retrieving and categorization. This paper presents our research in text mining in vehicle diagnostic applications. Specifically, an automatic typo correction system is proposed and implemented. We build multiple knowledge bases to detect and correct typos, and a neural network classifier to select good candidates for correcting typos. Experiment results show that our system outperforms state-of-art spell checking systems.","","Electronic:978-1-4673-5895-8; POD:978-1-4673-5894-1","10.1109/CIDM.2013.6597246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597246","Typo correction;domain knowledge;neural learning;text mining;vehicle diagnosis","Computational intelligence;Dictionaries;Knowledge based systems;Text mining;Text processing;Vehicles","automobiles;information retrieval;learning (artificial intelligence);neural nets;text analysis;traffic engineering computing","automatic information retrieval;automotive diagnosis typo correction;domain knowledge;engineering diagnoses;information categorization;machine learning;multiple knowledge bases;neural network classifier;root cause;self-invented domain specific terminologies;spell checking systems;text description;vehicle maintenance;vehicle repair process","","1","","22","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"A Fault Classification and Localization Method for Three-Terminal Circuits Using Machine Learning","H. Livani; C. Y. Evrenosoğlu","Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, USA","IEEE Transactions on Power Delivery","20130930","2013","28","4","2282","2290","This paper presents a traveling-wave-based method for fault classification and localization for three-terminal power transmission systems. In the proposed method, the discrete wavelet transform is utilized to extract transient information from the recorded voltages. Support-vector-machine classifiers are then used to classify the fault type and faulty line/half in the transmission networks. Bewley diagrams are observed for the traveling-wave patterns and the wavelet coefficients of the aerial mode voltage are used to locate the fault. Alternate Transients Program software is used for transients simulations. The performance of the method is tested for different fault inception angles, different fault resistances, nonlinear high impedance faults, and nontypical faults with satisfactory results.","0885-8977;08858977","","10.1109/TPWRD.2013.2272936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578595","Fault classification;fault location;support vector machine (SVM);three-terminal network;traveling waves;wavelet transformation","Circuit faults;Discrete wavelet transforms;Fault location;Machine learning;Power transmission;Support vector machines;Transient analysis","discrete wavelet transforms;learning (artificial intelligence);pattern classification;power system simulation;power system transients;power transmission faults;support vector machines","Bewley diagram;aerial mode voltage;alternate transients program software;discrete wavelet transform;fault classification method;fault inception angle;fault resistance;localization method;machine learning;nonlinear high impedance fault;support-vector-machine classifier;three-terminal circuit;three-terminal power transmission system;transient information extraction;traveling-wave-based method;voltage recording","","13","","32","","20130815","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Static prediction of recursion frequency using machine learning to enable hot spot optimizations","D. Tetzlaff; S. Glesner","Technische Universit&#x00E4;t Berlin, Chair Software Engineering for Embedded Systems, Ernst-Reuter-Platz 7, 10587 Berlin, Germany","2012 IEEE 10th Symposium on Embedded Systems for Real-time Multimedia","20130425","2012","","","42","51","Recursion poses a severe problem for static optimizations because its execution frequency usually depends upon runtime values, hence being rarely predictable at compile time. As a consequence, optimization potential of programs is sacrificed since possible hot paths where most of the execution time is spent and where optimization would be beneficial might be undiscovered. In this paper, we propose a sophisticated machine learning based approach to statically predict the recursion frequency of functions for programs in real-world application domains, which can be used to guide various hot spot optimizations. Our experiments with 369 programs of 25 benchmark suites from different domains demonstrate that our approach is applicable to a wide range of programs with different behavior and yields more precise heuristics than those generated by pure static analyses. Moreover, our results provide valuable insights into recursive structures in general, when they appear and how deep they are.","","Electronic:978-1-4673-4967-3; POD:978-1-4673-4968-0","10.1109/ESTIMedia.2012.6507027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6507027","","","learning (artificial intelligence);optimisation;program diagnostics","hot paths;hot spot optimizations;machine learning based approach;pure static analyses;real-world application domains;recursion frequency;static prediction","","1","","49","","","11-12 Oct. 2012","","IEEE","IEEE Conference Publications"
"Difficulties in choosing a single final classifier from non-dominated solutions in multiobjective fuzzy genetics-based machine learning","H. Ishibuchi; Y. Nojima","Department of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan","2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)","20130926","2013","","","1203","1208","A large number of non-dominated fuzzy rule-based classifiers are often obtained by applying a multiobjective fuzzy genetics-based machine learning (MoFGBML) algorithm to a pattern classification problem. The obtained set of non-dominated classifiers can be used to analyze their accuracy-interpretability tradeoff relation. One important issue, which has not been discussed in many studies on MoFGBML, is the choice of a single final classifier from a large number of non-dominated classifiers. The selected classifier is used for the classification of new input patterns. In this paper, we focus on this important research issue: classifier selection from a large number of non-dominated fuzzy rule-based classifiers. In general, it is not easy to choose a single final solution from non-dominated solutions in multiobjective optimization. This is because further information on the decision maker's preference is needed to choose the single final solution. In addition to this general difficulty in multiobjective optimization, MoFGBML has its own difficulty in classifier selection, which is the difference between training data accuracy and test data accuracy. While our true objective is to maximize the test data accuracy (i.e., classifier's generalization ability), only the training data accuracy is available for fitness evaluation and classifier selection. In this paper, we discuss why classifier selection is difficult in MoFGBML.","","Electronic:978-1-4799-0348-1; POD:978-1-4799-0346-7; USB:978-1-4799-0347-4","10.1109/IFSA-NAFIPS.2013.6608572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6608572","","Accuracy;Classification algorithms;Complexity theory;Error analysis;Fuzzy sets;Search problems;Training data","fuzzy set theory;genetic algorithms;knowledge based systems;learning (artificial intelligence);pattern classification","MoFGBML algorithm;accuracy-interpretability tradeoff relation;classifier selection;decision maker preference;fitness evaluation;multiobjective fuzzy genetics-based machine learning;multiobjective optimization;nondominated classifier;nondominated fuzzy rule-based classifiers;nondominated solutions;pattern classification problem;single final classifier;test data accuracy;training data accuracy","","0","","30","","","24-28 June 2013","","IEEE","IEEE Conference Publications"
"Machine learning of engineering diagnostic knowledge from unstructured verbatim text descriptions","Yinghao Huang; Y. L. Murphey; Yao Ge","Dept. of Electrical and Computer Engineering, University of Michigan-Dearborn, 48128, USA","2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)","20130916","2013","","","46","52","This paper presents our research in text mining for discovering important engineering fault diagnostic knowledge from unstructured and verbatim text descriptions. In particular we focus on developing machine learning algorithms for detecting documents that contain descriptions of systematic failures and root causes to the faults. We developed a machine algorithm based on entropy analysis to extract an A-word list, a list of words that are important to characterize the documents of interests, a vector space model to represent features of important documents, and a constraint based k-means clustering algorithm to generate high purity clusters for use in detecting important documents. We applied the algorithms to automotive diagnostic text data, which are unstructured and verbatim descriptions by customers and technicians that contain many typos and self-invented terms. We were able to reduce a list of 2183 words to a list of 137 important words. The classification system generated by these machine learning algorithms showed high recall and accuracy in detecting important diagnostic descriptions.","","Electronic:978-1-4673-5895-8; POD:978-1-4673-5894-1","10.1109/CIDM.2013.6597216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597216","engineering diagnostics;important document detection;machine learning;text mining","Automotive engineering;Clustering algorithms;Entropy;Machine learning algorithms;Training data;Vectors;Vehicles","automotive engineering;data mining;entropy;failure analysis;fault diagnosis;learning (artificial intelligence);pattern clustering;text analysis;word processing","A-word list extraction;automotive diagnostic text data;classification system;constraint based k-means clustering algorithm;document detection;engineering diagnostic knowledge;engineering fault diagnostic knowledge;entropy analysis;machine algorithm;machine learning algorithms;systematic failures;text mining;unstructured verbatim text descriptions;vector space model","","1","","15","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Automated method for extraction of lung tumors using a machine learning classifier with knowledge of radiation oncologists on data sets of planning CT and FDG-PET/CT images","H. Arimura; Z. Jin; Y. Shioyama; K. Nakamura; T. Magome; M. Sasaki","Dept. of Health Sci., Kyushu Univ., Fukuoka, Japan","2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20130926","2013","","","2988","2991","We have developed an automated method for extraction of lung tumors using a machine learning classifier with knowledge of radiation oncologists on data sets of treatment planning computed tomography (CT) and 18F-fluorodeoxyglucose (FDG)-positron emission tomography (PET)/CT images. First, the PET images were registered with the treatment planning CT images through the diagnostic CT images of PET/CT. Second, six voxel-based features including voxel values and magnitudes of image gradient vectors were derived from each voxel in the planning CT and PET /CT image data sets. Finally, lung tumors were extracted by using a support vector machine (SVM), which learned 6 voxel-based features inside and outside each true tumor region determined by radiation oncologists. The results showed that the average DSCs for 3 and 6 features for three cases were 0.744 and 0.899, and thus the SVM may need 6 features to learn the distinguishable characteristics. The proposed method may be useful for assisting treatment planners in delineation of the tumor region.","1094-687X;1094687X","Electronic:978-1-4577-0216-7; POD:978-1-4577-0215-0; USB:978-1-4577-0214-3","10.1109/EMBC.2013.6610168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6610168","","Computed tomography;Image segmentation;Lungs;Planning;Positron emission tomography;Support vector machines;Tumors","computerised tomography;gradient methods;learning (artificial intelligence);lung;medical image processing;positron emission tomography;support vector machines;tumours","18F-fluorodeoxyglucose;FDG-PET/CT images;SVM;diagnostic CT image;image gradient vector;lung tumor;machine learning classifier;positron emission tomography;radiation oncologist;support vector machine;treatment planning computed tomography;voxel-based feature","","0","","18","","","3-7 July 2013","","IEEE","IEEE Conference Publications"
"User Modeling on Communication Characteristics Using Machine Learning in Computer-Supported Collaborative Multiple Language Learning","M. Virvou; E. Alepis; C. Troussas","Dept. of Inf., Univ. of Piraeus, Piraeus, Greece","2012 IEEE 24th International Conference on Tools with Artificial Intelligence","20130411","2012","1","","1088","1093","Towards the creation of a multiple language learning environment which supports and enhances collaboration among its students we propose an approach that uses user modeling and machine learning. The well known theory of user modeling is used to collect user characteristics and as second step a classical machine learning approach is incorporated in order to intelligently use these characteristics to create student groups. The resulting student groups promote win-win collaboration, thus support the learning process and provide additional educational benefits for the learners.","1082-3409;10823409","Electronic:978-0-7695-4915-6; POD:978-1-4799-0227-9","10.1109/ICTAI.2012.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6495171","computer-supported collaborative learning;k-means algorithm;machine learning;multiple language learning;user modeling","Artificial intelligence;Clustering algorithms;Collaboration;Collaborative work;Computational modeling;Computer architecture;Servers","groupware;intelligent tutoring systems;learning (artificial intelligence);user modelling","communication characteristics;computer-supported collaborative multiple language learning environment;educational benefit;intelligent tutoring system;learning process;machine learning;student group;user characteristics;user modeling;win-win collaboration","","0","","20","","","7-9 Nov. 2012","","IEEE","IEEE Conference Publications"
"Radio frequency interference identification and mitigation in pulsar observations using machine learning techniques","M. McCarty; G. Doran; T. J. W. Lazio; D. R. Thompson; J. Ford; R. Prestage","National Radio Astronomy Observatory, Green Bank, WV, 24944, USA","2013 US National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)","20130606","2013","","","1","1","Summary form only given. Pulsar observations with the Robert C. Byrd Green Bank Telescope (GBT), located in Green Bank, WV, aid researchers in understanding the basic building blocks of our existence - matter, energy, space, and time - and how they behave under extreme physical conditions. Pulsars, rapidly rotating neutron stars with clock-like timing precision, can provide insights into a rich variety of physics and astrophysics.","","Electronic:978-1-4673-4778-5; POD:978-1-4673-4776-1","10.1109/USNC-URSI-NRSM.2013.6524993","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6524993","","Bandwidth;Green products;Laboratories;Propulsion;Radiofrequency interference;Timing;Training data","astronomy computing;learning (artificial intelligence);neutron stars;pulsars;radiofrequency interference;radiotelescopes","GBT;Green Bank;West Virginia;astrophysics;clock-like timing precision;green bank telescope;machine learning technique;pulsar observation;radio frequency interference identification;radio frequency interference mitigation;rapidly rotating neutron stars","","0","","","","","9-12 Jan. 2013","","IEEE","IEEE Conference Publications"
"Modern Machine Learning Techniques","J. Yu; D. Tao","","Modern Machine Learning Techniques and Their Applications in Cartoon Animation Research","20130424","2013","","","63","104","This chapter contains sections titled: <br> A Unified Framework for Manifold Learning <br> Spectral Clustering and Graph Cut <br> Ensemble Manifold Learning <br> Multiple Kernel Learning <br> Multiview Subspace Learning <br> Multiview Distance Metric Learning <br> Multi-Task Learning <br> Chapter Summary","","97811185599","10.1002/9781118559963.ch2","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6497311.pdf&bkn=6497234&pdfType=chapter","","","","","","","","","2013","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Framework for image retrieval using machine learning and statistical similarity matching techniques","M. Fakheri; T. Sedghi; M. G. Shayesteh; M. C. Amirani","Department of Electrical Engineering, Urmia University, Urmia, Iran","IET Image Processing","20130307","2013","7","1","1","11","The aim of this study is to take advantage of both shape and texture properties of image to improve the performance of image indexing and retrieval algorithm. Further, a framework for partitioning image into non-overlapping tiles of different sizes, which results in higher retrieval efficiency, is presented. In the new approach, the image is divided into different regions (tiles). Then, the energy and standard deviation of Hartley transform coefficients of each tile, which serve as the local descriptors of texture, are extracted as sub-features. Next, invariant moments of edge image are used to record the shape features. The shape features and combination of sub-features of texture provide a robust feature set for image retrieval. The most similar highest priority (MSHP) principle is used for matching of textural features and Canberra distance is utilised for shape features matching. The retrieved image is the image which has less MSHP and Canberra distance from the query image. The proposed method is evaluated on three different image sets, which contain about 17 000 images. The experimental results indicate that the proposed method achieves higher retrieval accuracy than several previously presented schemes, whereas the computational complexity and processing time of the new method are less than those of other approaches.","1751-9659;17519659","","10.1049/iet-ipr.2012.0104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6471891","","","Hartley transforms;computational complexity;image matching;image retrieval;image texture;learning (artificial intelligence)","Hartley transform coefficients;MSHP;computational complexity;image indexing;image retrieval algorithm;machine learning;most similar highest priority principle;nonoverlapping tiles;partitioning image;processing time;query image;retrieval efficiency;shape properties;statistical similarity matching techniques;texture properties","","4","","","","","February 2013","","IET","IET Journals & Magazines"
"Machine Learning Paradigms for Speech Recognition: An Overview","L. Deng; X. Li","Microsoft Research, Redmond","IEEE Transactions on Audio, Speech, and Language Processing","20130225","2013","21","5","1060","1089","Automatic Speech Recognition (ASR) has historically been a driving force behind many machine learning (ML) techniques, including the ubiquitously used hidden Markov model, discriminative learning, structured sequence learning, Bayesian learning, and adaptive learning. Moreover, ML can and occasionally does use ASR as a large-scale, realistic application to rigorously test the effectiveness of a given technique, and to inspire new problems arising from the inherently sequential and dynamic nature of speech. On the other hand, even though ASR is available commercially for some applications, it is largely an unsolved problem - for almost all applications, the performance of ASR is not on par with human performance. New insight from modern ML methodology shows great promise to advance the state-of-the-art in ASR technology. This overview article provides readers with an overview of modern ML techniques as utilized in the current and as relevant to future ASR research and systems. The intent is to foster further cross-pollination between the ML and ASR communities than has occurred in the past. The article is organized according to the major ML paradigms that are either popular already or have potential for making significant contributions to ASR technology. The paradigms presented and elaborated in this overview include: generative and discriminative learning; supervised, unsupervised, semi-supervised, and active learning; adaptive and multi-task learning; and Bayesian learning. These learning paradigms are motivated and discussed in the context of ASR technology and applications. We finally present and analyze recent developments of deep learning and learning with sparse representations, focusing on their direct relevance to advancing ASR technology.","1558-7916;15587916","","10.1109/TASL.2013.2244083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6423821","Bayesian;Machine learning;adaptive;deep learning;discriminative;dynamics;generative;speech recognition;super vised;unsupervised","Acoustics;Bayesian methods;Machine learning;Speech processing;Speech recognition;Training","hidden Markov models;learning (artificial intelligence);speech recognition","ASR communities;ASR research;ASR systems;Bayesian learning;active learning;adaptive learning;automatic speech recognition;cross-pollination;discriminative learning;generative learning;hidden Markov model;machine learning paradigms;machine learning techniques;multitask learning;overview;semisupervised learning;structured sequence learning;supervised learning;unsupervised learning","","41","","273","","20130130","May 2013","","IEEE","IEEE Journals & Magazines"
"The machine learning classifier based on Multi-Objective Genetic Algorithm","Zhou Litao; Wang Tiejun; Jiang Xi; Jin Jin","Science Technology and Information & Communication, Department, Sichuan Electric Power Corporation, Chengdu, China","2012 7th International Conference on Computing and Convergence Technology (ICCCT)","20130613","2012","","","405","409","This paper presents a machine learning classifier algorithm based on MOGA (Multi-Objective Genetic Algorithm), which applies the information entropy theory to optimize the MOGA and then can be used to discretize the continuous attributes. According to the practical problems, the fitness vector can be constructed by judging multi-objective functions to find the Pareto optimal solutions. Combining the classic set theories with the two relationships, i.e. coverage and contradictory, between chromosomes, more reasonable selection rules can be worked out to delete the redundant chromosomes and get more efficient classification rules. The new algorithm was applied to Iris and Wine dataset from UCI. By comparison, the algorithm in this paper has higher classification accuracy than KNN, C4.5 and NaiveBayes.","","Electronic:978-89-94364-22-3; POD:978-1-4673-0894-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6530367","Delete Rule;Discrete;Learning Classifier;MOGA;Multi-Objective;Pareto Optimization","","entropy;genetic algorithms;learning (artificial intelligence);pattern classification;set theory;vectors","Iris and Wine dataset;MOGA;Pareto optimal solutions;UCI;chromosomes;classic set theories;classification accuracy;classification rules;continuous attributes;fitness vector;information entropy theory;machine learning classifier algorithm;multiobjective functions;multiobjective genetic algorithm;redundant chromosomes;selection rules","","0","","9","","","3-5 Dec. 2012","","IEEE","IEEE Conference Publications"
"Osteoporosis risk prediction using machine learning and conventional methods","S. K. Kim; T. K. Yoo; E. Oh; D. W. Kim","Graduate Program in Biomedical Engineering, Yonsei University, Seoul, Korea","2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20130926","2013","","","188","191","A number of clinical decision tools for osteoporosis risk assessment have been developed to select postmenopausal women for the measurement of bone mineral density. We developed and validated machine learning models with the aim of more accurately identifying the risk of osteoporosis in postmenopausal women, and compared with the ability of a conventional clinical decision tool, osteoporosis self-assessment tool (OST). We collected medical records from Korean postmenopausal women based on the Korea National Health and Nutrition Surveys (KNHANES V-1). The training data set was used to construct models based on popular machine learning algorithms such as support vector machines (SVM), random forests (RF), artificial neural networks (ANN), and logistic regression (LR) based on various predictors associated with low bone density. The learning models were compared with OST. SVM had significantly better area under the curve (AUC) of the receiver operating characteristic (ROC) than ANN, LR, and OST. Validation on the test set showed that SVM predicted osteoporosis risk with an AUC of 0.827, accuracy of 76.7%, sensitivity of 77.8%, and specificity of 76.0%. We were the first to perform comparisons of the performance of osteoporosis prediction between the machine learning and conventional methods using population-based epidemiological data. The machine learning methods may be effective tools for identifying postmenopausal women at high risk for osteoporosis.","1094-687X;1094687X","Electronic:978-1-4577-0216-7; POD:978-1-4577-0215-0; USB:978-1-4577-0214-3","10.1109/EMBC.2013.6609469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6609469","","Accuracy;Artificial neural networks;Learning systems;Osteoporosis;Predictive models;Radio frequency;Support vector machines","biomedical measurement;bone;diseases;learning (artificial intelligence);neurophysiology;orthopaedics;regression analysis;risk management;sensitivity analysis;support vector machines","ROC;SVM;artificial neural networks;bone mineral density measurement;clinical decision tools;conventional methods;logistic regression;low bone density;machine learning models;medical records;osteoporosis risk assessment;osteoporosis risk prediction;osteoporosis self-assessment tool;population-based epidemiological data;postmenopausal women;random forests;receiver operating characteristic;support vector machines;training data set","","1","","18","","","3-7 July 2013","","IEEE","IEEE Conference Publications"
"Signal Processing and Machine Learning with Differential Privacy: Algorithms and Challenges for Continuous Data","A. D. Sarwate; K. Chaudhuri","Toyota Technological Institute at Chicago, 60637, Illinois United States","IEEE Signal Processing Magazine","20130819","2013","30","5","86","94","Private companies, government entities, and institutions such as hospitals routinely gather vast amounts of digitized personal information about the individuals who are their customers, clients, or patients. Much of this information is private or sensitive, and a key technological challenge for the future is how to design systems and processing techniques for drawing inferences from this large-scale data while maintaining the privacy and security of the data and individual identities. Individuals are often willing to share data, especially for purposes such as public health, but they expect that their identity or the fact of their participation will not be disclosed. In recent years, there have been a number of privacy models and privacy-preserving data analysis algorithms to answer these challenges. In this article, we will describe the progress made on differentially private machine learning and signal processing.","1053-5888;10535888","","10.1109/MSP.2013.2259911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6582713","","Approximation methods;Computer security;Data privacy;Noise measurement;Privacy;Signal processing algorithms","data analysis;data privacy;learning (artificial intelligence);security of data;signal processing","continuous data;data privacy;data security;differential privacy;digitized personal information;government entities;large-scale data;privacy models;privacy-preserving data analysis algorithms;private companies;private information;processing techniques;sensitive information;signal processing","","12","","61","","","Sept. 2013","","IEEE","IEEE Journals & Magazines"
"Sparse fuzzy techniques improve machine learning","R. Sanchez; C. Servin; M. Argaez","Computational Science Program, University of Texas at El Paso, 500 W. University, 79968, USA","2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)","20130926","2013","","","531","535","On the example of diagnosing cancer based on the microarray gene expression data, we show that fuzzy-technique description of imprecise knowledge can improve the efficiency of the existing machine learning algorithms. Specifically, we show that the fuzzy-technique description leads to a formulation of the learning problem as a problem of sparse optimization, and we use l1-techniques to solve the resulting optimization problem.","","Electronic:978-1-4799-0348-1; POD:978-1-4799-0346-7; USB:978-1-4799-0347-4","10.1109/IFSA-NAFIPS.2013.6608456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6608456","","Cancer;Educational institutions;Gene expression;Optimization;Support vector machines;Tumors;Vectors","cancer;fuzzy set theory;genetics;learning (artificial intelligence);optimisation;patient diagnosis","cancer diagnosis;fuzzy-technique description;imprecise knowledge;l<sub>1</sub>-techniques;learning problem;machine learning algorithms;microarray gene expression data;optimization problem;sparse fuzzy techniques;sparse optimization","","0","","11","","","24-28 June 2013","","IEEE","IEEE Conference Publications"
"Increasing anomaly handling efficiency in large organizations using applied machine learning","L. Jonsson","Ericsson AB and Link&#x00F6;ping University, Sweden","2013 35th International Conference on Software Engineering (ICSE)","20130926","2013","","","1361","1364","Maintenance costs can be substantial for large organizations (several hundreds of programmers) with very large and complex software systems. By large we mean lines of code in the range of hundreds of thousands or millions. Our research objective is to improve the process of handling anomaly reports for large organizations. Specifically, we are addressing the problem of the manual, laborious and time consuming process of assigning anomaly reports to the correct design teams and the related issue of localizing faults in the system architecture. In large organizations, with complex systems, this is particularly problematic because the receiver of an anomaly report may not have detailed knowledge of the whole system. As a consequence, anomaly reports may be assigned to the wrong team in the organization, causing delays and unnecessary work. We have so far developed two machine learning prototypes to validate our approach. The latest, a re-implementation and extension, of the first is being evaluated on four large systems at Ericsson AB. Our main goal is to investigate how large software development organizations can significantly improve development efficiency by replacing manual anomaly report assignment and fault localization with machine learning techniques. Our approach focuses on training machine learning systems on anomaly report databases; this is in contrast to many other approaches that are based on test case execution combined with program sampling and/or source code analysis.","0270-5257;02705257","Electronic:978-1-4673-3076-3; POD:978-1-4673-3075-6","10.1109/ICSE.2013.6606717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606717","Anomaly Handling;Automatic Fault Localization;Bug Assignment;Large Software Systems;Machine Learning;Ontologies;Stacked generalization","Accuracy;Databases;Ontologies;Organizations;Routing;Semantics;Software","learning (artificial intelligence);organisational aspects;program testing;software architecture;software development management;software fault tolerance;software maintenance;source coding","anomaly handling efficiency;anomaly report database;complex software system;fault localization;machine learning;manual anomaly report assignment;program sampling;software development efficiency;software development organization;software maintenance;source code analysis;system architecture;test case execution;training","","0","","17","","","18-26 May 2013","","IEEE","IEEE Conference Publications"
"A machine learning framework for space medicine predictive diagnostics with physiological signals","N. Wang; M. R. Lyu; C. Yang","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","2013 IEEE Aerospace Conference","20130513","2013","","","1","12","Prognostics and health management (PHM) in the context of space missions focuses on the fundamental issues of system failures in an attempt to predict when the failures may occur, and links these issues to system life cycle management. Space missions that are targeting for aerospace exploration or aviation also pose great challenges on the health conditions of people involved, such like astronauts, crew members, aviators, etc. Considering the inherent risks of space missions and the difficulty of direct communications between crew and ground support medical specialists, we see that greater autonomy in medical operations for crew is required. Namely, there is an urgent call for an effective onboard medical system to predict and prevent health problems in a timely manner, rather than following reactive approaches which are inherent to conventional medicine.","1095-323X;1095323X","Electronic:978-1-4673-1813-6; POD:978-1-4673-1812-9","10.1109/AERO.2013.6497431","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6497431","","Diseases;Electroencephalography;Epilepsy;Feature extraction;Frequency modulation;Medical diagnostic imaging;Sleep","","","","1","","44","","","2-9 March 2013","","IEEE","IEEE Conference Publications"
"Dhaka stock market timing decisions by hybrid machine learning technique","S. Banik; A. F. M. K. Khan; M. Anwer","School of Engineering and Computer Science, Independent University, Bangladesh, Dhaka, Bangladesh","2012 15th International Conference on Computer and Information Technology (ICCIT)","20130502","2012","","","384","389","Stock market prediction has been a challenging task due to the nature of the data which is very noisy and time varying. However, this theory has been faced by many empirical studies and a number of researchers have successfully applied machine learning approaches to predict stock market. The problem studied here is about stock prediction for the use of investors. It is true investors usually get loss because of unclear investment objective and blind investment. This paper proposes to investigate the rough set model, the artificial neural network model and the hybrid artificial neural network model and the rough set model for determining the optimal buy and sell of a share on a Dhaka stock exchange. Confusion matrix is used to evaluate the performance of the observed and predicted classes for selected models. Our experimental result shows that the proposed hybrid model has higher accuracy than the single rough set model and the artificial neural network model. We believe this paper will be useful to stock investors to determine the optimal buy and sell time on Dhaka Stock Exchange.","","Electronic:978-1-4673-4836-2; POD:978-1-4673-4833-1","10.1109/ICCITechn.2012.6509745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509745","Confusion matrix;Hybrid machine learning;Neural network;Rough set;Stock market prediction;Technical indicators","","decision making;investment;learning (artificial intelligence);neural nets;rough set theory;stock markets","Dhaka stock exchange;Dhaka stock market timing decision;blind investment;confusion matrix;hybrid artificial neural network model;hybrid machine learning;optimal buy and sell;rough set model;stock investors;stock market prediction","","2","","16","","","22-24 Dec. 2012","","IEEE","IEEE Conference Publications"
"Machine Learning with Brain Graphs: Predictive Modeling Approaches for Functional Imaging in Systems Neuroscience","J. Richiardi; S. Achard; H. Bunke; D. Van De Ville","Institue of Bioengineering, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland","IEEE Signal Processing Magazine","20130405","2013","30","3","58","70","The observation and description of the living brain has attracted a lot of research over the past centuries. Many noninvasive imaging modalities have been developed, such as topographical techniques based on the electromagnetic field potential [i.e., electroencephalography (EEG) and magnetoencephalography (MEG)], and tomography approaches including positron emission tomography and magnetic resonance imaging (MRI). Here we will focus on functional MRI (fMRI) since it is widely deployed for clinical and cognitive neurosciences today, and it can reveal brain function due to neurovascular coupling (see ?From Brain Images to fMRI Time Series?). It has led to a much better understanding of brain function, including the description of brain areas with very specialized functions such as face recognition. These neuroscientific insights have been made possible by important methodological advances in MR physics, signal processing, and mathematical modeling.","1053-5888;10535888","","10.1109/MSP.2012.2233865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6494687","","Adaptation models;Biomedical image processing;Brain modeling;Complex networks;Electroencephalography;Learning systems;Machine learning;Magnetoencephalography;Neuroscience;Predictive modeling","biomedical MRI;brain;cognition;graph theory;learning (artificial intelligence);medical image processing;neurophysiology","EEG;MEG;MR physics;brain area description;brain function;brain graphs;clinical neurosciences;cognitive neurosciences;electroencephalography;electromagnetic field potential;fMRI;functional MRI;functional imaging;living brain description;machine learning;magnetic resonance imaging;magnetoencephalography;mathematical modeling;neurovascular coupling;noninvasive imaging modalities;positron emission tomography;predictive modeling approach;signal processing;system neuroscience;tomography approach;topographical techniques","","27","","","","","May 2013","","IEEE","IEEE Journals & Magazines"
"An Empirical Study of Bugs in Machine Learning Systems","F. Thung; S. Wang; D. Lo; L. Jiang","Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore","2012 IEEE 23rd International Symposium on Software Reliability Engineering","20130404","2012","","","271","280","Many machine learning systems that include various data mining, information retrieval, and natural language processing code and libraries are used in real world applications. Search engines, internet advertising systems, product recommendation systems are sample users of these algorithm-intensive code and libraries. Machine learning code and toolkits have also been used in many recent studies on software mining and analytics that aim to automate various software engineering tasks. With the increasing number of important applications of machine learning systems, the reliability of such systems is also becoming increasingly important. A necessary step for ensuring reliability of such systems is to understand the features and characteristics of bugs occurred in the systems. A number of studies have investigated bugs and fixes in various software systems, but none focuses on machine learning systems. Machine learning systems are unique due to their algorithm-intensive nature and applications to potentially large-scale data, and thus deserve a special consideration. In this study, we fill the research gap by performing an empirical study on the bugs in machine learning systems. We analyze three systems, Apache Mahout, Lucene, and OpenNLP, which are data mining, information retrieval, and natural language processing tools respectively. We look into their bug databases and code repositories, analyze a sample set of bugs and corresponding fixes, and label the bugs into various categories. Our study finds that 22.6% of the bugs belong to the algorithm/method category, 15.6% of the bugs belong to the non-functional category, and 13% of the bugs belong to the assignment/initialization category. We also report the relationship between bug categories and bug severities, the time and effort needed to fix the bugs, and bug impacts. We highlight several bug categories that deserve attention in future research.","1071-9458;10719458","Electronic:978-0-7695-4888-3; POD:978-1-4673-4638-2","10.1109/ISSRE.2012.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405375","","Software reliability","data mining;information retrieval;learning (artificial intelligence);natural language processing;program debugging;software reliability","Apache Mahout;Internet advertising systems;Lucene;OpenNLP;algorithm-intensive code;algorithm-intensive nature;bug categories;bug databases;code repositories;data mining;information retrieval;machine learning systems;natural language processing code;recommendation systems;search engines;software engineering tasks;software mining;system reliability","","9","","42","","","27-30 Nov. 2012","","IEEE","IEEE Conference Publications"
"Non-destructive Quality Analysis of Kamod Oryza Sativa SSP Indica (Indian Rice) Using Machine Learning Technique","V. Shah; K. Jain; C. V. Maheshwari","G.H. Patel Coll. of Eng. & Tech, Vidyanagar, India","2013 International Conference on Communication Systems and Network Technologies","20130610","2013","","","95","99","Rice is one of the most important cereal grains. The paper presents a solution for quality evaluation and grading of Krishna Kamod rice using image processing and soft computing technique. In this paper basic problem of rice industry for quality assessment is defined which is traditionally done manually by human inspector. Machine vision provides one alternative for an automated, non-destructive and cost-effective technique. The proposed method for quality assessment of INDIAN KAMOD ORYZA SATIVA SSP INDICA (Krishna Kamod Rice) using image processing and multi-layer feed forward neural network technique which achieves high degree of quality than human vision inspection. The proposed algorithm based on morphological features is developed for counting the number of Krishna Kamod rice seeds with long seeds as well as small seeds. A trained multi-layer feed forward neural network based classifier is developed for identification of unknown rice seed quality.","","Electronic:978-1-4673-5603-9; POD:978-1-4799-1710-5","10.1109/CSNT.2013.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6524365","Computer vision;ISEF edge detection;Image processing;Morphological features;Oryza sativa L. (rice Seeds);Quality;Soft computing","Computer vision;Feeds;Image edge detection;Industries;Machine vision;Neural networks","computer vision;crops;learning (artificial intelligence);multilayer perceptrons;nondestructive testing;quality control","Indian rice;Kamod Oryza Sativa SSP Indica;Krishna Kamod Rice;cereal grains;cost-effective technique;human inspector;human vision inspection;image processing;machine learning technique;machine vision;morphological features;multilayer feed forward neural network technique;nondestructive quality analysis;nondestructive technique;quality assessment;quality evaluation;rice industry;rice seed quality;soft computing technique","","1","","15","","","6-8 April 2013","","IEEE","IEEE Conference Publications"
"An efficient comparative machine learning-based metagenomics binning technique via using Random forest","H. Saghir; D. B. Megherbi","Center for Human/Machine Intelligence, Networking and Distributed Systems, Department of Electrical and Computer Engineering, University of Massachusetts, Lowell, USA","2013 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)","20131003","2013","","","191","196","Metagenomics is the study of microorganisms collected directly from natural environments. Metagenomics studies use DNA fragments obtained directly from a natural environment using whole genome shotgun (WGS) sequencing. Sequencing random fragments obtained from whole genome shotgun into taxa-based groups is known as binning. Currently, there are two different methods of binning: sequence similarity methods and sequence composition methods. Sequence similarity methods are usually based on sequence alignment to known genome like BLAST, or MEGAN. As only a very small fraction of species is available in the current databases, similarity methods do not yield good results. As a given database of organisms grows, the complexity of the search will also grow. Sequence composition methods are based on compositional features of a given DNA sequence like K-mers, or other genomic signature(s). Most of these current methods for binning have two major issues: they do not work well with short sequences and closely related genomes. In this paper we propose new machine learning related predictive DNA sequence feature selection algorithms to solve binning problems in more accurate and efficient ways. In this work we use Oligonucleotide frequencies from 2-mers to 4-mers as features to differentiate between sequences. 2-mers produces 16 features, 3-mers produces 64 features and 4-mers produces 256 features. We did not use feature higher than 4-mers as the number of feature increases exponentially and for 5-mers the number of feature would be 1024 features. We found out that the 4-mers produces better results than 2-mers and 3-mers. The data used in this work has an average length of 250, 500, 1000, and 2000 base pairs. Experimental results of the proposed algorithms are presented to show the potential value of the proposed methods. The proposed algorithm accuracy is tested on a variety of data sets and the classification/prediction accuracy achieved is between 78% - 99% for various simu- ated data sets using Random forest classifier and 37% - 95% using Naïve Bayes classifier. Random forest Classifier did better in classification in all the dataset compared to Naïve Bayes.","2377-9314;23779314","Electronic:978-1-4673-4703-7; POD:978-1-4673-4702-0","10.1109/CIVEMSA.2013.6617419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617419","Binning;Bioinformatics;Computational intelligence;Machine learning;Metagenomics;Next generation Sequencing;Pattern Classification;Random forest;Reduction methods;bagged decision tree;forwaord sequential feature selection;ttest","Accuracy;Bioinformatics;Classification algorithms;DNA;Genomics;Organisms;Sequential analysis","DNA;bioinformatics;computational complexity;feature extraction;genomics;learning (artificial intelligence);microorganisms;pattern classification;search problems","DNA fragments;Naive Bayes classifier;WGS sequencing;bioinformatics;comparative machine learning-based metagenomics binning technique;microorganisms;natural environments;oligonucleotide frequencies;prediction accuracy;predictive DNA sequence feature selection algorithms;random forest classifier;random fragments;search complexity;sequence composition method;sequence similarity method;taxa-based groups;whole genome shotgun sequencing","","1","","27","","","15-17 July 2013","","IEEE","IEEE Conference Publications"
"A no-reference machine learning based video quality predictor","M. Shahid; A. Rossholm; B. Lövström","Department of Electrical Engineering, Blekinge Institute of Technology, SE-37179 Karlskrona, Sweden","2013 Fifth International Workshop on Quality of Multimedia Experience (QoMEX)","20130919","2013","","","176","181","The growing need of quick and online estimation of video quality necessitates the study of new frontiers in the area of no-reference visual quality assessment. Bitstream-layer model based video quality predictors use certain visual quality relevant features from the encoded video bitstream to estimate the quality. Contemporary techniques vary in the number and nature of features employed and the use of prediction model. This paper proposes a prediction model with a concise set of bitstream based features and a machine learning based quality predictor. Several full reference quality metrics are predicted using the proposed model with reasonably good levels of accuracy, monotonicity and consistency.","","Electronic:978-1-4799-0738-0; POD:978-1-4799-0737-3","10.1109/QoMEX.2013.6603233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603233","Bitstream Features;H.264/AVC;No-Reference;Support Vector Machine;Video Quality","Artificial neural networks;Encoding;Measurement;Predictive models;Quality assessment;Video recording;Video sequences","video coding","H.264/AVC;bitstream based features;bitstream-layer model;contemporary techniques;full reference quality metrics;no-reference machine learning based video quality predictor model;no-reference visual quality assessment;online video quality estimation","","2","","23","","","3-5 July 2013","","IEEE","IEEE Conference Publications"
"Performance Evaluation of South Esk Hydrological Sensor Web: Unsupervised Machine Learning and Semantic Linked Data Approach","R. Dutta; A. Morshed","Intelligent Sensing and Systems Laboratory, CSIRO, Hobart, Australia","IEEE Sensors Journal","20130828","2013","13","10","3806","3815","Technological progress has lead the sensor network domain to an era where environmental and agricultural domain applications are completely dependent on hydrological sensor networks. Data from the sensor networks are being used for knowledge management and critical decision support system. The quality of data can, however, vary widely. Existing automated quality assurance approach based on simple threshold rulebase could potentially miss serious errors requiring robust and complex domain knowledge to identify. This paper proposes a linked data concept, unsupervised pattern recognition, and semantic ontologies based dynamic framework to assess the reliability of hydrological sensor network and evaluate the performance of the sensor network. Newly designed framework is used successfully to evaluate the South Esk hydrological sensor web in Tasmania, indicating that domain ontology based linked data approach could be a very useful methodology for quality assurance of the complex data.","1530-437X;1530437X","","10.1109/JSEN.2013.2264666","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6521335","Linked data;linked open data cloud;ontology;performance map;principal component analysis;resource description framework;sensor network;unsupervised clustering","","agriculture;decision support systems;distributed sensors;environmental factors;environmental science computing;geophysics computing;hydrological techniques;knowledge engineering;learning (artificial intelligence);ontologies (artificial intelligence);pattern recognition;semantic Web","South Esk hydrological sensor web;Tasmania;agricultural domain applications;automated quality assurance approach;critical decision support system;data quality;dynamic framework;environmental domain applications;hydrological sensor network reliability;hydrological sensor networks;knowledge management;linked data concept;performance evaluation;semantic linked data approach;semantic ontologies;sensor network data;sensor network domain;threshold rulebase;unsupervised machine learning;unsupervised pattern recognition","","5","","33","","20130529","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"A Machine Learning Approach to Software Requirements Prioritization","A. Perini; A. Susi; P. Avesani","Fondazione Bruno Kessler. CIT - IRST, Trento","IEEE Transactions on Software Engineering","20130326","2013","39","4","445","461","Deciding which, among a set of requirements, are to be considered first and in which order is a strategic process in software development. This task is commonly referred to as requirements prioritization. This paper describes a requirements prioritization method called Case-Based Ranking (CBRank), which combines project's stakeholders preferences with requirements ordering approximations computed through machine learning techniques, bringing promising advantages. First, the human effort to input preference information can be reduced, while preserving the accuracy of the final ranking estimates. Second, domain knowledge encoded as partial order relations defined over the requirement attributes can be exploited, thus supporting an adaptive elicitation process. The techniques CBRank rests on and the associated prioritization process are detailed. Empirical evaluations of properties of CBRank are performed on simulated data and compared with a state-of-the-art prioritization method, providing evidence of the method ability to support the management of the tradeoff between elicitation effort and ranking accuracy and to exploit domain knowledge. A case study on a real software project complements these experimental measurements. Finally, a positioning of CBRank with respect to state-of-the-art requirements prioritization methods is proposed, together with a discussion of benefits and limits of the method.","0098-5589;00985589","","10.1109/TSE.2012.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249686","Requirements management;machine learning;requirements prioritization","Accuracy;Approximation methods;Boosting;Data models;Humans;Software","","","","20","","42","","20120726","April 2013","","IEEE","IEEE Journals & Magazines"
"Improving genetic programming based symbolic regression using deterministic machine learning","I. Icke; J. C. Bongard","Morphology, Evolution and Cognition Lab., Department of Computer Science, University of Vermont, Burlington, 05401, USA","2013 IEEE Congress on Evolutionary Computation","20130715","2013","","","1763","1770","Symbolic regression (SR) is a well studied method in genetic programming (GP) for discovering free-form mathematical models from observed data. However, it has not been widely accepted as a standard data science tool. The reluctance is in part due to the hard to analyze random nature of GP and scalability issues. On the other hand, most popular deterministic regression algorithms were designed to generate linear models and therefore lack the flexibility of GP based SR (GP-SR). Our hypothesis is that hybridizing these two techniques will create a synergy between the GP-SR and deterministic approaches to machine learning, which might help bring the GP based techniques closer to the realm of big learning. In this paper, we show that a hybrid deterministic/GP-SR algorithm outperforms GP-SR alone and the state-of-the-art deterministic regression technique alone on a set of multivariate polynomial symbolic regression tasks as the system to be modeled becomes more multivariate.","1089-778X;1089778X","Electronic:978-1-4799-0454-9; POD:978-1-4799-0453-2","10.1109/CEC.2013.6557774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6557774","elastic net;hybrid algorithms;regularization;symbolic regression","Buildings;Data models;Feature extraction;Input variables;Polynomials;Standards;Syntactics","deterministic algorithms;genetic algorithms;learning (artificial intelligence);polynomials;regression analysis;symbol manipulation","big learning;deterministic machine learning;deterministic regression algorithms;free-form mathematical model discovery;hybrid deterministic-GP-SR algorithm;improved genetic programming-based symbolic regression;linear models;multivariate polynomial symbolic regression tasks;scalability issues","","7","","26","","","20-23 June 2013","","IEEE","IEEE Conference Publications"
"Mathematical models for machine learning and pattern recognition","D. Bouchoffra; F. Ykhlef","Design and Implementation of Intelligent Machines Division (DIIM) Centre de D&#x00E9;veloppement des Technologies Avanc&#x00E9;es Algiers, Algeria","2013 8th International Workshop on Systems, Signal Processing and their Applications (WoSSPA)","20130919","2013","","","27","30","In this tutorial, we provide an in depth analysis of some important issues within the field of Machine Learning and Pattern Recognition. We intend to reflect recent developments and provide a comprehensive introduction to some fundamental issues pertaining to the field of machine learning and pattern recognition. We target advanced undergraduates or first year Ph.D. students as well as researchers and practitioners. The mathematical models covered during this tutorial include Machine Learning for Pattern Recognition, Hidden Markov Models and feature space Dimensionality Reduction. MATLAB projects are provided as experiments to the theory covered.","","Electronic:978-1-4673-5540-7; POD:978-1-4673-5539-1; USB:978-1-4673-5538-4","10.1109/WoSSPA.2013.6602331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6602331","","Conferences;Decision support systems;Signal processing","feature extraction;hidden Markov models;learning (artificial intelligence);mathematics computing;pattern recognition","MATLAB projects;feature space dimensionality reduction;fundamental issues;hidden Markov models;machine learning;mathematical models;pattern recognition","","0","","9","","","12-15 May 2013","","IEEE","IEEE Conference Publications"
"A statistical machine learning based modeling and exploration framework for run-time cross-stack energy optimization","C. Zhang; A. Ravindran","Department of Electrical and Computer Engineering, University of North Carolina at Charlotte, USA","2013 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)","20130715","2013","","","136","137","As the complexity of many-core processors grow, meeting performance, energy, temperature, reliability, and noise requirements under dynamically changing operating conditions requires run-time optimization of all parts of the computing stack - architecture, system software, and applications. Unfortunately, the combination of design parameters for the entire computing stack results in an operating space of millions of points that must be explored and evaluated at run-time. In this paper, we present a statistical machine learning (SML) based modeling framework that can be used to rapidly explore such vast operating spaces. We construct a multivariate adaptive regression spline (MARS) based model that uses a number of architecture and application parameters as predictor variables to predict performance and power. We then use a Pareto-front exploring evolutionary algorithm to determine operating points for optimal power and performance. The operating points constituting the Pareto front are stored in look-up tables for runtime use. The proposed framework is applied to an ×264 video encoding application executing on a quad core processor. The microarchitectural predictor variables include core and cache parameters. The application predictor variables include the video resolution, and visual quality determined by the choice of the motion estimation algorithm. The model outputs the average frames per second (FPS) and the average power consumption. The MARS model has an R<sup>2</sup> of 0.9657 and 0.9467 respectively for FPS and power. For a video frame resolution of 480x320, and FPS of 20, a power saving of 55% can be obtained by jointly tuning the microarchitectural parameters and the visual quality.","","Electronic:978-1-4673-5779-1; POD:978-1-4673-5776-0","10.1109/ISPASS.2013.6557161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6557161","cross stack;energy;modeling;optimization;run-time","Adaptation models;Benchmark testing;Measurement;Microarchitecture;Pareto optimization;Power demand;Visualization","Pareto optimisation;cache storage;computer architecture;evolutionary computation;image resolution;learning (artificial intelligence);motion estimation;multiprocessing systems;power aware computing;regression analysis;splines (mathematics);statistical analysis;video coding","MARS;Pareto-front exploring evolutionary algorithm;SML;average frames-per-second;average power consumption;cache parameters;computing stack-architecture;core parameters;energy requirement;look-up tables;many-core processor complexity;microarchitectural predictor variables;motion estimation algorithm;multivariate adaptive regression spline based model;noise requirement;performance prediction;performance requirement;power prediction;predictor variables;quad core processor;reliability requirement;run-time cross-stack energy optimization;run-time optimization;statistical machine learning based exploration framework;statistical machine learning based modeling framework;system software;temperature requirement;video encoding application;video resolution;visual quality","","0","","6","","","21-23 April 2013","","IEEE","IEEE Conference Publications"
"Applying machine learning classifiers to dynamic Android malware detection at scale","B. Amos; H. Turner; J. White","Dept. of Electrical and Computer Engineering, Virginia Tech, Blacksburg, USA","2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)","20130822","2013","","","1666","1671","The widespread adoption and contextually sensitive nature of smartphone devices has increased concerns over smartphone malware. Machine learning classifiers are a current method for detecting malicious applications on smartphone systems. This paper presents the evaluation of a number of existing classifiers, using a dataset containing thousands of real (i.e. not synthetic) applications. We also present our STREAM framework, which was developed to enable rapid large-scale validation of mobile malware machine learning classifiers.","2376-6492;23766492","Electronic:978-1-4673-2480-9; POD:978-1-4673-2479-3; USB:978-1-4673-2478-6","10.1109/IWCMC.2013.6583806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583806","IDS;anomaly detection;data collection;machine learning;mobile computing;smartphones","Androids;Humanoid robots;Malware;Mobile communication;Testing;Training;Vectors","invasive software;learning (artificial intelligence);mobile computing;pattern classification;smart phones","STREAM framework;dynamic Android malware detection;machine learning classifiers;malicious applications;mobile malware machine learning classifiers;rapid large-scale validation;smartphone devices;smartphone malware","","21","","30","","","1-5 July 2013","","IEEE","IEEE Conference Publications"
"The application of machine learning to the problem of classifying voxels in X-ray microtomographic scans of mineralogical samples","W. J. Shipman; A. L. Nel; D. Chetty; J. D. Miller; C. L. Lin","Department of Electrical and Electronic Engineering Science, University of Johannesburg, South Africa","2013 IEEE International Conference on Industrial Technology (ICIT)","20130422","2013","","","1184","1189","Processing X-ray microtomography scans of ore samples to extract quantitative mineralogical information regarding composition, porosity and particle size is complicated by the presence of noise in the tomograms and artefacts resulting from non-ideal scanning conditions. In order to obtain quantitative information, one must first classify voxels into their different mineral classes. This paper presents work done using fuzzy inference systems to learn the classification rules for identifying different mineral classes in the tomogram. The advantages and disadvantages of this method are discussed.","","Electronic:978-1-4673-4569-9; POD:978-1-4673-4567-5","10.1109/ICIT.2013.6505841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6505841","Fuzzy logic;Image classification;Image processing;Machine learning;Pattern analysis;X-ray tomography","Anisotropic magnetoresistance;Attenuation;Histograms;Minerals;Solids;Training","X-ray microscopy;fuzzy reasoning;geophysical image processing;image classification;minerals;particle size;porosity","X-ray microtomographic scans;artefacts;classification rule learning;fuzzy inference systems;machine learning;mineral class identification;mineralogical samples;nonideal scanning conditions;ore composition;ore particle size;ore porosity;ore samples;quantitative mineralogical information extraction;tomograms;voxel classification","","0","","28","","","25-28 Feb. 2013","","IEEE","IEEE Conference Publications"
"Machine learning for digital pulse shape discrimination","T. S. Sanderson; C. D. Scott; M. Flaska; J. K. Polack; S. A. Pozzi","University of Michigan, Dept. of Electrical Engineering and Computational Science, Ann Arbor, 48109, USA","2012 IEEE Nuclear Science Symposium and Medical Imaging Conference Record (NSS/MIC)","20130708","2012","","","199","202","Accurate discrimination of neutrons and gamma rays is critical for organic scintillation detectors, especially for detection systems where minimal false-alarm rates are paramount (nuclear non-proliferation). Poor pulse shape discrimination (PSD) necessitates long measurement times, and may also cause inaccurate characterization of emitted neutrons, leading to source misidentification. Digital, data-acquisition, measurement systems using a charge-integration PSD method are commonly used for particle classification. A 2-D, charge-integration PSD method tends to be reasonably accurate, although the separation is typically poor at lower energies (below - 500-keV neutron energy deposited). The charge-integration method originated in analog systems; however, with digital measurement systems there is no need to restrict to only two features (for instance, tail and total integrals) of the pulse. Instead, a classifier may be a much more complex function of the measured pulse. In this work, we apply a machine-learning methodology; namely, the support vector machine (SVM), to determine a PSD classifier. We show that the SVM method leads to improved detection performance with respect to the charge-integration method. We also apply a recently developed methodology that gives more accurate performance estimates by accounting for the fact that the training data needed for the SVM are 'contaminated'.","1082-3654;10823654","DVD:978-1-4673-2029-0; Electronic:978-1-4673-2030-6; POD:978-1-4673-2028-3","10.1109/NSSMIC.2012.6551092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6551092","","","data acquisition;gamma-ray detection;measurement systems;neutron detection;scintillation counters;support vector machines","2D charge-integration pulse shape discrimination method;analog systems;detection systems;digital data-acquisition measurement systems;digital measurement systems;digital pulse shape discrimination;gamma ray discrimination;improved detection performance;long measurement times;machine-learning methodology;minimal false-alarm rates;neutron discrimination;neutron energy;nuclear nonproliferation;organic scintillation detectors;performance estimates;pulse shape discrimination classifier;source misidentification;support vector machine method;training data","","3","","8","","","Oct. 27 2012-Nov. 3 2012","","IEEE","IEEE Conference Publications"
"Machine learning on Big Data","T. Condie; P. Mineiro; N. Polyzotis; M. Weimer","Cloud and Information Services Lab, Microsoft One Microsoft Way, Redmond, USA","2013 IEEE 29th International Conference on Data Engineering (ICDE)","20130624","2013","","","1242","1244","Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research.","1063-6382;10636382","Electronic:978-1-4673-4910-9; POD:978-1-4673-4909-3","10.1109/ICDE.2013.6544913","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6544913","","Big data;Communities;Computational modeling;Databases;Machine learning algorithms;Seminars;Tutorials","data analysis;learning (artificial intelligence)","big data;cross fertilizing research;database;neural networks;phase transition;pure academic endeavor;quality modeling;statistical machine learning;tera scale learning;tutorial","","4","","18","","","8-12 April 2013","","IEEE","IEEE Conference Publications"
"Machine learning based posture estimation for a wireless canine machine interface","R. Brugarolas; D. Roberts; B. Sherman; A. Bozkurt","Electr. & Comput. Eng., North Carolina State Univ., Raleigh, NC, USA","2013 IEEE Topical Conference on Biomedical Wireless Technologies, Networks, and Sensing Systems","20130930","2013","","","10","12","Effective training and accurate interpretation of canine behaviors are essential for dog welfare and to obtain the maximum benefits provided by working dogs. We are developing a canine body area network based interface to incorporate electronic sensing and computational behavior modeling into canine training, where computers will be able to provide real time feedback to trainers about canine behavior. In this study, we investigated the accuracy of machine learning algorithms in identifying canine posture through wireless inertial sensing with 3-axis accelerometers and 3-axis gyroscopes. Data was collected from two dogs performing a sequence of 5 postures (sit, stand, lie, stand on two legs, and eat off the ground). A two-stage cascade learning technique was used: one for differentiating samples of behaviors of interest from transitions between behaviors, and one for posture classification of the behaviors. The algorithms achieved high posture classification accuracies demonstrating potential to enable a real time canine computer interface.","","Electronic:978-1-4673-2958-3; POD:978-1-4673-2957-6","10.1109/BioWireleSS.2013.6613658","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613658","Cascade learning;animal machine interfaces;body area network;canine training;inertial measurement units","Accuracy;Classification algorithms;Dogs;Gyroscopes;Machine learning algorithms;Sensors;Training","accelerometers;body area networks;computer based training;gyroscopes;learning (artificial intelligence);network interfaces;pose estimation","3-axis accelerometers;3-axis gyroscopes;behavior posture classification;canine behavior interpretation;canine body area network based interface;canine training;computational behavior modeling;dog welfare;electronic sensing;machine learning algorithms;machine learning based posture estimation;real time canine computer interface;real time feedback;two-stage cascade learning technique;wireless canine machine interface;wireless inertial sensing","","4","","6","","","20-23 Jan. 2013","","IEEE","IEEE Conference Publications"
"Virtual screening using machine learning approach","D. Kumar; A. Sarvate; S. Singh; P. Priya","School of SBST, VIT University, India","2013 IEEE Conference on Information & Communication Technologies","20130715","2013","","","594","599","In this study, potential inhibitors against Harpin protein (Pectobacterium carotovorum), and Single- stranded DNA binding protein (Pseudomonas aeruginosa) is to be found. Modelled 3-D structure of target protein and their newly designed leads (inhibitors) are used for molecular docking studies using Hex 5.1. For machine learning approach, three data sets of leads are to be formed i.e. training, dependent test and independent test and their respective physiological descriptors are identified. For virtual screening of these leads RapidMiner 5.2.002 will be used. The support vector machine (SVM) application of this software (LibSVM), is used to make a model of training data set which will further be used to check the activity of the test data set. After this, the active leads will be considered as potential inhibitors against our target proteins. This study can thereby serve as pharmacophore for the designing of potential drugs against diseases.","","Electronic:978-1-4673-5758-6; POD:978-1-4673-5759-3","10.1109/CICT.2013.6558164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6558164","Harpin;Hex 5.1;LibSVM;RapidMiner 5.2.002;SVM;dependent test;independent test;pharmacophores;training test","Communications technology;Conferences;DNA;Drugs;Educational institutions;Proteins;Training","DNA;computer graphics;diseases;drugs;learning (artificial intelligence);pharmaceutical technology;proteins;support vector machines","Harpin protein;LibSVM;Pectobacterium carotovorum;Pseudomonas aeruginosa;RapidMiner 5.2.002;SVM application;diseases;machine learning;molecular docking;pharmacophore;physiological descriptors;potential drugs;protein 3D structure;single stranded DNA binding protein;support vector machine;test data set;training data set;virtual screening","","1","","10","","","11-12 April 2013","","IEEE","IEEE Conference Publications"
"Assessment of machine learning algorithms in cloud computing frameworks","K. Li; C. Gibson; D. Ho; Q. Zhou; J. Kim; O. Buhisi; D. E. Brown; M. Gerber","Univ. of Virginia, USA","2013 IEEE Systems and Information Engineering Design Symposium","20130701","2013","","","98","103","In the past decade, digitization of information has led to a data explosion in both volume and complexity. While traditional computing frameworks have failed to provide adequate computing power for the now common data-intensive computing tasks, cloud computing provides an effective alternative to enhance computing power. Machine learning algorithms are powerful analytical methods that allow machines to recognize patterns and facilitate human learning. However, the performance of individual machine learning algorithms within each cloud computing framework remains largely unknown. Furthermore, the lack of a robust selection methodology matching input data with effective machine learning algorithms limits the ability of practitioners to make effective use of cloud computing. This research compares various machine learning algorithms on the widely adopted Apache Mahout framework and the recently introduced GraphLab framework. Whereas previous work has examined the computational architectures of various cloud computing frameworks, this work focuses on a problem-based approach to architecture selection. The experimental results demonstrate that GraphLab generally outperforms Mahout with respect to runtime, scalability, and usability. However, Mahout outperforms GraphLab when the experiment focus shifts to error measurement.","","Electronic:978-1-4673-5663-3; POD:978-1-4673-5662-6","10.1109/SIEDS.2013.6549501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549501","","Cloud computing;Machine learning algorithms;Measurement uncertainty;Runtime;Scalability;Twitter","cloud computing;learning (artificial intelligence);pattern matching","GraphLab framework;cloud computing;computational architecture;data explosion;data intensive computing;data matching;error measurement;human learning;information digitization;machine learning algorithm assessment;pattern recognition;problem-based approach","","2","","23","","","26-26 April 2013","","IEEE","IEEE Conference Publications"
"Machine learning approach to an otoneurological classification problem","H. Joutsijoki; K. Varpa; K. Iltanen; M. Juhola","Sch. of Inf. Sci., Univ. of Tampere, Tampere, Finland","2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20130926","2013","","","1294","1297","In this paper we applied altogether 13 classification methods to otoneurological disease classification. The main point was to use Half-Against-Half (HAH) architecture in classification. HAH structure was used with Support Vector Machines (SVMs), k-Nearest Neighbour (k-NN) method and Naïve Bayes (NB) methods. Furthermore, Multinomial Logistic Regression (MNLR) was tested for the dataset. HAH-SVM with the linear kernel achieved clearly the best accuracy being 76.9% which was a good result with the dataset tested. From the other classification methods HAH-k-NN with cityblock metric, HAH-NB and MNLR methods achieved above 60% accuracy. Around 77% accuracy is a good result compared to previous researches with the same dataset.","1094-687X;1094687X","Electronic:978-1-4577-0216-7; POD:978-1-4577-0215-0; USB:978-1-4577-0214-3","10.1109/EMBC.2013.6609745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6609745","","Accuracy;Diseases;Educational institutions;Kernel;Niobium;Polynomials;Support vector machines","Bayes methods;diseases;learning (artificial intelligence);medical diagnostic computing;neurophysiology;pattern classification;regression analysis;support vector machines","Naive Bayes methods;half-against-half architecture;k-nearest neighbour method;linear kernel;machine learning approach;multinomial logistic regression;otoneurological disease classification;support vector machines","","0","","17","","","3-7 July 2013","","IEEE","IEEE Conference Publications"
"Savant: Automatic parallelization of a scheduling heuristic with machine learning","F. Pinel; P. Bouvry; B. Dorronsoro; S. U. Khan","FSTC/CSC/ILIAS, University of Luxembourg, Luxembourg","2013 World Congress on Nature and Biologically Inspired Computing","20131003","2013","","","52","57","This paper investigates the automatic parallelization of a heuristic for an NP-complete problem, with machine learning. The objective is to automatically design a new concurrent algorithm that finds solutions of comparable quality to the original heuristic. Our approach, called Savant, is inspired from the Savant syndrome. Its concurrency model is based on map-reduce. The approach is evaluated with the well-known Min-Min heuristic. Simulation results on two problem sizes are promising, the produced algorithm is able to find solutions of comparable quality.","","Electronic:978-1-4799-1415-9; POD:978-1-4799-1413-5","10.1109/NaBIC.2013.6617837","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617837","Conversion from sequential to parallel forms;Parallelism and concurrency;Pattern matching","Power capacitors","learning (artificial intelligence);optimisation;parallel algorithms;parallelising compilers;scheduling","NP-complete problem;Savant syndrome;automatic parallelization;concurrency model;concurrent algorithm;machine learning;map-reduce;min-min heuristic;scheduling heuristic","","1","","34","","","12-14 Aug. 2013","","IEEE","IEEE Conference Publications"
"Data Mining and Support Vector Regression Machine Learning in Semiconductor Manufacturing to Improve Virtual Metrology","B. Lenz; B. Barak","","2013 46th Hawaii International Conference on System Sciences","20130318","2013","","","3447","3456","Advanced Process Control is an important research area in Semiconductor Manufacturing to improve process stability crucial for product quality. Especially in low-volume-high-mixture fabrication plants, knowledge discovery in databases is extremely challenging due to complex technology mixtures and reduced availability of data for comparable process steps. Thus, actual research focuses on Data Mining using Machine Learning methods to model unknown functional interrelations. High Density Plasma Chemical Vapor Deposition appears to be a process area in semiconductor manufacturing predestinated for application of Data Mining. Promising results have been achieved by implementing statistical models to predict the thickness of dielectric layers deposited onto a metallization layer of the manufactured wafer. This paper describes the approach to predict the layer thickness using a state-of-the-art Machine Learning regression algorithm: Support Vector Regression. The recent extension of Support Vector Machines overcomes pure classification and deals with multivariate nonlinear input data for regression.","1530-1605;15301605","Electronic:978-1-5090-5646-0; POD:978-1-4673-5933-7; USB:978-0-7695-4892-0","10.1109/HICSS.2013.163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6480260","Chemical Vapor Deposition;Data Mining;Feature Selection;Generic Data Mining System;Knowledge Discovery in Databases;Machine Learning;Semiconductor Manufacturing;Support Vector Regression;Virtual Metrology","Manufacturing;Metrology;Optimization;Prediction algorithms;Process control;Semiconductor device measurement;Support vector machines","","","","6","","19","","","7-10 Jan. 2013","","IEEE","IEEE Conference Publications"
"Fault diagnosis in electric drives using machine learning approaches","A. A. Silva; A. M. Bazzi; S. Gupta","Laboratory of Intelligent Networks and Knowledge-Perception Systems (LINKS), Booth Engineering Center for Advanced Technology (BECAT), University of Connecticut, Storrs, USA","2013 International Electric Machines & Drives Conference","20130715","2013","","","722","726","This paper applies machine learning techniques to fault diagnosis in electric motor drives. As faults in motor drives can cause safety hazards in applications such as electric traction, propulsion, aircraft, and others, it is desired to diagnose the fault, i.e., detect it and isolate it, in order to recover or engage safe-mode operation. Machine learning methods are divided into three main steps: 1) Feature extraction using Principal Component Analysis (PCA); 2) Classification using the k-Nearest Neighbor (k-NN) or Probabilistic Neural Network (PNN) methods; and 3) Classifier performance evaluation using the Cross-Validation (CV) method. While electric machine, inverter, and sensor faults are introduced, the supervised learning algorithms are applied to four case studies where two fault modes occur in a current sensor, and two occur in the speed encoder. Classification accuracy, i.e., the ability to diagnose a fault, for all four cases is shown to exceed 98%. The paper also investigates a load profile used in automotive driving cycles which produces richer dynamic responses that are more interesting from an application perspective. The final goal is to implement these algorithms in real-time such that fault diagnosis can be used to isolate drive faults, especially sensor faults, and operate in a safe mode.","","Electronic:978-1-4673-4974-1; POD:978-1-4673-4975-8; USB:978-1-4673-4973-4","10.1109/IEMDC.2013.6556173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6556173","","Circuit faults;Fault diagnosis;Induction motor drives;Power electronics;Principal component analysis;Rotors","dynamic response;electrical safety;fault diagnosis;hazards;invertors;learning (artificial intelligence);motor drives;neural nets;power engineering computing;principal component analysis","CV method;PCA;PNN method;aircraft;automotive driving cycle;classifier performance evaluation;cross-validation method;current sensor fault;dynamic response;electric machine;electric motor drive;electric propulsion;electric traction;fault diagnosis;feature extraction;inverter;k-NN method;k-Nearest Neighbor method;machine learning approach;principal component analysis;probabilistic neural network method;safe-mode operation;safety hazards;supervised learning algorithm","","6","","16","","","12-15 May 2013","","IEEE","IEEE Conference Publications"
"Bio-inspired machine learning based Wireless Sensor Network security","H. Rathore; S. Jha","IIT, Rajasthan, India","2013 World Congress on Nature and Biologically Inspired Computing","20131003","2013","","","140","146","Exploring the symbiotic nature of biological systems can result in valuable knowledge for computer networks. Biologically inspired approaches to security in networks are interesting to evaluate because of the analogies between network security and survival of human body under pathogenic attacks. Wireless Sensor Network (WSN) is a network based on multiple low-cost, low-energy sensor nodes connected to physical signals. The network is made up of sensor nodes and gateways, where the server nodes acquire physical world data, while the gateway forwards the data to the end-user. While the spread of viruses in wired systems has been studied in-depth, applying trust in wireless sensor network nodes is an emerging area. This paper uses machine learning techniques to first differentiate between fraudulent and good nodes in the system. Next, it derives inspiration from the human immune system to present an idea of virtual antibodies in the system, to disable the fraudulent nodes in the system.","","Electronic:978-1-4799-1415-9; POD:978-1-4799-1413-5","10.1109/NaBIC.2013.6617852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617852","Biologically Inspired;Human Immune System;Machine Learning;Security;WSN","Immune system;Logic gates;Skin","artificial immune systems;computer network security;learning (artificial intelligence);wireless sensor networks","bio-inspired machine learning;computer networks;fraudulent nodes;good nodes;human immune system;trust;virtual antibodies;wireless sensor network security","","7","","19","","","12-14 Aug. 2013","","IEEE","IEEE Conference Publications"
"Learning Using Privileged Information with L-1 Support Vector Machine","L. Niu; Y. Shi; J. Wu","Res. Center on Fictitious Econ. & Data Sci., Grad. Univ. of Chinese Acad. of Sci., Beijing, China","2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20130502","2012","3","","10","14","In the process of human learning, teachers always play an important role. However, for most of the existing machine learning method, the role of teachers is seldom considered. Recently, Vapnik introduced an advanced learning paradigm called Learning Using Privileged Information(LUPI) to include the elements of human teaching in machine learning. Through theoretical analysis and numerical experiments, the superiority of LUPI over the classical learning paradigm has received preliminary proof. In this paper, on the basis of existing work for LUPI, we introduce the privileged information into the modeling of L-1 support vector machine(SVM). Compared with the existing research of LUPI with L-2 SVM, the new method has the advantage of spending less time on tuning model parameters and the additional benefits of performing feature selection in the training process. Experiments on the digit recognition problem validate the effectiveness of our method.","","Electronic:978-0-7695-4880-7; POD:978-1-4673-6057-9","10.1109/WI-IAT.2012.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6511639","1-norm;binary classification;privileged information;support vector machine","","learning (artificial intelligence);support vector machines","L1 support vector machine;LUPI paradigm;SVM;digit recognition problem;feature selection;human teaching element;learning paradigm;learning using privileged information;machine learning method;model parameter;training process","","2","","23","","","4-7 Dec. 2012","","IEEE","IEEE Conference Publications"
"Hardware requirements of communication-centric machine learning algorithms","L. Koskinen; E. Roverato","Department of Micro and Nanosciences, School of Electrical Engineering, Aalto University, P.O. Box 13000, FI-00076, Finland","2013 NASA/ESA Conference on Adaptive Hardware and Systems (AHS-2013)","20130919","2013","","","138","143","Machine learning type neuromorphic algorithms have the potential to enable the brains behind small autonomous robots, provided these algorithms can be implemented energy efficiently. The implementation difficulties are mainly extremely large memory size and high memory bandwidth making Von Neumann computational model realizations inefficient. However, these algorithms are inherently error robust, which may be taken advantage of in the realizations. For example, in with low operating voltage stochastic hardware. To determine the hardware requirements for an Application Specific Integrated Circuit (ASIC) realization, an example algorithm, Hierarchical Temporal Memory (HTM), is realized here. A 64×64 HTM network with 1440 connections per elementary processing element requires 530 mm<sup>2</sup> area, 340 Mb memory, and a 10MHz clock frequency in 65nm technology. With point-to-point connections these processing elements would have a communication radius of circa 50 elements and on-chip wideband technologies can increase the range further.","","Electronic:978-1-4673-6383-9; POD:978-1-4673-6382-2","10.1109/AHS.2013.6604237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6604237","Adaptive systems;Machine Learning;Parallel processing","Algorithm design and analysis;Hardware;Machine learning algorithms;Memory management;Microprocessors;Neuromorphics","application specific integrated circuits;learning (artificial intelligence);neural nets","ASIC realization;HTM;Von Neumann computational model;application specific integrated circuit;communication-centric machine learning algorithm;frequency 10 MHz;hierarchical temporal memory;machine learning type neuromorphic algorithm;point-to-point connection;size 65 nm","","0","","11","","","24-27 June 2013","","IEEE","IEEE Conference Publications"
"Fast flow regime recognition method of gas/water two-phase flow based on extreme learning machine","J. Zhao; F. Dong; C. Tan","Tianjin Key Lab. of Process Meas. & Control, Tianjin Univ., Tianjin, China","2013 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)","20130715","2013","","","1807","1811","Gas/water two-phase flow is widely encountered and of great importance in manufacture process and scientific researches, and recognition of its flow regimes is significant to the accurate measurement of its process parameters. Many groups have been working on the online recognition of flow regimes, but the recognition speed becomes a growing concern for online recognition. It is essential to look for ways to improve the recognition speed of the flow regimes. An efficient algorithm named extreme learning machine is applied to identify the flow regimes of gas/water two-phase flow in this paper. The flow parameters are obtained from ring-shaped conductance sensor, and five features that reflect the characteristics of flow regimes are extracted from the measured data. Based on the extracted features, extreme learning machine, least-square support vector machine (LS-SVM) and backpropagation neural network (BPNN) are adopted to separate the flow regimes. The results show that ELM is capable to recognize the flow regimes with high accuracy, and its recognition speed is faster than the other two popular methods.","1091-5281;10915281","Electronic:978-1-4673-4623-8; POD:978-1-4673-4621-4","10.1109/I2MTC.2013.6555726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6555726","extreme learning machine;flow regime recognition;ring-shaped conductance sensor;wavelet energy entropy","Accuracy;Entropy;Feature extraction;Machine learning algorithms;Neural networks;Support vector machines;Training","backpropagation;feature extraction;flow sensors;flow simulation;least squares approximations;mechanical engineering computing;neural nets;support vector machines;two-phase flow","BPNN;LS-SVM;backpropagation neural network;extreme learning machine;fast flow regime recognition method;feature extraction;gas-water two-phase flow;least-square support vector machine;manufacture process;online recognition;ring-shaped conductance sensor;scientific researches","","0","","23","","","6-9 May 2013","","IEEE","IEEE Conference Publications"
"A Machine Learning Algorithm for Searching Vectorised RDF Data","A. S. Hadi; P. Fergus; C. Dobbins; A. M. Al-Bakry","Software Dept., Univ. of Babylon, Hilla, Iraq","2013 27th International Conference on Advanced Information Networking and Applications Workshops","20130701","2013","","","613","618","The Internet has fundamentally changed the way we collect, access, and deliver information. However, this now means that finding the exact information we need is a significant problem. While search engines can find information based on the keywords we provide, using this technique alone is insufficient for rich information retrieval. Consequently, solutions, which lack the understanding of the syntax and semantics of content, find it difficult to accurately access the information we need. New approaches have been proposed that try to overcome this limitation by utilising Semantic Web and Linked Data techniques. Content is serialised using RDF, and queries executed using SPARQL. This approach requires an exact match between the query structure and the RDF content. While this is an improvement to keyword-based search, there is no support for probabilistic reasoning to show how close a query is to the content being searched. In this paper, we address this limitation by converting RDF content into a matrix of features and treat queries as a classification problem. We have successfully developed a working prototype system to demonstrate the applicability of our approach.","","Electronic:978-0-7695-4952-1; POD:978-1-4673-6239-9; USB:978-0-7695-4952-1","10.1109/WAINA.2013.204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550464","Linked Data;Machine Learning;Matrix;RDF;SPARQL;Semantic Web;Vectorisation;and Classification","Algorithm design and analysis;Classification algorithms;Decision trees;Matrix converters;Probabilistic logic;Resource description framework","data handling;learning (artificial intelligence);matrix algebra;query processing;search engines;semantic Web;vectors","Internet;RDF content;SPARQL;feature matrix;information access;information collection;information delivery;information retrieval;keyword-based search;linked data technique;machine learning algorithm;query structure;search engines;semantic Web technique;vectorised RDF data search","","1","","23","","","25-28 March 2013","","IEEE","IEEE Conference Publications"
"Machine learning approach to data center monitoring using wireless sensor networks","R. Khanna; H. Liu","Intel Corporation, 2111 NE 25th Ave., Hillsboro, OR 97124 USA","2012 IEEE Global Communications Conference (GLOBECOM)","20130422","2012","","","689","694","Data Centers face considerable challenges in seamless integration of telemetry and control functions. These functions are essential to management tasks related to power capping, cooling, reliability, predictability, survivability, and adaptability control. It is therefore essential to create an infrastructure of sensors that monitors the physical properties of the dynamically changing environment. The conventional approaches to support distributed sensor data collection and control using wired solutions are static, expensive, and non-scalable. In this paper sensors and control agents supporting this telemetry are a part of a dense and noisy network that are scattered across the data centers. We present an alternative approach for this unique environment using wireless sensor network to improve data efficiency and real-time delivery. We propose genetic algorithm (GA) approach for a densely populated sensor network to dynamically construct optimal collection trees through improved channel diversity that support context aware sensor data compression and reduced latency data delivery.","1930-529X;1930529X","Electronic:978-1-4673-0921-9; POD:978-1-4673-0920-2; USB:978-1-4673-0919-6","10.1109/GLOCOM.2012.6503193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6503193","","","computer centres;computerised monitoring;data compression;genetic algorithms;learning (artificial intelligence);telemetry;trees (mathematics);ubiquitous computing;wireless sensor networks","GA approach;adaptability control;context aware sensor data compression;control agents;control functions;cooling;data center monitoring;data efficiency;densely populated sensor network;distributed sensor data collection;dynamically construct optimal collection trees;genetic algorithm approach;improved channel diversity;machine learning approach;physical properties monitors;power capping;predictability;real-time delivery;reduced latency data delivery;reliability;sensor infrastructure;survivability;telemetry;wireless sensor network","","1","","13","","","3-7 Dec. 2012","","IEEE","IEEE Conference Publications"
"Generalization Evaluation of Machine Learning Numerical Observers for Image Quality Assessment","M. M. Kalayeh; T. Marin; J. G. Brankov","Department of Electrical and Computer Engineering, Illinois Institute of Technology, Chicago, IL, USA","IEEE Transactions on Nuclear Science","20130612","2013","60","3","1609","1618","In this paper, we present two new numerical observers (NO) based on machine learning for image quality assessment. The proposed NOs aim to predict human observer performance in a cardiac perfusion-defect detection task for single-photon emission computed tomography (SPECT) images. Human observer (HumO) studies are now considered to be the gold standard for task-based evaluation of medical images. However such studies are impractical for use in early stages of development for imaging devices and algorithms, because they require extensive involvement of trained human observers who must evaluate a large number of images.","0018-9499;00189499","","10.1109/TNS.2013.2257183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6515707","Channelized hotelling observer (CHO);human observer (HumO);image quality;numerical observer;relevance vector machine (RVM);single-photon emission computed tomography (SPECT)","Computational modeling;Feature extraction;Kernel;Noise;Numerical models;Observers;Support vector machines","learning (artificial intelligence);single photon emission computed tomography","SPECT images;cardiac perfusion-defect detection task;gold standard for task-based evaluation;human observer performance;human observer study;image quality assessment;imaging algorithms;imaging devices;machine learning numerical observers;medical images;single-photon emission computed tomography images","","7","","38","","20130516","June 2013","","IEEE","IEEE Journals & Magazines"
"A novel index measure imputation algorithm for missing data values: A machine learning approach","G. Madhu; T. V. Rajinikanth","Dept of Information Technology, VNR VJIET, Hyderabad, Andhra Pradesh, 500090, India","2012 IEEE International Conference on Computational Intelligence and Computing Research","20130502","2012","","","1","7","The problem of missing data in the real world datasets has very significant role in the real time data mining process and becomes more complex in large databases. The presence of missing values influences data set features and the class attributes, thus affecting the predictive accuracies of the classifiers. For the last one decade, many researchers have come out with different techniques for dealing with missing attribute values in databases with homogeneous and/or numeric attributes. In this research work, we proposed a new indexing measure to the imputation algorithm for missing data values of the attributes to compute the similarity measure between any two typical elements in the dataset. It can also be applied on any dataset be it a nominal and/or real. The proposed algorithm is evaluated by extensive experiments and comparison with KNNI, SVMI, WKNNI, KMI and FKMI algorithms. The results showed that the proposed algorithm has better performance than the existing imputation algorithms in terms of classification accuracy and also our decision tree algorithm employs highly accurate decision rules.","","Electronic:978-1-4673-1344-5; POD:978-1-4673-1342-1","10.1109/ICCIC.2012.6510198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6510198","classification;decision tree;index measure;missing values","","data mining;database management systems;decision trees;learning (artificial intelligence);pattern classification;support vector machines","FKMI algorithm;SVMI;WKNNI;class attributes;classification accuracy;classifier predictive accuracy;data set features;decision rules;decision tree algorithm;homogeneous attributes;index measure imputation algorithm;large databases;machine learning approach;missing attribute values;missing data values;numeric attributes;real time data mining process","","1","","40","","","18-20 Dec. 2012","","IEEE","IEEE Conference Publications"
"Real-Time Detection System of Driver Distraction Using Machine Learning","F. Tango; M. Botta","Department of Electric and Electronic Systems, Fiat Center of Research , Orbassano, Italy","IEEE Transactions on Intelligent Transportation Systems","20130529","2013","14","2","894","905","There is accumulating evidence that driver distraction is a leading cause of vehicle crashes and incidents. In particular, increased use of so-called in-vehicle information systems (IVIS) and partially autonomous driving assistance systems (PADAS) have raised important and growing safety concerns. Thus, detecting the driver's state is of paramount importance, to adapt IVIS and PADAS accordingly, therefore avoiding or mitigating their possible negative effects. The purpose of this paper is to show a method for the nonintrusive and real-time detection of visual distraction, using vehicle dynamics data and without using the eye-tracker data as inputs to classifiers. Specifically, we present and compare different models that are based on well-known machine learning (ML) methods. Data for training the models were collected using a static driving simulator, with real human subjects performing a specific secondary task [i.e., a surrogate visual research task (SURT)] while driving. Different training methods, model characteristics, and feature selection criteria have been compared. Based on our results, using a support vector machine (SVM) has outperformed all the other ML methods, providing the highest classification rate for most of the subjects. Potential applications of this paper include the design of an adaptive IVIS and of a “smarter” PADAS.","1524-9050;15249050","","10.1109/TITS.2013.2247760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484166","Accident prevention;artificial intelligence and machine learning (ML);driver distraction and inattention;intelligent supporting systems","Artificial neural networks;Fuzzy logic;Real-time systems;Safety;Training;Vehicles;Visualization","","","","11","","56","","20130321","June 2013","","IEEE","IEEE Journals & Magazines"
"Divergence estimation for machine learning and signal processing","M. Sugiyama","Department of Computer Science, Tokyo Institute of Technology Tokyo, Japan","2013 International Winter Workshop on Brain-Computer Interface (BCI)","20130422","2013","","","12","13","Approximating a divergence between two probability distributions from their samples is a fundamental challenge in the statistics, information theory, and machine learning communities, because a divergence estimator can be used for various purposes such as two-sample homogeneity testing, change-point detection, and class-balance estimation. Furthermore, an approximator of a divergence between the joint distribution and the product of marginals can be used for independence testing, which has a wide range of applications including feature selection and extraction, clustering, object matching, independent component analysis, and causality learning. In this talk, we review recent advances in direct divergence approximation that follow the general inference principle advocated by Vladimir Vapnik-one should not solve a more general problem as an intermediate step. More specifically, direct divergence approximation avoids separately estimating two probability distributions when approximating a divergence. We cover direct approximators of the Kullback-Leibler (KL) divergence, the Pearson (PE) divergence, the relative PE (rPE) divergence, and the L<sup>2</sup>-distance. Despite the overwhelming popularity of the KL divergence, we argue that the latter approximators are more useful in practice due to their computational efficiency, high numerical stability, and superior robustness against outliers.","","Electronic:978-1-4673-5974-0; Paper:978-1-4673-5973-3","10.1109/IWW-BCI.2013.6506611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6506611","Kullback-Leibler divergence;L 2-distance;Pearson divergence;relative Pearson divergence","Approximation methods;Estimation;Feature extraction;Mutual information;Neural networks;Probability distribution;Testing","approximation theory;independent component analysis;learning (artificial intelligence);signal processing;statistical distributions;statistical testing","KL divergence;Kullback-Leibler divergence;L<sup>2</sup>-distance;Pearson divergence;causality learning;change-point detection;class-balance estimation;clustering application;divergence approximation;divergence estimation;feature extraction;feature selection;independence testing;independent component analysis;inference principle;information theory;machine learning;object matching;probability distribution;relative PE divergence;signal processing;statistics;two-sample homogeneity testing","","0","","45","","","18-20 Feb. 2013","","IEEE","IEEE Conference Publications"
"Sentiment analysis of textual reviews; Evaluating machine learning, unsupervised and SentiWordNet approaches","V. K. Singh; R. Piryani; A. Uddin; P. Waila; Marisha","Department of Computer Science, South Asian University, New Delhi, India","2013 5th International Conference on Knowledge and Smart Technology (KST)","20130504","2013","","","122","127","This paper presents our experimental results on performance evaluation of all the three approaches for document-level sentiment classification. We have implemented two Machine Learning based classifiers (Naïve Bayes and SVM), the Unsupervised Semantic Orientation approach (SO-PMI-IR algorithm) and the SentiWordNet approaches for sentiment classification of movie reviews. We used two pre-existing large datasets and collected one of moderate size on our own. The paper primarily makes two useful contributions: (a) it presents a comprehensive evaluative account of performance of all the three available approaches on use with movie reviews, and (b) it presents a new modified Adjective+Adverb combine scheme of SentiWordNet approach.","","Electronic:978-1-4673-4853-9; POD:978-1-4673-4850-8","10.1109/KST.2013.6512800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6512800","Naïve Bayes;Semantic Orientation Approach;SentiWordNet;Sentiment Analysis;Support Vector Machine","Accuracy;Feature extraction;Motion pictures;Niobium;Semantics;Sentiment analysis;Support vector machines","","","","3","","21","","","Jan. 31 2013-Feb. 1 2013","","IEEE","IEEE Conference Publications"
"Auto-tuning of Cloud-Based In-Memory Transactional Data Grids via Machine Learning","P. Di Sanzo; D. Rughetti; B. Ciciani; F. Quaglia","DIAG, Sapienza Univ., Rome, Italy","2012 Second Symposium on Network Cloud Computing and Applications","20130307","2012","","","9","16","In-memory transactional data grids have revealed extremely suited for cloud based environments, given that they well fit elasticity requirements imposed by the pay-as-you-go cost model. Particularly, the non-reliance on stable storage devices simplifies dynamic resize of these platforms, which typically only involves setting up (or shutting down) some data-cache instance. On the other hand, defining the well suited amount of cache servers to be deployed, and the degree of replication of slices of data, in order to optimize reliability/availability and performance tradeoffs, is far from being a trivial task. As a example, scaling up/down the size of the underlying infrastructure might give rise to scarcely predictable secondary effects on the side of the synchronization protocol adopted to guarantee data consistency while supporting transactional accesses. In this paper we investigate on the usage of machine learning approaches with the aim at providing a means for automatically tuning the data grid configuration, which is achieved via dynamic selection of both the well suited amount of cache servers, and the well suited degree of replication of the data-objects. The final target is to determine configurations that are able to guarantee specific throughput or latency values (such as those established by some SLA), under some specific workload profile/intensity, while minimizing at the same time the cost for the cloud infrastructure. Our proposal has been integrated within an operating environment relying on the well known Infinispan data grid, namely a mainstream open source product by the Red Had JBoss division. Some experimental data are also provided supporting the effectiveness of our proposal, which have been achieved by deploying the data platform on top of Amazon EC2.","","Electronic:978-0-7695-4943-9; POD:978-1-4673-5581-0","10.1109/NCCA.2012.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6472453","cloud compitung;in-memory data platforms;transactional data platforms","Benchmark testing;Machine learning;Neural networks;Proposals;Servers;Throughput;Time factors","cache storage;cloud computing;grid computing;learning (artificial intelligence);public domain software","Amazon EC2;Infinispan data grid;Red Had JBoss division;cache servers;cloud-based in-memory transactional data grids auto-tuning;data consistency;elasticity requirements;machine learning;mainstream open source product;pay-as-you-go cost model;predictable secondary effects;stable storage devices;transactional accesses;workload profile-intensity","","5","","26","","","3-4 Dec. 2012","","IEEE","IEEE Conference Publications"
"Automatic construction of inlining heuristics using machine learning","S. Kulkarni; J. Cavazos; C. Wimmer; D. Simon","University of Delaware","Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)","20130408","2013","","","1","12","Method inlining is considered to be one of the most important optimizations in a compiler. However, a poor inlining heuristic can lead to significant degradation of a program's running time. Therefore, it is important that an inliner has an effective heuristic that controls whether a method is inlined or not. An important component of any inlining heuristic are the features that characterize the inlining decision. These features often correspond to the caller method and the callee methods. However, it is not always apparent what the most important features are for this problem or the relative importance of these features. Compiler writers developing inlining heuristics may exclude critical information that can be obtained during each inlining decision. In this paper, we use a machine learning technique, namely neuro-evolution [18], to automatically induce effective inlining heuristics from a set of features deemed to be useful for inlining. Our learning technique is able to induce novel heuristics that significantly out-perform manually-constructed inlining heuristics. We evaluate the heuristic constructed by our neuro-evolutionary technique within the highly tuned Java HotSpot server compiler and the Maxine VM C1X compiler, and we are able to obtain speedups of up to 89% and 114%, respectively. In addition, we obtain an average speedup of almost 9% and 11% for the Java HotSpot VM and Maxine VM, respectively. However, the output of neuro-evolution, a neural network, is not human readable. We show how to construct more concise and read-able heuristics in the form of decision trees that perform as well as our neuro-evolutionary approach.","","Electronic:978-1-4673-5525-4; POD:978-1-4673-5524-7","10.1109/CGO.2013.6495004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6495004","","Benchmark testing;Context;Decision trees;Measurement;Neural networks;Optimization;Training","learning (artificial intelligence);neural nets;program compilers","Java HotSpot server compiler;Maxine VM C1X compiler;callee method;caller method;inlining decision;inlining heuristics;machine learning;method inlining;neural network;neuro-evolution technique;program running time","","1","1","20","","","23-27 Feb. 2013","","IEEE","IEEE Conference Publications"
"Localizing and Comparing Weight Maps Generated from Linear Kernel Machine Learning Models","J. Schrouff; J. Cremers; G. Garraux; L. Baldassarre; J. Mourão-Miranda; C. Phillips","Cyclotron Res. Centre, Univ. of Liege, Liege, Belgium","2013 International Workshop on Pattern Recognition in Neuroimaging","20130919","2013","","","124","127","Recently, machine learning models have been applied to neuroimaging data, allowing to make predictions about a variable of interest based on the pattern of activation or anatomy over a set of voxels. These pattern recognition based methods present undeniable assets over classical (univariate) techniques, by providing predictions for unseen data, as well as the weights of each voxel in the model. However, the obtained weight map cannot be thresholded to perform regionally specific inference, leading to a difficult localization of the variable of interest. In this work, we provide local averages of the weights according to regions defined by anatomical or functional atlases (e.g. Brodmann atlas). These averages can then be ranked, thereby providing a sorted list of regions that can be (to a certain extent) compared with univariate results. Furthermore, we defined a ""ranking distance"", allowing for the quantitative comparison between localized patterns. These concepts are illustrated with two datasets.","","Electronic:978-0-7695-5061-9; POD:978-1-4799-0928-5","10.1109/PRNI.2013.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603572","fMRI;machine learning;pattern comparison;pattern localization;ranking","Accuracy;Biological system modeling;Computational modeling;Data models;Neuroimaging;Predictive models;Support vector machines","biomedical MRI;computational geometry;data analysis;learning (artificial intelligence);medical computing;neurophysiology","Brodmann atlas;activation pattern;anatomical atlases;anatomy pattern;fMRI;functional atlases;linear kernel machine learning models;neuroimaging data;pattern recognition based methods;ranking distance;weight map comparison;weight map localization","","1","","17","","","22-24 June 2013","","IEEE","IEEE Conference Publications"
"Diagnosis of Vertebral Column Disorders Using Machine Learning Classifiers","S. Ansari; F. Sajjad; Z. ul-Qayyum; N. Naveed; I. Shafi","","2013 International Conference on Information Science and Applications (ICISA)","20130815","2013","","","1","6","Medical science is characterized by the correct diagnosis of a disease and its accurate classification to avoid complexities at treatment/medication stage. This is often accomplished by a physician based on experience without much signal processing aids. It is envisioned that a sophisticated and intelligent medical diagnostic/classification system may be helpful in making right decisions especially at remote areas where specialist physicians are not present. With this in mind, this paper proposes diagnosis and classification of vertebral column disorders using machine learning classifiers including feed forward back propagation neural network, generalized regression neural network and support vector machine and evaluates their performance. The dataset is collected using the information from the magnetic resonance images (MRI) and is classified into three different classes which are disk hernia, spondylolisthesis and normal. The classifiers are trained using 50% ratio and 10 fold cross validation approaches and are comprehensively evaluated with different architectures, activation and kernel functions. Experimental results demonstrate that feed forward back propagation neural network is 93.87% accurate on unknown test cases and performs better than the other methods.","2162-9048;21629048","Electronic:978-1-4799-0604-8; POD:978-1-4799-0602-4","10.1109/ICISA.2013.6579446","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579446","","Accuracy;Artificial neural networks;Feeds;Neurons;Support vector machines;Training","biomedical MRI;decision making;feedforward neural nets;image classification;medical image processing;patient treatment;regression analysis;support vector machines","MRI;decision making;disk hernia;feed forward back propagation neural network;generalized regression neural network;intelligent medical classification system;intelligent medical diagnostic system;kernel function;machine learning classifier;magnetic resonance image;medical science;medication stage;performance evaluation;spondylolisthesis;support vector machine;treatment stage;vertebral column disorder diagnosis","","3","","18","","","24-26 June 2013","","IEEE","IEEE Conference Publications"
"Machine learning for the cosmic ray inspection and passive tomography project (CRIPT)","T. J. Stocki; C. Warren; M. P. C. Magill; B. E. Morgan; J. Smith; D. Ong; V. N. P. Anghel; J. Armitage; J. Botte; K. Boudjemline; D. Bryman; J. Bueno; E. Charles; T. Cousins; A. Erlandson; G. Gallant; R. Gazit; V. V. Golovko; R. Hydomako; C. Jewett; G. Jonkmans; Z. Liu; M. McCall; S. Noel; G. Oakham; A. Robichaud; M. Thompson; D. Waller","Health Canada, Ottawa, ON, Canada","2012 IEEE Nuclear Science Symposium and Medical Imaging Conference Record (NSS/MIC)","20130708","2012","","","91","94","Muons, which are produced naturally in the upper atmosphere, can be used to scan cargo for special nuclear materials (SNM). Preliminary simulated results show that detecting the presence of these materials can be accomplished by measuring the scattering of cosmic ray muons. Machine learning tools have been used on these data to classify it as SNM or not. The muon exists long enough, and is penetrating enough, that it can be used to passively scan cargo to detect SNM. By measuring the deflection angles of muons after they exit a container, one can determine whether or not SNM are present. Different detector approaches have been evaluated by considering the performance, cost, and robustness of several technologies. Simulations have been performed to help design the detectors and to determine the effectiveness of the proposed techniques. Realistic cargo containers have been simulated. Two types of techniques can be used to determine whether the cargo containers contain SNM. More traditional methods use an expert system which uses knowledge of physics to compute physical information about the cargo. The other approach is to use Machine Learning classifiers, which can be used to determine if the cargo contains SNM. These techniques include the following algorithms: decision trees, neural networks, special vector machines, and k nearest neighbours. Preliminary results from the two approaches to classification have been obtained and will be discussed in the paper.","1082-3654;10823654","DVD:978-1-4673-2029-0; Electronic:978-1-4673-2030-6; POD:978-1-4673-2028-3","10.1109/NSSMIC.2012.6551067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6551067","","","cosmic ray apparatus;cosmic ray muons;decision trees;learning (artificial intelligence);machine vector control;neural nets;nuclear materials safeguards;tomography","CRIPT;SNM;cargo containers;cosmic ray inspection;cosmic ray muon scattering;decision trees;machine learning classifiers;neural networks;passive tomography project;special nuclear materials;special vector machines;upper atmosphere","","0","","11","","","Oct. 27 2012-Nov. 3 2012","","IEEE","IEEE Conference Publications"
"A Survey on Machine-Learning Techniques in Cognitive Radios","M. Bkassiny; Y. Li; S. K. Jayaweera","Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, USA","IEEE Communications Surveys & Tutorials","20130731","2013","15","3","1136","1159","In this survey paper, we characterize the learning problem in cognitive radios (CRs) and state the importance of artificial intelligence in achieving real cognitive communications systems. We review various learning problems that have been studied in the context of CRs classifying them under two main categories: Decision-making and feature classification. Decision-making is responsible for determining policies and decision rules for CRs while feature classification permits identifying and classifying different observation models. The learning algorithms encountered are categorized as either supervised or unsupervised algorithms. We describe in detail several challenging learning issues that arise in cognitive radio networks (CRNs), in particular in non-Markovian environments and decentralized networks, and present possible solution methods to address them. We discuss similarities and differences among the presented algorithms and identify the conditions under which each of the techniques may be applied.","1553-877X;1553877X","","10.1109/SURV.2012.100412.00017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336689","Artificial intelligence;cognitive radio;decision-making;feature classification;machine learning;supervised learning;unsupervised learning","Cognition;Cognitive radio;Machine learning;Radio frequency;Sensors;Unsupervised learning","cognitive radio;decision making;feature extraction;learning (artificial intelligence);telecommunication computing","CRN;artificial intelligence;cognitive communication;cognitive radio network;decentralized networks;decision-making;feature classification;learning algorithms;machine-learning techniques;nonMarkovian environment;observation model","","60","","177","","20121022","Third Quarter 2013","","IEEE","IEEE Journals & Magazines"
"A Machine Learning Approach for Non-blind Image Deconvolution","C. J. Schuler; H. C. Burger; S. Harmeling; B. Schölkopf","Max Planck Inst. for Intell. Syst., Tubingen, Germany","2013 IEEE Conference on Computer Vision and Pattern Recognition","20131003","2013","","","1067","1074","Image deconvolution is the ill-posed problem of recovering a sharp image, given a blurry one generated by a convolution. In this work, we deal with space-invariant non-blind deconvolution. Currently, the most successful methods involve a regularized inversion of the blur in Fourier domain as a first step. This step amplifies and colors the noise, and corrupts the image information. In a second (and arguably more difficult) step, one then needs to remove the colored noise, typically using a cleverly engineered algorithm. However, the methods based on this two-step approach do not properly address the fact that the image information has been corrupted. In this work, we also rely on a two-step procedure, but learn the second step on a large dataset of natural images, using a neural network. We will show that this approach outperforms the current state-of-the-art on a large dataset of artificially blurred images. We demonstrate the practical applicability of our method in a real-world example with photographic out-of-focus blur.","1063-6919;10636919","Electronic:978-0-7695-4989-7; POD:978-1-4673-6410-2","10.1109/CVPR.2013.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618986","deblurring;deconvolution;learning;neural networks","Colored noise;Deconvolution;Kernel;Neural networks;Noise reduction;Training","Fourier transforms;convolution;deconvolution;image denoising;image restoration;learning (artificial intelligence);neural nets","Fourier domain;blurry image;colored noise removal;ill-posed problem;image convolution;image information;machine learning approach;natural image dataset;neural network;photographic out-of-focus blur;regularized blur inversion;sharp image recovery;space-invariant nonblind image deconvolution;two-step procedure","","22","","31","","","23-28 June 2013","","IEEE","IEEE Conference Publications"
"Implementation of machine learning algorism to autonomous surface vehicle for tracking and navigating AUV","J. Osaku; A. Asada; F. Maeda; Y. Yamagata; T. Kanamaru","Institute of Industrial Science, The University of Tokyo, Komaba, Tokyo-to, Japan","2013 IEEE International Underwater Technology Symposium (UT)","20130527","2013","","","1","4","On the construction of Kanda port in Fukuoka prefecture, many harmful chemical bombs have been discovered beneath the sea bottom and they are needed to be dug up carefully and quickly as possible. So our group is trying to develop a new sub-bottom interferometric synthetic aperture imaging sonar (sub-bottom interferometric SAS) system to recognize chemical bombs as centimeters-resolution 3D-sub-bottom acoustic image. In this R&D study, it is the reasonable methodology to use an autonomous underwater vehicle (AUV) which can survey the seafloor with sub-bottom interferometric SAS transmitter and receiver at a constant height. To accomplish this R&D goal, positioning AUV accurately is needed, so we are trying to develop the technique which minimizes the error of positioning, using autonomous surface vehicle (ASV) which tracks AUV and surveys its absolute position by super short-baseline (SSBL) method. In development of tracking ASV, it is important to develop the controlling algorism which orders ASV to steer stably and control adequately its velocity according to the result of SSBL positioning of the AUV. Based on machine learning method, we are trying to develop an algorism which infers appropriate control of ASV from precious controlling log. Implementation of this algorism will improve the precision of underwater positioning. This paper reports the development status of our ASV and controlling algorism.","","Electronic:978-1-4673-5949-8; POD:978-1-4673-5948-1","10.1109/UT.2013.6519900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6519900","","Acoustics;Compass;Computers;Global Positioning System;Software;Synthetic aperture sonar;Weapons","autonomous underwater vehicles;explosive detection;learning (artificial intelligence);marine engineering;navigation;position control;radar interferometry;sonar imaging;sonar tracking;synthetic aperture radar","AUV navigation;AUV tracking;autonomous surface vehicle;chemical bomb recognition;machine learning algorithm;steer stability;subbottom interferometric synthetic aperture imaging sonar;super short baseline method;underwater positioning","","0","","2","","","5-8 March 2013","","IEEE","IEEE Conference Publications"
"Comparison of Advanced Machine Learning Tools for Disruption Prediction and Disruption Studies","M. Odstrcil; A. Murari; J. Mlynar","Institute of Plasma Physics AS CR, v.v.i., Prague, Czech Republic","IEEE Transactions on Plasma Science","20130703","2013","41","7","1751","1759","Machine learning tools have been used since a long time ago to study disruptions and to predict their occurrence. On the other hand, the challenges posed by the quality and quantities of the data available remain substantial. In this paper, methods to optimize the training data set and the potential of kernels-based advanced machine learning tools are explored and assessed. Various alternatives, ranging from appropriate selection of the weights to the inclusion of artificial points, are investigated to improve the quality of the training data set. Support vector machines (SVM), relevance vector machines (RVMs), and one-class SVM are compared. The relative performances of the different approaches are initially assessed using synthetic data. Then they are applied to a relatively large database of JET disruptions. It is shown that in terms of final results, the optimization of the training databases proved to be very productive. Further, the RVM algorithm performs well when it is trained on a small set of discharges compared to the traditional methods.","0093-3813;00933813","","10.1109/TPS.2013.2264880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531635","Disruption;learning machines;prediction;relevance vector machine (RVM);support vector machines (SVM);tokamaks","Discharges (electric);Kernel;Optimization;Plasmas;Prediction algorithms;Support vector machines;Training","Tokamak devices;discharges (electric);learning (artificial intelligence);physics computing;plasma instability;plasma toroidal confinement;support vector machines","JET disruption database;RVM algorithm;discharges;disruption prediction study;kernels-based advanced machine learning tool;occurrence prediction;one-class SVM;relevance vector machine;support vector machine;training data set optimization;training database optimization","","1","","27","","20130613","July 2013","","IEEE","IEEE Journals & Magazines"
"User's utterance classification using machine learning for Arabic Conversational Agents","M. Hijjawi; Z. Bandar; K. Crockett","Information Technology College, Applied Science University, Amman, Jordan","2013 5th International Conference on Computer Science and Information Technology","20130905","2013","","","223","232","This paper presents a novel technique for the classification of Arabic sentences as Dialogue Acts, based on structural information contained in Arabic function words. It focuses on classifying questions and non-questions utterances as they are used in Conversational Agents. The proposed technique extracts function words features by replacing them with numeric tokens and replacing each content word with a standard numeric token. The Decision Tree has been chosen for this work to extract the classification rules. Experiments provide evidence for highly effective classification. The extracted classification rules will be embedded into a Conversational Agent called ArabChat in order to classify Arabic utterances before further processing on these utterances. This paper presents a complement work for the ArabChat to improve its performance by differentiating among question-based and non question-based utterances.","","Electronic:978-1-4673-5825-5; POD:978-1-4673-5610-7; USB:978-1-4673-5824-8","10.1109/CSIT.2013.6588784","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6588784","Arabic Utterances;Conversational Agents;Dialogue Acts;Machine learning and Decision Tree","Computer science;Decision trees;Educational institutions;Feature extraction;Information technology;Intelligent systems;Standards","decision trees;feature extraction;learning (artificial intelligence);multi-agent systems;natural language processing;pattern classification","ArabChat;Arabic conversational agent;Arabic function words;Arabic sentence classification;Arabic utterance classification;classification rule extraction;decision tree;dialogue acts;function words feature extraction;machine learning;nonquestions utterance classification;numeric tokens;questions utterance classification;structural information;user utterance classification","","0","","41","","","27-28 March 2013","","IEEE","IEEE Conference Publications"
"Machine learning based diagnosis support for ShipBoard Power Systems controls","R. Amgai; J. Shi; R. Santos; S. Abdelwahed","Department of Electrical and Computer Engineering, Mississippi state university, Starkville, 39762, USA","2013 IEEE Electric Ship Technologies Symposium (ESTS)","20130606","2013","","","405","410","In this paper, a machine learning based decision support system for a naval shipboard power management system is proposed considering contingencies and load priority. A probabilistic model based Bayes' classifier is implemented to classify the current operation state of the ShipBoard Power System (SPS), depending upon the power system readiness for critical contingencies. Real power, reactive power, and generator status are taken as input features for the algorithm. Loss of vital/non-vital load is calculated by solving optimal power flow (OPF) to help build the knowledge base. Training data are updated online to increase the accuracy of the proposed approach. The characterization of the operation states helps the shipboard power management system to take the appropriate control action. Initial results from tests are presented and the outcomes from the particular techniques are discussed. Moreover, we also present RTDS based experimental framework towards the ongoing research on overall management system including the diagnosis support. Naïve Bayes' approach has classified the system states with 97.67% accuracy to new instances. Preliminary results show the computation time of this approach is in the order of 25 ms.","","Electronic:978-1-4673-5245-1; POD:978-1-4673-5243-7","10.1109/ESTS.2013.6523768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6523768","Diagnosis support;E-Ship;Machine Learning;Naïve Bayes'","Accuracy;Computational modeling;Data models;Generators;Load modeling;Mathematical model;Vectors","learning (artificial intelligence);load flow control;marine power systems;power engineering computing;power system control;reactive power control","Bayes classifier;OPF;RTDS based experimental framework;diagnosis support;generator status;machine learning;naval shipboard power management;optimal power flow;reactive power;shipboard power system control","","3","","18","","","22-24 April 2013","","IEEE","IEEE Conference Publications"
"Consensus-based distributed optimization: Practical issues and applications in large-scale machine learning","K. I. Tsianos; S. Lawlor; M. G. Rabbat","Department of Electrical and Computer Engineering, McGill University, Montr&#x00E9;al, Qu&#x00E9;bec, Canada","2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)","20130321","2012","","","1543","1550","This paper discusses practical consensus-based distributed optimization algorithms. In consensus-based optimization algorithms, nodes interleave local gradient descent steps with consensus iterations. Gradient steps drive the solution to a minimizer, while the consensus iterations synchronize the values so that all nodes converge to a network-wide optimum when the objective is convex and separable. The consensus update requires communication. If communication is synchronous and nodes wait to receive one message from each of their neighbors before updating then progress is limited by the slowest node. To be robust to failing or stalling nodes, asynchronous communications should be used. Asynchronous protocols using bi-directional communications cause deadlock, and so one-directional protocols are necessary. However, with one-directional asynchronous protocols it is no longer possible to guarantee the consensus matrix is doubly stochastic. At the same time it is essential that the coordination protocol achieve consensus on the average to avoid biasing the optimization objective. We report on experiments running Push-Sum Distributed Dual Averaging for convex optimization in a MPI cluster. The experiments illustrate the benefits of using asynchronous consensus-based distributed optimization when some nodes are unreliable and may fail or when messages experience time-varying delays.","","Electronic:978-1-4673-4539-2; POD:978-1-4673-4537-8","10.1109/Allerton.2012.6483403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483403","","Convergence;Delays;Machine learning algorithms;Optimization;Peer-to-peer computing;Protocols;Stochastic processes","convex programming;gradient methods;learning (artificial intelligence);message passing;protocols","MPI cluster;asynchronous communications;asynchronous protocols;bidirectional communications;consensus iterations;convex optimization;coordination protocol;failing nodes;large-scale machine learning;nodes interleave local gradient descent steps;practical consensus-based distributed optimization algorithms;push-sum distributed dual averaging;stalling nodes;time-varying delays","","29","","33","","","1-5 Oct. 2012","","IEEE","IEEE Conference Publications"
"A Low-Power Processor With Configurable Embedded Machine-Learning Accelerators for High-Order and Adaptive Analysis of Medical-Sensor Signals","K. H. Lee; N. Verma","Department of Electrical Engineering, Princeton University, Princeton","IEEE Journal of Solid-State Circuits","20130621","2013","48","7","1625","1637","Low-power sensing technologies have emerged for acquiring physiologically indicative patient signals. However, to enable devices with high clinical value, a critical requirement is the ability to analyze the signals to extract specific medical information. Yet given the complexities of the underlying processes, signal analysis poses numerous challenges. Data-driven methods based on machine learning offer distinct solutions, but unfortunately the computations are not well supported by traditional DSP. This paper presents a custom processor that integrates a CPU with configurable accelerators for discriminative machine-learning functions. A support-vector-machine accelerator realizes various classification algorithms as well as various kernel functions and kernel formulations, enabling range of points within an accuracy-versus-energy and -memory trade space. An accelerator for embedded active learning enables prospective adaptation of the signal models by utilizing sensed data for patient-specific customization, while minimizing the effort from human experts. The prototype is implemented in 130-nm CMOS and operates from 1.2 V-0.55 V (0.7 V for SRAMs). Medical applications for EEG-based seizure detection and ECG-based cardiac-arrhythmia detection are demonstrated using clinical data, while consuming 273 μJ and 124 μJ per detection, respectively; this represents 62.4&times; and 144.7&times; energy reduction compared to an implementation based on the CPU. A patient-adaptive cardiac-arrhythmia detector is also demonstrated, reducing the analysis-effort required for model customization by 20 &times;.","0018-9200;00189200","","10.1109/JSSC.2013.2253226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493458","Active learning (subject-specific adaptation);biomedical electronics;machine learning (artificial intelligence);medical signal processing;support vector machine (SVM)","Adaptation models;Brain models;Computational modeling;Data models;Kernel;Support vector machines","CMOS integrated circuits;SRAM chips;biomedical electronics;cardiology;diseases;electroencephalography;electronic engineering computing;embedded systems;learning (artificial intelligence);low-power electronics;medical signal detection;pattern classification;support vector machines","CMOS;CPU;ECG-based cardiac-arrhythmia detection;EEG-based seizure detection;SRAM;accuracy-versus-energy;classification algorithm;clinical data;clinical value;configurable embedded machine-learning accelerator;custom processor;data-driven method;discriminative machine-learning function;embedded active learning;energy reduction;human expert;kernel formulation;kernel function;low-power processor;low-power sensing technology;medical application;medical information;medical-sensor signal;memory trade space;patient-adaptive cardiac-arrhythmia detector;patient-specific customization;physiologically indicative patient signal;signal analysis;signal model;size 130 nm;support-vector-machine accelerator;voltage 1.2 V to 0.55 V","","23","","35","","20130403","July 2013","","IEEE","IEEE Journals & Magazines"
"A Database-Hadoop Hybrid Approach to Scalable Machine Learning","M. Yui; I. Kojima","Inf. Technol. Res. Inst., Nat. Inst. of Adv. Ind. Sci. & Technol., Tsukuba, Japan","2013 IEEE International Congress on Big Data","20130916","2013","","","1","8","There are two popular schools of thought for performing large-scale machine learning that does not fit into memory. One is to run machine learning within a relational database management system, and the other is to push analytical functions into MapReduce. As each approach has its own set of pros and cons, we propose a database-Hadoop hybrid approach to scalable machine learning where batch-learning is performed on the Hadoop platform, while incremental-learning is performed on PostgreSQL. We propose a purely relational approach that removes the scalability limitation of previous approaches based on user-defined aggregates and also discuss issues and resolutions in applying the proposed approach to Hadoop/Hive. Experimental evaluations of classification performance and training speed were conducted using a commercial advertisement dataset provided in the KDD Cup 2012, Track 2. The experimental results show that our scheme has competitive classification performance and superior training speed compared with state-of-the-art scalable machine learning frameworks, 5 and 7.65 times faster than Vow pal Wabbit and Bismarck, respectively, for a regression task.","2379-7703;23797703","Electronic:978-0-7695-5006-0; POD:978-1-4799-0182-1","10.1109/BigData.Congress.2013.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597112","Hadoop;MapReduce;in-database analytics;iterative parameter mixture;logistic regression;stochastic gradient descent","Aggregates;Computational modeling;Machine learning algorithms;Predictive models;Relational databases;Training","learning (artificial intelligence);parallel programming;regression analysis;relational databases","PostgreSQL;batch learning;classification performance;database-Hadoop hybrid approach;incremental learning;purely relational approach;regression task;relational database management system;scalable machine learning;user-defined aggregates","","4","","27","","","June 27 2013-July 2 2013","","IEEE","IEEE Conference Publications"
"Class Imbalance Learning Methods for Support Vector Machines","H. He; Y. Ma","","Imbalanced Learning:Foundations, Algorithms, and Applications","20130626","2013","","","","","Support vector machines (SVMs) is a very popular machine learning technique, which has been successfully applied to many real-world classification problems from various domains. Despite of all its theoretical and practical advantages, SVMs could produce suboptimal results with imbalanced datasets. This chapter briefly reviews the learning algorithm of SVMs. It discusses why SVMs are sensitive to the imbalance in datasets. The chapter also reviews the methods found in the literature to handle the class imbalance problem for SVMs. These methods have been developed as both data preprocessing methods (called external methods) and algorithmic modifications to the SVM algorithm (called internal methods). Fuzzy SVMs for Class Imbalance Learning (FSVM-CIL) settings have resulted in better classification results on the datasets than the existing CIL methods applied for standard SVMs, namely random oversampling, random undersampling, synthetic minority oversampling technique (SMOTE), different error costs (DEC), and zSVM methods.","","97811186461","10.1002/9781118646106.ch5","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6542402.pdf&bkn=6542371&pdfType=chapter","","","","","","","","","2013","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Machine-learning-based hotspot detection using topological classification and critical feature extraction","Y. T. Yu; Geng-He Lin; I. H. R. Jiang; C. Chiang","Dept. of Electronics Engineering and Inst. of Electronics, National Chiao Tung University, Hsinchu, Taiwan","2013 50th ACM/EDAC/IEEE Design Automation Conference (DAC)","20130718","2013","","","1","6","Because of the widening sub-wavelength lithography gap in advanced fabrication technology, lithography hotspot detection has become an essential task in design for manufacturability. Current state-of-the-art works unite pattern matching and machine learning engines. Unlike them, we fully exploit the strengths of machine learning using novel techniques. By combing topological classification and critical feature extraction, our hotspot detection framework achieves very high accuracy. Furthermore, to speed up the evaluation, we verify only possible layout clips instead of full-layout scanning. After detection, we filter hotspots to reduce the false alarm. Experimental results show that the proposed framework is very accurate and demonstrates a rapid training convergence. Moreover, our framework outperforms the 2012 CAD Contest at ICCAD winner on accuracy and false alarm.","0738-100X;0738100X","Electronic:978-1-4503-2071-9; POD:978-1-4503-2071-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560660","Design for manufacturability;fuzzy pattern matching;hotspot detection;lithography hotspot;machine learning;support vector machine","Accuracy;Feature extraction;Kernel;Layout;Support vector machines;Training;Training data","design for manufacture;electronic engineering computing;feature extraction;learning (artificial intelligence);lithography;pattern matching;printed circuit layout;printed circuit manufacture;production engineering computing","critical feature extraction;design for manufacturability;fabrication technology;layout clip;lithography hotspot detection;machine learning engine;pattern matching;subwavelength lithography gap;topological classification","","1","","17","","","May 29 2013-June 7 2013","","IEEE","IEEE Conference Publications"
"Machine Learning-Based Software Quality Prediction Models: State of the Art","H. A. Al-Jamimi; M. Ahmed","Inf. & Comput. Sci. Dept., King Fahd Univ. of Pet. & Miner., Dhahran, Saudi Arabia","2013 International Conference on Information Science and Applications (ICISA)","20130815","2013","","","1","4","Quantification of parameters affecting the software quality is one of the important aspects of research in the field of software engineering. In this paper, we present a comprehensive literature survey of prominent quality molding studies. The survey addresses two views: (1) quantification of parameters affecting the software quality; and (2) using machine learning techniques in predicting the software quality. The paper concludes that, model transparency is a common shortcoming to all the surveyed studies.","2162-9048;21629048","Electronic:978-1-4799-0604-8; POD:978-1-4799-0602-4","10.1109/ICISA.2013.6579473","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579473","","Biological system modeling;Fuzzy logic;Object oriented modeling;Predictive models;Software engineering;Software quality","learning (artificial intelligence);software quality","machine learning;quality molding;software engineering;software quality prediction model","","1","","47","","","24-26 June 2013","","IEEE","IEEE Conference Publications"
"Feature selection in pulmonary function test data with machine learning methods","R. Karakış; İ. Güler; A. H. Işık","Elektronik ve Bilgisayar E&#x011F;itimi B&#x00F6;l&#x00FC;m&#x00FC;, Gazi &#x00DC;niversitesi, Ankara, T&#x00FC;rkiye","2013 21st Signal Processing and Communications Applications Conference (SIU)","20130613","2013","","","1","4","Pulmonary function test has vital importance in diagnosis and treatment of lung diseases. With this test, several parameters are measured such as forced vital capacity (FVC) and forced expiratory volume in the first second (FEV<sub>1</sub>) of patients. These parameters indicate different types of lung disorders. Main constraint in diagnosis is to selection of important parameters among test results. In this study, five results of pulmonary function test (PFT) are evaluated with machine learning methods and feature selections with test results are achieved. Feature selections are performed with using Naive bayes, support vector machine (SVM), linear discriminant analysis (LDA) and k-nearest neighbor classifier (k-NN) methods. The test results of 436 patients are obtained from Atatürk Chest Diseases and Thoracic Surgery Training and Research Hospital in Ankara/Turkey. SVM method has a highest performance values with 89,6% accuracy, 87,4 % specificity, 71,6% sensitivity respectively. Thus, it is found with feature selection that importance order of test results are FVC, FEV<sub>1</sub>, FEV<sub>1</sub>/FVC, PEF ve FEF<sub>25/75</sub> respectively. In this study, obtained performance values are higher than most of studies in the literature.","","Electronic:978-1-4673-5563-6; POD:978-1-4673-5562-9","10.1109/SIU.2013.6531578","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531578","feature selection;pulmonary function test","Bayes methods;Diseases;Electrical engineering;Feature extraction;Lungs;Support vector machines;Volume measurement","feature extraction;learning (artificial intelligence);lung;medical image processing;pattern classification;surgery","Ankara;Ataturk chest diseases;FEV1/FVC;LDA;Naive bayes;PEF ve FEF25/75;PFT;SVM;Turkey;feature selections;forced expiratory volume;forced vital capacity;k-NN methods;k-nearest neighbor classifier;linear discriminant analysis;lung disease diagnosis;lung disease treatment;lung disorders;machine learning methods;pulmonary function test data;research hospital;support vector machine;thoracic surgery training","","0","","25","","","24-26 April 2013","","IEEE","IEEE Conference Publications"
"Trace-by-classification: A machine learning approach to generate trace links for frequently occurring software artifacts","M. Wieloch; S. Amornborvornwong; J. Cleland-Huang","School of Computing, DePaul University, Chicago, IL, 60604, USA","2013 7th International Workshop on Traceability in Emerging Forms of Software Engineering (TEFSE)","20131007","2013","","","110","114","Over the past decade the traceability research community has focused upon developing and improving trace retrieval techniques in order to retrieve trace links between a source artifact, such as a requirement, and set of target artifacts, such as a set of java classes. In this Trace Challenge paper we present a previously published technique that uses machine learning to trace software artifacts that recur is similar forms across across multiple projects. Examples include quality concerns related to non-functional requirements such as security, performance, and usability; regulatory codes that are applied across multiple systems; and architectural-decisions that are found in many different solutions. The purpose of this paper is to release a publicly available TraceLab experiment including reusable and modifiable components as well as associated datasets, and to establish baseline results that would encourage further experimentation.","2157-2186;21572186","Electronic:978-1-4799-0495-2; POD:978-1-4799-0496-9","10.1109/TEFSE.2013.6620165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620165","challenge;machine learning;traceability","Educational institutions;Probabilistic logic;Security;Software;Standards;Training;Weight measurement","Java;information retrieval;learning (artificial intelligence);object-oriented programming;pattern classification;program diagnostics;security of data;software architecture;software quality;software reusability","Java classes;TraceLab experiment;architectural-decisions;component modifiability;component reusability;frequently occurring software artifacts;machine learning approach;performance requirement;quality concerns;regulatory codes;security requirement;target artifacts;trace challenge;trace link generation;trace link retrieval;trace retrieval techniques;trace-by-classification;traceability research community;usability requirement","","2","","15","","","19-19 May 2013","","IEEE","IEEE Conference Publications"
"Machine learning based search space optimisation for drug discovery","U. Senanayake; R. Prabuddha; R. Ragel","Department of Computer Engineering, University of Peradeniya, Peradeniya, CP 20400, Sri Lanka","2013 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20130912","2013","","","68","75","Drug discovery research has progressed to a place where it essentially counts on high performance computer systems and huge databases for its victory. As such, Virtual Screening (VS), a computationally intensive process, plays a major role in the systematic drug designing process for pressing diseases. Therefore, it is imperative that the VS process has to be made as fast as possible in order to efficiently dock the ligands from huge databases to a selected protein receptor, targeting a drug. The extremely high rate of increase of the number of ligands in the databases makes it impossible to tackle this problem only by improving the computing resources. Therefore, researchers work on an orthogonal technique, where they use soft computing to reduce the search space through identifying the ligands that are non-dockable, hence improving the throughput as a whole. Machine Learning (ML) can be used to train a binary classifier that can classify the ligands into two known classes: dockable and non-dockable ligands. In this paper, for the first time, we use three ML techniques (Support Vector Machines, Artificial Neural Networks and Random Forest) on a single problem domain (a Protease receptor of HIV) and evaluate the performance rendered by the respective models. We show that such classification improves the throughput by two folds with around 90% accuracy. In addition, we propose and use a technique for constructing a training set to be used for ML in VS applications in the instance of a non-synthesised receptor.","","Electronic:978-1-4673-5875-0; POD:978-1-4673-5874-3","10.1109/CIBCB.2013.6595390","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595390","Artificial Neural Networks;Autodock Vina;Machine Learning;Random Forest;Support Vector Machines;Virtual Screening","Accuracy;Databases;Drugs;Machine learning algorithms;Proteins;Support vector machines;Training","biology computing;drugs;learning (artificial intelligence);neural nets;proteins;support vector machines","HIV protease receptor;ML;artificial neural network;disease;dockable ligand;drug designing process;drug discovery;machine learning;nondockable ligand;orthogonal technique;protein receptor;random forest;search space optimisation;soft computing;support vector machine;virtual screening","","3","","29","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Machine learning-based prefetch optimization for data center applications","S. w. Liao; T. H. Hung; D. Nguyen; C. Chou; C. Tu; H. Zhou","Google Inc., Mountain View, California and National Taiwan University, Taipei, Taiwan","Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis","20130314","2009","","","1","10","Performance tuning for data centers is essential and complicated. It is important since a data center comprises thousands of machines and thus a single-digit performance improvement can significantly reduce cost and power consumption. Unfortunately, it is extremely difficult as data centers are dynamic environments where applications are frequently released and servers are continually upgraded. In this paper, we study the effectiveness of different processor prefetch configurations, which can greatly influence the performance of memory system and the overall data center. We observe a wide performance gap when comparing the worst and best configurations, from 1.4% to 75.1%, for 11 important data center applications. We then develop a tuning framework which attempts to predict the optimal configuration based on hardware performance counters. The framework achieves performance within 1% of the best performance of any single configuration for the same set of applications.","2167-4329;21674329","Electronic:978-1-60558-744-8; POD:978-1-4799-1685-6","10.1145/1654059.1654116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375514","","","computer centres;learning (artificial intelligence);storage management","data center applications;hardware performance counters;machine learning-based prefetch optimization;memory system performance;performance tuning framework;processor prefetch configurations;single-digit performance improvement","","8","","26","","","14-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"Incremental learning to reduce the burden of machine learning for P300 speller","T. Yokoi; T. Yoshikawa; T. Furuhashi","Graduate School of Engineering, Nagoya University","The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems","20130422","2012","","","167","170","The P300 speller is one of the BCI applications, which allows users to select letters just by thoughts. However, due to the difference of P300 in each person and with the passage of time, users are required to do machine learning every time before use (pre-training). This pre-training is a burden to users. This paper proposes an incremental learning using unknown data to reduce the training time. Consequently, this paper shows that the proposed method gives not only the reduction of the training time but also directly use of P300 speller without pre-training by using the data of last time.","","Electronic:978-1-4673-2743-5; POD:978-1-4673-2742-8","10.1109/SCIS-ISIS.2012.6505359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6505359","","","bioelectric potentials;brain-computer interfaces;electroencephalography;learning (artificial intelligence);medical signal processing","BCI application;EEG;P300 speller;brain-computer interface;electroencephalography;event related potential;incremental learning;letter selection;machine learning;user pretraining","","0","","9","","","20-24 Nov. 2012","","IEEE","IEEE Conference Publications"
"Interface schema matching with the machine learning for deep web","G. Zhu; N. Wang; H. Wang; Q. Jiao","College of Computer Science and Technology Harbin Engineering University Harbin, P. R. China","Proceedings of 2012 2nd International Conference on Computer Science and Network Technology","20130610","2012","","","822","825","With the rapid development of the World Wide Web, information contained in the deep web is increasing dramatically. Since different query interfaces are heterogeneous and autonomous inherently, even in the same domain, it is a huge challenge to allow users efficiently and quickly to get their own satisfying information. Deep web query interfaces integration can solve this problem well. The interface schema matching is the foremost step in the steps of the deep web query interfaces integration. This paper takes 120 data sources as a training set and 40 data sources as a testing set. Combined with the idea of multi-strategy learning technology, a deep web interface schema matching method based on machine learning is proposed. The method transformed the schema matching problem into the machine learning classification, and achieved the schema matching automatically. In order to enhance the accuracy of the mappings, the concept of domain ontology is introduced in this paper. The experimental results show that the method has an average accuracy rate of 80%-90%.","","Electronic:978-1-4673-2964-4; POD:978-1-4673-2963-7","10.1109/ICCSNT.2012.6526056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6526056","deep web;domain ontology;meta-learning;multi-stratry learning;schema matching","","Internet;learning (artificial intelligence);ontologies (artificial intelligence);pattern classification;query processing","World Wide Web;automatic schema matching;autonomous query interfaces;deep Web query interface integration;domain ontology;heterogeneous query interfaces;interface schema matching;machine learning classification;mapping accuracy enhancement;multistrategy learning technology","","0","","11","","","29-31 Dec. 2012","","IEEE","IEEE Conference Publications"
"Content feature based bit rate modelling for scalable video coding using machine learning algorithms","R. Bailleul; J. De Cock; P. Lambert; R. Van de Walle; B. Schrauwen","Ghent University - iMinds, ELIS - Multimedia Lab, Gaston Crommenlaan 8 bus 201, B-9050 Ledeberg, Belgium","2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)","20131003","2013","","","1","4","Rate control mechanisms for scalable video coding are known to be a complex problem, suffering from inaccurate performance due to the layered structure of scalable video. In this study, multiple machine learning methods are evaluated to design rate-complexity-quantization models for efficient rate control. Specifically, the bit rates of SVC multi-layered bit streams are predicted, based on the quantization parameters used for encoding and a number of features describing the complexity of the video content. The results indicate that general regression neural networks can be used as an alternative to the statistical models classically used for rate control. Moreover, this approach is able to capture the influence of video complexity on the bit rate of all layers at once, and offers the possibility of increasing its effectiveness as it gains experience through on-line learning. The constructed models provide a good prediction of the encoded bit rates, with a Pearson correlation well above 0.9 and an average error of about 5%. The resulting predictor can serve as basis for a more elaborate rate control system for scalable video coding.","","Electronic:978-1-4799-1604-7; POD:978-1-4799-1603-0; USB:978-1-4799-1602-3","10.1109/ICMEW.2013.6618276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618276","Scalable video coding (SVC);machine learning;rate-complexity-quantizationmodeling (R-C-Q)","Bit rate;Complexity theory;Encoding;Quantization (signal);Static VAr compensators;Streaming media;Video coding","computational complexity;learning (artificial intelligence);neural nets;quantisation (signal);regression analysis;video coding","Pearson correlation;SVC multilayered bit stream;content feature based bit rate modelling;encoding;general regression neural networks;machine learning algorithm;online learning;quantization parameters;rate control mechanism;rate-complexity-quantization model;scalable video coding;scalable video layered structure;statistical model;video complexity;video content complexity","","0","","18","","","15-19 July 2013","","IEEE","IEEE Conference Publications"
"Counter attack detection with machine learning from log files of RoboCup simulation","Y. Kobayashi; H. Kawamura; K. Suzuki","Synergetic Information Science, Graduate School of Information science and Technology, Hokkaido University","The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems","20130422","2012","","","1821","1826","Multi-agent systems have attracted a lot of attention recently. RoboCup Soccer Simulation is treated here as a testbed of such systems. This study aims to facilitate the analysis of team behavior and to clarify the role of different types of team possession in the game results of RoboCup Soccer Simulation. We construct a method of detecting counter attacks, which are one type of team possession, by analyzing the log files of games. To detecting the counter attacks, anisotropy feature and others are introduced. Based on these features, a support vector machine (SVM) based detector was able to achieve a 77% detection rate. The detecting method will be expected to reduce the burden of visually checking log data.","","Electronic:978-1-4673-2743-5; POD:978-1-4673-2742-8","10.1109/SCIS-ISIS.2012.6505088","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6505088","RoboCup Soccer Simulation;degree of anisotropy;support vector machine;team possession types","","data handling;learning (artificial intelligence);multi-agent systems;sport","RoboCup simulation file;RoboCup soccer simulation;SVM based detector;anisotropy feature;counter attack detection;log data checking;machine learning;multi-agent system;support vector machine;team behavior;team possession","","0","","7","","","20-24 Nov. 2012","","IEEE","IEEE Conference Publications"
"Predicting cloud resource provisioning using machine learning techniques","A. A. Bankole; S. A. Ajila","Department of Systems and Computer Engineering, Carleton University 1125 Colonel By Drive, Ottawa K1S 5B6, ON Canada","2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20130725","2013","","","1","4","In order to meet Service Level Agreement (SLA) requirements, Virtual Machine (VM) resources must be provisioned few minutes ahead due to the VM boot-up time. One way to do this is by predicting future resource demands. In this research, we have developed and evaluated cloud client prediction models for TPCW benchmark web application using three machine learning techniques: Support Vector Machine (SVM), Neural Networks (NN) and Linear Regression (LR). We included the SLA metrics for Response Time and Throughput to the prediction model with the aim of providing the client with a more robust scaling decision choice. Our results show that Support Vector Machine provides the best prediction model.","0840-7789;08407789","Electronic:978-1-4799-0033-6; POD:978-1-4799-0031-2","10.1109/CCECE.2013.6567848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567848","Cloud computing;Machine learning;Resource prediction;Resource provisioning","Artificial neural networks;Linear regression;Measurement;Predictive models;Support vector machines;Throughput;Time factors","cloud computing;contracts;learning (artificial intelligence);neural nets;regression analysis;resource allocation;support vector machines;virtual machines","LR;NN;SLA metrics;SVM;TPC-W benchmark Web application;VM boot-up time;cloud client prediction models;cloud resource provisioning prediction;future resource demand prediction;linear regression;machine learning techniques;neural networks;response time;robust scaling decision choice;service level agreement requirements;support vector machine;throughput;virtual machine resource","","8","","27","","","5-8 May 2013","","IEEE","IEEE Conference Publications"
"A new framework for IRIS and fingerprint recognition using SVM classification and extreme learning machine based on score level fusion","S. Sangeetha; N. Radha","PSGR Krishnammal College for Women, Coimbatore-641004, India","2013 7th International Conference on Intelligent Systems and Control (ISCO)","20130321","2013","","","183","188","In a Multimodal biometric system, the effective fusion method is necessary for combining information from various single modality systems. Two biometric characteristics are considered in this study: iris and fingerprint. Multimodal biometric system needs an effective fusion scheme to combine biometric characteristics derived from one or more modalities. The score level fusion is used to combine the characteristics from different biometric modalities. Fusion at the score level is a new technique, which has a high potential for efficient consolidation of multiple unimodal biometric matcher outputs. Support vector machine and extreme learning techniques are used in this system for recognition of biometric traits. In this, the Fingerprint-Iris system provides better performance and comparison of support vector machine and extreme learning machine based on score-level fusion methods is obtained. In score-level fusion, ELM provides better performance as compare to the SVM. It reduces the classification time of current system. This work is valuable and makes an efficient accuracy in such applications. This system can be utilized for person identification in several applications.","","CD-ROM:978-1-4673-4602-3; Electronic:978-1-4673-4603-0; POD:978-1-4673-4359-6","10.1109/ISCO.2013.6481145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6481145","Biometric;Extreme Learning Machine;Multimodal Biometric;Recognition System;Score Level Fusion;Support Vector Machine;k-Mean Clustering","Accuracy;Databases;Image recognition;Iris recognition;Machine learning;Sociology;Statistics","","","","5","","18","","","4-5 Jan. 2013","","IEEE","IEEE Conference Publications"
"Balancing Clinical and Pathologic Relevance in the Machine Learning Diagnosis of Epilepsy","W. T. Kerr; A. Y. Cho; A. Anderson; P. K. Douglas; E. P. Lau; E. S. Hwang; K. R. Raman; A. Trefler; M. S. Cohen; S. T. Nguyen; N. M. Reddy; D. H. Silverman","Lab. of Integrative Neuroimaging Technol., Univ. of California, Los Angeles, Los Angeles, CA, USA","2013 International Workshop on Pattern Recognition in Neuroimaging","20130919","2013","","","86","89","The application of machine learning to epilepsy can be used both to develop clinically useful computer-aided diagnostic tools, and to reveal pathologically relevant insights into the disease. Such studies most frequently use neurologically normal patients as the control group to maximize the pathologic insight yielded from the model. This practice yields potentially inflated accuracy because the groups are quite dissimilar. A few manuscripts, however, opt to mimic the clinical comparison of epilepsy to non-epileptic seizures, an approach we believe to be more clinically realistic. In this manuscript, we describe the relative merits of each control group. We demonstrate that in our clinical quality FDG-PET database the performance achieved was similar using each control group. Based on these results, we find that the choice of control group likely does not hinder the reported performance. We argue that clinically applicable computer-aided diagnostic tools for epilepsy must directly address the clinical challenge of distinguishing patients with epilepsy from those with non-epileptic seizures.","","Electronic:978-0-7695-5061-9; POD:978-1-4799-0928-5","10.1109/PRNI.2013.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603563","FDG-PET;controls;epilepsy;machine learning;neuroimaging;non-epileptic seizures","Accuracy;Artificial neural networks;Biomedical imaging;Diseases;Electroencephalography;Epilepsy;Temporal lobe","diseases;learning (artificial intelligence);medical computing;neurophysiology;patient diagnosis","clinical quality FDG-PET database;clinical relevance;computer-aided diagnostic tools;disease;epilepsy;machine learning diagnosis;nonepileptic seizures;pathologic relevance","","1","","30","","","22-24 June 2013","","IEEE","IEEE Conference Publications"
"Monitoring nutrient concentrations in Tampa Bay with MODIS images and machine learning models","N. B. Chang; Z. Xuan","Department of Civil, Environmental, and Construction Engineering, University of Central Florida, Orlando, USA","2013 10th IEEE INTERNATIONAL CONFERENCE ON NETWORKING, SENSING AND CONTROL (ICNSC)","20130627","2013","","","702","707","This paper explores the spatiotemporal nutrient patterns in Tampa Bay, Florida with the aid of Moderate Resolution Imaging Spectroradiometer (MODIS) images and Genetic Programming (GP) models that are designed to link Total Phosphorus (TP) levels and remote sensing reflectance bands in aquatic environments. In-situ data were drawn from a local database to support the calibration and validation of the GP model. The GP models show the effective capacity to demonstrating the snapshots of spatiotemporal distributions of TP across the Bay, which helps to delineate the short-term seasonality effect and the global trend of TP in the coastal bay. The model output can provide informative reference for the establishment of contingency plans in treating nutrients-rich runoff.","","Electronic:978-1-4673-5200-0; POD:978-1-4673-5198-0","10.1109/ICNSC.2013.6548824","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548824","MODIS;Remote sensing;coastal bay;genetic programming;nutrient monitoring;wastewater treatment","Biomedical monitoring;Cities and towns;Computational modeling;Data mining;Genetics;Monitoring;Reflectivity","environmental science computing;genetic algorithms;geophysical image processing;learning (artificial intelligence);phosphorus;remote sensing;water treatment","GP model;MODIS image;TP;Tampa Bay;aquatic environment;coastal bay;genetic programming;machine learning model;moderate resolution imaging spectroradiometer;nutrient concentration monitoring;remote sensing reflectance band;short-term seasonality effect;total phosphorus","","0","","17","","","10-12 April 2013","","IEEE","IEEE Conference Publications"
"Trustworthy services selection mechanism based on machine learning techniques","L. Chen; G. Yang; Qian Wang; Y. Zhang","College of Computer Science & Technology, Nanjing University of Posts and Telecommunications, 210003, Jiangsu, China","International Conference on Automatic Control and Artificial Intelligence (ACAI 2012)","20130404","2012","","","2218","2222","With the rapid growth of web services, users select the available services according to not only functional requirements, but also non-functional QoS characteristics. Therefore, research on how to find suitable and trustworthy service becomes increasingly important and challenging. In this paper, we propose an efficient Trustworthy Services Selection model named TSSelector by employing state-of-the-art machine learning techniques to improve services' semantic representation and predict services' QoS characteristics. Compared with the existing approaches, the TSSelector has at least two advantages. First, it imports WordNet and Latent Semantic Index to extend web services' semantic and represent it as the low-dimensional compact feature vectors. Second, it employs matrix completion technique to predict and correct the missing and corrupted QoS values. Preliminary experimental results performed on the real-world data set demonstrate the feasibility of the proposed approaches.","","Electronic:978-1-84919-537-9","10.1049/cp.2012.1440","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493047","Machine learning;Matrix completion;QoS prediction;Web services;WordNet","","","","","0","","","","","3-5 March 2012","","IET","IET Conference Publications"
"Implementation of network traffic classifier using semi supervised machine learning approach","V. S. Mahajan; B. Verma","","2012 Nirma University International Conference on Engineering (NUiCONE)","20130404","2012","","","1","6","Network Traffic Classification using classical techniques such as port number based and payload based is becoming very difficult because many applications use dynamic port number and encryption technique to avoid detection. To overcome the drawbacks of classical techniques various machine learning techniques were proposed. Machine learning technique faces the problem of labeled instances (in supervised learning) and time consuming manual work (in unsupervised learning). To address the above problems we proposed a semi supervised machine learning technique. The key idea of proposed technique is to build a classifier from training dataset consisting of both labeled and unlabeled instances. For experimental purpose KDD CUP 99 intrusion detection dataset and MATLAB tool is used. We evaluate and compare the performance of the classifier build with 10%, 20% and 30% labeled instances in training dataset. The result of experiments show that classifier build with 30% labeled instances in training dataset has better performance at number of clusters equals to 50.","2375-1282;23751282","Electronic:978-1-4673-1719-1; POD:978-1-4673-1720-7","10.1109/NUICONE.2012.6493192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493192","Classification;Clustering;Labeled Instances;Machine Learning;Unlabeled Instances","","cryptography;pattern classification;software performance evaluation;unsupervised learning","KDD CUP 99 intrusion detection dataset;MATLAB tool;avoid detection;classical techniques;dynamic port number;encryption technique;machine learning techniques;network traffic classification;network traffic classifier;performance evaluation;semisupervised machine learning approach;training dataset;unsupervised learning","","0","","31","","","6-8 Dec. 2012","","IEEE","IEEE Conference Publications"
"Microblogging sentiment analysis with lexical based and machine learning approaches","W. Maharani","Faculty of Informatics, Telkom Institute of Technology, Bandung Indonesia","2013 International Conference of Information and Communication Technology (ICoICT)","20130805","2013","","","439","443","The Digital World encounters rapid development nowadays, especially through the proliferation of social media in Indonesia. Twitter has become one of social media with expanded users within every sectors of society. There are so many part both individual as well as organization/enterprise which utilize twitter as tool for communication, business, customer relation, and other activities. Through the twitter's ever-expanding users with those particular purposes, the precise method to effectively and efficiently analyzing opinion-contained sentences become crucially needed. Therefore this research made for method analyzing through lexical based and model based approaches by machine learning to classify opinion-contained tweets using those 2 methods. The tested machine learning method are Support Vector Machine (SVM), Maximum Entropy (ME), Multinomial Naive Bayes (MNB), and k-Nearest Neighbor (k-NN). Based on the test outcome, lexical based approach highly depended on lexical database which became opinion classification matrix. Whilst machine learning approach can produce better accuracy due to its capability in new training data modeling based on outcome model. However, machine learning model based approach depends on various factors in analyzing sentiment.","","Electronic:978-1-4673-4992-5; POD:978-1-4673-4990-1","10.1109/ICoICT.2013.6574616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574616","Maximum Entropy;Multinomial Naive Bayes;Support Vector Machine;Twitter;k-Nearest Neighbor;lexical based;machine learning;tweet","Accuracy;Communications technology;Data mining;Data models;Databases;Entropy;Support vector machines","Bayes methods;data models;learning (artificial intelligence);maximum entropy methods;pattern classification;social networking (online);support vector machines;text analysis","Indonesia;ME;MNB;SVM;Twitter;business;communication tool;customer relation;digital world;enterprise;k-NN;k-nearest neighbor;lexical based approach;lexical database;machine learning;maximum entropy;microblogging sentiment analysis;model based approach;multinomial naive Bayes;opinion classification matrix;opinion-contained sentences;opinion-contained tweet classification;organization;social media;support vector machine;training data modeling","","2","","17","","","20-22 March 2013","","IEEE","IEEE Conference Publications"
"Evaluating Machine Learning and Unsupervised Semantic Orientation approaches for sentiment analysis of textual reviews","P. Waila; Marisha; V. K. Singh; M. K. Singh","DST-CIMS, Banaras Hindu University, Varanasi, India","2012 IEEE International Conference on Computational Intelligence and Computing Research","20130502","2012","","","1","6","This paper presents our experimental work on evaluation of Machine Learning based classification approaches (Naïve Bayes and SVM) with the Unsupervised Semantic Orientation based SO-PMI-IR algorithm for sentiment analysis of movie review texts. We have used both pre-existing data sets and our own dataset collection comprising of a large number of user reviews for Hindi movies. The Naïve Bayes and SVM approaches were implemented in multiple folds. The results, in addition to presenting a detailed comparative view of these techniques, demonstrate that with suitable selection of features the Naive Bayes algorithm performs reasonably well and at times matches the popularly believed superior performance level of SVM, at least for sentiment analysis task. The SO-PMI-IR algorithm produces substantially accurate sentiment classification without the requirement of any prior training. The accuracy of SO-PMI-IR however depends on POS tags used as features and thresholding/ aggregation schemes used.","","Electronic:978-1-4673-1344-5; POD:978-1-4673-1342-1","10.1109/ICCIC.2012.6510235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6510235","Movie Review Mining;Naïve Bayes;Semantic Orientation approach;Sentiment Analysis;Support Vector Machine","","humanities;learning (artificial intelligence);pattern classification;support vector machines;text analysis","Hindi movie;SO-PMI-IR algorithm;SVM;aggregation scheme;machine learning based classification approach;movie review text;naive Bayes approach;sentiment analysis;sentiment classification;support vector machines;textual review;thresholding scheme;unsupervised semantic orientation approach","","5","","18","","","18-20 Dec. 2012","","IEEE","IEEE Conference Publications"
"Behavior recognition based on machine learning algorithms for a wireless canine machine interface","R. Brugarolas; R. T. Loftin; P. Yang; D. L. Roberts; B. Sherman; A. Bozkurt","Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27697-7911, USA","2013 IEEE International Conference on Body Sensor Networks","20130808","2013","","","1","5","Training and handling working dogs is a costly process and requires specialized skills and techniques. Less subjective and lower-cost training techniques would not only improve our partnership with these dogs but also enable us to benefit from their skills more efficiently. To facilitate this, we are developing a canine body-area-network (cBAN) to combine sensing technologies and computational modeling to provide handlers with a more accurate interpretation for dog training. As the first step of this, we used inertial measurement units (IMU) to remotely detect the behavioral activity of canines. Decision tree classifiers and Hidden Markov Models were used to detect static postures (sitting, standing, lying down, standing on two legs and eating off the ground) and dynamic activities (walking, climbing stairs and walking down a ramp) based on the heuristic features of the accelerometer and gyroscope data provided by the wireless sensing system deployed on a canine vest. Data was collected from 6 Labrador Retrievers and a Kai Ken. The analysis of IMU location and orientation helped to achieve high classification accuracies for static and dynamic activity recognition.","2376-8886;23768886","Electronic:978-1-4799-0330-6; POD:978-1-4799-0331-3","10.1109/BSN.2013.6575505","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6575505","animal machine interfaces;body area network;canine training;cascade learning;inertial measurement units","Accelerometers;Accuracy;Dogs;Gyroscopes;Hidden Markov models;Legged locomotion;Sensors","","","","6","","13","","","6-9 May 2013","","IEEE","IEEE Conference Publications"
"Towards the Automated Evaluation of Crowd Work: Machine-Learning Based Classification of Complex Texts Simplified by Laymen","H. Hoffmann; A. Bullinger; C. Fellbaum","","2013 46th Hawaii International Conference on System Sciences","20130318","2013","","","1289","1298","The work paradigm of crowd sourcing holds huge potential for organizations by providing access to a large workforce. However, an increase of crowd work entails increasing effort to evaluate the quality of the submissions. As evaluations by experts are inefficient, time-consuming, expensive, and are not guaranteed to be effective, our paper presents a concept for an automated classification process for crowd work. Using the example of crowd generated patent transcripts we build on interdisciplinary research to present an approach to classifying them along two dimensions - correctness and readability. To achieve this, we identify and select text attributes from different disciplines as input for machine-learning classification algorithms and evaluate the suitability of three well regarded algorithms, Neural Networks, Support Vector Machines and k-Nearest Neighbor algorithms. Key findings are that the proposed classification approach is feasible and the SVM classifier performs best in our experiment.","1530-1605;15301605","Electronic:978-1-5090-5646-0; POD:978-1-4673-5933-7; USB:978-0-7695-4892-0","10.1109/HICSS.2013.568","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479991","classification;machine learning","Abstracts;Classification algorithms;Gold;Indexes;Patents;Pragmatics;Standards","learning (artificial intelligence);neural nets;outsourcing;pattern classification;support vector machines;text analysis","SVM classifier;automated classification process;automated evaluation;complex texts;correctness classification;crowd generated patent transcripts;crowd work;crowdsourcing;k-nearest neighbor algorithms;large workforce access;laymen;machine-learning-based classification;neural networks;readability classification;submission quality;support vector machines;text attributes","","0","","46","","","7-10 Jan. 2013","","IEEE","IEEE Conference Publications"
"Kernel-Based Machine Learning for Background Estimation of NaI Low-Count Gamma-Ray Spectra","M. Alamaniotis; J. Mattingly; L. H. Tsoukalas","Nuclear Engineering Program, The University of Utah, Salt Lake City, UT, USA","IEEE Transactions on Nuclear Science","20130612","2013","60","3","2209","2221","Virtually all gamma-ray spectrometry measurements contain background components due to the ubiquitous presence of primordial radionuclides in the Earth's crust and cosmic radiation interactions high in the Earth's atmosphere. In principle, spectral signatures due to radiation source(s) of actual interest can be extracted from the measured gamma-ray spectrum by background subtraction. However, if separate background measurements are unavailable or infeasible, and particularly for measurements exhibiting low signal-to-noise ratio (SNR), background subtraction is nontrivial, and it requires accurate background estimation . An example application of gamma-ray spectroscopy with low SNR is the “source search” scenario, where the position of a source is sought using measurements taken over very short time intervals by a detector in motion. We have developed an algorithm for background estimation in low-count gamma-ray spectra using kernel-based Gaussian processes (GP) taken from the field of machine learning. We have evaluated the performance of our algorithm using a group of three kernels tested against a dataset composed of background spectra measured in an urban environment using a mobile sodium iodide (NaI) detector. We have also simulated datasets containing nonbackground gamma-ray sources in an urban background measured with a NaI detector. The simulated scenarios employed a variety of source-detector distances and different types of source shielding. As a metric of algorithm performance, we calculated correlation coefficients, Theil inequality coefficients, and count difference statistics between estimated and actual backgrounds. We concluded that our method adequately estimates the gamma-ray background, but we also observed a strong dependence of the algorithm's performance on the selected kernel.","0018-9499;00189499","","10.1109/TNS.2013.2260868","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6520895","Background estimation;Gaussian processes (GP);gamma-ray spectroscopy;machine learning","Channel estimation;Detectors;Estimation;Gamma-rays;Gaussian processes;Kernel;Machine learning algorithms","Gaussian processes;gamma-ray detection;gamma-ray spectrometers;learning (artificial intelligence);physics computing;radioactive sources;radioisotopes;shielding;solid scintillation detectors","Earth atmosphere;Earth crust;NaI gamma-ray spectrometry measurements;NaI low-count gamma-ray spectra;algorithm performance;background components;background subtraction;correlation coefήcients;cosmic radiation interactions;gamma-ray background;inequality performance;kernel-based Gaussian processes;kernel-based machine learning;nonbackground gamma-ray sources;primordial radionuclides;radiation source;signal-to-noise;sodium iodide detector;source shielding;source-detector","","3","","28","","20130527","June 2013","","IEEE","IEEE Journals & Magazines"
"Recommending environmental knowledge as linked open data cloud using semantic machine learning","A. Morshed; R. Dutta; J. Aryal","Intell. Sensing & Syst. Lab., CSIRO, Hobart, TAS, Australia","2013 IEEE 29th International Conference on Data Engineering Workshops (ICDEW)","20130627","2013","","","27","28","Large scale environmental knowledge integration and development of a knowledge recommendation system for the Linked Open Data Cloud using semantic machine learning approach was the main mission of this research. This study considered five different environmental big data sources including SILO, AWAP, ASRIS, MODIS and CosmOz complementary for knowledge integration. Unsupervised clustering techniques based on principal component analysis (PCA) and Fuzzy-C-Means (FCM) and Self-organizing map (SOM) clustering was used to learn the extracted features and to create a 2D map based dynamic knowledge recommendation system. Knowledge was stored in a triplestore using triples format (subject, predicate, and object) along with the complete meta-data provenance information. The Resource Description Framework (RDF) representation made i-EKbase very flexible to integrate with the Linked Open Data (LOD) cloud. The developed Intelligent Environmental Knowledgebase (i-EKbase) could be used for any environmental decision support application.","","Electronic:978-1-4673-5304-5; POD:978-1-4673-5303-8","10.1109/ICDEW.2013.6547421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547421","FCM;Linked Open Data cloud;PCA;RDF;g-SOM based visual selection;i-EKbase;triplestore","Artificial intelligence;Databases;MODIS;Principal component analysis;Resource description framework;Semantics;Visualization","cloud computing;decision support systems;environmental science computing;fuzzy set theory;learning (artificial intelligence);meta data;open systems;pattern clustering;principal component analysis;recommender systems;self-organising feature maps","2D map-based dynamic environmental knowledge recommendation system;ASRIS;AWAP;CosmOz;FCM;LOD cloud;MODIS;PCA;RDF representation;Resource Description Framework representation;SILO;SOM clustering;environmental big-data sources;environmental decision support application;environmental knowledge development;environmental knowledge integration;feature extraction;fuzzy-c-means;i-EKbase could;intelligent environmental knowledgebase could;linked open data cloud;meta-data provenance information;principal component analysis;self-organizing map clustering;semantic machine learning;subject-predicate-object triples format;triplestore;unsupervised clustering techniques","","5","","6","","","8-12 April 2013","","IEEE","IEEE Conference Publications"
"A statistical machine learning approach for ticket mining in IT service delivery","E. E. Jan; J. Ni; N. Ge; N. Ayachitula; X. Zhang","IBM T.J. Watson Research Center, 19 Skyline Dr, Hawthorne, NY","2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013)","20130801","2013","","","541","546","Ticketing is a fundamental management process of IT service delivery. Customers typically express their requests in the form of tickets related to problems or configuration changes of existing systems. Tickets contain a wealth of information which, when connected with other sources of information such as asset and configuration information, monitoring information, can yield new insights that would otherwise be impossible to gain from one isolated source. Linking these various sources of information requires a common key shared by these data sources. The key is the server names. Unfortunately, due to historical as well as practical reasons, the server names are not always present in the tickets as a standalone field. Rather, they are embedded in unstructured text fields such as abstract and descriptions. Thus, automatically identifying server names in tickets is a crucial step in linking various information sources. In this paper, we present a statistical machine learning method called Conditional Random Field (CRF) that can automatically identify server names in tickets with high accuracy and robustness. We then illustrate how such linkages can be leveraged to create new business insights.","1573-0077;15730077","Electronic:978-3-901882-50-0; POD:978-1-4799-1708-2; USB:978-1-4673-5229-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6573030","Analytics;Data model;Machine Learning;Service management;Statistical Models","Business;Data models;Dictionaries;Robustness;Servers;Training;Training data","data mining;learning (artificial intelligence);statistical analysis;text analysis","CRF;IT service delivery;abstract text field;asset information;automatic server name identification;conditional random field;configuration information;data sources;description text field;management process;monitoring information;statistical machine learning approach;ticket mining;unstructured text fields","","0","","12","","","27-31 May 2013","","IEEE","IEEE Conference Publications"
"Machine learning for attack vector identification in malicious source code","V. A. Benjamin; H. Chen","Department of Management Information Systems, The University of Arizona, Tucson, 85721, USA","2013 IEEE International Conference on Intelligence and Security Informatics","20130815","2013","","","21","23","As computers and information technologies become ubiquitous throughout society, the security of our networks and information technologies is a growing concern. As a result, many researchers have become interested in the security domain. Among them, there is growing interest in observing hacker communities for early detection of developing security threats and trends. Research in this area has often reported hackers openly sharing cybercriminal assets and knowledge with one another. In particular, the sharing of raw malware source code files has been documented in past work. Unfortunately, malware code documentation appears often times to be missing, incomplete, or written in a language foreign to researchers. Thus, analysis of such source files embedded within hacker communities has been limited. Here we utilize a subset of popular machine learning methodologies for the automated analysis of malware source code files. Specifically, we explore genetic algorithms to resolve questions related to feature selection within the context of malware analysis. Next, we utilize two common classification algorithms to test selected features for identification of malware attack vectors. Results suggest promising direction in utilizing such techniques to help with the automated analysis of malware source code.","","Electronic:978-1-4673-6213-9; POD:978-1-4673-6214-6","10.1109/ISI.2013.6578779","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578779","Cyber security;Malware analysis;Static analysis","Accuracy;Biological cells;Communities;Computer hacking;Malware;Support vector machine classification","computer crime;genetic algorithms;invasive software;learning (artificial intelligence);pattern classification;peer-to-peer computing;source coding","automated malware source code file analysis;classification algorithm;cybercriminal asset sharing;feature selection;genetic algorithm;hacker community;information technology;machine learning;malicious source code;malware attack vector identification;malware code documentation;security domain;security threat detection","","6","","11","","","4-7 June 2013","","IEEE","IEEE Conference Publications"
"Grouping of Customer Opinions Written in Natural Language Using Unsupervised Machine Learning","F. Darena; J. ika; K. Burda","Dept. of Inf., Mendel Univ., Brno, Czech Republic","2012 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","20130318","2012","","","265","270","Among one of the current and most topical tasks in the area of textual documents processing belongs the problem of automatic categorization. Clustering as the most common form of unsupervised learning enables automatic grouping of unlabeled documents into subsets called clusters. In this paper, the authors are concerned with results of clustering of very large electronic real-world data collections containing customers' reviews written freely, in English as a natural language. The reviews are automatically clustered into two groups that should contain either positive or negative reviews. The paper focuses on the analysis why certain reviews are assigned wrongly to a group containing mostly reviews of a different class. The assignment of a review into a certain cluster is based on its properties, i.e., on the words that appeared in the review. Thus, words appearing in incorrectly categorized reviews were analyzed. It was found that words that are important from the correct classification viewpoint (and thus bearing some sentiment) are often similarly important as the words in a different set than expected, therefore do not take effect as misleading information unlike words that are much more or quite insignificant.","","Electronic:978-0-7695-4934-7; POD:978-1-4673-5026-6","10.1109/SYNASC.2012.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6481040","cluster mining;customer opinion;incorrect categorization;similarity;textual data","Clustering algorithms;Dictionaries;Entropy;Natural languages;Prediction algorithms;Training;Vectors","natural language processing;pattern classification;pattern clustering;text analysis;unsupervised learning","English;automatic categorization problem;automatic unlabeled document grouping;classification viewpoint;clusters;customer opinion grouping;customers reviews;electronic real-world data collections;natural language;textual documents processing;unsupervised machine learning","","0","","14","","","26-29 Sept. 2012","","IEEE","IEEE Conference Publications"
"Machine learning-based anomaly detection for post-silicon bug diagnosis","A. DeOrio; Q. Li; M. Burgess; V. Bertacco","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, 48109, USA","2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)","20130504","2013","","","491","496","The exponentially growing complexity of modern processors intensifies verification challenges. Traditional pre-silicon verification covers less and less of the design space, resulting in increasing post-silicon validation effort. A critical challenge is the manual debugging of intermittent failures on prototype chips, where multiple executions of a same test do not yield a consistent outcome. We leverage the power of machine learning to support automatic diagnosis of these difficult, inconsistent bugs. During post-silicon validation, lightweight hardware logs a compact measurement of observed signal activity over multiple executions of a same test: some may pass, somemay fail. Our novel algorithm applies anomaly detection techniques similar to those used to detect credit card fraud to identify the approximate cycle of a bug's occurrence and a set of candidate root-cause signals. Compared against other state-of-the-art solutions in this space, our new approach can locate the time of a bug's occurrence with nearly 4x better accuracy when applied to the complex OpenSPARC T2 design.","1530-1591;15301591","Electronic:978-3-9815370-0-0; POD:978-1-4673-5071-6","10.7873/DATE.2013.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6513558","","Clustering algorithms;Computer bugs;Detection algorithms;Hardware;Machine learning algorithms;Time measurement;Training data","","","","6","","12","","","18-22 March 2013","","IEEE","IEEE Conference Publications"
"Modeling and Evaluation of Machine Learning Based Network Management System for NGN","A. Bashar","Coll. of Comput. Eng. & Sci., Prince Mohammad Bin Fahd Univ., Al-Khobar, Saudi Arabia","2013 27th International Conference on Advanced Information Networking and Applications Workshops","20130701","2013","","","1473","1478","The recent emphasis on monitoring and managing telecommunication networks in more intelligent and autonomic manner has led to the emergence and popularity of Machine Learning based Network Management Systems. In order to study the behavior and assess the performance of such NMS, it is essential that a suitable modeling and evaluation framework exists. The work presented here addresses this need and proposes an autonomic NMS which employs the prediction capabilities of the Bayesian Networks (BN) models. To achieve this, it formulates and models the BN-based Decision Support System for providing real-time decisions with regard to the Call Admission Control (CAC) problem in the Next Generation Network (NGN) environment. Simulated experiments are performed to verify the suitability and practicality of the proposed models. The novelty and relevance of this research is demonstrated through offline modeling and online performance evaluation of BNAC (Bayesian Networks-based Admission Control) by considering the metrics of Packet Delay, Packet Loss, Queue Size and Blocking Probability. The paper concludes that BNAC approach performs better than the Peak Rate CAC in terms of online CAC functionality.","","Electronic:978-0-7695-4952-1; POD:978-1-4673-6239-9; USB:978-0-7695-4952-1","10.1109/WAINA.2013.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550604","Bayesian Networks;Call Admission Control;Network Management System;Next Generation Network","Bayes methods;Decision support systems;Delays;Next generation networking;Packet loss","Bayes methods;computer network management;control engineering computing;decision support systems;delays;learning (artificial intelligence);mobility management (mobile radio);next generation networks;performance evaluation;probability;queueing theory;telecommunication congestion control","BNAC;Bayesian network-based admission control;CAC;NGN;NMS;blocking probability;call admission control problem;decision support system;machine learning;packet delay;packet loss;performance evaluation;queue size;telecommunication network management system","","1","","18","","","25-28 March 2013","","IEEE","IEEE Conference Publications"
"Mapping the Internet: Geolocating Routers by Using Machine Learning","A. Prieditis; G. Chen","Neustar Labs., Mountain View, CA, USA","2013 Fourth International Conference on Computing for Geospatial Research and Application","20130919","2013","","","101","105","Knowing the geolocation of a router can help to predict the geolocation of an Internet user, which is important for local advertising, fraud detection, and geo-fencing applications. For example, the geolocation of the last router on the path to a user is a reasonable guess for the user's geolocation. Current methods for geolocating a router are based on parsing a router's name to find geographic hints. Unfortunately, these methods are noisy and often provide no hints. This paper presents results on using machine learning methods to ""sharpen"" a router's noisy location based on the time delay between one or more routers and a target router or end user IP address. The novelty of this approach is that geolocation of the one or more routers is not required to be known.","","Electronic:978-0-7695-5012-1; POD:978-1-4799-0301-6","10.1109/COMGEO.2013.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6602048","Clustering;Geolocation;Machine Learning;Prediction","Clustering algorithms;Computers;Geology;IP networks;Internet;Noise measurement;Training","Internet;geography;learning (artificial intelligence)","Internet;fraud detection;geo-fencing;local advertising;machine learning methods;time delay","","0","","8","","","22-24 July 2013","","IEEE","IEEE Conference Publications"
"A short review on the application of computational intelligence and machine learning in the bioenvironmental sciences","S. Fukuda; B. De Baets","Institute of Tropical Agriculture, Kyushu University, Fukuoka, Japan","The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems","20130422","2012","","","106","110","This paper aims to provide a short review on the application of computational intelligence (CI) and machine learning (ML) in the bioenvironmental sciences. To clearly illustrate the current status, we limit our focus to some key approaches, namely fuzzy systems (FSs), artificial neural networks (ANNs) and genetic algorithms (GAs) as well as some ML methods. The trends in the application studies are categorized based on the targets of the model such as animal, fish, plant, soil and water. We give an overview of specific topics in the bioenvironmental sciences on the basis of the review papers on model comparisons in the field. The summary of the modelling approaches with respect to their aim and potential application fields can promote the use of CI and ML in the bioenvironmental sciences.","","Electronic:978-1-4673-2743-5; POD:978-1-4673-2742-8","10.1109/SCIS-ISIS.2012.6505311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6505311","biology;environment;knowledge-based modelling;predictive modelling;spatiotemporal modelling","","biology computing;genetic algorithms;learning (artificial intelligence)","ANN;CI;FS;GA;artificial neural networks;bioenvironmental sciences;computational intelligence;fuzzy systems;genetic algorithms;machine learning","","0","","14","","","20-24 Nov. 2012","","IEEE","IEEE Conference Publications"
