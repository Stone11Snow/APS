"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5620916,6110956,6095486,6107890,6106486,5871647,5714717,6103444,6102090,6103383,6102108,6103399,6103338,6103439,6103461,6064897,6100295,5955081,6096574,5995172,6090737,6088224,6090220,6089335,6092648,5959985,6084055,6083794,5959167,6083733,6083998,6084112,6083741,6083845,6080801,6082211,5934438,5910412,6079396,6082916,6081097,6080942,5753882,5871585,6076539,6072825,6070377,6074384,6032714,6065634,6065715,6065208,6067610,6065716,6067047,6065414,6063405,6063601,6061664,6060321,6062032,6059997,6061328,6061464,6059933,6061479,6062118,6061226,5567099,6052011,6049592,6047850,6049369,6045955,6042728,6045143,6045098,6041863,6044305,6032536,6040836,6038084,6040507,6037290,6038590,6041410,6038600,6034918,5937024,6032259,6033117,6030361,6031517,6027200,6026089,5723040,5601723,6022143,6022100,5732709",2017/05/05 22:10:02
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Using KEEL software as a educational tool: A case of study teaching data mining","J. Derrac; J. Luengo; J. Alcalá-Fdez; A. Fernández; S. García","Department of Computer Science and Artificial Intelligence, CITIC-UGR, University of Granada, 18071, Spain","2011 7th International Conference on Next Generation Web Services Practices","20111201","2011","","","464","469","Regarding information technologies, transnational education has to face several challenges in order to offer a suitable education for computer science students worldwide. Software tools, and specially open source ones, give to the students the possibility of experiment with the most known techniques in the area. Among them, the KEEL software tool can be highlighted as a versatile framework for understanding the mechanics of several computational intelligence fields. The aim of this contribution is to present the educational aspects of KEEL software: An educational module well suited to be used in Data Mining, Machine Learning and Knowledge Discovery in Databases courses. This module provides the user with a visual feedback of the progress of the algorithms, thus being helpful in the task of evaluating and understanding the behavior of classic and modern techniques in these fields.","","Electronic:978-1-4577-1127-5; POD:978-1-4577-1125-1","10.1109/NWeSP.2011.6088224","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6088224","Data Mining;Educational Tool;Java;Knowledge Discovery in Databases;Machine Learning;Software Tool","Accuracy;Algorithm design and analysis;Biological system modeling;Data mining;Software algorithms;Software tools","computer aided instruction;computer science education;data mining;software tools","KEEL software;computational intelligence field;computer science student;data mining;databases course;educational tool;information technology;knowledge discovery;machine learning;software tool;transnational education","","2","","16","","","19-21 Oct. 2011","","IEEE","IEEE Conference Publications"
"Predicting Metal-Binding Sites from Protein Sequence","A. Passerini; M. Lippi; P. Frasconi","University of Trento, Trento","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20111114","2012","9","1","203","213","Prediction of binding sites from sequence can significantly help toward determining the function of uncharacterized proteins on a genomic scale. The task is highly challenging due to the enormous amount of alternative candidate configurations. Previous research has only considered this prediction problem starting from 3D information. When starting from sequence alone, only methods that predict the bonding state of selected residues are available. The sole exception consists of pattern-based approaches, which rely on very specific motifs and cannot be applied to discover truly novel sites. We develop new algorithmic ideas based on structured-output learning for determining transition-metal-binding sites coordinated by cysteines and histidines. The inference step (retrieving the best scoring output) is intractable for general output types (i.e., general graphs). However, under the assumption that no residue can coordinate more than one metal ion, we prove that metal binding has the algebraic structure of a matroid, allowing us to employ a very efficient greedy algorithm. We test our predictor in a highly stringent setting where the training set consists of protein chains belonging to SCOP folds different from the ones used for accuracy estimation. In this setting, our predictor achieves 56 percent precision and 60 percent recall in the identification of ligand-ion bonds.","1545-5963;15455963","","10.1109/TCBB.2011.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5871585","Metal-binding prediction;greedy algorithms.;machine learning;structured-output learning","Bioinformatics;Bonding;Greedy algorithms;Ions;Metals;Proteins;Three dimensional displays","biochemistry;biology computing;combinatorial mathematics;genomics;greedy algorithms;learning (artificial intelligence);molecular biophysics;proteins","SCOP folds;algebraic structure;bonding state;cysteines;genomic scale;greedy algorithm;histidines;ligand-ion bonds;matroid;pattern-based approach;protein chains;protein sequence;structured-output learning;training set;transition-metal-binding sites","Amino Acid Sequence;Binding Sites;Computational Biology;Databases, Protein;Metals;Molecular Sequence Data;Proteins;Sequence Analysis, Protein","4","","41","","20110609","Jan.-Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Incremental Learning From Stream Data","H. He; S. Chen; K. Li; X. Xu","Department of Electrical, Computer, and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA","IEEE Transactions on Neural Networks","20111212","2011","22","12","1901","1914","Recent years have witnessed an incredibly increasing interest in the topic of incremental learning. Unlike conventional machine learning situations, data flow targeted by incremental learning becomes available continuously over time. Accordingly, it is desirable to be able to abandon the traditional assumption of the availability of representative training data during the training period to develop decision boundaries. Under scenarios of continuous data flow, the challenge is how to transform the vast amount of stream raw data into information and knowledge representation, and accumulate experience over time to support future decision-making process. In this paper, we propose a general adaptive incremental learning framework named ADAIN that is capable of learning from continuous raw data, accumulating experience over time, and using such knowledge to improve future learning and prediction performance. Detailed system level architecture and design strategies are presented in this paper. Simulation results over several real-world data sets are used to validate the effectiveness of this method.","1045-9227;10459227","","10.1109/TNN.2011.2171713","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064897","Adaptive classification;concept shifting;data mining;incremental learning;machine learning;mapping function","Data mining;Distribution functions;Learning systems;Machine learning;Support vector machines","data handling;decision making;knowledge representation;learning (artificial intelligence)","ADAIN;data flow;decision making process;incremental learning;knowledge representation;machine learning;representative training data;stream data","Algorithms;Artificial Intelligence;Computer Simulation;Data Mining;Information Storage and Retrieval;Models, Theoretical;Pattern Recognition, Automated","29","1","63","","20111031","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Predicting software defects: A cost-sensitive approach","M. E. R. Bezerra; A. L. I. Oliveiray; P. J. L. Adeodatoz","Center of Informatics, Federal University of Pernambuco, UFPE, Recife PE, Brazil, 50.732-970","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","2515","2522","Find software defects is a complex and slow task which consumes most of the development budgets. In order to try reducing the cost of test activities, many researches have used machine learning to predict whether a module is defect-prone or not. Defect detection is a cost-sensitive task whereby a misclassification is more costly than a correct classification. Yet, most of the researches do not consider classification costs in the prediction models. This paper introduces an empirical method based in a COCOMO (COnstructive COst MOdel) that aims to assess the cost of each classifier decision. This method creates a cost matrix that is used in conjunction with a threshold-moving approach in a ROC (Receiver Operating Characteristic) curve to select the best operating point regarding cost. Public data sets from NASA (National Aeronautics and Space Administration) IV&V (Independent Verification & Validation) Facility Metrics Data Program (MDP) are used to train the classifiers and to provide some development effort information. The experiments are carried out through a methodology that complies with validation and reproducibility requirements. The experimental results have shown that the proposed method is efficient and allows the interpretation of the classifier performance in terms of tangible cost values.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6084055","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6084055","COCOMO;Defect prediction;MDP;NASA;ROC curve;machine learning;pattern recognition;software metrics;testing costs","Equations;Mathematical model;NASA;Neurons;Software;Testing;Training","cost reduction;learning (artificial intelligence);matrix algebra;program debugging;program testing;software cost estimation","constructive cost model;cost matrix;cost reduction;cost-sensitive approach;defect detection;empirical method;machine learning;receiver operating characteristic curve;software defect prediction;threshold-moving approach","","2","","24","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"Privacy Preserving Decision Tree Learning Using Unrealized Data Sets","P. K. Fong; J. H. Weber-Jahnke","University of Victoria, Victoria","IEEE Transactions on Knowledge and Data Engineering","20111222","2012","24","2","353","364","Privacy preservation is important for machine learning and data mining, but measures designed to protect private information often result in a trade-off: reduced utility of the training samples. This paper introduces a privacy preserving approach that can be applied to decision tree learning, without concomitant loss of accuracy. It describes an approach to the preservation of the privacy of collected data samples in cases where information from the sample database has been partially lost. This approach converts the original sample data sets into a group of unreal data sets, from which the original samples cannot be reconstructed without the entire group of unreal data sets. Meanwhile, an accurate decision tree can be built directly from those unreal data sets. This novel approach can be applied directly to the data storage as soon as the first sample is collected. The approach is compatible with other privacy preserving approaches, such as cryptography, for extra protection.","1041-4347;10414347","","10.1109/TKDE.2010.226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620916","Classification;data mining;machine learning;security and privacy protection.","Classification;Cryptography;Data mining;Data privacy;Decision trees;Information security;Machine learning;Privacy","cryptography;data mining;data privacy;decision trees;learning (artificial intelligence)","cryptography;data mining;data storage;machine learning;privacy preservation;privacy preserving decision tree learning","","14","","19","","20101109","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Automated extraction of non <h>-tagged headers in webpages by decision trees","H. Okada; H. Arakawa","Graduate School of Engineering, Kyoto Sangyo University, Kyoto, Japan","SICE Annual Conference 2011","20111027","2011","","","2117","2120","The guideline #5.2a in the JIS X 8341-3 reccomends to “represent headings with heading elements instead of difference in font size, etc”. Thus, in checking webpage accessibility, headers that are not tagged with heading tags (<;h1>;-<;h6>;) should be extracted as problems. In this paper, we propose a method for the extraction. Our idea is to let a machine learning method to automatically derive extraction rules from problem instances on the web. We define 26 attributes of HTML elements for deriving the rules. Values of these attributes are calculated by parsing the HTML source of the webpage. Accuracy of our method was evaluated by 10-fold cross validations with the data we collected from the web. The accuracy was 85-88% in average in terms of F-measure. Non <;h>;-tagged image headers were slightly better discriminated than non <;h>;-tagged text headers.","pending","DVD:978-1-907764-38-7; Electronic:978-4-907764-39-5; POD:978-1-4577-0714-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060321","Web accessibility;automated checking;decision tree;heading;machine learning","Accuracy;Decision trees;Guidelines;HTML;Learning systems;Machine learning;Vegetation","Internet;decision trees;hypermedia markup languages;learning (artificial intelligence);program compilers;text analysis","10-fold cross validation;F measure;HTML element;HTML source parsing;JIS X 8341-3;Web page;automated extraction rule;decision tree;heading element;heading tag;machine learning method;non <;h>;-tagged text header;non<;h>;tagged image header","","0","","5","","","13-18 Sept. 2011","","IEEE","IEEE Conference Publications"
"Comprehensive performance analysis of Spatio-Temporal Data Mining approach on multi-temporal coastal remote sensing datasets","B. Gokaraju; S. S. Durbha; R. L. King; N. H. Younan","GeoResources Institute (GRI), Center for Advanced Vehicular Systems (CAVS), Mississippi State University, 39762-9571, USA","2011 IEEE International Geoscience and Remote Sensing Symposium","20111020","2011","","","2153","2156","The present study discusses about the new textural feature extraction, its improvement and a comprehensive analysis of our previous Machine Learning based Spatio-Temporal (STML-HAB) Data Mining approach for HAB detection mentioned in Ref. [2]. This study is an elaborative analysis extending our first results presented in Ref. [2]. The additional Wavelet and GLCM textural features helped in improving the performance up to an accuracy of 0.9259 'K' using SeaWiFS sensor data. This is a significant improvement of almost 17% compared to our first results with an accuracy of (0.7513 'K').","2153-6996;21536996","DVD:978-1-4577-1004-9; Electronic:978-1-4577-1005-6; POD:978-1-4577-1003-2","10.1109/IGARSS.2011.6049592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6049592","Machine Learning;Spatio-Temporal;Support Vector Machines","Analytical models;Data mining;Data models;Feature extraction;Remote sensing;Sea measurements;Support vector machines","data mining;feature extraction;geophysics computing;learning (artificial intelligence);oceanographic techniques;remote sensing;support vector machines","GLCM textural feature;HAB detection;SeaWiFS sensor data;comprehensive performance analysis;machine learning based spatiotemporal data mining approach;multitemporal coastal remote sensing datasets;support vector machines;textural feature extraction;wavelet textural feature","","0","","5","","","24-29 July 2011","","IEEE","IEEE Conference Publications"
"Research of the classification feature selection based on artificial immune computation","Y. Xing; W. Xiang; L. Ye","College of Computer Science of ChongQing University, ChongQing University, Chongqing, China","2011 International Conference on Electronics, Communications and Control (ICECC)","20111103","2011","","","2778","2781","Feature selection is the important research in the current field of information, particularly the field of pattern recognition. In order to reduce the dimension of attributes and improve the classification accuracy, a algorithm of the classification feature selection based on artificial immune computation (CFSAIC) was proposed. Did simulation experiments with the data sets of Ionosphere, wdbc and pima-indians-diabetes respectively, selected a group of optimum feature subset, then constructed classifier with KNN Rule. It shows that the algorithm of feature selection based on artificial immune computation reduces the data dimension, after constructing classifier with KNN, it improves the classification accuracy comparing to KNN, and also higher than the algorithms of AINC, CSA, MVIN and FCM.","","Electronic:978-1-4577-0321-8; POD:978-1-4577-0320-1","10.1109/ICECC.2011.6067610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6067610","artificial immune;classification;feature selection;immune computing;machine learning","Accuracy;Algorithm design and analysis;Classification algorithms;Cloning;Diabetes;Immune system;Ionosphere","artificial immune systems;feature extraction;learning (artificial intelligence);pattern classification;set theory","CFSAIC algorithm;KNN rule classifier;classification accuracy improvement;classification feature selection based on artificial immune computation;ionosphere data sets;optimum feature subset;pattern recognition;pimaindians-diabetes data sets;wdbc data sets","","0","","7","","","9-11 Sept. 2011","","IEEE","IEEE Conference Publications"
"A Two-Layer SVM Classification Mechanism for Chinese Blog Article","G. H. Luo; J. c. Liu; S. M. Yuan","Inst. of Comput. Sci. & Eng., Nat. Chiao-Tung Univ., Hsinchu, Taiwan","2011 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20111117","2011","","","9","15","In Taiwan, the famous bloggers can be regard as professional writers now. More and more people subscribe their RSS (Really Simple Syndication) to receive updated information. But readers might only interest in few categories of articles, readers need to filter other articles by themselves. In order to help people select the information they want, this research proposed a two-layer SVM classification mechanism to classify blog articles. The schema is also evaluated in this research and the experiment result the proposed schema achieves 87% of recall and 95% of precision.","","Electronic:978-0-7695-4557-8; POD:978-1-4577-1827-4","10.1109/CyberC.2011.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079396","Article Classification;Blog;Data Mining;Machine Learning","Blogs;Dictionaries;Filtering;Support vector machine classification;Text categorization;Training","Web sites;classification;support vector machines","Chinese blog article;RSS;SVM;Taiwan;classification mechanism;really simple syndication","","0","","31","","","10-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"Categorizing software applications for maintenance","C. McMillan; M. Linares-Vásquez; D. Poshyvanyk; M. Grechanik","Department of Computer Science, The College of William and Mary, Williamsburg, Virginia, USA","2011 27th IEEE International Conference on Software Maintenance (ICSM)","20111117","2011","","","343","352","Software repositories hold applications that are often categorized to improve the effectiveness of various maintenance tasks. Properly categorized applications allow stakeholders to identify requirements related to their applications and predict maintenance problems in software projects. Unfortunately, for different legal and organizational reasons the source code is often not available, thus making it difficult to automatically categorize binary executables of software applications. In this paper, we propose a novel approach in which we use Application Programming Interface (API) calls from third-party libraries as attributes for automatic categorization of software applications that use these API calls. API calls can be extracted from source code and more importantly, from the byte-code of applications, thus making automatic categorization approaches applicable to closed source repositories. We evaluate our approach along with other machine learning algorithms for software categorization on two large Java repositories: an open-source repository containing 3,286 projects and a closed-source one with 745 applications. Our contribution is twofold: not only do we propose a new approach that makes it possible to categorize software projects without any source code using a small number of API calls as attributes, but also we carried out the first comprehensive empirical evaluation of automatic categorization approaches.","1063-6773;10636773","Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9","10.1109/ICSM.2011.6080801","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080801","closed-source;machine learning;open-source;software categorization","Companies;Entropy;Java;Libraries;Machine learning algorithms;Software;Support vector machines","Java;application program interfaces;learning (artificial intelligence);project management;public domain software;software maintenance;software management","API calls;Java repository;application programming interface;automatic categorization;binary executables;byte-code;categorizing software applications;closed source repository;closed-source repository;legal reasons;machine learning algorithms;maintenance tasks;open-source repository;organizational reasons;predict maintenance problems;software categorization;software projects;software repository;source code;third-party library","","13","","29","","","25-30 Sept. 2011","","IEEE","IEEE Conference Publications"
"Contextual Decision Making in General Game Playing","X. Sheng; D. Thuente","Comput. Sci. Dept., North Carolina State Univ., Raleigh, NC, USA","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","679","684","General Game Playing refers to designing Artificial Intelligence agents that are capable of playing different games without human intervention. The games are defined by sets of rules represented in logic descriptions and the agent players interact in a multi-agent system with a game server coordinating the legality of the operations and keeping the players informed of the state changes. This paper describes a general game agent that isolates the heuristic search coverage for contextual decision making by efficiently creating dynamic decision trees. The influence of certain game features is evaluated within the current decision context rather than on the whole game scale. The benefit of this approach is shown by performance comparison with agents that do search, learning, and learning with decision trees. We show this for a variety of games and have compared favorably against well known general game players and replicated actions of known human expert strategies.","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103399","General Game Playing;decision making;decision tree;machine learning","Algorithm design and analysis;Context;Decision making;Decision trees;Games;Humans;Training","artificial intelligence;decision trees;multi-agent systems","artificial intelligence;contextual decision making;dynamic decision trees;general game playing;heuristic search coverage;logic descriptions;multi agent system","","1","","18","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"A Multi-objective Genetic Algorithm for Pruning Support Vector Machines","M. F. A. Hady; W. Herbawi; M. Weber; F. Schwenker","Inst. of Neural Inf. Process., Univ. of Ulm, Ulm, Germany","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","269","275","Support vector machines (SVMs) often contain a large number of support vectors which reduce the run-time speeds of decision functions. In addition, this might cause an over fitting effect where the resulting SVM adapts itself to the noise in the training set rather than the true underlying data distribution and will probably fail to correctly classify unseen examples. To obtain more fast and accurate SVMs, many methods have been proposed to prune SVs in trained SVMs. In this paper, we propose a multi-objective genetic algorithm to reduce the complexity of support vector machines as well as to improve generalization accuracy by the reduction of over fitting. Experiments on four benchmark datasets show that the proposed evolutionary approach can effectively reduce the number of support vectors included in the decision functions of SVMs without sacrificing their classification accuracy.","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103338","Support vector machines;data mining;machine learning;multi-objective genetic algorithm","Complexity theory;Genetic algorithms;Kernel;Optimization;Support vector machines;Training;Vectors","computational complexity;genetic algorithms;pattern classification;support vector machines","complexity reduction;data distribution;multiobjective genetic algorithm;support vector machine pruning","","1","","18","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Knowledge Discovery Employing Grid Scheme Least Squares Support Vector Machines Based on Orthogonal Design Bee Colony Algorithm","T. J. Hsieh; W. C. Yeh","Dept. of Ind. Eng. &amp; Eng. Manage., Nat. Tsing Hua Univ., Hsinchu, Taiwan","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20110915","2011","41","5","1198","1212","This paper proposes a concept for machine learning that integrates a grid scheme (GS) into a least squares support vector machine (LSSVM) (called GS-LSSVM) with a mixed kernel in order to solve data classification problems. The purpose of GS-LSSVM is to execute feature selections, mixed kernel applications, and parameter optimization in a learning paradigm. The proposed learning paradigm includes three steps. First, an orthogonal design is utilized to initialize the number of input features and candidate parameters stored in GS. Then, the features are randomly selected according to the first grid acquired from the first step. These features and the candidate parameters are then passed to LSSVM. Finally, an artificial bee colony algorithm, the recently popular heuristic algorithm, is used to optimize parameters for LSSVM learning. For illustration and evaluation purposes, ten remarkable data sets from the University of California Irvine database are used as testing targets. The experimental results reveal that the proposed GS-LSSVM can produce a classification model more easily interpreted using a small number of features. In terms of accuracy (hit ratio), the GS-LSSVM can significantly outperform other methods listed in this paper. These findings imply that the GS-LSSVM is a promising approach to classification exploration.","1083-4419;10834419","","10.1109/TSMCB.2011.2116007","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5732709","Artificial bee colony (ABC) algorithm;classification;feature selection;grid scheme (GS);least squares support vector machines (LSSVMs);machine learning;orthogonal design (OD)","Algorithm design and analysis;Artificial neural networks;Computational modeling;Machine learning;Optimization;Support vector machines;Upper bound","data mining;grid computing;learning (artificial intelligence);optimisation;pattern classification;support vector machines","University of California Irvine database;data classification problems;feature selections;grid scheme least squares support vector machines;knowledge discovery;machine learning;mixed kernel applications;orthogonal design bee colony algorithm;parameter optimization","Classification;Cybernetics;Least-Squares Analysis;Support Vector Machines","18","","33","","20110317","Oct. 2011","","IEEE","IEEE Journals & Magazines"
"Chinese event place phrase recognition of emergency event using Maximum Entropy","F. Zhu; Z. Liu; J. Yang; P. Zhu","School of Computer Engineering and Science, Shanghai University, Shanghai, China","2011 IEEE International Conference on Cloud Computing and Intelligence Systems","20111013","2011","","","614","618","This paper provides a new method combining Maximum Entropy with rules for identify event place phrase. Firstly, all phrases which not include event trigger are extracted from event mention, and a rule base about event place phrases analyzes and filters these phrases for obtaining the phrase candidate set. Secondly, we explore some rich text features from three kinds of linguistics features that contain phrase, event trigger and context information. Thirdly, in order to establish a train set, we use some feature words representing these text features to build feature vector space. Then, a machine learning model to identify event place phrase is trained by using L-BFGS functions algorithm. At last, this predictive model is used to classify the test set. The result shows that the method is efficient. In open test, the recall, precision and F-measure reach 0.6296296, 0.8095238 and 0.7083333 respectively.","2376-5933;23765933","Electronic:978-1-61284-204-2; POD:978-1-61284-203-5","10.1109/CCIS.2011.6045143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045143","Chinese event place phrase recognition;Machine learning;Maximum Entropy;Natural language processing;Rule-based filtering","Adaptation models;Data mining;Entropy;Kernel;Machine learning;Pragmatics;Support vector machines","entropy;knowledge based systems;learning (artificial intelligence);natural language processing;pattern classification;text analysis","Chinese event place phrase recognition;L-BFGS functions algorithm;emergency event;feature vector space;identify event place phrase;linguistics features;machine learning model;maximum entropy;natural language processing;phrase candidate set;predictive model;rule-based filtering;test set classification;text features","","0","","11","","","15-17 Sept. 2011","","IEEE","IEEE Conference Publications"
"Mini-crowdsourcing end-user assessment of intelligent assistants: A cost-benefit study","A. Shinsel; T. Kulesza; M. Burnett; W. Curran; A. Groce; S. Stumpf; W. K. Wong","Oregon State University, Corvallis, U.S.A.","2011 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)","20111110","2011","","","47","54","Intelligent assistants sometimes handle tasks too important to be trusted implicitly. End users can establish trust via systematic assessment, but such assessment is costly. This paper investigates whether, when, and how bringing a small crowd of end users to bear on the assessment of an intelligent assistant is useful from a cost/benefit perspective. Our results show that a mini-crowd of testers supplied many more benefits than the obvious decrease in workload, but these benefits did not scale linearly as mini-crowd size increased - there was a point of diminishing returns where the cost-benefit ratio became less attractive.","1943-6092;19436092","Electronic:978-1-4577-1247-0; POD:978-1-4577-1246-3","10.1109/VLHCC.2011.6070377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6070377","crowdsourcing;end-user programming;machine learning;testing","Analysis of variance;Educational institutions;Reliability;Software;Software testing;Systematics","cost-benefit analysis;intelligent design assistants;program testing","cost-benefit ratio;cost-benefit study;diminishing returns;intelligent assistants;mini-crowd size;mini-crowdsourcing end-user assessment;systematic assessment","","2","","20","","","18-22 Sept. 2011","","IEEE","IEEE Conference Publications"
"An Analysis of the Accuracy of Wearable Sensors for Classifying the Causes of Falls in Humans","O. Aziz; S. N. Robinovitch","Injury Prevention and Mobility Laboratory, Simon Fraser University, Burnaby, Canada","IEEE Transactions on Neural Systems and Rehabilitation Engineering","20111205","2011","19","6","670","676","Falls are the number one cause of injury in older adults. Wearable sensors, typically consisting of accelerometers and/or gyroscopes, represent a promising technology for preventing and mitigating the effects of falls. At present, the goal of such “ambulatory fall monitors” is to detect the occurrence of a fall and alert care providers to this event. Future systems may also provide information on the causes and circumstances of falls, to aid clinical diagnosis and targeting of interventions. As a first step towards this goal, the objective of the current study was to develop and evaluate the accuracy of a wearable sensor system for determining the causes of falls. Sixteen young adults participated in experimental trials involving falls due to slips, trips, and “other” causes of imbalance. Three-dimensional acceleration data acquired during the falling trials were input to a linear discriminant analysis technique. This routine achieved 96% sensitivity and 98% specificity in distinguishing the causes of a falls using acceleration data from three markers (left ankle, right ankle, and sternum). In contrast, a single marker provided 54% sensitivity and two markers provided 89% sensitivity. These results indicate the utility of a three-node accelerometer array for distinguishing the cause of falls.","1534-4320;15344320","","10.1109/TNSRE.2011.2162250","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995172","Accelerometers;aging;balance;biomechanics;fall detection;falls;injury;linear discriminant analysis (LDA);machine learning;postural stability","Accelerometers;Failure analysis;Injuries;Machine learning;Sternum;Wearable sensors","accelerometers;biomechanics;biomedical equipment;geriatrics;gyroscopes;injuries;patient diagnosis","acceleration data;ambulatory fall monitoring;clinical diagnosis;gyroscopes;injury;linear discriminant analysis technique;older adults;slips;three-dimensional acceleration data;three-node accelerometer array;wearable sensor system","Acceleration;Accidental Falls;Adult;Algorithms;Ankle;Biomechanics;Data Interpretation, Statistical;False Negative Reactions;False Positive Reactions;Female;Functional Laterality;Head Movements;Humans;Linear Models;Male;Monitoring, Ambulatory;Pelvis;Reproducibility of Results;Risk;Sternum;Transducers;Young Adult","26","","26","","20110822","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Discriminative Reranking for Spoken Language Understanding","M. Dinarelli; A. Moschitti; G. Riccardi","Department of Information Engineering and Computer Science","IEEE Transactions on Audio, Speech, and Language Processing","20111212","2012","20","2","526","539","Spoken language understanding (SLU) is concerned with the extraction of meaning structures from spoken utterances. Recent computational approaches to SLU, e.g., conditional random fields (CRFs), optimize local models by encoding several features, mainly based on simple n-grams. In contrast, recent works have shown that the accuracy of CRF can be significantly improved by modeling long-distance dependency features. In this paper, we propose novel approaches to encode all possible dependencies between features and most importantly among parts of the meaning structure, e.g., concepts and their combination. We rerank hypotheses generated by local models, e.g., stochastic finite state transducers (SFSTs) or CRF, with a global model. The latter encodes a very large number of dependencies (in the form of trees or sequences) by applying kernel methods to the space of all meaning (sub) structures. We performed comparative experiments between SFST, CRF, support vector machines (SVMs), and our proposed discriminative reranking models (DRMs) on representative conversational speech corpora in three different languages: the ATIS (English), the MEDIA (French), and the LUNA (Italian) corpora. These corpora have been collected within three different domain applications of increasing complexity: informational, transactional, and problem-solving tasks, respectively. The results show that our DRMs consistently outperform the state-of-the-art models based on CRF.","1558-7916;15587916","","10.1109/TASL.2011.2162322","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5955081","Kernel methods;machine learning;natural language processing (NLP);spoken language understanding (SLU);stochastic language models;support vector machines (SVMs)","Cities and towns;Kernel;Labeling;Media;Semantics;Speech;Training","linguistics;speech synthesis;stochastic systems;support vector machines","ATIS;LUNA;MEDIA;computational approaches;discriminative reranking;spoken language understanding;stochastic finite state transducers;support vector machines","","5","","62","","20110718","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Higher Order Naïve Bayes: A Novel Non-IID Approach to Text Classification","M. C. Ganiz; C. George; W. M. Pottenger","Dogus University, Istanbul","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","7","1022","1034","The underlying assumption in traditional machine learning algorithms is that instances are Independent and Identically Distributed (IID). These critical independence assumptions made in traditional machine learning algorithms prevent them from going beyond instance boundaries to exploit latent relations between features. In this paper, we develop a general approach to supervised learning by leveraging higher order dependencies between features. We introduce a novel Bayesian framework for classification termed Higher Order Naïve Bayes (HONB). Unlike approaches that assume data instances are independent, HONB leverages higher order relations between features across different instances. The approach is validated in the classification domain on widely used benchmark data sets. Results obtained on several benchmark text corpora demonstrate that higher order approaches achieve significant improvements in classification accuracy over the baseline methods, especially when training data is scarce. A complexity analysis also reveals that the space and time complexity of HONB compare favorably with existing approaches.","1041-4347;10414347","","10.1109/TKDE.2010.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567099","IID.;Machine learning;naïve bayes;statistical relational learning;text classification","Bayesian methods;Classification algorithms;Large scale integration;Machine learning;Machine learning algorithms;Mathematical model;Training data","Bayes methods;classification;learning (artificial intelligence);text analysis","higher order naïve Bayes;independent and identically distributed;machine learning;non-IID approach;supervised learning;text classification","","16","","32","","20100909","July 2011","","IEEE","IEEE Journals & Magazines"
"A Survey on Video Caption Extraction","H. Liu; C. Zhou; J. Shen","Coll. of Comput. Sci. & Technol., Harbin Eng. Univ., Harbin, China","2010 Fifth International Conference on Internet Computing for Science and Engineering","20111114","2010","","","43","50","Over the last few decades, Content-based image/video retrieval (CBIR/CBVR) problem have developed a new height. As one of the most impartment methods of CBVR, video caption extraction obtained more and more application. A large number of techniques have been proposed to address this problem, we summarized most of the video caption extraction methods, analyzed the advantage and disadvantage of the existed methods. The purpose of this paper is to classify and review these algorithms, discuss benchmark data and performance evaluation, and to point out promising directions for future research.","2330-9857;23309857","Electronic:978-0-7695-4339-0; POD:978-1-4244-9954-0","10.1109/ICICSE.2010.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6076539","caption detection;content-based video retrieval;machine learning;video caption;video caption extraction","Feature extraction;Image color analysis;Optical character recognition software;Robustness;Semantics;Streaming media;Support vector machines","feature extraction;video retrieval;video signal processing","CBIR/CBVR;benchmark data;content based image/video retrieval;performance evaluation;video caption extraction","","0","","57","","","1-2 Nov. 2010","","IEEE","IEEE Conference Publications"
"Fall Detection with Wearable Sensors--Safe (Smart Fall Detection)","O. Ojetola; E. I. Gaura; J. Brusey","Coventry Univ., Coventry, UK","2011 Seventh International Conference on Intelligent Environments","20111031","2011","","","318","321","The high rate of falls incidence among the elderly calls for the development of reliable and robust fall detection systems. A number of such systems have been proposed, with claims of fall detection accuracy of over 90% based on accelerometers and gyroscopes. However, most such fall detection algorithms have been developed based on observational analysis of the data gathered, leading to thresholds setting for fall/non-fall situations. Whilst the fall detection accuracies reported appear to be high, there is little evidence that the threshold based methods proposed generalise well with different subjects and different data gathering strategies or experimental scenarios. Moreover, few attempts appear to have been made to validate the proposed methods in real-life scenarios or to deliver robust fall decisions in real-time. The research here uses machine learning and particularly decision trees to detect 4 types of falls (forward, backward, right and left). When applied to experimental data from 8 male subjects, the accelerometers and gyroscopes based system discriminates between activities of daily living (ADLs) and falls with a precision of 81% and recall of 92%. The performance and robustness of the method proposed has been further analysed in terms its sensitivity to subject physical profile and training set size.","","Electronic:978-0-7695-4452-6; POD:978-1-4577-0830-5","10.1109/IE.2011.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063405","Body Sensor Networks;MEMS Accelerometers;Machine Learning","Acceleration;Accelerometers;Accuracy;Angular velocity;Decision trees;Gyroscopes;Training","accelerometers;computerised instrumentation;decision trees;gyroscopes;learning (artificial intelligence);object detection;sensors","ADL;SAFE;accelerometers;decision trees;fall-nonfall situations;gyroscopes;machine learning;observational analysis;robust fall detection systems;smart fall detection;wearable sensors","","9","","13","","","25-28 July 2011","","IEEE","IEEE Conference Publications"
"Boosting Inductive Logic Programming via Decomposition, Merging, and Refinement","A. Chovanec; R. Bart´k","Fac. of Math. & Phys., Charles Univ. in Prague, Prague, Czech Republic","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","914","915","Inductive Logic Programming (ILP) deals with the problem of finding a hypothesis covering given positive examples and excluding negative examples. It is a sub field of machine learning that uses first-order logic as a uniform representation for examples and hypothesis. In this paper we propose a method to boost given ILP learning algorithm by first decomposing the set of examples to subsets and applying the learning algorithm to each subset separately, second, merging the hypotheses obtained for subsets to get a single hypothesis for the complete set of examples, and finally refining this single hypothesis to make it shorter.","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103444","boosting;inductive logic programming;machine learning;problem decomposition;solution refinement","Algorithm design and analysis;Boosting;Educational institutions;Logic programming;Machine learning algorithms;Merging;Proteins","inductive logic programming;learning (artificial intelligence);merging","ILP learning algorithm;first-order logic;inductive logic programming;machine learning;merging;problem decomposition","","0","","9","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Spectrum environment learning and prediction in cognitive radio","Y. Zhihui; F. Qi; S. Keqin","Nanjing University, Nanjing 210093, China","2011 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","20111027","2011","","","1","6","Using the theory of machine learning to spectrum cognition and management is a necessary requirement of realizing cognitive radio technology. Based on the objective license channel model, two evaluation parameters of packet loss rate and throughput are designed and simulated for analysis in this paper, according with the different service types of cognitive users. Study reveals that channel mean probability of error prediction related with vacancy state probability, which as a result, shows that the spectrum sensing performance of the cognitive user based on machine learning and prediction improves compared with random spectrum sensing both in packet loss rate and throughput.","","Electronic:978-1-4577-0894-7; POD:978-1-4577-0893-0","10.1109/ICSPCC.2011.6061664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6061664","channel time detection threshold;cognitive radio;machine learning;packet loss rate;throughput","Licenses;Machine learning;Sensors;Throughput;Upper bound;Wireless communication;Wireless sensor networks","cognitive radio;learning (artificial intelligence);probability","channel mean probability;cognitive radio;error prediction;machine learning;objective license channel model;packet loss rate and throughput;spectrum cognition;spectrum environment;vacancy state probability","","0","","8","","","14-16 Sept. 2011","","IEEE","IEEE Conference Publications"
"Deep and Wide: Multiple Layers in Automatic Speech Recognition","N. Morgan","International Computer Science Institute, Berkeley, CA, USA","IEEE Transactions on Audio, Speech, and Language Processing","20111219","2012","20","1","7","13","This paper reviews a line of research carried out over the last decade in speech recognition assisted by discriminatively trained, feedforward networks. The particular focus is on the use of multiple layers of processing preceding the hidden Markov model based decoding of word sequences. Emphasis is placed on the use of multiple streams of highly dimensioned layers, which have proven useful for this purpose. This paper ultimately concludes that while the deep processing structures can provide improvements for this genre, choice of features and the structure with which they are incorporated, including layer width, can also be significant factors.","1558-7916;15587916","","10.1109/TASL.2011.2116010","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714717","Machine learning;multilayer perceptrons;speech recognition","Acoustics;Artificial neural networks;Hidden Markov models;Speech;Speech recognition;Training;Vocabulary","hidden Markov models;speech recognition","automatic speech recognition;feedforward network;hidden Markov model based decoding;multiple streams","","35","","27","","20110217","Jan. 2012","","IEEE","IEEE Journals & Magazines"
"Japanese named entity recognition for question answering system","Y. Liu; F. Ren","Graduate School of Advanced Technology and Science, The University of Tokushima, Tokushima, Japan, Faculty of Engineering, The University of Tokushima, Japan","2011 IEEE International Conference on Cloud Computing and Intelligence Systems","20111013","2011","","","402","406","Current question answering (QA) systems usually contain named entity recognizer (NER) as a core component. NER is an important and difficult task in computational linguistics. It plays an important role in natural language processing application such as Question Answering, Machine Translation, and Information Retrieval etc. NER includes the identification and classification of certain proper nouns (like location, organization, person, data, money and others) in a text. The purpose of our study is to recognize and extract the exact Japanese sight seeing domain named entities. It is a basic step for the following processing: question analysis and keyword extraction information retrieval. As well as, through doing the named entity recognition, we consider that it can mine exact information from text document to respond to user. This paper describes how to do the Japanese sightseeing named entity recognition due to we are constructing a Japanese sightseeing question answering system. We adopt the hybrid method which combined with machine learning and rule-base method. In the experiment of Japanese sightseeing domain named entity recognition we have got excellent precision and recalling rates. It shows that our method is effective and can be used in a practical question answering system.","2376-5933;23765933","Electronic:978-1-61284-204-2; POD:978-1-61284-203-5","10.1109/CCIS.2011.6045098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045098","machine learning;named entity recognition;question answering system;rule-base","Data mining;Educational institutions;Machine learning;Organizations;Support vector machines;Text recognition;Training","information retrieval;language translation;natural language processing;speech recognition","Japanese named entity recognition;NER;QA;computational linguistics;keyword extraction information retrieval;machine translation;natural language processing;question answering system;text document","","1","","15","","","15-17 Sept. 2011","","IEEE","IEEE Conference Publications"
"Image feature extraction for solar flare prediction","X. Zhang; J. Liu; Q. Wang","Harbin Institute of Technology, 150001, China","2011 4th International Congress on Image and Signal Processing","20111212","2011","2","","910","914","Solar flare is the most violent solar activity which is the main driving source of space weather, so accurate prediction of flare occurrence in coming days would manner disaster treatment and protection. Due to detailed reasons of solar flares eruption are not clear in current field, so the prediction clues rely mainly on observing solar images. Many predictors have been used for solar flare prediction, mainly based on expert system or physical knowledge. In this paper, a system based on image information without prior physical knowledge for solar flare prediction is presented. The Magnetic field and texture distribution of active region, the largest sunspot group's fractal dimension, positive and negative areas and girth, extracted from SOHO/MDI longitudinal magnetograms are used in the model to describe the complexity of the photospheric magnetic field. Machine learning algorithms: C4.5 decision tree, CART tree and Bayesian network are employed to predict the flare level within 48 hours. It is concluded that the model trained by C4.5 decision tree could predict flare occurrence effectively.","","Electronic:978-1-4244-9306-7; POD:978-1-4244-9304-3","10.1109/CISP.2011.6100295","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100295","image data mining;image processing;machine learning","Decision trees;Feature extraction;Histograms;Magnetic fields;Magnetic flux;Magnetic resonance imaging;Predictive models","belief networks;decision trees;disasters;feature extraction;learning (artificial intelligence);solar flares;weather forecasting","Bayesian network;C4.5 decision tree;CART tree;SOHO/MDI longitudinal magnetograms;disaster protection;disaster treatment;expert system;flare occurrence;fractal dimension;image feature extraction;image information;machine learning;photospheric magnetic field;physical knowledge;solar flare prediction;solar flares eruption;solar images;space weather;sunspot group;texture distribution;violent solar activity","","2","","21","","","15-17 Oct. 2011","","IEEE","IEEE Conference Publications"
"The design and implementation of distributed mobile points of interest(POI) based on Mahout","Lin Ma; Haihong E; Ke Xu","PCN&CAD Center, Beijing University of Posts and Telecommunications, China","2011 6th International Conference on Pervasive Computing and Applications","20111219","2011","","","99","104","The paper is based on the machine learning development status and in-depth analysis and comparison of Mahout's machine learning algorithm, summarizes the principles of different Mahout's recommendation algorithm, characteristics, implementation method and function. Then the paper takes the characteristics of user recommendation system into consideration, design the user recommendation system, analysis the characteristics and issues of design and make further improvement; then make use of Mahout and Hadoop to accomplish the user recommendation system, which can dynamically capture user preferences, provide the user with recommendation when the user browses the web page. Finally, through practice, Hadoop and Mahout can meet the demand of massive data processing, and achieve a highly performance system by making use of the data re-processing method.","","Electronic:978-1-4577-0208-2; POD:978-1-4577-0209-9","10.1109/ICPCA.2011.6106486","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106486","Hadoop Distributed System;Machine Learning;Mahout;Points of Interest(POI)","Educational institutions;Information filters;Queueing analysis;Telecommunications","learning (artificial intelligence);recommender systems","Hadoop;Mahout recommendation algorithm;distributed mobile points of interest;machine learning development status;user preferences;user recommendation system","","0","","14","","","26-28 Oct. 2011","","IEEE","IEEE Conference Publications"
"Visual Analysis of Particle Behaviors to Understand Combustion Simulations","J. Wei; H. Yu; R. Grout; J. Chen; K. L. Ma","University of California, Davis","IEEE Computer Graphics and Applications","20111222","2012","32","1","22","33","Simulations of turbulent flames have used particles to capture the dynamic behavior of combustion in next-generation engines. Each particle includes a history of its movement positions and changing thermochemical states. Analyzing such a set of many millions of particles helps scientists understand turbulence. A dual-space method enables effective visual analysis of both the spatial movement and attribute evolution of particles. A cluster-label-classify strategy categorizes particles' attribute evolution curves. Intuitive tools integrate users' domain knowledge to steer the classification. The dual-space method has been used to analyze particle data in combustion simulations and can be applied to other scientific simulations involving particle-data analysis. This video shows an expository movie that combustion scientists have used when discussing their simulation results with colleagues. This simulation employs visual analysis in both the physical space and phase space, with categorization driven by supervised learning.","0272-1716;02721716","","10.1109/MCG.2011.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095486","artificial intelligence;computer graphics;graphics and multimedia;machine learning;modeling;simulation;visualization","Analytical models;Artificial intelligence;Clustering algorithms;Computational modeling;Computer graphics;Data models;Data visualization","combustion;data analysis;data visualisation;engines;learning (artificial intelligence);mechanical engineering computing;pattern classification;turbulence","cluster-label-classify strategy;combustion simulation;dual-space method;next-generation engines;particle attribute evolution curve;particle behaviors;particle-data analysis;supervised learning;turbulent flame simulation;user domain knowledge;visual analysis","","4","","5","","20111206","Jan.-Feb. 2012","","IEEE","IEEE Journals & Magazines"
"On the Feasibility of Predicting Radiological Observations from Computational Imaging Features of Liver Lesions in CT Scans","F. Gimenez; J. Xu; Y. Liu; T. T. Liu; C. F. Beaulieu; D. L. Rubin; S. Napel","Sch. of Med., Inf. Training Program, Stanford Univ., Stanford, CA, USA","2011 IEEE First International Conference on Healthcare Informatics, Imaging and Systems Biology","20111027","2011","","","346","350","We aim to predict radiological observations using computationally-derived imaging features extracted from CT images. Our dataset consists of 79 portal venous phase liver CT images containing lesions identified and annotated by a radiologist using a controlled vocabulary of 76 semantic terms. Computationally-derived features were extracted describing intensity, texture, shape, and edge sharpness. Linear discriminative analysis, logistic regression and LASSO were explored to predict the radiological observations using computational features. The approach was evaluated by leave one out cross-validation. Informative radiological observations such as lesion enhancement, hyper vascular attenuation, and homogeneous retention were discovered to be well-predicted by computational features. By exploiting relationships between computable and semantic features, this approach could lead to more accurate and efficient radiology reporting.","","Electronic:978-0-7695-4407-6; POD:978-1-4577-0325-6","10.1109/HISB.2011.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6061464","diagnostic imaging;image processing;machine learning;medical image analysis","Computed tomography;Feature extraction;Lesions;Liver;Semantics;Shape","computerised tomography;feature extraction;image texture;liver;medical image processing;radiology;regression analysis","CT Scans;LASSO;computable features;computational imaging features;edge sharpness;feature extraction;homogeneous retention;hyper vascular attenuation;intensity;leave one out cross validation;lesion enhancement;linear discriminative analysis;liver lesions;logistic regression;radiological observation prediction;semantic features;shape;texture;venous phase liver images","","5","","19","","","26-29 July 2011","","IEEE","IEEE Conference Publications"
"A Probabilistic Latent Factor approach to service ranking","G. Cassar; P. Barnaghi; K. Moessner","Centre for Communication Systems Research, University of Surrey, Guildford, UK, GU2 7XH","2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing","20111020","2011","","","103","109","In this paper we investigate the use of probabilistic machine-learning techniques to extract latent factors from semantically enriched service descriptions. The latent factors provide a model to represent service descriptions of any type in vector form. With this conversion, heterogeneous service descriptions can be represented on the same homogeneous plane thus achieving interoperability between different service description technologies. Automated service discovery and ranking is achieved by extracting latent factors from queries and representing the queries in vector form. Vector algebra can then be used to match services to the query. This approach is scalable to large service repositories and provides an efficient mechanism for publishing new services after the system is deployed.","","Electronic:978-1-4577-1481-8; POD:978-1-4577-1479-5","10.1109/ICCP.2011.6047850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6047850","machine-learning;ranking;semantics;service computing","Computational modeling;Feature extraction;Mathematical model;Organizations;Probabilistic logic;Semantics;Web services","feature extraction;learning (artificial intelligence);open systems;query processing;service-oriented architecture","automated service discovery;heterogeneous service description;latent factor extraction;probabilistic latent factor approach;probabilistic machine-learning technique;query match;service description;service description technology;service ranking;vector algebra","","4","","15","","","25-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Fast dependency-aware feature selection in very-high-dimensional pattern recognition","P. Somol; J. Grim; P. Pudil","Dept. of Pattern Recognition, Inst. of Information Theory and Automation, Czech Academy of Sciences, Pod vod&#x00E1;renskou v&#x011B;&#x017E;&#x00ED; 4, 182 08 Prague 8, Czech Republic","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","502","509","The paper addresses the problem of making dependency-aware feature selection feasible in pattern recognition problems of very high dimensionality. The idea of individually best ranking is generalized to evaluate the contextual quality of each feature in a series of randomly generated feature subsets. Each random subset is evaluated by a criterion function of arbitrary choice (permitting functions of high complexity). Eventually, the novel dependency-aware feature rank is computed, expressing the average benefit of including a feature into feature subsets. The method is efficient and generalizes well especially in very-high-dimensional problems, where traditional context-aware feature selection methods fail due to prohibitive computational complexity or to over-fitting. The method is shown well capable of over-performing the commonly applied individual ranking which ignores important contextual information contained in data.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083733","classification;feature selection;generalization;high dimensionality;machine learning;over-fitting;pattern recognition;ranking;stability","Accuracy;Computational complexity;Context;Optimization;Pattern recognition;Probes","computational complexity;feature extraction;learning (artificial intelligence);set theory;ubiquitous computing","context-aware feature selection method;dependency-aware feature rank;dependency-aware feature selection;prohibitive computational complexity;randomly generated feature subset;very high dimensionality;very-high-dimensional pattern recognition","","4","","48","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"A Real-Time Deformable Detector","K. Ali; F. Fleuret; D. Hasler; P. Fua","&#x00C9;cole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne (EPFL), Lausanne and Electronic Microtechnology (CSEM), Neuch&#x00E2;tel","IEEE Transactions on Pattern Analysis and Machine Intelligence","20111219","2012","34","2","225","239","We propose a new learning strategy for object detection. The proposed scheme forgoes the need to train a collection of detectors dedicated to homogeneous families of poses, and instead learns a single classifier that has the inherent ability to deform based on the signal of interest. We train a detector with a standard AdaBoost procedure by using combinations of pose-indexed features and pose estimators. This allows the learning process to select and combine various estimates of the pose with features able to compensate for variations in pose without the need to label data for training or explore the pose space in testing. We validate our framework on three types of data: hand video sequences, aerial images of cars, and face images. We compare our method to a standard boosting framework, with access to the same ground truth, and show a reduction in the false alarm rate of up to an order of magnitude. Where possible, we compare our method to the state of the art, which requires pose annotations of the training data, and demonstrate comparable performance.","0162-8828;01628828","","10.1109/TPAMI.2011.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5871647","Image processing and computer vision;machine learning;object detection.","Feature extraction;Image edge detection;Image processing;Learning systems;Machine learning;Object detection;Training data","object detection;pose estimation;real-time systems","AdaBoost procedure;aerial images;face images;object detection;pose estimators;real-time deformable detector;video sequences","","23","","35","","20110609","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Combining monocular and stereo-vision for real-time vehicle ranging and tracking on multilane highways","S. Sivaraman; M. M. Trivedi","","2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)","20111117","2011","","","1249","1254","In this paper, we introduce a novel stereo-monocular fusion approach to on-road localization and tracking of vehicles. Utilizing a calibrated stereo-vision rig, the proposed approach combines monocular detection with stereo-vision for on-road vehicle localization and tracking for driver assistance. The system initially acquires synchronized monocular frames and calculates depth maps from the stereo rig. The system then detects vehicles in the image plane using an active learning-based monocular vision approach. Using the image coordinates of detected vehicles, the system then localizes the vehicles in real-world coordinates using the calculated depth map. The vehicles are tracked both in the image plane, and in real-world coordinates, fusing information from both the monocular and stereo modalities. Vehicles' states are estimated and tracked using Kalman filtering. Quantitative analysis of tracks is provided. The full system takes 46ms to process a single frame.","2153-0009;21530009","Electronic:978-1-4577-2197-7; POD:978-1-4577-2198-4","10.1109/ITSC.2011.6082916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6082916","Active Safety;Driver Assistance;Machine Learning;Multi-sensor Fusion;Real-time Vision","Detectors;Equations;Feature extraction;Three dimensional displays;Trajectory;Vehicle detection;Vehicles","Kalman filters;driver information systems;stereo image processing","Kalman filtering;calibrated stereo-vision rig;depth map;driver assistance;monocular detection;monocular vision;multilane highways;on-road localization;on-road vehicle localization;real-time vehicle ranging;real-time vehicle tracking;stereo-monocular fusion","","17","","32","","","5-7 Oct. 2011","","IEEE","IEEE Conference Publications"
"Detection of Internet scam using logistic regression","M. Sharifi; E. Fink; J. G. Carbonell","Computer Science, Carnegie Mellon University, Pittsburgh, PA 15217, USA","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","2168","2172","Internet scam is fraudulent or intentionally misleading information posted on the web, usually with the intent of tricking people into sending money or disclosing sensitive information. We describe an application of logistic regression to detection of Internet scam. The developed system automatically collects 43 characteristic statistics about websites from 11 online sources and computes the probability that a given website is malicious. We present its empirical evaluation, which shows that its precision and recall are about 98%.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083998","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083998","Machine learning;web security","Encyclopedias;Google;Internet;Logistics;Security;Unsolicited electronic mail","Internet;Web sites;computer crime;fraud;probability;regression analysis","Internet scam detection;Web sites;World Wide Web;fraudulent information;intentionally misleading information;logistic regression;online sources;probability;sensitive information","","5","","12","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"An automatic approach to extracting review link from Chinese news pages","W. Liu","Inf. Source Center, Inst. of Sci. &amp; Tech. Inf. of China, Beijing, China","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","2","","411","415","Review links are widely used in some special kinds of web pages, especially news pages. They are very useful pieces of information in many applications, such as hot topic discovery and public opinion monitoring. Unfortunately, extracting review links manually from news pages is time-consuming and error-prone. Though lots of works on web data extraction have been developed, we argue that this is still not a trivial problem due to the diversity on both DOM tree structure and visual presentation. In this paper, a novel approach is proposed for automatically extracting the review links from web pages. This approach consists of two steps: first segment each news page into a set of blocks, and then identify the block(s) that contain the review link using a machine learning technique. Experimental results over a large number of Chinese news pages indicate that this approach is highly accurate.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030361","Machine learning;Review link;Visual feature;Web data extraction","Data mining;Decision trees;Feature extraction;HTML;Training;Visualization;Web pages","Internet;information retrieval;learning (artificial intelligence);reviews;tree data structures","Chinese news pages;DOM tree structure;Web data extraction;Web pages;machine learning technique;review link extraction;visual presentation","","0","","16","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Cross-Domain Semi-Supervised Learning Using Feature Formulation","X. Zhu","Faculty of Engineering and Information Technology, University of Technology, Sydney, Australia","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20111117","2011","41","6","1627","1638","Semi-Supervised Learning (SSL) traditionally makes use of unlabeled samples by including them into the training set through an automated labeling process. Such a primitive Semi-Supervised Learning (pSSL) approach suffers from a number of disadvantages including false labeling and incapable of utilizing out-of-domain samples. In this paper, we propose a formative Semi-Supervised Learning (fSSL) framework which explores hidden features between labeled and unlabeled samples to achieve semi-supervised learning. fSSL regards that both labeled and unlabeled samples are generated from some hidden concepts with labeling information partially observable for some samples. The key of the fSSL is to recover the hidden concepts, and take them as new features to link labeled and unlabeled samples for semi-supervised learning. Because unlabeled samples are only used to generate new features, but not to be explicitly included in the training set like pSSL does, fSSL overcomes the inherent disadvantages of the traditional pSSL methods, especially for samples not within the same domain as the labeled instances. Experimental results and comparisons demonstrate that fSSL significantly outperforms pSSL-based methods for both within-domain and cross-domain semi-supervised learning.","1083-4419;10834419","","10.1109/TSMCB.2011.2157999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5934438","Cross domain learning;machine learning;semi-supervised learning;transfer learning","Correlation;Data models;Feature extraction;Labeling;Machine learning;Semisupervised learning;Training","learning (artificial intelligence)","cross-domain semi-supervised learning;feature formulation;formative semi-supervised learning framework;within-domain semi-supervised learning","","7","","40","","20110627","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Comparison of NEAT and HyperNEAT Performance on a Strategic Decision-Making Problem","J. Lowell; S. Grabkovsky; K. Birger","Coll. of Comput. & Inf. Sci., Northeastern Univ., Boston, MA, USA","2011 Fifth International Conference on Genetic and Evolutionary Computing","20111013","2011","","","102","105","Neuroevolution is a useful machine learning approach for problems with limited domain knowledge, but it has not done well with strategic decision-making problems, where the correct action varies sharply as the agent moves across states. Two promising neuroevolution algorithms are Neuro Evolution of Augmenting Topologies (NEAT) and its extension, Hyper NEAT. We compare the performance of these two algorithms on a benchmark problem, Keep away Soccer, that requires strategic decision-making. Our results demonstrate that Hyper NEAT outperforms NEAT on a simple instance of the problem but that its advantage disappears when the problem is complicated.","","Electronic:978-0-7695-4449-6; POD:978-1-4577-0817-6","10.1109/ICGEC.2011.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042728","algorithm performance;genetic algorithms;machine learning;neuroevolution","Biological neural networks;Encoding;Machine learning;Machine learning algorithms;Network topology;Neurons","decision making;evolutionary computation;learning (artificial intelligence)","HyperNEAT;Keepaway Soccer;benchmark problem;machine learning;neuroevolution algorithm;neuroevolution of augmenting topologies;strategic decision making problem","","0","","15","","","Aug. 29 2011-Sept. 1 2011","","IEEE","IEEE Conference Publications"
"Gold Standard Evaluation of Ontology Learning Methods through Ontology Transformation and Alignment","E. Zavitsanos; G. Paliouras; G. A. Vouros","NCSR "Demokritos", Patriarhou Gregoriou and Neapoleos St., Athens, Athens","IEEE Transactions on Knowledge and Data Engineering","20110922","2011","23","11","1635","1648","This paper presents a method along with a set of measures for evaluating learned ontologies against gold ontologies. The proposed method transforms the ontology concepts and their properties into a vector space representation to avoid the common string matching of concepts and properties at the lexical layer. The proposed evaluation measures exploit the vector space representation and calculate the similarity of the two ontologies (learned and gold) at the lexical and relational levels. Extensive evaluation experiments are provided, which show that these measures capture accurately the deviations from the gold ontology. The proposed method is tested using the Genia and the Lonely Planet gold ontologies, as well as the ontologies in the benchmark series of the Ontology Alignment Evaluation Initiative.","1041-4347;10414347","","10.1109/TKDE.2010.195","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601723","Knowledge valuation;concept learning;machine learning;ontology design.","Concept learning;Knowledge discovery;Learning systems;Machine learning;Ontologies;Probability distribution","computational linguistics;learning (artificial intelligence);ontologies (artificial intelligence)","benchmark series;gold standard evaluation;learning;lexical layer;ontologies;ontology alignment;ontology transformation;vector space representation","","9","","24","","20101014","Nov. 2011","","IEEE","IEEE Journals & Magazines"
"From “security for privacy” to “privacy for security”","R. Bonazzi; B. Fritscher; Z. Liu; Y. Pigneur","Faculty of Business and Economics, University of Lausanne, 1015 Switzerland","2011 15th International Conference on Intelligence in Next Generation Networks","20111117","2011","","","319","324","This article envisions the use of context-awareness to improve single sign-on solutions (SSO) for mobile users. The attribute-based SSO is expected to increase users' perceived ease of use of the system and service providers' authentication security of the application. From these two features we derive two value propositions for a new business model for mobile platforms. The business model can be considered as an instantiation of the privacy-friendly business model pattern presented in our previous work, reinforcing our claim that privacy-friendly value propositions are possible and can be used to obtain a competitive advantage.","","Electronic:978-1-61284-319-3; POD:978-1-4799-1687-0; USB:978-1-61284-320-9","10.1109/ICIN.2011.6081097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081097","Authentication;Business;Current awareness systems;Machine learning","Authentication;Biological system modeling;Business;Mobile communication;Mobile handsets;Privacy","authorisation;data privacy;mobile radio;telecommunication security","attribute-based SSO;authentication security;business model;context-awareness;mobile users;privacy-friendly value propositions;service providers;single sign-on solutions","","0","","19","","","4-7 Oct. 2011","","IEEE","IEEE Conference Publications"
"No-reference image visual quality assessment using nonlinear regression","M. D. Dimitrievski; Z. A. Ivanovski; T. P. Kartalov","Faculty of Electrical Engineering and Information Technologies, Skopje, Karpos bb, 1000 Skopje, Macedonia","2011 Third International Workshop on Quality of Multimedia Experience","20111103","2011","","","78","83","In this paper, a novel no-reference image visual quality metric is proposed based on fusion of statistical and human visual system based metrics using ε-Support Vector Regression. Different order polynomial regression was also examined as an approximation that has lower computational complexity. Compared to existing image quality assessment metrics, the proposed fused metric is able to better quantify the image quality regardless of the type of degradation. We furthermore improve the image quality assessment by training a separate regression model for each degradation type. The latter degradation specific approach yields near perfect correlation with subjective scores, however, it relies on prior knowledge of the degradation process.","","Electronic:978-1-4577-1335-4; POD:978-1-4577-1333-0; USB:978-1-4577-1334-7","10.1109/QoMEX.2011.6065716","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065716","image quality;machine learning;metric;regression","Correlation;Degradation;Image coding;Mathematical model;Measurement;Polynomials;Training","computational complexity;image processing;regression analysis;support vector machines","computational complexity;fusion;human visual system;image quality assessment metrics;no-reference image visual quality assessment;nonlinear regression;polynomial regression;statistical system;support vector regression","","3","","19","","","7-9 Sept. 2011","","IEEE","IEEE Conference Publications"
"A vectorcardiogram-based classification system for the detection of Myocardial infarction","C. S. Huang; L. W. Ko; S. W. Lu; S. A. Chen; C. T. Lin","Brain Research Center and Institute of Electrical Control Engineering, National Chiao Tung University, Hsinchu, Taiwan","2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20111201","2011","","","973","976","Myocardial infarction (MI), generally known as a heart attack, is one of the top leading causes of mortality in the world. In clinical diagnosis, cardiologists generally utilize 12-lead ECG system to classify patients into MI symptoms: 1. ST segment elevation, 2. ST segment depression or T wave inversion. However unstable ischemic syndromes have rapidly changing supply versus demand characteristics that is one of the several limitations of 12-lead ECG system for MI detection. In addition, the ECG sensor placements of 12-lead system is not easily donned and doffed for tele-healthcare monitoring at home. Vectorcardiogram (VCG) system in clinic is another type of diagnosis plot which represents the magnitude and direction of the electrical potential in the form of a vector loop during cardiac electric activity. The VCG system can easily acquire three ECG waves from X, Y, Z directions to composite vector signal in space and the VCG signals can be transferred to 12-lead ECG signal through Dower transformation and vice versa. Hence, this study attempts to develop a VCG-based classification system for the detection of Myocardial infarction. In the experiment results, the proposed system can select the proper ECG features based on cardiologist's knowledge and proposed principal moments of QRS complex. The classification performance of MI detection can be reached to 99.89% of sensitivity, 92.51% of specificity, 95.35% of positive predictive value, and 96.96% overall accuracy with maximum-likelihood classifier (MLC).","1094-687X;1094687X","Electronic:978-1-4577-1589-1; POD:978-1-4244-4121-1; USB:978-1-4244-4122-8","10.1109/IEMBS.2011.6090220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6090220","12-lead ECG system;ECG;classification;machine learning;myocardial infarction;vectorcardiogram","Accuracy;Electrocardiography;Feature extraction;Heart;Myocardium;Support vector machines;Vectors","","","Algorithms;Diagnosis, Computer-Assisted;Equipment Design;Equipment Failure Analysis;Expert Systems;Humans;Myocardial Infarction;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Vectorcardiography","2","","17","","","Aug. 30 2011-Sept. 3 2011","","IEEE","IEEE Conference Publications"
"An evaluation of different modeling techniques for iterative compilation","E. Park; S. Kulkarni; J. Cavazos","Department of Computer and Information Sciences, University of Delaware, Newark, 19716, USA","2011 Proceedings of the 14th International Conference on Compilers, Architectures and Synthesis for Embedded Systems (CASES)","20111027","2011","","","65","74","Iterative compilation techniques, which involve iterating over different sets of optimizations, have proven useful in helping compilers choose the right set of optimizations for a given program. However, compilers typically have a large number of optimizations to choose from, making it impossible to iterate over a significant fraction of the entire optimization search space. Recent research has proposed to “intelligently” iterate over the optimization search space using predictive methods. In particular, state-the-art methods in iterative compilation use characteristics of the code being optimized to predict good optimization sequences to evaluate. Thus, an important step in developing predictive methods for compilation is deciding how to model the problem of choosing the right optimizations. In this paper, we evaluate three different ways of modeling the problem of choosing the right optimization sequences using machine learning techniques. We evaluate a novel prediction modeling technique, namely a tournament predictor, that is able to effectively predict good optimization sequences. We show that our tournament predictor can outperform current state-of-the-art predictors and the most aggressive setting of the Open64 compiler (-Ofast) on an average by 75% in just 10 iterations over a set of embedded and scientific kernels. Moreover, using our tournament predictor, we achieved on average 10% improvement over -Ofast for a set of MiBench applications.","","Electronic:978-1-4503-0713-0; POD:978-1-4503-0713-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062032","compiler optimization;iterative compilation;machine learning;regression","Data models;Kernel;Machine learning algorithms;Optimization;Predictive models;Radiation detectors;Training data","formal specification;iterative methods;learning (artificial intelligence);optimising compilers;search problems","-Ofast;MiBench application;Open64 compiler;code optimization;iterative compilation technique;machine learning technique;modeling technique;optimization search space;optimization sequence;predictive method;program optimization;tournament predictor","","0","","27","","","9-14 Oct. 2011","","IEEE","IEEE Conference Publications"
"SmartLeg: An intelligent active robotic prosthesis for lower-limb amputees","R. Dedić; H. Dindo","University of Mostar, Matice hrvatske bb, Mostar, Bosnia and Herzegovina","2011 XXIII International Symposium on Information, Communication and Automation Technologies","20111215","2011","","","1","7","In recent years, there has been a worldwide interest in improvement of mobility of people with lower limb amputation. In spite of significant development of new technologies during the last decade, commercial below-knee and above-knee prostheses are still energetically passive devices. However, many locomotive functions, like walking up stairs and slopes, need significant power in knee and ankle joints. The additional power for doing previously mentioned activities needs to be achieved by means of external energy sources, which should be integral prosthetic components. This paper presents preliminary investigations towards an active robotic prosthesis that could potentially enable people with an above- or below-knee amputation to perform different types of motions that require power in lower limb joints. Our initial prototype, SmartLeg, integrates advanced prosthetic and robotic technology with the state-of-the-art machine learning algorithms capable of adapting the working of the prosthesis to the optimal gait and power consumption patterns, and which therefore provide means to customize the device to a particular user.","","Electronic:978-1-4577-0746-9; POD:978-1-4577-0744-5","10.1109/ICAT.2011.6102090","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6102090","Active robotic prosthesis;assistive robotics;machine learning","Actuators;Joints;Knee;Legged locomotion;Prosthetics","learning (artificial intelligence);medical robotics;prosthetics","SmartLeg;above-knee prostheses;below-knee prostheses;intelligent active robotic prosthesis;lower limb amputation;lower limb joint;machine learning algorithm;optimal gait pattern;power consumption pattern","","1","","17","","","27-29 Oct. 2011","","IEEE","IEEE Conference Publications"
"Feature set comparison for automatic bird species identification","M. T. Lopes; C. N. Silla Junior; A. L. Koerich; C. A. A. Kaestner","Federal University of Technology of Paran&#x00E1;, Av. 7 de Setembro 3165, Curitiba, 80230-901, Brazil","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","965","970","This paper deals with the automated bird species identification problem, in which it is necessary to identify the species of a bird from its audio recorded song. This is a clever way to monitor biodiversity in ecosystems, since it is an indirect non-invasive way of evaluation. Different features sets which summarize in different aspects the audio properties of the audio signal are evaluated in this paper together with machine learning algorithms, such as probabilistic, instance-based, decision trees, neural networks and support vector machines. Experiments are conducted in a dataset of recorded songs of three bird species. The experimental results compare the performance of the features sets and different classifiers showing that it is possible to obtain very promising results in the automated bird species identification problem.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083794","bird species identification;machine learning;pattern recognition;signal processing","Birds;Databases;Feature extraction;Mel frequency cepstral coefficient;Signal processing algorithms;Support vector machines","audio signal processing;ecology;learning (artificial intelligence);neural nets;support vector machines;zoology","audio recorded song;audio signal;automatic bird species identification;biodiversity;ecosystems;feature set comparison;machine learning;neural networks;support vector machines","","11","","26","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"The interactive methods and technology in affective virtual human","Kunkun Du; Zhiliang Wang","College of Information Engineering, University of Science and Technology Beijing, China","Proceedings of 2011 Cross Strait Quad-Regional Radio Science and Wireless Technology Conference","20111010","2011","2","","1643","1648","Affective virtual human is considered to one of the hotspot in the field of virtual human-computer interaction. In this paper, the history and status quo of affective virtual human area have summarized. First, the relevant research history and development of affective virtual human-computer interaction at home and abroad is introduced and illustrated. Secondly, by induction the classification of affective model which is the core part of the affective virtual human technology, the characteristics, advantages and limitations of models are introduced and summarized. Then the involved theory and technique based on this field are discussed. Finally, the future of this area is prospected in the summary of the paper.","","Electronic:978-1-4244-9793-5; POD:978-1-4244-9792-8","10.1109/CSQRWC.2011.6037290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037290","affective computing;artificial psychology;emotional model;emotional virtual human;machine learning","Biology;Computational modeling;Computers;Hidden Markov models;Psychology;Rail to rail outputs","human computer interaction;pattern classification;virtual reality","affective model classification;affective virtual human;interactive methods;interactive technology;virtual human computer interaction","","1","","53","","","26-30 July 2011","","IEEE","IEEE Conference Publications"
"Nuclear detection using higher order learning","C. Nelson; W. M. Pottenger","RUTCOR, Rutgers University, Piscataway, New Jersey","2011 IEEE International Conference on Technologies for Homeland Security (HST)","20111219","2011","","","319","324","The detection of potentially threatening nuclear materials is a challenging homeland security problem. This research reports on the application of a novel statistical relational learning algorithm, Higher Order Naïve Bayes (HONB), to improve the detection and identification of nuclear isotopes. When classifying nuclear detection data, distinguishing potentially threatening from harmless radioisotopes is critical. These also must be distinguished from the naturally occurring radioactive background. This research applied Higher Order Learning to nuclear detection data to improve the detection and identification of four isotopes: Ga67, I131, In111, and Tc99m. In the research traditional IID machine learning methods are applied to the area of nuclear detection, and the results compared with the performance of leveraging higher-order dependencies between feature values using HONB. The findings give insight about the performance of higher-order classifiers (described in [2]) on datasets with small numbers of positive instances. In the initial study, Naïve Bayes was compared with its higher-order counterpart, Higher Order Naïve Bayes. HONB was found to perform statistically significantly better for isotope Ga67 when using a preprocessing methodology of discretizing then binarizing the input sensor data. Similar results were seen for different amounts of training data for I131, In111, and Tc99m. HONB was also found to perform statistically significantly better for isotopes I131 and Tc99m when the preprocessing involved normalization, discretization then binarization. This study shows that Higher Order Learning techniques can be very useful in the arena of nuclear detection.","","Electronic:978-1-4577-1376-7; POD:978-1-4577-1375-0","10.1109/THS.2011.6107890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107890","HONB;higher order naïve bayes;higher-order learning;machine learning;naïve bayes;nuclear detection","Accuracy;Isotopes;Machine learning;Measurement;Radioactive materials;Training;Weapons","Bayes methods;learning (artificial intelligence);national security;radiation detection;radioisotopes","Ga-67;Higher Order Naive Bayes;I-131;IID machine learning methods;In-111;Tc-99m;feature values;harmless radioisotopes;higher order learning techniques;higher-order classifiers;homeland security problem;input sensor data;naturally occurring radioactive background;nuclear detection data;nuclear isotopes;preprocessing methodology;statistical relational learning algorithm;threatening nuclear materials;training data","","2","","5","","","15-17 Nov. 2011","","IEEE","IEEE Conference Publications"
"Automatic classification of cognitive states","C. Cabral; M. Silveira; P. Figueiredo","Inst. for Syst. &amp; Robot., Tech. Univ. of Lisbon, Lisbon, Portugal","1st Portuguese Biomedical Engineering Meeting","20110922","2011","","","1","7","Functional Magnetic Resonance Imaging has established itself as the most powerful technique available today to measure brain activity induced by a perceptual or cognitive state. The inverse problem is considered in this study; given the measured brain activity, our goal is to predict the perceptual state. Machine Learning algorithms were used to address this problem in this work. Multi-subject fMRI data analysis poses a great challenge for the machine learning paradigm, by its characteristics: the low Signal to Noise Ratio (SNR), high dimensionality, small number of examples and inter-subject variability. To address this problem, several methods of classification and feature selection were tested. The main criterion of feature selection was mutual information in a univariate method, but a multivariate feature selection was also proposed. Both a single classifier and an ensemble of classifiers were tested. The ensemble of classifiers approach consisted on training an optimized classifier for each class and then the combination was made. The data analysed was obtained from three multi-subject experiments of visual stimulation with 4 classes of stimuli, at different magnetic field strengths. The ensemble of classifiers performs best for most data sets and methods of feature selection. In summary, the results suggest that a combination of classifiers can perform better than a single classifier, particularly when decoding stimuli associated with specific brain areas.","","Electronic:978-1-4577-0523-6; POD:978-1-4577-0522-9","10.1109/ENBENG.2011.6026089","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6026089","Brain decoding;ensemble of classifiers;fMRI;machine learning;multivariate feature selection;retinotopic mapping;visual localizer","Accuracy;Brain;Feature extraction;Gaussian processes;Mutual information;Training;Visualization","biomedical MRI;brain;cognition;feature extraction;image classification;inverse problems;learning (artificial intelligence);medical image processing","automatic classification;brain activity;cognitive states;feature selection;functional magnetic resonance imaging;intersubject variability;inverse problem;machine learning algorithms;multisubject fMRI data analysis;mutual information;perceptual state","","0","","17","","","1-4 March 2011","","IEEE","IEEE Conference Publications"
"CoTrade: Confident Co-Training With Data Editing","M. L. Zhang; Z. H. Zhou","School of Computer Science and Engineering, Southeast University, Nanjing, China","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20111117","2011","41","6","1612","1626","Co-training is one of the major semi-supervised learning paradigms that iteratively trains two classifiers on two different views, and uses the predictions of either classifier on the unlabeled examples to augment the training set of the other. During the co-training process, especially in initial rounds when the classifiers have only mediocre accuracy, it is quite possible that one classifier will receive labels on unlabeled examples erroneously predicted by the other classifier. Therefore, the performance of co-training style algorithms is usually unstable. In this paper, the problem of how to reliably communicate labeling information between different views is addressed by a novel co-training algorithm named COTRADE. In each labeling round, COTRADE carries out the label communication process in two steps. First, confidence of either classifier's predictions on unlabeled examples is explicitly estimated based on specific data editing techniques. Secondly, a number of predicted labels with higher confidence of either classifier are passed to the other one, where certain constraints are imposed to avoid introducing undesirable classification noise. Experiments on several real-world datasets across three domains show that COTRADE can effectively exploit unlabeled data to achieve better generalization performance.","1083-4419;10834419","","10.1109/TSMCB.2011.2157998","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5910412","Bias-variance decomposition;co-training;data editing;machine learning;semi-supervised learning","Algorithm design and analysis;Labeling;Machine learning;Prediction algorithms;Semisupervised learning","data handling;learning (artificial intelligence);pattern classification","COTRADE;classifier training;confident cotraining;data editing;semisupervised learning","","22","","51","","20110623","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Reduction of Knowledge Representation Using Logic Minimization Techniques","G. Borowik; T. Luba; D. Zydek","Inst. of Telecommun., Warsaw Univ. of Technol., Warsaw, Poland","2011 21st International Conference on Systems Engineering","20111013","2011","","","482","485","This paper is dedicated to two seemingly different problems. The first one concerns information theory and the second one is connected to logic synthesis methods. The reason why these issues are considered together is the important task of the efficient representation of data in information systems and as well as in logic systems. An efficient algorithm to solve the task of attributes/arguments reduction is presented.","","Electronic:978-0-7695-4495-3; POD:978-1-4577-1078-0","10.1109/ICSEng.2011.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041863","attribute reduction;complement;discernibility function;knowledge representation;logic minimization;machine learning","Algorithm design and analysis;Boolean functions;Frequency modulation;Information systems;Input variables;Minimization;Rough sets","data structures;information systems;knowledge representation;minimisation of switching nets","argument reduction;attribute reduction;data representation;information system;information theory;knowledge representation reduction;logic minimization technique;logic synthesis method;logic system","","1","","12","","","16-18 Aug. 2011","","IEEE","IEEE Conference Publications"
"A Survey on Graphical Methods for Classification Predictive Performance Evaluation","R. C. Prati; G. E. A. P. A. Batista; M. C. Monard","Centro de Mat., Comput. e Cognicao, Univ. Fed. do ABC, Sao Paulo, Brazil","IEEE Transactions on Knowledge and Data Engineering","20110922","2011","23","11","1601","1618","Predictive performance evaluation is a fundamental issue in design, development, and deployment of classification systems. As predictive performance evaluation is a multidimensional problem, single scalar summaries such as error rate, although quite convenient due to its simplicity, can seldom evaluate all the aspects that a complete and reliable evaluation must consider. Due to this, various graphical performance evaluation methods are increasingly drawing the attention of machine learning, data mining, and pattern recognition communities. The main advantage of these types of methods resides in their ability to depict the trade-offs between evaluation aspects in a multidimensional space rather than reducing these aspects to an arbitrarily chosen (and often biased) single scalar measure. Furthermore, to appropriately select a suitable graphical method for a given task, it is crucial to identify its strengths and weaknesses. This paper surveys various graphical methods often used for predictive performance evaluation. By presenting these methods in the same framework, we hope this paper may shed some light on deciding which methods are more suitable to use in different situations.","1041-4347;10414347","","10.1109/TKDE.2011.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723040","Machine learning;ROC curves;cost curves;data mining;lift graphs.;performance evaluation","Data mining;Equations;Error analysis;Learning systems;Machine learning;Performance evaluation","data mining;error statistics;graph theory;learning (artificial intelligence);pattern classification;software performance evaluation","classification predictive performance evaluation;classification systems;data mining;error rate;graphical methods;graphical performance evaluation methods;machine learning;multidimensional problem;multidimensional space;pattern recognition community;single scalar measure;single scalar summary","","22","","40","","20110303","Nov. 2011","","IEEE","IEEE Journals & Magazines"
"Computing and AI for a Sustainable Future","D. H. Fisher","Vanderbilt University","IEEE Intelligent Systems","20111208","2011","26","6","14","18","This inaugural article of the AI and Sustainability department sets the stage for articles in the area over the coming months and years. AI and sustainability is a nascent area, and elaborating it's brief history with pointers to recent and notable activities is this article's primary goal, as well as contextualizing AI and sustainability within the larger computing and sustainability movement.","1541-1672;15411672","","10.1109/MIS.2011.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6096574","AI;Intelligent systems;biodiversity;cyber-physical systems;machine learning;optimization;smart grid;socio-technical sciences;sustainability","Artificial intelligence;Optimization;Smart grids;Sustainability","artificial intelligence;environmental factors;sustainable development","AI;computing;sustainability department;sustainability movement;sustainable future","","0","","22","","","Nov.-Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Multilayered feedforward neural networks as a tool for distinction of the authors of texts","S. Selman; A. Husagic-Selman","Faculty of Engineering and Natural Sciences, International University of Sarajevo, Bosnia and Herzegovina","2011 XXIII International Symposium on Information, Communication and Automation Technologies","20111215","2011","","","1","6","This paper proposes a means of using a multilayered feedforward neural network to identify the author of a text. The network has to be trained where multilayer feedforward neural network as a powerful scheme for learning complex input-output mapping have been used in learning of the textual descriptors in a paragraphs of an author. The resulting training information we get will be used to identify the texts written by authors. The computational complexity is solved by dividing it into a number of computationally simple tasks where the input space is divided into a set of subspaces and then combining the solutions to those tasks. By this, we have been able to successfully distinguish the books authored by Leo Tolstoy, from the ones authored by Fyodor Dostoyevsky.","","Electronic:978-1-4577-0746-9; POD:978-1-4577-0744-5","10.1109/ICAT.2011.6102108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6102108","Machine learning;artificial neural networks;author identification","Accuracy;Biological neural networks;Multilayer perceptrons;Neurons;Testing;Training","computational complexity;learning (artificial intelligence);multilayer perceptrons;pattern classification;text analysis","author identification;classification problem;complex input-output mapping;computational complexity;machine learning;multilayered feedforward neural network;textual descriptor","","1","","32","","","27-29 Oct. 2011","","IEEE","IEEE Conference Publications"
"xMiner: Nip the Zero Day Exploits in the Bud","M. Z. Rafique; M. Abulaish","Center of Excellence in Inf. Assurance (CoEIA), King Sand Univ., Riyadh, Saudi Arabia","2011 IEEE 10th International Symposium on Network Computing and Applications","20111010","2011","","","99","106","Vulnerability exploits present in malformed messages are one of the major sources to remotely launch malicious activities in different protocols. Sometimes, a single malformed message could be enough to crash remote servers or to gain unfettered access over them. In this paper, we propose the design of a generic vulnerability exploits detection system xMiner to detect malformed messages in real time for avoiding any network hazard. The proposed xMiner exploits the information embedded within byte-level sequences of network messages. xMiner applies multi-order Markov process and principal component analysis (PCA) to extract novel discriminative features and uses them to detect attacks launched through malicious packets in real-time. The novelty of xMiner lies in its light-weight design which requires less processing and memory resources and makes it easily deployable on resource-constrained devices like smart phones. The system is evaluated on real-world datasets pertaining to three different protocols - HTTP, FTP and SIP. Five different classifiers are deployed to establish the effectiveness of the proposed system. On evaluation we found that the decision tree classifier performs well for HTTP and FTP datasets whereas, SVM shows highest performance in case of SIP packets.","","Electronic:978-0-7695-4489-2; POD:978-1-4577-1052-0","10.1109/NCA.2011.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038590","Network security;feature extraction;machine learning;vulnerability exploits detection","Correlation;Feature extraction;Markov processes;Principal component analysis;Protocols;Real time systems;Servers","Markov processes;computer network security;invasive software;principal component analysis","Markov process;byte-level sequences;discriminative features;malformed messages;malicious activities;malicious packets;network hazard;network messages;principal component analysis;resource-constrained devices;smart phones;vulnerability exploits detection system;xMiner","","0","","41","","","25-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Salient features based on visual attention for multi-view vehicle classification","A. M. Cretu; P. Payeur; R. Laganière","School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada","2011 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA) Proceedings","20111027","2011","","","1","6","The continuous rise in the amount of vehicles in circulation brings an increasing need for automatically and efficiently recognizing vehicle categories for multiple applications such as optimizing available parking spaces, balancing ferry load, planning infrastructure and managing traffic, or servicing vehicles. This paper describes the design and implementation of a vehicle classification system using a set of images collected from 6 views. The proposed computational system combines human visual attention mechanisms to identify a set of salient discriminative features and a series of binary support vector machines to achieve fast automated classification. An average classification rate of 96% is achieved for 3 vehicle categories. An improvement to 99.13% is achieved by using additional measurement on the width and height of the vehicles.","2159-1547;21591547","Electronic:978-1-61284-925-6; POD:978-1-61284-924-9","10.1109/CIMSA.2011.6059933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6059933","machine learning;saliency;support vector machines;vehicle classification;visual attention","Cameras;Computational modeling;Feature extraction;Support vector machine classification;Vehicles;Visualization","height measurement;image classification;road vehicles;support vector machines;traffic engineering computing","automated classification;available parking space optimisation;binary support vector machine;computational system;ferry load balancing;height measurement;human visual attention mechanism;infrastructure planning;multiview vehicle classification;salient features;traffic management;vehicle category recognition;vehicle classification system;vehicle servicing;width measurement","","2","","18","","","19-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"File Block Classification by Support Vector Machine","L. Sportiello; S. Zanero","Dipt. di Elettron. e Inf., Politec. di Milano, Milan, Italy","2011 Sixth International Conference on Availability, Reliability and Security","20111017","2011","","","307","312","Retrieval of files without the support of file system structures is arguably essential for digital forensics. Files are typically stored as sequences of data blocks, which have to be reconstructed in the retrieval process. This is commonly performed, among other approaches, through file carving, in general detecting the original block sequences by means of signatures of known headers and footers of files. Of course, this creates challenges with fragmented files, where blocks belonging to different files may be interleaved. Ways to classify file blocks into file types relying on their content may provide a support to achieve a successful reconstruction. We propose to classify file blocks using Support Vector Machines (SVMs), and we do so by studying in-depth the impact of an appropriate selection of the features used in the classification process. We analyze several potential features and test their performance over a large and representative collection of file blocks and file types. We find out that SVM classifiers can achieve a good accuracy and that a specific type of features (based on byte frequency distribution) performs well across almost all of the examined file types.","","Electronic:978-0-7695-4485-4; POD:978-1-4577-0979-1","10.1109/ARES.2011.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045955","File Block Classification;File Carving;Forensic Analysis;Machine Learning","Complexity theory;Computational modeling;Entropy;Feature extraction;Mathematical model;Support vector machines;Training","computer forensics;information retrieval;pattern classification;support vector machines","SVM classifiers;block sequence;byte frequency distribution;digital forensics;file block;file block classification;file retrieval;file type;fragmented file;support vector machine","","7","1","13","","","22-26 Aug. 2011","","IEEE","IEEE Conference Publications"
"Performance analysis for classification in balanced and unbalanced data set","S. Padma; S. S. Kumar; R. Manavalan","Department of Computer Science, KSR College of Arts and Science, Tiruchengode, India","2011 6th International Conference on Industrial and Information Systems","20111010","2011","","","300","304","This paper focuses on performance evaluation of the classification algorithms for problems of unbalanced and balanced large data sets. Three methods such as ELM, MRAN, and SRAN have been proposed for solving the set classification problem and studied. The ELM is based on randomly chosen hidden nodes and analytically determines the output weights of SLFNs. Then the next method M-RAN is a sequential learning radial basis function neural network which combines the growth criterion of the resource allocating network (RAN) of Platt with a pruning strategy based on the relative contribution of each hidden unit to the overall network output. The last method SRAN uses of misclassification information and hinge loss error in growing/learning criterion helps in approximating the decision function accurately. The performance evaluation using balanced and imbalanced data sets shows that one of the proposed algorithms SRAN generates minimal network with higher classification performance.","2164-7011;21647011","Electronic:978-1-4577-0035-4; POD:978-1-4577-0032-3","10.1109/ICIINFS.2011.6038084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038084","Extreme Learning Machine;M-RAN;SRAN","Classification algorithms;Machine learning;Neurons;Radio access networks;Testing;Training;Training data","learning (artificial intelligence);pattern classification;radial basis function networks","ELM;MRAN;SLFN;SRAN;balanced large data sets;classification algorithms;extreme learning machine;performance evaluation;pruning strategy;resource allocating network;sequential learning radial basis function neural network;set classification problem;unbalanced large data sets","","0","","7","","","16-19 Aug. 2011","","IEEE","IEEE Conference Publications"
"Drosophila Gene Expression Pattern Annotation through Multi-Instance Multi-Label Learning","Y. X. Li; S. Ji; S. Kumar; J. Ye; Z. H. Zhou","Nanjing University, Nanjing","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20111114","2012","9","1","98","112","In the studies of Drosophila embryogenesis, a large number of two-dimensional digital images of gene expression patterns have been produced to build an atlas of spatio-temporal gene expression dynamics across developmental time. Gene expressions captured in these images have been manually annotated with anatomical and developmental ontology terms using a controlled vocabulary (CV), which are useful in research aimed at understanding gene functions, interactions, and networks. With the rapid accumulation of images, the process of manual annotation has become increasingly cumbersome, and computational methods to automate this task are urgently needed. However, the automated annotation of embryo images is challenging. This is because the annotation terms spatially correspond to local expression patterns of images, yet they are assigned collectively to groups of images and it is unknown which term corresponds to which region of which image in the group. In this paper, we address this problem using a new machine learning framework, Multi-Instance Multi-Label (MIML) learning. We first show that the underlying nature of the annotation task is a typical MIML learning problem. Then, we propose two support vector machine algorithms under the MIML framework for the task. Experimental results on the FlyExpress database (a digital library of standardized Drosophila gene expression pattern images) reveal that the exploitation of MIML framework leads to significant performance improvement over state-of-the-art approaches.","1545-5963;15455963","","10.1109/TCBB.2011.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753882","Drosophila.;Gene expression pattern;image annotation;machine learning;multi-instance multi-label (MIML) learning;support vector machine","Bioinformatics;Computational biology;Databases;Embryo;Gene expression;Head;Machine learning","bioinformatics;biological techniques;genetics;learning (artificial intelligence);support vector machines","Drosophila embryogenesis;Drosophila gene expression pattern annotation;anatomical ontology terms;annotation task;automated annotation;computational methods;controlled vocabulary;developmental ontology terms;embryo imaging;flyexpress database;gene functions;local expression patterns;machine learning framework;manual annotation;multiinstance multilabel learning;rapid accumulation;spatio-temporal gene expression dynamics;state-of-the-art approaches;support vector machine algorithms;two-dimensional digital imaging","Animals;Computational Biology;Databases, Factual;Drosophila;Embryo, Nonmammalian;Gene Expression Regulation, Developmental;Molecular Sequence Annotation;Support Vector Machines","18","","57","","20110421","Jan.-Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Searching the 'Web of Things'","B. Christophe; V. Verdot; V. Toubiana","Villarceaux Res. Center, Alcatel-Lucent Bell Labs. France, Nozay, France","2011 IEEE Fifth International Conference on Semantic Computing","20111027","2011","","","308","315","With the proliferation of connected devices and the widespread adoption of the Web, ubiquitous computing success has recently been brought into the fashion of an emergent paradigm called the 'Web of Things', where Web-enabled objects are offered through interconnected smart spaces. While some predict a near future with billions of Web-enabled objects, the success of this vision now depends on the creation of efficient processes and the availability of tools enabling users or applications to find connected objects matching a set of requirements (and expectations). We present an on-going work that aims to develop a search process dedicated to the 'Web of Things' and that relies on three contributions. The creation and use of semantic profiles for connected objects, the establishment of similarities between semantic profiles of different connected objects to gather them into clusters and, the computation of a score associating a 'context of search' to an incoming request and enabling the selection of the most appropriate search algorithms, involving either probabilistic or precise reasoning.","","Electronic:978-0-7695-4492-2; POD:978-1-4577-1648-5","10.1109/ICSC.2011.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6061479","Semantic Web;Web-of-Things;machine learning;ontology;search mechanisms","Intelligent sensors;OWL;Ontologies;Search engines;Search problems;Semantics","Internet;Web sites;ubiquitous computing","Web of Things;World Wide Web;object matching;search algorithm;search process;semantic profiles;ubiquitous computing success","","18","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Summarizing software artifacts: a case study of bug reports","S. Rastkar; G. C. Murphy; G. Murray","University of British Columbia","2010 ACM/IEEE 32nd International Conference on Software Engineering","20111027","2010","1","","505","514","Many software artifacts are created, maintained and evolved as part of a software development project. As software developers work on a project, they interact with existing project artifacts, performing such activities as reading previously filed bug reports in search of duplicate reports. These activities often require a developer to peruse a substantial amount of text. In this paper, we investigate whether it is possible to summarize software artifacts automatically and effectively so that developers could consult smaller summaries instead of entire artifacts. To provide focus to our investigation, we consider the generation of summaries for bug reports. We found that existing conversation-based generators can produce better results than random generators and that a generator trained specifically on bug reports can perform statistically better than existing conversation-based generators. We demonstrate that humans also find these generated summaries reasonable indicating that summaries might be used effectively for many tasks.","0270-5257;02705257","Electronic:978-1-60558-719-6; POD:978-1-60558-719-6","10.1145/1806799.1806872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062118","human-centric software engineering;machine learning","Computer bugs;Electromagnetic compatibility;Electronic mail;Humans;Programming;Software;Training","program debugging;software engineering","bug reports;conversation-based generators;software artifacts summarization;software development project","","27","1","22","","","2-8 May 2010","","IEEE","IEEE Conference Publications"
"Classification Based on Specific Vocabulary","J. Savoy; O. Zubaryeva","Comput. Sci. Dept., Univ. of Neuchatel, Neuchatel, Switzerland","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","120","123","Assuming a binomial distribution for word occurrence, we propose computing a standardized Z score to define the specific vocabulary of a subset compared to that of the entire corpus. This approach is applied to weight terms characterizing a document (or a sample of texts). We then show how these Z score values can be used to derive an efficient categorization scheme. To evaluate this proposition we categorize speeches given by B. Obama as either electoral or presidential. The results tend to show that the suggested classification scheme performs better than a Support Vector Machine scheme, and a Naive Bayes classifier (10-fold cross validation).","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040507","Lexical Analysis;Machine Learning;Natural Language Processing;Political Discourse;Text Categorization","Frequency measurement;Machine learning;Smoothing methods;Speech;Support vector machines;Text categorization;Vocabulary","binomial distribution;classification;text analysis;vocabulary","binomial distribution;categorization scheme;classification scheme;document weight terms characterization;naive Bayes classifier;specific vocabulary;standardized Z score computation;support vector machine scheme;word occurrence","","0","","16","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Model-Assisted Stochastic Learning for Robotic Applications","J. A. Marvel; W. S. Newman","Institute for Research in Electronics and Applied Physics, University of Maryland, College Park, United States","IEEE Transactions on Automation Science and Engineering","20111003","2011","8","4","835","845","We present here a framework for the generation, application, and assessment of assistive models for the purpose of aiding automated robotic parameter optimization methods. Our approach represents an expansion of traditional machine learning implementations by employing models to predict the performances of input parameter sequences and then filter a potential population of inputs prior to evaluation on a physical system. We further provide a basis for numerically qualifying these models to determine whether or not they are of sufficient quality to be capable of fulfilling their predictive responsibilities. We demonstrate the effectiveness of this approach using an industrial robotic testbed on a variety of mechanical assemblies, each requiring a different strategy for completion.","1545-5955;15455955","","10.1109/TASE.2011.2159708","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5937024","Intelligent robots;machine learning;model-based learning;parameter optimization","Genetic algorithms;Intelligent robots;Machine learning;Numerical analysis;Optimization;Stochastic processes;Unsupervised learning","force control;learning (artificial intelligence);manipulators","automated robotic parameter optimization method;machine learning;model-assisted stochastic learning;robotic application;robotic manipulators","","4","","45","","20110704","Oct. 2011","","IEEE","IEEE Journals & Magazines"
"A novel semi-supervised approach for network traffic clustering","Y. Wang; Y. Xiang; J. Zhang; S. Yu","School of Information Technology, Deakin University, Melbourne, Australia","2011 5th International Conference on Network and System Security","20111027","2011","","","169","175","Network traffic classification is an essential component for network management and security systems. To address the limitations of traditional port-based and payload-based methods, recent studies have been focusing on alternative approaches. One promising direction is applying machine learning techniques to classify traffic flows based on packet and flow level statistics. In particular, previous papers have illustrated that clustering can achieve high accuracy and discover unknown application classes. In this work, we present a novel semi-supervised learning method using constrained clustering algorithms. The motivation is that in network domain a lot of background information is available in addition to the data instances themselves. For example, we might know that flow f<sub>1</sub> and f<sub>2</sub> are using the same application protocol because they are visiting the same host address at the same port simultaneously. In this case, f<sub>1</sub> and f<sub>2</sub> shall be grouped into the same cluster ideally. Therefore, we describe these correlations in the form of pair-wise must-link constraints and incorporate them in the process of clustering. We have applied three constrained variants of the K-Means algorithm, which perform hard or soft constraint satisfaction and metric learning from constraints. A number of real-world traffic traces have been used to show the availability of constraints and to test the proposed approach. The experimental results indicate that by incorporating constraints in the course of clustering, the overall accuracy and cluster purity can be significantly improved.","","Electronic:978-1-4577-0460-4; POD:978-1-4577-0458-1","10.1109/ICNSS.2011.6059997","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6059997","constrained clustering;constraints;machine learning;semi-supervised learning;traffic classification","Classification algorithms;Clustering algorithms;Correlation;Measurement;Partitioning algorithms;Payloads;Protocols","computer network management;computer network security;constraint handling;learning (artificial intelligence);pattern clustering","constrained clustering algorithms;constraint satisfaction;flow level statistics;k-means algorithm;machine learning techniques;metric learning;network management;network traffic classification;network traffic clustering;payload based methods;port based methods;security systems;semi supervised approach;semi supervised learning method","","11","","23","","","6-8 Sept. 2011","","IEEE","IEEE Conference Publications"
"A boolean model for spam detection","B. Naouel; B. Fatiha; A. Baghdad","Comput. Sci. Dept., Univ. of Oran, Oran, Algeria","2011 International Conference on Communications, Computing and Control Applications (CCCA)","20110929","2011","","","1","6","Spam, also known as unsolicited or junk mail quickly became a major problem on the Internet. To address this growing burden of this type of spam, several detection techniques exist to automatically classify incoming emails as spam or legitimate. In this context, we propose a supervised classification approach based on Boolean cellular automaton. To evaluate the performance of this new approach, we conduct a series of experiments on the LingSpam corpus.","","DVD:978-1-4244-9794-2; Electronic:978-1-4244-9796-6; POD:978-1-4244-9795-9","10.1109/CCCA.2011.6031517","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031517","Email;cellular automaton;machine learning;spam","Accuracy;Automata;Filtering;Learning automata;Pragmatics;Unsolicited electronic mail","Boolean functions;Internet;cellular automata;pattern classification;security of data;unsolicited e-mail","Boolean cellular automaton;Boolean model;Internet;LingSpam corpus;junk mail;spam detection;supervised classification approach;unsolicited mail","","0","","17","","","3-5 March 2011","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Study on advanced variance-considered machines using Mahalanobis distance","J. Park; S. M. Park; K. B. Sim","Sch. of Electr. & Electron. Eng., Chung-Ang Univ., Seoul, South Korea","2011 Seventh International Conference on Natural Computation","20110919","2011","1","","388","391","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>Support Vector Machine maximizes a margin between two groups. Variance-considered machine improves SVM to align hyper plane according to two classes' variance and prior probability to reduce the error rate. There is probabilistically imprecise things those data classified by VCM. In this paper, we introduce the VCM and try to propose a concept that is to confer reliability estimated by Mahalanobis distance upon data separated by VCM.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022100","Machine Learning;Mahalanobis distance;Reliability;Support Vector Machine;Variance Considered Machines","Educational institutions;Kernel;Reliability;Support vector machine classification;Training;Training data","pattern classification;probability;reliability;support vector machines","Mahalanobis distance;advanced variance-considered machines;data classification;error rate reduction;reliability estimation;support vector machine","","0","","7","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Logic of integrity, fuzzy logic and knowledge modeling for machine education","F. K. Bunyatova; G. Salamov","Intellect Scholl Baku, Azerbaijan","2011 5th International Conference on Application of Information and Communication Technologies (AICT)","20111222","2011","","","1","3","This article deals with the modelling of learning meaningful knowledge for machine learning without teacher. Model of knowledge is built on logic integrity of Piaget and fuzzy logic of Zade.","","Electronic:978-1-61284-832-7; POD:978-1-61284-831-0","10.1109/ICAICT.2011.6110956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6110956","fuzzy logic;logic of integrity;machine learning model;natural and artificial intelligence;numeric properties","Indium tin oxide","computer aided instruction;fuzzy logic;learning (artificial intelligence)","fuzzy logic;knowledge modeling;logic integrity;machine education","","0","","9","","","12-14 Oct. 2011","","IEEE","IEEE Conference Publications"
"Learning to adapt requirements specifications of evolving systems: (NIER track)","R. V. Borges; A. d'Avila Garcez; L. C. Lamb; B. Nuseibeh","City University London, London, United Kingdom","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","856","859","We propose a novel framework for adapting and evolving software requirements models. The framework uses model checking and machine learning techniques for verifying properties and evolving model descriptions. The paper offers two novel contributions and a preliminary evaluation and application of the ideas presented. First, the framework is capable of coping with errors in the specification process so that performance degrades gracefully. Second, the framework can also be used to re-engineer a model from examples only, when an initial model is not available. We provide a preliminary evaluation of our framework by applying it to a Pump System case study, and integrate our prototype tool with the NuSMV model checker. We show how the tool integrates verification and evolution of abstract models, and also how it is capable of re-engineering partial models given examples from an existing system.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1985924","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032536","adaptation;machine learning in software engineering","Adaptation models;Computational modeling;Knowledge engineering;Machine learning;Numerical models;Robustness;Software","formal specification;formal verification","NIER track;NuSMV model checker;evolving system;machine learning;model checking;pump system;requirement specification process;software requirement model","","2","","14","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"Proximity-based sentiment analysis","S. M. S. Hasan; D. A. Adjeroh","Department of Computer Science, Virginia Tech, 24061, USA","Fourth International Conference on the Applications of Digital Information and Web Technologies (ICADIWT 2011)","20111010","2011","","","106","111","Sentiment analysis seeks to characterize opinionated or evaluative aspects of natural language text thus helping people to discover valuable information from large amounts of unstructured data [1]. In this paper we explore a new methodology for sentiment analysis called proximity-based sentiment analysis. We take a different approach, by considering a new set of features based on word proximities in a written text. We propose three proximity-based features, namely, proximity distribution, mutual information between proximity types, and proximity patterns. We applied this approach to the analysis of movie reviews. Our experimental results show that proximity-based sentiment analysis is able to extract sentiments from a specific domain, with performance comparable to the state-of-the-art. To the best of our knowledge, this is the first attempt at focusing on only proximity based features as the primary features in sentiment analysis.","","Electronic:978-1-4244-9825-3; POD:978-1-4244-9824-6","10.1109/ICADIWT.2011.6041410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041410","machine learning;movie reviews;natural language processing;sentiment analysis;text mining","Buildings;Classification algorithms","natural language processing;text analysis","movie reviews;natural language text;proximity based sentiment analysis;proximity distribution;proximity patterns;proximity types;unstructured data","","3","","35","","","4-6 Aug. 2011","","IEEE","IEEE Conference Publications"
"Classification of Hyperspectral Imagery Using GPs and the OAD Covariance Function with Automated Endmember Extraction","S. Schneider; A. Melkumyan; R. J. Murphy; E. Nettleton","Australian Centre for Field Robot., Univ. of Sydney, Sydney, NSW, Australia","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","579","584","In this paper we use a machine learning algorithm based on Gaussian Processes (GPs) and the Observation Angle Dependent (OAD) covariance function to classify hyper spectral imagery for the first time. This paper demonstrates the potential of the GP-OAD method for use in autonomous mining to identify and map geology and mineralogy on a vertical mine face. We discuss the importance of independent training data (i.e. a spectral library) to map any mine face without a priori knowledge. We compare an independent spectral library to other libraries, based on image data, and evaluate their relative performances to distinguish ore bearing zones from waste. Results show that the algorithm yields high accuracies (90%) and F-scores (77%), the best results are achieved when libraries are combined. We also demonstrate mapping of geology using imagery under different conditions of illumination (e.g. shade).","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103383","automation;gaussian processes;geology;hyperspectral;machine learning;mining","Hyperspectral imaging;Libraries;Lighting;Rocks;Training;Training data","Gaussian processes;cartography;geology;geophysical image processing;image classification;learning (artificial intelligence);minerals;mining;mobile robots;robot vision","GP;GP-OAD method;Gaussian processes;OAD covariance function;automated endmember extraction;autonomous mining;geology mapping;hyperspectral imagery classification;machine learning algorithm;mineralogy mapping;observation angle dependent","","0","","18","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Exploring How to Support Software Revision in Software Non-intensive Projects Using Existing Techniques","H. Kaiya; K. Hara; K. Kobayashi; A. Osada; K. Kaijiri","Dept. of Comput. Sci., Shinshu Univ., Nagano, Japan","2011 IEEE 35th Annual Computer Software and Applications Conference Workshops","20111003","2011","","","327","334","Most industrial products are developed based on their former products including software. Revising existing software according to new requirements is thus an important issue. However, innovative techniques for software revision cannot be easily introduced to projects where software is not a central part. In this paper, we report how to explore and apply software engineering techniques to such non-ideal projects to encourage technology transfer to industry. We first show our experiences with industrial partners to explore which tasks could be supported in such projects and which techniques could be applied to such tasks. As a result, we found change impact analysis could be technically supported, and traceability techniques using information retrieval seemed to be suitable for it. We second had preliminary experiences of a method using such techniques with data in industry and evaluated them with our industrial partners. Based on the evaluation, we third improved such a method by using following techniques, indexing of technical documents for characterizing requirements changes, machine learning on source codes for validating predicted traceability and static source code analysis for finding indirect impacts. Our industrial partners finally evaluated the improved method, and they confirmed the improved method worked better than ever.","","Electronic:978-07695-4459-5; POD:978-1-4577-0980-7","10.1109/COMPSACW.2011.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032259","CASE Tool;Change Impact Analysis;Indexing;Information Retrieval;Machine Learning;Requirements Change;Software Revision;Traceability","Cryptography;Indexing;Industries;Machine learning;Measurement;Software;Unified modeling language","document handling;indexing;information retrieval;learning (artificial intelligence);program diagnostics;software engineering","industrial products;information retrieval;machine learning;predicted traceability validation;requirement changes;software engineering techniques;software nonintensive projects;software revision;source codes;static source code analysis;technical document indexing;technology transfer;traceability techniques","","0","","17","","","18-22 July 2011","","IEEE","IEEE Conference Publications"
"Discriminative time-frequency kernels for gait analysis for amyotrophic lateral sclerosis","L. Sugavaneswaran; K. Umapathy; S. Krishnan","Department of Electrical and Computer Engineering, Ryerson University, 350 Victoria Street, Toronto, Ontario, M5B 2K3, Canada","2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20111201","2011","","","2683","2686","Many stochastic systems show certain trends which in turn govern their underlying non-stationary time varying behavior. In order to facilitate efficient quantification of such signals, their analysis necessitates the use of robust tools for discerning between different classes of data. Research show that, use of time-frequency techniques offer intelligible representations for non-stationary signals, along with facilitating computation of instantaneous parameters. Further, in order to obtain efficient discrimination machine learning (ML) modules are often used alongside suitable representation techniques. In this work, we exploit the concepts of ML-kernel functions directly by incorporating them in the ambiguity time-frequency (TF) space, thereby obtaining a one-step discrimination between different non-stationary patterns. The proposed technique is evaluated for quantification applications for gait signal analysis. An overall classification accuracy of 93.1% is reported for the neurological gait database consisting of signals from 16-control and 13-amyotrophic lateral sclerosis (ALS) subjects. Results indicate that this scheme offers great potential in designing robust tools for time-varying signal analysis.","1094-687X;1094687X","Electronic:978-1-4577-1589-1; POD:978-1-4244-4121-1; USB:978-1-4244-4122-8","10.1109/IEMBS.2011.6090737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6090737","Ambiguity Domain;kernels;machine learning;non-stationary","Accuracy;Feature extraction;Kernel;Machine learning;Signal analysis;Time frequency analysis;Vectors","gait analysis;learning (artificial intelligence);medical disorders;neurophysiology;time-frequency analysis","amyotrophic lateral sclerosis;discriminative time frequency kernels;gait analysis;machine learning;neurological gait database;nonstationary signals","Amyotrophic Lateral Sclerosis;Gait;Humans","1","","12","","","Aug. 30 2011-Sept. 3 2011","","IEEE","IEEE Conference Publications"
"NRProF: Neural response based protein function prediction algorithm","H. K. Yalamanchili; J. Wang; Quan-Wu Xiao","Department of Biochemistry, LKS Faculty of Medicine, The University of Hong Kong, China","2011 IEEE International Conference on Systems Biology (ISB)","20111003","2011","","","33","40","A large amount of proteomic data is being generated due to the advancements in high-throughput genome sequencing. But the rate of functional annotation of these sequences falls far behind. To fill the gap between the number of sequences and their annotations, fast and accurate automated annotation methods are required. Many methods, such as GOblet, GOfigure, and Gotcha, are designed based on the BLAST search. Unfortunately, the sequence coverage of these methods is low as they cannot detect the remote homologues. The lack of annotation coverage of the existing methods advocates novel methods to improve protein function prediction. Here we present a automated protein functional assignment method based on the neural response algorithm, which simulates the neuronal behavior of the visual cortex in the human brain. The main idea of this algorithm is to define a distance metric that corresponds to the similarity of the subsequences and reflects how the human brain can distinguish different sequences. Given query protein, we predict the most similar target protein using a two layered neural response algorithm and thereby assigned the GO term of the target protein to the query. Our method predicted and ranked the actual leaf GO term among the top 5 probable GO terms with 87.66% accuracy. Results of the 5-fold cross validation and the comparison with PFP and FFPred servers indicate the prominent performance by our method. The NRProF program, the dataset, and help files are available at http://www.jjwanglab.org/NRProF/.","2164-2389;21642389","Electronic:978-1-4577-1666-9; POD:978-1-4577-1661-4; USB:978-1-4577-1665-2","10.1109/ISB.2011.6033117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033117","Algorithms;Artificial intelligence;Genome annotation;Machine learning;Ontology","Accuracy;Classification algorithms;Hidden Markov models;Kernel;Libraries;Proteins;Servers","biology computing;genomics;molecular biophysics;neural nets;neurophysiology;proteins;proteomics","BLAST search;GOblet;GOfigure;Gotcha;NRProF program;functional annotation;high-throughput genome sequencing;human brain;neural response;neuronal behavior;protein function prediction algorithm;proteomic data;query protein;visual cortex","","0","","42","","","2-4 Sept. 2011","","IEEE","IEEE Conference Publications"
"Quantifying the Impact of Different Non-functional Requirements and Problem Domains on Software Effort Estimation","R. Abdukalykov; I. Hussain; M. Kassab; O. Ormandjieva","CSE Dept., Concordia Univ., Montreal, QC, Canada","2011 Ninth International Conference on Software Engineering Research, Management and Applications","20111103","2011","","","158","165","The effort estimation techniques used in the software industry often tend to ignore the impact of Non-functional Requirements (NFR) on effort and reuse standard effort estimation models without local calibration. Moreover, the effort estimation models are calibrated using data of previous projects that may belong to problem domains different from the project which is being estimated. Our approach suggests a novel effort estimation methodology that can be used in the early stages of software development projects. Our proposed methodology initially clusters the historical data from the previous projects into different problem domains and generates domain specific effort estimation models, each incorporating the impact of NFR on effort by sets of objectively measured nominal features. We reduce the complexity of these models using a feature subset selection algorithm. In this paper, we discuss our approach in details, and we present the results of our experiments using different supervised machine learning algorithms. The results show that our approach performs well by increasing the correlation coefficient and decreasing the error rate of the generated effort estimation models and achieving more accurate effort estimates for the new projects.","","Electronic:978-0-7695-4490-8; POD:978-1-4577-1028-5","10.1109/SERA.2011.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065634","Non-functional Requirements;Software Effort Estimation;Supervised Machine Learning","Correlation;Data models;Estimation;Numerical models;Programming;Semantics;Software","formal verification;learning (artificial intelligence);pattern clustering;project management;set theory;software management","correlation coefficient;domain specific effort estimation model;feature subset selection algorithm;historical data clustering;local calibration;nonfunctional requirement;reuse standard effort estimation model;software development project;software effort estimation;software industry;supervised machine learning algorithm","","1","","30","","","10-12 Aug. 2011","","IEEE","IEEE Conference Publications"
"A methodology of forest monitoring from hyperspectral images with sparse regularization","K. Yoshida; T. Ohki; M. Terabe; H. Sekine; T. Takeda","Mitsubishi Research Institute, Inc., 100-8141 Chiyoda-ku, Tokyo, Japan","2011 IEEE International Geoscience and Remote Sensing Symposium","20111020","2011","","","1565","1568","This paper presents a methodology to extract information on existing conditions of a forest from hyperspectral images and SAR images for the forest management. To overcome the difficulties in hyperspectral image analysis such as optimal band selection and model overfitting, a machine learning technique called sparse regularization was adopted. Experimental results show the effectiveness of this approach.","2153-6996;21536996","DVD:978-1-4577-1004-9; Electronic:978-1-4577-1005-6; POD:978-1-4577-1003-2","10.1109/IGARSS.2011.6049369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6049369","Forest management;Hyperspectral imaging;Machine learning;Sensor fusion;Sparse regularization","Accuracy;Hyperspectral imaging;Monitoring;Predictive models;Vegetation","geophysical image processing;learning (artificial intelligence);remote sensing by radar;synthetic aperture radar;vegetation","SAR images;forest management;forest monitoring;hyperspectral images;machine learning technique;model overfitting;optimal band selection;sparse regularization","","2","","9","","","24-29 July 2011","","IEEE","IEEE Conference Publications"
"Floor accuracy improvement of wireless LAN based large scale indoor positioning","H. Yang; Giwan Yoon; D. Han","Dept. of Comput. Sci., KAIST, Daejeon, South Korea","2011 IEEE MTT-S International Microwave Workshop Series on Intelligent Radio for Future Personal Terminals","20110926","2011","","","1","2","WLAN signal based positioning is most popular in indoor localization, where GPS is hardly working inside buildings. In WLAN localization system, floor errors are occurred occasionally, which cause the serious side effects in indoor navigation system. In this paper, we introduce our floor-error correcting method. Simply, the correction method is based on Wi-Fi access point set similarity. We devised a new method with less floor errors than conventional system. We applied our proposed method to COEX, the most realistic case comparing with other researches. Therefore we expect that the result in this paper is meaningful to the researchers in same discipline.","","Electronic:978-1-4577-0963-0; POD:978-1-4577-0961-6","10.1109/IMWS2.2011.6027200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6027200","Coordinate measuring machines;machine learning algorithms;navigation;pervasive computing;wireless LAN","Accuracy;Bayesian methods;Estimation;Fingerprint recognition;Floors;IEEE 802.11 Standards;Wireless LAN","Global Positioning System;building management systems;wireless LAN","COEX method;GPS;WLAN localization system;WLAN signal based positioning;Wi-Fi access point;floor accuracy improvement;floor-error correcting method;indoor localization;indoor navigation system;large scale indoor positioning;wireless LAN","","1","","3","","","24-25 Aug. 2011","","IEEE","IEEE Conference Publications"
"A comparative study of supervised learning techniques for data-driven haptic simulation","W. Abdelrahman; S. Farag; S. Nahavandi; D. Creighton","Center for Intelligent Systems Research, Deakin University, Australia","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","2842","2846","This paper focuses on the choice of a supervised learning algorithm and possible data preprocessing in the domain of data-driven haptic simulation. This is done through a comparison of the performance of different supervised learning techniques with and without data preprocessing. The simulation of haptic interactions with deformable objects using data-driven methods has emerged as an alternative to parametric methods. The accuracy of the simulation depends on the empirical data and the learning method. Several methods were suggested in the literature and here we provide a comparison between their performance and applicability to this domain. We selected four examples to be compared: singular learning mechanism which is artificial neural networks (ANN), attribute selection followed by ANN learning process, ensemble of multiple learning techniques, and attribute selection followed by the learning ensemble. These methods performance was compared in the domain of simulating multiple interactions with a deformable object with nonlinear material behavior.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6084112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6084112","Data-driven simulation;haptics;machine learning","Artificial neural networks;Data models;Deformable models;Haptic interfaces;Supervised learning;Three dimensional displays;Training data","haptic interfaces;learning (artificial intelligence);neural nets","artificial neural networks;attribute selection;data preprocessing;data-driven haptic simulation;deformable objects;haptic interactions;learning ensemble;singular learning mechanism;supervised learning","","0","","25","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"Real time detection of the back view of a preceding vehicle for automated heterogeneous platoons in unstructured environment using video","M. Alfraheed; A. Dröge; R. Kunze; M. Klingender; D. Schilberg; S. Jeschke","Institute of Information Management in Mechanical Engineering (IMA) & Center for Learning and Knowledge Management (ZLW) & Associated Institute form Management Cybernetics e.V. (IfU), RWTH Aachen University, Germany","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","549","555","Due to the increase in road transportation several projects concerning automated highway systems were initiated to optimize highway capacity. In the future, the developed techniques should be applicable in unstructured environment (e.g. desert) and adaptable for heterogeneous vehicles. But before, several challenges, i.e. independency of lane markings, have to be overcome. Our solution is to consider the back view of the preceding vehicle as a reference point for the lateral and longitudinal control of the following vehicle. This solution is independent from the environmental structure as well as additional equipment like infrared emitters. Thus, both the detection and tracking process of the back view are needed to provide automated highway systems with the distance and the deviation degree of the preceding vehicle. In this paper the first step, the detection and location of the back view on video streams, is discussed. For a definite detection in a heterogeneous platoon several features of the back view are detected. A method is proposed to run rejection cascades generated by the AdaBoost classifier theory on the video stream. Compared to other methods related to object detection, the proposed method reduces the running time for the detection of the back view to 0.03-0.08 s/frame. Furthermore, the method enables a more accurate detection of the back view.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083741","Automated Highway System;Machine Learning;Real Time Detection;Unstructured Environment","Cameras;Classification algorithms;Feature extraction;Real time systems;Streaming media;Training;Vehicles","automated highways;learning (artificial intelligence);object detection;pattern classification;traffic engineering computing;video streaming","AdaBoost classifier theory;automated heterogeneous platoons;automated highway systems;highway capacity;infrared emitters;lane markings;lateral control;longitudinal control;preceding vehicle;real time back view detection;road transportation;unstructured environment;video streams","","3","","25","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"A multi-metric fusion approach to visual quality assessment","T. J. Liu; W. Lin; C. C. J. Kuo","Ming Hsieh Department of Electrical Engineering, and Signal and Image Processing Institute, University of Southern California, Los Angeles, CA 90089, USA","2011 Third International Workshop on Quality of Multimedia Experience","20111103","2011","","","72","77","This paper presents a new methodology for objective visual quality assessment with multi-metric fusion (MMF). The current research is motivated by the observation that there is no single metric that gives the best performance scores in all situations. To achieve MMF, we adopt a regression approach. First, we collect a large number of image samples, each of which has a score labeled by human observers and scores associated with different metrics. The new MMF score is set to be the nonlinear combination of multiple metrics with suitable weights obtained by a training process. Furthermore, we divide image distortions into groups and perform regression within each group, which is called “context-dependent MMF” (CD-MMF). One task in CD-MMF is to determine the context automatically, which is achieved by a machine learning approach. It is shown by experimental results that the proposed MMF metric outperforms all existing metrics by a significant margin.","","Electronic:978-1-4577-1335-4; POD:978-1-4577-1333-0; USB:978-1-4577-1334-7","10.1109/QoMEX.2011.6065715","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065715","Visual quality assessment;context-dependent MMF (CD-MMF);context-free MMF (CF-MMF);machine learning;multi-metric fusion (MMF)","Context;Image edge detection;Machine learning;Measurement;Noise;Training;Visualization","image processing;learning (artificial intelligence);regression analysis;sensor fusion","CD-MMF;context-dependent MMF;human observers;image distortions;multimetric fusion;regression approach;training process;visual quality assessment","","15","1","21","","","7-9 Sept. 2011","","IEEE","IEEE Conference Publications"
"Unsupervised deviation detection by GMM — A simulation study","M. Svensson; T. Rognvaldsson; S. Byttner; M. West; B. Andersson","Volvo Technology, Gotaverksgatan 10, 405 08 Goteborg, Sweden","8th IEEE Symposium on Diagnostics for Electrical Machines, Power Electronics & Drives","20111031","2011","","","51","54","A new approach to improve fault detection of electrical machines is proposed. The increased usage of electrical machines and the higher demands on their availability requires new approaches to fault detection. In this paper we demonstrate that it is possible to detect a certain fault on a PMSM (Permanent Magnet Synchronous Machine) by using multiple similar motors, or a single motor, to build a norm of expected behavior by monitoring signal relations. This means that the machine is monitored in an unsupervised way. Four levels of an increased temperature in the rotor magnets have been investigated. The results are based on simulations and the signals used (for relation measurements) are available in a real motor installation. The method shows promising results in detecting two of the temperature faults.","","Electronic:978-1-4244-9303-6; POD:978-1-4244-9301-2; USB:978-1-4244-9302-9","10.1109/DEMPED.2011.6063601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063601","Data mining;PMSM;fault detection;machine learning;mechatronics","","Gaussian processes;fault diagnosis;permanent magnet machines;rotors;synchronous machines","GMM;Gaussian mixture model;electrical machines;fault detection;permanent magnet synchronous machine;rotor magnets;signal relations;temperature faults;unsupervised deviation detection","","0","","11","","","5-8 Sept. 2011","","IEEE","IEEE Conference Publications"
"Vision-based technique for periodical defect detection in hot steel strips","F. G. Bulnes; R. Usamentiaga; D. F. García; J. Molleda; J. L. Rendueles","Department of Computer Science, University of Oviedo, Campus de Viesques, 33204, Gij&#x00F3;n, Espa&#x00F1;a, Spain","2011 IEEE Industry Applications Society Annual Meeting","20111110","2011","","","1","8","This document presents a technique to detect a particularly serious problem: periodical defects. Periodical defects can cause serious damage to steel strips, and so should be corrected as quickly as possible. The technique proposed, which is based on information provided by an artificial vision system, reports on periodical defects detected in one strip before starting to roll the next. A backtracking-based algorithm is proposed to detect periodical defects. This algorithm was trained to work optimally using grid computing techniques to overcome the massive computational requirements. A set of representative strips were chosen to test this technique. The results are shown and compared with those provided by a tool used worldwide.","0197-2618;01972618","Electronic:978-1-4244-9500-9; POD:978-1-4244-9498-9","10.1109/IAS.2011.6074384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6074384","Computer vision;Grid computing;Intelligent systems;Machine learning algorithms;Metal product industries","Strips","automatic optical inspection;backtracking;computer vision;grid computing;production engineering computing;quality control;steel;steel manufacture;strips","artificial vision system;backtracking-based algorithm;grid computing techniques;hot steel strips;periodical defect detection","","0","","11","","","9-13 Oct. 2011","","IEEE","IEEE Conference Publications"
"Local Discretization of Numerical Data for Galois Lattices","N. Girard; K. Bertet; M. Visani","Lab. L3i, Univ. of La Rochelle, La Rochelle, France","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","902","903","Galois lattices' (GLs) definition is defined for a binary table (called context). Therefore, in the presence of continuous data, a discretization step is needed. Discretization is classically performed before the lattice construction in a global way. However, local discretization is reported to give better classification rates than global discretization when used jointly with other symbolic classification methods such as decision trees (DTs). We present a new algorithm performing local discretization for GLs using the lattice properties. Our local discretization algorithm is applied iteratively to particular nodes (called concepts) of the GL. Experiments are performed to assess the efficiency and the effectiveness of the proposed algorithm compared to global discretization.","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103439","Classification;Discretization;Galois Lattices;Machine Learning","Context;Databases;Decision trees;Glass;Iris recognition;Lattices;Navigation","Galois fields;decision trees;iterative methods;numerical analysis;pattern classification","Galois lattice property;binary table;classification rate;continuous data;decision tree;global discretization;lattice construction;local discretization algorithm;numerical data;symbolic classification method","","0","","13","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Quantifying Features Using False Nearest Neighbors: An Unsupervised Approach","J. A. A. Filho; A. C. P. L. F. Carvalho; R. F. Mello; S. Alelyani; H. Liu","ICMC, USP, Sao Carlos, Brazil","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","994","997","Real-world datasets commonly present high dimensional data, which means an increased amount of information. However, this does not always imply an improvement in learning technique performance. Furthermore, some features may be correlated or add unexpected noise, thereby reducing data clustering performance. This has motivated the development of feature selection methods to find the most relevant subset of features to describe data. In this work, we focus on the problem of unsupervised feature selection. The main goal is to define a method to identify the number of features to select after sorting them based on some criterion. This task is done by means of the False Nearest Neighbor technique, which is rooted in chaos theory. Results have shown that this technique gives a good approximate number of features to select. When compared to other techniques, in most of the analyzed cases, it maintains the quality of the generated partitions while selecting fewer features.","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103461","Chaos Theory;Clustering;Machine Learning;Unsupervised Feature Selection","Chaos;Equations;Glass;Iris;Mutual information;Space vehicles;Time series analysis","feature extraction;unsupervised learning","data clustering;false nearest neighbor;features selection;learning technique;quantifying feature;real world datasets;unsupervised feature selection","","1","","15","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Rapid estimation of point source chemical pollutant coverage in catastrophe situation using hierarchical binary decision tree ensemble and probability membership value based ensemble approaches","K. L. Bakos; P. Gamba; P. Bura","University of Pavia, Department of Electronics, Italy","2011 3rd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","20111117","2011","","","1","4","In this paper we present the test results of an extension developed to the Hierarchical Binary Decision Tree (HBDT) ensemble classifier that was introduced in the WHISPERS2009 conference. The new methodology is the Probability Membership Value based Ensemble (PMVE). It uses the HBDTC designer algorithm to select suitable processing chains for decision fusion, but the actual decision fusion is carried out in an unsupervised manner using a weighted re-mapping of the probability membership values of multiple classifiers. The test data used in this study was acquired during the “red sludge” event in Hungary at the end of 2010. Results of traditional classification approaches are also presented for sake of comparison.","2158-6268;21586268","Electronic:978-1-4577-2201-1; POD:978-1-4577-2202-8","10.1109/WHISPERS.2011.6080942","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080942","Classification;Decision Fusion;Ensembles;Hyperspectral;Machine Learning","Accuracy;Algorithm design and analysis;Classification algorithms;Hyperspectral imaging;Principal component analysis;Support vector machines","decision trees;disasters;geophysical image processing;geophysical techniques;industrial pollution;land pollution;pattern classification;sensor fusion;uncertainty handling","AD 2010;HBDT ensemble classifier;HBDTC designer algorithm;Hungary;catastrophe situation;decision fusion;hierarchical binary decision tree ensemble;multiple classifier;point source chemical pollutant coverage;probability membership value based ensemble;rapid estimation;red sludge event","","1","","17","","","6-9 June 2011","","IEEE","IEEE Conference Publications"
"MulTiSEX - A Multi-language Timex Sequential Extractor","S. Rigo; A. Lavelli","Human Language Technol. Res. Unit, Fondazione Bruno Kessler, Trento, Italy","2011 Eighteenth International Symposium on Temporal Representation and Reasoning","20111103","2011","","","163","170","In this paper we present a light-weighted Machine Learning based approach to the recognition and semantic classification of temporal expressions in different languages. We applied the proposed approach to English, Italian and Spanish with limited porting efforts. The experimental results show that our system produces state-of-the-art performance on all the corpora used and in some cases outperforms available systems.","1530-1311;15301311","Electronic:978-0-7695-4508-0; POD:978-1-4577-1242-5","10.1109/TIME.2011.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065208","Machine Learning;Natural Language Processing;Temporal Expressions;Temporal Processing","Accuracy;Computer architecture;Context;Pattern matching;Semantics;Tagging;Training","computational linguistics;learning (artificial intelligence);natural language processing;pattern classification;programming language semantics","English;Italian;Spanish;corpora;machine learning;multilanguage timex sequential extractor;semantic classification;temporal expression recognition","","0","","29","","","12-14 Sept. 2011","","IEEE","IEEE Conference Publications"
"The Syntactic Features and Identification Analysis of ""Planting"" Verb Metaphors","Z. Wang; Y. Jia; L. He","Beijing Language & Culture Univ., Beijing, China","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","185","188","This paper explores the rules of the construction and the syntactic features of the ""planting"" verbal metaphors, with the detailed analysis on syntax, semantics and constitute of the verbal metaphorical expression. Furthermore, we extract the key features to distinguish the verbal metaphors based on the differences between the verbal metaphorical expressions and the literal meanings, and apply the machine learning method to the identification of the verbal metaphor. The experiments show that verbal metaphor has its own unique features on syntax. It would greatly improve the performance of the machine learning models with the addition of these features. Lastly, this method could be extended to other kinds of verbal metaphor.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040836","machine learning;metaphor recognition;metaphorical mapping;syntactic features","Context;Feature extraction;Heart;Pragmatics;Semantics;Support vector machines;Syntactics","computational linguistics;learning (artificial intelligence)","machine learning method;metaphor constitution;metaphor semantics;metaphor syntax;planting verbal metaphor;verbal metaphorical expression","","0","","10","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Data-Driven Intelligent Transportation Systems: A Survey","J. Zhang; F. Y. Wang; K. Wang; W. H. Lin; X. Xu; C. Chen","Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China","IEEE Transactions on Intelligent Transportation Systems","20111128","2011","12","4","1624","1639","For the last two decades, intelligent transportation systems (ITS) have emerged as an efficient way of improving the performance of transportation systems, enhancing travel security, and providing more choices to travelers. A significant change in ITS in recent years is that much more data are collected from a variety of sources and can be processed into various forms for different stakeholders. The availability of a large amount of data can potentially lead to a revolution in ITS development, changing an ITS from a conventional technology-driven system into a more powerful multifunctional data-driven intelligent transportation system (D<sup>2</sup>ITS) : a system that is vision, multisource, and learning algorithm driven to optimize its performance. Furthermore, D<sup>2</sup>ITS is trending to become a privacy-aware people-centric more intelligent system. In this paper, we provide a survey on the development of D<sup>2</sup>ITS, discussing the functionality of its key components and some deployment issues associated with D<sup>2</sup>ITS Future research directions for the development of D<sup>2</sup>ITS is also presented.","1524-9050;15249050","","10.1109/TITS.2011.2158001","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5959985","Data mining;data-driven intelligent transportation systems ( <formula formulatype=""inline""><tex Notation=""TeX"">$hbox{D}^{2}hbox{ITS}$</tex></formula>);machine learning;microblog;mobility;visual analytics;visualization","Data mining;Machine learning;Visual analytics;Visualization","automated highways;learning (artificial intelligence);security of data","D<sup>2</sup>ITS;data-driven intelligent transportation systems;learning algorithm;privacy-aware people-centric more intelligent system;technology-driven system;travel security","","192","","131","","20110721","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Agile Sentiment Analysis of Social Media Content for Security Informatics Applications","R. Colbaugh; K. Glass","Sandia Nat. Labs., Albuquerque, NM, USA","2011 European Intelligence and Security Informatics Conference","20111027","2011","","","327","331","Inferring the sentiment of social media content, for instance blog posts and forum threads, is both of great interest to security analysts and technically challenging to accomplish. This paper presents a new method for estimating social media sentiment which addresses the challenges associated with Web-based analysis. The approach formulates the task as one of learning-based text classification, models the data as a bipartite graph of documents and words, and provides accurate sentiment estimation using only a small lexicon of words of known sentiment orientation, in particular, good performance is obtained without the need for labeled training documents. This capability for effective learning without (labeled) exemplar documents is realized by 1.)exploiting the information present in unlabeled documents and words, which are abundant online, and 2.) appropriately smoothing the sentiment polarity estimates for documents and words in the bipartite graph data model. The utility of the proposed algorithm is demonstrated through implementation with a ""standard""sentiment analysis task involving online consumer product reviews. Additionally, we illustrate the potential of the method for security informatics by inferring regional public opinion regarding the Egyptian revolution via analysis of Arabic, Indonesian, and Danish blog posts.","","Electronic:978-0-7695-4406-9; POD:978-1-4577-1464-1","10.1109/EISIC.2011.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6061226","machine learning;security informatics;sentiment analysis;social media","Algorithm design and analysis;Blogs;Classification algorithms;Informatics;Media;Security;Training","Web sites;classification;security of data;social sciences computing;text analysis","Arabic blog post;Danish blog post;Egyptian revolution;Indonesian blog post;Web-based analysis;agile sentiment analysis;bipartite graph;consumer product;forum thread;learning-based text classification;security informatics;sentiment estimation;sentiment orientation;social media content;social media sentiment;standard sentiment analysis","","7","","16","","","12-14 Sept. 2011","","IEEE","IEEE Conference Publications"
"Artificial intelligence and finite element modelling for monitoring flood defence structures","A. L. Pyayt; I. I. Mokhov; A. Kozionov; V. Kusherbaeva; N. B. Melnikova; V. V. Krzhizhanovskaya; R. J. Meijer","Corp. Technol., Siemens LLC, St. Petersburg, Russia","2011 IEEE Workshop on Environmental Energy and Structural Monitoring Systems","20111103","2011","","","1","7","We present a hybrid approach to monitoring the stability of flood defence structures equipped with sensors. This approach combines the finite element modelling with the artificial intelligence for real-time signal processing and anomaly detection. This combined method has been developed for the UrbanFlood early warning system and successfully tested on a large-scale sea dike during a simulated strong storm with very high water level. The artificial intelligence module detects the onset of dike instability after being trained on the data from the Virtual Dike finite element simulation.","","Electronic:978-1-4577-0609-7; POD:978-1-4577-0610-3","10.1109/EESMS.2011.6067047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6067047","UrbanFlood project;Virtual Dike;anomaly detection;machine learning methods","Alarm systems;Artificial intelligence;Computational modeling;Floods;Levee;Numerical models;Sensors","alarm systems;artificial intelligence;condition monitoring;finite element analysis;floods;geotechnical engineering;structural engineering computing;virtual reality","UrbanFlood early warning system;anomaly detection;artificial intelligence module;finite element modelling;flood defence structure stability monitoring;large-scale sea dike;real-time signal processing;virtual dike finite element simulation","","4","","29","","","28-28 Sept. 2011","","IEEE","IEEE Conference Publications"
"Resident's activity at different abstraction levels: Proposition of a general theoretical framework","L. Pomponio; M. Le Goc; E. Pascual; A. Anfosso","LSIS, Laboratoire des Sciences de d'Information et de Syst&#x00E8;mes, Domaine universitaire de Saint J&#x00E9;r&#x00F4;me, Avenue Escadrille Normandie Niemen, 13397 MARSEILLE Cedex 20, France","Proceedings of the 6th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems","20111110","2011","2","","540","545","One of the major issues of monitoring activities in smart environments is the building of activity models from sensor's timed data. This paper proposes a general theoretical approach to this aim that provides operational results as it is illustrated with the prototypical home of the GerHome project. This proposal is based on the use of a Knowledge Engineering methodology and a Machine Learning process that are both funded on a general theory of dynamic process modeling, the Timed Observation Theory.","","Electronic:978-1-4577-1425-2; POD:978-1-4577-1426-9","10.1109/IDAACS.2011.6072825","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6072825","Abstraction Levels;Dynamic Process Modeling;Machine Learning;Smart Environments","Databases;Humans;Machine learning;Monitoring;Proposals;Semantics;Sensors","computerised monitoring;home computing;learning (artificial intelligence)","GerHome project;abstraction levels;activity models;dynamic process modeling;knowledge engineering methodology;machine learning process;monitoring activities;prototypical home;sensor timed data;smart environment;timed observation theory","","1","","34","","","15-17 Sept. 2011","","IEEE","IEEE Conference Publications"
"SmartNotes: Application of crowdsourcing to the detection of web threats","M. Sharifi; E. Fink; J. G. Carbonell","Computer Science, Carnegie Mellon University, Pittsburgh, PA 15217, USA","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","1346","1350","We describe a crowdsourcing system, called SmartNotes, which detects security threats related to web browsing, such as Internet scams, deceptive sales of substandard products, and websites with intentionally misleading information. It combines automatically collected data about websites with user votes and comments, and uses them to identify potential threats. We have implemented it as a browser extension, which is available for free public use.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083845","Crowdsourcing;machine learning;web security","Browsers;Electronic mail;Privacy;Security;Web pages;Web services","Web sites;security of data","Internet scams;SmartNotes;Web browsing;Web threat detection;Websites;browser extension;crowdsourcing system;security threats;substandard product deceptive sales","","4","","12","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"Non-intrusive Estimation of QoS Degradation Impact on E-Commerce User Satisfaction","N. Poggi; D. Carrera; R. Gavalda; E. Ayguade","Tech. Univ. of Catalonia (UPC), Barcelona, Spain","2011 IEEE 10th International Symposium on Network Computing and Applications","20111010","2011","","","179","186","With the massification of high speed Internet access, recent industry consumer reports show that Web site performance is increasingly becoming a key feature in determining user satisfaction, and finally, a decisive factor in whether a user will purchase on a Web site or even return to it. Traditional Web infrastructure capacity planning has focused on maintaining high throughput and availability on Web sites, optimizing the number of servers to serve peak hours to minimize costs. However, as we will show with our study, the conversion rate-the fraction of users that purchase on a site-is higher at peak hours, where systems are more exposed to suffer overload. In this article we propose a methodology to determine the thresholds of user satisfaction as the QoS delivered by an online business degrades, and to estimate its effects on actual sales. The novelty of the presented technique is that it does not involve any intrusive manipulation of production systems, but a learning process over historic sales data that is combined with system performance measurements. The methodology has been applied to Atra palo.com, a top national Travel and Booking site. For our experiments, we were given access to a 3 year long sales history dataset, as well as actual HTTP and resource consumption logs for several weeks. Obtained results enable autonomic resource managers to set best performance goals and optimize the number of server according to the workload, without surpassing the thresholds of user satisfaction and maximizing revenue for the site.","","Electronic:978-0-7695-4489-2; POD:978-1-4577-1052-0","10.1109/NCA.2011.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038600","Degradation;E-commerce;Machine Learning;Non-intrusive;QoS;Response Time;User Satisfaction;Web;Web Session;performance","Business;Marketing and sales;Quality of service;Servers;Time factors;Training;Web sites","Internet;Web sites;customer satisfaction;electronic commerce;quality of service","Atrapalo.com;QoS degradation impact;Web infrastructure capacity planning;Web site performance;e-commerce user satisfaction;high speed Internet access;nonintrusive estimation;online business","","1","","23","","","25-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Intelligent Green IT Management for Enterprises through System Profiling","S. V. Rao; J. Saravanakumar; K. Sundararaman; J. Parthasarathi; S. Ramesh","Global Technol. Office, Cognizant Technol. Solutions, Chennai, India","2011 IEEE/ACM International Conference on Green Computing and Communications","20111027","2011","","","206","211","Green IT service aim at reducing carbon footprints in workplace and hence save cost using technologies that are sustainable. The current work presents an intelligent Green IT management technique through the system profiling and application of Machine Learning techniques towards generating the system usage patterns. A batch program was developed to control PCs based on the usage pattern. The solution could be implemented in data centers, development centers where thousands of PCs whose usage behavior varies. Such a system could be extended by building ontology's for multiple users using a single system.","","Electronic:978-0-7695-4466-3; POD:978-1-4577-1006-3","10.1109/GreenCom.2011.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6061328","Association Rules;Green IT;Machine Learning;PC profiling","Association rules;Engines;Flexible printed circuits;Green products;Intelligent systems;Protocols;Servers","data mining;environmental factors;learning (artificial intelligence)","PC;association rules;batch program;data centers;green IT service;intelligent green IT management;machine learning techniques;system profiling;system usage patterns","","0","","5","","","4-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Classification Learning System Based on Multi-objective GA and Microthermal Weather Forecast","H. Zhang; J. Xu; S. Zou","Coll. of Comput., Chengdu Univ. of Inf. Technol., Chengdu, China","2011 Second International Conference on Digital Manufacturing & Automation","20111020","2011","","","301","304","A new classification learning system based on multi-objective GA is proposed in this paper. Firstly, the continuous attributes of samples are made discretion with a supervised segmentation method, so generaLization and intelLigibiLity of machine learning are improved. Moreover, comparison and selection mechanism based on partial order in set theory are infused into multi-objective GA. They enhance the abiLity to choose better chromosomes. The new algorithm is used to forecast microthermal weather in northern ZheJiang province. The experiment result indicates that it has unique intelLigence, higher accuracy.","","Electronic:978-0-7695-4455-7; POD:978-1-4577-0755-1","10.1109/ICDMA.2011.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6052011","Machine Learning;Microthermal Weather Forecast;Multi-objective GA;Supervised Segmentation Method","Biological cells;Classification algorithms;Encoding;Learning systems;Neodymium;Weather forecasting","generalisation (artificial intelligence);genetic algorithms;geophysics computing;learning (artificial intelligence);pattern classification;set theory;weather forecasting","China;classification learning system;generalization improvement;intelligibility improvement;machine learning;microthermal weather forecast;multiobjective GA;northern ZheJiang province;partial order;selection mechanism;set theory;supervised segmentation method","","0","","9","","","5-7 Aug. 2011","","IEEE","IEEE Conference Publications"
"Progressive Alignment and Discriminative Error Correction for Multiple OCR Engines","W. B. Lund; D. D. Walker; E. K. Ringger","Comput. Sci. Dept., Brigham Young Univ., Provo, UT, USA","2011 International Conference on Document Analysis and Recognition","20111103","2011","","","764","768","This paper presents a novel method for improving optical character recognition (OCR). The method employs the progressive alignment of hypotheses from multiple OCR engines followed by final hypothesis selection using maximum entropy classification methods. The maximum entropy models are trained on a synthetic calibration data set. Although progressive alignment is not guaranteed to be optimal, the results are nonetheless strong. The synthetic data set used to train or calibrate the selection models is chosen without regard to the test data set, hence, we refer to it as ""out of domain."" It is synthetic in the sense that document images have been generated from the original digital text and degraded using realistic error models. Along with the true transcripts and OCR hypotheses, the calibration data contains sufficient information to produce good models of how to select the best OCR hypothesis and thus correct mistaken OCR hypotheses. Maximum entropy methods leverage that information using carefully chosen feature functions to choose the best possible correction. Our method shows a 24.6% relative improvement over the word error rate (WER) of the best performing of the five OCR engines employed in this work. Relative to the average WER of all five OCR engines, our method yields a 69.1% relative reduction in the error rate. Furthermore, 52.2% of the documents achieve a new low WER.","1520-5363;15205363","Electronic:978-07695-4520-2; POD:978-1-4577-1350-7","10.1109/ICDAR.2011.303","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065414","Error correction;Machine learning;Multiple sequence alignment;Optical character recognition;Optical character recognition software;Progressive text alignment;Synthetic training data set","Calibration;Engines;Entropy;Error analysis;Lattices;Optical character recognition software;Training","document image processing;image classification;optical character recognition","OCR engines;WER;digital text;discriminative error correction;document images;entropy classification methods;optical character recognition;progressive alignment;realistic error models;synthetic data set;word error rate","","2","","19","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Kalman Filter as a pre-processing technique to improve the support vector machine","M. Hassan; R. Rajkumar; D. Isa; R. Arelhi","Department of Electrical and Electronic Engineering, Faculty of Engineering, University of Nottingham, Malaysia Campus, Jalan Broga, 43500, Semenyih, Selangor","2011 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology (STUDENT)","20111201","2011","","","107","112","The Support Vector Machine is widely used as a classification tool to analyze data and recognize patterns. In certain applications of Support Vector Machine, noisy data can greatly affect accuracy and performance. To improve the accuracy of the system, the Kalman Filter has been proposed as a suitable pre-processing technique which can be implemented before using the Support Vector Machine to classify the information. This system has been tested using a dataset obtained from a pipeline defect monitoring system in the department's pipeline laboratory. This test rig uses long range ultrasonic testing to detect minor defects inside a stainless steel pipe. MATLAB simulations show promising results where Kalman Filter and Support Vector Machine combination in a single system produced higher accuracy compared to the discrete wavelet transform in a noisy environment.","","Electronic:978-1-4577-0444-4; POD:978-1-4577-0443-7","10.1109/STUDENT.2011.6089335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6089335","Artificial Intelligence;Kalman Filter;Machine Learning;Pipeline;Support Vector Machine (SVM)","Accuracy;Kalman filters;Mathematical model;Noise;Pipelines;Sensors;Support vector machines","Kalman filters;classification;discrete wavelet transforms;pattern classification;support vector machines","Kalman filter;Matlab simulations;classification tool;data analysis;discrete wavelet transform;pattern classification;support vector machine","","0","","24","","","20-21 Oct. 2011","","IEEE","IEEE Conference Publications"
"Early detection of network applications using neural networks","M. Zelina; M. Oravec","Slovak University of Technology, Faculty of Electrical Engineering and Information Technology, Ilkovi&#x010D;ova 3 81219, Bratislava, Slovakia","Proceedings ELMAR-2011","20111013","2011","","","161","164","Network traffic classification is essential in several fields such as network security and design, or providing adequate QoS. Early detection of network applications is an important feature, which enables recognition of the application online, without the need to capture and examine whole network flow. In this paper we propose a method for classification of Internet applications in the first phases of connection using sizes of first several packets only. For this purpose we used 2 types of neural network (multilayer perceptron and radial basis function network). We examine the performance of this approach for various number of packets from flow and map packet sizes to bins to decrease computational complexity.","1334-2630;13342630","Electronic:978-953-7044-12-1; POD:978-1-61284-949-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6044305","Application recognition;Early detection;Machine learning;Traffic classification","","Internet;neural nets;quality of service;telecommunication traffic","Internet applications;NoSw early detection;QoS;computational complexity;enakles recognition;multilayer perceptron;network security;network traffic classification;neural network;quality of service;radial basis function network","","0","","10","","","14-16 Sept. 2011","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>A novel QoS evaluation scheme based on support vector machine","J. Wang; H. Liu; M. Song","Sch. of Electron. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","2011 Seventh International Conference on Natural Computation","20110919","2011","2","","724","727","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>The quality of service (QoS) is an important factor for networks; guarantee the QoS in network is then very important for the network performance. Anyway, the research on the accurately evaluation on QoS is still lacked. In this paper, we employ the computational learning theory to study this problem and present the QoS evaluation model. Then the QoS evaluation scheme base on support vector machine (SVM) is proposed. Simulation results show that our propose scheme is more effective and improve the performance of the QoS evaluation.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022143","Computational Learning;Machine Learning;QoS evaluation;Support Vector Machine","Computational efficiency;Computational modeling;Machine learning;Quality of service;Support vector machines;Telecommunications;Training data","computer network performance evaluation;quality of service;support vector machines;telecommunication computing;ubiquitous computing","QoS evaluation scheme;SVM;computational learning theory;network performance;quality of service;support vector machine;ubiquitous heterogeneous network","","0","","6","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Utilising numerical weather forecast for planning electricity production in cogeneration plant","M. B. Kursa; S. Walkowiak; L. Ligowski; W. R. Rudnicki","","2011 16th International Conference on Intelligent System Applications to Power Systems","20111117","2011","","","1","4","Production of heat and electricity in the cogeneration plant depends on weather, thus forecasting production is dependent on weather forecasts. Here we present the models of the heat production based on two weather forecast models, COAMPS and UM. The linear models that are based on the predicted air temperature can explain up to 90% of variability of production and deteriorate slowly with the range of forecast. The models of heat productions that are based on UM weather forecasts significantly outperforms those that are based on the models based on the COAMPS weather forecasts. The machine learning algorithm random forest is used to improve the basic models. To this end the residuals from the linear models are predicted using various meteorological variables along with variables governing activity of city inhabitants, such as hour of the day or day of the week. This machine learning approach leads to small but significant improvement in comparison to the original model.","","Electronic:978-1-4577-0809-1; POD:978-1-4577-0807-7","10.1109/ISAP.2011.6082211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6082211","heat electricity cogeneration;machine learning;weather forecast","Adaptation models;Heating;IEEE Xplore;Laboratories;Lead;Oceans;Predictive models","cogeneration;learning (artificial intelligence);power engineering computing;power generation planning;weather forecasting","COAMPS weather forecasts;UM weather forecasts;cogeneration plant;electricity production;electricity production planning;heat production;linear models;machine learning algorithm random forest;meteorological variables;numerical weather forecast models","","0","","10","","","25-28 Sept. 2011","","IEEE","IEEE Conference Publications"
"A real-time rescheduling heuristic using decentralized knowledge-based decisions for flexible flow shops with unrelated parallel machines","Y. Tan; M. Aufenanger","Bremer Institut f&#x00FC;r Produktion und Logistik (BIBA) - University of Bremen - Bremen - Germany","2011 9th IEEE International Conference on Industrial Informatics","20111006","2011","","","431","436","In a manufacturing planning and control system, a change of system environment or of the production requirements may invalidate the current production schedule. In that case, rescheduling as a self-adaption function of the system is necessary for generating a new schedule, regarding the current state of the production system. This rescheduling process is time critical and normally requires real time solutions. In this paper we present a rescheduling approach with offline self-learning and online self-decision-making abilities. It solves the rescheduling problem of flexible flow shops (FFS) with unrelated parallel machines. The optimality criterion is the makespan. The approach uses a centralized heuristic to guarantee the generation of active schedules. In addition, it integrates a decentralized knowledge-based decision making system in the heuristic. This decision making system can learn from previous scheduling problems and their schedules. Consequently, it uses the obtained knowledge to dynamically select the most appropriate dispatching rule for scheduling the production, depending on the current system state. Computational results show that the proposed approach is superior to only using one single dispatching rule constantly. Furthermore, due to its efficient runtime the approach is suitable for real time applications.","1935-4576;19354576","Electronic:978-1-4577-0434-5; POD:978-1-4577-0435-2; USB:978-1-4577-0433-8","10.1109/INDIN.2011.6034918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034918","dynamic dispatching rule;flexible flow shop;machine learning;rescheduling;scheduling","Dispatching;Job shop scheduling;Knowledge based systems;Least squares approximation;Schedules;Training","decision making;dynamic scheduling;flexible manufacturing systems;flow shop scheduling;heuristic programming;production planning","decentralized knowledge-based decisions;decision making system;flexible flow shops;manufacturing control systems;manufacturing planning systems;production dispatching rule;production scheduling;production system self adaption function;realtime rescheduling heuristics;rescheduling process;unrelated parallel machines","","2","","12","","","26-29 July 2011","","IEEE","IEEE Conference Publications"
"Image Annotation Using the SimpleDecisionTree","S. Wan","Sch. of Inf. & Safety Eng., Zhongnan Univ. of Econ. & Law, Wuhan, China","2011 Fifth International Conference on Management of e-Commerce and e-Government","20111201","2011","","","141","146","Automatic image annotation is an important but highly challenging problem in semantic-based image retrieval. In this paper, we formulate image annotation as a supervised learning image classification problem under region-based image annotation framework. In region-based image annotation, keywords are usually associated with individual regions in the training data set. This paper applys a novel simple decision tree (SDT) algorithm in our image annotation system, which can classify a large number of training data faster and more effectively. The proposed SDT algorithm is experimented on image annotation Corel data sets. Compared to classical algorithms, SDT accelerates the operation speed of the algorithm, and the classification accuracy remains robustness. It has a good application in automatic image annotation system.","","Electronic:978-0-7695-4544-8; POD:978-1-4577-1659-1","10.1109/ICMeCG.2011.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6092648","Automatic image annotation;machine learning","Accuracy;Classification algorithms;Complexity theory;Feature extraction;Image segmentation;Training;Visualization","decision trees;image classification;image retrieval;learning (artificial intelligence)","SDT;image annotation Corel data sets;image classification;image retrieval;simple decision tree;supervised learning","","0","","24","","","5-6 Nov. 2011","","IEEE","IEEE Conference Publications"
"A Framework for Learning Comprehensible Theories in XML Document Classification","J. Wu","CSIRO ICT Centre, Canberra","IEEE Transactions on Knowledge and Data Engineering","20111121","2012","24","1","1","14","XML has become the universal data format for a wide variety of information systems. The large number of XML documents existing on the web and in other information storage systems makes classification an important task. As a typical type of semistructured data, XML documents have both structures and contents. Traditional text learning techniques are not very suitable for XML document classification as structures are not considered. This paper presents a novel complete framework for XML document classification. We first present a knowledge representation method for XML documents which is based on a typed higher order logic formalism. With this representation method, an XML document is represented as a higher order logic term where both its contents and structures are captured. We then present a decision-tree learning algorithm driven by precision/recall breakeven point (PRDT) for the XML classification problem which can produce comprehensible theories. Finally, a semi-supervised learning algorithm is given which is based on the PRDT algorithm and the cotraining framework. Experimental results demonstrate that our framework is able to achieve good performance in both supervised and semi-supervised learning with the bonus of producing comprehensible learning theories.","1041-4347;10414347","","10.1109/TKDE.2011.158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5959167","XML document;knowledge representation;machine learning;semi-supervised learning.","Knowledge representation;Learning systems;Machine learning;Machine learning algorithms;Supervised learning;Unsupervised learning;XML","Internet;XML;formal logic;knowledge representation;learning (artificial intelligence);pattern classification;storage management","XML document classification;comprehensible theories;decision-tree learning algorithm;information storage systems;information systems;knowledge representation method;precision/recall breakeven point;semi-supervised learning algorithm;typed higher order logic formalism;universal data format;web","","6","","57","","20110721","Jan. 2012","","IEEE","IEEE Journals & Magazines"
"Power-Efficient Hardware Architecture of K-Means Clustering With Bayesian-Information-Criterion Processor for Multimedia Processing Applications","T. W. Chen; C. H. Sun; H. H. Su; S. Y. Chien; D. Deguchi; I. Ide; H. Murase","Graduate School of Information Science, Nagoya University, Nagoya-shi, Japan","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","20111107","2011","1","3","357","368","A power-efficient K-Means hardware architecture that can automatically estimate the number of clusters in the clustering process is proposed. The contributions of this work include two main aspects. The first is the integration of the hierarchical data sampling in the hardware to accelerate the clustering speed. The second is the development of the “Bayesian-Information-Criterion (BIC) Processor” to estimate the number of clusters of K-Means. The architecture of the “BIC Processor” is designed based on the simplification of the BIC computations, and the precision of the logarithm function is also analyzed. The experiments show that the proposed architecture can be employed in different multimedia applications, such as motion segmentation and edge-adaptive noise reduction. Besides, the gate count of the hardware is 51 K with the 90-nm complimentary metal-oxide-semiconductor technology. It is also shown that this work can achieve high efficiency compared with a GPU, and the power consumption scales well with the number of clusters and the number of dimensions. The power consumption ranges between 10.72 and 12.95 mW in different modes when the operating frequency is 233 MHz.","2156-3357;21563357","","10.1109/JETCAS.2011.2165231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032714","Clustering methods;K-Means;energy efficiency;hardware design;machine learning","Bayesian methods;Clustering algorithms;Computer architecture;Hardware;Image color analysis;Monitoring;Multimedia communication","Bayes methods;multimedia systems;pattern clustering;power aware computing","Bayesian-information-criterion processor;complimentary metal-oxide-semiconductor technology;edge-adaptive noise reduction;hierarchical data sampling;k-means clustering;logarithm function;motion segmentation;multimedia processing applications;power consumption;power-efficient hardware architecture","","11","","26","","20111003","Sept. 2011","","IEEE","IEEE Journals & Magazines"
