"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7381882,7379742,7379507,7379953,7383136,7379596,7381378,7381880,7379716,7051274,7379259,7379729,7382159,7382048,7379463,7379339,7379527,7382933,7380518,7379623,7377562,7375198,7377670,7378020,7375206,7375291,7375359,7375593,7377982,7335566,7247654,7370174,7372238,7372210,7372234,7372198,7366364,7373916,7372237,7371532,7373006,7317517,7372954,7372633,7372024,7372214,7372580,7373987,7372114,7371813,7372570,7372990,7372229,7373128,7373896,7371866,7371525,7372192,7373514,7367349,7000992,6949596,7321003,7315025,7368025,7163608,7214290,7364091,7363882,7363176,7363906,7363929,7363742,7363123,7363892,7363213,7363841,7365790,7363944,7363748,7362892,7364941,7365904,7363883,7363339,7363884,7364690,7364014,7363939,7364099,7362853,7362478,7363259,7363922,7042341,7283568,7361145,7031444,7361233,7360567",2017/05/05 21:49:26
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Statistical learning in chip (SLIC)","R. D. Blanton; X. Li; K. Mai; D. Marculescu; R. Marculescu; J. Paramesh; J. Schneider; D. E. Thomas","Electrical and Computer Engineering Department, Carnegie Mellon University, Pittsburgh, PA 15213, USA","2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","20160107","2015","","","664","669","Despite best efforts, integrated systems are “born” (manufactured) with a unique `personality' that stems from our inability to precisely fabricate their underlying circuits, and create software a priori for controlling the resulting uncertainty. It is possible to use sophisticated test methods to identify the best-performing systems but this would result in unacceptable yields and correspondingly high costs. The system personality is further shaped by its environment (e.g., temperature, noise and supply voltage) and usage (i.e., the frequency and type of applications executed), and since both can fluctuate over time, so can the system's personality. Systems also “grow old” and degrade due to various wear-out mechanisms (e.g., negative-bias temperature instability), and unexpectedly due to various early-life failure sources. These “nature and nurture” influences make it extremely difficult to design a system that will operate optimally for all possible personalities. To address this challenge, we propose to develop statistical learning in-chip (SLIC). SLIC is a holistic approach to integrated system design based on continuously learning key personality traits on-line, for self-evolving a system to a state that optimizes performance hierarchically across the circuit, platform, and application levels. SLIC will not only optimize integrated-system performance but also reduce costs through yield enhancement since systems that would have before been deemed to have weak personalities (unreliable, faulty, etc.) can now be recovered through the use of SLIC.","","Electronic:978-1-4673-8388-2; POD:978-1-4673-8109-3; USB:978-1-4673-8389-9","10.1109/ICCAD.2015.7372633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372633","Integrated system design;low-power design;statistical and machine learning","Actuators;Data models;Integrated circuit modeling;Statistical learning;Time-frequency analysis;Training data;Uncertainty","electronic engineering computing;integrated circuit design;learning (artificial intelligence)","SLIC;cost reduction;integrated system design;integrated-system performance optimization;statistical learning in chip;yield enhancement","","","","32","","","2-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Robustness-Driven Feature Selection in Classification of Fibrotic Interstitial Lung Disease Patterns in Computed Tomography Using 3D Texture Features","D. Y. Chong; H. J. Kim; P. Lo; S. Young; M. F. McNitt-Gray; F. Abtin; J. G. Goldin; M. S. Brown","Center for Computer Vision and Imaging Biomarkers, Department of Radiology, David Geffen School of Medicine at UCLA, Los Angeles, CA, USA","IEEE Transactions on Medical Imaging","20151229","2016","35","1","144","157","Lack of classifier robustness is a barrier to widespread adoption of computer-aided diagnosis systems for computed tomography (CT). We propose a novel Robustness-Driven Feature Selection (RDFS) algorithm that preferentially selects features robust to variations in CT technical factors. We evaluated RDFS in CT classification of fibrotic interstitial lung disease using 3D texture features. CTs were collected for 99 adult subjects separated into three datasets: training, multi-reconstruction, testing. Two thoracic radiologists provided cubic volumes of interest corresponding to six classes: pulmonary fibrosis, ground-glass opacity, honeycombing, normal lung parenchyma, airway, vessel. The multi-reconstruction dataset consisted of CT raw sinogram data reconstructed by systematically varying slice thickness, reconstruction kernel, and tube current (using a synthetic reduced-tube-current algorithm). Two support vector machine classifiers were created, one using RDFS (“with-RDFS”) and one not (“without-RDFS”). Classifier robustness was compared on the multi-reconstruction dataset, using Cohen's kappa to assess classification agreement against a reference reconstruction. Classifier performance was compared on the testing dataset using the extended g-mean (EGM) measure. With-RDFS exhibited superior robustness (kappa 0.899-0.989) compared to without-RDFS (kappa 0.827-0.968). Both classifiers demonstrated similar performance on the testing dataset (EGM 0.778 for with-RDFS; 0.785 for without-RDFS), indicating that RDFS does not compromise classifier performance when discarding nonrobust features. RDFS is highly effective at improving classifier robustness against slice thickness, reconstruction kernel, and tube current without sacrificing performance, a result that has implications for multicenter clinical trials that rely on accurate and reproducible quantitative analysis of CT images col- ected under varied conditions across multiple sites, scanners, and timepoints.","0278-0062;02780062","","10.1109/TMI.2015.2459064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163608","High-resolution computed tomography;fibrotic interstitial lung disease;machine learning;pattern recognition and classification","Computed tomography;Image reconstruction;Lungs;Resource description framework;Robustness;Testing;Training","computerised tomography;diseases;feature selection;image classification;image reconstruction;image texture;lung;medical image processing;support vector machines","3D texture feature;CT classification;CT image analysis;CT raw sinogram data reconstruction;Cohen kappa;SVM classifier;airway;classifier robustness;computed tomography;computer-aided diagnosis system;extended g-mean measurement;fibrotic interstitial lung disease pattern classification;ground-glass opacity;honeycombing;multireconstruction dataset;normal lung parenchyma;pulmonary fibrosis;reconstruction kernel;robustness-driven feature selection;slice thickness;support vector machine;synthetic reduced-tube-current algorithm;tube current;vessel","","1","","33","","20150721","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Predicting Delays in Software Projects Using Networked Classification (T)","M. Choetkiertikul; H. K. Dam; T. Tran; A. Ghose","Sch. of Comput. & Inf. Technol., Univ. of Wollongong, Wollongong, NSW, Australia","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","20160107","2015","","","353","364","Software projects have a high risk of cost and schedule overruns, which has been a source of concern for the software engineering community for a long time. One of the challenges in software project management is to make reliable prediction of delays in the context of constant and rapid changes inherent in software projects. This paper presents a novel approach to providing automated support for project managers and other decision makers in predicting whether a subset of software tasks (among the hundreds to thousands of ongoing tasks) in a software project have a risk of being delayed. Our approach makes use of not only features specific to individual software tasks (i.e. local data) -- as done in previous work -- but also their relationships (i.e. networked data). In addition, using collective classification, our approach can simultaneously predict the degree of delay for a group of related tasks. Our evaluation results show a significant improvement over traditional approaches which perform classification on each task independently: achieving 46% -- 97% precision (49% improved), 46% -- 97% recall (28% improved), 56% -- 75% F-measure (39% improved), and 78% -- 95% Area Under the ROC Curve (16% improved).","","Electronic:978-1-5090-0025-8; POD:978-1-5090-0026-5","10.1109/ASE.2015.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372024","Machine Learning;Networked classification;Risk management;Software analytics","Data mining;Delays;Information technology;Predictive models;Risk management;Software;Software engineering","pattern classification;project management;software engineering;software management","F-measure;Networked Classification;ROC Curve;software engineering community;software project management","","","","57","","","9-13 Nov. 2015","","IEEE","IEEE Conference Publications"
"Genetic deep neural networks using different activation functions for financial data mining","L. M. Zhang","Soft Tech Consulting, Inc., Chantilly, VA, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2849","2851","A Deep Neural Network (DNN) using the same activation function for all hidden neurons has an optimization limitation due to its single mathematical functionality. To solve it, a new DNN with different activation functions is designed to globally optimize both parameters (weights and biases) and function selections. In addition, a novel Genetic Deep Neural Network (GDNN) with different activation functions uses genetic algorithms to optimize the parameters and selects the best activation function combination for different neurons among many activation function combinations through sufficient simulations. Two sample financial data sets (""Dow Jones Industrial Average"" and ""30-Year Treasury Constant Maturity Rate"" were used for performance analysis. Simulation results indicate that a GDNN using different activation functions can perform better than one using a single activation function. Future works include (1) developing more effective DNNs using different activation functions by using both cloud and GPU computing, (2) creating more effective DNNs by using new training optimization methods different from genetic algorithms, (3) using big data to further test the performance of the new GDNN, and (4) expanding its big data mining application areas (i.e. health and biomedical informatics, computer vision, social networks, security, etc.).","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364099","Deep learning;activation functions;big data mining;genetic algorithms;machine learning;neural networks;optimization","Big data;Biological neural networks;Genetic algorithms;Neurons;Testing;Training","Big Data;cloud computing;data mining;financial data processing;graphics processing units;neural nets","30-year treasury constant maturity rate;Dow Jones industrial average;GDNN;GPU computing;activation functions;big data mining application areas;cloud computing;financial data mining;financial data sets;genetic deep neural networks;mathematical functionality;training optimization methods","","","","12","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"A generalized flow for multi-class and binary classification tasks: An Azure ML approach","M. Bihis; S. Roychowdhury","Electrical Engineering, University of Washington, Bothell, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1728","1737","The constant growth in the present day real-world databases pose computational challenges for a single computer. Cloud-based platforms, on the other hand, are capable of handling large volumes of information manipulation tasks, thereby necessitating their use for large real-world data set computations. This work focuses on creating a novel Generalized Flow within the cloud-based computing platform: Microsoft Azure Machine Learning Studio (MAMLS) that accepts multi-class and binary classification data sets alike and processes them to maximize the overall classification accuracy. First, each data set is split into training and testing data sets, respectively. Then, linear and nonlinear classification model parameters are estimated using the training data set. Data dimensionality reduction is then performed to maximize classification accuracy. For multi-class data sets, data-centric information is used to further improve overall classification accuracy by reducing the multi-class classification to a series of hierarchical binary classification tasks. Finally, the performance of optimized classification model thus achieved is evaluated and scored on the testing data set. The classification characteristics of the proposed flow are comparatively evaluated on 3 public data sets and a local data set with respect to existing state-of-the-art methods. On the 3 public data sets, the proposed flow achieves 78-97.5% classification accuracy. Also, the local data set, created using the information regarding presence of Diabetic Retinopathy lesions in fundus images, results in 85.3-95.7% average classification accuracy, which is higher than the existing methods. Thus, the proposed generalized flow can be useful for a wide range of application-oriented ""big data sets"".","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363944","Big Data;Classification;Fundus Images;Generalized Flow;Microsoft Azure Machine Learning Studio","Big data;Data models;Lesions;Support vector machines;Testing;Training data;Vegetation","cloud computing;data reduction;database management systems;learning (artificial intelligence);parameter estimation;pattern classification","Azure ML approach;MAMLS;Microsoft Azure Machine Learning Studio;application-oriented Big Data sets;binary classification data sets;classification accuracy;cloud-based computing platform;cloud-based platforms;data dimensionality reduction;data-centric information;diabetic retinopathy lesions;fundus images;generalized flow;hierarchical binary classification tasks;large real-world data set computations;local data set;multiclass classification data sets;multiclass classification tasks;nonlinear classification model parameters estimation;optimized classification model;public data sets;real-world databases","","2","","13","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Exploring Accuracy-Cost Tradeoff in In-Home Living Activity Recognition Based on Power Consumptions and User Positions","K. Ueda; H. Suwa; Y. Arakawa; K. Yasumoto","Nara Inst. of Sci. & Technol., Nara, Japan","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","1130","1137","Advanced context-aware services at home such as elderly monitoring requires highly accurate living activity recognition in a home environment. Existing studies on living activity recognition suffer from high deployment and maintenance costs, privacy intrusion due to utilization of cameras and microphones, and few recognizable activities or low recognition accuracy. In this paper, to solve these problems, we propose a new living activity recognition method. Our method utilizes only power meters attached to appliances and a positioning sensor attached to a resident of a home to mitigate privacy intrusion. We target 10 different living activities which cover most of our daily lives at home and construct activity recognition models based on machine-leaning. To accurately recognize the activities from the sensor data by power meters and position sensor, we explore the best combination of time window width for samples of training/test data, features, and machine-learning algorithms. Furthermore, we thoroughly investigate the tradeoff between the sensor data granularity and the consequent recognition accuracy. Through experiments using sensor data collected by four participants in our smart home, the proposed method achieved 97.8% average F-measure of recognizing 10 target activities with the finest sensor data granularity (position estimation error ≤ 0.1m, 16 power meters) and 86.9 % F-measure with room-level position accuracy and one power meter for each of four rooms.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363213","activity recognition;in-home lining activity;machine learning;power consumption;user position","Data visualization;Home appliances;Intelligent sensors;Sensor systems;Smart homes;TV","data privacy;geriatrics;home automation;learning (artificial intelligence);patient monitoring;power consumption;power meters;security of data;sensors;ubiquitous computing;user interfaces","accuracy-cost tradeoff;advanced context-aware services;cameras utilization;consequent recognition accuracy;deployment costs;elderly monitoring;in-home living activity recognition;machine-learning algorithms;maintenance costs;microphones utilization;positioning sensor;power consumptions;power meters;privacy intrusion mitigation;sensor data granularity;smart home;time window width;user positions","","1","","22","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Ultrasonic fatty liver imaging","Y. Deng; J. Jago; Y. Gong","Philips Research China, Shanghai, China","2015 23rd European Signal Processing Conference (EUSIPCO)","20151228","2015","","","2591","2595","Fatty liver disease is a prevalent condition which may result in serious liver complications and is currently lack of an effective and efficient approach for its quantification. In the paper, we propose to directly image the fat content distribution in liver based on ultrasound echo radio-frequency signals. In the proposed method, spectral difference is utilized to represent the small pieces of liver tissues. Then the connection between the data representation and liver tissues is directly established by an elaborately designed learning process in the high-dimensional feature space, which includes comprehensive hyperparameter learning and model learning. Experimental results demonstrate the effectiveness of the proposed method which is able to visualize the fat distribution and has a 0.93 correlation coefficient with the fat-percentage quantification results of doctor's pathological analysis.","","Electronic:978-0-9928-6263-3; POD:978-1-4799-8851-8","10.1109/EUSIPCO.2015.7362853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362853","Fatty liver;Imaging;Machine learning;Quantification;Ultrasound echo signal","Attenuation;Imaging;Liver diseases;RF signals;Radio frequency;Ultrasonic imaging","biological tissues;biomedical ultrasonics;diseases;feature extraction;learning (artificial intelligence);liver;medical image processing","high-dimensional feature space;hyperparameter learning process;liver tissues;ultrasonic fatty liver imaging;ultrasound echo radiofrequency signals","","","","32","","","Aug. 31 2015-Sept. 4 2015","","IEEE","IEEE Conference Publications"
"Learning-Based Emulation of Sea Surface Wind Fields From Numerical Model Outputs and SAR Data","L. He; R. Fablet; B. Chapron; J. Tournadre","Laboratory of Oceanography from Space, Ifremer, Plouzane, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20160108","2015","8","10","4742","4750","The availability of sea surface wind conditions with a high-resolution (HR) space-time sampling is a critical issue for a wide range of applications. Currently, no observation systems nor model forecasts provide relevant information with a high sampling rate in both space and time. Synthetic aperture radar (SAR) satellite systems deliver HR sea surface fields, with a spatial resolution below 0.01°, but they are also characterized by a large revisit time up 7 to 10 days for temperate zones. Meanwhile, operational model predictions typically involve a high temporal resolution (e.g., every 6 h), but also a low spatial resolution (0.5°). With a view to leveraging both data sources, we investigate statistical downscaling schemes. In this study, a new model based on a machine learning method, namely support vector regression (SVR), is built to reconstruct HR sea surface wind fields from low-resolution operational model forecasts. The considered case study off Norway demonstrates the relevance of the proposed SVR model. It outperforms state-of-the-art approaches [namely, linear, analog, and empirical orthogonal function (EOF) downscaling models] in terms of mean square error. It also realistically reproduces complex space-time variabilities of the observed SAR wind fields. We further discuss the SVR model as a generalization of the popular linear and analog models.","1939-1404;19391404","","10.1109/JSTARS.2015.2496503","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335566","Coastal wind;downscaling;high resolution (HR);machine learning;support vector regression (SVR)","Machine learning;Numerical models;Predictive models;Sea surface;Support vector machines;Synthetic aperture radar;Wind forecasting","numerical analysis;regression analysis;remote sensing by radar;synthetic aperture radar;wind","Norway;SAR data;data source;empirical orthogonal function;high-resolution space-time sampling;machine learning method;numerical model;sea surface wind condition;sea surface wind field learning-based emulation;statistical downscaling scheme;support vector regression;synthetic aperture radar satellite system;temperate zone;time 7 day to 10 day","","1","","36","","20151123","Oct. 2015","","IEEE","IEEE Journals & Magazines"
"Automatic Evaluation Methods of Trainee's Answers to Develop a 4R Risk Prediction Training System","H. Minowa; H. Fujimoto; K. Takeuchi","Dept. of Bus. Adm., Okayama Shoka Univ., Okayama, Japan","2015 IIAI 4th International Congress on Advanced Applied Informatics","20160107","2015","","","283","286","4 Rounds (4R) training method is practiced in industrial office site for reducing accidents caused by human factors. The 4R method enables to raise hazard-prediction capability of worker such as coping, decision-making to avoid danger situation. The workers as trainees train on their own by finding hazards which lurked in the hazard prediction training (KYT in Japanese) sheet. However, there is a large problem that a single trainee cannot train oneself using 4R method because the training of 4R method needs instruction of expert as human instructor. To solve that problem, we aim to develop hazard prediction training system. The advantage of this system enables trainee to train oneself anytime/anywhere using 4R method. In this research paper, we reports about our proposal of training system, the development of subsystem which based on machine learning to evaluate trainee's answer correct or not, and reports the result of evaluation experimental that showed the average accuracy was 63.0±22.9 [%].","","Electronic:978-1-4799-9958-3; POD:978-1-4799-9959-0","10.1109/IIAI-AAI.2015.301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373916","e-learning;machine learning;natural language processing;training","Accidents;Chemicals;Computers;Hazards;Training;Training data","computer based training;hazards;industrial accidents;industrial training;learning (artificial intelligence);natural language processing;risk analysis","4 Rounds training method;4R risk prediction training system;accidents reducing;automatic trainee answer evaluation methods;decision-making;hazard prediction training sheet;hazard prediction training system;hazard-prediction capability;human factors;industrial office site;machine learning","","","","5","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"Reframing in Frequent Pattern Mining","C. F. Ahmed; M. Samiullah; N. Lachiche; M. Kull; P. Flach","ICube Lab., Univ. of Strasbourg, Strasbourg, France","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","799","806","Mining frequent patterns is a crucial task in data mining. Most of the existing frequent pattern mining methods find the complete set of frequent patterns from a given dataset. However, in real-life scenarios we often need to predict the future frequent patterns for different tasks such as business policy making, web page recommendation, stock-market behavior and road traffic analysis. Predicting future frequent patterns from the currently available set of frequent patterns is challenging due to dataset shift where data distributions may change from one dataset to another. In this paper, we propose a new approach called reframing in frequent pattern mining to solve this task. Moreover, we experimentally show the existence of dataset shift in two real-life transactional datasets and the capability of our approach to handle these unknown shifts.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372214","Adaptation;Data Mining;Dataset Shift;Frequent Pattern Mining;Machine Learning","Adaptation models;Business;Cities and towns;Context;Data mining;Data models;Databases","data mining;recommender systems;stock markets","Web page recommendation;business policy making;data mining;frequent pattern mining;road traffic analysis;stock-market behavior","","","","18","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Situation Analytics: A Foundation for a New Software Engineering Paradigm","C. K. Chang","Iowa State University","Computer","20160114","2016","49","1","24","33","Advances in cognitive science along with modern-day smart technologies and software services that take into account our mental state will enable a software industry that is poised to meet customers' needs on the fly in new and truly individualized ways.","0018-9162;00189162","","10.1109/MC.2016.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383136","aware computing;cognitive science;context awareness;human-computer interaction;machine learning;requirements engineering;runtime adaptation;services computing;situation awareness;software engineering","Cognition;Context awareness;Machine learning;Services computing;Software engineering","cognition;software engineering;software houses","cognitive science;customer needs;modern-day smart technologies;software engineering paradigm;software industry;software services","","4","","23","","","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Intelligent analysis of data cube via statistical methods","M. M. Awan; M. Usman","Department of Computer Science, Shaheed Zulfikar Ali Bhutto Institute of Science and Technology, Islamabad, Pakistan","2015 Tenth International Conference on Digital Information Management (ICDIM)","20160114","2015","","","20","27","Data cube is a multi-dimensional structure of data representation used in data warehousing, which is analyzed using Online Analytical Process(OLAP). However, OLAP in itself is incapable of intelligent analysis in terms of generating a compact and useful data cube as well as lacks the power of predicting empty measures in data cube. Recently statistical methods have been applied for compact cube generation and prediction of empty measures in data cube. In this paper we reviewed and critically evaluated the available work done in this area. Literature review highlighted that sparsity, data redundancy and need of domain knowledge are problems in the way of intelligent analysis. Statistical methods have solved these issues in schema generation, compact cube generation and in prediction of empty measures of data cube individually. Methodology to solve these problems and then to perform an intelligent analysis has not yet been developed. In order to develop such an integrated methodology, we propose a conceptual model for intelligent analysis of data cube via statistical methods in the first stage. This model is integrating statistical methods used in generating a compact cube with a prediction mechanism. Our next target is to develop this model into a complete methodology.","","Electronic:978-1-4673-9152-8; POD:978-1-4673-9153-5","10.1109/ICDIM.2015.7381880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381880","Cube analysis;Data cube with statistical methods;Machine learning and OLAP;OLAP analysis;Prediction;Statistical methods for OLAP","Analysis of variance;Area measurement;Redundancy","data mining;data structures;data warehouses;statistical analysis","OLAP;compact cube generation;data cube;data redundancy;data representation;data warehousing;intelligent analysis;multidimensional structure;online analytical process;prediction mechanism;schema generation;statistical methods","","","","12","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Feature learning with deep scattering for urban sound analysis","J. Salamon; J. P. Bello","Center for Urban Science and Progress, New York University, USA","2015 23rd European Signal Processing Conference (EUSIPCO)","20151228","2015","","","724","728","In this paper we evaluate the scattering transform as an alternative signal representation to the mel-spectrogram in the context of unsupervised feature learning for urban sound classification. We show that we can obtain comparable (or better) performance using the scattering transform whilst reducing both the amount of training data required for feature learning and the size of the learned codebook by an order of magnitude. In both cases the improvement is attributed to the local phase invariance of the representation. We also observe improved classification of sources in the background of the auditory scene, a result that provides further support for the importance of temporal modulation in sound segregation.","","Electronic:978-0-9928-6263-3; POD:978-1-4799-8851-8","10.1109/EUSIPCO.2015.7362478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362478","Unsupervised learning;acoustic event classification;machine learning;scattering transform;urban","Algorithm design and analysis;Clustering algorithms;Modulation;Scattering;Signal processing algorithms;Spectrogram;Transforms","audio signal processing;learning (artificial intelligence);signal classification","deep scattering;feature learning;local phase invariance;mel-spectrogram;scattering transform;signal representation;sound segregation;temporal modulation;unsupervised feature learning;urban sound analysis;urban sound classification","","2","","29","","","Aug. 31 2015-Sept. 4 2015","","IEEE","IEEE Conference Publications"
"DA vision 2015: From here to eternity","M. Potkonjak; D. Chen; P. Kalla; S. P. Levitan","Computer Science Department, University of California, Los Angeles, United States","2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","20160107","2015","","","271","277","Design automation (DA) is at a historical moment where it has a chance - after mathematics, statistics, and computer science - to establish itself as the fourth universal approach with widespread applications in a variety of scientific, engineering, and economic domains. We start by outlining some of the most important research contributions and industrial applications of the design automation; we identify key conceptual DA techniques and describe how they interact to form synthesis and analysis flows. Next, we discuss the most attractive emerging and pending DA domains by analyzing several recent technologies, applications, and conceptual trends. Our emphasis is not just on the most challenging research or the most lucrative application areas but also on the technological trends relevant to DA. Furthermore, we elaborate on the types of new DA techniques and tools that are required for further fundamental progress and improved practical relevance. In order to provide a balanced picture of DA, we also identify the most pronounced dangers in false starts and false research in DA. Finally, we briefly discuss the need for a DA educational reform and community social reorganization that are beneficial for rapid and impactful research and development contributions.","","Electronic:978-1-4673-8388-2; POD:978-1-4673-8109-3; USB:978-1-4673-8389-9","10.1109/ICCAD.2015.7372580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372580","design automation;engineering;machine learning;science;statistics","Companies;Computer science;Design automation;Industries;Integrated circuits;Optimization;Security","electronic design automation","DA domains;DA educational reform;analysis flows;community social reorganization;design automation;economic domains;historical moment;impactful research;lucrative application areas;technological trends","","2","","20","","","2-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Hybrid Swarm Based Method for Link Prediction in Social Networks","S. Aouay; S. Jamoussi; F. Gargouri","Multimedia Inf. Syst. & Adv. Comput. Lab., Higher Inst. of Comput. Sci. & Multimedia, Sfax, Tunisia","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","974","981","Understanding the evolution of dynamic network structures is an emerging and very interesting topic, which is motivated by several real applications in many scientific fields. In this article, we discuss the link prediction problem, which is one of the key issues in the analysis of social evolving networks. We propose a new hybrid approach to predict the connections in social networks. The approach is inspired from the particle swarm algorithm and is combined with supervised machine learning strategy into a hybrid system. The paper includes an experimental study using real world data sets to compare the proposed methods against other approaches. The obtained results show good performance and prove the effectiveness of the proposed method.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372237","Link predi ction;Particle Swarm Optimization;Social Networks;Supervised machine learning","Artificial intelligence;Conferences","learning (artificial intelligence);particle swarm optimisation;social networking (online)","hybrid swarm based method;hybrid system;link prediction problem;particle swarm algorithm;social network link prediction;supervised machine learning","","","","23","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Anticipation of winning probability in poker using data mining","G. Ambekar; T. Chikane; S. Sheth; A. Sable; K. Ghag","Department of Information Technology, Shah and Anchor Kutchhi Engineering College, Mumbai, India","2015 International Conference on Computer, Communication and Control (IC4)","20160111","2015","","","1","6","Poker is one of the world's most popular and widely played card games. In Poker, there is a fixed set of winning conditions and the player with the highest winning condition wins the game. The main part of the game is to bet strategically and in a calculated manner so that there is less chance of risk and the opponents are not able to guess the cards in the hand. To help players understand when and how to bet smartly, this application will be developed. This system provides knowledge to the users about their probability of winning based on the cards available to them. The system which has been developed is lightweight and easy-to-use so that all types of players can use it. The aim of this system is to help gamblers bet better thereby increasing their winnings, addiction to Poker gambling and also generate greater revenue collections for gaming consortiums. The most important point of this paper is to show how we have used data mining and statistical probabilities to formulate an algorithm which gives out correct predictions of the winning hand. We formally define the system and outline the challenges that arose while developing technology to support it. We hope that this paper will encourage more research by the gaming consortiums and the gambling community in this exciting area of winning by probability calculations and card counting.","","Electronic:978-1-4799-8164-9; POD:978-1-4799-8165-6","10.1109/IC4.2015.7375593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375593","Data mining;Machine learning;Naive Bayes algorithm;Poker;Winning Probability","","computer games;data mining;probability;statistical analysis","Poker gambling;card counting;data mining;gambling community;gaming consortium;statistical probability;winning probability","","","","9","","","10-12 Sept. 2015","","IEEE","IEEE Conference Publications"
"SMS spam detection for Indian messages","S. Agarwal; S. Kaur; S. Garhwal","Department of Computer Science, Thapar University, Patiala, India","2015 1st International Conference on Next Generation Computing Technologies (NGCT)","20160111","2015","","","634","638","The growth of the mobile phone users has led to a dramatic increase in SMS spam messages. Though in most parts of the world, mobile messaging channel is currently regarded as “clean” and trusted, on the contrast recent reports clearly indicate that the volume of mobile phone spam is dramatically increasing year by year. It is an evolving setback especially in the Middle East and Asia. SMS spam filtering is a comparatively recent errand to deal such a problem. It inherits many concerns and quick fixes from Email spam filtering. However it fronts its own certain issues and problems. This paper inspires to work on the task of filtering mobile messages as Ham or Spam for the Indian Users by adding Indian messages to the worldwide available SMS dataset. The paper analyses different machine learning classifiers on large corpus of SMS messages for Indian people.","","DVD:978-1-4673-6807-0; Electronic:978-1-4673-6809-4; POD:978-1-4673-6810-0","10.1109/NGCT.2015.7375198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375198","Mobile Phone Spam;SMS Spam;Spam Filtering;Supervised machine learning;Text classification","Algorithm design and analysis;Electronic mail;Filtering;Machine learning algorithms;Measurement;Mobile communication;Mobile handsets","electronic messaging;learning (artificial intelligence);mobile computing;mobile handsets;text analysis;trusted computing;unsolicited e-mail","Asia;Email spam filtering;Indian messages;Indian users;Middle East;SMS spam detection;SMS spam filtering;SMS spam messages;machine learning classifiers;mobile message filtering;mobile messaging channel;mobile phone spam;mobile phone users","","","","14","","","4-5 Sept. 2015","","IEEE","IEEE Conference Publications"
"Large-scale learning with AdaGrad on Spark","A. T. Hadgu; A. Nigam; E. Diaz-Aviles","L3S Research Center, Hannover, Germany","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2828","2830","Stochastic Gradient Descent (SGD) is a simple yet very efficient online learning algorithm for optimizing convex (and often non-convex) functions and one of the most popular stochastic optimization methods in machine learning today. One drawback of SGD is that it is sensitive to the learning rate hyper-parameter. The Adaptive Sub-gradient Descent, AdaGrad, dynamically incorporates knowledge of the geometry of the data observed in earlier iterations to calculate a different learning rate for every feature. In this work, we implement a distributed version of AdaGrad for large-scale machine learning tasks using Apache Spark. Apache Spark is a fast cluster computing engine that provides similar scalability and fault tolerance properties to MapReduce, but in contrast to Hadoop's two-stage disk-based MapReduce paradigm, Spark's multi-stage in-memory primitives allow user programs to load data into a cluster's memory and query it repeatedly, which makes it ideal for building scalable machine learning applications. We empirically evaluate our implementation on large-scale real-world problems in the machine learning canonical tasks of classification and regression. Comparing our implementation of AdaGrad with the SGD scheduler currently available in Spark's Machine Learning Library (MLlib), we experimentally show that AdaGrad saves time by avoiding manually setting a learning-rate hyperparameter, converges fast and can even achieve better generalization errors.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364091","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364091","Adaptive gradient;Distributed machine learning;Spark","Aggregates;History;Sparks;Standards;Stochastic processes;Support vector machines;Training","convex programming;data handling;fault tolerant computing;geometry;gradient methods;learning (artificial intelligence);parallel processing;stochastic programming;user interfaces","AdaGrad;Apache Spark;Hadoop;MLlib;SGD;cluster computing engine;convex functions;disk-based MapReduce paradigm;fault tolerance properties;geometry;large-scale learning;machine learning library;online learning algorithm;stochastic gradient descent;stochastic optimization;user programs","","","","7","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"SAFS3 algorithm: Frequency statistic and semantic similarity based semantic classification use case","N. H. N. D. de Silva","Department of Computer Science & Engineering, University of Moratuwa, Sri Lanka","2015 Fifteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20160111","2015","","","77","83","Sentiment analysis on movie reviews is a topic of interest for artists and businessmen alike for the purpose of gauging the reception of an artwork or to understand the trends in the market for the benefit of future productions. In this study we introduce an algorithm (SAFS3) to classify documents into multiple classes. This paper then evaluates the SAFS3 algorithm through the use case of analysing a set of reviews from Rotten Tomatoes. Thenovel algorithm results in an accuracy of 53.6%. SAFS3 algorithm outperforms the benchmark for this context as well as the set of generic machine learning algorithms commonly used for tasks of this nature.","","CD-ROM:978-1-4673-9439-0; Electronic:978-1-4673-9441-3; POD:978-1-4673-9442-0","10.1109/ICTER.2015.7377670","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377670","Classification;Sentiment Analysis;TF-IDF;machine learning;semantic similarity","Lead;Licenses;Marine vehicles;Media;Motion pictures","classification;document handling;entertainment;learning (artificial intelligence)","Rotten Tomatoes;SAFS3 algorithm;classify document;frequency statistic similarity;generic machine learning algorithm;movie review;semantic similarity based semantic classification use case;sentiment analysis","","","","34","","","24-26 Aug. 2015","","IEEE","IEEE Conference Publications"
"A Large-Area Image Sensing and Detection System Based on Embedded Thin-Film Classifiers","W. Rieutort-Louis; T. Moy; Z. Wang; S. Wagner; J. C. Sturm; N. Verma","Department of Electrical Engineering, Princeton University, Princeton, NJ, USA","IEEE Journal of Solid-State Circuits","20151230","2016","51","1","281","290","This paper presents a large-area image sensing and detection system that integrates, on glass, sensors and thin-film transistor (TFT) circuits for classifying images from sensor data. Large-area electronics (LAE) enables the formation of millions of sensors spanning physically large areas; however, to perform processing functions, thousands of sensor signals must be interfaced to CMOS ICs, posing a critical limitation to system scalability. This work presents an approach whereby image detection of shapes is performed using simple circuits in the LAE domain based on amorphous silicon (a-Si) TFTs. This reduces the interfaces to the CMOS domain. The limited computational capability of TFT circuits as well as high variability and high density of process defects affecting TFTs and sensors is overcome using a machine-learning algorithm known as error-adaptive classifier boosting (EACB) to form embedded weak classifiers. Through EACB, we show that high-dimensional sensor data from a-Si photoconductors can be reduced to a small number of weak-classifier decisions, which can then be combined in CMOS to achieve strong-classifier performance. For demonstration, a system classifying five shapes achieves performance of >85%/>95% [true-positive (tp)/true-negative (tn) rates] [near the level of an ideal software-implemented support vector machine (SVM) classifier], while the total number of signals from 36 sensors in the LAE domain is reduced by $3.5text{-}9times$.","0018-9200;00189200","","10.1109/JSSC.2015.2489842","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321003","Amorphous silicon (a-Si);boosting;classification;image detection;machine learning;sensing;thin film;thin-film transistor (TFT);variability","CMOS integrated circuits;Data models;Sensor systems;Shape;Thin film transistors;Training","CMOS image sensors;amorphous semiconductors;elemental semiconductors;image classification;learning (artificial intelligence);object detection;silicon;thin film circuits;thin film sensors;thin film transistors;transistor circuits","CMOS ICs;EACB;SVM classifier;Si;TFT circuits;amorphous silicon TFTs;embedded thin-film classifiers;error-adaptive classifier boosting;high-dimensional sensor data;image classification;large-area electronics;large-area image sensing and detection system;machine-learning algorithm;photoconductors;shape image detection;software-implemented support vector machine;thin-film transistor circuits","","2","","17","","20151105","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Authorship Analysis on Dark Marketplace Forums","M. Spitters; F. Klaver; G. Koot; M. v. Staalduinen","TNO, The Hague, Netherlands","2015 European Intelligence and Security Informatics Conference","20160114","2015","","","1","8","Anonymity networks like Tor harbor many underground markets and discussion forums dedicated to the trade of illegal goods and services. As they are gaining in popularity, the analysis of their content and users is becoming increasingly urgent for many different parties, ranging from law enforcement and security agencies to financial institutions. A major issue in cyber forensics is that anonymization techniques like Tor's onion routing have made it very difficult to trace the identities of suspects. In this paper we propose classification set-ups for two tasks related to user identification, namely alias classification and authorship attribution. We apply our techniques to data from a Tor discussion forum mainly dedicated to drug trafficking, and show that for both tasks we achieve high accuracy using a combination of character-level n-grams, stylometric features and timestamp features of the user posts.","","CD-ROM:978-1-4799-8651-4; Electronic:978-1-4799-8657-6; POD:978-1-4799-8658-3","10.1109/EISIC.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379716","alias detection;author attribution;authorship analysis;dark web;machine learning;stylometric analysis;text mining","Discussion forums;Distance measurement;Drugs;Message systems;Roads;Security;Writing","law;marketing;security of data;stock markets","Tor harbor;Tor onion routing;anonymity networks;authorship analysis;dark marketplace forums;financial institutions;illegal goods;illegal services;law enforcement;security agencies;underground markets","","","","32","","","7-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"Energy-efficient acceleration of big data analytics applications using FPGAs","K. Neshatpour; M. Malik; M. A. Ghodrat; A. Sasan; H. Homayoun","Department of Electrical and Computer Engineering, George Mason University","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","115","123","A recent trend for big data analytics is to provide heterogeneous architectures to allow support for hardware specialization. Considering the time dedicated to create such hardware implementations, an analysis that estimates how much benefit we gain in terms of speed and energy efficiency, through offloading various functions to hardware would be necessary. This work analyzes data mining and machine learning algorithms, which are utilized extensively in big data applications in a heterogeneous CPU+FPGA platform. We select and offload the computational intensive kernels to the hardware accelerator to achieve the highest speed-up and best energy-efficiency. We use the latest Xilinx Zynq boards for implementation and result analysis. We also perform a first order comprehensive analysis of communication and computation overheads to understand how the speedup of each application contributes to its overall execution in an end-to-end Hadoop MapReduce environment. Moreover, we study how other system parameters such as the choice of CPU (big vs little) and the number of mapper slots affect the performance and power-efficiency benefits of hardware acceleration. The results show that a kernel speedup of upto χ 321.5 with hardware+software co-design can be achieved. This results in χ2.72 speedup, 2.13χ power reduction, and 15.21χ energy efficiency improvement (EDP) in an end-to-end Hadoop MapReduce environment.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363748","FPGA;Hadoop;MapReduce;Zynq boards;hardware+software co-design;machine learning","Acceleration;Big data;Field programmable gate arrays;Hardware;Kernel;Servers;Support vector machines","Big Data;data mining;field programmable gate arrays;hardware-software codesign;learning (artificial intelligence);microprocessor chips;parallel processing;performance evaluation","Big Data analytics;CPU;EDP;Xilinx Zynq boards;communication overhead;computation overhead;computational intensive kernels;data mining;end-to-end Hadoop MapReduce environment;energy efficiency improvement;energy-efficient acceleration;hardware acceleration;hardware specialization;hardware-plus-software co-design;heterogeneous CPU-plus-FPGA platform;heterogeneous architectures;machine learning;mapper slots;performance analysis;power reduction;power-efficiency","","6","","25","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"A Scalable Geospatial Web Service for Near Real-Time, High-Resolution Land Cover Mapping","K. Karantzalos; D. Bliziotis; A. Karmas","Remote Sensing Laboratory, National Technical University of Athens, Athens, Greece","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20160108","2015","8","10","4665","4674","A land cover classification service is introduced toward addressing current challenges on the handling and online processing of big remote sensing data. The geospatial web service has been designed, developed, and evaluated toward the efficient and automated classification of satellite imagery and the production of high-resolution land cover maps. The core of our platform consists of the Rasdaman array database management system for raster data storage and the open geospatial consortium web coverage processing service for data querying. Currently, the system is fully covering Greece with Landsat 8 multispectral imagery, from the beginning of its operational orbit. Datasets are stored and preprocessed automatically. A two-stage automated classification procedure was developed which is based on a statistical learning model and a multiclass support vector machine classifier, integrating advanced remote sensing and computer vision tools like Orfeo Toolbox and OpenCV. The framework has been trained to classify pansharpened images at 15-m ground resolution toward the initial detection of 31 spectral classes. The final product of our system is delivering, after a postclassification and merging procedure, multitemporal land cover maps with 10 land cover classes. The performed intensive quantitative evaluation has indicated an overall classification accuracy above 80%. The system in its current alpha release, once receiving a request from the client, can process and deliver land cover maps, for a 500-$text{km}^2$ region, in about 20 s, allowing near real-time applications.","1939-1404;19391404","","10.1109/JSTARS.2015.2461556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7247654","Automation;classification;earth observation (EO);land cover;land use;machine learning;multispectral","Automation;Geospatial analysis;Image classification;Machine learning;Multispectral imaging;Remote sensing;Web services","geophysics computing;land cover;remote sensing","Greece;Landsat 8 multispectral imagery;OpenCV;Orfeo Toolbox;Rasdaman array database management system;high-resolution land cover mapping;land cover classification service;multiclass support vector machine classifier;open geospatial consortium web coverage processing service;remote sensing data;scalable geospatial web service","","3","","44","","20150909","Oct. 2015","","IEEE","IEEE Journals & Magazines"
"Temporal pattern recognition for gait analysis applications using an ""intelligent carpet"" system","O. Costilla-Reyes; P. Scully; K. B. Ozanyan","School of Electrical and Electronic Engineering and Photon Science Institute, The University of Manchester, Manchester M13 9PL, United Kingdom","2015 IEEE SENSORS","20160107","2015","","","1","4","We report on the demonstration of a novel floor sensor system for gait analysis in the time domain. The ability of the system to detect changes in gait was evaluated using pattern recognition techniques. The selected machine learning models successfully classified 10 different walking manners performed on the floor sensor system. Their range was defined in terms of the amplitude, frequency and type of the temporal signal. Between three and five consecutive footsteps were captured per gait experiment. For the data analysis five machine learning time series features were engineered for assessment of 12 machine learning models. The tested machine learning models includes linear, non-linear and ensemble methods. The top F-score performance obtained was 88% using a finely tuned Random Forest model. We conclude that pattern recognition in gait activities monitored by the floor sensor system is suitable for gait analysis applications, ranging from biometrics to healthcare.","","Electronic:978-1-4799-8203-5; POD:978-1-4799-8204-2","10.1109/ICSENS.2015.7370174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7370174","floor sensor system;gait analysis;machine learning;pattern recognition;temporal analysis;time series classification","Foot;Legged locomotion;Optical fibers;Pattern recognition;Sensor systems;Supervised learning;Time-domain analysis","carpets;gait analysis;learning (artificial intelligence);pattern recognition","finely tuned random forest model;floor sensor system;gait analysis;intelligent carpet system;machine learning models;temporal pattern recognition;time domain","","1","","14","","","1-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"A text classification algorithm based on quantum information","Songtao Shang; Minyong Shi; Wenqian Shang; Zhiguo Hong","Sch. of Comput. Sci., Commun. Univ. of China, Beijing, China","2015 11th International Conference on Natural Computation (ICNC)","20160111","2015","","","381","384","Text classification is one of key problems in pattern recognition. The KNN algorithm is a widely used text classification algorithm, because it is simple, valid and non-parameters. The main idea of KNN algorithm is to calculate the similarity between the new sample with unknown class label and the training samples, and choosing the class label of the highest k nearest neighbors as the new sample's class label. However, the text contains hundreds and thousands of features. The similarity computing in large numbers of vector will cost many time. In fact that, many machine learning algorithms are unable to manipulate and compute large number of vectors in high-dimensional space. Quantum computing algorithms are good at computing high-dimensional vectors in large tensor product spaces. It can provide exponential speed-up over its classical counterparts. The N-dimensional quantum vectors represent 2N quantum superposition states. The similarity computing on the N-dimensional vectors is also on the 2N quantum superposition states simultaneously. Therefore, this paper introduces a KNN algorithms based on quantum computing, which uses fidelity to compute the similarity between two quantum states. The Control-Swap Test gate is very convenient as a fidelity estimator.","","CD-ROM:978-1-4673-7678-5; Electronic:978-1-4673-7679-2; POD:978-1-4673-7680-8","10.1109/ICNC.2015.7378020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378020","KNN;machine learning;quantum information;text classification","Classification algorithms;Logic gates;Machine learning algorithms;Quantum computing;Registers;Text categorization;Training","matrix multiplication;pattern classification;quantum computing;tensors;text analysis","KNN algorithm;N-dimensional quantum vectors;class label;control-swap test gate;fidelity estimator;high-dimensional vectors;k-nearest neighbors;pattern recognition;quantum computing algorithm;quantum information;quantum superposition states;similarity computing;tensor product space;text classification algorithm","","","","14","","","15-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"Development of Web System to Find Control Rules from Environmental Data on Farmland","Y. Yamasaki; K. Matsumoto; Y. Yamashita; N. Horibe; S. I. Aoqui","Fac. of Comput. & Inf. Sci., Sojo Univ., Kumamoto, Japan","2015 IIAI 4th International Congress on Advanced Applied Informatics","20160107","2015","","","659","662","In Japanese agriculture, skills of cultivations are losing by decreasing of population of farmers. To solve this problem, it is necessary to realize the system to inherit the farmer's skills. The purpose of our research is to build a system which can be used to store skillful farmer's actions and environmental changes. We develop a function for analyzing agricultural environment from the latest environmental data on farmland. We show that the system can support to analyze each attributes of environmental data. We execute a cultivation experiment in greenhouses, and apply the collected data to a learning algorithm.","","Electronic:978-1-4799-9958-3; POD:978-1-4799-9959-0","10.1109/IIAI-AAI.2015.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373987","Data analysis;ICT on agriculture;Machine learning;Web system","Agriculture;Data mining;Sociology;Statistics;Temperature distribution;Temperature sensors","Internet;data analysis;environmental factors;farming;learning (artificial intelligence)","Japanese agriculture;Web system development;agricultural environment analysis;cultivation;environmental data analysis;farmland;greenhouses;learning algorithm","","","","5","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"An interactive learning framework for scalable classification of pathology images","M. Nalisnik; D. A. Gutman; J. Kong; L. A. D. Cooper","Department of Computer Science and Mathematics, Emory University, Emory University School of Medicine, Atlanta, GA 30322","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","928","935","Recent advances in microscopy imaging and genomics have created an explosion of patient data in the pathology domain. Whole-slide images (WSIs) of tissues can now capture disease processes as they unfold in high resolution, recording the visual cues that have been the basis of pathologic diagnosis for over a century. Each WSI contains billions of pixels and up to a million or more microanatomic objects whose appearances hold important prognostic information. Computational image analysis enables the mining of massive WSI datasets to extract quantitative morphologic features describing the visual qualities of patient tissues. When combined with genomic and clinical variables, this quantitative information provides scientists and clinicians with insights into disease biology and patient outcomes. To facilitate interaction with this rich resource, we have developed a web-based machine-learning framework that enables users to rapidly build classifiers using an intuitive active learning process that minimizes data labeling effort. In this paper we describe the architecture and design of this system, and demonstrate its effectiveness through quantification of glioma brain tumors.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363841","biomedical image processing;interactive systems;machine learning;pathology","Algorithm design and analysis;Cancer;Data visualization;Image analysis;Microscopy;Pathology;Training","diseases;genomics;image classification;learning (artificial intelligence);medical image processing;tumours","Web-based machine-learning;disease;genomics;glioma brain tumor;interactive learning framework;intuitive active learning process;microanatomic object;microscopy imaging;pathologic diagnosis;pathology image;patient tissues;prognostic information;quantitative morphologic feature;scalable classification;whole-slide image","","","","22","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Rankboost-Based Result Merging","B. Ghansah; S. Wu; N. Ghansah","Sch. of Comput. Sci. & Telecommun. Eng., Jiangsu Univ., Zhenjiang, China","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","907","914","The explosion of searchable text content especially on the web has rendered information to be distributed among many disjoint text information sources (Federated Search). How to merge the results returned by selected sources is a major problem of the Federated Search task. We study the problem of learning to rank a set of objects by combining various sources of ranking. The problem of merging search results arises in several domains, for example combining the results of different verticals and also Meta search applications. This paper presents a supervised learning solution to the result merging problem. Our approach combines multiple sources of evidence to inform the merging decision. We use the Rankboost Method, a boosting approach to machine learning which learns a function that merges results based on information that is readily available: i.e. the ranks, titles, summaries, URLs and click-through data, which are found in the results pages. We combine these evidences by treating result merging as a multiclass machine learning problem. By not downloading additional information such as the full document, we decrease processing cost in terms of bandwidth usage and latency. We compare our results against existing result merging methods which rely on evidence found only in ranked lists, Semi-Supervised Learning (SSL), Sample-Agglomerate Fitting Estimate (SAFE) and CORI. An extensive set of experiments demonstrates that our method is more effective than the baseline result-merging algorithm under a variety of conditions.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363176","Distributed Information retrieval;Information Retrieval;Machine learning;Result merging;rankboost","Classification algorithms;Feature extraction;Merging;Metasearch;Training;Training data","information retrieval;learning (artificial intelligence);merging;search engines;text analysis","Federated Search task;Rankboost-based search result merging;URL;bandwidth usage;click-through data;disjoint text information sources;latency;merging decision;meta search application;multiclass machine learning problem;object rank learning;ranking sources;ranks;searchable text content;summaries;supervised learning;titles","","","","39","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Feature Selection for SUNNY: A Study on the Algorithm Selection Library","R. Amadini; F. Biselli; M. Gabbrielli; T. Liu; J. Mauro","Dept. of Comput. Sci. & Eng., Univ. of Bologna, Bologna, Italy","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","25","32","Given a collection of algorithms, the Algorithm Selection (AS) problem consists in identifying which of them is the best one for solving a given problem. The selection depends on a set of numerical features that characterize the problem to solve. In this paper we show the impact of feature selection techniques on the performance of the SUNNY algorithm selector, taking as reference the benchmarks of the AS library (ASlib). Results indicate that a handful of features is enough to reach similar, if not better, performance of the original SUNNY approach that uses all the available features. We also present sunny-as: a tool for using SUNNY on a generic ASlib scenario.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372114","Algorithm Portfolio;Algorithm Selection;Feature Selection;Machine Learning","Feature extraction;Libraries;Portfolios;Prediction algorithms;Runtime;Software algorithms;Training","constraint handling;optimisation","AS library;SUNNY algorithm selector;algorithm selection library;feature selection techniques;generic ASlib scenario;sunny-as","","","","36","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"An L1-Regression Random Forests Method for Forecasting of Hoa Binh Reservoir's Incoming Flow","T. T. Nguyen","Fac. of Comput. Sci. & Eng., Thuyloi Univ., Hanoi, Vietnam","2015 Seventh International Conference on Knowledge and Systems Engineering (KSE)","20160107","2015","","","360","364","Random Forests (RF) method has been widely used as a powerful ensemble learning tool for forecasting problems. RF uses the least squares criteria to search the best split when growing trees and takes the mean over all trees to aggregate the final forecast. The performance may not be accurate when applied to data set with respect to the presence of outliers and skewed distributions. In this paper, we proposed to use the l1-norm as the splitting rule for growing trees and take the median to obtain the forecast values in the forest. The proposed RF is applied to forecast the incoming flow of Hoa Binh's reservoir for 10 lead days. Experimental result showed that the proposed RF outperforms other state-of-the-art methods in reducing of RMSE measure, the proposed approach provides an useful and feasible method for forecasting the incoming flow problem.","","Electronic:978-1-4673-8013-3; POD:978-1-4673-8014-0","10.1109/KSE.2015.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371813","Data mining;Forecasting Incoming Flow;Machine learning;Random Forests","Bagging;Forecasting;Mathematical model;Predictive models;Radio frequency;Vegetation;Yttrium","geophysics computing;learning (artificial intelligence);least mean squares methods;regression analysis;reservoirs;trees (mathematics)","Hoa Binh reservoir incoming flow;RF;RMSE measure;ensemble learning tool;forecasting problems;growing trees;incoming flow problem;l<sub>1</sub>-regression random forests method;least squares criteria;skewed distributions","","","","20","","","8-10 Oct. 2015","","IEEE","IEEE Conference Publications"
"Reliable navigation-path extraction system for an autonomous mobile vehicle","E. Coronel; A. Pojomovsky; F. Gaona","Research Group in Electronics and Mechatronics, Polytechnic School, National University of Asunci&#243;n, Paraguay","2015 Tenth International Conference on Digital Information Management (ICDIM)","20160114","2015","","","175","181","This paper describes the algorithms for path recognition and obstacle detection for an autonomous mobile vehicle. The Path Extraction Algorithm (PEA) recognizes drivable paths on the road by image processing. The Environment Extraction Algorithm (EEA) provides the spacial pose of the mobile vehicle and obstacle detection by the data processing of the 2D laser scanner. The Pattern Classification Algorithm (PCA), a machine learning process based on the supervised method, enables to classify road patterns by the use of trained Artificial Neural Networks. The Navigation-Path Extraction Algorithm (NPEA) is comprised of these three sub-systems. Our test results demonstrate that the Navigation-Path Extraction System (NPES) is reliable and robust to be implementable on a mobile vehicle to achieve self-driving.","","Electronic:978-1-4673-9152-8; POD:978-1-4673-9153-5","10.1109/ICDIM.2015.7381882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381882","2D Laser Scanner;Artificial Neural Networks;Environment Extraction;Image Processing;Machine Learning;Obstacle Detection;Path Extraction;Path Recognition;Self-Driving","Image segmentation;Lead;MATLAB;Mechatronics;Navigation;Reliability;Roads","image classification;learning (artificial intelligence);neural nets;object detection;optical scanners;road vehicles","2D laser scanner;PCA;autonomous mobile vehicle;data processing;environment extraction algorithm;image processing;machine learning process;obstacle detection;path recognition;pattern classification algorithm;reliable navigation-path extraction algorithm;reliable navigation-path extraction system;road pattern classification;supervised method;trained artificial neural networks","","","","21","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Mitigating effects of non-ideal synaptic device characteristics for on-chip learning","P. Y. Chen; B. Lin; I. T. Wang; T. H. Hou; J. Ye; S. Vrudhula; J. s. Seo; Y. Cao; S. Yu","Arizona State University, Tempe, 85281, US","2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","20160107","2015","","","194","199","The cross-point array architecture with resistive synaptic devices has been proposed for on-chip implementation of weighted sum and weight update in the training process of learning algorithms. However, the non-ideal properties of the synaptic devices available today, such as the nonlinearity in weight update, limited ON/OFF range and device variations, can potentially hamper the learning accuracy. This paper focuses on the impact of these realistic properties on the learning accuracy and proposes the mitigation strategies. Unsupervised sparse coding is selected as a case study algorithm. With the calibration of the realistic synaptic behavior from the measured experimental data, our study shows that the recognition accuracy of MNIST handwriting digits degrades from ~97 % to ~65 %. To mitigate this accuracy loss, the proposed strategies include 1) the smart programming schemes for achieving linear weight update; 2) a dummy column to eliminate the off-state current; 3) the use of multiple cells for each weight element to alleviate the impact of device variations. With the improved synaptic behavior by these strategies, the accuracy increases back to ~95 %, enabling the reliable integration of realistic synaptic devices in the neuromorphic systems.","","Electronic:978-1-4673-8388-2; POD:978-1-4673-8109-3; USB:978-1-4673-8389-9","10.1109/ICCAD.2015.7372570","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372570","cross-point array;machine learning;neuromorphic computing;resistive memory;synaptic device","Computer architecture;Encoding;Neuromorphics;Support vector machines;System-on-chip;Testing;Training","learning (artificial intelligence);neural nets","cross-point array architecture;handwriting digits;learning algorithms;linear weight update;neuromorphic systems;nonideal synaptic device characteristics;on-chip learning;resistive synaptic devices;smart programming schemes;synaptic behavior;unsupervised sparse coding;weighted sum","","6","","20","","","2-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Cross-Examination for Angle-Closure Glaucoma Feature Detection","S. Issac Niwas; W. Lin; C. K. Kwoh; C. C. J. Kuo; C. C. Sng; M. C. Aquino; P. T. K. Chew","School of Computer Engineering, Nanyang Technological University, Singapore","IEEE Journal of Biomedical and Health Informatics","20151231","2016","20","1","343","354","Effective feature selection plays a vital role in anterior segment imaging for determining the mechanism involved in angle-closure glaucoma (ACG) diagnosis. This research focuses on the use of redundant features for complex disease diagnosis such as ACG using anterior segment optical coherence tomography images. Both supervised [minimum redundancy maximum relevance (MRMR)] and unsupervised [Laplacian score (L-score)] feature selection algorithms have been cross-examined with different ACG mechanisms. An AdaBoost machine learning classifier is then used for classifying the five various classes of ACG mechanism such as iris roll, lens, pupil block, plateau iris, and no mechanism using both feature selection methods. The overall accuracy has shown that the usefulness of redundant features by L-score method in improved ACG diagnosis compared to minimum redundant features by MRMR method.","2168-2194;21682194","","10.1109/JBHI.2014.2387207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000992","Angle-closure glaucoma;Angle-closure glaucoma (ACG);Laplacian score (L-score);anterior segment optical coherence tomography;anterior segment optical coherence tomography (AS-OCT);laplacian score;machine learning classifier;minimum redundancy maximum relevance;minimum redundancy maximum relevance (MRMR);redundant features;unsupervised feature selection","Accuracy;Classification algorithms;Feature extraction;Iris;Lenses;Machine learning algorithms;Mutual information","biomedical optical imaging;diseases;eye;feature extraction;feature selection;image classification;medical image processing;optical tomography","ACG diagnosis;ACG mechanism;AdaBoost machine learning classifier;L-score method;Laplacian score feature selection algorithm;MRMR method;angle-closure glaucoma diagnosis;angle-closure glaucoma feature detection;anterior segment optical coherence tomography images;disease diagnosis;feature selection methods;iris roll;lens;minimum redundancy maximum relevance feature selection algorithm;plateau iris;pupil block;unsupervised feature selection algorithm","0","3","","29","","20150101","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Prediction of diabetes based on personal lifestyle indicators","A. Anand; D. Shakti","Centre of Information Technology, University of Petroleum & Energy Studies, Dehradun, India","2015 1st International Conference on Next Generation Computing Technologies (NGCT)","20160111","2015","","","673","676","Diabetes Mellitus or Diabetes has been portrayed as worse than Cancer and HIV (Human Immunodeficiency Virus). It develops when there are high blood sugar levels over a prolonged period. Recently, it has been quoted as a risk factor for developing Alzheimer, and a leading cause for blindness & kidney failure. Prevention of the disease is a hot topic for research in the healthcare community. Many techniques have been discovered to find the causes of diabetes and cure it. This research paper is a discussion on establishing a relationship between diabetes risk likely to be developed from a person's daily lifestyle activities such as his/her eating habits, sleeping habits, physical activity along with other indicators like BMI (Body Mass Index), waist circumference etc. Initially, a Chi-Squared Test of Independence was performed followed by application of the CART (Classification and Regression Trees) machine learning algorithm on the data and finally using Cross-Validation, the bias in the results was removed.","","DVD:978-1-4673-6807-0; Electronic:978-1-4673-6809-4; POD:978-1-4673-6810-0","10.1109/NGCT.2015.7375206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375206","Cross-Validation;Decision Trees;Diabetes;Machine Learning;Prediction Model","Data visualization;Diabetes;Diseases;Insulin;Next generation networking;Predictive models","data analysis;diseases;health care;learning (artificial intelligence);medical diagnostic computing","Alzheimer;CART machine learning algorithm;blindness;blood sugar levels;chi-squared independence test;classification and regression trees;daily lifestyle activities;data analysis;diabetes mellitus prediction;disease prevention;healthcare;kidney failure;personal lifestyle indicators","","","","11","","","4-5 Sept. 2015","","IEEE","IEEE Conference Publications"
"Block-Row Sparse Multiview Multilabel Learning for Image Classification","X. Zhu; X. Li; S. Zhang","School of Mathematics and Statistics, Xi&#8217;an Jiaotong University, Xi&#x2019;an, China","IEEE Transactions on Cybernetics","20160114","2016","46","2","450","461","In image analysis, the images are often represented by multiple visual features (also known as multiview features), that aim to better interpret them for achieving remarkable performance of the learning. Since the processes of feature extraction on each view are separated, the multiple visual features of images may include overlap, noise, and redundancy. Thus, learning with all the derived views of the data could decrease the effectiveness. To address this, this paper simultaneously conducts a hierarchical feature selection and a multiview multilabel (MVML) learning for multiview image classification, via embedding a proposed a new block-row regularizer into the MVML framework. The block-row regularizer concatenating a Frobenius norm (F-norm) regularizer and an l<sub>2,1</sub>-norm regularizer is designed to conduct a hierarchical feature selection, in which the F-norm regularizer is used to conduct a high-level feature selection for selecting the informative views (i.e., discarding the uninformative views) and the 12,1-norm regularizer is then used to conduct a low-level feature selection on the informative views. The rationale of the use of a block-row regularizer is to avoid the issue of the over-fitting (via the block-row regularizer), to remove redundant views and to preserve the natural group structures of data (via the F-norm regularizer), and to remove noisy features (the 12,1-norm regularizer), respectively. We further devise a computationally efficient algorithm to optimize the derived objective function and also theoretically prove the convergence of the proposed optimization method. Finally, the results on real image datasets show that the proposed method outperforms two baseline algorithms and three state-of-the-art algorithms in terms of classification performance.","2168-2267;21682267","","10.1109/TCYB.2015.2403356","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051274","Feature selection;image classification;joint sparse learning;machine learning;multiview learning","Joints;Learning systems;Linear programming;Noise measurement;Optimization;Transforms;Visualization","feature selection;image classification;image representation;learning (artificial intelligence)","F-norm regularizer;Frobenius norm regularizer;MVML framework;block-row over-fitting;block-row regularizer;block-row sparse multiview multilabel learning;data structures;feature extraction;hierarchical feature selection;high-level feature selection;image analysis;image representation;informative view selection;l<sub>2,1</sub>-norm regularizer;low-level feature selection;multiview image classification;noisy feature removal;optimization method;real image datasets;redundant views;visual features","","26","","66","","20150227","Feb. 2016","","IEEE","IEEE Journals & Magazines"
"On generative models for sequential formation of clusters","P. M. Djurić; K. Yu","Department of Electrical & Computer Engineering, Stony Brook University, Stony Brook, NY 11794, USA","2015 23rd European Signal Processing Conference (EUSIPCO)","20151228","2015","","","2786","2790","In the literature of machine learning, a class of unsupervised approaches is based on Dirichlet process mixture models. These approaches fall into the category of nonparametric Bayesian methods, and they find a wide range of applications including in biology, computer science, engineering, and finance. An important assumption of the Dirichlet process mixture models is that the data are exchangeable. This is a restriction for many types of data whose structures vary over time or space or some other independent variables. In this paper, we address generative models that remove the restriction of exchangeability of the Dirichlet process model, which allows for creation of mixtures with time-varying structures. We also address how these models can be applied to sequential estimation of clusters.","","Electronic:978-0-9928-6263-3; POD:978-1-4799-8851-8","10.1109/EUSIPCO.2015.7362892","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362892","Chinese restaurant processes with finite capacities;Dirichlet processes;machine learning;time-varying clustering","Bayes methods;Computational modeling;Estimation;Europe;Manganese;Mixture models;Signal processing","Bayes methods;learning (artificial intelligence);mixture models;pattern clustering;signal processing;statistical analysis","Dirichlet process mixture models;biology;clusters sequential formation;computer science;generative models;machine learning;nonparametric Bayesian methods;unsupervised approaches","","","","15","","","Aug. 31 2015-Sept. 4 2015","","IEEE","IEEE Conference Publications"
"Smartphone based fall detection system","S. Madansingh; T. A. Thrasher; C. S. Layne; B. C. Lee","Department of Health and Human Performance, University of Houston, Texas USA","2015 15th International Conference on Control, Automation and Systems (ICCAS)","20151228","2015","","","370","374","This paper describes the design of a smartphone based fall detection system and characterizes the preliminary efficacy of the proposed system in activities of daily living (ADLs). Using the embedded sensors available in a smartphone (i.e., accelerometer, gyroscope and magnetometer), kinematic analysis of movement can be performed in real-time, allowing for continuous monitoring of fall status. Fall sensing thresholds are defined based on angular rate of change (TH1), maximum acceleration (TH2), and maximum attitude change (TH3). TH1 is measured from the resultant pitch and roll angular velocity vector and defined as 3.1 rad/s (~180°/s). TH2 is measured from the resultant acceleration vector and defined as 1.6 g. TH3 is measured from the resultant vector of the pitch and roll angles, and defined at 0.59 rad (39°). A proof-of-concept study was performed on five ADL tasks: 1) comfortable walking, 2) stand-to-seated posture, 3) seated-to-standing posture, 4) pivoting at the waist to pick up an object, and 5) stand-to-seated-to-laying transition. No trials violated the defined thresholds for fall detection, signifying no false positives. These results are important for the definition of machine learning algorithms, currently under development, to minimize false positive and false negative fall detection events.","2093-7121;20937121","Electronic:978-8-9932-1508-3; USB:978-8-9932-1509-0","10.1109/ICCAS.2015.7364941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364941","Activities of daily living;Fall detection;Kinematic analysis;Machine learning;Smartphone","Acceleration;Biomedical monitoring;Lead;Magnetometers;Monitoring;Semiconductor device measurement","geriatrics;intelligent sensors;learning (artificial intelligence);patient monitoring;smart phones","ADL;activities of daily living;angular rate of change;embedded sensors;fall sensing thresholds;fall status continuous monitoring;false negative fall detection events;false positive fall detection events;machine learning algorithms;maximum acceleration;maximum attitude change;movement kinematic analysis;smartphone based fall detection system","","1","","26","","","13-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Optimizing false positive in anomaly based intrusion detection using Genetic algorithm","D. Narsingyani; O. Kale","Department of Computer Engineering, LJIET, Ahmedabad, India","2015 IEEE 3rd International Conference on MOOCs, Innovation and Technology in Education (MITE)","20160111","2015","","","72","77","In recent years, with increasing use of internet the computer systems are facing many number of security issues. Intrusion detection system (IDS) is one of the principal components of any information security system. Identification of anomalous activity in computer network is first step in identifying the threat to information system. Our focus is mainly on Genetic algorithm (GA) based anomaly detection technique, as GA is one of the most effective evolutionary techniques for machine learning. In this paper Genetic algorithm is applied for network intrusion detection. Our approach for optimization specifically focusing on false positive rate. Reduction in false positive rate also improves accuracy and performance. The limitation of other techniques of accuracy, false positive rates has been addressed in this paper. Experimental results show the efficient detection rates based on KDD99cup datasets which is a standard dataset for intrusion detection.","","Electronic:978-1-4673-6747-9; POD:978-1-4673-6748-6; USB:978-1-4673-6746-2","10.1109/MITE.2015.7375291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375291","Anomaly Intrusion Detection;DoS;False Positive;Features Selection;Genetic Algorithms;Machine Learning","Computers;Optimization;Protocols;Technological innovation;Training","Internet;computer network security;genetic algorithms;learning (artificial intelligence);principal component analysis","IDS;Internet;KDD99cup datasets;anomalous activity;anomaly based intrusion detection system;computer network;computer systems;false positive optimization;genetic algorithm based anomaly detection technique;information security system;machine learning;network intrusion detection;principal components","","","","18","","","1-2 Oct. 2015","","IEEE","IEEE Conference Publications"
"Neural Network-Based Model Design for Short-Term Load Forecast in Distribution Systems","N. Ding; C. Benoit; G. Foggia; Y. Bésanger; F. Wurtz","DES-RTE, Versailles Cedex, France","IEEE Transactions on Power Systems","20151221","2016","31","1","72","81","Accurate forecasts of electrical substations are mandatory for the efficiency of the Advanced Distribution Automation functions in distribution systems. The paper describes the design of a class of machine-learning models, namely neural networks, for the load forecasts of medium-voltage/low-voltage substations. We focus on the methodology of neural network model design in order to obtain a model that has the best achievable predictive ability given the available data. Variable selection and model selection are applied to electrical load forecasts to ensure an optimal generalization capacity of the neural network model. Real measurements collected in French distribution systems are used to validate our study. The results show that the neural network-based models outperform the time series models and that the design methodology guarantees the best generalization ability of the neural network model for the load forecasting purpose based on the same data.","0885-8950;08858950","","10.1109/TPWRS.2015.2390132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031444","Model design;machine learning;neural network;short-term load forecast;variable selection;virtual leave-one-out","Computational modeling;Data models;Hidden Markov models;Load forecasting;Load modeling;Predictive models;Training","distribution networks;generalisation (artificial intelligence);learning (artificial intelligence);load forecasting;neural nets;power engineering computing;substation automation;time series","Distribution Au- tomation functions;French distribution system;generalization ability;machine-learning model;medium-voltage-low-voltage substation;model selection;neural network-based model design;optimal generalization capacity;predictive ability;short-term load forecasting;time series model;variable selection","","3","","47","","20150204","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Mobile gesture-based iPhone user authentication","K. Khare; T. S. Moh","Department of Computer Science, San Jose State University, San Jose, CA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1615","1621","Efforts have been made to introduce an extra layer of security on mobile devices, including a good amount of research initiated in the behavioral biometrics domain. However, all prior research approaches for mobile gesture-based authentication has been carried out uni-directionally. Despite of the fact that there are many devices with their own configurations, the study of mobile authentication based on behavioral biometrics has been done only with the Android operating system and devices. In this paper, a novel approach to identifying the owner of a mobile device based on Behavioral Biometrics Mobile Gestures Recognition is presented. This research takes the first step towards implementing behavioral biometrics identification for iOS based iPhone devices. In this research work, it is shown that a user can be identified as the true owner or an imposter of such a device based on the interactive behavior and gestures of the user. In this way continuous identification or authentication of an owner can be done based on the interaction of the user and the device. It is shown that a continuous authentication mechanism can be established using a self-learning model based on machine learning classification approaches such as Random Forests, Gradient Boosting Machine, Deep Learning, and Naive Bayes. The results in this paper show that, with behavioral biometrics, automated user authentication mechanism, EER (Equal Error Rate) can be improved to around 27%, clearly demonstrating that the chances of authenticating the user are good.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363929","Authentication;Behavioral;Biometrics;Gestures;Machine Learning;iOS;iPhone","Authentication;Biometrics (access control);Keyboards;Mobile communication;Mobile handsets;Shape","Android (operating system);behavioural sciences computing;biometrics (access control);gesture recognition;iOS (operating system);learning (artificial intelligence);mobile computing;security of data;smart phones","Android device;Android operating system;EER;behavioral biometrics domain;behavioral biometrics mobile gesture recognition;equal error rate;iOS based iPhone device;machine learning classification approach;mobile device;mobile gesture-based iPhone user authentication","","","","17","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Skin Temperature Prediction in Lower Limb Prostheses","N. Mathur; I. Glesk; A. Buis","Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.","IEEE Journal of Biomedical and Health Informatics","20151231","2016","20","1","158","165","Increased temperature and perspiration within a prosthetic socket is a common complaint of many amputees. The heat dissipation in prosthetic sockets is greatly influenced by the thermal conductive properties of the socket and interface liner materials. These materials influence the body's temperature regulation mechanism and might be the reason for thermal discomfort in prosthetic sockets. Monitoring interface temperature at skin level is notoriously complicated. The problem might be considered notorious because embedding wires and sensors in an elastomer eventually results in elastomer failures because of the high strain induced when donning a liner (amputees roll the liners onto their limbs). Another reason is because placing sensors and wires directly against the skin could cause irritation and chaffing over just a short period of time. We describe a route wherein if the thermal properties of the socket and liner materials are known, the in-socket residual limb temperature could be accurately predicted by monitoring the temperature between socket and liner rather than skin and liner using the Gaussian process technique.","2168-2194;21682194","","10.1109/JBHI.2014.2368774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949596","Gaussian Process for Machine Learning;Gaussian process for machine learning (GPML);Lower Limb Prosthetics;Modeling;Temperature;lower limb prosthetics;modeling;temperature","Legged locomotion;Materials;Prosthetics;Skin;Sockets;Temperature;Training","Gaussian processes;artificial limbs;biomedical measurement;biothermics;patient monitoring;skin;temperature measurement","Gaussian process technique;body temperature regulation mechanism;elastomer;heat dissipation;in-socket residual limb temperature;interface liner material;interface temperature monitoring;liner material temperature monitoring;liner material thermal property;lower limb prosthesis;prosthetic socket;skin temperature prediction;socket temperature monitoring;socket thermal property;thermal discomfort","0","5","","24","","20141107","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Defect Diagnosis via Segment Delay Learning","J. Chung; W. Kang","Department of Electronic Engineering, Incheon National University, Incheon, Korea","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20151224","2016","24","1","388","392","This brief presents a scalable, high-quality delay defect diagnosis method based on segment delay estimation. Several recent studies have assumed that accurate segment delay recovery leads to a better diagnosis method, and they predict segment delays using Gaussian prior distributions on them. We show that the assumption is not necessarily true and propose to rank segments by the probability of the occurrence for the estimated delays. When random localized defects are considered, prior distributions on segment delays can have a long tail, but all the previous studies fail to model this region properly. We propose to modify the standard deviations of the Gaussian priors depending on the defect size. Our experiment shows that one of our methods achieves ~14% first hit rank improvements and 100× speedup on average over a previous method based on linear programming.","1063-8210;10638210","","10.1109/TVLSI.2015.2392092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042341","Defect diagnosis;VLSI testing;VLSI testing.;machine learning;postsilicon debug;postsilicon validation;process variation","Circuit faults;Delay estimation;Logic gates;Runtime;Sensitivity;Very large scale integration","Gaussian distribution;integrated circuit manufacture;learning (artificial intelligence)","Gaussian priors;delay occurrence probability;prior distributions;random localized defects;scalable-high-quality delay defect diagnosis method;segment delay estimation;segment delay learning;segment delay recovery;standard deviations","","0","","12","","20150213","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Remotely inferring device manipulation of industrial control systems via network behavior","G. Lontorfos; K. D. Fairbanks; L. Watkins; W. H. Robinson","Johns Hopkins University, Information Security Institute, USA","2015 IEEE 40th Local Computer Networks Conference Workshops (LCN Workshops)","20151228","2015","","","603","610","This paper presents preliminary findings on a novel method to remotely fingerprint a network of Cyber Physical Systems and demonstrates the ability to remotely infer the functionality of an Industrial Control System device. A monitoring node measures the target device's response to network requests and statistically analyzes the collected data to build and classify a profile of the device's functionality via machine learning. As ICSs are used to control critical infrastructure processes such as power generation and distribution, it is vital to develop methods to detect tampering. A system employing our measurement technique could discover if an insider has made unauthorized changes to a device's logic. Our architecture also has advantages because the monitoring node is separate from the measured device. Our results indicate the ability to accurately infer (i.e., using a tunable threshold value) discrete ranges of task cycle periods (i.e., CPU loads) that could correspond to different functions.","","Electronic:978-1-4673-6773-8; POD:978-1-4673-6774-5","10.1109/LCNW.2015.7365904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7365904","cyber-physical systems;device fingerprinting;machine learning;network traffic analysis;processor workload;security;tampering","Central Processing Unit;Delays;Feature extraction;Fingerprint recognition;Monitoring;Telecommunication traffic;Time factors","learning (artificial intelligence);process control;production engineering computing;statistical analysis","ICSs;critical infrastructure process control;cyber physical systems;industrial control system device;industrial control systems;machine learning;measurement technique;monitoring node;network behavior;power distribution;power generation;profile classification;remote network fingerprinting;remotely inferring device manipulation;statistical analysis;tampering detection","","","","16","","","26-29 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Density-Based Approach for Instance Selection","J. L. Carbonera; M. Abel","Inst. of Inf., Univ. Fed. do Rio Grande do Sul - UFRGS, Porto Alegre, Brazil","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","768","774","Instance selection is an important preprocessing step that can be applied in many machine learning tasks. Due to the increasing of the size of the datasets, techniques for instance selection have been applied for reducing the data to a manageable volume, leading to a reduction of the computational resources that are necessary for performing the learning process. Besides that, algorithms of instance selection can also be applied for removing useless, erroneous or noisy instances, before applying learning algorithms. This step can improve the accuracy in classification problems. In the last years, several approaches for instance selection have been proposed. However, most of them have long runtimes and, due to this, they cannot be used for dealing with large datasets. In this paper, we propose a simple and effective density-based approach for instance selection. Our approach, called LDIS (local density-based instance selection), evaluates the instances of each class separately and keeps only the densest instances in a given (arbitrary) neighborhood. This ensures a reasonably low time complexity. Our approach was evaluated on 15 well-known data sets and its performance was compared with the performance of 5 state-of-the-art algorithms, considering three measures: accuracy, reduction and effectiveness. For evaluating the accuracy achieved using the datasets produced by the algorithms, we applied the KNN algorithm. The results show that LDIS achieves a performance (in terms of balance of accuracy and reduction) that is better or comparable to the performances of the other algorithms considered in the evaluation.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372210","Data mining;Instance reduction;Instance selection;Instance-based learning;Machine learning;dataset reduction","Algorithm design and analysis;Clustering algorithms;Machine learning algorithms;Noise measurement;Runtime;Time complexity;Training","data reduction;learning (artificial intelligence);pattern classification","KNN algorithm;LDIS;classification problems;computational resource reduction;data reduction;density-based approach;erroneous instances;large datasets;local density-based instance selection;machine learning tasks;noisy instances;useless instances","","1","","19","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"An Adaptive Model-Based Mutation Operator for the Wind Farm Layout Optimisation Problem","M. Mayo; M. Daoud","Dept. of Comput. Sci., Univ. of Waikato, Hamilton, New Zealand","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","671","676","A novel mutation operator for the wind farm layout optimisation problem is proposed and tested. When a wind farm layout is simulated, statistics such as an individual turbine's wake free ratio can be computed. These statistics are in addition to the global measure being optimised, for example the overall cost of energy extraction of the farm. We present algorithms that first of all build a predictive model of the wake free ratio across an entire wind farm. This model is then used inside a mutation operator to perturb turbines towards positions of high predicted wake free ratio. We evaluate our approach by comparing a 1+1 Evolutionary Strategy using this new mutation operator vs. The same algorithm with a more standard random mutation operator, and show that our new operator leads to the discovery of wind farm layouts having a statistically significantly lower cost of energy extraction.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379259","cost of energy;evolutionary strategy;machine learning;mutation operator;predictive model;stochastic hill climbing;wake free ratio;wind farm layout optimisation problem","Layout;Optimization;Prediction algorithms;Predictive models;Wind farms;Wind turbines","evolutionary computation;optimisation;turbines;wakes;wind power plants","1+1 evolutionary strategy;adaptive model-based mutation operator;energy extraction;global measure;predictive model;random mutation operator;turbine wake free ratio;wind farm layout optimisation problem","","1","","8","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Triaging Diagnostically Relevant Regions from Pathology Whole Slides of Breast Cancer: A Texture Based Approach","M. Peikari; M. J. Gangeh; J. Zubovits; G. Clarke; A. L. Martel","Medical Biophysics, University of Toronto, Canada","IEEE Transactions on Medical Imaging","20151229","2016","35","1","307","315","Purpose: Pathologists often look at whole slide images (WSIs) at low magnification to find potentially important regions and then zoom in to higher magnification to perform more sophisticated analysis of the tissue structures. Many automated methods of WSI analysis attempt to preprocess the down-sampled image in order to select salient regions which are then further analyzed by a more computationally intensive step at full magnification. Although it can greatly reduce processing times, this process may lead to small potentially important regions being overlooked at low magnification. We propose a texture analysis technique to ease the processing of H&E stained WSIs by triaging clinically important regions. Method: Image patches randomly selected from the whole tissue area were divided into smaller tiles and Gaussian-like texture filters were applied to them. Texture filter responses from each tile were combined together and statistical measures were derived from their histograms of responses. Bag of visual words pipeline was then employed to combine extracted features from tiles to form one histogram of words per every image patch. A support vector machine classifier was trained using the calculated histograms of words to be able to distinguish between clinically relevant and irrelevant patches. Result: Experimental analysis on 5151 image patches from 10 patient cases (65 tissue slides) indicated that our proposed texture technique out-performed two previously proposed colour and intensity based methods with an area under the ROC curve of 0.87. Conclusion: Texture features can be employed to triage clinically important areas within large WSIs.","0278-0062;02780062","","10.1109/TMI.2015.2470529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214290","Bag of visual words;breast cancer;fast <formula formulatype=""inline""><tex Notation=""TeX"">$k$</tex></formula>-means;image analysis;machine learning;pathology;texture","Feature extraction;Histograms;Image color analysis;Pathology;Training;Visualization","biological tissues;cancer;feature extraction;medical image processing;support vector machines","Gaussian-like texture filters;WSI analysis;breast cancer;colour based method;image patches;intensity based method;pathology whole slide image;salient regions;support vector machine classifier;texture analysis technique;texture based approach;tissue structures;visual words pipeline;word histogram","","1","","41","","20150820","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Real-time energy prediction for a milling machine tool using sparse Gaussian process regression","J. Park; K. H. Law; R. Bhinge; M. Chen; D. Dornfeld; S. Rachuri","Civil and Environmental Engineering, Stanford University, Stanford, CA, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1451","1460","This paper describes a real-time data collection framework and an adaptive machining learning method for constructing a real-time energy prediction model for a machine tool. To effectively establish the energy consumption pattern of a machine tool over time, the energy prediction model is continuously updated with new measurement data to account for time-varying effects of the machine tool, such as tool wear and machine tool deterioration. In this work, a real-time data collection and processing framework is developed to retrieve raw data from a milling machine tool and its sensors and convert them into relevant input features. The extracted input features are then used to construct the energy prediction model using Gaussian Process (GP) regression. To update the GP regression model with real-time streaming data, we investigate the use of sparse representation of the covariance matrix to reduce the computational and storage demands of the GP regression. We compare computational efficiency of sparse GP to that of full GP regression model and show the effectiveness of the sparse GP regression model for tracking the variation in the energy consumption pattern of the target machine.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363906","MTConnect;Sparse Gaussian regression;energy prediction model;machine learning;milling machine","Adaptation models;Computational modeling;Data collection;Data models;Energy consumption;Predictive models;Real-time systems","Gaussian processes;covariance matrices;feature extraction;learning (artificial intelligence);machining;milling machines;production engineering computing;regression analysis;wear","GP regression;adaptive machining learning method;covariance matrix;data collection framework;energy consumption pattern;energy prediction model;input feature extraction;machine tool deterioration;measurement data;milling machine tool;real-time energy prediction;sparse Gaussian process regression;sparse representation;tool wear;variation tracking","","1","","17","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Comparison between mixed binary classification and voting technique for active user authentication using mouse dynamics","A. A. Khalifa; M. A. Hassan; T. A. Khalid; H. Hamdoun","Electrical Engineering Department, University of Khartoum, Sudan","2015 International Conference on Computing, Control, Networking, Electronics and Embedded Systems Engineering (ICCNEEE)","20160114","2015","","","281","286","The rapid proliferation of computing processing power has facilitated a rise in the adoption of computers in various aspects of human lives. From education to shopping and other everyday activities to critical applications in finance, banking and, recently, degree awarding online education. Several approaches for user authentication based on Behavioral Biometrics (BB) were suggested in order to identify unique signature/footprint for improved matching accuracy for genuine users and flagging for abnormal behaviors from intruders. In this paper we present a comparison between two classification algorithms for identifying users' behavior using mouse dynamics. The algorithms are based on support vector machines (SVM) classifier allowing for direct comparison between different authentication-based metrics. The voting technique shows low False Acceptance Rate(FAR) and noticeably small learning time; making it more suitable for incorporation within different authentication applications.","","CD-ROM:978-1-4673-7867-3; Electronic:978-1-4673-7869-7; POD:978-1-4673-7870-3","10.1109/ICCNEEE.2015.7381378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381378","active authentication;machine learning;mouse dynamics;pattern recognition;support vector machines","Artificial neural networks;Biometrics (access control)","behavioural sciences computing;government data processing;learning (artificial intelligence);mouse controllers (computers);pattern classification;security of data;support vector machines","FAR;SVM;active user authentication;behavioral biometrics;false acceptance rate;learning time;mixed binary classification;mouse dynamics;support vector machine;voting technique","","","","22","","","7-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"A real time urban flood monitoring system for metro Manila","F. C. C. Garcia; A. E. Retamar; J. C. Javier","Solutions and Services Engineering Division, Advanced Science and Technology Institute, ASTI Bldg., CP Garcia Ave., University of the Philippines Technology Park, Quezon City, Philippines","TENCON 2015 - 2015 IEEE Region 10 Conference","20160107","2015","","","1","5","A real time urban flood monitoring system was deployed into two streets (Earnshaw and San Diego Streets) on España Boulevard, Manila. The system consists of a ground-based pressure sensor and a rain gauge connected to a locally designed data logger with telemetry capabilites using GPRS network. Data from the stations are received by a TCP server and is processed in order to provide visual information and realtime flood updates through mobile and web services. An ahead of time flood estimation system was implemented using a Random Forest algorithm in order to provide an early warning advisory to motorist and users of the system. Results from the test validation show that the resulting prediction model indicates a strong predictive performance without relying on rainfall-runoff model obtained through geological and hydrological surveys.","2159-3442;21593442","Electronic:978-1-4799-8641-5; POD:978-1-4799-8642-2","10.1109/TENCON.2015.7372990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372990","Disaster Response and Risk Management;Machine Learning;Random Forests;Urban Flood;Warning systems;Web Visualization and Information Systems","Estimation;Floods;Monitoring;Prediction algorithms;Predictive models;Rain;Real-time systems","Web services;floods;hydrological techniques;telemetry","Earnshaw Street;Espana Boulevard;GPRS network;Manila;San Diego Street;TCP server;early warning advisory;geological survey;ground-based pressure sensor;hydrological survey;locally designed data logger;mobile service;prediction model;predictive performance;rain gauge;rainfall-runoff model;random forest algorithm;real time urban flood monitoring system;realtime flood updates;telemetry capabilites;time flood estimation system;web service","","","","8","","","1-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Detecting Jihadist Messages on Twitter","M. Ashcroft; A. Fisher; L. Kaati; E. Omer; N. Prucha","Dept. of Inf. tech., Uppsala Univ., Uppsala, Sweden","2015 European Intelligence and Security Informatics Conference","20160114","2015","","","161","164","Jihadist groups such as ISIS are spreading online propaganda using various forms of social media such as Twitter and YouTube. One of the most common approaches to stop these groups is to suspend accounts that spread propaganda when they are discovered. This approach requires that human analysts manually read and analyze an enormous amount of information on social media. In this work we make a first attempt to automatically detect messages released by jihadist groups on Twitter. We use a machine learning approach that classifies a tweet as containing material that is supporting jihadists groups or not. Even tough our results are preliminary and more tests needs to be carried out we believe that results indicate that an automated approach to aid analysts in their work with detecting radical content on social media is a promising way forward. It should be noted that an automatic approach to detect radical content should only be used as a support tool for human analysts in their work.","","CD-ROM:978-1-4799-8651-4; Electronic:978-1-4799-8657-6; POD:978-1-4799-8658-3","10.1109/EISIC.2015.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379742","Jihadist groups;Machine learning;Twitter","Media;Organizations;Support vector machines;Tagging;Twitter;Videos;YouTube","pattern classification;social networking (online);social sciences computing;terrorism;text analysis","Twitter;jihadist message detection;machine learning;radical content detection;social media;tweet classification","","2","","22","","","7-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"Sentiment analysis and Feedback Evaluation","A. Kumar; R. Jain","Department of Computer Science and Engineering, UIET, CSJM University, Kanpur, India","2015 IEEE 3rd International Conference on MOOCs, Innovation and Technology in Education (MITE)","20160111","2015","","","433","436","Feedback Evaluation is a necessary part of any institute to maintain and monitor the academic quality of the system. Traditionally, a questionnaire based system is used to evaluate the performance of teachers of an institute. Here, we propose an automatic evaluation system based on sentiment analysis, which shall be more versatile and meaningful than existing system. In our proposed system, feedback is collected in the form of running text and sentiment analysis is performed to identify important aspects along with the orientations using supervised and semi supervised machine learning techniques.","","Electronic:978-1-4673-6747-9; POD:978-1-4673-6748-6; USB:978-1-4673-6746-2","10.1109/MITE.2015.7375359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375359","Feedback Analysis;Machine learning;Sentiment Analysis;Text Mining","Entropy;Feature extraction;Mutual information;Sentiment analysis;Support vector machines;Training","educational administrative data processing;learning (artificial intelligence);sentiment analysis","academic quality;automatic evaluation system;feedback evaluation;semi supervised machine learning techniques;sentiment analysis;teacher performance evaluation;text analysis","","","","10","","","1-2 Oct. 2015","","IEEE","IEEE Conference Publications"
"Maritime situation analysis framework: Vessel interaction classification and anomaly detection","H. Y. Shahir; U. Glasser; A. Y. Shahir; H. Wehn","Software Technology Lab, School of Computing Science, Simon Fraser University, Burnaby, BC, Canada","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1279","1289","Maritime domain awareness is critical for protecting sea lanes, ports, harbors, offshore structures like oil and gas rigs and other types of critical infrastructure against common threats and illegal activities. Typical examples range from smuggling of drugs and weapons, human trafficking and piracy all the way to terror attacks. Limited surveillance resources constrain maritime domain awareness and compromise full security coverage at all times. This situation calls for innovative intelligent systems for interactive situation analysis to assist marine authorities and security personal in their routine surveillance operations. In this article, we propose a novel situation analysis approach to analyze marine traffic data and differentiate various scenarios of vessel engagement for the purpose of detecting anomalies of interest for marine vessels that operate over some period of time in relative proximity to each other. We consider such scenarios as probabilistic processes and analyze complex vessel trajectories using machine learning to model common patterns. Specifically, we represent patterns as left-to-right Hidden Markov Models and classify them using Support Vector Machines. To differentiate suspicious activities from unobjectionable behavior, we explore fusion of data and information, including kinematic features, geospatial features, contextual information and maritime domain knowledge. Our experimental evaluation shows the effectiveness of the proposed approach using comprehensive real-world vessel tracking data from coastal waters of North America.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363883","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363883","Anomaly Detection;Big Data;Critical Infrastructure Protection;Intelligent Systems;Machine Learning;Maritime Domain Awareness","Geospatial analysis;Hidden Markov models;Kinematics;Security;Surveillance;Time series analysis;Trajectory","data analysis;hidden Markov models;learning (artificial intelligence);marine engineering;marine vehicles;pattern classification;probability;security;support vector machines;surveillance;traffic engineering computing","anomaly detection;complex vessel trajectory analysis;contextual information;data fusion;geospatial features;information fusion;innovative intelligent systems;interactive situation analysis;kinematic features;left-to-right hidden Markov models;machine learning;marine traffic data analysis;maritime domain awareness;maritime domain knowledge;maritime situation analysis framework;pattern classification;pattern representation;probabilistic processes;routine surveillance operations;security;support vector machines;vessel engagement;vessel interaction classification;vessel tracking data","","2","","41","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Robust Approach for Medical Data Classification and Deploying Self-Care Management System for Sickle Cell Disease","M. Khalaf; A. J. Hussain; D. Al-Jumeily; R. Keenan; P. Fergus; I. O. Idowu","Appl. Comput. Res. Group, Liverpool John Moores Univ., Liverpool, UK","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","575","580","Intelligent systems and smart devices have played the major role in improving the healthcare organisation in terms of continuous tele-monitoring therapy and maintaining telemedicine management system for sickle cell disease. The biggest challenge facing majority of patients is the fact that there is still a lack of communication with healthcare professionals. Smart home (out-of hospital care) can raise personal self-sufficiency in association with living independently for longer as this disease is considered life-long condition. By using a self-care management system, we tend to improve patient welfare and mitigate patient illness before it gets worse over time, particularly with elderly people. This paper describes the state of the art in pervasive healthcare applications and the communication technologies that assist healthcare providers to offer better services for patients. This research proposes an alert system that could send immediate information to the medical consultants once detects serious condition from the collected data of the patient. Furthermore, the system is able to track various types of symptoms through mobile application in the purpose of obtaining support from medical specialists when it is required. A machine-learning algorithm was conducted to perform the classification process. Four experiments were carried out to classify sickle cell disease patients from normal patients using machine-learning algorithm in which 99.5984% classification accuracy was achieved using Multi-layer perceptron. Classification using Core Vector Regression, Hyper Pipes and Zero-Rule based algorithms achieved classification accuracy of 95.9839 %, 87.9518% and 70.6827 %, respectively.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363123","E-Health;Machine Learning Algorithm;Mobile Healthcare Service;Real-time data;Self-care Management System;Sickle Cell Disease","Diseases;Hospitals;Medical diagnostic imaging;Mobile communication;Monitoring","assisted living;diseases;health care;learning (artificial intelligence);mobile computing;multilayer perceptrons;pattern classification;regression analysis;telemedicine","alert system;communication technologies;continuous telemonitoring therapy;core vector regression;elderly people;healthcare organisation;healthcare professionals;hyper pipes algorithm;intelligent systems;machine learning algorithm;medical data classification;mobile application;multilayer perceptron;out-of hospital care;patient classification;patient illness mitigation;patient welfare improvement;pervasive healthcare applications;self-care management system deployment;sickle cell disease;smart devices;smart home;telemedicine management system;zero-rule based algorithm","","","","15","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Unknown pattern extraction for statistical network protocol identification","Y. Wang; C. Chen; Y. Xiang","School of Information Technology, Deakin University, Melbourne, Australia","2015 IEEE 40th Conference on Local Computer Networks (LCN)","20160107","2015","","","506","509","The past decade has seen a lot of research on statistics-based network protocol identification using machine learning techniques. Prior studies have shown promising results in terms of high accuracy and fast classification speed. However, most works have embodied an implicit assumption that all protocols are known in advance and presented in the training data, which is unrealistic since real-world networks constantly witness emerging traffic patterns as well as unknown protocols in the wild. In this paper, we revisit the problem by proposing a learning scheme with unknown pattern extraction for statistical protocol identification. The scheme is designed with a more realistic setting, where the training dataset contains labeled samples from a limited number of protocols, and the goal is to tell these known protocols apart from each other and from potential unknown ones. Preliminary results derived from real-world traffic are presented to show the effectiveness of the scheme.","","Electronic:978-1-4673-6770-7; POD:978-1-4673-6771-4","10.1109/LCN.2015.7366364","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366364","constrained clustering;machine learning;network protocol;semi-supervised learning","Data mining;Internet;Ports (Computers);Protocols;Testing;Training;Training data","computer networks;learning (artificial intelligence);pattern classification;protocols","classification speed;machine learning techniques;pattern extraction;statistical network protocol identification","","","","16","","","26-29 Oct. 2015","","IEEE","IEEE Conference Publications"
"The development of phone duration model in speech synthesis in the Serbian language","S. Sovilj-Nikić; I. Sovilj-Nikić","Faculty of Technical Sciences, University of Novi Sad, Trg Dositeja Obradovi&#263;a 6, Novi Sad, Serbia","2015 23rd Telecommunications Forum Telfor (TELFOR)","20160111","2015","","","693","699","Having in mind the importance of segmental duration from the perceptual point of view, the possibility of automatic prediction of natural duration of phones is essential for achieving the naturalness of synthetic speech. In this paper various machine learning techniques were used for phone duration modeling of the Serbian language. In this paper different phone duration models for the Serbian language using linear regression, tree-based algorithms and meta-learning algorithms such as additive regression, bagging and stacking algorithm are presented. Phone duration models have been developed for the full phoneme set of the Serbian language as well as for vowels and consonants separately. A large speech corpus and a feature set of 21 parameters describing phones and their contexts were used for segmental duration prediction. These features have been extracted from the large speech database for the Serbian language. The phone duration model obtained using additive regression method outperformed the other models developed for the Serbian language which are also presented in this paper. The results obtained for the full phoneme set as well as for consonants and vowels are comparable with or even outperform those reported in the literature for Czech, Greek, English, Lithuanian, Korean, Turkish and Indian languages Hindi and Telugu.","","CD-ROM:978-1-5090-0054-8; Electronic:978-1-5090-0055-5; POD:978-1-5090-0056-2","10.1109/TELFOR.2015.7377562","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377562","duration model;machine learning algorithms;phone duration","Computational modeling;Databases;Machine learning algorithms;Prediction algorithms;Predictive models;Regression tree analysis;Speech","feature extraction;learning (artificial intelligence);natural language processing;regression analysis;speech synthesis;trees (mathematics)","Serbian language;additive regression method;bagging algorithm;feature extraction;linear regression;machine learning;meta-learning algorithms;natural duration prediction;phone duration modeling;segmental duration prediction;speech synthesis;stacking algorithm;synthetic speech;tree-based algorithms","","","","29","","","24-26 Nov. 2015","","IEEE","IEEE Conference Publications"
"A Step Towards Detecting Online Grooming -- Identifying Adults Pretending to be Children","M. Ashcroft; L. Kaati; M. Meyer","Uppsala Univ., Uppsala, Sweden","2015 European Intelligence and Security Informatics Conference","20160114","2015","","","98","104","Online grooming is a major problem in todays society where more and more time is spent online. To become friends and establish a relationship with their young victims in online communities, groomers often pretend to be children. In this paper we describe an approach that can be used to detect if an adult is pretending to be a child in a chat room conversation. The approach involves a two step process wherein authors are first classified as being children or adults, and then each child is being examined and false children distinguished from genuine children. Our results show that even if it is hard to separate ordinary adults from children in chat logs it is possible to distinguish real children from adults pretending to be children with a high accuracy. In this paper we will discuss the accuracy of the methods proposed, as well as the features that were important in their success. We believe that this work is an important step towards automated analysis of chat room conversation to detect and possible attempts of grooming. Our approach where we use text analysis to distinguish adults who are pretending to be children from actual children could be used to inform children about the true age of the person that they are communicating. This would be a step towards making the Internet more secure for young children and eliminate grooming.","","CD-ROM:978-1-4799-8651-4; Electronic:978-1-4799-8657-6; POD:978-1-4799-8658-3","10.1109/EISIC.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379729","adaboost;cyber grooming;machine learning","Blogs;Book reviews;Electronic mail;Estimation;Feature extraction;Internet;Writing","Internet;learning (artificial intelligence);security of data;social sciences computing;text analysis","Internet;adults identification;chat room conversation;online communities;online grooming;text analysis;young children","","","","28","","","7-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"Predicting service metrics for cluster-based services using real-time analytics","R. Yanggratoke; J. Ahmed; J. Ardelius; C. Flinta; A. Johnsson; D. Gillblad; R. Stadler","ACCESS Linnaeus Center, KTH Royal Institute of Technology, Sweden","2015 11th International Conference on Network and Service Management (CNSM)","20160104","2015","","","135","143","Predicting the performance of cloud services is intrinsically hard. In this work, we pursue an approach based upon statistical learning, whereby the behaviour of a system is learned from observations. Specifically, our testbed implementation collects device statistics from a server cluster and uses a regression method that accurately predicts, in real-time, client-side service metrics for a video streaming service running on the cluster. The method is service-agnostic in the sense that it takes as input operating-systems statistics instead of service-level metrics. We show that feature set reduction significantly improves prediction accuracy in our case, while simultaneously reducing model computation time. We also discuss design and implementation of a real-time analytics engine, which processes streams of device statistics and service metrics from testbed sensors and produces model predictions through online learning.","","Electronic:978-3-9018-8277-7; POD:978-1-4673-7857-4","10.1109/CNSM.2015.7367349","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367349","Quality of service;cloud computing;machine learning;network analytics;statistical learning","Computational modeling;Measurement;Predictive models;Real-time systems;Servers;Statistical learning;Yttrium","cloud computing;quality of service;regression analysis","client-side service metrics;cloud services;cluster-based services;device statistics;feature set reduction;input operating-systems statistics;model computation time;real-time analytics engine;regression method;server cluster;service-level metrics;statistical learning;testbed sensors;video streaming service","","1","","45","","","9-13 Nov. 2015","","IEEE","IEEE Conference Publications"
"Searching from Mars","J. Lin; C. L. A. Clarke; G. Baruah","University of Waterloo","IEEE Internet Computing","20160106","2016","20","1","78","82","How would you search from Mars? It's the user model, stupid!","1089-7801;10897801","","10.1109/MIC.2016.2","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373514","Big Data;Internet/Web technologies;machine learning;user models","Big data;Internet;Machine learning;Mars;Search engines;Web services","Internet;Mars;information retrieval","Mars searching;user model","","","","16","","","Jan.-Feb. 2016","","IEEE","IEEE Journals & Magazines"
"Predicting Vulnerability Exploits in the Wild","M. Edkrantz; S. Truvé; A. Said","Recorded Future, Gothenburg, Sweden","2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing","20160107","2015","","","513","514","Every day numerous new vulnerabilities and exploits are reported for a wide variety of different software configurations. There is a big need to be able to quickly assess associated risks and sort out which vulnerabilities that are likely to be exploited in real-world attacks. A small percentage of all vulnerabilities account for almost all the observed attack volume. We use machine learning to make automatic predictions for unseen vulnerabilities based on previous exploit patterns.","","Electronic:978-1-4673-9300-3; POD:978-1-4673-9301-0","10.1109/CSCloud.2015.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371532","Information Security;Machine Learning;Vulnerability Prediction","Computer hacking;Databases;Media;Software;Support vector machines;Twitter","learning (artificial intelligence);security of data","machine learning;software configuration;vulnerability exploit prediction","","1","","20","","","3-5 Nov. 2015","","IEEE","IEEE Conference Publications"
"Architecting for Causal Intelligence at Nanoscale","S. Khasanvis; M. Li; M. Rahman; A. K. Biswas; M. Salehi-Fashami; J. Atulasimha; S. Bandyopadhyay; C. A. Moritz","BlueRISC","Computer","20151229","2015","48","12","54","64","Conventional Von Neumann microprocessors are inefficient for supporting machine intelligence due to layers of abstraction, limiting the feasibility of machine-learning frameworks in critical applications. A new approach for architecting intelligent systems, using physical equivalence and leveraging emerging nanotechnology, can pave the way to machine intelligence everywhere.","0018-9162;00189162","","10.1109/MC.2015.367","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368025","advanced technologies;emerging technologies;machine learning;magneto-electric circuits;mixed-signal computation;non-Von Neumann architectures;probabilistic inference;rebooting computing","Bayes methods;Cognition;Computer architecture;Machine intelligence;Nanoscale devices;Probabilistic logic","learning (artificial intelligence);microcomputers;nanotechnology","intelligent system;machine intelligence;machine-learning framework;nanotechnology;von Neumann microprocessor","","2","","19","","","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"A Novel Data Mining Method on Falling Detection and Daily Activities Recognition","Y. Peng; T. Zhang; L. Sun; J. Chen","Sch. of Comput. Sci. & Technol., Donghua Univ., Shanghai, China","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","675","681","With the intensification of aging population, a growing number of elderly people have to live alone due to domestic and social reasons. Falling becomes one of the most crucial factors in threatening the elderly's lives, which is always difficult to be detected as it is instantaneous and easy to be confused with other motions, such as lying down. In this paper, a new method is proposed for accurate falling detection and activities recognition. It applies hierarchical classifiers to the time series data set including eleven activities of daily living (ADLs), collected by four wearable sensors. The new method combines two machine learning algorithms, performs concrete analysis on the original outcome and then obtains several scarcely-confused groups separately. The experiment indicates that the new method improves the accuracy of classification to a larger extent, reached to more than 90%. Furthermore, the matched algorithm for applying these classifiers, called Hierarchical Classifier Algorithm (HCA), is proposed as well.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372198","Falling detection;Hierarchical Classifier Algorithm (HCA);machine learning algorithm;wearable sensor","Acceleration;Classification algorithms;Hidden Markov models;Machine learning algorithms;Senior citizens;Sensors;Support vector machines","assisted living;data mining;learning (artificial intelligence);pattern classification;pattern recognition;time series","ADL;HCA;activity-of-daily living;aging population intensification;classification accuracy improvement;daily-activity recognition;data mining method;domestic reasons;elderly people;falling detection;hierarchical classifier algorithm;hierarchical classifiers;machine learning algorithms;scarcely-confused groups;social reasons;time series data set;wearable sensors","","1","","18","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Detection of SIP signaling attacks using two-tier fine grained model for VoIP","G. Vennila; M. S. K. Manikandan; S. Aswathi","Department of Electronics and Communication Engineering, Thiagarajar College of Engineering, Madurai, Tamilnadu, India","TENCON 2015 - 2015 IEEE Region 10 Conference","20160107","2015","","","1","7","Recently, Voice over Internet Protocol (VoIP) applications is experiencing tremendous growth in terms of number of users. Most of the applications use Session Initiation Protocol (SIP) as a signaling protocol to establish and terminate call sessions. To facilitate interconnection, SIP uses gateways and servers that pave way for intruders. However, signaling attack during SIP session causes server congestion and thereby affects Quality of Service (QoS). Existing multiclass SVM uses a maximum of 38 features for achieving low False Positive (FP) with an increased training and testing duration. In this paper, we propose a two-tier fine grained model against signaling attack, by integrating Support Vector Machine (SVM) with an entropy model. The first tier introduces a strong learning phase with minimal feature set classifying the Internet traffic into VoIP and non-VoIP classes. Subsequently, in the second tier VoIP samples are characterized into flooding and non-flooding attacks using an entropy model that is optimized. Performance evaluation results from the experimental test bed shows that the fine grained model detects signaling attacks with high classification accuracy.","2159-3442;21593442","Electronic:978-1-4799-8641-5; POD:978-1-4799-8642-2","10.1109/TENCON.2015.7372954","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372954","SIP;VoIP;entropy;machine learning;signaling attack;traffic classification","Entropy;Feature extraction;Floods;Real-time systems;Servers;Support vector machines;Training","Internet telephony;internetworking;learning (artificial intelligence);pattern classification;quality of service;signalling protocols;support vector machines;telecommunication congestion control","Internet traffic;QoS;SIP signaling attack detection;VoIP class;entropy model;flooding attack;gateway;high classification accuracy;interconnection;learning phase;minimal feature set;multiclass SVM;nonVoIP class;nonflooding attack;performance evaluation;quality of service;server congestion;session initiation protocol;signaling protocol;support vector machine;two-tier fine grained model;voice over Internet protocol","","","","18","","","1-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Performance Regression Testing on the Java Virtual Machine Using Statistical Test Oracles","F. Hewson; J. Dietrich; S. Marsland","Sch. of Eng. & Adv. Technol., Massey Univ., Palmerston North, New Zealand","2015 24th Australasian Software Engineering Conference","20151228","2015","","","18","27","Engineering performance-critical systems often requires manual, expensive fine-tuning of critical application parts such as start-up routines, authentication sequences and transactions. It is highly desirable to protect this investment by regression tests that indicate when performance characteristics such as memory usage or thread allocation change. While traditional testing techniques can be used, they are often too coarse, as systems are tested against static thresholds, and therefore important changes that can result in declining system performance will not be detected. To address these limitations, we propose a novel approach to performance regression testing based on automatically generated statistical test oracles. Machine learning methods are used to detect deviations from the profiles shown in these oracles. We present Buto, a proof-of-concept tool tightly integrated into the JUnit testing framework that can be used to test applications executed on the Java virtual machine (JVM). Buto uses data obtained by transparently monitoring applications through Java Management Extensions (JMX). In this paper we describe the Buto framework and demonstrate how to calibrate the tool using an evaluation based on a set of benchmarking examples.","1530-0803;15300803","Electronic:978-1-4673-9390-4; POD:978-1-4673-9391-1","10.1109/ASWEC.2015.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7365790","java;jmx;machine learning;monitoring;performance regression testing;test case generation;testing","Benchmark testing;Java;Monitoring;Performance evaluation;Software;Training","Java;learning (artificial intelligence);program testing;regression analysis;software performance evaluation;virtual machines","Buto framework;JMX;JUnit testing framework;JVM;Java Management Extensions;Java virtual machine;machine learning methods;performance regression testing;proof-of-concept tool;statistical test oracles","","","","31","","","Sept. 28 2015-Oct. 1 2015","","IEEE","IEEE Conference Publications"
"Super-CWC and super-LCC: Super fast feature selection algorithms","K. Shin; T. Kuboyama; T. Hashimot; D. Shepard","University of Hyogo, Kobe, Japan","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1","7","Feature selection is a useful tool for identifying which features, or attributes, of a dataset cause or explain phenomena, and improving the efficiency and accuracy of learning algorithms for discovering such phenomena. Consequently, feature selection has been studied intensively in machine learning research. However, advanced feature selection algorithms that can avoid redundant selection of features and can detect interacting features require heavy computation in general and hence are seldom used for big data analysis. To eliminate this limitation, we tried to improve the run-time performance of two of the most advanced feature selection algorithms known in the literature. We have developed two accurate and extremely fast algorithms, namely Super CWC and Super LCC. In experiments with multiple real datasets which are actually studied in big data research, we have demonstrated that our algorithms improve the performance of their original algorithms remarkably. For example, for two datasets, one with 15,568 instances and 15,741 features and another with 200,569 instances and 99,672 features, Super-CWC performed feature selection in 1.4 seconds and in 405 seconds, respectively. This is a remarkable improvement, because it is estimated that the original algorithms would need several hours to a few ten days to perform feature selection on the same datasets.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363742","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363742","categorical feature selection;machine learning;supervised learning","Algorithm design and analysis;Big data;Clustering algorithms;Feature extraction;Machine learning algorithms;Mutual information;Redundancy","Big Data;data mining;learning (artificial intelligence)","Super-CWC;Super-LCC;big data;learning algorithm;machine learning;super fast feature selection algorithm","","1","","16","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"MP-Shield: A Framework for Phishing Detection in Mobile Devices","G. Bottazzi; E. Casalicchio; D. Cingolani; F. Marturana; M. Piu","Dept. of Comput. Sci., Univ. of Rome &#x201C;Tor Vergata&#x201D;, Rome, Italy","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","1977","1983","Today, there is an exponential growth of e-services requiring the exchange of personal and sensible data over the Internet. Phishing techniques are emerging as the easiest solution to break the weakest link of the security chain: the end user. Social engineering attacks are deployed by financial/cyber criminals at a very low cost to induce naïve Internet users to reveal user credentials such as bank account and credit card numbers. This problem needs to be addressed in the mobile field as well, due to the large diffusion of mobile devices such as smartphones, tablet, etc. In this paper we propose a novel framework for phishing detection in Android mobile devices which, on the one hand exploits well-known techniques already implemented by popular web browsers plug-in, such as public blacklist search, and, on the other hand, implements a machine learning detection engine which ensure zero-hour protection from new phishing campaigns.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363339","blacklists;heuristics;machine learning;mobile phishing;proxy","Engines;IP networks;Internet;Mobile communication;Smart phones;Uniform resource locators","Android (operating system);Internet;computer crime;mobile computing","Android mobile devices;Internet;MP-Shield;Web browsers plug-in;e-services;financial-cyber criminals;machine learning detection engine;mobile devices;phishing detection;public blacklist search;security chain;social engineering attacks;zero-hour protection","","2","","22","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Performance evaluation of different support vector machine kernels for face emotion recognition","I. A. Adeyanju; E. O. Omidiora; O. F. Oyedokun","Department of Computer Engineering, Federal University Oye-Ekiti (FUOYE), Ekiti state, Nigeria","2015 SAI Intelligent Systems Conference (IntelliSys)","20151221","2015","","","804","806","Face emotion recognition systems identify emotions expressed on the face without necessarily identifying the person involved, as in Face recognition. Support Vector Machine (SVM) has been shown to give better performance on other classification tasks but has not been applied to emotion recognition, especially with still face images. This research work analyses the performance of four different SVM kernels (Radial Basis Function, Linear Function, Quadratic Function and Polynomial Function) for face emotion recognition. A database of 714 face emotion images was created by capturing twice, seven facial expressions of 51 persons with a digital camera. Principal component analysis was used to extract distinctive features by reducing the dimensionality of each image from 571 × 800 pixels to four smaller dimensions; 50 × 50, 100 × 100, 150 × 150 and 200 × 200 pixels. The performance of four SVM kernels were evaluated for face emotion recognition with 476 training and 238 testing to recognise seven emotions; Fear, Anger, Disgust, Happiness, Sadness, Surprise and Neutral. The SVM multi-class classification scheme was used in the design of our experiments. Empirical results indicate that the Quadratic Function SVM kernel performs best for face emotion recognition with an average accuracy of 99.33%. Also, larger dimensions of the reduced image results in better performance accuracy though with increasing computation time. We intend to experiment on other classifiers for emotion recognition in our future work.","","Electronic:978-1-4673-7606-8; POD:978-1-4673-7607-5; USB:978-1-4673-7605-1","10.1109/IntelliSys.2015.7361233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361233","SVM;artificial intelligence;biometrics;emotion;face;machine learning;recognition","Emotion recognition;Face;Face recognition;Feature extraction;Kernel;Support vector machines","emotion recognition;face recognition;feature extraction;image classification;principal component analysis;support vector machines","SVM multiclass classification scheme;anger emotion;dimensionality reduction;disgust emotion;face emotion recognition;fear emotion;feature extraction;happiness emotion;linear function;neutral emotion;performance evaluation;polynomial function;principal component analysis;quadratic function;radial basis function;sadness emotion;support vector machine kernels;surprise emotion","","","","16","","","10-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Efficient Modeling of User-Entity Preference in Big Social Networks","A. N. Richter; M. Crawford; B. Heredia; T. M. Khoshgoftaar","Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","982","988","Data generated by social media are frequently leveraged to build machine learning models that can accurately profile human behavior and sentiment. Twitter is a readily available source of population data that can be collected and used by any organization. Therefore, accurate machine learning models must be created to learn from this user-generated content. In this paper, we explore the task of classifying a user's preference towards a specific entity. Particularly, we study the accuracy of classification models as an increasing number of tweets (status posts) per user is provided to the models. New users and tweets are constantly being created, warranting the use of techniques to reduce the size of data needed for machine learning algorithms. We find that there is a diminishing return on model performance as the number of tweets per user is increased, and identify a threshold where adding more tweets per user does not result in statistically better performance. Utilizing this threshold, as opposed to the maximum amount of tweets per user, data collection time is reduced by 80% while dataset size is reduced by 75%.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372238","classification;machine learning;social media;social networks;twitter","Logistics;Media;Niobium;Regression tree analysis;Twitter;Vegetation","learning (artificial intelligence);pattern classification;social networking (online)","Twitter;big social networks;classification models;data collection;human behavior profiling;human sentiment profiling;machine learning algorithms;machine learning models;social media;user preference classification;user-entity preference modeling;user-generated content","","","","17","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Selecting expansion terms based on path-constrained term-relationship graphs","Bo Zhang; Bin Zhang; Shubo Zhang; Daming Sun","School of Information Science & Engineering, Northeastern University, Shenyang, China","2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20160114","2015","","","1460","1464","During selection of expansion terms from both clicked documents and queries in log, current methods never consider the large amount of irrelevant feedbacks in records of new queries, which leads to the inconsistency between users' intents and selected expansion terms. To solve this problem, this paper integrated the ranking model with the recognition of irrelevant document content according to users' study processes, so it can reduce the weights of irrelevant expansion terms. The experimental results show that this method can measure relevancy between query and document terms better, especially in the situation when records have more irrelevant feedbacks, and can select expansion terms accorded with users' intent better.","","CD-ROM:978-1-4673-7681-5; Electronic:978-1-4673-7682-2; POD:978-1-4673-7683-9","10.1109/FSKD.2015.7382159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382159","irrelevant feedback recognition;log mining;machine learning;query expansion","Computational modeling;Estimation;Fuzzy systems;Information science;Knowledge discovery;Search engines;Uniform resource locators","document handling;graph theory;learning (artificial intelligence);query processing","clicked documents;document terms;irrelevant document content;irrelevant expansion terms;irrelevant feedbacks;path-constrained term-relationship graphs;queries;ranking model","","","","15","","","15-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"Eagle: User profile-based anomaly detection for securing Hadoop clusters","C. Gupta; R. Sinha; Y. Zhang","eBay Inc. San Jose, CA, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1336","1343","Existing Big data analytics platforms, such as Hadoop, lack support for user activity monitoring. Several diagnostic tools such as Ganglia, Ambari, and Cloudera Manager are available to monitor health of a cluster, however, they do not provide algorithms to detect security threats or perform user activity monitoring. Hence, there is a need to develop a scalable system that can detect malicious user activities, especially in real-time, so that appropriate actions can be taken against the user. At eBay, we developed such a system named Eagle, which collects audit logs from Hadoop clusters and applications running on them, analyzes users behavior, generates profiles per user of the system, and predicts anomalous user activities based on their prior profiles. Eagle is a highly scalable system, capable of monitoring multiple eBay clusters in real-time. It includes machine-learning algorithms that create user profiles based on the user's history of activities. As far as we know, this is the first activity monitoring system on the Hadoop-ecosystem for the detection of intrusion-related activities using behavior-based profiles of users. When a user performs any operation in the cluster, Eagle matches current user action against his prior activity pattern and raises alarm if it suspects anomalous action. We investigate two machine-learning algorithms: density estimation, and principal component analysis (PCA). In this paper, we introduce the Eagle system, discuss the algorithms in detail, and show performance results. We demonstrate that the sensitivity of the density estimation algorithm is 93%, however the sensitivity of our system increases by 4.94% (on average) to 98% (approximately) by using an ensemble of the two algorithms during anomaly detection.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363892","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363892","Hadoop;anomaly detection;cluster;machine learning;user activity monitoring;user profiles","Algorithm design and analysis;Clustering algorithms;Estimation;Monitoring;Principal component analysis;Real-time systems;Training","Big Data;learning (artificial intelligence);principal component analysis;security of data","Big data analytics;Eagle system;Hadoop cluster;Hadoop-ecosystem;PCA;density estimation;eBay;intrusion-related activity;machine-learning algorithm;principal component analysis;security threat;user profile-based anomaly detection","","","","30","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Stock market prediction: A big data approach","G. V. Attigeri; Manohara Pai M M; R. M. Pai; A. Nayak","Manipal Institute of Technology, 576104, India","TENCON 2015 - 2015 IEEE Region 10 Conference","20160107","2015","","","1","5","The Stock market process is full of uncertainty and is affected by many factors. Hence the Stock market prediction is one of the important exertions in finance and business. There are two types of analysis possible for prediction, technical and fundamental. In this paper both technical and fundamental analysis are considered. Technical analysis is done using historical data of stock prices by applying machine learning and fundamental analysis is done using social media data by applying sentiment analysis. Social media data has high impact today than ever, it can aide in predicting the trend of the stock market. The method involves collecting news and social media data and extracting sentiments expressed by individual. Then the correlation between the sentiments and the stock values is analyzed. The learned model can then be used to make future predictions about stock values. It can be shown that this method is able to predict the sentiment and the stock performance and its recent news and social data are also closely correlated.","2159-3442;21593442","Electronic:978-1-4799-8641-5; POD:978-1-4799-8642-2","10.1109/TENCON.2015.7373006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373006","Big data;machine learning;prediction;social media analytics","Algorithm design and analysis;Annealing;Companies;Market research;Prediction algorithms;Support vector machines","Big Data;learning (artificial intelligence);social networking (online);stock markets","Big data approach;machine learning;sentiment analysis;stock market prediction;stock value","","","","19","","","1-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Predictive Modelling of RF Energy for Wireless Powered Communications","F. Azmat; Y. Chen; N. Stocks","School of Engineering, University of Warwick, Coventry, U.K.","IEEE Communications Letters","20160107","2016","20","1","173","176","Energy harvesting enables perpetual operation of wireless networks without the need for battery change. In particular, energy can be harvested from radio waves in the radio frequency spectrum. To ensure a reliable performance, energy prediction modelling is a key component for optimizing energy harvesting because it equips the harvesting node with adaptation to energy availability. We use two machine learning techniques, linear regression (LR) and decision trees (DT) to model the harvested energy using real-time power measurements in the radio spectrum. Numerical results show that LR outperforms DT by attaining minimum 85% prediction accuracy. These models will be useful for defining the scheduling policies of harvesting nodes.","1089-7798;10897798","","10.1109/LCOMM.2015.2497306","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7317517","Energy harvesting;energy prediction model;machine learning","Energy harvesting;Power measurement;Predictive models;Radio frequency;Time-frequency analysis;Wireless communication","decision trees;energy harvesting;learning (artificial intelligence);radio networks;regression analysis;telecommunication network reliability","DT;LR;RF energy;battery change;decision trees;energy availability;energy harvesting;energy prediction modelling;harvesting node;linear regression;machine learning techniques;predictive modelling;radio frequency spectrum;radio spectrum;radio waves;real-time power measurements;reliable performance;scheduling policies;wireless networks;wireless powered communications","","3","","14","","20151103","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Real-time 3D fish tracking and behaviour analysis","H. AlZu'bi; W. Al-Nuaimy; J. Buckley; L. Sneddon; Iain Young","Department of Electrical Engineering and Electronics, University of Liverpool, Brownlow Hill, L69 3GJ, UK","2015 IEEE Jordan Conference on Applied Electrical Engineering and Computing Technologies (AEECT)","20151221","2015","","","1","5","Over half a million fish are used in scientific procedures annually in the UK alone. Most fish are subject to invasive procedures which may cause pain distress or death. A range of procedures such as fin clipping, tagging and exposure to chemicals of low pH have been associated with change in behaviour. Abnormal behaviour after common procedures may influence and confuse experiment output.","","Electronic:978-1-4799-7431-3; POD:978-1-4799-7432-0","10.1109/AEECT.2015.7360567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360567","3D Tracking;Behaviour;Machine Learning;SVM;Zebrafish","Feature extraction;Real-time systems;Software;Support vector machines;Three-dimensional displays;Trajectory","aquaculture;real-time systems","abnormal behaviour;behaviour analysis;death;invasive procedures;pain distress;real-time 3D fish tracking","","","","12","","","3-5 Nov. 2015","","IEEE","IEEE Conference Publications"
"Improving the Accuracy of the Cases in the Automatic Case Elicitation-Based Hybrid Agents for Checkers","H. C. Neto; R. M. S. Julia; V. A. R. Duarte","Comput. Sci. Dept., Fed. Univ. of Uberlandia, Uberlandia, Brazil","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","912","919","This work proposes the improvement of the calculus for the rating of cases generated in the context of hybrid player agents that conciliate Automatic Case Elicitation and static problem solvers. The system used as a benchmark is the agent for Checkers called ACE-RL-Checkers. This agent is a hybrid system that combines the best abilities from the automatic Checkers players CHEBR and LS-VisionDraughts. CHEBR is an Automatic Case Elicitation-based agent with a learning approach that performs random exploration in the search space. These random explorations allow the agent to present an extremely adaptive and non-deterministic behavior. On the other hand, the high frequency at which decisions are made randomly compromises the agent in terms of maintaining a good performance. LS-VisionDraughts is a Multi-Layer Perceptron Neural Network player trained through Reinforcement Learning. Such an agent presents an inconvenience in that it is completely predictable, as the same move is always executed when presented with the same board of play. By combining the best abilities from these players, ACE-RL-Checkers uses knowledge provided from LS-VisionDraughts in order to direct random exploration of the automatic case elicitation technique to more promising regions in the search space. Therewith, the ACE-RL-Checkers gains in terms of performance as well as acquires adaptability in its decision-making -- choosing moves based on the current game dynamics. Although ACE-RL-Checkers has proven its efficiency when pitted against its adversaries, the authors propose in the present paper two alternative strategies to calculate the rating of the cases generated in ACE-RL-Checkers in such a way as to improve future performance. Briefly, in these new alternatives two distinct strategies are investigated: elimination of the decaying memory and the insertion of the exploration/exploitation tradeoff dilemma inherent to UCT (Upper Confidence bounds applied to Trees) technique. Experiments carri- d out in tournaments involving these new strategies and the original strategy adopted in ACE-RL-Checkers confirm the improvement in the accuracy of the cases generated by the proposed strategies and their consequent performance in relation to the original strategy.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372229","Automatic Case Elicitation;Case-based Reasoning;Games;Machine Learning;Reinforcement Learning","Artificial intelligence;Cognition;Complexity theory;Games;Libraries;Probabilistic logic;Training","case-based reasoning;computer games;learning (artificial intelligence);multi-agent systems;multilayer perceptrons","ACE-RL-Checkers;CHEBR;LS-VisionDraughts;UCT;automatic Checkers players;automatic case elicitation;automatic case elicitation-based hybrid agents;hybrid player agents;multilayer perceptron neural network player;reinforcement learning;static problem solvers;upper confidence bounds applied to trees technique","","","","22","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Towards building a predictive model for remote river quality monitoring for mining sites","M. R. J. E. Estuar; E. Q. Espiritu; E. Enriquez; C. Oppus; A. D. Coronel; M. L. Guico; J. C. Monje","Department of Information Systems and Computer Science, Ateneo de Manila University, Quezon City, Philippines","TENCON 2015 - 2015 IEEE Region 10 Conference","20160107","2015","","","1","5","Most, if not all, mining sites in the Philippines are not equipped with expensive or modern monitoring tools to check for quality of soil, water and air elements which are relevant to ensure safety and wellness of miners. This study focused on the development of low cost mobile electronic sensors to monitor quality of water from rivers near mining sites. Low cost electronic sensors connected to a smart phone were developed to capture dissolved oxygen (DO2), pH, Turbidity, Temperature, and Salinity. The data for mercury (Hg) and arsenic (As) were obtained through AAS analyses to form baseline data for the model. Data was collected for over a period of one year, with site visits once every two months. A conditional inference tree (ctree) using recursive binary partitioning was used to generate the prediction model using 70 - 30 split on the training and test data set. The multi-feature model returns Good, Not Good or Unknown based on the scores of each element. The results showed a possible three feature model with significant results for site, salinity and pH balance.","2159-3442;21593442","Electronic:978-1-4799-8641-5; POD:978-1-4799-8642-2","10.1109/TENCON.2015.7373128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373128","data mining;low cost mobile electronic sensors;machine learning;quality monitoring","Cities and towns;Data mining;Decision trees;Monitoring;Predictive models;Rivers;Sensors","computerised monitoring;inference mechanisms;mining;pH;salinity (geophysical);sensors;smart phones;tree data structures;turbidity;water quality","AAS analysis;Philippines;air element quality monitoring;baseline data;conditional inference tree;ctree;data collection;dissolved oxygen capture;feature model;low-cost electronic sensors;miner safety;miner wellness;mining sites;mobile electronic sensor development;multifeature model returns;pH balance;predictive model;recursive binary partitioning;remote river quality monitoring;salinity;smart phone;soil quality monitoring;temperature value;turbidity;water quality monitoring","","","","9","","","1-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Learning Curves for Automating Content Analysis: How Much Human Annotation is Needed?","E. Ishita; D. W. Oard; K. R. Fleischmann; Y. Tomiura; Y. Takayama; A. S. Cheng","Univ. Libr., R&D Div., Kyushu Univ., Fukuoka, Japan","2015 IIAI 4th International Congress on Advanced Applied Informatics","20160107","2015","","","171","176","In this paper, we explore the potential for reducing human effort when coding text segments for use in content analysis. The key idea is to do some coding by hand, to use the results of that initial effort as training data, and then to code the remainder of the content automatically. The test collection includes 102 written prepared statements about Net neutrality from public hearings held by the U.S Congress and the U.S. Federal Communications Commission (FCC). Six categories used in this analysis: wealth, social order, justice, freedom, innovation and honor. A support vector machine (SVM) classifier and a Naïve Bayes (NB) classifier were trained on manually annotated sentences from between one and 51 documents and tested on a held out of set of 51 documents. The results show that the inflection point for a standard measure of classifier accuracy (F1) occurs early, reaching at least 85% of the best achievable result by the SVM classifier with only 30 training documents, and at least 88% of the best achievable result by NB classifier with only 30 training documents. With the exception of honor, the results show that the scale of machine classification would reasonably be scaled up to larger collections of similar documents without additional human annotation effort.","","Electronic:978-1-4799-9958-3; POD:978-1-4799-9959-0","10.1109/IIAI-AAI.2015.295","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373896","automatic content analysis;computational social science;human values;learning curve;machine learning","Encoding;FCC;Network neutrality;Niobium;Support vector machines;Training;Training data","Bayes methods;Internet;support vector machines;text analysis","Net neutrality;SVM classifier;automating content analysis;freedom;honor;human annotation;innovation;justice;learning curves;machine classification;naive Bayes classifier;social order;support vector machine;text segment;wealth","","","","18","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"Using hidden markov model for dynamic malware analysis: First impressions","M. Imran; M. T. Afzal; M. A. Qadir","Department of Computer Science, Mohammad Ali Jinnah University, Islamabad, Pakistan 44000","2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20160114","2015","","","816","821","Malware developers are coming up with new techniques to escape malware detection. Furthermore, with the common availability of malware construction kits and metamorphic virus generators, creation of obfuscated malware has become a child's play. This has made the task of anti-malware industry a challenging one, who need to analyze tens of thousands of new malware samples everyday in order to provide defense against the malware threat. The silver lining is that most of the malware generated by such means is different only syntactically, and hence techniques employing dynamic analysis and behavior modeling can be effectively used for classifying malware. In this paper we have proposed a malware classification scheme based on Hidden Markov Models using system calls as observed symbols. Our approach combines the powerful statistical pattern analysis capability of Hidden Markov Models with the proven capacity of system calls as discriminating dynamic features for countering malware obfuscation. Testing the proposed technique on system call logs of real malware shows that it has the potential of effectively classifying unknown malware into known classes.","","CD-ROM:978-1-4673-7681-5; Electronic:978-1-4673-7682-2; POD:978-1-4673-7683-9","10.1109/FSKD.2015.7382048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382048","Hidden Markov Model;Machine learning;dynamic malware analysis;malware classification","Analytical models;Computer science;Feature extraction;Hidden Markov models;Malware;Training","hidden Markov models;invasive software;pattern classification","dynamic malware analysis;hidden Markov model;malware classification scheme;malware obfuscation;statistical pattern analysis capability;system call logs","","2","","30","","","15-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"A combined convolutional neural network and potential region-of-interest model for saliency detection","Yu Hu; Z. Liang; Z. Chi; H. Fu","Department of Electronic and Information Engineering, the Hong Kong Polytechnic University, China","2015 11th International Conference on Natural Computation (ICNC)","20160111","2015","","","154","158","A saliency detection model for approaching the human performance is a challenging research topic. In this paper, a new saliency model is proposed to detect saliency in natural scenes by using a trained convolutional neural network and a region-based validation method. The convolutional neural network (CNN) focuses on image details and local contrast of an image, while the region-based validation method focus on global information. Experimental results show that the two components of the model are complementary for each other in producing high-quality saliency maps.","","CD-ROM:978-1-4673-7678-5; Electronic:978-1-4673-7679-2; POD:978-1-4673-7680-8","10.1109/ICNC.2015.7377982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377982","convolutional neural networks;machine learning;saliency detection;saliency map","Biology;Image segmentation;Sun","convolution;feature extraction;neural nets","CNN;convolutional neural network;image contrast;image detail;natural scene;region-of-interest model;saliency detection model;saliency map","","","","19","","","15-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"PAIRS: A scalable geo-spatial data analytics platform","L. J. Klein; F. J. Marianno; C. M. Albrecht; M. Freitag; S. Lu; N. Hinds; X. Shao; S. Bermudez Rodriguez; H. F. Hamann","IBM TJ Watson Research Center Yorktown Heights, NY 10598","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1290","1298","Geospatial data volume exceeds hundreds of Petabytes and is increasing exponentially mainly driven by images/videos/data generated by mobile devices and high resolution imaging systems. Fast data discovery on historical archives and/or real time datasets is currently limited by various data formats that have different projections and spatial resolution, requiring extensive data processing before analytics can be carried out. A new platform called Physical Analytics Integrated Repository and Services (PAIRS) is presented that enables rapid data discovery by automatically updating, joining, and homogenizing data layers in space and time. Built on top of open source big data software, PAIRS manages automatic data download, data curation, and scalable storage while being simultaneously a computational platform for running physical and statistical models on the curated datasets. By addressing data curation before data being uploaded to the platform, multi-layer queries and filtering can be performed in real time. In addition, PAIRS offers a foundation for developing custom analytics. Towards that end we present two examples with models which are running operationally: (1) high resolution evapo-transpiration and vegetation monitoring for agriculture and (2) hyperlocal weather forecasting driven by machine learning for renewable energy forecasting.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363884","GIS;Hadoop & HBase for geospatial data;MapReduce;big data analytics;data management systems;machine learning","Data models;Geospatial analysis;Real-time systems;Satellites;Spatial resolution;Weather forecasting","Big Data;data analysis;geographic information systems;learning (artificial intelligence);public domain software","PAIRS;automatic data download;data curation;data filtering;fast data discovery;high resolution evapotranspiration;hyperlocal weather forecasting;machine learning;multilayer queries;open source big data software;physical analytics integrated repository and services;renewable energy forecasting;scalable data storage;scalable geospatial data analytics platform;vegetation monitoring","","1","","35","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Discovering time-evolving influence from dynamic heterogeneous graphs","C. Hu; H. Cao","Department of Computer Science, New Mexico State University, New Mexico, 88003","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2253","2262","Influence among objects prevalently exists in graph structured data. However, most existing research efforts detect influence among objects from snapshots of homogeneous graphs. In this paper, we study a new problem of detecting time-evolving influence among objects from dynamic heterogeneous graphs. We propose a probabilistic graphical model, Time-evolving Influence Model (TIM), to capture the temporal dynamics of graphs, in which the time-evolving influence is hidden, and to leverage the information from heterogeneous graphs, with which we can improve the learned knowledge. To learn the graphical model, we design both non-parallel and parallel Gibbs sampling algorithms. We conduct extensive experiments on both synthetic and real data sets to show the effectiveness of the proposed model and the efficiency of the learning algorithms.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364014","Dynamic graphs;Graph mining;Machine learning","Algorithm design and analysis;Graphical models;Heuristic algorithms;Machine learning algorithms;Probabilistic logic;Twitter","Markov processes;Monte Carlo methods;data mining;graph theory;learning (artificial intelligence);mathematics computing","Gibbs sampling algorithm;TIM model;dynamic heterogeneous graph;graph structured data;graphical model learning;time-evolving influence discovery","","","","34","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"New ICT trends in solving the problem of accelerated population aging","R. I. Muhamedyev; A. T. Mansharipova; R. Butin; E. Muhamedyeva; N. Rakhimzhanova","Institute of Information and Computer Technology, Almaty, Kazakhstan","2015 15th International Conference on Control, Automation and Systems (ICCAS)","20151228","2015","","","1969","1973","The article examines the main trends in the development of geriatric service on the ground of increasing capabilities of ICT. In recent years, the measures to improve geriatric care of the population are taken in the Republic of Kazakhstan. Relevance of this issue is determined by a population aging on the one hand, and by RK humanization policy on the other hand. Consideration of these issues is impossible without corresponding data support, which is necessary for organizational tasks and for the entire cycle of medical data processing, starting from data collection, through a comprehensive analysis and issue of recommendation. Using modern software, communication and intelligent technologies promises not only improving of geriatric care quality but reducing the cost and social-economic benefits. The project of multi-level distributed personified electronic system is offered. The system would be based on results of researches in the field of AAL, M2M, machine learning, human behavior analysis etc. The main domains of the system are discussed briefly. An economic impact of the system realization is estimated approximately.","2093-7121;20937121","Electronic:978-8-9932-1508-3; USB:978-8-9932-1509-0","10.1109/ICCAS.2015.7364690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364690","Ambient Assisted Living;Big Data;Broadband Networks;Computer Vision;Geriatric Care;Human behavior analysis;Information systems;M2M;Machine Learning","5G mobile communication;Atmospheric measurements;Europe;Gerontology;Particle measurements;Sociology;Statistics","distributed processing;geriatrics;health care;learning (artificial intelligence);medical information systems;socio-economic effects","AAL;ICT capabilities;M2M;RK humanization policy;Republic of Kazakhstan;accelerated population aging problem;communication technologies;comprehensive analysis;cost reduction;data collection;geriatric care quality improvement;geriatric service;human behavior analysis;intelligent technologies;machine learning;medical data processing;multilevel distributed personified electronic system;organizational tasks;social-economic benefit reduction","","","","38","","","13-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Enhancement of Medical Named Entity Recognition Using Graph-Based Features","S. Keretna; C. P. Lim; D. Creighton","Centre for Intell. Syst. Res., Deakin Univ., Melbourne, VIC, Australia","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","1895","1900","Named Entity Recognition (NER) is a crucial step in text mining. This paper proposes a new graph-based technique for representing unstructured medical text. The new representation is used to extract discriminative features that are able to enhance the NER performance. To evaluate the usefulness of the proposed graph-based technique, the i2b2 medication challenge data set is used. Specifically, the 'treatment' named entities are extracted for evaluation using six different classifiers. The F-measure results of five classifiers are enhanced, with an average improvement of up to 26% in performance.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379463","Machine learning;Q451biomedical named entity recognition;conditional random field;information extraction;medical text mining","Australia;Context;Data mining;Drugs;Feature extraction;Intelligent systems;Training","graph theory;medical information systems;text analysis","F-measure;NER;graph-based features;graph-based technique;i2b2 medication challenge data set;medical named entity recognition enhamcement;unstructured medical text","","","","30","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Mixed-initiative social media analytics at the World Bank: Observations of citizen sentiment in Twitter data to explore ""trust"" of political actors and state institutions and its relationship to social protest","N. A. Calderon; B. Fisher; J. Hemsley; B. Ceskavich; G. Jansen; R. Marciano; V. L. Lemieux","Simon Fraser University","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1678","1687","This paper discusses a project that studied the relationship between citizen trust and social protest using visual analysis of approximately 11 million sentiment classified Tweets from the period of the 2014 Brazilian World Cup. The results of the study reveal that the 2014 World Cup protests in Brazil sprang from a wide range of grievances coupled with a relative sense of deprivation compared with emergent comparative `standards'. This sense of grievance gave rise to sentiments that activated online protest that may have led to other forms of social protest, such as demonstrations. The paper describes an innovative approach to big data analytics-mixed initiative social media analytics - and discusses the potential of using big data in social science research of this kind, as well as some of the open methodological, technical and ethical issues still to be addressed.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363939","Visual analytics;governance;interactive machine learning;political trust;social media;social protest","Big data;Government;Media;Predictive models;Standards;Twitter;Visualization","Big Data;data analysis;politics;sentiment analysis;social networking (online);social sciences computing;sport","2014 Brazilian World Cup;Big Data analytics;Twitter data;citizen sentiment;interactive machine learning;political actor;political trust;social media analytics;social protest;state institution;visual analysis","","1","","54","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Applying regression models to calculate the Q factor of multiplexed video signal based on Optisystem","R. Rudra; A. Biswas; P. Dutta; G. Aarthi","School of Electronics Engineering, VIT University, Vellore, India","2015 SAI Intelligent Systems Conference (IntelliSys)","20151221","2015","","","201","209","The objective is to analyze the input parameters of Dense Wavelength Multiplexing System and accurately predict the output parameters, using machine learning techniques and model its dependencies on the input parameters such as Frequency, Frequency Spacing, Bit Rate and Fiber length. The training data will be mined from Optisystem 13.0 software and machine learning algorithms will be implemented using R and MATLAB. The algorithms used are Multivariable regression models and neural networks. The accuracy of the two methods are compared. The predicted values have a close co-relation with input parameters and cost function errors have been minimized making use of these techniques.","","Electronic:978-1-4673-7606-8; POD:978-1-4673-7607-5; USB:978-1-4673-7605-1","10.1109/IntelliSys.2015.7361145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361145","Applied Machine Learning;Dense Wavelength Multiplexing System;Levenberg-Marquardt Back-propagation algorithm;Neural Networks;Q-Factor;Regression;Residuals","Analytical models;Bit error rate;Data mining;Data models;Mathematical model;Multiplexing;Predictive models","learning (artificial intelligence);neural nets;regression analysis;video signal processing;wavelength division multiplexing","MATLAB;Q factor;bit rate;cost function errors;dense wavelength multiplexing system;fiber length;frequency spacing;machine learning algorithms;machine learning techniques;multiplexed video signal;multivariable regression models;neural networks;optisystem;output parameters","","","","10","","","10-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Temperature Modulated Gas Sensing E-Nose System for Low-Cost and Fast Detection","X. Yin; L. Zhang; F. Tian; D. Zhang","College of Communication Engineering, Chongqing University, Chongqing, China","IEEE Sensors Journal","20151222","2016","16","2","464","474","Constant sensor-heating voltage is commonly used in electronic nose, such that multiple sensors should be integrated as a sensor array in order to differentiate multiple odor analytes. However, supplying a constant heating voltage for each sensor cannot provide rich pattern information, resulting in high cost and weak capability of an E-nose in detection. To address this issue, this paper aims at introducing an optimal temperature modulation technique of gas sensors for achieving low-cost, fast, and accurate detection. The contributions of this paper include: 1) the temperature modulated gas sensing system proposed in this paper operates in a linearly dynamical region by generating a linear control signal waveform of sensors' heating voltage; 2) with a highly efficient extreme learning machine that follows a random projection-based learning mechanism, the proposed system is developed for simultaneous gas classification and gas concentration prediction; and 3) the optimal heating voltage analysis of gas sensors is explored by using machine learning methods for providing some perspective and insight for optimal heating voltage selection. The experimental results and comparisons in terms of gas classification accuracy, concentration prediction error, system cost, and power consumption significantly demonstrate the high precision and efficacy of our proposed E-nose system. The data are available in http://www.escience.cn/people/lei/index.html.","1530-437X;1530437X","","10.1109/JSEN.2015.2483901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283568","Electronic nose;extreme learning machine;gas detection;temperature modulation","Gas detectors;Heating;Sensor arrays;Temperature distribution;Temperature sensors","electronic noses;learning (artificial intelligence);low-power electronics","E-nose system;electronic nose;gas classification;gas concentration prediction;low-cost fast detection;machine learning methods;optimal heating voltage analysis;optimal temperature modulation technique;power consumption;temperature modulated gas sensing","","1","","40","","20150929","Jan.15, 2016","","IEEE","IEEE Journals & Magazines"
"Hardware Fault Compensation Using Discriminative Learning","F. N. Taher; J. Callenes-Sloan","Dept. of Electr. Eng., Univ. of Texas at Dallas, Richardson, TX, USA","2015 IEEE 21st Pacific Rim International Symposium on Dependable Computing (PRDC)","20160107","2015","","","225","234","With process scaling and the adoption of postCMOS technologies, permanent faults are becoming a fundamental problem. Circuits containing defects are either discarded (reducing yield) or partially disabled (reducing performance). In this paper, we propose a general approach using supervised and discriminative learning techniques to compensate for the effect of permanent faults on a circuit's output. The insight for this approach is that many emerging systems and applications are able to tolerate some loss of quality in their computed results. Therefore, more scalable and lower overhead compensation techniques may be used to approximately correct for the effect of hardware faults on the circuit output. The proposed approach is shown to improve the output quality of complex accelerator and application-specific logic by 2-3 orders of magnitude while incurring <;10% area overhead and <;3% performance overhead.","","Electronic:978-1-4673-9376-8; POD:978-1-4673-9377-5","10.1109/PRDC.2015.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371866","Approximate Computing;Error Compensation;Error Tolerance;Hardware Fault;Machine Learning;Supervised learning","Circuit faults;Hardware;Integrated circuit modeling;Integrated circuit reliability;Supervised learning;Testing","fault tolerant computing;learning (artificial intelligence)","application-specific logic;complex accelerator;discriminative learning;hardware fault compensation;permanent fault effect;postCMOS technology adoption;process scaling;supervised learning","","","","25","","","18-20 Nov. 2015","","IEEE","IEEE Conference Publications"
"Two-Way Graphic Password for Mobile User Authentication","M. Jiang; A. He; K. Wang; Z. Le","Connected Finance Lab., Suning R&D Center, Palo Alto, CA, USA","2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing","20160107","2015","","","476","481","In this mobile era, people cannot live without smart phones. But how smart and trustworthy they are is still a problem. User authentication is one of the most important issues. The prevalent solutions are simple (4-digit) password, regular textbased password, pattern password and fingerprint. However, all of them are one-way authentication and each of them has its own limitations. This paper proposes a two-way authentication method which fuses knowledge-based secret and personal trait information. Two types of demos are implemented, Android and Web. The experiments and analysis prove our approach is stronger than existing ones.","","Electronic:978-1-4673-9300-3; POD:978-1-4673-9301-0","10.1109/CSCloud.2015.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371525","machine learning;mobile user security;multi-model user authentication","Authentication;Fingerprint recognition;Mobile communication;Shape;Yttrium","Android (operating system);message authentication;smart phones","4-digit password;Android;World Wide Web;knowledge-based secret;mobile user authentication;one-way authentication;pattern password;personal trait information;regular textbased password;smart phone;two-way authentication method;two-way graphic password","","","","11","","","3-5 Nov. 2015","","IEEE","IEEE Conference Publications"
"Open research challenges with Big Data ??? A data-scientist's perspective","S. R. Sukumar","Computational Sciences and Engineering Division, Oak Ridge National Laboratory, 1 Bethel Valley Road, Oak Ridge, TN, 37831, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1272","1278","In this paper, we discuss data-driven discovery challenges of the Big Data era. We observe that recent innovations in being able to collect, access, organize, integrate, and query massive amounts of data from a wide variety of data sources have brought statistical data mining and machine learning under more scrutiny and evaluation for gleaning insights from the data than ever before. In that context, we pose and debate the question - Are data mining algorithms scaling with the ability to store and compute? If yes, how? If not, why not? We survey recent developments in the state-of-the-art to discuss emerging and outstanding challenges in the design and implementation of machine learning algorithms at scale. We leverage experience from real-world Big Data knowledge discovery projects across domains of national security, healthcare and manufacturing to suggest our efforts be focused along the following axes: (i) the `data science' challenge - designing scalable and flexible computational architectures for machine learning (beyond just data-retrieval); (ii) the ` science of data' challenge - the ability to understand characteristics of data before applying machine learning algorithms and tools; and (iii) the `scalable predictive functions' challenge - the ability to construct, learn and infer with increasing sample size, dimensionality, and categories of labels. We conclude with a discussion of opportunities and directions for future research.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363882","Scalable machine learning;data science;science of data","Algorithm design and analysis;Big data;Machine learning algorithms;Manufacturing;Mathematical model;Medical services;Prediction algorithms","Big Data;data integration;data mining;learning (artificial intelligence);query processing","Big Data knowledge discovery projects;data access;data characteristics;data collection;data integration;data organization;data query;data science;data sources;data-driven discovery;data-retrieval;label categories;label dimensionality;label size;machine learning;scalable predictive functions;scalable-flexible computational architecture design;science-of-data challenge;statistical data mining","","","","31","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"A New Searching Method of Splitting Threshold Values for Continuous Attribute Decision Tree Problems","K. Y. Lian; R. F. Liu","Dept. of Electr. Eng., Nat. Taipei Univ. of Technol., Taipei, Taiwan","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","1157","1160","In the paper, we extend the well-known golden-section search (GSS) method to make an unprecedented attempt to do discrete sequence searches. The GSS method is originally used to find the extremum of a strictly unimodal continuous function. We apply it on searching the best threshold for discretizing continuous attribute data in decision tree problems. Compared to typical methods, the shortcomings relating to massive calculation requirements for searching threshold values are eliminated. Whether it is used along with information gain or Gini index as the measure indicator for data purity of decision tree, the algorithm produces good results. To verify the proposed method, data set provided by UCI database is used on Mat lab platform to carry out the simulation. Results indicate that under the same performance index, the discrete GSS method significantly lowers iteration numbers of searching threshold values and, hence, verify the feasibility of this algorithm.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379339","continuous attributes;decision tree;golden section search;machine learning","Classification algorithms;Decision trees;Indexes;Search problems;Simulation;Training data","data handling;decision trees;search problems","GSS method;Gini index;Matlab platform;UCI database;continuous attribute data;continuous attribute decision tree problems;data purity;discrete sequence search;golden-section search method;information gain;searching method;splitting threshold values;strictly unimodal continuous function extremum","","","","14","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Travel Time Prediction on Highways","J. Rupnik; J. Davies; B. Fortuna; A. Duke; S. S. Clarke","BT Group plc, Ipswich, UK","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","1435","1442","We describe the development of a predictive model for vehicle journey time on highways. Accurate travel time prediction is an important problem since it enables planning of cost effective vehicle routes and departure times, with the aim of saving time and fuel while reducing pollution. The main information source used is data from roadside double inductive loop sensors which measure vehicle speed, flow and density at specific locations. We model the spatiotemporal distribution of travel times by using local linear regression. The use of real-time data is very accurate for shorter journeys starting now and less reliable as journey times increase. Local linear regression can be used to optimally balance the use of historical and real time data. The main contribution of the paper is the extension of local linear models with higher order autoregressive travel time variables, namely vehicle flow data, and density data. Using two years of UK Highways Agency (HA) loop sensor data we found that the extended model significantly improves predictive performance while retaining the main benefits of earlier work: interpretability of linear models as well as computationally simple predictions.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363259","data integration;machine learning;traffic;travel time prediction;variable coefficient models","Computational modeling;Data models;Predictive models;Real-time systems;Roads;Vehicles","regression analysis;roads;traffic information systems;vehicle routing","UK HA loop sensor data;UK Highways Agency loop sensor data;density data;higher order autoregressive travel time variable;information source;local linear regression;predictive model development;roadside double inductive loop sensor;spatiotemporal distribution;travel time prediction;vehicle flow data;vehicle route","","","","18","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Development of Computer-Aided Diagnostic (CADx) System for Distinguishing Neoplastic from Nonneoplastic Lesions in CT Colonography (CTC): Toward CTC beyond Detection","K. Suzuki; M. Zarshenas; J. Liu; Y. Fan; N. Makkinejad; P. Forti; A. H. Dachman","Dept. of Electr. & Comput. Eng., Illinois Inst. of Technol., Chicago, IL, USA","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","2262","2266","Half of the polyps surgically removed during conventional colonoscopy are benign with no malignant potential. Our purpose was to develop a CADx system for distinction between neoplastic and non-neoplastic lesions in CTC to reduce ""unnecessary"" colonoscopic polypectomy. Although computer aided detection (CADe) systems have been developed, less attention was given to the development of CADx systems. Our CADx system consists of shape-index-based coarse segmentation of lesions, 3D volume growing and sub-voxel refinement for fine segmentation of lesions, morphologic and texture feature analysis, Wilks' lambda-based stepwise feature selection, linear discriminant analysis for providing an integrated imaging biomarker for diagnosis of neoplastic lesions. Our database contained biopsy-confirmed 54 neoplastic lesions in 29 patients and 14 non-neoplastic lesions in 10 patients. Our CADx system integrating the selected features was able to determine an accurate likelihood of being a neoplasm and distinguish 87% (47/54) neoplastic lesions from 57% (8/14) non-neoplastic lesions correctly only using computed tomography (CT) images, achieving an area under the receiver operating characteristic curve (AUC) of 0.82. This study showed the potential of the use of CTC as a diagnostic tool beyond already accepted detection, thus, CTC with CADx would be potentially useful for reducing ""unnecessary"" polypectomy.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.395","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379527","Colon cancer;cancer diagnosis;computer-aided diagnosis;imaging biomarker;machine learning","Biomedical imaging;Cancer;Computed tomography;Image segmentation;Lesions;Three-dimensional displays","cancer;computerised tomography;feature extraction;feature selection;image segmentation;image texture;medical image processing;sensitivity analysis","3D volume growing;CT colonography;Wilk lambda-based stepwise feature selection;area under the receiver operating characteristic curve;colonoscopic polypectomy;computed tomography images;computer-aided diagnostic system;linear discriminant analysis;morphologic feature analysis;neoplastic lesion diagnosis;shape-index-based coarse segmentation;subvoxel refinement;texture feature analysis","","","","20","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Analysis of Actual Smartphone Logs for Predicting the User's Routine Settings of Application Volume","T. Hasegawa; M. Koshino; H. Kimura","Div. of Healthcare Inf., Tokyo Healthcare Univ., Tokyo, Japan","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","2654","2659","Although the volume settings of smartphones are important for users, they still need to push the hardware sound button manually. The purpose of our study is to improve the usability of volume settings. Our proposed method predicts the user's routine volume settings by learning the actual daily smartphone logs. Related works used suitable volume settings input by the experimental participants to learn the volume setting pattern for each user. In contrast, this study uses actual smartphone logs. This paper describes three results of the analyses of many actual smartphone logs. First, we investigate the rate at which the users change the application volume. Second, we examine the accuracy of the results predicted by our method. Third, we classify the test users as users for whom our method effectively works or others. Finally, we discuss the appropriateness of the predicted results for users' routine settings.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.464","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379596","machine learning;routine of setting;smartphone intelligence;volume setting","Batteries;Games;Machine learning algorithms;Motion pictures;Smart phones;Switches;Turning","learning (artificial intelligence);mobile computing;smart phones","hardware sound button;smartphone log analysis;smartphone volume settings;user routine application volume setting prediction","","","","8","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"A generic and adaptive approach for workload distribution in multi-tier cluster systems with an application to distributed matrix multiplication","D. Malysiak; T. Kopinski","Hochschule Ruhr West Computer Science Institute, Bottrop, Germany","2015 16th IEEE International Symposium on Computational Intelligence and Informatics (CINTI)","20160114","2015","","","255","266","We present a novel approach of distributing matrix multiplications among GPU-equipped nodes in a cluster system. In this context we discuss the induced challenges and possible solutions. Additionally we state an algorithm which outperforms optimized GPU BLAS libraries for small matrices. Furthermore we provide a novel theoretical model for distributing algorithms within homogeneous computation systems with multiple hierarchies. In the context of this model we develop an algorithm which can find the optimal distribution parameters for each involved subalgorithm. We provide a detailed analysis of the algorithms space and time complexities and justify its use with a structured evaluation within a small GPU-equipped Beowulf cluster.","","Electronic:978-1-4673-8520-6; POD:978-1-4673-8521-3; USB:978-1-4673-8519-0","10.1109/CINTI.2015.7382933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382933","BLAS;cluster systems;cuda;gpgpu;high performance computing;machine learning;matrix multiplication;neural networks;opencl;statistics","Algorithm design and analysis;Clustering algorithms;Complexity theory;Computational modeling;Graphics processing units;Instruction sets;Processor scheduling","computational complexity;graphics processing units;mathematics computing;matrix multiplication","GPU-equipped Beowulf cluster;GPU-equipped nodes;adaptive approach;distributed matrix multiplication;generic approach;homogeneous computation systems;matrix multiplications;multitier cluster systems;optimal distribution parameters;space complexity;structured evaluation;time complexity;workload distribution","","","","14","","","19-21 Nov. 2015","","IEEE","IEEE Conference Publications"
"Comparative analysis of bagging, stacking and random subspace algorithms","P. Shrivastava; M. Shukla","Computer Science and Information Technology, Jayoti Vidyapeeth Women's University, Jaipur, India","2015 International Conference on Green Computing and Internet of Things (ICGCIoT)","20160114","2015","","","511","516","Data mining is a powerful new technology and is an important area of science and engineering. In this paper show that the comparing results using bagging, stacking and random subspace algorithms on forest fire data set in to WEKA data mining suite. We compare better results of these methods and improve classification accuracy. Performance results show that the classifiers built. These classifiers are more accurate than that produced by the classification methods. Finally, we are explaining the combining technique for increasing accuracy on the data set is presented. Experimental results are based on minimum time and minimum error rates.","","Electronic:978-1-4673-7910-6; POD:978-1-4673-7911-3; USB:978-1-4673-7909-0","10.1109/ICGCIoT.2015.7380518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380518","Bagging;Data mining;Forest fire data set;Machine learning;Random subspace;Stacking;WEKA Tool;combining classifier","Algorithm design and analysis;Bagging;Biomedical monitoring;Monitoring;Software;Software algorithms;Stacking","data mining;pattern classification;random processes","WEKA data mining suite;bagging algorithms;classification accuracy;classifiers;data mining technology;forest fire data set;minimum error rates;minimum time;random subspace algorithms;stacking algorithms","","","","26","","","8-10 Oct. 2015","","IEEE","IEEE Conference Publications"
"Weighted Naïve Bayes Classifier with Forgetting for Drifting Data Streams","B. Krawczyk; M. Wozniak","Dept. of Syst. & Comput. Networks, Wroclaw Univ. of Technol. Wroclaw, Wroc&#x0142;aw, Poland","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","2147","2152","Mining massive data streams in real-time is one of the contemporary challenges for machine learning systems. Such a domain encompass many of difficulties hidden beneath the term of Big Data. We deal with massive, incoming information that must be processed on-the-fly, with lowest possible response delay. We are forced to take into account time, memory and quality constraints. Our models must be able to quickly process large collection of data and swiftly adapt themselves to occurring changes (shifts and drifts) in data streams. In this paper, we propose a novel version of simple, yet effective Naïve Bayes classifier for mining streams. We add a weighting module, that automatically assigns an importance factor to each object extracted from the stream. The higher the weight, the bigger influence given object exerts on the classifier training procedure. We assume, that our model works in the non-stationary environment with the presence of concept drift phenomenon. To allow our classifier to quickly adapt its properties to evolving data, we imbue it with forgetting principle implemented as weight decay. With each passing iteration, the level of importance of previous objects is decreased until they are discarded from the data collection. We propose an efficient sigmoidal function for modeling the forgetting rate. Experimental analysis, carried out on a number of large data streams with concept drift prove that our weighted Naïve Bayes classifier displays highly satisfactory performance in comparison with state-of-the-art stream classifiers.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379507","big data;concept drift;data stream;forgetting;incremental learning;machine learning","Adaptation models;Data mining;Data models;Detectors;Memory management;Probability;Training","Big Data;data mining;learning (artificial intelligence);pattern classification","Big Data;classifier training procedure;data collection;data stream drifting;data stream mining;machine learning systems;object extraction;quality constraints;sigmoidal function;weighted Naive Bayes classifier","","","","22","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
"Energy cost forecasting for event venues","A. Zagar; K. Grolinger; M. Capretz; L. Seewald","Department of Electrical and Computer Engineering, Western University, London, ON, Canada N6A 5B9","2015 IEEE Electrical Power and Energy Conference (EPEC)","20160114","2015","","","220","226","Electricity price, consumption, and demand forecasting has been a topic of research interest for a long time. The proliferation of smart meters has created new opportunities in energy prediction. This paper investigates energy cost forecasting in the context of entertainment event-organizing venues, which poses significant difficulty due to fluctuations in energy demand and wholesale electricity prices. The objective is to predict the overall cost of energy consumed during an entertainment event. Predictions are carried out separately for each event category and feature selection is used to select the most effective combination of event attributes for each category. Three machine learning approaches are considered: k-nearest neighbor (KNN) regression, support vector regression (SVR) and neural networks (NN). These approaches are evaluated on a case study involving a large event venue in Southern Ontario. In terms of prediction accuracy, KNN regression achieved the lowest average error. Error rates varied greatly among different event categories.","","Electronic:978-1-4799-7664-5; POD:978-1-4799-7665-2; USB:978-1-4799-7663-8","10.1109/EPEC.2015.7379953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379953","demand forecasting;energy cost forecasting;machine learning;prediction methods;smart meters","Artificial neural networks;Biological neural networks;Energy consumption;Forecasting;Neurons;Predictive models;Support vector machines","feature selection;learning (artificial intelligence);load forecasting;neural nets;power consumption;power engineering computing;regression analysis;smart meters;support vector machines","KNN regression;NN;SVR;Southern Ontario;electricity consumption;electricity demand forecasting;electricity price;energy cost forecasting;energy prediction;entertainment event-organizing venue context;feature selection;k-nearest neighbor regression;machine learning approach;neural network;smart meter proliferation;support vector regression","","","","23","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Non-parametric Conformity-Based Test for Transfer Decisions","S. Zhou; E. N. Smirnov; G. Schoenmakers; R. Peeters; K. Driessens","Dept. of Knowledge Eng., Maastricht Univ., Maastricht, Netherlands","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","628","635","This paper proposes a new non-parametric test to decide whether to transfer from source data to target data in order to improve the performance of predictive models on target domains. The test is based on the conformity framework. It statistically tests whether the target data and source data have been generated from the target distribution under the exchangeability assumption. The source data is transferred if and only if the test is positive. The experiments show that the test is better at deciding on instance transfer than existing methods.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372192","knowledge transfer;machine learning;statistical learning","Context;Estimation;Predictive models;Probability distribution;Testing;Yttrium","learning (artificial intelligence);nonparametric statistics;statistical testing","exchangeability condition;instance-transfer learning;nonparametric conformity-based test;performance improvement;predictive model;source data;statistical tests;target data;target distribution;target domain;transfer decisions","","","","20","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Twitter opinion mining for adverse drug reactions","L. Wu; T. S. Moh; N. Khuri","Department of Computer Science, San Jose State University, San Jose, CA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1570","1574","Although rigorous clinical studies are required before a drug is placed on the market, it is impossible to predict all side effects for the approved medication. The United States Food and Drug Administration actively monitors approved drugs to identify adverse events. The FDA Adverse Event Reporting System (FAERS) contains a database of adverse drug events reported by the healthcare providers and consumers. The ubiquitous online social networks, such as Twitter, can provide complementary information about adverse drug events. Short Twitter postings, or tweets, are often used to express an opinion about drugs, as well as solicit and receive feedback from consumers of a drug. Thus, adverse drug events can be discovered by extracting from tweets users' opinions about drugs. Here, we developed a computational pipeline for collecting, processing, and analyzing tweets to find signals about adverse drug reactions, defined as drug side effects caused by a drug at a normal dose during normal use. Manual examination of processed tweets identified several known side effects of four drugs.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363922","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363922","Adverse Drug Reactions;Machine Learning;Nature Language Processing;Opinion Mining;Sentiment Analysis","Data mining;Databases;Drugs;Feature extraction;Pipelines;Sentiment analysis;Twitter","data mining;drugs;health care;medical computing;social networking (online)","FDA adverse event reporting system;Twitter opinion mining;United States Food and Drug Administration;adverse drug reaction;clinical studies;drug side effect;healthcare;ubiquitous online social network","","2","","37","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Representing and Learning Variations","F. Badra","INSERM, LIMICS, Paris, France","2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI)","20160107","2015","","","950","957","In machine learning, objects are usually grouped according to similarities found in the objects descriptions. Recent works, however, suggest that representing the differences between object descriptions is also pertinent in many learning tasks. But not much study has been made on how to represent and learn from differences. This paper proposes a qualitative representation of inter-object variations that can be used as input of a learning task. The main idea is to define inter-objects variations as attributes of repetitions of objects, so that machine learning methods will be able to manipulate them in the same way as they manipulate object attributes. The approach is tested on both classification and a numerical value prediction tasks and shows encouraging results.","1082-3409;10823409","Electronic:978-1-5090-0163-7; USB:978-1-5090-0162-0","10.1109/ICTAI.2015.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372234","knowledge representation;machine learning;qualitative representation of variations","Cognition;Extraterrestrial measurements;Learning systems;Motion pictures;Pattern recognition;Semantics;Space vehicles","learning (artificial intelligence);numerical analysis","interobject variations;learning variations;machine learning methods;numerical value prediction;objects descriptions;qualitative representation;representing variations","","1","","13","","","9-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"A 90 nm CMOS, <inline-formula><tex-math notation=""LaTeX"">$6 {upmu {text{W}}}$</tex-math></inline-formula> Power-Proportional Acoustic Sensing Frontend for Voice Activity Detection","K. M. H. Badami; S. Lauwereins; W. Meert; M. Verhelst","Departement Elektrotechniek ESAT-MICAS Kasteelpark, KU Leuven, Leuven, Belgium","IEEE Journal of Solid-State Circuits","20151230","2016","51","1","291","302","This work presents a sub-6 μW acoustic frontend for speech/non-speech classification in a voice activity detection (VAD) in 90 nm CMOS. Power consumption of the VAD system is minimized by architectural design around a new power-proportional sensing paradigm and the use of machine-learning assisted moderate-precision analog analytics for classification. Power-proportional sensing allows for hierarchical and context-aware scaling of the frontend's power consumption depending on the complexity of the ongoing information extraction, while the use of analog analytics brings increased power efficiency through switching ON/OFF the computation of individual features depending on the features' usefulness in a particular context. The proposed VAD system reduces the power consumption by 10× as compared to state-of-the-art (SotA) systems and yet achieves an 89% average hit rate (HR) for a 12 dB signal-to-acoustic-noise ratio (SANR) in babble context, which is at par with softwarebased VAD systems.","0018-9200;00189200","","10.1109/JSSC.2015.2487276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7315025","Acoustic frontend;analog machine learning;context-aware computing;hierarchical computing;scalable low power analog;voice activity detection (VAD)","","CMOS integrated circuits;acoustic signal detection;acoustic transducers;low-power electronics;signal conditioning circuits;speech recognition","CMOS integrated circuit;context aware power consumption scaling;machine learning assisted classification;nonspeech classification;power 6 muW;power-proportional acoustic sensing frontend;power-proportional sensing;size 90 nm;voice activity detection","","4","","28","","20151102","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Nonparametric Discovery of Contexts and Preferences in Smart Home Environments","C. L. Wu; T. C. Chiang; L. C. Fu; Y. C. Zeng","Intel-NTU Connected Context Comput. Center, Nat. Taiwan Univ., Taipei, Taiwan","2015 IEEE International Conference on Systems, Man, and Cybernetics","20160114","2015","","","2817","2822","With the popularity of Internet of Things, lots of resource constrained devices equipped with sensors and actuators are pervasively deployed to compose a smart environment, and Big Data are obtainable for a system to do further analytics thus to achieve human-centric purposes. One such human-centric system is a smart home which analyze Big Data to recognize contexts and their corresponding preferences for service configuration thus to provide context-aware services. However, since these Big Data are generated in real-time with huge amount, analytics based on conventional supervised way is not desirable due to the requirement of human efforts. In addition, there are usually multiple inhabitants with multiple combination of contexts in a home environment, and it is difficult to fully collect all these possible context combination as well as their corresponding preferences in advance. Therefore, this paper proposes an unsupervised nonparametric analytics method with a framework for human-centric smart homes to automatically discover contexts and their corresponding service configurations, and the models resulting from the proposed analytics can also be used to determine the preference for a context combination unseen before.","","Electronic:978-1-4799-8697-2; POD:978-1-4799-8698-9","10.1109/SMC.2015.491","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379623","Activity Recognition;Ambient Intelligence;Knowledge Acquisition;Machine Learning;Non-parametric Learning Model;Smart Environment","Conferences;Cybernetics","Big Data;Internet of Things;home automation;home computing","Big Data;Internet of Things;actuators;context combination;context-aware services;human efforts;human-centric purposes;human-centric smart homes;human-centric system;nonparametric discovery;resource constrained devices;sensors;service configuration;smart environment;smart home environments;unsupervised nonparametric analytics method","","","","10","","","9-12 Oct. 2015","","IEEE","IEEE Conference Publications"
