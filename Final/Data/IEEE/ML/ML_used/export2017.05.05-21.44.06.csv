"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7566001,7565979,7568339,7523950,7566373,7567338,7566779,7569028,7568898,7302049,7563651,7336493,7560255,7562739,7562966,7562727,7560256,7562661,7560173,7562691,7562806,7562982,7562789,7561298,7562656,7562824,7562326,7539610,7559590,7559547,7559580,7560134,7480352,7534775,7515194,7555983,7556813,7557439,7557589,7557229,7555985,7557518,7555551,7557675,7552343,7552350,7557682,7552353,7557547,7557599,7555990,7552326,7552336,7556031,7557778,7346466,7556193,7556817,7429700,7347429,7555341,7552873,7552011,7552193,7549457,7550946,7551432,7548954,7552135,7552300,7552539,7551827,7551576,7550752,7529219,7523201,7532683,7533139,7532573,7429689,7532896,7511662,7544930,7546525,7546323,7545064,7544810,7543750,7546324,7546110,7543745,7546102,7543784,7545366,7543901,7546176,7545841,7546187,7547116,7545984",2017/05/05 21:44:06
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Multi-view Bi-clustering to Identify Smartphone Sensing Features Indicative of Depression","A. A. Farhan; J. Lu; J. Bi; A. Russell; B. Wang; A. Bamis","Dept. of Comput. Sci. & Eng., Univ. of Connecticut, Storrs, CT, USA","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20160818","2016","","","264","273","Depression is a major public health issue with direct and significant effects on both physical and mental health. In this study, we analyze smartphone sensing data to find differential behavioral features that are correlated with depression measures such as patient health questionnaire (PHQ-9). Our approach uses an innovative multi-view bi-clustering algorithm. It takes multiple views of sensing data as input to identify homogeneous behavioral groups and simultaneously the key sensing features that characterize the different groups. Using a publicly available dataset, we discover that these behavioral groups with differential sensing features are highly discriminative of PHQ-9 scores that are self reported by the study subjects. For instance, the group comprising less active users in the sensed activities corresponds to overall higher PHQ-9 scores. We then employ the key sensing features that distinguish the different groups to create predictive models to predict the group assignment of individuals. We verify the generalizability of these models using the support vector machine classifier. Cross validation studies show that our classifiers can classify individuals into the correct subgroups with an overall accuracy of 87%.","","Electronic:978-1-5090-0943-5; POD:978-1-5090-0944-2","10.1109/CHASE.2016.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545841","Depression;Human Behavior;Machine Learning;Smartphones","Data mining;Feature extraction;Global Positioning System;Market research;Mood;Sensors;Support vector machines","health care;mobile computing;pattern clustering;smart phones;statistical analysis;support vector machines","SVM classifier;depression;multiview biclustering;public health;smart phone sensing feature;support vector machine classifier","","","","","","","27-29 June 2016","","IEEE","IEEE Conference Publications"
"A Real-Time FPGA Based Human Detector","P. Y. Hsiao; S. Y. Lin; C. Y. Chen","Dept. of Electr. Eng., Nat'l Univ. of Kaohsiung, Kaohsiung, Taiwan","2016 International Symposium on Computer, Consumer and Control (IS3C)","20160818","2016","","","1014","1017","An ARM-platform and FPGA-based accelerator rather than PC-based system is utilized in this study for completing a real-time FPGA-based human detector. The system presents the advantages of small size, low cost, high computing speed, and being portable and could be built in small cameras for surveillance applications. When background segmentation is introduced, the computing efficiency could reach about 15 fps. Moreover, this study has proven that the reduction on the total detection rate is less than 0.3% while changing HOG algorithm into the presented FPGA hardware implementation.","","Electronic:978-1-5090-3071-2; POD:978-1-5090-3072-9","10.1109/IS3C.2016.256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545366","FPGA Accelerator;HOG;Human Detection;Machine Learning;Real-Time Embedded System","Feature extraction;Field programmable gate arrays;Hardware;Machine learning algorithms;Real-time systems;Support vector machines;Training","field programmable gate arrays;image segmentation;microprocessor chips;object detection;real-time systems;video surveillance","ARM-platform;FPGA-based accelerator;HOG algorithm;background segmentation;cameras;computing efficiency;high computing speed system;histograms of oriented gradients;low cost system;portable system;real-time FPGA-based human detector;small size system;surveillance applications","","","","","","","4-6 July 2016","","IEEE","IEEE Conference Publications"
"Deep TSK Fuzzy Classifier with Stacked Generalization and Triplely Concise Interpretability Guarantee for Large Data","T. Zhou; S. Wang; F. L. Chung","Ta Zhou is with the School of Digital Media, Jiangnan University, Wuxi 214122, China. He is also with the campus of Zhangjiagang, Jiangsu University of Science and Technology, Zhenjiang 212003, China (e-mail: jkdzhout@just.edu.cn).","IEEE Transactions on Fuzzy Systems","","2016","PP","99","1","1","Although Takagi-Sugeno-Kang (TSK) fuzzy classifier has been applied to a wide range of practical scenarios, how to enhance its classification accuracy and interpretability simultaneously is still a challenging task. In this paper, based on the powerful stacked generalization principle, a deep TSK fuzzy classifier called D-TSK-FC is proposed to achieve the enhanced classification accuracy and triplely concise interpretability for fuzzy rules. D-TSK-FC consists of base building units. Just like the existing popular deep learning, D-TSK-FC can be built in a layer-by-layer way. In terms of the stacked generalization principle, the training set plus random shifts obtained from random projections of prediction results of current base building unit is presented as the input of the next base building unit. The hidden layer in each base building unit of D-TSK-FC is represented by triplely concise interpretable fuzzy rules in the sense of randomly selected features with the fixed five fuzzy partitions, random rule combinations and the same input space kept in every base building unit of D-TSK-FC. The output layer of each base building unit can be learnt quickly by least learning machine (LLM). Besides, benefiting from LLM, D-TSK-FC’s deep learning can be well scaled up for large datasets. Our extensive experimental results witness the power of the proposed deep TSK fuzzy classifier.","1063-6706;10636706","","10.1109/TFUZZ.2016.2604003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555341","TSK fuzzy classifier;deep learning;interpretability;large data;least learning machine;stacked generalization","Buildings;Classification algorithms;Fuzzy sets;Fuzzy systems;Genetic algorithms;Machine learning;Neural networks","","","","","","","","20160829","","","IEEE","IEEE Early Access Articles"
"Assessing photograph aesthetic quality with color based descriptor","X. Zhu; T. S. Moh","Department of Computer Science, San Jose State University, San Jose, CA, USA","2016 International Conference on High Performance Computing & Simulation (HPCS)","20160915","2016","","","222","229","Assessing photograph aesthetic quality is an interesting and important problem of computer vision. The understanding of how to classify photographs based on their aesthetic value not only provides us with important knowledge about effective methods and techniques of summarizing information embedded in digital images, but also has numerous practical applications in photo management systems, image search engines, photo library optimization processes, and smart cameras. Previous work has explored the method of using generic local descriptors extracted from gray-scale photographs to assess the aesthetic quality. In our work, we designed an aesthetic descriptor based on color information of local patches to asses the aesthetic quality of photographs. We employed the Bag of Words (BOW) model to describe our data. The BOW model is widely used in text analysis tasks due to its good performance. This model can also be adopted by computer vision tasks to classify and categorize images. With such a model, every photograph in our dataset was represented as a vector of visual words derived from the color descriptors. A Gaussian mixture model was used to cluster and verbalize photographs, which is proven to be highly effective in our classification task. The best performance we achieved in our experiments was 72.9% AUC.","","Electronic:978-1-5090-2088-1; POD:978-1-5090-2089-8","10.1109/HPCSim.2016.7568339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568339","Aesthetic Quality;Color Descriptor;Computer Vision;Image Classification;Machine Learning","Computational modeling;Gaussian mixture model;Histograms;Image color analysis;Visualization;Vocabulary","Gaussian processes;computer vision;image classification;image colour analysis;mixture models","BOW model;Gaussian mixture model;aesthetic descriptor;bag of words model;color based descriptor;computer vision;digital images;gray-scale photographs;image categorization;image classification;image search engines;photo library optimization;photo management systems;photograph aesthetic quality;photograph classification;smart cameras","","","","","","","18-22 July 2016","","IEEE","IEEE Conference Publications"
"An efficient star skeleton extraction for human action recognition using hidden Markov models","P. T. Hai; H. H. Kha","Faculty of Electrical & Electronics Engineering, Ho Chi Minh City University of Technology, Vietnam","2016 IEEE Sixth International Conference on Communications and Electronics (ICCE)","20160908","2016","","","351","356","This paper aims at finding an efficient approach for automatic human action recognition to classify human actions in both outdoor and indoor environments. A human action recognition system (HARS) collects video frames of human activities, extracts the desired features of each human skeleton. These characteristics are calculated, classified to build a skeleton database that can distinguish almost human gestures. This HARS converts every sequence of human gestures to the sequences of skeletal joint mapping (SJM). Then it assigns corresponding observation symbols to each SJM. Those observation sequences are used to train of hidden Markov models (HMMs) corresponding to seven actions: standing, walking, running, jumping, falling, lying, and sitting. Baum-Welch and forward-backward algorithms are employed to find optimal parameters of each HMM. During a recognition phase, each human gesture sequence is converted to an observation sequence and put into seven optimized HMM models. The current action can be identified by finding a model with the highest probability. The experimental results show that the proposed HARS offers high accuracy of action recognition in real-time.","","","10.1109/CCE.2016.7562661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562661","Hidden Markov model;human action recognition;machine learning;star skeleton extraction","Databases;Feature extraction;Hidden Markov models;Real-time systems;Skeleton;Training;Vector quantization","feature extraction;gesture recognition;hidden Markov models","Baum-Welch algorithms;HARS;HMM;automatic human action recognition;feature extraction;forward-backward algorithms;hidden Markov models;human action recognition;human action recognition system;human gesture sequence;recognition phase;skeletal joint mapping;skeleton database;star skeleton extraction","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Data analysis system for online short video comments","N. Yang; S. Cao; S. Zhang","New Media Institute, Communication University of China, Beijing, China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","6","Online short video has become a very popular form of video nowadays. The video providers involve small ones, like a stand-alone video maker, a UGC studio, or some big video producers. They focus on providing the content, and they are eager to learn whether their videos are popular or not. Most of them hope that some widely accepted third party institution provide the benchmark for the short videos industry among the country. For their convenience, a data analysis system has been setup specialized for this purpose. Firstly, it can fetch short video comments information from the internet, either mobile or not. Then it analyzes the fetched information with machine learning algorithms. Finally it can provide the result to the video providers, for the utilization of product improvement. Sometimes this information can even help to decide the awards for the video provider's association. This article makes an introduction to the system, especially for the data fetching and data analyzing technologies and their utility.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550946","comments for online video;data analyzing;data fetching;machine learning","Data mining;Internet;Media;Mobile communication;Mobile handsets;Sentiment analysis;Uniform resource locators","Internet;data analysis;learning (artificial intelligence);video signal processing","data analysis system;data fetching;machine learning;online short video comment","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"IPAS: Intelligent protection against silent output corruption in scientific applications","I. Laguna; M. Schulz; D. F. Richards; J. Calhoun; L. Olson","Lawrence Livermore National Laboratory, Livermore, CA, USA","2016 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)","20160905","2016","","","227","238","This paper presents IPAS, an instruction duplication technique that protects scientific applications from silent data corruption (SDC) in their output. The motivation for IPAS is that, due to natural error masking, only a subset of SDC errors actually affects the output of scientific codes - we call these errors silent output corruption (SOC) errors. Thus applications require duplication only on code that, when affected by a fault, yields SOC. We use machine learning to learn code instructions that must be protected to avoid SOC, and, using a compiler, we protect only those vulnerable instructions by duplication, thus significantly reducing the overhead that is introduced by instruction duplication. In our experiments with five workloads, IPAS reduces the percentage of SOC by up to 90% with a slowdown that ranges between 1.04x and 1.35x, which corresponds to as much as 47% less slowdown than state-of-the-art instruction duplication techniques.","","Electronic:978-1-4503-3778-6; POD:978-1-5090-4245-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559547","Resilience;compiler analysis;high-performance computing;machine learning","Computer crashes;Error correction codes;Hardware;Mathematical model;Program processors;Runtime;Training","data handling;learning (artificial intelligence)","IPAS;SDC;instruction duplication;intelligent protection;machine learning;natural error masking;scientific applications;scientific codes;silent output corruption","","","","","","","12-18 March 2016","","IEEE","IEEE Conference Publications"
"Predicting Temperament from Twitter Data","A. C. E. S. Lima; L. N. de Castro","Natural Comput. Lab., Mackenzie Presbyterian Univ., Sao Paulo, Brazil","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","599","604","Temperament is an innate psychological characteristic associated with how we relate with the world. This feature is often used to direct careers, manage conflicts, develop leadership, improve teaching, etc. The data generated by social media users represent user behavior facing the various situations of everyday life. With this, machine learning techniques can be used to infer the temperament, as is already done in the vast research on sentiment analysis and the growing research on personality prediction. This paper proposes a framework for temperament classification according to the theory of psychologist David Keirsey. Our results present an accuracy higher than 70% for the Artisan and Guardian types.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557682","Machine Learn-ing;Social Data Mining;Social Media;Temperament;Text Classification","Business;Context;Data mining;Engineering profession;Media;Psychology;Twitter","behavioural sciences computing;inference mechanisms;learning (artificial intelligence);pattern classification;psychology;sentiment analysis;social networking (online)","Twitter data;machine learning;psychological characteristic;sentiment analysis;social media;temperament classification;temperament inference;temperament prediction;user behavior","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Efficient Residual DPCM Using an <inline-formula><tex-math notation=""LaTeX"">$l_1$</tex-math> </inline-formula> Robust Linear Prediction in Screen Content Video Coding","J. W. Kang; S. K. Ryu; N. Y. Kim; M. J. Kang","Department of Electronics Engineering, Ewha Womans University, Seoul, Korea","IEEE Transactions on Multimedia","20160915","2016","18","10","2054","2065","In this paper, a residual differential pulse code modulation (RDPCM) coding technique using a weighted linear combination of neighboring residual samples is proposed to provide coding efficiency in the screen content video coding. The RDPCM performs the sample-based prediction of residue to reduce spatial redundancies. The proposed method uses the l<sub>1</sub> optimization in the weight derivation by considering the statistical characteristics of graphical components in videos in an intracoding. Specifically we use the least absolute shrinkage and selection operator to derive the weights because the solution is accurate in high variance residue. Furthermore, we enhance parallelism in a line processing by restricting the support to the row-wise prediction to above samples or the column-wise prediction to the left samples. The proposed method uses an explicit RDPCM scheme, so a coding mode determined by rate-distortion optimization is transmitted to a decoder. For coding the overhead, we develop a context design in CABAC based on correlation between an intraprediction direction and an RDPCM prediction mode. It is demonstrated with the experimental results that the proposed method provides a significant coding gain over the state-of-the-art reference codec for screen content video coding.","1520-9210;15209210","","10.1109/TMM.2016.2595259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523950","l1optimization, lossy and lossless coding;machine learning;parallelism;residual differential pulse code modulation (RDPCM);screen content coding (SCC)","Correlation;Decoding;Encoding;Optimization;Parallel processing;Transforms;Video coding","differential pulse code modulation;optimisation;statistical analysis;video coding","CABAC;RDPCM coding technique;column-wise prediction;intracoding;l<sub>1</sub> robust linear prediction;least absolute shrinkage;line processing;neighboring residual samples;rate-distortion optimization;residual differential pulse code modulation coding technique;row-wise prediction;screen content video coding","","","","","","20160727","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Review of automated glaucoma detection techniques","S. Nawaldgi","Dept. of Electronics & Communication Engineering, APPA Institute of Engineering & Technology, Kalaburagi, Karnataka, India","2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","20160915","2016","","","1435","1438","Glaucoma, an eye disease, is often referred to as the silent thief of sight. The damage done by glaucoma is irreversible. Early detection and treatment of glaucoma is the only solution. Till date many works have been done towards automatic glaucoma detection using Color Fundus Images (CFI) and Optical Coherence Tomography (OCT) images by extracting structural features. Structural features can be extracted from optic nerve head (ONH) analysis in case of CFI and Retinal Layers (RL) analysis in OCT images for glaucoma assessment. But unfortunately, the works till date fall short of expected accuracy in this regard. A review of automated glaucoma detection techniques is presented in this paper. The paper also discusses various structural features that are relevant to CFI and OCT images respectively for automated glaucoma detection. The paper concludes that combining structural features from both CFI and OCT images would result in more accurate glaucoma assessment.","","","10.1109/WiSPNET.2016.7566373","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566373","Cup-to-disk ratio;Feature extraction;Fundoscopy;Glaucoma;Machine Learning;Optical Coherence Tomography;Retinal layers","Feature extraction;Image segmentation;Optical distortion;Optical fibers;Optical imaging;Retina","eye;feature extraction;image colour analysis;medical image processing;optical tomography","CFI;OCT images;ONH analysis;automated glaucoma detection techniques;color fundus images;eye disease;feature extraction;glaucoma assessment;glaucoma treatment;optic nerve head analysis;optical coherence tomography images;retinal layers analysis","","","","","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Learning to infer: A new variational inference approach for power grid topology identification","Y. Zhao; J. Chen; H. V. Poor","Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY 11794","2016 IEEE Statistical Signal Processing Workshop (SSP)","20160825","2016","","","1","5","Identifying arbitrary topologies of power networks is a computationally hard problem due to the number of hypotheses that grows exponentially with the network size. A new variational inference approach is developed for efficient marginal inference of every line status in the network. Optimizing the variational model is transformed to and solved as a discriminative learning problem. A major advantage of the developed learning based approach is that the labeled data used for learning can be generated in an arbitrarily large amount at very little cost. As a result, the power of offline training is fully exploited to offer effective real-time topology identification. The proposed methods are evaluated in the IEEE 30-bus system. With relatively simple variational models and only an undercomplete measurement set, the proposed method already achieves very good performance in identifying arbitrary power network topologies.","","Electronic:978-1-4673-7803-1; POD:978-1-4673-7804-8","10.1109/SSP.2016.7551827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551827","Power grid topology identification;line outage detection;machine learning;variational inference","Computational modeling;Data models;Network topology;Power grids;Real-time systems;Topology;Training","inference mechanisms;learning (artificial intelligence);optimisation;power engineering computing;power grids;power system reliability;variational techniques","IEEE 30-bus system;blackout prevention;discriminative learning problem;power grid topology identification;power network arbitrary topology identification;real-time topology identification;variational inference approach;variational model optimization","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Regression Model for Context Awareness in Mobile Commerce","M. Alrammal; M. Naveed; H. Osta; A. Zahrawi","Alkhawarizmi Internaional Univ. Coll., Abu Dhabi, United Arab Emirates","2015 International Conference on Developments of E-Systems Engineering (DeSE)","20160912","2015","","","285","289","This work presents a novel approach, socalled RBCM, in modeling a domain to construct contextaware model for mobile computing. RBCM is based on a multivariate regression method to construct a probability density function for action schema in a domain. A machine learning algorithm is applied to map the action schema with a context. RBCM is evaluated using a benchmark dataset. The results are compared with the start-of-the-art rivals of RBCM. The main candidate rivals of RBCM are based on the latest variations of Nayes-bias, MOCART and Decision Tree. The results show that our model outperform its rival techniques in accuracy and precision. RBCM predicts the preferences of the users with a higher accuracy than its rivals. RBCM perform better with the sample size greater than 50.","","","10.1109/DeSE.2015.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563651","Context awareness;m-commerce;machine learning;regression model","Automobiles;Benchmark testing;Computational modeling;Context;Context modeling;Decision trees;Mobile applications","learning (artificial intelligence);mobile commerce;probability;regression analysis","RBCM;action schema mapping;context awareness;context-aware model;machine learning algorithm;mobile commerce;mobile computing;multivariate regression method;probability density function;regression model","","","","","","","13-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Power quality prediction designed as binary classification in AC coupling Off-Grid system","T. Vantuch; S. Mišák; J. Stuchlý","Department of Computer Science, VSB - Technical University of Ostrava, Faculty of Electrical Engineering and Computer Science, Ostrava, Czech Republic","2016 IEEE 16th International Conference on Environment and Electrical Engineering (EEEIC)","20160901","2016","","","1","6","One of the most critical problems of autonomous energy systems (so called Off-Grid systems) is the keeping of the power quality parameters (PQP) in the requested limits. This paper focuses on development of a simple binary classification as a tool for the forecasting of a PQP. This tool will help as an advisor for a shifting of the load in the Off-Grid system, which keeps the PQP in the requested limits. Some of the most frequently applied machine learning (ML) algorithms like artificial neural network, support vector machine and decision trees with bagging and boosting technique are used in this paper to demonstrate this way of solving the PQP forecasting.","","CD-ROM:978-1-5090-2319-6; Electronic:978-1-5090-2320-2; POD:978-1-5090-2321-9","10.1109/EEEIC.2016.7555551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555551","Machine Learning Techniques;Off-Grid Systems;Power Quality Parameters;Renewable Sources","Artificial neural networks;Classification algorithms;Forecasting;Optimization;Power quality;Support vector machines;Weather forecasting","decision trees;learning (artificial intelligence);load forecasting;neural nets;power engineering computing;power supply quality;support vector machines","AC coupling;PQP forecasting;artificial neural network;autonomous energy system;bagging technique;binary classification;boosting technique;decision trees;machine learning algorithm;off-grid system;power quality parameter;power quality prediction;support vector machine","","","","","","","7-10 June 2016","","IEEE","IEEE Conference Publications"
"Hybrid classification model of correlation-based feature selection and support vector machine","V. K. Dubey; A. K. Saxena","Department of Computer Science and Information Technology, Guru Ghasidas Vishwavidyalaya, Bilaspur, 495009, Chattisgarh, India","2016 IEEE International Conference on Current Trends in Advanced Computing (ICCTAC)","20160915","2016","","","1","6","In this paper, we propose a hybrid classification model, which has correlation based filter feature selection algorithm and support vector machine as a classifier. In this method, features are ordered according to their Absolute correlation value with respect to the class attribute. Then top K Features are selected from ordered list of features to form a reduced dataset. The classification accuracy is measured using SVM classifiers with and without extending features of the reduced dataset. This proposed classifier model is applied to five high-dimensional binary class datasets. It is observed that the proposed method yields higher classification accuracies in the case of three out of five high dimensional datasets with a reasonably small number of features.","","","10.1109/ICCTAC.2016.7567338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7567338","Correlation;Dimensionality Reduction;Feature selection;High Dimensional Dataset;Hybrid model;Machine Learning;Support Vector Machine","Classification algorithms;Computational modeling;Correlation;Feature extraction;Filtering algorithms;Mathematical model;Support vector machines","feature selection;pattern classification;support vector machines","K-features;SVM classifiers;classification accuracy;correlation based filter feature selection algorithm;high-dimensional binary class datasets;high-dimensional datasets;hybrid classification model;support vector machine","","","","","","","10-11 March 2016","","IEEE","IEEE Conference Publications"
"Use of Haar Features and Multi-Layer Perception to Support Connectivism","B. V. Thiyagarajan","P.I.C.T., Univ. of Pune, Pune, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","707","712","MOOCs have refined the way of teaching where the electronic devices can provide knowledge on the go, which says that knowledge is omnipresent. The connectivism is a technique where the knowledge is contained in the electronic media, which can be delivered as per the requirement. The use of Face detection with Haar based algorithms help to track the current status of the user and perform the teaching accordingly. The Multi-Layer Perception classifier is used to learn about the user attributes and provides the best teaching method to the user. These methods aim to deliver the knowledge completely and in the most effective form in which the user can comprehend. The major parts of the paper include Prediction, Face-Tracking, Face-Detection, Connectivism and ""Teach and Learn"". The use of multi-perception is for a dual purpose, which includes the training of the previous data and also includes the storage of the real-time data for future prediction purpose. This includes 4 teaching techniques for the students who are physically normal and 2 for the students who are visually impaired or deaf. Hence this proposed project could be a personal assistant for the students by tracking, teaching and also learning from the real-time.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546187","Haar wavelets;MOOCs;Machine Learning;Multi Layer-Perception;Object Detection;face detection","Algorithm design and analysis;Classification algorithms;Face;Feature extraction;Real-time systems;Training","Haar transforms;computer aided instruction;face recognition;image classification;multilayer perceptrons;object tracking;prediction theory;teaching","Haar features;MOOCs;connectivism;electronic devices;electronic media;face detection;face tracking;multilayer perception classifier;prediction purpose;teaching techniques","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Stem cell microscopic image segmentation using supervised normalized cuts","X. Huang; C. Li; M. Shen; K. Shirahama; J. Nyffeler; M. Leist; M. Grzegorzek; O. Deussen","Pattern Recognition Group, University of Siegen, Germany","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","4140","4144","A vast amount of toxicological data can be obtained from feature analysis of cells treated in vitro. However, this requires microscopic image segmentation of cells. To this end, we propose a new strategy, namely Supervised Normalized Cut Segmentation (SNCS), to segment cells that partially overlap and have a large amount of curved edges. SNCS approach is a machine learning based method, where loosely annotated images are used first to train and optimise parameters, and then the optimal parameters are inserted into a Normalized Cut segmentation process. Furthermore, we compare our segmentation results using SNCS to another four classical and two state-of-the-art methods. The overall experimental result shows the usefulness and effectiveness of our method over the six comparison methods.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7533139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533139","Image Segmentation;Machine Learning;Stem Cells;Supervised Normalized Cut","Biomedical imaging;Image edge detection;Image segmentation;Joining processes;Microscopy;Stem cells;Training","image segmentation;learning (artificial intelligence)","SNCS approach;feature analysis;machine learning based method;stem cell microscopic image segmentation;supervised normalized cut segmentation;supervised normalized cuts","","","","18","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Entity Linking of Artists Names in Japanese Music Articles","T. Urata; A. Maeda","Grad. Sch. of Inf. Sci. & Eng., Ritsumeikan Univ., Kusatsu, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","179","184","The opportunity to read music articles and blogs on the Web to get music information is more and more increasing. However, hyperlinks to artist information do not often exist in such articles, and it is a troublesome task for the reader to look it up online. In this paper, in order to make it easy to look up artist information in music articles, we propose a method to extract entities such as artist names in music articles in Japanese, and to perform entity linking which links from artist entities to artist information automatically. The method consists of two phases. First, we extract artist names in music articles. An artist name is a named entity, and it is necessary to distinguish artist names from other named entities, such as personal names of non-artists, place names, organization names, etc. In order to achieve it, we prepare training data of music articles in which artist names are manually tagged, and extract artist names using Support Vector Machine (SVM). Next, we choose a web page of artist information for each extracted artist name. We use Wikipedia as the source of artist information to verify the usefulness of the proposed method, we conducted evaluation experiments using cross-validation. For the experiments, we used 35 Japanese music articles and extracted artist names manually from the articles, and used them for cross-validation. We achieved the recall of 0.2788, precision of 0.7530, and F-measure of 0.4070. We also conducted an experiment to find correct artist information from Wikipedia using edit distance between extracted artist names from ten music articles and Wikipedia titles. We achieved the correct rate of 0.8740 in linking correct Wikipedia articles for artist names.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557599","Named entity extraction;machine learning","Electronic publishing;Encyclopedias;Feature extraction;Internet;Joining processes;Support vector machines","Internet;Web sites;music;support vector machines","Japanese music articles;SVM;Wikipedia;World Wide Web;artists names;blogs;entity linking;music information;support vector machine","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Orthogonalized coupled learning and application for face hallucination","T. Nagata; H. Maekawa; M. Suitani; H. Futada; K. Matsuzaki; A. Sano; T. Hagiwara; A. Hizukuri; H. Tomozawa","Information and Communication Research Division, Mizuho Information & Research Institute, Inc. (MHIR) Tokyo, Japan","2016 11th France-Japan & 9th Europe-Asia Congress on Mechatronics (MECATRONICS) /17th International Conference on Research and Education in Mechatronics (REM)","20160818","2016","","","058","063","We propose a new coupled learning method with high accuracy and high-speed, and apply to face hallucination and inspect its validity.","","Electronic:978-1-5090-1787-4; POD:978-1-5090-1788-1","10.1109/MECATRONICS.2016.7547116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547116","PCA;coupled learning;face hallucination;machine learning;super resolution","Active appearance model;Databases;Face;Facial features;Image resolution;Prediction algorithms;Principal component analysis","face recognition;learning (artificial intelligence)","face hallucination;orthogonalized coupled learning","","","","","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"Affective-feature-based sentiment analysis using SVM classifier","F. Luo; C. Li; Z. Cao","School of Aerospace, Tsinghua University, Beijing, China","2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20160915","2016","","","276","281","Based on the methods of the traditional topic-based text classification, machine learning method was performed to the coarse-grained sentiment classification of reviews. Sentiment classification involved a lot of problems. In this paper, the sentiment Vector Space Model (s-VSM) was used for text representation to solve data sparseness. In addition, the critical issues of the sentiment classification, i.e. the selection of classification algorithms, the determination of feature selection method and the selection of feature dimension, are verified by experiments. Furthermore, in order to consider the entire corpus contribution of features and each category contribution of features, the feature selection method of Chi-square Difference between the Positive and Negative Categories (CDPNC) was proposed. It combined DF with CHI and had the better performance. Experiments showed that the Macro-F and Micro-F achieved 90.18% and 90.08% respectively.","","","10.1109/CSCWD.2016.7566001","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566001","Classification algorithm;Feature selection;Machine learning;Reviews;Sentiment classification","Algorithm design and analysis;Classification algorithms;Feature extraction;Learning systems;Sentiment analysis;Support vector machines;Training","feature selection;learning (artificial intelligence);pattern classification;sentiment analysis;support vector machines","CDPNC;SVM classifier;affective-feature-based sentiment analysis;category contribution;chi-square difference between the positive and negative categories;coarse-grained sentiment classification;corpus contribution;data sparseness;feature dimension selection;machine learning;s-VSM;sentiment vector space model;support vector machine;text representation;topic-based text classification","","","","","","","4-6 May 2016","","IEEE","IEEE Conference Publications"
"Body sensor networks for human activity recognition","G. Chetty; M. White","Faculty of ESTeM, University of Canberra, Australia","2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN)","20160915","2016","","","660","665","Body Sensor Networks aim to capture the state of the user and its environment by utilizing from information heterogeneous sensors, and allow continuous monitoring of numerous physiological signals, where these sensors are attached to the subject's body. This can be immensely useful in activity recognition for identity verification, health and ageing and sport and exercise monitoring applications. In this paper, the application of body sensor networks for automatic and intelligent daily activity monitoring for elderly people, using wireless body sensors and smartphone inertial sensors has been reported. The scheme uses information theory-based feature ranking algorithms and classifiers based on random forests, ensemble learning and lazy learning. Extensive experiments using different publicly available datasets of human activity show that the proposed approach can assist in the development of intelligent and automatic real time human activity monitoring technology for eHealth application scenarios for elderly, disabled and people with special needs.","","","10.1109/SPIN.2016.7566779","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566779","activity recognition;assisted living;body sensor;machine learning;smart phone","Databases;Decision trees;Intelligent sensors;Sensor phenomena and characterization;Smart phones","body sensor networks;gesture recognition;health care;learning (artificial intelligence)","automatic real time human activity monitoring technology;body sensor networks;eHealth application scenarios;ensemble learning;human activity recognition;information theory-based feature ranking algorithms;lazy learning;random forests;sensors;smartphone inertial sensors;wireless body sensors","","","","","","","11-12 Feb. 2016","","IEEE","IEEE Conference Publications"
"Online Unusual Behavior Detection for Temperature Sensor Networks","H. Zhao; S. X. D. Tan; H. Wang; H. B. Chen","Dept. of Electr. & Comput. Eng., Univ. of California, Riverside, Riverside, CA, USA","2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)","20160908","2016","","","59","62","In modern smart building climate control systems, accurate detection of unusual behavior in temperature sensors (outliers) can help reduce or prevent waste of energy consumption in a Heating, Ventilation and Air Conditioning (HVAC) system. In this work, we propose online learning-distance based outlier detection method. In the new method, we train and tune a multilayer neural network to learn a nonlinear distance function from historical building operation data and detect outliers according to the calculated distance. The online detection method is less computational expensive than the offline version. By gradually including new and drop old building operation record, the new method is capable to adjust the underlying distance function on-the-fly. The converging speed of the learned distance function and tuning difficulty of network training are also discussed. The proposed online outlier detection method can work in an unsupervised manner except requiring only one data-specific parameter. In the experiments of two simulated buildings, the data-specific parameter can be chosen from a relatively wide range, which allows less tuning effort, to achieve good online detection precision and recall.","","Electronic:978-1-4673-9039-2; POD:978-1-4673-9040-8","10.1109/ISVLSI.2016.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560173","machine learning;online detection;outlier detection;smart building","Buildings;Detectors;Intelligent sensors;Sensor systems;Temperature sensors;Training","HVAC;building management systems;learning systems;neurocontrollers;nonlinear functions;temperature sensors","HVAC system;data-specific parameter;energy consumption waste reduction;heating, ventilation and air conditioning system;multilayer neural network;nonlinear distance function;online learning-distance based outlier detection;online unusual behavior detection;smart building climate control systems;temperature sensor networks","","","","","","","11-13 July 2016","","IEEE","IEEE Conference Publications"
"Data reduction for bug triage using effective prediction of reduction order techniques","V. Govindasamy; V. Akila; G. Anjanadevi; H. Deepika; G. Sivasankari","Pondicherry Engineering College, India","2016 International Conference on Computation of Power, Energy Information and Commuincation (ICCPEIC)","20160901","2016","","","085","090","A large open source project consists of a wide range of bug reports. In open source project, bug reports are available and these reports can be modified by anyone. Bugs are software defects whose prediction is highly difficult. To detect the bugs, machine learning classifier has been proposed. It segregates the bug reports and developers and it learns the type of report suitable for each developer. Bug triage is the process of assigning the bug for the appropriate developer. The techniques include preprocessing, machine learning classifier, instance selection and feature selection. The aim of this paper is to attain a data set reduction in bug triage by including the representative values along with the statistical values of the bug data set. Our work considers the dataset from the open source project Eclipse. We focus on reducing the data scale and thereby improving the accuracy. This can be achieved by building a representative model for prediction of reduction orders by including the summary, metadata. Our proposed work attains an accuracy result of 96.5% that is better when compared with existing work.","","CD-ROM:978-1-5090-0900-8; Electronic:978-1-5090-0901-5; POD:978-1-5090-0902-2","10.1109/ICCPEIC.2016.7557229","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557229","Open source projects;feature selection;instance selection;machine learning classifier;representative values;selection techniques","Classification algorithms;Computer bugs;Data models;Filtering algorithms;Ions;Predictive models;Software","data reduction;feature selection;learning (artificial intelligence);meta data;pattern classification;program debugging;public domain software;statistical analysis","Eclipse;bug data set;bug reports;bug triage;data set reduction;feature selection;instance selection;large open source project;machine learning classifier;metadata;reduction order prediction;representative values;software defects;statistical values","","","","","","","20-21 April 2016","","IEEE","IEEE Conference Publications"
"Multimodal transport model: Enhancing collaboration among mobility sharing schemes by identifying an optimal transit station","T. S. L. Prashanth; A. K. Tamilselvan; S. Chandrodaya","Oracle, JP Nagar, Bengaluru, Karnataka - 560076, India","2016 International Conference on Internet of Things and Applications (IOTA)","20160908","2016","","","286","291","In order to return urban places to people and create more livable cities, establishing a sustainable, environment-friendly transport system is the need of the hour. Mobility sharing schemes, particularly via public transport systems, are known to reduce traffic congestion by removing a large set of social vehicles occupying the road. The impact of mobility sharing can be enhanced by enabling effective collaboration among different schemes. However, for seamless integration of public transport vehicles into urban transport fabric, dissemination of real-time information concerning vehicle arrivals and their future availability is essential. In this paper, a new model is proposed to facilitate effective collaboration among mobility schemes involving public and private vehicles by forming a multi-modal transport network. The proposed approach identifies a single transit station along the passenger's trajectory which could be used to switch to a public transport vehicle going towards the desired destination. Machine learning algorithms like SVR and ANN are employed to predict arrival times, availability and associated waiting times of buses at each transit station along the route aiding this selection. The proposed model was applied on a comprehensive archived traffic data set and its performance in predicting various parameters was evaluated by comparing the estimated values against the actual ground-truth data.","","","10.1109/IOTA.2016.7562739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562739","bus arrival time prediction;intelligent Transport Systems;machine learning;mobility sharing;multimodal transport;public transport system;traffic congestion","Artificial neural networks;Automobiles;Autoregressive processes;Data models;Predictive models;Support vector machines","learning (artificial intelligence);neural nets;public transport;regression analysis;support vector machines;traffic engineering computing","ANN;SVR;arrival times prediction;artificial neural network;availability prediction;machine learning algorithms;mobility scheme collaboration;mobility sharing schemes;multimodal transport model;private vehicles;public transport vehicle;support vector regression;transit station identification;waiting times prediction","","","","","","","22-24 Jan. 2016","","IEEE","IEEE Conference Publications"
"Emotion estimation from EEG signals during listening to Quran using PSD features","M. Alsolamy; A. Fattouh","Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia","2016 7th International Conference on Computer Science and Information Technology (CSIT)","20160825","2016","","","1","5","Emotions play an important role in our thinking and behavior and hence contribute in shaping up of our personality. Many theoretical and experimental researches have been conducted to recognize the emotions from verbal or non-verbal behaviors. It is well known that the electroencephalogram (EEG) signals contain rich information about the activities of the brain and they can reliably enable us to estimate the emotions if they are properly interpreted. In this paper, we propose a model to discriminate the emotional state of a person by analyzing his brain signals recorded during listening to the Quran and using a machine learning approach. It is assumed that listening to the Quran brings reverence, and hence two types of emotions emerge which are distinguished as happy and unhappy. In our analysis, we used the Power Spectral Density (PSD) of different bands as features and the Support Vector Machine (SVM) as a classifier. Experiments were conducted by 14 participants and they gave a classification accuracy rate 85.86%.","","Electronic:978-1-4673-8914-3; POD:978-1-4673-8915-0","10.1109/CSIT.2016.7549457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549457","EEG;emotion recognition;machine learning;power spectral density (PSD);support vector machine (SVM)","Brain modeling;Electroencephalography;Emotion recognition;Mathematical model;Speech;Speech recognition;Support vector machines","behavioural sciences computing;electroencephalography;emotion recognition;learning (artificial intelligence);psychology;signal classification;spectral analysis;support vector machines","EEG signals;PSD features;Quran;SVM classifier;brain signal analysis;electroencephalogram signals;emotion estimation;emotional state discrimination;happy;machine learning;power spectral density;reverence;support vector machine;unhappy","","","","","","","13-14 July 2016","","IEEE","IEEE Conference Publications"
"Learning Representation for fMRI Data Analysis Using Autoencoder","S. Kamonsantiroj; P. Charoenvorakiat; L. Pipanmaekaporn","Dept. of Comput. & Inf. Sci., King Mongkut's Univ. of Technol., Bangkok, Thailand","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","560","565","Analysis of fMRI data is very useful for studying relationship between neural activity and a variety of brain functions. For many years, a number of brain image analysis techniques using machine learning were proposed. However, this task is still challenging due to the unique characteristics of the brain data with very small samples but extremely high dimensionality, reducing generalization performance. This paper presents a novel analysis method for fMRI data. It consists of three major steps: (1) Identifying informative voxels, (2) extracting feature space by analyzing semantic relationships among voxels and (3) learning fMRI classifier from the extracted features. Preliminary experimental results conducted on the task of image prediction from fMRI data confirmed that the proposed method achieves improvements of classification accuracy more than 20% in mean accuracy in comparing with current neuroimaging methods.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557675","Autoencoder;Brain Image Analysis;Machine learning;Semantic Feature Extraction;fMRI","Biological neural networks;Feature extraction;Indexes;Neurons;Semantics;Training;Transforms","biomedical MRI;brain;learning (artificial intelligence);medical image processing;neurophysiology","autoencoder;brain functions;brain image analysis;fMRI data analysis;learning representation;machine learning;neural activity;neuroimaging","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Predicting medical subject headings based on abstract similarity and citations to MEDLINE records","A. K. Kehoe; V. I. Torvik","Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, Champaign, IL, USA","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","167","170","We describe a classifier-enhanced nearest neighbor approach to assigning Medical Subject Headings (MeSH<sup>®</sup>) to unlabeled documents using a combination of abstract similarities and direct citations to labeled MEDLINE records. The approach frames the classification problem by decomposing it into sets of siblings in the MeSH hierarchy (e.g., training a classifier for predicting “Heterocyclic Compounds, 2-Ring” vs. other “Heterocyclic Compounds”). Preliminary experiments using a small but diverse set of MeSH terms shows the highest performance when using both abstracts and citations compared to each alone, and coupled with a non-naive classifier: 90+% precision and recall with 10-fold cross-validation. NLM's Medical Text Indexer (MTI) tool achieves similar overall performance but varies more across the terms tested. For example, MTI performs better on “Heterocyclic Compounds, 2-Ring”, while our approach performs better on Alzheimer Disease and Neuroimaging. Our approach can be applied broadly to documents with abstracts that are similar to (or cite) MEDLINE abstracts, which would help linking and searching across bibliographic databases beyond MEDLINE.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559580","Controlled vocabularies;Curation of bibliographic databases;Machine Learning;Medical subject headings","Biomedical imaging;Compounds;Dementia;Libraries;Neuroimaging","bibliographic systems;citation analysis;diseases;indexing;medical computing;pattern classification","Alzheimer disease;MEDLINE records;MTI tool;MeSH hierarchy;abstract similarity;bibliographic databases;classifier-enhanced nearest neighbor approach;direct citations;medical subject headings;medical text indexer tool;neuroimaging","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Design and testing tool for a safe monitoring system for neurodegenerative disorder patients","N. E. Halabi; R. Achkar; R. A. Z. Daou; A. Hayek; J. Börcsök","Department of Computer and Communications Engineering, Faculty of Engineering, American University of Science and Technology, Beirut, Lebanon","2016 3rd International Conference on Advances in Computational Tools for Engineering Applications (ACTEA)","20160905","2016","","","172","177","This paper aims to develop a sensor based monitoring and analyzing system for Neuro-Degenerative Disorder patients (NDD); this may consist on SpO2 sensor, Electrophysiological sensors, NIBP, Motion Capture sensors and Eye Monitoring sensor, taking into consideration an acceptable cost for the whole system. Recorded data will be sent to an embedded decision making unit where detection, analysis, classification, prediction and action control will occur. The sensors and the decision making unit will be implemented in a comfortable jacket that doesn't affect the patients' movements and that can be used by several patients with reduced sensor placement alterations. The decision that can be made is creating a stimulus to avoid falling in case of sudden stop while moving, initiating an alarm, sending a notification to a mobile phone application, and/or telemedicine monitoring features. Artificial Neural Networks will be used to classify and predict the abnormal cases where action should be taken, and since the sensors will be continuously recording, it is possible to achieve continuous learning for the ANN as a first phase. Initial models will be defined by testing normal behaviors and some known abnormal behaviors or symptoms related to the electrical activity and other characteristics of the heart, oxygen saturation level, eye activity and body motion.","","Electronic:978-1-4673-8523-7; POD:978-1-4673-8524-4","10.1109/ACTEA.2016.7560134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560134","Artificial Neural Networks;Biomedical-based sensors;Neuro-Degenerative disease;Smart Wearable Sensors;machine learning;statistical methodologies","Alzheimer's disease;Artificial neural networks;Biomedical monitoring;Decision making;Monitoring;Parkinson's disease","bioelectric phenomena;biomechanics;eye;intelligent sensors;medical disorders;neural nets;neurophysiology;patient monitoring;telemedicine","NIBP;SpO2 sensor;artificial neural networks;body motion;decision making unit;electrical activity;electrophysiological sensor;eye activity;eye monitoring sensor;heart characteristics;mobile phone application;motion capture sensors;neurodegenerative disorder patient;oxygen saturation level;patient movement;reduced sensor placement alteration;safe monitoring system;sensor-based monitoring;sudden stop;telemedicine monitoring feature","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Shore-based microstructural indices: do they tell us more?","A. Mendez; S. Obertino; G. Menegaz","University of Verona, Department of Computer Science, Italy","2016 International Workshop on Pattern Recognition in Neuroimaging (PRNI)","20160901","2016","","","1","4","Recent methods for diffusion weighted magnetic resonance convey information about tissue microstructure. In the last years, many models have been proposed for recovering the diffusion signal and extracting information to constitute new families of microstructural indices. Here we focus on three leading diffusion MRI models: NODDI (Neurite Orientation Dispersion and Density Imaging), 3D-SHORE (3D Simple Harmonic Oscillator-based Reconstruction and Estimation) and its formulation in the Cartesian space, the MAPMRI (Mean Apparent Propagator MRI) and analyze the information conveyed by the respective set of indices based on information-theoretic measures. This will allow to objectively assess the ability of each index of capturing microstructural features and thus to shed light on their exploitability in discriminative tasks. To this end, the microstructural descriptors are treated as machine learning features and analyzed via information-theoretic methods. First results on in-vivo data suggest that 3D-SHORE and MAPMARI could be more eloquent in describing microstructure and that a combination of descriptors obtained from all models may provide the best subset of features for a classification task.","","Electronic:978-1-4673-6530-7; POD:978-1-4673-6531-4","10.1109/PRNI.2016.7552343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552343","Diffusion MRI;Machine Learning;micro-structural models","Biological system modeling;Dispersion;Image reconstruction;Magnetic resonance imaging;Numerical models;Redundancy;Solid modeling","biomedical MRI;harmonic oscillators;image classification;image reconstruction;information theory;learning (artificial intelligence);medical image processing","3D simple harmonic oscillator-based reconstruction and estimation;3D-SHORE;Cartesian space;MAPMRI;NODDI;classification task;diffusion MRI models;diffusion signal;diffusion weighted magnetic resonance;discriminative tasks;information-theoretic measures;machine learning features;mean apparent propagator MRI;microstructural features;microstructural indices;neurite orientation dispersion and density imaging;shore-based microstructural indices;tissue microstructure","","","","","","","22-24 June 2016","","IEEE","IEEE Conference Publications"
"Fast brain decoding with random sampling and random projections","A. Hoyos-Idrobo; G. Varoquaux; B. Thirion","Parietal team, INRIA, CEA, University Paris-Saclay, France","2016 International Workshop on Pattern Recognition in Neuroimaging (PRNI)","20160901","2016","","","1","4","Machine learning from brain images is a central tool for image-based diagnosis and diseases characterization. Predicting behavior from functional imaging, brain decoding, analyzes brain activity in terms of the behavior that it implies. While these multivariate techniques are becoming standard brain mapping tools, like mass-univariate analysis, they entail much larger computational costs. In an time of growing data sizes, with larger cohorts and higher-resolutions imaging, this cost is increasingly a burden. Here we consider the use of random sampling and projections as fast data approximation techniques for brain images. We evaluate their prediction accuracy and computation time on various datasets and discrimination tasks. We show that the weight maps obtained after random sampling are highly consistent with those obtained with the whole feature space, while having a fair prediction performance. Altogether, we present the practical advantage of random sampling methods in neuroimaging, showing a simple way to embed back the reduced coefficients, with only a small loss of information.","","Electronic:978-1-4673-6530-7; POD:978-1-4673-6531-4","10.1109/PRNI.2016.7552350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552350","High-dimensional estimators;Nystrom;brain imaging;machine learning","Brain;Decoding;Face;Kernel;Logistics;Support vector machines;Visualization","approximation theory;brain;diseases;learning (artificial intelligence);medical image processing;random processes;sampling methods","brain decoding;brain image;brain mapping tool;data approximation technique;disease characterization;functional imaging;image-based diagnosis;machine learning;mass-univariate analysis;multivariate technique;neuroimaging;random projection;random sampling","","","","","","","22-24 June 2016","","IEEE","IEEE Conference Publications"
"Relationships between classical factors, social factors and box office collections","V. Biramane; H. Kulkarni; A. Bhave; P. Kosamkar","Dept. of Computer Engg., MIT, Pune","2016 International Conference on Internet of Things and Applications (IOTA)","20160908","2016","","","35","39","Every year the number of movie produced and released surpass the previous year's count and so do the total box office collections. So in this quality centric industry, it becomes imperative that the movie succeeds both in terms of box office collections and critical reviews and also renders profit. Due to advent of predictive analytics and big data generated through various social interactions, models to predict accurately the total gross of a movie can be devised, which eventually help the movie studio by giving constructive feedback both in pre-production and post-production phase. So the availability of this data gathered from various social platforms like IMDb, YouTube and Wikipedia can help to gauge the society's reaction and response towards a particular movie. It can also foretell a society's anticipation towards a particular movie. In this paper, we have built predictive models by establishing links between classical features, social media features and the overall success of the movie which includes total box office collection and the critics rating or review. The results show that the prediction model built using integration of classical as well as social factors can achieve higher accuracy rate.","","","10.1109/IOTA.2016.7562691","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562691","Box office gross;Critical review;Data Mining;Machine learning;Movie;Movie success;Predictive analytics;Rating","Electronic publishing;Encyclopedias;Internet;Media;Motion pictures;Predictive models","Big Data;entertainment;social networking (online);social sciences computing","big data;box office collections;classical factors;movie production;predictive analytics;quality centric industry;social factors;social media features;social platforms;society response","","","","","","","22-24 Jan. 2016","","IEEE","IEEE Conference Publications"
"Bayesian Mechanisms and Detection Methods for Wireless Network with Malicious Users","A. K. Chorppath; T. Alpcan; H. Boche","Institute of Theoretical Information Technology, Munich University of Technology, Munich, Germany","IEEE Transactions on Mobile Computing","20160830","2016","15","10","2452","2465","Strategic users in a wireless network cannot be assumed to follow the network algorithms blindly. Moreover, some of these users aim to use their knowledge about network algorithms to maliciously gain more resources and also to create interference to other users. We consider a scenario, in which the network and legitimate users gather probabilistic information about the presence of malicious users by observing the network over a long time period. The network (mechanism designer) and legitimate users modify their actions according to this Bayesian information. We consider Bayesian mechanisms, both pricing schemes and auctions, and obtain the Bayesian Nash Equilibrium (BNE) points. The BNE points provide conditions under which, the uncertainty about user's nature (type) is better for regular (legitimate) users. To derive these conditions, we compare the Bayesian case to the complete information case. We obtain the optimal prices and allocations, which counter the malicious users. We also provide detection methods based on machine learning algorithms for the detection of malicious users, by observing the prices and rate allocations. In addition, we provide detection using regression learning by observing the anomalies in the utility functions of malicious users from prices, which is implemented along with the pricing mechanism itself. For the designer and the regular users, in a complementary fashion, the results of the detections provide a better estimate of the statistics of malicious users to implement the pricing mechanisms. We have also proposed a truthful Bayesian mechanism in the presence of malicious users. The numerical studies for malicious user detection are carried out with the model proposed in the paper as well as using real Botnet dataset.","1536-1233;15361233","","10.1109/TMC.2015.2505724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347429","Bayesian games;Wireless network layer security;game theory;jamming;machine learning;mechanism design","Bayes methods;Interference;Jamming;Pricing;Resource management;Uncertainty;Wireless networks","Bayes methods;computer network security;game theory;invasive software;learning (artificial intelligence);pricing;radio networks;radiofrequency interference;regression analysis","BNE points;Bayesian Nash equilibrium point;Bayesian mechanism;detection method;machine learning algorithm;malicious user;malicious user detection;pricing scheme;real Botnet dataset;regression learning;wireless network","","","","","","20151204","Oct. 1 2016","","IEEE","IEEE Journals & Magazines"
"Can you learn it? Probably! Developing learning analytics tools in R","G. M. Di Nunzio","Department of Information Engineering, University of Padua Via Gradenigo 6/a, 35131 Padua, Italy","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","213","214","Automatic text categorization is an effective way to organize large text datasets in Digital Libraries (DL). However, most of the available machine learning tools are complex and go beyond the scope of what a digital library curator need or is able to do in order to classify the objects of a DL. Drawing inspiration from the field of Learning Analytics and Interactive Machine Learning, we design and implement visual interactive classifiers that are intuitive to train and easy to use. In this poster, we present an interactive Web application in R that allows users to use text classifier in an innovative way. The source code of the application is available at the following link: https://github.com/gmdn/educational-data-mining.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559590","Automated Text Classification;Interactive Machine Learning;Learning Analytics;Naïve Bayes;R programming","Data visualization;Libraries;Niobium;Probabilistic logic;Programming;Text categorization;Visualization","digital libraries;learning (artificial intelligence);pattern classification;text analysis","automatic text categorization;digital libraries;interactive machine learning;large text datasets;learning analytics tools;text classifier;visual interactive classifiers","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Early Experiences in Using Blood Cells Biomembranes as Markers for Diabetes Diagnosis","E. Cordelli; G. Pani; D. Pitocco; G. Maulucci; P. Soda","Dept. of Eng., Univ. Campus Bio-Medico di Roma, Rome, Italy","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","197","202","Investigation of membrane fluidity by two photon fluorescence microscopy opens up a new and important area of translational research, being a useful and sensitive method for disease monitoring and treatment. In this paper we investigate if biomembranes in human red blood cells (RBC) and peripheral mononuclear cells (PMC) could be used as markers for type 1 diabetes mellitus (T1DM) diagnosis, leading to the development of a method for monitoring T1DM progression that nowadays is lacking, as clinical exams cannot pursue this task with enough reliability. To this aim, we present a set of features computed from PMC and RBC images that are given to a multi-experts system leveraging on multi-spectral information for positive/negative classifications. The experiments are carried out on a dataset of 800 blood cell images belonging to 18 subjects adopting the leave-one-person-out approach.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545984","Feature extraction;Image processing;Machine learning;Two photon microscopy;Type 1 Diabetes","Biomembranes;Blood;Cells (biology);Diseases;Monitoring;Principal component analysis;Training","biomembranes;diseases;medical image processing;patient diagnosis","PMC image;RBC image;T1DM progression;blood cells biomembrane;clinical exam;diabetes diagnosis;disease monitoring;disease treatment;human red blood cells;leave-one-person-out approach;membrane fluidity;multiexperts system;multispectral information;peripheral mononuclear cells;photon fluorescence microscopy;positive-negative classification;type 1 diabetes mellitus","","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"A top web security vulnerability SQL injection attack — Survey","J. Abirami; R. Devakunchari; C. Valliyammai","Dept. of Computer Technology, Madras Institute of Technology, Anna University, Chennai","2015 Seventh International Conference on Advanced Computing (ICoAC)","20160908","2015","","","1","9","Online services serve today's basic needs of people in this modern internet era. This internet based services make use of huge volumes of data for their processing. Social media is another interaction media through which huge volumes of data are stored on a daily basis. These data have to be stored in databases. SQL queries provide a mean for accessing, modifying and retrieval of data from databases. If an attacker finds a way in modifying queries with unauthorized access, the evidence of data for future purposes is under danger. Such SQL injection attack is found to be predominant in web applications. Such an attack has to be mitigated and addressed soon for protecting the huge data. The survey reveals the importance of data and effects of SQL Injection attack over data and the techniques involving its detection and prevention.","","","10.1109/ICoAC.2015.7562806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562806","Detection techniques;Machine Learning;SQL Injection attack","Access control;Authentication;Databases;Internet;Media;Runtime","SQL;Web services;authorisation;data protection;social networking (online)","Internet based services;SQL queries;Web security vulnerability SQL injection attack;data protection;online services;social media;unauthorized access","","","","","","","15-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"Towards automatic assessment of compulsive hoarding from images","A. Tooke; J. Konrad; J. Muroff","Department of Electrical and Computer Engineering, Boston University, Boston, MA 02215","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1324","1328","Hoarding is a complex and impairing psychiatric disorder and a public health problem. Traditionally it is assessed through observation and interview, but recently a new method has been proposed where living quarters of an individual are visually compared with a set of template images ranked according to the “Clutter Image Rating” (CIR) scale from 1 to 9. However, such an assessment is time-consuming, subjective, and weak in repeatability. We propose an automatic method for classifying hoarding images according to the CIR scale. Since clutter in living quarters (e.g., piles of boxes, newspapers, clothing) corresponds to “busy” areas with lots of edges in captured images, we use the histogram-of-gradients (HOG) descriptor to characterize images and estimate the CIR value using two methods: regression and classification. In 4-fold cross-validation on 620 images that we harvested from the internet, both methods result in mean-absolute CIR error of about 1.2. Given the simplicity of our method, this is an encouraging result as it approximates ratings by trained professionals who admit assigning CIR values within ± 1 CIR point.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532573","Compulsive hoarding assessment;HOG;SVM;machine learning;object clutter","Clothing;Clutter;Estimation;Image edge detection;Public healthcare;Static VAr compensators;Support vector machines","image classification;psychology;regression analysis","4-fold cross-validation;CIR scale;HOG descriptor;clutter image rating;compulsive hoarding automatic assessment;histogram-of-gradients descriptor;hoarding image classification;impairing psychiatric disorder;public health problem;regression","","","","16","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"NILC: A two level learning algorithm with operator selection","I. S. Montagner; N. S. T. Hirata; R. Hirata; S. Canu","Institute of Mathematics and Statistics, University of Sao Paulo, Sao Paulo, Brazil","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1873","1877","Machine learning is a very promising way of solving some image processing tasks. However, existing approaches fails at integrating feature selection within the learning task. This paper introduces a new two stage learning algorithm called near infinitely linear combination (NILC) that performs at the same time variable selection and error minimization. Empirical evidence reported on different document processing tasks shows that our approach significantly outperforms existing approaches.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532683","Window determination;image operator learning;image processing;machine learning","Computational efficiency;Estimation;Image processing;Manuals;Minimization;Optimization;Training","document image processing;feature selection;learning (artificial intelligence)","NILC;document processing;error minimization;feature selection;image processing;learning algorithm;machine learning;near infinitely linear combination;operator selection;time variable selection","","","","15","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"A neural decision forest scheme with application to EMG gesture classification","D. Rodriguez; A. Piryatinska; X. Zhang","Department of Mathematics, San Francisco State University, San Francisco, CA 94132","2016 SAI Computing Conference (SAI)","20160901","2016","","","243","252","Herein presents a novel neural decision forest by bootstrap aggregating randomized neural decision trees with the purpose of untangling signal data representations and performing heirarchical classification. The individual trees in a neural decision forest embed randomized neural networks (rNet) with 1-hidden layer acting as bottlenecks and hard gating functions. The rNets are trained using a multi-class exchange method with l<sub>2</sub>-regularization to sparsify the networks. By applying a projection map prior to each rNet input layer, a novel method to randomly window a vectorized tensor of electromyogram (EMG) signals recorded from hand gestures is attained. These random windows show the promise of greatly simplifying and generalizing the process of feature extraction. Neural decision forests prevent overfitting and the inability of single trees to generalize to new variations by bootstrap sampling the training set, controling the rNet convergence rates, and increasing the forest size. The key findings in three gesture classification experiments are: i) neural decision forests with random windows outperform the random forest algorithm in terms of accuracy measures in personalized gestures by as much as 20% with equal tree sizes, ii) neural decision forests outperform random forests in intra-subject classification discriminating 27 gestures on 4 out of 5 people, and iii) neural decision forests are competitive with random forests in discriminating 7 gestures recorded with a low sampling rate.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7555990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555990","artificial intelligence;artificial limb;biocontrol;decision trees;electromyography;gesture classification;handsfree devices;machine learning;neural decision forests;neural networks;neural tree;pattern recognition;representation learning;signal processing","Biological neural networks;Decision trees;Electromyography;Feature extraction;Training;Vegetation","convergence;decision trees;electromyography;feature extraction;medical signal processing;neural nets;signal classification;signal sampling;tensors;vectors","EMG gesture classification;EMG signal vectorized tensor;bootstrap sampling;electromyogram signal vectorized tensor;feature extraction;gesture classification;hard gating functions;l<sub>2</sub>-regularization;multiclass exchange method;neural decision forest embed rNet;neural decision forest embed randomized neural networks;neural decision forest scheme;rNet convergence rates;random forest algorithm;randomized neural decision trees;untangling signal data representations","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"CASH: Supporting IaaS Customers with a Sub-core Configurable Architecture","Y. Zhou; H. Hoffmann; D. Wentzlaff","Electr. Eng. Dept., Princeton Univ., Princeton, NJ, USA","2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)","20160825","2016","","","682","694","Infrastructure as a Service (IaaS) Clouds have grown increasingly important. Recent architecture designs support IaaS providers through fine-grain configurability, allowing providers to orchestrate low-level resource usage. Little work, however, has been devoted to supporting IaaS customers who must determine how to use such fine-grain configurable resources to meet quality-of-service (QoS) requirements while minimizing cost. This is a difficult problem because the multiplicity of configurations creates a non-convex optimization space. In addition, this optimization space may change as customer applications enter and exit distinct processing phases. In this paper, we overcome these issues by proposing CASH: a fine-grain configurable architecture co-designed with a cost-optimizing runtime system. The hardware architecture enables configurability at the granularity of individual ALUs and L2 cache banks and provides unique interfaces to support low-overhead, dynamic configuration and monitoring. The runtime uses a combination of control theory and machine learning to configure the architecture such that QoS requirements are met and cost is minimized. Our results demonstrate that the combination of fine-grain configurability and non-convex optimization provides tremendous cost savings (70% savings) compared to coarse-grain heterogeneity and heuristic optimization. In addition, the system is able to customize configurations to particular applications, respond to application phases, and provide near optimal cost for QoS targets.","1063-6897;10636897","Electronic:978-1-4673-8947-1; POD:978-1-4673-8948-8","10.1109/ISCA.2016.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551432","Configurable Architectures;Control System;Machine Learning;Manycore Architectures","Convex functions;Multicore processing;Optimization;Quality of service;Resource management;Runtime","cloud computing;concave programming;learning (artificial intelligence);reconfigurable architectures;resource allocation","ALU;CASH;IaaS clouds;IaaS customers;L2 cache banks;QoS requirements;control theory;cost minimization;cost savings;cost-optimizing runtime system;fine-grain configurability;fine-grain configurable architecture;fine-grain configurable resources;hardware architecture;infrastructure as a service;low-level resource usage;machine learning;nonconvex optimization;quality-of-service requirements;subcore configurable architecture","","1","","","","","18-22 June 2016","","IEEE","IEEE Conference Publications"
"Transfer String Kernel for Cross-Context DNA-Protein Binding Prediction","R. Singh; J. Lanchantin; G. Robins; Y. Qi","Department of Computer Science, University of Virginia, Charlottesville VA, 22903. (E-mail: rs3zz@virginia.edu)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2016","PP","99","1","1","Through sequence-based classification, this paper tries to accurately predict the DNA binding sites of transcription factors (TFs) in an unannotated cellular context. Related methods in the literature fail to perform such predictions accurately, since they do not consider sample distribution shift of sequence segments from an annotated (source) context to an unannotated (target) context. We, therefore, propose a method called “Transfer String Kernel” (TSK) that achieves improved prediction of transcription factor binding site (TFBS) using knowledge transfer via cross-context sample adaptation. TSK maps sequence segments to a high-dimensional feature space using a discriminative mismatch string kernel framework. In this high-dimensional space, labeled examples of the source context are re-weighted so that the revised sample distribution matches the target context more closely. We have experimentally verified TSK for TFBS identifications on fourteen different TFs under a cross-organism setting. We find that TSK consistently outperforms the state-of-the-art TFBS tools, especially when working with TFs whose binding sequences are not conserved across contexts. We also demonstrate the generalizability of TSK by showing its cutting-edge performance on a different set of cross-context tasks for the MHC peptide binding predictions.","1545-5963;15455963","","10.1109/TCBB.2016.2609918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569028","Bioinformatics;Domain Adaptation;Machine Learning;String Classification;String Kernel;Support Vector Machines","Bioinformatics;Context;DNA;Genomics;Kernel;Proteins;Support vector machines","","","","","","","","20160915","","","IEEE","IEEE Early Access Articles"
"A Learning-Based Approach to Secure JTAG Against Unseen Scan-Based Attacks","X. Ren; R. D. Blanton; V. G. Tavares","Fac. of Eng., Univ. of Porto, Porto, Portugal","2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)","20160908","2016","","","541","546","Security is becoming an essential problem for integrated circuits (ICs). Various attacks, such as reverse engineering and dumping on-chip data, have been reported to undermine IC security. IEEE 1149.1, also known as JTAG, is primarily used for IC manufacturing test but inevitably provides a ""backdoor"" that can be exploited to attack ICs. Encryption has been used extensively as an effective mean to protect ICs through authentication, but a few weaknesses subsist, such as key leakage. Signature-based techniques ensure security using a database that includes known attacks, but fail to detect attacks that are not contained by the database. To overcome these drawbacks, a two-layer learning-based protection scheme is proposed. Specifically, the scheme monitors the execution of JTAG instructions and uses support vector machines (SVM) to identify abnormal instruction sequences. The use of machine learning enables the detection of unseen attacks without the need for key-based authentication. The experiments based on the OpenSPARC T2 platform demonstrate that the proposed scheme improves the accuracy of detecting unseen attacks by 50% on average when compared to previous work.","","Electronic:978-1-4673-9039-2; POD:978-1-4673-9040-8","10.1109/ISVLSI.2016.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560255","Hardware Security;JTAG;Machine Learning;Support Vector Machines","Authentication;Integrated circuit modeling;Real-time systems;Support vector machines;System-on-chip","IEEE standards;cryptography;electronic engineering computing;integrated circuit testing;learning (artificial intelligence);support vector machines","IC manufacturing;IC security;IEEE 1149.1;JTAG instructions;JTAG security;OpenSPARC T2 platform;SVM;abnormal instruction sequence identification;dumping on-chip data;integrated circuits;machine learning;signature-based techniques;support vector machines;two-layer learning-based protection;unseen attack detection accuracy;unseen scan-based attacks","","","","","","","11-13 July 2016","","IEEE","IEEE Conference Publications"
"Spatio–Temporal Clustering and Active Learning for Change Classification in Satellite Image Time Series","N. Débonnaire; A. Stumpf; A. Puissant","Laboratoire Image, Ville, Environnement, Centre National de la Recherche Scientifique UMR 7362, University of Strasbourg, Strasbourg, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20160830","2016","9","8","3642","3650","Active learning (AL) has emerged as a versatile approach to reduce the training data required for remote sensing image classification, but its use for the analysis of satellite image time series (SITS) has not been explored yet. This study targets to explore a new object-based framework for change detection in SITS, combining the state-of-the-art spatio-temporal clustering and the use of different machine learning algorithms. Indeed, this study aims at testing whether standard machine learning algorithms can detect changes in long time series and whether AL can improve the results compared to traditional supervised learning. The tested AL algorithms comprise random forest-based heuristics that use a combination of uncertainty and diversity criteria, and a classical SVM breaking ties heuristic. The different implementations are evaluated with two datasets that depict changes around the Arcachon basin (West of France) and around the city of Colmar (East of France) spanning over more than 20 years and comprising four change classes (urban sprawl, forest gain, forest loss, and other). The tests demonstrate that steeper learning curves can be obtained with AL when compared to supervised learning. However, the performance of different AL algorithms depends on the dataset.","1939-1404;19391404","","10.1109/JSTARS.2016.2525940","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429700","Image classification;machine learning;satellite time series analysis;spatio–temporal clustering","Entropy;Feature extraction;Radio frequency;Remote sensing;Satellites;Time series analysis;Training","forestry;geophysical image processing;image classification;land cover;land use;learning (artificial intelligence);pattern clustering;remote sensing;support vector machines;time series","Arcachon basin change;Colmar;SVM;active learning;change detection;eastern France;forest gain;forest loss;machine learning algorithm;random forest-based heuristics;remote sensing image classification;satellite image time series;spatiotemporal clustering;urban sprawl;western France","","","","","","20160309","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Border crossing data acquisition, analysis, and use","W. Lese; P. Rawat","LOGITCON Stafford, VA, USA","2016 IEEE Symposium on Technologies for Homeland Security (HST)","20160915","2016","","","1","6","The centerpiece of the legacy system was the system to capture the identifying information of a traveler and private vehicles, forward to a central processing facility, and obtain the guidance on whether the subject should be admitted. Surveillance cameras, fingerprint scanners, RFID tag readers, and license plate readers did generate additional data but it maintained its own identity. Looking at this operation from an IoT (Internet of Things) lens, and taking account of the latest technology, it seems necessary and desirable to integrate the data sources to make sure that the perspective that decision makers need is based on a complete picture of the situation - not just whether the traveler or a vehicle is on the watch list. This paper looks at some of the issues and opportunities that appear to be worth considering. It is necessarily a cursory look presented in the hope that it will be of use as the thought process for such a project starts. These are strictly personal views of the authors who have no connection with any law-enforcement agency.","","","10.1109/THS.2016.7568898","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568898","AI;IoT;big-data;machine learning","Big data;Internet of things;Program processors;Sensors;Servers;Sparks;Surveillance","Big Data;Internet of Things;data acquisition;government data processing","Internet of Things;IoT;border control agency;data acquisition;private vehicle;traveler","","","","","","","10-11 May 2016","","IEEE","IEEE Conference Publications"
"Recent advances for handling imbalancement and uncertainty in labelling in medicinal chemistry data analysis","J. C. S. de Souza; S. G. Claudino; R. da Silva Simões; P. R. Oliveira; K. M. Honório","School of Arts, Science and Humanities, University of S&#x00E3;o Paulo","2016 SAI Computing Conference (SAI)","20160901","2016","","","217","222","The discovery of new drugs is a very important area of study in medicinal chemistry. Developing a drug is not an easy task, as much time and money are needed to undertake all steps required for the development and test of new drugs. Amid this context, chemoinformatics is the area that has the role of interfacing between chemistry and computing, assisting in the process of identifying potential new drugs, through machine learning techniques for classification. This article will present the difficulties of classification found in chemoinformatics and approach machine learning techniques that, applied in the context of chemoinformatics, assist in treating issues related to uncertainty in data labeling and unbalanced classes, as they are common problems when using data sets of a chemical nature.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7555985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555985","Classification;Imbalanced data;Machine learning methods;Uncertainty of labeling","Biology;Chemicals;Compounds;Drugs;Labeling;Uncertainty","chemistry computing;drugs;learning (artificial intelligence);medical computing;pattern classification","chemical nature data sets;chemoinformatic context;data labeling;drug development;drug discovery;drug test;machine learning techniques;medicinal chemistry data analysis;unbalanced classes","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Weather Monitoring Using Artificial Intelligence","T. R. V. Anandharajan; G. A. Hariharan; K. K. Vignajeth; R. Jijendiran; Kushmita","Velammal Inst. of Technol., Chennai, India","2016 2nd International Conference on Computational Intelligence and Networks (CINE)","20160901","2016","","","106","111","Weather forecasting is rather a statistical measure than a binary decision. We intend to develop an intelligent weather predicting module since this has become a necessary tool. This tool considers measures such as maximum temperature, minimum temperature and rainfall for a sampled period of days and are analyzed. An intelligent prediction based on the available data is accomplished using machine learning techniques. The analysis and prediction is based on linear regression which predicts the next day's weather with good accuracy. An accuracy of more than 90% is obtained, based on the data set. Recent studies have reflected that machine learning techniques achieved better performance than traditional statistical methods. Machine learning, a branch of artificial intelligence has been proved to be a robust method in predicting and analyzing a given data set. The module plays a vital role in agricultural, industrial and logistical fields where the weather forecast is an important criterion.","2375-5822;23755822","Electronic:978-1-5090-0451-5; POD:978-1-5090-0452-2","10.1109/CINE.2016.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556813","Artificial intelligence;Linear regression;Machine learning;Weather forecasting","Clouds;Cost function;Linear regression;Support vector machines;Training;Weather forecasting","data analysis;geophysics computing;learning (artificial intelligence);regression analysis;weather forecasting","agricultural fields;artificial intelligence;data set analysis;industrial fields;intelligent weather predicting module;linear regression;logistical fields;machine learning techniques;statistical measure;weather forecasting","","","","","","","11-11 Jan. 2016","","IEEE","IEEE Conference Publications"
"Method of Classification through Normal Distribution Approximation Using Estimating the Adjacent and Multidimensional Scaling","N. Kobayashi; T. Mihara; H. Shiina","Fac. of Human Sci., Sanyo Gakuen Univ., Okayama, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","128","133","A Two types of classification methods are applied performing classification using machine learning: (1) those for which there is a presumption of data distribution using kernel functions, such as in support vector machine (SVM) and (2) those for which data distribution is not presumed, such as the k-NN. With such methods, it is easy to obtain data whose values are close for the class as a whole. In addition, it is assumed that there is a high probability that data with close values apparently belong to the same class. In contrast, while it may be easy to obtain approximate values of data for each class, there exists a relatively high probability of approximate values manifesting as data of the same class. Consequently, there is a high probability of the same class of data appearing around the position of parameters of the data manifested in feature space where data parameters are obtained. This study proposes machine learning algorithms that approximates this using a density function of normal distribution. In addition, if small amounts of data of a different class exist where data of the same class is being collected, the impact of those classes will be significant. This study propose two types of algorithms. One is a method of calculating the influence of the proximity of the training data for the entire feature space calculates. The other is a method of calculating the effect on the entire feature space for each training data. Both methods utilize two parameters as the influence of each training data and the range to be used as neighborhood data. Two parameters determine the quasi-optimal solution by the steepest descent method. Furthermore, in order to reduce the density of the influence of the training data, we propose improved method that relocates the training data from the distance between the training data by multidimensional scaling as preprocessing.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557589","Classifiaction;Machine learning;Multidimensional scaling;Normal distribution","Approximation algorithms;Covariance matrices;Density functional theory;Gaussian distribution;Informatics;Support vector machines;Training data","approximation theory;estimation theory;gradient methods;learning (artificial intelligence);neural nets;normal distribution;pattern classification;probability;support vector machines","SVM;adjacent scaling estimation;classification methods;data distribution;data parameters;k-NN;kernel functions;machine learning;multidimensional scaling estimation;normal distribution approximation;normal distribution density function;probability;steepest descent method;support vector machine;training data proximity","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Utilization of unlabeled data for smartphone-robot localization","J. Yoo; H. J. Kim","Department of Mechanical and Aerospace, Seoul National University, Seoul, South Korea","2016 International Conference on Electronics, Information, and Communications (ICEIC)","20160908","2016","","","1","4","This paper studies an indoor localization for smartphone-based mobile robot. Due to the difficulty for collecting labeled training data in realistic applications, we propose the learning approach using only a small amount of labeled training data. The key aspect is the utilization of unlabeled data, by combining core concepts of pseudolabelling and time-series learning. The experimental result shows that the developed learning algorithm is the most accurate and robust to the varying number of training data, when compared with other state-of-the-art semi-supervised learning methods.","","Electronic:978-1-4673-8016-4; POD:978-1-4673-8017-1","10.1109/ELINFOCOM.2016.7562982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562982","localization;machine learning;smartphone-robot","Algorithm design and analysis;Estimation;IEEE 802.11 Standard;Laplace equations;Robots;Semisupervised learning;Training data","control engineering computing;indoor navigation;learning (artificial intelligence);mobile robots;path planning;smart phones","indoor localization;pseudolabelling;smartphone-based mobile robot;smartphone-robot localization;time-series learning;unlabeled data utilization","","","","","","","27-30 Jan. 2016","","IEEE","IEEE Conference Publications"
"Integrative Analysis of Proteomic, Glycomic, and Metabolomic Data for Biomarker Discovery","M. Wang; G. Yu; H. W. Ressom","Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA","IEEE Journal of Biomedical and Health Informatics","20160905","2016","20","5","1225","1231","Studies associating changes in the levels of multiple biomolecules including proteins, glycans, glycoproteins, and metabolites with the onset of cancer have been widely investigated to identify clinically relevant diagnostic biomarkers. Advances in liquid or gas chromatography mass spectrometry (LC-MS, GC-MS) have enabled high-throughput qualitative and quantitative analysis of these biomolecules. While results from separate analyses of different biomolecules have been reported widely, the mutual information obtained by partly or fully combining them has been relatively unexplored. In this study, we investigate integrative analysis of proteins, N-glycans, and metabolites to take advantage of complementary information to improve the ability to distinguish cancer cases from controls. Specifically, support vector machine-recursive feature elimination algorithm is utilized to select a panel of proteins, N-glycans, and metabolites based on LC-MS and GC-MS data previously acquired by the analysis of blood samples from two cohorts in a liver cancer study. Improved performances are observed by integrative analysis compared to separate proteomic, glycomic, and metabolomic studies in distinguishing liver cancer cases from patients with liver cirrhosis.","2168-2194;21682194","","10.1109/JBHI.2016.2574201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7480352","Cancer biomarker discovery;machine learning;multiomic data integration;systems biology","Blood;Cancer;Glycomics;Liver;Proteins;Proteomics;Support vector machines","bioinformatics;cancer;chromatography;genomics;liver;mass spectroscopy;proteins;proteomics;support vector machines","biomarker discovery;biomolecules;blood samples;diagnostic biomarkers;gas chromatography mass spectrometry;glycans;glycomic data;glycoproteins;high-throughput qualitative analysis;integrative analysis;liquid chromatography mass spectrometry;liver cancer study;liver cirrhosis;metabolites;metabolomic data;proteomic data;support vector machine-recursive feature elimination algorithm","","","","","","20160527","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Classification of Web Pages as Evergreen Or Ephemeral Based on Content","M. Javed; A. Akhtar; A. K. Yusufzai","Dept. of Comput. Eng., Jamia Millia Islamia, New Delhi, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","1381","1385","Classification of web content is an interesting and widely pursued field of research in machine learning. Web classification could be done in various ways based upon the criteria chosen. Subjective classification involves classification of web pages based upon the subject to which these pages belong (say history, economics, politics, etc.). Another way of classifying web pages could be based upon the lifetime of these pages. A similar problem was introduced by Stumble Upon to classify the web pages as evergreen (larger lifetime) or ephemeral (not lasting for very long). The training dataset provided by Stumble Upon was a set of urls with some Meta information like the category of the page, html ratio, is news, along with some boilerplate code (like title and content) of the page. In this paper we have tried to use a novel methodology to classify these documents. The approach that we have used is a combination of text classification and other binary classification. Using this we have been able to get an overall accuracy of 88%.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546324","Data mining;Ephemeral Content;Evergreen content;Machine learning;Text classification;Web Classification;Web mining","Classification algorithms;HTML;Logistics;Predictive models;Support vector machines;Training;Web pages","Internet;learning (artificial intelligence);pattern classification;set theory","Web page classification;boilerplate code;ephemeral;evergreen;machine learning;meta information;text classification;training dataset;urls set","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"MRI based biomarker for brain aging in rodents and non-human primates","K. Frankea; R. Dahnke; G. Clarke; A. Kuo; C. Li; P. Nathanielsz; M. Schwab; C. Gaser","Department of Neurology, University Hospital Jena, Jena, Germany","2016 International Workshop on Pattern Recognition in Neuroimaging (PRNI)","20160901","2016","","","1","4","This work presents two novel species-specific adaptations of a MRI based biomarker that indicates individual deviations from normal brain aging trajectories for rodents and non-human primates. By employing automatic, species-specific preprocessing of anatomical brain MRI as well as high-dimensional pattern recognition methods, this approach uses the distribution of healthy brain-aging patterns to estimate individual brain ages. This biomarker may probably enable tracking the effects of developmental and environmental influences, manipulations, and (preventive) treatments on individual deviations from species-specific brain aging trajectories in experimental mammal models across the life-course.","","Electronic:978-1-4673-6530-7; POD:978-1-4673-6531-4","10.1109/PRNI.2016.7552326","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552326","Aging; BrainAGE;DBM;MRI;VBM;machine learning;mammals;relevance vector regression (RVR)","Aging;Brain models;Data models;Estimation;Magnetic resonance imaging;Rodents","biomedical MRI;brain;learning (artificial intelligence);neurophysiology;pattern recognition","MRI based biomarker;anatomical brain MRI;automatic species-specific preprocessing;brain aging trajectories;experimental mammal models;healthy brain-aging pattern distribution;high-dimensional pattern recognition method;individual brain age estimation;nonhuman primates;rodents;species-specific adaptations;species-specific brain aging trajectories","","","","","","","22-24 June 2016","","IEEE","IEEE Conference Publications"
"Big Data Analytics for Emergency Communication Networks: A Survey","J. Wang; Y. Wu; N. Yen; S. Guo; Z. Cheng","School of Computer Science and Engineering, University of Aizu, Aizuwakamatsu, Japan","IEEE Communications Surveys & Tutorials","20160819","2016","18","3","1758","1778","Disaster management is a crucial and urgent research issue. Emergency communication networks (ECNs) provide fundamental functions for disaster management, because communication service is generally unavailable due to large-scale damage and restrictions in communication services. Considering the features of a disaster (e.g., limited resources and dynamic changing of environment), it is always a key problem to use limited resources effectively to provide the best communication services. Big data analytics in the disaster area provides possible solutions to understand the situations happening in disaster areas, so that limited resources can be optimally deployed based on the analysis results. In this paper, we survey existing ECNs and big data analytics from both the content and the spatial points of view. From the content point of view, we survey existing data mining and analysis techniques, and further survey and analyze applications and the possibilities to enhance ECNs. From the spatial point of view, we survey and discuss the most popular methods and further discuss the possibility to enhance ECNs. Finally, we highlight the remaining challenging problems after a systematic survey and studies of the possibilities.","1553-877X;1553877X","","10.1109/COMST.2016.2540004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429689","Big data analytics;Content analytics;Emergency communication networks;Machine learning;Spatial analytics","Ad hoc networks;Big data;Communication networks;Earthquakes;Mobile computing;Routing;Routing protocols","Big Data;data analysis;data mining;emergency management","Big Data analytics;ECN;content points of view;data analysis technique;data mining;disaster management;emergency communication network;spatial points of view","","1","","","","20160309","thirdquarter 2016","","IEEE","IEEE Journals & Magazines"
"Improved 2D-to-3D video conversion by fusing optical flow analysis and scene depth learning","J. L. Herrera; C. R. del-Blanco; N. Garcıa","Grupo de Tratamiento de Imagenes. ETSI Telecomunicacion. Universidad Politecnica de Madrid","2016 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON)","20160825","2016","","","1","4","Automatic 2D-to-3D conversion aims to reduce the existing gap between the scarce 3D content and the incremental amount of displays that can reproduce this 3D content. Here, we present an automatic 2D-to-3D conversion algorithm that extends the functionality of the most of the existing machine learning based conversion approaches to deal with moving objects in the scene, and not only with static backgrounds. Under the assumption that images with a high similarity in color have likely a similar 3D structure, the depth of a query video sequence is inferred from a color + depth training database. First, a depth estimation for the background of each image of the query video is computed adaptively by combining the depths of the most similar images to the query ones. Then, the use of optical flow enhances the depth estimation of the different moving objects in the foreground. Promising results have been obtained in a public and widely used database.","","Electronic:978-1-5090-3313-3; POD:978-1-5090-3314-0; USB:978-1-5090-3312-6","10.1109/3DTV.2016.7548954","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548954","2D-to-3D conversion;clustering;depth maps;depth prior;machine learning","Clustering algorithms;Color;Databases;Estimation;Image edge detection;Three-dimensional displays;Video sequences","image colour analysis;image sequences;learning (artificial intelligence);video signal processing","2D-to-3D video conversion;auotomatic 2D-to-3D conversion algorithm;color+depth training database;depth estimation enhancement;image color;machine learning based conversion approach;optical flow analysis;query video sequence depth;scene depth learning","","","","","","","4-6 July 2016","","IEEE","IEEE Conference Publications"
"Relevance Singular Vector Machine for Low-Rank Matrix Reconstruction","M. Sundin; C. R. Rojas; M. Jansson; S. Chatterjee","ACCESS Linnaeus Centre, KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Transactions on Signal Processing","20160824","2016","64","20","5327","5339","We develop Bayesian learning methods for low-rank matrix reconstruction and completion from linear measurements. For under-determined systems, the developed methods reconstruct low-rank matrices when neither the rank nor the noise power is known a priori. We derive relations between the proposed Bayesian models and low-rank promoting penalty functions. The relations justify the use of Kronecker structured covariance matrices in a Gaussian-based prior. In the methods, we use expectation maximization to learn the model parameters. The performance of the methods is evaluated through extensive numerical simulations on synthetic and real data.","1053-587X;1053587X","","10.1109/TSP.2016.2597121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529219","Bayes methods;Machine learning;compressed sensing","Bayes methods;Convex functions;Covariance matrices;Estimation;Signal processing algorithms;Sparse matrices;Standards","Bayes methods;covariance matrices;expectation-maximisation algorithm;learning (artificial intelligence);signal reconstruction","Bayesian learning method;Bayesian models;Gaussian-based prior;Kronecker structured covariance matrices;a priori;expectation maximization;linear measurements;low-rank matrix reconstruction;noise power;penalty functions;relevance singular vector machine;underdetermined system","","","","","","20160802","Oct.15, 15 2016","","IEEE","IEEE Journals & Magazines"
"Eastern Arabic Numerals: A Stand out from Other Jargons","N. Gautam; R. S. Sharma; G. Hazrati","Comput. Sci. Dept., Rajasthan Tech. Univ., Kota, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","337","338","Handwriting recognition is to accept and illustrate comprehensible handwritten input and Optical character recognition (OCR) is one of the approaches of loading texts in order to electronically search texts, which is going to be used in the machine learning techniques. Focusing on the Arabic numerals which are used in numerous languages like Farsi and Urdu still requires profound analysis. Whereas, Persian and Urdu languages include a variant of Eastern Arabic numerals and which is viewed as East Arabic-Indic. In this paper recognition of Eastern Arabic numerals is shown by OCR technique leading to accuracy of 82.91%.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546110","Eastern Arabic numerals;Handwriting Recognition;Machine Learning;OCR","Character recognition;Computer science;Feature extraction;Handwriting recognition;Image segmentation;Optical character recognition software","handwriting recognition;learning (artificial intelligence);natural language processing;optical character recognition","East Arabic-Indic;Eastern Arabic numerals;OCR technique;Persian languages;Urdu languages;handwriting recognition;machine learning techniques;optical character recognition;paper recognition","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Empirical Investigation of Code and Process Metrics for Defect Prediction","W. Han; C. H. Lung; S. A. Ajila","Dept. of Syst. & Comput. Eng., Carleton Univ. Ottawa, Ottawa, ON, Canada","2016 IEEE Second International Conference on Multimedia Big Data (BigMM)","20160818","2016","","","436","439","Data science is becoming more important for software engineering problems. Software defect prediction is a critical area which can help the development team allocate test resource efficiently and better understand the root cause of defects. Furthermore, it can help find the reason why a component or even a project is failure-prone. This paper deals with binary classification in predicting if a software component has a bug by using three widely used machine learning algorithms: Random Forest (RF), Neural Networks (NN), and Support Vector Machine (SVM). The paper investigates the applications of these algorithms to the challenging issue of predicting defects in software components. This paper combines code metrics and process metrics as indicators for the Eclipse environment using the aforementioned three algorithms for a sample of weekly Eclipse features. Feature reduction is also adopted using General Linear Model (GLM) to save computational time. The results confirm the predictive capabilities of using two features -- NBD_max and Pre-defects -- and are comparable to the results of using all 61 features. Additionally, this paper evaluates the performance of the three algorithms. NN and RF turn out to have the best fit.","","Electronic:978-1-5090-2179-6; POD:978-1-5090-2180-2","10.1109/BigMM.2016.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545064","Data analysis;Eclipse;Machine learning techniques;Software Defect Prediction","Machine learning algorithms;Measurement;Prediction algorithms;Principal component analysis;Radio frequency;Software;Support vector machines","data analysis;decision trees;feature extraction;learning (artificial intelligence);neural nets;program testing;resource allocation;software development management;software fault tolerance;software metrics;support vector machines","Eclipse environment;GLM;NBD-max feature;NN algorithm;RF algorithm;SVM;binary classification;code metrics;computational time saving;data science;development team;failure-prone component;failure-prone project;feature reduction;general linear model;machine learning algorithm;neural networks;pre-defects features;process metrics;random forest algorithm;software component;software defect prediction;software engineering problems;support vector machine;test resource allocation","","","","","","","20-22 April 2016","","IEEE","IEEE Conference Publications"
"Detecting Web Attacks Using Multi-stage Log Analysis","M. Moh; S. Pininti; S. Doddapaneni; T. S. Moh","Dept. of Comput. Sci., San Jose State Univ., San Jose, CA, USA","2016 IEEE 6th International Conference on Advanced Computing (IACC)","20160818","2016","","","733","738","Web-based applications have gained universal acceptance in every sector of lives, including social, commercial, government, and academic communities. Even with the recent emergence of cloud technology, most of cloud applications are accessed and controlled through web interfaces. Web security has therefore continued to be fundamentally important and extremely challenging. One major security issue of web applications is SQL-injection attacks. Most existing solutions for detecting these attacks use log analysis, and employ either pattern matching or machine learning methods. Pattern matching methods can be effective, dynamic, they however cannot detect new kinds of attacks. Supervised machine learning methods can detect new attacks, yet they need to rely on an off-line training phase. This work proposes a multi-stage log analysis architecture, which combines both pattern matching and supervised machine learning methods. It uses logs generated by the application during attacks to effectively detect attacks and to help preventing future attacks. The architecture is described in detail, a proof-of-concept prototype is implemented and hosted on Amazon AWS, using Kibana for pattern matching and Bayes Net for machine learning. It is evaluated on 10,000 logs for detecting SQL injection attacks. Experiment results show that the two-stage system has combined the advantages of both systems, and has substantially improved the detection accuracy. The proposed work is significant in advancing web securities, while the multi-stage log analysis concept would be highly applicable to many intrusion detection applications.","","Electronic:978-1-4673-8286-1; POD:978-1-4673-8287-8","10.1109/IACC.2016.141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544930","Log Analysis;Pattern Matching;SQL injection;Supervised Machine Learning;Text Classification;Web Security","Cloud computing;Data visualization;Databases;Learning systems;Pattern matching;Security;Training","Internet;learning (artificial intelligence);pattern matching;security of data","Amazon AWS;Bayes net;Kibana;SQL injection attacks detection;Web attacks detection;Web interfaces;Web security;Web-based applications;academic communities;attacks prevention;cloud applications;cloud technology;commercial communities;government communities;intrusion detection;multistage log analysis architecture;pattern matching;proof-of-concept prototype;social communities;supervised machine learning","","1","","","","","27-28 Feb. 2016","","IEEE","IEEE Conference Publications"
"Realizing Students' Understanding through Rule Based Reasoning","V. P. Doshi; B. Roy","St. Francis Inst. of Technol., Univ. of Mumbai, Mumbai, India","2016 IEEE 6th International Conference on Advanced Computing (IACC)","20160818","2016","","","56","61","Lectures are one of the medium used in Teaching-Learning strategy. However, amount of knowledge gained by the student is not always equal to the amount of knowledge shared in the lecture. This can be due to several reasons like long lecture hours, lack of concentration of student and many others. If the concepts which are not clearly understood are pre-requisite to understand next/other concept/topic then there are high chances that student won't understand even that. In such scenario, to ensure that all students have understood each and every concept taught, there is a need for identifying which concepts the students have not understood properly. So to fulfill the requirement, an online exam evaluation system is proposed that will not only assess the competence but also highlights the concepts that the student have not understood properly or is confused with, through custom reports generated using Machine Learning and Rule Based Reasoning.","","Electronic:978-1-4673-8286-1; POD:978-1-4673-8287-8","10.1109/IACC.2016.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544810","Assessment;Confusion;Custom Reports;Evaluation;Examination;Lecture;MCQ;Machine learning;Online Exam System;Rule based reasoning;Student;Understanding;competence;level;option selection;teaching learning;threshold","Cognition;Computers;Conferences;Databases;Education;Logic gates;Manganese","cognition;computer aided instruction;learning (artificial intelligence);teaching","machine learning;online exam evaluation system;rule based reasoning;student concentration;student understanding;teaching-learning strategy","","","","","","","27-28 Feb. 2016","","IEEE","IEEE Conference Publications"
"Ontology-based modeling student learning behaviour analysis in digital library domain knowledge using Markov chain and GUHA","F. M. H. Fernandez; R. Ponnusamy","Sathyabama University, Tamil Nadu, India","2015 Seventh International Conference on Advanced Computing (ICoAC)","20160908","2015","","","1","6","In current days, student learning model in digital library has leading boom. We propose domain ontology for student learning process in digital library to track student behavior. This method used to categories its users conferring to their behavior. The proposed model provides sensible support to students for utilizing knowledge resources which improves the required types of resources and facilities used by students. We used General Unary Hypotheses Automaton (GUHA) and Markov chain-based analysis for modeling student activities and we integrate student profile (historical) data relating their behavior which helps to provide interested topics.","","","10.1109/ICoAC.2015.7562789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562789","Behavior analysis;Behavior tracking;Digital library;Machine Learning;Personalized ontology","","Markov processes;behavioural sciences computing;computer aided instruction;digital libraries;ontologies (artificial intelligence)","GUHA;Markov chain;digital library domain knowledge;domain ontology;general unary hypotheses automaton;student learning behaviour analysis;student profile data","","","","","","","15-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"On the computational overhead of automatic security classification","P. E. Engelstad","Oslo and Akershus University College of Applied Sciences (HiOA), Oslo, Norway","2016 International Conference on Electronics, Information, and Communications (ICEIC)","20160908","2016","","","1","4","We investigate the importance of the computational overhead when machine learning methods, such as SVM, LASSO, Adaboosting and Adabagging, are used for automatic security classification.","","Electronic:978-1-4673-8016-4; POD:978-1-4673-8017-1","10.1109/ELINFOCOM.2016.7562966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562966","Multi-level security;classification;cross-domain information exchange;ensemble methods;feature selection;machine learning","Aging;Measurement;Performance gain;Security;Solids;Support vector machines;Training","learning (artificial intelligence);pattern classification;security of data","automatic security classification;computational overhead;machine learning methods","","","","","","","27-30 Jan. 2016","","IEEE","IEEE Conference Publications"
"Cortically Coupled Computing: A New Paradigm for Synergistic Human-Machine Interaction","S. Saproo; J. Faller; V. Shih; P. Sajda; N. R. Waytowich; A. Bohannon; V. J. Lawhern; B. J. Lance; D. Jangraw","Columbia University","Computer","20160907","2016","49","9","60","68","Unlike traditional brain-computer interfaces that use brain signals for direct control of computers and robotics, a cortically coupled computer system opportunistically senses the brain state, capturing a user's implicit or explicit computation, and then communicates this information to a traditional computer system via a neural interface.","0018-9162;00189162","","10.1109/MC.2016.294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562326","AI;BCI;C3V;CV;HMI;IEEE Brain Initiative;artificial intelligence;bioengineering;bioinformatics;brain-computer interface;computer vision;computing paradigms;cortically coupled computer vision;cortically coupled computing;data analysis;deep learning;human-autonomy integration;human-machine interaction;human-machine interface;intelligent systems;machine learning;neural computing;visualization","Artificial intelligence;Bioengineering;Computer vision;Coupled computing;Data analysis;Intelligent systems;Machine learning;Man-machine interfaces;Neural computing","brain-computer interfaces;human computer interaction","brain-computer interface;cortically coupled computing;neural interface;synergistic human-machine interaction","","","","","","","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Automated rejection and repair of bad trials in MEG/EEG","M. Jas; D. Engemann; F. Raimondo; Y. Bekhti; A. Gramfort","CNRS LTCI, Telecom ParisTech, Universite Paris-Saclay, France","2016 International Workshop on Pattern Recognition in Neuroimaging (PRNI)","20160901","2016","","","1","4","We present an automated solution for detecting bad trials in magneto-/electroencephalography (M/EEG). Bad trials are commonly identified using peak-to-peak rejection thresholds that are set manually. This work proposes a solution to determine them automatically using cross-validation. We show that automatically selected rejection thresholds perform at par with manual thresholds, which can save hours of visual data inspection. We then use this automated approach to learn a sensor-specific rejection threshold. Finally, we use this approach to remove trials with finer precision and/or partially repair them using interpolation.We illustrate the performance on three public datasets. The method clearly performs better than a competitive benchmark on a 19-subject Faces dataset.","","Electronic:978-1-4673-6530-7; POD:978-1-4673-6531-4","10.1109/PRNI.2016.7552336","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552336","artifact rejection;automation;electroencephalography;machine learning;magnetoencephalography;preprocessing","Interpolation;Magnetic sensors;Maintenance engineering;Manuals;Pipelines;Robustness","electroencephalography;interpolation;magnetoencephalography;medical signal processing","EEG;MEG;bad trials automated rejection;bad trials repair;electroencephalography;interpolation;magnetoencephalography;peak-to-peak rejection thresholds;sensor-specific rejection threshold;visual data inspection","","","","","","","22-24 June 2016","","IEEE","IEEE Conference Publications"
"Adaptive learning process for the evolution of ontology-described classification model in big data context","R. Peixoto; C. Cruz; N. Silva","GECAD-ISEP, Polytechnic of Porto, Porto, Portugal","2016 SAI Computing Conference (SAI)","20160901","2016","","","532","540","One of the biggest challenges in Big Data is to exploit value from large volumes of variable and changing data. For this, one must focus on analyzing the data in these Big Data sources and classify the data items according to a domain model (e.g. an ontology). To automatically classify unstructured text documents according to an ontology, a hierarchical multi-label classification process called Semantic HMC was proposed. This process uses ontologies to describe the classification model. To prevent cold start and user overload, the classification process automatically learns the ontology-described classification model from a very large set of unstructured text documents. However, data is always being generated and its statistical properties can change over time. In order to learn in such environment, the classification processes must handle streams of non-stationary data to adapt the classification model. This paper proposes a new adaptive learning process to consistently adapt the ontology-described classification model according to a non-stationary stream of unstructured text data in Big Data context. The adaptive process is then instantiated for the specific case of of the previously proposed Semantic HMC.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7556031","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556031","Maintenance;adaptive learning;machine learning;multi-label classification;ontology","Adaptation models;Big data;Context;Data mining;Data models;Ontologies;Semantics","Big Data;learning (artificial intelligence);ontologies (artificial intelligence);statistical analysis","adaptive learning process;big data;hierarchical multilabel classification;ontology-described classification model;semantic HMC;statistical property","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"A hybrid approach for Thai word segmentation with crowdsourcing feedback system","K. Chaonithi; S. Prom-on","Computer Engineering Department, Faculty of Engineering, King Mongkut's University of Technology Thonburi, Bangkok, Thailand","2016 13th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","20160908","2016","","","1","6","This paper proposes a new hybrid method for Thai word segmentation using crowd-sourced dictionary integrated with word bi-gram model. The main dictionary is extracted into basic and compound word dictionaries to improve dictionary based algorithm performance. The word segmentation process begins with heuristic exhaustive matching algorithm using basic word dictionary to generate all possible basic word sequence candidates from an input string. Then, the best candidate is selected by word bi-gram model to solve ambiguity problem. Finally, the sequence of basic words is combined into compound words with compound word dictionary. Another part of this work is applying crowdsourcing paradigm. We implemented a web application for training bi-gram model and dictionary updates from user feedbacks. This process improves the lexical knowledge of the platform over the time. The algorithm was evaluated with two corpora. With InterBEST 2009 corpus, the proposed algorithm yields average precision, recall and f-measure at 97.52%, 97.70%, and 97.63%. With social network corpus, the proposed method yields average precision, recall and f-measure at 98.47%, 98.59%, and 98.54% respectively.","","Electronic:978-1-4673-9749-0; POD:978-1-4673-9750-6","10.1109/ECTICon.2016.7561298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561298","bi-gram;crowdsourcing;exhaustive matching;hybrid method;machine learning;web service;word segmentation","Compounds;Computers;Crowdsourcing;Dictionaries;Heuristic algorithms;Merging;Training","Web services;learning (artificial intelligence);string matching;text analysis;word processing","Thai word segmentation;Web application;With InterBEST 2009 corpus;basic word dictionaries;basic word sequence;bigram model training;compound word dictionaries;crowd-sourced dictionary;crowdsourcing feedback system;dictionary based algorithm performance improvement;dictionary updates;f-measure value;heuristic exhaustive matching algorithm;hybrid approach;input string;lexical knowledge improvement;main dictionary extraction;precision value;recall value;social network corpus;user feedbacks;word bigram model","","","","","","","June 28 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Road-Map to Bridge Theoretical and Practical Approaches for Elevator Operations","T. Inamoto; Y. Higami; S. Y. Kobayashi","Grad. Sch. of Sci. & Eng., Ehime Univ., Matsuyama, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","1097","1102","In this paper, we propose a road-map to bridge theoretical and practical approaches in the discipline of the elevator operation problem (EOP). The theoretical approach is to obtain optimal solutions for static EOPs, here “static” means all information on users of the elevator system is known before scheduling. The practical approach is to construct rule-bases for realistic situations. The proposed road-map is comprised of 5 stages: (1) to obtain a formally-optimal solution for a problem instance of a static EOP, (2) to construct a statically-peculiar optimal rule-base from the optimal solution, (3) to construct a dynamically-peculiar optimal rule-base which is effective for the problem instance and functions on a continuous elevator system, (4) to construct a dynamically-narrow rule-base which is effective for a set of problem instances, and (5) to construct a dynamically-wide rule-base which is effective for various sets of problem instances. In computer illustrations, preliminary verification on earlier stages are displayed.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557778","elevator operation problem;genetics-based machine learning;mathematical programming;rule-base","Automobiles;Bridges;Elevators;Mathematical model;Pragmatics;Trajectory;Urban areas","knowledge based systems;lifts;optimisation;traffic engineering computing","dynamically-narrow rule-base;dynamically-peculiar optimal rule-base;dynamically-wide rule-base;elevator operation problem;road-map;static EOP;statically-peculiar optimal rule-base","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"LogOptPlus: Learning to Optimize Logging in Catch and If Programming Constructs","S. Lal; N. Sardana; A. Sureka","JIIT, Noida, India","2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)","20160825","2016","1","","215","220","Software logging is a common software development practice which is used to log program execution points. This execution information is later used by software developers for debugging purpose. Software logging is useful but it has cost and benefit tradeoff. Hence it is important to optimize the number of log statements in the code. However, previous studies on logging show that optimal logging is challenging for software developers. Hence tools and techniques which can help developers in making optimized logging decision can be beneficial. We propose LogOptPlus, a machine learning based tool to help software developers to optimize the number of log statements in the source code, for two focused code construct types. LogOptPlus is a significant extension of our previously published work 'LogOpt'. LogOpt is designed to predict logging for catch-blocks. We extend the functionality of LogOpt to predict logging for both if-blocks and catch-blocks. We identify distinguishing static features from the source code for logging prediction. We present intuition and results of quantitative analysis of all the features. We present results of comprehensive evaluation of LogOptPlus with five different machine learning algorithms on two two large Open Source projects (i.e., Apache Tomcat and CloudStack). Encouraging experimental results on two Open Source projects show that LogOptPlus is effective in logging prediction for two focused code construct types.","","Electronic:978-1-4673-8845-0; POD:978-1-4673-8846-7","10.1109/COMPSAC.2016.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552011","Logging;Machine Learning;Software Debugging and Maintenance;Source Code Analysis;Tracing","Complexity theory;Containers;Debugging;Feature extraction;Java;Software;Statistical analysis","learning (artificial intelligence);program debugging;public domain software;source code (software);system monitoring","Apache Tomcat;CloudStack;LogOptPlus;catch programming constructs;catch-blocks logging;code construct types;if programming constructs;if-blocks logging;log statements;logging optimization;logging prediction;machine learning based tool;open source projects;optimal logging;program execution points logging;software debugging;software developers;software development practice;software logging;source code","","1","","","","","10-14 June 2016","","IEEE","IEEE Conference Publications"
"Using grayscale images for object recognition with convolutional-recursive neural network","H. M. Bui; M. Lech; E. Cheng; K. Neville; I. S. Burnett","School of Engineering, RMIT University, Melbourne, Australia","2016 IEEE Sixth International Conference on Communications and Electronics (ICCE)","20160908","2016","","","321","325","There is a common tendency in object recognition research to accumulate large volumes of image features to improve performance. However, whether using more information contributes to higher accuracy is still controversial given the increased computational cost. This work investigates the performance of grayscale images compared to RGB counterparts for visual object classification. A comparison between object recognition based on RGB images and RGB images converted to grayscale was conducted using a cascaded CNN-RNN neural network structure, and compared with other types of commonly used classifiers such as Random Forest, SVM and SP-HMP. Experimental results showed that classification with grayscale images resulted in higher accuracy classification than with RGB images across the different types of classifiers. Results also demonstrated that utilizing a small receptive field CNN and edgy feature selection on grayscale images can result in higher classification accuracy with the advantage of reduced computational cost.","","","10.1109/CCE.2016.7562656","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562656","convolutional neural network;image classification;machine learning;object recognition","Computational efficiency;Feature extraction;Gray-scale;Image color analysis;Neural networks;Object recognition;Training","feature extraction;image classification;image colour analysis;neural nets;object recognition;recursive estimation","RGB image;cascaded CNN-RNN neural network structure;convolutional-recursive neural network;edgy feature selection;grayscale image;object recognition;reduced computational cost;small receptive field CNN;visual object classification","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Human Activity Recognition by Means of Online Semi-supervised Learning","H. L. Cardoso; J. M. Moreira","Fac. of Eng., Univ. of Porto, Porto, Portugal","2016 17th IEEE International Conference on Mobile Data Management (MDM)","20160825","2016","2","","75","77","Human activity recognition (HAR) is a reasonably recent field of study for the computer science community. It aims at automatically analysing ongoing events and extract their context from the captured data. The detection of human activities, such as walking, running, falling, or even cycling, allows for several heterogeneous applications, from surveillance systems to patient monitoring systems. Despite being a particularly active field of study in the past years, HAR still leaves many strategies left to explore and key aspects left to address. There are two main approaches in terms of data extraction: Video and sensors. The sensor approach is, however, the most promising, due to its extreme portability and unobtrusiveness. Most sensor-based HAR systems are trained in a static dataset with Supervised Learning techniques, generating a classification model with a relatively low error rate. However, these systems commonly ignore one of HAR's challenges, the difference of input signals produced by different people when doing the same activities. Consequently, as a user's movements drift from the generic, the system error increases. The activity classification method should therefore be able to generate adapted results for each different user. This article exhibits and discloses an under explored approach to this problem: By means of Online Semi-supervised Learning, An incremental technique capable of adapting the classification model to the user of the application by continuously updating it as the data from the user's own specific input signals arrives. This is possible due to the nature of Semi-supervised learning, which trains on both labeled and unlabeled data, making it possible to keep learning even after reaching its final user, without the need of any manual input.","","Electronic:978-1-5090-0883-4; POD:978-1-5090-0884-1","10.1109/MDM.2016.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551576","Human Activity Recognition;Machine Learning;Online Semi-Supervised Learning","Data models;Decision trees;Semisupervised learning;Sensors;Supervised learning;Training","image recognition;learning (artificial intelligence)","activity classification method;classification model;computer science community;cycling;data extraction;falling;heterogeneous applications;human activity recognition;incremental technique;online semisupervised learning;patient monitoring systems;portability;running;sensor-based HAR systems;sensors;surveillance systems;unobtrusiveness;video;walking","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Boosting connectome classification via combination of geometric and topological normalizations","D. Petrov; Y. Dodonova; L. Zhukov; M. Belyaev","Institute for Information Transmission Problems (Kharkevich Institute), Moscow, Russia","2016 International Workshop on Pattern Recognition in Neuroimaging (PRNI)","20160901","2016","","","1","4","The structural connectome classification is a challenging task due to a small sample size and high dimensionality of feature space. In this paper, we propose a new data prepossessing method that combines geometric and topological connectome normalization and significantly improves classification results. We validate this approach by performing classification between autism spectrum disorder and normal development connectomes in children and adolescents. We demonstrate a significant enhancement in performance using weighted and normalized data over the best available model (boosted decision trees) trained on baseline features.","","Electronic:978-1-4673-6530-7; POD:978-1-4673-6531-4","10.1109/PRNI.2016.7552353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552353","Autism spectrum disorder;Brain networks;Diffusion tensor imaging;Graph theory;Machine Learning","Algorithm design and analysis;Autism;Brain;Feature extraction;Machine learning algorithms;Measurement;Support vector machines","decision trees;geometry;medical computing;medical disorders;pattern classification;support vector machines","SVM;autism spectrum disorder;boosted decision tree;data prepossessing;geometric normalization;normal development connectome;structural connectome classification;support vector machine;topological normalization","","1","","","","","22-24 June 2016","","IEEE","IEEE Conference Publications"
"Modeling 3D Environments through Hidden Human Context","Y. Jiang; H. S. Koppula; A. Saxena","Computer Science Department, Cornell University, Ithaca, NY","IEEE Transactions on Pattern Analysis and Machine Intelligence","20160901","2016","38","10","2040","2053","The idea of modeling object-object relations has been widely leveraged in many scene understanding applications. However, as the objects are designed by humans and for human usage, when we reason about a human environment, we reason about it through an interplay between the environment, objects and humans. In this paper, we model environments not only through objects, but also through latent human poses and human-object interactions. In order to handle the large number of latent human poses and a large variety of their interactions with objects, we present Infinite Latent Conditional Random Field (ILCRF) that models a scene as a mixture of CRFs generated from Dirichlet processes. In each CRF, we model objects and object-object relations as existing nodes and edges, and hidden human poses and human-object relations as latent nodes and edges. ILCRF generatively models the distribution of different CRF structures over these latent nodes and edges. We apply the model to the challenging applications of 3D scene labeling and robotic scene arrangement. In extensive experiments, we show that our model significantly outperforms the state-of-the-art results in both applications. We further use our algorithm on a robot for arranging objects in a new scene using the two applications aforementioned.","0162-8828;01628828","","10.1109/TPAMI.2015.2501811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346466","3D scene understanding, human context, machine learning, robotics perception","Computational modeling;Context;Context modeling;Labeling;Monitoring;Three-dimensional displays;Yttrium","computer vision;statistical analysis","3D scene labeling;CRF;ILCRF;human poses;human-object relations;infinite latent conditional random field;object-object relations;robotic scene arrangement","","2","","","","20151203","Oct. 1 2016","","IEEE","IEEE Journals & Magazines"
"A clustering based approach for energy efficient routing","P. Kosmides; L. Lambrinos; V. Asthenopoulos; K. Demestichas; E. Adamopoulou","Department of Communication and Internet Studies, Cyprus University of Technology, Limassol, Cyprus","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","232","237","One of the most significant issues the research community has focused on during the last decades, is the reduction of the energy consumed in every aspect of everyday life. A standout amongst the most important factors of energy consumption is transportation. To this end, a lot of work in the field of Intelligent Transport Systems concentrates on enhancing energy efficiency. This trend was reinforced by the appearance of Fully Electric Vehicles (FEVs), where it is more crucial to increase their energy efficiency in any manner. Eco-routing refers to the choice of the most energy efficient route towards a destination and seems very promising for reducing everyday energy consumption. In this paper, we present a novel method for predicting energy consumption levels, based on machine learning techniques. In addition, addressing the problem of ever increasing amounts of tracking data acquired from vehicles, we introduce a clustering based prediction method and apply it on real world measurements in order to evaluate its performance.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543745","Intelligent Transport Systems;clustering based prediction;energy efficiency;machine learning","Energy consumption;Energy efficiency;Multilayer perceptrons;Roads;Routing;Support vector machines;Vehicles","electric vehicles;energy conservation;energy consumption;intelligent transportation systems;learning (artificial intelligence);pattern clustering;power aware computing","FEV;clustering based approach;clustering based prediction;eco-routing;energy consumption levels prediction;energy consumption reduction;energy efficiency;energy efficient routing;fully electric vehicles;intelligent transport systems;machine learning;transportation","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"An Approach to Design and Analyze the Framework for Preventing Cyberbullying","W. D. Yu; M. Gole; N. Prabhuswamy; S. Prakash; V. G. Shankaramurthy","Comput. Eng. Dept., San Jose State Univ., San Jose, CA, USA","2016 IEEE International Conference on Services Computing (SCC)","20160901","2016","","","864","867","The advent of the internet has paved the means for global communication. In today's world, social networking websites like Facebook, Twitter, SnapChat, and Reddit are an integral part of youth and kids. Being exposed to many strangers on their social network, today's youth and kids are vulnerable to cyberbullying attacks, more so than ever. It has been a growing concern for parents and government as it has steadily increased the mortality rates of youth and kids. Given the degree of freedom one can have on the internet, it's a pain to prevent cyberbullying efficiently.","","Electronic:978-1-5090-2628-9; POD:978-1-5090-2629-6","10.1109/SCC.2016.125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557547","Apache Spark;Cyber Security;Cyberbully;Extract;Load;Machine Learning;Transform","Algorithm design and analysis;Cellular phones;Classification algorithms;Clustering algorithms;Internet;Machine learning algorithms;Sparks","social networking (online);social sciences computing","Facebook;Reddit;SnapChat;Twitter;cyberbullying attacks;cyberbullying prevention;social networking Web sites","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Data-driven modeling method for analyzing grade crossing safety","E. Trudel; C. Yang; Y. Liu","National Research Council Canada, Ottawa, Ontario Canada","2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20160915","2016","","","145","151","A grade crossing is defined as an intersection between a roadway and a railway at the same elevation or grade. Multiple new prevention measures have been implemented to reduce the number of train-vehicle collisions; however, crossing safety is still a major issue as accidents still frequently occur. The push for data-driven models to evaluate risks at grade crossings has also increased to keep up with the changing technologies. There are many different protection types (gates with bells, cross-buck, stop-sign, mirrors and etc.) that serve to warn or stop oncoming traffic. Many attributes have an inherent impact on accident frequency; including the protection type, train speed, traffic volume and e.t.c. To address which factors are most important, we propose a data-driven modeling method to effectively analyze the impact of multiple factors that affect crossing safety and subsequently provide scientific insight for key factors for enhancing crossing safety. In this work, the Canadian crossing accident database for the years of 2004 - 2013 was used with additional generated features to enhance the scope of the study. These include features that were computed using GIS and sightline measurements. Data-driven modeling using RandomForests were used to rank and analyze 21 attributes for each protection type. From the analysis results it is possible to identify which key factors have the highest influence on improving safety and collision prediction at grade crossings.","","","10.1109/CSCWD.2016.7565979","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565979","GIS;Grade crossing;RandomForest regression;crossing safety;data-driven modeling;feature generation;machine learning algorithm","Accidents;Databases;Decision trees;Machine learning algorithms;Predictive models;Safety;Training","geographic information systems;rail traffic;railway accidents;railway safety;random processes;road traffic","Canadian crossing accident database;GIS;accident frequency;data-driven modeling method;geographic information system;grade crossing safety;prevention measures;protection type;random forests;roadway-railway intersection;sightline measurements;traffic volume;train speed;train-vehicle collisions","","","","","","","4-6 May 2016","","IEEE","IEEE Conference Publications"
"Data-driven distributed analytics and control platform for smart grid situational awareness","C. S. Saunders; G. Liu; Y. Yu; W. Zhu","Global Energy Interconnection Research Institute, North America, Santa Clara, CA, 95054, USA","CSEE Journal of Power and Energy Systems","20160908","2016","2","3","51","58","A conceptual, data-driven framework for organizing the data analytics and control functions in an electrical distribution network is proposed in this paper. The framework is built such that it tightly corresponds to the naturally existing physical hierarchy of typical radial distribution networks, allowing for an organized and highly-localized set of data storage and analytics processes, which in turn correspond well to likely control commands. By utilizing this structure, the computational entities in the framework are endowed with persistent local situational awareness. However, the framework also permits, through a series of tiered communications, the operation of a centralized authority for overall system observability and controllability.","","","10.17775/CSEEJPES.2016.00035","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562824","Data analytics;data warehousing;distributed control;distributed systems;machine learning;situational awareness","Computational modeling;Distributed databases;Monitoring;Smart grids;Warehousing","distribution networks;smart power grids","data-driven distributed analytics;electrical distribution network;radial distribution networks;smart grid situational awareness","","","","","","","Sept. 2016","","CSEE","CSEE Journals & Magazines"
"Semantic data extraction over MQTT for IoTcentric wireless sensor networks","S. Wagle","Department of Instrumentation and Control, Vishwakarma Institute of Technology, Pune, India","2016 International Conference on Internet of Things and Applications (IOTA)","20160908","2016","","","227","232","The emergence of the paradigm of Internet of Things (IoT) has necessitated the development of machine-to-machine (M2M) protocols geared towards wireless sensor network interfacing to the Internet and implementing machine learning algorithms over the cloud. This paper discusses the viability of the MQ Telemetry Transport (MQTT) protocol for such applications. This paper introduces MQTT along with its merits and demerits and suitability towards IoT applications. Then it outlines an implementation of a typical IoT application involving ubiquitous sensing, M2M communication, cloud computing and semantic data extraction. The results of this experiment are then analyzed. Finally, the paper looks at future improvements in the proposed architecture for widespread use.","","","10.1109/IOTA.2016.7562727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562727","Data Extraction;Internet of Things;Machine Learning;Wireless Sensor Networks","Data mining;Internet of things;Logic gates;Protocols;Quality of service;Semantics;Servers","Internet of Things;protocols;wireless sensor networks","Internet of Things;IoT centric wireless sensor networks;MQ telemetry transport protocol;MQTT protocol;cloud computing;machine-to-machine protocols;semantic data extraction","","","","","","","22-24 Jan. 2016","","IEEE","IEEE Conference Publications"
"Using Statistical Models to Improve the Reliability of Delay-Based PUFs","X. Xu; W. Burleson; D. E. Holcomb","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Amherst, MA, USA","2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)","20160908","2016","","","547","552","Physical Unclonable Functions (PUFs) use random physical variations to map input challenges to output responses in a way that is unique to each chip. PUFs are promising low cost security primitives but unreliability of outputs limits the practical applications of PUFs. This work addresses two causes of unreliability: environmental noise and device aging. To improve reliability, we constructively apply Machine Learning modeling, and use the models to predict and then discard challenge-response pairs (CRPs) that will be unreliable with respect to noise and aging on a given PUF instance. The proposed method provides flexibility to control error rate by deciding what percentage of challenges to discard. Our experiments find that a PUF with nominal reliability of 91% can be made fully reliable by discarding only 20% of challenges.","","Electronic:978-1-4673-9039-2; POD:978-1-4673-9040-8","10.1109/ISVLSI.2016.125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560256","Aging;Machine Learning;Physical Unclonablel Function;Reliability","Aging;Computational modeling;Delays;Integrated circuit modeling;Integrated circuit reliability;Working environment noise","electronic engineering computing;integrated circuit reliability;learning (artificial intelligence);statistical analysis","CRF;challenge-response pairs;delay-based PUF;device aging;environmental noise;error rate;integrated circuits;low cost security primitives;machine learning modeling;physical unclonable functions;reliability improvement;statistical models","","","","","","","11-13 July 2016","","IEEE","IEEE Conference Publications"
"A Probabilistic Modeling Approach to Hearing Loss Compensation","T. van de Laar; B. de Vries","Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20160907","2016","24","11","2200","2213","Hearing Aid (HA) algorithms need to be tuned (“fitted”) to match the impairment of each specific patient. The lack of a fundamental HA fitting theory is a strong contributing factor to an unsatisfying sound experience for about 20% of HA patients. This paper proposes a probabilistic modeling approach to the design of HA algorithms. The proposed method relies on a generative probabilistic model for the hearing loss problem and provides for automated inference of the corresponding (1) signal processing algorithm, (2) the fitting solution as well as (3) a principled performance evaluation metric. All three tasks are realized as message passing algorithms in a factor graph representation of the generative model, which in principle allows for fast implementation on HA or mobile device hardware. The methods are theoretically worked out and simulated with a custom-built factor graph toolbox for a specific hearing loss model.","2329-9290;23299290","","10.1109/TASLP.2016.2599275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539610","Hearing aids;factor graphs;hearing loss compensation;machine learning;message passing;probabilistic modeling","Auditory system;Gain;Hearing aids;Probabilistic logic;Signal processing;Signal processing algorithms;Tuning","ear;hearing;hearing aids;inference mechanisms;medical signal processing;message passing;physiological models;statistical analysis","automated inference;factor graph representation;fundamental HA fitting theory;hearing aid algorithms;hearing loss compensation;message passing algorithms;principled performance evaluation metric;probabilistic modeling approach;signal processing algorithm","","","","","","20160810","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Automatic Assessment of Speech Intelligibility for Individuals With Aphasia","D. Le; K. Licata; C. Persad; E. M. Provost","University of Michigan, Ann Arbor, MI, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20160905","2016","24","11","2187","2199","Traditional in-person therapy may be difficult to access for individuals with aphasia due to the shortage of speech-language pathologists and high treatment cost. Computerized exercises offer a promising low-cost and constantly accessible supplement to in-person therapy. Unfortunately, the lack of feedback for verbal expression in existing programs hinders the applicability and effectiveness of this form of treatment. A prerequisite for producing meaningful feedback is speech intelligibility assessment. In this work, we investigate the feasibility of an automated system to assess three aspects of aphasic speech intelligibility: clarity, fluidity, and prosody. We introduce our aphasic speech corpus, which contains speech-based interaction between individuals with aphasia and a tablet-based application designed for therapeutic purposes. We present our method for eliciting reliable ground-truth labels for speech intelligibility based on the perceptual judgment of nonexpert human evaluators. We describe and analyze our feature set engineered for capturing pronunciation, rhythm, and intonation. We investigate the classification performance of our system under two conditions, one using human-labeled transcripts to drive feature extraction, and another using transcripts generated automatically. We show that some aspects of aphasic speech intelligibility can be estimated at human-level performance. Our results demonstrate the potential for the computerized treatment of aphasia and lay the groundwork for bridging the gap between human and automatic intelligibility assessment.","2329-9290;23299290","","10.1109/TASLP.2016.2598428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534775","Aphasia;acoustic modeling;apraxia;clinical application;machine learning;speech intelligibility assessment","Acoustics;Adaptation models;Feature extraction;Medical treatment;Speech;Speech processing;Speech recognition","feature extraction;medical signal processing;notebook computers;patient treatment;signal classification;speech processing","aphasia;aphasic speech corpus;automatic speech intelligibility assessment;clarity aspect;computerized exercises;feature extraction;feature set;fluidity aspect;human intelligibility assessment;human-labeled transcripts;in-person therapy;intonation;perceptual nonexpert human evaluator judgment;pronunciation;prosody aspect;rhythm;speech-based interaction;speech-language pathologists shortage;tablet-based application;verbal expression","","","","","","20160805","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Cost-Effective Supervised Learning Models for Software Effort Estimation in Agile Environments","K. Moharreri; A. V. Sapre; J. Ramanathan; R. Ramnath","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)","20160825","2016","2","","135","140","Software development effort estimation is the process of predicting the most realistic effort required to develop or maintain software. It is important to develop estimation models and appropriate techniques to avoid losses caused by poor estimation. However, no method exists that is the most appropriate one for Agile Development where frequent iterations involve the customer causing time consuming estimation process. To address this an automated estimation methodology called ""Auto-Estimate"" is proposed complementing Agile's manual Planning Poker. The Auto-Estimate leverages features extracted from Agile story cards, and their actual effort time. The approach is justified by evaluating alternative machine learning algorithms for effort prediction. It is shown that selected machine learning methods perform better than Planning Poker estimates in the later stages of a project. This estimation approach is evaluated for accuracy, applicability and value, and the results are presented within a real-world setting.","","Electronic:978-1-4673-8845-0; POD:978-1-4673-8846-7","10.1109/COMPSAC.2016.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552193","Agile Software Estimation and Planning;Classifier;Machine Learning;Planning Poker;Software Estimation","Decision trees;Estimation;Feature extraction;Planning;Software;Supervised learning;Vegetation","learning (artificial intelligence);software development management;software maintenance;software prototyping","Agile story cards;Auto-Estimate;Planning Poker;agile development;agile environment;cost-effective supervised learning model;machine learning algorithm;software development effort estimation;software maintenance","","","","","","","10-14 June 2016","","IEEE","IEEE Conference Publications"
"Goal Set Inverse Optimal Control and Iterative Replanning for Predicting Human Reaching Motions in Shared Workspaces","J. Mainprice; R. Hayne; D. Berenson","Autonomous Motion Department, Max-Planck-Institute for Intelligent Systems, T&#x00FC;bingen, Germany","IEEE Transactions on Robotics","20160824","2016","32","4","897","908","To enable safe and efficient human-robot collaboration in shared workspaces, it is important for the robot to predict how a human will move when performing a task. While predicting human motion for tasks not known a priori is very challenging, we argue that single-arm reaching motions for known tasks in collaborative settings (which are especially relevant for manufacturing) are indeed predictable. Two hypotheses underlie our approach for predicting such motions: First, that the trajectory the human performs is optimal with respect to an unknown cost function, and second, that human adaptation to their partner's motion can be captured well through iterative replanning with the above cost function. The key to our approach is thus to learn a cost function that “explains” the motion of the human. To do this, we gather example trajectories from pairs of participants performing a collaborative assembly task using motion capture. We then use inverse optimal control to learn a cost function from these trajectories. Finally, we predict reaching motions from the human's current configuration to a task-space goal region by iteratively replanning a trajectory using the learned cost function. Our planning algorithm is based on the trajectory optimizer: stochastic trajectory optimizer for motion planning [1]; it plans for a 23-degree-of-freedom human kinematic model and accounts for the presence of a moving collaborator and obstacles in the environment. Our results suggest that in most cases, our method outperforms baseline methods when predicting motions. We also show that our method outperforms baselines for predicting human motion when a human and a robot share the workspace.","1552-3098;15523098","","10.1109/TRO.2016.2581216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523201","Human-robot interaction, machine learning, motion analysis, motion planning, robot motion","Collaboration;Cost function;Hidden Markov models;Optimal control;Planning;Robots;Trajectory","human-robot interaction;learning systems;optimal control;path planning;stochastic systems;trajectory control","23-degree-of-freedom human kinematic model;collaborative assembly task;cost function learning;goal set inverse optimal control;human reaching motion prediction;human-robot collaboration;iterative replanning;motion capture;motion planning;single-arm reaching motions;stochastic trajectory optimizer","","1","","","","20160727","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Evaluating the Visualization of What a Deep Neural Network Has Learned","W. Samek; A. Binder; G. Montavon; S. Lapuschkin; K. R. Müller","Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany.","IEEE Transactions on Neural Networks and Learning Systems","","2016","PP","99","1","14","Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the ""importance"" of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.","2162-237X;2162237X","","10.1109/TNNLS.2016.2599820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552539","Convolutional neural networks;explaining classification;image classification;interpretable machine learning;relevance models.","Algorithm design and analysis;Biological neural networks;Deconvolution;Heating;Learning systems;Neurons;Sensitivity","","","","","","","","20160825","","","IEEE","IEEE Early Access Articles"
"Learning-based quality assessment of retargeted stereoscopic images","Y. Liu; L. Sun; S. Yang","Department of Computer Science and Technology, Tsinghua University, Tsinghua NLIST. Beijing, China","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Stereoscopic image retargeting techniques aim to flexibly display 3D images with different aspect ratios and simultaneously preserve salient regions and comfortable depth perception. Various stereoscopic image retargeting techniques have been proposed recently. However, there is still no effective objective metric for visual quality assessment of retargeted stereoscopic images. In this paper, we build a stereoscopic image retargeting database and propose a learning-based objective method to evaluate the stereoscopic image retargeting quality. The perception quality of the database are evaluated by subjects. We extract new features of quality assessment and fuse them to assess stereoscopic image retargeting quality using neural network. Experiments conducted with above-mentioned database confirm the effectiveness of the proposed method. The results show the good consistency between the objective assessments and subjective rankings.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552873","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552873","Quality assessment;disparity;machine learning;stereoscopic image retargeting","Databases;Distortion;Distortion measurement;Feature extraction;Stereo image processing;Three-dimensional displays;Visualization","feature extraction;learning (artificial intelligence);neural nets;stereo image processing","3D images display;depth perception;features extraction;learning-based objective method;learning-based visual quality assessment;neural network;salient regions preservation;stereoscopic image retargeting techniques","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Improving extraction of protein — Protein interaction datasets from KUPS using hashing approach","G. Kumar; R. Kumar; M. Kumar Pal; P. Gupta; R. Gupta; S. Mehra","Department of Applied Science, Indian Institute of Information Technology - Allahabad, India - 211012","2016 International Conference on Bioinformatics and Systems Biology (BSB)","20160825","2016","","","1","4","The machine learning approaches frequently address the extraction of training datasets from the online databases to build computational or mathematical models. The training data downloaded from the online server and databases are most often carry redundancy and noise. Heuristics methods are most common to filter the data. Dataset filtering process is time consuming and researcher has to do this tedious work. We propose a more generic filter to detect frequent exceptions to increase the quality of generated datasets based on Perl Hash Programming and regular expression methodology. Future development of noise and error reduction approaches is important to make use of the full potential of available database knowledge. We make use of the datasets of protein - protein interaction generated by The University of Kansas Proteomics Service (KUPS).","","Electronic:978-1-5090-2261-8; POD:978-1-5090-2262-5","10.1109/BSB.2016.7552135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552135","Kansas Proteomics Service;Machine Learning;Protein — Protein interaction","Computational modeling;Databases;Feature extraction;Filtering;Proteins;Radiation detectors;Servers","bioinformatics;learning (artificial intelligence);molecular biophysics;proteins;proteomics","KUPS;Perl Hash Programming;dataset filtering process;error reduction approach;generated dataset quality;generic filter;hashing approach;heuristics method;machine learning approach;noise reduction approach;online database;online server;protein-protein interaction dataset extraction;regular expression methodology","","","","","","","4-6 March 2016","","IEEE","IEEE Conference Publications"
"Automatic Fish Recognition and Counting in Video Footage of Fishery Operations","S. Luo; X. Li; D. Wang; J. Li; C. Sun","Sch. of Design, Commun. & IT, Univ. of Newcastle, Newcastle, NSW, Australia","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","296","299","This paper presents an accurate and automatic algorithm to recognize and count fish in the video footages of fishery operations. The unique character of the approach is that it combines machine learning techniques with statistical methods to fully make use the benefits of these algorithms. The approach consists of three major stages including video data preparation such as noise deduction, preliminary fish recognition with artificial neural network to classify image areas into either fish or non-fish, and fine fish recognition and counting with statistical shape models. Experiment results of tuna recognition and counting using the proposed method are presented with performance validation and discussion.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546102","fish counting;fish recognition;machine learning;statistical shape models","Aquaculture;Artificial neural networks;Feature extraction;Fish;Image color analysis;Shape;Training","aquaculture;image classification;image denoising;learning (artificial intelligence);neural nets;video signal processing","artificial neural network;automatic fish counting;automatic fish recognition;fishery operations;image area classification;machine learning;noise deduction;performance validation;statistical methods;statistical shape models;tuna recognition;video data preparation;video footage","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Scalable Cloud-Based Analysis Framework for Medical Big-Data","R. Pakdel; J. Herbert","Dept. of Comput. Sci., Univ. Coll. Cork, Cork, Ireland","2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)","20160825","2016","2","","647","652","Medical care can be improved by efficient analysis of the large amounts of data involved in patient care. Two important challenges for patient care big-data analysis are the need to cope with unstructured images and text (as well as structured data) and the need for efficient methods that scale for large amounts of data generated by the many patients. The framework described here is designed to cope with these challenges. Firstly it is composed of generic components where the initial stage can transform unstructured image or text data into a set of features for the latter stages. Secondly the machine learning analytics engine incorporates three optimizations which allow the framework to scale and deal with large amounts of unstructured data. The framework is evaluated using both image and text data, and shown to provide an efficient scalable solution.","","Electronic:978-1-4673-8845-0; POD:978-1-4673-8846-7","10.1109/COMPSAC.2016.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552300","Big Data;Cloud-based Big Data Analytics;Machine Learning;Medical;Scable Framework","Biomedical imaging;Cloud computing;Feature extraction;Image segmentation;Optimization;Training;White blood cells","Big Data;cloud computing;data analysis;learning (artificial intelligence);medical administrative data processing;patient care","machine learning analytics;medical big-data;patient care big-data analysis;scalable cloud-based analysis framework;unstructured data;unstructured images","","","","","","","10-14 June 2016","","IEEE","IEEE Conference Publications"
"Phoenix: A Self-Optimizing Chess Engine","A. R. Rahul; G. Srinivasaraghavan","Res. Labs., IBM India, Bangalore, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","652","657","Since the advent of computers, many tasks which required humans to spend a lot of time and energy have been trivialized by the computers' ability to perform repetitive tasks extremely quickly. However there are still many areas in which humans excel in comparison with the machines. One such area is chess. Even with great advances in the speed and computational power of modern machines, Grandmasters often beat the best chess programs in the world with relative ease<sup>1</sup>. This may be due to the fact that a game of chess cannot be won by pure calculation. There is more to the goodness of a chess position than some numerical value which apparently can be seen only by the human brain. Here an effort has been made to improve current chess engines by letting themselves evolve over a period of time. Firstly, the problem of learning is reduced into an optimization problem by defining Position Evaluation in terms of Positional Value Tables (PVTs). Next, the PVTs are optimized using Multi-Niche Crowding which successfully identifies the optima in a multimodal function, thereby arriving at distinctly different solutions which are close to the global optimum.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546176","Computer Chess;Genetic Optimization;Machine Learning;Multi-Niche Crowding","Computers;Engines;Games;Genetic algorithms;Optimization;Sociology;Statistics","computer games;genetic algorithms;learning (artificial intelligence)","Grandmasters;PVT;Phoenix;chess engine improvement;chess programs;genetic optimization;global optimum;human brain;learning problem;multimodal function;multiniche crowding;optimization problem;position evaluation;positional value tables;self-optimizing chess engine","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Data Analytics for Fault Localization in Complex Networks","M. X. Cheng; W. B. Wu","Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA","IEEE Internet of Things Journal","20160908","2016","3","5","701","708","We consider the problem of identifying the source of failure in a network after receiving alarms or having observed symptoms. To locate the root cause accurately and timely in a large communication system is challenging because a single fault can often result in a large number of alarms, and multiple faults can occur concurrently. In this paper, we present a new fault localization method using a machine-learning approach. We propose to use logistic regression to study the correlation among network events based on end-to-end measurements. Then based on the regression model, we develop fault hypothesis that best explains the observed symptoms. Unlike previous work, the machine-learning algorithm requires neither the knowledge of dependencies among network events, nor the probabilities of faults, nor the conditional probabilities of fault propagation as input. The “low requirement” feature makes it suitable for large complex networks where accurate dependencies and prior probabilities are difficult to obtain. We then evaluate the performance of the learning algorithm with respect to the accuracy of fault hypothesis and the concentration property. Experimental results and theoretical analysis both show satisfactory performance.","2327-4662;23274662","","10.1109/JIOT.2015.2503270","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336493","Complex networks;computer network reliability;fault diagnosis;fault location;logistic regression;machine learning","Algorithm design and analysis;Complex networks;Correlation;Logistics;Machine learning algorithms;Regression analysis;Training data","complex networks;computer network reliability;data analysis;fault tolerant computing;learning (artificial intelligence);network theory (graphs);regression analysis","complex networks;computer networks;concentration property;data analytics;end-to-end measurements;fault hypothesis;fault localization method;logistic regression;machine learning approach;network events","","","","","","20151124","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Oblique random forest based on partial least squares applied to pedestrian detection","A. J. L. Correia; W. R. Schwartz","Smart Surveillance Interest Group, Computer Science Department, Universidade Federal de Minas Gerais, Minas Gerais, Brazil","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","2931","2935","The increasing popularity of approaches based on random forest in computer vision tasks is due to its simplicity and flexibility with complex data. Random forest is a set of decision trees that can be divided in two subsets according to the view of the feature descriptors provided as input: orthogonal and oblique. In the former, the feature space is separated orthogonally (axis-aligned) by a single feature at a time. In the latter, it separates the space by oriented hyperplanes, which usually provides better data modeling. This work proposes a novel oblique random forest associated with Partial Least Squares to perform the oblique split. We validate the proposed approach, referred to as oRF-PLS, on the challenge INRIA Person dataset. Experimental results demonstrate that the proposed method outperforms traditional state-of-the-art detectors. In addition, we demonstrate that PLS is a more suitable choice to build oblique random forest than SVM, being faster and producing more accurate forests.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532896","Pedestrian detection;machine learning;oblique random forest;partial least squares;random forest","Computer vision;Decision trees;Indexes;Protocols;Support vector machines;Surveillance;Vegetation","computer vision;decision trees;feature extraction;object detection;pedestrians","INRIA Person dataset;computer vision;data modeling;decision trees;feature descriptors;feature space;oRF-PLS approach;oblique random forest;partial least squares;pedestrian detection","","","","18","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"An Optimization Approach to Services Sales Forecasting in a Multi-staged Sales Pipeline","A. Megahed; P. Yin; H. R. M. Nezhad","Cloud Services Analytics Group, IBM Almaden Res. Center, San Jose, CA, USA","2016 IEEE International Conference on Services Computing (SCC)","20160901","2016","","","713","719","Services organization manage a pipeline of sales opportunities with variable enterprise sales engagement lifespan, maturity levels (belonging to progressive sales stages), and contract values at any given point in time. Accurate forecasting of contract signings by the end of a time period (e.g., a quarter) is a desire for many services organizations in order to get an accurate projection of incoming revenues, and to provide support for delivery planning, resource allocation, budgeting, and effective sales opportunity management. While the problem of sales forecasting has been investigated in its generic context, sales forecasting for services organizations entails the consideration of additional complexities, which has not been thoroughly investigated: (i) considering opportunities in multi-staged sales pipeline, which means providing stage-specific treatment of sales opportunities in each group, and (ii) using the information of the current pipeline build-up, as well as the projection of the pipeline growth over the remaining time period before the end of the target time period in order to make predictions. In this paper, we formulate this problem, considering the service-specific context, as a machine learning problem over the set of historical services sales data. We introduce a novel optimization approach for finding the optimized weights of a sales forecasting function. The objective value of our optimization model minimizes the average error rates for predicting sales based on two factors of conversion rates and growth factors for any given point in time in a sales period over historical data. Our model also optimally determines the number of historical periods that should be used in the machine learning framework to predict the future revenue. We have evaluated the presented method, and the results demonstrate superior performance (in terms of absolute and relative errors) compared to a baseline state of the art method.","","Electronic:978-1-5090-2628-9; POD:978-1-5090-2629-6","10.1109/SCC.2016.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557518","Forecasting;IT Services;Optimization and Machine Learning;Sales Forecasting;Sales Prediction;Services Enterprise Sales;Services Sales Management","Contracts;Data models;Forecasting;Optimization;Organizations;Pipelines;Predictive models","budgeting;customer services;forecasting theory;learning (artificial intelligence);optimisation;planning;resource allocation;sales management;service industries","average error rate minimization;budgeting;contract signing forecasting;contract value;conversion rate;delivery planning;enterprise sales engagement lifespan;future revenue prediction;historical services sales data;machine learning problem;maturity level;multistaged sales pipeline;optimization;pipeline growth projection;progressive sales stages;resource allocation;revenue projection;sales opportunities;sales opportunity management;service sales forecasting;services organization","","1","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Automatic Environmental Sound Recognition: Performance Versus Computational Cost","S. Sigtia; A. M. Stark; S. Krstulović; M. D. Plumbley","Queen Mary University of London, London, U.K.","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20160905","2016","24","11","2096","2107","In the context of the Internet of Things, sound sensing applications are required to run on embedded platforms where notions of product pricing and form factor impose hard constraints on the available computing power. Whereas Automatic Environmental Sound Recognition (AESR) algorithms are most often developed with limited consideration for computational cost, this paper seeks which AESR algorithm can make the most of a limited amount of computing power by comparing the sound classification performance as a function of its computational cost. Results suggest that Deep Neural Networks yield the best ratio of sound classification accuracy across a range of computational costs, while Gaussian Mixture Models offer a reasonable accuracy at a consistently small cost, and Support Vector Machines stand between both in terms of compromise between accuracy and computational cost.","2329-9290;23299290","","10.1109/TASLP.2016.2592698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515194","Automatic environmental sound recognition;computational auditory scene analysis;deep learning;machine learning","Acoustics;Computational efficiency;IEEE transactions;Internet of things;Speech;Speech processing;Speech recognition","Gaussian processes;acoustic signal processing;mixture models;signal classification;speech recognition;support vector machines","AESR algorithms;Gaussian mixture models;Internet of Things;automatic environmental sound recognition algorithm;automatic speech recognition;computational cost function;deep neural networks;embedded platforms;form factor;performance cost;product pricing;sound classification performance;sound sensing;support vector machines","","1","","","","20160718","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Enabling vision-based services with a cloud robotic system","J. Y. Huang; W. P. Lee","Department of Information Management, National Sun Yat-sen University, Kaohsiung, Taiwan","2016 Asia-Pacific Conference on Intelligent Robot Systems (ACIRS)","20160901","2016","","","84","88","Today cloud computing technologies have been rapidly advancing and researchers often provide various types of resources on the internet to share with each other. In this work, we present a cloud-based robotic service framework for robots to work on such a distributed platform. Our work includes two important services, face recognition and behavior recognition, to supports vision-based robot tasks. Experiments are conducted to validate the proposed methodology and to evaluate its corresponding performance. The results show that successful recognition can be achieved in the static and dynamic experimental environments.","","CD-ROM:978-1-5090-1361-6; Electronic:978-1-5090-1362-3; POD:978-1-5090-1363-0","10.1109/ACIRS.2016.7556193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556193","ROS;cloud computing;cloud robot;human recognition;machine learning;service robot","Cloud computing;Face;Face detection;Face recognition;Feature extraction;Streaming media","cloud computing;control engineering computing;face recognition;robot vision","Internet;behavior recognition;cloud computing technologies;cloud robotic system;face recognition;vision-based robot tasks;vision-based services","","","","","","","20-22 July 2016","","IEEE","IEEE Conference Publications"
"Automated GPR Rebar Analysis for Robotic Bridge Deck Evaluation","P. Kaur; K. J. Dana; F. A. Romero; N. Gucunski","Department of Electrical and Computer Engineering, Rutgers University, Piscataway, NJ, USA","IEEE Transactions on Cybernetics","20160914","2016","46","10","2265","2276","Ground penetrating radar (GPR) is used to evaluate deterioration of reinforced concrete bridge decks based on measuring signal attenuation from embedded rebar. The existing methods for obtaining deterioration maps from GPR data often require manual interaction and offsite processing. In this paper, a novel algorithm is presented for automated rebar detection and analysis. We test the process with comprehensive measurements obtained using a novel state-of-the-art robotic bridge inspection system equipped with GPR sensors. The algorithm achieves robust performance by integrating machine learning classification using image-based gradient features and robust curve fitting of the rebar hyperbolic signature. The approach avoids edge detection, thresholding, and template matching that require manual tuning and are known to perform poorly in the presence of noise and outliers. The detected hyperbolic signatures of rebars within the bridge deck are used to generate deterioration maps of the bridge deck. The results of the rebar region detector are compared quantitatively with several methods of image-based classification and a significant performance advantage is demonstrated. High rates of accuracy are reported on real data that includes thousands of individual hyperbolic rebar signatures from three real bridge decks.","2168-2267;21682267","","10.1109/TCYB.2015.2474747","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7302049","Automatic rebar detection;depth correction;ground penetrating radar (GPR);histogram of oriented gradients (HOG);hyperbolic signature;machine learning;pattern recognition;robotic bridge inspection;robust curve fitting;support vector machines (SVM)","Bridges;Concrete;Ground penetrating radar;Image edge detection;Robots;Support vector machines;Training","bridges (structures);feature extraction;gradient methods;ground penetrating radar;image classification;inspection;learning (artificial intelligence);radar detection;radar receivers;rebar","GPR sensor;automated GPR rebar analysis;automated rebar detection;embedded rebar;ground penetrating radar;image-based gradient feature;machine learning classification;manual interaction;offsite processing;rebar hyperbolic signature;rebar region detector;reinforced concrete bridge deck deterioration evaluation;robotic bridge deck evaluation;robust curve fitting;signal attenuation measurement;state-of-the-art robotic bridge inspection system","","1","","","","20151026","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Algorithm selection for classification problems","N. Pise; P. Kulkarni","Department of Computer Engineering and Information Technology, College of Engineering, Pune, India","2016 SAI Computing Conference (SAI)","20160901","2016","","","203","211","A number of algorithms are available in the areas of data mining, machine learning and pattern recognition for solving the same kind of problem. But there is a little guidance for suggesting algorithm to use which gives best results for the problem at hand. This paper shows an approach for solving this problem using meta-learning. The paper uses three types of data characteristics. Simple, information theoretic, and statistical data characteristics are used. Results are generated using nine different algorithms on thirty eight benchmark datasets from UCI repository. The proposed approach uses K-nearest neighbor algorithm for suggesting the suitable algorithm. Classifier accuracy is taken as a basis for recommending the algorithm. By using meta-learning, accurate method can be recommended as per the given data, and cognitive overload for applying each method, comparing with other methods and then selecting the suitable method for use can be reduced. Thus it helps in adaptive learning methods. The experimentation shows that predicted accuracies are matching with the actual accuracies for more than 90 % of the benchmark datasets used. Thus it is concluded that the number of attributes, the number of instances, the number of classes, maximum probability of class and class entropy are playing a major role in classifier accuracy and algorithm selection for thirty eight datasets used for experimentation.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7555983","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555983","algorithm selection;classifiers;data mining;machine learning;meta-learning","Bagging;Classification algorithms;Data mining;Entropy;Machine learning algorithms;Prediction algorithms;Support vector machines","data mining;entropy;learning (artificial intelligence);pattern classification;probability","K-nearest neighbor algorithm;UCI repository;adaptive learning methods;algorithm selection;class entropy;classification problems;cognitive overload;data mining;information theoretic;machine learning;maximum probability;meta-learning;pattern recognition;statistical data characteristics","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems","A. Datta; S. Sen; Y. Zick","Carnegie Mellon Univ., Pittsburgh, PA, USA","2016 IEEE Symposium on Security and Privacy (SP)","20160818","2016","","","598","617","Algorithmic systems that employ machine learning play an increasing role in making substantive decisions in modern society, ranging from online personalization to insurance and credit decisions to predictive policing. But their decision-making processes are often opaque-it is difficult to explain why a certain decision was made. We develop a formal foundation to improve the transparency of such decision-making systems. Specifically, we introduce a family of Quantitative Input Influence (QII) measures that capture the degree of influence of inputs on outputs of systems. These measures provide a foundation for the design of transparency reports that accompany system decisions (e.g., explaining a specific credit decision) and for testing tools useful for internal and external oversight (e.g., to detect algorithmic discrimination). Distinctively, our causal QII measures carefully account for correlated inputs while measuring influence. They support a general class of transparency queries and can, in particular, explain decisions about individuals (e.g., a loan decision) and groups (e.g., disparate impact based on gender). Finally, since single inputs may not always have high influence, the QII measures also quantify the joint influence of a set of inputs (e.g., age and income) on outcomes (e.g. loan decisions) and the marginal influence of individual inputs within such a set (e.g., income). Since a single input may be part of multiple influential sets, the average marginal influence of the input is computed using principled aggregation measures, such as the Shapley value, previously applied to measure influence in voting. Further, since transparency reports could compromise privacy, we explore the transparency-privacy tradeoff and prove that a number of useful transparency reports can be made differentially private with very little addition of noise. Our empirical validation with standard machine learning algorithms demonstrates that QII measures are a useful transpare- cy mechanism when black box access to the learning system is available. In particular, they provide better explanations than standard associative measures for a host of scenarios that we consider. Further, we show that in the situations we consider, QII is efficiently approximable and can be made differentially private while preserving accuracy.","","Electronic:978-1-5090-0824-7; POD:978-1-5090-0825-4","10.1109/SP.2016.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546525","fairness;machine learning;transparency","Algorithm design and analysis;Atmospheric measurements;Correlation;Decision making;Machine learning algorithms;Particle measurements;Privacy","data privacy;decision making;learning (artificial intelligence)","QII measures;Shapley value;algorithmic discrimination;algorithmic systems;algorithmic transparency;black box access;credit decisions;decision making systems;insurance decisions;learning systems;machine learning;marginal influence;online personalization;predictive policing;principled aggregation measures;quantitative input influence;system decisions;transparency queries;transparency reports;transparency-privacy tradeoff","","2","","","","","22-26 May 2016","","IEEE","IEEE Conference Publications"
"Concept Detection and Cluster Analysis from Newsfeed-Singular Value Decomposition Based Approach","R. C. Chikkamath; B. S. Babu","Comput. Sci. & Eng., Siddaganga Inst. of Technol., Tumkur, India","2016 2nd International Conference on Computational Intelligence and Networks (CINE)","20160901","2016","","","130","135","Concept detection plays an important role if there is a huge amount of data available. We know that cluster analysis, topic detection, opinion mining have got a major role in the product marketing, online shopping, E-commerce. In this paper, we have conducted the topic detection and clustering experiments on the News samples which were sourced from online newspapers. Our aim is to find out the topics which also available in the text documents as a group of words and apply a clustering technique using the Singular value decomposition method. Then opinions are extracted from the comments, collected on a particular subject of interest like the comments for Smartphone. Finally, the clustering technique is applied on these sentiments to figure out the opinions of the people towards different features of the Smartphone. The results obtained here are competitive with the technology available.","2375-5822;23755822","Electronic:978-1-5090-0451-5; POD:978-1-5090-0452-2","10.1109/CINE.2016.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556817","Clusters;Independent Component analysis;Latent semantic Indexing;Machine learning;Sentiments;Singular value decomposition;Term document matrix;Topic detection","Clustering algorithms;Data mining;Feature extraction;Indexing;Matrix decomposition;Semantics;Singular value decomposition","document handling;pattern clustering;sentiment analysis;singular value decomposition","cluster analysis;clustering technique;concept detection;newsfeed;online newspapers;opinion extraction;sentiment analysis;singular value decomposition method;smartphone;text documents;topic detection","","","","","","","11-11 Jan. 2016","","IEEE","IEEE Conference Publications"
"Car parking occupancy detection using smart camera networks and Deep Learning","G. Amato; F. Carrara; F. Falchi; C. Gennaro; C. Vairo","ISTI-CNR, via G. Moruzzi 1, Pisa, Italy","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","1212","1217","This paper presents an approach for real-time car parking occupancy detection that uses a Convolutional Neural Network (CNN) classifier running on-board of a smart camera with limited resources. Experiments show that our technique is very effective and robust to light condition changes, presence of shadows, and partial occlusions. The detection is reliable, even when tests are performed using images captured from a viewpoint different than the viewpoint used for training. In addition, it also demonstrates its robustness when training and tests are executed on different parking lots. We have tested and compared our solution against state of the art techniques, using a reference benchmark for parking occupancy detection. We have also produced and made publicly available an additional dataset that contains images of the parking lot taken from different viewpoints and in different days with different light conditions. The dataset captures occlusion and shadows that might disturb the classification of the parking spaces status.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543901","Classification;Convolutional Neural Networks;Deep Learning;Machine Learning","Automobiles;Computer architecture;Machine learning;Monitoring;Smart cameras;Training","cameras;image capture;image classification;learning (artificial intelligence);lighting;neural nets;traffic engineering computing","CNN classifier;convolutional neural network classifier;image capture;light condition;parking lots;parking space status classification;partial occlusions;real-time car parking occupancy detection","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Analytic and learning framework for quantifying Value in Value Based Care","P. Saripalli","Edifecs Inc. Bellevue, WA, USA","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","261","266","Value Based Care (VBC) is changing the way health care is administered, to cut costs and improve outcomes. There are no tools available to quantitatively assess Value. We present a fully quantitative analytic and learning framework using machine learning for assessing Value in VBC as a direct function of the Quality outcomes and Cost metrics, specific to a particular medical treatment. It can be used by various Stakeholders to plan, track, assess and agree upon the Value of a variety of healthcare services. Results are presented to demonstrate the proposed framework for the Total Hip Replacement (THR) treatment. Multivariate Regression and Logistic Regression with Dummy Coding are shown to be useful for predicting Value, using the basic algorithms proposed here.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543750","HEDIS;Healthcare;Medical Machine Learning;Total Hip Replacement (THR);Value;Value Based Care","Diseases;Hip;Measurement;Sociology;Stakeholders;Statistics","encoding;health care;learning (artificial intelligence);medical computing;patient treatment;regression analysis","THR treatment;VBC;analytic framework;dummy coding;health care service;learning framework;logistic regression;machine learning;multivariate regression;total hip replacement;value based care;value quantification","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Image Segmentation via Probabilistic Graph Matching","A. Heimowitz; Y. Keller","Faculty of Engineering, Bar-Ilan University, Ramat Gan, Israel","IEEE Transactions on Image Processing","20160819","2016","25","10","4743","4752","This paper presents an unsupervised and semi-automatic image segmentation approach where we formulate the segmentation as an inference problem based on unary and pairwise assignment probabilities computed using low-level image cues. The inference is solved via a probabilistic graph matching scheme, which allows rigorous incorporation of low-level image cues and automatic tuning of parameters. The proposed scheme is experimentally shown to compare favorably with contemporary semi-supervised and unsupervised image segmentation schemes, when applied to contemporary state-of-the-art image sets.","1057-7149;10577149","","10.1109/TIP.2016.2590832","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7511662","Image segmentation;inference algorithms;machine learning;semisupervised learning;statistical learning;unsupervised learning","Computational modeling;Cost function;Image segmentation;Minimization;Probabilistic logic;Shape;Training","graph theory;image matching;image segmentation;inference mechanisms;probability;unsupervised learning","inference problem;low-level image cue;pairwise assignment probability;parameter automatic tuning;probabilistic graph matching scheme;semiautomatic image segmentation approach;unary probability;unsupervised image segmentation approach","","","","","","20160713","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"A Framework for Ensuring the Quality of a Big Data Service","J. Ding; D. Zhang; X. H. Hu","Dept. of Comput. Sci., East Carolina Univ., Greenville, NC, USA","2016 IEEE International Conference on Services Computing (SCC)","20160901","2016","","","82","89","During past several years, we have built an online big data service called CMA that includes a group of scientific modeling and analysis tools, machine learning algorithms and a large scale image database for biological cell classification and phenotyping study. Due to the complexity and “nontestable” of scientific software and machine learning algorithms, adequately verifying and validating big data services is a grand challenge. In this paper, we introduce a framework for ensuring the quality of big data services. The framework includes an iterative metamorphic testing technique for testing “non-testable” scientific software, and an experiment based approach with stratified 10-fold cross validation for validating machine learning algorithms. The effectiveness of the framework for ensuring the quality of big data services is demonstrated through verifying and validating the software and algorithms in CMA.","","Electronic:978-1-5090-2628-9; POD:978-1-5090-2629-6","10.1109/SCC.2016.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557439","big data;diffraction image;machine learning;metamorphic testing;scientific software","Big data;Computer architecture;Diffraction;Microprocessors;Software;Testing;Three-dimensional displays","Big Data;iterative methods;learning (artificial intelligence);program testing","Big Data service quality;CMA service;biological cell classification;iterative metamorphic testing technique;large scale image database;machine learning algorithms;nontestable scientific software testing;phenotyping study;stratified 10-fold cross validation","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"On the potential of ensemble regression techniques for future mobile network planning","J. Moysen; L. Giupponi; J. Mangues-Bafalluy","Centre Tecnol&#x00F2;gic de Telecomunicacions de Catalunya-CTTC, Av. Carl Friedrich Gauss 7, 08860 Castelldefels (Spain)","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","477","483","Planning of current and future mobile networks is becoming increasingly complex due to the heterogeneity of deployments, which feature not only macrocells, but also an underlying layer of small cells whose deployment is not fully under the control of the operator. In this paper, we focus on selecting the most appropriate Quality of Service (QoS) prediction techniques for assisting network operators in planning future dense deployments. We propose to use machine learning as a tool to extract the relevant information from the huge amount of data generated in current 4G and future 5G networks during normal operation, which is then used to appropriately plan networks. In particular, we focus on radio measurements to develop correlative statistical models with the purpose of improving QoS-based network planning. In this direction, we combine multiple learners by building ensemble methods and use them to do regression in a reduced space rather than in the original one. We then compare the QoS prediction accuracy of various approaches that take as input the 3GPP Minimization of Drive Tests (MDT) measurements collected throughout a heterogeneous network and analyse their trade-offs. We also explain how the collected data is processed and used to predict QoS expressed in terms of Physical Resource Block (PRB)/ Megabit (MB) transmitted. This metric was selected because of the interest it may have for operators in planning, since it relates lower layer resources with their impact in terms of QoS up in the protocol stack, hence closer to the end-user.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543784","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543784","Big Data;Machine Learning;Minimization of Drive Tests;Network planning;Prediction;Quality of Service","3GPP;Computers;Measurement;Planning;Principal component analysis;Quality of service;Training","3G mobile communication;4G mobile communication;5G mobile communication;cellular radio;learning (artificial intelligence);mobile communication;protocols;quality of service;regression analysis;telecommunication network planning","3GPP minimization of drive tests measurements;4G networks;5G networks;MDT measurements;PRB;QoS prediction techniques;Quality of Service prediction techniques;ensemble regression techniques;heterogeneous network;machine learning;macrocells;mobile network planning;physical resource block;protocol stack;radio measurements","","1","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"A Survey on Feature Selection Techniques for Internet Traffic Classification","Y. Dhote; S. Agrawal; A. J. Deen","Dept. of Comput. Sci. & Eng., Univ. Inst. of Technol., Bhopal, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","1375","1380","Feature selection technique has a great importance in Internet traffic classification. Machine learning (ML) algorithms have been generally applied in novel traffic classification. In this paper we provide an overview of three major approaches to classify different categories of Internet traffic: Port based approach, Payload based approach, Statistical-based approach. This paper also explain feature selection algorithms, which are classified into 3 methods: Filter method, Wrapper method, Embedded Method along with their benefits and limitations and also provides an overview of some of the feature selection technique present in literature. The aim of the survey gives a brief idea about feature selection techniques which can be applied to many machine learning algorithms to avoid problems like class imbalance, concept drift, low efficiency, and low classification rate etc.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546323","feature selection;internet traffic classification;machine learning","Classification algorithms;Filtering algorithms;Internet;Machine learning algorithms;Organizations;Payloads;Ports (Computers)","Internet;feature selection;learning (artificial intelligence);pattern classification;statistical analysis","Internet traffic classification;ML;Wrapper method;embedded method;feature selection techniques;filter method;machine learning algorithms;payload based approach;port based approach;statistical-based approach","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"An elastic group recommendation system designed for multivariate dynamic attributes","N. Mysore","EMC Corporations, Santa Clara, CA","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","6","In this paper an introduction to an elastic group recommendation system is made where recommendation happens by collaborative and content filtering at three phases for multivariate dynamic attributes. Most regular recommendation systems work on static data contents where as an elastic group recommendation is designed to work for dynamic data inputs and on different use cases. recommendation systems which are commercially available today focuses on individual behavior however for events like movies and restaurants we need a group recommendation systems where group requirements are prioritized. The system introduced here is a breed model of content based and collaborative filtering techniques and filtering is done at three phases so that we can make a recommendation which works best for an individual as well as the group. The system model designed here can have wide applications in making recommendations for restaurants, movies or events for a group of people in real time for varying attributes like users tastes and preferences. On the other hand the system tries to address a classic human psychology problem called Abileneparadox [2].","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550752","Collaborative filtering;Content based filtering;Data Mining;Group recommendation systems;Hybrid models;Knowledge Discovery;Learning approaches;Machine Learning","Collaboration;Cultural differences;Databases;Electromagnetic compatibility;Feature extraction;Motion pictures;Real-time systems","collaborative filtering;data mining;recommender systems","collaborative filtering;content filtering;dynamic data input;elastic group recommendation system;multivariate dynamic attribute;static data content","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
