"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6620085,6622364,6619058,6617402,6616516,6618910,6619103,6616894,6618357,6618316,6617302,6616467,6617390,6616512,6618342,6616488,6619061,6613133,6615099,6614057,6614365,6614047,6614371,6522505,6611745,6612287,6612186,6606652,6612204,6606651,6611715,6606552,6612144,6607330,6606765,6607607,6606778,6609170,6611717,6607445,6331490,6601865,6601881,6602033,6601870,6603577,6601309,6601049,6597663,6515172,6597817,6596395,6597819,6597204,6597218,6597821,6595866,6595393,6595183,6595491,6595396,6555821,6589238,6338362,6525409,6586284,6464273,6583856,6583538,6583855,6338929,6475129,6420841,6515157,6578854,6578830,6577854,6578785,6577848,6580967,6578226,6313586,6575366,6544641,6575523,6545303,6574680,6571670,6573088,6365160,6569076,6570158,6502722,6567205,6567739,6566324,6567342,6567682,6567459,6568370",2017/05/05 22:03:45
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A Virtual Sample Generation Approach for Speculative Multithreading Using Feature Sets and Abstract Syntax Trees","B. Liu; Y. Zhao; M. Li; Y. Liu; B. Feng","Sch. of Electron. & Inf. Eng., Xi'an Jiaotong Univ., Xi'an, China","2012 13th International Conference on Parallel and Distributed Computing, Applications and Technologies","20130909","2012","","","39","44","Speculative multithreading (SpMT) is a thread level automatic parallelization technique to accelerate sequential programs. Since approaches based on heuristic rules only get the local optimal speculative thread solution and have reached their speedup performance limit, machine learning approaches have been introduced into speculative multithreading to avoid the shortcomings of the heuristic rules relied on experience. However, few irregular programs can meet the need for training model of machine learning. To solve this problem, we first build feature sets based on Olden benchmarks and then disturb them into new sets. With the new sets, virtual samples are generated by abstract syntax trees (ASTs). By this means, we effectively resolve the shortage of samples for speculative multithreading based on machine learning. On Prophet, which is a generic SpMT processor to evaluate the performance of multithread programs, the validity of virtual samples is verified and reaches an average speedup of 1.47. Experiments show that the virtual samples can simulate a variety of procedure structures of Olden benchmarks and this sample generation technique can provide sufficient samples for training model.","2379-5352;23795352","Electronic:978-0-7695-4879-1; POD:978-1-4673-5704-3","10.1109/PDCAT.2012.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6589238","Automatic Parallelization;Machine Learning;Program Features;Speculative Multithreading;Virtual Samples","Abstracts;Algorithm design and analysis;Feature extraction;Instruction sets;Multithreading;Partitioning algorithms;Training","computational linguistics;learning (artificial intelligence);multi-threading;set theory;software performance evaluation;trees (mathematics)","AST;Olden benchmarks;Prophet;abstract syntax trees;feature sets;generic SpMT processor;machine learning approach;multithread programs;performance evaluation;sequential programs;speculative multithreading;thread level automatic parallelization technique;training model;virtual sample generation approach;virtual sample verification;virtual samples","","1","","15","","","14-16 Dec. 2012","","IEEE","IEEE Conference Publications"
"Automatic detection of performance deviations in the load testing of Large Scale Systems","H. Malik; H. Hemmati; A. E. Hassan","Software Analysis and Intelligence Lab (SAIL) School of Computing, Queen's University, Kingston, Canada","2013 35th International Conference on Software Engineering (ICSE)","20130926","2013","","","1012","1021","Load testing is one of the means for evaluating the performance of Large Scale Systems (LSS). At the end of a load test, performance analysts must analyze thousands of performance counters from hundreds of machines under test. These performance counters are measures of run-time system properties such as CPU utilization, Disk I/O, memory consumption, and network traffic. Analysts observe counters to find out if the system is meeting its Service Level Agreements (SLAs). In this paper, we present and evaluate one supervised and three unsupervised approaches to help performance analysts to 1) more effectively compare load tests in order to detect performance deviations which may lead to SLA violations, and 2) to provide them with a smaller and manageable set of important performance counters to assist in root-cause analysis of the detected deviations. Our case study is based on load test data obtained from both a large scale industrial system and an open source benchmark application. The case study shows, that our wrapper-based supervised approach, which uses a search-based technique to find the best subset of performance counters and a logistic regression model for deviation prediction, can provide up to 89% reduction in the set of performance counters while detecting performance deviations with few false positives (i.e., 95% average precision). The study also shows that the supervised approach is more stable and effective than the unsupervised approaches but it has more overhead due to its semi-automated training phase.","0270-5257;02705257","Electronic:978-1-4673-3076-3; POD:978-1-4673-3075-6","10.1109/ICSE.2013.6606651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606651","Machine Learning;Performance;Signature","Control charts;Large-scale systems;Logistics;Monitoring;Principal component analysis;Radiation detectors;Testing","input-output programs;program testing;public domain software;regression analysis;software performance evaluation;unsupervised learning","CPU utilization;LSS;SLA violations;automatic performance deviation detection;deviation prediction;disk I-O;large scale systems;load testing;logistic regression model;machine learning;memory consumption;network traffic;open source benchmark application;performance counters;root-cause analysis;run-time system properties;search-based technique;service level agreements;wrapper-based supervised approach","","17","","18","","","18-26 May 2013","","IEEE","IEEE Conference Publications"
"A Wireless Electronic Training System for Cricket","I. A. Zualkernan; K. Assaleh; S. G. Dabrai; M. H. Hoque; H. Y. Pedhiwala","Comput. Sci. & Eng., AUS, Sharjah, United Arab Emirates","2013 IEEE 13th International Conference on Advanced Learning Technologies","20130919","2013","","","55","57","With the advent of cheap and readily available body-worn sensors, new electronic pedagogical approaches are emerging. This paper describes the design and development of a prototype electronic training system for the game of Cricket. The system is designed to provide real-time feedback to players and coaches to help improve technique and performance in a game. The system uses a watch with a built-in accelerometer that transmits real-time 3-axis acceleration data from a player using a proprietary wireless protocol. Machine learning techniques are used to analyze this data to provide real-time critique to the player. Player's performance data is also recorded in a Learning Management System (LMS) and a coach or the player can view various reports related to their past performance. The system has been implemented using Dynamic Time Warping (DTW) and shows over 93% accuracy.","2161-3761;21613761","Electronic:978-0-7695-5009-1; POD:978-1-4799-0373-3","10.1109/ICALT.2013.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601865","automatic game training;cricket;dynamic time warping;ez430chronos;machine learning","Accelerometers;Cameras;Games;Portable computers;Real-time systems;Watches;Wireless communication","computer based training;computer games;data analysis;learning (artificial intelligence)","Cricket game;DTW;LMS;built-in accelerometer;data analysis;dynamic time warping;learning management system;machine learning technique;proprietary wireless protocol;wireless electronic training system","","0","","13","","","15-18 July 2013","","IEEE","IEEE Conference Publications"
"Near-Optimal Coresets for Least-Squares Regression","C. Boutsidis; P. Drineas; M. Magdon-Ismail","Department of Mathematical Sciences, IBM T. J. Watson Research Center, Yorktown Heights, NY, USA","IEEE Transactions on Information Theory","20130911","2013","59","10","6880","6892","We study the (constrained) least-squares regression as well as multiple response least-squares regression and ask the question of whether a subset of the data, a coreset, suffices to compute a good approximate solution to the regression. We give deterministic, low-order polynomial-time algorithms to construct such coresets with approximation guarantees, together with lower bounds indicating that there is not much room for improvement upon our results.","0018-9448;00189448","","10.1109/TIT.2013.2272457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6555821","Least mean square algorithms;machine learning algorithms;regression analysis","Approximation algorithms;Approximation methods;Distributed databases;Electronic mail;Linear regression;Time series analysis;Vectors","least squares approximations;regression analysis","approximate solution;least squares regression;near optimal coresets;polynomial time algorithms","","4","","18","","20130709","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Signature discovery for personalized medicine","K. Y. Yeung","University of Washington, Seattle, 98195 USA","2013 IEEE International Conference on Intelligence and Security Informatics","20130815","2013","","","333","338","Various types of genome-wide data, such as sequence and gene expression data, have been generated and are available from public databases. These genome-wide data present major computational challenges as the number of variables far exceeds the number of observations. Many computational tools have been developed for the analyses of these high dimensional data, and these methods have led to improved understanding of molecular biology. In particular, signature discovery (also known as variable selection or feature selection), a machine learning technique in which subsets of variables are selected to build robust models, are useful in mining these high-dimensional functional genomic data. In this paper, we will review the applications of signature discovery methods in mining these high dimensional data. Specifically, we will focus on two applications, namely, the identification of signature genes predictive of disease phenotypes and the inference of regulatory networks. Signature genes predictive of disease phenotypes can be potentially used in the diagnosis and prognosis of diseases. Regulatory networks that capture the gene-to-gene influences can be used to provide the context of therapeutic intervention.","","Electronic:978-1-4673-6213-9; POD:978-1-4673-6214-6","10.1109/ISI.2013.6578854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578854","Bioinformatics;Machine learning;Regression analysis;Systems biology","Bayes methods;Bioinformatics;Cancer;Diseases;Gene expression;Genomics;Robustness","bioinformatics;data mining;diseases;feature extraction;genetics;genomics;learning (artificial intelligence);medical computing;patient diagnosis","computational tools;dimensional functional genomic data mining;disease diagnosis;disease phenotypes;disease prognosis;feature selection;gene expression data;gene-to-gene influences;genome-wide data;high dimensional data analysis;machine learning technique;molecular biology;public databases;regulatory network inference;regulatory networks;signature discovery methods;signature genes;variable selection","","0","","61","","","4-7 June 2013","","IEEE","IEEE Conference Publications"
"A Tour Construction Framework for the Travelling Salesman Problem","B. M. Ahrens","GSCIS, Nova Southeastern University, Fort Lauderdale-Davie, Florida, USA","2013 Proceedings of IEEE Southeastcon","20130725","2013","","","1","8","The Tour Construction Framework (TCF) integrates both global and local heuristics in a complementary framework in order to efficiently solve the Travelling Salesman Problem (TSP). Most tour construction heuristics are strictly local in nature. However, the experimental method presented in this research includes a global heuristic to efficiently solve the TSP. The Global Path (GP) component and Super Node (SN) component comprise the TCF. Each component heuristic is tuned with one or more parameters. The performance of the TCF is evaluated for speed, accuracy, and computational complexity, and it is compared against six mainstream TSP solvers: LinKernighan-Helsgaun (LKH-2), 2-Opt, Greedy, Boruvka, QuickBoruvka, and Nearest Neighbor. The empirical study demonstrates the effectiveness of the TCF in achieving near-optimal solutions for the TSP with reasonable costs.","1091-0050;10910050","Electronic:978-1-4799-0053-4; POD:978-1-4799-0052-7","10.1109/SECON.2013.6567459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567459","Combinatorial Optimization;Machine Learning;Scheduling","Cities and towns;Complexity theory;Heuristic algorithms;Measurement;Memory management;Optimization;Tin","travelling salesman problems","GP component;TCF;TSP;computational complexity;global heuristics;global path component;local heuristics;super node component;tour construction framework;travelling salesman problem","","1","","18","","","4-7 April 2013","","IEEE","IEEE Conference Publications"
"Predicting Targets of Human Reaching Motions Using Different Sensing Technologies","D. Novak; X. Omlin; R. Leins-Hess; R. Riener","Sensory-Motor Systems Lab, ETH Zurich, CH-8092 Zurich, Switzerland","IEEE Transactions on Biomedical Engineering","20130816","2013","60","9","2645","2654","Rapid recognition of voluntary motions is crucial in human-computer interaction, but few studies compare the predictive abilities of different sensing technologies. This paper thus compares performances of different technologies when predicting targets of human reaching motions: electroencephalography (EEG), electrooculography, camera-based eye tracking, electromyography (EMG), hand position, and the user's preferences. Supervised machine learning is used to make predictions at different points in time (before and during limb motion) with each individual sensing modality. Different modalities are then combined using an algorithm that takes into account the different times at which modalities provide useful information. Results show that EEG can make predictions before limb motion onset, but requires subject-specific training and exhibits decreased performance as the number of possible targets increases. EMG and hand position give high accuracy, but only once the motion has begun. Eye tracking is robust and exhibits high accuracy at the very onset of limb motion. Several advantages of combining different modalities are also shown, including advantages of combining measurements with contextual data. Finally, some recommendations are given for sensing modalities with regard to different criteria and applications. The information could aid human-computer interaction designers in selecting and evaluating appropriate equipment for their applications.","0018-9294;00189294","","10.1109/TBME.2013.2262455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6515157","Human–computer interaction;intention detection;machine learning;physiology;sensor fusion","Accuracy;Electroencephalography;Electromyography;Electrooculography;Feature extraction;Sensors;Tracking","biomechanics;cameras;electroencephalography;electromyography;learning (artificial intelligence);man-machine systems;medical signal processing","EEG;EMG;camera-based eye tracking;electroencephalography;electromyography;electrooculography;hand position;human reaching motion;human-computer interaction;limb motion;sensing technology;signal preprocessing;supervised machine learning;user preferences","Adult;Artificial Intelligence;Biomedical Engineering;Electrodiagnosis;Female;Humans;Intention;Male;Man-Machine Systems;Movement;Reproducibility of Results;Signal Processing, Computer-Assisted;Task Performance and Analysis;Upper Extremity","9","","26","","20130513","Sept. 2013","","IEEE","IEEE Journals & Magazines"
"Optimizing 1-Nearest Prototype Classifiers","P. Wohlhart; M. Köstinger; M. Donoser; P. M. Roth; H. Bischof","Inst. for Comput. Vision & Graphics, Graz Univ. of Technol., Graz, Austria","2013 IEEE Conference on Computer Vision and Pattern Recognition","20131003","2013","","","460","467","The development of complex, powerful classifiers and their constant improvement have contributed much to the progress in many fields of computer vision. However, the trend towards large scale datasets revived the interest in simpler classifiers to reduce runtime. Simple nearest neighbor classifiers have several beneficial properties, such as low complexity and inherent multi-class handling, however, they have a runtime linear in the size of the database. Recent related work represents data samples by assigning them to a set of prototypes that partition the input feature space and afterwards applies linear classifiers on top of this representation to approximate decision boundaries locally linear. In this paper, we go a step beyond these approaches and purely focus on 1-nearest prototype classification, where we propose a novel algorithm for deriving optimal prototypes in a discriminative manner from the training samples. Our method is implicitly multi-class capable, parameter free, avoids noise over fitting and, since during testing only comparisons to the derived prototypes are required, highly efficient. Experiments demonstrate that we are able to outperform related locally linear methods, while even getting close to the results of more complex classifiers.","1063-6919;10636919","Electronic:978-0-7695-4989-7; POD:978-1-4673-6410-2","10.1109/CVPR.2013.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618910","Classification;Discriminative Prototype Learning;Machine Learning;Nearest Neighbor Classification;Optimization","Computer vision;Fasteners;Kernel;Measurement;Prototypes;Training;Training data","computational complexity;computer vision;image classification;optimisation","1-nearest prototype classifier optimization;computer vision;large scale datasets;linear classifiers;locally linear methods;low complexity;multiclass handling;training samples","","4","","19","","","23-28 June 2013","","IEEE","IEEE Conference Publications"
"Superpixel Clustering and Planar Fit Segmentation of 3D LIDAR Point Clouds","H. Mahmoudabadi; T. Shoaf; M. J. Olsen","Sch. of Civil & Constr. Eng., Oregon State Univ., Corvallis, OR, USA","2013 Fourth International Conference on Computing for Geospatial Research and Application","20130919","2013","","","1","7","Terrestrial laser scanning (TLS, also called ground based Light Detection and Ranging, LIDAR) is an effective data acquisition method capable of high precision, detailed 3D models for surveying natural environments. However, despite the high density, and quality, of the data itself, the data acquired contains no direct intelligence necessary for further modeling and analysis - merely the 3D geometry (XYZ), 3-component color (RGB), and laser return signal strength (I) for each point. One common task for LIDAR data processing is the selection of an appropriate methodology for the extraction of geometric features from the irregularly distributed point clouds. Such recognition schemes must accomplish both segmentation and classification. Planar (or other geometrically primitive) feature extraction is a common method for point cloud segmentation, however, current algorithms are computationally expensive and often do not utilize color or intensity information. In this paper we present an efficient algorithm, that takes advantage of both colorimetric and geometric data as input and consists of three principal steps to accomplish a more flexible form of feature extraction. First, we employ a Simple Linear Iterative Clustering (SLIC) super pixel algorithm for clustering and dividing the colorimetric data. Second, we use a plane-fitting technique on each significantly smaller cluster to produce a set of normal vectors corresponding to each super pixel. Last, we utilize a Least Squares Multi-class Support Vector Machine (LSMSVM) to classify each cluster as either ""ground"", ""wall"", or ""natural feature"". Despite the challenging problems presented by the occlusion of features during data acquisition, our method effectively generates accurate (>85%) segmentation results by utilizing the color space information, in addition to the standard geometry, during segmentation.","","Electronic:978-0-7695-5012-1; POD:978-1-4799-0301-6","10.1109/COMGEO.2013.2","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6602033","Clustering;LIDAR;Laser Point Cloud;Machine Learning;SVM;Superpixel","Clustering algorithms;Feature extraction;Image color analysis;Laser modes;Support vector machines;Three-dimensional displays;Vectors","feature extraction;image colour analysis;iterative methods;least squares approximations;optical radar;radar computing;support vector machines","3-component color;3D LIDAR point clouds;3D geometry;LIDAR data processing;SLIC super pixel algorithm;classification;color space information;colorimetric data;data acquisition method;feature occlusion;geometric data;geometric feature extraction;ground-based light detection and ranging;high-precision detailed 3D model;irregularly-distributed point clouds;laser return signal strength;least square multiclass support vector machine;planar feature extraction;planar fit segmentation;point cloud segmentation;simple-linear iterative clustering super pixel algorithm;terrestrial laser scanning","","0","","17","","","22-24 July 2013","","IEEE","IEEE Conference Publications"
"Temporally Consistent Probabilistic Detection of New Multiple Sclerosis Lesions in Brain MRI","C. Elliott; D. L. Arnold; D. L. Collins; T. Arbel","Centre for Intelligent Machines, McGill University, Montreal, Canada","IEEE Transactions on Medical Imaging","20130729","2013","32","8","1490","1503","Detection of new Multiple Sclerosis (MS) lesions on magnetic resonance imaging (MRI) is important as a marker of disease activity and as a potential surrogate for relapses. We propose an approach where sequential scans are jointly segmented, to provide a temporally consistent tissue segmentation while remaining sensitive to newly appearing lesions. The method uses a two-stage classification process: 1) a Bayesian classifier provides a probabilistic brain tissue classification at each voxel of reference and follow-up scans, and 2) a random-forest based lesion-level classification provides a final identification of new lesions. Generative models are learned based on 364 scans from 95 subjects from a multi-center clinical trial. The method is evaluated on sequential brain MRI of 160 subjects from a separate multi-center clinical trial, and is compared to 1) semi-automatically generated ground truth segmentations and 2) fully manual identification of new lesions generated independently by nine expert raters on a subset of 60 subjects. For new lesions greater than 0.15 cc in size, the classifier has near perfect performance (99% sensitivity, 2% false detection rate), as compared to ground truth. The proposed method was also shown to exceed the performance of any one of the nine expert manual identifications.","0278-0062;02780062","","10.1109/TMI.2013.2258403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6502722","Bayesian inference;change detection;machine learning;multiple sclerosis;new lesion segmentation;subtraction imaging","Bayes methods;Image segmentation;Joints;Lesions;Magnetic resonance imaging;Manuals;Probabilistic logic","Bayes methods;biological tissues;biomedical MRI;brain;diseases;image classification;image segmentation;image sequences;learning (artificial intelligence);medical image processing","Bayesian classifier;magnetic resonance imaging;multiple sclerosis lesions;probabilistic brain tissue classification;random-forest based lesion-level classification;sequential brain MRI;temporally consistent probabilistic detection;temporally consistent tissue segmentation","Bayes Theorem;Brain;Databases, Factual;Humans;Image Interpretation, Computer-Assisted;Magnetic Resonance Imaging;Multiple Sclerosis;Reproducibility of Results","11","","37","","20130416","Aug. 2013","","IEEE","IEEE Journals & Magazines"
"Network traffic anomaly detection using clustering techniques and performance comparison","D. Liu; C. H. Lung; I. Lambadaris; N. Seddigh","Department of Systems and Computer Eng. Carleton University, Ottawa, Ontario, Canada","2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20130725","2013","","","1","4","Real-time network traffic anomaly detection is crucial for the confidentiality, integrity, and security of network information. Machine learning approaches are widely used to distinguish traffic flow outliers based on different anomalies with unique statistical characteristics. K-means clustering and Gaussian Mixture Model (GMM) are effective clustering techniques with many variations and easy to implement. Fuzzy clustering is more flexible than hard clustering and is practical for intrusion detection because of the natural treatment of data using fuzzy clustering. Fuzzy c-means clustering (FCM) is an iteratively optimal algorithm normally based on the least square method to partition data sets, which has high computational overhead. This paper proposes modifications to the objective function and the distance function that reduce the computational complexity of FCM while keeping clustering accurate. A combination of FCM clustering GMM, and feature transformation methods are proposed and a comparison of the related testing results and clustering methods is presented.","0840-7789;08407789","Electronic:978-1-4799-0033-6; POD:978-1-4799-0031-2","10.1109/CCECE.2013.6567739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567739","FCM;GMM;anomaly detection machine learning;nonnegative matrix factorization;statistical analysis","Clustering algorithms;Covariance matrices;Gaussian mixture model;Partitioning algorithms;Principal component analysis;Telecommunication traffic","Gaussian processes;fuzzy set theory;iterative methods;learning (artificial intelligence);least squares approximations;pattern clustering;security of data;statistical analysis","FCM;GMM;Gaussian mixture model;clustering techniques;fuzzy c-means clustering;fuzzy clustering;intrusion detection;iteratively optimal algorithm;k-means clustering;least square method;machine learning;network information security;performance comparison;real-time network traffic anomaly detection;statistical characteristics;traffic flow outliers","","7","","14","","","5-8 May 2013","","IEEE","IEEE Conference Publications"
"Time Series Qlet: Invariant approach for data mining","A. Anand; V. Padmanabhan","School of Computer and Information Sciences, University of Hyderabad, Hyderabad, A.P. 500046","2013 Sixth International Conference on Contemporary Computing (IC3)","20130926","2013","","","24","29","In the last decade or so the problem of Time Series Classification (TSC) has attained considerable research interests in both the Machine learning and Datamining community. In a TSC problem any real valued data is considered as a time series and the challenge is to find the best discriminating features based on the ordering of variables. Recently, the research interest has shifted to Time Series Shapelets which are small local patterns in a time series that are highly predictive of a class and are thus very useful features for building classifiers. Most of the work in time-series shapelet till date makes use of a supervised learning approach. One of the major drawbacks with the supervised shapelet approach is that they consider global features of the time series dataset to compute a shapelet which in turn leads to more time and space complexity issues. We believe that instead of taking global features of a time series data only the local features that are of interest to the problem at hand should be considered. How to find these local features from a given time series data set and to get the natural shaplet by an unsupervised approach is an interesting problem as such and in this paper we aim to propose solutions to this end. Here we introduce a new approach for time series, called Time Series Qlet, a novel approach for data mining, which addresses the above limitations. Qlets are quantized continuous subsequences of data obtained after a natural break (chunking) of quantized time series data set. Moreover we focus only on local features of a data-set ignoring the global features.","","Electronic:978-1-4799-0192-0; POD:978-1-4799-0191-3","10.1109/IC3.2013.6612204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6612204","Classification;Data Mining;Machine Learning","Data mining;Educational institutions;Entropy;Floors;Indexing;Shape;Time series analysis","data mining;time series;unsupervised learning","chunking;data mining;local features;natural time-series shapelet;quantized continuous subsequences;quantized time series data set;time series Qlet;unsupervised learning","","1","","9","","","8-10 Aug. 2013","","IEEE","IEEE Conference Publications"
"Automated extraction of non-functional requirements in available documentation","J. Slankas; L. Williams","Department of Computer Science, North Carolina State University Raleigh, North Carolina, USA","2013 1st International Workshop on Natural Language Analysis in Software Engineering (NaturaLiSE)","20130926","2013","","","9","16","While all systems have non-functional requirements (NFRs), they may not be explicitly stated in a formal requirements specification. Furthermore, NFRs may also be externally imposed via government regulations or industry standards. As some NFRs represent emergent system proprieties, those NFRs require appropriate analysis and design efforts to ensure they are met. When the specified NFRs are not met, projects incur costly re-work to correct the issues. The goal of our research is to aid analysts in more effectively extracting relevant non-functional requirements in available unconstrained natural language documents through automated natural language processing. Specifically, we examine which document types (data use agreements, install manuals, regulations, request for proposals, requirements specifications, and user manuals) contain NFRs categorized to 14 NFR categories (e.g. capacity, reliability, and security). We measure how effectively we can identify and classify NFR statements within these documents. In each of the documents evaluated, we found NFRs present. Using a word vector representation of the NFRs, a support vector machine algorithm performed twice as effectively compared to the same input to a multinomial naïve Bayes classifier. Our k-nearest neighbor classifier with a unique distance metric had an F1 measure of 0.54, outperforming in our experiments the optimal naïve Bayes classifier which had a F1 measure of 0.32. We also found that stop word lists beyond common determiners had no minimal performance effect.","","Electronic:978-1-4673-6271-9; POD:978-1-4673-6270-2","10.1109/NAturaLiSE.2013.6611715","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6611715","classification;documentation;machine learning;natural language processing;non-functional requirements","Classification algorithms;Documentation;Machine learning algorithms;Measurement;Natural languages;Security;Standards","Bayes methods;formal specification;learning (artificial intelligence);natural language processing;pattern classification;support vector machines;text analysis;user manuals","F1 measure;NFR statements;automated extraction;automated natural language processing;data use agreements;distance metric;document types;formal requirements specification;government regulations;industry standards;install manuals;k-nearest neighbor classifier;multinomial naïve Bayes classifier;nonfunctional requirements;optimal naïve Bayes classifier;support vector machine algorithm;system proprieties;unconstrained natural language documents;user manuals;word vector representation","","10","","22","","","25-25 May 2013","","IEEE","IEEE Conference Publications"
"Learning revised models for planning in adaptive systems","D. Sykes; D. Corapi; J. Magee; J. Kramer; A. Russo; K. Inoue","Imperial College London, UK","2013 35th International Conference on Software Engineering (ICSE)","20130926","2013","","","63","71","Environment domain models are a key part of the information used by adaptive systems to determine their behaviour. These models can be incomplete or inaccurate. In addition, since adaptive systems generally operate in environments which are subject to change, these models are often also out of date. To update and correct these models, the system should observe how the environment responds to its actions, and compare these responses to those predicted by the model. In this paper, we use a probabilistic rule learning approach, NoMPRoL, to update models using feedback from the running system in the form of execution traces. NoMPRoL is a technique for nonmonotonic probabilistic rule learning based on a transformation of an inductive logic programming task into an equivalent abductive one. In essence, it exploits consistent observations by finding general rules which explain observations in terms of the conditions under which they occur. The updated models are then used to generate new behaviour with a greater chance of success in the actual environment encountered.","0270-5257;02705257","Electronic:978-1-4673-3076-3; POD:978-1-4673-3075-6","10.1109/ICSE.2013.6606552","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606552","adaptive systems;feedback;machine learning;runtime model;software architecture","Adaptation models;Adaptive systems;Computational modeling;Planning;Probabilistic logic;Robot sensing systems","adaptive systems;inductive logic programming;learning (artificial intelligence);planning (artificial intelligence);software architecture","NoMPRoL technique;adaptive systems;environment domain models;execution traces;inductive logic programming task;learning revised models;machine learning;nonmonotonic probabilistic rule learning;software architecture","","7","","25","","","18-26 May 2013","","IEEE","IEEE Conference Publications"
"1st International workshop on data analysis patterns in software engineering (DAPSE 2013)","C. Bird; T. Menzies; T. Zimmermann","Microsoft Research, USA","2013 35th International Conference on Software Engineering (ICSE)","20130926","2013","","","1517","1518","Data scientists in software engineering seek insight in data collected from software projects to improve software development. The demand for data scientists with domain knowledge in software development is growing rapidly and there is already a shortage of such data scientists. Data science is a skilled art with a steep learning curve. To shorten that learning curve, this workshop will collect best practices in form of data analysis patterns, that is, analyses of data that leads to meaningful conclusions and can be reused for comparable data. In the workshop we compiled a catalog of such patterns that will help experienced data scientists to better communicate about data analysis. The workshop was targeted at experienced data scientists and researchers and anyone interested in how to analyze data correctly and efficiently in a community accepted way.","0270-5257;02705257","Electronic:978-1-4673-3076-3; POD:978-1-4673-3075-6","10.1109/ICSE.2013.6606765","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606765","big data;business intelligence;data mining;data science;machine learning;predictive analytics;smart data;software analytics;software engineering;software intelligence","Conferences;Data analysis;Data mining;Sociology;Software;Software engineering;Statistics","","","","0","","","","","18-26 May 2013","","IEEE","IEEE Conference Publications"
"3D brain tissue selection and segmentation from MRI","V. Uher; R. Burget; J. Masek; M. K. Dutta","Dept. of Telecommun., Brno Univ. of Technol., Brno, Czech Republic","2013 36th International Conference on Telecommunications and Signal Processing (TSP)","20130930","2013","","","839","842","Magnetic resonance imaging (MRI) is a visualizing method used in radiology that enables viewing internal structures of the body. Using several mathematical methods with data retrieved from MRI it is possible to quantify the brain compartment volume, which has many applications in cognitive, clinical and comparative neurosciences. This paper introduces a new fully automatic method, which can measure the volume of brain tissue using scans obtained from MRI devices. The method introduced in this paper was trained on data taken from 12 patients and the trained result was validated on other independent data obtained from 10 patients and compared to a human expert's accuracy. The result achieves 99.407 % +/- 0.062 voxel error accuracy, which is comparable to results achieved by humans (99.540 % + 0.0775) but in a significantly shorter time and without the need of human involvement.","","Electronic:978-1-4799-0404-4; POD:978-1-4799-0401-3","10.1109/TSP.2013.6614057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6614057","Image processing;brain selection;machine learning;segmentation;skull stripping","Accuracy;Brain modeling;Image segmentation;Magnetic resonance imaging;Testing;Three-dimensional displays","biological tissues;biomedical MRI;brain;image segmentation;medical image processing;volume measurement","3D brain compartment volume quantification;3D brain tissue segmentation;3D brain tissue selection;MRI device;body internal structure visualization;brain tissue volume measurement;clinical neuroscience;cognitive neuroscience;comparative neuroscience;data retrieval;magnetic resonance imaging;mathematical method;radiology;voxel error accuracy","","1","","12","","","2-4 July 2013","","IEEE","IEEE Conference Publications"
"Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets","A. Lucchi; Y. Li; P. Fua","","2013 IEEE Conference on Computer Vision and Pattern Recognition","20131003","2013","","","1987","1994","We propose a working set based approximate sub gradient descent algorithm to minimize the margin-sensitive hinge loss arising from the soft constraints in max-margin learning frameworks, such as the structured SVM. We focus on the setting of general graphical models, such as loopy MRFs and CRFs commonly used in image segmentation, where exact inference is intractable and the most violated constraints can only be approximated, voiding the optimality guarantees of the structured SVM's cutting plane algorithm as well as reducing the robustness of existing sub gradient based methods. We show that the proposed method obtains better approximate sub gradients through the use of working sets, leading to improved convergence properties and increased reliability. Furthermore, our method allows new constraints to be randomly sampled instead of computed using the more expensive approximate inference techniques such as belief propagation and graph cuts, which can be used to reduce learning time at only a small cost of performance. We demonstrate the strength of our method empirically on the segmentation of a new publicly available electron microscopy dataset as well as the popular MSRC data set and show state-of-the-art results.","1063-6919;10636919","Electronic:978-0-7695-4989-7; POD:978-1-4673-6410-2","10.1109/CVPR.2013.259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6619103","computer vision;electron microscopy;image segmentation;machine learning;structured prediction;subgradient","Approximation algorithms;Convergence;Fasteners;Image segmentation;Inference algorithms;Labeling;Training","Markov processes;gradient methods;graph theory;image segmentation;inference mechanisms;learning (artificial intelligence);random processes;support vector machines","CRFs;MSRC data set;Markov random fields;approximate inference techniques;belief propagation;conditional random fields;convergence property;electron microscopy dataset;exact inference;graph cuts;graphical models;image segmentation;loopy MRFs;margin-sensitive hinge loss minimization;max-margin learning frameworks;structured SVM cutting plane algorithm;structured prediction learning;working set based approximate subgradient descent algorithm","","4","","31","","","23-28 June 2013","","IEEE","IEEE Conference Publications"
"Ant colony based semi-greedy algorithm for regression tree induction","G. A. Melnikov; V. V. Gubarev","Novosibirsk State Technical University, Department of Computing Science, Russia","Ifost","20131003","2013","2","","238","240","Regression trees belong to a very important class of regression models which allows to split feature space into segments with building specialized local model for each of them and to achieve visualizable, easy interpretable and accurate piece-wise models. In this paper we propose a novel ant colony based semi-greedy algorithm for regression tree induction, combining techniques from both traditional regression tree induction algorithms and Ant Colony Optimization. The results of experiments on publicly available data sets show that the proposed algorithm outperforms conventional algorithms for regression tree induction in accuracy and results in less complex solutions.","","Electronic:978-1-4799-0933-9; POD:978-1-4799-0932-2","10.1109/IFOST.2013.6616894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6616894","ant colony optimization;data mining;machine learning;model trees;regression;regression trees","Computational modeling","greedy algorithms;optimisation;regression analysis;tree data structures","ant colony based semigreedy algorithm;ant colony optimization;feature space split;piecewise models;regression models;regression tree induction algorithms","","0","","12","","","June 28 2013-July 1 2013","","IEEE","IEEE Conference Publications"
"Wearable Recognition System for Physical Activities","A. M. Khan; M. Lawo; P. Homer","TZi-Univ. Bremen, Bremen, Germany","2013 9th International Conference on Intelligent Environments","20130916","2013","","","245","249","Physical activity is a major part of a user's context for wearable computing applications. The system should be able to acquire the user's physical activities by using body worn sensors. We want to develop a personal activity recognition system that is practical, reliable, and can be used for health-care related applications. We propose to use the axivity device [1] which is a ready-made, light weight, small and easy to use device for identifying basic physical activities like lying, sitting, walking, standing, cycling, running, ascending and descending stairs using decision tree classifier. In this paper, we present an approach to build a system that exhibits this property and provides evidence based on data for 8 different activities collected from 12 different subjects. Our results indicate that the system has a good accuracy rate.","","Electronic:978-0-7695-5038-1; POD:978-1-4799-0745-8","10.1109/IE.2013.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597819","3D accelerometer sensor;Physical activities;machine learning classifiers","","biomedical equipment;body sensor networks;health care;patient monitoring;telemedicine;wearable computers","axivity device;body worn sensor;health-care related application;personal activity recognition system;physical activity;wearable computing application;wearable recognition system","","2","","21","","","16-17 July 2013","","IEEE","IEEE Conference Publications"
"Bayesian posterior probability classification of colorectal cancer probed with Affymetrix microarray technology","M. Simjanoska; A. Madevska Bogdanova; Z. Popeska","Ss. Cyril and Methodius University, Faculty of Information Sciences and Computer Engineering, Skopje, Macedonia","2013 36th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20130916","2013","","","959","964","Colorectal cancer is one of the most common types of cancer worldwide. Assuming increased or decreased gene expression is the reason for abnormal cells work and processes interference in the colorectal region, in our previous work we used data from Illumina microarray technology to analyse gene expression values. Once we have unveiled biomarker genes and developed methodology for Bayesian posterior probability classification, we proceeded with implementing the same methodology on data obtained from Affymetrix microarray technology. However, our research results showed that different microarray technologies require different statistical approach for classification analyses. In this paper we use colorectal data probed with Affymetrix microarray technology, and propose a new methodology that intends to eliminate the noise and produce more robust preprocessed data appropriate for prior distribution modelling. This allows us to construct an efficient Bayesian a posteriori classificator. In order to test the procedure reliability we used different set of carcinogenic and healthy patients.","","Electronic:978-953-233-073-1; POD:978-0-7695-4695-7; POD:978-953-233-073-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6596395","Affymetrix;Bayesian Classification;Colorectal Cancer;Illumina;Machine Learning;Microarray Technology","Bayes methods;Biological system modeling;Cancer;Gene expression;Testing","cancer;genetic engineering;lab-on-a-chip;learning (artificial intelligence);medical computing;probability","Bayesian posterior probability classification;abnormal cells;affymetrix microarray technology;approach;carcinogenic;classification analyses;colorectal cancer;colorectal data;gene expression;genes;healthy patients;illumina microarray technology;machine learning method;posteriori classificator;preprocessed data;prior distribution modelling;procedure reliability;processes interference;statistical approach;unveiled biomarker genes","","0","","29","","","20-24 May 2013","","IEEE","IEEE Conference Publications"
"Prostate Histopathology: Learning Tissue Component Histograms for Cancer Detection and Classification","L. Gorelick; O. Veksler; M. Gaed; J. A. Gómez; M. Moussa; G. Bauman; A. Fenster; A. D. Ward","Departments of Computer Science and Medical Biophysics, Robarts Research Institute, Western University, London, Canada","IEEE Transactions on Medical Imaging","20130927","2013","32","10","1804","1818","Radical prostatectomy is performed on approximately 40% of men with organ-confined prostate cancer. Pathologic information obtained from the prostatectomy specimen provides important prognostic information and guides recommendations for adjuvant treatment. The current pathology protocol in most centers involves primarily qualitative assessment. In this paper, we describe and evaluate our system for automatic prostate cancer detection and grading on hematoxylin & eosin-stained tissue images. Our approach is intended to address the dual challenges of large data size and the need for high-level tissue information about the locations and grades of tumors. Our system uses two stages of AdaBoost-based classification. The first provides high-level tissue component labeling of a superpixel image partitioning. The second uses the tissue component labeling to provide a classification of cancer versus noncancer, and low-grade versus high-grade cancer. We evaluated our system using 991 sub-images extracted from digital pathology images of 50 whole-mount tissue sections from 15 prostatectomy patients. We measured accuracies of 90% and 85% for the cancer versus noncancer and high-grade versus low-grade classification tasks, respectively. This system represents a first step toward automated cancer quantification on prostate digital histopathology imaging, which could pave the way for more accurately informed postprostatectomy patient care.","0278-0062;02780062","","10.1109/TMI.2013.2265334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6522505","Automated prostate cancer detection;cancer grading;digital pathology image analysis;machine learning;quantitative pathology, superpixels","Accuracy;Glands;Histograms;Labeling;Pathology;Prostate cancer","cancer;image classification;learning (artificial intelligence);medical image processing;patient care;tumours","AdaBoost-based classification;adjuvant treatment;automatic prostate cancer detection;cancer classification;cancer quantification;digital histopathology imaging;digital pathology images;eosin-stained tissue images;hematoxylin;high-level tissue component labeling;high-level tissue information;learning tissue component histograms;organ-confined prostate cancer;postprostatectomy patient care;prostate histopathology;prostatectomy patients;prostatectomy specimen;radical prostatectomy;superpixel image partitioning;tumor grades;whole-mount tissue","Artificial Intelligence;Histological Techniques;Humans;Image Interpretation, Computer-Assisted;Male;Prognosis;Prostate;Prostatectomy;Prostatic Neoplasms","17","","46","","20130531","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Towards behaviour inference in smart environments","M. Antunes; D. Gomes; R. Aguiar","Instituto de Telecomunica&#x00E7;&#x00F5;es, Universidade de Aveiro, Portugal","2013 Conference on Future Internet Communications (CFIC)","20130725","2013","","","1","8","Smart environments are physical places that are richly and invisibly populated with sensors, actuators and computational elements. The objective of such environments is to adapt themselves to its users in order to increase their comfort and usefulness. This paper proposes a platform, named APOLLO, capable of inferring behaviour rules from a smart environment and apply them to provide an intelligent space. The APOLLO platform is built upon a Service Oriented Architecture (SOA), in which collected context information is used to infer behaviour rules though statistical and machine learning techniques. The proposed platform is to be deployed in a home automation scenario.","","Electronic:978-1-4799-0059-6; POD:978-1-4799-0058-9","10.1109/CFIC.2013.6566324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6566324","SOA;Smart environments;knowledge extraction;machine learning","Actuators;Context;Intelligent sensors;Optimization;Temperature measurement;Temperature sensors","actuators;home automation;learning (artificial intelligence);sensors;service-oriented architecture;statistical analysis","APOLLO;SOA;actuators;behaviour inference;behaviour rules;computational elements;context information;home automation scenario;intelligent space;machine learning techniques;sensors;service oriented architecture;smart environments;statistical techniques","","0","","21","","","15-16 May 2013","","IEEE","IEEE Conference Publications"
"Emotion tracking in music using continuous conditional random fields and relative feature representation","V. Imbrasaitė; T. Baltrušaitis; P. Robinson","Computer Laboratory, University of Cambridge, UK","2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)","20131003","2013","","","1","6","Digitization of how people acquire music calls for better music information retrieval techniques, and dimensional emotion tracking is increasingly seen as an attractive approach. Unfortunately, the majority of models we still use are borrowed from other problems that do not suit emotion prediction well, as most of them tend to ignore the temporal dynamics present in music and/or the continuous nature of Arousal-Valence space. In this paper we propose the use of Continuous Conditional Random Fields for dimensional emotion tracking and a novel feature vector representation technique. Both approaches result in a substantial improvement on both rootmean-squared error and correlation, for both short and long term measurements. In addition, they can both be easily extended to multimodal approaches to music emotion recognition.","","Electronic:978-1-4799-1604-7; POD:978-1-4799-1603-0; USB:978-1-4799-1602-3","10.1109/ICMEW.2013.6618357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618357","Arousal-Valence space;acoustic features;continuous emotions;feature representation;machine learning","Correlation;Emotion recognition;Feature extraction;Mathematical model;Measurement uncertainty;Training;Vectors","emotion recognition;feature extraction;information retrieval;music;signal representation;statistical analysis","arousal-valence space;continuous conditional random fields;dimensional emotion tracking;long term measurements;multimodal approach;music emotion recognition;music information retrieval techniques;relative feature vector representation technique;root mean-squared error;short term measurements;temporal dynamics","","3","","25","","","15-19 July 2013","","IEEE","IEEE Conference Publications"
"Learning context to adapt business processes","J. d. E. S. Carvalho; F. M. Santoro; K. Revoredo; V. T. Nunes","Postgraduate Information Systems Program, UNIRIO, Rio de Janeiro, Brazil","Proceedings of the 2013 IEEE 17th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20130815","2013","","","229","234","Dynamic adaptation is the customization of a business process to make it applicable to a particular situation at any time of its life cycle. Adapting requires experience, and involves knowledge about various, internal and external, aspects of business. Thus, we argue for the application of adaptation rules, considering the context of a particular process instance. Furthermore, we state that a context-based adaptation environment should go beyond, and learn from decisions, as well as continuously identify new unforeseen situations (context definitions). The aim of this paper is to present a computational engine that infers the need to update situations and adaptation rules, suggesting changes to them. An application scenario is presented to discuss the usage of the proposal.","","Electronic:978-1-4673-6085-2; POD:978-1-4673-6084-5","10.1109/CSCWD.2013.6580967","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6580967","Context;Machine learning;Process adaptation","Adaptation models;Aircraft;Context;Itemsets;Proposals;Runtime","business data processing;learning (artificial intelligence)","business process customization;computational engine;context-based adaptation environment;dynamic adaptation;learning context","","1","","21","","","27-29 June 2013","","IEEE","IEEE Conference Publications"
"Improvement of assistive robot behavior by experience-based learning","P. Nauth","Fachhochschule Frankfurt a.M. - University of Applied Sciences, Germany","2013 6th International Conference on Human System Interactions (HSI)","20130815","2013","","","363","367","Robots designed for assisting humans in their homes need to adapt to the changing requirements of daily life. This requires multimodal sensor systems as well as learning strategies for understanding new goals and for recognizing new objects. However, coping with changes is not limited to environmental sensing. In order to achieve full autonomy, the robots must adapt their behavior due to good and bad experiences made. Concepts and first results of modelling intelligent sensing and adaptive behavior in an artificial mind as well as of merging mind and machine are presented in this paper.","2158-2246;21582246","Electronic:978-1-4673-5637-4; POD:978-1-4673-5635-0","10.1109/HSI.2013.6577848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6577848","Adaptive Behavior;Autonomous Robots;Experience-based Learning;Human-Interactive Robots;Intelligent Multimodal Sensor Systems;Machine Learning;Robot Intelligence;Self-Generating Will","","educational robots;human-robot interaction;intelligent robots;learning (artificial intelligence);object recognition;robot vision;sensors;service robots","adaptive behavior;artificial mind;assistive robot behavior;environmental sensing;experience-based learning;intelligent sensing modelling;learning strategies;multimodal sensor systems;object recognition","","0","","10","","","6-8 June 2013","","IEEE","IEEE Conference Publications"
"CASAS: A Smart Home in a Box","D. J. Cook; A. S. Crandall; B. L. Thomas; N. C. Krishnan","Washington State University","Computer","20130808","2013","46","7","62","69","The CASAS architecture facilitates the development and implementation of future smart home technologies by offering an easy-to-install lightweight design that provides smart home capabilities out of the box with no customization or training.","0018-9162;00189162","","10.1109/MC.2012.328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6313586","activity discovery;activity recognition;machine learning;pervasive computing;smart home","Computer architecture;Intelligent sensors;Knowledge discovery;Machine learning;Middleware;Pervasive computing;Smart homes","home computing","CASAS architecture;lightweight design;smart home technologies","","48","","11","","20120926","July 2013","","IEEE","IEEE Journals & Magazines"
"A Unified Probabilistic Approach to Improve Spelling in an Event-Related Potential-Based Brain–Computer Interface","P. J. Kindermans; H. Verschore; B. Schrauwen","Department of Electronics and Information Systems, Ghent University, Ghent, Belgium","IEEE Transactions on Biomedical Engineering","20130916","2013","60","10","2696","2705","In recent years, in an attempt to maximize performance, machine learning approaches for event-related potential (ERP) spelling have become more and more complex. In this paper, we have taken a step back as we wanted to improve the performance without building an overly complex model, that cannot be used by the community. Our research resulted in a unified probabilistic model for ERP spelling, which is based on only three assumptions and incorporates language information. On top of that, the probabilistic nature of our classifier yields a natural dynamic stopping strategy. Furthermore, our method uses the same parameters across 25 subjects from three different datasets. We show that our classifier, when enhanced with language models and dynamic stopping, improves the spelling speed and accuracy drastically. Additionally, we would like to point out that as our model is entirely probabilistic, it can easily be used as the foundation for complex systems in future work. All our experiments are executed on publicly available datasets to allow for future comparison with similar techniques.","0018-9294;00189294","","10.1109/TBME.2013.2262524","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6515172","Brain-computer interface (BCI);P300;dynamic stopping;event-related potential;language models;machine learning","Brain modeling;Computational modeling;Electroencephalography;Predictive models;Probabilistic logic;Training;Vectors","bioelectric potentials;brain-computer interfaces;electroencephalography;languages;learning (artificial intelligence);medical computing;medical signal processing;neurophysiology;physiological models;probability","ERP spelling accuracy;ERP spelling speed;brain-computer interface;classifier;complex system;dataset;dynamic stopping strategy;event-related potential;language model;machine learning approach;unified probabilistic model","Algorithms;Artificial Intelligence;Brain-Computer Interfaces;Data Interpretation, Statistical;Electroencephalography;Evoked Potentials, Visual;Humans;Language;Visual Cortex;Writing","17","","31","","20130513","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Image visualization based malware detection","K. Kancherla; S. Mukkamala","Institute for Complex Additive Systems and Analysis, (ICASA), New Mexico Institute of Mining and Technology, Socorro, 87801, U.S.A.","2013 IEEE Symposium on Computational Intelligence in Cyber Security (CICS)","20130916","2013","","","40","44","Malware detection is one of the challenging tasks in Cyber security. The advent of code obfuscation, metamorphic malware, packers and zero day attacks has made malware detection a challenging task. In this paper we present a visualization based approach for malware detection. First the executable is converted to a gray-scale image called byteplot. Later we extract low level features like intensity based and texture based features. We apply computationally intelligent techniques for malware detection using these features. In this work we used Support Vector Machines (SVMs) and obtained an accuracy of 95% on a dataset containing 25000 malware and 12000 benign samples.","","Electronic:978-1-4673-5867-5; POD:978-1-4673-5866-8","10.1109/CICYBS.2013.6597204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597204","Machine Learning;Malware Detection;Support Vector Machines (SVMs);Textures based Features","Accuracy;Feature extraction;Malware;Support vector machines;Visualization;Wavelet transforms","image colour analysis;invasive software;support vector machines","SVM;byteplot;code obfuscation;cyber security;gray-scale image;image visualization;malware detection;metamorphic malware;support vector machines;zero day attacks","","4","","18","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Big data, little decisions: Tightening the loop between data crunching and human expertise","Z. Bennett; M. G. L'Heureux","LexisNexis, Dayton, Ohio USA","2013 International Conference on Collaboration Technologies and Systems (CTS)","20130725","2013","","","65","66","This presentation is a case study examining how LexisNexis uses scaled active learning on the HPCC Systems environment to focus manual topical annotations on critical documents pulled from a large corpus. The active learning system uses natural language processing and machine learning techniques to identify and present “next best” training set candidates to legal editors, combining massive parallel processing with expert human analysis to improve classifier accuracy while minimizing human effort.","","Electronic:978-1-4673-6404-1; POD:978-1-4673-6403-4","10.1109/CTS.2013.6567205","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567205","active learning;annotations;large corpus;machine learning;text classification;training set","Classification algorithms;Data handling;Data storage systems;Information management;Parallel processing;Support vector machines;Training","learning (artificial intelligence);natural language processing;parallel processing;text analysis","HPCC systems environment;LexisNexis;classifier accuracy;critical documents;data crunching;expert human analysis;machine learning techniques;massive parallel processing;natural language processing;scaled active learning system;text classification","","0","","7","","","20-24 May 2013","","IEEE","IEEE Conference Publications"
"Generic Approach for Security Error Detection Based on Learned System Behavior Models for Automated Security Tests","C. Schanes; A. Hübler; F. Fankhauser; T. Grechenig","Ind. Software (INSO), Vienna Univ. of Technol., Vienna, Austria","2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops","20130801","2013","","","453","460","The increasing complexity of software and IT systems creates the necessity for research on technologies addressing current key security challenges. To meet security requirements in IT infrastructures, a security engineering process has to be established. One crucial factor contributing to a higher level of security is the reliable detection of security vulnerabilities during security tests. In the presented approach, we observe the behavior of the system under test and introduce machine learning methods based on derived behavior metrics. This is a generic method for different test targets which improves the accuracy of the security test result of an automated security testing approach. Reliable automated determination of security failures in security test results increases the security quality of the tested software and avoids costly manual validation.","","Electronic:978-0-7695-4993-4; POD:978-1-4799-1324-4","10.1109/ICSTW.2013.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6571670","Machine learning;Robustness;Security;System testing;Unsupervised learning","Measurement;Monitoring;Neurons;Security;Software;Testing;Vectors","learning (artificial intelligence);program testing;security of data;software quality","IT infrastructures;automated security testing approach;behavior metrics;generic approach;machine learning methods;security engineering process;security error detection;security failure automated determination;security vulnerability detection;software testing security quality;system behavior model learning","","0","","27","","","18-22 March 2013","","IEEE","IEEE Conference Publications"
"A centralized management framework of network-based Intrusion Detection and Prevention System","E. Wonghirunsombat; T. Asawaniwed; V. Hanchana; N. Wattanapongsakorn; S. Srakaew; C. Charnsripinyo","Department of Computer Engineering, King Mongkut's University of Technology Thonburi, Bangkok, Thailand","The 2013 10th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20130725","2013","","","183","188","Many network attacks on the internet such as Denial of Service, Port Scanning, and Internet Worm can cause a lot of problems to a network system and tend to be more severe. Therefore, awareness of internet attacks is important. In this paper, we propose a centralized management framework of network-based Intrusion Detection and Prevention System (IDPS) via web application, which allows the network administrator to remotely and efficiently manage the smultiple network-based IDPSsecurity of network system. In our new framework design, multiple network-based IDPSs can be placed in various locations to inspect internet packets in the network. Each IDPS can be easily managed from anywhere and anytime by using a personal computer or a mobile device through a web browser. The web-based management system allows the network administrator to remotely monitor and handle security issues such as managing network port and IP address, updating new network information to identify new malware attacks, as well as displaying the system performance and result analysis. In addition, our network-based IDPS approach can efficiently detect network attacks and internet worms within a short time (i.e., within 2-3 seconds). Several well-known machine learning algorithms can be applied as traffic classification technique in our IDPS approach. From experimental results, we found that our network-based IDPS can analyze internet traffic which include normal packets and malware packets with high accuracy (more than 99%) as well as can immediately protect the network after intrusion detection.","","Electronic:978-1-4799-0806-6; POD:978-1-4799-0805-9","10.1109/JCSSE.2013.6567342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567342","IDPS (Intrusion Detection and Prevention System);internet worm detection;machine learning;online detection;web application","Grippers;IP networks;Internet;Intrusion detection;Ports (Computers);Probes;Servers","Internet;computer network security;invasive software;learning (artificial intelligence);online front-ends;pattern classification;telecommunication traffic","Internet attacks;Internet packet inspection;Internet traffic;Internet worm;Web application;Web browser;Web-based management system;centralized management framework;denial of service;machine learning algorithms;malware packets;mobile device;multiple network-based IDPS;network attack detection;network system security;network-based intrusion detection and prevention system;normal packets;personal computer;port scanning;traffic classification technique","","1","2","15","","","29-31 May 2013","","IEEE","IEEE Conference Publications"
"Early lung cancer detection using nucleus segementation based features","K. Kancherla; S. Mukkamala","Institute for Complex Additive Systems and Analysis (ICASA) Computational Analysis and Network Enterprise Solutions (CAaNES) New Mexico Institute of Mining and Technology Socorro, New Mexico 87801, U.S.A.","2013 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20130912","2013","","","91","95","In this study we propose an early lung cancer detection methodology using nucleus based features. First the sputum samples from patients are labeled with Tetrakis Carboxy Phenyl Porphine (TCPP) and fluorescent images of these samples are taken. TCPP is a porphyrin that is able to assist in labeling lung cancer cells by increasing numbers of low density lipoproteins coating on the surface of cancer. We study the performance of well know machine learning techniques in the context of lung cancer detection on Biomoda dataset. We obtained an accuracy of 81% using 71 features related to shape, intensity and color in our previous work. By adding the nucleus segmented features we improved the accuracy to 87%. Nucleus segmentation is performed by using Seeded region growing segmentation method. Our results demonstrate the potential of nucleus segmented features for detecting lung cancer.","","Electronic:978-1-4673-5875-0; POD:978-1-4673-5874-3","10.1109/CIBCB.2013.6595393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595393","Bioinformatics;Lung Cancer detection;Machine Learning;Seeded Region Growing segmentation","Accuracy;Bioinformatics;Cancer;Cancer detection;Feature extraction;Lungs;Shape","biology computing;cancer;feature extraction;image colour analysis;image segmentation;learning (artificial intelligence);object detection","Biomoda dataset;TCPP image;Tetrakis Carboxy Phenyl Porphine image;color feature;early lung cancer detection;fluorescent image;intensity feature;machine learning technique;nucleus segmentation based feature;seeded region growing segmentation method;shape feature","","1","2","21","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"An Adaptive Interface for Computer-Assisted Rubrics in an E-Marking Tool Using Nearest Neighbor","I. Cabrera; J. Villalon","Sch. of Eng. & Sci., Adolfo Ibanez Univ., Santiago, Chile","2013 IEEE 13th International Conference on Advanced Learning Technologies","20130919","2013","","","72","76","With an always growing number of student enrolment in higher education, providing quality feedback in both digital and paper based assessment becomes a heavy burden for teachers and tutors. The use of assessment rubrics can help overcome this burden, defining several criteria including formative feedback within it. However, current computer-assisted rubric systems present some drawbacks that hinder their adoption. This paper presents the design of an adaptive interface for an e-Marking tool that uses rubrics, that is able to suggest assessors on the next criterion to be evaluated, based on nearest neighbor approach. An experimental setup showed encouraging results that provide evidence that the use of advanced learning technologies for assessment can help improve efficiency even in ill-defined domains.","2161-3761;21613761","Electronic:978-0-7695-5009-1; POD:978-1-4799-0373-3","10.1109/ICALT.2013.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601870","computer-assisted rubrics;e-assessment;e-marking;evaluations;machine learning;rubrics","Algorithm design and analysis;Computers;Educational institutions;Prediction algorithms;Reliability;Visualization","computer aided instruction;further education;learning (artificial intelligence)","computer-assisted rubrics;digital based assessment;e-marking tool;electronic marking tool;higher education;learning technology;nearest neighbor approach;paper based assessment;student enrolment","","0","","16","","","15-18 July 2013","","IEEE","IEEE Conference Publications"
"Patterns of chromatin-modifications discriminate different genomic features in Arabidopsis","A. Srivastava; X. Zhang; S. Lamarca; L. Cai; R. L. Malmberg","Institute of Bioinformatics, University of Georgia, Athens, GA 30602-7229, USA. Also with The Jackson Laboratory, Bar Harbor, Maine 04609, USA","Tsinghua Science and Technology","20131003","2013","18","5","431","440","Dynamic regulation and packaging of genetic information is achieved by the organization of DNA into chromatin. Nucleosomal core histones, which form the basic repeating unit of chromatin, are subject to various post-translational modifications such as acetylation, methylation, phosphorylation, and ubiquitinylation. These modifications have effects on chromatin structure and, along with DNA methylation, regulate gene transcription. The goal of this study was to determine if patterns in modifications were related to different categories of genomic features, and, if so, if the patterns had predictive value. In this study, we used publically available data (ChIP-chip) for different types of histone modifications (methylation and acetylation) and for DNA methylation for Arabidopsis thaliana and then applied a machine learning based approach (a support vector machine) to demonstrate that patterns of these modifications are very different among different kinds of genomic feature categories (protein, RNA, pseudogene, and transposon elements). These patterns can be used to distinguish the types of genomic features. DNA methylation and H3K4me3 methylation emerged as features with most discriminative power. From our analysis on Arabidopsis, we were able to predict 33 novel genomic features, whose existence was also supported by analysis of RNA-seq experiments. In summary, we present a novel approach which can be used to discriminate/detect different categories of genomic features based upon their patterns of chromatin modification and DNA methylation.","","","10.1109/TST.2013.6616516","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6616516","Arabidopsis;DNA methylation;chromatin modification;machine learning;support vector machine","Bioinformatics;DNA;Genomics;Packaging;Proteins;RNA;Support vector machines","","","","0","","","","","Oct. 2013","","TUP","TUP Journals & Magazines"
"Sign language recognition using Microsoft Kinect","A. Agarwal; M. K. Thakur","Department of Computer Science and Engineering, Jaypee Institute of Information Technology, Noida, India - 201307","2013 Sixth International Conference on Contemporary Computing (IC3)","20130926","2013","","","181","185","In last decade lot of efforts had been made by research community to create sign language recognition system which provide a medium of communication for differently-abled people and their machine translations help others having trouble in understanding such sign languages. Computer vision and machine learning can be collectively applied to create such systems. In this paper, we present a sign language recognition system which makes use of depth images that were captured using a Microsoft Kinect® camera. Using computer vision algorithms, we develop a characteristic depth and motion profile for each sign language gesture. The feature matrix thus generated was trained using a multi-class SVM classifier and the final results were compared with existing techniques. The dataset used is of sign language gestures for the digits 0-9.","","Electronic:978-1-4799-0192-0; POD:978-1-4799-0191-3","10.1109/IC3.2013.6612186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6612186","computer vision;gesture recognition;kernel;machine learning;sign language recognition;support vector machine","Accuracy;Assistive technology;Feature extraction;Gesture recognition;Kernel;Support vector machines;Training","computer vision;learning (artificial intelligence);pattern classification;sign language recognition;support vector machines","Microsoft Kinect camera;characteristic depth;computer vision algorithms;depth images;feature matrix;machine learning;motion profile;multiclass SVM classifier;sign language gesture;sign language recognition system","","7","","18","","","8-10 Aug. 2013","","IEEE","IEEE Conference Publications"
"PARNT: A Statistic based Approach to Extract Non-Taxonomic Relationships of Ontologies from Text","I. Serra; R. Girardi; P. Novais","Comput. Sci. Dept., Fed. Univ. of Maranhao, Sa&#x0303;o Lui&#x0301;s, Brazil","2013 10th International Conference on Information Technology: New Generations","20130930","2013","","","561","566","Learning Non-Taxonomic Relationships is a sub-field of Ontology learning that aims at automating the extraction of these relationships from text. This article proposes PARNT, a novel approach that supports ontology engineers in extracting these elements from corpora of plain English. PARNT is parametrized, extensible and uses original solutions that help to achieve better results when compared to other techniques for extracting non-taxonomic relationships from ontology concepts and English text. To evaluate the PARNT effectiveness, a comparative experiment with another state of the art technique was conducted.","","Electronic:978-0-7695-4967-5; POD:978-1-4673-5960-3","10.1109/ITNG.2013.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6614365","Learning non-taxonomic relationships;Machine learning;Natural language processing;Ontology;Ontology learning","Association rules;Logistics;Natural language processing;Ontologies;Proposals","learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);statistical analysis;text analysis","English text;PARNT;learning nontaxonomic relationships of ontologies;natural language processing;ontology concepts;ontology learning;plain English language;statistic based approach","","6","","27","","","15-17 April 2013","","IEEE","IEEE Conference Publications"
"Analyzing Student Viewing Patterns in Lecture Videos","C. Ullrich; R. Shen; W. Xie","Dept. of Comput. Sci., Shanghai Jiao Tong Univ., Shanghai, China","2013 IEEE 13th International Conference on Advanced Learning Technologies","20130919","2013","","","115","117","A large amount of educational content is available as lecture videos, which record teachers as they proceed through a course. Students watch these videos in different ways. They rewind, skip forward, watch some scenes repeatedly. This work investigates what can be learned by analyzing such viewing patterns. We show how to use machine learning techniques to analyze such data, and present the outcomes of an analysis of data collected from the interactions of 2992 students in 253 courses. The viewing pattern were put into relation to seven different variables, such as the final score of the student and the rating teachers received from students Our analysis shows that some variables, such as the teacher rating, were indeed predictable from the viewing patterns.","2161-3761;21613761","Electronic:978-0-7695-5009-1; POD:978-1-4799-0373-3","10.1109/ICALT.2013.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601881","educational datamining;learning analytics;lecture videos;machine learning","Computer science;Educational institutions;Media;Navigation;Vectors;Videos","computer aided instruction;learning (artificial intelligence)","educational content;lecture videos;machine learning techniques;student viewing patterns","","1","","4","","","15-18 July 2013","","IEEE","IEEE Conference Publications"
"SentiMeter-Br: A Social Web Analysis Tool to Discover Consumers' Sentiment","R. L. Rosa; D. Z. Rodriguez; G. Bressan","Dept. of Comput. Sci. & Digital Syst., Univ. of Sao Paulo, Sao Paulo, Brazil","2013 IEEE 14th International Conference on Mobile Data Management","20130729","2013","2","","122","124","This article analyzes Brazilian Consumers' Sentiments in a specific domain using a system, SentiMeter-Br. A Portuguese dictionary focused in a specific field of study was built, in which tenses and negative words are treated in a different way to measure the polarity, the strength of positive or negative sentiment, in short texts extracted from Twitter. For the Portuguese Dictionary performance validation, the results are compared with the SentiStrength tool and are evaluated by three Specialists in the field of study; each one analyzed 2000 texts captured from Twitter. Comparing the efficiency of the SentiMeter-Br and the SentiStrength against the Specialists' opinion, a Pearson correlation factor of 0.89 and 0.75 was reached, respectively, proving that the metric used in the Sentimeter-Br is better than the one used in the SentiStrength. The polarity of the short texts were also tested through machine learning, with correctly classified instances of 71.79% by Sequential Minimal Optimization algorithm and F-Measure of 0.87 for positive and 0.91 for negative phrases. Another contribution is a Twitter and Facebook search framework that extracts online tweets and Facebook posts, the latter with geographic location, gender and birth date of the user who posted the comments, and can be accessed by mobile phones.","1551-6245;15516245","Electronic:978-0-7695-4973-6; POD:978-1-4673-6068-5","10.1109/MDM.2013.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6569076","Facebook;Twitter;consumer sentiment;machine learning;social web analysis tool;support vector machines","Classification algorithms;Decision trees;Dictionaries;Facebook;Hair;Software;Twitter","consumer behaviour;data mining;dictionaries;information retrieval;learning (artificial intelligence);natural language processing;optimisation;performance evaluation;social networking (online);text analysis","Brazilian consumer sentiment analysis;F-Measure;Facebook posts;Facebook search framework;Pearson correlation factor;Portuguese dictionary performance validation;SentiMeter-Br;Twitter;birth date;consumer sentiment discovery;gender;geographic location;machine learning;mobile phones;negative phrases;negative sentiment;negative words;online tweet extraction;positive phrases;positive sentiment;sequential minimal optimization algorithm;short texts;social Web analysis tool;specialist opinion;tenses","","1","","3","","","3-6 June 2013","","IEEE","IEEE Conference Publications"
"On Nonparametric Ordinal Classification with Monotonicity Constraints","W. Kotlowski; R. Slowinski","Inst. of Comput. Sci., Pozna'n Univ. of Technol., Pozna'n, Poland","IEEE Transactions on Knowledge and Data Engineering","20130919","2013","25","11","2576","2589","We consider the problem of ordinal classification with monotonicity constraints. It differs from usual classification by handling background knowledge about ordered classes, ordered domains of attributes, and about a monotonic relationship between an evaluation of an object on the attributes and its class assignment. In other words, the class label (output variable) should not decrease when attribute values (input variables) increase. Although this problem is of great practical importance, it has received relatively low attention in machine learning. Among existing approaches to learning with monotonicity constraints, the most general is the nonparametric approach, where no other assumption is made apart from the monotonicity constraints assumption. The main contribution of this paper is the analysis of the nonparametric approach from statistical point of view. To this end, we first provide a statistical framework for classification with monotonicity constraints. Then, we focus on learning in the nonparametric setting, and we consider two approaches: the ""plug-in"" method (classification by estimating first the class conditional distribution) and the direct method (classification by minimization of the empirical risk). We show that these two methods are very closely related. We also perform a thorough theoretical analysis of their statistical and computational properties, confirmed in a computational experiment.","1041-4347;10414347","","10.1109/TKDE.2012.204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331490","Machine learning;isotonic classification;isotonic regression;monotone functions;monotonicity constraints;nonparametric methods;ordinal classification;ordinal regression;preference learning","Input variables;Loss measurement;Machine learning;Minimization;Probability distribution;Training;Vectors","learning (artificial intelligence);pattern classification;statistical analysis","direct method;machine learning;monotonicity constraints;nonparametric ordinal classification;plug-in method;statistical framework","","18","","47","","20121016","Nov. 2013","","IEEE","IEEE Journals & Magazines"
"Music genre recognition with risk and rejection","B. L. Sturm","Audio Analysis Lab, Dept. Architecture, Design and Media Technology, Aalborg University Copenhagen, A.C. Meyers V&#x00E6;nge 15, DK-2450, Denmark","2013 IEEE International Conference on Multimedia and Expo (ICME)","20130926","2013","","","1","6","We explore risk and rejection for music genre recognition (MGR) within the minimum risk framework of Bayesian classification. In this way, we attempt to give an MGR system knowledge that some misclassifications are worse than others, and that deferring classification to an expert may be a better option than forcing a label under high uncertainty. Our experiments show this approach to have some success with respect to reducing false positives and negatives.","1945-7871;19457871","Electronic:978-1-4799-0015-2; POD:978-1-4799-0014-5; USB:978-1-4799-0013-8","10.1109/ICME.2013.6607607","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6607607","Bayesian classification;Music genre recognition;machine learning","Bayes methods;Educational institutions;Feature extraction;Metals;Testing;Training;Vectors","Bayes methods;music;pattern classification","Bayesian classification;MGR system knowledge;minimum risk framework;music genre recognition;rejection","","1","","53","","","15-19 July 2013","","IEEE","IEEE Conference Publications"
"Low complexity, high performance neuro-fuzzy system for Internet traffic flows early classification","A. Rizzi; S. Colabrese; A. Baiocchi","DIET - University of Roma &#x201C;Sapienza&#x201D; - Vi a Eudossiana 18 - 00184, Italy","2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)","20130822","2013","","","77","82","Traffic flow classification to identify applications and activity of users is widely studied both to understand privacy threats and to support network functions such as usage policies and QoS. For those needs, real time classification is required and classifier's complexity is as important as accuracy, especially given the increasing link speeds also in the access section of the network. We propose the application of a highly efficient classification system, specifically Min-Max neurofuzzy networks trained by PARC algorithm, showing that it achieves very high accuracy, in line with the best performing algorithms onWeka, by considering two traffic data sets collected in different epochs and places. It turns out that required classification model complexity is much lower with Min-Max networks with respect to SVM models, enabling the implementation of effective classification algorithms in real time on inexpensive platforms.","2376-6492;23766492","Electronic:978-1-4673-2480-9; POD:978-1-4673-2479-3; USB:978-1-4673-2478-6","10.1109/IWCMC.2013.6583538","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583538","Traffic flow classification;classifier complexity;features selection;machine learning;neurofuzzy networks","Accuracy;Complexity theory;Computational modeling;Educational institutions;Protocols;Support vector machines;Training","Internet;communication complexity;data privacy;fuzzy neural nets;learning (artificial intelligence);minimax techniques;pattern classification;quality of service;telecommunication links;telecommunication traffic","Internet traffic flow classification;PARC learning algorithm;QoS;Weka;classification model complexity;link speed improvement;low-complexity-high performance neuro-fuzzy system;network access section;network functions;privacy threats;traffic data sets;user activity identification;users application identification","","7","","25","","","1-5 July 2013","","IEEE","IEEE Conference Publications"
"Supervised video scene segmentation using similarity measures","R. Burget; J. K. Rai; V. Uher; J. Masek; M. K. Dutta","Fac. of Electr. Eng., Brno Univ. of Technol., Brno, Czech Republic","2013 36th International Conference on Telecommunications and Signal Processing (TSP)","20130930","2013","","","793","797","Video scene segmentation is a process for dividing video into semantically meaningful blocks. This can help e.g. search engines to divide video into better manageable parts and enable more relevant search in video. Unfortunately, scene segmentation is based on the semantic and therefore it is a difficult task for computers. This work is preliminary study involved into supervised video scene segmentation, which is driven by the way how human segments scenes in a movie. Since these video segments represent semantic parts in video, it can be used for better video annotation and also for searching in videos. As a training set, only high quality movies were used and from these movies 100 training samples have been extracted and used for evaluation. Resulting model is a method based on general color layout, Tamura similarity measure and k-nearest neighbors achieving 97.00% accuracy.","","Electronic:978-1-4799-0404-4; POD:978-1-4799-0401-3","10.1109/TSP.2013.6614047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6614047","Image analysis;machine learning;similarity measure;video segmentation","Accuracy;Feature extraction;Image segmentation;Motion pictures;Training;Training data;Visualization","image colour analysis;image segmentation;video signal processing","color layout;high quality movies;k-nearest neighbors;semantically meaningful blocks;video annotation;video scene segmentation;video segments","","2","","20","","","2-4 July 2013","","IEEE","IEEE Conference Publications"
"Semantic sketch-based 3D model retrieval","Bo Li; Yijuan Lu; R. Fares","Department of Computer Science, Texas State University, USA","2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)","20131003","2013","","","1","4","Query-by-Sketch is an intuitive way to retrieve relevant 3D models given a user sketch. It has many promising application potentials in human computer interaction, 3D animation, game design, etc. However, it is a very challenging task due to the big semantic gap between human-drawn sketches and 3D models. A human-drawn sketch is usually composed of several simplified and exaggerated curves as the iconic representation of an object, while a 3D model of the object is generally an accurate representation of its geometry information. Such big semantic gap makes the search based on a direct 2D-3D comparison suffer low accuracy and high computational cost. In this paper, we propose a novel semantic sketch-based 3D model search to bridge the semantic gap by first recognizing the potential semantic meanings of the user sketch and then performing 2D-3D matching for the 3D models within the predicted categories. The experimental results demonstrate that our approach achieves significant improvements in both search accuracy and efficiency, which further validate that our approach can effectively bridge the semantic gap between user sketches and 3D models.","","Electronic:978-1-4799-1604-7; POD:978-1-4799-1603-0; USB:978-1-4799-1602-3","10.1109/ICMEW.2013.6618316","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618316","Sketch-based 3D model retrieval;machine learning;semantic information;sketch recognition","Benchmark testing;Bridges;Computational modeling;Feature extraction;Semantics;Solid modeling;Three-dimensional displays","computational geometry;computer animation;handwriting recognition;human computer interaction;image retrieval;query processing","3D animation;game design;geometry information;human computer interaction;human drawn sketches;iconic representation;query-by-sketch;semantic gap;semantic sketch based 3D model retrieval","","1","","6","","","15-19 July 2013","","IEEE","IEEE Conference Publications"
"Techniques for testing scientific programs without an oracle","U. Kanewala; J. M. Bieman","Comput. Sci. Dept., Colorado State Univ., Fort Collins, CO, USA","2013 5th International Workshop on Software Engineering for Computational Science and Engineering (SE-CSE)","20130930","2013","","","48","57","The existence of an oracle is often assumed in software testing. But in many situations, especially for scientific programs, oracles do not exist or they are too hard to implement. This paper examines three techniques that are used to test programs without oracles: (1) Metamorphic testing, (2) Run-time Assertions and (3) Developing test oracles using machine learning. We examine these methods in terms of their (1) fault finding ability, (2) automation, and (3) required domain knowledge. Several case studies apply these three techniques to effectively test scientific programs that do not have oracles. Certain techniques have reported a better fault finding ability than the others when testing specific programs. Finally, there is potential to increase the level of automation of these techniques, thereby reducing the required level of domain knowledge. Techniques that can potentially be automated include (1) detection of likely metamorphic relations, (2) static analyses to eliminate spurious invariants and (3) structural analyses to develop machine learning generated oracles.","","Electronic:978-1-4673-6261-0; POD:978-1-4673-6260-3","10.1109/SECSE.2013.6615099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6615099","Assertion checking;Machine learning;Metamorphic relation;Metamorphic testing;Mutation analysis;Scientific software testing;Test oracles","Automation;Decision trees;Predictive models;Software;Software testing;Training","learning (artificial intelligence);program diagnostics;program testing","domain knowledge;fault finding ability;machine learning;metamorphic testing;run-time assertions;scientific programs;software testing;static analysis;structural analysis;test oracles","","2","","31","","","18-18 May 2013","","IEEE","IEEE Conference Publications"
"Automatic Differentiation between Alzheimer's Disease and Mild Cognitive Impairment Combining PET Data and Psychological Scores","F. Segovia; C. Bastin; E. Salmon; J. M. Górriz; J. Ramírez; C. Phillips","Cyclotron Res. Centre, Univ. of Liege, Liege, Belgium","2013 International Workshop on Pattern Recognition in Neuroimaging","20130919","2013","","","144","147","In recent years, several approaches to develop computer aided diagnosis systems for dementia have been proposed. The purpose of this work is to measure the advantages of using not only brain images as data source for those systems but also some psychological scores. To this aim, we compared the accuracy rates achieved by systems that use psychological scores beside the image data in the classification step and systems that use only the image data. The experiments show that the formers achieve higher accuracy rates regardless of the procedure carried out to analyze the image data.","","Electronic:978-0-7695-5061-9; POD:978-1-4799-0928-5","10.1109/PRNI.2013.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603577","Alzheimer's disease;PET imaging;machine learning;mild cognitive impairment","Accuracy;Dementia;Positron emission tomography;Psychology;Vectors","brain;cognition;diseases;image classification;medical disorders;medical image processing;neurophysiology;positron emission tomography;psychology","Alzheimer's disease;PET data;brain images;computer aided diagnosis systems;data source;dementia;image data;mild cognitive impairment;psychological scores","","0","","21","","","22-24 June 2013","","IEEE","IEEE Conference Publications"
"A Survey on Human Activity Recognition using Wearable Sensors","O. D. Lara; M. A. Labrador","Department of Computer Science and Engineering, University of South Florida, Tampa, FL 33620","IEEE Communications Surveys & Tutorials","20130731","2013","15","3","1192","1209","Providing accurate and opportune information on people's activities and behaviors is one of the most important tasks in pervasive computing. Innumerable applications can be visualized, for instance, in medical, security, entertainment, and tactical scenarios. Despite human activity recognition (HAR) being an active field for more than a decade, there are still key aspects that, if addressed, would constitute a significant turn in the way people interact with mobile devices. This paper surveys the state of the art in HAR based on wearable sensors. A general architecture is first presented along with a description of the main components of any HAR system. We also propose a two-level taxonomy in accordance to the learning approach (either supervised or semi-supervised) and the response time (either offline or online). Then, the principal issues and challenges are discussed, as well as the main solutions to each one of them. Twenty eight systems are qualitatively evaluated in terms of recognition performance, energy consumption, obtrusiveness, and flexibility, among others. Finally, we present some open problems and ideas that, due to their high relevance, should be addressed in future research.","1553-877X;1553877X","","10.1109/SURV.2012.110112.00192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365160","Human-centric sensing;context awareness;machine learning;mobile applications","Accelerometers;Feature extraction;Pervasive computing;Wearable sensors","image motion analysis;learning (artificial intelligence);mobile computing;wearable computers","energy consumption;human activity recognition;mobile devices;open problems;pervasive computing;recognition performance;response time;semi-supervised learning;two-level taxonomy;wearable sensors","","228","","95","","20121129","Third Quarter 2013","","IEEE","IEEE Journals & Magazines"
"Facial Age Estimation by Learning from Label Distributions","X. Geng; C. Yin; Z. H. Zhou","Southeast University, Nanjing","IEEE Transactions on Pattern Analysis and Machine Intelligence","20130821","2013","35","10","2401","2412","One of the main difficulties in facial age estimation is that the learning algorithms cannot expect sufficient and complete training data. Fortunately, the faces at close ages look quite similar since aging is a slow and smooth process. Inspired by this observation, instead of considering each face image as an instance with one label (age), this paper regards each face image as an instance associated with a label distribution. The label distribution covers a certain number of class labels, representing the degree that each label describes the instance. Through this way, one face image can contribute to not only the learning of its chronological age, but also the learning of its adjacent ages. Two algorithms, named IIS-LLD and CPNN, are proposed to learn from such label distributions. Experimental results on two aging face databases show remarkable advantages of the proposed label distribution learning algorithms over the compared single-label learning algorithms, either specially designed for age estimation or for general purpose.","0162-8828;01628828","","10.1109/TPAMI.2013.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6475129","Age estimation;face image;label distribution;machine learning","Aging;Algorithm design and analysis;Estimation;Humans;Neural networks;Training;Vectors","face recognition;learning (artificial intelligence);neural nets;probability;visual databases","CPNN;IIS-LLD;chronological age;conditional probability neural network;face databases;face image;facial age estimation;label distribution learning algorithms","Aging;Algorithms;Artificial Intelligence;Biometry;Face;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","56","","42","","20130306","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Combining one-class classifiers for imbalanced classification of breast thermogram features","B. Krawczyk; G. Schaefer; M. Wozniak","Dept. of Systems and Computer Networks Wroclaw University of Technology Wroclaw, Poland","2013 Fourth International Workshop on Computational Intelligence in Medical Imaging (CIMI)","20130822","2013","","","36","41","Thermography provides an interesting modality for diagnosing breast cancer as it is a non-contact, non-invasive and passive technique that is able to detect small tumors, which in turn can lead to earlier diagnosis. We perform computer-aided diagnosis of breast thermograms based on image features describing bilateral differences in regions of interest and a pattern classification approach that learns from previous examples. As is often the case in medical diagnosis, such training sets are imbalanced as typically (many) more benign cases get recorded compared to malignant cases. In this paper, we address this problem and perform classification using an ensemble of one-class classifiers. One-class classification uses samples from a single distribution to derive a decision boundary, and employing this method on the minority class can significantly boost its recognition rate and hence the sensitivity of our approach. We combine several one-class classifiers using a random subspace approach and a diversity measure to select members of the committee. We show that our proposed technique works well and leads to significantly improved performance compared to a single one-class predictor as well as compared to state-of-the-art classifier ensembles for imbalanced data.","2326-991X;2326991X","Electronic:978-1-4673-5919-1; POD:978-1-5090-0005-0","10.1109/CIMI.2013.6583855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583855","breast cancer;breast thermogram;imbalanced classification;machine learning;medical imaging;multiple classifier system;one-class classification","Biomedical imaging;Breast cancer;Diversity reception;Feature extraction;Sensitivity","biomedical optical imaging;cancer;feature extraction;image classification;infrared imaging;learning (artificial intelligence);medical image processing;random processes","breast cancer diagnosis;breast thermogram feature classification;breast tumor detection;computer-aided diagnosis;decision boundary;image feature classification;image recognition;one-class classifier;one-class predictor;pattern classification approach;random subspace approach;regions of interest;thermography","","4","","35","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"2nd International workshop on realizing artificial intelligence synergies in software engineering (RAISE 2013)","R. Harrison; M. Mernik; P. Henriques; D. da Cruz; T. Menzies; D. Rodriguez","Oxford Brookes University, UK","2013 35th International Conference on Software Engineering (ICSE)","20130926","2013","","","1543","1544","The RAISE'13 workshop brought together researchers from the AI and software engineering disciplines to build on the interdisciplinary synergies which exist and to stimulate research across these disciplines. The first part of the workshop was devoted to current results and consisted of presentations and discussion of the state of the art. This was followed by a second part which looked over the horizon to seek future directions, inspired by a number of selected vision statements concerning the AI-and-SE crossover. The goal of the RAISE workshop was to strengthen the AI-and-SE community and also develop a roadmap of strategic research directions for AI and software engineering.","0270-5257;02705257","Electronic:978-1-4673-3076-3; POD:978-1-4673-3075-6","10.1109/ICSE.2013.6606778","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606778","AI;computational intelligence;data mining;machine learning;software engineering","Artificial intelligence;Cognition;Communities;Conferences;Educational institutions;Software;Software engineering","","","","0","","","","","18-26 May 2013","","IEEE","IEEE Conference Publications"
"An outer loop link adaptation for BICM-OFDM that learns","S. Wahls; H. V. Poor","Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA","2013 IEEE 14th Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","20130926","2013","","","719","723","Wireless BICM-OFDM systems usually perform some link adaptation procedure in order to adapt their transmission parameters to the changing channel. It is common practice to choose modulation and code rate based on thresholds on the signal-to-noise ratios (inner loop link adaptation), while these thresholds are shifted in an external control loop (outer loop link adaptation). This paper proposes a new approach for adjusting the threshold offset. Adaptive kernel regression is used in order to learn the relationship between offsets, the channel state, and packet error rates for each code rate in an online fashion. The proposed algorithm exploits this knowledge when selecting offsets. This is in contrast to current approaches, which do not anticipate the effect of changes to the offset but rely on probing only. Another advantage is that frequency-selective modulation can (but does not have to) be employed. Some less-known arguments in favor of frequency-selective modulation are pointed out.","1948-3244;19483244","Electronic:978-1-4673-5577-3; POD:978-1-4673-5576-6; USB:978-1-4673-5575-9","10.1109/SPAWC.2013.6612144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6612144","Link adaptation;Machine learning algorithms;OFDM;Unsupervised learning","Adaptation models;Kernel;Modulation;OFDM;Signal processing algorithms;Signal to noise ratio;Wireless communication","OFDM modulation;channel coding;error statistics;frequency modulation;interleaved codes;modulation coding;radio links;regression analysis;telecommunication computing;unsupervised learning","adaptive kernel regression;bit interleaved coded modulation;channel state;code rate;external control loop;frequency selective modulation;inner loop link adaptation;machine learning;orthogonal frequency division multiplexing;outer loop link adaptation;packet error rate;signal to noise ratio;threshold offset;transmission parameter;wireless BICM-OFDM system","","3","","18","","","16-19 June 2013","","IEEE","IEEE Conference Publications"
"Constraints as Features","S. Asafi; D. Cohen-Or","Tel Aviv Univ., Tel Aviv, Israel","2013 IEEE Conference on Computer Vision and Pattern Recognition","20131003","2013","","","1634","1641","In this paper, we introduce a new approach to constrained clustering which treats the constraints as features. Our method augments the original feature space with additional dimensions, each of which derived from a given Cannot-link constraints. The specified Cannot-link pair gets extreme coordinates values, and the rest of the points get coordinate values that express their spatial influence from the specified constrained pair. After augmenting all the new features, a standard unconstrained clustering algorithm can be performed, like k-means or spectral clustering. We demonstrate the efficacy of our method for active semi-supervised learning applied to image segmentation and compare it to alternative methods. We also evaluate the performance of our method on the four most commonly evaluated datasets from the UCI machine learning repository.","1063-6919;10636919","Electronic:978-0-7695-4989-7; POD:978-1-4673-6410-2","10.1109/CVPR.2013.214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6619058","clustering;image segmentation;machine learning;semi-supervised","Clustering algorithms;Clustering methods;Extraterrestrial measurements;Image segmentation;Matrix converters;Standards","image segmentation;learning (artificial intelligence);pattern clustering","Cannot-link constraints;Cannot-link pair;UCI machine learning repository;active semisupervised learning;constrained clustering;extreme coordinate values;feature space;image segmentation;k-means clustering;spectral clustering;standard unconstrained clustering algorithm","","0","","27","","","23-28 June 2013","","IEEE","IEEE Conference Publications"
"Detecting inconsistencies in wrappers: A case study","H. Femmer; D. Ganesan; M. Lindvall; D. McComas","Technische Universit&#x00E4;t M&#x00FC;nchen, Munich, Germany","2013 35th International Conference on Software Engineering (ICSE)","20130926","2013","","","1022","1031","Exchangeability between software components such as operating systems, middleware, databases, and hardware components is a common requirement in many software systems. One way to enable exchangeability is to promote indirect use through a common interface and an implementation for each component that wraps the original component. As developers use the interface instead of the underlying component, they assume that the software system will behave in a specific way independently of the actual component in use. However, differences in the implementations of the wrappers may lead to different behavior when one component is changed for another, which might lead to failures in the field. This work reports on a simple, yet effective approach to detect these differences. The approach is based on tool-supported reviews leveraging lightweight static analysis and machine learning. The approach is evaluated in a case study that analyzes NASA's Operating System Abstraction Layer (OSAL), which is used in various space missions. We detected 84 corner-case issues of which 57 turned out to be bugs that could have resulted in runtime failures.","0270-5257;02705257","Electronic:978-1-4673-3076-3; POD:978-1-4673-3075-6","10.1109/ICSE.2013.6606652","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606652","Abstraction;Equivalence;Inconsistencies;Interfaces;Machine Learning;Wrappers","Computer bugs;Data mining;Feature extraction;Measurement;Software systems;Training","learning (artificial intelligence);object-oriented programming;operating systems (computers);program diagnostics;system recovery","NASA Operating System Abstraction Layer;OSAL;common interface;database;hardware components;lightweight static analysis;machine learning;middleware;operating system;runtime failure;software component exchangeability;software system behavior;space mission;tool-supported review;wrapper inconsistency detection","","3","","27","","","18-26 May 2013","","IEEE","IEEE Conference Publications"
"Self-Organizing Maps for Fingerprint Image Quality Assessment","M. A. Olsen; E. Tabassi; A. Makarov; C. Busch","","2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops","20130912","2013","","","138","145","Fingerprint quality assessment is a crucial task which needs to be conducted accurately in various phases in the biometric enrolment and recognition processes. Neglecting quality measurement will adversely impact accuracy and efficiency of biometric recognition systems (e.g. verification and identification of individuals). Measuring and reporting quality allows processing enhancements to increase probability of detection and track accuracy while decreasing probability of false alarms. Aside from predictive capabilities with respect to the recognition performance, another important design criteria for a quality assessment algorithm is to meet the low computational complexity requirement of mobile platforms used in national biometric systems, by military and police forces. We propose a computationally efficient means of predicting biometric performance based on a combination of unsupervised and supervised machine learning techniques. We train a self-organizing map (SOM) to cluster blocks of fingerprint images based on their spatial information content. The output of the SOM is a high-level representation of the finger image, which forms the input to a Random Forest trained to learn the relationship between the SOM output and biometric performance. The quantitative evaluation performed demonstrates that our proposed quality assessment algorithm is a reasonable predictor of performance. The open source code of our algorithm will be posted at NIST NFIQ 2.0 website.","2160-7508;21607508","Electronic:978-0-7695-4990-3; POD:978-1-4799-0994-0","10.1109/CVPRW.2013.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595866","Kohonen self-organizing map;biometric;evaluation;fingerprint;machine learning;quality;random forest;standard","Accuracy;Histograms;Quality assessment;Topology;Training;Vectors;Vegetation","computational complexity;fingerprint identification;image representation;military computing;mobile computing;pattern clustering;police;probability;self-organising feature maps;unsupervised learning","NIST NFIQ 2.0 Website;SOM;accuracy tracking;biometric enrolment;biometric recognition systems;computational complexity requirement;detection probability;finger image high-level representation;fingerprint image block clustering;fingerprint image quality assessment;military force;mobile platforms;national biometric systems;police forces;quality measurement;random forest;recognition process;self-organizing maps;spatial information content;supervised machine learning techniques;unsupervised machine learning techniques","","6","","19","","","23-28 June 2013","","IEEE","IEEE Conference Publications"
"Improvements in the clustering validity indexes of the load profiling methodology","I. P. Panapakidis; A. S. Dagoumas; M. C. Alexiadis; G. K. Papagiannis","Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece","2013 10th International Conference on the European Energy Market (EEM)","20130926","2013","","","1","8","In the recent years the utilization of the load profiling tool for tracking the demand patterns is gathering momentum. There is variety of different clustering algorithms for the formation of daily load curve clusters. Their effectiveness is tested by a set of validity indexes or adequacy measures. This paper examines the behavior of all the adequacy measures that have been proposed in the related literature. We propose an alternative form of the measures that involves a weighting factor that refers to the variance of each element of the vector that represents the demand pattern. This fact increases the accuracy of the dissimilarity measures within and among the clusters. The data sample refers to the daily load curves of an existing high voltage industry within the Greek region and the period of study is the years 2003-2011. This vast amount of data is sufficient for assessing the load profiling methodology.","2165-4077;21654077","Electronic:978-1-4799-2008-2; POD:978-1-4799-2558-2; USB:978-1-4799-2009-9","10.1109/EEM.2013.6607330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6607330","Clustering validation;Competative learning neural networks;Load profiles;Unsupervised machine learning","Artificial neural networks;Silicon","electricity supply industry;pattern clustering;power engineering computing;unsupervised learning","Greek region;adequacy measures;clustering algorithms;clustering validity indexes;daily load curve cluster formation;demand pattern tracking;dissimilarity measures;high voltage industry;load profiling methodology;unsupervised machine learning;weighting factor","","1","","15","","","27-31 May 2013","","IEEE","IEEE Conference Publications"
"Predicting mine dam levels and energy consumption using artificial intelligence methods","A. N. Hasan; B. Twala; T. Marwala","Department of Electric and Electronic Engineering Science, University of Johannesburg, South Africa","2013 IEEE Symposium on Computational Intelligence for Engineering Solutions (CIES)","20130926","2013","","","171","175","Four machine learning algorithms (artificial neural networks, a naive Bayes' classifier, a support vector machines and decision trees) were applied for a single pump station mine to monitor and predict the dam levels and energy consumption. This work was undertaken to investigate the feasibility of using artificial intelligence in certain aspects of the mining industry. If successful, artificial intelligence systems could lead to improved safety and reduced electrical energy consumption. The results show neural networks to be more efficient when compared with support vector machines, a naive Bayes' classifier and in particular, decision trees in terms of predicting underground dam levels. Artificial neural networks showed 60% accuracy, out-performing support vector machine, naive Bayes' classifier and decision trees. For the prediction of water pump energy consumption, an artificial neural network and a naive Bayes' classifier had the same accuracy of 99.0%, whereas a support vector machine and decision trees achieved a lower accuracy.","","Electronic:978-1-4673-5851-4; POD:978-1-4673-5850-7","10.1109/CIES.2013.6611745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6611745","de-watering system;deep gold mines;energy consumption;machine learning algorithms;underground pump stations","Computational intelligence;Decision support systems;Economic indicators;Handheld computers","Bayes methods;dams;decision trees;energy consumption;mining;mining industry;neural nets;pattern classification;power engineering computing;production engineering computing;support vector machines","artificial intelligence method;artificial neural networks;decision trees;energy consumption prediction;machine learning algorithms;mine dam level prediction;mining industry;naive Bayes classifier;reduced electrical energy consumption;safety;single pump station mine;support vector machines;underground dam levels;water pump energy consumption","","2","","21","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Exploiting Unsupervised Learning in Publish Subscribe System Design","C. Chen; P. C. Tung; W. C. Teng","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ. of Sci. & Technol., Taipei, Taiwan","2013 International Symposium on Biometrics and Security Technologies","20130916","2013","","","32","39","Skewed ness in popularity among subscriptions and events is an inherent property in publish/subscribe systems. In this paper, we propose to exploit the popularity skew by utilizing unsupervised machine learning techniques in the design of publish/subscribe systems. The design comprises three main ideas. First, similar subscriptions are clustered together using unsupervised machine learning methods, and the resulting cluster membership information is then distributed to all the brokers in the system. Secondly, the brokers apply unsupervised learning methods again to partition the published events they receive. By grouping similar events together, the events can be delivered in batches, instead of single event-based delivery as commonly employed in publish/subscribe systems. Thirdly, the event batches are delivered either as a single message using traditional publish/subscribe system delivery process, or using application level multicast trees maintained by the system. We explore the traditional delivery process case in this paper. Our design admits a spectrum of possible accuracy and efficiency choices in the design of publish/subscribe systems. Using an extensive set of experiments, our proposal is shown to deliver events using the collective resources of the overlay network effectively, while achieving reasonable accuracy.","","Electronic:978-1-4673-5314-4; POD:978-1-4673-5313-7","10.1109/ISBAST.2013.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597663","publish/subscribe services;published event;structured P2P Networks;subscription;unsupervised machine learning","Clustering algorithms;Overlay networks;Peer-to-peer computing;Routing;Servers;Subscriptions;Unsupervised learning","message passing;middleware;pattern clustering;trees (mathematics);unsupervised learning","application level multicast trees;cluster membership information;event batch;overlay network collective resources;popularity skewedness;publish subscribe system design;publish-subscribe system delivery process;similar subscription clustering;single event-based delivery;unsupervised machine learning techniques","","0","","28","","","2-5 July 2013","","IEEE","IEEE Conference Publications"
"Smart grid distribution prediction and control using computational intelligence","S. A. Chandler; J. G. Hughes","Department of Smart Grid Technology, Portland General Electric, Portland, Oregon, USA","2013 1st IEEE Conference on Technologies for Sustainability (SusTech)","20131003","2013","","","86","89","Smart-grid systems (SGS) may comprise distributed generation, automated demand response, mega-watt scale batteries, and a variety of other utility energy resources and programs. Their physical characteristics and operating flexibility within the distribution grid introduce new challenges to solving the power economic dispatch (PED) problem. Good operation of an SGS requires efficient use of available assets over both the short and long-term. Ideally resources will be scheduled and dispatched to equal loads (demand) in an optimal way, i.e., at the lowest cost, taking into account the differing operating constraints of assets and the changing conditions of the system and its environment. An experimental intelligent controller has been developed as part of the Pacific Northwest Smart Grid Demonstration (PNWSGD) project to address SGS demand-dependent non-linear cost functions, microgrid reliability zone constraints, and dynamic availability states. The controller is embedded within an existing utility control system that provides real time, historical, and forecast data used to predict energy demand for the next 72 hours and to create a near-optimal dispatch schedule for the next 24 hours. Both demand forecasts and schedules are updated every 5 minutes. The modularity of the controller architecture allows for a variety of load forecast and dispatch optimization tools and methods to be used; the current version uses computational intelligence, specifically neural networks. Its generality and versatility provides guidance for development of intelligent controllers adaptable and scalable to a variety of SGS applications.","","Electronic:978-1-4673-4630-6; POD:978-1-4673-4629-0; USB:978-1-4673-4628-3","10.1109/SusTech.2013.6617302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617302","Smart grid;computational intelligence;machine-learning;neural networks;power economic dispatch;transactive control","Computational intelligence;Control systems;Load forecasting;Microgrids;Real-time systems;Schedules;Smart grids","distributed power generation;intelligent control;load forecasting;neural nets;power distribution control;power engineering computing;power generation dispatch;secondary cells","PNWSGD project;Pacific Northwest Smart Grid Demonstration project;SGS;automated demand response;computational intelligence;demand forecasts;dispatch optimization;distributed generation;energy demand;intelligent controller;load forecast;mega-watt scale batteries;microgrid reliability zone constraints;neural networks;power economic dispatch;smart grid distribution control;smart grid distribution prediction;smart grid systems;utility energy resources","","3","","3","","","1-2 Aug. 2013","","IEEE","IEEE Conference Publications"
"MobSafe: cloud computing based forensic analysis for massive mobile applications using data mining","J. Xu; Y. Yu; Z. Chen; B. Cao; W. Dong; Y. Guo; J. Cao","Department of Computer Science and Technology and Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing 100084, China","Tsinghua Science and Technology","20130805","2013","18","4","418","427","With the explosive increase in mobile apps, more and more threats migrate from traditional PC client to mobile device. Compared with traditional Win+Intel alliance in PC, Android+ARM alliance dominates in Mobile Internet, the apps replace the PC client software as the major target of malicious usage. In this paper, to improve the security status of current mobile apps, we propose a methodology to evaluate mobile apps based on cloud computing platform and data mining. We also present a prototype system named MobSafe to identify the mobile app's virulence or benignancy. Compared with traditional method, such as permission pattern based method, MobSafe combines the dynamic and static analysis methods to comprehensively evaluate an Android app. In the implementation, we adopt Android Security Evaluation Framework (ASEF) and Static Android Analysis Framework (SAAF), the two representative dynamic and static analysis methods, to evaluate the Android apps and estimate the total time needed to evaluate all the apps stored in one mobile app market. Based on the real trace from a commercial mobile app market called AppChina, we can collect the statistics of the number of active Android apps, the average number apps installed in one Android device, and the expanding ratio of mobile apps. As mobile app market serves as the main line of defence against mobile malwares, our evaluation results show that it is practical to use cloud computing platform and data mining to verify all stored apps routinely to filter out malware apps from mobile app markets. As the future work, MobSafe can extensively use machine learning to conduct automotive forensic analysis of mobile apps based on the generated multifaceted data in this stage.","","","10.1109/TST.2013.6574680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574680","Android platform;big data;cloud computing;data mining;forensic analysis;hadoop distributed file system;machine learning;mobile malware detection;redis key-value store","Androids;Cloud computing;Humanoid robots;Malware;Mobile communication;Smart phones","","","","3","","","","","August 2013","","TUP","TUP Journals & Magazines"
"A framework for manipulating vacuumed data in temporal relational database","M. S. Fami; E. S. Fami; M. A. Montazeri; M. T. Isaai","Islamic Azad University of Arak, Arak, Iran","The 5th Conference on Information and Knowledge Technology","20131007","2013","","","312","317","The Temporal database is one of the databases that manipulate by append-only policy instead of updating in-place. The data in these databases have two main features: valid-time and transaction-time. Since, the data aren't deleted in temporal database; instead they are increasingly expanded and grown up, it's necessary to adopt a mechanism for controlling the volume and capacity of the database. In such a database a large quantity of the information are fetched less, while some are fetched more, so that it is essential to use a vacuuming data method as well as physical deletion technique to control the database volume. In the present research, we introduce an intelligent vacuuming system based on an unintelligent model of SDVMT which attempts to vacuum the data based on the extent of data importance, transaction time and valid time using a distributed middleware platform. The intelligent model increased the accuracy of the unintelligent model. This model behaves intelligently by learning from the behavior of the system administrator, end user and the server's performance. Therefore, the importance of data is identified by analyzing the behavior of end users. In such a process, the servers are classified based on their performance by continuous monitoring of servers and observing the behavior of system administrators in data vacuuming.","","Electronic:978-1-4673-6490-4; POD:978-1-4673-6488-1","10.1109/IKT.2013.6620085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620085","database design;database models;machine learning;modeling and management;temporal databases","Data models;Distributed databases;Neural networks;Organizations;Random access memory;Servers","data handling;middleware;relational databases","append-only policy;data importance;data vacuuming;database volume;distributed middleware platform;physical deletion technique;server monitoring;system administrator;temporal relational database;transaction-time;unintelligent SDVMT model;vacuumed data manipulation;valid-time","","0","","22","","","28-30 May 2013","","IEEE","IEEE Conference Publications"
"Scenarios generation for multi-agent simulation of electricity markets based on intelligent data analysis","G. Santos; I. Praça; T. Pinto; S. Ramos; Z. Vale","GECAD - Knowledge Engineering and Decision Support Research Center Institute of Engineering - Polytechnic of Porto (ISEP/IPP) Porto, Portugal","2013 IEEE Symposium on Intelligent Agents (IA)","20130912","2013","","","5","12","This document presents a tool able to automatically gather data provided by real energy markets and to generate scenarios, capture and improve market players' profiles and strategies by using knowledge discovery processes in databases supported by artificial intelligence techniques, data mining algorithms and machine learning methods. It provides the means for generating scenarios with different dimensions and characteristics, ensuring the representation of real and adapted markets, and their participating entities. The scenarios generator module enhances the MASCEM (Multi-Agent Simulator of Competitive Electricity Markets) simulator, endowing a more effective tool for decision support. The achievements from the implementation of the proposed module enables researchers and electricity markets' participating entities to analyze data, create real scenarios and make experiments with them. On the other hand, applying knowledge discovery techniques to real data also allows the improvement of MASCEM agents' profiles and strategies resulting in a better representation of real market players' behavior. This work aims to improve the comprehension of electricity markets and the interactions among the involved entities through adequate multi-agent simulation.","","Electronic:978-1-4673-5881-1; POD:978-1-4673-5880-4","10.1109/IA.2013.6595183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595183","Electricity Markets;Knowledge Discovery in Databases;Machine Learning;Multi-Agent Simulators;Real Electricity Markets;Scenarios Generation","Adaptation models;Context;Databases;Knowledge discovery;Power markets;Production","data mining;decision support systems;document handling;learning (artificial intelligence);multi-agent systems;power engineering computing;power markets","MASCEM;artificial intelligence techniques;data mining algorithms;decision support;document presentation;electricity markets;energy markets;intelligent data analysis;knowledge discovery processes;knowledge discovery techniques;machine learning methods;multiagent simulation;multiagent simulator of competitive electricity markets","","2","","31","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Detecting foreground disambiguation of depth images using fuzzy logic","T. Banerjee; J. M. Keller; M. Skubic","Department of Electrical and Computer Engineering, University of Missouri, Columbia, 65211, USA","2013 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20131007","2013","","","1","7","We present a unique occlusion and foreground overlap detection technique from depth sensor data using a fuzzy rule-based system. Features such as bounding box parameters and skeletonization were extracted from the foreground images and then input to the Fuzzy Inference System. Overlap and occlusion confidence measures were taken for each frame in the image sequence and compared against the extracted ground truth. This technique can help filter out occluded regions in the image sequence which, in an Eldercare environment, can then be used to compute accurate estimates of fall risk parameters such as stride time, stride length, and walking speed on a daily basis in in order to monitor the well-being of older adults in an ambient assisted living facility.","1098-7584;10987584","Electronic:978-1-4799-0022-0; POD:978-1-4799-0021-3","10.1109/FUZZ-IEEE.2013.6622364","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6622364","activity analysis;depth image;fuzzy rules;machine learning;occlusion","Feature extraction;Fuzzy logic;Image sequences;Knowledge based systems;Legged locomotion;Pragmatics;Time measurement","assisted living;feature extraction;fuzzy logic;fuzzy reasoning;gait analysis;geriatrics;image motion analysis;image sequences;image thinning;medical image processing;patient monitoring;risk analysis","Eldercare environment;ambient assisted living facility;bounding box parameters;depth image;depth sensor data;fall risk parameter;feature extraction;foreground disambiguation detection;foreground image;foreground overlap detection technique;fuzzy inference system;fuzzy logic;fuzzy rule-based system;ground truth extraction;image sequence;occluded region filtering;occlusion confidence measure;occlusion detection;older adult well-being monitor;overlap confidence measure;skeletonization feature;stride length;stride time;walking speed","","3","","18","","","7-10 July 2013","","IEEE","IEEE Conference Publications"
"Routing tables building methods for increasing DNS(SEC) resolving platforms efficiency","E. Herbert; D. Migault; S. Senecal; S. Francfort; M. Laurent","France Telecom R&D/Orange Labs, 38-40 rue du G&#x00E9;n&#x00E9;ral Leclerc 92130 Issy-les-Moulineaux, France","2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013)","20130801","2013","","","824","827","This paper proposes to use optimization and machine learning methods in order to develop innovative techniques for balancing the DNS(SEC) traffic according to Fully Qualified Domain Names (FQDN), rather than according to the IP addresses. With DNS traffic doubling every year and the deployment of its secure extension DNSSEC, DNS resolving platforms require more and more resources. A way to cope with these increasing resources demands is to balance the DNS traffic among the DNS platform servers based on the queried FQDN. Several methods are considered to build a FQDN based routing table: mixed integer linear programming (MILP), a K-means clustering algorithm and a heuristic scheme. These load balancing approaches are run and evaluated on real DNS traffic data extracted from the operational IP network of an Internet Service Provider (ISP) and they result in a difference of less than 2% CPU between the servers of a platform.","1573-0077;15730077","Electronic:978-3-901882-50-0; POD:978-1-4799-1708-2; USB:978-1-4673-5229-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6573088","DNS;DNSSEC;load balancing;machine learning;optimization;routing","Clustering algorithms;IP networks;Load management;Optimization;Routing;Servers;Stacking","IP networks;Internet;integer programming;learning (artificial intelligence);linear programming;pattern clustering;resource allocation;telecommunication network routing;telecommunication traffic","DNS platform servers;DNS(SEC) resolving platform efficiency;DNS(SEC) traffic;DNSSEC;FQDN based routing table building method;ISP;Internet service provider;MILP;domain name system;fully qualified domain names;heuristic scheme;k-means clustering algorithm;load balancing approach;machine learning method;mixed integer linear programming;operational IP network;optimization methods;real DNS traffic data","","0","","16","","","27-31 May 2013","","IEEE","IEEE Conference Publications"
"Inferential measurements for situation awareness","P. Rattadilok; A. Petrovski","School of Computing Science and Digital Media, Robert Gordon University, Aberdeen, UK","2013 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)","20131003","2013","","","93","98","The paper proposes a generic approach to building inferential measurement systems. The large amount of data needed to be acquired and processed by such systems necessitates the use of machine learning techniques. In this study, an inferential measurement system aimed at enhancing situation awareness has been developed and tested on simulated traffic surveillance data. The performance of several Computational Intelligence techniques within this system has been examined and compared on the data containing anomalous driving patterns.","2377-9314;23779314","Electronic:978-1-4673-4703-7; POD:978-1-4673-4702-0","10.1109/CIVEMSA.2013.6617402","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617402","anomaly detection;inferential measurement;machine learning;situation awareness;unmanned aerial vehicles","Artificial neural networks;Buildings;Computational intelligence;Computational modeling;Surveillance;Traffic control;Vehicles","learning (artificial intelligence);traffic engineering computing","anomalous driving patterns;computational intelligence techniques;inferential measurement systems;machine learning;simulated traffic surveillance data;situation awareness;traffic surveillance","","2","","14","","","15-17 July 2013","","IEEE","IEEE Conference Publications"
"Detecting Object Motion Using Passive RFID: A Trauma Resuscitation Case Study","S. Parlak; I. Marsic","Qualcomm Technologies Inc., Santa Clara, CA, USA","IEEE Transactions on Instrumentation and Measurement","20130807","2013","62","9","2430","2437","We studied object motion detection in an indoor environment using RFID technology. Unlike prior work, we focus on dynamic scenarios, such as emergency medical situations, subject to signal interference by people and many RFID tags. We build a realistic trauma resuscitation setting and record a dataset of around 14000 detection instances. We find that factors affecting radio signal, such as tag motion, have different statistical fingerprints, making them discernible using statistical methods. Our method for object motion detection extracts descriptive features of the received signal strength and classifies them using machine-learning techniques. We report experimental results obtained with several statistical features and classifiers, and provide guidelines for feature and classifier selection in different environments. Experimental results show that object motion could be detected with an accuracy of 80% in complex scenarios and 90% on average. The motion type, on the other hand, could not be identified with such high accuracy using currently available passive RFID technology.","0018-9456;00189456","","10.1109/TIM.2013.2258772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6545303","Machine learning;RFID;motion detection;radio signal strength;trauma resuscitation","","feature extraction;injuries;learning (artificial intelligence);medical signal detection;medical signal processing;radiofrequency identification;signal classification;statistical analysis","feature extraction;machine-learning techniques;object motion detection;passive RFID technology;radiosignal strength;signal classification;signal interference;statistical fingerprints;statistical methods;tag motion;trauma resuscitation","","5","","28","","20130621","Sept. 2013","","IEEE","IEEE Journals & Magazines"
"Reverse engineering of gene regulation models from multi-condition experiments","N. Kennedy; A. Mizeranschi; P. Thompson; H. Zheng; W. Dubitzky","University of Ulster, Northern Ireland, UK","2013 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20130912","2013","","","112","119","Reverse-engineering of quantitative, dynamic gene-regulatory network (GRN) models from time-series gene expression data is becoming important as such data are increasingly generated for research and other purposes. A key problem in the reverse-engineering process is the under-determined nature of these data. Because of this, the reverse-engineered GRN models often lack robustness and perform poorly when used to simulate system responses to new conditions. In this study, we present a novel method capable of inferring robust GRN models from multi-condition GRN experiments. This study uses two important computational intelligence methods: artificial neural networks and particle swarm optimization.","","Electronic:978-1-4673-5875-0; POD:978-1-4673-5874-3","10.1109/CIBCB.2013.6595396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595396","Gene regulatory networks;machine learning;multi-model fusion;optimization;reverse-engineering","Artificial neural networks;Biological system modeling;Data models;Gene expression;Mathematical model;Predictive models;Robustness","biological techniques;biology computing;genetics;neural nets;particle swarm optimisation;reverse engineering","artificial neural network;computational intelligence method;data generation;data under-determined nature;dynamic GRN model;gene regulation model;model performance;model robustness;multicondition GRN experiment;multicondition experiment;particle swarm optimization;quantitative gene-regulatory network model;reverse engineering;reverse-engineered GRN model;robust GRN model inferring;system response simulation;time-series gene expression data","","4","","31","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Evasive bots masquerading as human beings on the web","J. Jin; J. Offutt; N. Zheng; F. Mao; A. Koehl; H. Wang","George Mason University, USA","2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)","20130808","2013","","","1","12","Web bots such as crawlers are widely used to automate various online tasks over the Internet. In addition to the conventional approach of human interactive proofs such as CAPTCHAs, a more recent approach of human observational proofs (HOP) has been developed to automatically distinguish web bots from human users. Its design rationale is that web bots behave intrinsically differently from human beings, allowing them to be detected. This paper escalates the battle against web bots by exploring the limits of current HOP-based bot detection systems. We develop an evasive web bot system based on human behavioral patterns. Then we prototype a general web bot framework and a set of flexible de-classifier plugins, primarily based on application-level event evasion. We further abstract and define a set of benchmarks for measuring our system's evasion performance on contemporary web applications, including social network sites. Our results show that the proposed evasive system can effectively mimic human behaviors and evade detectors by achieving high similarities between human users and evasive bots.","1530-0889;15300889","Electronic:978-1-4673-6472-0; POD:978-1-4673-6471-3","10.1109/DSN.2013.6575366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6575366","Web security;bot;human observation proofs;machine learning","Servers","Internet;data mining;security of data;social networking (online)","CAPTCHA;HOP-based bot detection systems;Internet;Web applications;application-level event evasion;crawlers;evasive Web bot system;flexible declassifier plugins;general Web bot framework;human behavioral patterns;human interactive proof approach;human observational proofs;online task automation;social network sites;system evasion performance","","0","","25","","","24-27 June 2013","","IEEE","IEEE Conference Publications"
"Ranking Instances by Maximizing the Area under ROC Curve","H. A. Güvenir; M. Kurtcephe","Bilkent University, Ankara","IEEE Transactions on Knowledge and Data Engineering","20130821","2013","25","10","2356","2366","In recent years, the problem of learning a real-valued function that induces a ranking over an instance space has gained importance in machine learning literature. Here, we propose a supervised algorithm that learns a ranking function, called ranking instances by maximizing the area under the ROC curve (RIMARC). Since the area under the ROC curve (AUC) is a widely accepted performance measure for evaluating the quality of ranking, the algorithm aims to maximize the AUC value directly. For a single categorical feature, we show the necessary and sufficient condition that any ranking function must satisfy to achieve the maximum AUC. We also sketch a method to discretize a continuous feature in a way to reach the maximum AUC as well. RIMARC uses a heuristic to extend this maximization to all features of a data set. The ranking function learned by the RIMARC algorithm is in a human-readable form; therefore, it provides valuable information to domain experts for decision making. Performance of RIMARC is evaluated on many real-life data sets by using different state-of-the-art algorithms. Evaluations of the AUC metric show that RIMARC achieves significantly better performance compared to other similar methods.","1041-4347;10414347","","10.1109/TKDE.2012.214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6338929","Algorithm design and analysis;Machine learning;Machine learning algorithms;Measurement;Nickel;Ranking;Training;Training data;data mining;decision support;machine learning","Algorithm design and analysis;Machine learning;Machine learning algorithms;Measurement;Nickel;Training;Training data","data mining;decision making;learning (artificial intelligence);optimisation","AUC metric;AUC value;RIMARC algorithm;ROC curve area maximization;continuous feature discretization;decision making;human-readable form;machine learning literature;necessary and sufficient condition;performance evaluation;performance measure;ranking instance space;ranking quality evaluation;real-valued function learning;receiver operating characteristic analysis;single categorical feature;supervised algorithm","","13","","51","","20121024","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Model-based reinforcement learning for humanoids: A study on forming rewards with the iCub platform","A. Fachantidis; A. Di Nuovo; A. Cangelosi; I. Vlahavas","Department of Informatics Aristotle University of Thessaloniki, Thessaloniki 54124, Greece","2013 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)","20130926","2013","","","87","93","Technological advancements in robotics and cognitive science are contributing to the development of the field of cognitive robotics. Modern robotic platforms are able to exhibit the ability to learn and reason about complex tasks and to follow behavioural goals in complex environments. Nevertheless, many challenges still exist. One of these great challenges is to equip these robots with cognitive systems that allow them to deal with less constrained situations, beyond constrained scenarios as in industrial robotics. In this work we explore the application of the Reinforcement Learning (RL) paradigm to study the autonomous development of robot controllers without a priori supervised learning. Such a model-based RL architecture is discussed for the cognitive implications of applying RL in humanoid robots. To this end we show a developmental framework for RL in robotics and its implementation and testing for the iCub robotic platform in two novel experimental scenarios. In particular we focus on iCub simulation experiments with comparisons between internal perception-based reward signals and external ones, in order to compare learning performance of the robot guided by its own perception of action's outcomes with the one when the robot has its actions externally evaluated.","","Electronic:978-1-4673-5871-2; POD:978-1-4673-5870-5","10.1109/CCMB.2013.6609170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6609170","Cognitive Robotics;Humanoid Robotics;Machine Learning;Reinforcement Learning","Accuracy;Humanoid robots;Joints;Learning (artificial intelligence);Robot kinematics;Robot sensing systems","cognitive systems;humanoid robots;learning (artificial intelligence)","RL paradigm;cognitive robotics;cognitive science;cognitive systems;forming rewards;humanoid robots;iCub platform;model-based RL architecture;model-based reinforcement learning;robot controllers;robotics","","2","","22","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Mining traffic accident features by evolutionary fuzzy rules","P. Krömer; T. Beshah; D. Ejigu; V. Snášel; J. Platoš; A. Abraham","IT4Innovations, VSB - Technical University of Ostrava","2013 IEEE Symposium on Computational Intelligence in Vehicles and Transportation Systems (CIVTS)","20130926","2013","","","38","43","Traffic accidents represent a major problem threatening peoples lives, health, and property. Traffic behavior and driving in particular is a social and cultural phenomenon that exhibits significant differences across countries and regions. Therefore, traffic models developed in one country might not be suitable for other countries. Similarly, attributes of importance, dependencies, and patterns found in data describing traffic in one region might not be valid for other regions. All this makes traffic accident analysis and modelling a task suitable for data mining and machine learning approaches that develop models based on actual real-world data. In this study, we investigate a data set describing traffic accidents in Ethiopia and use a machine learning method based on artificial evolution and fuzzy systems to mine symbolic description of selected features of the data set.","","Electronic:978-1-4673-5913-9; POD:978-1-4673-5912-2","10.1109/CIVTS.2013.6612287","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6612287","binary classification;fuzzy rules;genetic programming;machine learning;multi-class classification;traffic accidents","Accidents;Analytical models;Data mining;Data models;Injuries;Roads;Vehicles","data mining;evolutionary computation;fuzzy set theory;learning (artificial intelligence);road accidents;traffic engineering computing","Ethiopia;artificial evolution;cultural phenomenon;data mining;evolutionary fuzzy rules;fuzzy system;machine learning;social phenomenon;symbolic description;traffic accident analysis;traffic accident feature mining;traffic accident modeling;traffic behavior","","3","","40","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Algorithm-Driven Architectural Design Space Exploration of Domain-Specific Medical-Sensor Processors","M. Shoaib; N. K. Jha; N. Verma","Department of Electrical Engineering, Princeton University, Princeton, NJ, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20130909","2013","21","10","1849","1862","Data-driven machine-learning techniques enable the modeling and interpretation of complex physiological signals. The energy consumption of these techniques, however, can be excessive, due to the complexity of the models required. In this paper, we study the tradeoffs and limitations imposed by the energy consumption of high-order detection models implemented in devices designed for intelligent biomedical sensing. Based on the flexibility and efficiency needs at various processing stages in data-driven biomedical algorithms, we explore options for hardware specialization through architectures based on custom instruction and coprocessor computations. We identify the limitations in the former, and propose a coprocessor-based platform that exploits parallelism in computation as well as voltage scaling to operate at a subthreshold minimum-energy point. We present results from post-layout simulation of cardiac arrhythmia detection with patient data from the MIT-BIH database. After wavelet-based feature extraction, which consumes 12.28 μJ, we demonstrate classification computations in the 12.00-120.05 μJ range using 10000-100000 support vectors. This represents 1170× lower energy than that of a low-power processor with custom instructions alone. After morphological feature extraction, which consumes 8.65 μJ of energy, the corresponding energy numbers are 10.24-24.51 μJ, which is 1548× smaller than one based on a custom-instruction design. Results correspond to V<sub>dd</sub>=0.4 V and a data precision of 8 b.","1063-8210;10638210","","10.1109/TVLSI.2012.2220161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6338362","Biomedical sensor processors;classification accelerators;embedded machine learning;low-energy design by voltage and precision scaling;structured hardware specialization;support-vector machines","Complexity theory;Computational modeling;Feature extraction;Kernel;Program processors;Support vector machines;Vectors","bioelectric potentials;electrocardiography;feature extraction;learning (artificial intelligence);medical signal detection;medical signal processing;sensors;support vector machines;wavelet transforms","MIT-BIH database;cardiac arrhythmia detection;coprocessor computation;custom instruction;data-driven biomedical algorithm;data-driven machine-learning technique;domain-specific medical-sensor processor;energy 12.00 muJ to 120.05 muJ;energy consumption;hardware specialization;high-order detection model;intelligent biomedical sensing;parallelism;patient data;physiological signal;subthreshold minimum-energy point;support vector machine;voltage scaling;wavelet-based feature extraction","","1","","49","","20121023","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Improving supply chain security using big data","D. Zage; K. Glass; R. Colbaugh","Sandia National Laboratories, Albuquerque, NM, USA 87185-9300","2013 IEEE International Conference on Intelligence and Security Informatics","20130815","2013","","","254","259","Previous attempts at supply chain risk management are often non-technical and rely heavily on policies/procedures to provide security assurances. This is particularity worrisome as there are vast volumes of data that must be analyzed and data continues to grow at unprecedented rates. In order to mitigate these issues and minimize the amount of manual inspection required, we propose the development of mathematically-based automated screening methods that can be incorporated into supply chain risk management. In particular, we look at methods for identifying deception and deceptive practices that may be present in the supply chain. We examine two classes of constraints faced by deceivers, cognitive/computational limitations and strategic tradeoffs, which can be used to developed graph-based metrics to represent entity behavior. By using these metrics with novel machine learning algorithms, we can robustly detect deceptive behavior and identify potential supply chain issues.","","Electronic:978-1-4673-6213-9; POD:978-1-4673-6214-6","10.1109/ISI.2013.6578830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578830","Deception Detection;Machine Learning;Supply Chain Risk Management","Algorithm design and analysis;Communities;Information management;Measurement;Security;Supply chains;Vectors","cognitive systems;graph theory;inspection;learning (artificial intelligence);production engineering computing;risk management;security of data;strategic planning;supply chain management","big data;cognitive limitations;computational limitations;deception identification;deceptive practices;entity behavior representation;graph-based metrics;machine learning algorithms;manual inspection minimization;mathematically-based automated screening method development;potential supply chain issue identification;robust deceptive behavior detection;security assurances;strategic tradeoffs;supply chain risk management;supply chain security improvement","","4","","36","","","4-7 June 2013","","IEEE","IEEE Conference Publications"
"Profiieseeker — Early warning system for predicting economic situation of small and medium enterprises","A. Burda; P. Cudek; Z. S. Hippe","University of Management and Administration, Zamo&#x015B;&#x0107;, Poland","2013 6th International Conference on Human System Interactions (HSI)","20130815","2013","","","398","400","This paper presents the construction of the ProfileSEEKER the information system for early warning small and medium-sized enterprises from bankruptcy. The developed system is a set of five classifiers, using a variety of topologies of artificial neural networks and Bayes belief network, supported by supervised machine learning methods. System performance was evaluated using the original validation, called queue validation procedure.","2158-2246;21582246","Electronic:978-1-4673-5637-4; POD:978-1-4673-5635-0","10.1109/HSI.2013.6577854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6577854","artificial neural networks;machine learning;predicting economic situation SMEs;queue validation","Artificial neural networks;Biological system modeling;Companies;Data models;Economics;Predictive models","bank data processing;economics;learning (artificial intelligence);management information systems;neural nets;small-to-medium enterprises","Bayes belief network;ProfileSEEKER;artificial neural networks;bankruptcy;early warning system;economic situation prediction;information system;queue validation procedure;small and medium enterprises;supervised machine learning methods","","0","","10","","","6-8 June 2013","","IEEE","IEEE Conference Publications"
"Self-adaptive and sensitivity-aware QoS modeling for the cloud","T. Chen; R. Bahsoon","School of Computer Science, University of Birmingham, Birmingham, UK. B15 2TT","2013 8th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)","20130912","2013","","","43","52","Given the elasticity, dynamicity and on-demand nature of the cloud, cloud-based applications require dynamic models for Quality of Service (QoS), especially when the sensitivity of QoS tends to fluctuate at runtime. These models can be autonomically used by the cloud-based application to correctly self-adapt its QoS provision. We present a novel dynamic and self-adaptive sensitivity-aware QoS modeling approach, which is fine-grained and grounded on sound machine learning techniques. In particular, we combine symmetric uncertainty with two training techniques: Auto-Regressive Moving Average with eXogenous inputs model (ARMAX) and Artificial Neural Network (ANN) to reach two formulations of the model. We describe a middleware for implementing the approach. We experimentally evaluate the effectiveness of our models using the RUBiS benchmark and the FIFA 1998 workload trends. The results show that our modeling approach is effective and the resulting models produce better accuracy when compared with conventional models.","2157-2305;21572305","Electronic:978-1-4673-4401-2; POD:978-1-4673-4399-2","10.1109/SEAMS.2013.6595491","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595491","QoS modeling;cloud computing;interference;machine learning;prediction;sensitivity","Accuracy;Adaptation models;Data models;Quality of service;Sensitivity;Software;Uncertainty","autoregressive moving average processes;cloud computing;learning (artificial intelligence);neural nets;quality of service","ANN;ARMAX model;FIFA 1998 workload trend;QoS provision;RUBiS benchmark;artificial neural network;autoregressive moving average with exogenous inputs model;cloud computing;cloud-based application;machine learning technique;quality of service;self-adaptive QoS modeling;sensitivity-aware QoS modeling","","4","1","31","","","20-21 May 2013","","IEEE","IEEE Conference Publications"
"Detection of onset of Alzheimer's disease from MRI images using a GA-ELM-PSO classifier","S. Saraswathi; B. S. Mahanand; A. Kloczkowski; S. Suresh; N. Sundararajan","Battelle Center for Mathematical Medicine The Research Institute at Nationwide Children's Hospital, Columbus, OH, USA","2013 Fourth International Workshop on Computational Intelligence in Medical Imaging (CIMI)","20130822","2013","","","42","48","In this paper, a novel method for detecting the onset of Alzheimer's disease (AD) from Magnetic Resonance Imaging (MRI) scans is presented. It uses a combination of three different machine learning algorithms in order to get improved results and is based on a three-class classification problem. The three classes for classification considered in this study are normal, very mild AD and mild and moderate AD subjects. The machine learning algorithms used are: the Extreme Learning Machine (ELM) for classification, with its performance optimized by a Particle Swarm Optimization (PSO) and a Genetic algorithm (GA) used for feature selection. A Voxel-Based Morphometry (VBM) approach is used for feature extraction from the MRI images and GA is used to reduce the high dimensional features needed for classification. The GA-ELM-PSO classifier yields an average training accuracy of 94.57 % and a testing accuracy of 87.23 %, averaged across the three classes, over ten random trials. The results clearly indicate that the proposed approach can differentiate between very mild AD and normal cases more accurately, indicating its usefulness in detecting the onset of AD.","2326-991X;2326991X","Electronic:978-1-4673-5919-1; POD:978-1-5090-0005-0","10.1109/CIMI.2013.6583856","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583856","Alzheimer's;Machine Learning;Neural networks;Particle swarm optimization;Voxel-Based Morphometry","Accuracy;Diseases;Feature extraction;Genetic algorithms;Magnetic resonance imaging;Testing;Training","biomedical MRI;diseases;feature extraction;genetic algorithms;image classification;learning (artificial intelligence);medical image processing;particle swarm optimisation","Alzheimer disease detection;GA-ELM-PSO classifier;MRI image;VBM approach;extreme learning machine algorithm;feature extraction;feature selection;genetic algorithm;magnetic resonance imaging scan;particle swarm optimization;three-class classification problem;voxel-based morphometry","","2","","35","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Identifying temporal relations between main events in new articles","I. Berrazega; R. Faiz","LARODEC, University of Tunis - ISG, 2000 Bardo, Tunisia","2013 ACS International Conference on Computer Systems and Applications (AICCSA)","20131003","2013","","","1","4","With the expansion of the Web 2.0, daily huge amount of data is produced everywhere, namely new articles. These contents need to be exploited in order to extract relevant information and to build knowledge databases. In this concern, processing the temporal dimension of language and extracting temporal information from electronic news articles is becoming a prominent task. In this concern, we propose an approach for identifying inter-sentential temporal relations between main events from news articles. Our approach is based on a complete linguistic analysis of texts and supervised learning models.","2161-5322;21615322","Electronic:978-1-4799-0792-2; POD:978-1-4799-0791-5; USB:978-1-4799-0790-8","10.1109/AICCSA.2013.6616467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6616467","Classification;Linguistic Analysis;Machine Learning;Natural Language Processing;Temporal Information Extraction;Temporal Relation Identification;Web 2.0","Accuracy;Data mining;Feature extraction;Natural language processing;Pragmatics;Semantics;Syntactics","Internet;information retrieval","Web 2.0;electronic news articles;intersentential temporal relation identification;knowledge databases;linguistic text analysis;supervised learning models;temporal information extraction;temporal language dimension","","0","","13","","","27-30 May 2013","","IEEE","IEEE Conference Publications"
"A Hybrid Approach for Automatic Incident Detection","J. Wang; X. Li; S. S. Liao; Z. Hua","Department of Information Systems, University of Science and Technology of China&#x2013;City University of Hong Kong Joint Advanced Research Center, Suzhou, China","IEEE Transactions on Intelligent Transportation Systems","20130829","2013","14","3","1176","1185","This paper presents a hybrid approach to automatic incident detection (AID) in transportation systems. It combines time series analysis (TSA) and machine learning (ML) techniques in light of the fault diagnosis theory. In this approach, the time series component is to forecast the normal traffic for the current time point based on prior (normal) traffic. The ML component aims to detect incidents using features of real-time traffic, predicted normal traffic, as well as differences between the two. We validate our approach using a real-world data set collected in previous research. The results show that the hybrid approach is able to detect incidents more accurately [higher detection rate (DR)] and faster (shorter mean time to detect) under the requirement of a similar false alarm rate (FAR), as compared with state-of-the-art algorithms. This paper lends support to further studies on combining TSA with ML to address problems related to intelligent transportation systems (ITS).","1524-9050;15249050","","10.1109/TITS.2013.2255594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525409","Automatic incident detection (AID);hybrid approach;machine learning (ML);time series analysis (TSA)","","automated highways;fault diagnosis;learning (artificial intelligence);road traffic;time series","AID;DR;FAR;ITS;ML techniques;TSA;automatic incident detection;detection rate;false alarm rate;fault diagnosis theory;hybrid approach;intelligent transportation systems;machine learning techniques;normal traffic;real-time traffic;real-world data set;time series analysis","","11","","50","","20130606","Sept. 2013","","IEEE","IEEE Journals & Magazines"
"SentiMeter-Br: A new social web analysis metric to discover consumers' sentiment","R. L. Rosa; D. Z. Rodríguez; G. Bressan","Department of Computer Science and Digital Systems - University of S&#x00E3;o Paulo - Brazil","2013 IEEE International Symposium on Consumer Electronics (ISCE)","20130729","2013","","","153","154","This article analyzes Brazilian Consumers' Sentiments in a specific domain using a system, SentiMeter-Br. A Portuguese dictionary focused in a specific field of study was built, in which tenses and negative words are treated in a different way of other dictionaries, with a different metric. For the Portuguese dictionary performance validation, the results are compared with the SentiStrength algorithm and are evaluated by three Specialists in the field of study; each one analyzed 2000 texts captured from Twitter. Comparing the efficiency of the SentiMeter-Br and the SentiStrength against the Specialists' opinion, a Pearson correlation factor of 0.89 and 0.75 was reached, respectively. The polarity of the short texts were also tested through machine learning, with correctly classified instances of 71.79% by Sequential Minimal Optimization algorithm and F-Measure of 0.87 for positive and 0.91 for negative phrases.","0747-668X;0747668X","Electronic:978-1-4673-6199-6; POD:978-1-4673-6198-9","10.1109/ISCE.2013.6570158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6570158","consumer sentiment;machine learning;social web analysis tool;support vector machines","Algorithm design and analysis;Classification algorithms;Dictionaries;Google;Hair;Market research;Twitter","Internet;consumer behaviour;dictionaries;learning (artificial intelligence);marketing data processing;social networking (online);text analysis","Brazilian consumers sentiments discovery;F-Measure;Pearson correlation factor;Portuguese dictionary performance validation;SentiMeter-Br;SentiStrength algorithm;Twitter;machine learning;sequential minimal optimization algorithm;short texts polarity;social Web analysis metric;text analysis","","3","","1","","","3-6 June 2013","","IEEE","IEEE Conference Publications"
"Ready-to-use activity recognition for smartphones","P. Siirtola; J. Röning","Computer Science and Engineering Department, P.O. BOX 4500, FI-90014, University of Oulu, Finland","2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)","20130916","2013","","","59","64","In this study, every day activities are recognized from data collected using smartphones accelerometer sensors. Offline experiments are made to show that the presented method is user- and body position-independent. In addition, it is shown that the features used in the classification are not dependent on the calibration of the phone. The recognition models trained using the offline data are also tested online. A mobile application running these models is built for two operating systems: Symbian^3 and Android. Real-time experiments using these applications are made to show that the presented method can be implemented to any operating system and hardware variations do not affect recognition results. High recognition accuracies are obtained, in the offline study, the average recognition rate is almost 99% and, also, in the online study, the average recognition accuracy is over 90%.","","Electronic:978-1-4673-5895-8; POD:978-1-4673-5894-1","10.1109/CIDM.2013.6597218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597218","Accelerometer;activity recognition;machine learning;mobile phones","Accelerometers;Calibration;Feature extraction;Hardware;Operating systems;Sensors;Smart phones","accelerometers;operating systems (computers);pattern classification;pattern recognition;smart phones","Android operating system;Symbian^3 operating system;average recognition rate;body position-independent method;data classification;data collection;offline recognition;online recognition;ready-to-use activity recognition;recognition model training;smart phone accelerometer sensors;user-independent method","","10","","15","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Coupling Recursive Hyperspheric Classification with Linear Discriminant Analysis for Improved Results","S. B. Reed; T. R. C. Reed; S. M. Dascalu","Dept. of Comput. Sci. & Eng., Univ. of Nevada, Reno, NV, USA","2013 10th International Conference on Information Technology: New Generations","20130930","2013","","","596","601","Recursive Hyper spheric Classification (RHC) can accurately and succinctly classify large datasets by dissecting labeled vectors into their constituent groups, or hyper spheres. While RHC is a powerful classification tool, coupling RHC with other linear classifiers enhances the ability and accuracy of the classification system, improving recognition of unlabeled vectors. In this paper, RHC is paired with Linear Discriminant Analysis (LDA) for improved classification and recognition rates.","","Electronic:978-0-7695-4967-5; POD:978-1-4673-5960-3","10.1109/ITNG.2013.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6614371","Dimensional Reduction;Linear Discriminant Analysis;Machine Learning;Recursive Hyperspheric Classification;Wine Dataset","Classification algorithms;Couplings;Euclidean distance;Linear discriminant analysis;Support vector machine classification;Vectors","learning (artificial intelligence);pattern classification;vectors","LDA;classification rates;classification system;coupling RHC;hyper spheres;linear classifiers;linear discriminant analysis;powerful classification tool;recognition rates;recursive hyperspheric classification;unlabeled vectors recognition","","0","","11","","","15-17 April 2013","","IEEE","IEEE Conference Publications"
"Survey of Automated Speaker Identification Methods","M. Sidorov; A. Schmitt; S. Zablotskiy; W. Minker","Inst. of Commun. Eng., Univ. of Ulm, Ulm, Germany","2013 9th International Conference on Intelligent Environments","20130916","2013","","","236","239","In this paper we present an overview of state-of-the-art approaches for speaker identification. Due to the increased number of dialogue system applications the interest in that field has grown significantly in recent years. Nevertheless, there are many open issues in the field of automatic speaker identification. Among them the choice of the appropriate speech signal features and machine learning algorithms could be mentioned. We make here an overview of modern methods designed for the problem of speaker identification. We also describe here our direction for possible improvements to the automated speaker identification.","","Electronic:978-0-7695-5038-1; POD:978-1-4799-0745-8","10.1109/IE.2013.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597817","Gaussian mixture models;machine learning algorithms;speaker identification","Accuracy;Databases;Mel frequency cepstral coefficient;Speech;Support vector machines;Testing;Training","learning (artificial intelligence);speaker recognition","automated speaker identification;dialogue system application;machine learning algorithm;speech signal features","","2","","22","","","16-17 July 2013","","IEEE","IEEE Conference Publications"
"Automatically identifying a software product's quality attributes through sentiment analysis of tweets","R. Dehkharghani; C. Yilmaz","Dept. of Computer Science and Engineering, Sabanci University, Istanbul, Turkey","2013 1st International Workshop on Natural Language Analysis in Software Engineering (NaturaLiSE)","20130926","2013","","","25","30","Software quality attributes can be identified based on software features such as security, reliability and user-friendliness. This process can be done either manually or automatically. Sentiment analysis refers to the sentiment extraction task from resources such as natural language texts. We study the application of sentiment analysis on extracting the quality attributes of a software product based on the opinions of end-users that have been stated in microblogs such as Twitter. Our findings obtain advantageous techniques such as document frequency of words in a large number of tweets. The extracted results can help software developers know the advantages and disadvantages of their products.","","Electronic:978-1-4673-6271-9; POD:978-1-4673-6270-2","10.1109/NAturaLiSE.2013.6611717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6611717","Sentiment analysis;data mining;machine learning;software quality attributes;twitter","Accuracy;Feature extraction;Internet;Security;Software;Training;Twitter","data mining;human computer interaction;natural language processing;security of data;social networking (online);software quality;software reliability;text analysis","Twitter;document frequency of words;microblogs;natural language texts;sentiment analysis;sentiment extraction task;software developers;software product quality attributes;software reliability;software security;software user-friendliness;tweets","","2","1","11","","","25-25 May 2013","","IEEE","IEEE Conference Publications"
"A Bayesian-learning technique for automatic pre-emptive loads through I/O devices via the mouse pointer","C. J. Vantin; D. B. Megherbi","CMINDS Research Center, Department of Electrical and Computer Engineering, University of Massachusetts, Lowell, 01854 USA","2013 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)","20131003","2013","","","25","30","In today's computing environment, it is well known that the computing bottleneck is rather at the I/O peripheral levels instead of at the level of CPU and memory. The access times to fetch data from an external device such as a CD-ROM, a network drive, or even the delay of dragging a mouse pointer to a desktop icon consumes seconds of time while CPU operations take nanoseconds. In this thesis, we show how our proposed Bayesian technique can anticipate certain memory intensive programs and how it can be used to preload its contents before the user selects the actual program. We evaluate the I/O peripheral of the mouse cursor and how to leverage historic mouse data to make these predictions. We show that using such Artificial Intelligence (AI) techniques results in a more productive computing environment relieving the user from waiting for a program to load.","2377-9314;23779314","Electronic:978-1-4673-4703-7; POD:978-1-4673-4702-0","10.1109/CIVEMSA.2013.6617390","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617390","Artificial Intelligence;Human/machine intelligent interaction;I/O Devices Loads;Machine Learning;Memory-intensive loads applications","Artificial intelligence;Bayes methods;Computers;Hardware;Mice;Software;Training","belief networks;learning (artificial intelligence);mouse controllers (computers);storage management","AI;Bayesian-learning technique;CD-ROM;CPU;CPU operations;IO devices;IO peripheral levels;artificial intelligence techniques;automatic preemptive loads;computing bottleneck;desktop icon;memory intensive programs;mouse cursor;mouse pointer;network drive;productive computing environment","","0","","21","","","15-17 July 2013","","IEEE","IEEE Conference Publications"
"AdAPT -- A Dynamic Approach for Activity Prediction and Tracking for Ambient Intelligence","J. Frey","German Res. Center for Artificial Intell. (DFKI), Saarbr&#x03C5;&#x0308;cken, Germany","2013 9th International Conference on Intelligent Environments","20130916","2013","","","254","257","With recent advancements in supporting fields like embedded systems and Ambient Assisted Living (AAL), intelligent environments are becoming reality. However, instrumenting an environment with a set of sensors and actuators and applying some automation rules alone doesn't make the environment intelligent. Learning and adapting to user behaviors and gaining some basic knowledge about the underlying intention is an essential feature of an intelligent system. Here, we introduce AdAPT, which is an incremental approach for recognizing, predicting and tracking Activities of Daily Living (ADLs) within a smart home infrastructure. Our approach does not make any predefined assumptions about typical activity models but tries to learn and adapt to the user's actual behavior continuously. We focus on designing suitable interaction concepts to support an optimal, continuous and unobtrusive adaption to the user. In this paper, we introduce the AdAPT project, highlight relevant research questions and provide a first description of the proposed system design.","","Electronic:978-0-7695-5038-1; POD:978-1-4799-0745-8","10.1109/IE.2013.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597821","Ambient Assisted Living;Ambient Intelligence;Intelligent User Interfaces;Machine Learning","Actuators;Ambient intelligence;Intelligent sensors;Pattern recognition;Smart homes;User interfaces","artificial intelligence;assisted living;cloud computing;user interfaces","AAL;ADL prediction;ADL recognition;ADL tracking;AdAPT system;activities-of-daily living;activity prediction;activity tracking;ambient assisted living;ambient intelligence;embedded system;intelligent environment;intelligent system;user behavior","","2","","18","","","16-17 July 2013","","IEEE","IEEE Conference Publications"
"Context extraction from reviews for Context Aware Recommendation using Text Classification techniques","F. Z. Lahlou; H. Benbrahimand; A. Mountassir; I. Kassou","ALBIRONI Research Team, ENSIAS, Mohamed V University, Souissi, Rabat, Morocco","2013 ACS International Conference on Computer Systems and Applications (AICCSA)","20131003","2013","","","1","4","In this paper, we investigate the use of Text Classification techniques to extract contextual information from user reviews for Context Aware Recommendation. We conduct several experiments to identify the best Text Representation settings and the best classification algorithm for our dataset. We carry out our experiments on hotel reviews. We focus on extracting the trip type, as contextual information, from these reviews. Results show that the Naïve Bayes classifier yields the best results with up to 72.2% in terms of F1-measure. To extract context from user reviews with text classification techniques, we recommend to use raw text rather than employing stemming, to use the normalized frequency based weighting rather than the presence based one, to remove terms that occur once in the data set, and to combine unigrams, bigrams and trigrams.","2161-5322;21615322","Electronic:978-1-4799-0792-2; POD:978-1-4799-0791-5; USB:978-1-4799-0790-8","10.1109/AICCSA.2013.6616512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6616512","Context Aware Recommender Systems;Machine Learning;Natural Langage Processing;Text Classification","Classification algorithms;Context;Context-aware services;Niobium;Support vector machines;Text categorization","Bayes methods;pattern classification;text analysis","Naïve Bayes classifier;bigrams;classification algorithm;context aware recommendation;context extraction;contextual information;hotel reviews;text classification techniques;text representation settings;trigrams;unigrams;user reviews","","1","","3","","","27-30 May 2013","","IEEE","IEEE Conference Publications"
"Evaluating music emotion recognition: Lessons from music genre recognition?","B. L. Sturm","Audio Analysis Lab, AD:MT, Aalborg University Copenhagen, A.C. Meyers V&#x00E6;nge 15, DK-2450","2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)","20131003","2013","","","1","6","A fundamental problem with nearly all work in music genre recognition (MGR) is that evaluation lacks validity with respect to the principal goals of MGR. This problem also occurs in the evaluation of music emotion recognition (MER). Standard approaches to evaluation, though easy to implement, do not reliably differentiate between recognizing genre or emotion from music, or by virtue of confounding factors in signals (e.g., equalization). We demonstrate such problems for evaluating an MER system, and conclude with recommendations.","","Electronic:978-1-4799-1604-7; POD:978-1-4799-1603-0; USB:978-1-4799-1602-3","10.1109/ICMEW.2013.6618342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618342","Evaluation;machine learning;music emotion recognition;music genre recognition","Accuracy;Computer crashes;Emotion recognition;Lightning;Multiple signal classification;Music;Training","emotion recognition;learning (artificial intelligence);music","MER;MGR;music emotion recognition;music genre recognition","","4","","36","","","15-19 July 2013","","IEEE","IEEE Conference Publications"
"Learning Graphical Model Parameters with Approximate Marginal Inference","J. Domke","NICTA and Australia National University, Canberra","IEEE Transactions on Pattern Analysis and Machine Intelligence","20130821","2013","35","10","2454","2467","Likelihood-based learning of graphical models faces challenges of computational complexity and robustness to model misspecification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.","0162-8828;01628828","","10.1109/TPAMI.2013.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6420841","Graphical models;conditional random fields;inference;machine learning;segmentation","Approximation algorithms;Entropy;Function approximation;Markov processes;Optimization;Vectors","approximation theory;computational complexity;inference mechanisms;learning (artificial intelligence);solid modelling","approximate marginal inference;computational complexity;graphical model parameter learning;inference approximations;likelihood-based approximations;likelihood-based learning;marginalization-based learning;model misspecification","Algorithms;Artificial Intelligence;Computer Simulation;Models, Statistical;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique","23","","55","","20130125","Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Information fusion and S&P500 trend prediction","S. Lahmiri; M. Boukadoum; S. Chartier","ESCA School of Management, Casablanca, Morocco","2013 ACS International Conference on Computer Systems and Applications (AICCSA)","20131003","2013","","","1","7","The purpose of this study is the prediction of Standard & Poor's (S&P500) trends (ups and downs) with macroeconomic variables, technical indicators, and investor moods using k-NN algorithm and probabilistic neural networks. More precisely, eleven economic factors, twelve technical indicators and four measures of investor's mood were selected as potential predictive variables. Then, the Granger causality test was performed to identify among them the predictive variables that show a strong relationship with the stock market. Finally, the identified inputs are fed to k-NN and PNN separately and the correct detection of stock market ups (+0.5%)-aggressive investment strategy - is computed using the obtained hit ratios. The simulations results from 10-fold experiments show that the average detection rate of k-NN and PNN are respectively 93.45% (±0.0019, standard deviation) and 92.4% (±0.006, standard deviation). The results suggest that aggregating the three categories of information (economic, technical, and psychological information) along with k-NN as classifier leads to high detection accuracy of future stock market ups and downs.","2161-5322;21615322","Electronic:978-1-4799-0792-2; POD:978-1-4799-0791-5; USB:978-1-4799-0790-8","10.1109/AICCSA.2013.6616488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6616488","classification;information fusion;machine learning;stock market;trend","Autoregressive processes;Mathematical model;Neurons;Stock markets;Time series analysis;Training","causality;forecasting theory;investment;learning (artificial intelligence);macroeconomics;neural nets;pattern classification;sensor fusion;stock markets","Granger causality test;PNN;S&P500 Trend Prediction;Standard & Poors trend prediction;aggressive investment strategy;classifier;economic factors;hit ratios;information fusion;investor moods;k-NN algorithm;k-nearest neighbour algorithm;macroeconomic variables;probabilistic neural networks;stock market;technical indicators","","0","","22","","","27-30 May 2013","","IEEE","IEEE Conference Publications"
"Moving target defense for adaptive adversaries","R. Colbaugh; K. Glass","Sandia National Laboratories, Albuquerque, NM USA","2013 IEEE International Conference on Intelligence and Security Informatics","20130815","2013","","","50","55","Machine learning (ML) plays a central role in the solution of many security problems, for example enabling malicious and innocent activities to be rapidly and accurately distinguished and appropriate actions to be taken. Unfortunately, a standard assumption in ML - that the training and test data are identically distributed - is typically violated in security applications, leading to degraded algorithm performance and reduced security. Previous research has attempted to address this challenge by developing ML algorithms which are either robust to differences between training and test data or are able to predict and account for these differences. This paper adopts a different approach, developing a class of moving target (MT) defenses that are difficult for adversaries to reverse-engineer, which in turn decreases the adversaries' ability to generate training/test data differences that benefit them. We leverage the coevolutionary relationship between attackers and defenders to derive a simple, flexible MT defense strategy which is optimal or nearly optimal for a broad range of security problems. Case studies involving two distinct cyber defense applications demonstrate that the proposed MT algorithm outperforms standard static methods, offering effective defense against intelligent, adaptive adversaries.","","Electronic:978-1-4673-6213-9; POD:978-1-4673-6214-6","10.1109/ISI.2013.6578785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578785","adaptive adversaries;cyber security;hybrid dynamical systems;machine learning;moving target defense","Biological system modeling;Games;Security;Switches;Training;Unsolicited electronic mail","learning (artificial intelligence);performance evaluation;reverse engineering;security of data","ML algorithms;adaptive adversaries;algorithm performance degradation;flexible MT defense strategy;innocent activities;machine learning;malicious activities;moving target defense;reverse-engineer;security applications;security problems;standard static methods","","1","","27","","","4-7 June 2013","","IEEE","IEEE Conference Publications"
"Deriving behavior primitives from aggregate network features using support vector machines","O. McCusker; S. Brunza; D. Dasgupta","Guardian Services, Sonalysts, Inc, Waterford, CT, USA","2013 5th International Conference on Cyber Conflict (CYCON 2013)","20130725","2013","","","1","18","Establishing long-view situation awareness of threat agents requires an operational capability that scales to large volumes of network data, leveraging the past to make-sense of the present and to anticipate the future. Yet, today we are dominated by short-view capabilities driven by misuse based strategies; triggered by the structural qualities of attack vectors. The structural aspects of cyber threats are in a constant flux, rendering most defensive technologies reactive to previously unknown attack vectors. Unlike structural signature based approaches, both the real-time and aggregate behaviors exhibited by cyber threats over a network provide insight into making-sense of anomalies found on our networks. In this work, we explore the challenges posed in identifying and developing a set of behavior primitives that facilitate the creation of threat narratives use to describe cyber threats anomalies. Thus, we investigate the use aggregate behaviors derived from network flow data establishing initial behavior models used to detect complex cyber threats such as Advanced Persistent Threats (APTs). Our cyber data fusion prototype employs a unique layered methodology that extracts features from network flow data aggregating it by time. This approach is more scalable and flexible in its application in large network data volumes. The preliminary evaluation of the proposed methodology and supporting models shows some promising results.","2325-5366;23255366","Electronic:978-9949-9211-5-7; POD:978-1-4799-0450-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6568370","Behavior analysis;aggregate behaviors;anomaly detection;machine learning;network flow analysis","Aggregates;Collaboration;Correlation;Feature extraction;Intrusion detection;Real-time systems;Vectors","feature extraction;security of data;sensor fusion;support vector machines","APT;advanced persistent threats;aggregate behaviors;aggregate network features;attack vector structural quality;behavior primitives;cyber data fusion prototype;cyber threat structural aspects;feature extraction;initial behavior models;long-view situation awareness;misuse based strategy;network flow data;operational capability;short-view capability;support vector machines;threat agents","","2","","30","","","4-7 June 2013","","IEEE","IEEE Conference Publications"
"Predicting Fault-Prone Software Modules with Rank Sum Classification","J. Cahill; J. M. Hogan; R. Thomas","Fac. of Sci. & Eng., Queensland Univ. of Technol., Brisbane, QLD, Australia","2013 22nd Australian Software Engineering Conference","20130919","2013","","","211","219","The detection and correction of defects remains among the most time consuming and expensive aspects of software development. Extensive automated testing and code inspections may mitigate their effect, but some code fragments are necessarily more likely to be faulty than others, and automated identification of fault prone modules helps to focus testing and inspections, thus limiting wasted effort and potentially improving detection rates. However, software metrics data is often extremely noisy, with enormous imbalances in the size of the positive and negative classes. In this work, we present a new approach to predictive modelling of fault proneness in software modules, introducing a new feature representation to overcome some of these issues. This rank sum representation offers improved or at worst comparable performance to earlier approaches for standard data sets, and readily allows the user to choose an appropriate trade-off between precision and recall to optimise inspection effort to suit different testing environments. The method is evaluated using the NASA Metrics Data Program (MDP) data sets, and performance is compared with existing studies based on the Support Vector Machine (SVM) and Naïve Bayes (NB) Classifiers, and with our own comprehensive evaluation of these methods.","1530-0803;15300803","Electronic:978-0-7695-4995-8; POD:978-1-4799-0226-2","10.1109/ASWEC.2013.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601309","fault proneness;machine learning;metrics","Inspection;Measurement;NASA;Niobium;Software;Support vector machines;Testing","program testing;software fault tolerance;software metrics","MDP data sets;NASA metrics data program;NB classifiers;SVM;automated fault identification;automated testing;code fragments;code inspections;defect correction;defect detection;detection rates;fault prone modules;fault proneness;fault-prone software modules prediction;naïve Bayes classifier;predictive modelling;rank sum classification;rank sum representation;software development;software metrics data;support vector machine;testing environments","","1","","32","","","4-7 June 2013","","IEEE","IEEE Conference Publications"
"An empirical study about the behavior of a genetic learning algorithm on searching spaces pruned by a completeness condition","D. García; A. González; R. Pérez","Department of Computer Sciences and Artificial Intelligence, C/Periodista Daniel Saucedo Aranda, University of Granada (Spain), 18071","2013 IEEE International Workshop on Genetic and Evolutionary Fuzzy Systems (GEFS)","20130919","2013","","","8","15","The main difficulty faced by a learning algorithm is to find the appropriate knowledge inside of the huge search space of possible solutions. Typically, the researchers try to solve this problem developing more efficient search algorithms, defining “ad-hoc” heuristic for the specific problem or reducing the expressiveness of the knowledge representation. This work explores an alternative way that consists of reducing the search space using a completeness condition. The proposed model is implemented on NSLV, a fuzzy rule learning algorithm based on genetic algorithms. We present an experimental study of the behavior of NSLV on pruned search spaces. The experimental results show that when we work with these spaces it is possible to find a good trace-off among prediction capacity, complexity of the knowledge obtained and learning time.","","Electronic:978-1-4673-5899-6; POD:978-1-4673-5898-9","10.1109/GEFS.2013.6601049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601049","Fuzzy Sets;Genetic Algorithms;Machine Learning","Accuracy;Databases;Genetic algorithms;Genetics;Prediction algorithms;Proposals;Training","fuzzy set theory;genetic algorithms;knowledge representation;learning (artificial intelligence);search problems","NSLV;completeness condition;fuzzy rule learning algorithm;genetic learning algorithm;knowledge complexity;knowledge representation;learning time;prediction capacity;search algorithms;searching space","","1","","19","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"FARE: A framework for benchmarking reliability of cyber-physical systems","L. Wu; G. Kaiser","Department of Computer Science Columbia University New York, NY 10027, USA","2013 IEEE Long Island Systems, Applications and Technology Conference (LISAT)","20130815","2013","","","1","6","A cyber-physical system (CPS) is a system featuring a tight combination of, and coordination between, the system's computational and physical elements. System reliability is a critical requirement of cyber-physical systems. An unreliable CPS often leads to system malfunctions, service disruptions, financial losses and even human life. Improving CPS reliability requires an objective measurement, estimation and comparison of the CPS system reliability. This paper describes FARE (Failure Analysis and Reliability Estimation), a framework for benchmarking reliability of cyber-physical systems. Some prior researches have proposed reliability benchmark for some specific CPS such as wind power plant and wireless sensor networks. There were also some prior researches on the components of CPS such as software and some specific hardware. But according to the best of our knowledge, there isn't any reliability benchmark framework for CPS in general. FARE framework provides a CPS reliability model, a set of methods and metrics on the evaluation environment selection, failure analysis and reliability estimation for benchmarking CPS reliability. It not only provides a retrospect evaluation and estimation of the CPS system reliability using the past data, but also provides a mechanism for continuous monitoring and evaluation of CPS reliability for runtime enhancement. The framework is extensible for accommodating new reliability measurement techniques and metrics. It is also generic and applicable to a wide range of CPS applications. For empirical study, we applied the FARE framework on a smart building management system for a large commercial building in New York City. Our experiments showed that FARE is easy to implement, accurate for comparison and can be used for building useful industry benchmarks and standards after accumulating enough data.","","Electronic:978-1-4673-6245-0; POD:978-1-4673-6244-3","10.1109/LISAT.2013.6578226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578226","cyber-physical system;data mining;failure analysis;machine learning;reliability;reliability estimation;software reliability;statistical analysis","Benchmark testing;Buildings;Estimation;Measurement;Software;Software reliability","benchmark testing;building management systems;failure analysis;reliability","CPS applications;CPS reliability model;CPS system reliability;FARE framework;New York City;commercial building;continuous monitoring and evaluation mechanism;cyber-physical systems;evaluation environment selection;failure analysis and reliability estimation;reliability benchmark framework;reliability measurement metrics;reliability measurement techniques;service disruptions;smart building management system;system computational elements;system physical elements;system reliability","","2","","16","","","3-3 May 2013","","IEEE","IEEE Conference Publications"
"Data Quality: Some Comments on the NASA Software Defect Datasets","M. Shepperd; Q. Song; Z. Sun; C. Mair","Brunel University, Uxbridge","IEEE Transactions on Software Engineering","20130828","2013","39","9","1208","1215","Background--Self-evidently empirical analyses rely upon the quality of their data. Likewise, replications rely upon accurate reporting and using the same rather than similar versions of datasets. In recent years, there has been much interest in using machine learners to classify software modules into defect-prone and not defect-prone categories. The publicly available NASA datasets have been extensively used as part of this research. Objective--This short note investigates the extent to which published analyses based on the NASA defect datasets are meaningful and comparable. Method--We analyze the five studies published in the IEEE Transactions on Software Engineering since 2007 that have utilized these datasets and compare the two versions of the datasets currently in use. Results--We find important differences between the two versions of the datasets, implausible values in one dataset and generally insufficient detail documented on dataset preprocessing. Conclusions--It is recommended that researchers 1) indicate the provenance of the datasets they use, 2) report any preprocessing in sufficient detail to enable meaningful replication, and 3) invest effort in understanding the data prior to applying machine learners.","0098-5589;00985589","","10.1109/TSE.2013.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6464273","Empirical software engineering;data quality;defect prediction;machine learning","Abstracts;Communities;Educational institutions;NASA;PROM;Software;Sun","data analysis;learning (artificial intelligence);pattern classification;software reliability","IEEE Transactions on Software Engineering;NASA software defect dataset;National Aeronautics and Space Administration;data preprocessing;data quality;data replication;dataset provenance;defect-prone classification;machine learning;not-defect-prone classification;software module classification","","38","","21","","20130218","Sept. 2013","","IEEE","IEEE Journals & Magazines"
"A web based software system for database generation for online dynamic security assessment studies (ML4DSA)","J. Geeganage; U. D. Annakkage; B. A. Archer; T. Weekes","Department of Electrical and Computer Engineering University of Manitoba","2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20130725","2013","","","1","4","This paper presents a software system that generates a database for power system dynamic security assessment. The generated database is intended to be used in machine learning techniques. The development of algorithms to generate data is a very time consuming task. This software tool is aimed at facilitating faster generation of the appropriate database. Further, the system allows the user to plug-in the case specific limit checks and algorithms for system specific corrective actions depending on the type of study. The proposed system automates the Power System Simulator for Engineering (PSSE) which is an industry standard software used in many electrical power utilities. The proposed software system, ML4DSA, is based on Python which is available in the public domain with plenty of supporting communities and powerful libraries. These features enable the user to develop algorithms for system specific corrective actions. The web interface facilitates access to the authenticated users of PSSE over the web, therefore, requires no additional software installed on the client computer. ML4DSA is successfully tested on the 39 Bus New England test system and the Midwest Reliability Organization (MRO) system which has over 50,000 buses.","0840-7789;08407789","Electronic:978-1-4799-0033-6; POD:978-1-4799-0031-2","10.1109/CCECE.2013.6567682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567682","Dynamic security assessment;Machine learning;Software tools","Databases;Heuristic algorithms;Power system dynamics;Power system stability;Software;Software algorithms;Stability analysis","Internet;learning (artificial intelligence);power engineering computing;power system security;software tools","ML4DSA;PSSE;Python;Web based software system;Web interface;database generation;electrical power utilities;machine learning techniques;midwest reliability organization system;online dynamic security assessment studies;power system dynamic security assessment;power system simulator for engineering;software tool","","1","","6","","","5-8 May 2013","","IEEE","IEEE Conference Publications"
"Learning Non-Linear Functions With Factor Graphs","F. A. N. Palmieri","Dipartimento di Ingegneria Industriale e dell'Informazione, Seconda Universit&#x00E0; di Napoli (SUN), Aversa (CE), ITALY","IEEE Transactions on Signal Processing","20130808","2013","61","17","4360","4371","We show how to use a discrete-variable factor graph for learning non-linear continuous functions from examples. The paper proposes a scheme for embedding soft quantization in a probabilistic Bayesian graph. The quantized input variables are grouped into a compound variable that is mapped through a stochastic matrix into the discrete output distribution. Specific output values are then obtained through a process of de-quantization. The information flow carried by message propagation is bi-directional and an algorithm for learning the factor graph parameters is explicitly derived. The model, that can easily merge discrete and continuous variables, is demonstrated with examples and simulations.","1053-587X;1053587X","","10.1109/TSP.2013.2270463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6544641","Factor graphs;machine learning;non linear function approximation;soft quantization","","Bayes methods;graph theory;nonlinear functions;quantisation (signal)","de-quantization;discrete-variable factor graph;factor graph parameters;message propagation;nonlinear continuous functions;probabilistic Bayesian graph;soft quantization;stochastic matrix","","6","","21","","20130620","Sept.1, 2013","","IEEE","IEEE Journals & Magazines"
"Fast heterogeneous boosting","N. Jankowski","Department of Informatics, Nicolaus Copernicus University, Poland","2013 IEEE Symposium on Computational Intelligence and Ensemble Learning (CIEL)","20130930","2013","","","1","8","The main goal of this paper is introduction of fast heterogeneous boosting algorithm. `Heterogeneous' means that boosting is based not on single-type learning machine, but may use machines of several types coherently. The main idea behind the construction of heterogeneous boostings was to use it with learning machines of low complexity (O(nd)). Thanks to that, the heterogeneous boosting is still a fast algorithm of linear learning (and usage) complexity. The paper presents a comparison of homogeneous boostings of a few types of fast learning machines with introduced heterogeneous boosting, which base on a small group of fast learning machines. The presented comparison proves that heterogeneous boosting is efficient and accurate.","","Electronic:978-1-4673-5853-8; POD:978-1-4673-5852-1","10.1109/CIEL.2013.6613133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613133","Computational intelligence;adaptive boosting;classifier;machine learning","Accuracy;Bagging;Benchmark testing;Boosting;Cardiography;Complexity theory;Computational intelligence","computational complexity;learning (artificial intelligence);pattern classification","fast heterogeneous boosting algorithm;fast learning machines;linear learning complexity;low complexity (O(nd));single-type learning machine","","0","","26","","","16-19 April 2013","","IEEE","IEEE Conference Publications"
"Individualized apnea prediction in preterm infants using cardio-respiratory and movement signals","J. R. Williamson; D. W. Bliss; D. W. Browne; P. Indic; E. Bloch-Salisbury; D. Paydarfar","Massachusetts Institute of Technology, Lincoln Laboratory, Lexington, MA","2013 IEEE International Conference on Body Sensor Networks","20130808","2013","","","1","6","Apnea of prematurity is a common developmental disorder in preterm infants that is implicated in a number of acute and long-term complications. Therapeutic stochastic resonance (TSR) is a noninvasive preventative intervention for stabilizing breathing patterns and reducing the incidence of apnea and hypoxia. Because the stabilizing effect of TSR lags its initiation, it can be used most effectively if it is linked to a system for apnea prediction. We present a real-time algorithm for generating apnea predictions based on cardio-respiratory and movement features extracted from multiple physiological sensors. The features are used to create patient-specific statistical models of apnea precursors. The state parameters generated by these models are evaluated over time to form apnea predictions. The algorithms predictions are evaluated using a short, 5.5 minute prediction horizon. The algorithm obtains highly accurate predictions, with statistical significance obtained on five out of the six patients that it is evaluated on.","2376-8886;23768886","Electronic:978-1-4799-0330-6; POD:978-1-4799-0331-3","10.1109/BSN.2013.6575523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6575523","algorithm;bradycardia;feature vector;hypoxia;machine learning;monitoring;prematurity","Correlation;Educational institutions;Eigenvalues and eigenfunctions;Feature extraction;Pediatrics;Prediction algorithms;Rail to rail inputs","","","","3","","25","","","6-9 May 2013","","IEEE","IEEE Conference Publications"
"Fully-Connected CRFs with Non-Parametric Pairwise Potential","N. D. F. Campbell; K. Subr; J. Kautz","Univ. Coll. London, London, UK","2013 IEEE Conference on Computer Vision and Pattern Recognition","20131003","2013","","","1658","1665","Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a non-parametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.","1063-6919;10636919","Electronic:978-0-7695-4989-7; POD:978-1-4673-6410-2","10.1109/CVPR.2013.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6619061","CRF;machine learning;non-parametric","Approximation methods;Computational modeling;Data models;Inference algorithms;Kernel;Training;Training data","Gaussian processes;computer vision;graph theory;nonparametric statistics","Gaussian kernel;approximate Euclidean feature space;computer vision;conditional pairwise potentials;conditional random fields;density estimation technique;embedding technique;fully-connected CRF;graph;nonlinear dissimilarity measure;nonparametric models;nonparametric pairwise potentials;pairwise interactions","","11","","18","","","23-28 June 2013","","IEEE","IEEE Conference Publications"
"Sentiment analysis of Sina Weibo based on semantic sentiment space model","H. He","School of Management, Harbin Institute of Technology, P.R. China, 150001","2013 International Conference on Management Science and Engineering 20th Annual Conference Proceedings","20130829","2013","","","206","211","With the rapid development of Web 2.0, more and more people begin to publish information or their custom opinions on the Internet. Micro-blog's application satisfies people's need and provides a public platform for people to post and interact in real time. As a result of the rapidly increasing number of micro-blog updates, a lot of information and emotions complex data release in this platform, researches on micro-blog have attracted more and more attention, especially, one continuous heat topic, sentiment analysis of short message. So far, Chinese micro-blog exploration still needs lots of further work. Focus on Sina Weibo's sentiment analysis, the key of this paper is to put forward three methods of Micro-Blog orientation classification to resolve the problem of Micro-Blog sentiment analysis, and compare the accuracy and performance of each classification method.","2155-1847;21551847","Electronic:978-1-4799-0474-7; POD:978-1-4799-0473-0","10.1109/ICMSE.2013.6586284","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6586284","feature extraction;machine learning;sentiment analysis;sina weibo","Accuracy;Analytical models;Feature extraction;Prototypes;Support vector machines;Training;Training data","classification;learning (artificial intelligence);social networking (online)","Chinese microblog exploration;Internet;Sina Weibo sentiment analysis;Web 2.0;custom opinions;emotions;machine learning;microblog application;microblog orientation classification;microblog updates;public platform;semantic sentiment space model;short message","","4","","30","","","17-19 July 2013","","IEEE","IEEE Conference Publications"
"Computational sports broadcasting: Automated director assistance for live sports","C. Chen; O. Wang; S. Heinzle; P. Carr; A. Smolic; M. Gross","ETH Zurich, Germany","2013 IEEE International Conference on Multimedia and Expo (ICME)","20130926","2013","","","1","6","Live sports broadcast is seeing a large increase in the number of cameras used for filming. More cameras can provide better coverage of the field and a wider range of experiences for viewers. However, choosing optimal cameras for broadcast demands a high level of concentration, awareness and experience from sports broadcast directors. We present an automatic assistant to help select likely candidates from a large array of possible cameras. Sports directors can then choose the final broadcast camera from the reduced suggestion set. Our assistant uses both widely acknowledged cinematography guidelines for sports directing, as well as a data-driven approach that learns specific styles from directors.","1945-7871;19457871","Electronic:978-1-4799-0015-2; POD:978-1-4799-0014-5; USB:978-1-4799-0013-8","10.1109/ICME.2013.6607445","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6607445","Computational Broadcast;Image Understanding;Machine Learning;Shot Selection","Broadcasting;Cameras;Computational modeling;Games;Support vector machines;Training;Training data","","","","3","","15","","","15-19 July 2013","","IEEE","IEEE Conference Publications"
