"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6975566,6975461,6976945,6977370,6978237,6978239,6857380,6978597,6977295,6977292,6978238,6977350,6974096,6969569,6974532,6970169,6974324,6972942,6972266,6974397,6974825,6970358,6928893,6974391,6970257,6970340,6973889,6972099,6913349,6913316,6968258,6968411,6969024,6967567,6968347,6969782,6911965,6670778,6677603,6965035,6964687,6965000,6962419,6962291,6957296,6953346,6960597,6959942,6957226,6957293,6701396,6963042,6958958,6958448,6956761,6961263,6913001,6898024,6954236,6952698,6952028,6952577,6954239,6952663,6952391,6952509,6952848,6952502,6950737,6875913,6943548,6944424,6875959,6876013,6807760,6946573,6945715,6945483,6943981,6918491,6948867,6876049,6948483,6941337,6939792,6810000,6936976,6938918,6938728,6936978,6936592,6936711,6931452,6931162,6931453,6933005,6931854,6934672,6934138,6934761",2017/05/05 21:57:27
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Applications of expectation maximization algorithm for coherent optical communication","D. Zibar; O. Winther; R. Borkowski; I. T. Monroy; L. Carvalho; J. Oliveira","Technical University of Denmark, DTU Fotonik/Computing, Kgs. Lyngby, Denmark","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","1890","1894","In this invited paper, we present powerful statistical signal processing methods, used by machine learning community, and link them to current problems in optical communication. In particular, we will look into iterative maximum likelihood parameter estimation based on expectation maximization algorithm and its application in coherent optical communication systems for linear and nonlinear impairment mitigation. Furthermore, the estimated parameters are used to build the probabilistic model of the system for the synthetic impairment generation. It is shown numerically and experimentally that iterative parameter estimation based on expectation maximization algorithm is a powerful tool in combating system impairments such as non-linear phase noise, inphase and quadrature (I/Q) modulator imperfections and laser linewidth. We show experimentally that for a dispersion managed polarization multiplexed 16-quadrature amplitude modulation (QAM) system at 14 Gbaud a gain in the nonlinear system tolerance of up to 3 dB can be obtained. For, a dispersion unmanaged system this gain reduces to 0.5 dB. Moreover, we show that joint estimation of carrier frequency, phase, signal means and noise covariance, can be performed iteratively by employing expectation maximization. Using experimental data we show that joint carrier synchronization and detection offers an improvement of 0.5 dB in terms of input power compared to hard decision digital phaselocked loop (PLL) based carrier synchronization and demodulation.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952698","expectation maximization;machine learning;nonlinear impairments;optical communication","Abstracts;Communities;Optical modulation;Optical polarization;Optical sensors","expectation-maximisation algorithm;maximum likelihood estimation;modulators;optical communication;phase locked loops;quadrature amplitude modulation;signal processing;synchronisation","16-quadrature amplitude modulation system;I-Q modulator;PLL based carrier synchronization;PLL based demodulation;carrier frequency estimation;coherent optical communication;digital phase-locked loop;dispersion managed polarization multiplexed QAM system;expectation maximization algorithm;inphase and quadrature modulator imperfections;iterative maximum likelihood parameter estimation;joint carrier detection;joint carrier synchronization;laser linewidth;linear impairment mitigation;machine learning;noise covariance;nonlinear impairment mitigation;nonlinear phase noise;phase signal means estimation;probabilistic model;statistical signal processing method;synthetic impairment generation","","0","","5","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Quality assessment of collaborative content with minimal information","D. H. Dalip; H. Lima; M. A. Gon√ßalves; M. Cristo; P. Calado","Dept of Computer Science - UFMG, Belo Horizonte/MG, Brazil","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","201","210","Content generated by users is one of the most interesting phenomena of published media. However, the possibility of unrestricted edition is a source of doubts about its quality. This issue has motivated many studies on how to automatically assess content quality in collaborative web sites. Generally, these studies use machine learning techniques to combine large number of quality indicators into a single value representing the overall quality of the document. This need for a high number of indicators, however, has detrimental implications both on the efficiency and on the effectiveness of the quality assessment algorithms. In this work, we exploit and extend a feature selection method based on the SPEA2 multi-objective genetic algorithm. Results show that we can reduce the feature set to a fraction of 15% through 25% of the original, while obtaining error rates comparable to the state of the art.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970169","Feature Selection;Genetic Algorithm;Machine Learning;Quality Assessment;Wikipedia","Electronic publishing;Genetic algorithms;History;Information services;Internet;Quality assessment;Sociology","Web sites;genetic algorithms;information analysis;learning (artificial intelligence)","SPEA2 multiobjective genetic algorithm;collaborative content;collaborative web sites;content quality;feature selection method;machine learning techniques;minimal information;published media;quality assessment;quality assessment algorithms","","0","","26","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"HERCULES: Strong Patterns towards More Intelligent Predictive Modeling","E. Park; C. Kartsaklis; J. Cavazos","Univ. of Delaware, Newark, DE, USA","2014 43rd International Conference on Parallel Processing","20141120","2014","","","172","181","Recent work has shown that program analysis techniques to select meaningful code features of programs are important in the task of deciding the best compiler optimizations. Although, there are many successful state-of-the-art program analysis techniques, they often do not provide a simple method to extract the most expressive information about loops, especially when a target program is computationally intensive with complex loops and data dependencies. In this paper, we introduce a static technique to characterize a program using a pattern-driven system named HERCULES. This characterization technique not only helps a user to understand programs by searching pattern-of-interests, but also can be used for a predictive model that effectively selects the proper compiler optimizations. We formulated 35 loop patterns, then evaluated our characterization technique by comparing the predictive models constructed using HERCULES to three other state-of-the-art characterization methods. We show that our models outperform three state-of-the-art program characterization techniques on two multicore systems in selecting the best optimization combination from a given loop transformation space. We achieved up to 67% of the best possible speedup achievable with the optimization search space we evaluated.","0190-3918;01903918","Electronic:978-1-4799-5618-0; POD:978-1-4799-7858-8","10.1109/ICPP.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957226","compiler optimization;machine learning;pattern-based program characterization;predictive modeling","Arrays;Data mining;Feature extraction;Optimization;Pattern matching;Predictive models;Radiation detectors","optimising compilers;program control structures;program diagnostics;search problems","HERCULES;code features;compiler optimization;data dependency;intelligent predictive modeling;loop patterns;multicore systems;optimization combination;optimization search space;pattern-driven system;program analysis technique;program characterization techniques;static technique","","0","","23","","","9-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Motion estimation for Super-resolution based on recognition of error artifacts","A. Stojkovic; Z. Ivanovski","University Ss Cyril and Methodius, Skopje, Macedonia","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","246","250","The work presents an effective approach for subpixel motion estimation for Super-resolution (SR). The objective is to improve the quality of the estimated SR image by increasing the accuracy of the motion vectors used in the SR procedure. The correction of the motion vectors is based on appearance of error artifacts in the SR image, introduced due to registration errors. First, SR is performed using full pixel accuracy motion vectors obtained using full search block matching algorithm (FS-BMA). Then, machine learning based method is applied on the resulting images in order to detect and classify artifacts introduced due to missing subpixel components of the motion vectors. The outcome of the classification is a subpixel component of the motion vector. In the final step, SR process is repeated using the corrected (subpixel accuracy) motion vectors.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952028","artifacts detection;image registration;machine learning;super-resolution","Accuracy;Feature extraction;Image edge detection;Image resolution;Motion estimation;Support vector machine classification;Vectors","image classification;image matching;image registration;image resolution;learning (artificial intelligence);motion estimation","SR image quality improvement;artifact classification;error artifact recognition;full search block matching algorithm;machine learning based method;motion estimation;motion vector correction;registration error;subpixel component classification;super resolution","","0","","22","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Measuring activities and counting steps with the SmartSocks - An unobtrusive and accurate method","J. Lu; T. Zhang; F. Hu; Y. Wu; K. Bao","Department of Electrical and Computer Engineering, University of Alabama, USA","IEEE Global Humanitarian Technology Conference (GHTC 2014)","20141204","2014","","","694","698","Physical inactivity is an important contributor to non-communicable diseases in countries of high income, and increasingly so in those of low and middle income. Physical inactivity is the leading cause of many diseases. It has been estimated that as many as 250,000 deaths per year in the United States, approximately 12% of the total, are attributable to a lack of regular physical activity. Measuring physical activities and counting steps is an effective method to diagnose some diseases. It can also serve as an effective method to encourage people to increase their physical activity. Pedometers have been invented as a convenient way of counting steps. However most of them lack the functionality of differentiating activities. Pressure sensor pads can measure steps and gait, but as the pad has a limited size, it can not meet the need of anytime and anywhere usage. In this study, we made the Sensor Socks for measuring physical activities and counting steps. It is unobtrusive and convenient for everyday usage. Our experimental results show that the system has a high accuracy of the classification of physical activities and counting steps in a home or community environment.","","Electronic:978-1-4799-7193-0; POD:978-1-4799-7194-7","10.1109/GHTC.2014.6970358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970358","Biomedicine;Data Mining;Machine Learning;Wearable Sensors","Accuracy;Biomedical measurement;Computers;Diseases;Legged locomotion;Support vector machines;Vectors","biomedical measurement;diseases;gait analysis;medical computing;patient diagnosis;pressure sensors","SmartSocks;accurate method;counting steps;gait analysis;noncommunicable diseases diagnosis;pedometers;physical activity classification;physical inactivity measurement;pressure sensor;regular physical activity;sensor socks;unobtrusive method","","0","","16","","","10-13 Oct. 2014","","IEEE","IEEE Conference Publications"
"Mapping past human activity using low representative site location datasets and elevation data","J. Jasiewicz; I. Sobkowiak-Tabaka","Inst. of Geoecology & Geoinf., Adam Mickiewicz Univ., Poznan, Poland","2014 IEEE Geoscience and Remote Sensing Symposium","20141106","2014","","","910","913","Archaeological maps based on the location of sites are strongly biased by the degree of archaeological recognition and inform little about the real pattern of past human activities, especially on areas poorly covered by surveys. Continuous maps and spatial models, independent of the degree of archaeological recognition of the area, can used as a tool for explanation of the patterns of past human activity [1]. There are several methods (see: [2, 3, 4, 1] for details) which couple information about the location of archaeological remnants and variables derived from natural datasets and social and economic variables. These methods use Geographic Information Science technology and statistical algorithms and result in maps of past human activity. Correct models require the user to know the importance of variables what is difficult to proceed on insensibly contrasted areas like temperate lowlands (Jasiewicz, Hildebrandt-Radke 2009). and requires a large amount of representative data so its application is limited only to well recognized areas where data representativeness is not questionable - which does not occur very often. Furthermore, archaeological remnants tend to be clustered also that some areas were examined more thoroughly than others. This leads to the problem of data imbalance. The term refers to any dataset that exhibits an radically unequal distribution between its classes [5, 6].","2153-6996;21536996","Electronic:978-1-4799-5775-0; POD:978-1-4799-5314-1; USB:978-1-4799-5774-3","10.1109/IGARSS.2014.6946573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6946573","Archaeological datasets;CART;machine learning;predictive modeling","Analytical models;Data models;Educational institutions;Indexes;Lakes;Spatial databases;Standards","archaeology;geographic information systems;terrain mapping","Geographic Information Science technology;archaeological maps;archaeological recognition;continuous maps;economic variables;elevation data;low representative site location datasets;past human activity mapping;social variables;spatial models;statistical algorithms","","0","","15","","","13-18 July 2014","","IEEE","IEEE Conference Publications"
"A single vs. multi-sensor approach to enhanced detection of smartphone placement","J. J. Guiry; C. J. Karr; P. van de Ven; J. Nelson; M. Begale","Department of Electronic and Computer Engineering, University of Limerick, Limerick, Ireland","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","3691","3694","In this paper, the authors evaluate the ability to detect on-body device placement of smartphones. A feasibility study is undertaken with N=5 participants to identify nine key locations, including in the hand, thigh and backpack, using a multitude of commonly available smartphone sensors. Sensors examined include the accelerometer, magnetometer, gyroscope, pressure and light sensors. Each sensor is examined independently, to identify the potential contributions it can offer, before a fused approach, using all sensors is adopted. A total of 139 features are generated from these sensors, and used to train five machine learning algorithms, i.e. C4.5, CART, NaiÃàve Bayes, Multilayer Perceptrons, and Support Vector Machines. Ten-fold cross validation is used to validate these models, achieving classification results as high as 99%.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6944424","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6944424","Enhanced Contextual Awareness;Machine Learning;Multi-Sensor Fusion;Smartphone Placement","Accelerometers;Breast;Gyroscopes;Hip;Magnetic sensors;Magnetometers","accelerometers;belief networks;gyroscopes;magnetometers;mobile computing;multilayer perceptrons;pressure sensors;sensor fusion;sensor placement;smart phones;support vector machines","C4.5;CART;NaiÃàve Bayes;accelerometer;gyroscope;light sensors;machine learning algorithms;magnetometer;multilayer perceptrons;on-body device placement;pressure sensors;smartphone placement;smartphone sensors;support vector machines","","0","","14","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"<sc>Lift</sc>: Multi-Label Learning with Label-Specific Features","M. L. Zhang; L. Wu","School of Computer Science and Engineering, Southeast University, Nanjing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","20141206","2015","37","1","107","120","Multi-label learning deals with the problem where each example is represented by a single instance (feature vector) while associated with a set of class labels. Existing approaches learn from multi-label data by manipulating with identical feature set, i.e. the very instance representation of each example is employed in the discrimination processes of all class labels. However, this popular strategy might be suboptimal as each label is supposed to possess specific characteristics of its own. In this paper, another strategy to learn from multi-label data is studied, where label-specific features are exploited to benefit the discrimination of different class labels. Accordingly, an intuitive yet effective algorithm named LIFT, i.e. multi-label learning with Label specific Features, is proposed. LIFT firstly constructs features specific to each label by conducting clustering analysis on its positive and negative instances, and then performs training and testing by querying the clustering results. Comprehensive experiments on a total of 17 benchmark data sets clearly validate the superiority of LIFT against other well-established multi-label learning algorithms as well as the effectiveness of label-specific features.","0162-8828;01628828","","10.1109/TPAMI.2014.2339815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6857380","Machine learning;label correlations;label-specific features;multi-label learning","Algorithm design and analysis;Clustering algorithms;Correlation;Measurement;Text categorization;Training;Vectors","learning (artificial intelligence);pattern clustering","LIFT;clustering analysis;multi label learning with label specific feature algorithm","","19","","60","","20140716","Jan. 1 2015","","IEEE","IEEE Journals & Magazines"
"Improving the Recognition Performance of NIALM Algorithms through Technical Labeling","M. Mathis; A. Rumsch; R. Kistler; A. Andrushevich; A. Klapproth","CEESAR-iHomeLab, Univ. of Appl. Sci. & Arts, Horw, Switzerland","2014 12th IEEE International Conference on Embedded and Ubiquitous Computing","20141120","2014","","","227","233","A myriad of different electrical devices populate a typical household nowadays. Non-intrusive appliance load monitoring (NIALM) is an approach to find out how much energy each of them consumes in order to take measures to improve the overall energy efficiency. This article describes the ongoing research on improving electric loads recognition performed by NIALM algorithms within the context of smart homes and intelligent environments. The recognition performance can be significantly improved by decreasing the number of categories to be analyzed. The authors studied several labeling methods to categorize and group loads in order to increase the overall recognition rate. 31 different devices have been measured and labeled in different device states. Their input curves have been compared with 5 different machine learning algorithms. The best results could be reached by dividing all the loads into groups with small divergence in their normalized current curve. This approach has significantly increased the performance of NIALM recognition algorithms.","","Electronic:978-0-7695-5249-1; POD:978-1-4799-7609-6","10.1109/EUC.2014.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6962291","Fourier Transformation;NIALM;NILM;Wavelet;device categorisation;device labeling;intelligent environment;load disaggregation;load recognition;machine learning algorithm;technical labeling","Accuracy;Current measurement;Labeling;Machine learning algorithms;Object recognition;Performance evaluation;Wavelet transforms","domestic appliances;energy conservation;learning (artificial intelligence);load (electric);power aware computing","NIALM recognition algorithm performance;electric load recognition;electrical devices;energy efficiency;input curves;machine learning algorithms;nonintrusive appliance load monitoring;normalized current curve;overall recognition rate;smart homes;technical labeling","","3","","16","","","26-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Leveraging Formal Concept Analysis with Topic Correlation for Service Clustering and Discovery","M. Aznag; M. Quafafou; Z. Jarir","LSIS, Aix-Marseille Univ., Marseille, France","2014 IEEE International Conference on Web Services","20141204","2014","","","153","160","With a growing number of web services, discovering services that can match with a user's query becomes a challenging task. It's very tedious for a service consumer to select the appropriate one according to her/his needs. In this paper, we propose a non-logic-based matchmaking approach that uses the Correlated Topic Model (CTM) to extract topic from semantic service descriptions and model the correlation between the extracted topics. Based on the topic correlation, service descriptions can be grouped into hierarchical clusters. In our approach, we use the Formal Concept Analysis (FCA) formalism to organize the constructed hierarchical clusters into concept lattices according to their topics. Thus, service discovery may be achieved more easily using the concept lattice. In our approach, topic models are used as efficient dimension reduction techniques, which are able to capture semantic relationships between word-topic and topic-service interpreted in terms of probability distributions. In our experiment, we compared the accuracy of the our hierarchical clustering algorithm with that of a classical hierarchical agglomerative clustering. The comparisons of Precision@n and Normalised Discounted Cumulative Gain (NDCGn) values for our approach, Apache lucene and SAWSDL-MX2 Matchmaker indicate that the method based on CTM presented in this paper outperform all the others matchmakers in terms of ranking of the most relevant services.","","Electronic:978-1-4799-5054-6; POD:978-1-4799-5055-3","10.1109/ICWS.2014.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6928893","Data Representation;Discovery and ranking;Formal Concept Analysis;Hierarchical Clustering;Machine Learning;Topic Models;Web service","Clustering algorithms;Correlation;Lattices;Mathematical model;Power capacitors;Semantics;Web services","Web services;data mining;formal concept analysis;pattern clustering;statistical distributions","Apache lucene;CTM;FCA;NDCGn value;SAWSDL-MX2 Matchmaker;Web services;concept lattices;correlated topic model;dimension reduction techniques;formal concept analysis;hierarchical agglomerative clustering;hierarchical clustering algorithm;nonlogic-based matchmaking approach;normalised discounted cumulative gain;probability distribution;service clustering;service consumer;service descriptions;service discovery;topic correlation;topic-service;word-topic","","8","","19","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"Content-Based Prediction of Movie Style, Aesthetics, and Affect: Data Set and Baseline Experiments","J. Tarvainen; M. Sj√∂berg; S. Westman; J. Laaksonen; P. Oittinen","Department of Media Technology, Aalto University School of Science, Espoo, Finland","IEEE Transactions on Multimedia","20141113","2014","16","8","2085","2098","The affective content of a movie is often considered to be largely determined by its style and aesthetics. Recently, studies have attempted to estimate affective movie content with computational features, but results have been mixed, one of the main reasons being a lack of data on perceptual stylistic and aesthetic attributes of film, which would provide a ground truth for the features. The distinctions between energetic and tense arousal as well as perceived and felt affect are also often neglected. In this study, we present a data set of ratings by 73 viewers of 83 stylistic, aesthetic, and affective attributes for a selection of movie clips containing complete scenes taken from mainstream movies. The affective attributes include the temporal progression of perceived and felt valence and arousal within the clips. The data set is aimed to be used to train algorithms that predict viewer assessments based on low-level computational features. With this data set, we performed a baseline study modeling the relation between a large selection of low-level computational features (i.e., visual, auditory, and temporal) and perceptual stylistic, aesthetic, and affective attributes of movie clips. Two algorithms were compared in a realistic prediction scenario: linear regression and the neural-network-based Extreme Learning Machine (ELM). Felt and perceived affect as well as stylistic attributes were shown to be equally easy to predict, whereas the prediction of aesthetic attributes failed. The performance of the ELM predictor was overall found to be slightly better than the linear regression. A feature selection experiment illustrated that features from all low-level computational modalities, visual, auditory and temporal, contribute to the prediction of the affect assessments. We have made our assessment data and extracted computational features publicly available.","1520-9210;15209210","","10.1109/TMM.2014.2357688","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898024","Aesthetics;content-based analysis;felt affect;film;machine learning;modeling;perceived affect;style","Computational modeling;Feature extraction;Hidden Markov models;Machine learning;Motion pictures;Prediction methods","content-based retrieval;feature extraction;feature selection;learning (artificial intelligence);neural nets;regression analysis;video retrieval","aesthetic attributes;affective attributes;affective movie content;computational feature extraction;feature selection experiment;linear regression;low-level computational features;movie clips;movie style content-based prediction;neural-network-based ELM;neural-network-based extreme learning machine;perceptual stylistic attributes;viewer assessment prediction","","2","","80","","20140912","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"An opinion mining approach for Romanian language","R. M. Russu; M. Dinsoreanu; O. L. Vlad; R. Potolea","Technical University of Cluj-Napoca, Romania","2014 IEEE 10th International Conference on Intelligent Computer Communication and Processing (ICCP)","20141030","2014","","","43","46","The paper proposes a solution for document and aspect levels sentiment analysis for unstructured documents written in the Romanian language. The opinion extraction relies on two different approaches for polarity identification. At the aspect level we propose a rule-based approach. For the document level we consider supervised learning techniques, based on features extracted and filtered in different layers, based on their polarity discriminative power.","","Electronic:978-1-4799-6569-4; POD:978-1-4799-6570-0","10.1109/ICCP.2014.6936978","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936978","NLP;Romanian;implementation;machine learning;opinion mining","Classification algorithms;Educational institutions;Feature extraction;Niobium;Search engines;Support vector machines;Text categorization","data mining;knowledge based systems;learning (artificial intelligence);natural language processing","Romanian language;aspect level sentiment analysis;document analysis;feature extraction;opinion extraction;opinion mining;polarity identification;rule-based approach;supervised learning","","0","","8","","","4-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"Automatic Human Mocap Data Classification","H. Kadu; C. C. J. Kuo","Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Multimedia","20141114","2014","16","8","2191","2202","Automatic classification of human motion capture (mocap) data has many commercial, biomechanical, and medical applications and is the principal focus of this paper. First, we propose a multi-resolution string representation scheme based on the tree-structured vector quantization (TSVQ) to transform the time-series of human poses into codeword sequences. Then, we take the temporal variations of human poses into account via codeword sequence matching. Furthermore, we develop a family of pose-histogram-based classifiers to examine the spatial distribution of human poses. We analyze the performance of the temporal and spatial classifiers separately. To achieve a higher classification rate, we merge their decisions and soft scores using novel fusion methods. The proposed fusion solutions are tested on a wide variety of sequences from the CMU mocap database using five-fold cross validation, and a correct classification rate of 99.6% is achieved.","1520-9210;15209210","","10.1109/TMM.2014.2360793","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913001","Database management;SVM;human motion analysis;machine learning;mocap data;motion recognition;n-fold cross validation;suffix array;vector quantization","Arrays;Indexes;Joints;Three-dimensional displays;Training;Vectors","image classification;image fusion;image matching;image motion analysis;image representation;image resolution;pose estimation;time series","CMU mocap database;TSVQ;automatic human mocap data classilication;biomechanical applications;codeword sequence matching;codeword sequences;commercial applications;five-fold cross validation;fusion methods;human motion capture;human pose time-series;medical applications;multiresolution string representation scheme;pose-histogram-based classifiers;temporal variations;tree-structured vector quantization","","1","","47","","20140929","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Applying Reinforcement Learning for Resolving Ambiguity in Service Composition","A. Jungmann; F. Mohr; B. Kleinjohann","C-Lab., Univ. of Paderborn, Paderborn, Germany","2014 IEEE 7th International Conference on Service-Oriented Computing and Applications","20141206","2014","","","105","112","Automatically composing service-based software solutions is still a challenging task. Functional as well as non-functional properties have to be considered in order to satisfy individual user requests. Regarding non-functional properties, the composition process can be modeled as optimization problem and solved accordingly. Functional properties, in turn, can be described by means of a formal specification language. State-space based planning approaches can then be applied to solve the underlying composition problem. However, depending on the expressiveness of the applied formalism and the completeness of the functional descriptions, formally equivalent services may still differ with respect to their implemented functionality. As a consequence, the most appropriate solution for a desired functionality can hardly be determined without considering additional information. In this paper, we demonstrate how to overcome this lack of information by means of Reinforcement Learning. In order to resolve ambiguity, we expand state-space based service composition by a recommendation mechanism that supports decision-making beyond formal specifications. The recommendation mechanism adjusts its recommendation strategy based on feedback from previous composition runs. Image processing serves as case study. Experimental results show the benefit of our proposed solution.","2163-2871;21632871","Electronic:978-1-4799-6833-6; POD:978-1-4799-6834-3","10.1109/SOCA.2014.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978597","Machine Learning;Reinforcement Learning;Service Composition;Service Functionality;Service Recommendation","Concrete;Context;Decision making;Image processing;Learning (artificial intelligence);Markov processes;Planning","formal specification;learning (artificial intelligence);optimisation;recommender systems","decision-making;formal specification language;functional descriptions;individual user requests;nonfunctional properties;optimization problem;recommendation mechanism;reinforcement learning application;service composition;state space based planning;state-space based service composition","","0","","25","","","17-19 Nov. 2014","","IEEE","IEEE Conference Publications"
"The potential of network state-based algorithm selection to improve power flow management","J. King; S. Jupe; P. Taylor","Parsons Brinckerhoff, Newcastle upon Tyne, UK","2014 IEEE PES General Meeting | Conference & Exposition","20141030","2014","","","1","5","Power flow management, within an active network management scheme, curtails generators' output in order to alleviate overloads on network branches. In this paper, several algorithms for power flow management - based on constraint satisfaction, optimal power flow, and power flow sensitivity factors - are applied to a version of the IEEE 14-bus system. Depending on the network state, the algorithms vary in their ability to alleviate overloads and the amount of curtailment they apply. A performance benefit is demonstrated from appropriately selecting which algorithm to use based on network state, rather than always using the same algorithm for all network states. The paper also contains an overview of how systems could be built to select algorithms based on measurements of network state.","1932-5517;19325517","Electronic:978-1-4799-6415-4; POD:978-1-4799-6416-1; USB:978-1-4799-6414-7","10.1109/PESGM.2014.6938918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6938918","Algorithms;Machine learning;Power system control;Power systems;Smart grids","Algorithm design and analysis;Approximation algorithms;Feature extraction;Generators;Machine learning algorithms;Power systems;Prediction algorithms","active networks;load flow;power system management;power system measurement;sensitivity","IEEE 14-bus system;active network management scheme;curtails generator output;network state-based algorithm selection;power flow management;power flow sensitivity factors","","1","","18","","","27-31 July 2014","","IEEE","IEEE Conference Publications"
"Comparative Analysis of Filter-Wrapper Approach for Random Forest Performance on Multivariate Data","S. Dinakaran; P. R. J. Thangaiah","Dept. of CA, Karunya Univ., Coimbatore, India","2014 International Conference on Intelligent Computing Applications","20141124","2014","","","174","178","Feature selection is the process of selecting the superlative feature from the preprocessed datasets. It is also useful in machine learning to improve the speed as well as to improve the classification accuracy. This paper deals with filter and wrapper approach to identify their pros and cons with respect to decision tree based classification algorithm. Filter and wrapper approach with a best first search method and genetic search method is used with a decision tree based random forest algorithm to compare the classification accuracy. Datasets are taken from the UCI machine learning repository to test the accuracy rate. The results obtained are compared with the existing algorithms and are discussed based on the classification accuracy.","","Electronic:978-1-4799-3966-4; POD:978-1-4799-3967-1","10.1109/ICICA.2014.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965035","Feature selection;Random forest;best first search;genetic search;machine learning","Accuracy;Classification algorithms;Decision trees;Filtering algorithms;Information filters;Search methods","decision trees;feature selection;genetic algorithms;learning (artificial intelligence);pattern classification;search problems","classification algorithm;decision tree;feature selection;filter-wrapper approach;genetic search method;machine learning;multivariate data;random forest algorithm","","1","","22","","","6-7 March 2014","","IEEE","IEEE Conference Publications"
"GPS-Based Vehicle Moving State Recognition Method and Its Applications on Dynamic In-Car Navigation Systems","H. Qi; Y. Liu; D. Wei","Coll. of Comput. Sci. & Technol, Jilin Univ., Changchun, China","2014 IEEE 12th International Conference on Dependable, Autonomic and Secure Computing","20141106","2014","","","354","360","In order to effectively determine whether a vehicle is turning or not, we proposed a method to map arbitrary consecutive GPS heading information to 2 dimensional feature space. Then we applied K-means clustering algorithm to divide the feature space into 2 classes: going straight and turning. After that, we used supervised learning algorithm to analyze these labeled data and build a model to recognize vehicle moving state. The experimental results showed that the model built in this way has good generalization. Based on the above research achievement, we designed and implemented a vehicle moving state recognition learning system for dynamic in-car navigation systems and applied this learning system to the map-matching field. The improved map-matching algorithm was tested on a complex urban road network and the result showed that the new algorithm can significantly improve the performance of the junction match.","","CD-ROM:978-1-4799-5078-2; Electronic:978-1-4799-5079-9; POD:978-1-4799-5080-5","10.1109/DASC.2014.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945715","Artificial Intelligence;Dynamic In-Car Navigation Systems;GPS;Machine Learning","Clustering algorithms;Global Positioning System;Roads;Servers;Turning;Vehicles","Global Positioning System;computerised navigation;generalisation (artificial intelligence);learning (artificial intelligence);pattern clustering;pattern recognition;traffic engineering computing","2 dimensional feature space;GPS heading information;GPS-based vehicle moving state recognition method;K-means clustering algorithm;complex urban road network;dynamic in-car navigation systems;improved map-matching algorithm;supervised learning algorithm;vehicle moving state recognition learning system","","0","","24","","","24-27 Aug. 2014","","IEEE","IEEE Conference Publications"
"Gaussian process for interpreting pulsed eddy current signals for ferromagnetic pipe profiling","N. Ulapane; A. Alempijevic; T. Vidal-Calleja; J. V. Miro; J. Rudd; M. Roubal","Centre for Autonomous Systems, University of Technology Sydney, Australia","2014 9th IEEE Conference on Industrial Electronics and Applications","20141023","2014","","","1762","1767","This paper describes a Gaussian Process based machine learning technique to estimate the remaining volume of cast iron in ageing water pipes. The method utilizes time domain signals produced by a commercially available pulsed Eddy current sensor. Data produced by the sensor are used to train a Gaussian Process model and perform inference of the remaining metal volume. The Gaussian Process model was learned using sensor data obtained from cast iron calibration plates of various thicknesses. Results produced by the Gaussian Process model were validated against the remaining wall thickness acquired using a high resolution laser scanner after the pipes were sandblasted to remove corrosion. The evaluation shows agreement between model outputs and ground truth. The paper concludes by discussing the implications or results and how the proposed method can potentially advance the current technological setup by facilitating real time pipe profiling.","2156-2318;21562318","CD-ROM:978-1-4799-4316-6; Electronic:978-1-4799-4315-9; POD:978-1-4799-4314-2","10.1109/ICIEA.2014.6931453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6931453","Gaussian process;ferromagnetic;machine learning;non-destructive testing;pulsed Eddy current;sensor model","Cast iron;Eddy currents;Feature extraction;Gaussian processes;Testing;Training data;Uncertainty","Gaussian processes;condition monitoring;corrosion;eddy current testing;ferromagnetic materials;learning (artificial intelligence);mechanical engineering computing;optical scanners;pipes","Gaussian process;cast iron calibration;corrosion;eddy current sensors;ferromagnetic pipe profiling;machine learning technique;pulsed eddy current signals;remaining metal volume;sandblasting;water pipe ageing","","4","","18","","","9-11 June 2014","","IEEE","IEEE Conference Publications"
"Improving Automatic Image Annotation with Google Semantic Link","H. Xu; P. Pan; Y. Lu; C. Xu; D. Chen","Sch. of Comput. Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China","2014 10th International Conference on Semantics, Knowledge and Grids","20141124","2014","","","177","184","During the past few years, there has been a massive explosion of multimedia content such as un-annotated images on the web. Automatic image annotation is an important task for multimedia retrieval. By automatically allocating semantic concepts to un-annotated images, image retrieval can be performed over annotation concepts. In this work, we address the problem of automatic image annotation, namely automatically describing semantic content of image by concept classifier. Traditional approaches mainly consider the link between image and concept, but ignore the link between annotation concepts. We propose a novel Google Semantic link based image Annotation Model (GSAM), which can leverage the associated concept network (ACN) to enhance automatic semantic annotation performance. When several concepts appear in training set with high co-occurrence frequency, our model utilizes Google semantic link to increase the chances of predicting one concept if there is strong visual evidence for others. Additionally, the fusion between Google concept link and local concept link, and semantic links between single-concepts and multi-concepts are employed to improve annotation performance. In order to investigate the feasibility and effectiveness of our approach, we conduct experiments on Corel and IAPR datasets. The experimental results show that our approach considering semantic link outperforms existing state-of-the-art methods.","","Electronic:978-1-4799-6715-5; POD:978-1-4799-6716-2","10.1109/SKG.2014.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6964687","Google distance;automatic semantic annotation;machine learning;semantic link","Correlation;Google;Mathematical model;Semantics;Training;Visualization;Vocabulary","image classification;image retrieval;search engines","Corel dataset;GSAM model;Google Semantic link;IAPR dataset;automatic image annotation;concept classifier;multimedia content;multimedia retrieval;semantic concepts","","1","","36","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"A Density based clustering with Artificial Immunity inspired preprocessing","S. K. Paul; P. Bhaumik","Information Technology, Tata Consultancy Services, Kolkata, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","2648","2654","In this paper we propose an algorithm which can identify varied shaped clusters from wide variety of input dataset with high degree of accuracy in presence of noise. The initial data processing module adopts a novel approach of Artificial Immune system to reduce data redundancy while preserving the original data patterns. The clustering module pursues a density based approach to identify clusters from the compressed dataset produced by the preprocessing module. We introduced several new concepts like selective Antigenic binding, Local Reachability Factor, Global Reachability Factor to effectively recognize clusters with varied shape, varied density and low intercluster separation with acceptable computational cost. We performed experimental evaluation of our algorithm with wide variety of real and synthetic dataset and obtained higher cluster success rate for all dataset when compared to DBSCAN.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968258","Artificial Immune Systems;Density based clustering algorithms;Detecting varied shaped clusters;Machine Learning;Pattern Recognition","Complexity theory;Sorting","artificial immune systems;pattern clustering;reachability analysis","DBSCAN;artificial immune system;artificial immunity inspired preprocessing;clustering module;data redundancy redundancy;density based clustering;global reachability factor;initial data processing module;local reachability factor;selective antigenic binding","","0","","19","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Effective intrusion detection system using semi-supervised learning","S. K. Wagh; S. R. Kolhe","Department of Computer Engineering, MES College of Engineering, Pune, India","2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)","20141113","2014","","","1","5","Network security is a very important aspect of internet enabled systems in the present world scenario. As the internet keeps developing the number of security attacks as well as their severity has shown a significant increase. Due to intricate chain of computers the opportunities for intrusions and attacks have increased. Therefore it is need of the hour to find the best ways possible to protect our systems. Every day new kind of attacks are being faced by industries. Hence intrusion detection system are playing vital role for computer security. The most effective method used to solve problem of IDS is machine learning. Getting labeled data does not only require more time but it is also expensive. Labeled data along with unlabeled data is used in semi-supervised methods. The rising field of semi-supervised learning offers a assured way for complementary research. In this paper, an effective semi-supervised method to reduce false alarm rate and to improve detection rate for IDS is proposed.","","Electronic:978-1-4799-4674-7; POD:978-1-4799-4673-0","10.1109/ICDMIC.2014.6954236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954236","Boosting algorithm;Intrusion Detection System;Machine learning;Semi-supervised Learning","Accuracy;Algorithm design and analysis;Intrusion detection;Semisupervised learning;Supervised learning;Testing;Training","learning (artificial intelligence);security of data","IDS;computer security;detection rate;false alarm rate reduction;intrusion detection system;machine learning;network security;security attacks;semisupervised learning","","0","","14","","","5-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"gpuRF and gpuERT: Efficient and Scalable GPU Algorithms for Decision Tree Ensembles","K. Jansson; H. Sundell; H. Bostr√∂m","Sch. of Bus. & I, T Univ. of Boras, Boras, Sweden","2014 IEEE International Parallel & Distributed Processing Symposium Workshops","20141204","2014","","","1612","1621","We present two new parallel implementations of the ensemble learning methods Random Forests (RF) and Extremely Randomized Trees (ERT), called gpuRF and gpuERT, for emerging many-core platforms, e.g., contemporary graphics cards suitable for general-purpose computing (GPGPU). RF and ERT are two ensemble methods for generating predictive models that are of high importance within machine learning. They operate by constructing a multitude of decision trees at training time and outputting a prediction by comparing the outputs of the individual trees. Thanks to the inherent parallelism of the task, an obvious platform for its computation is to employ contemporary GPUs with a large number of processing cores. Previous parallel algorithms for RF in the literature are either designed for traditional multi-core CPU platforms or early history GPUs with simpler architecture and relatively few cores. For ERT, only briefly sketched parallelization attempts exist in the literature. The new parallel algorithms are designed for contemporary GPUs with a large number of cores and take into account aspects of the newer hardware architectures, such as memory hierarchy and thread scheduling. They are implemented using the C/C++ language and the CUDA interface to attain the best possible performance on NVidia-based GPUs. An experimental study comparing the most important previous solutions for CPU and GPU platforms to the novel implementations shows significant advantages in the aspect of efficiency for the latter, often with several orders of magnitude.","","Electronic:978-1-4799-4116-2; POD:978-1-4799-4115-5","10.1109/IPDPSW.2014.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969569","CUDA;GPGPU;Machine Learning;Parallel Algorithms;Random Forest","Decision trees;Graphics processing units;Histograms;Instruction sets;Kernel;Radio frequency;Vegetation","decision trees;graphics processing units;learning (artificial intelligence);mathematics computing;multi-threading;parallel algorithms;parallel architectures","C/C++ language;CUDA interface;GPGPU;GPU algorithms;NVidia-based GPUs;contemporary graphics cards;decision tree ensembles;decision trees;ensemble learning methods;ensemble methods;extremely randomized trees;general-purpose computing;gpuERT;gpuRF;machine learning;many-core platforms;memory hierarchy;parallel algorithms;parallel implementations;predictive model generation;random forests;thread scheduling","","0","","21","","","19-23 May 2014","","IEEE","IEEE Conference Publications"
"How many packets are most effective for early stage traffic identification: An experimental study","L. Peng; B. Yang; Y. Chen; T. Wu","Shandong Provincial Key Lab. for Network Based Intell. Comput., Univ. of Jinan, Jinan, China","China Communications","20141128","2014","11","9","183","193","Accurately identifying network traffics at the early stage is very important for the application of traffic identification. Recent years, more and more research works have tried to build effective machine learning models to identify traffics with the few packets at the early stage. However, a basic and important problem is still unresolved, that is how many packets are most effective in early stage traffic identification. In this paper, we try to resolve this problem using experimental methods. We firstly extract the packet size of the first 2-10 packets of 3 traffic data sets. And then execute crossover identification experiments with different numbers of packets using 11 well-known machine learning classifiers. Finally, statistical tests are applied to find out which number is the best performed one. Our experimental results show that 5-7 are the best packet numbers for early stage traffic identification.","1673-5447;16735447","","10.1109/CC.2014.6969782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969782","early stage traffic classification;feature extraction;machine learning","Feature extraction;Machine learning;Packet switching;Telecommunication network management;Telecommunication traffic","Internet;learning (artificial intelligence);telecommunication traffic","crossover identification experiment;early stage traffic identification;feature extraction;machine learning model;packet size;traffic data sets","","1","","","","","Sept. 2014","","IEEE","IEEE Journals & Magazines"
"User modeling with limited data: Application to stakeholder-driven watershed design","S. Mukhopadhyay; V. B. Singh; M. Babbar-Sebens","Computer & Information Science, Indiana University Purdue University Indianapolis, USA","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","3855","3860","We have developed a web-based, interactive, watershed planning system called WRESTORE (Watershed Restoration Using Spatio-Temporal Optimization of Resources) (http://wrestore.iupui.edu) that allows stake-holder communities to participate in a democratic, collaborative form of optimization process for designing best management practices (BMPs) on their landscape, while also optimizing based on subjective, qualitative landowners' criteria beyond the usual socio-economic, physical, and ecological criteria. This system utilizes multiple advanced computational approaches including the SWAT (Soil and Water Assessment Tool) hydrologic model for watershed simulations, interactive genetic algorithms and reinforcement-based machine learning algorithms for search and optimization, and deep learning artificial neural networks for user modeling, within an encompassing human-computer interaction framework. A substantial user study of the WRESTORE system was conducted recently involving multiple real stakeholders varying from consultants, government officials, watershed alliance members, etc., with the objective of gaining insight about WRESTORE'S usability and utility. In particular focus was the user modeling component that develops a computational model of a user's preferences and criteria, based on real-time user-provided ratings for a subset of possible designs (similar to the idea of user profiling commonly done for human-computer interaction systems). The user model constructed based on the real user's personalized feedbacks can then be used to influence the automated search and optimization for BMP alternatives in WRESTORE. In this paper, we describe the methods developed for user modeling for interactive optimization, and the experimental set-up as well as results with real user studies. These results clearly demonstrate that development of user models for such personalized, interactive optimization is both feasible and valuable for developing community-based computa- ional water sustainability solutions.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974532","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974532","decision support system;interactive optimization;machine learning;sustainability design;user modeling","Adaptation models;Artificial neural networks;Computational modeling;Data models;Mathematical model;Optimization","Internet;environmental science computing;human computer interaction;hydrology;interactive systems;learning (artificial intelligence);neural nets;socio-economic effects;water resources","BMP;SWAT hydrologic model;WRESTORE;Web-based interactive watershed planning system;best management practices;community-based computational water sustainability solutions;deep learning artificial neural networks;ecological criteria;human-computer interaction framework;interactive genetic algorithms;limited data;physical criteria;reinforcement-based machine learning algorithms;socio-economic criteria;soil and water assessment tool;stakeholder-driven watershed design;user modeling;watershed restoration using spatio-temporal optimization of resources","","0","","21","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"A stochastic 3MG algorithm with application to 2D filter identification","E. Chouzenoux; J. C. Pesquet; A. Florescu","Universit&#x00E9; Paris-Est, LIGM, UMR CNRS 8049, Champs sur Marne, France","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","1587","1591","Stochastic optimization plays an important role in solving many problems encountered in machine learning or adaptive processing. In this context, the second-order statistics of the data are often unknown a priori or their direct computation is too intensive, and they have to be estimated on-line from the related signals. In the context of batch optimization of an objective function being the sum of a data fidelity term and a penalization (e.g. a sparsity promoting function), Majorize-Minimize (MM) subspace methods have recently attracted much interest since they are fast, highly flexible and effective in ensuring convergence. The goal of this paper is to show how these methods can be successfully extended to the case when the cost function is replaced by a sequence of stochastic approximations of it. Simulation results illustrate the good practical performance of the proposed MM Memory Gradient (3MG) algorithm when applied to 2D filter identification.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952577","Newton method;adaptive filtering;descent methods;filter identification;machine learning;majorization-minimization;memory gradient methods;optimization;recursive algorithms;sparsity;stochastic approximation;subspace algorithms","Algorithm design and analysis;Approximation methods;Context;Convergence;Kernel;Optimization;Signal processing algorithms","approximation theory;filtering theory;higher order statistics;optimisation","2D filter identification;MM memory gradient algorithm;adaptive processing;batch optimization;data fidelity term;machine learning;majorize-minimize subspace methods;second-order statistics;stochastic 3MG algorithm;stochastic approximations","","0","","21","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Predicting dynamic computational workload of a self-driving car","Y. W. Seo; J. Kim; R. Rajkumar","The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA USA","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","3030","3035","This study aims at developing a method that predicts the CPU usage patterns of software tasks running on a self-driving car. To ensure safety of such dynamic systems, the worst-case-based CPU utilization analysis has been used; however, the nature of dynamically changing driving contexts requires more flexible approach for an efficient computing resource management. To better understand the dynamic CPU usage patterns, this paper presents an effort of designing a feature vector to represent the information of driving environments and of predicting, using regression methods, the selected tasks' CPU usage patterns given specific driving contexts. Experiments with real-world vehicle data show a promising result and validate the usefulness of the proposed method.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974391","Prediction of software tasks' CPU usage patterns;machine learning;regression;self-driving car","Linear regression;Planning;Regression tree analysis;Roads;Trajectory;Vectors;Vehicles","automobiles;learning (artificial intelligence);resource allocation;software architecture;traffic engineering computing","CPU usage patterns;computational workload prediction;computing resource management;driving context;self-driving car;software tasks;worst-case-based CPU utilization analysis","","0","","21","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Identifying Significant Genes from DNA Microarray Using Genetic Algorithm","K. Dheenathayalan; J. Ramsingh; V. Bhuvaneswari","","2014 International Conference on Intelligent Computing Applications","20141124","2014","","","1","5","Microarray technology is used to monitor thousands of gene expression levels simultaneously and gained attention in recent years. Identifying significant Gene based on expression levels becomes important for diseases prognosis and diagnosis. Evolutionary algorithms like Genetic algorithms are used for finding optimized solutions. The focus of this paper is to apply genetic algorithms as preprocessing technique for identifying significant genes from microarray datasets. The identified genes can be used for analysis for diseases prediction using data mining tasks. The genetic algorithm is implemented using R language for the lymphoma microarray dataset.","","Electronic:978-1-4799-3966-4; POD:978-1-4799-3967-1","10.1109/ICICA.2014.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965000","Microarray;gene expression;genetic algorithm;machine learning;significant genes","Biological cells;Data mining;Gene expression;Genetic algorithms;Sociology;Statistics","bioinformatics;data mining;genetic algorithms","DNA microarray;R language;data mining;genes identification;genetic algorithms;lymphoma microarray dataset;preprocessing technique","","0","","18","","","6-7 March 2014","","IEEE","IEEE Conference Publications"
"Dynamic Weighting New method of weighting panels with large numbers of weighting parameters","M. Pery","Military University of Technology, Faculty of Cybernetics, Warsaw, Poland","2014 Federated Conference on Computer Science and Information Systems","20141023","2014","","","129","134","The algorithm for dynamic weighing presented in this paper is a method used in research studies based on samples when due to the large number of weighting parameters it is not possible to establish a fixed set of sample weights without non-acceptable dispersion of weights.","","Electronic:978-83-60810-58-3; POD:978-1-4799-2853-8; USB:978-8-3608-1057-6","10.15439/2014F488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933005","dynamic weighting;internet audience research;machine learning;multiple classifier systems;weighting methods","Dispersion;Equations;Heuristic algorithms;Internet;Mathematical model;Sociology;Statistics","algorithm theory","dynamic weighing algorithm;dynamic weighting method;panel weighting;weight dispersion;weighting parameters","","0","","16","","","7-10 Sept. 2014","","IEEE","IEEE Conference Publications"
"Classification of BGP anomalies using decision trees and fuzzy rough sets","Y. Li; H. J. Xing; Q. Hua; X. Z. Wang; P. Batta; S. Haeri; L. Trajkoviƒá","Hebei University, Baoding, China","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","1312","1317","Border Gateway Protocol (BGP) is the core component of the Internet's routing infrastructure. Abnormal routing behavior impairs global Internet connectivity and stability. Hence, designing and implementing anomaly detection algorithms is important for improving performance of routing protocols. While various machine learning techniques may be employed to detect BGP anomalies, their performance strongly depends on the employed learning algorithms. These techniques have multiple variants that often work well for detecting a particular anomaly. In this paper, we use the decision tree and fuzzy rough set methods for feature selection. Decision tree and extreme learning machine classification techniques are then used to maximize the accuracy of detecting BGP anomalies. The proposed techniques are tested using Internet traffic traces.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974096","Machine learning;decision tree;extreme learning machine;fuzzy rough sets;weighted extreme learning machine","Accuracy;Approximation methods;Decision trees;Feature extraction;Grippers;Rough sets;Training","Internet;decision trees;feature selection;fuzzy set theory;internetworking;learning (artificial intelligence);pattern classification;rough set theory;routing protocols;telecommunication traffic","BGP anomaly classification;Internet routing infrastructure;Internet traffic traces;anomaly detection algorithms;border gateway protocol;decision trees;extreme learning machine classification techniques;feature selection;fuzzy rough sets;machine learning techniques;routing protocols","","2","","36","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Learning Race from Face: A Survey","S. Fu; H. He; Z. G. Hou","Department of Electrical, Computer, and Biomedical Engineering, University of Rhode Island, Kingston, RI","IEEE Transactions on Pattern Analysis and Machine Intelligence","20141030","2014","36","12","2483","2509","Faces convey a wealth of social signals, including race, expression, identity, age and gender, all of which have attracted increasing attention from multi-disciplinary research, such as psychology, neuroscience, computer science, to name a few. Gleaned from recent advances in computer vision, computer graphics, and machine learning, computational intelligence based racial face analysis has been particularly popular due to its significant potential and broader impacts in extensive real-world applications, such as security and defense, surveillance, human computer interface (HCI), biometric-based identification, among others. These studies raise an important question: How implicit, non-declarative racial category can be conceptually modeled and quantitatively inferred from the face? Nevertheless, race classification is challenging due to its ambiguity and complexity depending on context and criteria. To address this challenge, recently, significant efforts have been reported toward race detection and categorization in the community. This survey provides a comprehensive and critical review of the state-of-the-art advances in face-race perception, principles, algorithms, and applications. We first discuss race perception problem formulation and motivation, while highlighting the conceptual potentials of racial face processing. Next, taxonomy of feature representational models, algorithms, performance and racial databases are presented with systematic discussions within the unified learning scenario. Finally, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potentially important cross-cutting themes and research directions for the issue of learning race from face.","0162-8828;01628828","","10.1109/TPAMI.2014.2321570","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6810000","Race classification;computer vision;data clustering;face database;face recognition;image categorization;machine learning","Computational modeling;Computer vision;Cultural differences;Face recognition;Feature extraction;Image classification;Image color analysis;Psychology","computer vision;face recognition;learning (artificial intelligence);prejudicial factors","HCI;biometric-based identification;computational intelligence;computer graphics;computer science;computer vision;cross-cutting theme;face-race perception;feature representational model;human computer interface;learning scenario;machine learning;multidisciplinary research;neuroscience;psychology;race categorization;race classification;race detection;racial category;racial databases;racial face analysis;racial face processing;security and defense;social signals;surveillance;systematic discussion","0","13","","243","","20140502","Dec. 1 2014","","IEEE","IEEE Journals & Magazines"
"Personalized video summarization based on Multi-Layered Probabilistic Latent Semantic Analysis with shared topics","C. T. Chung; H. K. Hsiung; C. K. Wei; L. S. Lee","Graduate Institute of Electrical Engineering, National Taiwan University, Taiwan","The 9th International Symposium on Chinese Spoken Language Processing","20141027","2014","","","173","177","In this paper, we propose a multi-layered Probabilistic Latent Semantic Analysis (PLSA) model for personalized video summarization problem based on time synchronous comments offered by multiple users. Preliminary evaluations performed on an animation series of 624 minutes long with 12212 users show that the proposed model is able to capture the relationships among the preference of each individual user and the various video events, therefore is able to generate personalized summaries of unseen videos for different users.","","Electronic:978-1-4799-4219-0; POD:978-1-4799-4218-3; USB:978-1-4799-4220-6","10.1109/ISCSLP.2014.6936592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936592","Machine Learning;PLSA;Personalization;Unsupervised Learning;Video Summary","Animation;Joints;Mathematical model;Probabilistic logic;Semantics;Streaming media;Vocabulary","computer animation;probability;video signal processing","PLSA model;animation series;multilayered probabilistic latent semantic analysis model;personalized summary;personalized video summarization problem;shared topics;time synchronous comments;unseen videos;video events","","0","","20","","","12-14 Sept. 2014","","IEEE","IEEE Conference Publications"
"Distinguishing chemicals using CMUT chemical sensor array and artificial neural networks","Q. Stedman; K. K. Park; B. T. Khuri-Yakub","Stanford University, CA, USA","2014 IEEE International Ultrasonics Symposium","20141023","2014","","","162","165","Capacitive micromachined ultrasonic transducers (CMUTs) can function as extremely sensitive mass-loading chemical sensors. The resonant frequency of the CMUT changes as mass is added due to chemicals absorbing into a chemical-sensitive layer on the top of the plate. However, these sensors suffer from the problem that they are not selective to a single chemical. As a solution, we present a system of four CMUT chemical sensors with different functionalization layers. Neural networks are used to do pattern recognition on the sensor outputs in order to distinguish different chemicals. The system is capable of distinguishing water, ethanol, acetone, ethyl acetate, methane and carbon dioxide in air at concentrations less than 1% with 98% accuracy. Once the chemical is identified, the concentration can be determined using polynomial regression with an RMS percentage error ranging from 1.1% to 13%, depending on the analyte.","1051-0117;10510117","Electronic:978-1-4799-7049-0; POD:978-1-4799-7050-6","10.1109/ULTSYM.2014.0041","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6931854","CMUT;Chemical Sensor;Machine Learning;Neural Network","Chemical and biological sensors;Chemical sensors;Chemicals;Linear regression;Neural networks;Nitrogen","capacitive sensors;carbon compounds;chemical sensors;neural nets;organic compounds;pattern recognition;signal processing;ultrasonic transducers;water","CMUT chemical sensor array;CMUT resonant frequency;CO<sub>2</sub>;H<sub>2</sub>O;acetone;artificial neural networks;capacitive micromachined ultrasonic transducers;carbon dioxide;chemical sensitive layer;ethanol;ethyl acetate;functionalization layer;mass loading chemical sensors;methane;polynomial regression;sensor output pattern recognition;water","","1","","6","","","3-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"A text mining approach to automated healthcare for the masses","V. S. Pendyala; Yi Fang; J. Holliday; A. Zalzala","Dept of Computer Eng'g, Santa Clara University, CA 95053 USA","IEEE Global Humanitarian Technology Conference (GHTC 2014)","20141204","2014","","","28","35","There is a tremendous amount of attention being focused on improving human health these days. The World Health Organization (WHO) statistics show that disease and mortality rate greatly depend on access to proper healthcare, which is not available to a vast majority of the global population. This technical paper presents our vision of automating some of the healthcare functions such as monitoring and diagnosis for mass deployment. We explain our ideas on how machines can help in this essential life supporting activity. Diagnosis part of the problem has been researched for long, so we set out working on this first, while the remaining is still in idea stage. We give insights into our work on automating medical diagnosis using text mining techniques and include some initial results.","","Electronic:978-1-4799-7193-0; POD:978-1-4799-7194-7","10.1109/GHTC.2014.6970257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970257","Information Retrieval;Machine Learning;Medical Diagnosis;Text Mining","Discharges (electric);Diseases;Medical diagnosis;Monitoring;Text mining;Vectors","data mining;health care;medical administrative data processing;text analysis","WHO;World Health Organization;health care automation;human health;mass deployment;text mining approach","","2","","31","","","10-13 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Heuristic for the Automatic Parametrization of the Spectral Clustering Algorithm","P. Bruneau; O. Parisot; B. Otjacques","Centre de Rech. Public - Gabriel Lippmann, Belvaux, Luxembourg","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","1313","1318","Finding the optimal number of groups in the context of a clustering algorithm is identified as a difficult problem. In this article, we automate this choice for the spectral clustering algorithm with a novel heuristic. Our method is deterministic, and remarkable by its low computational burden. We show its effectiveness with respect to the state of the art, and further investigate assumptions underlying previous work through an empirical study, with the support of synthetic and real data sets.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976945","Classification and clustering;Machine learning and data mining;Semi-supervised learning and spectral methods","Clustering algorithms;Eigenvalues and eigenfunctions;Equations;Indexes;Iris;Laplace equations;Principal component analysis","data mining;learning (artificial intelligence);pattern clustering","automatic parametrization;data mining;machine learning;real data sets;semi-supervised learning;spectral clustering algorithm;synthetic data sets","","0","","24","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Towards a generic framework for short term firm-specific stock forecasting","M. Ahmed; A. Sriram; S. Singh","Department of Information and Communication Technology, Manipal Institute of Technology, 576104, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","2681","2688","This paper investigates the predictive power of technical analysis, sentiment analysis and stock market analysis coupled with a robust learning engine in predicting stock trends in the short term for specific companies. Using large and varied datasets stretching over a duration of ten years, we set out to train, test and validate our system in order to either contradict or confirm efficient market hypothesis. Our results reveal a significant improvement over the efficient market hypothesis for majority companies and thus strongly challenge it. Technical parameters and algorithms operating upon them are shown to have a significant impact upon the end-predictive power of the system, thus bolstering claims of their efficacy. Moreover, sentiment analysis results also show a strong correlation with future market trends. Lastly, the superiority of supervised non-shallow learning architectures is illustrated via a comparison of results obtained through a myriad of optimization and clustering algorithms.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968411","Machine Learning;Sentiment Analysis;Stock Forecasting;Technical Analysis","Companies;Forecasting;Market research;Neural networks;Sentiment analysis;Stock markets","forecasting theory;learning (artificial intelligence);optimisation;pattern clustering;stock markets","clustering algorithms;end-predictive power;market hypothesis;optimization;robust learning engine;sentiment analysis;stock market analysis;stock trends prediction;supervised nonshallow learning architectures;technical analysis;technical parameters","","0","","25","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Weighted ensemble based automatic detection of exudates in fundus photographs","P. Prentasic; S. Loncaric","Faculty of Electrical Engineering and Computing, University of Zagreb, Unska 3, 10000 Zagreb, Croatia","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","138","141","Diabetic retinopathy (DR) is a visual complication of diabetes, which has become one of the leading causes of preventable blindness in the world. Exudate detection is an important problem in automatic screening systems for detection of diabetic retinopathy using color fundus photographs. In this paper, we present a method for detection of exudates in color fundus photographs, which combines several preprocessing and candidate extraction algorithms to increase the exudate detection accuracy. The first stage of the method consists of an ensemble of several exudate candidate extraction algorithms. In the learning phase, simulated annealing is used to determine weights for combining the results of the ensemble candidate extraction algorithms. The second stage of the method uses a machine learning-based classification for detection of exudate regions. The experimental validation was performed using the DRiDB color fundus image set. The validation has demonstrated that the proposed method achieved higher accuracy in comparison to state-of-the art methods.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6943548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6943548","diabetic retinopathy;exudate detection;image processing and analysis;machine learning","Accuracy;Diabetes;Feature extraction;Image color analysis;Retina;Retinopathy;Standards","biomedical optical imaging;diseases;feature extraction;image colour analysis;learning (artificial intelligence);medical image processing;photography;simulated annealing;vision defects","DRiDB color fundus image set;automatic screening systems;color fundus photographs;diabetes visual complication;diabetic retinopathy detection;experimental validation;exudate candidate extraction algorithm ensemble;exudate detection accuracy;exudate region detection;learning phase;machine learning-based classification;preprocessing;preventable blindness;simulated annealing;weighted ensemble based automatic detection","","0","","13","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Evolutionary Design of Decision-Tree Algorithms Tailored to Microarray Gene Expression Data Sets","R. C. Barros; M. P. Basgalupp; A. A. Freitas; A. C. P. L. F. de Carvalho","Faculdade de Inform&#65533;&#65533;tica, Pontif&#65533;&#65533;cia Universidade Cat&#65533;&#65533;lica do Rio Grande do Sul, Porto Alegre, Brazil","IEEE Transactions on Evolutionary Computation","20141125","2014","18","6","873","892","Decision-tree induction algorithms are widely used in machine learning applications in which the goal is to extract knowledge from data and present it in a graphically intuitive way. The most successful strategy for inducing decision trees is the greedy top-down recursive approach, which has been continuously improved by researchers over the past 40 years. In this paper, we propose a paradigm shift in the research of decision trees: instead of proposing a new manually designed method for inducing decision trees, we propose automatically designing decision-tree induction algorithms tailored to a specific type of classification data set (or application domain). Following recent breakthroughs in the automatic design of machine learning algorithms, we propose a hyper-heuristic evolutionary algorithm called hyper-heuristic evolutionary algorithm for designing decision-tree algorithms (HEAD-DT) that evolves design components of top-down decision-tree induction algorithms. By the end of the evolution, we expect HEAD-DT to generate a new and possibly better decision-tree algorithm for a given application domain. We perform extensive experiments in 35 real-world microarray gene expression data sets to assess the performance of HEAD-DT, and compare it with very well known decision-tree algorithms such as C4.5, CART, and REPTree. Results show that HEAD-DT is capable of generating algorithms that significantly outperform the baseline manually designed decision-tree algorithms regarding predictive accuracy and F-measure.","1089-778X;1089778X","","10.1109/TEVC.2013.2291813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6670778","Automatic algorithm design;automatic algorithm design;classification;decision trees;evolutionary algorithms;hyper-heuristics;hyperheuristics;machine learning","Accuracy;Algorithm design and analysis;Decision trees;Evolutionary computation;Machine learning algorithms;Prediction algorithms;Training","biology computing;decision trees;evolutionary computation;genetics;learning (artificial intelligence);pattern classification","F-measure;HEAD-DT algorithm;application domain;classification data set;decision-tree algorithms;decision-tree induction algorithms;evolutionary design;greedy top-down recursive approach;hyperheuristic evolutionary algorithm;machine learning applications;microarray gene expression data set","","7","","55","","20131120","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Low-cost radar-based target identification prototype using an expert system","D. P√©rez; M. Villaverde; F. Moreno; N. Nogar; F. Ezcurra; E. Aznar","Centro de Electr&#243;nica Industrial (CEI), ETSII Universidad Polit&#233;cnica de Madrid (UPM) Madrid, Spain","2014 12th IEEE International Conference on Industrial Informatics (INDIN)","20141106","2014","","","54","59","Smart and green cities are hot topics in current research because people are becoming more conscious about their impact on the environment and the sustainability of their cities as the population increases. Many researchers are searching for mechanisms that can reduce power consumption and pollution in the city environment. This paper addresses the issue of public lighting and how it can be improved in order to achieve a more energy efficient city. This work is focused on making the process of turning the streetlights on and off more intelligent so that they consume less power and cause less light pollution. The proposed solution is comprised of a radar device and an expert system implemented on a low-cost platform based on a DSP. By analyzing the radar echo in both the frequency and time domains, the system is able to detect and identify objects moving in front of it. This information is used to decide whether or not the streetlight should be turned on. Experimental results show that the proposed system can provide hit rates over 80% promising a good performance. In addition, the proposed solution could be useful in kind of other applications such as intelligent security and surveillance systems and home automation.","1935-4576;19354576","Electronic:978-1-4799-4905-2; POD:978-1-4799-4904-5; USB:978-1-4799-4906-9","10.1109/INDIN.2014.6945483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945483","artificial intelligence;classification tree;expert system;green cities;machine learning;radar target identification;smart cities;street lighting","Cities and towns;Classification algorithms;Classification tree analysis;Correlation;Lighting;Object recognition;Radar","digital signal processing chips;expert systems;green computing;object detection;power aware computing;radar computing;radar cross-sections;radar detection;street lighting;time-frequency analysis","DSP;energy efficient city;expert system;green cities;moving object identification;pollution reduction;power consumption reduction;public lighting;radar device;radar echo analysis;smart cities;street lighting;time-frequency analysis","","1","","18","","","27-30 July 2014","","IEEE","IEEE Conference Publications"
"Next generation data classification and linkage: Role of probabilistic models and artificial intelligence","G. P. Hettiarachchi; N. N. Hettiarachchi; D. S. Hettiarachchi; A. Ebisuya","Department of Physics, Osaka University, Japan","IEEE Global Humanitarian Technology Conference (GHTC 2014)","20141204","2014","","","569","576","Data classification and linkage is the task of identifying information corresponding to the same entity from one or more data sources. Methods used to tackle data classification and linkage problems fall into two broad categories. One commonly used method is deterministic models, in which sets of often very complex rules are used to classify pairs of entities as links. The other is the probabilistic model, in which statistical or probabilistic approaches are used to classify pairs. However, these models fail to deliver when there are lots of missing values, typographical errors, non-standardized entities, etc. To this end, intelligent routines making use of artificial neural networks, genetic algorithms and clustering algorithms can provide the next generation models for data classification and linkage. An introduction to data linkage, impact on humanity and community, current models, associated pitfalls, new directions and issues both technical and social for next generation data classification and linkage systems are discussed using an example prototype. A new model for linkage is proposed, where it is highlighted that not only the relationships between attributes of different entities, but also identification of relationships within the attributes of an entity is important in handling missing values and can provide better accuracy.","","Electronic:978-1-4799-7193-0; POD:978-1-4799-7194-7","10.1109/GHTC.2014.6970340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970340","Big data;classification;data linkage;machine learning;phonetic matching;probabilistic models;string comparison","Accuracy;Artificial neural networks;Couplings;Data models;Joining processes;Next generation networking;Probabilistic logic","genetic algorithms;learning (artificial intelligence);neural nets;pattern classification;probability","artificial intelligence;artificial neural networks;clustering algorithms;complex rules;data sources;deterministic models;entity attributes;genetic algorithms;information identification;missing value handling;next generation data classification;next generation data linkage;probabilistic approach;probabilistic model;relationship identification;social issues;statistical approach;technical issues","","0","","12","","","10-13 Oct. 2014","","IEEE","IEEE Conference Publications"
"Enhanced learning classifier to locate data in cloud datacenters","B. Biswal; S. Shetty; T. Rogers","College of Engineering, Tennessee State University, Nashville, USA","2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)","20141201","2014","","","375","380","Cloud subscribers would like to verify the location of outsourced data in the cloud datacenters to ensure that the availability of data satisfies the Service Level Agreement. Cloud users may not have access to their outsourced data in the event of operational failures in datacenters or occurrence of natural disasters and/or power outages. Recently, IP geolocation techniques have been proposed to locate data files in cloud datacenters. However these techniques exploit relationships between Internet delays and distance and are not extensible to incorporate different network measurements, which may be used along with Internet delay to improve accuracy. Also, most of the existing techniques have only been validated with one cloud provider (Amazon Web Services). In this paper, we propose an enhanced learning classifier IP geolocation algorithm, which incorporates multiple network measurements to improve the accuracy of geolocating data files in datacenters in four commercial cloud providers. To demonstrate the accuracy of our approach, we evaluate the performance on Amazon Web Services, Microsoft Azure, Google App Engine and Rackspace. Our experimental results demonstrate that our approach is geolocating data files accurately, more closely to the true location and also detecting violation of location restrictions.","","Electronic:978-1-4799-2730-2; POD:978-1-4799-2732-6; USB:978-1-4799-2727-2","10.1109/CloudNet.2014.6969024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969024","Cloud Auditing;IP Geolocation;Machine Learning","Accuracy;Cities and towns;Cloud computing;Delays;Extraterrestrial measurements;Geology;IP networks","Web services;cloud computing;computer centres;contracts;learning (artificial intelligence);outsourcing","Amazon Web services;Google App Engine;IP geolocation algorithm;Microsoft Azure;Rackspace;cloud datacenters;learning classifier;outsourced data location;service level agreement","","0","","20","","","8-10 Oct. 2014","","IEEE","IEEE Conference Publications"
"Prediction of energy consumption indices in the automotive industry","A. Almeida; A. Azevedo; A. Caldas","Faculty of Engineering, University of Porto, Porto, Portugal","2013 IEEE International Conference on Industrial Engineering and Engineering Management","20141124","2013","","","285","289","Since the automotive industry is one of the most competitive markets, key players should be capable of evolving their management strategy from a reactive to proactive approach. This way, it is critical for this type of companies to explore a new performance management approach where an effective interaction between the strategic and operational layers should be achieved. In line with this vision, a framework is presented that helps stakeholders make decisions based on the ability to anticipate future performance behaviours. Using leading indicators as reference, the key idea is to structure and model the existing knowledge within a mathematical tool, in order to project the manufacturing system's behaviour into the future. In order to show the reliability and importance of this framework, this paper presents a research performed at an automotive plant. The aim is to model the factors affecting energy consumption and thus estimate the future behaviour in terms of sustainability issues.","2157-3611;21573611","Electronic:978-1-4799-0986-5; POD:978-1-4799-0984-1; USB:978-1-4799-0985-8","10.1109/IEEM.2013.6962419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6962419","Automotive Industry;Estimation;Machine Learning;Performance Management;Sustainability;Systems Dynamics","Companies;Energy consumption;Estimation;Manufacturing systems;Paints;Vehicle dynamics","automobile industry;energy consumption;sustainable development","automotive industry;competitive markets;energy consumption index;performance management approach;stakeholder decisions;sustainability issues","","0","","5","","","10-13 Dec. 2013","","IEEE","IEEE Conference Publications"
"Financial risk modelling in vehicle credit portfolio","U. Bhuvaneswari; P. James Daniel Paul; S. Sahu","VIT University, Chennai, Tamil Nadu, India","2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)","20141113","2014","","","1","7","Luxury cars are a segment of vehicles which are usually bought by people with a higher purchasing power. Still, majority of people make this luxury investment through vehicle finance services. The people from this segment tend to have a good credit record and thus are granted credit by vehicle finance service providers. Despite the good credit record and high purchasing power, a certain amount of risk is associated with these credit portfolios. This study deals with the analysis of a data set comprising of opulent vehicle credit portfolios characterized by relevant variables. It aims at assessing the risk associated with these portfolios and finally presents a predictive model which highlights the important variables and depicts the combination of those variables that classify a client under defaulter or non-defaulter. The study starts with the use of conventional statistical techniques and subsequently presents machine learning approach using three different decision tree classifiers.","","Electronic:978-1-4799-4674-7; POD:978-1-4799-4673-0","10.1109/ICDMIC.2014.6954239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954239","Credit Risk;Decision Tree Classifiers;Machine Learning;Vehicle Finance","Classification algorithms;Companies;Decision trees;Electromagnetic interference;Logistics;Neural networks;Support vector machines","data analysis;decision trees;financial data processing;investment;learning (artificial intelligence);pattern classification;purchasing;risk analysis;statistical analysis","data set analysis;decision tree classifiers;financial risk modelling;luxury cars;luxury investment;machine learning approach;opulent vehicle credit portfolios;predictive model;purchasing;relevant variables;statistical techniques;vehicle credit portfolio;vehicle finance services","","0","","21","","","5-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"Gaussian process for learning solar panel maximum power point characteristics as functions of environmental conditions","N. N. B. Ulapane; S. G. Abeyratne","Centre for Autonomous Syst., Univ. of Technol. Sydney, Sydney, NSW, Australia","2014 9th IEEE Conference on Industrial Electronics and Applications","20141023","2014","","","1756","1761","This paper proposes a method to learn the variation of solar panel Maximum Power Point (MPP) parameters as functions of environmental conditions using Gaussian Process (GP) based machine learning. As a result of using GP, functions are learned along with the additional information of their uncertainty margins. The paper discusses about learning three functions specifically, where each of them take the two environmental variables 'solar irradiance' and 'cell temperature' as arguments and map these environmental variables to the corresponding MPP parameters, namely, the maximum power, the MPP voltage and the MPP current. Learned functions presented in the paper have been trained for a commercially available solar panel using MPP data generated using a previously published solar panel simulator. The learned function for maximum power has been validated by comparing the function outputs (GP results) against the manufacturer specified power values. A discussion about how learning such functions can help in advancing MPP Tracking (MPPT) is also provoked while highlighting the impact machine learning can make to the field of photovoltaics.","2156-2318;21562318","CD-ROM:978-1-4799-4316-6; Electronic:978-1-4799-4315-9; POD:978-1-4799-4314-2","10.1109/ICIEA.2014.6931452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6931452","Gaussian Process;MPPT;Machine Learning;Solar panel simulation","Accuracy;Artificial intelligence;Photovoltaic systems;Training;Training data;Uncertainty","Gaussian processes;environmental factors;learning (artificial intelligence);maximum power point trackers;photovoltaic power systems;power system simulation;solar power stations;sunlight","GP;Gaussian process;MPPT current parameter;MPPT voltage parameter;cell temperature;environmental condition;learning solar panel maximum power point tracking characteristics;machine learning;solar irradiance;solar panel simulator","","1","","9","","","9-11 June 2014","","IEEE","IEEE Conference Publications"
"A Novel Robust Modified Support Vector Machines","S. Liu; J. Guo; S. Zhong; Y. Li","Comput. Center Dept., East China Normal Univ., Shanghai, China","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3834","3838","In this paper, a novel general robust SVM approach for classification is proposed which can better characterize the distribution of the data compared with the traditional SVM. The classical Support Vector Machines is heavily relied on the Support Vector which has neglected the holistic distribution of the data that sometimes will lead to gross errors. We first take use of the majority of the data distribution. Then we apply the distance between the two classes and modify the original SVM objective function. In the last step we search the best weights to make a balance between the distance and the maximum margin. We developed an improved method for optimizing over the SVM algorithm. Experiments on 10 famous data sets clearly demonstrate improved performance and this method is also readily applicable for data sets with different distribution.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.658","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977370","Machine Learning;SVM;classification","Classification algorithms;Kernel;Optimization;Risk management;Robustness;Support vector machines;Training","data handling;learning (artificial intelligence);pattern classification;support vector machines","SVM algorithm;SVM objective function;classification;data distribution characterization;machine learning;performance improvement;robust modified support vector machines","","0","","13","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"VarifocalReader ‚Äî In-Depth Visual Analysis of Large Text Documents","S. Koch; M. John; M. W√∂rner; A. M√ºller; T. Ertl","Institute of Visualization and Interactive Systems (VIS)","IEEE Transactions on Visualization and Computer Graphics","20141106","2014","20","12","1723","1732","Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.","1077-2626;10772626","","10.1109/TVCG.2014.2346677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875959","distant reading;document analysis;literary analysis;machine learning;natural language processing;text mining;visual analytics","Data mining;Data visualization;Document handling;Interactive systems;Natural language processing;Navigation;Tag clouds;Text mining","data visualisation;learning (artificial intelligence);text analysis","document analysis;focus-context techniques;in-depth visual analysis;intermediate text levels;literary analysis;machine learning techniques;natural language processing;text documents;text mining;varifocalreader;visual abstraction","","9","","48","","","Dec. 31 2014","","IEEE","IEEE Journals & Magazines"
"Automated prediction of the apnea-hypopnea index using a wireless patch sensor","N. Selvaraj; R. Narasimhan","Vital Connect Inc., Campbell, CA 95008, USA","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","1897","1900","Polysomnography (PSG) is the gold standard that manually quantifies the apnea-hypopnea index (AHI) to assess the severity of sleep apnea syndrome (SAS). This study presents an algorithm that automatically estimates the AHI value using a disposable HealthPatch<sup>TM</sup> sensor. Volunteers (n=53, AHI: 0.1-85.8) participated in an overnight PSG study with patch sensors attached to their chest at three specified locations and data were wirelessly acquired. Features were computed for 150-second epochs of patch sensor data using analyses of heart rate variability, respiratory signals, posture and movements. Linear Support Vector Machine classifier was trained to detect the presence/absence of apnea/hypopnea events for each epoch. The number of epochs identified with events was subsequently mapped to AHI values using quadratic regression analysis. The classifier and regression models were optimized to minimize the mean-square error of AHI based on leave-one-out cross-validation. Comparison of predicted and reference AHI values resulted in linear correlation coefficients of 0.87, 0.88 and 0.92 for the three locations, respectively. The predicted AHI values were subsequently used to classify the control-to-mild apnea group (AHI<;15) and moderate-to-severe apnea (AHI‚â•15) with an accuracy (95% confidence intervals) of 89.4% (77.4-95.4%), 85.0% (70.9-92.9%), and 82.9% (67.3-91.9%) for the three locations, respectively. Overnight physiological monitoring using a wireless patch sensor provides an accurate estimate of AHI.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6943981","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6943981","Actigraphy;Apnea-Hypopnea Index;Heart rate variability;Machine Learning;Respiration","Biomedical monitoring;Indexes;Monitoring;Prediction algorithms;Sleep apnea;Standards;Synthetic aperture sonar","correlation methods;data analysis;electrocardiography;mean square error methods;medical disorders;medical signal processing;patient monitoring;regression analysis;sleep;support vector machines;wireless sensor networks","SAS;apnea-hypopnea index;apnea/hypopnea events;automated prediction;control-to-mild apnea group;data analysis;disposable HealthPatchTM sensor;epoch number;gold standard;heart rate variability;leave-one-out cross-validation;linear correlation coefficients;linear support vector machine classifier;mean-square error;moderate-to-severe apnea;movements;overnight PSG study;overnight physiological monitoring;polysomnography;posture;predicted AHI values;quadratic regression analysis;reference AHI values;regression models;respiratory signals;sleep apnea syndrome severity;time 150 s;wireless patch sensor","","1","","7","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Computer Assisted Analysis System of Electroencephalogram for Diagnosing Epilepsy","M. A. Ahmad; N. A. Khan; W. Majeed","Signal Image & Video Process. Lab., LUMS, Lahore, Pakistan","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3386","3391","Automation of Electroencephalogram (EEG) analysis can significantly help the neurologist during the diagnosis of epilepsy. During last few years lot of work has been done in the field of computer assisted analysis to detect an epileptic activity in an EEG. Still there is a significant amount of need to make these computer assisted EEG analysis systems more convenient and informative for a neurologist. After briefly discussing some of the existing work we have suggested an approach which can make these systems more helpful, detailed and precise for the neurologist. In our proposed approach we have handled each epoch of each channel for each type of epileptic pattern exclusive to each other. In our approach feature extraction starts with an application of multilevel Discrete Wavelet Transform (DWT) on each 1 sec non-overlapping epochs. Then we apply Principal Component Analysis (PCA) to reduce the effect of redundant and noisy data. Afterwards we apply Support Vector Machine (SVM) to classify these epochs as Epileptic or not. In our system a user can mark any mistakes he encounters. The concept behind the inclusion of the retraining is that, if there is more than one example with same attributes but different labels, the classifier is going to get trained to the one with most population. These corrective marking will be saved as examples. On retraining the classifier will improve its classification, hence it will tries to adapt the user. In the end we have discussed the results we have acquired till now. Due to limitation in the available data we are only able to report the classification performance for generalised absence seizure. The reported accuracy is resulted on very versatile dataset of 21 patients from Punjab Institute of Mental Health (PIMH) and 21 patients from Children Hospital Boston (CHB) which have different number of channel and sampling frequency. This usage of the data proves the robustness of our algorithm.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977295","Biomedical Signal Processing;Electroencephalography (EEG);Epilepsy;Machine Learning","Accuracy;Discrete wavelet transforms;Electroencephalography;Epilepsy;Feature extraction;Principal component analysis;Support vector machines","discrete wavelet transforms;diseases;electroencephalography;image classification;medical disorders;medical image processing;neurophysiology;principal component analysis","DWT;EEG;SVM;channel frequency;computer assisted analysis;electroencephalogram;epilepsy;multilevel discrete wavelet transform;principal component analysis;sampling frequency;support vector machine","","1","","32","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Time-Frequency Analysis as Probabilistic Inference","R. E. Turner; M. Sahani","Department of Engineering, University of Cambridge, Cambridge, UK","IEEE Transactions on Signal Processing","20141106","2014","62","23","6171","6183","This paper proposes a new view of time-frequency analysis framed in terms of probabilistic inference. Natural signals are assumed to be formed by the superposition of distinct time-frequency components, with the analytic goal being to infer these components by application of Bayes' rule. The framework serves to unify various existing models for natural time-series; it relates to both the Wiener and Kalman filters, and with suitable assumptions yields inferential interpretations of the short-time Fourier transform, spectrogram, filter bank, and wavelet representations. Value is gained by placing time-frequency analysis on the same probabilistic basis as is often employed in applications such as denoising, source separation, or recognition. Uncertainty in the time-frequency representation can be propagated correctly to application-specific stages, improving the handing of noise and missing data. Probabilistic learning allows modules to be co-adapted; thus, the time-frequency representation can be adapted to both the demands of the application and the time-varying statistics of the signal at hand. Similarly, the application module can be adapted to fine properties of the signal propagated by the initial time-frequency processing. We demonstrate these benefits by combining probabilistic time-frequency representations with non-negative matrix factorization, finding benefits in audio denoising and inpainting tasks, albeit with higher computational cost than incurred by the standard approach.","1053-587X;1053587X","","10.1109/TSP.2014.2362100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918491","Audio signal processing;inference;machine- learning;time-frequency analysis","Hidden Markov models;Noise;Noise reduction;Probabilistic logic;Spectrogram;Time-frequency analysis;Uncertainty","Bayes methods;Fourier transforms;Kalman filters;Wiener filters;channel bank filters;matrix decomposition;source separation;time-frequency analysis","Bayes rule;Kalman filters;Wiener filters;computational cost;filter bank;natural signals;natural time-series;nonnegative matrix factorization;probabilistic inference;probabilistic learning;short-time Fourier transform;source separation;time-frequency analysis;time-varying statistics;wavelet representations","","2","","54","","20141008","Dec.1, 2014","","IEEE","IEEE Journals & Magazines"
"Finding Waldo: Learning about Users from their Interactions","E. T. Brown; A. Ottley; H. Zhao; Q. Lin; R. Souvenir; A. Endert; R. Chang","Tufts U","IEEE Transactions on Visualization and Computer Graphics","20141106","2014","20","12","1663","1672","Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.","1077-2626;10772626","","10.1109/TVCG.2014.2346575","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875913","Analytic Provenance;Applied Machine Learning;User Interactions;Visualization","Accuracy;Computers;Data visualization;Encoding;Mice;Visual analytics","data analysis;data visualisation;graphical user interfaces;learning (artificial intelligence)","Finding Waldo;average task completion time;extraversion;human collaborator;machine learning algorithms;mine interactions;mixed initiative visual analytics systems;neuroticism;user interaction data analysis;user personality factors;user personality traits;visual search task","0","15","","47","","","Dec. 31 2014","","IEEE","IEEE Journals & Magazines"
"#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media","J. Zhao; N. Cao; Z. Wen; Y. Song; Y. R. Lin; C. Collins","University of Toronto","IEEE Transactions on Visualization and Computer Graphics","20141106","2014","20","12","1773","1782","We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.","1077-2626;10772626","","10.1109/TVCG.2014.2346922","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876013","Retweeting threads;anomaly detection;information visualization;machine learning;social media;visual analytics","Data visualization;Feature extraction;Instruction sets;Media;Message systems;Social network services;Twitter;Visual analytics","data analysis;data visualisation;decision making;learning (artificial intelligence);social networking (online)","#FluxFlow;Facebook;Hurricane Sandy;Twitter;advanced machine learning algorithms;anomalous information behaviors;anomalous information spreading;anomalous retweeting threads;back-end anomaly detection model;crowd messages;data analyst capability;decision-making;deeper analysis;dynamic crowd behaviors;front-end interactive visualizations;interactive visual analysis system;quantitative measurements;social media Websites;social signals","1","18","","48","","","Dec. 31 2014","","IEEE","IEEE Journals & Magazines"
"A latent variable-based Bayesian regression to address recording replications in Parkinson's Disease","C. J. P√©rez; L. Naranjo; J. Mart√≠n; Y. Campos-Roca","Department of Mathematics, University of Extremadura, C&#x00E1;ceres, Spain","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","1447","1451","Subject-based approaches are proposed to automatically discriminate healthy people from those with Parkinson's Disease (PD) by using speech recordings. These approaches have been applied to one of the most used PD datasets, which contains repeated measurements in an imbalanced design. Most of the published methodologies applied to perform classification from this dataset fail to account for the dependent nature of the data. This fact artificially increases the sample size and leads to a diffuse criterion to define which subject is suffering from PD. The first proposed approach is based on data aggregation. This reduces the sample size, but defines a clear criterion to discriminate subjects. The second one handles repeated measurements by introducing latent variables in a Bayesian logistic regression framework. The proposed approaches are conceptually simple and easy to implement.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952509","Bayesian logistic regression;Data aggregation;Latent variable;Machine learning;Parkinson's disease;Voice features","Accuracy;Bayes methods;Logistics;Parkinson's disease;Speech;Testing;Training","Bayes methods;diseases;regression analysis;speech","Bayesian logistic regression framework;Parkinson disease;data aggregation;latent variable;speech recordings;subject-based approaches","","0","","16","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"PeerShark: Detecting Peer-to-Peer Botnets by Tracking Conversations","P. Narang; S. Ray; C. Hota; V. Venkatakrishnan","Dept. of Comput. Sci. & Inf. Syst., Birla Inst. of Technol. & Sci.-Pilani, Hyderabad, India","2014 IEEE Security and Privacy Workshops","20141120","2014","","","108","115","The decentralized nature of Peer-to-Peer (P2P) botnets makes them difficult to detect. Their distributed nature also exhibits resilience against take-down attempts. Moreover, smarter bots are stealthy in their communication patterns, and elude the standard discovery techniques which look for anomalous network or communication behavior. In this paper, we propose PeerShark, a novel methodology to detect P2P botnet traffic and differentiate it from benign P2P traffic in a network. Instead of the traditional 5-tuple 'flow-based' detection approach, we use a 2-tuple 'conversation-based' approach which is port-oblivious, protocol-oblivious and does not require Deep Packet Inspection. PeerShark could also classify different P2P applications with an accuracy of more than 95%.","","Electronic:978-1-4799-5103-1; POD:978-1-4799-5104-8","10.1109/SPW.2014.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957293","botnet;machine learning;peer-to-peer","Electronic mail;Feature extraction;Firewalls (computing);IP networks;Internet;Peer-to-peer computing;Ports (Computers)","computer network security;invasive software;peer-to-peer computing;telecommunication traffic","2-tuple conversation-based approach;P2P applications;P2P botnet traffic;PeerShark;anomalous network;communication behavior;communication patterns;conversations tracking;flow-based detection;peer-to-peer botnets detection;port-oblivious;protocol-oblivious;standard discovery techniques","","5","","36","","","17-18 May 2014","","IEEE","IEEE Conference Publications"
"Classification ensemble to improve medical Named Entity Recognition","S. Keretna; C. P. Lim; D. Creighton; K. B. Shaban","Centre for Intelligent Systems Research, Deakin University, Australia","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","2630","2636","An accurate Named Entity Recognition (NER) is important for knowledge discovery in text mining. This paper proposes an ensemble machine learning approach to recognise Named Entities (NEs) from unstructured and informal medical text. Specifically, Conditional Random Field (CRF) and Maximum Entropy (ME) classifiers are applied individually to the test data set from the i2b2 2010 medication challenge. Each classifier is trained using a different set of features. The first set focuses on the contextual features of the data, while the second concentrates on the linguistic features of each word. The results of the two classifiers are then combined. The proposed approach achieves an f-score of 81.8%, showing a considerable improvement over the results from CRF and ME classifiers individually which achieve f-scores of 76% and 66.3% for the same data set, respectively.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974324","Machine learning;biomedical named entity recognition;conditional random field;information extraction;maximum entropy;medical text mining","Context modeling;Entropy;Feature extraction;Information retrieval;Testing;Text recognition;Training","data mining;learning (artificial intelligence);maximum entropy methods;medical information systems;pattern classification;random processes;text analysis","CRF;ME classifiers;NER;classification ensemble;conditional random field;contextual features;ensemble machine learning approach;informal medical text;knowledge discovery;linguistic features;maximum entropy classifiers;medical named entity recognition;text mining;unstructured medical text","","1","","37","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Smart glove with gesture recognition ability for the hearing and speech impaired","T. Chouhan; A. Panse; A. K. Voona; S. M. Sameer","Department of Electronics and Communication Engineering, National Institute of Technology Calicut, Kerala, India","2014 IEEE Global Humanitarian Technology Conference - South Asia Satellite (GHTC-SAS)","20141201","2014","","","105","110","With the advent of wearable technology, it is now possible to implement numerous and extremely creative ideas to serve humanity in unprecedented ways. Thus inspired, we have developed a smart system which would be able to serve as best friend to the hearing and speech impaired person. The primary goal of this paper is to design and implement a low cost wired interactive glove, interfaced with a computer running MATLAB or Octave, with a high degree of accuracy for gesture recognition. The glove maps the orientation of the hand and fingers with the help of bend sensors, Hall Effect sensors and an accelerometer. The data is then transmitted to a computer using automatic repeat request (ARQ) as an error controlling scheme. The system is modeled for the differently abled section of the society to help convert sign language to a more human understandable form such as textual messages.","","CD-ROM:978-1-4799-4098-1; Electronic:978-1-4799-4097-4; POD:978-1-4799-4096-7","10.1109/GHTC-SAS.2014.6967567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967567","Gesture recognition;data extraction method;data glove;machine learning","Gesture recognition;Hall effect;Magnetic sensors;Speech;Thumb","Hall effect transducers;accelerometers;automatic repeat request;data gloves;gesture recognition;handicapped aids;interactive devices;wearable computers","ARQ;Hall Effect sensors;MATLAB;Octave;accelerometer;automatic repeat request;bend sensors;error controlling scheme;gesture recognition ability;hearing impaired;low cost wired interactive glove;sign language conversion;smart glove;speech impaired;wearable technology","","5","","9","","","26-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Disease-medicine topic model for prescription record mining","S. Park; D. Choi; W. Lee; D. Jung; M. Kim; I. C. Moon","","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","86","93","Analyzing patient records is important for improving the quality of medical services and for understanding each patient's historical diseases. However, the huge size of the data requires statistical analysis procedures. In this paper, we proposed a probabilistic model-the disease-medicine topic model (DMTM)-to explore connected knowledge about diseases and medicines. In the model, diseases and medicines are modeled using generative process. We used the latent Dirichlet allocation, which is one of the most popular topic models, as the baseline model. Then, we compared the qualities of topic representations quantitatively and qualitatively. The comparison results showed that the topics derived from the DMTM are clearer to identify and that specific patterns were found in the diseases and medicines. In the case of topic network analysis, these specific patterns were proved using centrality measurements.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973889","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973889","information retrivial;machine learning;medical mining;text mining;topic modeling","Adaptation models;Analytical models;Biological system modeling;Coherence;Data mining;Diseases;Medical diagnostic imaging","data mining;diseases;information retrieval;learning (artificial intelligence);medical computing;medicine;probability;statistical analysis","DMTM;Dirichlet allocation;disease-medicine topic model;medical services;network analysis;patient record analysis;prescription record mining;probabilistic model;statistical analysis procedures","","1","","19","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator","D. Neil; S. C. Liu","Institute of Neuroinformatics, University of Z&#65533;&#65533;rich, ETH Z&#65533;&#65533;rich, Z&#x00FC;rich, Switzerland","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20141120","2014","22","12","2621","2628","Current neural networks are accumulating accolades for their performance on a variety of real-world computational tasks including recognition, classification, regression, and prediction, yet there are few scalable architectures that have emerged to address the challenges posed by their computation. This paper introduces Minitaur, an event-driven neural network accelerator, which is designed for low power and high performance. As an field-programmable gate array-based system, it can be integrated into existing robotics or it can offload computationally expensive neural network tasks from the CPU. The version presented here implements a spiking deep network which achieves 19 million postsynaptic currents per second on 1.5 W of power and supports up to 65 K neurons per board. The system records 92% accuracy on the MNIST handwritten digit classification and 71% accuracy on the 20 newsgroups classification data set. Due to its event-driven nature, it allows for trading off between accuracy and latency.","1063-8210;10638210","","10.1109/TVLSI.2013.2294916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701396","Deep belief networks;field programmable arrays;machine learning;neural networks;restricted Boltzmann machines;spiking neural networks","Biological neural networks;Clocks;Computer architecture;Field programmable gate arrays;Mathematical model;Neurons;Performance evaluation","field programmable gate arrays;neural nets","CPU;MNIST handwritten digit classification;Minitaur;event-driven FPGA;event-driven neural network accelerator;field-programmable gate array-based system;neural networks;newsgroups classification data;robotics;spiking deep network;spiking network accelerator","","25","","28","","20140109","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Kernel principal component analysis for UWB-based ranging","V. Savic; E. G. Larsson; J. Ferrer-Coll; P. Stenumgaard","Dept. of Electrical Engineering (ISY), Link&#x00F6;ping University, Sweden","2014 IEEE 15th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","20141103","2014","","","145","149","Accurate positioning in harsh environments can enable many application, such as search-and-rescue in emergency situations. For this problem, ultra-wideband (UWB) technology can provide the most accurate range estimates, which are required for range-based positioning. However, it still faces a problem in non-line-of-sight (NLOS) environments, in which range estimates based on time-of-arrival (TOA) are positively biased. There are many techniques that try to address this problem, mainly based on NLOS identification and NLOS error mitigation. However, these techniques do not exploit all available information from the UWB channel impulse response. In this paper, we propose a novel ranging technique based on kernel principal component analysis (kPCA), in which the selected channel parameters are projected onto nonlinear orthogonal high-dimensional space, and a subset of these projections is then used for ranging. We tested this technique using UWB measurements obtained in a basement tunnel of LinkoÃàping university, and found that it provides much better ranging performance comparing with standard techniques based on PCA and TOA.","1948-3244;19483244","Electronic:978-1-4799-4903-8; POD:978-1-4799-4902-1; USB:978-1-4799-3912-1","10.1109/SPAWC.2014.6941337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6941337","kernel principal component analysis;machine learning;ranging;time-of-arrival;ultra-wideband","Delays;Distance measurement;Eigenvalues and eigenfunctions;Kernel;Nonlinear optics;Polynomials;Principal component analysis","principal component analysis;radionavigation;time-of-arrival estimation;transient response;ultra wideband communication","NLOS error mitigation;NLOS identification;TOA;UWB channel impulse response;UWB measurements;UWB-based ranging technique;channel parameters;emergency situations;harsh environments;kPCA;kernel principal component analysis;nonline-of-sight environments;nonlinear orthogonal high-dimensional space;range estimates;range-based positioning;search-and-rescue;time-of-arrival estimation;ultra-wideband technology","","1","","15","","","22-25 June 2014","","IEEE","IEEE Conference Publications"
"Enhancing the performance of Feed-Forward Neural Networks in the bus short-term load forecasting","I. P. Panapakidis; G. K. Papagiannis","School of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece","2014 49th International Universities Power Engineering Conference (UPEC)","20141023","2014","","","1","6","Bus load patterns present low correlation in respect to the aggregated system load, due to their volatility and high complexity. Thus, special care should be placed in the sophisticated selection and training of the appropriate forecasting model. This paper is concerned with the Short-Term Load Forecasting on a distribution transformer that feeds a suburban area in Northern Greece. The forecaster corresponds to a modified version of the Feed-Forward Neural Network (FFNN) that has been proposed for the Greek interconnected system. Two novel FFNNs are introduced that differ with the previous one in the types of the variables of the input layer. Experimental results denote that the proposed FFNNs lead to higher prediction accuracy.","","CD-ROM:978-1-4799-6556-4; Electronic:978-1-4799-6557-1; POD:978-1-4799-6558-8","10.1109/UPEC.2014.6934672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6934672","Bus load;load forecasting;machine learning;neural networks;power distribution","Artificial neural networks;Forecasting;Load forecasting;Load modeling;Neurons;Predictive models;Training","distribution networks;feedforward neural nets;load forecasting;power engineering computing","FFNN;Greek interconnected system;Northern Greece;bus load patterns;distribution transformer;feedforward neural network;short-term load forecasting;suburban area","","0","","20","","","2-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Unsupervised Learning of GDL Classifier","T. Hachaj; M. R. Ogiela","Inst. of Comput. Sci. & Comput. Methods, Pedagogical Univ. of Krakow, Krakow, Poland","2014 Eighth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing","20141206","2014","","","186","191","GDL (Gesture Description Language) is a pattern recognition method that enables syntactic description and real time recognition of static body poses and movement sequences. The syntax of context free GDL script (GDLs) language is intuitive and easy to learn for new user, however so far GDLs rules had to be implemented without feedback of machine learning methods. In this paper we present proposition and initial evaluation of unsupervised method of GDL classifier learning that enables automatic generation of GDLs descriptions using specified features and sample movements recordings. New automatically generated GDLs are well understandable the same as manually defined descriptions. This property enables easy interpretation of obtained training results in contrast to the results from others popular pattern recognition methods.","","CD-ROM:978-1-4799-4333-3; Electronic:978-1-4799-4331-9; POD:978-1-4799-7891-5","10.1109/IMIS.2014.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975461","Gesture Description Language;gestures recognition;machine learning;unsupervised learning","Gesture recognition;Hidden Markov models;Joints;Real-time systems;Training","context-free languages;learning (artificial intelligence);pattern classification","GDL classifier;gesture description language;pattern recognition method;real time recognition;syntactic description;unsupervised learning","","1","","17","","","2-4 July 2014","","IEEE","IEEE Conference Publications"
"Multi-layer multi-center atom set cohesion clustering algorithm","D. Zhou; L. Zhang; X. Deng","Dalian University of Technolog","Fifth International Conference on Computing, Communications and Networking Technologies (ICCCNT)","20141120","2014","","","1","6","Aiming at existing partition clustering algorithms restricted by a single clustering and separation degree depends on the initial cluster centers, For example, K-means algorithm, the K-center, etc. However the hierarchical clustering algorithm (AGNES) whose time complexity and space complexity is higher is not suitable for large-scale numerical data calculation, and the density clustering algorithms such as DBSCAN algorithm depends on the number of data points in the field of fixed radius and the threshold. It is also very sensitive to the parameters. An agglomerative clustering algorithm based on multi center atom sets is proposed, MMACA for short. This algorithm is based on the idea of multi center, in accordance with the initial number of atoms randomly forming atomic set, then removing the local noise atomic concentration, constituting the original atomic set. Finally, condensation according to changes in the radius of the original atomic nucleus set, in order to control the number of iterations of the aggregation process. The MMACA algorithm is applied to large data sets and through a lot of experiments to fully verify the reliability and validity of MMACA algorithm.","","CD-ROM:978-1-4799-2695-4; Electronic:978-1-4799-2696-1; POD:978-1-4799-2697-8","10.1109/ICCCNT.2014.6963042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6963042","Clustering algorithms;Clustering methods;Data mining;Machine Learning;Multi-layer Multi-center","Atomic layer deposition;Atomic measurements;Clustering algorithms;Heuristic algorithms;Noise;Partitioning algorithms;Time complexity","computational complexity;pattern clustering","AGNES;DBSCAN;MMACA;atomic nucleus set;density clustering algorithms;hierarchical clustering algorithm;initial cluster centers;k-center;k-means algorithm;large-scale numerical data calculation;local noise atomic concentration;multilayer multicenter atom set cohesion clustering algorithm;partition clustering algorithms;separation degree;space complexity;time complexity","","0","","19","","","11-13 July 2014","","IEEE","IEEE Conference Publications"
"Ultra wideband and bluetooth detection based on energy features","H. Soleimani; G. Caso; L. De Nardis; M. G. Di Benedetto","Department of Information Engineering, Electronics and Telecommunications (DIET) Sapienza University of Rome Rome, Italy","2014 IEEE International Conference on Ultra-WideBand (ICUWB)","20141120","2014","","","96","101","Detection, classification, and recognition based on the detection of energy features of Ultra Wide Band (UWB) vs. signals emitted in the Industrial Scientific and Medical (ISM) radio bands, such as Bluetooth, is a challenging issue. This work addressed this issue by analyzing the behavior of UWB versus Bluetooth signals in various noisy environments. The focus was on identifying robust feature extraction algorithms, that would enable encoding UWB and Bluetooth signals with features such as, for example, short time energy, Fast Fourier transform energy, and derivatives of short time energy. Results of experimental analysis showed that with respect to other signals, short-time energy of UWB over small overlapping time windows had acceptable discriminative performance. The different feature selection algorithms were tested with the following classifiers; Support Vector Machine with related kernel methods, Probabilistic Neural Networks, K Nearest Neighborhood, and Naive Bayes were tested in order to select the best option towards detection performance in different noisy conditions.","2162-6588;21626588","Electronic:978-1-4799-5396-7; POD:978-1-4799-5397-4; USB:978-1-4799-6520-5","10.1109/ICUWB.2014.6958958","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6958958","Bluetooth;Energy features;Features Selection;Machine Learning;Noise;Ultra Wide Band","Bluetooth;Classification algorithms;Feature extraction;Kernel;Signal to noise ratio;Support vector machines","Bluetooth;encoding;fast Fourier transforms;feature extraction;neural nets;support vector machines;ultra wideband technology","Bluetooth detection;Bluetooth signals;ISM radio bands;encoding;energy features detection;fast Fourier transform energy;feature extraction algorithms;industrial scientific and medical;probabilistic neural networks;support vector machine","","0","","10","","","1-3 Sept. 2014","","IEEE","IEEE Conference Publications"
"Feature Selection Methods on Biological Knowledge Discovery and Data Mining: A Survey","H. Mhamdi; F. Mhamdi","Lab. of Technol. of Inf. & Commun. & Electr. Eng. (LaTICE), Nat. Super. Sch. of Eng. of Tunis (ENSIT), Tunis, Tunisia","2014 25th International Workshop on Database and Expert Systems Applications","20141204","2014","","","46","50","Feature selection is an important component of data mining and knowledge discovery process, due to the availability of data with hundreds of variables leading to data with very high dimension. It aims at reducing the number of features by removing irrelevant or redundant ones, while trying to reduce computation time, preserve or improve prediction performance, and to a better understanding of the data in machine learning or pattern recognition and specific in bioinformatics applications where the number of features is significantly larger than the number of samples. In this paper we provide an overview of some feature selection methods present in literature. We focus on Filter, Wrapper and hybrid methods. We also apply some of the feature selection techniques on standard databank to demonstrate their applicability.","1529-4188;15294188","Electronic:978-1-4799-5722-4; POD:978-1-4799-7866-3","10.1109/DEXA.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974825","Bioinformatics;Feature selection;KDD;machine learning","Classification algorithms;Data mining;Feature extraction;Filtering algorithms;Prediction algorithms;Proteins","biology computing;data mining;feature selection;information filtering","biological knowledge discovery;feature selection methods;filter method;hybrid methods;public databases;wrapper method","","1","","21","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Speech based emotion recognition using spectral feature extraction and an ensemble of kNN classifiers","S. A. Rieger; R. Muraleedharan; R. P. Ramachandran","Electrical and Computer Engineering, Rowan University, Glassboro, NJ, 08028, USA","The 9th International Symposium on Chinese Spoken Language Processing","20141027","2014","","","589","593","Security (and cyber security) is an important issue in existing and developing technology. It is imperative that cyber security go beyond password based systems to avoid criminal activities. A human biometric and emotion based recognition framework implemented in parallel can enable applications to access personal or public information securely. The focus of this paper is on the study of speech based emotion recognition using a pattern recognition paradigm with spectral feature extraction and an ensemble of k nearest neighbor (kNN) classifiers. The five spectral features are the linear predictive cepstrum (CEP), mel frequency cepstrum (MFCC), line spectral frequencies (LSF), adaptive component weighted cepstrum (ACW) and the post-filter cepstrum (PFL). The bagging algorithm is used to train the ensemble of kNNs. Fusion is implicitly accomplished by ensemble classification. The LDC emotional prosody speech database is used in all the experiments. Results show that the maximum gain in performance is achieved by using two kNNs as opposed to using a single kNN.","","Electronic:978-1-4799-4219-0; POD:978-1-4799-4218-3; USB:978-1-4799-4220-6","10.1109/ISCSLP.2014.6936711","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936711","cyber security;emotion recognition;ensemble kNN classifier;fusion;machine learning","Cepstrum;Emotion recognition;Mel frequency cepstral coefficient;Speech;Speech recognition;Training;Vectors","emotion recognition;feature extraction;learning (artificial intelligence);security of data;signal classification;speech recognition","ACW feature;CEP feature;LDC emotional prosody speech database;LSF feature;MFCC feature;Mel frequency cepstrum;PFL feature;adaptive component weighted cepstrum;bagging algorithm;biometric based recognition framework;cyber security;emotion based recognition framework;k-nearest neighbor;kNN classifier ensemble;line spectral frequencies;linear predictive cepstrum;password based system;pattern recognition paradigm;personal information;post-filter cepstrum;public information;spectral feature extraction;speech based emotion recognition","","3","","31","","","12-14 Sept. 2014","","IEEE","IEEE Conference Publications"
"Verification and validation of Parallel Support Vector Machine algorithm based on MapReduce Program model on Hadoop cluster","M. Kiran; A. Kumar; B. R. Prathap","Department of Computer Science and Engineering Christ University Faculty of Engineering Bangalore, India","2013 International Conference on Advanced Computing and Communication Systems","20141030","2013","","","1","6","From the recent years the large volume of data is growing bigger and bigger. It is difficult to measure the total volume of structured and unstructured data that require machine-based systems and technologies in order to be fully analyzed. Efficient implementation techniques are the key to meeting the scalability and performance requirements entailed in such scientific data analysis. So for the same in this paper the Sequential Support Vector Machine in WEKA and various MapReduce Programs including Parallel Support Vector Machine on Hadoop cluster is analyzed and thus, in this way Algorithms are Verified and Validated on Hadoop Cluster using the Concept of MapReduce. In this paper, the performance of above applications has been shown with respect to execution time/training time and number of nodes. Experimental Results shows that as the number of nodes increases the execution time decreases. This experiment is basically a research study of above MapReduce applications.","","Electronic:978-1-4799-3506-2; POD:978-1-4799-3507-9","10.1109/ICACCS.2013.6938728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6938728","Hadoop;LIBSVM;Machine Learning;MapReduce;MultiFileWordCount;Parallel SVM;SVM;WEKA Tool","Communication systems;Computational modeling;File systems;Machine learning algorithms;Prediction algorithms;Support vector machines;Vectors","data analysis;parallel processing;support vector machines","Hadoop cluster;MapReduce program model;WEKA;execution time;machine-based systems;parallel support vector machine algorithm;scientific data analysis;sequential support vector machine;structured data;training time;unstructured data","","0","","13","","","19-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Applying game theory rules to enhance decision support systems in credit and financial applications","T. Alskheliwi; C. Jim; K. Lateef; S. Penn; A. Salem","Department of Computer Science & Information Technology Hood College Frederick, MD","2014 Computer Games: AI, Animation, Mobile, Multimedia, Educational and Serious Games (CGAMES)","20141023","2014","","","1","10","This paper examines the potential of applying Game Theory to Data Mining mechanisms to enhance the accuracy of predicting risk in financial settings. There have been many attempts made in the past to enhance Data Mining results using different methods including Game Theory principles. Despite the promising results of previous work in integrating Game Theory and Data Mining, further research is needed to explore the potential of creating a combined model that can be applied to a range of datasets to successfully enhance risk prediction. We use the German credit dataset using a variety of different data mining mechanisms then we propose a combined model to enhance the results using Game Theory principles and the decision tree ‚ÄúJ48‚Äù algorithm as a data mining mechanism.","","CD-ROM:978-1-4799-5853-5; Electronic:978-1-4799-5854-2; POD:978-1-4799-5855-9","10.1109/CGames.2014.6934138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6934138","Data mining;Game Theory;Machine Learning;WEKA;data classification;decision trees;genetic algorithm;genetic programming;neural networks;support vector machine","Accuracy;Data mining;Game theory;Games;Genetic programming;Neural networks;Support vector machines","data mining;decision support systems;decision trees;financial data processing;game theory;risk management","German credit dataset;J48 algorithm;credit application;data mining mechanism;decision support systems;decision tree algorithm;financial application;game theory;risk prediction","","0","","18","","","28-30 July 2014","","IEEE","IEEE Conference Publications"
"Reusing Genetic Programming for Ensemble Selection in Classification of Unbalanced Data","U. Bhowan; M. Johnston; M. Zhang; X. Yao","Knowledge and Data Engineering Group, School of Statistics and Computer Science, Trinity College, Dublin, Ireland","IEEE Transactions on Evolutionary Computation","20141125","2014","18","6","893","908","Classification algorithms can suffer from performance degradation when the class distribution is unbalanced. This paper develops a two-step approach to evolving ensembles using genetic programming (GP) for unbalanced data. The first step uses multiobjective (MO) GP to evolve a Pareto-approximated front of GP classifiers to form the ensemble by trading-off the minority and the majority class against each other during learning. The MO component alleviates the reliance on sampling to artificially rebalance the data. The second step, which is the focus this paper, proposes a novel ensemble selection approach using GP to automatically find/choose the best individuals for the ensemble. This new GP approach combines multiple Pareto-approximated front members into a single composite genetic program solution to represent the (optimized) ensemble. This ensemble representation has two main advantages/novelties over traditional genetic algorithm (GA) approaches. First, by limiting the depth of the composite solution trees, we use selection pressure during evolution to find small highly-cooperative groups of individuals for the ensemble. This means that ensemble sizes are not fixed a priori (as in GA), but vary depending on the strength of the base learners. Second, we compare different function set operators in the composite solution trees to explore new ways to aggregate the member outputs and thus, control how the ensemble computes its output. We show that the proposed GP approach evolves smaller more diverse ensembles compared to an established ensemble selection algorithm, while still performing as well as, or better than the established approach. The evolved GP ensembles also perform well compared to other bagging and boosting approaches, particularly on tasks with high levels of class imbalance.","1089-778X;1089778X","","10.1109/TEVC.2013.2293393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6677603","Classification;ensemble machine learning;genetic programming;unbalanced data","Accuracy;Bagging;Genetic algorithms;Silicon;Sociology;Statistics;Training","Pareto optimisation;approximation theory;genetic algorithms;learning (artificial intelligence);pattern classification;trees (mathematics)","GP classifiers;Pareto-approximated front;bagging approach;boosting approach;composite solution trees;ensemble selection approach;genetic programming;learning;single composite genetic program solution;unbalanced data classification","","9","","56","","20131128","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"A discriminative learning approach to probabilistic acoustic source localization","H. Kayser; J. Anem√ºller","Medizinische Physik and Cluster of Excellence Hearing4all Universit&#x00E4;t Oldenburg, D-26111 Oldenburg, Germany","2014 14th International Workshop on Acoustic Signal Enhancement (IWAENC)","20141120","2014","","","99","103","Sound source localization algorithms commonly include assessment of inter-sensor (generalized) correlation functions to obtain direction-of-arrival estimates. Here, we present a classification-based method for source localization that uses discriminative support vector machine-learning of correlation patterns that are indicative of source presence or absence. Subsequent probabilistic modeling generates a map of sound source presence probability in given directions. Being data-driven, the method during training adapts to characteristics of the sensor setup, such as convolution effects in non-free-field situations, and to target signal specific acoustic properties. Experimental evaluation was conducted with algorithm training in anechoic single-talker scenarios and test data from several reverberant multi-talker situations, together with diffuse and real-recorded background noise, respectively. Results demonstrate that the method successfully generalizes from training to test conditions. Improvement over the best of five investigated state-of-the-art angular spectrum-based reference methods was on average about 45% in terms of relative F-measure-related error reduction.","","Electronic:978-1-4799-6808-4; POD:978-1-4799-6809-1; USB:978-1-4799-6807-7","10.1109/IWAENC.2014.6953346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6953346","Direction-of-arrival estimation;discriminative classification;machine learning","Acoustics;Conferences;Direction-of-arrival estimation;Estimation;Signal to noise ratio;Speech","acoustic signal processing;correlation methods;direction-of-arrival estimation;learning (artificial intelligence);probability;reverberation;support vector machines","anechoic single-talker scenario;correlation patterns;direction-of-arrival estimates;discriminative classification;probabilistic acoustic source localization;reverberant multitalker situations;sound source localization;uses discriminative support vector machine learning","","2","","23","","","8-11 Sept. 2014","","IEEE","IEEE Conference Publications"
"Identification of spam comments using natural language processing techniques","C. RƒÉdulescu; M. Dinsoreanu; R. Potolea","Technical University of Cluj-Napoca, Romania","2014 IEEE 10th International Conference on Intelligent Computer Communication and Processing (ICCP)","20141030","2014","","","29","35","The high popularity of modern web is partly due to the increase in the number of content sharing applications. The social tools provided by the content sharing applications allow online users to interact, to express their opinions and to read opinions from other users. However, spammers provide comments which are written intentionally to mislead users by redirecting them to web sites to increase their rating and to promote products less known on the market. Reading spam comments is a bad experience and a waste of time for most of the online users but can also be harming and cause damage to the reader. Research has been performed in this domain in order to identify and eliminate spam comments. Our goal is to detect comments which are likely to represent spam considering some indicators: a discontinuous text flow, inadequate and vulgar language or not related to a specific context. Our approach relies on machine learning algorithms and topic detection.","","Electronic:978-1-4799-6569-4; POD:978-1-4799-6570-0","10.1109/ICCP.2014.6936976","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936976","Co-occurrence;Feature vector;Machine learning;Opinion;Post-comment similarity;Sentiment;Spam;Topic extraction","Context;Feature extraction;Natural language processing;Unsolicited electronic mail;White spaces;YouTube","learning (artificial intelligence);natural language processing;social networking (online);text analysis","Web sites;content sharing applications;discontinuous text flow;machine learning algorithms;natural language processing techniques;social tools;spam comment identification;spam comment reading;topic detection;vulgar language","","1","","10","","","4-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"Home energy management based on Bayesian network considering resident convenience","T. Shoji; W. Hirohashi; Y. Fujimoto; Y. Hayashi","WASEDA University, Tokyo, Japan","2014 International Conference on Probabilistic Methods Applied to Power Systems (PMAPS)","20141120","2014","","","1","6","Total electricity consumption in Japan increased rapidly and the power consumption per household is also continuing to increase. The framework of demand response (DR) to promote the reduction of electricity consumption in the household sector by regulating the price of the electricity will be introduced in the future. In this situation, residents must operate their appliances so as not to affect much to their lifestyles while taking into account the power cost. A home energy management system (HEMS) will have an essential role to control appliances such as air conditioners (ACs), battery energy storage systems (BESSs), electric vehicles (EVs), and heat pump water heaters (HPWHs) and automatically match their operations to the behavior of a resident when the electricity price changes. In this study, a Bayesian network, a fundamental tool of machine learning, is adapted to an HEMS to learn the behavior of the resident and appropriate operations of controllable appliances.","","Electronic:978-1-4799-3561-1; POD:978-1-4799-3562-8","10.1109/PMAPS.2014.6960597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6960597","Bayesian network (BN);demand response (DR);home energy management system (HEMS);machine learning;smart grid","Bayes methods;Electricity;Energy consumption;Energy management;Home appliances;Probabilistic logic;Resistance heating","belief networks;building management systems;domestic appliances;energy management systems;learning (artificial intelligence);power consumption;power engineering computing","Bayesian network;HEMS;demand response framework;electricity consumption reduction;electricity price regulation;home energy management system;household sector;machine learning;resident convenience","","1","","21","","","7-10 July 2014","","IEEE","IEEE Conference Publications"
"On improving sub-pixel accuracy by means of B-spline","S. R. Fernandes; V. V. Estrela; O. Saotome","Instituto Federal de Educacao, Ciencia e Tecnologia do Sudeste de Minas Gerais, Juiz de Fora, Brazil","2014 IEEE International Conference on Imaging Systems and Techniques (IST) Proceedings","20141120","2014","","","68","72","Local perturbations nearby contours strongly perturb the final result of processing remotely sensed images (RSI). It is common to establish a priori data to aid the estimation process. One can move some steps forward by means of a deformable model, for example, the snake model. In up to date research, the deformable contour is represented via B-spline snakes, which allows local control, concise depiction, and the use of fewer parameters. The estimation of edges with sub-pixel accuracy via a global B-spline depiction depends on determining the edge according to a Maximum Likelihood (ML) agenda and using the observed information likelihood. This practice guarantees that outliers present in data will be cleaned out. The data likelihood is calculated as a result of the observation model comprising both orientation and position data. Experiments where this procedure and the traditional spline interpolation have revealed that the algorithm introduced outperforms the conventional method for Gaussian as well as Salt and Pepper noise.","1558-2809;15582809","Electronic:978-1-4799-5220-5; POD:978-1-4799-5221-2","10.1109/IST.2014.6958448","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6958448","B-Splines;image processing;interpolation;machine learning;sub-pixel accuracy;surveillance","Accuracy;Computational modeling;Estimation;Image edge detection;Noise;Splines (mathematics);Vectors","edge detection;geophysical image processing;image denoising;interpolation;maximum likelihood estimation;remote sensing;splines (mathematics)","B-spline snakes;ML;RSI;concise depiction;data likelihood;deformable contour;edges estimation;global B-spline depiction;information likelihood;local perturbations;maximum likelihood agenda;remotely sensed images;salt-and-pepper noise;snake model;spline interpolation;subpixel accuracy","","0","","30","","","14-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Mining the Big Data: The Critical Feature Dimension Problem","Q. Liu; B. Ribeiro; A. H. Sung; D. Suryakumar","Dept. of Comput. Sci., Sam Houston State Univ., Huntsville, TX, USA","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","499","504","In mining massive datasets, often two of the most important and immediate problems are sampling and feature selection. Proper sampling and feature selection contributes to reducing the size of the dataset while obtaining satisfactory results in model building. Theoretically, therefore, it is interesting to investigate whether a given dataset possesses a critical feature dimension, or the minimum number of features that is required for a given learning machine to achieve ""satisfactory"" performance. (Likewise, the critical sampling size problem concerns whether, for a given dataset, there is a minimum number of data points that must be included in any sample for a learning machine to achieve satisfactory performance.) Here the specific meaning of ""satisfactory"" performance is to be defined by the user. This paper addresses the complexity of both problems in one general theoretical setting and shows that they have the same complexity and are highly intractable. Next, an empirical method is applied in an attempt to find the approximate critical feature dimension of datasets. It is demonstrated that, under generally reasonable assumptions pertaining to feature ranking algorithms, the critical feature dimension are successfully discovered by the empirical method for a number of datasets of various sizes. The results are encouraging in achieving significant feature size reduction and point to a promising way in dealing with big data. The significance of the existence of crucial dimension in datasets is also explained.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913349","critical dimension;data mining;dimension reduction;feature ranking;machine learning","Accuracy;Classification algorithms;Complexity theory;Data mining;Educational institutions;Electromagnetic interference;Vectors","Big Data;data mining;feature selection;learning (artificial intelligence)","Big Data mining;feature dimension problem;feature ranking algorithms;feature selection;learning machine","","1","","11","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Pedestrianly event detection using grid-based features","J. Preechasuk; P. Piamsa-nga","Department of Computer Engineering, Faculty of Engineering, Kasetsart University, Jatujak, Bangkok, Thailand","2014 International Computer Science and Engineering Conference (ICSEC)","20141206","2014","","","440","445","Video surveillance systems in public areas are grown rapidly for safety and security; therefore, the number of monitors becomes too large to watch by human. Automatic event detection system becomes more important. A trouble of surveillance camera in pedestrianly areas is that position of camera is too far or too close to the target objects and it compromises detection performance. In order to limit effects of camera positions, this paper proposes an event detection framework using grid-based features, which is a combination of localized information and event rules. Relationship between grid resolution and accuracy performance of event detection is studied. Grid-based features are tested on Neural Network and SVM classifiers. Experimental results show that grid-based features perform better than non-grid features. Performance of learning machines is also related to event types and grid size. The larger grid size is appropriate for the farther camera position.","","Electronic:978-1-4799-4963-2; POD:978-1-4799-4962-5","10.1109/ICSEC.2014.6978237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978237","event classification;event detection;grid-based features;machine learning;surveillance","Accuracy;Artificial neural networks;Event detection;Explosions;Feature extraction;Support vector machines;Surveillance","image sensors;neural nets;support vector machines;video surveillance","SVM classifiers;automatic event detection system;camera position;camera surveillance;grid based features;grid resolution;learning machines;localized information;neural network;pedestrianly event detection;public areas;video surveillance systems","","0","","25","","","July 30 2014-Aug. 1 2014","","IEEE","IEEE Conference Publications"
"Unsupervised seizure detection using modulation spectra measures: A preliminary study","O. Smart","Department of Neurosurgery, Emory University, Atlanta, Georgia USA","2014 40th Annual Northeast Bioengineering Conference (NEBEC)","20141204","2014","","","1","2","Epileptic seizures affect millions worldwide, impairing their quality of life in incapacitating ways. Many epilepsy patients undergo electroencephalography (EEG) continuously for days to weeks in a hospital to have seizures that might help doctors identify the anatomical focus of those seizures. But screening days to weeks of iEEG for seizures that can happen anytime or not at all is a time-consuming clinical burden for clinicians and staff. Thus, a computerized method to perform this duty objectively in lieu of subjective manual labor is highly beneficial toward robust timely clinical care of patients. I present such a method using two unsupervised machine learning techniques applied to cross-frequency coupling measures, comparing the classification performance of the methods. The methods perform similarly in accuracy, sensitivity, specificity, and selectivity (positive predictive value). Overall a proof-of-concept for a new approach is made. With more development, either approach could be used in practical clinical settings.","2160-6986;21606986","Electronic:978-1-4799-3728-8; POD:978-1-4799-3729-5","10.1109/NEBEC.2014.6972942","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972942","epilepsy;iEEG;pattern classification;principal component analysis;unsupervised machine learning","Couplings;Electroencephalography;Equations;Pattern classification;Principal component analysis;Shape measurement","electroencephalography;feature extraction;medical disorders;medical signal detection;medical signal processing;neurophysiology;signal classification;spectral analysis;unsupervised learning","classification accuracy;classification performance;classification selectivity;classification sensitivity;classification specificity;clinical care;computerized method;cross-frequency coupling measure;electroencephalography;epilepsy patient;epileptic seizure;iEEG screening;modulation spectra measure;positive predictive value;practical clinical setting;seizure anatomical focus identification;unsupervised machine learning techniques;unsupervised seizure detection","","1","","7","","","25-27 April 2014","","IEEE","IEEE Conference Publications"
"An alive electroencephalogram analysis system to assist the diagnosis of epilepsy","M. A. Ahmad; W. Majeed; N. A. Khan","SIVPLab, EE, SBASSE, Lahore University of Management Sciences, Pakistan","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","2340","2344","Computer assisted electroencephalograph analysis tools are trained to classify the data based upon the ‚Äúground truth‚Äù provided by the clinicians. After development and delivery of these systems there is no simple mechanism for these clinicians to improve the system's classification while encountering any false classification by the system. So the improvement process of the system's classification after initial training (during development) can be termed as `dead'. We consider neurologist as the best available benchmark for system's learning. In this article, we propose an `alive' system, capable of improving its performance by taking clinician's feedback into consideration. The system is based on taking DWT transform which has been shown to be very effective for EEG signal analysis. PCA is applied on the statistical features which are extracted from DWT coefficients before classification by an SVM classifier. After corrective marking of few epochs the initial average accuracy of 94.8% raised to 95.12.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952848","Biomedical Signal Processing;Computer Assisted Analysis;Electroencephalography (EEG);Epilepsy;Machine Learning","Accuracy;Discrete wavelet transforms;Electroencephalography;Epilepsy;Feature extraction;Support vector machines;Training","discrete wavelet transforms;electroencephalography;medical signal processing;patient diagnosis;principal component analysis;signal classification;support vector machines","DWT coefficients;DWT transform;EEG signal analysis;PCA;SVM classifier;alive electroencephalogram analysis system;alive system;clinician feedback;computer assisted electroencephalograph analysis tools;epilepsy diagnosis;false classification;ground truth;neurologist;statistical features","","0","","19","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Can We Identify NAT Behavior by Analyzing Traffic Flows?","Y. Gokcen; V. A. Foroushani; A. N. Z. Heywood","Fac. of Comput. Sci., Dalhousie Univ., Halifax, NS, Canada","2014 IEEE Security and Privacy Workshops","20141120","2014","","","132","139","It is shown in the literature that network address translation devices have become a convenient way to hide the source of malicious behaviors. In this research, we explore how far we can push a machine learning (ML) approach to identify such behaviors using only network flows. We evaluate our proposed approach on different traffic data sets against passive fingerprinting approaches and show that the performance of a machine learning approach is very promising even without using any payload (application layer) information.","","Electronic:978-1-4799-5103-1; POD:978-1-4799-5104-8","10.1109/SPW.2014.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957296","Network address translation classification;machine learning;traffic analysis;traffic flows","Browsers;Classification algorithms;Computers;Fingerprint recognition;IP networks;Internet;Payloads","Internet;learning (artificial intelligence);telecommunication traffic","NAT behavior;machine learning;malicious behaviors;network address translation devices;passive fingerprinting approach;payload information;traffic flows","","4","","18","","","17-18 May 2014","","IEEE","IEEE Conference Publications"
"Cascade-Structured Classifier Based on Adaptive Devices","R. Suzuki Okada; J. Jose","Escola Politec., Univ. de Sao Paulo (USP), Sa&#x0301;o Paulo, Brazil","IEEE Latin America Transactions","20141106","2014","12","7","1307","1324","This paper presents a novel approach to decision making based on uncertain data. Typical supervised learning algorithms assume that training data is perfectly accurate, and weight each training instance equally, resulting in a static classifier, whose structure can not be changed once built unless retrained from scratch. In this paper, we address this issue by using adaptive devices that can be incrementally trained, allowing them to aggregate new pieces of information while processing new input entries. We also propose a confidence model to weight each instance according to an estimate of its likelihood.","1548-0992;15480992","","10.1109/TLA.2014.6948867","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948867","Adaptive technology;cascade-based classification;classification combination;decision making;hybrid intelligent systems;machine learning","Abstracts;Adaptation models;Computational modeling;Decision making;Decision support systems;Robustness;Warehousing","decision making;estimation theory;learning (artificial intelligence);pattern classification","adaptive devices;cascade-structured classifier;confidence model;decision making;likelihood estimation;static classifier;supervised learning algorithms;training data;uncertain data","","0","","","","","Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Cross project change prediction using open source projects","R. Malhotra; A. J. Bansal","Software Engineering Department, Delhi Technological, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","201","207","Predicting the changes in the next release of software, during the early phases of software development is gaining wide importance. Such a prediction helps in allocating the resources appropriately and thus, reduces costs associated with software maintenance. But predicting the changes using the historical data (data of past releases) of the software is not always possible due to unavailability of data. Thus, it would be highly advantageous if we can train the model using the data from other projects rather than the same project. In this paper, we have performed cross project predictions using 12 datasets obtained from three open source Apache projects, Abdera, POI and Rave. In the study, cross project predictions include both the inter-project (different projects) and inter-version (different versions of same projects) predictions. For cross project predictions, we investigated whether the characteristics of the datasets are valuable for selecting the training set for a known testing set. We concluded that cross project predictions give high accuracy and the distributional characteristics of the datasets are extremely useful for selecting the appropriate training set. Besides this, within cross project predictions, we also examined the accuracy of inter-version predictions.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968347","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968347","Change prediction;Cross Project;Inter-version prediction;Machine learning;Metrics;Object oriented paradigm","Accuracy;Data models;Object oriented modeling;Predictive models;Software;Testing;Training","cost reduction;project management;public domain software;resource allocation;software maintenance","Abdera;POI;Rave;cost reduction;cross project change prediction;interproject prediction;interversion prediction;open source Apache projects;open source projects;resource allocation;software development;software maintenance","","0","","32","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Identification in Encrypted Wireless Networks Using Supervised Learning","C. Swartz; A. Joshi","CSEE Dept., UMBC, Baltimore, MD, USA","2014 IEEE Military Communications Conference","20141120","2014","","","210","215","In recent years, not only has the number of wireless devices significantly increased, but also their level of integration into daily life. Devices ranging from laptops and cell phones to cameras and TVs are now connected to networks. As the ability to secure these devices advances, public and private organizations are adopting and establishing both public and private wireless networks. Wireless networks ease this integration, but not without cost. The nature of this medium presents challenges. This work aims to demonstrate and codify a mechanism by which we can increase our ability to verify and validate the identity of the device through encrypted data observation. This paper focuses on device identification. Multiple supervised learning techniques were vetted and a reference implementation was constructed and executed using real traffic. Incremental learning methods were identified as the classification mechanism of choice for streaming data.","2155-7578;21557578","Electronic:978-1-4799-6770-4; POD:978-1-4799-6771-1","10.1109/MILCOM.2014.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6956761","802.11;WiFi;machine learning;network traffic analysis;network traffic classification;online learning;profiling;supervised learning","Accuracy;Ad hoc networks;Communication system security;IEEE 802.11 Standards;Performance evaluation;Supervised learning;Wireless communication","cryptography;learning (artificial intelligence);pattern classification;radio networks;telecommunication computing","Incremental learning method;TV;camera;cell phone;data observation encryption;encrypted wireless network;laptop;multiple supervised learning technique;streaming data classification mechanism;telecommunication traffic;wireless device identification","","0","","10","","","6-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Learning Multiple Complex Features Based on Classification Results","Y. Sato; K. Kozuka; Y. Sawada; M. Kiyono","Adv. Technol. Res. Labs., Panasonic Corp., Kyoto, Japan","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3369","3373","Recently, methods for the unsupervised learning of features from large data sets have been attracting much attention. These methods have been especially successful in the area of computer vision. However, there is a problem that it is difficult to determine what kind of features will result in a high classification performance. Indeed, the difficulty of determining the learning parameters is a widely known problem in the field of feature learning. To address this problem, this paper presents a feature-learning method which uses classification results to progressively learn multiple features of varied complexity. The proposed method enables the learning of both simple robust features and complex features which represents difficult patterns. In addition, we assign regularization weights that are based on the complexity of the features. This modification emphasizes simple representation and prevents over fitting. Experimental results with medical image classification show that the proposed method is superior to the conventional method, especially when classification is difficult.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977292","Feature learning;Machine learning;Medical imaging","Accuracy;Complexity theory;Computed tomography;Diseases;Feature extraction;Training;Vectors","computer vision;medical image processing;pattern classification;unsupervised learning","classification results;computer vision;feature-learning method;large data sets;learning parameters;medical image classification;multiple complex features learning;regularization weights;unsupervised learning","","0","","11","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Application of time-series and Artificial Neural Network models in short term load forecasting for scheduling of storage devices","K. M. U. Ahmed; M. Ampatzis; P. H. Nguyen; W. L. Kling","Department of Electrical Engineering Technische Universiteit Eindhoven, the Netherlands","2014 49th International Universities Power Engineering Conference (UPEC)","20141023","2014","","","1","6","In the context of the smart grid, scheduling residential energy storage device is necessary to optimize technical and market integration of distributed energy resources (DERs), especially the ones based on renewable energy. The first step to achieve proper scheduling of the storage devices is electricity consumption forecasting at individual household level. This paper compares the forecasting ability of Artificial Neural Network (ANN) and AutoRegressive Integrated Moving Average (ARIMA) model. The benefit of proper storage scheduling is demonstrated via a use-case. The work is a part of a project focused on photovoltaic generation with integrated energy storage at household level. The methods under study attempt to capture the daily electricity consumption profile of an individual household.","","CD-ROM:978-1-4799-6556-4; Electronic:978-1-4799-6557-1; POD:978-1-4799-6558-8","10.1109/UPEC.2014.6934761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6934761","Artificial Neural Network (ANN);AutoRegressive Integrated Moving Average (ARIMA);machine learning;short-term load forecasting (STLF);storage device scheduling","Artificial neural networks;Biological system modeling;Electricity;Forecasting;Load modeling;Predictive models;Time series analysis","autoregressive moving average processes;energy storage;load forecasting;neural nets;power consumption;power engineering computing;power generation scheduling;power markets;smart power grids;solar cells;time series","ANN;ARIMA model;DER;artificial neural network model;autoregressive integrated moving average model;distributed energy resource;household daily electricity consumption forecasting;integrated energy storage;market integration;photovoltaic generation;renewable energy;residential energy storage device scheduling;short term load forecasting;smart grid;time series application","","0","","17","","","2-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Modified reinforcement learning for sequential action behaviors and its application to robotics","C. Robinson","Dept. of Electrical and Computer Engineering, University of Louisville Speed School of Engineering, KY, USA","IEEE SOUTHEASTCON 2014","20141110","2014","","","1","8","When developing a robot or other automaton, the efficacy of the agent is highly dependent on the performance of the behaviors which underpin the control system. Especially in the case of agents which must act in real world or disorganized environments, the design of robust behaviors can be both difficult and time consuming, and often requires the use of sensitive tuning. In response to this need, we present a behavioral, goal-oriented, reinforcement-based machine learning strategy which is flexible, simple to implement, and designed for application in real-world environments, but with the capability of software-based training. In this paper, we will explain our design paradigms, the formal implementation thereof, and the algorithm proper. We will show that the algorithm is able to emulate standard reinforcement learning within comparable training time, and to extend the capabilities thereof as well. We also demonstrate extension of learning beyond the scope of training examples, and present an example of a physical robot which learns a sequential action behavior by experimentation.","1091-0050;10910050","Electronic:978-1-4799-6585-4; POD:978-1-4799-6586-1","10.1109/SECON.2014.6950737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6950737","Algorithms;Behavior Based Robotics;Behaviors;Machine learning;Operant Conditioning;Probabilistic learning;Reinforcement learning;Robot control;Robots","Learning (artificial intelligence);Learning automata;Robots;Standards;Three-dimensional displays;Vectors","control engineering computing;learning (artificial intelligence);multi-agent systems;robots","behavioral goal-oriented reinforcement-based machine learning strategy;comparable training time;control system;disorganized environments;formal implementation;modified reinforcement learning;physical robot;reinforcement learning;sensitive tuning;sequential action behaviors;software-based training","","0","","6","","","13-16 March 2014","","IEEE","IEEE Conference Publications"
"Artificial neural network modeling for variable area ratio ejector","C. Haoran; C. Wenjian","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2014 9th IEEE Conference on Industrial Electronics and Applications","20141023","2014","","","220","225","In this article, machine learning method is applied to model ejectors. Three-layer feed-forward neural network with sigmoid active functions was employed to estimate the outlet pressure of ejector given states of primary and secondary inlets. Well prediction results were achieved within the boundary of training dataset in experiment on ejector based multi-evaporator refrigeration system. The number of hidden layer neurons is optimized by minimizing validation error. Moreover, this research lays the foundation of optimizing system parameters and building control strategies for ejector based refrigeration system based on the machine learning methods.","2156-2318;21562318","CD-ROM:978-1-4799-4316-6; Electronic:978-1-4799-4315-9; POD:978-1-4799-4314-2","10.1109/ICIEA.2014.6931162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6931162","Ejector;Ejector Based Multi-Evaporator Refrigeration System;Feed Forward Artificial Neural Network;Machine Learning;Modeling","Artificial neural networks;Biological neural networks;Computational fluid dynamics;Mathematical model;Neurons;Testing;Thermodynamics","control engineering computing;feedforward neural nets;learning (artificial intelligence);optimisation;pressure control;refrigeration","artificial neural network modeling;feed-forward neural network;machine learning method;multievaporator refrigeration system control;outlet pressure estimation;sigmoid active functions;system parameter optimization;training dataset;variable area ratio ejector","","0","","17","","","9-11 June 2014","","IEEE","IEEE Conference Publications"
"Voting based automatic exudate detection in color fundus photographs","P. Prenta≈°iƒá; S. Lonƒçariƒá","Image Processing Group, Faculty of Electrical Engineering and Computing, University of Zagreb, Unska 3, 10000, Croatia","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","1816","1820","Diabetic retinopathy is one of the leading causes of preventable blindness. Screening programs using color fundus photographs enable early diagnosis of diabetic retinopathy, which enables timely treatment of the disease. Exudate detection algorithms are important for development of automatic screening systems and in this paper we present a method for detection of exudate regions in color fundus photographs. The method combines different preprocessing and candidate extraction algorithms to increase the exudate detection accuracy. First, we form an ensemble of different candidate extraction algorithms, which are used to increase the accuracy. After extracting the potential exudate regions we apply machine learning based classification for detection of exudate regions. For experimental validation we use the DRiDB color fundus image set where the presented method achieves higher accuracy in comparison to other state-of-the art methods.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952663","diabetic retinopathy;ensemble;exudate detection;image processing and analysis;machine learning","Biomedical imaging;Diabetes;Feature extraction;Image color analysis;Retina;Retinopathy;Standards","colour photography;diseases;feature extraction;image classification;image colour analysis;learning (artificial intelligence);medical image processing","DRiDB color fundus image set;automatic screening systems;candidate extraction algorithms;color fundus photographs;diabetic retinopathy diagnosis;disease treatment;exudate detection algorithms;machine learning based classification;preventable blindness;screening programs;voting based automatic exudate detection","","0","","13","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics","C. D. Stolper; A. Perer; D. Gotz","School of Interactive Computing, Georgia Institute of Technology","IEEE Transactions on Visualization and Computer Graphics","20141106","2014","20","12","1653","1662","As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.","1077-2626;10772626","","10.1109/TVCG.2014.2346574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876049","Progressive visual analytics;electronic medical records;information visualization;interactive machine learning","Algorithm design and analysis;Data visualization;Heuristic algorithms;Unsolicited electronic mail;Visual analytics","data analysis;data visualisation;learning (artificial intelligence)","analytic algorithms;computational speed;dataset grow;electronic medical records;event sequences;in-progress analytics;information visualization techniques;progressive insights;progressive visual analytic systems;user-driven visual exploration","1","13","","43","","","Dec. 31 2014","","IEEE","IEEE Journals & Magazines"
"Automated Biosignal Quality Analysis for Electromyography Using a One-Class Support Vector Machine","G. D. Fraser; A. D. C. Chan; J. R. Green; D. T. MacIsaac","Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada","IEEE Transactions on Instrumentation and Measurement","20141106","2014","63","12","2919","2930","This paper introduces the importance of biosignal quality assessment and presents a pattern classification approach to differentiate clean from contaminated electromyography (EMG) signals. Alternatively to traditional bottom-up approaches, which examine specific contaminants only, we present a top-down approach using a one-class support vector machine (SVM) trained on clean EMG and tested on artificially contaminated EMG. Both simulated and real EMG are used. Results are evaluated for each contaminant: 1) power line interference; 2) motion artifact; 3) ECG interference; 4) quantization noise; 5) analog-to-digital converter clipping; and 6) amplifier saturation, as a function of the level of signal contamination. Results show that different ranges of contamination can be detected in the EMG depending on the type of contaminant. At high levels of contamination, the SVM classifies all EMG signals as contaminated, whereas at low levels of contamination, it classifies the majority of EMG signals as contaminant free. A transition point for each contaminant is identified, where the classification accuracy drops and variance in classification increases. In some cases, contamination can be detected with the SVM when it is not visually discernible. This method is shown to be successful in detecting problems due to single contaminants but is generic to all forms of contamination in EMG.","0018-9456;00189456","","10.1109/TIM.2014.2317296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6807760","Biomedical measurements;biosignal quality analysis;electromyography (EMG);machine learning;myoelectric signals;support vector machines (SVMs);support vector machines (SVMs).","Biomedical measurement;Contamination;Electrocardiography;Electromyography;Machine learning;Support vector machines","electromyography;medical signal processing;pattern classification;signal classification;support vector machines","ECG interference;EMG signals;amplifier saturation;analog-to-digital converter clipping;automated biosignal quality analysis;biosignal quality assessment;contaminated electromyography signals;motion artifact;one-class support vector machine;pattern classification approach;power line interference;quantization noise;signal contamination","","7","","50","","20140429","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Adaptive window and adaptive threshold method for microcalcification detection","O. Intharasombat; P. Piamsa-nga","Department of Computer Engineering, Faculty of Engineering, Kasetsart University, Bangkok, Thailand","2014 International Computer Science and Engineering Conference (ICSEC)","20141206","2014","","","446","451","Microcalcifications are identified in mammograms by pixels that have a brightness greater than their boundary. The distribution of detected microcalcifications depends on their intensity and window size. We propose an adaptive window and adaptive threshold (AWAT) method for microcalcification detection. Based on the intensity of the distribution, we found that 2 times of standard deviation (2SD) is the optimum threshold for detecting local maxima. We also propose an adaptive window that is dependent on the surrounding tissue. The local maxima are identified using a threshold adapted to each window. Then, small objects are removed using morphological operations. The remaining local maxima are called candidates and classified into microcalcification or normal tissue using three classifiers: a multilayer perceptron, a radial basis function neural network, and a support vector machine. We compared the results of our method to a method using five different fixed window sizes, evaluating the performance using the area under the receiver operating characteristic curve. Our experimental results revealed that our method outperformed all the fixed window size approaches, for all the classifiers investigated. Overall, the multilayer perceptron performed the best among the classifiers, with area under ROC curve A<sub>z</sub>=0.951 (compared with A<sub>z</sub>=0.916 and A<sub>z</sub>=0.847). Finally, the results found that size of window varies from 10 and 131 pixels, while the threshold also varies from 5.628 and 229.959 of intensity. In the spatial domain, both threshold and window size are required to detect local maxima. The results of our experiments demonstrated that the proposed AWAT method performed better than fixed window size methods.","","Electronic:978-1-4799-4963-2; POD:978-1-4799-4962-5","10.1109/ICSEC.2014.6978238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978238","adaptive threshold;machine learning;microcalcification classification;microcalcification detection","Breast cancer;Breast tissue;Computer science;Feature extraction;Radial basis function networks;Standards;Support vector machines","cancer;image classification;image segmentation;learning (artificial intelligence);mammography;medical image processing;multilayer perceptrons;radial basis function networks;support vector machines","2-times-of-standard deviation;2SD;AWAT method;ROC curve;adaptive window-and-adaptive threshold method;distribution intensity;image pixels;local maxima detection;local maxima identification;mammograms;microcalcification detection;microcalcification identification;morphological operations;multilayer perceptron classifier;normal tissue;optimum threshold;performance evaluation;radial basis function neural network classifier;receiver operating characteristic curve;spatial domain;support vector machine classifier","","0","","29","","","July 30 2014-Aug. 1 2014","","IEEE","IEEE Conference Publications"
"Trusted Detection of Sensitive Activities on Mobile Phones Using Power Consumption Measurements","M. Guri; G. Kedma; B. Zadov; Y. Elovici","Dept. of Inf. Syst. Eng., Ben-Gurion Univ., Beer-Sheva, Israel","2014 IEEE Joint Intelligence and Security Informatics Conference","20141206","2014","","","145","151","The unprecedented popularity of modern mobile phones has made them a lucrative target for skillful and motivated offenders. A typical mobile phone is packed with sensors, which can be turned on silently by a malicious program, providing invaluable information to the attacker. Detecting such hidden activities through software monitors can be blindfolded and bypassed by rootkits and by anti-forensic methods applied by the malicious program. Moreover, detecting power consumption by software running on the mobile phone is susceptible to similar evasive techniques. Consequently, software based detection of hidden malicious activities, particularly the silent activation of sensors, cannot be considered as trusted. In this paper we present a method which detects hidden activities using external measurement of power consumption. The classification model is acquired using machine-learning multi-label classification algorithms. Our method overcomes the inherent weaknesses of software-based monitors, and provides a trusted solution. We describe the measurement setup, and provide detailed evaluation results of the algorithms used. The results obtained so far support the feasibility of our method.","","CD-ROM:978-1-4799-6363-8; Electronic:978-1-4799-6364-5; POD:978-1-4799-6365-2","10.1109/JISIC.2014.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975566","Machine learning;Mobile phone security;Multi-label classification;Trusted measurement","Battery charge measurement;Global Positioning System;IEEE 802.11 Standards;Mobile handsets;Monitoring;Power demand;Power measurement","learning (artificial intelligence);smart phones;telecommunication security;trusted computing","machine learning multilabel classification algorithms;malicious program;mobile phones;power consumption measurements;sensitive activities;software monitors;trusted detection","","0","","23","","","24-26 Sept. 2014","","IEEE","IEEE Conference Publications"
"Efficient Methods for Early Protocol Identification","B. Hull√°r; S. Laki; A. Gy√∂rgy","Dept. of Phys. of Complex Syst., Eotvos Lorand Univ., Budapest, Hungary","IEEE Journal on Selected Areas in Communications","20141127","2014","32","10","1907","1918","To manage and monitor their networks in a proper way, network operators are often interested in automatic methods that enable them to identify applications generating the traffic traveling through their networks as fast (i.e., from the first few packets) as possible. State-of-the-art packet-based traffic classification methods are either based on costly inspection of the payload of several packets in each flow or on basic flow statistics without taking into account the packet content. In this paper, we consider an intermediate approach of analyzing only the first few bytes of the first (or first few) packet(s) of each flow and propose automatic, machine-learning-based methods with very low computational complexity and memory footprint. The performance of these techniques are thoroughly analyzed, showing that outstanding early classification accuracy can be achieved on traffic traces generated by a diverse set of applications (including P2P TV and file sharing) in a laboratory environment as well as on a real-world data set collected in the network of a large European ISP.","0733-8716;07338716","","10.1109/JSAC.2014.2358832","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911965","Traffic classification;machine learning;payload statistics","Context;Data models;Memory management;Payloads;Protocols;Vectors;Vegetation","IP networks;computational complexity;computer network management;learning (artificial intelligence);pattern classification;protocols;telecommunication traffic","European ISP;P2P TV;automatic machine-learning-based methods;computational complexity;early protocol identification;file sharing;memory footprint;network management;network monitoring;network operators;network traffic;packet content;packet-based traffic classification methods;traffic traces","","0","","19","","20140926","Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Comparing initialisation methods for the Heuristic Memetic Clustering Algorithm","B. G. W. Craenen; T. Ristaniemi; A. K. Nandi","Department of Mathematical Information Technology, University of Jyv&#x00E4;skyl&#x00E4;, Finland","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","1158","1162","In this study we investigate the effect five initialisation methods from literature have on the performance of the Heuristic Memetic Clustering Algorithm (HMCA). The evaluation is based on an extensive experimental comparison on three benchmark datasets between HMCA and the commonly-used k-Medoids algorithm. Analysis of the experimental effectiveness and efficiency metrics confirms that the HMCA substantially outperforms k-Medoids, with the HMCA capable of finding bestter clusterings using substantially less computation effort. The Sample and Cluster initialisation methods were found to be the most suitable for the HMCA, with the results of the k-Medoids suggesting this to be the case for other algorithms as well.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952391","Clustering;Heuristics;Machine Learning;Memetic Algorithms","Algorithm design and analysis;Clustering algorithms;Glass;Heuristic algorithms;Iris;Sociology;Statistics","learning (artificial intelligence);pattern clustering","HMCA;cluster initialisation methods;heuristic memetic clustering algorithm;k-medoids algorithm;machine learning;sample initialisation methods;three benchmark datasets","","0","","18","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Automated Real-Time Classification and Decision Making in Massive Data Streams from Synoptic Sky Surveys","S. G. Djorgovski; A. Mahabal; C. Donalek; M. Graham; A. Drake; M. Turmon; T. Fuchs","California Inst. of Technol., Pasadena, CA, USA","2014 IEEE 10th International Conference on e-Science","20141204","2014","1","","204","211","The nature of scientific and technological data collection is evolving rapidly: data volumes and rates grow exponentially, with increasing complexity and information content, and there has been a transition from static data sets to data streams that must be analyzed in real time. Interesting or anomalous phenomena must be quickly characterized and followed up with additional measurements via optimal deployment of limited assets. Modern astronomy presents a variety of such phenomena in the form of transient events in digital synoptic sky surveys, including cosmic explosions (supernovae, gamma ray bursts), relativistic phenomena (black hole formation, jets), potentially hazardous asteroids, etc. We have been developing a set of machine learning tools to detect, classify and plan a response to transient events for astronomy applications, using the Catalina Real-time Transient Survey (CRTS) as a scientific and methodological testbed. The ability to respond rapidly to the potentially most interesting events is a key bottleneck that limits the scientific returns from the current and anticipated synoptic sky surveys. Similar challenge arise in other contexts, from environmental monitoring using sensor networks to autonomous spacecraft systems. Given the exponential growth of data rates, and the time-critical response, we need a fully automated and robust approach. We describe the results obtained to date, and the possible future developments.","","Electronic:978-1-4799-4287-9; POD:978-1-4799-4286-2","10.1109/eScience.2014.7","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972266","Bayesian methods;automated decision making;classification;machine learning;massive data streams;sky surveys","Astronomy;Cathode ray tubes;Extraterrestrial measurements;Pollution measurement;Real-time systems;Time measurement;Transient analysis","astronomical surveys;astronomy computing;data analysis;decision making;learning (artificial intelligence);pattern classification","CRTS;Catalina Real-time Transient Survey;astronomy applications;automated real-time classification;automated real-time decision making;black hole formation;cosmic explosions;data analysis;digital synoptic sky surveys;gamma ray bursts;jets;machine learning tools;massive data streams;potentially hazardous asteroids;relativistic phenomena;scientific data collection;supernovae;technological data collection","","1","","36","","","20-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Simulator for Intelligent Energy Demand Side Management","G. Platt; Y. Guo","Div. of Energy Technol., CSIRO, Newcastle, NSW, Australia","2013 1st International Conference on Artificial Intelligence, Modelling and Simulation","20141120","2013","","","348","353","Demand Side Management or DSM refers to the reduction or postponement of energy consumption. Current DSM technology can now provide automated off-site control of domestic and industrial devices. Many questions arise in regards to controlling a potentially large proportion of the population's electricity: To what level can we reduce demand? What incentives could retailers offer customers? How do we ensure consumers are satisfied? Previous trials of DSM control techniques have had various levels of success in reducing demand and in changing the consumption habits of individuals over time. The main criticism of existing automated control techniques is that they do not account for customer satisfaction and therefore do not survive in the long term. We propose a novel automated machine learning approach that incorporates customer satisfaction into automated demand reduction, satisfying both customers and retailers. Through a simulation of 200,000 households equipped with automated demand control, we conduct experiments measuring electricity levels alongside population satisfaction levels under different energy control policies. We illustrate that significant energy and cost savings can be achieved without compromising consumer satisfaction.","","Electronic:978-1-4799-3251-1; POD:978-1-4799-3252-8","10.1109/AIMS.2013.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6959942","demand side management;machine learning;reinforcement learning;smart meters consumer satisfaction","Australia;Customer satisfaction;Electricity;Energy consumption;Generators;Home appliances;Optimization","demand side management;learning (artificial intelligence);power engineering computing","DSM control techniques;DSM technology;customer satisfaction;energy consumption;energy control policy;intelligent energy demand side management;machine learning approach","","0","","11","","","3-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Classification and Clustering English Writing Errors Based on Native Language","B. Flanagan; C. Yin; T. Suzuki; S. Hirokawa","Grad. Sch. of Inf. Sci. & Electr. Eng., Kyushu Univ., Fukuoka, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","318","323","It is important for language learners to determine and reflect on their writing errors in order to overcome weaknesses. Each language learner has their own unique writing error characteristics and therefore has different learning needs. In this paper, we analyze the writing errors of foreign language learners on the language learning SNS website Lang-8 to investigate the characteristics of errors by native language. 142,465 sentences were collected from Lang-8 for analysis. For each native language, the predicted scores of 15 error categories from SVM machine learning models are used as a vector representation of each sentence. These score vectors are then clustered to determine error co-occurrence within the same sentence. The results were then analyzed to determine the error characteristics of different native languages.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913316","Language learning;machine learning;native language characteristics;writing error categories","Data models;Educational institutions;Principal component analysis;Support vector machines;Vectors;Writing","computer aided instruction;learning (artificial intelligence);natural language processing;pattern classification;pattern clustering;social networking (online);support vector machines;vectors","English writing errors;Lang-8;SNS Web site;SVM;classification;clustering;error characteristics;machine learning;native language;vector representation","","1","","13","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Neural network based predictors for 3D content streaming and rendering","V. Vani; S. Mohan","College of Computer and Information Systems, Al yamamah University, Riyadh, Kingdom of Saudi Arabia","2014 International Computer Science and Engineering Conference (ICSEC)","20141206","2014","","","452","457","3D content streaming and rendering system has attracted a significant attention from both academia and industry. However, these systems struggle to provide comparable quality to that of locally stored and rendered 3D data. Since the rendered 3D content on to the client machine is controlled by the users, their interactions have a strong impact on the performance of 3D content streaming and rendering system. Thus, considering user behaviors in these systems could bring significant performance improvements. In this paper, an Artificial Neural Network (ANN) based predictor is proposed for 3D content streaming and rendering. The user interactions on various 3D contents are profiled and used as information to train the Neural Network predictors. The 3D content could be static or dynamic 3D object / scene. We test our model through another set of interactions over the 3D contents by same users. The tested result shows that our model can learn the user interactions and is able to predict several interactions to help in optimizing the streaming and rendering for better performance. We also propose various approaches based on traces collected from the same/different users to accelerate the learning process of the neural network.","","Electronic:978-1-4799-4963-2; POD:978-1-4799-4962-5","10.1109/ICSEC.2014.6978239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978239","3D Streaming;Artificial Neural Network;Machine Learning;Predictive Model;Progressive Meshing;User Interactions Profiling","Computational modeling;Heuristic algorithms;Prediction algorithms;Predictive models;Solid modeling;Three-dimensional displays;Training","neural nets;rendering (computer graphics);solid modelling","3D content streaming and rendering system;artificial neural network based predictor;client machine;dynamic 3D object;learning process;neural network based predictors;static 3D object","","0","","9","","","July 30 2014-Aug. 1 2014","","IEEE","IEEE Conference Publications"
"Towards Automated Classification of Seabed Substrates in Underwater Video","M. Pugh; B. Tiddeman; H. Dee; P. Hughes","Aberystwyth Univ., Aberystwyth, UK","2014 ICPR Workshop on Computer Vision for Analysis of Underwater Imagery","20141120","2014","","","9","16","In this work, we present a system for the automated classiffication of seabed substrates in underwater video. Classiffication of seabed substrates traditionally requires manual analysis by a marine biologist, according to an established classiffication system. Accurate, consistent and robust classiffication is difficult in underwater video due to varying lighting conditions, turbidity and method of original recording. We have developed a system that uses ground truth data from marine biologists to train and test per-frame classiffiers. In this paper we present preliminary results of this using various feature representations (histograms, Gabor wavelets) and classiffiers (SVC, kNN) on both full-frame and patched-based analysis, achieving up to 93% accuracy.","","Electronic:978-1-4799-6713-1; POD:978-1-4799-6714-8","10.1109/CVAUI.2014.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6961263","Gabor;machine learning;substrate classiffcation;texture;underwater video analysis","Biology;Histograms;Image color analysis;Lighting;Monitoring;Substrates;Training","image classification;video signal processing;wavelet transforms","Gabor wavelets;SVC;automated classification;feature representations;histograms;kNN;marine biologist;patched-based analysis;robust classiffication system;seabed substrates;underwater video","","0","","11","","","24-24 Aug. 2014","","IEEE","IEEE Conference Publications"
"A support system for selection of reviewers","J. Protasiewicz","National Information Processing Institute in Poland","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","3062","3065","In this paper we deal with a reviewer assignment problem and as a solution we propose a decision support system which is able to recommend relevant reviewers to evaluate grant proposals as well as manuscripts. The system is composed of a user interface and three modules responsible for data transformation into information and knowledge. Firstly, a data acquisition module collects data concerning researchers. Next, an information retrieval module builds researchers' profiles using various machine learning methods for keyword extraction, information classification and disambiguation. Finally, a recommendation module generates a ranking of potential reviewers based on a cosine similarity measure between researchers' profiles and a problem that has to be reviewed. The system is meant to work autonomously, without any manual adjustment. It is available for free use on the Internet (http://sssr.opi.org.pl)1.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974397","decision support system;machine learning;reviewer assignment problem","Data acquisition;Data mining;Indexes;Information retrieval;Proposals;Vectors","Internet;data acquisition;decision support systems;information retrieval;learning (artificial intelligence);pattern classification;user interfaces","Internet;cosine similarity measure;data acquisition module;data transformation;decision support system;disambiguation;information classification;information retrieval module;keyword extraction;machine learning method;recommendation module;researcher profiles;reviewer assignment problem;user interface","","1","","29","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Modelling temporal variations by polynomial regression for classification of radar tracks","L. W. Jochumsen; J. √òstergaard; S. H. Jensen; M. √ò. Pedersen","Terma A/S, Hovmarken 4, Lystrup, Denmark","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","1412","1416","The sampling rate of a radar is often too low to reliably capture the acceleration of moving targets such as birds. Moreover, the sampling rate depends upon the target's acceleration and heading and will therefore generally be time varying. When classifying radar tracks using temporal features, too low or highly varying sampling rates deteriorates the classifier's performance. In this work, we propose to model the temporal variations of the target's speed by low-order polynomial regression. Using the polynomial we obtain the conditional statistics of the targets speed at some future time given its speed at the current time. When used in a classifier based on Gaussian mixture models and with real radar data, it is shown that the inclusions of conditional statistics describing the targets temporal variations, leads to a substantial improvement in the overall classification performance.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952502","Automatic target classification;Machine learning;Radar;Surveillance","Acceleration;Birds;Marine vehicles;Radar cross-sections;Radar tracking;Target tracking","Gaussian processes;mixture models;polynomials;radar tracking;regression analysis;signal classification;target tracking","Gaussian mixture model;conditional statistics;moving target acceleration;polynomial regression;radar track classification;sampling rate;target heading;temporal variation modelling","","0","","9","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"[Demo] Real-time illumination estimation from faces for coherent rendering","S. B. Knorr; D. Kurz","Metaio GmbH","2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","20141106","2014","","","349","350","We showcase a method for estimating the real-world lighting conditions within a scene based on the visual appearance of the user's face captured in a single image of a monocular user-facing RGB camera. The implementation is based on our ISMAR 2014 paper [8]. The light reflected from the face towards the camera is measured and the most plausible real-world lighting condition explaining the measurement is estimated in real-time based on knowledge acquired in a one-time pre-processing of a set of images of different faces under known illumination. The estimated illumination is instantly used for the rendering of the virtual objects.","","Electronic:978-1-4799-6184-9; POD:978-1-4799-6185-6","10.1109/ISMAR.2014.6948483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948483","Augmented Reality;Coherent Rendering;Computer Graphics;Computer Vision;Demo;ISMAR 2014;Illumination Estimation;Inverse Lighting;Machine Learning;Monocular;Precomputed Radiance Transfer;Real-Time;Spherical Harmonics","","","","","0","","","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Mining DEOPS Records: Big Data's Insights into Dictatorship","D. d. M. Navarro; R. C. Prati","Centro de Mat., Comput. e Cognicao (CMCC), Univ. Fed. do ABC (UFABC), Santo Andre, Brazil","2014 IEEE 10th International Conference on e-Science","20141204","2014","2","","67","70","Historical data provide valuable information for the nderstanding of human interactions through time. However, mining this data is challenging as the available records are generally noise digitized handwritten, typewritten or press printed documents. In this research proposal, we plan to develop tools and techniques for pre-processing and extracting information from documents of the military dictatorship period that ruled Brazil from 1964 to 1985. The data to be analyzed consists of digitized images of records from DEOPS/SP (SaÃÉo Paulo State Department of Political and Social Order), an emblematic police agency which have monitored (and in some cases, harassed and tortured) hundreds of thousands Brazilian citizens during that period. The idea is to use state-of-the-art powerful artificial intelligence algorithms in conjunction with crowd sourcing techniques to pre-process and extract information from this important period of the Brazilian History.","","Electronic:978-1-4799-4287-9; POD:978-1-4799-4286-2","10.1109/eScience.2014.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972099","Brazilian military dictatorship;DEOPS;artificial intelligence;big data;crowdsourcing;data mining;escience;image processing;machine learning;text processing","Character recognition;Crowdsourcing;Data mining;Optical character recognition software;Presses;Smart phones;Strips","Big Data;artificial intelligence;data analysis;data mining;document handling;history;military computing;police","Brazilian history;DEOPS record mining;DEOPS-SP;SaÃÉo Paulo State Department of Political and Social Order;artificial intelligence algorithms;big data;crowd sourcing techniques;data analysis;data mining;document information extraction;document preprocessing;emblematic police agency;historical data;military dictatorship;noise digitized handwritten documents;press printed documents;typewritten documents","","0","","11","","","20-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"Fast Similarity Search Using Multiple Binary Codes","S. Shirakawa","Coll. of Sci. & Eng., Aoyama Gakuin Univ., Sagamihara, Japan","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3714","3719","One of the fast similarity search techniques is a binary hashing method that transforms a real-valued vector into a binary code. The similarity between two binary codes is measured by their Hamming distance. In this method, a hash table is often used for realizing the constant time similarity search. The number of accesses to the hash table, however, increases when the number of bits becomes long. In this paper, we consider the method that does not access the data with long Hamming radius by using multiple binary codes. Then, we propose the learning method of the binary hash functions for multiple binary codes. We conduct the experiment on similarity search utilizing up to 20 million data set, and show that our proposed method achieves a fast similarity search compared with the conventional linear scan and hash table search.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977350","Binary hash;image retrieval;machine learning;similarity search","Binary codes;Computational efficiency;Databases;Hamming distance;Linear programming;Training;Vectors","binary codes;file organisation;information retrieval;learning (artificial intelligence);vectors","Hamming distance;Hamming radius;binary hash functions;binary hashing method;constant time similarity search;fast similarity search techniques;hash table;learning method;multiple binary codes;real-valued vector","","0","","15","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Learning energy demand domain knowledge via feature transformation","S. Siddique; R. J. Povinelli","Department of EECE, Marquette University, Milwaukee, Wisconsin USA","2014 IEEE PES General Meeting | Conference & Exposition","20141030","2014","","","1","5","Domain knowledge is an essential factor for forecasting energy demand. This paper introduces a method that incorporates machine learning techniques to learn domain knowledge by transforming the input features. Our approach divides the inputs into subsets and then searches for the best machine learning technique for transforming each subset of inputs. Preprocessing of the inputs is not required in our approach because the machine learning techniques appropriately transform the inputs. Hence, this technique is capable of learning where nonlinear transformations of the inputs are needed. We show that the learned data transformations correspond to energy forecasting domain knowledge. Transformed subsets of the inputs are combined using ensemble regression, and the final forecasted value is obtained. Our approach is tested with natural gas and electricity demand signals. Experimental results show how this method can learn domain knowledge, which yields improved forecasts.","1932-5517;19325517","Electronic:978-1-4799-6415-4; POD:978-1-4799-6416-1; USB:978-1-4799-6414-7","10.1109/PESGM.2014.6939792","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6939792","Demand forecasting;Domain knowledge;Feature transformation;Machine learning;Time series analysis","Artificial neural networks;Electricity;Feature extraction;Forecasting;Natural gas;Predictive models;Regression tree analysis","learning (artificial intelligence);load forecasting;power engineering computing;regression analysis","electricity demand signal;energy demand domain knowledge;energy demand forecasting;ensemble regression;feature transformation;machine learning;natural gas;nonlinear transformation","","0","","17","","","27-31 July 2014","","IEEE","IEEE Conference Publications"
