"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7424401,7424411,7424325,7424466,7424387,7424398,7424463,7424305,7424328,7424372,7424443,7424410,7424436,7424375,7424352,7424399,7424407,7424488,7424417,7424495,7424413,7424468,7424404,7424433,7424357,7424492,7424361,7424366,7424412,7424295,7424341,7424303,7424425,7424340,7424392,7424302,7424383,7424327,7424478,7424453,7424339,7424445,7424347,7424391,7424278,7424382,7424431,7424496,7424442,7424477,7424452,7424409,7424296,7424338,7424317,7424467,7424388,7424370,7424306,7424448,7424455,7424373,7424286,7424403,7424298,7424390,7424277,7424457,7424288,7424405,7424300,7424290,7424292,7424381,7424430,7424283,7424484,7424441,7424355,7424334,7424476,7424428,7424343,7424281,7424320,7424420,7424451,7424487,7424358,7424337,7424316,7424482,7424493,7424416,7424377,7424362,7424439,7424353,7424311,7424474",2017/05/05 00:01:21
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Scalable Learning of Entity and Predicate Embeddings for Knowledge Graph Completion","P. Minervini; N. Fanizzi; C. d'Amato; F. Esposito","Dept. of Comput. Sci., Univ. degli Studi di Bari Aldo Moro, Bari, Italy","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","162","167","Knowledge Graphs (KGs) are a widely used formalism for representing knowledge in the Web of Data. We focus on the problem of link prediction, i.e. predicting missing links in large knowledge graphs, so to discover new facts about the world. Representation learning models that embed entities and relation types in continuous vector spaces recently were used to achieve new state-of-the-art link prediction results. A limiting factor in these models is that the process of learning the optimal embedding vectors can be really time-consuming, and might even require days of computations for large KGs. In this work, we propose a principled method for sensibly reducing the learning time, while converging to more accurate link prediction models. Furthermore, we employ the proposed method for training and evaluating a set of novel and scalable models. Our extensive evaluations show significant improvements over state-of-the-art link prediction methods on several datasets.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424303","knowledge graphs;link prediction;representation learning;semantic web","Computational modeling;Knowledge engineering;Predictive models;Resource description framework;Semantics;Training","data handling;graph theory;knowledge representation;learning (artificial intelligence);vectors","Web of Data;continuous vector spaces;knowledge graph completion;knowledge representation;missing link prediction;optimal embedding vectors;predicate embeddings;principled method;representation learning models;scalable entity learning","","1","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Donor Selection for Hematopoietic Stem Cell Transplant Using Cost-Sensitive SVM","A. Sivasankaran; V. Cherkassky; M. Albrecht; E. Williams; M. Maiers","Biomed. Inf. &. Comput. Biol., Univ. of Minnesota, Minneapolis, MN, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","831","836","Donor selection for Hematopoietic Stem Cell Transplant often requires physicians to manually select 3 to 5 donors from a list of 100s of genetically compatible donors as identified by HLA-based matching algorithms. The decision process is complicated by a lack of strict guidelines governing a ""secondary"" selection process, which is based upon non-HLA donor attributes. Our research is aimed at modeling this ""secondary"" decision process which can help physicians choose the right donors, based on donor attributes and historical choice behavior. Proposed black box models will help in improving selection consistency.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424425","SVM classification;donor selection;predictive data analytics;stem cell transplant;unbalanced data","Data models;Mathematical model;Medical services;Numerical models;Stem cells;Support vector machines;Training","biology computing;blood;cellular biophysics;genetics;support vector machines","HLA-based matching algorithms;black box models;cost-sensitive SVM;donor selection;genetically compatible donors;hematopoietic stem cell transplant;historical-choice behavior;nonHLA donor attributes;secondary decision process;secondary selection process;selection consistency improvement","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Nearest Neighbor Minutia Quadruplets Based Fingerprint Matching with Reduced Time and Space Complexity","A. T. Rao; N. P. Ramaiah; V. R. Reddy; C. K. Mohan","Dept. of Comput. Sci. & Eng., Inidan Inst. of Technol. Hyderabad, Medak, India","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","378","381","The fingerprint biometric is often used as the primary source of person authentication in a large population person identity system because fingerprints have unique properties like distinctiveness and persistence. However, the large volumes of fingerprint data may lead to the scalability issues which are to be addressed in the context of memory and computational complexity. In this paper, an attempt is made to develop an efficient fingerprint matching algorithm using nearest neighbor minutia quadruplets (NNMQ). These minutia quadruplets are both rotation and translation invariant. Experimental results demonstrate that the proposed fingerprint matching algorithm achieves the reduced space and time complexities with the publicly available standard fingerprint benchmark databases FVC ongoing, FVC2000 and FVC2004.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424340","Fingerprint recognition;k-nearest neighbors;minutia quadruplets","Databases;Euclidean distance;Feature extraction;Fingerprint recognition;Probes;Signal processing algorithms","computational complexity;fingerprint identification;image matching","NNMQ;computational complexity;fingerprint biometric;fingerprint matching algorithm;nearest neighbor minutia quadruplets;person authentication;reduced time complexity;space complexity","","","","12","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"On Asymmetric Similarity Search","A. Garg; C. G. Enright; M. G. Madden","Coll. of Eng. & Inf., Nat. Univ. of Ireland, Galway, Galway, Ireland","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","649","654","Similarity, and the strongly related inverse concept of distance, plays an important role in many data mining techniques. Typically, the definitions of similarity/distance measures are restricted to being symmetric. In this paper, however, we consider asymmetric measures and show that there are justifiable reasons in many domains for preferring asymmetric measures. Our review of the literature indicates that these ideas have occasionally been considered in various guises, but not formalized. In this context, we use our proposed Contains concept to represent an asymmetric relation. We show how asymmetry can be introduced into some widely used binary similarity/distance measures and evaluate their performance on data sets from multiple domains. The results show that asymmetric Contains measures can yield better performance, and are never worse than the corresponding symmetric measures.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424392","asymmetry;distance metrics;similarity","Context;Frequency measurement;Informatics;Libraries;Object recognition;Weight measurement","data mining;search problems","asymmetric measures;asymmetric similarity search;binary similarity/distance measures;data mining;strongly related inverse concept","","","","39","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Hybrid Method for Intrusion Detection","Y. Canbay; S. Sagiroglu","Comput. Eng. Dept., Gazi Univ., Ankara, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","156","161","Intrusion Detection Systems (IDSs) are used to detect malicious actions on information systems such as computing and networking systems. Abnormal behaviors or activities on the network systems could be detected by security systems. But, conventional security systems such as anti-virus and firewall cannot be successful in many malicious actions. To overcome this problem, better and more intelligent IDS solutions are required. In this study, a hybrid approach was proposed to use to detect network attacks. Genetic Algorithm (GA) and K-Nearest Neighbor (KNN) methods were combined to model and detect the attacks. KNN was employed to classify the attacks and GA was used to select k neighbors of an attack sample. This hybrid system was first applied in intrusion detection field. The system provides advantages such as, decreasing dependency of full training data set and providing plausible solution for intrusion detection. The results showed that the proposed system provides better results than single system.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424302","Intrusion detection;genetic algorithm;k-nearest neighbor;network attacks","Biological cells;Classification algorithms;Genetic algorithms;Intrusion detection;Niobium;Support vector machines;Training","firewalls;genetic algorithms;pattern recognition","GA;KNN methods;anti-virus;firewall;genetic algorithm;hybrid method;hybrid system;information systems;intelligent IDS solutions;intrusion detection field;intrusion detection systems;k-nearest neighbor;malicious actions;security systems","","","","33","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Local Coordinate Projective Non-negative Matrix Factorization","Q. Liao; X. Zhang; N. Guan; Q. Zhang","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","604","607","Non-negative matrix factorization (NMF) decomposes a group of non-negative examples into both lower-rank factors including the basis and coefficients. It still suffers from the following deficiencies: 1) it does not always ensure the decomposed factors to be sparse theoretically, and 2) the learned basis often stays away from original examples, and thus lacks enough representative capacity. This paper proposes a local coordinate projective NMF (LCPNMF) to overcome the above deficiencies. Particularly, LCPNMF induces sparse coefficients by relaxing the original PNMF model meanwhile encouraging the basis to be close to original examples with the local coordinate constraint. Benefitting from both strategies, LCPNMF can significantly boost the representation ability of the PNMF. Then, we developed the multiplicative update rule to optimize LCPNMF and theoretically proved its convergence. Experimental results on three popular frontal face image datasets verify the effectiveness of LCPNMF comparing to the representative methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424383","Local coordinate factorization;Non-negative matrix factorization","Clustering algorithms;Convergence;Electronic mail;Linear programming;Matrix decomposition;Optimization;Sparse matrices","image sequences;learning (artificial intelligence);matrix decomposition;pattern clustering","LCPNMF;convergence;local coordinate projective NMF;local coordinate projective nonnegative matrix factorization;multiplicative update rule;sparse coefficient","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Statistical Downscaling of Climate Change Scenarios of Rainfall and Temperature over Indira Sagar Canal Command Area in Madhya Pradesh, India","R. Shukla; P. D. Khare; R. Deo","Dept. of Water Resources Dev. & Manage., Indian Inst. of Technol., Roorkee, Roorkee, India","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","313","317","General circulation models (GCMs) have been employed by climate agencies to predict future climate change. A challenging issue with GCM output for local relevance is their coarse spatial resolution of the projected variables. Statistical Downscaling Model (SDSM) identifies relationships between large-scale predictors (i.e., GCM-based) and local-scale predictands using multiple linear regression models. In this study (SDSM) was applied to downscale rainfall and temperature from GCMs. The data from single station located in the Indira Sagar canal command area at Madhya Pradesh, India were used as input of the SDSM. The study included calibration and validation with large-scale atmospheric variables encompassing the NCEP reanalysis data, the future estimation due to a climate scenario, which is HadCM3 A2. Results of the downscaling experiment demonstrate that during the calibration and validation stages, the SDSM model can be well acceptable regard its performance in the downscaling of daily rainfall and temperature. For a future period (2010-2099), the SDSM model estimated an increase in total average annual rainfall and annual average temperature for station. This indicates that the area of station considered will be wet and humid in the future. Also, the mean temperature is projected to rise to 1.5 C to 2.5 C for present study area. However, the model projections show a rise in mean daily precipitation with varying percentage in the months of July (0.59% to 2.09%) and August (0.79% to 1.19) under A2 of HadCM3 model for future periods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424327","GCM data;SDSM;Scenario generation;Statistical downscaling;canal command","Atmospheric modeling;Calibration;Correlation;Meteorology;Ocean temperature;Predictive models;Temperature distribution","atmospheric temperature;climatology;rain;regression analysis;weather forecasting","AD 2010 to 2099;HadCM3 A2 model;India;Indira Sagar canal command area;Madhya Pradesh;NCEP reanalysis data;annual average temperature;climate change;daily rainfall;daily temperature;general circulation model;mean daily precipitation;multiple linear regression model;statistical downscaling model;total average annual rainfall","","","","14","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Basin Clustering of Turkey by Use of Monthly Stream-Flow Data","Y. Arslan; A. Birturk; S. Eren","Tubitak MAM Energy Inst. Ankara, Ankara, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1169","1174","Security of the energy supply is an important topic in energy field. It has two parts which are supply and demand. To ensure that demand is met, the supply at the specific time points has to be known or predicted. Supply is predicted by use of seasonal, yearly and regional information. The stream-flow dataset resolution is monthly and it supplies the yearly and seasonal information. The only missing part for supply prediction is the regional information. The aim of this study to find the basin based regional clustering of the streams and correspondingly hydroelectric power plants. In this paper, 14 out of 26 basins of Turkey, which contain over 80% of the hydroelectric power plants of Turkey in Dispatcher Information System, are clustered by use of different clustering techniques. Results are visualized on Turkey basin map.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424478","basin based clustering;dynamic time warping;hierarchical clustering;k-means;longest common subsequence;stream-flow rate","Correlation;Couplings;Electronic mail;Market research;Measurement;Power generation;Time series analysis","data analysis;electricity supply industry;hydroelectric power stations;pattern clustering;security","Turkey;basin clustering;energy supply security;hydroelectric power plants;monthly stream-flow data","","","","10","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Car Following Markov Regime Classification and Calibration","A. B. Zaky; W. Gomaa; M. A. Khamis","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1013","1018","The car following behavior has recently gained much attention due to its wide variety of applications. This includes accident analysis, driver assessment, support systems, and road design. In this paper, we present a model that leverages Markov regime switching models to classify various car following regimes. The detected car following regimes are then mined to calibrate the parameters of drivers to be dependent on the driver's current driving regime. A two stage Markov regime switching model is utilized to detect different car following regimes. The first stage discriminates normal car following regimes from abnormal ones, while the second stage classifies normal car following regimes to their fine-grained regimes like braking, accelerating, standing, free-flowing, and normal following. A genetic algorithm is then employed to the observed driver data in each car following regime to optimize car following model parameter values of the driver in each regime. Experimental evaluation of the proposed model using a real dataset shows that it can detect up-normal (rare and short time) events. In addition, it can infer the switching process dynamics such as the expected duration, the probability of moving from one regime to another and the switching parameters of each regime. Finally, the model is able to accurately calibrate the parameters of drivers according to their driving regimes, so we can achieve a better understanding of drivers behavior and better simulation of driving situation.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424453","Markov switching model;car following model;driver behavior;model calibration;regime classification","Acceleration;Data models;Hidden Markov models;Markov processes;Switches;Time series analysis;Vehicles","Markov processes;acceleration;automobiles;behavioural sciences computing;braking;data mining;driver information systems;genetic algorithms;pattern classification","abnormal car following regime;accelerating regime;braking regime;car following Markov regime classification;car following behavior;car following model parameter value optimization;driver behavior;driver parameter calibration;expected duration;fine-grained regimes;free-flowing regime;genetic algorithm;normal car following regime;normal following regime;rare-time event detection;regime switching parameters;short-time event detection;standing regime;switching process dynamics;two-stage Markov regime switching model;up-normal event detection","","","","24","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Vibration Learning and Control towards Vibration Actuated Robotic Systems","W. Y. Joe","Dept. of Mech. & Manuf. Eng., Tennessee State Univ., Nashville, TN, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","375","377","This paper presents in-process research and details vibration analysis of a single actuator that can be used for robotic navigation and locomotion. The key steps to potential success of this works are (1) static and dynamic vibration analysis of generalized shapes for robots, (2) studies on solid mechanics based vibration propagation into the structure of the robot, (3) development of active control schemes of vibration isolation for the robot's navigation and locomotion purposes, and (4) analysis, simulation and design of passive leg mechanism for vibration driven robotic systems. Here, the author introduces state-of-the-art vibration driven robotic systems in the field, basic equations for a simple off-centered rotation mechanism, model and simulation/test bed for vibration excitement, and introduction of active vibration control to one of control schemes for effective vibration isolation as preliminary work.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.225","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424339","active control;isolation;robot;vibration","Actuators;Damping;Legged locomotion;Mathematical model;Vibrations","learning systems;mobile robots;vibration isolation","actuator vibration analysis;dynamic vibration analysis;off-centered rotation mechanism;passive leg mechanism;robotic locomotion;robotic navigation;solid mechanics based vibration propagation;static vibration analysis;vibration actuated robotic systems;vibration control;vibration driven robotic systems;vibration isolation active control schemes;vibration learning","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Rejection Factors of Pull Requests Filed by Core Team Developers in Software Projects with High Acceptance Rates","D. M. Soares; M. L. d. L. Júnior; L. Murta; A. Plastino","Fed. Univ. of Acre, Rio Branco, Brazil","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","960","965","When developers want to contribute to an opensource project, they fork the repository, make changes, and send a pull request to the core team to incorporate these changes back into the repository. However, some projects enforce this collaboration model even for changes made by core team developers. This potentially enhances the quality of the repository by adding an inspection step before accepting a contribution into the repository. In this context, though less frequently, the contributions may be rejected. The understanding of the factors that lead to the rejection of these internal contributions is crucial for the improvement of the ways core developers collaborate, having a direct impact on the team productivity. In this work we extract association rules from pull request data stored in software repositories in order to find factors that have influence over the decision of rejecting contributions made by core developers. In addition, we present a qualitative analysis of some cases, helping to understand the patterns that arose from the association rules. The results indicate that some key factors increase the changes of having internal contributions rejected: (i) the inexperience with pull requests, (ii) the complexity of contributions, as well as the locality of the artifacts that have been modified, and (iii) the contribution policy of the projects.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424445","association rules;data mining;pull request;software engineering","Collaboration;Computational modeling;Context;Data mining;Databases;Measurement;Software","data mining;groupware;public domain software;software management","association rules;collaboration model;high acceptance rates;inspection step;opensource project;pull request data;rejection factors;software projects;software repositories","","","","11","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Lambda Consensus Clustering","D. R. Heisterkamp","Comput. Sci. Dept., Oklahoma State Univ., Stillwater, OK, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","410","413","This paper introduces an extension to consensus clustering that allows a feedback of the results of the consensus to the original clustering processes. The original clustering processes may use this information to update their partitioning of the data. An exponential weighting approach, called lambda consensus, is presented as a method to merged the consensus information into graph based and vector space based clustering algorithms. Successful consensus clustering is highly dependent on the quality and diversity of the partitions in the ensemble. The feedback signal allows the clustering processes to adapt their algorithms to attempt to improve quality and diversity of the set of partitions in the ensemble. Communication requirements are on the same order as consensus clustering as only the consensus labels are returned to the clustering processes. The method is evaluated on real world data sets.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424347","consensus clustering;ensemble clustering;k-means clustering;pinch ratio clustering","Clustering algorithms;Encoding;Kernel;Labeling;Partitioning algorithms;Privacy;Weight measurement","feedback;graph theory;pattern clustering;unsupervised learning;vectors","data partitioning;exponential weighting approach;feedback;graph based clustering algorithms;lambda consensus clustering;vector space based clustering algorithms","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Malware Detection in Android-Based Mobile Environments Using Optimum-Path Forest","K. A. P. d. Costa; L. A. d. Silva; G. B. Martins; G. H. Rosa; C. R. Pereira; J. P. Papa","Dept. of Comput., Sao Paulo State Univ., Bauru, Brazil","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","754","759","Nowadays, people use smartphones and tablets with the very same purposes as desktop computers: web browsing, social networking and home-banking, just to name a few. However, we are often facing the problem of keeping our information protected and trustworthy. As a result of their popularity and functionality, mobile devices are a growing target for malicious activities. In such context, mobile malwares have gained significant ground since the emergence and growth of smartphones and handheld devices, becoming a real threat. In this paper, we introduced a recently developed pattern recognition technique called Optimum-Path Forest in the context of malware detection, as well we present ""DroidWare"", a new public dataset to foster the research on mobile malware detection. In addition, we also proposed to use Restricted Boltzmann Machines for unsupervised feature learning in the context of malware identification.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424412","Malware Detection;Optimum-Path Forest;Restricted Boltzmann Machines","Feature extraction;Malware;Mobile communication;Prototypes;Smart phones;Training;Vegetation","Android (operating system);Boltzmann machines;Internet;banking;invasive software;mobile computing;pattern recognition;smart phones;social networking (online);unsupervised learning","Android-based mobile environments;DroidWare;Web browsing;desktop computers;home-banking;malware detection;optimum-path forest;pattern recognition;restricted Boltzmann machines;smartphones;social networking;unsupervised feature learning","","","","30","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Extracting Topical Information of Tweets Using Hashtags","Z. Z. Alp; S. G. Öðüdücü","Inst. of Sci. & Technol., Istanbul Tech. Univ., Istanbul, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","644","648","Twitter is one of the largest micro blogging web sites where users share news, their opinions, moods, recommendations by posting text messages, and it is mostly used like a news media. Since the data being shared via Twitter is vast, many researches are focusing on extracting meaningful information with the help of information retrieval systems. Retrieving meaningful information from social media applications became important for several tasks such as sentiment analysis, detecting anomalies, and recommendation systems. Topic modeling is one of the mostly studied and hard problems in information retrieval area, and it is even more challenging to model topics when the documents are too short such as tweets. In this paper, we focus on developing an effective and efficient method to overcome this challenge of tweets being too short for topic modeling. We compare different topic modeling schemes, one of which is not studied before, based on Latent Dirichlet Allocation (LDA) that merges tweets in order to improve LDA performance. We also demonstrate our experimental results with unbiased data collection and evaluation methodologies.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424391","","Data collection;Data mining;Market research;Media;Tagging;Twitter","information retrieval;sentiment analysis;social networking (online)","LDA;Twitter;anomalies detection;data collection;hashtags;information retrieval systems;latent Dirichlet allocation;microblogging Web sites;news media;recommendation systems;sentiment analysis;social media applications;text messages posting;topic modeling;topical information extraction;tweets","","1","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Coordinate Descent Fuzzy Twin Support Vector Machine for Classification","B. B. Gao; J. J. Wang; Y. Wang; C. Y. Yang","Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","7","12","In this paper, we develop a novel coordinate descent fuzzy twin SVM (CDFTSVM) for classification. The proposed CDFTSVM not only inherits the advantages of twin SVM but also leads to a rapid and robust classification results. Specifically, our CDFTSVM has two distinguished advantages: (1) An effective fuzzy membership function is produced for removing the noise incurred by the contaminant inputs. (2) A coordinate descent strategy with shrinking by active set is used to deal with the computational complexity brought by the high dimensional input. In addition, a series of simulation experiments are conducted to verify the performance of the CDFTSVM, which further supports our previous claims.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424278","Active set shrinking;Coordinate descent;Fuzzy;High-dimensional input;SVM;TSVM","Eigenvalues and eigenfunctions;Kernel;Matrices;Robustness;Support vector machines;Training","computational complexity;fuzzy set theory;pattern classification;support vector machines","CDFTSVM;active set shrinking;classification;computational complexity;contaminant inputs;coordinate descent fuzzy twin support vector machine;coordinate descent strategy;fuzzy membership function;noise removal","","","","20","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"State Tracking of Composite Delaminations with a Bayesian Filter","E. D. Gregory; S. D. Holland","Dept. of Aerosp. Eng., Iowa State Univ., Ames, IA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","600","603","We propose a method for tracking the condition of a composite part using Bayesian filtering of nondestructive evaluation (NDE) data over the lifetime of the part. NDE provides information about the state of a part or material without destroying or degrading the part. The Bayesian process builds on the lifetime history of NDE scans and can give better estimates of material condition compared to the most recent scan alone, which is the common practice in the aerospace industry. Bayesian inference provides probabilistic estimates of damage state that are updated as each new set of NDE data becomes available. The method is tested on simulated data and then on an experimental data set. Flash thermography NDE data was collected over the lifetime of a part to serve as a time history of that part. Computed tomography (CT) data was also collected after each damage event and provided a high resolution volume model of damage that acted as 'truth'. After each time point, the condition estimate was compared to 'ground truth' from CT to evaluate the performance of the thermography-based condition tracking.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424382","Bayesian Inference;Flash Thermography;Nondestructive Evaluation","Aerospace industry;Bayes methods;Computational modeling;Computed tomography;Data models;Delamination;Time measurement","Bayes methods;aerospace materials;composite materials;computerised tomography;condition monitoring;delamination;mechanical energy storage;mechanical engineering computing;nondestructive testing;production engineering computing;tracking filters","Bayesian filter;Bayesian inference;CT data;NDE scan lifetime history;aerospace industry;composite delaminations;computed tomography;damage state probabilistic estimates;flash thermography NDE data;ground truth;high-resolution volume model;nondestructive evaluation;state tracking;thermography-based condition tracking","","","","10","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Zero Shot Deep Learning from Semantic Attributes","P. M. Burlina; A. C. Schmidt; I. J. Wang","Johns Hopkins Univ. Appl. Phys. Lab., Laurel, MD, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","871","876","We study the problem of classifying images when no training exemplars are available for some image classes, and therefore direct classification is not possible. We use instead semantic attributes: if attributes of yet unseen classes can be determined, then class labels may themselves be decided based on prior knowledge of class to attributes relationships. We present several methods for determining attributes, including (A) an approach based on attribute classifiers, and approaches using (B) MAP and (C) MMSE attribute estimators using image classifiers for known classes. Preliminary tests obtained using a dataset comprised of ImageNet images and Human218 attributes yield encouraging performance.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424431","","Estimation;Neural networks;Semantics;Support vector machines;Taxonomy;Training;Visualization","image classification;learning (artificial intelligence);least mean squares methods","Human218;ImageNet images;MAP;MMSE;attribute classifiers;image classes;image classification;prior knowledge;semantic attributes;zero shot deep learning","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"An Application of Classification and Class Decomposition to Use Case Point Estimation Method","M. Azzeh; A. B. nassif; S. Banitaan","Dept. of Software Eng., Appl. Sci. Univ., Amman, Jordan","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1268","1271","Use Case Points (UCP) estimation method describes the process of computing the software project size and productivity from use case diagram elements. These metrics are then used to predict the project effort at early stage of software development. The main challenges with previous models are that they were constructed based on a very limited number of observations, and using limited productivity ratios. This paper presents a new approach to predict productivity from UCP environmental factors by applying classification with decomposition technique. A class decomposition provides a number of advantages to supervised learning algorithms through segmenting classes into more homogenous classes, and therefore, increase their diversity. The proposed model is constructed and validated over two datasets that have relatively sufficient number of observations. The accuracy results are promising and have potential to increase accuracy of early effort estimation.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424496","Classification;Clustering;Effort Prediction","Classification algorithms;Computational modeling;Environmental factors;Estimation;Predictive models;Productivity;Software","estimation theory;learning (artificial intelligence);software development management","UCP environmental factor;class decomposition;classification method;software development;software project size;supervised learning algorithm;use case diagram element;use case point estimation method","","1","","11","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Measuring Level-K Reasoning, Satisficing, and Human Error in Game-Play Data","T. Biswas; K. Regan","Dept. of CSE, Univ. at Buffalo, Amherst, NY, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","941","947","Inferences about structured patterns in human decision making have been drawn from medium-scale simulated competitions with human subjects. The concepts analyzed in these studies include level-k thinking, satisficing, and other human error tendencies. These concepts can be mapped via a natural depth of search metric into the domain of chess, where copious data is available from hundreds of thousands of games by players of a wide range of precisely known skill levels in real competitions. The games are analyzed by strong chess programs to produce authoritative utility values for move decision options by progressive deepening of search. Our experiments show a significant relationship between the formulations of level-k thinking and the skill level of players. Notably, the players are distinguished solely on moves where they erred -- according to the average depth level at which their errors are exposed by the authoritative analysis. Our results also indicate that the decisions are often independent of tail assumptions on higher-order beliefs. Further, we observe changes in this relationship in different contexts, such as minimal versus acute time pressure. We try to relate satisficing to insufficient level of reasoning and answer numerically the question, why do humans blunder?","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424442","Game theory;blunder;level-k thinking;satisficing.","Cognition;Complexity theory;Decision making;Engines;Games;Law","decision making;game theory;inference mechanisms","authoritative analysis;authoritative utility value;chess program;game-play data;human decision making;human error tendency;level-k reasoning;medium-scale simulated competition","","","","40","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Class Discovery via Bimodal Feature Selection in Unsupervised Settings","J. Curtis; M. Kon","Dept. of Math. & Stat., Boston Univ., Boston, MA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","699","702","In machine learning there are numerous supervised techniques that extend naturally to analogous unsupervised methods, such as clustering. In this paper, we consider so-called rare-weak models, in which the number of important features is small (or rare) and the signal strength of each important feature is minimal (or weak). When classical clustering is applied crudely in ""big data"" scenarios, significant problems can arise, including long computational run times and significant clustering errors. One solution is to use feature selection (FS) to reduce dataset dimensionality before clustering. We introduce two novel unsupervised feature selection methods, one parametric and one nonparametric, based on what we call bimodal feature selection. These methods produce ranked lists of features based on their univariate multi-modality. Unlike previously developed univariate FS methods, which have typically been restricted to 2-cluster scenarios, our method has been adapted and tested to discriminate binary and higher level clusterings. The method is particularly advantageous in rare-weak settings, since reducing data dimensionality allows classical clustering methods to be applied computationally faster and with greater accuracy.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424401","clustering;feature selection;unsupervised data","Clustering algorithms;Clustering methods;Electronic mail;Estimation;Kernel;Standards","Big Data;feature selection;learning (artificial intelligence);pattern clustering","2-cluster scenario;analogous unsupervised method;big data scenario;bimodal feature selection;binary level clustering;class discovery;classical clustering method;clustering error;data dimensionality;dataset dimensionality;higher level clustering;machine learning;rare-weak model;signal strength;supervised technique;univariate multimodality;unsupervised feature selection method;unsupervised setting","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Probabilistic Models for One-Day Ahead Solar Irradiance Forecasting in Renewable Energy Applications","C. V. A. Silva; L. Lim; D. Stevens; D. Nakafuji","Dept. of Inf. & Comp. Sci, Univ. of Hawai`i at Manoa, Honolulu, HI, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1163","1168","Solar irradiance forecasting is an important problem in renewable energy management where any dips in solar energy generation must be made up for by reserves in order to ensure an uninterrupted energy supply. In this paper, we study several data mining methods for short term solar irradiance forecasting at a given location. In particular, we apply linear regression, probabilistic models, and naive Bayes classifier to forecast solar irradiance one day ahead, i.e., we forecast what tomorrow's solar irradiance will be like at sundown today. We evaluate the forecasting performance of our adaptations of the three models using land-based weather data from several weather stations on the island of Oahu in Hawai'i.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424477","","Computational modeling;Data models;Forecasting;Meteorology;Predictive models;Probabilistic logic;Training data","Bayes methods;data mining;load forecasting;regression analysis;solar power","data mining methods;land-based weather data;linear regression;naive Bayes classifier;probabilistic models;renewable energy management;short term solar irradiance forecasting;solar energy generation;uninterrupted energy supply;weather stations","","","","11","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Learning Common Metrics for Homogenous Tasks in Traffic Flow Prediction","H. Hong; X. Zhou; W. Huang; X. Xing; F. Chen; Y. Lei; K. Bian; K. Xie","Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1007","1012","Nearest neighbor based nonparametric regression is a classic data-driven method for traffic flow prediction in intelligent transportation systems (ITS). Performances of those models depend heavily on the similarity or distance metric used to search nearest neighborhood. Metric learning algorithms have been developed to learn the distance metrics from data in recent years. In real-world transportation application, multiple forecasting tasks are set since there are lots of road sections and detector points in the traffic network. Previous works tend to learn only one global metric to be used for all the tasks or learn multiple local metrics for each task which may lead to under-fitting or over-fitting problem. To balance these two kinds of methods and improve the generalization of learned metrics, we propose a common metric learning algorithm under the intuition that homogenous tasks tend to have similar local metrics. Then the learned common metrics are used in common metric KNN (CM-KNN) for traffic flow prediction. Experimental results show that our algorithm to learn common metrics are reasonable and CM-KNN method for traffic flow prediction outperforms other competing methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424452","CM-KNN;Common Metric Learning;LCM;Metric Learning;Traffic Flow Prediction","Euclidean distance;Kernel;Prediction algorithms;Predictive models;Roads","intelligent transportation systems;learning (artificial intelligence);nonparametric statistics;regression analysis;road traffic;traffic engineering computing","CM-KNN;ITS;common metric learning algorithm;data-driven method;detector point;distance metrics;homogenous tasks;intelligent transportation system;nearest neighbor search;nonparametric regression;road section;traffic flow prediction","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Regularized Supervised Topic Model for Continuous Emotion Analysis","P. Lade; H. Venkateswara; S. Panchanathan","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","739","744","Dimension reduction techniques form the core of predictive analytics systems and they help us create a new feature space that is more helpful in predicting response variables. But these techniques do not necessarily guarantee a better predictive capability as most of them are unsupervised, especially in regression learning. In regression analysis literature, supervised dimension reduction techniques have not been explored much and in this work we provide a solution to this through probabilistic topic models. In this work, we have shown that the double mixture structure of Latent Dirichlet Allocation topic model helps us 1) to visualize feature patterns, and 2) to project features onto a topic simplex that is more predictive of responses, when compared to popular techniques like PCA and KernelPCA. Until now, topic models have not been explored in a supervised context of video analysis and in this work we introduce a Regularized supervised topic model (RSLDA) that models video and audio features and has outperformed supervised dimension reduction techniques like SPCA and Correlation based feature selection algorithms. All the models discussed in this work have been evaluated to predict continuous human emotions from video data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424409","Dimension Reduction;Regression Analysis;Topic Models","Analytical models;Computational modeling;Correlation;Predictive models;Principal component analysis;Testing;Training","emotion recognition;learning (artificial intelligence);probability;regression analysis","continuous emotion analysis;latent Dirichlet allocation topic model;predictive analytics system;probabilistic topic model;regression learning;regularized supervised topic model;supervised dimension reduction technique","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Example-Specific Density Based Matching Kernels for Scene Classification Using Support Vector Machines","A. Sachdev; V. Thenkanidiyoor; A. D. Dileep; C. C. Sekhar","Sch. of Comput. & Electr. Eng., Indian Inst. of Technol. Mandi, Mandi, India","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","122","127","In this paper, we propose the example-specific density based matching kernel (ESDMK) for classification of scene images represented as sets of local feature vectors. The proposed kernel is computed between the pair of examples, represented as sets of local feature vectors, by matching the estimates of example-specific densities computed at every local feature vector in those two examples. In this work, the number of local feature vectors of an example among the K nearest neighbors of a local feature vector is considered as an estimate of the example-specific density. The minimum of the two example-specific densities, one for each example, at a local feature vector is considered as the matching score. The ESDMK is then computed as the sum of the matching score computed at every local feature vector in a pair of examples. We also propose the spatial ESDMK (SESDMK) to include spatial information present in the scene images while matching the pair of scene images. Each of the scene images is divided spatially into a fixed number of regions. Then the SESDMK is computed as a combination of region specific ESDMKs that match the corresponding regions. We study the performance of the support vector machine (SVM) based classifiers using the proposed ESDMKs for scene classification and compare with that of the SVM-based classifiers using the state-of-the-art kernels for sets of local feature vectors.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424296","","Feature extraction;Histograms;Kernel;Maximum likelihood estimation;Semantics;Support vector machines;Visualization","image classification;image matching;support vector machines;vectors","K nearest neighbors;SVM based classifiers;example-specific density based matching kernels;local feature vectors;scene image classification;scene image matching;spatial ESDMK;support vector machines","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Summary Sentence Classification Using Stylometry","R. Shams; R. E. Mercer","Dept. of Comput. Sci., Univ. of Western Ontario, London, ON, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1220","1227","Summary sentence classification is an important step to generate document surrogates known as summary extracts. The quality of an extract depends much on the correctness of this step. We aim to classify potential summary sentences using a statistical learning method that models sentences according to a linguistic technique which examines writing styles, known as Stylometry. The sentences in documents are represented using a novel set of stylometric attributes. For learning, an innovative two-stage classification is set up that comprises two learners in subsequent steps: k-Nearest Neighbour and Naive Bayes. We train and test the learners with the newswire documents collected from two benchmark datasets, viz., the CAST and the DUC2002 datasets. Extensive experimentation strongly suggests that our method has outstanding performance for the single document summarization task. However, its performance is mixed for classifying summary sentences from multiple documents. Finally, comparisons show that our method performs significantly better than most of the popular extractive summarization methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424488","Summarization;classification;data mining;machine learning;natural language processing;stylometry;text mining","Benchmark testing;Complexity theory;Data mining;Indexes;Pragmatics;Semantics;Writing","Bayes methods;learning (artificial intelligence);pattern classification;statistical analysis;text analysis","CAST datasets;DUC2002 datasets;Naıve Bayes method;document summarization;document surrogate generation;innovative two-stage classification;k-nearest neighbour;linguistic technique;newswire documents;statistical learning method;stylometric attributes;stylometry;summary extracts;summary sentence classification","","","","32","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Model Shrinking for Embedded Keyword Spotting","M. Sun; V. Nagaraja; B. Hoffmeister; S. Vitaladevuni","Amazon.com, Inc., Cambridge, MA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","369","374","In this paper we present two approaches to improve computational efficiency of a keyword spotting system running on a resource constrained device. This embedded keyword spotting system detects a pre-specified keyword in real time at low cost of CPU and memory. Our system is a two stage cascade. The first stage extracts keyword hypotheses from input audio streams. After the first stage is triggered, hand-crafted features are extracted from the keyword hypothesis and fed to a support vector machine (SVM) classifier on the second stage. This paper focuses on improving the computational efficiency of the second stage SVM classifier. More specifically, select a subset of feature dimensions and merge the SVM classifier to a smaller size, while maintaining the keyword spotting performance. Experimental results indicate that we can remove more than 36% of the non-discriminative SVM features, and reduce the number of support vectors by more than 60% without significant performance degradation. This results in more than 15% relative reduction in CPU utilization.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424338","feature selection;keyword spotting;support vector merging","Decoding;Feature extraction;Hidden Markov models;Kernel;Merging;Speech recognition;Support vector machines","feature extraction;signal classification;speech processing;support vector machines","SVM classifier;embedded keyword spotting system;feature dimension;hand-crafted feature extraction;keyword hypothesis extraction;model shrinking;speech utterance;support vector machines","","","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Online Learning Algorithm for Collective LDA","X. Chen; J. Yao; Y. Wang; Y. Zhang","Shanghai Key Lab. of Digital Media Process. & Transmissions, Shanghai Jiao Tong Univ., Shanghai, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","251","258","Collective Latent Dirichlet Allocation (C-LDA) is proposed as an extension of LDA to simultaneously model multiple corpora from different domains in order to overcome bias of individual corpus. However, with large volume of document collections from various sources, it becomes challenging to achieve fast convergence for C-LDA. The high time complexity of C-LDA limits its application to real-world tasks. Luckily, online learning has shown promise for speeding up the convergence of LDA. In this paper, we propose to explore online learning for collective LDA (OVCLDA). We first develop an efficient variational inference algorithm for collective LDA and then extend it to the online learning framework. We perform experiments with various real-world corpora. Experimental results have shown that OVCLDA can learn comparable topics with C-LDA and better than Online LDA, and achieves comparable computational efficiency with Online LDA and is much more efficient than C-LDA.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424317","data mining;multi-corpora;online learning;topic model;variational inference","Analytical models;Approximation algorithms;Computational modeling;Convergence;Inference algorithms;Media;Resource management","computational complexity;convergence;data mining;inference mechanisms;learning (artificial intelligence)","OVCLDA;Online LDA;collective LDA;collective latent Dirichlet allocation;comparable topics learning;convergence;data mining;document collections;online learning algorithm;time complexity;variational inference algorithm","","","","20","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Efficient and Rotation Invariant Fingerprint Matching Algorithm Using Adjustment Factor","A. I. Khan; M. A. Wani","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1103","1110","This paper presents a new efficient and rotation invariant algorithm that makes use of local features forfingerprint matching. Minutiae points are first extracted from afingerprint image. Minutiae code mc, defined in this paper, is then generated for each extracted minutiae point. The proposed minutiae code is invariant to rotation of the fingerprint image. Adjustment factor (AF) is introduced to address the problem due to differences in a claimant fingerprint and a template fingerprint of the same person that may be present due to variations in inking or variations in pressure applied between a finger and the scanner. Adjustment factor is calculated from the minutiae code (mc) of the two fingerprints being matched. A two stage fingerprint matching process is proposed. During first stage only a few minutiae codes are checked to decide if the second stage of matching process is required. This makes the matching process faster. The proposed strategy is tested on a number of publicly available images (DB1 of FVC2004 database) and the results are promising.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424467","AFIS;Bifurcation;Fingerprint;Minutia Code;Minutiae;Ridge","Bifurcation;Databases;Feature extraction;Fingerprint recognition;Fingers;Image matching","feature extraction;fingerprint identification;image matching","AF;FVC2004 database;adjustment factor;claimant fingerprint;fingerprint image;minutiae code;minutiae points extraction;rotation invariant fingerprint matching algorithm;template fingerprint;two stage fingerprint matching process","","","","26","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Sequential Covariance-Matrix Estimation with Application to Mitigating Catastrophic Forgetting","T. Lancewicki; B. Goodrich; I. Arel","Dept. of Electr. Eng. & Comput. Sci., Univ. of Tennessee, Knoxville, TN, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","628","633","Catastrophic forgetting is a problem encountered with neural networks as well as other learning systems whereby past representations are lost as new representations are learned. It has been shown that catastrophic forgetting can be mitigated in neural networks by using a neuron selection technique, dubbed ""cluster-select,"" which performs online clustering over the network inputs to partition the network such that only a subset of neurons are used for a given input vector. Cluster-select can benefit by using Mahalanobis distance which relies on an inverse covariance estimate. Unfortunately, covariance estimation is problematic when lacking a very large number of samples relative to the number of input dimensions. One way to tackle this problem is through the use of a shrinkage estimator that offers a compromise between the sample covariance matrix and a well-conditioned matrix with the aim of minimizing the mean-squared error (MSE). In online environments, such as those in which catastrophic forgetting can occur, data arrives sequentially, requiring the covariance matrix to be estimated sequentially. Therefore, in this work we derive sequential update rules for the shrinkage estimator and approximate it's related inverse. The online covariance estimator is applied to the cluster-select technique with results that demonstrate further improvements in terms of effectively mitigating catastrophic forgetting.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424388","","Covariance matrices;Eigenvalues and eigenfunctions;Estimation;Manganese;Neural networks;Neurons;Training","covariance matrices;learning (artificial intelligence);neural nets","MSE minimization;Mahalanobis distance;catastrophic forgetting mitigation;cluster-select technique;learning systems;mean-squared error minimization;neural networks;neuron selection technique;representation learning;sequential covariance-matrix estimation;shrinkage estimator","","","","27","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"An Industrial-Strength Pipeline for Recognizing Fasteners","N. Sephus; S. Bhagavatula; P. Shastri; E. Gabriel","Partpic Inc., Atlanta, GA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","781","786","Image classification and computer vision for search are rapidly emerging in today's technology and consumer markets. Specifically, startup companies have leveraged state-of-the-art image search capabilities in automating recognition of logos and titles, pop-up advertisements based on video content, and recommendations of products in the fashion industry. Partpic focuses on image search for replacement parts, and we present our industrial pipeline for such, with application to fasteners. We discuss how we have aimed to overcome issues such as acquiring enough training data, training and classification of many different types of fasteners, identification of customized specifications of fasteners (such as finish type, dimensions, etc.), establishing constraints for the user to take an good-enough image, and scalability of many pieces of data associated with thousands of fasteners.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424417","fasteners;image recognition;industrial;machine learning","Computer vision;Databases;Fasteners;Image recognition;Image segmentation;Imaging;Training","advertising data processing;computer vision;fasteners;image classification;image retrieval;learning (artificial intelligence);object recognition;pipelines","automatic logo recognition;automatic title recognition;computer vision;consumer markets;customized specification identification;fashion industry;fastener classification;fastener recognition;fastener training;good-enough image;image classification;image search;industrial pipeline;industrial-strength pipeline;pop-up advertisements;product recommendation;replacement parts;training data;video content","","","","8","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Does the Inclusion of Data Sampling Improve the Performance of Boosting Algorithms on Imbalanced Bioinformatics Data?","A. Fazelpour; T. M. Khoshgoftaar; D. J. Dittman; A. Napolitano","Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","527","534","Bioinformatics datasets contain many challenging characteristics, such as class imbalance, which adversely impacts the performance of supervised classification models built on these datasets. Techniques such as ensemble learning and data sampling from the domain of data mining can be deployed to alleviate the problem and to improve the classification performance. In this study, we sought to seek whether inclusion of data sampling within the ensemble framework can further improve the performance of classification models. To this end, we performed an experimental study using two newly hybrid ensemble techniques, one integrates feature selection within the boosting process and the other incorporates random under-sampling followed by feature selection within the boosting framework, two learners, three forms of feature rankers, and four feature subset sizes on 15 highly imbalanced bioinformatics datasets. Our results and statistical analysis demonstrate that the difference between the two boosting methods is statistically insignificant. Therefore, as the inclusion of data sampling has no significant positive effect on the performance of ensemble classifiers, it is not required to achieve maximum classification performance. To our knowledge, this is the first empirical study that examined the effects of data sampling, random under-sampling, to enhance classification performance of boosting algorithm for highly imbalanced bioinformatics data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424370","Boosting;bioinformatics;class imbalance;data sampling;ensemble learning","Bioinformatics;Boosting;Buildings;Data mining;Data models;Measurement;Training","bioinformatics;data mining;feature selection;learning (artificial intelligence);pattern classification;statistical analysis","boosting algorithm;data mining;data sampling;ensemble classifier performance;ensemble framework;feature ranker;feature selection;hybrid ensemble technique;imbalanced bioinformatics data;random undersampling;statistical analysis;supervised classification model","","","","30","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Predicting Churn of Expert Respondents in Social Networks Using Data Mining Techniques: A Case Study of Stack Overflow","I. Adaji; J. Vassileva","Univ. of Saskatchewan, Saskatoon, SK, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","182","189","In Q&A social networks, the few respondents that answer most of the questions are an asset to that network. Being able to predict the churn of these expert respondents will enable the owners of such network put things in place in order to keep them. In this paper, we predicted the churn of expert respondents in Stack Overflow. We identified experts based on the InDegree of the respondents and the value of the incentives earned by these experts from the questions they have answered in the past. Using four data mining techniques: logistic regression, neural networks, support vector machines and random forests, we predicted user churn and evaluated our results with four evaluation metrics: percentage correctly classified, area under receiver operating characteristic curve, precision and recall. Of the four data mining algorithms, random forests performed best with PCC of 76%, ROC area of 0.82, precision of 0.76 and recall of 0.77.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424306","Churn prediction;data mining;social networks","Algorithm design and analysis;Classification algorithms;Data mining;Logistics;Measurement;Prediction algorithms;Social network services","data mining;logistics;neural nets;regression analysis;social networking (online);support vector machines","Q&A;data mining techniques;expert respondents;logistic regression;neural networks;random forests;social networks;stack overflow;support vector machines","","1","","31","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"NewsCubeSum: A Personalized Multidimensional News Update Summarization System","D. Wang; L. Li; T. Li","Dept. of Copm. & Elc. Eng. & Comput., Sci. Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","981","986","Popular online publishers produce huge amount of news articles every day, so it is important to summarize the most up-to-the-minute information to help users quickly know the progresses of their interested news events. In this paper, we develop NewsCubeSum, a novel personalized news summarization system utilizing OLAP and supervised sentence selection techniques to generate brief summaries delivering news updates in multiple dimensions (such as time, entity, and topic). An illustrative case study and experimental results on summarization performance comparisons are provided to show the effectiveness of NewsCubeSum.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424448","","Conferences;DH-HEMTs;Integrated circuits","Internet;data mining;information retrieval;natural language processing;text analysis","NewsCubeSum;OLAP;brief summary;news articles;news events;online publishers;personalized multidimensional news update summarization system;supervised sentence selection technique;up-to-the-minute information","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Comparative Evaluation of Top-N Recommenders in e-Commerce: An Industrial Perspective","D. Paraschakis; B. J. Nilsson; J. Holländer","Dept. of Comput. Sci., Malmo Univ., Malmo, Sweden","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1024","1031","We experiment on two real e-commerce datasets and survey more than 30 popular e-commerce platforms to reveal what methods work best for product recommendations in industrial settings. Despite recent academic advances in the field, we observe that simple methods such as best-seller lists dominate deployed recommendation engines in e-commerce. We find our empirical findings to be well-aligned with those of the survey, where in both cases simple personalized recommenders achieve higher ranking than more advanced techniques. We also compare the traditional random evaluation protocol to our proposed chronological sampling method, which can be used for determining the optimal time-span of the training history for optimizing the performance of algorithms. This performance is also affected by a proper hyperparameter tuning, for which we propose golden section search as a fast alternative to other optimization techniques.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424455","collaborative filtering;e-commerce;hyperparameter optimization;implicit feedback;recommender systems;recommender systems survey","Algorithm design and analysis;Engines;History;Measurement;Recommender systems;Testing;Training","electronic commerce;optimisation;recommender systems;sampling methods","chronological sampling method;comparative evaluation;e-commerce dataset;hyperparameter tuning;industrial setting;optimization technique;product recommendation;random evaluation protocol;recommendation engine;top-N recommender","","","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Non-parametric Hidden Markov Clustering Model with Applications to Time Varying User Activity Analysis","W. Wei; C. Liu; M. Y. Zhu; S. A. Matei","Dept. of Stat., Purdue Univ., West Lafayette, IN, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","549","554","Activity data of individual users on social media are easily accessible in this big data era. However, proper modeling strategies for user profiles have not been well developed in the literature. Existing methods or models usually have two limitations. The first limitation is that most methods target the population rather than individual users, and the second is that they cannot model non-stationary time-varying patterns. Different users in general demonstrate different activity modes on social media. Therefore, one population model may fail to characterize activities of individual users. Furthermore, online social media are dynamic and ever evolving, so are users' activities. Dynamic models are needed to properly model users' activities. In this paper, we introduce a non-parametric hidden Markov model to characterize the time-varying activities of social media users. An EM algorithm has been developed to estimate the parameters of the proposed model. In addition, based on the proposed model, we develop a clustering method to group users with similar activity patterns.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424373","B-spline;Clustering;EM Algorithm;Hidden Markov Model;Nonparametric;User Profile Modeling","Analytical models;Clustering algorithms;Data models;Hidden Markov models;Mathematical model;Media;Splines (mathematics)","expectation-maximisation algorithm;hidden Markov models;pattern clustering;social networking (online)","Big Data;EM algorithm;activity modes;activity patterns;dynamic models;expectation-maximization algorithm;nonparametric hidden Markov clustering model;online social media;parameters estimation;population model;time varying user activity analysis","","","","27","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Statistical Fault Localization Based on Importance Sampling","A. S. Namin","Comput. Sci. Dept., Texas Tech Univ. Lubbock, Lubbock, TX, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","58","63","This paper presents a novel probabilistic approach for the fault localization challenge based on importance sampling. The iterative approach utilizes test results and execution profiles to estimate the likelihood of suspiciousness of program statements. Over a few iterations of probability updates and sampling, the procedure directs its attention towards those statements that are more likely to be faulty. The proposed approach is designed to be more sensitive to failing test cases in comparison to passing test cases. The effectiveness of the proposed stochastic approach is evaluated through two case studies and the results are compared against other popular fault localization methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424286","Fault Localization;Importance Sampling","Debugging;Iterative methods;Measurement;Monte Carlo methods;Probabilistic logic;Probability distribution","fault diagnosis;importance sampling;iterative methods;probability;statistical analysis","importance sampling;iterative approach;probabilistic approach;program statements;statistical fault localization","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"An Asynchronous Implementation of the Limited Memory CMA-ES","V. Arkhipov; M. Buzdalov; A. Shalyto","ITMO Univ., St. Petersburg, Russia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","707","712","We present our asynchronous implementation of the LM-CMA-ES algorithm, which is a modern evolution strategy for solving complex large-scale continuous optimization problems. Our implementation brings the best results when the number of cores is relatively high and the computational complexity of the fitness function is also high. The experiments with benchmark functions show that it is able to overcome its origin on the Sphere function, reaches certain thresholds faster on the Rosenbrock and Ellipsoid function, and surprisingly performs much better than the original version on the Rastrigin function.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424403","CMA-ES;asynchronous algorithms;parallel algorithms","Algorithm design and analysis;Benchmark testing;Computational complexity;Convergence;Covariance matrices;Optimization","computational complexity;covariance matrices;evolutionary computation","LM-CMA-ES algorithm;Rastrigin function;Rosenbrock function;asynchronous implementation;benchmark function;complex large-scale continuous optimization problem;computational complexity;ellipsoid function;evolution strategy;fitness function;limited memory CMA-ES;sphere function","","1","","8","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Two-Step Dynamic Inventory Forecasting Model for Large Manufacturing","Q. Zhou; R. Han; T. Li","Autom. Dept., Xiamen Univ., Xiamen, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","749","753","Inventory forecasting aims to predict the demand of a specific item in the future and reserve the amount of item based on the forecasting results. An accurate and reliable inventory prediction can avoid product overstock and greatly reduce the maintenance cost. Inventory data is a kind of time series data, which has its own characteristics of large volume, long time span, wide covering range and poor regularity. The existing inventory forecasting methods usually only consider the contemporary data or similar goods historical data and achieve the prediction by calculating past average, which cannot capture the complex characteristics, such as long term trend, periodic, and special events. In this work, we treat inventory management as a data mining problem and propose a two-step dynamic prediction model, which first adopts six machine learning techniques and combines them with time series analysis methods to obtain a forecasting basis, then takes into account multiple factors of inventory to fulfill a dynamic inventory forecasting. Moreover, our proposed dynamic forecasting model, as one of core algorithms, is incorporated into an intelligent inventory management system. The experimental results and practical application demonstrate the effectiveness and efficiency of our proposed method.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424411","","Conferences","costing;data mining;forecasting theory;inventory management;learning (artificial intelligence);maintenance engineering;manufacturing systems;production engineering computing;time series","Inventory data;data mining problem;intelligent inventory management system;inventory management;inventory prediction;large manufacturing;machine learning techniques;maintenance cost;product overstock;time series analysis methods;time series data;two-step dynamic inventory forecasting model;two-step dynamic prediction model","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"SMS Spam Filtering Through Optimum-Path Forest-Based Classifiers","D. Fernandes; K. A. P. d. Costa; T. A. Almeida; J. P. Papa","Dept. of Comput., Sao Paulo State Univ., Bauru, Brazil","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","133","137","In the past years, SMS messages have shown to be a profitable revenue to the cell-phone industries, being one of the most used communication systems to date. However, this very same scenario has led spammers to concentrate their attentions into spreading spam messages through SMS, thus achieving some success due to the lack of proper tools to cope with this problem. In this paper, we introduced the Optimum-Path Forest classifier to the context of spam filtering in SMS messages, as well as we compared it against with some state-of-the-art supervised pattern recognition techniques. We have shown promising results with an user-friendly classifier, which requires minimum user interaction and less knowledge about the dataset.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424298","Optimum-Path Forest;SMS Spam","Bayes methods;Context;Feature extraction;Measurement;Probability density function;Prototypes;Training","electronic messaging;information filtering;learning (artificial intelligence);pattern classification;unsolicited e-mail","SMS messages;SMS spam filtering;cell-phone industries;communication systems;minimum user interaction;optimum-path forest classifier;profitable revenue;spam messages","","","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"VISAGE: A Support Vector Machine Approach to Group Dynamic Analysis","A. Ravichander; S. Vijay; V. Ramaseshan; S. Natarajan","Dept. of Comput. Sci. & Eng., PES Inst. of Technol., Bangalore, India","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","640","643","A group is defined as a collective entity usually consisting of two or more individuals each connected by social relationships. The term 'group dynamics' was originally coined by social psychologist Kurt Lewin to describe the positive and negative forces within groups of people. Its study is useful today in a wide variety of applications such as gaining a better understanding of decision making behavior or evaluating the health of workplace environments. Metrics need to be defined to measure the quality of relations in a group by performing an analysis on each individual member of the group. Previous research in the field performs this through the means of surveying (generally through questionnaires) each member of the group. In this project we propose a novel method to analyze group dynamics from a single static image by performing automated facial expression recognition.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424390","Action Units;Facial Expression Recognition;Group Dynamics;Support Vector Machines","Dynamics;Face;Face recognition;Feature extraction;Indexes;Measurement;Support vector machines","face recognition;social sciences computing;support vector machines","VISAGE approach;automated facial expression recognition;decision making behavior;group dynamic analysis;relations quality measure;social relationships;support vector machine approach;workplace environment","","","","6","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Feature Selection Using Gustafson-Kessel Fuzzy Algorithm in High Dimension Data Clustering","G. Georgiev; N. Gueorguieva; M. Chiappa; A. Krauza","Comput. Sci. Dept., Univ. of Wisconsin, Oshkosh, WI, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1","6","The performance of objective function-based fuzzy clustering algorithms depends on the shape and the volume of clusters, the initialization of clustering algorithm, the distribution of the data objects, and the number of clusters in the data. Feature selection is also one of the most important issues in high dimension data clustering specifically in bioinformatics, data mining, signal processing etc., where the feature space dimension tends to be very large, making both clustering and classification tasks very difficult. It is evident that the feature subset needed to successfully perform a given clustering and recognition task depends on the discriminatory qualities of the chosen features. We propose a new hybrid approach addressing feature selection, based on informative weights, which takes into account the membership degrees of the features performed by Gustafson-Kessel fuzzy algorithm. The purpose is to efficiently achieve high degree of dimensionality reduction and enhance or maintain predictive accuracy with selected features. The candidate feature subsets are generated by using iterative feature elimination procedure which results in estimation of feature informative weights. We use both supervised and unsupervised methods in order to evaluate the clustering abilities of feature subsets.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424277","cluster validation;feature selection;fuzzy clustering;informative weight","Classification algorithms;Clustering algorithms;Covariance matrices;Filtering algorithms;Indexes;Partitioning algorithms;Signal processing algorithms","feature selection;fuzzy set theory;iterative methods;pattern clustering","Gustafson-Kessel fuzzy algorithm;clustering algorithm initialization;data cluster;data object distribution;feature informative weights estimation;feature selection;feature space dimension;high dimension data clustering;informative weights;iterative feature elimination procedure;membership degree;objective function-based fuzzy clustering algorithm","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"What to Learn Next: Recommending Commands in a Feature-Rich Environment","S. Zolaktaf; G. C. Murphy","Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1038","1044","Despite an abundance of commands to make tasks easier to perform, the users of feature-rich applications, such as development environments, use only a fraction of the commands available. Earlier work has shown that command recommendation -- in which, given the command usage history of a set of users, the objective is to predict a command that is likely useful for the user to learn -- can improve the usage of a range of commands available within such applications. In this paper, we present a new algorithm, CoDis, which is built upon three hypotheses. First, we hypothesize that in feature-rich applications there exists co-occurrence patterns between commands. Second, we hypothesize that users of feature-rich applications have prevalent discovery patterns. Finally, we hypothesize that users need different recommendations based on the time elapsed between their last activity and the time of recommendation. We show on data submitted by many users of an integrated development environment (Eclipse) that CoDis outperforms existing approaches: compared to ADAGRAD, the best performing baseline, it achieves an improvement of 10.22% in recall, for a top-N recommendation task (N = 20).","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424457","","Collaboration;Computational modeling;Computer science;Documentation;History;Recommender systems;Software","data mining;recommender systems;software engineering","CoDis algorithm;Eclipse integrated development environment;command recommendation;feature-rich applications;pattern discovery;top-N recommendation task","","","","19","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Topic Novelty Detection Using Infinite Variational Inverted Dirichlet Mixture Models","W. Fan; N. Bouguila","Dept. of Comput. Sci. & Technol., Huaqiao Univ., Xiamen, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","70","75","We propose model-based inference for topic novelty detection using a non-parametric Bayesian probability model. The probability model is a Dirichlet process mixture of inverted Dirichlet distributions which can be viewed as an infinite mixture model. The inference is based on variational Bayes deployed using approximate conjugate priors to the inverted Dirichlet. Detailed experimental study demonstrates the merits of our approach and shows that it gives good description of the data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424288","Dirichlet process;Inverted Dirichlet;mixture model;nonparametric Bayesian;topic novelty detection;variational Bayes","Bayes methods;Buildings;Computational modeling;Data models;Inference algorithms;Mixture models","Bayes methods;data mining;inference mechanisms","Dirichlet process mixture;approximate conjugate priors;infinite variational inverted Dirichlet mixture models;inverted Dirichlet distributions;model-based inference;nonparametric Bayesian probability model;topic novelty detection;variational Bayes","","","","31","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Study of How the Integration of Artificial Neural Network and Genetic Algorithm Should Be Made for Modeling Meteorological Data","T. M. Ventura; A. G. d. Oliveira; C. A. Martins; J. M. d. Figueiredo; R. d. S. R. Gomes","Inst. of Comput., Fed. Univ. of Mato Grosso Cuiaba, Cuiaba, Brazil","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","719","722","Artificial Neural Networks (ANN) have been widely used to model several types of data. The precision of ANN models is dependent upon their configuration, i.e., input parameters, training algorithm and architecture configurations. The problem lies in the amount of possible combinations of these parameters which results in countless unique ANNs. One method of finding a good combination of ANN parameters is to use a Genetic Algorithm (GA). Several studies combine a GA with an ANN to solve problems, however, it is not clear which parameters of an ANN the GA should determine. This work performed thousands of tests to verify the best combinations of parameters to use in integrations between GA and ANN especially in modeling meteorological data. Results have shown that the best approach is to use GA to define the input variables, activation function and the number of neurons of the ANN. Other tests showed that this same combination had similar results with different types of data indicating that this work can perhaps be applied to several types of problems.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424405","network topology;neuroevolution;weather data","Artificial neural networks;Biological neural networks;Data models;Genetic algorithms;Input variables;Neurons;Training","genetic algorithms;geophysics computing;meteorology;neural nets","ANN parameter;activation function;architecture configuration;artificial neural network;genetic algorithm;input parameter;meteorological data;training algorithm","","","","19","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Optimizing Attack Surface and Configuration Diversity Using Multi-objective Reinforcement Learning","B. Tozer; T. Mazzuchi; S. Sarkani","Dept. of Eng. Manage. & Syst. Eng., George Washington Univ., Washington, DC, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","144","149","Minimizing the attack surface of a system and introducing diversity into a system are two effective ways to improve system security. However, determining how to include diversity in a system without increasing the attack surface more than necessary is a difficult problem, requiring knowledge about the system characteristics, operating environment, and available permutations that is generally not available prior to system deployment. We propose viewing a system's components, interfaces, and communication channels as a set of states and actions that can be analyzed using a sequential decision making process, and using a multi-objective reinforcement learning algorithm to learn a set of policies that minimize a system's attack surface and execute those policies to obtain configuration diversity while a system is operating. We describe a methodology for designing a system such that its components and behaviors can be translated into a multi-objective Markov Decision Process, demonstrate the use of multi-objective reinforcement learning to learn a set of optimal policies using three different multi-objective reinforcement learning algorithms in the context of an online file sharing application, and show that our multi-objective temporal difference afterstate algorithm outperforms the alternatives for the example problem.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424300","cybersecurity;moving target defense;multi-objective reinforcement learning","Algorithm design and analysis;Communication channels;Computer architecture;Learning (artificial intelligence);Markov processes;Security;Surface treatment","Markov processes;decision making;learning (artificial intelligence);security of data","configuration diversity;multiobjective Markov decision process;multiobjective reinforcement learning algorithm;multiobjective temporal difference;online file sharing application;sequential decision making process;system attack surface;system security","","","","24","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Nonparametric Bayesian Modeling for Automated Database Schema Matching","E. Ferragut; J. Laska","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","82","88","The problem of merging databases arises in many government and commercial applications. Schema matching, a common first step, identifies equivalent fields between databases. We introduce a schema matching framework that builds nonparametric Bayesian models for each field and compares them by computing the probability that a single model could have generated both fields. Our experiments show that our method is more accurate and faster than the existing instance-based matching algorithms in part because of the use of nonparametric Bayesian models.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424290","","Bayes methods;Computational modeling;Data integration;Databases;Government;Metadata","Bayes methods;database management systems","automated database schema matching;instance-based matching algorithm;nonparametric Bayesian modeling","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"The Effect of Dataset Size on Training Tweet Sentiment Classifiers","J. Prusa; T. M. Khoshgoftaar; N. Seliya","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","96","102","Using automated methods of labeling tweet sentiment, large volumes of tweets can be labeled and used to train classifiers. Millions of tweets could be used to train a classifier, however, doing so is computationally expensive. Thus, it is valuable to establish how many tweets should be utilized to train a classifier, since using additional instances with no gain in performance is a waste of resources. In this study, we seek to find out how many tweets are needed before no significant improvements are observed for sentiment analysis when adding additional instances. We train and evaluate classifiers using C4.5 decision tree, Naïve Bayes, 5 Nearest Neighbor and Radial Basis Function Network, with seven datasets varying from 1000 to 243,000 instances. Models are trained using four runs of 5-fold cross validation. Additionally, we conduct statistical tests to verify our observations and examine the impact of limiting features using frequency. All learners were found to improve with dataset size, with Naïve Bayes being the best performing learner. We found that Naïve Bayes did not significantly benefit from using more than 81,000 instances. To the best of our knowledge, this is the first study to investigate how learners scale in respect to dataset size with results verified using statistical tests and multiple models trained for each learner and dataset size. Additionally, we investigated using feature frequency to greatly reduce data grid size with either a small increase or decrease in classifier performance depending on choice of learner.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424292","Big Data;Classification;Sentiment Analysis;Tweet Mining","Decision trees;Labeling;Sentiment analysis;Tagging;Training;Training data;Twitter","Bayes methods;decision trees;pattern classification;radial basis function networks;sentiment analysis;social networking (online)","5 nearest neighbor;C4.5 decision tree;data grid size reduction;dataset size effect;feature frequency;naive Bayes;radial basis function network;sentiment analysis;statistical tests;tweet sentiment classifiers training","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"ABC-sampling for Balancing Imbalanced Datasets Based on Artificial Bee Colony Algorithm","A. Braytee; F. K. Hussain; A. Anaissi; P. J. Kennedy","Center Quantum Comput. & Intell. Syst., Univ. of Technol. Sydney, Sydney, NSW, Australia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","594","599","Class imbalanced data is a common problem for predictive modelling in domains such as bioinformatics. It occurs when the distribution of classes is not uniform among samples and results in a biased prediction of learning towards majority classes. In this study, we propose the ABC-Sampling algorithm based on a swarm optimization method called Artificial Bee Colony, which models the natural foraging behaviour of honeybees. Our algorithm lessens the effects of imbalanced classes by selecting the most informative majority samples using a forward search and storing them in a ranked subset. Then we construct a balanced dataset with a planned undersampling strategy to extract the most frequent majority samples from the top ranked subset and combine them with all minority samples. Our algorithm is superior to a state-of-the-art method on nine benchmark datasets with various levels of imbalance ratios.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424381","","Genetic algorithms;Particle swarm optimization;Partitioning algorithms;Prediction algorithms;Silicon;Standards;Training","evolutionary computation;pattern classification;sampling methods;support vector machines","ABC-sampling algorithm;artificial bee colony algorithm;bioinformatics;honeybees natural foraging behaviour;imbalance ratio;imbalanced dataset balancing;predictive modelling;swarm optimization method;undersampling strategy","","","","19","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Recognizing Human Activities from Raw Accelerometer Data Using Deep Neural Networks","L. Zhang; X. Wu; D. Luo","Dept. of Machine Intell., Peking Univ., Beijing, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","865","870","Activity recognition from wearable sensor data has been researched for many years. Previous works usually extracted features manually, which were hand-designed by the researchers, and then were fed into the classifiers as the inputs. Due to the blindness of manually extracted features, it was hard to choose suitable features for the specific classification task. Besides, this heuristic method for feature extraction could not generalize across different application domains, because different application domains needed to extract different features for classification. There was also work that used auto-encoders to learn features automatically and then fed the features into the K-nearest neighbor classifier. However, these features were learned in an unsupervised manner without using the information of the labels, thus might not be related to the specific classification task. In this paper, we recommend deep neural networks (DNNs) for activity recognition, which can automatically learn suitable features. DNNs overcome the blindness of hand-designed features and make use of the precious label information to improve activity recognition performance. We did experiments on three publicly available datasets for activity recognition and compared deep neural networks with traditional methods, including those that extracted features manually and auto-encoders followed by a K-nearest neighbor classifier. The results showed that deep neural networks could generalize across different application domains and got higher accuracy than traditional methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424430","accelerometer data;activity recognition;deep neural networks;feature learning","Acceleration;Accelerometers;Decision trees;Feature extraction;Neural networks;Testing;Training","accelerometers;data analysis;neural nets;pattern classification","DNN;K-nearest neighbor classifier;accelerometer data;auto-encoders;deep neural networks;human activity recognition","","1","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Evaluating Real-Time Anomaly Detection Algorithms -- The Numenta Anomaly Benchmark","A. Lavin; S. Ahmad","Numenta, Inc., Redwood City, CA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","38","44","Much of the world's data is streaming, time-series data, where anomalies give significant information in critical situations, examples abound in domains such as finance, IT, security, medical, and energy. Yet detecting anomalies in streaming data is a difficult task, requiring detectors to process data in real-time, not batches, and learn while simultaneously making predictions. There are no benchmarks to adequately test and score the efficacy of real-time anomaly detectors. Here we propose the Numenta Anomaly Benchmark (NAB), which attempts to provide a controlled and repeatable environment of open-source tools to test and measure anomaly detection algorithms on streaming data. The perfect detector would detect all anomalies as soon as possible, trigger no false alarms, work with real-world time-series data across a variety of domains, and automatically adapt to changing statistics. Rewarding these characteristics is formalized in NAB, using a scoring algorithm designed for streaming data. NAB evaluates detectors on a benchmark dataset with labeled, real-world time-series data. We present these components, and give results and analyses for several open source, commercially-used algorithms. The goal for NAB is to provide a standard, open source framework with which the research community can compare and evaluate different algorithms for detecting anomalies in streaming data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424283","anomaly detection;benchmarks;streaming data;time-series data","Algorithm design and analysis;Benchmark testing;Detection algorithms;Detectors;Measurement;Real-time systems;Standards","public domain software;real-time systems;security of data;time series","NAB;Numenta anomaly benchmark;commercially-used algorithms;data streaming;open-source tools;real-time anomaly detection algorithms;statistics;time-series data","","1","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Using Bipartite Anomaly Features for Cyber Security Applications","E. Goodman; J. Ingram; S. Martin; D. Grunwald","Sandia Nat. Labs., Albuquerque, NM, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","301","306","In this paper we use anomaly scores derived from a technique for bipartite graphs as features for a supervised machine learning algorithm for two cyber security problems: classifying Short Message Service (SMS) text messages as either spam or non-spam and detecting malicious lateral movement within a network. While disparate problems, both spam and lateral movement detection can be viewed as bipartite graphs and we can compute bipartite anomaly scores for each situation. The bipartite anomaly scores by themselves are not very predictive, but used as auxiliary features can boost the receiver operating characteristic (ROC) curve of a supervised classifier. We examine the UCI SMS Spam Collection Data Set for the SPAM problem and use an authentication graph from Los Alamos National Laboratory. We create features by dimensionality reduction through principal component analysis (PCA) on the message-term or user-computer matrix, and then augment those features with anomaly scores. By using the anomaly scores we are able to improve the area under the curve (AUC) for the receiver operating characteristic (ROC) up to 27.5% for the spam data and 21.4% for the authentication data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424325","anomaly detection;authentication graphs;bipartite graphs;cyber security;lateral movement;spam","Authentication;Bipartite graph;Electronic mail;Feature extraction;Principal component analysis;Supervised learning","e-mail filters;electronic messaging;graph theory;matrix algebra;pattern classification;principal component analysis;security of data;support vector machines;unsolicited e-mail","AUC improvement;Los Alamos National Laboratory;ROC curve;UCI SMS Spam Collection Data Set;area-under-the-curve improvement;authentication data;authentication graph;auxiliary features;bipartite anomaly features;bipartite anomaly scores;bipartite graphs;cyber security applications;dimensionality reduction;disparate problems;malicious lateral movement detection;message-term;nonspam SMS text messages;principal component analysis;receiver operating characteristic curve;short-message service text messages;spam SMS text messages;spam data;spam detection;supervised classifier;supervised machine learning algorithm;user-computer matrix","","","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"An EMD Based Method for Reduction of Ballistocardiogram Artifact from EEG Studies of Evoked Potentials","E. Javed; I. Faye; A. S. Malik; J. M. Abdullah","Dept. of Electr. & Electron. Eng., Univ. Teknol. PETRONAS, Tronoh, Malaysia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1199","1203","Multi-modality data acquisition is a topic of research that gained interest in the recent years. It provides the opportunity to gather detailed information for analysis. Simultaneous electroencephalography (EEG) and functional magnetic resonance imaging is one good example of it. The information we get after fusing data from EEG and fMRI have both high temporal and spatial resolution. On the other side, this EEG recording suffers from some additional artifacts due to the fMRI environment, in particular, the Ballistocardiogram artifact. In this article, a new method of removing Ballistocardiogram Artifact from evoked potential studies is proposed. The method does not require any reference signal or prior information. The results presented are using the data of three subjects (volunteers). The results show that the proposed method can efficiently reduce Ballistocardiogram artifact and has performed better compared to the conventional methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424484","Ballistocardiogram artifact;Empirical Mode Decomposition;Event Related Potentials;Simultaneous EEG & fMRI","Data mining;Electrodes;Electroencephalography;Magnetic resonance imaging;Scalp;Signal to noise ratio;Spatial resolution","bioelectric potentials;biomedical MRI;data acquisition;electroencephalography;medical signal processing","EEG recording;EEG study;EMD based method;ballistocardiogram artifact reduction;electroencephalography;evoked potential study;functional magnetic resonance imaging;multimodality data acquisition;reference signal","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Class Decomposition Using K-Means and Hierarchical Clustering","S. Banitaan; A. B. Nassif; M. Azzeh","Dept. of Math., Univ. of Detroit Mercy, Detroit, MI, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1263","1267","This paper presents a clustering-based class decomposition approach to improve the performance of classifiers. Class decomposition works by dividing each class into clusters, and by relabeling instances contained by each cluster with a new class. Several case studies used class decomposition combined with linear classifiers. While there is an essential improvement in classification accuracy because of class decomposition, the most effective clustering algorithm is not obvious. The aim of this work is to investigate the effect of two clustering algorithms, K-means and hierarchical, on class decomposition. In this work, we study class decomposition when combined with the Naive Bayes classifier using four real-world datasets. Experimental results show an improvement in classification accuracy for most of the datasets when class decomposition using both K-means and hierarchical clustering is performed. The results also show that class decomposition is not suitable for all datasets.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424495","Class Decomposition;Classification;Clustering;Machine Learning","Clustering algorithms;Computers;Convergence;Couplings;Data mining;Ionosphere;Liver","Bayes methods;learning (artificial intelligence);pattern classification;pattern clustering","classification accuracy;clustering algorithm;clustering-based class decomposition approach;hierarchical clustering;k-means;linear classifier;naive Bayes classifier","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Diagnosis of Bearing Defects in Induction Motors by Fuzzy-Neighborhood Density-Based Clustering","M. Farajzadeh-Zanjani; R. Razavi-Far; M. Saif; J. Zarei; V. Palade","Dept. of Electr. & Comput. Eng., Univ. of Windsor, Windsor, ON, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","935","940","In this paper, a supervised fuzzy-neighborhood density-based clustering approach is proposed for the fault diagnosis of induction motors' bearings. The proposed approach makes use of the labeled data regarding the actual classes of faulty and fault-free cases, in order to train the fuzzy-neighborhood density-based clustering algorithm in a supervised manner, by resorting to an invasive weed optimization algorithm that aims to minimize an error-based objective function. The proposed classifier can properly classify multi-class data with complex and variously shaped decision boundaries among the different classes of faults and the fault-free state, and is robust against noise. This is due mainly to the fact that the classifier is constructed using the fuzzy-neighborhood density based clustering method, which is not sensitive to the geometrical shape of clusters in the feature space.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424441","bearing defects;fault diagnosis;fuzzy-neighborhood density-based clustering;induction motors","Clustering algorithms;Feature extraction;Harmonic analysis;Induction motors;Partitioning algorithms;Robustness;Vibrations","fault diagnosis;fuzzy set theory;induction motors;learning (artificial intelligence);machine bearings;mechanical engineering computing;minimisation;pattern classification;pattern clustering","decision boundaries;error-based objective function minimization;fault diagnosis;fault-free state;faulty state;feature space;induction motor bearing defect diagnosis;invasive weed optimization algorithm resorting;labeled data;multiclass data classification;noise robustness;supervised fuzzy-neighborhood density-based clustering approach;supervised training","","","","24","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Using Vector Quantization of Hough Transform for Circle Detection","B. Zhou","Dept. of Comput. Sci., Sam Houston State Univ., Huntsville, TX, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","447","450","Circles are important patterns in many automatic image inspection applications. The Hough Transform (HT) is a popular method for extracting shapes from original images. It was first introduced for the recognition of straight lines, and later extended to circles. The drawbacks of standard Hough Transform for circle detection are the large computational and storage requirements. In this paper, we propose a modified HT called Vector Quantization of Hough Transform (VQHT) to detect circles more efficiently. The basic idea is to first decompose the edge image into many sub-images by using Vector Quantization algorithm based on their natural spatial relationship. The edge points resided in each sub-image are considered as one circle candidate group. Then the VQHT algorithm is applied for fast circle detection. Experimental results show that the proposed algorithm can quickly and accurately detect multiple circles from the noisy background.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424355","Circle detection;hough transform;vector quantization","Digital images;Feature extraction;Image edge detection;Noise measurement;Standards;Transforms;Vector quantization","Hough transforms;feature extraction;image denoising;object detection;vector quantisation","VQHT;circle detection;image inspection application;shape extraction;vector quantization algorithm;vector quantization of Hough transform","","","","9","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Automatically Discovering Fatigue Patterns from Sparsely Labelled Temporal Data","K. Guo; P. Schrater","Dept. of Comput. Sci., Univ. of Minnesota, Minneapolis, MN, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","351","355","In many problems, we would like to find relation between data and description. However, this description, or label information, may not always be explicitly associated with the data. In this paper, we deal with the data with incomplete label information. In other words, the label only represents a general concept of a bag of data vectors instead of a specific information of one data vector. Our approach assumed that the feature vectors generated from the bag of data can be partitioned into baglabel relevant and irrelevant parts. Under this assumption, we give an algorithm that allows for efficiently extracting meaningful features from a large pool of features, and learning a multiple instance based predictor. We applied our algorithm to the monkey fixation data to predict the monkeys' quit behavior. Our algorithm outperforms other standard classification methods such as binary classifier and one-class classifier. In addition, the microsaccade is interpreted from a large set of features using our method. We find that it is the most effective element to predict the quit behavior.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424334","","Biomedical monitoring;Fatigue;Feature extraction;Learning systems;Mathematical model;Monitoring;Training","data mining;feature extraction;learning (artificial intelligence);pattern classification","binary classifier;data partitioning;data vectors;fatigue pattern discovery;feature extraction;instance-based predictor learning;label information;monkey fixation data;one-class classifier;sparsely labelled temporal data","","","","8","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Concept of 4th Dimension for Databases","E. Irmak; Ö. Kurtuldu","Fac. of Technol., Electr. & Electron. Eng. Dept., Gazi Univ., Ankara, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1159","1162","In these days, the data are being more and more important for not only social or commercial aspects but also military and security aspects. Therefore, storing the data accurately and accessing it exactly are quite important issues. Currently, most databases use 3 dimension (3D) data structure to store the physical parameters of real objects, which are width, length and depth/height. If the data have the four dimension for any object, it will definitely be more useful than 3D structure. In this paper, we investigated to how the time can be used as the 4th dimension for any object and the concepts of dynamic calculation of the time in order to store it in databases. Some type of objects have been selected as base shapes such as rectangular, cylinder, sphere, ellipse, pyramid and cone, for 4th dimension objects and a sample application is given in the study in order to explain how the time dimension can be used for databases.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424476","Four dimension;databases;time series","Buildings;Databases;Global Positioning System;Poles and towers;Shape;Three-dimensional displays;Time series analysis","data structures;database management systems","4th dimension object;databases;dynamic calculation;fourth dimension","","","","10","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"An Interval-Radial Algorithm for Hierarchical Clustering Analysis","C. Rhodes; J. Lemon; C. Hu","Comput. Sci. Dept., Univ. of Central Arkansas, Conway, AR, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","849","856","Hierarchical clustering analysis (HCA) produces a structure that is more informative than an unstructured set of clusters. However, the advantage comes at the cost of lower efficiency. In analyzing large dataset with HCA, it is important to improve its efficiency. Motivated by the fact that small quantitative differences may not necessarily reflect changes of qualitative property, we report an interval-radial algorithm for HCA. By grouping data points within a neighborhood, the interval-radial algorithm is O(N^2) for both agglomerative and divisive approaches under an easy to satisfy weak condition. The algorithm can adaptively adjust radius during its execution. Furthermore, the algorithm provides flexibility to users for them to select initial radius and step size such that to produce customized output automatically. We report the algorithm, its analysis, and results of computational experiments on several benchmark datasets. Examples and illustrative dendrograms are included.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424428","Efficiency;Flexibility;Hierarchical Clustering;Interval-Radial Algorithm","Algorithm design and analysis;Arrays;Benchmark testing;Clustering algorithms;Couplings;Measurement;Merging","pattern clustering","HCA;agglomerative approach;divisive approach;hierarchical clustering analysis;interval-radial algorithm;qualitative property","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Active Learning for One-Class Classification","V. Barnabé-Lortie; C. Bellinger; N. Japkowicz","Sch. of Electr. Eng. & Comput. Sci., Univ. of Ottawa, Ottawa, ON, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","390","395","Active learning is a common solution for reducing labeling costs and maximizing the impact of human labeling efforts in binary and multi-class classification settings. However, when we are faced with extreme levels of class imbalance, a situation in which it is not safe to assume that we have a representative sample of the minority class, it has been shown effective to replace the binary classifiers with a one-class classifiers. In such a setting, traditional active learning methods, and many previously proposed in the literature for one-class classifiers, prove to be inappropriate, as they rely on assumptions about the data that no longer stand. In this paper, we propose a novel approach to active learning designed for one-class classification. The proposed method does not rely on many of the inappropriate assumptions of its predecessors and leads to more robust classification performance. The gist of this method consists of labeling, in priority, the instances considered to fit the learned class the least by previous iterations of a one-class classification model. We provide empirical evidence for the merits of the proposed method compared to the available alternatives, and discuss how the method may have an impact in an applied setting.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424343","","Context;Data models;Labeling;Learning systems;Radiation monitoring;Training;Uncertainty","learning (artificial intelligence);pattern classification","active learning designe;active learning method;binary classification;binary classifier;class imbalance;human labeling effort;labeling cost;minority class;multiclass classification setting;one-class classification;one-class classifier;robust classification performance","","1","","25","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Learning Multi-valued Biological Models with Delayed Influence from Time-Series Observations","T. Ribeiro; M. Magnin; K. Inoue; C. Sakama","SOKENDAI, Grad. Univ. for Adv. Studies, Tokyo, Japan","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","25","31","Delayed effects are important in modeling biological systems, and timed Boolean networks have been proposed for such a framework. Yet it is not an easy task to design such Boolean models with delays precisely. Recently, an attempt to learn timed Boolean networks has been made in Ribeiro et al 2015 in the framework of learning state transition rules from time-series data. However, this approach still has two limitations: (1) The maximum delay has to be given as input to the algorithm, (2) The possible value of each state is assumed to be Boolean, i.e., twovalued. In this paper, we extend the previous learning mechanism to overcome these limitations. We propose an algorithm to learn multi-valued biological models with delayed influence by automatically tuning the delay. The delay is determined so as to minimally explain the necessary influences. The merits of our approach is then verified on benchmarks coming from the DREAM4 challenge.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424281","Boolean networks;Markov(k);delay;dynamical systems;inductive logic programming;learning from interpretation transition;multi-valued models","Biological system modeling;Biological systems;Delays;Electronic mail;Heuristic algorithms;Logic programming","biology computing;delays;learning (artificial intelligence);multivalued logic;time series","DREAM4 challenge;delay;multivalued biological model learning;multivalued logic;time-series observations","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Fine-Grained Opinion Extraction with Markov Logic Networks","L. G. Mojica; V. Ng","Human Language Technol. Res. Inst., Univ. of Texas at Dallas, Richardson, TX, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","271","276","Markov Logic Networks, a joint inference framework that combines logical and probabilistic representations, enable effective modeling of the dependencies that exist between different instances of a data sample. While its ability to capture relational dependencies makes it an ideal framework for predicting the structures inherent in many natural language processing (NLP) tasks, it is arguably underused in NLP, especially in comparison to other joint inference frameworks such as integer linear programming. In this paper, we present the first Markov logic model for the NLP task of fine-grained opinion extraction that exploits a factuality lexicon. When evaluated on a standard evaluation corpus, our approach surpasses a state-of-the-art approach in performance.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424320","Joint Inference;Markov Logic Networks;Opinion Extraction","Data models;Feature extraction;Linear programming;Markov random fields;Natural language processing;Training","Markov processes;data mining;natural language processing","Markov logic networks;data sample;factuality lexicon;fine-grained opinion extraction;joint inference framework;logical representations;natural language processing tasks;opinion mining;probabilistic representations;relational dependencies","","","","24","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Sequence Classification with Neural Conditional Random Fields","M. Abramson","Naval Res. Lab., Washington, DC, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","799","804","The proliferation of sensor devices monitoring human activity generates voluminous amount of temporal sequences needing to be interpreted and categorized. Moreover, complex behavior detection requires the personalization of multi-sensor fusion algorithms. Conditional random fields (CRFs) are commonly used in structured prediction tasks such as part-of-speech tagging in natural language processing. Conditional probabilities guide the choice of each tag/label in the sequence conflating the structured prediction task with the sequence classification task where different models provide different categorization of the same sequence. The claim of this paper is that CRF models also provide discriminative models to distinguish between types of sequence regardless of the accuracy of the labels obtained if we calibrate the class membership estimate of the sequence. We introduce and compare different neural network based linear-chain CRFs and we present experiments on two complex sequence classification and structured prediction tasks to support this claim.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424420","hybrid;neurocrfs;sequence classification","Computational modeling;Hidden Markov models;Neural networks;Prediction algorithms;Predictive models;Probabilistic logic;Viterbi algorithm","natural language processing;neural nets;pattern classification;probability;sensor fusion","class membership estimate;complex behavior detection;complex sequence classification;conditional probability;human activity;linear-chain CRF;multisensor fusion algorithm;natural language processing;neural conditional random field;neural network;part-of-speech tagging;sensor devices;sequence classification task;structured prediction task;temporal sequence","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Interpretable Classifier for Identifying High-Value Child Support Cases","B. Dolan; K. Ocke; E. Gross; Y. Charif","Scalable Data Analytics Res. Lab., PARC A Xerox Co., Webster, NY, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1001","1006","This work brings interpretable and accurate data analytics to child support agencies with the goal of substantially increasing their effectiveness. In the realm of child support, a custodial parent may be entitled to periodic child support payments from the noncustodial parent. In order to analyze this process, we have gathered case data from several child support agencies. The objective of the work is to develop analytical models that characterize and predict high-value child support cases. High-value cases are those that result in successful payments and require far fewer resources for enforcement. We create interpretable and accurate scoring models to identify these cases so that the key attributes driving their prediction are easily understood by the caseworkers. This information may be integrated with case management systems to schedule and prioritize the caseload.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424451","case management;child support;data analytics;decision support;interpretable modeling;predictive scoring systems","Analytical models;Buildings;Data analysis;Data models;Logistics;Numerical models;Predictive models","data analysis;pattern classification;social aspects of automation","accurate data analytics;accurate scoring models;case management systems;child support agencies;high-value child support cases;interpretable classifier;noncustodial parent;periodic child support payments","","","","19","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Online One-Class SVMs with Active-Set Optimization for Data Streams","K. Gao","Dept. of Stat., Stanford Univ., Stanford, CA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","116","121","A great advantage of support vector machines (SVMs) is its capability to learn decision borders, represented by a set of particular data points called margin support vectors. The real-time or nearly real-time online learning and detection from data streams poses stringent time and space constraints for the learner. We consider solving online one-class SVMs with an active-set method for quadratic programming (QP). At each iteration, the problem size is the size of the estimated support vectors so far. Active-set programming has the nice property that the solution of a previous problem can serve as a warm start of the next and computation time can thereby be greatly reduced. In general, finding a good warm-start point is difficult. We propose a method to find a good warm start by exploiting the structure of the SVM optimization problem.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424295","","Kernel;Quadratic programming;Real-time systems;Standards;Support vector machines;Training","data handling;learning (artificial intelligence);quadratic programming;support vector machines","SVM optimization problem;active-set optimization;active-set programming;data points;data streams;decision borders;margin support vectors;online one-class SVM;quadratic programming;real-time online learning;space constraints;support vector machines;warm-start point","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Resource Allocation Predictive Modeling to Optimize Virtual World Simulator Performance","S. Mondesire; D. Maxwell; J. Stevens; R. Leis","U.S. Army Res. Lab., Orlando, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1215","1219","Virtual world simulation for military training is an emerging domain. As such, detailed analysis is required to optimize the performance the simulators. Unfortunately, due to a lack of extensive virtual world performance analysis, simulator administrators often make arbitrary resource allocations to support their environments and training scenarios. In this paper, we provide a lightweight predictive model that will be used in an automated, dynamic resource allocation system in the popular three-dimensional open-sourced virtual world simulator OpenSimulator. Prior to this investigation, only OpenSimulator developers and users with extensive experience with the platform could manually load balance the server resources based on anticipated usage. Now, with the proposed system and its predictive model, the simulator advances towards having an automated mechanism to determine the minimal critical resources that are required to support a target number of concurrent users in the virtual world.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424487","Distributed Simulation;Predictive Model;Simulation-Based Training;Vertical Scaling;Virtual World","Bandwidth;Data models;Hardware;Predictive models;Resource management;Scalability;Training","computer based training;digital simulation;military computing;public domain software;resource allocation","OpenSimulator;automated dynamic resource allocation system;load balancing;military training;minimal critical resources;predictive model;resource allocation predictive modeling;server resources;three-dimensional open-sourced virtual world simulator;virtual world performance analysis;virtual world simulator performance optimization","","","","12","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Learning from Synthetic Data Using a Stacked Multichannel Autoencoder","X. Zhang; Y. Fu; S. Jiang; L. Sigal; G. Agam","Illinois Inst. of Technol., Chicago, IL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","461","464","Learning from synthetic data has many important and practical applications, An example of application is photo-sketch recognition. Using synthetic data is challenging due to the differences in feature distributions between synthetic and real data, a phenomenon we term synthetic gap. In this paper, we investigate and formalize a general framework -- Stacked Multichannel Autoencoder (SMCAE) that enables bridging the synthetic gap and learning from synthetic data more efficiently. In particular, we show that our SMCAE can not only transform and use synthetic data on the challenging face-sketch recognition task, but that it can also help simulate real images, which can be used for training classifiers for recognition. Preliminary experiments validate the effectiveness of the framework.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424358","Autoencoder;data synthesis;transfer learning","Electronic mail;Face recognition;Image recognition;Image reconstruction;Measurement;Training;Transforms","face recognition;learning (artificial intelligence);pattern classification","SMCAE;face-sketch recognition;feature distributions;image recognition;learning;photo-sketch recognition;stacked multichannel autoencoder;synthetic data;training classifiers","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Layer-Specific Adaptive Learning Rates for Deep Networks","B. Singh; S. De; Y. Zhang; T. Goldstein; G. Taylor","Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","364","368","The increasing complexity of deep learning architectures is resulting in training time requiring weeks or even months. This slow training is due in part to ""vanishing gradients,"" in which the gradients used by back-propagation are extremely large for weights connecting deep layers (layers near the output layer), and extremely small for shallow layers (near the input layer), this results in slow learning in the shallow layers. Additionally, it has also been shown that in highly non-convex problems, such as deep neural networks, there is a proliferation of high-error low curvature saddle points, which slows down learning dramatically [1]. In this paper, we attempt to overcome the two above problems by proposing an optimization method for training deep neural networks which uses learning rates which are both specific to each layer in the network and adaptive to the curvature of the function, increasing the learning rate at low curvature points. This enables us to speed up learning in the shallow layers of the network and quickly escape high-error low curvature saddle points. We test our method on standard image classification datasets such as MNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracy as well as reduces the required training time over standard algorithms.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424337","adaptive learing rate;deep networks","Adaptive systems;Neural networks;Optimization methods;Standards;Training;Training data","backpropagation;concave programming;image classification;neural nets","CIFAR10 dataset;ImageNet dataset;MNIST dataset;backpropagation;deep learning architectures;deep networks;deep neural networks;high-error low curvature saddle points;highly nonconvex problems;image classification datasets;layer-specific adaptive learning rates;optimization method;vanishing gradients","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Highly Distributable Computational Framework for Fast Cloud Data Retrieval","A. H. Basirat; A. I. Khan; B. Srinivasan","Clayton Sch. of IT, Monash Univ., Melbourne, VIC, Australia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","246","250","Unlike the existing relational, hierarchical and object-oriented schemes, associative models can analyze data in similar ways to which our brain links information. Such interactions when implemented in voluminous data clouds can assist in searching for overarching relations in complex and highly distributed data sets with speed and accuracy. In this paper, a different perspective of data recognition will be considered. Rather than looking at conventional approaches, such as statistical computations and deterministic learning schemes, this paper will be focusing on distributed processing approach for scalable data recognition and processing through applying an access scheme that will enable fast data retrieval across multiple records and data segments associatively, utilizing a parallel approach. Doing so will yield a new form of databaselike functionality that can scale up or down over the available infrastructure without interruption or degradation, dynamically and automatically. In our proposed model, data records are treated as patterns. As a result, data storage and retrieval is performed using a distributed pattern recognition approach that is implemented through the integration of loosely-coupled computational networks, followed by a divide-and-distribute approach that facilitates distribution of these networks within the cloud dynamically.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424316","Associative Memory;Cloud Computing;Distributed Computing;Hierachical Graph Neuron;Neural Networks;Parallel Processing","Data models;Distributed databases;Indexes;Neurons;Object oriented modeling;Pattern recognition;Silicon","cloud computing;content-addressable storage;neural nets;pattern recognition;statistical analysis","associative model;cloud data retrieval;data storage;deterministic learning scheme;distributable computational framework;distributed pattern recognition;divide-and-distribute approach;scalable data recognition;statistical computation","","","","10","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"An Edge-Less Approach to Horizon Line Detection","T. Ahmad; G. Bebis; M. Nicolescu; A. Nefian; T. Fong","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1095","1102","Horizon line is a promising visual cue which can be exploited for robot localization or visual geo-localization. Prominent approaches to horizon line detection rely on edge detection as a pre-processing step which is inherently a non-stable approach due to parameter choices and underlying assumptions. We present a novel horizon line detection approach which uses machine learning and Dynamic Programming (DP) to extract the horizon line from a classification map instead of an edge map. The key idea is assigning a classification score to each pixel, which can be interpreted as the likelihood of the pixel belonging to the horizon line, and representing the classification map as a multi-stage graph. Using DP, the horizon line can be extracted by finding the path that maximizes the sum of classification scores. In contrast to edge maps which are typically binary (edge vs no-edge) and contain gaps, classification maps are continuous and contain no gaps, yielding significantly better solutions. Using classification maps instead of edge maps allows for removing certain assumptions such as the horizon is close to the top of the image or that the horizon forms a straight line. The purpose of these assumptions is to bias the DP solution but they fail to produce good results when they are not valid. We demonstrate our approach on three different data sets and provide comparisons with a traditional approach based on edge maps. Although our training set is comprised of a very small number of images from the same location, our results illustrate that our method generalizes well to images acquired under different conditions and geographical locations.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424466","convolutional neural networks;dynamic programming;horizon line detection;skyline extraction;support vector machines","Hidden Markov models;Image color analysis;Image edge detection;Navigation;Support vector machines;Training;Visualization","dynamic programming;edge detection;feature extraction;graph theory;image classification;learning (artificial intelligence)","classification map;dynamic programming;edge detection;edge map;edge-less approach;geographical locations;horizon line detection;horizon line extraction;machine learning;multistage graph;pixel classification score;pixel likelihood;robot localization;visual cue;visual geo-localization","","1","","30","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Weakly Supervised Learning of Dialogue Structure in MOOC Forum Threads","R. Fisher; R. Simmons; C. Malin-Mayor","Carnegie Mellon Univ., Pittsburgh, PA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","624","627","In this paper we present a new method for understanding discussions between students in MOOC forums. In particular, we introduce a machine learning method for discovering instances in which a response relation exists between a pair of posts in a forum thread, for example when one student provides the answer to a question or comments on something another student previously said. Research has shown that understanding conversational structure between students is paramount to evaluating the productivity of the collaboration and estimating outcomes. However, previous methods often rely on human supplied dialogue act labels or discourse parsing algorithms requiring large labeled datasets. Our method, which utilizes a fast, exact optimization process known as spectral optimization, does not require manually annotated training data and is highly scalable and generalizable. Empirical results are given using real world datasets consisting of conversations between students participating in Coursera courses, and we see predictive accuracy above 90% - nearing the human inter-annotator agreement rate for these datasets.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424387","Discourse parsing;education;moocs","Computational modeling;Education;Hidden Markov models;Message systems;Optimization;Psychology;Testing","Internet;courseware;educational courses;learning (artificial intelligence);natural language processing","Coursera courses;MOOC forum threads;dialogue structure;human inter-annotator agreement rate;machine learning method;massive online open courseware;spectral optimization;weakly supervised learning","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Artificial Neural Network Based Abdominal Organ Segmentations: A Review","E. Goceri; E. Martinez","Dept. of Biomed. Inf., Ohio State Univ., Columbus, OH, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1191","1194","There are many neural network based abdominal organ segmentation approaches from medical images. Computed tomography images were mostly used in these approaches. Applied techniques are usually based on prior information regarding position, shape, and size of organs in these methods. In the literature, there are only a few neural network based techniques that were implemented to segment abdominal organs from magnetic resonance based images. In this paper, we present these methods and their results.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424482","CT images;MR images;Organ segmentation;neural networks","Artificial neural networks;Biomedical imaging;Computed tomography;Image segmentation;Liver;Shape","biomedical MRI;computerised tomography;image segmentation;medical image processing;neural nets","artificial neural network based abdominal organ segmentations;computed tomography images;magnetic resonance based images;medical images","","1","","31","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Random Forest with Random Projection to Impute Missing Gene Expression Data","L. Gondara","Dept. of Comput. Sci., Univ. of Illinois, Springfield, IL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1251","1256","Measurement error or lack of proper experimental setup often results in invalid or missing data in gene expression studies. Small sample size and cost of re-running the experiment presents a need for an efficient missing data imputation technique. In this paper, we propose a method based on Random forest using Random projection as a data pre-processing filter. Initial results using varying missing data proportions on variety of real datasets show that the imputation process based on Random forest performs equally well or better than K-Nearest Neighbor & Support Vector Regression based methods. Using Random projection we show that dimensionality of a dataset can be reduced by 50 percent without affecting the imputation process.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424493","gene expression data;imputation;missing data;random forest;random projection","Correlation;Data models;Gene expression;Principal component analysis;Radio frequency;Support vector machines;Vegetation","biology computing;data mining;genetics;random processes","data preprocessing filter;missing data imputation technique;missing gene expression data;random forest;random projection","","","","32","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Performance Investigation of UCB Policy in Q-learning","K. Saito; A. Notsu; S. Ubukata; K. Honda","Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","777","780","In this paper, we investigated performance and usability of UCBQ algorithm proposed in previous research. This is the algorithm that UCB, which is one of bandit algorithms, is applied to Q-Learning, and can balance between exploitation and exploration. We confirmed in the previous research that it was able to realize effective learning in a partially observable Markov decision process by using a continuous state spaces shortest path problem. We numerically examined it by using a variety of simpler learning situation which is the 2 dimensional goal search problem in a Markov decision process, comparing to previous methods. As a result, we confirmed that it had a better performance than other methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424416","Q-learning;Reinforcement Learning;UCB Policy","Damping;Learning (artificial intelligence);Markov processes;Search problems;Shortest path problem;Upper bound;Usability","Markov processes;learning (artificial intelligence);search problems","Q-learning;UCB policy;UCBQ algorithm;bandit algorithm;continuous state spaces shortest path problem;partially observable Markov decision process;two-dimensional goal search problem","","","","8","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Support Vector Classification Model with Partial Empirical Risks Given","L. Luo; L. Ye; Q. Zhou; H. Peng","Dept. of Autom., Xiamen Univ., Xiamen, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","570","575","A novel model of support vector classification with partial empirical risks given (P-SVC) is proposed. A sequential minimal optimization for P-SVC is also provided. P-SVC is an extension of the classical support vector classification (C-SVC) and can be used in the case where partial empirical risks are requested. The experiments on some artificial and benchmark datasets show P-SVC obtains a better classification accuracy and a more stable classification result than C-SVC does when partial empirical risks are known.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424377","confidence risk;empirical risk;structural risk minimization;support vector machine","Benchmark testing;Kernel;Optimization;Static VAr compensators;Support vector machine classification;Training","pattern classification;support vector machines","C-SVC;P-SVC;classical support vector classification;partial empirical risks;partial empirical risks given;sequential minimal optimization;support vector classification model","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Demographic Group Classification of Smart Device Users","A. R. Alharbi; M. A. Thornton","Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","481","486","Interacting with smart devices is a common experience and is becoming an integral part of daily life for many people. Modern smart devices are equipped with a large variety of environmental and user input sensors. We hypothesize that a fusion of smart device sensor data can provide biometric data that allows for classification of user demographics such as age, gender, and native language. A smart device is instrumented with sensor data collection software and with user demographic classification software. An experiment is devised where data is collected for a sample group of users. The data is analyzed, and two classification algorithms are implemented based on the fusion of the different sensors. The classification methods are based upon decision tree and principle component analysis. The results of the experiment indicate that high accuracy is achieved for user demographic classification. Finally, we further discuss the applications and limitations of the study's approach.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424362","decision tree;demographic classification;principle component analysis","Data collection;Data visualization;Feature extraction;Games;Intelligent sensors","biometrics (access control);data analysis;decision trees;pattern classification;principal component analysis;smart phones","biometric data;classification algorithm;classification method;data analysis;decision tree;demographic group classification;environmental input sensor;native language;principle component analysis;sensor data collection software;smart device sensor data;smart device user;user demographic classification software;user demographics;user input sensor","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Adaptive Modular Approach for Online Fault Diagnosis of Discrete Event Systems","M. Sayed-Mouchaweh","Inst. Mines-Telecom Mines-Douai, Douai, France","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","923","928","In this paper, an adaptive modular approach is proposed to achieve the fault diagnosis of discrete event systems. The desired (normal) behavior is represented by a set of specifications while faults of each predefined fault type are considered to be the execution of specific fault behavior violating a specification. The inference of the fault type of each fault is achieved by a diagnosis module called diagnoser. This approach considers that only normal behavior is known in advance. Then, it adapts the diagnoser in order to integrate new specific fault behaviors into its inference engine. This adaptation allows increasing the diagnosis capacity, called diagnosability, over time.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.230","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424439","Adaptive approaches; fault diagnosis; discrete event systems; diagnosabiliy","Adaptation models;Adaptive systems;Fault diagnosis;Mathematical model;Radio frequency;Sensors;Valves","discrete event systems;fault diagnosis;inference mechanisms","adaptive modular approach;diagnosability;discrete event systems;fault type inference;inference engine;online fault diagnosis","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Semi Supervised Learning for Human Activity Recognition Using Depth Cameras","M. F. Mabrouk; N. M. Ghanem; M. A. Ismail","Comput. & Syst. Eng. Dept. Fac. of Eng., Alexandria Univ. Alexandria, Alexandria, Egypt","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","681","686","Human action recognition is a very active research topic in computer vision and pattern recognition. Recently, it has shown a great potential for human action recognition using the 3D depth data captured by the promising RGB-D cameras, and particularly, the Microsoft Kinect which has made high resolution real-time depth cheaply available. Several features and descriptors have been proposed for depth based action recognition, and they have given high results when recognizing the actions, but one dilemma always exists, the labeled data given, which are manually set by humans. They are not enough to build the system, especially that the use of human action recognition is mainly for surveillance of people activities. In this paper, the paucity of labeled data is addressed, by the popular semi supervision machine learning technique ""co-training"", which makes full use of unlabeled samples of two different independent views. Through the experiments on two popular datasets (MSR Action 3D, and MSR DailyActivity 3D), we demonstrate that our proposed framework outperforms the state of art. It improves the accuracy up to 83% in case of MSR Action 3D, and up to 80% MSR DailyActivity 3D, using the same number of labeled samples.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424398","action recognition;co-training;depth;skeleton","Cameras;Feature extraction;Sensors;Skeleton;Supervised learning;Three-dimensional displays;Training","cameras;feature extraction;image recognition;learning (artificial intelligence)","3D depth data;MSR Action 3D dataset;MSR DailyActivity 3D dataset;Microsoft Kinect;RGB-D cameras;co-training technique;depth-based action recognition;depth-cameras;high-resolution real-time depth;human activity recognition;labeled data;people activity surveillance;semisupervised learning;semisupervision machine learning technique","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Scrubbing the Web for Association Rules: An Application in Predictive Text","J. Lovinger; I. Valova","Comput. & Inf. Sci. Dept., Univ. of Massachussetts Dartmouth, Dartmouth, MA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","439","442","Modern smartphones have led to an explosion of interest in predictive text. Predicting the next word that a user will type saves precious time on the compact keyboards that smartphones use. By leveraging the vast amounts of text data available on the Internet, we can easily gather information on natural human writing. We can then use this data with association rules to efficiently determine the probability of one word appearing after another given word. In this paper, we explore the gathering of text data from online social media. We also examine the use of association rules for predictive text, and develop an algorithm that can quickly and efficiently generate rules for predictive text. The results of the presented algorithm are compared to Google's Android keyboard.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424353","association rules;predictive text analysis;web scrubbing","Blogs;Data mining;Internet;Itemsets;Prediction algorithms;Twitter","Internet;data mining;smart phones;social networking (online);text analysis","Google Android keyboard;Internet;association rules;compact keyboards;natural human writing;online social media;predictive text;smartphones;text data","","","","12","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Classification of Evolving Data Streams with Infinitely Delayed Labels","V. M. A. Souza; D. F. Silva; G. E. A. P. A. Batista; J. Gama","","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","214","219","The majority of evolving data streams classification algorithms assume that the actual labels of the predicted examples are readily available without any time delay just after a prediction is made. However, given the high label costs, dependence of an expert, limitations in data transmission or even restrictions imposed by the problem's nature, there is a large number of real-world applications in which the availability of actual labels is infinitely delayed (never available). In these cases, it is necessary the use of algorithms that does not follow the traditional process of monitoring the error rate to detect changes in data distribution and uses the most recent labeled data to update the classification model. In this paper, we propose the method MClassification to classify evolving data streams with infinitely delayed labels. Our method is inspired on the use of Micro-Cluster representation from online clustering algorithms. Considering the presence of incremental drifts, our approach uses a distance-based strategy to maintain the Micro-Clusters' positions updated. An evaluation in several synthetic and real data shows that MClassification achieves competitive accuracy results to state-of-the-art methods and adequate computational cost. The main advantage of the proposed method is the absence of critical parameters that require user's prior knowledge, as occurs with rival methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424311","classification;data stream;delayed labels;extreme verification latency;online clustering","Classification algorithms;Clustering algorithms;Computational efficiency;Data models;Delay effects;Prediction algorithms;Shape","pattern classification;pattern clustering","MClassification method;classification algorithm;clustering algorithms;data transmission;distance-based strategy;evolving data stream classification;incremental drift;infinitely delayed labels;microcluster representation","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Resampling-Based Variable Selection with Lasso for p >> n and Partially Linear Models","M. A. Mares; Y. Guo","Comput. Dept., Data Sci. Inst., London, UK","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1076","1082","The linear model of the regression function is a widely used and perhaps, in most cases, highly unrealistic simplifying assumption, when proposing consistent variable selection methods for large and highly-dimensional datasets. In this paper, we study what happens from theoretical point of view, when a variable selection method assumes a linear regression function and the underlying ground-truth model is composed of a linear and a non-linear term, that is at most partially linear. We demonstrate consistency of the Lasso method when the model is partially linear. However, we note that the algorithm tends to increase even more the number of selected false positives on partially linear models when given few training samples. That is usually because the values of small groups of samples happen to explain variation coming from the non-linear part of the response function and the noise, using a linear combination of wrong predictors. We demonstrate theoretically that false positives are likely to be selected by the Lasso method due to a small proportion of samples, which happen to explain some variation in the response variable. We show that this property implies that if we run the Lasso on several slightly smaller size data replications, sampled without replacement, and intersect the results, we are likely to reduce the number of false positives without losing already selected true positives. We propose a novel consistent variable selection algorithm based on this property and we show it can outperform other variable selection methods on synthetic datasets of linear and partially linear models and datasets from the UCI machine learning repository.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424463","big data;feature selection;high-dimensional data;lasso regression;non-linearity;variable selection","Computational modeling;Data models;Estimation;Input variables;Mathematical model;Prediction algorithms;Training","Big Data;feature selection;learning (artificial intelligence);regression analysis;sampling methods","Lasso method;UCI machine learning repository;data replications;ground-truth model;highly-dimensional datasets;linear regression function;partially linear models;resampling-based variable selection","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Web-Based Auction Platform for Electricity Retail Markets","B. Çolak; M. A. Gökmen; H. Kiliç","Comput. Eng. Dept., Gediz Univ., Izmir, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1148","1152","A web-based combinatorial reverse auction platform for electricity retail markets is designed and implemented. At consumer side, the system provides cheaper electricity consumption by means of established competitive market environment. The competitive set up allows suppliers a continuous channel of bidding and chance to increase number of their customers. The winner determination problem of combinatorial auctions - known to be NP-Hard is solved by using available commercial off the shelf optimizer. Experimental results showed that the performance critical component of the platform (i.e. the optimizer) performs quite satisfactory in terms of solution time & memory loads. We observed that there is no correlation between different number of bidders, bids per bidder and solution time & memory load values.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424474","combinatorial reverse auctions;e-commerce;electricity retail markets;optimization;web application","Companies;Consumer electronics;Contracts;Electricity supply industry;Minimization;Optimization;Protocols","Internet;electricity supply industry;electronic commerce;optimisation;power consumption;power markets;retailing","NP-hard problem;Web-based auction platform;combinatorial reverse auction platform;commercial off the shelf optimizer;electricity consumption;electricity retail markets;market environment","","","","25","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Metabolic Profiling of 1H NMR Spectra in Chronic Kidney Disease with Local Predictive Modeling","M. M. Luck; A. Yartseva; G. Bertho; E. Thervet; P. Beaune; N. Pallet; C. Damon","Hypercube Inst., Paris, France","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","176","181","Metabolic profiling, the study of changes in the concentration of the metabolites in the organism induced by biological differences within subpopulations, has to deal with a very large amount of complex data. It therefore requires the use of powerful data processing and machine learning methods. To overcome over-fitting, a common concern in metabolic profiling where the number of features is often much larger than the number of observations, many predictive analyses combined dimension reduction techniques with multivariate predictive linear modeling. Moreover, they built a global model that identifies biomarkers predictive of the output of interest giving their overall trend variations. However, this fails to capture local biological phenomena underlying subgroups of subjects. More recently, local exploration methods based on decision trees approaches have been applied in metabolomics but they only explore random parts of the feature space. In this study, we used a supervised rule-mining algorithm that locally and exhaustively explores the feature space to predict chronic kidney disease (CDK) stages based on proton Nuclear Magnetic Resonance (<sup>1</sup>H NMR) data. From the discriminant subregions obtained with this exploration, we extracted local features and learned a L<sub>2</sub>-regularized Logistic regression (L<sub>2</sub>LR) classifier. We compared the resulting local predictive model with a standard one, combining classical univariate supervised feature selection techniques with a L<sub>2</sub>LR, and a model mixing both global and local features. Results show that the local predictive model is more powerful in terms of predictive performance than the mixed and global models. Additionally, it gives key insights into biological variations specific to subgroups of subjects.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424305","","Biological system modeling;Diseases;Feature extraction;Metabolomics;Nuclear magnetic resonance;Predictive models;Space exploration","biomedical NMR;data mining;diseases;feature extraction;kidney;medical computing;pattern classification;regression analysis","1H NMR spectra data;L2-regularized logistic regression classifier;chronic kidney disease stage prediction;classical univariate supervised feature selection technique;data processing;decision trees approach;feature extraction;machine learning method;metabolic profiling;metabolite concentration;multivariate predictive linear modeling;proton nuclear magnetic resonance;supervised rule-mining algorithm","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Hidden Markov Support Vector Machines for Self-Paced Brain Computer Interfaces","H. Bashashati; R. K. Ward; A. Bashashati","Electr. & Comput. Eng. Dept., Univ. of British Columbia, Vancouver, BC, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","382","385","Brain Computer Interfaces (BCI) aim at providing a means to control devices with brain signals. Self-paced BCIs, as opposed to synchronous ones, have the advantage of being operational at all times and not only at specific system-defined periods. Traditionally, in the BCI field, a sliding window over the brain signal is used to detect the intention of the user at a given time. This approach ignores the temporal correlations between the adjacent time windows. This paper proposes a novel approach to classify self-paced BCI data using structural support vector machines. Our proposed approach considers the history of the brain signals in the context of sequential supervised learning to better detect the intention of the user from his/her brain signals. We have compared our proposed model to the sliding window approach with Support Vector Machines (SVM) and Linear Discriminant Analysis (LDA) classifiers. Using data collected from 4 individuals form BCI competition IV, it is shown that the F1 score of our approach is significantly better than the sliding window approach. The average F1 score of our method across all subjects is 0.3 and 0.5 higher than the sliding window with SVM and LDA classifiers, respectively.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424341","","Brain modeling;Correlation;Electroencephalography;Feature extraction;Hidden Markov models;Kernel;Support vector machines","brain;brain-computer interfaces;hidden Markov models;learning (artificial intelligence);signal classification;support vector machines","BCI competition;LDA classifier;SVM classifier;brain signals;hidden Markov support vector machines;linear discriminant analysis classifier;self-paced BCI data classification;self-paced brain computer interfaces;sequential supervised learning;structural support vector machines;temporal correlations","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Prediction of SPEI Using MLR and ANN: A Case Study for Wilsons Promontory Station in Victoria","S. Mouatadid; R. C. Deo; J. F. Adamowski","Dept. of Bioresource Eng., McGill Univ., Montre&#x0301;al, QC, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","318","324","The prediction of drought is of major importance in climate-related studies, hydrologic engineering, wildlife or agricultural studies. This study explores the ability of two machine learning methods to predict 1, 3, 6 and 12 months standardized precipitation and evapotranspiration index (SPEI) for the Wilsons Promontory station in Eastern Australia. The two methods are multiple linear regression (MLR) and artificial neural networks (ANN). The data-driven models were based on combinations of the input variables: mean precipitations, mean, maximum and minimum temperatures and evapotranspiration, for data between 1915 and 2012. Two performance metrics were used to compare the performance of the optimum MLR and ANN models: the coefficient of determination (R2) and the root mean square error (RMSE). It was found that ANN provided greater accuracy than MLR in forecasting the 1, 3, 6 and 12 months SPEI.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424328","artifial neural network model;drought modelling;multi-linear regression model;standardized precipitation index","Artificial neural networks;Biological system modeling;Computational modeling;Data models;Indexes;Neurons;Temperature distribution","atmospheric precipitation;geophysics computing;hydrology;learning (artificial intelligence);mean square error methods;neural nets;regression analysis","ANN;MLR;RMSE;SPEI;Victoria;Wilsons promontory station;agricultural studies;artificial neural networks;climate-related studies;data-driven models;determination coefficient;eastern Australia;hydrologic engineering;machine learning methods;multiple linear regression;root mean square error;standardized precipitation and evapotranspiration index;wildlife studies","","","","35","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Predicting Vulnerable Software Components through N-Gram Analysis and Statistical Feature Selection","Y. Pang; X. Xue; A. S. Namin","Dept. of Math., Southern Connecticut State Univ., New Haven, CT, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","543","548","Vulnerabilities need to be detected and removed from software. Although previous studies demonstrated the usefulness of employing prediction techniques in deciding about vulnerabilities of software components, the accuracy and improvement of effectiveness of these prediction techniques is still a grand challenging research question. This paper proposes a hybrid technique based on combining N-gram analysis and feature selection algorithms for predicting vulnerable software components where features are defined as continuous sequences of token in source code files, i.e., Java class file. Machine learning-based feature selection algorithms are then employed to reduce the feature and search space. We evaluated the proposed technique based on some Java Android applications, and the results demonstrated that the proposed technique could predict vulnerable classes, i.e., software components, with high precision, accuracy and recall.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424372","Feature selection;N-gram;Vulnerability prediction;Wilcoxon test","Feature extraction;Java;Measurement;Prediction algorithms;Predictive models;Software;Support vector machines","feature selection;learning (artificial intelligence);object-oriented methods;software fault tolerance;statistical analysis","machine learning-based feature selection algorithms;n-gram analysis;prediction techniques;statistical feature selection algorithm;vulnerability detection;vulnerable software components prediction","","1","","23","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Boosting the Detection of Malicious Documents Using Designated Active Learning Methods","N. Nissim; A. Cohen; Y. Elovici","Dept. of Inf. Syst. Eng., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","760","765","Most organizations usually create, send and receive huge amounts of documents daily, Attackers increasingly take advantage of innocent users who tend to casually open email massages assumed to be benign, carrying malicious documents. Recent targeted attacks aimed at organizations, utilize the new Microsoft Word documents (*.docx). Anti-virus software fails to detect new unknown malicious files, including malicious docx files. In this study, we present SFEM feature extraction methodology and designated Active Learning (AL) methods, aimed at accurate detection of new unknown malicious docx files that also efficiently enhances the detection's model capabilities over time. Our AL methods identify and acquire only small set of new docx files that are most likely malicious, as well as informative benign files, these files are used for enhancing the knowledge stores of both the detection model and the anti-virus software. Results show that our active learning methods used only 14% of the labeled docx files within organization which led to a reduction of 95.5% in labeling efforts compared to passive learning and SVM-Margin (existing active learning method). Our AL methods also showed a significant improvement of 91% in unknown docx malware acquisition compared to passive learning and SVM-Margin, thus providing an improved updating solution for detection model, as well as the anti-virus software widely used within organizations.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424413","Active Learning;Documents;Machine Learning;Malicious;Malware;Microsoft office files;Structural;docx","Feature extraction;Learning systems;Malware;Organizations;Software;XML","document handling;electronic mail;feature extraction;learning (artificial intelligence);security of data;support vector machines","Microsoft word document;SFEM feature extraction methodology;SVM-margin;antivirus software;designated AL method;designated active learning method;malicious document detection;malicious docx files;open email massage;unknown docx malware acquisition","","1","","10","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Synthetic Oversampling for Advanced Radioactive Threat Detection","C. Bellinger; N. Japkowicz; C. Drummond","Sch. of Electr. Eng. & Comput. Sci., Univ. of Ottawa, Ottawa, ON, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","948","953","Gamma-ray spectral classification requires the automatic identification of a large background class and a small minority class composed of instances that may pose a risk to humans and the environment. Accurate classification of such instances is required in a variety of domains, spanning event and port security to national monitoring for failures at industrial nuclear facilities. This work proposes a novel form of synthetic oversampling based on artificial neural network architecture and empirically demonstrates that it is superior to the state-of-the-art in synthetic oversampling on the target domain. In particular, we utilize gamma-ray spectral data collected for security purposes at the Vancouver 2010 winter Olympics and on a node of Health Canada's national monitoring networks.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424443","artificial neural networks;autoencoders;class imbalance;classification;gamma-ray spectra;machine learning;synthetic oversampling","Gamma-rays;Isotopes;Machine learning algorithms;Monitoring;Neural networks;Security;Training","radioactive waste","Health Canadas national monitoring networks;Vancouver 2010;advanced radioactive threat detection;gamma-ray spectral classification;industrial nuclear facilities","","2","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Hierarchical Deep Neural Network for Fault Diagnosis on Tennessee-Eastman Process","D. Xie; L. Bai","Coll. of Eng., Temple Univ., Philadelphia, PA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","745","748","This paper proposes a hierarchical deep neural network (HDNN) for diagnosing the faults on the Tennessee-Eastman process (TEP). The TEP process is a benchmark simulation model for evaluating process control and monitoring method. A supervisory deep neural network is trained to categorize the whole faults into a few groups. For each group of faults, a special deep neural network which is trained for the particular group is triggered for further diagnosis. The training and test data is generated from the Tennessee Eastman process simulation. The performance of the proposed method is evaluated and compared to single neural network (SNN) and duty-oriented hierarchical artificial neural network (DOHANN) methods. The results of experiment demonstrate that our method outperforms the SNN and DOHANN methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424410","Deep neural network;Tennessee-Eastman process;chemical engineering;fault diagnosis","Artificial neural networks;Biological neural networks;Fault diagnosis;Machine learning;Machine learning algorithms;Training","chemical engineering computing;fault diagnosis;learning (artificial intelligence);neural nets","Tennessee-Eastman process;duty-oriented hierarchical artificial neural network;fault diagnosis;hierarchical deep neural network;single neural network;supervisory deep neural network","","","","7","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Robust Vehicle Tracking Using Perceptual Hashing Algorithm","Z. Li; J. F. Yang; L. Chen; J. Zha","Sch. of Mobile Inf. Eng., Sun Yat-sen Univ., Zhuhai, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1111","1116","Vehicle tracking, significant in the computer vision using machine learning method, allows the vehicle to comprehend its immediate environment and therefore, enhances the intelligence of the vehicles and the safety of vehicle occupants. We propose a novel tracking algorithm that can work robustly under challenging circumstances such as road scene where several kinds of appearance and motion changes of a tracking object occur. Our algorithm is based on the perceptual hashing algorithm (PHA) and the color, low-frequency and rotation information are considered. By means of PHA, our tracker generates a single identification at each frame. The sliding windows produce a series of candidates between consecutive frames so that the new position of tracking object can be updated by comparing the binary code of candidates and identification. In the experiment, the quantitative and qualitative results are expressed by center location error(CLE) and VOC overlap ratio(VOR). Compared to the advanced tracker at present, PHA tracker shows its robustness when confronting violent changes of noise, illumination, background clutter and part occlusion, which demonstrates its state-of-the-art performance in the field of dynamic vehicle tracking.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424468","","Binary codes;Context;Discrete cosine transforms;Feature extraction;Robustness;Target tracking;Vehicles","clutter;computer vision;image colour analysis;lighting;object tracking;optical noise","PHA tracker;VOC overlap ratio;VOR;background clutter;binary code;center location error;color information;computer vision;illumination;low-frequency information;noise;object tracking;part occlusion;perceptual hashing algorithm;rotation information;sliding windows;vehicle tracking","","","","26","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Multi-level Resolution Features for Classification of Transportation Trajectories","A. Macdonald; J. Ellen","Sch. of Comput. Sci. & Eng., Univ. of California, San Diego, San Diego, CA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","713","718","We explore the use of filter-like multi-level resolution features of a positional trajectory for classification. Our approach is time and location agnostic which increases generality. Several filter types are discussed and used in feature extraction including moments and wavelets. Previous work by Bolbol et al. is extended to incorporate these features and results are shown for each framework and filter type. We attempt a 6-way classification of mode of transportation from GPS trajectories obtained from cell phone handsets. Our primary contribution is that our approach can classify an entire trajectory, regardless of its length, overcoming a deficiency in other approaches which require trajectories to be segmented into equal length parts. We achieve >60% accuracy split between 6 classes where the 'random' feature accuracy is <;28%, an 'informative' gain of over 30%..","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424404","filters;machine learning;trajectories","Bicycles;Feature extraction;Global Positioning System;Standards;Trajectory;Wavelet transforms","Global Positioning System;feature extraction;pattern classification;traffic engineering computing;transportation","6-way classification;GPS trajectories;cell phone handsets;feature extraction;filter-like multilevel resolution features;positional trajectory;transportation trajectories classification","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Detecting Erosion Events in Earth Dam and Levee Passive Seismic Data with Clustering","W. Belcher; T. Camp; V. V. Krzhizhanovskaya","Dept. of Electr. Eng. & Comput. Sci., Colorado Sch. of Mines, Golden, CO, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","903","910","Geophysical sensor technologies can be used to understand the structural integrity of Earth Dams and Levees (EDLs). We are part of an interdisciplinary team researching techniques for the advancement of EDL health monitoring and the automatic detection of internal erosion events. We present results from our performance study that uses signal processing, feature extraction, and unsupervised learning on passive seismic data from an experimental laboratory earth embankment. We used popular unsupervised clustering algorithms to gain insights to this real-world problem, and evaluated our results using internal and external validation techniques. In four of the clustering algorithms applied, results consistently show a clear separation of events from non-events. We provide proof of concept and an initial pattern recognition process that could be used as a tool for nonintrusive and long-term EDL monitoring.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424436","Earth levee;geophysical;machine learning;passive seismic;pattern recognition;signal processing;time series;unsupervised clustering","Clustering algorithms;Data mining;Earth;Feature extraction;Machine learning algorithms;Signal processing algorithms;Time series analysis","condition monitoring;dams;erosion;feature extraction;geophysical signal processing;pattern clustering;seismology;structural engineering computing;unsupervised learning;vibrations","EDL health monitoring;automatic detection;earth dams and levees;earth embankment;external validation techniques;feature extraction;geophysical sensor technologies;internal erosion events detection;internal validation techniques;long-term EDL monitoring;nonintrusive EDL monitoring;passive seismic data;pattern recognition;signal processing;structural integrity;unsupervised clustering algorithms;unsupervised learning","","1","","28","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Thompson Sampling Guided Stochastic Searching on the Line for Non-stationary Adversarial Learning","S. Glimsdal; O. C. Granmo","Dept. of ICT, Univ. of Agder, Grimstad, Norway","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","687","692","This paper reports the first known solution to the N-Door puzzle when the environment is both non-stationary and deceptive (adversarial learning). The Multi-Armed-Bandit (MAB) problem is the iconic representation of the exploration versus exploitation dilemma. In brief, a gambler repeatedly selects and play, one out of N possible slot machines or arms and either receives a reward or a penalty. The objective of the gambler is then to locate the most rewarding arm to play, while in the process maximize his winnings. In this paper we investigate a challenging variant of the MAB problem, namely the non-stationary N-Door puzzle. Here, instead of directly observing the reward, the gambler is only told whether the optimal arm lies to the ""left"" or to the ""right"" of the selected arm, with the feedback being erroneous with probability 1 -- p. However, due to the non-stationary property the optimal arm can abruptly and without notice switch place with a previous sub-optimal arm. To further complicate the situation, we do not assume that the environment is informative, that is, we allow for a traitorous environment that on-average guide the gambler in the opposite direction of the optimal arm (adversarial learning problem). This coupled with the non-stationary property makes for a highly demanding reinforcement learning problem. The novel scheme presented in this paper enhance the previous top contender for the stationary N-door problem with the capability to detect and adapt to a changing environment. The resulting scheme TS-NSPL is then empirically proved to be superior to the existing state-of-art.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.203","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424399","Adversarial Learning;Bayesian Learning;Multi-armed Bandit Problem;N-Door Puzzle;Non-stationary;Stochastic Point Search;Thompson Sampling","Bayes methods;Learning (artificial intelligence);Mathematical model;Probabilistic logic;Search problems;Space exploration;Stochastic processes","feedback;learning (artificial intelligence);probability;sampling methods;stochastic processes","MAB problem;TS-NSPL;Thompson sampling guided stochastic searching;deceptive adversarial learning;exploitation dilemma;exploration dilemma;feedback;iconic representation;multiarmed-bandit problem;nonstationary adversarial learning;nonstationary n-door puzzle;nonstationary property;optimal arm;probability;reinforcement learning problem;slot machine;stationary N-door problem","","1","","19","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Simplicity of Kmeans Versus Deepness of Deep Learning: A Case of Unsupervised Feature Learning with Limited Data","M. Dundar; Q. Kou; B. Zhang; Y. He; B. Rajwa","Dept. of Comput. & Inf. Sci., Indiana Univ. - Purdue Univ., Indianapolis, IN, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","883","888","We study a bio-detection application as a case study to demonstrate that Kmeans -- based unsupervised feature learning can be a simple yet effective alternative to deep learning techniques for small data sets with limited intra-as well as inter-class diversity. We investigate the effect on the classifier performance of data augmentation as well as feature extraction with multiple patch sizes and at different image scales. Our data set includes 1833 images from four different classes of bacteria, each bacterial culture captured at three different wavelengths and overall data collected during a three-day period. The limited number and diversity of images present, potential random effects across multiple days, and the multi-mode nature of class distributions pose a challenging setting for representation learning. Using images collected on the first day for training, on the second day for validation, and on the third day for testing Kmeans -- based representation learning achieves 97% classification accuracy on the test data. This compares very favorably to 56% accuracy achieved by deep learning and 74% accuracy achieved by handcrafted features. Our results suggest that data augmentation or dropping connections between units offers little help for deep-learning algorithms, whereas significant boost can be achieved by Kmeans -- based representation learning by augmenting data and by concatenating features obtained at multiple patch sizes or image scales.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424433","bio-detection;deep learning;kmeans clustering;unsupervised feature learning","Encoding;Feature extraction;Machine learning;Microorganisms;Neural networks;Testing;Training","biology computing;data handling;feature extraction;image classification;image representation;microorganisms;unsupervised learning","K-means-based representation learning;K-means-based unsupervised feature learning;bacterial culture;biodetection application;data augmentation classifier performance;deep learning techniques;feature extraction;limited data;limited interclass diversity;limited intraclass diversity","","2","","14","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"RPC: An Efficient Classifier Ensemble Using Random Projections","L. Gondara","Dept. of Comput. Sci., Univ. of Illinois Springfield, Springfield, IL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","559","564","We propose a classifier ensemble called RPC based on principles of rotation forest using random projections. Random projections project the original high dimensional data into lower dimensions while preserving the dataset's geometrical structure reducing classifier's complexity. Random projections are also an efficient dimensionality reduction tool, removing noisy features from dataset and representing the information using only small number of features. Training set for RPC is created by applying random projection on random subsets of the feature set. The randomness of random projection coupled with random sampling adds diversity to RPC. Initial evaluation using datasets from UCI machine learning repository shows that RPC performs equally well or better than Random Forest, Bagging and AdaBoost. We demonstrate that using dimensionality reduction with RPC we can dramatically reduce datasets dimensions without any loss in classification accuracy and significantly enhance computational performance. Finally, we experiment building RPC with different base learners.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424375","Bagging;Classifier ensembles;Dimensionality reduction;Feature extraction;Random Forest;Random Projection","Bagging;Decision trees;Diversity reception;Principal component analysis;Radio frequency;Standards;Training","computational complexity;geometry;learning (artificial intelligence);pattern classification","AdaBoost;RPC;UCI machine learning repository;bagging;classifier complexity;efficient classifier ensemble;geometrical structure;high dimensional data;random projections;rotation forest","","","","33","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Probabilistic Graphical Models and Deep Belief Networks for Prognosis of Breast Cancer","M. Khademi; N. S. Nedialkov","Dept. of Comput. & Software, McMaster Univ., Hamilton, ON, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","727","732","We propose a probabilistic graphical model (PGM) for prognosis and diagnosis of breast cancer. PGMs are suitable for building predictive models in medical applications, as they are powerful tools for making decisions under uncertainty from big data with missing attributes and noisy evidence. Previous work relied mostly on clinical data to create a predictive model. Moreover, practical knowledge of an expert was needed to build the structure of a model, which may not be accurate. In our opinion, since cancer is basically a genetic disease, the integration of microarray and clinical data can improve the accuracy of a predictive model. However, since microarray data is high-dimensional, including genomic variables may lead to poor results for structure and parameter learning due to the curse of dimensionality and small sample size problems. We address these problems by applying manifold learning and a deep belief network (DBN) to microarray data. First, we construct a PGM and a DBN using clinical and microarray data, and extract the structure of the clinical model automatically by applying a structure learning algorithm to the clinical data. Then, we integrate these two models using softmax nodes. Extensive experiments using real-world databases, such as METABRIC and NKI, show promising results in comparison to Support Vector Machines (SVMs) and k-Nearest Neighbors (k-NN) classifiers, for classifying tumors and predicting events like recurrence and metastasis.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424407","breast cancer;deep belief networks;microarray data;probabilistic graphical models","Approximation algorithms;Breast cancer;Manifolds;Probabilistic logic;Prognostics and health management;Training","bioinformatics;cancer;genomics;graph theory;learning (artificial intelligence);pattern classification;probability;tumours","DBN;METABRIC database;NKI database;PGM;SVM classifier;breast cancer diagnosis;breast cancer prognosis;clinical data integration;curse-of-dimensionality;deep-belief networks;genetic disease;genomic variables;high-dimensional microarray data;k-NN classifier;k-nearest neighbors classifier;manifold learning;medical applications;metastasis event prediction;microarray data integration;parameter learning;predictive model;predictive model accuracy improvement;probabilistic graphical model;recurrence event prediction;softmax nodes;structure learning;structure learning algorithm;support vector machine classifier;tumors","","","","20","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Multiscale Spectral Method for Learning Number of Clusters","A. Little; A. Byrd","Dept. of Math., Jacksonville Univ., Jacksonville, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","457","460","We propose a novel multiscale, spectral algorithm for estimating the number of clusters in a data set. Our algorithm computes the eigenvalues of the graph Laplacian iteratively for a large range of values of the scale parameter, and estimates the number of clusters from the maximal eigengap. Thus variation of the scale parameter, which usually confuses the clustering problem, is used to infer the number of clusters in a robust and efficient way. Commute distances are used to transform the distance matrix into a block-diagonal form, allowing the algorithm to succeed on irregularly shaped clusters, and the algorithm is applied to test data sets (both simulated and real-world) for method validation.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424357","Clustering;Multiscale Analysis;Spectral Methods","Clustering algorithms;Eigenvalues and eigenfunctions;Euclidean distance;Laplace equations;Machine learning algorithms;Robustness","eigenvalues and eigenfunctions;graph theory;learning (artificial intelligence);matrix algebra;pattern clustering","block-diagonal matrix form;cluster number learning;distance matrix;eigengap;eigenvalue;graph Laplacian;multiscale spectral method;scale parameter","","","","32","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Prediction of Continuous Phenotypes in Mouse, Fly, and Rice Genome Wide Association Studies with Support Vector Regression SNPs and Ridge Regression Classifier","A. Aljouie; U. Roshan","Dept. of Comput. Sci., New Jersey Inst. of Technol., Newark, NJ, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1246","1250","The ranking of SNPs and prediction of phenotypes in continuous genome wide association studies is a subject of increasing interest with applications in personalized medicine and animal and plant breeding. The ranking of SNPs in case control (discrete label) genome wide association studies has been examined in several previous studies with machine learning techniques but this is poorly explored for studies with quantitative labels. Here we study ranking of SNPs in mouse, fly, and rice continuous genome wide association studies given by the popular univariate Pearson correlation coefficient and the multivariate support vector regression and ridge regression. We perform cross-validation with the support vector regression and ridge regression models on top ranked SNPs and compute correlation coefficients between true and predicted phenotypes. Our results show that ridge regression prediction with top ranked support vector regression SNPs gives the highest accuracy. On all datasets we achieve accuracies comparable to previously published values but with fewer SNPs. Our work shows we can learn parsimonious SNP models for predicting continuous labels in genome wide studies.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.224","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424492","Phenotype prediction;SNP selection;genome wide association studies;ridge regression;support vector regression","Bioinformatics;Correlation;Genomics;Mice;Predictive models;Support vector machines;Training","biology computing;genomics;regression analysis;support vector machines","SNP;animal breeding;continuous phenotypes;fly;mouse;multivariate support vector regression;personalized medicine;rice genome wide association studies;ridge regression classifier;univariate Pearson correlation coefficient","","","","27","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Bayesian Classification Approach to Improving Performance for a Real-World Sales Forecasting Application","C. Gallagher; M. G. Madden; B. D'Arcy","Coll. of Eng. & Inf., Nat. Univ. of Ireland Galway, Galway, Ireland","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","475","480","Many businesses rely on forecasting techniques to detect whether sales opportunities are likely to be won or at risk of being lost. This enables the businesses to respond proactively. This paper describes a new method of sales forecasting that improves on an existing Qualitative Sales Predictor (QSP) in Hewlett-Packard (HP). QSP is based on a series of qualitative assessments that are made by sales personnel, the results of which are combined using weighted factors. In this research, we have developed an alternative method of forecasting sales opportunities, with three key differences: (1) the qualitative assessments are supplemented with quantitative data describing attributes of the opportunity, (2) we replace the weight factors with a Tree Augmented Naïve Bayes (TAN) classifier that can capture dependences between variables and produces a probabilistic output to which thresholds can be applied, (3) the TAN classifier is of course learned from historical data, whereas the existing QSP has fixed weights. Our approach has an accuracy of 90.6% in predicting whether sales will be won or lost, a substantial improvement on the existing approach's accuracy of 75.6% on the same unseen test data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424361","Bayesian models;classification;data analytics;machine learning;sales forecasting;tree augmented na??ve Bayes","Bayes methods;Classification algorithms;Contracts;Forecasting;Niobium;Predictive models","learning (artificial intelligence);marketing data processing;pattern classification;sales management","Bayesian classification approach;Hewlett-Packard;QSP;TAN classifier;opportunity attribute;probabilistic output;qualitative assessment;qualitative sales predictor;real-world sales forecasting application;tree augmented naive Bayes classifier;weighted factors","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Data-Based Statistical Models of Data Networks","A. e. Kuleshov; A. Bernstein; Y. Agalakov","Inst. for Inf. Transm. Problems, Moscow, Russia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","433","438","Machine (Statistical) learning methods are used for predicting the delivery times of the packages transmitted through the data network (DN). The statistical model of the DN is proposed, this model allows predicting the delivery times depending on a state of the DN (network load) and the statistical dependences between the delivery times of different transmitted packages. For constructing this model, various statistical methods (forecasting, dimensionality reduction) are applied to the data which are the results of computational experiments performed with detailed simulation model of the DN. The constructed model simulates the processes of package transmission over the DN. Motivation for a construction of such model is a need to create Monte Carlo network simulators to imitate the delivery times of transmitted packages, such simulators can be used in modeling of Information and Control Systems whose objects communicate with each other through the DN.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424352","data network simulation;dimensionality reduction;forecasting;information and control systems modeling;statistical learning;surrogate modeling","Biological system modeling;Computational modeling;Covariance matrices;Data models;Integrated circuit modeling;Load modeling;Predictive models","Monte Carlo methods;data analysis;learning (artificial intelligence);statistical analysis","DN;Monte Carlo network simulators;data networks;data-based statistical models;dimensionality reduction method;forecasting method;information-and-control system modeling;machine learning methods;network load;simulation model;transmitted package delivery time prediction","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Path for Kernel Adaptive One-Class Support Vector Machine","V. K. Le; P. Beauseroy","Inst. Charles Delauna, Univ. of Technol. of Troyes, Troyes, France","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","503","508","This paper proposes a Kernel Adaptive One Class SVM (KAOC-SVM) method based on the model introduced by A. Scholkopf and al. [7]. The aim is to find the solution path - the path of Lagrange multiplier a - as the kernel parameter changes from one value to another. It is similar to the regularization path approach proposed by Hastie and al. [2], which finds the path when the regularization parameter ? changes from 0 to 1. In present case, the main difference is that the Lagrange multiplier paths are not piecewise linear anymore. Experimental results show that the proposed method is able to compute one-class SVMs with the same accuracy as traditional method but exploring all solutions combining 2 kernels. Simulation results are presented and CPU requirement is analyzed.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424366","Adaptive method;Machine learning;One class SVM;SVM","Convergence;Electronic mail;Indexes;Kernel;Proposals;Support vector machines;Training","support vector machines","KAOC-SVM method;Lagrange multiplier;kernel adaptive one-class support vector machine;kernel parameter;regularization parameter;regularization path approach","","","","15","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
