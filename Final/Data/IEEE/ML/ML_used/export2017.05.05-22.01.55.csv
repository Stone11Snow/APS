"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6720751,6722274,6722234,6718248,6719267,6714674,6719956,6719856,6718265,6718267,6717241,6719875,6714778,6690197,6714067,6716495,6714957,6600804,6687233,6710346,6713749,6710356,6705583,6502216,6514923,6707198,6704442,6703755,6703097,6704185,6707649,6560375,6707569,6693358,6695836,6693415,6693350,6693432,6698975,6693365,6693152,6693452,6694026,6693442,6595571,6693117,6694077,6697978,6693500,6699018,6693355,6694712,6584807,6646259,6693087,6699052,6694781,6693353,6693521,6693529,6699061,6693515,6691669,6691736,6691737,6691730,6690092,6690618,6690771,6690053,6690735,6691731,6691746,6691627,6691752,6690652,6399471,6689035,6685487,6689032,6686058,6686263,6686063,6682136,6680058,6681508,6682236,6681552,6681372,6681379,6681555,6680499,6681260,6679819,6679853,6682061,6682934,6680357,6514032,6676933",2017/05/05 22:01:55
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Breaking free from your information prison: A recommender based on semantically enriched context descriptions","J. Lutz; B. Thönssen; H. F. Witschel","FHNW, Univ. of Appl. Sci. & Arts Northwestern Switzerland, Olten, Switzerland","Proceedings of the First International Conference on Enterprise Systems: ES 2013","20131223","2013","","","1","9","Information repositories, implemented as Enterprise Portals (EP) on the intranet, are increasingly popular in companies of all sizes. Enterprise Portals allow for structuring information in a way that resembles the organization of paper copies, i.e. simulating folders and registries and furthermore, provide simple routines for publishing and collaborating. Hence, in general, such kind of information management is not much different from paper management: electronic documents must be uploaded into the Enterprise Portal manually, filed into folders (which have to be created manually, too), tagged and related to other information objects if need be. With this approach information structuring remains subject to the individual user leading to the well-known problems of multiple filing, overlooking relevant information and incomprehensible folder structure. The SEEK!sem project aims at improving such kind of information system by automatically identifying and recommending related information resources to be added to a folder. The recommendations are based on rules, exploiting content and context similarity of information resources. Rules can be created upfront, based on explicitly defined relations between information objects. They can also be machine learned, i.e. the recommender exploits the existing linkage between documents, folders and other objects to learn “relatedness rules”. In either case, potential new connections are inferred by applying the rules in a reasoning step. Recommended new connections are ranked by the sum of the scores of all applied rules - the rule scores, again, can either be provided by experts or machine-learned. The applied rules can serve as an explanation of a recommendation, i.e. they can assist users in understanding why a particular connection is suggested.","","Electronic:978-1-4673-6412-6; POD:978-1-4673-6413-3","10.1109/ES.2013.6690092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690092","context;information management;machine learning;similarity","Abstracts;Context;Information management;Information services;Ontologies;Portals","Web sites;business data processing;intranets;learning (artificial intelligence);portals;recommender systems","SEEK!sem project;context similarity;electronic documents;enterprise portals;incomprehensible folder structure;information management;information prison;information repositories;information resources;information system;intranet;machine learning;paper management;recommender system;relatedness rules;semantically enriched context descriptions","","1","","27","","","7-8 Nov. 2013","","IEEE","IEEE Conference Publications"
"Novel methods for feature extraction based on motion history images and evaluation with regard to altering viewing angles","J. Richter; G. Hirtz","Dept. of Electr. Eng. & Inf. Technol., Chemnitz Univ. of Technol., Chemnitz, Germany","2013 IEEE Third International Conference on Consumer Electronics ¿¿ Berlin (ICCE-Berlin)","20140102","2013","","","1","5","In recent years Western countries have been facing the impact of demographic change. Due to factors such as a rising lifetime expectancy and a decreasing birth rate, our society is getting older. This development is accompanied by constant lack of nursing staff, which leads to an imbalance of people who need care and professionally trained personnel caring for them. There already is a variety of approaches investigating vision-based action recognition. In this paper novel methods for feature extraction from motion history images are proposed.","2166-6814;21666814","Electronic:978-1-4799-1412-8; POD:978-1-4799-1410-4","10.1109/ICCE-Berlin.2013.6697978","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6697978","AAL;ADL;action recognition;image models;machine learning;motion history image;view variance","Cameras;Feature extraction;History;Materials;Support vector machine classification;Training","feature extraction;image motion analysis;image recognition;medical image processing;patient care","Western country;altering viewing angle;feature extraction;motion history imaging;nursing staff;professionally trained personnel;vision-based action recognition","","0","","6","","","9-11 Sept. 2013","","IEEE","IEEE Conference Publications"
"Using coreference and surrounding contexts for entity linking","H. M. Huynh; T. T. Nguyen; T. H. Cao","University of Technology - VNUHCM, Vietnam","The 2013 RIVF International Conference on Computing & Communication Technologies - Research, Innovation, and Vision for Future (RIVF)","20140123","2013","","","1","5","Ambiguity in meanings of words or phrases in a document is considered one of the most primary barriers in natural language processing. In this work, we address the task of identifying and linking mentions of entities into correct referents described in a given knowledge base. To deal with it, we propose a supervised learning method for ranking candidate entities in combination with exploiting a heuristic and coreference relations among mentions in a document. Furthermore, another advantage of our method is its simplicity and effectiveness with using much fewer features than other systems. The results from evaluation on TAC-KBP 2012 datasets show that our combination is efficient and this method has a comparable performance to the state-of-the-art ones.","","Electronic:978-1-4799-1350-3; POD:978-1-4799-1348-0","10.1109/RIVF.2013.6719856","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719856","coreference;entity disambiguation;machine learning;wikification","Electronic publishing;Encyclopedias;Internet;Joining processes;Knowledge based systems;Text analysis","knowledge based systems;learning (artificial intelligence);natural language processing","TAC-KBP 2012 dataset;coreference relation;entity disambiguation;entity linking;heuristic relation;knowledge base;natural language processing;supervised learning method","","1","","26","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"Stress Recognition Using Wearable Sensors and Mobile Phones","A. Sano; R. W. Picard","Affective Comput. Group, Massachusetts Inst. of Technol. Media Lab., Cambridge, MA, USA","2013 Humaine Association Conference on Affective Computing and Intelligent Interaction","20131212","2013","","","671","676","In this study, we aim to find physiological or behavioral markers for stress. We collected 5 days of data for 18 participants: a wrist sensor (accelerometer and skin conductance), mobile phone usage (call, short message service, location and screen on/off) and surveys (stress, mood, sleep, tiredness, general health, alcohol or caffeinated beverage intake and electronics usage). We applied correlation analysis to find statistically significant features associated with stress and used machine learning to classify whether the participants were stressed or not. In comparison to a baseline 87.5% accuracy using the surveys, our results showed over 75% accuracy in a binary classification using screen on, mobility, call or activity level information (some showed higher accuracy than the baseline). The correlation analysis showed that the higher-reported stress level was related to activity level, SMS and screen on/off patterns.","2156-8103;21568103","Electronic:978-0-7695-5048-0; POD:978-1-4799-0632-1","10.1109/ACII.2013.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681508","accelerometer;classification;machine learning;mobile phone;skin conductance;smart phone;stress;wearable sensor","Accuracy;Biomedical monitoring;Feature extraction;Mobile handsets;Mood;Skin;Stress","emotion recognition;learning (artificial intelligence);neurophysiology;pattern classification;sensors;smart phones;wearable computers","SMS;behavioral marker;binary classification;correlation analysis;higher-reported stress level;machine learning;mobile phone usage;mobile phones;mobility;physiological marker;screen on/off pattern;stress recognition;wearable sensors;wrist sensor","","42","","23","","","2-5 Sept. 2013","","IEEE","IEEE Conference Publications"
"A Gesture Learning Interface for Simulated Robot Path Shaping With a Human Teacher","P. M. Yanik; J. Manganelli; J. Merino; A. L. Threatt; J. O. Brooks; K. E. Green; I. D. Walker","Dept. of Eng. & Technol., Western Carolina Univ., Cullowhee, NC, USA","IEEE Transactions on Human-Machine Systems","20140116","2014","44","1","41","54","Recognition of human gestures is an active area of research integral for the development of intuitive human-machine interfaces for ubiquitous computing and assistive robotics. In particular, such systems are key to effective environmental designs that facilitate aging in place. Typically, gesture recognition takes the form of template matching in which the human participant is expected to emulate a choreographed motion as prescribed by the researchers. A corresponding robotic action is then a one-to-one mapping of the template classification to a library of distinct responses. In this paper, we explore a recognition scheme based on the growing neural gas (GNG) algorithm that places no initial constraints on the user to perform gestures in a specific way. Motion descriptors extracted from sequential skeletal depth data are clustered by GNG and mapped directly to a robotic response that is refined through reinforcement learning. A simple good/bad reward signal is provided by the user. This paper presents results that show that the topology-preserving quality of GNG allows generalization between gestured commands. Experimental results using an automated reward are presented that compare learning results involving single nodes versus results involving the influence of node neighborhoods. Although separability of input data influences the speed of learning convergence for a given neighborhood radius, it is shown that learning progresses toward emulation of an associative memory that maps input gesture to desired action.","2168-2291;21682291","","10.1109/TSMC.2013.2291714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6687233","Gesture recognition;human-robot interaction;machine learning;robots","Gesture recognition;Hidden Markov models;Neural networks;Robot sensing systems;Topology","gesture recognition;human-robot interaction;image classification;neurocontrollers;path planning;robot vision;robots","GNG algorithm;assistive robotics;associative memory;choreographed motion emulation;generalization;gesture learning interface;good-bad reward signal;growing neural gas;human gesture recognition;human teacher;input data separability;intuitive human-machine interfaces;motion descriptors;node neighborhoods;one-to-one mapping;reinforcement learning;sequential skeletal depth data;simulated robot path shaping;template classification;template matching;topology-preserving quality;ubiquitous computing","","11","","75","","20131218","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Automatic Chord Estimation from Audio: A Review of the State of the Art","M. McVicar; R. Santos-Rodríguez; Y. Ni; T. D. Bie","Dept. of Eng. Math., Univ. of Bristol, Bristol, UK","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20140114","2014","22","2","556","575","In this overview article, we review research on the task of Automatic Chord Estimation (ACE). The major contributions from the last 14 years of research are summarized, with detailed discussions of the following topics: feature extraction, modeling strategies, model training and datasets, and evaluation strategies. Results from the annual benchmarking evaluation Music Information Retrieval Evaluation eXchange (MIREX) are also discussed as well as developments in software implementations and the impact of ACE within MIR. We conclude with possible directions for future research.","2329-9290;23299290","","10.1109/TASLP.2013.2294580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6705583","Music information retrieval;expert systems;knowledge based systems;machine learning;supervised learning","Accuracy;Feature extraction;Harmonic analysis;Spectrogram;Time-frequency analysis;Tuning;Vectors","feature extraction;information retrieval;learning (artificial intelligence);music","ACE;MIR;MIREX;audio signal;automatic chord estimation;feature extraction;model training;music information retrieval evaluation exchange","","7","","105","","20140109","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"A Synergistic Framework for Geographic Question Answering","W. Chen; E. Fosler-Lussier; N. Xiao; S. Raje; R. Ramnath; D. Sui","Dept. of Comput. Sci. & Eng., Ohio State Univ. Columbus, Columbus, OH, USA","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","94","99","QA (question answering) systems designated for answering in-depth geographic questions are highly demanded but not quite available. Previous research has visited various individual aspects of a QA system but few synergistic frameworks have been proposed. This paper investigates the nature of geographic question formation and observes their unique linguistic structures that can be semantically translated into a spatial query. We create a new task of solving non-trivial questions using GIS (Geographic Information System) and test it with an associated corpus. A dynamic programming algorithm is developed for classification and voting algorithm for verification. Two types of ontologies are integrated for disambiguating and discriminating spatial terms. PostGIS serves as the GIS backend to provide domain expertise for spatial reasoning. Results show that exact answers can be returned quickly and correctly by our system. Contrast classification results in improved accuracy compared with the baseline which proves the effectiveness of proposed methods.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693500","dynamic programming;gis;machine learning;nlp;ontology;question answering;spatial SQL;voting algorithm","Accuracy;Cities and towns;Classification algorithms;Feature extraction;Geographic information systems;Knowledge discovery;Ontologies","computational linguistics;dynamic programming;geographic information systems;ontologies (artificial intelligence);pattern classification;question answering (information retrieval);spatial reasoning","PostGIS;QA system;associated corpus;contrast classification;dynamic programming algorithm;geographic information system;geographic question answering;geographic question formation;linguistic structures;nontrivial questions;ontologies;question answering system;spatial query;spatial reasoning;spatial terms;synergistic framework;voting algorithm","","2","","27","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Predicting the Performance of Opponent Models in Automated Negotiation","T. Baarslag; M. Hendrikx; K. Hindriks; C. Jonker","Interactive Intell. Group, Delft Univ. of Technol., Delft, Netherlands","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","2","","59","66","When two agents settle a mutual concern by negotiating with each other, they usually do not share their preferences so as to avoid exploitation. In such a setting, the agents may need to analyze each other's behavior to make an estimation of the opponent's preferences. This process of opponent modeling makes it possible to find a satisfying negotiation outcome for both parties. A large number of such opponent modeling techniques have already been introduced, together with different measures to assess their quality. The quality of an opponent model can be measured in two different ways: one is to use the agent's performance as a benchmark for the model's quality, the other is to directly evaluate its accuracy by using similarity measures. Both methods have been used extensively, and both have their distinct advantages and drawbacks. In this work we investigate the exact relation between the two, and we pinpoint the measures for accuracy that best predict performance gain. This leads us to new insights in how to construct an opponent model, and what we need to measure when optimizing performance.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690771","Intelligent agents;Machine learning;Multiagent systems","Accuracy;Analytical models;Bayes methods;Correlation;Current measurement;Estimation","learning (artificial intelligence);multi-agent systems","agent performance;automated negotiation;opponent model performance prediction;opponent modeling techniques;opponent preference estimation","","3","","16","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"Constructing Defect Predictors and Communicating the Outcomes to Practitioners","T. Taipale; M. Qvist; B. Turhan","EB (Elektrobit Wireless Commun. Ltd.), Finland","2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement","20131212","2013","","","357","362","Background: An alternative to expert-based decisions is to take data-driven decisions and software analytics is the key enabler for this evidence-based management approach. Defect prediction is one popular application area of software analytics, however with serious challenges to deploy into practice. Goal: We aim at developing and deploying a defect prediction model for guiding practitioners to focus their activities on the most problematic parts of the software and improve the efficiency of the testing process. Method: We present a pilot study, where we developed a defect prediction model and different modes of information representation of the data and the model outcomes, namely: commit hotness ranking, error probability mapping to the source and visualization of interactions among teams through errors. We also share the challenges and lessons learned in the process. Result: In terms of standard performance measures, the constructed defect prediction model performs similar to those reported in earlier studies, e.g. 80% of errors can be detected by inspecting 30% of the source. However, the feedback from practitioners indicates that such performance figures are not useful to have an impact in their daily work. Pointing out most problematic source files, even isolating error-prone sections within files are regarded as stating the obvious by the practitioners, though the latter is found to be helpful for activities such as refactoring. On the other hand, visualizing the interactions among teams, based on the errors introduced and fixed, turns out to be the most helpful representation as it helps pinpointing communication related issues within and across teams. Conclusion: The constructed predictor can give accurate information about the most error prone parts. Creating practical representations from this data is possible, but takes effort. The error prediction research done in Elektrobit Wireless Ltd is concluded to be useful and we will further improve the present- tions made from the error prediction data.","1949-3770;19493770","Electronic:978-0-7695-5056-5; POD:978-1-4799-1144-8","10.1109/ESEM.2013.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681379","data-driven decisions;error prediction;machine learning algorithms;prediction algorithms;software testing","Accuracy;Data mining;Data models;Error probability;Predictive models;Software;Testing","data visualisation;error statistics;learning (artificial intelligence);program testing;software metrics","data information representation;data-driven decisions;defect predictor construction;error probability mapping;error-prone section isolation;evidence-based management approach;expert-based decisions;hotness ranking;interaction source;interaction visualization;machine learning algorithms;outcome communication;performance measures;software analytics;source files;testing process","","3","","7","","","10-11 Oct. 2013","","IEEE","IEEE Conference Publications"
"Access Control Policy Extraction from Unconstrained Natural Language Text","J. Slankas; L. Williams","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2013 International Conference on Social Computing","20140102","2013","","","435","440","While access control mechanisms have existed in computer systems since the 1960s, modern system developers often fail to ensure appropriate mechanisms are implemented within particular systems. Such failures allow for individuals, both benign and malicious, to view and manipulate information that they should not otherwise be able to access. The goal of our research is to help developers improve security by extracting the access control policies implicitly and explicitly defined in natural language project artifacts. Developers can then verify and implement the extracted access control policies within a system. We propose a machine-learning based process to parse existing, unaltered natural language documents, such as requirement or technical specifications to extract the relevant subjects, actions, and resources for an access control policy. To evaluate our approach, we analyzed a public requirements specification. We had a precision of 0.87 with a recall of 0.91 in classifying sentences as access control or not. Through a bootstrapping process utilizing dependency graphs, we correctly identified the subjects, actions, and objects elements of the access control policies with a precision of 0.46 and a recall of 0.54.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693365","access control;documentation;machine learning;natural language processing;relation extraction;security","Access control;Grammar;Natural languages;Pattern matching;Process control;Speech","authorisation;learning (artificial intelligence);natural language processing;pattern classification;text analysis","access control mechanisms;access control policy extraction;actions element;bootstrapping process;dependency graphs;machine learning based process;natural language documents;natural language project artifacts;objects element;public requirements specification;security improvement;sentence classification;subjects element;unconstrained natural language text","","2","","19","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Heuristically-Accelerated Multiagent Reinforcement Learning","R. A. C. Bianchi; M. F. Martins; C. H. C. Ribeiro; A. H. R. Costa","Department of Electrical Engineering, Centro Universit&#x00E1;rio da FEI, S&#x00E3;o Bernardo do Campo, Brazil","IEEE Transactions on Cybernetics","20140114","2014","44","2","252","265","This paper presents a novel class of algorithms, called Heuristically-Accelerated Multiagent Reinforcement Learning (HAMRL), which allows the use of heuristics to speed up well-known multiagent reinforcement learning (RL) algorithms such as the Minimax-Q. Such HAMRL algorithms are characterized by a heuristic function, which suggests the selection of particular actions over others. This function represents an initial action selection policy, which can be handcrafted, extracted from previous experience in distinct domains, or learnt from observation. To validate the proposal, a thorough theoretical analysis proving the convergence of four algorithms from the HAMRL class (HAMMQ, HAMQ(λ), HAMQS, and HAMS) is presented. In addition, a comprehensive systematical evaluation was conducted in two distinct adversarial domains. The results show that even the most straightforward heuristics can produce virtually optimal action selection policies in much fewer episodes, significantly improving the performance of the HAMRL over vanilla RL algorithms.","2168-2267;21682267","","10.1109/TCYB.2013.2253094","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6502216","Artificial intelligence;heuristic algorithms;machine learning;multiagent systems","","learning (artificial intelligence);multi-agent systems","HAMRL algorithms;heuristic function;heuristically accelerated multiagent reinforcement learning;systematical evaluation;virtually optimal action selection","1","11","","39","","20130415","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Service Discovery Method Based on User Intent","Y. Kataoka; T. Watanabe; K. Tanaka; S. Higashino","NTT Service Evolution Labs., Nippon Telegraph & Telephonecorporation, Yokosuka, Japan","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","1","","473","480","This paper introduces a method that supports a user who has only a vague idea of service use in discovering suitable mobile applications. The proposal allows the user to add application functions after selecting the purpose of service use from a list of novel application functions. The proposal is based on our concept of ISHI (Intent of Service and Human Interface) which works as an interface between service and user. ISHI can automatically determine the importance level and the novelty level of an application from various data. The proposed method is based on not only natural language but also the structured data of mobile applications. User experiments show that the proposed method yields, compared to the conventional method, better performance with respect to the time duration of application search and the frequency of recourse to new service functions.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690053","information recommendation;machine learning;service discovery;service indexing","Androids;Humanoid robots;Indexing;Mobile communication;Natural languages;Silicon;Vectors","human factors;information retrieval;mobile computing;natural languages;recommender systems","ISHI;application functions;application search;importance level;intent of service and human interface;mobile applications;natural language;novelty level;recourse frequency;service discovery method;structured data;time duration;user experiments;user intent","","0","","11","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"The royal birth of 2013: Analysing and visualising public sentiment in the UK using Twitter","V. D. Nguyen; B. Varghese; A. Barker","Big Data Lab., Univ. of St Andrews, St. Andrews, UK","2013 IEEE International Conference on Big Data","20131223","2013","","","46","54","Analysis of information retrieved from microblog-ging services such as Twitter can provide valuable insight into public sentiment in a geographic region. This insight can be enriched by visualising information in its geographic context. Two underlying approaches for sentiment analysis are dictionary-based and machine learning. The former is popular for public sentiment analysis, and the latter has found limited use for aggregating public sentiment from Twitter data. The research presented in this paper aims to extend the machine learning approach for aggregating public sentiment. To this end, a framework for analysing and visualising public sentiment from a Twitter corpus is developed. A dictionary-based approach and a machine learning approach are implemented within the framework and compared using one UK case study, namely the royal birth of 2013. The case study validates the feasibility of the framework for analysis and rapid visualisation. One observation is that there is good correlation between the results produced by the popular dictionary-based approach and the machine learning approach when large volumes of tweets are analysed. However, for rapid analysis to be possible faster methods need to be developed using big data techniques and parallel methods.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691669","Twitter;aggregate sentiment;dictionary-based approach;machine learning;public opinion;royal birth;sentiment analysis","Correlation;Data visualization;Dictionaries;Real-time systems;Tiles;Twitter;Visualization","data visualisation;dictionaries;learning (artificial intelligence);social networking (online);text analysis","Twitter;UK case study;dictionary-based approach;geographic region;machine learning;microblogging services;public sentiment analysis;royal birth of 2013","","4","","25","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Kernel-Based Learning From Both Qualitative and Quantitative Labels: Application to Prostate Cancer Diagnosis Based on Multiparametric MR Imaging","É. Niaf; R. Flamary; O. Rouvière; C. Lartizien; S. Canu","Universit&#x00E9; de Lyon; CREATIS; CNRS UMR5220; INSERM U1044; INSA-Lyon; Universit&#x00E9; Lyon 1, Lyon, France","IEEE Transactions on Image Processing","20140120","2014","23","3","979","991","Building an accurate training database is challenging in supervised classification. For instance, in medical imaging, radiologists often delineate malignant and benign tissues without access to the histological ground truth, leading to uncertain data sets. This paper addresses the pattern classification problem arising when available target data include some uncertainty information. Target data considered here are both qualitative (a class label) or quantitative (an estimation of the posterior probability). In this context, usual discriminative methods, such as the support vector machine (SVM), fail either to learn a robust classifier or to predict accurate probability estimates. We generalize the regular SVM by introducing a new formulation of the learning problem to take into account class labels as well as class probability estimates. This original reformulation into a probabilistic SVM (P-SVM) can be efficiently solved by adapting existing flexible SVM solvers. Furthermore, this framework allows deriving a unique learned prediction function for both decision and posterior probability estimation providing qualitative and quantitative predictions. The method is first tested on synthetic data sets to evaluate its properties as compared with the classical SVM and fuzzy-SVM. It is then evaluated on a clinical data set of multiparametric prostate magnetic resonance images to assess its performances in discriminating benign from malignant tissues. P-SVM is shown to outperform classical SVM as well as the fuzzy-SVM in terms of probability predictions and classification performances, and demonstrates its potential for the design of an efficient computer-aided decision system for prostate cancer diagnosis based on multiparametric magnetic resonance (MR) imaging.","1057-7149;10577149","","10.1109/TIP.2013.2295759","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690197","Computer-assisted decision system;machine learning;maximal margin algorithm;medical imaging;multiparametric magnetic resonance imaging;support vector machines;uncertain labels","Estimation;Kernel;Labeling;Probabilistic logic;Support vector machines;Training;Uncertainty","biological tissues;biomedical MRI;cancer;estimation theory;fuzzy systems;image classification;learning (artificial intelligence);medical image processing;probability;radiology;support vector machines","P-SVM;benign tissue;computer-aided decision system;fuzzy-SVM;kernel-based learning;malignant tissue;medical imaging;multiparametric MR imaging;multiparametric prostate magnetic resonance imaging;pattern classification;posterior probability estimation;probability support vector machine;prostate cancer diagnosis;radiologist;supervised classification;synthetic data set testing;training database","1","6","","30","","20131220","March 2014","","IEEE","IEEE Journals & Magazines"
"Exploring the relationships between students' learning styles and social media use in educational settings","F. Leon; E. Popescu","Dept. of Comput. Sci. & Eng., Tech. Univ. Gheorghe Asachi of Iasi, Iasi, Romania","2013 17th International Conference on System Theory, Control and Computing (ICSTCC)","20131219","2013","","","657","662","With the growing popularity of Web 2.0 tools in educational settings, it becomes important to investigate the influence of students' learning styles on the adoption and use of these emerging tools. Currently, there are only few studies addressing this issue and most of them are based on student self-reported data, e.g., preference, acceptance or attitude toward social media tools, captured by means of questionnaires. This paper explores the relationships between actual students' use of the Web 2.0 tools and their learning styles classified according to Felder-Silverman model. The context of the study is an undergraduate course on Web Applications' Design, with 45 enrolled students. Several machine learning algorithms for classification, association rule induction and feature selection are applied. Results show that learning styles have a limited influence on the students' level of interaction with each of the four Web 2.0 tools considered.","","CD-ROM:978-1-4799-2227-7; Electronic:978-1-4799-2228-4; POD:978-1-4799-2229-1","10.1109/ICSTCC.2013.6689035","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6689035","learning styles;machine learning algorithms;social media","Blogs;Electronic publishing;Information services;Media;Twitter;Web 2.0","Internet;computer aided instruction;data mining;learning (artificial intelligence);pattern classification","Felder-Silverman model;Web 2.0 tools;Web application design;association rule induction;classification;educational settings;feature selection;learning styles;machine learning algorithms;social media use;student self-reported data;undergraduate course","","1","","20","","","11-13 Oct. 2013","","IEEE","IEEE Conference Publications"
"Happiness Recognition from Mobile Phone Data","A. Bogomolov; B. Lepri; F. Pianesi","SKIL Telecom Italia Lab., Univ. of Trento, Trento, Italy","2013 International Conference on Social Computing","20140102","2013","","","790","795","In this paper we provide the first evidence that daily happiness of individuals can be automatically recognized using an extensive set of indicators obtained from the mobile phone usage data (call log, sms and Bluetooth proximity data) and ``background noise'' indicators coming from the weather factor and personality traits. Our final machine learning model, based on the Random Forest classifier, obtains an accuracy score of 80.81% for a 3-class daily happiness recognition problem. Moreover, we identify and discuss the indicators, which have strong predictive power in the source and the feature spaces, discuss different approaches, machine learning models and provide an insight for future research.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693415","Affective Computing;Emotional State Recognition;Happiness Recognition;Human Behavior Analysis;Machine Learning;Mobile Phone Usage Patterns;Pervasive Computing;Reality Mining;Recognition Systems;Social Computing;Subjective Well-Being","Educational institutions;Educational robots;Mechatronics;Project management;Service robots","behavioural sciences computing;learning (artificial intelligence);mobile computing;mobile handsets;pattern classification","3-class daily happiness recognition problem;background noise indicators;machine learning model;mobile phone data;mobile phone usage data;personality traits;random forest classifier;weather factor","","10","","32","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"A Generic Learning Approach to Modelling Netflows from Historic Observations","P. A. Chronz; F. Feldhaus; P. Kasprzak","","2012 7th Open Cirrus Summit","20140102","2012","","","30","34","In this paper we present a generic learning algo- rithm that models the communication patterns between services. Current service landscapes especially in federated environments are characterized by a huge number of services and by a high de- gree of change. In this paper we present a method for quantifying the communication patterns between services in a autonomous fashion to allow predictions of future usage patterns in the service landscape for optimization and simulation. The proposed learning algorithm uses machine learning techniques and generates a probabilistic model based on observed network flow information. We perform the learning and evaluate the learning algorithm based on real world netflow data captured on a cloud testbed. The paper finally discusses potential applications of the proposed algorithm in a autonomous optimization framework for service management.","","Electronic:978-0-7695-4908-8; POD:978-1-4673-4652-8","10.1109/OCS.2012.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6695836","autonomic computing;clustering;communication patterns;machine learning;model combination;netflows;workload prediction","Computational modeling;Correlation;Data models;Hidden Markov models;Optimization;Prediction algorithms;Predictive models","IP networks;cloud computing;learning (artificial intelligence);optimisation;probability;telecommunication traffic","Netflow modelling;autonomous optimization framework;cloud testbed;communication pattern modelling;generic learning approach;historic observation;machine learning techniques;network flow information;probabilistic model;service landscape;service management;usage pattern prediction","","0","","13","","","19-20 June 2012","","IEEE","IEEE Conference Publications"
"Experiments on company name disambiguation with supervised classification techniques","N. Polat","Dept. of Electr. & Comput. Eng., Istanbul Sehir Univ., Istanbul, Turkey","2013 International Conference on Electronics, Computer and Computation (ICECCO)","20140123","2013","","","139","142","Entity disambiguation is the task of identifying the real world entity was referred to in a context. Ambiguous references to entities can occur due to variations of how entity was referenced (BT, British Telecom) or inherit ambiguities of the names used for entities (Orange Telecom vs. fruit orange) and misspellings (Best Buy vs. BestBuy). Ambiguities in company names however come with a price, when it comes to finding information about the company on the Web. Recently, tracking social media for brand management has become a very important part of the process in marketing, public relations, and product marketing. Therefore, resolving references to the real world objects has become an important part of the social media analytics systems. In this paper, we study different machine learning techniques for entity disambiguation in micro-blogging posts. Our experiments show that using supervised algorithms with carefully selected features, one can improve the disambiguation quality significantly.","","Electronic:978-1-4799-3343-3; POD:978-1-4799-3344-0","10.1109/ICECCO.2013.6718248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718248","Information Retrieval;Machine Learning;Twitter;name ambiguity;online reputation management","Accuracy;Companies;Encyclopedias;Feature extraction;Twitter","Internet;information retrieval;learning (artificial intelligence);marketing data processing;pattern classification;social networking (online)","World Wide Web;brand management;company name disambiguation;entity disambiguation;entity identification;information retrieval;machine learning techniques;microblogging posts;product marketing;public relations;social media analytics systems;supervised classification techniques","","0","","14","","","7-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"News and Sentiment Analysis of the European Market with a Hybrid Expert Weighting Algorithm","G. G. Creamer; Y. Ren; Y. Sacamoto; J. V. Nickerson","Stevens Inst. of Technol., Hoboken, NJ, USA","2013 International Conference on Social Computing","20140102","2013","","","391","396","This paper proposes a hybrid human machine system based on an expert weighting algorithm that combines the responses of both humans and machine learning algorithms. The general topic of the paper is the use of the crowd to interpret text, and the power of that interpretation to predict future events. This topic is addressed through an experiment, in which news sentiment is evaluated by crowds and experts in different configurations. Their classifications are used as training sets for machine learning algorithms, including one that weights both machine and human predictions. The testing is done based on Thomson Reuters news stories and the returns of the stocks mentioned right after the stories appear. The hybrid expert weighting algorithm forecasts asset returns similar to the different versions of the trained and crowd groups because it combines the best results of the machine learning algorithms with human answers. The forecast of the expert weighting algorithm does not always show the best performance in comparison with the other learning algorithms, however its performance is very similar to the best algorithm in most cases. From a cognitive perspective, the capacity of the expert weighting algorithm to select dynamically the best expert according to its previous performance is consistent with an evolving collective intelligence: the final decision is a combination of the best individual answers - some of these come from machines, and some from humans.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693358","Computational finance;cognitive modeling;crowdsourcing;machine learning;text analysis","Algorithm design and analysis;Heuristic algorithms;Machine learning algorithms;Market research;Niobium;Prediction algorithms;Support vector machines","learning (artificial intelligence);market opportunities","European market;Thomson Reuters news stories;hybrid expert weighting algorithm;hybrid human machine system;machine learning;sentiment analysis;training sets","","0","","39","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Control and prediction of beliefs on social network","T. Wang; H. Krim","Dept. of Phys., North Carolina State Univ., Raleigh, NC, USA","2013 5th IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","20140120","2013","","","300","303","In this paper we propose a belief flow model for social networks and evaluate its application on estimation of public converged beliefs. The model reveals that the control of beliefs in a social network heavily depends on its degree centralities and clustering coefficients. The application of this model to social network belief flow simulation leads to a capacity to control and predict the converged beliefs in a social network. Two different network models, preferential attachment model and generalized Markov Graph model, are applied to the belief flow model. Experiments with published real social network data are provided and demonstrate very good performance of the belief flow model as well as a comparison between different network models.","","Electronic:978-1-4673-3146-3; POD:978-1-4673-3145-6","10.1109/CAMSAP.2013.6714067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714067","Information Flow;Machine Learning;Social Networks","Adaptation models;Analytical models;Computational modeling;Markov processes;Social network services;Training;Vectors","Markov processes;belief networks;graph theory;social networking (online)","belief control;belief flow model;clustering coefficients;generalized Markov graph model;information flow;preferential attachment model;social network belief flow simulation","","1","","9","","","15-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Entity Matching in Online Social Networks","O. Peled; M. Fire; L. Rokach; Y. Elovici","Dept. of Inf. Syst. Eng., Ben Gurion Univ., Beer-Sheva, Israel","2013 International Conference on Social Computing","20140102","2013","","","339","344","In recent years, Online Social Networks (OSNs) have essentially become an integral part of our daily lives. There are hundreds of OSNs, each with its own focus and offers for particular services and functionalities. To take advantage of the full range of services and functionalities that OSNs offer, users often create several accounts on various OSNs using the same or different personal information. Retrieving all available data about an individual from several OSNs and merging it into one profile can be useful for many purposes. In this paper, we present a method for solving the Entity Resolution (ER), problem for matching user profiles across multiple OSNs. Our algorithm is able to match two user profiles from two different OSNs based on machine learning techniques, which uses features extracted from each one of the user profiles. Using supervised learning techniques and extracted features, we constructed different classifiers, which were then trained and used to rank the probability that two user profiles from two different OSNs belong to the same individual. These classifiers utilized 27 features of mainly three types: name based features (i.e., the Soundex value of two names), general user info based features (i.e., the cosine similarity between two user profiles), and social network topological based features (i.e., the number of mutual friends between two users' friends list). This experimental study uses real-life data collected from two popular OSNs, Facebook and Xing. The proposed algorithm was evaluated and its classification performance measured by AUC was 0.982 in identifying user profiles across two OSNs.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693350","Entity Resolution;Machine Learning;Online Social Networks","Crawlers;Erbium;Facebook;Feature extraction;Training;Vectors","information retrieval;learning (artificial intelligence);social networking (online);topology","AUC;ER;Facebook;OSN;Xing;available data retrieval;entity matching;entity resolution;extracted features;machine learning techniques;online social networks;personal information;social network topological based features;supervised learning techniques;user profile matching","","15","1","9","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Automated pollen identification system for forensic geo-historical location applications","G. M. Hwang; K. C. Riley; C. T. Christou; G. M. Jacyna; J. P. Woodard; R. M. Ryan; M. B. Bush; B. G. Valencia; C. N. H. McMichael; S. W. Punyasena; D. L. Masters","MITRE Corp., McLean, VA, USA","2013 IEEE International Conference on Technologies for Homeland Security (HST)","20140102","2013","","","297","303","The use of pollen grain analysis for forensic geo-historical location has been explored for several decades, yet it is not widely adopted in the United States. We confirmed significant improvement in geographic precision, i.e., from 2.5×10<sup>7</sup> to 1.2×10<sup>5</sup> km<sup>2</sup>, by simultaneously applying flowering plant data from four different taxa at the genus and species levels. Moreover, when we calculated precision using collected pollen data, we found that co-occurring, pairwise genus-level distinctions based on expert-provided indicator taxa resulted in average precision values of 4° and 4.5° in latitude and longitude, respectively - corresponding to roughly 1.8×10<sup>5</sup> km<sup>2</sup>. We also applied computer vision techniques to identify morphologically similar pollen grains, which resulted in grain-identification error rates of 2.18% and 6.24% at the genus and species levels, respectively, surpassing previously published records. Collectively, our results demonstrate that algorithmic identification of species-specific pollen morphology, founded on established computer vision techniques, when combined with species-level pollen distribution, has the potential to revolutionize the scope, accuracy, and precision of forensic geographic attribution.","","CD-ROM:978-1-4799-3963-3; Electronic:978-1-4799-1535-4; POD:978-1-4799-3964-0","10.1109/THS.2013.6699018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6699018","Bayesian methods;GBIF;computer vision;geo-historical location;geographic attribution;machine learning;plant taxa;pollen forensics","Accuracy;Computer vision;Databases;Educational institutions;Feature extraction;Forensics;Three-dimensional displays","botany;computer vision;geophysical image processing;image classification","United States;computer vision techniques;expert-provided indicator taxa;flowering plant data;forensic geo-historical location applications;forensic geographic attribution;geographic precision;morphologically similar pollen grains;pairwise genus-level distinctions;pollen grain analysis;pollen identification system;species-level pollen distribution","","2","","25","","","12-14 Nov. 2013","","IEEE","IEEE Conference Publications"
"Handling Missing Syndromes in Board-Level Functional-Fault Diagnosis","F. Ye; S. Jin; Z. Zhang; K. Chakrabarty; X. Gu","ECE Dept., Duke Univ., Durham, NC, USA","2013 22nd Asian Test Symposium","20131223","2013","","","73","78","Functional fault diagnosis is widely used in board manufacturing to ensure product quality and improve product yield. Advanced machine-learning techniques have recently been advocated for reasoning-based diagnosis, these technologies are based on historical data of successfully repaired boards. However, traditional diagnosis systems fail to provide appropriate repair suggestions when the diagnostic logs are fragmented and some error outcomes, or syndromes, are not available during diagnosis. We describe the design of a diagnosis system, based on support vector machines, that can handle missing syndromes by using the method of imputation. Several imputation methods are discussed and compared in terms of their efficiency in handling missing syndromes. Two large-scale synthetic data sets generated from the log information of complex industrial boards in volume production are used to validate the proposed diagnosis system in terms of diagnosis accuracy and training time.","1081-7735;10817735","Electronic:978-0-7695-5080-0; POD:978-1-4799-0871-4","10.1109/ATS.2013.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690618","Board-level diagnosis;functional failure;label imputation;machine learning;missing syndrome","Accuracy;Engines;Fault diagnosis;Maintenance engineering;Support vector machines;Training;Training data","circuit analysis computing;circuit reliability;fault diagnosis;learning (artificial intelligence);printed circuits;product quality;support vector machines","advanced machine-learning techniques;board manufacturing;board-level functional-fault diagnosis system;complex industrial boards;diagnostic log information;imputation methods;large-scale synthetic data sets;missing syndromes;product quality;product yield;reasoning-based diagnosis;support vector machines","","2","","23","","","18-21 Nov. 2013","","IEEE","IEEE Conference Publications"
"An Evaluation of the Effect of Spam on Twitter Trending Topics","G. Stafford; L. L. Yu","Dept. of Comput. Sci., Pomona Coll., Claremont, CA, USA","2013 International Conference on Social Computing","20140102","2013","","","373","378","In this paper we investigate to what extent the trending topics in Twitter, a popular social network, are manipulated by spammers. Researchers have developed various models for spam detection in social media, but there has been little analysis on the effects of spam on Twitter's trending topics. We gathered over 9 million tweets in Twitter's hourly trending topics over a 7 day period and extracted tweet features identified by previous research as relevant to spam detection. Hand-labeling a random sample of 1500 tweets allowed us to train a moderately accurate naive Bayes classifier for tweet classification. Our findings suggest that spammers do not drive the trending topics in Twitter, but may opportunistically target certain topics for their messages.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693355","Twitter;data mining;machine learning;social networking analysis;spam","Feature extraction;Market research;Measurement;Twitter;Unsolicited electronic mail","Bayes methods;pattern classification;social networking (online)","Twitter trending topics;hand-labeling;naive Bayes classifier;social media;social network;spam detection;tweet classification","","3","","9","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Towards Identification of Software Improvements and Specification Updates by Comparing Monitored and Specified End-User Behavior","T. Roehm; B. Bruegge; T. M. Hesse; B. Paech","Tech. Univ. Munchen, Munich, Germany","2013 IEEE International Conference on Software Maintenance","20131202","2013","","","464","467","Support of end-user needs is an important success factor for a software application. In order to optimize the support of end-user needs, developers have to be aware of them and their evolution over time. But a communication gap between developers and users leads to ignorance of developers about how users use their application. Also, developer assumptions about user behavior are rarely tested and corrected if they are wrong. Consequently, many software applications have a mediocre support of user needs and user problems as well as changes in user needs are detected rather late. In this paper, we present a research agenda addressing this problem by comparing use case descriptions to monitored user actions. More specifically, we propose to monitor user actions using instrumentation, detect the current use case of a user using machine learning, and compare use case steps to monitored user actions. By detecting differences between both, we identify mismatches between user behavior and developer assumptions reflected in use case descriptions. Those mismatches can serve as starting points to identify software improvements, to test the use case specification and identify updates, and to revise training programs. Finally, we sketch a plan to evaluate our approach.","1063-6773;10636773","Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5","10.1109/ICSM.2013.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676933","Comparison of observed and specified behavior;Machine learning;Reverse modeling;Software evolution;Specification testing;Use case detection;User monitoring;User needs","Instruments;Monitoring;Object oriented modeling;Training;Usability;User interfaces","learning (artificial intelligence);program testing;software process improvement","machine learning;monitored end-user behavior;software improvement identification;software specification updates;specified end-user behavior;training programs;use case descriptions;use case specification testing;user action monitoring","","0","2","21","","","22-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"Approach Towards a Natural Language Analysis for Diagnosing Mood Disorders and Comorbid Conditions","N. Howard","Brain Sci. Found., Providence, RI, USA","2013 12th Mexican International Conference on Artificial Intelligence","20140123","2013","","","234","243","Here we propose an approach for developing a diagnosis system for mood disorders, such as depression and bipolar disorder, based on language analysis from speech and text. Our system is based on the Mood State Indicator algorithm (MSI) for real-time analysis of a patient's mental state. MSI is designed to give a quantitative measure of cognitive state based on axiological values and time orientation of lexical features. MSI's multi-layered analytic engine consists of multiple information processing modules to systematically retrieve, parse and process features of a patient's discourse. Gold standard clinical criteria will be used to match language analysis indicators to mood disorder diagnosis.","","Electronic:978-1-4799-2605-3; POD:978-1-4799-2606-0","10.1109/MICAI.2013.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714674","Mood State Indicator; LXIO; mood disorders; comorbid conditions; axiological values; machine learning;language analysis","Algorithm design and analysis;Context;Dementia;Machine learning algorithms;Pragmatics;Speech;Training data","cognition;computational linguistics;feature extraction;grammars;medical disorders;natural language processing;patient diagnosis;pattern matching;psychology;speech synthesis;text analysis","Gold standard clinical criteria;MSI algorithm;axiological values;comorbid conditions;feature parsing;feature processing;language analysis indicators matching;lexical feature orientation;mood disorder diagnosis;mood state indicator algorithm;multilayered analytic engine;multiple information processing module;natural language analysis;patient discourse;quantitative cognitive state measure;speech analysis;systematic feature retrieval;text analysis","","1","","26","","","24-30 Nov. 2013","","IEEE","IEEE Conference Publications"
"Comparison of different algorithms for sentiment classification","M. Ćirić; A. Stanimirović; N. Petrović; L. Stoimenov","Fac. of Electron. Eng., Univ. of Nis, Nis&#x030C;, Serbia","2013 11th International Conference on Telecommunications in Modern Satellite, Cable and Broadcasting Services (TELSIKS)","20140109","2013","02","","567","570","Sentiment classification has various applications and information from social networks can be especially useful. In this paper we perform sentiment classification of Twitter messages, so called tweets. We compare several machine learning classification algorithms and try to improve results by using processing pipes that extract meaningful features and remove noise.","","Electronic:978-1-4799-0902-5; POD:978-1-4799-0901-8","10.1109/TELSKS.2013.6704442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704442","Machine learning;Sentiment classification;Twitter","Accuracy;Classification algorithms;Entropy;Machine learning algorithms;Nickel;Training;Twitter","classification;learning (artificial intelligence);social networking (online)","Twitter messages;machine learning classification algorithms;processing pipes;sentiment classification;social networks;tweets","","0","","23","","","16-19 Oct. 2013","","IEEE","IEEE Conference Publications"
"Non-negative matrix factorization via projected gradient method for credit risk analysis","H. Chen; J. Ma; J. Liu; J. Wang","Dept. of Math., China Univ. of Min. & Technol., Xuzhou, China","2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering","20140109","2013","2","","119","122","Credit risk assessment of financial intermediaries is an essential problem in finance. The key is to find accurate predictors of individual risk in the credit portfolios of institutions. However, accessing credit risk is very difficult because many factors may contribute to the risk and their relationship is complicated to capture. In recent years, machine learning techniques, such as SVM classifier, have been successfully applied into the field of credit risk analysis. SVM is a strong classifier that is effective in capturing nonlinear relationship in the data. However, high dimensional training data not only results in time-consuming computation but also affects the performance of the classifier. In this paper, we will adopt non-negative matrix factorization via project gradient method to transform the data into lower dimensional space that will contribute to good performance in the credit risk classification. We test our method in a real-world credit risk prediction task, and our empirical results demonstrate the advantage of our method by comparing with other state of art methods.","2155-1456;21551456","Electronic:978-1-4799-0245-3; POD:978-1-4799-0243-9","10.1109/ICIII.2013.6703097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703097","credit risk analysis;feature extraction;machine learning;nonnegative matrix factorization;projected gradient method","Feature extraction;Gradient methods;Principal component analysis;Risk analysis;Support vector machines;Training;Training data","finance;gradient methods;learning (artificial intelligence);matrix decomposition;risk analysis;support vector machines","SVM classifier;credit portfolios;credit risk analysis;credit risk assessment;credit risk classification;dimensional space;essential problem;finance;financial intermediaries;high dimensional training data;machine learning;nonlinear relationship;nonnegative matrix factorization;project gradient method;real world credit risk prediction task;time consuming computation","","0","","13","","","23-24 Nov. 2013","","IEEE","IEEE Conference Publications"
"An improved BP algorithm over out-of-order streams for big data","Kun Wang; Linchao Zhuo; Heng Lu; Huang Guo; Lili Xu; Yuhua Zhang","Key Lab. of Broadband Wireless Commun. & Sensor Network Technol., Nanjing Univ. of Posts & Telecommun., Nanjing, China","2013 8th International Conference on Communications and Networking in China (CHINACOM)","20140102","2013","","","840","845","Due to the difficulty of getting the association rules over out-of-order streams for big data, a new improved BP algorithm based on dynamic adjustment is proposed. We firstly use a dynamic adaptive structural adjustment mechanism to change the network training structure according to the environmental requirements, which can automatically remove invalid training node, and optimize the iterative training process. Secondly, we adjust three factors (i.e. learning index, momentum factor and scaling factor) during the learning process to speed up the learning response, and to enhance the stability of the network. Simulation results show that compared with traditional BP algorithm, this algorithm can get more convergence times,the convergence rate can be improved effectively, and finally obtain the association rules over out-of-order data streams.","","Electronic:978-1-4799-1406-7; POD:978-1-4799-1405-0; USB:978-1-4799-1404-3","10.1109/ChinaCom.2013.6694712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694712","BP Algorithm;Big Data;Machine Learning;Out-of-order Streams","Association rules;Convergence;Heuristic algorithms;Indexes;Neurons;Simulation;Training","backpropagation;iterative methods;telecommunication computing","BP algorithm;big data;dynamic adaptive structural adjustment mechanism;iterative training process;learning index;momentum factor;network stability;network training structure;out-of-order data streams;out-of-order streams;scaling factor;training node","","0","","12","","","14-16 Aug. 2013","","IEEE","IEEE Conference Publications"
"Towards an Affective Brain-Computer Interface Monitoring Musical Engagement","G. Leslie; A. Ojeda; S. Makeig","Dept. of Music, Univ. of California San Diego, La Jolla, CA, USA","2013 Humaine Association Conference on Affective Computing and Intelligent Interaction","20131212","2013","","","871","875","A non-invasive way to monitor a music listener's level of engagement could give us a valuable tool for music classification, technology, and therapy. To investigate whether musical engagement can be monitored, we developed an experimental protocol using the mobile brain/body imaging (MoBI) paradigm in which participants make expressive rhythmic arm gestures to encourage and/or index musical engagement. Participants communicate the feeling pulse of music they are hearing via simple rhythmic U-shaped back-and-forth hand/arm 'conducting' gesture cycles that animate, in real time, the mirroring movement of a spot of light on a video display in front of them. Participants are asked to imagine that this display is also being viewed remotely by a deaf friend to whom they are attempting to communicate the feeling of the music they are hearing. In an Engaged condition, listeners are encouraged to fully engage themselves in this musical/emotional communication task. In a Not Engaged condition, a concurrent internal arithmetic distractor task is introduced to induce less fully engaged listening. Here, we report results of training a classifier using a frequency-based common spatial patterns (FBCSP) approach to correctly distinguish Engaged and Not Engaged conditions from concurrently recorded EEG data. Here the approach gave 67% classification accuracy across subjects (versus 50% chance), and 85% accuracy within subjects, cross-validated using a block wise paradigm.","2156-8103;21568103","Electronic:978-0-7695-5048-0; POD:978-1-4799-0632-1","10.1109/ACII.2013.163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681555","EEG;brain-computer interface;emotion;engagement;listening;machine learning;music","Accuracy;Brain modeling;Electroencephalography;Mathematical model;Monitoring;Music;Sensors","biomedical MRI;brain-computer interfaces;electroencephalography;gesture recognition;handicapped aids;human computer interaction;image classification;music;video signal processing","EEG data;FBCSP;MoBI;affective brain-computer interface;blockwise paradigm;concurrent internal arithmetic distractor task;deaf friend;emotional communication task;frequency-based common spatial patterns;machine learning;mobile brain-body imaging paradigm;music classification;music technology;music therapy;musical communication task;musical engagement monitoring;rhythmic U-shaped back-and-forth arm conducting gesture cycles;rhythmic U-shaped back-and-forth hand conducting gesture cycles;video display","","0","","24","","","2-5 Sept. 2013","","IEEE","IEEE Conference Publications"
"Rough Set Based Approach to Text Classification","L. Zhang; Y. Li; C. Sun; W. Nadee","Sch. of Electr. Eng. & Comput. Sci., Queensland Univ. of Technol., Brisbane, QLD, Australia","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","3","","245","252","Textual document set has become an important and rapidly growing information source in the web. Text classification is one of the crucial technologies for information organisation and management. Text classification has become more and more important and attracted wide attention of researchers from different research fields. In this paper, many feature selection methods, the implement algorithms and applications of text classification are introduced firstly. However, because there are much noise in the knowledge extracted by current data-mining techniques for text classification, it leads to much uncertainty in the process of text classification which is produced from both the knowledge extraction and knowledge usage, therefore, more innovative techniques and methods are needed to improve the performance of text classification. It has been a critical step with great challenge to further improve the process of knowledge extraction and effectively utilization of the extracted knowledge. Rough Set decision making approach is proposed to use Rough Set decision techniques to more precisely classify the textual documents which are difficult to separate by the classic text classification methods. The purpose of this paper is to give an overview of existing text classification technologies, to demonstrate the Rough Set concepts and the decision making approach based on Rough Set theory for building more reliable and effective text classification framework with higher precision, to set up an innovative evaluation metric named CEI which is very effective for the performance assessment of the similar research, and to propose a promising research direction for addressing the challenging problems in text classification, text mining and other relative fields.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690735","Decision Making;Feature Selection;Machine Learning;Rough Set;Text Classification","Approximation methods;Decision making;Feature extraction;Support vector machines;Training;Uncertainty;Vectors","knowledge acquisition;rough set theory;text analysis","feature selection methods;information management;information organisation;knowledge extraction;knowledge usage;rough set decision making approach;rough set decision technique;text classification;textual document set","","3","","70","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"A rotation and location invariant face identification and localization with or without occlusion using modified RBFN","D. Bhakta; G. Sarker","Comput. Sci. & Eng. Dept., NIT Durgapur, Durgapur, India","2013 IEEE Second International Conference on Image Information Processing (ICIIP-2013)","20140109","2013","","","533","538","This paper presents a new modified Radial Basis Function Network (RBFN) for identifying and localizing faces with or without occlusion for single images as well as for multiple image frame. The present method of facial identification is completely rotation and location invariant in the image frame. The technique of using the modified RBFN to perform learning of the different facial images and subsequent identification and location invariant localization of the clear, rotated and occluded faces is efficient, effective and fast. Also the identification rate of faces in single and multi-frame is quiet moderate.","","Electronic:978-1-4673-6101-9; POD:978-1-4673-6102-6","10.1109/ICIIP.2013.6707649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707649","ANN;BP Networks;Face Identification;Face Localization;Identification Rate;Machine Learning;OCA;RBFN","Clustering algorithms;Conferences;Databases;Face;Neural networks;Training;Vectors","face recognition;learning (artificial intelligence);radial basis function networks","facial images;image frame;location invariant face identification;location invariant face localization;machine learning;modified RBFN;modified radial basis function network;multiple image frame;occlusion;rotation invariant face identification;rotation invariant face localization","","1","","28","","","9-11 Dec. 2013","","IEEE","IEEE Conference Publications"
"Detection of E-Commerce Systems with Sparse Features and Supervised Classification","K. U. Stoll; M. Hepp","E-Bus. & Web Sci. Res. Group, Univ. der Bundeswehr Munchen, Neubiberg, Germany","2013 IEEE 10th International Conference on e-Business Engineering","20131219","2013","","","199","206","Enriching web shop pages with structured data has recently become popular in e-commerce. It is mainly driven by search engines favouring those pages. While structured data in e-commerce is mainly generated automatically by shop extensions, this data covers only a small share of the market, resulting in a major hamper for applications operating on aggregated data. In this context, more than 90% of product detail pages on the web are generated by only 7 e-commerce systems. Meanwhile, little research addresses methods to automatically detect e-commerce systems. Automated detection would allow to design system-specific extractors able to grow the amount of structured data in e-commerce. Therefore, we propose a novel approach to this problem, which filters features generated from HTML tag attributes with an e-commerce specific white list. We evaluate 6 classification algorithms on the problem and discuss computational effort. We can show that this approach is capable of detecting the 6 most important e-commerce systems with a F1-score of 0.9 by analyzing only one HTML page per web shop. We evaluate our findings on an independent dataset and on reference shop sites.","","Electronic:978-0-7695-5111-1; POD:978-1-4799-1453-1","10.1109/ICEBE.2013.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6686263","e-commerce systems;supervised machine learning;web page classification","Algorithm design and analysis;Business;HTML;Radio frequency;Support vector machines;Training;Web pages","Internet;classification;electronic commerce;hypermedia markup languages;retail data processing;search engines","F1-score;HTML page;HTML tag attributes;Web shop pages;aggregated data;automated detection;classification algorithms;e-commerce systems detection;search engines;shop extensions;shop sites;sparse features;structured data;supervised classification;system-specific extractors","","0","","34","","","11-13 Sept. 2013","","IEEE","IEEE Conference Publications"
"Feature selection strategies for classifying high dimensional astronomical data sets","C. Donalek; S. G. Djorgovski; A. A. Mahabal; M. J. Graham; A. J. Drake; A. A. Kumar; N. S. Philip; T. J. Fuchs; M. J. Turmon; M. T. C. Yang; G. Longo","California Inst. of Technol., Pasadena, CA, USA","2013 IEEE International Conference on Big Data","20131223","2013","","","35","41","The amount of collected data in many scientific fields is increasing, all of them requiring a common task: extract knowledge from massive, multi parametric data sets, as rapidly and efficiently possible. This is especially true in astronomy where synoptic sky surveys are enabling new research frontiers in the time domain astronomy and posing several new object classification challenges in multi dimensional spaces; given the high number of parameters available for each object, feature selection is quickly becoming a crucial task in analyzing astronomical data sets. Using data sets extracted from the ongoing Catalina Real-Time Transient Surveys (CRTS) and the Kepler Mission we illustrate a variety of feature selection strategies used to identify the subsets that give the most information and the results achieved applying these techniques to three major astronomical problems.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691731","CRTS;astroinformatics;feature selection;machine learning","Algorithm design and analysis;Astronomy;Cathode ray tubes;Classification algorithms;Feature extraction;Training;Transient analysis","astronomy computing;feature extraction;knowledge acquisition;pattern classification","CRTS;Catalina real-time transient surveys;Kepler Mission;astronomical data set analysis;astronomical problems;feature selection strategies;high dimensional astronomical data set classification;knowledge extraction;multiparametric data sets;scientific fields","","5","","21","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Automatic Extraction of Personal Experiences from Patients' Blogs: A Case Study in Chronic Obstructive Pulmonary Disease","M. Greenwood; G. Elwyn; N. Francis; A. Preece; I. Spasic","Sch. of Comput. Sci. & Inf., Cardiff Univ., Cardiff, UK","2013 International Conference on Cloud and Green Computing","20131219","2013","","","377","382","People with long-term illness such as chronic obstructive pulmonary disease (COPD) often use social media to document and share information, opinions and their experiences with others. Analysing the self-reported experiences of patients shared online has the potential to help medical researchers gain insight into some of the key issues affecting patients. However, the scale of health conversation taking place online poses considerable challenges to traditional content analysis. In this paper, we present a system which automates extraction of patient statements which refer to a personal experience. We applied a crowd sourcing methodology to create a set of 1770 annotated sentences from blog posts written by COPD patients. Our machine learning approach trained on lexical features successfully extracted sentences about patient experience with 93% precision and 80% recall (F-measure: 86%). Automatic annotation of sentences about patient experience can facilitate subsequent content analysis by highlighting the most relevant sentences to this particular problem.","","Electronic:978-0-7695-5114-2; POD:978-1-4799-1362-6","10.1109/CGC.2013.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6686058","blog mining;blogs;health informatics;machine learning;natural language processing;social media;text processing","Blogs;Diseases;Feature extraction;Internet;Media;Training","Web sites;diseases;learning (artificial intelligence);medical administrative data processing;medical computing","COPD;automatic extraction;chronic obstructive pulmonary disease;content analysis;crowd sourcing methodology;health conversation;machine learning approach;patient statements;patients blogs;personal experiences;social media","","1","","33","","","Sept. 30 2013-Oct. 2 2013","","IEEE","IEEE Conference Publications"
"H.264/AVC to HEVC Video Transcoder Based on Dynamic Thresholding and Content Modeling","E. Peixoto; T. Shanableh; E. Izquierdo","Dept. de Eng. Eletr., Univ. de Brasilia, Brasilia, Brazil","IEEE Transactions on Circuits and Systems for Video Technology","20140109","2014","24","1","99","112","The new video coding standard, High Efficiency Video Coding (HEVC), was developed to succeed the current standard, H.264/AVC, as the state of the art in video compression. However, there is a lot of legacy content encoded with H.264/AVC. This paper proposes and evaluates several transcoding algorithms from the H.264/AVC to the HEVC format. In particular, a novel transcoding architecture, in which the first frames of the sequence are used to compute the parameters so that the transcoder can learn the mapping for that particular sequence, is proposed. Then, two types of mode mapping algorithms are proposed. In the first solution, a single H.264/AVC coding parameter is used to determine the outgoing HEVC partitions using dynamic thresholding. The second solution uses linear discriminant functions to map the incoming H.264/AVC coding parameters to the outgoing HEVC partitions. This paper contains experiments designed to study the impact of the number of frames used for training in the transcoder. Comparisons with existing transcoding solutions reveal that the proposed work results in lower rate-distortion loss at a competitive complexity performance.","1051-8215;10518215","","10.1109/TCSVT.2013.2273651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560375","High Efficiency Video Coding (HEVC);machine learning;transcoding","Discrete cosine transforms;Measurement;Training;Transcoding;Transform coding;Vectors;Video coding","data compression;image sequences;transcoding;video coding","H.264/AVC;HEVC video transcoder algorithm;competitive complexity performance;content modeling;dynamic thresholding;high efficiency video coding;legacy content;linear discriminant functions;mode mapping algorithms;rate-distortion loss;video coding standard;video compression","","27","","43","","20130716","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"An effective method to recognize the language of a text in a collection of multilingual documents","S. Kadri; A. Moussaoui","Dept. of ICST, Univ. of M' sila, M'sila, Algeria","2013 International Conference on Electronics, Computer and Computation (ICECCO)","20140123","2013","","","208","211","Identifying the language of a text means that we assign this text to a language in which it is written. This identification becomes important because of the increased diversity of textual data in different languages on the web. A real recognition of the text language is not possible if we just consider the word as a basic unit of information. It could be possible in some languages but very difficult for some other languages. The approach of the segmentation of the text into characteristic n-grams represents a very efficient alternative solution in this field. It also becomes a preferred tool in language acquisition and the extraction of knowledge from texts. In this paper, we present the most known identification methods and we propose a new method based on n-grams of characters. We also evaluate the obtained results with other methods by adopting the two approaches respectively: the segmentation into words and the segmentation into n-grams.","","Electronic:978-1-4799-3343-3; POD:978-1-4799-3344-0","10.1109/ICECCO.2013.6718265","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718265","N-grams;language identification;machine learning;text categorization;text mining","Distance measurement;Educational institutions;Pragmatics;Probability;Text categorization;Text recognition;Training","Internet;character recognition;data mining;natural language processing;text analysis","World Wide Web;characteristic n-grams;knowledge extraction;language acquisition;multilingual documents;text language;textual data","","0","","20","","","7-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"Exploring sketches for probability estimation with sublinear memory","A. Kleerekoper; M. Luján; G. Brown","Sch. of Comput. Sci., Univ. of Manchester, Manchester, UK","2013 IEEE International Conference on Big Data","20131223","2013","","","79","86","As data sets become ever larger it becomes increasingly complex to apply traditional machine learning techniques to them. Feature selection can greatly reduce the computational requirements of machine learning but it too can be memory intensive. In this paper we explore the use of succinct data structures called sketches for probability estimation as a component of information theoretic feature selection. These data structures are sublinear in the number of items but were designed only for estimating the frequency of the most frequent items. To the best of our knowledge this is the first time they have been examined for estimating the frequency of all items and we find that often some information theoretic measures can be estimated to within a few percent of the correct values.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691737","big data;information theoretic feature selection;machine learning;memory efficiency;sketch data structures","Entropy;Equations;Estimation;Frequency estimation;Mathematical model;Radiation detectors;Standards","data handling;data structures;information theory;learning (artificial intelligence);probability","computational requirements;data sets;frequent items;information theoretic feature selection;information theoretic measures;machine learning techniques;probability estimation;sublinear memory;succinct data structures","","1","","9","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Nearest neighbour regression outperforms model-based prediction of specific star formation rate","K. Stensbo-Smidt; C. Igel; A. Zirm; K. S. Pedersen","","2013 IEEE International Conference on Big Data","20131223","2013","","","141","144","Data in astronomy is rapidly growing with upcoming surveys producing 30 TB of images per night. Highly informative spectra are too expensive to measure for each detected object, hence ways of reliably estimating physical properties from images alone are paramount. The objective of this work is to test whether a “big data ready” k-nearest neighbour regression can successfully estimate the specific star formation rate (sSFR) from colours of low-redshift galaxies. The nearest neighbour algorithm achieves a root mean square error (RMSE) of 0.30, outperforming the state-of-the-art astronomical model achieving a RMSE of 0.36.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691746","astronomy;machine learning;nearest neighbour regression;specific star formation rate","Astronomy;Data mining;Data models;Educational institutions;Extraterrestrial measurements;Image color analysis;Predictive models","astronomical image processing;galaxies;learning (artificial intelligence);mean square error methods;regression analysis","RMSE;astronomy data;k-nearest neighbour regression;low-redshift galaxies;model-based prediction;root mean square error;specific star formation rate","","2","","6","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Malicious URL filtering — A big data application","M. S. Lin; C. Y. Chiu; Y. J. Lee; H. K. Pao","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ. of Sci. & Technol., Taipei, Taiwan","2013 IEEE International Conference on Big Data","20131223","2013","","","589","596","Malicious URLs have become a channel for Internet criminal activities such as drive-by-download, spamming and phishing. Applications for the detection of malicious URLs are accurate but slow (because they need to download the content or query some Internet host information). In this paper we present a novel lightweight filter based only on the URL string itself to use before existing processing methods. We run experiments on a large dataset and demonstrate a 75% reduction in workload size while retaining at least 90% of malicious URLs. Existing methods do not scale well with the hundreds of millions of URLs encountered every day as the problem is a heavily-imbalanced, large-scale binary classification problem. Our proposed method is able to handle nearly two million URLs in less than five minutes. We generate two filtering models by using lexical features and descriptive features, and then combine the filtering results. The on-line learning algorithms are applied here not only for dealing with large-scale data sets but also for fitting the very short lifetime characteristics of malicious URLs. Our filter can significantly reduce the volume of URL queries on which further analysis needs to be performed, saving both computing time and bandwidth used for content retrieval.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691627","Data Mining;Information Filtering;Information Security;Machine learning","Dictionaries;Feature extraction;IP networks;Prediction algorithms;Predictive models;Training;Web sites","Internet;computer crime;learning (artificial intelligence);pattern classification;query processing","Internet criminal activities;URL queries;URL string;big data application;content retrieval;drive-by-download;heavily-imbalanced large-scale binary classilication problem;lifetime characteristics;lightweight lilter;malicious URL filtering;on-line learning algorithms;phishing;spamming","","6","","21","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Numerical Surrogates for Human Observers in Myocardial Motion Evaluation From SPECT Images","T. Marin; M. M. Kalayeh; F. M. Parages; J. G. Brankov","Illinois Institute of Technology, The Medical imaging Research Center, Chicago, IL, USA","IEEE Transactions on Medical Imaging","20140102","2014","33","1","38","47","In medical imaging, the gold standard for image-quality assessment is a task-based approach in which one evaluates human observer performance for a given diagnostic task (e.g., detection of a myocardial perfusion or motion defect). To facilitate practical task-based image-quality assessment, model observers are needed as approximate surrogates for human observers. In cardiac-gated SPECT imaging, diagnosis relies on evaluation of the myocardial motion as well as perfusion. Model observers for the perfusion-defect detection task have been studied previously, but little effort has been devoted toward development of a model observer for cardiac-motion defect detection. In this work, we describe two model observers for predicting human observer performance in detection of cardiac-motion defects. Both proposed methods rely on motion features extracted using previously reported deformable mesh model for myocardium motion estimation. The first method is based on a Hotelling linear discriminant that is similar in concept to that used commonly for perfusion-defect detection. In the second method, based on relevance vector machines (RVM) for regression, we compute average human observer performance by first directly predicting individual human observer scores, and then using multi reader receiver operating characteristic analysis. Our results suggest that the proposed RVM model observer can predict human observer performance accurately, while the new Hotelling motion-defect detector is somewhat less effective.","0278-0062;02780062","","10.1109/TMI.2013.2279517","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6584807","Cardiac motion;cardiac-gated single photon emission computed tomography;image quality;machine learning;model observers;numerical observer","Feature extraction;Image sequences;Kernel;Myocardium;Observers;Predictive models;Single photon emission computed tomography","cardiology;feature extraction;haemodynamics;medical disorders;medical image processing;motion estimation;muscle;physiological models;regression analysis;single photon emission computed tomography;support vector machines","Hotelling linear discriminant;Hotelling motion-defect detector;RVM model observer;SPECT images;average human observer performance;cardiac-gated SPECT imaging;cardiac-motion defect detection;deformable mesh model;diagnostic task;individual human observer scores;medical imaging;motion feature extraction;multireader receiver operating characteristic analysis;myocardial motion evaluation;myocardial perfusion detection;myocardium motion estimation;numerical surrogates;perfusion-defect detection task;practical task-based image-quality assessment;regression analysis;relevance vector machines;task-based approach","0","2","","44","","20130822","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Cardiac Electrophysiological Activation Pattern Estimation From Images Using a Patient-Specific Database of Synthetic Image Sequences","A. Prakosa; M. Sermesant; P. Allain; N. Villain; C. A. Rinaldi; K. Rhode; R. Razavi; H. Delingette; N. Ayache","Inria, Asclepios Team, Sophia Antipolis, France","IEEE Transactions on Biomedical Engineering","20140116","2014","61","2","235","245","While abnormal patterns of cardiac electrophysiological activation are at the origin of important cardiovascular diseases (e.g., arrhythmia, asynchrony), the only clinically available method to observe detailed left ventricular endocardial surface activation pattern is through invasive catheter mapping. However, this electrophysiological activation controls the onset of the mechanical contraction; therefore, important information about the electrophysiology could be deduced from the detailed observation of the resulting motion patterns. In this paper, we present the study of this inverse cardiac electrokinematic relationship. The objective is to predict the activation pattern knowing the cardiac motion from the analysis of cardiac image sequences. To achieve this, we propose to create a rich patient-specific database of synthetic time series of the cardiac images using simulations of a personalized cardiac electromechanical model, in order to study this complex relationship between electrical activity and kinematic patterns in the context of this specific patient. We use this database to train a machine-learning algorithm which estimates the depolarization times of each cardiac segment from global and regional kinematic descriptors based on displacements or strains and their derivatives. Finally, we use this learning to estimate the patient's electrical activation times using the acquired clinical images. Experiments on the inverse electrokinematic learning are demonstrated on synthetic sequences and are evaluated on clinical data with promising results. The error calculated between our prediction and the invasive intracardiac mapping ground truth is relatively small (around 10 ms for ischemic patients and 20 ms for nonischemic patient). This approach suggests the possibility of noninvasive electrophysiological pattern estimation using cardiac motion imaging.","0018-9294;00189294","","10.1109/TBME.2013.2281619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6600804","Cardiac electrophysiology;computer model;inverse problem;machine learning;non-invasive mapping;synthetic images","Databases;Image segmentation;Image sequences;Imaging;Kinematics;Myocardium;Strain","bioelectric potentials;cardiovascular system;catheters;diseases;electrocardiography;image sequences;learning (artificial intelligence);medical image processing;motion estimation;time series","arrhythmia;asynchrony;cardiac electrophysiological activation pattern estimation;cardiac image sequences;cardiac motion imaging;cardiac segment;cardiovascular diseases;depolarization times;electrical activity;error calculation;global kinematic descriptors;invasive catheter mapping;invasive intracardiac mapping ground truth;inverse cardiac electrokinematic relationship;inverse electrokinematic learning;ischemic patients;left ventricular endocardial surface activation pattern;machine-learning algorithm;mechanical contraction;motion patterns;patient electrical activation times;patient-specific database;personalized cardiac electromechanical model;regional kinematic descriptors;synthetic image sequences;synthetic time series;time 10 ms;time 20 ms","0","6","1","40","","20130916","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Preventing erosion of architectural tactics through their strategic implementation, preservation, and visualization","M. Mirakhorli","Sch. of Comput., DePaul Univ., Chicago, IL, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","20140102","2013","","","762","765","Nowadays, a successful software production is increasingly dependent on how the final deployed system addresses customers' and users' quality concerns such as security, reliability, availability, interoperability, performance and many other types of such requirements. In order to satisfy such quality concerns, software architects are accountable for devising and comparing various alternate solutions, assessing the trade-offs, and finally adopting strategic design decisions which optimize the degree to which each of the quality concerns is satisfied. Although designing and implementing a good architecture is necessary, it is not usually enough. Even a good architecture can deteriorate in subsequent releases and then fail to address those concerns for which it was initially designed. In this work, we present a novel traceability approach for automating the construction of traceabilty links for architectural tactics and utilizing those links to implement a change impact analysis infrastructure to mitigate the problem of architecture degradation. Our approach utilizes machine learning methods to detect tactic-related classes. The detected tactic-related classes are then mapped to a Tactic Traceability Pattern. We train our trace algorithm using code extracted from fifty performance-centric and safety-critical open source software systems and then evaluate it against a real case study.","","Electronic:978-1-4799-0215-6; POD:978-1-4799-0216-3","10.1109/ASE.2013.6693152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693152","Architecture;machine learning;tactics;traceability;traceability patterns","Computer architecture;Heart beat;Software;Software architecture;Software reliability","learning (artificial intelligence);safety-critical software;software architecture;software quality","architectural tactic;change impact analysis infrastructure;interoperability;machine learning;performance-centric open source software system;reliability;safety-critical open source software system;security;software architect;software production;tactic traceability pattern;tactic-related class;traceabilty link","","0","","25","","","11-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Using Equilibrium Policy Gradients for Spatiotemporal Planning in Forest Ecosystem Management","M. Crowley","Dept. of Electr. & Comput. Eng., Oregon State Univ., Corvallis, OR, USA","IEEE Transactions on Computers","20131203","2014","63","1","142","154","Spatiotemporal planning involves making choices at multiple locations in space over some planning horizon to maximize utility and satisfy various constraints. In Forest Ecosystem Management, the problem is to choose actions for thousands of locations each year including harvesting, treating trees for fire or pests, or doing nothing. The utility models could place value on sale of lumber, ecosystem sustainability or employment levels and incorporate legal and logistical constraints on actions such as avoiding large contiguous areas of clearcutting. Simulators developed by forestry researchers provide detailed dynamics but are generally inaccesible black boxes. We model spatiotemporal planning as a factored Markov decision process and present a policy gradient planning algorithm to optimize a stochastic spatial policy using simulated dynamics. It is common in environmental and resource planning to have actions at different locations be spatially interelated; this makes representation and planning challenging. We define a global spatial policy in terms of interacting local policies defining distributions over actions at each location conditioned on actions at nearby locations. Markov chain Monte Carlo simulation is used to sample landscape policies and estimate their gradients. Evaluation is carried out on a forestry planning problem with 1,880 locations using a variety of value models and constraints.","0018-9340;00189340","","10.1109/TC.2013.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6514032","Markov decision processes;computational sustainability;ecosystem management;forestry planning;machine learning;optimization;policy gradient planning;reinforcement learning","","Markov processes;Monte Carlo methods;ecology;forestry;gradient methods;optimisation;planning;sustainable development;utility theory","Markov chain Monte Carlo simulation;ecosystem sustainability;employment levels;environmental planning;equilibrium policy gradient planning algorithm;factored Markov decision process;forest ecosystem management;forestry planning problem;generally inaccesible black boxes;global spatial policy;interacting local policies;landscape policies;legal constraints;logistical constraints;lumber;planning horizon;resource planning;simulated dynamics;spatially interelated locations;spatiotemporal planning;stochastic spatial policy optimization;utility models","","1","","42","","20130506","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Learning the Gain Values and Discount Factors of Discounted Cumulative Gains","K. Zhou; H. Zha; Y. Chang; G. R. Xue","Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Knowledge and Data Engineering","20131220","2014","26","2","391","404","Evaluation metric is an essential and integral part of a ranking system. In the past, several evaluation metrics have been proposed in information retrieval and web search, among them Discounted Cumulative Gain (DCG) has emerged as one that is widely adopted for evaluating the performance of ranking functions used in web search. However, the two sets of parameters, the gain values and discount factors, used in DCG are usually determined in a rather ad-hoc way, and their impacts have not been carefully analyzed. In this paper, we first show that DCG is generally not coherent, i.e., comparing the performance of ranking functions using DCG very much depends on the particular gain values and discount factors used. We then propose a novel methodology that can learn the gain values and discount factors from user preferences over rankings, modeled as a special case of learning linear utility functions. We also discuss how to extend our methods to handle tied preference pairs and how to explore active learning to reduce preference labeling. Numerical simulations illustrate the effectiveness of our proposed methods. Moreover, experiments are also conducted over a side-by-side comparison data set from a commercial search engine to validate the proposed methods on real-world data.","1041-4347;10414347","","10.1109/TKDE.2012.252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6399471","Discounted cumulative gains;evaluation metric;machine learning;user preference;utility function","Measurement;Optimization;Production;Search engines;Vectors;Web search","learning (artificial intelligence);search engines","DCG;Web search;commercial search engine;discount factors;discounted cumulative gain;evaluation metric;gain values;information retrieval;linear utility functions learning;numerical simulations;preference labeling;ranking functions;ranking system;side-by-side comparison data;user preferences","","1","","23","","20121231","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Colon cancer survival prediction using ensemble data mining on SEER data","R. Al-Bahrani; A. Agrawal; A. Choudhary","Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA","2013 IEEE International Conference on Big Data","20131223","2013","","","9","16","We analyze the colon cancer data available from the SEER program with the aim of developing accurate survival prediction models for colon cancer. Carefully designed preprocessing steps resulted in removal of several attributes and applying several supervised classification methods. We also adopt synthetic minority over-sampling technique (SMOTE) to balance the survival and non-survival classes we have. In our experiments, ensemble voting of the three of the top performing classifiers was found to result in the best prediction performance in terms of prediction accuracy and area under the ROC curve. We evaluated multiple classification schemes to estimate the risk of mortality after 1 year, 2 years and 5 years of diagnosis, on a subset of 65 attributes after the data clean up process, 13 attribute carefully selected using attribute selection techniques, and SMOTE balanced set of the same 13 attributes, while trying to retain the predictive power of the original set of attributes. Moreover, we demonstrate the importance of balancing the classes of the data set to yield better results.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691752","Colon Cancer;Ensemble;Machine Learning;Prediction","Accuracy;Cancer;Colon;Data mining;Decision trees;Logistics;Predictive models","cancer;data analysis;data mining;medical computing;pattern classification","ROC curve;SEER data;SEER program;SMOTE balanced set;Surveillance, Epidemiology, and End Results Program;attribute selection techniques;colon cancer data;colon cancer survival prediction;ensemble data mining;multiple classification schemes;prediction accuracy;supervised classification methods;synthetic minority over-sampling technique","","4","","22","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"A Region-Based Framework for Design Feature Identification of Systematic Process Variations","S. Y. Hsu; C. H. Hsu; T. S. Hsu; J. J. Liou","Dept. of Electr. Eng., Nat. TsingHua Univ., Hsinchu, Taiwan","2013 22nd Asian Test Symposium","20131223","2013","","","265","270","Process monitoring circuitry such as ring oscillators or delay-test-based diagnosis method has been applied to characterize process variations of a chip. For a design process, it is also desirable to consider circuit features that might cause such a systematic process variation. In this paper, we use the variation map built from measured excessive delays to analyze the correlation between circuits and systematic variations. With support vector regression, a physical map of a circuit is partitioned into different regions that are inherently affected by similar causes. And then possible features (e.g., cell types, layout characteristics, etc.) that influences these regions are ranked. Experimental results show that the proposed method can effectively identify process regions and rank major features at top orders with injected variations.","1081-7735;10817735","Electronic:978-0-7695-5080-0; POD:978-1-4799-0871-4","10.1109/ATS.2013.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690652","machine learning;process modeling;systematic variation","","CMOS integrated circuits;integrated circuit design;integrated circuit testing;oscillators;process monitoring;regression analysis;support vector machines","delay-test-based diagnosis;design feature identification;process monitoring circuitry;process regions;region-based framework;ring oscillators;support vector regression;systematic process variations;variation map","","0","","21","","","18-21 Nov. 2013","","IEEE","IEEE Conference Publications"
"Automatic Crowdsourcing-Based Classification of Marketing Messaging on Twitter","R. Machedon; W. Rand; Y. Joshi","Center for Complexity in Bus., Univ. of Maryland, College Park, MD, USA","2013 International Conference on Social Computing","20140102","2013","","","975","978","As the volume of social media communications grow, many different stakeholders have sought to apply tools and methods for automatic identification of sentiment and topic in social network communications. In the domain of social media marketing it would be useful to automatically classify social media messaging into the classic framework of informative, persuasive and transformative advertising. In this paper we develop and present the construction and evaluation of supervised machine-learning classifiers for these concepts, drawing upon established procedures from the domains of sentiment analysis and crowd sourced text classification. We demonstrate that a reasonably effective classifier can be created to identify the informative nature of Tweets based on crowd sourced training data, we also present results for identifying persuasive and transformative content. We finish by summarizing our findings regarding applying these methods and by discussing recommendations for future work in the area of classifying the marketing content of Tweets.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693452","advertising;classification;crowdsourcing;machine learning;marketing","Accuracy;Advertising;Labeling;Media;Reliability;Training;Transforms","advertising;learning (artificial intelligence);pattern classification;social networking (online)","Twitter;automatic crowdsourcing-based classification;automatic sentiment identification;automatic topic identification;crowdsourced text classification;informative advertising;marketing messaging;persuasive advertising;sentiment analysis;social media communications;social media marketing;social media messaging;social network communications;stakeholders;supervised machine-learning classifiers;transformative advertising;tweets","","4","","10","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Image-Based Fall Detection with Human Posture Sequence Modeling","X. Dai; M. Wu; B. Davidson; M. Mahoor; J. Zhang","Dept. of Electr. & Comput. Eng., Univ. of Denver, Denver, CO, USA","2013 IEEE International Conference on Healthcare Informatics","20131212","2013","","","376","381","In this paper, an image-based method is presented for fall detection using statistical human posture sequence modeling. Specifically, a series of laboratory simulated falls and activities of daily living (ADLs) are performed and recorded by a Kinect sensor as training video data. The skeleton view of a human body in these video recordings is extracted using the Kinect for Windows SDK. Hidden Markov Models are used for modeling the fall posture sequences and distinguishing different fall activities and ADLs. Our experimental results demonstrate an average fall recognition rate above 80% and the capability of early warning for falls.","","Electronic:978-0-7695-5089-3; POD:978-1-4799-0974-2","10.1109/ICHI.2013.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680499","Fall detection;hidden Markov model;image processing;kinect;machine learning","Feature extraction;Hidden Markov models;Joints;Principal component analysis;Senior citizens;Testing","assisted living;hidden Markov models;human computer interaction;image sensors;image sequences;image thinning;object detection;statistical analysis;video signal processing","ADL;Kinect sensor;Windows SDK;activities-of-daily living;hidden Markov models;image-based fall detection method;laboratory simulated falls;machine learning;skeleton view extraction;statistical human posture sequence modeling;training video data;video recordings","","2","","11","","","9-11 Sept. 2013","","IEEE","IEEE Conference Publications"
"Mining WiFi Data for Business Intelligence","D. Arora; S. W. Neville; K. F. Li","Dept. of Electr. & Comput. Eng., Univ. of Victoria, Victoria, BC, Canada","2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20131212","2013","","","394","398","The WiFi networks provide an ease of accessing email, Web, and other Internet applications while on the move. However, deploying additional WiFi hotspots that can provide both increased coverage and enhance user quality of service largely depends upon the number of access points already existing and user densities. Extracting usage patterns and information from the available data has the potential to answer several business-focussed questions. In this paper, we show that by plotting WiFi locations in a two-dimensional space of incoming (downloading) and outgoing (uploading) data amount, in conjunction with the simple k-means clustering, it is possible to gain insight into the basic data usage patterns. When combined with information about geographic location of the WiFi hotspots such analysis can answer questions related to spatial patterns of data usage and make informed business decisions including charging customers at selected locations for WiFi service.","","Electronic:978-0-7695-5094-7; POD:978-1-4799-1266-7","10.1109/3PGCIC.2013.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681260","WiFi;clustering;machine learning;telecommunications","Business;Clustering algorithms;Data mining;IEEE 802.11 Standards;Machine learning algorithms;Quality of service","competitive intelligence;data mining;pattern clustering;quality of service;wireless LAN","Internet applications;Web access;Wi-Fi data mining;Wi-Fi hotspots;Wi-Fi location plotting;Wi-Fi networks;Wi-Fi service;access points;business decision making;business intelligence;business-focussed questions;coverage improvement;data usage patterns;downloaded data amount;e-mail access;geographic location;incoming data amount;information extraction;k-means clustering;outgoing data amount;spatial data patterns;two-dimensional space;uploaded data amount;usage pattern extraction;user densities;user quality-of-service enhancement","","0","","22","","","28-30 Oct. 2013","","IEEE","IEEE Conference Publications"
"Aligned-Parallel-Corpora Based Semi-Supervised Learning for Arabic Mention Detection","I. Zitouni; Y. Benajiba","Microsoft, Redmond, WA, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20140102","2014","22","2","314","324","In the last two decades, significant effort has been put into annotating linguistic resources in several languages. Despite this valiant effort, there are still many languages left that have only small amounts of such resources. The goal of this article is to present and investigate a method of propagating information (specifically mentions) from a resource-rich language such as English into a relatively less-resource language such as Arabic. We compare also this approach to its equivalent counterpart using monolingual resources. Part of the investigation is to quantify the contribution of propagating information in different conditions - based on the availability of resources in the target language. Experiments on the language pair Arabic-English show that one can achieve relatively decent performance by propagating information from a language with richer resources such as English into Arabic alone (no resources or models in the source language Arabic). Furthermore, results show that propagated features from English do help improve the Arabic system performance even when used in conjunction with all feature types built from the source language. Experiments also show that using propagated features in conjunction with lexically-derived features only (as can be obtained directly from a mention annotated corpus) brings the system performance at the one obtained in the target language by using feature derived from many linguistic resources, therefore improving the system when such resources are not available.","2329-9290;23299290","","10.1109/TASLP.2013.2287055","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6646259","Information extraction;cross-lingual NLP;machine learning;mention detection;natural language processing","Entropy;Feature extraction;IEEE transactions;Pragmatics;Semisupervised learning;Speech;Speech processing","learning (artificial intelligence);natural language processing","aligned parallel corpora based semisupervised learning;mention detection;monolingual resources;resource rich language;source language","","2","","46","","20131024","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Survival Analysis of Automobile Components Using Mutually Exclusive Forests","A. Eyal; L. Rokach; M. Kalech; O. Amir; R. Chougule; R. Vaidyanathan; K. Pattada","Dept. of Inf. Syst. Eng., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20140114","2014","44","2","246","253","An ability to predict the mileage at failure of components in a complicated system, particularly in automobiles, is a challenging task. In the current work, a methodology for estimating the distribution of failure and survival rate of automobile components affected by multiple factors is presented. A novel adaptation of an ensemble recursive partitioning and tree-based learning method, mutually exclusive forest, is introduced. The proposed method is capable of handling a high dimensional dataset and maximizing the extracted information to estimate the distribution of mileage at failure of automobile components. Each tree in the proposed mutually exclusive forest uses a mutually exclusive set of factors in each of its constituent decision trees to classify the failure data. Information across the trees is combined to obtain the failure rate distribution of an automobile component with respect to mileage. A case study, based on real-world field failure data and censored data of automobile components, is presented to evaluate the proposed algorithm. Results show similar results to the C-Forest approach in terms of prediction quality, while generating models with significantly lower space that are easier to interpret.","2168-2216;21682216","","10.1109/TSMC.2013.2248357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6514923","Classification and regression trees (CART);conditional inference;ensemble algorithms;machine learning;random forests;survival analysis;survival trees","","automotive components;data handling;decision trees;failure analysis;learning (artificial intelligence);pattern classification;regression analysis;traffic engineering computing","C-forest approach;CART;automobile components;classification and regression trees;decision trees;ensemble recursive partitioning;failure data classification;failure distribution estimation;high dimensional dataset handling;mutually exclusive forests;real-world held failure data;survival analysis;survival rate;tree-based learning method","","1","","26","","20130513","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Multiclass image classification using multiscale biorthogonal wavelet transform","O. Prakash; M. Khare; R. K. Srivastava; A. Khare","Dept. of Electron. & Commun., Univ. of Allahabad, Allahabad, India","2013 IEEE Second International Conference on Image Information Processing (ICIIP-2013)","20140109","2013","","","131","135","Image classification is an important problem because of its applications in many fields like shape analysis, object tracking, image retrieval etc. Many techniques have been proposed in literature for classification of objects into two classes. Multi class image classification with high accuracy is a challenging task. In this paper we propose a new algorithm for multi class image classification that uses biorthogonal wavelet transform as image feature. Original images are decomposed into subbands LL, LH, HL and HH using Biorthogonal wavelet transform at multiple scales. The coefficients of LH, HL, HH subbands are used as features for classification. The approximate shift invariance and linear phase properties of Biorthogonal wavelet transform are useful for classification of images. Also, the lifting-scheme of Biorthogonal wavelet yields reduced computational cost. Quantitative evaluation of classification accuracy demonstrates the strength of the proposed method.","","Electronic:978-1-4673-6101-9; POD:978-1-4673-6102-6","10.1109/ICIIP.2013.6707569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707569","Biorthogonal wavelet transform;Multiclass image classification;feature selection;machine learning","Accuracy;Bicycles;Image classification;Motorcycles;Support vector machines;Wavelet transforms","approximation theory;cost reduction;feature selection;image classification;wavelet transforms","HH subbands coefficients;HL subbands coefficients;LH subbands coefficients;LL subbands coefficients;approximate shift invariance;computational cost reduction;image decomposition;image feature selection;lifting scheme;linear phase;multiclass image classification;multiscale biorthogonal wavelet transform;object classification","","1","","14","","","9-11 Dec. 2013","","IEEE","IEEE Conference Publications"
"We Know What You Are--A User Classification Based on Mobile Data","D. Hu; F. Sun; L. Tu; B. Huang","EIE Dept., Huazhong Univ. of Sci. & Technol., Wuhan, China","2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing","20131212","2013","","","1282","1289","With the rapid development of wireless communication technology and computer network technology, making calls through mobile handheld devices, i.e. mobile phone, sending SMS messages and getting access to wireless Internet have become the urgent needs of a large number of users. It seems to be quite necessary to understand and analyze the behavior pattern of wireless users. This paper aims to recognize the identities of users according to the rules and characteristics of mobile phone usage behaviors of users with different identities. This paper has collected the record of mobile phone usage behaviors from 140 users in Huazhong University of Science and Technology (including 70 teachers and 70 students), analyzed the behavior differences of these two types of users in making calls, sending SMS messages and surfing the Internet, and identified the users by machine learning algorithm according to the characteristics of user behaviors. The experimental results have verified the validity of user identity classification method proposed by this paper.","","Electronic:978-0-7695-5046-6; POD:978-1-4799-0631-4","10.1109/GreenCom-iThings-CPSCom.2013.223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682236","User Classification;machine learning;socialnetwork","Accuracy;Data mining;Data models;Decision trees;Mobile communication;Mobile handsets;Training","Internet;behavioural sciences computing;electronic messaging;learning (artificial intelligence);mobile computing;mobile handsets;pattern classification","Huazhong University of Science and Technology;SMS messages;behavior pattern analysis;computer network technology;machine learning algorithm;mobile data;mobile handheld devices;mobile phone;mobile phone usage behavior characteristics;user identity classification method validity;wireless Internet surfing;wireless communication technology","","2","","9","","","20-23 Aug. 2013","","IEEE","IEEE Conference Publications"
"ParalTabs: A Parallel Scheme of Decision Tables Construction","B. Moreno-Montiel; R. MacKinney-Romero","Dept. Ing. Electr., Univ. Autonoma Metropolitana - Iztapalapa, Mexico City, Mexico","2013 Mexican International Conference on Computer Science","20131212","2013","","","47","54","Decision Tables is a well known classification algorithm which is both efficient and accurate. This paper presents the Parallel Scheme of Decision Tables (ParalTabs) which is an implementation of decision tables using the parallel model of Single Program and Multiple Data Streams (SPMD). This model communicates through shared memory, i.e., the threads communicate with each other by reading and writing in the same physical address space. The algorithm uses a parallel scheme that follows the strategy of divide and conquer (D & C). Data is given to different threads to work on and the results collected to obtain the final decision table. We found, by a series of tests, the granularity most appropriate to divide data and obtain a reduction in execution times. A sequential version of Decision Tables was used to perform tests on the data and also other classification tools were used in order to have a thorough comparison with the parallel classifier proposed. We found ParalTabs a useful algorithm to perform classification on large databases, obtaining improvements in execution times and performance measures.","1550-4069;15504069","Electronic:978-0-7695-5087-9; POD:978-1-4799-1145-5","10.1109/ENC.2013.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679819","Classification;Data Base;Decision Tables;Machine Learning;Parallel Computing","Clouds;Complexity theory;Data models;Parallel processing;Rain;Training;Vectors","decision tables;parallel programming;pattern classification;shared memory systems;very large databases","ParalTabs;SPMD;classification algorithm;decision tables construction;large databases;multiple data streams;parallel scheme;shared memory;single program","","0","","18","","","Oct. 30 2013-Nov. 1 2013","","IEEE","IEEE Conference Publications"
"Mining Web Technical Discussions to Identify Malware Capabilities","J. Saxe; D. Mentis; C. Greamo","Invincea Inc., Fairfax, VA, USA","2013 IEEE 33rd International Conference on Distributed Computing Systems Workshops","20131212","2013","","","1","5","The exponential growth of unique malware binary artifacts has led researchers to explore automated techniques for characterizing unknown malware binaries' capabilities. Thus far, automatic malware analysis systems have relied on labeled training data and analyst defined rules to identify malware samples' software features and functional categories. Such approaches require substantial expert analyst effort to maintain, as malware authors change programming languages, APIs, malicious tactics, and operating system targets. In this paper we present preliminary results demonstrating the viability of a new research direction for malware capability identification that addresses these issues, the concept of mining web technical documentation to automatically identify malware capabilities. This approach does not require expert generation of rules or training labels and automatically stays up to date with the latest software engineering trends. We make two contributions aimed at demonstrating the value of this research direction: first, with a corpus of 6 million web technical postings from the programming question and answer website StackOverflow.com, we show that symbols found in a corpus of malicious executable files, such as registry keys, file names, and API call names, also occur frequently in the StackOverflow data, suggesting that applying natural language processing to the StackOverflow posts (and other technical documents) may help us automatically generate characterizations of technical symbols, and, thereby, capabilities, found in malware. Our second contribution is to show that by analyzing function call symbol co-occurrence within StackOverflow posts, as well as the semantic tags associated with these posts, we can create function relationship graphs over the symbols which show promise in helping to identifying malware software capabilities. We argue that these early findings demonstrate the promise of a web technical document based approach to automating mal- are capability identification.","1545-0678;15450678","Electronic:978-1-4799-3248-1; POD:978-1-4799-3249-8","10.1109/ICDCSW.2013.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679853","computer security;data mining;machine learning;malware analysis;natural language processing;statistical modeling","Clustering algorithms;Data mining;Internet;Malware;Programming;Webcams","Internet;Web sites;application program interfaces;data mining;invasive software;natural language processing;system documentation","API call names;APIs;StackOverflow data;StackOverflow posts;Web technical discussion mining;Web technical document based approach;Web technical documentation mining;answer Web site StackOverflow.com;automatic malware analysis systems;file names;function call symbol co-occurrence analysis;function relationship graphs;functional category;labeled training data;malicious tactics;malware capability identification;malware sample software feature identification;natural language processing;operating system targets;programming languages;programming question;registry keys;semantic tags;software engineering;training labels;unique malware binary artifacts","","0","","9","","","8-11 July 2013","","IEEE","IEEE Conference Publications"
"Nearest neighbor classification using bottom-k sketches","S. Dahlgaard; C. Igel; M. Thorup","Department of Computer Science, University of Copenhagen","2013 IEEE International Conference on Big Data","20131223","2013","","","28","34","Bottom-k sketches are an alternative to k×minwise sketches when using hashing to estimate the similarity of documents represented by shingles (or set similarity in general) in large-scale machine learning. They are faster to compute and have nicer theoretical properties. In the case of k×minwise hashing, the bias introduced by not truly random hash function is independent of the number k of hashes, while this bias decreases with increasing k when employing bottom-k. In practice, bottom-k sketches can expedite classification systems if the trained classifiers are applied to many data points with a lot of features (i.e., to many documents encoded by a large number of shingles on average). An advantage of b-bit k×minwise hashing is that it can be efficiently incorporated into machine learning methods relying on scalar products, such as support vector machines (SVMs). Still, experimental results indicate that a nearest neighbors classifier with bottom-k sketches can be preferable to using a linear SVM and b-bit k×minwise hashing if the amount of training data is low or the number of features is high.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691730","document encoding;hashing;large-scale machine learning;nearest neighbor classification;set similarity","Accuracy;Indexes;Kernel;Support vector machines;Training;Training data;Vectors","document handling;learning (artificial intelligence);pattern classification;support vector machines","bottom-k sketches;classification systems;documents similarity;hash function;k-minwise hashing;large-scale machine learning;linear SVM;nearest neighbor classification;scalar products;support vector machines","","0","","17","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Application of Support Vector Machine and k-means clustering algorithms for robust chronic lymphocytic leukemia color cell segmentation","E. A. Mohammed; B. H. Far; M. M. A. Mohamed; C. Naugler","Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada","2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)","20140127","2013","","","622","626","Chronic lymphocytic leukemia (CLL) is the most common type of blood cancer in Canadian adults. The relative 5-year survival rates for CLL in Canada is decreasing. CLL cell morphology maybe similar to normal lymphocytes and require a hematopathologist examination for diagnosis. There are a low number of related works on image analysis in CLL. This paper focuses on lymphocyte color cell segmentation using Support Vector Machine (SVM) and k-means clustering algorithms. The algorithm overcomes the occlusion problem when lymphocytes are tightly bound to the surrounding Red Blood Cells. Over and under-segmentation problems are significantly reduced. In this paper we used 440 lymphocyte images (normal and CLL), in which 140 images are used for segmentation accuracy measurement and 12 images for SVM training. The algorithm obtained 98.43% maximum accuracy for nucleus segmentation, and 98.69% for cell segmentation. The cytoplasm region can be extracted by 99.85% maximum accuracy with simple mask subtraction.","","Electronic:978-1-4673-5801-9; POD:978-1-4673-5799-9","10.1109/HealthCom.2013.6720751","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720751","Bioinformatics;Chronic Lymphocytic Leukemia (CLL);Color image segmentation;K-means;Machine learning;SVM;White Blood Cell (WBC)","Accuracy;Classification algorithms;Clustering algorithms;Image color analysis;Image segmentation;Support vector machines;Training","blood;cancer;cellular biophysics;image colour analysis;image segmentation;medical image processing;pattern clustering;support vector machines","CLL cell morphology;Canadian adult;SVM;blood cancer;cytoplasm region;k-means clustering algorithm;lymphocyte color cell segmentation;mask subtraction;normal lymphocytes;nucleus segmentation;occlusion problem;red blood cell;robust chronic lymphocytic leukemia;support vector machine","","1","","17","","","9-12 Oct. 2013","","IEEE","IEEE Conference Publications"
"SCoRS—A Method Based on Stability for Feature Selection and Mapping in Neuroimaging","J. M. Rondina; T. Hahn; L. de Oliveira; A. F. Marquand; T. Dresler; T. Leitner; A. J. Fallgatter; J. Shawe-Taylor; J. Mourao-Miranda","Centre for Neuroimaging Sciences, Institute of Psychiatry, King's College London, UK","IEEE Transactions on Medical Imaging","20140102","2014","33","1","85","98","Feature selection (FS) methods play two important roles in the context of neuroimaging based classification: potentially increase classification accuracy by eliminating irrelevant features from the model and facilitate interpretation by identifying sets of meaningful features that best discriminate the classes. Although the development of FS techniques specifically tuned for neuroimaging data is an active area of research, up to date most of the studies have focused on finding a subset of features that maximizes accuracy. However, maximizing accuracy does not guarantee reliable interpretation as similar accuracies can be obtained from distinct sets of features. In the current paper we propose a new approach for selecting features: SCoRS (survival count on random subsamples) based on a recently proposed Stability Selection theory. SCoRS relies on the idea of choosing relevant features that are stable under data perturbation. Data are perturbed by iteratively sub-sampling both features (subspaces) and examples. We demonstrate the potential of the proposed method in a clinical application to classify depressed patients versus healthy individuals based on functional magnetic resonance imaging data acquired during visualization of happy faces.","0278-0062;02780062","","10.1109/TMI.2013.2281398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595571","Classification;classification accuracy;depression;faces visualization;feature selection;functional magnetic resonance imaging (fMRI);machine learning;multivariate mapping;regression;support vector machines","Accuracy;Context;Educational institutions;Neuroimaging;Support vector machines;Training;Vegetation","biomedical MRI;face recognition;feature selection;image classification;iterative methods;medical image processing;neurophysiology;random processes","SCoRS;data perturbation;face visualization;feature apping;feature selection methods;functional magnetic resonance imaging data;iterative subsampling;neuroimaging based classification;stability selection theory;survival count on random subsamples","0","15","","45","","20130911","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Data chaos: An entropy based MapReduce framework for scalable learning","J. Chen; H. Chen; X. Chen; G. Zheng; Z. Wu","","2013 IEEE International Conference on Big Data","20131223","2013","","","71","78","Chaos of data is the total unpredictability of all the data elements, and can by quantified by Shannon entropy. In this paper, we firstly propose an entropy based theoretic framework for machine learning, which states that chaos in sample data will decrease and rule will advance as learning progresses. However, it is usually time consuming to apply the theoretic framework because groups of rule need to be trained iteratively and data chaos will be recalculated during each iteration. To implement the theoretic framework for scalable learning, we propose a MapReduce based distributed computational framework. In a case study of classification, the framework parallelly trains multiple classifiers and calculats chaos of the sample set during each iteration, and then resamples a small sample subset with the highest entropy for training of the next iteration, reducing chaos in sample data as quickly as possible. With typical classification benchmarks, our experiment presents entropy in sample data, and proves that the theoretic framework is rational and can help improve the accuracy of machine learning. Meanwhile, the computational framework shows high performance including high efficiency and scalability for large scale learning on hadoop cluster.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691736","Chaos;Entropy;Machine Learning;MapReduce","Accuracy;Benchmark testing;Chaos;Entropy;Prediction algorithms;Training;Uncertainty","entropy;learning (artificial intelligence);parallel processing;pattern classification","Hadoop cluster;MapReduce based distributed computational framework;Shannon entropy;classification benchmark;computational framework;data chaos;data element total unpredictability;entropy based MapReduce framework;entropy based theoretic framework;large scale learning;machine learning;multiple classifier parallel training;scalable learning","","1","","24","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Pairwise Learning to Rank for Search Query Correction","A. Novak; J. Sedivy","Dept. of Cybern., Czech Tech. Univ., Prague, Czech Republic","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","3054","3059","This article introduces a new algorithm for a Search Query Spelling Correction System. It is based on learning to rank approach and allows to use large number of various signals leading to an improved accuracy. The performance will be tested against the conventional solution - the Noisy Channel Model. The new system was developed on a Czech Internet search query set, but the feature vector structure and the algorithm can be easily adapted for any other language when sufficient data is available. We will describe the algorithm details, the training and validation data sets. Further, we will discuss the selection and impact of the new feature vector signals.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722274","feature vector;learning to rank;machine learning;noisy channel model;query correction","Data models;Electronic publishing;Encyclopedias;Internet;Noise measurement;Vectors","Internet;learning (artificial intelligence);query processing;spelling aids","Czech Internet search query set;feature vector signals;feature vector structure;learning to rank model;noisy channel model;pairwise learning;search query correction rank;search query spelling correction system","","0","","14","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Learning-Assisted Intelligent Scheduling System","A. Madureira; J. P. Pereira; I. Pereira","GECAD Res. Group, Polytech. Inst. of Porto, Porto, Portugal","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","2820","2825","This paper addresses the developing of Learning-Assisted Intelligent Scheduling Systems that uses active learning by accumulation and interpretation of scheduling experience or even by observation of expert's decisions. The design of intelligent systems (IS) that learn with experts is a very hard and challenging domain because current systems are becoming more and more complex and subject to rapid changes. The model for the proposed system will be presented.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722234","Decision Support Systems;Human-Computer Interaction;Intelligent Scheduling;Learning by Observation;Machine Learning","Artificial intelligence;Dynamic scheduling;Job shop scheduling;Manufacturing;Optimization;Organizations","decision support systems;human computer interaction;learning (artificial intelligence);scheduling","active learning;intelligent systems;learning-assisted intelligent scheduling system;scheduling experience accumulation;scheduling experience interpretation","","2","","31","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Learning effective query transformations for enhanced requirements trace retrieval","T. Dietrich; J. Cleland-Huang; Y. Shin","Center of Excellence for Software Traceability (CoEST), DePaul Univ., Chicago, IL, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","20140102","2013","","","586","591","In automated requirements traceability, significant improvements can be realized through incorporating user feedback into the trace retrieval process. However, existing feedback techniques are designed to improve results for individual queries. In this paper we present a novel technique designed to extend the benefits of user feedback across multiple trace queries. Our approach, named Trace Query Transformation (TQT), utilizes a novel form of Association Rule Mining to learn a set of query transformation rules which are used to improve the efficacy of future trace queries. We evaluate TQT using two different kinds of training sets. The first represents an initial set of queries directly modified by human analysts, while the second represents a set of queries generated by applying a query optimization process based on initial relevance feedback for trace links between a set of source and target documents. Both techniques are evaluated using requirements from theWorldVista Healthcare system, traced against certification requirements for the Commission for Healthcare Information Technology. Results show that the TQT technique returns significant improvements in the quality of generated trace links.","","Electronic:978-1-4799-0215-6; POD:978-1-4799-0216-3","10.1109/ASE.2013.6693117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693117","association rules;contractual requirements;machine learning;query replacement;requirements traceability;text mining","Association rules;Educational institutions;Itemsets;Manuals;Medical services;Standards;Training","data mining;formal verification;health care;learning (artificial intelligence);medical computing;program diagnostics;query processing;relevance feedback;text analysis","Commission for Healthcare Information Technology;TQT technique;WorldVista Healthcare system;association rule mining;automated requirements traceability;certification requirements;effective query transformation learning;machine learning;query optimization process;relevance feedback;requirement trace retrieval enhancement process;software engineering activities;source documents;target documents;text mining;trace query transformation;training sets;user feedback","","2","","23","","","11-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Personalized defect prediction","T. Jiang; L. Tan; S. Kim","Univ. of Waterloo, Waterloo, ON, Canada","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","20140102","2013","","","279","289","Many defect prediction techniques have been proposed. While they often take the author of the code into consideration, none of these techniques build a separate prediction model for each developer. Different developers have different coding styles, commit frequencies, and experience levels, causing different defect patterns. When the defects of different developers are combined, such differences are obscured, hurting prediction performance. This paper proposes personalized defect prediction-building a separate prediction model for each developer to predict software defects. As a proof of concept, we apply our personalized defect prediction to classify defects at the file change level. We evaluate our personalized change classification technique on six large software projects written in C and Java-the Linux kernel, PostgreSQL, Xorg, Eclipse, Lucene and Jackrabbit. Our personalized approach can discover up to 155 more bugs than the traditional change classification (210 versus 55) if developers inspect the top 20% lines of code that are predicted buggy. In addition, our approach improves the F1-score by 0.01-0.06 compared to the traditional change classification.","","Electronic:978-1-4799-0215-6; POD:978-1-4799-0216-3","10.1109/ASE.2013.6693087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693087","Change classification;machine learning;personalized defect prediction;software reliability","Computer bugs;Feature extraction;Mars;Predictive models;Syntactics;Training;Vectors","Java;Linux;program compilers","C software projects;Eclipse;Jackrabbit;Linux kernel;Lucene;PostgreSQL;Xorg;coding styles;commit frequencies;different defect patterns;experience levels;java software projects;personalized defect prediction;separate prediction model;software defect prediction","","21","","59","","","11-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"An improved fingerprint algorithm of 3D-DCT for video fingerprinting","M. Diao; Y. Zhu; Z. Sun; X. Liu; L. Zhang","Shenzhen Grad. Sch., Peking Univ., Shenzhen, China","2013 8th International Symposium on Image and Signal Processing and Analysis (ISPA)","20140109","2013","","","290","295","In this paper, a new learned basis set algorithm (3D-LBT) based on 3D-DCT (Discrete Cosine Transform) is proposed for video fingerprinting and matching, in which for different video categories an Adaboost-based machine learning method is applied to each category of videos for selecting suitable sets of 3D-DCT coefficients to generate fingerprints, and a weighted distance of fingerprints is also defined for fingerprint matching. Our experimental results have illustrated that the proposed algorithm outperforms the conventional 3D-DCT algorithm and the 3D-RBT (Randomized Basis seT) algorithm in terms of robustness and uniqueness. Moreover, the proposed algorithm has better security performance for copyright applications.","1845-5921;18455921","Electronic:978-953-184-194-8; POD:978-1-4799-3125-5; USB:978-953-184-187-0","10.1109/ISPA.2013.6703755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703755","3D-DCT;adaboost;copyright protection;machine learning;video fingerprint;weighted distance","Algorithm design and analysis;Brightness;Databases;Fingerprint recognition;Machine learning algorithms;Robustness;Signal processing algorithms","discrete cosine transforms;fingerprint identification;video signal processing","3D DCT algorithm;3D DCT coefficients;3D LBT;3D RBT;Adaboost based machine learning;copyright applications;discrete cosine transform;fingerprint algorithm;fingerprint matching;learned basis set algorithm;randomized basis set;security performance;video categories;video fingerprinting;video matching","","0","","11","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Visual analysis to generate and validate geographical heuristics","A. Graves; A. Cadiz; F. Lalanne; J. Bustos","Inria Chile, Santiago, Chile","IEEE Latin America Transactions","20140120","2014","12","1","69","72","The popularity of smartphones has opened endless possibilities for researchers. The adoption of these devices by all kind of users has transformed each one of them into a mobile sensor that can measure different types of data. These data can eventually be transmitted via Internet to servers where it can be studied to understand different aspects of the environment and human behavior in ways that were not possible a few years ago. Even with all this information available, the granularity of the data can be coarse, and the amount of it can be scarce, making it difficult to study and evaluate such data. This is especially true for certain geographically-related problems, where conventional algorithms are difficult to design. For these problems it is possible to design heuristics to reach a good approximation, however the methodology to assess the effectiveness of such heuristics is unclear. In this paper we present our work towards a methodology to generate and evaluate such heuristics. This methodology is based on displaying geographical information visually so human evaluators can judge the quality of the heuristic and combining it with the calculation power of computers.","1548-0992;15480992","","10.1109/TLA.2014.6716495","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716495","geographical heuristics;machine learning;visual inspection;visualizations","Electronic mail;Internet;Measurement;Mobile communication;Psychoacoustic models;Smart phones;Visual analytics;Visualization","geographic information systems;inspection","Internet;geographical heuristics;geographical information;geographically-related problems;mobile sensor;smartphones;visual analysis;visual inspection","","0","","","","","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Optimization of emergency response using higher order learning and clustering of 911 text messages","C. Nelson; W. M. Pottenger","CCICADA, Rutgers Univ., Piscataway, NJ, USA","2013 IEEE International Conference on Technologies for Homeland Security (HST)","20140102","2013","","","486","491","In real-time emergency response an accurate picture of the situation is needed quickly. Often during large-scale disasters, cell towers become overloaded, and the only way of communication is through text messages. It becomes important to gather information from text messages sent to emergency numbers in order to respond quickly and efficiently with life-saving efforts. In addition, responders are unable to manually handle the large volume of incoming texts. To add to this difficult problem, these data sources tend to be microtext. This research developed a methodology to summarize text messages sent during an emergency, including analysis of locations. The real-time disaster needs were then input into a mixed integer programming resource allocation model for distribution of resources for disaster aid. Prior research included resource allocation and text modeling, but the combination of the two is a novel application not only in this arena, but more broadly across domains.","","CD-ROM:978-1-4799-3963-3; Electronic:978-1-4799-1535-4; POD:978-1-4799-3964-0","10.1109/THS.2013.6699052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6699052","HO-LDA;HONB;Higher Order Latent Dirichlet Allocation;Higher Order Naïve Bayes;Higher Order topic modeling;LDA;Latent Dirichlet Allocation;disaster response;higher order learning;machine learning;mixed integer programming;operations research;optimization;topic modeling","Data models;Injuries;Media;Real-time systems;Resource management;Sociology;Statistics","emergency management;integer programming;learning (artificial intelligence);pattern clustering;resource allocation","disaster aid;emergency numbers;emergency response optimization;higher order learning;information gathering;mixed integer programming resource allocation model;text message clustering;text modeling","","0","","13","","","12-14 Nov. 2013","","IEEE","IEEE Conference Publications"
"The Role of Emotions in Contributors Activity: A Case Study on the GENTOO Community","D. Garcia; M. S. Zanetti; F. Schweitzer","Dept. of Syst. Design, ETH Zurich, Zurich, Switzerland","2013 International Conference on Cloud and Green Computing","20131219","2013","","","410","417","We analyze the relation between the emotions and the activity of contributors in the Open Source Software project GENTOO. Our case study builds on extensive data sets from the project's bug tracking platform BUGZILLA, to quantify the activity of contributors, and its mail archives, to quantify the emotions of contributors by means of sentiment analysis. The GENTOO project is known for a period of centralization within its bug triaging community. This was followed by considerable changes in community organization and performance after the sudden retirement of the central contributor. We analyze how this event correlates with the negative emotions, both in bilateral email discussions with the central contributor, and at the level of the whole community of contributors. We then extend our study to consider the activity patterns of GENTOO contributors in general. We find that contributors are more likely to become inactive when they express strong positive or negative emotions in the bug tracker, or when they deviate from the expected value of emotions in the mailing list. We use these insights to develop a Bayesian classifier that detects the risk of contributors leaving the project. Our analysis opens new perspectives for measuring online contributor motivation by means of sentiment analysis and for real-time predictions of contributor turnover in Open Source Software projects.","","Electronic:978-0-7695-5114-2; POD:978-1-4799-1362-6","10.1109/CGC.2013.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6686063","activity;machine learning;motivation;open source;sentiment analysis;turnover","Communities;Media;Open source software;Organizations;Psychology;Social network services","human factors;program debugging;public domain software","BUGZILLA project bug tracking platform;Bayesian classifier;GENTOO community;bilateral email discussions;bug triaging community;contributor activity;online contributor motivation;open source software project;sentiment analysis","","5","","51","","","Sept. 30 2013-Oct. 2 2013","","IEEE","IEEE Conference Publications"
"Ensemble classifiers for biomedical data: Performance evaluation","H. I. Elshazly; A. M. Elkorany; A. E. Hassanien; A. T. Azar","Fac. of Comput. & Inf., Cairo Univ., Cairo, Egypt","2013 8th International Conference on Computer Engineering & Systems (ICCES)","20140109","2013","","","184","189","Machine Learning concept offers the biomedical research field a great support. It provides many opportunities for disease discovering and related drugs revealing. The machine learning medical applications had been evolved from the physician needs and motivated by the promising results extracted from empirical studies. Medical support systems can be provided by screening, medical images, pattern classification and microarrays gene expression analysis. Typically medical data is characterized by its huge dimensionality and relatively limited examples. Feature selection is a crucial step to improve classification performance. Recent studies in machine learning field about classification process emerged a novel strong classifier scheme called the ensemble classifier. In this paper, a study for the performance of two novel ensemble classifiers namely Random Forest (RF) and Rotation Forest (ROT) for biomedical data sets is tested with five medical datasets. Three different feature selection methods were used to extract the most relevant features in each data set. Prediction performance is evaluated using accuracy measure. It was observed that ROT achieved the highest classification accuracy in most tested cases.","","Electronic:978-1-4799-0080-0; POD:978-1-4799-0079-4","10.1109/ICCES.2013.6707198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707198","Biomedical classification;Data Mining;Ensemble Classifier;Feature selection (FS);Knowledge discovery;Machine Learning (ML);Random Forest;Rotation Forest","Accuracy;Feature extraction;Medical diagnostic imaging;Radio frequency;Support vector machines;Vegetation","data mining;diseases;drugs;feature extraction;feature selection;genetics;learning (artificial intelligence);medical diagnostic computing;pattern classification;random processes","ROT;biomedical data;classification accuracy measure;data dimensionality;disease discovery;drugs;ensemble classifiers scheme;feature extraction;feature selection methods;machine learning medical applications;medical images;medical support systems;microarrays gene expression analysis;pattern classihcation;prediction performance evaluation;random forest;rotation forest;screening","","4","","33","","","26-28 Nov. 2013","","IEEE","IEEE Conference Publications"
"Data mining in insurance claims (DMICS) two-way mining for extreme values","S. Aftab; W. Abbas; M. M. Bilal; T. Hussain; M. Shoaib; S. H. Mehmood","Protege Global, Islamabad, Pakistan","Eighth International Conference on Digital Information Management (ICDIM 2013)","20140102","2013","","","1","6","In insurance claims extreme values are inevitable and cannot be discarded for predictive model building. Moreover, settling insurance claims involves many objections, human sentiments and unseen factors which are hard to be estimated. This simple fact presents the greatest challenge to analysts working on such problems. This paper presents an optimal approach to minimize the effects of this problem on predictive analysis. The data in question includes insurance settlement cases. The proposed approach firstly deals with extreme values by classifying them separately and then applies machine learning models for predicting settlement amount for each claim. This two way mining increases the overall accuracy in predicting settlement amount for insurance claims.","","Electronic:978-1-4799-0615-4; POD:978-1-4799-0614-7","10.1109/ICDIM.2013.6694026","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694026","classification;extreme values;insurance claims;insurance settlements;machine learning;predictive model;two way mining","Accuracy;Data models;Floors;Insurance;Predictive models;Regression tree analysis;Support vector machines","data mining;insurance data processing;learning (artificial intelligence)","DMICS;data mining;extreme values;human sentiments;insurance claims;machine learning models;predictive analysis;predictive model building;settlement amount prediction;two-way mining;unseen factors","","0","","9","","","10-12 Sept. 2013","","IEEE","IEEE Conference Publications"
"A mobile emotion recognition system based on speech signals and facial images","Y. H. Wu; S. J. Lin; D. L. Yang","Dept. of Inf. Eng. & Comput. Sci., Feng Chia Univ., Taichung, Taiwan","2013 International Computer Science and Engineering Conference (ICSEC)","20140102","2013","","","212","217","Smartphones are used daily for personal and business communications, and they have become a primary medium to capture human emotions. By recognizing the emotions of speakers during a conversation, one can deliver or understand messages better, make successful negotiations, and provide more personal services. Therefore, we developed an emotion recognition system on a mobile platform based on speech signals and facial images. This research has two phases, a training phase and a testing phase. In the first phase, speech signals and facial images are processed through data preprocessing, feature extraction, and SVM classifier construction steps. In the second phase, the participants generated video recordings as test data. These data were transformed for feature extraction and classified into four emotion classes by using the generated classifiers. Feature selection methods were exploited to choose useful features. We proposed an adjustable weighted segmentation method to determine the final results of emotion recognition. Various experiments were performed using real world simulations to evaluate the proposed system. The result showed an average accuracy rate of 87 percent with the highest accuracy rate at 91 percent. Facial images were also used to improve emotion recognition especially during periods of silence in conversations.","","Electronic:978-1-4673-5324-3; POD:978-1-4673-5323-6; USB:978-1-4799-1635-1","10.1109/ICSEC.2013.6694781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694781","Affective Computing;Emotion Recognition;Facial Image;Machine Learning;Speech Signal","Accuracy;Databases;Emotion recognition;Feature extraction;Image segmentation;Speech;Speech recognition","emotion recognition;face recognition;feature extraction;image classification;image segmentation;smart phones;speech processing;support vector machines","SVM classifier;adjustable weighted segmentation method;data preprocessing;facial images;feature extraction;feature selection methods;mobile emotion recognition system;mobile platform;smart phones;speech signals;support vector machines;testing phase;training phase","","0","","19","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Emotion Recognition from EEG during Self-Paced Emotional Imagery","C. A. Kothe; S. Makeig; J. A. Onton","Swartz Center for Comput. Neurosci., Univ. of California San Diego, La Jolla, CA, USA","2013 Humaine Association Conference on Affective Computing and Intelligent Interaction","20131212","2013","","","855","858","Here we present an analysis of a 12-subject electroencephalographic (EEG) data set in which participants were asked to engage in prolonged, self-paced episodes of guided emotion imagination with eyes closed. Our goal is to correctly predict, given a short EEG segment, whether the participant was imagining a positive respectively negative-valence emotional scenario during the given segment using a predictive model learned via machine learning. The challenge lies in generalizing to novel (i.e., previously unseen) emotion episodes from a wide variety of scenarios including love, awe, frustration, anger, etc. based purely on spontaneous oscillatory EEG activity without stimulus event-locked responses. Using a variant of the Filter-Bank Common Spatial Pattern algorithm, we achieve an average accuracy of 71.3% correct classification of binary valence rating across 12 different emotional imagery scenarios under rigorous block-wise cross-validation.","2156-8103;21568103","Electronic:978-0-7695-5048-0; POD:978-1-4799-0632-1","10.1109/ACII.2013.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681552","EEG;brain-computer interface;emotion;guided imagery;machine learning;valence","Accuracy;Band-pass filters;Electroencephalography;Emotion recognition;IIR filters;Scalp;Spatial filters","behavioural sciences computing;channel bank filters;electroencephalography;emotion recognition;learning (artificial intelligence)","EEG segment;binary valence rating;block-wise cross-validation;electroencephalographic data set;emotion recognition;emotional imagery scenarios;filter-bank common spatial pattern algorithm;machine learning;negative-valence emotional scenario;predictive model;self-paced emotional imagery;spontaneous oscillatory EEG activity","","9","","17","","","2-5 Sept. 2013","","IEEE","IEEE Conference Publications"
"Online Ridge Regression Method Using Sliding Windows","P. Arce; L. Salinas","Center for Technol. Innovation in High Performance Comput., UTFSM, Valparaiso, Chile","2012 31st International Conference of the Chilean Computer Science Society","20140102","2012","","","87","90","A new regression method based on the aggregating algorithm for regression (AAR) is presented. The proposal shows how ridge regression can be modified in order to reduce the number of operations by avoiding the inverse matrix calculation only considering a sliding window of the last input values. This modification allows algorithm expression in a recursive way and therefore its use in an online context. Ridge regression, AAR and our proposal were compared using the closing stock prices of 45 stocks from the technology market from 2000 to 2012. Empirical results show that our proposal performs better than the other two methods in 28 of 45 stocks analyzed, due to the lower MSE error.","1522-4902;15224902","Electronic:978-1-4799-2938-2; POD:978-1-4799-2939-9","10.1109/SCCC.2012.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694077","Machine Learning;Online Learning;Ridge Regression","Context;Equations;Mathematical model;Prediction algorithms;Predictive models;Proposals;Vectors","financial data processing;learning (artificial intelligence);mathematics computing;matrix inversion;regression analysis","AAR;aggregating algorithm-for-regression;closing stock prices;inverse matrix calculation avoidance;machine learning;online learning;online ridge regression method;sliding windows","","0","","8","","","12-16 Nov. 2012","","IEEE","IEEE Conference Publications"
"Twitter Sentiment Analysis: A Bootstrap Ensemble Framework","A. Hassan; A. Abbasi; D. Zeng","Dept. of Syst. & Inf. Eng., Univ. of Virginia, Charlottesville, VA, USA","2013 International Conference on Social Computing","20140102","2013","","","357","364","Twitter sentiment analysis has become widely popular. However, stable Twitter sentiment classification performance remains elusive due to several issues: heavy class imbalance in a multi-class problem, representational richness issues for sentiment cues, and the use of diverse colloquial linguistic patterns. These issues are problematic since many forms of social media analytics rely on accurate underlying Twitter sentiments. Accordingly, a text analytics framework is proposed for Twitter sentiment analysis. The framework uses an elaborate bootstrapping ensemble to quell class imbalance, sparsity, and representational richness issues. Experiment results reveal that the proposed approach is more accurate and balanced in its predictions across sentiment classes, as compared to various comparison tools and algorithms. Consequently, the bootstrapping ensemble framework is able to build sentiment time series that are better able to reflect events eliciting strong positive and negative sentiments from users. Considering the importance of Twitter as one of the premiere social media platforms, the results have important implications for social media analytics and social intelligence.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693353","machine learning;opinion mining;sentiment analysis;social media analytics;text mining","Analytical models;Classification algorithms;Data models;Media;Parametric statistics;Training;Twitter","computational linguistics;computer bootstrapping;pattern classification;social networking (online)","Twitter sentiment analysis;Twitter sentiment classification;bootstrap ensemble framework;colloquial linguistic patterns;sentiment cues;social intelligence;social media analytics","","18","","32","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Non-negative matrix factorization with sparseness constraints for credit risk assessment","Y. Liu; J. Du; F. Wang","Dept. of Math, Ohio State Univ., Columbus, OH, USA","Proceedings of 2013 IEEE International Conference on Grey systems and Intelligent Services (GSIS)","20140120","2013","","","211","214","As the most important tasks of a bank, assessment of credit card users is aimed to keep the risk of a credit loss low and to minimize costs of failure over risk groups. Credit risk assessment is an essential problem in finance. However, accessing credit risk is very difficult because many factors may contribute to the risk and their relationship is complicated to capture. Recent years have witnessed a growing trend in applying machine learning methods, such as SVM classifier, for credit risk analysis. SVM is a strong classifier that is effective in capturing nonlinear relationship in the data. However, high dimensional training data not only results in time-consuming computation but also affects the performance of the classifier. In this paper, we will adopt sparse non-negative matrix factorization to transform the data into lower dimensional space that will contribute to good performance in the credit risk classification. We test our method in a real-world credit risk prediction task, and our empirical results demonstrate the advantage of our method by comparing with other state of art methods.","2166-9430;21669430","Electronic:978-1-4673-5248-2; POD:978-1-4673-5246-8","10.1109/GSIS.2013.6714778","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714778","Credit Risk Analysis;Feature Extraction;L1-Norm;Machine Learning;Sparse Non-Negative Matrix Factorization","Accuracy;Classification algorithms;Convergence;Equations;Feature extraction;Principal component analysis;Support vector machines","bank data processing;learning (artificial intelligence);matrix decomposition;minimisation;pattern classification;risk analysis;smart cards;sparse matrices;support vector machines","SVM classifier;bank;cost minimization;credit card user assessment;credit loss;credit risk analysis;high dimensional training data;machine learning method;real-world credit risk prediction task;sparse nonnegative matrix factorization;sparseness constraints","","0","","13","","","15-17 Nov. 2013","","IEEE","IEEE Conference Publications"
"A gate model of emotional learning","S. Khachatryan; K. Grigoryan","Coll. of Sci. & Eng., American Univ. of Armenia Yerevan, Yerevan, Armenia","Ninth International Conference on Computer Science and Information Technologies Revised Selected Papers","20140116","2013","","","1","8","The paradigm of stimulus-driven emotional learning is embraced within a more integral field of machine learning. A computational model is suggested, where the actions of stimuli are represented by matrices acting on agent's state vector. The model is validated against several classical experiments in the area of classical conditioning. Eventually, ways of further development are indicated and the conditioning phenomena not covered yet by the model are listed.","","Electronic:978-1-4799-2461-5; POD:978-1-4799-2462-2","10.1109/CSITechnol.2013.6710346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710346","Machine learning;classical conditioning;cognitive process;computational model;emotion","Computational modeling;Decision making;Integrated circuit modeling;Logic gates;Testing;Training;Vectors","learning (artificial intelligence);matrix algebra","agents state vector;classical conditioning phenomena;computational model;emotional learning gate model;machine learning;matrices;stimulus-driven emotional learning","","0","","26","","","23-27 Sept. 2013","","IEEE","IEEE Conference Publications"
"Analyzing Close Friend Interactions in Social Media","M. Madeira; A. Joshi","Dept. of Comput. Sci. & Electr. Eng., Univ. of Maryland, Baltimore, MD, USA","2013 International Conference on Social Computing","20140102","2013","","","932","935","Social media has increasingly become an outlet for expression in society. Users of online social networks often associate with many other users who are all treated as ""friends, "" even if they do not have a strong connection, or what would be described as a friendship in real life. In this paper, we present an approach for predicting a user's closest friends on Facebook using machine learning techniques. We identify Facebook interactions that are most useful for predicting relationship strength and are able to predict a user's closest friends with up to 85% accuracy.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693442","data mining;machine learning;social network analysis;tie strength","Accuracy;Data mining;Facebook;Feature extraction;Media;Prediction algorithms","data analysis;learning (artificial intelligence);social networking (online)","Facebook interactions;close friend interactions analysis;machine learning techniques;online social networks;relationship strength prediction;social media","","2","","11","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Personalized technology for supporting health behaviors","S. C. Wangberg; C. Psychol","","2013 IEEE 4th International Conference on Cognitive Infocommunications (CogInfoCom)","20140123","2013","","","339","344","Previous work within health communication has been concerned with how to tailor intervention content in a way that is most effective in supporting the individual in changing health behaviors such as smoking, physical activity or diet. This kind of tailoring is based on data gathered from the user through questionnaires with textual feedback adapted by algorithms pre-specified according to behavioral theory. The Internet opened up for a new generation of tailored interventions that were more sophisticated, more synchronous and more longitudinal. In the current paper I present the results of a scoping review to explore literature relevant to how the third generation of tailored interventions might look like, using sensors embedded in commonly available ICT such as PCs and smartphones and machine learning for tailoring these kinds of interventions in real time, thus becoming cognitive infocommunications (CogInfoCom) applications that enhance the human brain. The main aim of the paper is to inspire further multidisciplinary research and development on addressing the important topic of supporting the individual in changing and maintaining health behaviors.","","Electronic:978-1-4799-1546-0; POD:978-1-4799-1545-3; USB:978-1-4799-1544-6","10.1109/CogInfoCom.2013.6719267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719267","Attention;EDA;Eye-tracking;Health Behavior;Internet-Based Interventions;Machine Learning;Personalization;Tailoring;mHealth","Computers;Conferences;Educational institutions;Heart rate;Internet;Real-time systems;Sensors","Internet;behavioural sciences computing;cognition;learning (artificial intelligence);smart phones","CogInfoCom applications;ICT;Internet-based interventions;PC;behavioral theory;cognitive infocommunication applications;data gathering;diet;health behavior change;health behavior maintenance;health communication;human brain enhancement;intervention content;machine learning;multidisciplinary research and development;personalized technology;physical activity;smart phones;smoking;textual feedback","","0","","50","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Energy Aware Resource Management for Clusters of Web Servers","S. Kiertscher; B. Schnor","Univ. of Potsdam, Potsdam, Germany","2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing","20131212","2013","","","148","156","Web server clusters guarantee high performance and high availability for applications like google and amazon. Typically, over-provisioning is used to guarantee a Service Level Agreement in the case of peak load situations. We present an energy saving mechanism which extends the capabilities of traditional load balancers like for example the Linux Virtual Server (LVS). The energy saving daemon called Cherub, running on the front node of the cluster, turns nodes on and off depending on the current load situation. We evaluate different load determination and forecasting methods to detect the utilization of the back end servers in a test bed using requests from a web server log file of the Wikimedia Foundation. Even for the most challenging situation, i.e. in case of a peak load, LVS enhanced with Cherub saves 92% of the theoretical possible optimum saving, while keeping the service level agreement at 99.4% in the experiment.","","Electronic:978-0-7695-5046-6; POD:978-1-4799-0631-4","10.1109/GreenCom-iThings-CPSCom.2013.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682061","cluster of web servers;energy awareness;energy saving;energy-aware techniques;green web server;machine learning;resource management","Benchmark testing;Encyclopedias;Internet;Measurement;Quality of service;Servers;Switches","Internet;contracts;file servers;power aware computing;resource allocation","Cherub;LVS;Linux virtual server;Web server clusters;Web server log file;Wikimedia foundation;back end servers;energy aware resource management;energy saving daemon mechansim;forecasting methods;front node;load balancers;load determination;service level agreement","","1","","29","","","20-23 Aug. 2013","","IEEE","IEEE Conference Publications"
"A novel higher-order semantic kernel for text classification","B. Altlnel; M. C. Ganiz; B. Diri","Dept. of Comput. Eng., Marmara Univ., Istanbul, Turkey","2013 International Conference on Electronics, Computer and Computation (ICECCO)","20140123","2013","","","216","219","In conventional text categorization algorithms, documents are symbolized as “bag of words” (BOW) with the fact that documents are supposed to be independent from each other. While this approach simplifies the models, it ignores the semantic information between terms of each document. In this study, we develop a novel method to measure semantic similarity based on higher-order dependencies between documents. We propose a kernel for Support Vector Machines (SVM) algorithm using these dependencies which is called Higher-Order Semantic Kernel. With the aim of presenting comparative performance of Higher-Order Semantic Kernel we performed many experiments not only with our algorithm but also with existing traditional first-order kernels such as Polynomial Kernel, Radial Basis Function Kernel, and Linear Kernel. The experiments using Higher-Order Semantic Kernel on several well-known datasets show that classification performance improves significantly over the first-order methods.","","Electronic:978-1-4799-3343-3; POD:978-1-4799-3344-0","10.1109/ICECCO.2013.6718267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718267","Machine learning;higher order paths;semantic kernel;support vector machine;text classification","Accuracy;Kernel;Polynomials;Semantics;Support vector machines;Text categorization;Training","pattern classification;support vector machines;text analysis","BOW;SVM algorithm;bag of words;higher-order dependencies;higher-order semantic kernel;semantic information;semantic similarity measurement;support vector machines algorithm;text categorization algorithms;text classification","","3","","19","","","7-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"Application of competitive learning clustering in the load time series segmentation","I. P. Panapakidis; M. C. Alexiadis; G. K. Papagiannis","Dept. of Electr. & Comput. Eng., Aristotle Univ. of Thessaloniki, Thessaloniki, Greece","Power Engineering Conference (UPEC), 2013 48th International Universities'","20140120","2013","","","1","6","Load time series segmentation can serve as the basis for the implementation of variety of applications that have the potential to modify the demand patterns. The scope of this study is three-fold. Firstly, a novel modeling technique of the metered load data of a high voltage industrial consumer is introduced. Instead of representing the daily load curve with a vector with T elements, where T is the time interval of the metering, it is proposed to represent the demand with six indicators that are related with the shape of the curve. Secondly, a new clustering algorithm is introduced in the load time series segmentation field of research. Lastly, a new clustering validity indicator is proposed that can provide an accurate evidence on the optimal number of clusters. The data under study are the active and reactive metered load of a full year.","","Electronic:978-1-4799-3254-2; POD:978-1-4799-3255-9; USB:978-1-4799-3253-5","10.1109/UPEC.2013.6714957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714957","Clustering validity;Load curves classification;Load profiles;Time series analysis;Unsupervised machine learning","Algorithm design and analysis;Clustering algorithms;Neurons;Shape;Time series analysis;Unsupervised learning;Vectors","metering;pattern clustering;power system analysis computing;time series;unsupervised learning","clustering algorithm;clustering validity indicator;competitive learning clustering;high voltage industrial consumer;load curve classification;load time series segmentation;reactive metered load data;unsupervised learning","","0","","10","","","2-5 Sept. 2013","","IEEE","IEEE Conference Publications"
"Subspace Similarity-Based Algorithm for Combine Multiple Clustering","S. Xu; X. Li; R. Chen; S. Wu; J. Ni","Sch. of Inf. Eng., Yancheng Inst. of Technol., Yancheng, China","2013 Seventh International Conference on Internet Computing for Engineering and Science","20131212","2013","","","69","76","Ensemble learning methods train multiple classifiers before classification combination. The methods have been proved to be very effective in supervised machine learning. In this paper, we present an approach to solve ensemble problem of clustering. Beginning with pursuing a ""best"" subspace, we formulate the problem as an optimization of square sum of Euclidean distances between the standard orthogonal basis of the target subspace and the given subspace sets. We then reach the status that the low dimensional embedding of instances and hyper-edges are simultaneously attained. Finally, we use the K-mean algorithm in optimization principle to cluster instances according to their coordinates in the embedding space. This way, we obtain stable clustering results. We apply our ensemble algorithm on several well-recognized datasets. After comparing our experimental results with others, can conclude that our algorithm outperforms other algorithms in terms of the normalized mutual information.","2330-9857;23309857","Electronic:978-0-7695-5118-0; POD:978-1-4799-2238-3","10.1109/ICICSE.2013.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680058","cluster ensembling;clustering analysis;machine learning;normalization mutual information","Internet","learning (artificial intelligence);optimisation;pattern classification;pattern clustering","Euclidean distance;K-mean algorithm;ensemble learning method;hyper-edges;low dimensional embedding;multiple classifier;multiple clustering;optimization principle;orthogonal basis;subspace similarity-based algorithm;supervised machine learning","","0","","15","","","20-22 Sept. 2013","","IEEE","IEEE Conference Publications"
"Recent Advances in Computational Epidemiology","M. V. Marathe; N. Ramakrishnan","","IEEE Intelligent Systems","20131212","2013","28","4","96","101","Public health epidemiology aims to understand the spatiotemporal spread of diseases and to develop methods to control such spread. Computational epidemiology has become increasingly multidisciplinary and has led to novel computational methods for understanding and controlling spatiotemporal disease spread. Recent advances focus specifically on modeling, data mining, and inferential and planning questions.","1541-1672;15411672","","10.1109/MIS.2013.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682934","computational epidemiology;data mining;intelligent systems;machine learning;public health epidemiology","Computational modeling;Epidemiology;Medical services","data mining;diseases;epidemics;public administration","computational epidemiology;computational methods;data mining;public health epidemiology;spatiotemporal disease spread","","2","","28","","","July-Aug. 2013","","IEEE","IEEE Journals & Magazines"
"Application of ensemble learning approach in function approximation for dimensional synthesis of a 6 DOF parallel manipulator","D. Modungwa; N. Tlale; B. Twala","Mechatron. & Micro-Manuf., Council for Sci. & Ind. Res., Pretoria, South Africa","2013 6th Robotics and Mechatronics Conference (RobMech)","20131219","2013","","","26","33","Presented in this paper is an investigation of the use of ensemble methods in machine learning for developing function approximation models of the analytical objective function, to be applied to an optimization search process of a 6 DOF parallel manipulator. The process of optimization of these mechanisms can be cumbersome, as it often involves complex objective functions and diverse design parameters. The use of ensemble methods in machine learning methods combination is demonstrated and evaluated against the individual or base methods using dataset from a parallel robotic manipulator. Experiments are carried out to determine whether an ensemble performs better than the base methods.","","Electronic:978-1-4799-1518-7; POD:978-1-4799-1517-0; USB:978-1-4799-1516-3","10.1109/RoboMech.2013.6685487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685487","ensemble methods in machine learning;optimization;parallel manipulators","Actuators;Jacobian matrices;Joints;Kinematics;Learning systems;Manipulators;Optimization","approximation theory;learning (artificial intelligence);manipulators;optimisation;search problems","6 DOF parallel robotic manipulator;complex objective functions;dimensional synthesis;diverse design parameters;ensemble learning approach;function approximation models;machine learning;optimization search process","","0","","42","","","30-31 Oct. 2013","","IEEE","IEEE Conference Publications"
"Social Networks' Facebook' Statutes Updates Mining for Sentiment Classification","J. Akaichi","Comput. Sci. Dept., ISG-Univ. of Tunis, Le Bardo, Tunisia","2013 International Conference on Social Computing","20140102","2013","","","886","891","In recent years, text mining and sentiment analysis have received great attention due to the abundance of opinion data that exist in social networks such as Facebook, Twitter, etc. Sentiments are projected on these media using texts for expressing feelings such as friendship, social support, anger, happiness, etc. Existing sentiment analysis studies tend to identify user behaviors and state of minds but remain insufficient due to complexities in conveyed texts. In this research paper, we focus on the usage of text mining for sentiment classification. Illustration is performed on Tunisian users' statuses on ""Facebook"" posts during the ""Arabic Spring"" era. Our aim is to extract useful information, about users' sentiments and behaviors during this sensitive and significant period. For that purpose, we propose a method based on Support Vector Machine (SVM) and Naïve Bayes. We also construct a sentiment lexicon, based on the emoticons, interjections and acronyms', from extracted statuses updates. Moreover, we perform some comparative experiments between two machine learning algorithms SVM and Naïve Bayes through a training model for sentiment classification.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693432","Machine learning;Naïve Bayes;Sentiment analysis;Social networks","Classification algorithms;Data mining;Facebook;Feature extraction;Support vector machines;Training","Bayes methods;data mining;natural language processing;pattern classification;social networking (online);support vector machines;text analysis","Arabic Spring era;Facebook posts;Facebook statut update mining;SVM;Tunisian users statuses;Twitter;acronyms;anger;emoticons;friendship;happiness;information extraction;interjections;machine learning algorithm;naive Bayes;opinion data;sentiment analysis;sentiment classification;sentiment lexicon;social network;social support;support vector machine;text mining;user behavior identification;user state of mind","","1","","28","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Detection, Clustering and Tracking of Life Cycle Events on Twitter Using Electric Fields Analogy","D. Terrana; G. Pilato","ICAR (Ist. di Calcolo e Reti ad Alte Prestazioni), Palermo, Italy","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","220","227","With the recent explosion of social networks, there is a growing need for systems capable to extract useful information from this amount of data. Social networks generate a large amount of text content over time because of continuous interaction between people. Given the amount and cadence of the data generated by those platforms, classical text mining techniques are not suitable. ""Events"" can be deduced from aggregations of tweets in the stream. In this paper, we talk about detection, clustering and tracking of events in tweets stream. We will present an online framework that considers a tweet post as an electric charge and anew event as an electric field. A new event on Twitter is created when several tweets deal with the same topic. This event will disappear over time when there are no more tweet debating it. A corpus of 400 million tweets has been created and analyzed using our algorithm. The results show the effectiveness of the technique, both in terms of time and memory performance.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693521","Electric Fields Analogy;Event Detection;Machine Learning;Twitter Stream Analysis","Data mining;Entropy;Market research;Memory management;Real-time systems;Sun;Twitter","data mining;social networking (online);text analysis","electric charge;electric fields analogy;information extraction;life cycle event clustering;life cycle event detection;life cycle event tracking;online framework;social networks;text mining techniques;twitter","","0","","17","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Random Forest Classification for Detecting Android Malware","M. S. Alam; S. T. Vuong","Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing","20131212","2013","","","663","669","Internet connected smartphone devices play a crucial role in the application domain of Internet of Things. These devices are being widely used for day-to-day activities such as remotely controlling lighting and heating at homes, paying for parking, and recently for paying for goods using saved credit card information using Near Field Communication (NFC). Android is the most popular smartphone platform today. It is also the choice of malware authors to obtain secure and private data. In this paper we exclusively apply the machine learning ensemble learning algorithm Random Forest supervised classifier on an Android feature dataset of 48919 points of 42 features each. Our goal was to measure the accuracy of Random Forest in classifying Android application behavior to classify applications as malicious or benign. Moreover, we wanted to focus on detection accuracy as the free parameters of the Random Forest algorithm such as the number of trees, depth of each tree and number of random features selected are varied. Our experimental results based on 5-fold cross validation of our dataset shows that Random Forest performs very well with an accuracy of over 99 percent in general, an optimal Out-Of-Bag (OOB) error rate [3] of 0.0002 for forests with 40 trees or more, and a root mean squared error of 0.0171 for 160 trees.","","Electronic:978-0-7695-5046-6; POD:978-1-4799-0631-4","10.1109/GreenCom-iThings-CPSCom.2013.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682136","Android;Machine Learning;Malware","Androids;Error analysis;Humanoid robots;Malware;Smart phones;Vectors;Vegetation","Android (operating system);Internet of Things;data privacy;feature selection;invasive software;learning (artificial intelligence);pattern classification;smart phones","Android application behavior;Android feature dataset;Android malware detection;Internet connected smartphone devices;Internet of Things;application domain;machine learning ensemble learning algorithm;optimal out-of-bag error rate;random feature selection;random forest algorithm;random forest classification;random forest supervised classifier;root mean squared error","","8","","24","","","20-23 Aug. 2013","","IEEE","IEEE Conference Publications"
"Detecting Life Events in Feeds from Twitter","B. D. Eugenio; N. Green; R. Subba","Univ. of Illinois at Chicago, Chicago, IL, USA","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","274","277","Short posts on micro-blogs are characterized by high ambiguity and non-standard language. We focus on detecting life events from such micro-blogs, a type of event which have not been paid much attention so far. We discuss the corpus we assembled and our experiments. Simpler models based on unigrams perform better than models that include history, number of retweets and semantic roles.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693529","Machine Learning;Semantic Role Labelling;Social Media;Text Classification;Twitter","Accuracy;Employment;History;Interviews;Semantics;Support vector machines;Twitter","social networking (online);social sciences computing","Twitter;life events detection;microblogs;unigrams","","3","","19","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"RIPTIDE: Learning violation prediction models from boarding activity data","H. Chalupsky; E. Hovy","Inf. Sci. Inst., Univ. of Southern California, Marina del Rey, CA, USA","2013 IEEE International Conference on Technologies for Homeland Security (HST)","20140102","2013","","","48","53","Part of the U.S. Coast Guard's mission is to monitor vessels and their operators for compliance with a large body of safety and fisheries regulations. Recently the Coast Guard has devised a system called OPTIDE, which aims at improving operations efficiency by ranking vessels via a risk score computed from current information and aggregated past boarding observations. Ships with higher risk should be preferentially boarded, since they have higher probability of being in violation of some regulation. To improve upon OPTIDE, we developed RIPTIDE which uses machine learning to automatically learn a more fine-grained and data-driven violation prediction and ranking model from past boarding activity data. The learning problem is challenging, since the data is very unbalanced (only about 20% of all boardings actually find some violation), it has significant sampling bias, and in general the signal for predicting violations is weak. Nevertheless, our best RIPTIDE model outperforms OPTIDE by up to 86% on a ranking experiment. The main reason for this improvement comes from being able to distinguish vessels in a more fine-grained manner, which allows RIPTIDE to make winning decisions more often, even if the underlying signal is very weak. A software package implementing RIPTIDE has been developed to allow the Coast Guard to experiment with the learned models and apply them to operational data.","","CD-ROM:978-1-4799-3963-3; Electronic:978-1-4799-1535-4; POD:978-1-4799-3964-0","10.1109/THS.2013.6698975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698975","fisheries;machine learning;maritime law enforcement;risk estimation","Aquaculture;Classification algorithms;Data models;Decision trees;Marine vehicles;Monitoring;Safety","aquaculture;data handling;decision making;environmental legislation;learning (artificial intelligence);marine engineering;sampling methods;ships","OPTIDE;RIPTIDE model;US Coast Guard mission;boarding activity data;data-driven violation prediction model;fine-grained violation prediction model;fishery regulation;machine learning;operation efficiency;risk score;rule induction OPTIDE;safety regulations;ships;software package;vessel ranking model;winning decision making","","0","","5","","","12-14 Nov. 2013","","IEEE","IEEE Conference Publications"
"Unrestrained sensors using piezoelectric elements for bed-leaving prediction","H. Madokoro; N. Shimoi; K. Sato","Fac. of Syst. Sci. & Technol., Akita Prefectural Univ., Yurihonjo, Japan","2013 13th International Conference on Control, Automation and Systems (ICCAS 2013)","20140109","2013","","","1599","1604","This paper presents a sensor system that predicts behavior patterns that occur when a patient leaves a bed. We originally developed plate-shaped sensors using piezoelectric elements. Existing sensors such as clip sensors and mat sensors require that patients be restrained. The features of our sensors are that they require no power supply or patient restraint for privacy problems. Moreover, we developed machine-learning algorithms to predict behavior patterns without setting thresholds. We evaluated our system for three subjects at an experimental environment constructed in reference to a clinical site. The mean recognition accuracy was 78.6% for seven behavior patterns. Especially, the recognition accuracies of lateral sitting and terminal sitting were each 94.4%. We consider that these capabilities are useful for bed-leaving prediction in practical use.","2093-7121;20937121","Electronic:978-89-93215-05-2; POD:978-1-4799-0549-2","10.1109/ICCAS.2013.6704185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704185","Bed-leaving Prediction;Machine Learning;Piezoelectric Elements;Quality of Life","Sensors;Zigbee","learning (artificial intelligence);patient treatment;piezoelectric materials;sensors","bed-leaving prediction;behavior patterns;clinical site;machine learning;piezoelectric elements;plate-shaped sensors;unrestrained sensors","","0","","12","","","20-23 Oct. 2013","","IEEE","IEEE Conference Publications"
"Muscle-based skeletal bipedal locomotion using neural evolution","A. Topchyan; T. Topchyan","Tech. Univ. of Munic, Munich, Germany","Ninth International Conference on Computer Science and Information Technologies Revised Selected Papers","20140116","2013","","","1","6","The developmental of bipedal walkers has long been a very important problem in the fields of robotics and computer simulation. In this work we propose using evolutionary methods and muscle based control to evolve bipedal walkers. We present an efficient method for evolving walking controller, which are used by a robot to walk large distances. Our approach mimics both the human limb control mechanism and the human learning process to create natural walking patterns and provides valuable insight into the learning process.","","Electronic:978-1-4799-2461-5; POD:978-1-4799-2462-2","10.1109/CSITechnol.2013.6710356","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710356","Artificial intelligence;bipedal locomotion;machine learning;muscle simulation;neural evolution","Artificial neural networks;Joints;Legged locomotion;Muscles;Sociology;Statistics","gait analysis;legged locomotion;muscle;neurocontrollers","bipedal walkers;human learning process;human limb control mechanism;muscle-based skeletal bipedal locomotion control;natural walking pattern creation;neural evolution;walking controller","","0","","7","","","23-27 Sept. 2013","","IEEE","IEEE Conference Publications"
"Can Automated Text Classification Improve Content Analysis of Software Project Data?","J. Noll; D. Seichter; S. Beecham","Irish Software Eng. Res. Centre, Univ. of Limerick, Limerick, Ireland","2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement","20131212","2013","","","300","303","Content analysis is a useful approach for analyzing unstructured software project data, but it is labor-intensive and slow. Can automated text classification (using supervised machine learning) be used to reduce the labor or improve the speed of content analysis? We conducted a case study involving data from a previous study that employed content analysis of an open source software project. We used a human-coded data set with 3256 samples to create different size training sets ranging in size from 100 to 3000 samples to train an ""ensemble"" text classifier to assign one of five different categories to a test set of samples. The results show that the automated classifier could be trained to recognize categories, but much less accurately than the human classifiers. In particular, both precision and recall for low-frequency categories was very low (less than 20%). Nevertheless, we hypothesize that automated classifiers could be used to filter a sample to identify common categories before human researchers examine the remainder for more difficult categories.","1949-3770;19493770","Electronic:978-0-7695-5056-5; POD:978-1-4799-1144-8","10.1109/ESEM.2013.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681372","Content Analysis;Machine Learning;Open Source Software;Qualitative Research;Software Engineering;Text Classification","Accuracy;Encoding;Message systems;Software;Software engineering;Software measurement;Training","data analysis;learning (artificial intelligence);pattern classification;project management;public domain software;software management;text analysis","automated text classification;content analysis;ensemble text classifier;human-coded data set;open source software project;size training sets;supervised machine learning;unstructured software project data analysis","","0","","21","","","10-11 Oct. 2013","","IEEE","IEEE Conference Publications"
"Analysis of the effects of image transformation, template selection, and partial information on face recognition with time-varying expressions for homeland security applications","I. V. Voynichka; D. B. Megherbi","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Lowell, MA, USA","2013 IEEE International Conference on Technologies for Homeland Security (HST)","20140102","2013","","","541","546","Facial recognition, especially with time-varying facial expressions and/or disguises, is crucial in many homeland security applications. The recent Boston Marathon attack is one example reminder of the importance of developing accurate and reliable facial recognition algorithms. While various face recognition algorithms have been proposed in the literature, unfortunately many of them still remain in their infancy. This is mainly due to their lack of high recognition rates in the presence of varying image face artifacts and conditions. In order to develop more accurate facial recognition systems there is a primary need to identify and, as much as possible, derive some of the causes that may affect some face recognition accuracy rates. The main contribution of this paper is the investigation and analysis of how and what factors, other than illumination noise, and occlusion, may affect the recognition accuracy rate of some of the most popular and currently widely used face recognition algorithms, namely, Eigenface-based, Fisherface-based and Direct Correlation-based ones. In particular, in this work we show the effects, on these facial recognition accuracy, of facial reasonable registration with or without off-the-plane face rotation, the type and number of individual's face template(s) selection, and the type and increasing amount of partial facial information contained in face images. Finally experimental results are presented to demonstrate the potential value and importance of each of these proposed factors on facial recognition.","","CD-ROM:978-1-4799-3963-3; Electronic:978-1-4799-1535-4; POD:978-1-4799-3964-0","10.1109/THS.2013.6699061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6699061","Biometrics;Computational Intelligence;Computer and Machine Vision;Digital Image Processing;Facial Recognition;Machine Learning;correlation-based face recognition;eigenfaces;fisher-faces","Accuracy;Databases;Face;Face recognition;Image recognition;Image registration;Training","face recognition;military computing","Boston Marathon attack;direct correlation-based algorithm;eigenface-based algorithm;face recognition;facial recognition algorithms;fisherface-based algorithm;homeland security applications;illumination noise;image face artifacts;image transformation;occlusion;partial facial information;partial information;recognition accuracy;recognition rates;template selection;time-varying facial disguises;time-varying facial expressions","","2","","37","","","12-14 Nov. 2013","","IEEE","IEEE Conference Publications"
"Correlation analysis of complex network metrics on the topology of the Internet","A. Garcia-Robledo; A. Diaz-Perez; G. Morales-Luna","Inf. Technol. Lab., Ciudad Victoria, Mexico","2013 10th International Conference and Expo on Emerging Technologies for a Smarter World (CEWIT)","20140116","2013","","","1","6","We present an experimental study on the linear relationship between a rich set of complex network metrics, to methodologically select a subset of non-redundant and potentially independent metrics that explain different aspects of the topology of the Autonomous System view of the Internet. We followed a data-driven approach based on (1) a correlation study of different properties of evolving Internet networks, and (2) the validation of a non-redundant set of metrics by evaluating the performance of supervised and unsupervised machine learning techniques. We confirm pair-wise metric correlations observed in other types of networks and identify sets of highly correlated metrics that may reveal patterns specific to the topology of the Internet.","","Electronic:978-1-4799-2546-9; POD:978-1-4799-2547-6","10.1109/CEWIT.2013.6713749","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6713749","Internet;autonomous systems;complex networks;correlation analysis;machine learning","Complex networks;Correlation;Heating;Internet;Measurement;Principal component analysis","Internet;complex networks;computer network performance evaluation;telecommunication computing;telecommunication network topology;unsupervised learning","Internet networks;Internet topology;autonomous system view;complex network metrics;correlation analysis;pair-wise metric correlations;performance evaluation;unsupervised machine learning technique","","3","","21","","","21-22 Oct. 2013","","IEEE","IEEE Conference Publications"
"Text mining facebook status updates for sentiment classification","J. Akaichi; Z. Dhouioui; M. J. López-Huertas Pérez","Comput. Sci. Dept., Inst. Super. de Gestion de Tunis (ISG), Le Bardo, Tunisia","2013 17th International Conference on System Theory, Control and Computing (ICSTCC)","20131219","2013","","","640","645","In recent years, text mining and sentiment analysis have received great attention due to the abundance of opinion data that exist in social networks such as Facebook, Twitter, etc. Sentiments are projected on these media using texts for expressing feelings such as friendship, social support, anger, happiness, etc. Existing sentiment analysis studies tend to identify user behaviors and state of minds but remain insufficient due to complexities in conveyed texts. In this research paper, we focus on the usage of text mining for sentiment classification. Illustration is performed on Tunisian users' statuses on Facebook posts during the “Arabic Spring” era. Our aim is to extract useful information, about users' sentiments and behaviors during this sensitive and significant period. For that purpose, we propose a method based on Support Vector Machine (SVM) and Naïve Bayes. We also construct a sentiment lexicon, based on the emoticons, interjections and acronyms', from extracted statuses updates. Moreover, we perform some comparative experiments between two machine learning algorithms SVM and Naïve Bayes through a training model for sentiment classification.","","CD-ROM:978-1-4799-2227-7; Electronic:978-1-4799-2228-4; POD:978-1-4799-2229-1","10.1109/ICSTCC.2013.6689032","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6689032","machine learning;naïve Bayes;sentiment analysis;social networks","Classification algorithms;Data mining;Facebook;Feature extraction;Support vector machines;Training","Bayes methods;classification;data mining;learning (artificial intelligence);social networking (online);support vector machines;text analysis","Arabic spring;SVM;Twitter;emoticons;information extraction;interjections;machine learning algorithms;naïve Bayes;opinion data;sentiment analysis;sentiment classification;sentiment lexicon;social networks;support vector machine;text mining Facebook status updates;training model;user behaviors","","4","","28","","","11-13 Oct. 2013","","IEEE","IEEE Conference Publications"
"An Unsupervised Data-Driven Cross-Lingual Method for Building High Precision Sentiment Lexicons","P. Sangiorgi; A. Augello; G. Pilato","ICAR (Ist. di Calcolo e Reti ad Alte Prestazioni), Palermo, Italy","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","184","190","In this paper we present a completely unsupervised approach for creating a sentiment lexicon. The approach has been realized by designing a pipeline which implements an unsupervised system that covers different aspects: the automatic extraction of user reviews, the pre-processing of text, the use of a scoring measure which combines: entropy, term frequency, inverse document frequency, and finally a cross lingual intersection. We have validated the approach though the analysis of a previews present in the Google Play market. The results show the effectiveness of the approach given by satisfactory values of precision for the obtained lexicon.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693515","Machine Learning;Sentiment Analysis;Sentiment Lexicon","Buildings;Dictionaries;Entropy;Frequency measurement;Google;Pipelines;Pragmatics","computational linguistics;entropy;information retrieval;text analysis;unsupervised learning","Google Play market;cross lingual intersection;entropy;high precision sentiment lexicons;inverse document frequency;scoring measure;term frequency;text preprocessing;unsupervised data-driven cross-lingual method;unsupervised system;user reviews automatic extraction","","0","","22","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Online hybrid internet traffic classification algorithm based on signature statistical and port methods to identify internet applications","H. A. H. Ibrahim; S. M. Nor; H. A. Jamil","Fac. of Electr. Eng., Univ. Teknol. Malaysia, Skudai, Malaysia","2013 IEEE International Conference on Control System, Computing and Engineering","20140123","2013","","","185","190","Internet traffic classification gained significant attention in the last few years. Most of the current classification methods were only valid for offline classification. Each of the three common classification methods (port, payload, statistics) has some limitations. To increase the value of Internet traffic classifiers, this paper combines the three methods to produce a new classification algorithm (SSPC). In the proposed algorithm, each traffic flow was classified in parallel three times by one of the three method classifiers. Based on certain priority rules, SSPC makes classification decisions for each traffic flow. The SSPC algorithm was tested by classifying WWW applications traffic in two stages: offline and online. The results of both cases show that SSPC is the higher accuracy when compared with other classifiers. In addition, the results indicate that the SSPC algorithm was suitable for online classification decisions, which is taken with the speed of the Inter-net traffic.","","Electronic:978-1-4799-1508-8; POD:978-1-4799-1507-1","10.1109/ICCSCE.2013.6719956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719956","Internet traffic Classification;Machine Learning;WWW applications;hybrid classifier;signature classifier","Accuracy;Algorithm design and analysis;Classification algorithms;Cryptography;Grippers;Ports (Computers);World Wide Web","Internet;learning (artificial intelligence);pattern classification;statistical analysis;telecommunication traffic","Internet application identification;Internet service providers;SSPC algorithm;machine learning;offline stages;online hybrid Internet traffic classification algorithm;online stage;signature port method;signature statistical method","","0","","20","","","Nov. 29 2013-Dec. 1 2013","","IEEE","IEEE Conference Publications"
"A Critical Study of Selected Classification Algorithms for Dengue Fever and Dengue Hemorrhagic Fever","W. Farooqi; S. Ali","Comput. Sci. & IT Dept., Univ. of Lahore, Lahore, Pakistan","2013 11th International Conference on Frontiers of Information Technology","20140123","2013","","","140","145","Dengue fever is viral infection caused by dengue virus which is transmitted in human body by bite of female Eddie mosquito. There are 50 million people suffer from it globally every year. Pakistan has been victim of this rapidly growing disease from last few years. The world health organization identified two main types of dengue fever. This paper appraises the selected classification algorithms for the classification of dengue fever (DF) and dengue haemraghic fever (DHF) datasets. Naïve Bayes classifier, Decision Tree, K-nearest neighbor algorithm, multilayered perception algorithm and Support vector machines are considered here for classification of dengue fever. These algorithms are measured based on five criteria: Accuracy, Precision, Sensitivity, Specificity and false negative rate.","","Electronic:978-1-4799-2503-2; POD:978-1-4799-2700-5","10.1109/FIT.2013.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6717241","Dataminingmining;dengue fever;supervised machine learning","Accuracy;Classification algorithms;Decision trees;Hospitals;Pain;Sensitivity;Support vector machines","Bayes methods;decision trees;diseases;medical diagnostic computing;microorganisms;multilayer perceptrons;pattern classification;support vector machines","K-nearest neighbor algorithm;Pakistan;accuracy;classification algorithm;decision tree;dengue fever;dengue hemorrhagic fever;dengue virus;disease;false negative rate;female Eddie mosquito;human body;multilayered perception algorithm;naïve Bayes classifier;precision;sensitivity;specificity;support vector machine;viral infection","","0","","21","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic Mash Up Music Video Generation System by Remixing Existing Video Content","H. Ohya; S. Morishima","Dept. Adv. Sci. & Eng., Waseda Univ., Tokyo, Japan","2013 International Conference on Culture and Computing","20131212","2013","","","157","158","Music video is a short film which presents a visual representation of recent music. In these days, there is a trend that amateur users create music video in the video sharing website. Especially, the music video which is created by cutting and pasting existing video is called mashup music video. In this paper, we proposed the system that users can easily create mushup music video by using existing music videos. In addition, we conducted assessment evaluation experiment for our system. The system firstly extracts music features and video features from existing music videos. Then, the each feature is clustered and the relationship between each feature is learned by Hidden Markov Model. At last, the system cuts learned video scene which is the closest feature among learned videos and pastes it synchronizing with input song. Experiment shows that our method can generate more synchronized video than a previous method.","","Electronic:978-0-7695-5047-3; POD:978-1-4799-0617-8","10.1109/CultureComputing.2013.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680357","machine learning;music analysis;music video;video content analysis","Feature extraction;Hidden Markov models;Markov processes;Synchronization;Training;Video sequences;Viterbi algorithm","Web sites;feature extraction;hidden Markov models;learning (artificial intelligence);music;video signal processing","Hidden Markov Model;automatic mash up music video generation system;music feature extraction;music videos;video content;video sharing Web site;visual representation","","1","","3","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"On the effect of the label bias problem in part-of-speech tagging","Phuong Le-Hong; Xuan-Hieu Phan; The-Trung Tran","Univ. of Sci., Hanoi, Vietnam","The 2013 RIVF International Conference on Computing & Communication Technologies - Research, Innovation, and Vision for Future (RIVF)","20140123","2013","","","103","108","This paper investigates the effect of the label bias problem of maximum entropy Markov models for part-of-speech tagging, a typical sequence prediction task in natural language processing. This problem has been underexploited and underappreciated. The investigation reveals useful information about the entropy of local transition probability distributions of the tagging model which enables us to exploit and quantify the label bias effect of part-of-speech tagging. Experiments on a Vietnamese treebank and on a French treebank show a significant effect of the label bias problem in both of the languages.","","Electronic:978-1-4799-1350-3; POD:978-1-4799-1348-0","10.1109/RIVF.2013.6719875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719875","CRF;French;MEMM;Vietnamese;label bias problem;machine learning;part-of-speech tagging;treebank","Accuracy;Context;Entropy;Hidden Markov models;Predictive models;Probability distribution;Tagging","Markov processes;learning (artificial intelligence);maximum entropy methods;natural language processing;speech processing;statistical distributions","French treebank;Vietnamese treebank;label bias problem;local transition probability distribution entropy;maximum entropy Markov models;natural language processing;part-of-speech tagging;sequence prediction task","","0","","14","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
