"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6208621,6208957,6145754,6204490,6205441,6204520,6204736,6204659,6204765,6204519,6204703,6204613,6183517,6200710,6201853,6202092,6201210,6201946,6199471,6199095,6129537,6196965,6196956,6197118,6197406,6196948,6197061,6196888,6194631,6194595,6195377,6194610,6195332,6194623,6187804,6187952,6184710,6188269,6184865,6187366,6187346,6183461,6183079,6181075,6181600,6181679,6182253,6181049,6165213,6165186,6177810,6178937,6178884,6178448,6178862,6174579,6174288,6173579,6177726,6173215,6173611,6173603,6173581,6177732,6029340,6168322,6169828,6170432,6169838,6166704,6166699,6166605,6166669,6166680,6164512,6164556,6163977,6163048,6163970,6158835,6158779,5560637,6158826,6158827,6123212,6126049,6126047,6156003,5975166,6153232,6150030,6150231,6148885,6146920,6149145,6149156,6143219,6144947,6142974,6144875",2017/05/05 22:46:32
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An efficient clustering algorithm based on Z-Score ranking method","V. Kathiresan; P. Sumathi","Department of MCA, RVS College of Arts & science, Coimbatore, India","2012 International Conference on Computer Communication and Informatics","20120301","2012","","","1","4","In this paper, we propose an algorithm to compute initial cluster centers for K-means clustering based on Z-Score ranking. This scoring technique is a statistical method of ranking numerical and nominal attributes based on distance measure. The data are sorted based on the score values. Then divide the ranked data into k subsets. Calculate the mean values of each k subsets. Pick the nearby value of data to the mean as the initial centroid. The experimental results suggest that the proposed algorithm is effective, converge to better clustering results than those of the random initialization method. The research also indicated the proposed algorithm would greatly improve the likelihood of every cluster containing some data in it.","","Electronic:978-1-4577-1583-9; POD:978-1-4577-1580-8","10.1109/ICCCI.2012.6158779","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158779","Centroid Initialization;Clustering Algorithm;K Medoid Clustering;K-means Clustering","Accuracy;Algorithm design and analysis;Clustering algorithms;Convergence;Data mining;Machine learning algorithms;Partitioning algorithms","data mining;pattern clustering;random processes;statistical analysis","data mining technique;distance measure;initial cluster center computation;k-means clustering algorithm;nominal attribute ranking;numerical attribute ranking;random initialization method;scoring technique;statistical method;z-score ranking method","","3","","15","","","10-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"An approach for measuring semantic similarity between words using SVM and LS-SVM","S. Lavanya; S. S. Arya","Dept. of CSE, Sona College of Technology, Salem, India","2012 International Conference on Computer Communication and Informatics","20120301","2012","","","1","4","Measuring semantic similarity between words plays vital role in information retrieval and natural language processing. The existing system uses page counts and snippets retrieved by a search engine to measure semantic similarity between words. Various similarity scores are calculated from the page counts retrieved by the search engine for the queried conjunctive words. A lexical pattern extraction algorithm identifies the patterns from the snippets. Different patterns showing the same semantic relation are clustered using a lexical pattern clustering algorithm. The existing system makes use of Support Vector Machines to combine the similarity scores from page counts and clusters of patterns from snippets for measuring similarity. We propose a different machine learning approach called Latent Structural Support Vector Machine which can handle the missing data values which occurs frequently in statistical data analysis. The proposed system also makes a comparative study between similarity results from both SVM and LS-SVM.","","Electronic:978-1-4577-1583-9; POD:978-1-4577-1580-8","10.1109/ICCCI.2012.6158835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158835","Latent Support Vector Machine;Support Vector Machine;Web Mining","Computers;Machine learning;Search engines;Semantics;Support vector machines;Training;Web search","data analysis;learning (artificial intelligence);natural language processing;pattern clustering;query processing;search engines;semantic Web;statistical analysis;support vector machines","LS-SVM;information retrieval;latent structural support vector machine;lexical pattern clustering algorithm;lexical pattern extraction algorithm;machine learning approach;missing data value handling;natural language processing;page counts;page snippets;queried conjunctive words;search engine;semantic relation;semantic similarity measurement;similarity scores;statistical data analysis","","0","","16","","","10-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"""Boom"" or ""Ruin""--Does It Make a Difference? Using Text Mining and Sentiment Analysis to Support Intraday Investment Decisions","M. Siering","Goethe-Univ., Frankfurt, Germany","2012 45th Hawaii International Conference on System Sciences","20120209","2012","","","1050","1059","Investors have to deal with an increasing amount of information in order to make beneficial investment decisions. Thus, text mining is often applied to support the decision-making process by predicting the stock price impact of financial news. Recent research has shown that there exists a relation between news article sentiment and stock prices. However, this is not considered by previous text mining studies. In this paper, we develop a novel two-stage approach that connects text mining with sentiment analysis to predict the stock price impact of company-specific news. We find that the combination of text mining and sentiment analysis improves forecasting results. Additionally, a higher accuracy can be achieved by using finance-related word lists for sentiment analysis instead of a generic dictionary.","1530-1605;15301605","Electronic:978-1-5090-5638-5; POD:978-1-4577-1925-7; USB:978-0-7695-4525-7","10.1109/HICSS.2012.2","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6149156","Financial Decision-Making;Sentiment Analysis;Text Mining","Dictionaries;Indexes;Investments;Labeling;Machine learning;Support vector machines;Text mining","data mining;investment;stock markets;text analysis","company-specific news;decision making process;financial news;intraday investment decisions;sentiment analysis;stock price;text mining","","3","","36","","","4-7 Jan. 2012","","IEEE","IEEE Conference Publications"
"Learning conditional abstractions","B. A. Brady; R. E. Bryant; S. A. Seshia","IBM, Poughkeepsie, NY 12601","2011 Formal Methods in Computer-Aided Design (FMCAD)","20120209","2011","","","116","124","Abstraction is central to formal verification. In term-level abstraction, the design is abstracted using a fragment of first-order logic with background theories, such as the theory of uninterpreted functions with equality. The main challenge in using term-level abstraction is determining what components to abstract and under what conditions. In this paper, we present an automatic technique to conditionally abstract register transfer level (RTL) hardware designs to the term level. Our approach is a layered approach that combines random simulation and machine learning inside a counter-example guided abstraction refinement (CEGAR) loop. First, random simulation is used to determine modules that are candidates for abstraction. Next, machine learning is used on the resulting simulation traces to generate candidate conditions under which those modules can be abstracted. Finally, a verifier is invoked. If spurious counterexamples arise, we refine the abstraction by performing a further iteration of random simulation and machine learning. We present an experimental evaluation on processor designs.","","Electronic:978-0-9835678-1-3; POD:978-1-4673-0896-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6148885","","Computational modeling;Data models;Integrated circuit modeling;Machine learning;Nickel;Vectors","formal logic;formal verification;learning (artificial intelligence)","CEGAR loop;RTL hardware design;conditional abstraction;counter-example guided abstraction refinement;first-order logic;formal verification;machine learning;random simulation;register transfer level;term-level abstraction","","0","","25","","","Oct. 30 2011-Nov. 2 2011","","IEEE","IEEE Conference Publications"
"Review of ontology mapping","L. Huang; G. Hu; X. Yang","The Elementary Educational College, Jiangxi Normal University, Jiangxi Province, Nanchang, P.R. China","2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet)","20120517","2012","","","537","540","In semantic Web applications, Ontology heterogeneity causes for the information exchange problems, ontology mapping is the main method to solve Ontology heterogeneity. The paper first describes the concept of ontology mapping, and contrasts to several current mainstream ontology mapping methods and analyzes system for comparative. At last it concludes that the current process of ontology mapping problems and points out research directions in future.","","DVD:978-1-4577-1413-9; Electronic:978-1-4577-1415-3; POD:978-1-4577-1414-6","10.1109/CECNet.2012.6202092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6202092","Mapping System;Ontology;Ontology Mapping;Review","Educational institutions;Joints;Machine learning;Ontologies;Semantics;Statistical analysis;Syntactics","ontologies (artificial intelligence);semantic Web","information exchange problems;mainstream ontology mapping methods;ontology heterogeneity;semantic Web applications","","3","","14","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
"Subliminal calibration for machine operation with prediction based filtering","H. Igarashi","Department of Electrical and Electronic Engineering, Tokyo Denki University, 2-2, Kanda-Nishiki-cho, Chiyoda-ku, Tokyo 1018457, Japan","2012 12th IEEE International Workshop on Advanced Motion Control (AMC)","20120510","2012","","","1","6","This paper addresses a skill assist technique without awareness. Generally, human assist system is by adding autonomous input to the operation command as force from obstacles. Although these assists are suitable in a particular task, they may bring about hindering human learning process. This paper focused on the human learning to utilize for suitable human-machine systems. The assist is carried out without human awareness, namely “subliminal”, and it does not hinder the operator's learning ability. Furthur, since the technique is based on prediction of operator's input command, subliminal filtering method is applied to improve its prediction accuracy. Then, in spite that the experimental results show the proposed technique make NOT the operators aware of, the operation performance is improved especially on low skilled operators.","1943-6572;19436572","Electronic:978-1-4577-1073-5; POD:978-1-4577-1072-8; USB:978-1-4577-1071-1","10.1109/AMC.2012.6197118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197118","","Calibration;Humans;Impedance;Machine learning;Man machine systems;Predictive models;Target tracking","calibration;filtering theory;machinery production industries;man-machine systems;production equipment;training","human assist system;human learning process;human-machine system;machine operation;operator input command;prediction based filtering;skill assist technique;subliminal assist;subliminal calibration","","5","","12","","","25-27 March 2012","","IEEE","IEEE Conference Publications"
"Research on PSVM Ensemble Algorithm Based on Relief (F) Object to Robot","Y. Shang","Coll. of Comput. & Inf. Eng., Xinxiang Univ., Xinxiang, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","1","","205","207","An efficient proximal support vector machine (PSVM) ensemble algorithm based on Relief (F) is proposed in this paper. Firstly, the feature perturbation based on the Relief (F) algorithm is introduced into the original PSVM ensemble method to create the integrated individuals with high diversity, and then the classification results obtained via integration with applying the majority voting.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187804","proximal support vector machine;relief (F) algorithm;robot","Bagging;Classification algorithms;Machine learning;Robots;Silicon;Support vector machines;Training","nonlinear programming;robot vision;support vector machines","PSVM ensemble algorithm;feature perturbation;proximal support vector machine;relief nonlinear optimization algorithm;relief object;robot visual recognition","","2","","5","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Learning Rate of Least Square Regressions with Some Kind of Mercer Kernel","B. Sheng; L. Duan; P. Ye","Dept. of Math., Shaoxing Coll. of Arts & Sci., Shaoxing, China","2012 Second International Conference on Intelligent System Design and Engineering Application","20120403","2012","","","329","332","We consider the error estimate of least square regression with data dependent hypothesis and coefficient regularization algorithms based on general kernel. When the kernel belongs to some kind of Mercer kernel, under a mild regularity condition on the regression function, we derive a dimensional-free learning rate m-1/6.","","Electronic:978-0-7695-4608-7; POD:978-1-4577-2120-5","10.1109/ISdea.2012.633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173215","Coe&#64259;Data Dependent Hypothesis;Learning Rate Introduction;Mercer Kernel;Square Regressions;cient Regularization","Convergence;Educational institutions;Eigenvalues and eigenfunctions;Kernel;Least squares approximation;Machine learning","learning (artificial intelligence);least squares approximations;regression analysis","Mercer kernel;coefficient regularization algorithms;data dependent hypothesis;general kernel;learning rate;least square regressions","","0","","14","","","6-7 Jan. 2012","","IEEE","IEEE Conference Publications"
"A Novel Approach to Feature Selection for Clustering","T. Liu; Y. Liang; W. Ni","Dept. of Inf. Eng., Shandong Univ. of Sci. & Technol., Taian, China","2012 Fifth International Conference on Intelligent Computation Technology and Automation","20120213","2012","","","41","44","Feature selection has received considerable attentions in various areas as a way to select informative features and to simplify the statistical model through dimensional reduction. In this work, we introduce a novel concept, membership probability of a feature, and propose a novel approach to feature selection for clustering which can find the most optimal candidate features effectively among the original feature space. The efficiency and effectiveness of our approach is demonstrated through extensive comparisons with other methods using real-world data of high dimensionality.","","Electronic:978-0-7695-4637-7; POD:978-1-4673-0470-2","10.1109/ICICTA.2012.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150231","clustering;feature selection;unsupervised learning","Accuracy;Algorithm design and analysis;Clustering algorithms;Filtering;Filtering algorithms;Machine learning;Unsupervised learning","learning (artificial intelligence);pattern clustering;statistical analysis","dimensional reduction;feature selection;membership probability;statistical model","","1","","15","","","12-14 Jan. 2012","","IEEE","IEEE Conference Publications"
"Traffic classification based on visualization","Y. Zhibin; G. B. Kil; Y. d. Choi; S. h. Kim","Electrical Engineering and Computer Science, Kyungpook National University, Daegu, South Korea","2011 IEEE 2nd International Conference on Networked Embedded Systems for Enterprise Applications","20120202","2011","","","1","6","Nowadays application based on encryption flows are increasing. Such applications are beneficial to protect the privacy but also offer convenience to hackers to avoid detection. This paper discusses the feasibility of applying a visualization technique to recognize traffic flows without reading payloads. We proposed a method to extract features from packet size and intervals and then change them to a 2-D image. Unlike most of machine learning methods which use features directly, we enhance the images with a modified mountain function to explore the potential of flow features. Finally principle component analysis is used to classify the traffic flows based on pattern recognition. The result shows that the images generated from flows can be recognized more easily after image enhancement.","","Electronic:978-1-4673-0498-6; POD:978-1-4673-0495-5","10.1109/NESEA.2011.6144947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6144947","Pattern recognition;Traffic classification;Visualization","Computer science;Educational institutions;Internet;Machine learning;Mice;Pattern recognition;Protocols","cryptography;data privacy;data visualisation;image enhancement;learning (artificial intelligence);principal component analysis;telecommunication traffic","2D image;PCA;encryption flows;flow features;image enhancement;machine learning methods;modified mountain function;packet size;pattern recognition;principle component analysis;privacy protection;traffic classification;traffic flows recognition;visualization technique","","1","","22","","","8-9 Dec. 2011","","IEEE","IEEE Conference Publications"
"Reinforcement learning for peer to peer video streaming applications","M. Sayıt; O. Sönmez","Uluslararas&#x0131; Bilgisayar Enstit&#x00FC;s&#x00FC;, Ege &#x00DC;niversitesi, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","In this study, a system with reinforcement learning for push-pull mesh based video streaming applications running over p2p networks is designed. In push-pull based video streaming systems, each node in the system may receive video data from more than one parent. In the proposed system, a node which started to receive insufficient video data from any parent selects a new parent with a probabilistic method based on its previous experience. Afterwards, it learns that parent's performance with Q-learning. In this paper, design parameters of the proposed system is given and performance results obtained from simulations are compared with random parent selection method. The observed results show that the proposed system is superior than the random parent selection method in terms of average bitrate and the number of parent exchanges.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204659","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204659","","Abstracts;Internet;Learning;Learning systems;Machine learning;Peer to peer computing;Streaming media","learning (artificial intelligence);multimedia communication;peer-to-peer computing;video streaming","P2P networks;Q-learning;design parameters;peer to peer video streaming;push-pull mesh based video streaming;random parent selection method;reinforcement learning","","1","","12","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"Efficient web information retrieval based on usage mining","I. Mukherjee; V. Bhattacharya; S. Banerjee; P. K. Gupta; P. K. Mahanti","Department of Computer Science, Birla Institute of Technology, Mesra, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","591","595","The objective of this paper is to analyze web logs using data mining so as to present users with more personalized web content. We classify users based on their internet usage patterns and for each class, maintain a cache of web documents. Searching is performed based on term set analysis and direction cosine distance approach. Finally a more personalized and relevant result set is generated for the query.","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194595","personalized retrieval;searching;term set analysis;web mining","Google;Machine learning","Internet;cache storage;data mining;information retrieval;pattern classification","Internet usage patterns;Web document cache;Web information retrieval;Web log analysis;data mining;direction cosine distance approach;personalized Web content;term set analysis;usage mining","","3","","17","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"Improved Duplicate Bug Report Identification","Y. Tian; C. Sun; D. Lo","Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore","2012 16th European Conference on Software Maintenance and Reengineering","20120405","2012","","","385","390","Bugs are prevalent in software systems. To improve the reliability of software systems, developers often allow end users to provide feedback on bugs that they encounter. Users could perform this by sending a bug report in a bug report management system like Bugzilla. This process however is uncoordinated and distributed, which means that many users could submit bug reports reporting the same problem. These are referred to as duplicate bug reports. The existence of many duplicate bug reports may cause much unnecessary manual efforts as often a triager would need to manually tag bug reports as being duplicates. Recently, there have been a number of studies that investigate duplicate bug report problem which in effect answer the following question: given a new bug report, retrieve k other similar bug reports. This, however, still requires substantive manual effort which could be reduced further. Jalbert and Weimer are the first to introduce the direct detection of duplicate bug reports, it answers the question: given a new bug report, classify if it as a duplicate bug report or not. In this paper, we extend Jalbert and Weimer's work by improving the accuracy of automated duplicate bug report identification. We experiments with bug reports from Mozilla bug tracking system which were reported between February 2005 to October 2005, and find that we could improve the accuracy of the previous approach by about 160%.","1534-5351;15345351","Electronic:978-0-7695-4666-7; POD:978-1-4673-0984-4","10.1109/CSMR.2012.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178884","Bugzilla;Duplicate bug reports;relative similarity","Computer bugs;Frequency measurement;Harmonic analysis;Machine learning;Software systems;Training;Training data","feedback;program debugging;software reliability","Bugzilla;Mozilla bug tracking system;bug report management system;duplicate bug report identification;feedback;reliability;software systems","","27","","24","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"Novel comment filtering approach based on outlier on streaming data","N. Özalp; G. Yılmaz; U. Ayan","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Hava Harp Okulu, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","This is the preliminary work for a project which will be filtering comments made on news and papers automatically. Our database has over 1 million news and comments. Due to the intensity of our data, 30.677 comments made on 15.064 articles on 44 different categories are used as experimental data. Proposed anomaly based method have been obtained fast and high accuracy results without the high storage requirement and high computational complexity with respect to other classification based methods on literature.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204765","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204765","","Conferences;Databases;Filtering;Machine learning;Neural networks;Text categorization","information filtering;media streaming;statistical analysis","comment filtering;computational complexity;news;outlier;streaming data","","1","","18","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"An iterative ellipsoid-based anomaly detection technique for intrusion detection systems","S. Suthaharan","Department of Computer Science, University of North Carolina at Greensboro, USA","2012 Proceedings of IEEE Southeastcon","20120510","2012","","","1","6","Intrusion detection datasets play a major role in evaluating machine learning techniques for Intrusion Detection Systems. The Intrusion detection datasets are generally very large and contain many noncontributing features and redundant data. These drawbacks lead to inaccurate intrusion detection and increased computational cost when machine learning techniques are evaluated. Several data cleaning techniques have been proposed to eliminate redundant records and noncontributing features. These techniques reduce the size of the datasets significantly and make the characteristics of the data closer to the characteristics of intrusions in a real network. This paper identifies anomaly problems in normal and intrusion attacks data, and proposes an ellipsoid-based technique to detect anomalies and clean the intrusion detection datasets further. Publically available KDD'99 and NSL-KDD datasets are used to demonstrate its performance. It reveals an interesting property, i.e. monotonically decreasing behavior, of the NSL-KDD dataset.","1091-0050;10910050","Electronic:978-1-4673-1375-9; POD:978-1-4673-1374-2","10.1109/SECon.2012.6196956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6196956","KDD'99 dataset;NSL-KDD dataset;anomaly detection;intrusion detection","Accuracy;Approximation methods;Ellipsoids;Feature extraction;Intrusion detection;Kernel;Machine learning","learning (artificial intelligence);redundancy;security of data","KDD'99 datasets;NSL-KDD datasets;anomaly problems;data cleaning techniques;ellipsoid-based technique;intrusion attacks data;intrusion detection datasets;intrusion detection systems;iterative ellipsoid-based anomaly detection technique;machine learning techniques;redundant data;redundant record elimination","","1","","9","","","15-18 March 2012","","IEEE","IEEE Conference Publications"
"Moving Virtual Boundary strategy for selective sampling","Xiaoyu Zhang; J. Cheng","Research Center for Strategic S&T Issues, Institute of Scientific and Technical Information of China, Beijing, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","1520","1524","In relevance feedback of information retrieval system, selective sampling is often used to alleviate the burden of labeling by selecting only the most informative data to label. The traditional batch labeling model neglects the data's correlation and thus degrades the performance; while the theoretical optimal one-by-one training model is not efficient enough because of the high computational complexity. In this paper, we propose a Moving Virtual Boundary (MVB) strategy for informative data selection. We adopt a novel one-by-one labeling model, using the previous labeled data as extra guidance for the selection of next, and achieve better experimental results.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182253","active learning;information retrieval;relevance feedback;selective sampling;support vector machine","Accuracy;Image retrieval;Information retrieval;Labeling;Machine learning;Support vector machines;Training","computational complexity;information retrieval systems;relevance feedback","data correlation;high computational complexity;information retrieval system;informative data selection;moving virtual boundary strategy;one-by-one labeling model;optimal one-by-one training model;relevance feedback;selective sampling;traditional batch labeling model","","0","","7","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Centroid-Based Nearest Neighbor Feature Representation for E-Government Intrusion Detection","C. F. Tsai; J. H. Tsai; J. S. Chou","Dept. of Inf. Manage., Nat. Central Univ., Jungli, Taiwan","2012 World Telecommunications Congress","20120315","2012","","","1","6","Accompanied by the invention of information and communication of technologies, e-government has become a prominent feature of modern governance in every country. The aims of e-government are to promote executive efficiencies, to reduce transaction costs of citizen, and to increase the responsiveness of the public sector. However, the requirement of pursuing these goals is based on the security measures of intrusion detection systems (IDS). If technologies are not advanced enough to distinguish between normal connections and illegal attacks, citizens would be doubtful in using the access of e-government to interact with the public sector and will eventually lose the trust of government. Technically, feature representation is an important key to successful pattern classification. However, very few studies focus on extracting better representative features of normal connections and attacks for better detection. Therefore, this paper proposes a novel feature representation approach by cluster centers and nearest neighbors, namely CANN. In this approach, two distances are measured and summed. The first one is based on the distance between each data sample and its cluster center, and the second distance is between the data and its nearest neighbor in the same cluster. Then, this new and one-dimensional distance based feature is used to represent each data sample for intrusion detection The experimental results based on the KDD-Cup 99 dataset show that CANN not only can make the k-nearest neighbor classifier perform reasonably well, but also provides high computational efficiency for the time of training and testing a classifier.","","Electronic:978-4-88552-257-4; POD:978-1-4577-1459-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6170432","","Data mining;Feature extraction;Intrusion detection;Learning systems;Machine learning;Support vector machines;Training","Internet;government data processing;pattern classification;public administration;security of data;transaction processing;trusted computing","CANN;IDS;KDD-Cup 99 dataset;centroid-based nearest neighbor feature representation;cluster centers;computational efficiency;e-government intrusion detection;executive efficiency;feature representation approach;government trust;illegal attacks;intrusion detection systems;k-nearest neighbor classifier;modern governance;nearest neighbors;normal connections;one-dimensional distance;pattern classification;public sector;security measures;transaction costs","","1","","18","","","5-6 March 2012","","IEEE","IEEE Conference Publications"
"A New Method of Class Centriod Vectors Classification Based on the Feedback","L. Weijiang; C. Xing; Z. Tiejun; W. Xiangang","Comput. Applic. Key Lab. of Yunnan Province, Kunming Univ. of Sci. & Technol., Kunming, China","2012 International Conference on Computer Distributed Control and Intelligent Environmental Monitoring","20120405","2012","","","56","60","It is a great challenge for information technology that how to organize and manage large amount of document data, and find users' interested information quickly and exactly. Text classification can achieve the goal of information distributaries and solve the problem of information disorder, and then it can offer the convenience to users to make decisions. Centroid classifier is one of the most efficient models. Firstly the paper expatiates on the disadvantage of traditional weight calculation method applied in text classification, and then a new method which uses feature selection evaluation function value as a factor to term frequency is proposed. This paper present an improved centroid classifier based on feedback. The main idea of the algorithm is using the misfit samples in the training set to modify the center vectors which are related with them. From test results, the algorithm proposed by the paper is valid.","","Electronic:978-0-7695-4639-1; POD:978-1-4673-0458-0","10.1109/CDCIEM.2012.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178448","centriod vector;feedback;text classificationt","Classification algorithms;Machine learning;Support vector machine classification;Text categorization;Training;Vectors","pattern classification;text analysis","class centriod vectors classification;document data;feature selection evaluation function value;feedback;information disorder;information distributaries;information technology;term frequency;text classification","","0","","13","","","5-6 March 2012","","IEEE","IEEE Conference Publications"
"Personalized Learning Resources Recommendation Model Based on Transfer Learning","H. Chen","Comput. Coll., China West Normal Univ., Nanchong, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","2","","14","16","This paper based on the traditional learning resources of collaborative-filtering personalized recommendation systems exist sparse and cold start is put forward based on the personal learning resources study migration recommend model, study method can move from existing data transfer knowledge, to help the new knowledge in the future study. E-Learning environment, use of knowledge transfer for learners to provide the study resources recommended. And in a certain degree of collaborative-filtering solve sparse solution and cold start-up problem.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187952","Transfer Learning Collaborative filtering Personal learning resources recommended","Collaboration;Data models;Electronic learning;Filtering;Learning systems;Machine learning;Vectors","computer aided instruction;recommender systems","cold start-up problem;collaborative-filtering personalized recommendation systems;data transfer knowledge;e-learning environment;knowledge transfer;personal learning resources study migration recommend model;personalized learning resources recommendation model;traditional learning resources;transfer learning","","2","","10","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Cognitive machine-to-machine communications: visions and potentials for the smart grid","Y. Zhang; R. Yu; M. Nekovee; Y. Liu; S. Xie; S. Gjessing","Simula Research Laboratory and University of Oslo, Norway","IEEE Network","20120517","2012","26","3","6","13","Based upon cognitive radio technology, we propose a new Machine-to-Machine (M2M) communications paradigm, namely Cognitive M2M (CM2M) communication. We first motivate the use of cognitive radio technology in M2M communications from different point of views, including technical, applications, industry support, and standardization perspectives. Then, our CM2M network architecture and cognitive machine model are presented and the CM2M systems coexistence in TV white spaces is discussed. After that, a CM2M communications architecture for the smart grid is presented, for which we also propose an energy-efficiency driven spectrum discovery scheme. Numerical results demonstrate significant energy saving and the reliability in supporting data transmissions in the smart grid.","0890-8044;08908044","","10.1109/MNET.2012.6201210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6201210","","Cognitive radio;Machine learning;Sensors;Smart grids;TV;White spaces","cognitive radio;data communication;power system measurement;reliability;smart power grids","cognitive machine model;cognitive radio technology;data transmissions;energy saving;machine-to-machine communications paradigm;reliability;smart grid;white spaces","","142","","11","","","May-June 2012","","IEEE","IEEE Journals & Magazines"
"WiP Abstract: A Human-Centered Cyber-Physical Systematic Approach for Post-Stroke Monitoring","H. Wang; X. Deng; F. Tian","State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China","2012 IEEE/ACM Third International Conference on Cyber-Physical Systems","20120510","2012","","","209","209","We proposed a human-centered cyber-physical systematic approach for post-stroke monitoring. This system is composed of wearable inertial and physiological sensors as well as novel machine learning algorithms to analyze human behavior and physiological signals in the context of health caring for patients with cerebrovascular diseases such as stroke.","","Electronic:978-0-7695-4695-7; POD:978-1-4673-1537-1","10.1109/ICCPS.2012.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197406","Cyber-physical system;health care","Biomedical monitoring;Diseases;Humans;Machine learning algorithms;Monitoring;Wearable sensors","diseases;health care;learning (artificial intelligence);medical computing;patient monitoring;sensors","cerebrovascular diseases;health caring;human-centered cyber-physical systematic approach;machine learning algorithms;physiological sensors;post-stroke monitoring;wearable inertial sensors","","1","","3","","","17-19 April 2012","","IEEE","IEEE Conference Publications"
"On the automatic categorisation of android applications","B. Sanz; I. Santos; C. Laorden; X. Ugarte-Pedrero; P. G. Bringas","S3Lab, DeustoTech - Computing, Deusto Institute of Technology, Avenida de las Universidades 24, 48007, Bilbao, Spain","2012 IEEE Consumer Communications and Networking Conference (CCNC)","20120412","2012","","","149","153","The presence of mobile devices has increased in our lives offering almost the same functionality as a personal computer. Android devices have appeared lately and, since then, the number of applications available for this operating system have increased exponentially. Google already has its Android Market where applications are offered and, as happens with every popular media, is prone to misuse. A malware writer may insert a malicious application into this market without being noticed. Indeed, there are already several cases of Android malware within the Android Market. Therefore, an approach that can automatically characterise the different types of applications can be helpful for both organising the Android Market and detecting fraudulent or malicious applications. In this paper, we propose a new method for categorising Android applications through machine-learning techniques. To represent each application, our method extracts different feature sets: (i) the frequency of occurrence of the printable strings, (ii) the different permissions of the application itself and (iii) the permissions of the application extracted from the Android Market. We evaluate this approach of automatically categorisation of Android applications and show that achieves a high performance.","2331-9852;23319852","Electronic:978-1-4577-2071-0; POD:978-1-4577-2070-3","10.1109/CCNC.2012.6181075","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181075","","Androids;Feature extraction;Humanoid robots;Learning systems;Machine learning;Malware;Training","fraud;invasive software;learning (artificial intelligence);mobile computing;operating systems (computers);search engines;smart phones","Android applications;Android malware;Android market;Google;automatic categorisation;feature sets;fraudulent application;machine-learning techniques;malicious application;malware writer;mobile devices;operating system;personal computer;printable strings","","11","","31","","","14-17 Jan. 2012","","IEEE","IEEE Conference Publications"
"Generalized SMO Algorithm for SVM-Based Multitask Learning","F. Cai; V. Cherkassky","Dept. of Electr. & Comput. Eng., Univ. of Minnesota, Minneapolis, MN, USA","IEEE Transactions on Neural Networks and Learning Systems","20120521","2012","23","6","997","1003","Exploiting additional information to improve traditional inductive learning is an active research area in machine learning. In many supervised-learning applications, training data can be naturally separated into several groups, and incorporating this group information into learning may improve generalization. Recently, Vapnik proposed a general approach to formalizing such problems, known as “learning with structured data” and its support vector machine (SVM) based optimization formulation called SVM+. Liang and Cherkassky showed the connection between SVM+ and multitask learning (MTL) approaches in machine learning, and proposed an SVM-based formulation for MTL called SVM+MTL for classification. Training the SVM+MTL classifier requires the solution of a large quadratic programming optimization problem which scales as O(n<sup>3</sup>) with sample size n. So there is a need to develop computationally efficient algorithms for implementing SVM+MTL. This brief generalizes Platt's sequential minimal optimization (SMO) algorithm to the SVM+MTL setting. Empirical results show that, for typical SVM+MTL problems, the proposed generalized SMO achieves over 100 times speed-up, in comparison with general-purpose optimization routines.","2162-237X;2162237X","","10.1109/TNNLS.2012.2187307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183517","<formula formulatype=""inline""><tex Notation=""TeX"">${rm SVM}{+}$</tex></formula>;Classification;learning with structured data;multitask learning;quadratic optimization;sequential minimal optimization;support vector machine (SVM)","Machine learning;Optimization;Support vector machines;Training;Training data;Vectors;Zirconium","data structures;learning (artificial intelligence);quadratic programming;support vector machines","MTL;Platt sequential minimal optimization;SVM based multitask learning;data structure;generalized SMO algorithm;group information;inductive learning;machine learning;multitask learning;optimization formulation;quadratic programming optimization problem;supervised learning applications;support vector machine","","9","","21","","20120413","June 2012","","IEEE","IEEE Journals & Magazines"
"Impact of Word Segmentation Errors on Automatic Chinese Text Classification","X. Luo; W. Ohyama; T. Wakabayashi; F. Kimura","Grad. Sch. of Eng., Mie Univ., Tsu, Japan","2012 10th IAPR International Workshop on Document Analysis Systems","20120507","2012","","","271","275","In this paper, several sets of experiments were carried out to study the impact of word segmentation errors on automatic Chinese text classification. Comparison experiment of four word-based approaches was first carried out and the results show that the performance was significantly reduced when using automatic word segmentation instead of manual word segmentation which means errors caused by automatic word segmentation have an obvious impact on classification performance. We further conducted the experiment using character-based approach (N-gram). Although N-gram approach produces a large number of ambiguous words, the results show that it performed better than automatic word segmentation.","","Electronic:978-0-7695-4661-2; POD:978-1-4673-0868-7","10.1109/DAS.2012.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6195377","Chinese text classification/categorization;ICTCLAS;N-gram;support vector machine;word segmentation","Kernel;Machine learning;Manuals;Support vector machine classification;Text categorization;Training data","pattern classification;text analysis;word processing","N-gram approach;automatic Chinese text classification;automatic word segmentation;character-based approach;classification performance;word segmentation error impact;word-based approach","","0","1","10","","","27-29 March 2012","","IEEE","IEEE Conference Publications"
"Three-level HAC on food borne disease and related treatment to help medical DSS","T. Kadam; V. Chitre","Computer Engineering, Mumbai University, PIIT, New Panvel, Maharashtra, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","672","676","Medical Database include all the essential information to predict, diagnosis and make decision about treatment to any disease, but we cannot recognize the hidden knowledge with nude eyes. We need microscope to do its works, so we use data mining method clustering as microscope on medical database to extract hidden knowledge which will be helpful to medical domain. Applying Conceptual clustering is an important way of summarizing data. This paper focuses on HAC method of clustering to analyze food borne diseases & help medical domain to take decision on those disease. The goal is to find knowledge of disease causation, to prevent and control disease, and to help administrative guidance.","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194610","Attribute table;Clustering;Data mining;HAC;Medical Database","Data mining;Databases;Diseases;Information technology;Learning systems;Machine learning;Medical diagnostic imaging","data mining;decision support systems;diseases;medical information systems;pattern clustering","administrative guidance;conceptual clustering;data mining;food borne disease;medical DSS;medical database;medical domain;three-level HAC","","0","","13","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"Multiple Feature-Classifier Combination in Automated Text Classification","L. S. P. Busagala; W. Ohyama; T. Wakabayashi; F. Kimura","Sokoine Nat. Agric. Libr., Sokoine Univ. of Agric., Morogoro, Tanzania","2012 10th IAPR International Workshop on Document Analysis Systems","20120507","2012","","","43","47","Automatic text classification (ATC) is important in applications such as indexing and organizing electronic documents in databases leading to enhancement of information access and retrieval. We propose a method which employs various types of feature sets and learning algorithms to improve classification effectiveness. Unlike the conventional methods of multi-classifier combination, the proposed method considers the contributions of various types of feature sets and classifiers. It can therefore be known as multiple feature-classifier combination (MFC) method. In this paper we present empirical evaluation of MFC using two benchmarks of text collections to determine its effectiveness. Empirical evaluation show that MFC consistently outperformed all compared methods.","","Electronic:978-0-7695-4661-2; POD:978-1-4673-0868-7","10.1109/DAS.2012.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6195332","Feature reduction;Feature-Classifier Combination;Multi-classifier combination;Text Classification/Categorization;ensembles","Information retrieval;Machine learning;Principal component analysis;Support vector machines;Text categorization;Training;Vectors","learning (artificial intelligence);pattern classification;text analysis","automated text classification;classification effectiveness;electronic document;feature set;information access;information retrieval;learning algorithm;multiple feature-classifier combination;text collection","","0","2","23","","","27-29 March 2012","","IEEE","IEEE Conference Publications"
"Web2MexADL: Discovery and Maintainability Verification of Software Systems Architecture","J. Castrejón; R. Lozano; G. Vargas-Solar","Inst. Tecnol. y de Estudios Super. de Monterrey, Mexico City, Mexico","2012 16th European Conference on Software Maintenance and Reengineering","20120405","2012","","","531","534","This paper introduces Web2MexADL, a tool that can discover architectural documentation for web systems, by analyzing properties and relationships of their source code artifacts. This analysis is based on the use of probabilistic methods executed through machine learning tools. The resulting documentation includes an Architecture Description Language (ADL) document and a Scalable Vectors Graphic (SVG) file depicting an architecture view of the analyzed system. Finally, the resulting ADL document can be used to verify the maintainability of the system under analysis, by taking advantage of the MexADL approach.","1534-5351;15345351","Electronic:978-0-7695-4666-7; POD:978-1-4673-0984-4","10.1109/CSMR.2012.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178937","Documentation;Software engineering;Software maintenance;Software verification and validation","Bayesian methods;Computer architecture;Documentation;Machine learning;Probabilistic logic;Software systems","Internet;document handling;formal verification;learning (artificial intelligence);probability;software architecture;software maintenance;software tools;system documentation","ADL;SVG;Web systems;Web2MexADL;architectural documentation;architecture description language document;discovery verification;machine learning tools;maintainability verification;probabilistic methods;scalable vectors graphic file;software systems architecture;source code artifacts","","0","","19","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"A novel and incremental classification algorithm","H. Özkan; Ö. S. Pelvan; A. Akman; S. S. Kozat","Elektrik ve Elektronik M&#x00FC;hendisli&#x011F;i B&#x00F6;l &#x00FC;m&#x00FC;, Ko&#x00E7; &#x00DC;niversitesi, Rumelifeneri Yolu, &#x0130;stanbul, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","In this paper, using “context tree weighting method”, a novel classification algorithm is proposed for real time machine learning applications, which is mathematically shown to be “competitive” with respect to a certain class of algorithms. The computational complexity of our algorithm is independent with the amount of data to be processed and linearly controllable. The proposed algorithm, hence, is highly scalable. In our experiments, our algorithm is observed to provide a comparable classification performance to the Support Vector Machines with Gaussian kernel with 40~1000× computational efficiency in the training phase and 5~35× in the test phase.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204520","","Context;Data mining;Kernel;Machine learning;Machine learning algorithms;Support vector machines;Training","Gaussian processes;computational complexity;learning (artificial intelligence);signal classification;support vector machines","Gaussian kernel;computational complexity;context tree weighting method;incremental classification algorithm;real time machine learning applications;support vector machines","","0","","10","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"Ranking social emotions by learning listwise preference","Qishen Wang; Ou Wu; Weiming Hu; Jinfeng Yang; Wanqing Li","Aeronautical Automation College, Civil Aviation University of China, Tianjin, China","The First Asian Conference on Pattern Recognition","20120312","2011","","","164","168","Emotion modeling has received a great attention in recent years. This paper models the online social emotions that are the online users' emotional responds when they are exposed to news articles. Specifically, we rank social emotion labels for online documents. Unlike the existing method, referred to as Pair-LR, which learns pairwise preference and adopts binary classification, we address the problem of ranking social emotions by learning listwise preference. In particular, a novel approach, referred to as List-LR, is proposed to learn a ranking model for social emotion labels of online documents by minimizing the listwise loss defined on instances. Empirical experiments show that the proposed approach outperforms Pair-LR and is also competitive to other two start-of-the-art approaches for label ranking.","0730-6512;07306512","Electronic:978-1-4577-0121-4; POD:978-1-4577-0122-1","10.1109/ACPR.2011.6166699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166699","label ranking;listwise preference;social emotions","Accuracy;Learning systems;Machine learning;Measurement;Predictive models;Training;Vectors","pattern classification;social networking (online);social sciences computing","Pair-LR;binary classification;label ranking;listwise preference learning;news articles;online documents;online social emotions;online user emotional response;pairwise preference;social emotion labels;social emotion ranking","","5","","13","","","28-28 Nov. 2011","","IEEE","IEEE Conference Publications"
"Optimized feature selection with k-means clustered triangle SVM for Intrusion Detection","R. Ashok; A. J. Lakshmi; G. D. V. Rani; M. Naresh Kumar","Department of Computer Science, DVR & Dr. HS, MIC College of Technology, Kanchikacherla, Andhra Pradesh, India - 521180","2011 Third International Conference on Advanced Computing","20120409","2011","","","23","27","With the rapid progress in the network based applications, the threat of attackers and security threats has grown exponentially. Misleading of data shows many financial losses in all kind of network based environments. Day by day new vulnerabilities are detected in networking and computer products that lead to new emerging problems. One of the new prevention techniques for network threats is Intrusion Detection System (IDS). Feature selection is the major challenging issues in IDS in order to reduce the useless and redundant features among the attributes (e.g. attributes in KDD cup'99, an Intrusion Detection Data Set). In this paper, we aim to reduce feature vector space by calculating distance relation between features with Information Measure (IM) by evaluating the relation between feature and class to enhance the feature selection. Here we incorporate the Information Measure (IM) method with k-means Cluster Triangular Area Based Support Vector Machine (CTSVM) and SVM (Support Vector Machine) classifier to detect intrusion attacks. By dealing with both continuous and discrete attributes, our proposed method extracts best features with high Detection Rate (DR) and False Positive Rate (FPR).","2377-6927;23776927","Electronic:978-1-4673-0671-3; POD:978-1-4673-0670-6","10.1109/ICoAC.2011.6165213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165213","Detection Rate;False Positive Rate;Information Measure;Intrusion Detection;Support Vector Machine;k-means Clustering","Data mining;Feature extraction;Intrusion detection;Machine learning algorithms;Support vector machine classification;Training","pattern classification;pattern clustering;security of data;support vector machines","SVM classifier;attacker threat;continuous attribute;detection rate;discrete attribute;false positive rate;feature selection;feature vector space;information measure;intrusion detection;k-means cluster triangular area based support vector machine;network based application;security threat;support vector machines;threat prevention technique;triangle SVM;vulnerability detection","","1","","15","","","14-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Concept of stochastic memory & data retrieval using artificial neural networks increasing memory capacity and data security by data overlapping","S. Roy; A. Kundu","Department of Computer Science & Engineering, Indian School of Mines, Dhanbad, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","468","473","This paper presents the concept of a physical memory whose state is dependent on a stochastic variable. The stochastic parameter used is temperature. This gives way to efficient space utilization by overlapping data patches upon existing data and overcoming the upper limit of storage space, i.e. more storage data with less hardware and more data security. Furthermore, the paper goes on to present retrieval solutions, for such overlapped data patch structures, using Deep Belief Networks made up of layers of. Restricted Boltzmann machines (RBM), along with mapping with a Bidirectional Associative Memory (BAM).","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194623","Adaptive Learning;Bidirectional Associative Memory (BAM);Boltzmann machine (BM);Data Patch Structures;Deep Belief Nets;Gibb's sampling;Markov Chains;Parallel Tampering (PT);Restricted Boltzmann Machine (RBM);Stochastic memory","Associative memory;Data models;Floors;Machine learning;Neurons;Training;Vectors","Boltzmann machines;information retrieval;security of data;stochastic processes","BAM;RBM;artificial neural networks;bidirectional associative memory;data overlapping;data patch structures;data retrieval;data security;deep belief networks;memory capacity;physical memory;restricted Boltzmann machines;stochastic memory;stochastic parameter;stochastic variable;storage space","","0","","23","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"Learning in Stages: A Layered Learning Approach for Genetic Programming","T. H. Nguyen; X. H. Nguyen","Le Quy Don Univ., Hanoi, Vietnam","2012 IEEE RIVF International Conference on Computing & Communication Technologies, Research, Innovation, and Vision for the Future","20120315","2012","","","1","4","In this paper, we propose a new layered learning approach for Genetic Programming (GP), called GPLL. Our new GPLL is an extension of the earlier work in [8] incorporating theoretically and experimentally founded components derived from progressive sampling (PS). This new version of GPLL is tested and compared with standard GP on three real-world problems. Tuned for computational efficiency, it is able to demonstrate very substantial reductions in computational cost for relatively small (and generally non-significant) reductions in generalisation accuracy. At the other extreme, computational costs are still substantially less than for GP, while generalisation accuracies are consistently slightly better.","","Electronic:978-1-4673-0309-5; POD:978-1-4673-0307-1","10.1109/rivf.2012.6169838","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169838","","Accuracy;Convergence;Educational institutions;Genetic programming;Machine learning;Schedules;Training","genetic algorithms;learning (artificial intelligence)","computational cost;computational efficiency;generalisation accuracy;genetic programming;layered learning approach;progressive sampling;real-world problems","","0","","14","","","Feb. 27 2012-March 1 2012","","IEEE","IEEE Conference Publications"
"A Scilab toolbox of nonlinear regression models using a linear solver","Y. J. Qu; B. G. Hu","NLPR/LIAMA, Institute of Automation, Chinese Academy of Sciences, Beijing, China","2011 IEEE International Workshop on Open-source Software for Scientific Computation","20120423","2011","","","142","147","This work describes a toolbox of nonlinear regression models developed on an open-source platform of Scilab. The models are formed from radial basis function (RBF) neural network structures. For a fast calculation of the models, we adopt a linear solver in implementations. A specific effort is made on applications of linear priors, which presents a unique feature different from other existing regression toolboxes. In this work, we define linear priors to be a class of prior information that exhibits a linear relation to the attributes of interests, such as variables, free parameters, or their functions of the models. Two approaches of incorporating linear priors are implemented in the models, namely, Lagrange Multiplier (LM) and Direct Elimination (DE). Several numerical examples are demonstrated in the toolbox for the educational purpose on learning nonlinear regression models. From the numerical examples, users can understand the importance of utilizing linear priors in models. The linear priors include the hard constraints on interpolation points and soft constraints on ranking list.","","Electronic:978-1-61284-495-4; POD:978-1-61284-492-3","10.1109/OSSC.2011.6184710","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184710","linear constraints;linear priors;nonlinear regression;radial basis function networks;transparency","Interpolation;Machine learning;Noise;Noise measurement;Numerical models;Reliability;Training data","interpolation;radial basis function networks;regression analysis","DE;LM;Lagrange Multiplier;RBF;Scilab toolbox;direct elimination;hard constraints;interpolation points;linear solver;neural network structures;nonlinear regression models;open-source platform;radial basis function;regression toolboxes;soft constraints","","0","","25","","","12-14 Oct. 2011","","IEEE","IEEE Conference Publications"
"Using Machine Translation for Recognizing Textual Entailment in Vietnamese Language","M. Q. N. Pham; M. L. Nguyen; A. Shimazu","Japan Adv. Inst. of Sci. & Technol., Ishikawa, Japan","2012 IEEE RIVF International Conference on Computing & Communication Technologies, Research, Innovation, and Vision for the Future","20120315","2012","","","1","6","Recognizing Textual Entailment (RTE) is a fundamental task in Natural Language Understanding. The task is to determine whether the meaning of a text can be inferred from the meaning of the other one. This paper explores the use of Machine Translation (MT) in recognizing textual entailment in texts written in Vietnamese. We present two methods of using Machine Translation for Vietnamese RTE. The first method integrates a MT component into front-end of an English RTE system. The second method uses a MT component to produce English translation of Vietnamese RTE data, and both original Vietnamese data and its translation are used to learn an entailment classifier. Experimental results achieve on Vietnamese RTE corpus built from RTE3 data set suggest that Machine Translation can help to improve Vietnamese RTE.","","Electronic:978-1-4673-0309-5; POD:978-1-4673-0307-1","10.1109/rivf.2012.6169828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169828","","Data mining;Engines;Feature extraction;Machine learning;Semantics;Syntactics;Training","language translation;learning (artificial intelligence);natural language processing;pattern classification","English RTE system;MT component;RTE3 data set;Vietnamese RTE;Vietnamese RTE corpus;Vietnamese RTE data English translation;Vietnamese language;entailment classifier learning;machine translation;natural language understanding;recognizing textual entailment","","1","","28","","","Feb. 27 2012-March 1 2012","","IEEE","IEEE Conference Publications"
"Energy-Aware Autonomic Resource Allocation in Multitier Virtualized Environments","D. Ardagna; B. Panicucci; M. Trubian; L. Zhang","Politecnico di Milano, Milan","IEEE Transactions on Services Computing","20120301","2012","5","1","2","19","With the increase of energy consumption associated with IT infrastructures, energy management is becoming a priority in the design and operation of complex service-based systems. At the same time, service providers need to comply with Service Level Agreement (SLA) contracts which determine the revenues and penalties on the basis of the achieved performance level. This paper focuses on the resource allocation problem in multitier virtualized systems with the goal of maximizing the SLAs revenue while minimizing energy costs. The main novelty of our approach is to address-in a unifying framework-service centers resource management by exploiting as actuation mechanisms allocation of virtual machines (VMs) to servers, load balancing, capacity allocation, server power state tuning, and dynamic voltage/frequency scaling. Resource management is modeled as an NP-hard mixed integer nonlinear programming problem, and solved by a local search procedure. To validate its effectiveness, the proposed model is compared to top-performing state-of-the-art techniques. The evaluation is based on simulation and on real experiments performed in a prototype environment. Synthetic as well as realistic workloads and a number of different scenarios of interest are considered. Results show that we are able to yield significant revenue gains for the provider when compared to alternative methods (up to 45 percent). Moreover, solutions are robust to service time and workload variations.","1939-1374;19391374","","10.1109/TSC.2010.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560637","Performance attributes;energy cost reduction.;optimization;performance of systems;quality concepts;resource allocation","Energy consumption;Load management;Load modeling;Machine learning;Optimization;Resource management;Servers","integer programming;nonlinear programming;power aware computing;resource allocation;search problems;virtual machines","IT infrastructure;NP-hard;SLA contract;capacity allocation;complex service-based system;dynamic voltage scaling;energy consumption;energy cost;energy management;energy-aware autonomic resource allocation;frequency scaling;load balancing;local search procedure;mixed integer nonlinear programming problem;multitier virtualized environment;server power state tuning;service centers resource management;service level agreement;virtual machine","","74","","38","","20100902","Jan.-March 2012","","IEEE","IEEE Journals & Magazines"
"Towards distributed coverage of complex spatiotemporal profiles","J. Oyekan; H. Hu","School of Computer Science and Electronic Engineering, University of Essex, Wivenhoe Park, Colchester CO3 4SQ, United Kingdom","2011 IEEE International Conference on Robotics and Biomimetics","20120412","2011","","","2090","2095","Inspired by self-organization in natural organisms, an approach that would enable robotic agents form a visual representation of an invisible distributed hazardous substance is presented. Such a resource would enable humans observe and stay away from areas of high hazardous substance concentration. In this work, a proportional-integral control law and a machine learning scheme is used to obtain optimal parameter values that would enable optimal visual mapping whilst keeping computational resources low.","","DVD:978-1-4577-2137-3; Electronic:978-1-4577-2138-0; POD:978-1-4577-2136-6","10.1109/ROBIO.2011.6181600","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181600","Bio-inspired Algorithms;Environmental monitoring;Optimal Coverage;Self-Organization;Template learning","Equations;Genetic algorithms;Machine learning;Mathematical model;Microorganisms;Pi control;Robots","PI control;environmental factors;learning (artificial intelligence);robots","complex spatiotemporal profiles;distributed coverage;invisible distributed hazardous substance;machine learning scheme;natural organisms;optimal parameter;proportional-integral control law;robotic agents","","0","","13","","","7-11 Dec. 2011","","IEEE","IEEE Conference Publications"
"Genetic & Evolutionary Biometrics: Hybrid feature selection and weighting for a multi-modal biometric system","A. Alford; C. Steed; M. Jeffrey; D. Sweet; J. Shelton; L. Small; D. Leflore; G. Dozier; K. Bryant; T. Abegaz; J. C. Kelly; K. Ricanek","Center for Advanced Studies in Identity Sciences, North Carolina A & T State University, Greensboro, USA","2012 Proceedings of IEEE Southeastcon","20120510","2012","","","1","8","The Genetic & Evolutionary Computation (GEC) research community is seeing the emergence of a new and exciting subarea, referred to as Genetic & Evolutionary Biometrics (GEB), as GECs are increasingly being applied to a variety of biometric problems. In this paper, we present successful GEB techniques for multi-biometric fusion and multi-biometric feature selection and weighting. The first technique, known as GEF (Genetic & Evolutionary Fusion), seeks to optimize weights for score-level fusion. The second technique is known as GEFeWS<sub>ML</sub> (Genetic & Evolutionary Feature Weighting and Selection-Machine Learning). The goal of GEFeWS<sub>ML</sub> is to evolve feature masks (FMs) that achieve high recognition accuracy, use a low percentage of features, and generalize well to unseen subjects. GEFeWS<sub>ML</sub> differs from the other GEB techniques for feature selection and weighting in that it incorporates cross validation in an effort to evolve FMs that generalize well to unseen subjects.","1091-0050;10910050","Electronic:978-1-4673-1375-9; POD:978-1-4673-1374-2","10.1109/SECon.2012.6197061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197061","Biometrics;Cross Validation;Estimation of Distribution Algorithm;Feature Selection;Feature Weighting;Genetic & Evolutionary Computation;Local Binary Pattern","Accuracy;Biometrics;Feature extraction;Frequency modulation;Genetics;Machine learning;Training","biometrics (access control);feature extraction;genetic algorithms;learning (artificial intelligence);sensor fusion","GEB;GEC;GEF;GEFeWSML;feature mask;feature weighting;genetic & evolutionary biometric;genetic & evolutionary computation;genetic & evolutionary fusion;hybrid feature selection;multibiometric feature selection;multibiometric fusion;multimodal biometric system;optimization;score level fusion","","3","","44","","","15-18 March 2012","","IEEE","IEEE Conference Publications"
"Local Sensitive Frontier Analysis based facial expression recognition","C. Wang; Z. Shen","School of Electrical & Electronics Engineering Nanyang Technological University, Singapore","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","4","Facial expression recognition plays an important role in interactive entertainment. In this paper, LSFA (Local Sensitive Frontier Analysis) a novel feature extraction method is introduced for facial expression recognition. LSFA is designed as manifold based feature extraction method to obtain useful features from the facial expression pictures, since the facial expression scatter in high dimensional space as a point will embed in low dimensional manifold. From comparing several feature extraction methods in the experiment, it can be found that this algorithm gets better expression recognition result.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6173611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173611","Facial Expression;LSFA;Manifold Learning","Algorithm design and analysis;Educational institutions;Face;Face recognition;Feature extraction;Machine learning;Manifolds","face recognition;feature extraction","LSFA;facial expression pictures;facial expression recognition;feature extraction method;interactive entertainment;local-sensitive frontier analysis;low-dimensional manifold","","0","","14","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"A framework for merging and ranking of answers in DeepQA","D. C. Gondek; A. Lally; A. Kalyanpur; J. W. Murdock; P. A. Duboue; L. Zhang; Y. Pan; Z. M. Qiu; C. Welty","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20120405","2012","56","3.4","14:1","14:12","The final stage in the IBM DeepQA pipeline involves ranking all candidate answers according to their evidence scores and judging the likelihood that each candidate answer is correct. In DeepQA, this is done using a machine learning framework that is phase-based, providing capabilities for manipulating the data and applying machine learning in successive applications. We show how this design can be used to implement solutions to particular challenges that arise in applying machine learning for evidence-based hypothesis evaluation. Our approach facilitates an agile development environment for DeepQA; evidence scoring strategies can be easily introduced, revised, and reconfigured without the need for error-prone manual effort to determine how to combine the various evidence scores. We describe the framework, explain the challenges, and evaluate the gain over a baseline machine learning approach.","0018-8646;00188646","","10.1147/JRD.2012.2188760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6177810","","Information analysis;Logistics;Machine learning;Training data","","","","5","4","19","","","May-June 2012","","IBM","IBM Journals & Magazines"
"MUTE: Majority under-sampling technique","C. Bunkhumpornpat; K. Sinapiromsaran; C. Lursinsap","Department of Mathematics and Computer Science, Faculty of Science, Chulalongkorn University, Bangkok 10330, Thailand","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","4","An application which operates on an imbalanced dataset loses its classification performance on a minority class, which is rare and important. There are a number of over-sampling techniques, which insert minority instances into a dataset, to adjust the class distribution. Unfortunately, these instances highly affect the computation of generating a classifier. In this paper, a new simple and effective under-sampling called MUTE is proposed. Its strategy is to get rid of noise majority instances which over-lap with minority instances. The removal majority instances are considered based on their safe levels relying on the Safe-Level-SMOTE concept. MUTE not only reduces the classifier construction time because of a downsizing dataset but also improves the prediction rate on a minority class. The experimental results show that MUTE improves F-measure by comparing to SMOTE techniques.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6173603","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173603","Class Imbalance;Classification;Safe-Level-SMOTE;Under-sampling","Classification algorithms;Computer science;Conferences;Data mining;Machine learning;Noise","pattern classification;sampling methods","MUTE effective under-sampling;imbalanced dataset;majority under-sampling technique;safe-level-SMOTE technique","","2","","22","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Minimum entropy linear embedding based on Gaussian mixture model","Libo Hou; Ran He","Liaoning Police Academy, Dalian, China 116036","The First Asian Conference on Pattern Recognition","20120312","2011","","","362","366","In this paper, we introduce an information theory motivated algorithm for constructing a low dimensional representation for data sampled from a higher dimensional space. The proposed minimum entropy linear embedding algorithm tries to minimize the information uncertainty (measured by entropy) as much as possible. The entropy is estimated by Gaussian mixture model probability density function and an upper bound of entropy is derived. As a result, the numerical integration involved in the objective function is reduced to a computationally efficient eigenfunction problem. The superiority of proposed method is that it can be used to find the intrinsic character of high dimensional data and has potential ability to reduce redundancy and to improve classification accuracy. Numerical results on toy data, UCI machine learning data set and face recognition illustrate this superiority.","0730-6512;07306512","Electronic:978-1-4577-0121-4; POD:978-1-4577-0122-1","10.1109/ACPR.2011.6166704","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166704","","Eigenvalues and eigenfunctions;Entropy;Gaussian distribution;Machine learning;Principal component analysis;Uncertainty;Upper bound","Gaussian processes;data structures;eigenvalues and eigenfunctions;integration;minimum entropy methods;pattern classification;sampling methods","Gaussian mixture model;UCI machine learning data set;classification accuracy improvement;data intrinsic character;data redundancy reduction;data sampling;eigenfunction problem;entropy upper bound;face recognition;information theory;information uncertainty minimization;low dimensional data representation;minimum entropy linear embedding algorithm;numerical integration;objective function;probability density function","","0","","23","","","28-28 Nov. 2011","","IEEE","IEEE Conference Publications"
"Mining closed sequences with constraint based on BIDE algorithm","S. Shyamala; T. Sathya","Dept. of Comput. Sci., Sona Coll. of Technol., Salem, India","2012 International Conference on Computer Communication and Informatics","20120301","2012","","","1","5","Mining sequential pattern is one of the common data mining task for many real-life applications. Previous existing algorithm such as CAMLS(Constraint-based Apriori Algorithm for Mining Long Sequences) mines the complete set of frequent sequences(Long) satisfying a min-sup threshold in a sequence. However, mining long sequences will generate an explosive number of frequent sequences, which is prohibitively costly in both run time and space storage. In this paper, we propose to improve CAMLS algorithm to produce only for closed sequences. Instead of mining full set of sequences, we plan to mine only short(closed) sequences. i.e., those containing, no super sequences with same support. Our motivation is to mine closed sequences from long sequences using BIDE algorithm with improved CAMLS algorithm and make the pruning strategy even more efficient. BIDE is an efficient algorithm for mining closed sequences which works under without candidate-maintenance and test paradigm.","","Electronic:978-1-4577-1583-9; POD:978-1-4577-1580-8","10.1109/ICCCI.2012.6158826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158826","Constraint-based mining;closed sequences;frequent patterns;long sequences;sequence database","Algorithm design and analysis;Computers;Data mining;Databases;Explosives;Informatics;Machine learning algorithms","data mining","BIDE algorithm;CAMLS algorithm;bidirectional extension;closed sequence mining;constraint-based apriori algorithm for mining long sequences;data mining;pruning strategy;sequential pattern mining","","0","","12","","","10-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"An efficient coarse-to-fine scheme for text detection in videos","Liuan Wang; L. L. Huang; Yang Wu","School of Automation Science and Electrical Engineering, Beihang University, China","The First Asian Conference on Pattern Recognition","20120312","2011","","","475","479","To achieve fast and accurate text detection from videos, we propose an efficient coarse-to-fine scheme comprising three stages: key frame extraction, candidate text line detection and fine text detection. Key frames, which are assumed to carry texts, are extracted based on multi-threshold difference of color histogram (MDCH). From the key frames, candidate text lines are detected by morphological operations and connected component analysis. Sliding window classification is performed on the candidate text lines so as to detect refined text lines. We use two types of features: histogram of gradients (HOG) and local assembled binary (LAB), and two classifiers: Real Adaboost and polynomial neural network (PNN), for improving the classification accuracy. The effectiveness of the proposed method has been demonstrated by the experiment results on a large video dataset. Also, the benefits of key frame extraction and combining multiple features and classifiers have been justified.","0730-6512;07306512","Electronic:978-1-4577-0121-4; POD:978-1-4577-0122-1","10.1109/ACPR.2011.6166605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166605","coarse-to-fine scheme;key frame extraction;multi-classifier fusion;video text detection","Accuracy;Feature extraction;Histograms;Image color analysis;Image edge detection;Machine learning;Videos","image enhancement;neural nets;pattern classification;text detection;video signal processing","MDCH;PNN;candidate text line detection;coarse-to-fine scheme;connected component analysis;fine text detection;histogram of gradients;key frame extraction;local assembled binary;multithreshold difference of color histogram;polynomial neural network;real Adaboost;sliding window classification;text detection","","0","","12","","","28-28 Nov. 2011","","IEEE","IEEE Conference Publications"
"Robot self-preservation and adaptation to user preferences in game play, a preliminary study","Á. Castro-González; F. Amirabdollahian; D. Polani; M. Malfaz; M. A. Salichs","RoboticsLab at the Carlos III University of Madrid, 28911, Legan&#x00E9;s, Madrid, Spain","2011 IEEE International Conference on Robotics and Biomimetics","20120412","2011","","","2491","2498","It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.","","DVD:978-1-4577-2137-3; Electronic:978-1-4577-2138-0; POD:978-1-4577-2136-6","10.1109/ROBIO.2011.6181679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181679","","Batteries;Games;Humans;Learning;Machine learning;Machine learning algorithms;Robots","human-robot interaction;learning (artificial intelligence)","Q-learning algorithm;commercial robots;game play;human-robot interaction;personal robots;reinforcement learning;robot behaviour personalisation;robot self-preservation;user preferences adaptation","","2","","28","","","7-11 Dec. 2011","","IEEE","IEEE Conference Publications"
"Task-Driven Dictionary Learning","J. Mairal; F. Bach; J. Ponce","University of California Berkeley, Berkeley","IEEE Transactions on Pattern Analysis and Machine Intelligence","20120220","2012","34","4","791","804","Modeling data with linear combinations of a few elements from a learned dictionary has been the focus of much recent research in machine learning, neuroscience, and signal processing. For signals such as natural images that admit such sparse representations, it is now well established that these models are well suited to restoration tasks. In this context, learning the dictionary amounts to solving a large-scale matrix factorization problem, which can be done efficiently with classical optimization tools. The same approach has also been used for learning features from data for other purposes, e.g., image classification, but tuning the dictionary in a supervised way for these tasks has proven to be more difficult. In this paper, we present a general formulation for supervised dictionary learning adapted to a wide variety of tasks, and present an efficient algorithm for solving the corresponding optimization problem. Experiments on handwritten digit classification, digital art identification, nonlinear inverse image problems, and compressed sensing demonstrate that our approach is effective in large-scale settings, and is well suited to supervised and semi-supervised classification, as well as regression tasks for data that admit sparse representations.","0162-8828;01628828","","10.1109/TPAMI.2011.156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975166","Basis pursuit;Lasso;compressed sensing.;dictionary learning;matrix factorization;semi-supervised learning","Cost function;Dictionaries;Machine learning;Sensors;Sparse matrices;Vectors","compressed sensing;data models;handwritten character recognition;image classification;image representation;image restoration;learning (artificial intelligence);matrix decomposition;regression analysis","classical optimization tools;compressed sensing;data modeling;digital art identification;handwritten digit classification;image classification;large-scale matrix factorization problem;learned dictionary;linear combinations;machine learning;natural images;neuroscience;nonlinear inverse image problems;regression tasks;restoration tasks;semisupervised classification;signal processing;sparse representations;supervised dictionary learning;task-driven dictionary learning","Algorithms;Databases, Factual;Humans;Pattern Recognition, Automated","262","5","58","","20110804","April 2012","","IEEE","IEEE Journals & Magazines"
"Stochastic Competitive Learning in Complex Networks","T. C. Silva; L. Zhao","Department of Computer Sciences, Institute of Mathematics and Computer Science, University of S&#x00E3;o Paulo, S&#x00E3;o Carlos, Brazil","IEEE Transactions on Neural Networks and Learning Systems","20120227","2012","23","3","385","398","Competitive learning is an important machine learning approach which is widely employed in artificial neural networks. In this paper, we present a rigorous definition of a new type of competitive learning scheme realized on large-scale networks. The model consists of several particles walking within the network and competing with each other to occupy as many nodes as possible, while attempting to reject intruder particles. The particle's walking rule is composed of a stochastic combination of random and preferential movements. The model has been applied to solve community detection and data clustering problems. Computer simulations reveal that the proposed technique presents high precision of community and cluster detections, as well as low computational complexity. Moreover, we have developed an efficient method for estimating the most likely number of clusters by using an evaluator index that monitors the information generated by the competition process itself. We hope this paper will provide an alternative way to the study of competitive learning..","2162-237X;2162237X","","10.1109/TNNLS.2011.2181866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123212","Community detection;complex networks;data clustering;preferential walk;random walk;stochastic competitive learning","Communities;Complex networks;Legged locomotion;Machine learning;Mathematical model;Stochastic processes;Vectors","computational complexity;neural nets;pattern clustering;unsupervised learning","artificial neural networks;community detection;complex networks;computational complexity;data clustering problems;evaluator index;large-scale networks;machine learning approach;particle walking rule;preferential movements;random movements;stochastic competitive learning","0","20","","64","","20120105","March 2012","","IEEE","IEEE Journals & Magazines"
"Feature ranking for pattern recognition: A comparison of filter methods","E. Test; V. Kecman; R. Strack; Qi Li; R. Salman","Virginia Commonwealth University, 401 West Main Street, Richmond, 23284, USA","2012 Proceedings of IEEE Southeastcon","20120510","2012","","","1","5","This paper presents an approach for comparing various feature ranking (FR) methods. First, six classification benchmarks are created using Exhaustive Search (ES) to select the best feature subsets. The subset selections have been done within double (nested) cross-validation procedures guaranteeing realistic accuracy predictions to unseen examples. Next, seven filter FR approaches are compared and ranked in respect to the top five best feature subsets for each data set. This paper also introduces a method for quantifying and comparing FR results. The results hint that using Gini index or scatter ratios leads to rankings closest to ES on average.","1091-0050;10910050","Electronic:978-1-4673-1375-9; POD:978-1-4673-1374-2","10.1109/SECon.2012.6196888","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6196888","Entropy;Exhaustive Search;Feature Ranking;Gini index;Scatter ratio","Accuracy;Benchmark testing;Glass;Indexes;Iris;Machine learning;Pattern recognition","filtering theory;pattern recognition;search problems","ES;FR methods;Gini index;double cross-validation procedures;exhaustive search;feature ranking methods;filter methods;pattern recognition","","0","","9","","","15-18 March 2012","","IEEE","IEEE Conference Publications"
"Deep Belief Network based state classification for structural health diagnosis","P. Tamilselvan; Y. Wang; P. Wang","Wichita State University, 1845 Fairmount St, Wichita, KS 67260","2012 IEEE Aerospace Conference","20120419","2012","","","1","11","Effective health diagnosis provides multifarious benefits such as improved safety, improved reliability and reduced costs for the operation and maintenance of complex engineered systems. This paper presents a novel multi-sensor health diagnosis method using Deep Belief Networks (DBN). The DBN has recently become a popular approach in machine learning for its promised advantages such as fast inference and the ability to encode richer and higher order network structures. The DBN employs a hierarchical structure with multiple stacked Restricted Boltzmann Machines and works through a layer by layer successive learning process. The proposed multi-sensor health diagnosis methodology using the DBN based state classification can be structured in three consecutive stages: first, defining health states and preprocessing the sensory data for DBN training and testing; second, developing DBN based classification models for the diagnosis of predefined health states; third, validating DBN classification models with testing sensory dataset. The performance of health diagnosis using DBN based health state classification is compared with support vector machine technique and demonstrated with aircraft wing structure health diagnostics and aircraft engine health diagnosis using 2008 PHM challenge data.","1095-323X;1095323X","Electronic:978-1-4577-0557-1; POD:978-1-4577-0556-4","10.1109/AERO.2012.6187366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187366","Fault diagnosis;artificial intelligence in diagnostic classification;deep belief networks","Condition monitoring;Data models;Learning systems;Machine learning;Neurons;Support vector machines;Training","Boltzmann machines;aerospace components;aerospace computing;aircraft;belief networks;condition monitoring;cost reduction;learning (artificial intelligence);pattern classification;sensor fusion","aircraft engine health diagnosis;aircraft wing structure health diagnostics;cost reduction;deep belief network classification model;deep belief network testing;deep belief network training;health state classification;hierarchical structure;layer by layer successive learning process;machine learning;multisensor health diagnosis method;sensory data preprocessing;stacked restricted Boltzmann machine;structural health diagnosis","","2","","28","","","3-10 March 2012","","IEEE","IEEE Conference Publications"
"Early prediction of tilt test outcome, with support vector machine non linear classifier, using ECG, pressure and impedance signals","F. J. Gimeno-Blanes; J. L. Rojo-Álvarez; A. García-Alberola; J. R. Gimeno-Blanes; A. Rodríguez-Martínez; A. Mocci; J. A. Flores-Yepes","Universidad Miguel Hern&#x00E1;ndez, Elche, Spain","2011 Computing in Cardiology","20120309","2011","","","101","104","The tilt test is a valuable clinical tool for the diagnosis of Vasovagal Syncope. No practical system has been implemented to predict the tilt test outcome at the beginning in the procedure. Our objective was to evaluate and benchmark, over a sufficient database, the predictive performance of the proposed parameters in the literature. We analyzed a database of 727 consecutive cases of tilt test. Previously proposed features were measured from heart rate and systolic/diastolic pressure, in several representative signal segments. A support vector machine (SVM) was used to predict the test outcome with the available features. Also the inclusion of additional physiological signals (impedance) was intended to improve the performance. The predictive performance of the nonline-arly combined previously proposed features was limited (p<;0.03 and area under ROC curve 0.57±0.12), especially in the beginning of the test, which is the most clinically relevant period. The improvement with additional available physiological information and SVM was limited (area under ROC curve 0.59±0.22). We conclude that the existing methods for tilt test outcome prediction knowledge should be considered with caution.","0276-6574;02766574","Electronic:978-1-4577-0611-0; POD:978-1-4577-0612-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164512","","Benchmark testing;Databases;Heart rate;Machine learning;Optimized production technology;Support vector machines","electrocardiography;medical signal processing;pattern classification;physiology;signal classification;support vector machines","ECG;ROC curve;SVM;diastolic pressure signal;heart rate;impedance signal;linear classifier;physiological information;physiological signals;predictive performance;representative signal segment;support vector machine;systolic pressure signal;tilt test;vasovagal syncope diagnosis","","0","","26","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Research on Web Spam Detection Based on Support Vector Machine","Z. Jia; W. Li; W. Gao; Y. Xia","Dept. of Inf. Sci. & Technol., Yunnan Univ., Lijiang, China","2012 International Conference on Communication Systems and Network Technologies","20120517","2012","","","517","520","With the fast development of Internet, web pages created by web spam which aimed at cheating the search engine and increasing rankings in the search results are prevailing. Web spam is a big problem for today's search engine; therefore it is necessary for search engines to be able to detect web spam during crawling. The web spam detection problem is viewed as a classification problem, that means classification models are created by machine learning classification algorithms, which given a web page, it will classify it in one of two categories: Normal and Spam. For support vector machine classification model, soft margin classifier based on linear support vector machine was developed by learning the sample set, and penalty functions were defined according to the links between web pages that seems to have similar characteristics. Not only the content features but also the link structures between web pages were taken advantage of to build classifier.","","Electronic:978-0-7695-4692-6; POD:978-1-4673-1538-8","10.1109/CSNT.2012.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200710","SVM;anti-spam;search engine;web spam;web spam detection","Educational institutions;Feature extraction;Machine learning;Search engines;Support vector machines;Unsolicited electronic mail;Web pages","Web services;information retrieval;pattern classification;search engines;support vector machines;unsolicited e-mail","Internet;Web page;Web spam detection;classification problem;crawling;linear support vector machine;machine learning classification algorithm;penalty function;search engine;soft margin classifier","","2","","10","","","11-13 May 2012","","IEEE","IEEE Conference Publications"
"CinC challenge — Assessing the usability of ECG by ensemble decision trees","S. Zaunseder; R. Huhle; H. Malberg","Dresden University of Technology, Institute of Biomedical Engineering, Dresden, Germany","2011 Computing in Cardiology","20120309","2011","","","277","280","For various biomedical applications, an automated quality assessment is an essential but also complex task. Ensembles of decision trees (EDTs) have proven to be a suitable choice for such classification tasks. Within this contribution we invoke EDTs to assess the usability of ECGs. Our classification relies on the usage of simple spectral features which were derived directly from individual ECG channels. EDTs are generated by bootstrap aggregating while invoking the concept of random forrests. Though their simplicity, the trained ensemble classifiers turned out to be a very robust choice yielding an accuracy of 90.4 %. Therewith, the proposed method offers a good tradeoff between accuracy and computational simplicity. Further improving the accuracy, however, turns out to be hardly feasible considering the chosen feature space.","0276-6574;02766574","Electronic:978-1-4577-0611-0; POD:978-1-4577-0612-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164556","","Accuracy;Decision trees;Electrocardiography;Feature extraction;Hafnium;Machine learning;Silicon","decision trees;electrocardiography;medical signal processing","CinC challenge;accuracy;automated quality assessment;biomedical applications;bootstrap aggregation;computational simplicity;ensemble decision trees;feature space;individual ECG channels;random forrests;simple spectral features;trained ensemble classifiers","","1","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Relevance feature selection with data cleaning for intrusion detection system","S. Suthaharan; T. Panchagnula","Department of Computer Science, University of North Carolina at Greensboro, USA","2012 Proceedings of IEEE Southeastcon","20120510","2012","","","1","6","Labeled datasets play a major role in the process of validating and evaluating machine learning techniques in intrusion detection systems. In order to obtain good accuracy in the evaluation, very large datasets should be considered. Intrusion traffic and normal traffic are in general dependent on a large number of network characteristics called features. However not all of these features contribute to the traffic characteristics. Therefore, eliminating the non-contributing features from the datasets, to facilitate speed and accuracy to the evaluation of machine learning techniques, becomes an important requirement. In this paper we suggest an approach which analyzes the intrusion datasets, evaluates the features for its relevance to a specific attack, determines the level of contribution of feature, and eliminates it from the dataset automatically. We adopt the Rough Set Theory (RST) based approach and select relevance features using multidimensional scatter-plot automatically. A pair-wise feature selection process is adopted to simplify. In our previous research we used KDD'99 dataset and validated the RST based approach. There are lots of redundant data entries in KDD'99 and thus the machine learning techniques are biased towards most occurring events. This property leads the algorithms to ignore less frequent events which can be more harmful than most occurring events. False positives are another important drawback in KDD'99 dataset. In this paper, we adopt NSL-KDD dataset (an improved version of KDD'99 dataset) and validate the automated RST based approach. The approach presented in this paper leads to a selection of most relevance features and we expect that the intrusion detection research using KDD'99-based datasets will benefit from the good understanding of network features and their influences to attacks.","1091-0050;10910050","Electronic:978-1-4673-1375-9; POD:978-1-4673-1374-2","10.1109/SECon.2012.6196965","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6196965","NSL-KDD dataset;Rough Set Theory;intrusion detection;labeled datasets;relevance feature selection","Approximation methods;Cleaning;Feature extraction;Gaussian distribution;Internet;Intrusion detection;Machine learning","feature extraction;learning (artificial intelligence);rough set theory;security of data","KDD'99-based datasets;NSL-KDD dataset;automated RST based approach;data cleaning;intrusion detection system;intrusion traffic;machine learning technique;multidimensional scatter-plot;network characteristics;network features;noncontributing feature;pairwise feature selection process;redundant data entries;relevance feature selection;rough set theory","","3","","17","","","15-18 March 2012","","IEEE","IEEE Conference Publications"
"A novel support vector machine kernel based on Slepian semi-wavelets","X. Shen","Department of Mathematics, Athens, OH 45701, USA","Proceedings of the 2011 IEEE National Aerospace and Electronics Conference (NAECON)","20120416","2011","","","65","68","In this paper, we construct a positive definite kernel associated with Slepian semi-wavelets. The kernel possesses multiscale structure and exhibits a strong localization property. It is convolution type associated with asymptotic sparse Gram matrix and allows the use of thresholding methods. We then focus on developing practical numerical algorithm to compute the kernel. Applications of the kernel in the context of kernel adaptive filtering are discussed.","0547-3578;05473578","Electronic:978-1-4577-1041-4; POD:978-1-4577-1040-7","10.1109/NAECON.2011.6183079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183079","","Hilbert space;Kernel;Machine learning;Presses;Uncertainty;Wave functions;Wavelet transforms","Hilbert spaces;adaptive filters;convolution;sparse matrices;support vector machines;wavelet transforms","Slepian semiwavelets-based support vector machine kernel;asymptotic sparse Gram matrix;kernel adaptive filtering;localization property;multiscale structure;numerical algorithm;positive definite kernel;thresholding methods","","0","","22","","","20-22 July 2011","","IEEE","IEEE Conference Publications"
"A review of some Bayesian Belief Network structure learning algorithms","S. Mittal; S. L. Maskara","Department of CS&IT, JIIT, Noida, UP, India","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","5","Bayesian Belief Networks (BBNs) are useful in modeling complex situations. Such graphical models help in giving better insight and understanding of the situation. Many algorithms for machine learning of BBN structures have been developed. In this paper six different algorithms have been reviewed by constructing BBN structures for two different datasets using various algorithms. Some inferences have been drawn from the results obtained from the study which may help in decision making.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6173579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173579","Bayesian Belief Network;Hepatitis Domain Diseases;Structure Learning;Urinary System Diseases","Bayesian methods;Diseases;Inference algorithms;Learning systems;Machine learning algorithms;Size measurement","belief networks;inference mechanisms;learning (artificial intelligence)","BBN structures;Bayesian belief network structure learning algorithms;decision making;graphical models;machine learning","","2","","14","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Data Mining method based on Lattice","X. Li-Ping","Business School, University of Shanghai for Science and Technology, Shanghai China","2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet)","20120517","2012","","","2487","2489","With the development of internet and storage technology, we have got a lot of data. In order to find the information from these data, Data Mining has become an increasingly important topic in research as well as in industrial application. Up to now, there are a lot of Data Mining methods and specific tools. This article mainly talks about a new Data Mining Method called Data Mining based on Lattice. It has been applied in many research areas, such as: Data Bases, Data Analysis and Machine Learning Technology. The experiments finished by foreign researcher showed it may be a useful method for information retrieval and machine learning problem domains. Data Mining based on Lattice is indeed a better method of organization, which is useful for each domain. The use and application of Data Mining based on Lattice is an area of active and promising research in various fields. Therefore, it is important for us to study the Data Mining Method based on Lattice.","","DVD:978-1-4577-1413-9; Electronic:978-1-4577-1415-3; POD:978-1-4577-1414-6","10.1109/CECNet.2012.6201853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6201853","Data Mining;Lattice;compressed lattice;concept lattice;data reduction","Algorithm design and analysis;Data mining;Data structures;Databases;Lattices;Machine learning;Upper bound","data mining","Internet;data mining method;information retrieval;lattice;machine learning problem domains;storage technology","","0","","11","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
"A simple process model generation using a new association rule mining algorithm and clustering approach","M. S. Saravanan; R. J. R. Sree","Dept. of I.T in Vel Tech, Bharathiar Univ., Coimbatore, India","2011 Third International Conference on Advanced Computing","20120409","2011","","","265","269","In the recent research area, the association rule mining is one of the popular technique in the domain of data mining. The association rule mining is first implemented in dyeing unit in my previous research papers. But already this association rule mining technique is used in the area of finance, healthcare, automobile and sales and distribution, etc. In this article, the dyeing process, generate the simple process model for the dyeing unit. The simplified process model is not in the form of diagram, instead rules. These rules are developing using association rule mining algorithms. The process mining algorithms, Heuristic Miner (HM) and Disjunctive Workflow Schema (DWS) are used to generate the association rule mining rules. Hence, the proposed LinkRuleMiner (LRM) association rule mining algorithm is implemented in the dyeing unit using HM or DWS algorithm. The dyeing process is dynamic and unstructured in nature. The dyeing process is recorded and stored in the form of event logs. These event logs are converted in to the log file. These log files are given as input to the LRM algorithm. The LRM algorithm produces the simple association rules. These rules can be easily understood by the dyeing expert called dyer to process the colouring process of the dyeing unit. These generated association rules can also be grouped for the same or different shades using the clustering approach. Therefore, this article simplify the dyeing process using LRM algorithm to give better knowledge to the dyer and to reduce the dyeing processing problems of the dyeing unit.","2377-6927;23776927","Electronic:978-1-4673-0671-3; POD:978-1-4673-0670-6","10.1109/ICoAC.2011.6165186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165186","LinkRuleMiner;association rules;colouring;dyer;event logs;shade","Association rules;Clustering algorithms;Data structures;Databases;Heuristic algorithms;Machine learning algorithms","data mining;dyeing;pattern clustering;production engineering computing","LRM algorithm;LinkRuleMiner algorithm;association rule mining algorithm;automobile;clustering approach;colouring process;data mining;diagram form;disjunctive workflow schema;dyeing expert;dyeing unit;dyer;finance;healthcare;heuristic miner;rule form;sales and distribution;simple process model generation","","2","","12","","","14-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Probability-Confidence-Kernel-Based Localized Multiple Kernel Learning With <formula formulatype=""inline""><tex Notation=""TeX"">$l_{p}$</tex></formula> Norm","Y. Han; G. Liu","School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20120511","2012","42","3","827","837","Localized multiple kernel learning (LMKL) is an attractive strategy for combining multiple heterogeneous features in terms of their discriminative power for each individual sample. However, models excessively fitting to a specific sample would obstacle the extension to unseen data, while a more general form is often insufficient for diverse locality characterization. Hence, both learning sample-specific local models for each training datum and extending the learned models to unseen test data should be equally addressed in designing LMKL algorithm. In this paper, for an integrative solution, we propose a probability confidence kernel (PCK), which measures per-sample similarity with respect to probabilistic-prediction-based class attribute: The class attribute similarity complements the spatial-similarity-based base kernels for more reasonable locality characterization, and the predefined form of involved class probability density function facilitates the extension to the whole input space and ensures its statistical meaning. Incorporating PCK into support-vectormachine-based LMKL framework, we propose a new PCK-LMKL with arbitrary -norm constraint implied in the definition of PCKs, where both the parameters in PCK and the final classifier can be efficiently optimized in a joint manner. Evaluations of PCK-LMKL on both benchmark machine learning data sets (ten University of California Irvine (UCI) data sets) and challenging computer vision data sets (15-scene data set and Caltech-101 data set) have shown to achieve state-of-the-art performances.","1083-4419;10834419","","10.1109/TSMCB.2011.2179291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129537","Local learning;multiple kernel learning;support vector machines","Data models;Distributed databases;Kernel;Machine learning;Optimization;Phase change materials;Support vector machines","learning (artificial intelligence);probability;support vector machines","class attribute similarity;class probability density function;computer vision data set;discriminative power;diverse locality characterization;input space;integrative solution;localized multiple kernel learning;machine learning data set;probabilistic prediction based class attribute;probability confidence kernel;sample-specific local model;spatial similarity based base kernels;support vector machine;training datum","Algorithms;Artificial Intelligence;Computer Simulation;Confidence Intervals;Decision Support Techniques;Models, Statistical;Pattern Recognition, Automated","7","","44","","20120112","June 2012","","IEEE","IEEE Journals & Magazines"
"Effect of Feature Selection, SMOTE and under Sampling on Class Imbalance Classification","N. Qazi; K. Raza","Fac. of Eng. Sci. & Technol., IQRA Univ., Pakistan","2012 UKSim 14th International Conference on Computer Modelling and Simulation","20120528","2012","","","145","150","Accurate identification of network intrusions is one of the biggest challenges of Network Intrusion Detection (NID) systems. In recent years Machine learning classification techniques have been used to precisely identify network intrusion. However, the multi class distribution in network intrusion detection system has found to be highly skewed, leading to classification accuracy problem due to class imbalance data set. The work presented in this paper not only explores the role of the attribute selection in improving classification accuracy but also investigates the problem of class imbalance using the Synthetic Minority Over-sampling (SMOTE) and under sampling of major classes. The classification performance is then evaluated over several types of classifiers. The outcome of this work is that for the class imbalance data set the under-sampling technique is more effective than SMOTE in detecting minor classes. It has also found during this research work that the decision tree algorithms (JRIP) and Naïve Bayes are more accurate classifiers as compared to the Radial basis neural network and support vector machine. However no single algorithm can be used for the classification of multiclass and it is proposed in this research work that combination of classifier consisting of Naïve Bayes and JRIP could be used for the classification of minor classes in an imbalance class data set of intrusion detection system.","","Electronic:978-0-7695-4682-7; POD:978-1-4673-1366-7","10.1109/UKSim.2012.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6205441","Class imbalance;Feature Selection;Network intrusion;Support Vector Machines","Accuracy;Classification algorithms;Decision trees;Intrusion detection;Machine learning;Machine learning algorithms;Support vector machines","Bayes methods;computer network security;decision trees;feature extraction;learning (artificial intelligence);pattern classification;radial basis function networks;support vector machines","JRIP;NID systems;Naive Bayes method;SMOTE;attribute selection;class imbalance classification;classification accuracy problem;decision tree algorithms;feature selection;machine learning classification techniques;multiclass classification;multiclass distribution;network intrusion detection systems;network intrusions identification;radial basis neural network;support vector machine;synthetic minority over-sampling;under-sampling technique","","0","","22","","","28-30 March 2012","","IEEE","IEEE Conference Publications"
"Fact-based question decomposition in DeepQA","A. Kalyanpur; S. Patwardhan; B. K. Boguraev; A. Lally; J. Chu-Carroll","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20120403","2012","56","3.4","13:1","13:11","Factoid questions often contain more than one fact or assertion about their answers. Question-answering (QA) systems, however, typically do not use such fine-grained distinctions because of the need for deep understanding of the question in order to identify and separate the facts. We argue that decomposing complex factoid questions is beneficial to QA systems, because the more facts that support an answer candidate, the more likely it is to be the correct answer. We broadly categorize decomposable questions into two types: parallel and nested. Parallel decomposable questions contain subquestions that can be evaluated independent of each other. Nested questions require decompositions to be processed in sequence, with the answer to an “inner” subquestion plugged into an “outer” subquestion. In this paper, we present a novel question decomposition framework capable of handling both decomposition types, built on top of the base IBM Watson™ QA system for Jeopardy!™. The framework contains a suite of decomposition rules that use predominantly lexico-syntactic features to identify facts within complex questions. It also contains a question-rewriting component and a candidate re-ranker, which uses machine learning and heuristic selection strategies to generate a final ranked answer list, taking into account answer confidences from the base QA system. We apply our decomposition framework to the particularly challenging domain of Final Jeopardy! questions, which are found to be difficult even for qualified Jeopardy! players, and we show a statistically significant improvement in the performance of our baseline QA system.","0018-8646;00188646","","10.1147/JRD.2012.2188934","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6177726","","Companies;Complexity theory;Context awareness;History;Machine learning;Syntactics","","","","1","2","14","","","May-June 2012","","IBM","IBM Journals & Magazines"
"Applying feature bagging for more accurate and robust automated speaking assessment","L. Chen","Educational Testing Service, Princeton NJ USA","2011 IEEE Workshop on Automatic Speech Recognition & Understanding","20120305","2011","","","473","477","The scoring model used in automated speaking assessment systems is critical for achieving accurate and robust scoring of speaking skills automatically. In the automated speaking assessment research field, using a single classifier model is still a dominant approach. However, ensemble learning, which relies on a committee of classifiers to predict jointly (to overcome each individual classifier's weakness) has been actively advocated by the machine learning researchers and widely used in many machine learning tasks. In this paper, we investigated applying a special ensemble learning method, feature-bagging, on the task of automatically scoring non-native spontaneous speech. Our experiments show that this method is superior to the method of using a single classifier in terms of scoring accuracy and the robustness to cope with possible feature variations.","","Electronic:978-1-4673-0367-5; POD:978-1-4673-0365-1; USB:978-1-4673-0366-8","10.1109/ASRU.2011.6163977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163977","ensemble learning;feature bagging;speech assessment;speech recognition","Bagging;Feature extraction;Humans;Machine learning;Speech;Speech recognition;Testing","learning (artificial intelligence);speech processing","automated speaking assessment systems;ensemble learning;feature bagging;machine learning;nonnative spontaneous speech;robust automated speaking assessment;scoring model;single classifier model","","0","","18","","","11-15 Dec. 2011","","IEEE","IEEE Conference Publications"
"Classification of microblogging users","M. Özgür Cingiz; B. Diri","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Y&#x0131;ld&#x0131;z Teknik &#x00DC;niversitesi, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","Recent advancements in Web 2.0, people can't be regarded as simple content reader, they can also contribute content as writers. This work consists of microblogging and text categorization. Text categorization steps were used in microblogs to find out users whose contributions are more valuable for its related category. 2015 RSS news feeds were taken for training and users' tweets were used as test data. This study also differs from other related projects in selection of features. Selected test feature must be also in training data. If it doesn't, test feature can't be taken as feature in test data. In conclusion, contents of news bots in Twitter have more categorical content than ordinary microbloggers.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204519","","Conferences;Educational institutions;Java;Machine learning;Support vector machines;Text categorization;Twitter","Internet;feature extraction;pattern classification;social networking (online);text analysis;training","2015 RSS news feeds;Twitter;Web 2.0;categorical content;content reader;feature selection;microblogging users classification;news bots;text categorization;user tweets","","0","","14","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"A Market-Based Bug Allocation Mechanism Using Predictive Bug Lifetimes","H. Hosseini; R. Nguyen; M. W. Godfrey","Univ. of Waterloo, Waterloo, ON, Canada","2012 16th European Conference on Software Maintenance and Reengineering","20120405","2012","","","149","158","Bug assignment in large software projects is typically a time-consuming and tedious task, effective assignment requires that bug triagers hold significant contextual information about both the reported bugs and the pool of available developers. In this paper, we propose an auction-based multiagent mechanism for assigning bugs to developers that is intended to minimize backlogs and overall bug lifetime. In this approach, developers and triagers are both modeled as intelligent software agents working on behalf of individuals in a multiagent environment. Upon receiving a bug report, triager agents auction off the bug and collect the requests. Developer agents compute their bids as a function of the developer's profile, preferences, current schedule of assigned bugs, and estimated time-to-fix of the bug. This value is then sent to the triager agent for the final decision. We use the Eclipse and Firefox bug repositories to validate our approach, our studies suggest that the proposed auction-based multiagent mechanism can improve the bug assignment process compared to currently practised methods. In particular, we found a 16% improvement in the number of fixed bugs compared to the historic data, based on a sample size of 213,000 bug reports over a period of 6 years.","1534-5351;15345351","Electronic:978-0-7695-4666-7; POD:978-1-4673-0984-4","10.1109/CSMR.2012.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178862","Multiagent system;bug lifetime;bug repositories;market mechanism","Accuracy;Computer bugs;Data mining;Fires;Machine learning algorithms;Prediction algorithms;Resource management","computer viruses;multi-agent systems","Eclipse bug repository;Firefox bug repository;auction-based multiagent mechanism;backlog minimization;bug assignment;developer agent;intelligent software agent;market-based bug allocation mechanism;predictive bug lifetime;software project;triager agent","","5","","25","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"Adaptive traffic signal control system with cloud computing based online learning","D. K. Prasad","School of Computer Engineering, Nanyang Technological University, Singapore","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","5","We present an extended architecture for adaptive traffic signal control system with online learning feature. The presented architecture is modified to incorporate the advantages of cloud computing such that the resultant architecture has high accuracy, online learning capability, scalability, robustness, and real time performance.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6173581","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173581","cloud computing;image processing;online learning;traffic signal","Adaptive systems;Cloud computing;Computer architecture;Control systems;Machine learning;Servers;Vehicles","cloud computing;image processing;learning (artificial intelligence);road traffic control","adaptive traffic signal control system;cloud computing;online learning capability;online learning feature","","2","","24","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Enhancement of associative rule based FOIL and PRM algorithms","D. Rai; A. S. Thoke; K. Verma","Department of Electrical Engineering, National Institute of Technology, Raipur-492010, India","2012 Students Conference on Engineering and Systems","20120514","2012","","","1","4","Classification is one of the important problems in Data Mining. There are various methods of classification available like Rule based method, Decision tree, Neural network, and Bayesian networks. This paper focuses on Associative rule based classifier. FOIL (First order Inductive Learner) and PRM (Predictive Rule Mining) algorithms have been analysed in this work. The proposed work is superior to reported works in terms of memory requirements by eliminating use of intermediate data structure without sacrificing classification accuracy. The proposed work is an enhancement of existing FOIL and PRM algorithms.","","Electronic:978-1-4673-0455-9; POD:978-1-4673-0456-6","10.1109/SCES.2012.6199095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6199095","Association rules;classification;data mining;first order inductive learner (FOIL) algorithm;predictive rule mining (PRM) algorithm","Accuracy;Algorithm design and analysis;Classification algorithms;Data mining;Machine learning algorithms;Memory management;Prediction algorithms","belief networks;data analysis;data mining;decision trees;learning (artificial intelligence);neural nets;pattern classification","Bayesian networks;FOIL algorithm;PRM algorithm;associative rule enhancement;classification method;data mining;decision tree;first order inductive learner algorithm;intermediate data structure usage elimination;memory requirements;neural network;predictive rule mining algorithm;rule based method;training data analysis","","0","","14","","","16-18 March 2012","","IEEE","IEEE Conference Publications"
"Study on fault diagnosis of hydraulic pump based on sphere-structured support vector machines","X. Hu","Huaiyin Institute of Technology, Huaian 223003, China","2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet)","20120517","2012","","","2894","2896","This paper proposes the algorithm of defect classification of sphere-structured suppot vecor machines, constituting the multi-breakdown sorter to carry on the hydraulic pump's fault recognition, in accordance with the insufficient data sample from fault diagnosis. The results show that training the classifier only needs a small quantity of fault data samples in time domain and does need signal preprocessing applied for multi-fault recognition and diagnosis. it has the advantage of strong ability of fault classification in the few sample situation compared to BP neural network.","","DVD:978-1-4577-1413-9; Electronic:978-1-4577-1415-3; POD:978-1-4577-1414-6","10.1109/CECNet.2012.6201946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6201946","fault diagnosis;hydraulic pump;suppot vecor machines","Classification algorithms;Fault diagnosis;Kernel;Machine learning;Pumps;Support vector machines;Training","backpropagation;condition monitoring;fault diagnosis;hydraulic systems;mechanical engineering computing;neural nets;pumps;signal classification;support vector machines;time-domain analysis","BP neural network;defect classification;fault classification;fault data samples;fault diagnosis;hydraulic pump;multifault recognition;signal preprocessing;sphere-structured support vector machines;time domain","","1","","4","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
"Network-Based Stochastic Semisupervised Learning","T. C. Silva; L. Zhao","Department of Computer Sciences, Institute of Mathematics and Computer Science, University of S&#x00E3;o Paulo, S&#x00E3;o Carlos, Brazil","IEEE Transactions on Neural Networks and Learning Systems","20120227","2012","23","3","451","466","Semisupervised learning is a machine learning approach that is able to employ both labeled and unlabeled samples in the training process. In this paper, we propose a semisupervised data classification model based on a combined random-preferential walk of particles in a network (graph) constructed from the input dataset. The particles of the same class cooperate among themselves, while the particles of different classes compete with each other to propagate class labels to the whole network. A rigorous model definition is provided via a nonlinear stochastic dynamical system and a mathematical analysis of its behavior is carried out. A numerical validation presented in this paper confirms the theoretical predictions. An interesting feature brought by the competitive-cooperative mechanism is that the proposed model can achieve good classification rates while exhibiting low computational complexity order in comparison to other network-based semisupervised algorithms. Computer simulations conducted on synthetic and real-world datasets reveal the effectiveness of the model.","2162-237X;2162237X","","10.1109/TNNLS.2011.2181413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6126049","Classification;complex networks;preferential walk;random walk;semisupervised learning;stochastic competitive learning","Biological neural networks;Computational modeling;Machine learning;Mathematical model;Semisupervised learning;Stochastic processes;Vectors","computational complexity;data analysis;learning (artificial intelligence);numerical analysis;stochastic processes","combined random-preferential walk;competitive-cooperative mechanism;computational complexity;input dataset;labeled samples;machine learning approach;mathematical analysis;network-based stochastic semisupervised learning;nonlinear stochastic dynamical system;numerical validation;real-world datasets;semisupervised data classification model;synthetic datasets;training process;unlabeled samples","0","19","","50","","20120109","March 2012","","IEEE","IEEE Journals & Magazines"
"Importance sampling for model-based reinforcement learning","O. Sönmez; A. T. Cemgil","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Bo&#x011F;azi&#x00E7;i &#x00DC;niversitesi, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","Most of the state-of-the-art reinforcement learning algorithms are based on Bellman equations and make use of fixed-point iteration methods to converge to suboptimal solutions. However, some of the recent approaches transform the reinforcement learning problem into an equivalent likelihood maximization problem with using appropriate graphical models. Hence, it allows the adoption of probabilistic inference methods. Here, we propose an expectation-maximization method that employs importance sampling in its E-step in order to estimate the likelihood and then to determine the optimal policy.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204703","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204703","","Abstracts;Inference algorithms;Learning;Machine learning;Markov processes;Monte Carlo methods;Probabilistic logic","expectation-maximisation algorithm;importance sampling;inference mechanisms;learning (artificial intelligence)","Bellman equation;E-step;equivalent likelihood maximization problem;expectation-maximization method;fixed-point iteration method;graphical models;importance sampling;model-based reinforcement learning;optimal policy;probabilistic inference method","","0","","9","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"Automatic Classification of Tibetan Web Pages","G. Xu; C. Xiang; X. Gao; X. Zhao; G. Yang","Coll. of Inf. Eng., Minzu Univ. of China, Beijing, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","3","","423","426","A classification approach for Tibetan web pages is introduced in this paper. It takes advantage of the class feature dictionary and Rocchio classification algorithm to classify the Tibetan web pages into the predefined classes rapidly and accurately. The experimental results present that the approach has better classification accuracy for Tibetan web pages classification. It is useful and helpful for the construction of the statistical and rule-based classification of Tibetan texts as well as construction of high-quality Tibetan corpus.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188269","Classification of Web Pages;Text classification;Tibetan Information Processing","Classification algorithms;Dictionaries;Information processing;Kernel;Machine learning;Text categorization;Web pages","Web sites;natural language processing;pattern classification;statistical analysis;text analysis","Rocchio classification algorithm;Tibetan texts;automatic Tibetan Web page classification;class feature dictionary;high-quality Tibetan corpus;rule-based classification;statistical classification","","1","","21","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Kernel based K-means clustering using rough set","B. K. Tripathy; A. Ghosh; G. K. Panda","SCSE, VIT University, Vellore, Tamil Nadu","2012 International Conference on Computer Communication and Informatics","20120301","2012","","","1","5","From the beginning of the data analysis system cluster computing plays an important role on it. The very early developed clustering algorithms which can handle only numerical data and K-means clustering is one of them and was proposed by Macqueen [1] in 1967. This algorithm helps us to find the homogeneity of the data set. This K-means algorithm has been modified in many ways to get the modified K-means and kernel based K-means is one of them. It is a nonlinear transformation which transforms the sample data into high dimensional feature space. Though this kernel based K-means performs good almost on every data set but it is unable to handle uncertainty. After rough set theory has been proposed by Pawlak [2], we have many clustering algorithms based on it which can handle uncertainty and heterogeneous data and Rough based K-means is one of them. So in this paper we are proposing the combination of these two methods and known as kernel based K-Means using rough set.","","Electronic:978-1-4577-1583-9; POD:978-1-4577-1580-8","10.1109/ICCCI.2012.6158827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158827","Cluster;Data analysis;Homogeneity;Kernel;Uncertainty","Approximation methods;Clustering algorithms;Euclidean distance;Kernel;Machine learning;Set theory;Uncertainty","data analysis;pattern clustering;rough set theory;uncertainty handling","cluster computing;clustering algorithms;data analysis system;data set homogeneity;high dimensional feature space;kernel based k-means clustering;nonlinear transformation;numerical data handling;rough based k-means;rough set theory;uncertainty handling","","1","","17","","","10-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"A Text Analysis Approach to Motivate Knowledge Sharing via Microsoft SharePoint","R. M. Patton; W. McNair; C. T. Symons; J. N. Treadwell; T. E. Potok","","2012 45th Hawaii International Conference on System Sciences","20120209","2012","","","3670","3678","Creating incentives for knowledge workers to share their knowledge within an organization continues to be a challenging task. Strong, innate behaviors of the knowledge worker, such as self-preservation and self-advancement, are difficult to overcome, regardless of the level of knowledge. Many incentive policies simply focus on providing external pressure to promote knowledge sharing. This work describes a technical approach to motivate sharing. Utilizing text analysis and machine learning techniques to create an enhanced knowledge sharing experience, a prototype system was developed and tested at Oak Ridge National Laboratory that reduces the overhead cost of sharing while providing a quick, positive payoff for the knowledge worker. This work describes the implementation and experiences of using the prototype in a corporate production environment.","1530-1605;15301605","Electronic:978-1-5090-5638-5; POD:978-1-4577-1925-7; USB:978-0-7695-4525-7","10.1109/HICSS.2012.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6149145","","Knowledge management;Laboratories;Machine learning;Organizations;Prototypes;Text analysis;Vectors","behavioural sciences;incentive schemes;knowledge management;learning (artificial intelligence);organisational aspects;personnel;text analysis","Microsoft sharepoint;Oak Ridge National Laboratory;corporate production environment;incentive policies;innate behaviors;knowledge sharing;knowledge workers;machine learning;organization;text analysis","","1","","19","","","4-7 Jan. 2012","","IEEE","IEEE Conference Publications"
"Team-based software/system development in a vertically-integrated project-based course","R. Abler; E. Coyle; A. Kiopa; J. Melkers","Georgia Institute of Technology","2011 Frontiers in Education Conference (FIE)","20120202","2011","","","T3F-1","T3F-7","We use per-student virtual machines to allow new students to configure servers, thus enabling them to develop an understanding of the complex eStadium system. The outcomes include: student learning as the per-student virtual machines progress into software development and production machines supporting the eStadium game-day environment; the teamwork and leadership skills that evolve as students progress from initial learning to leadership roles in the creation of sophisticated applications; guidelines for instructors mentoring students through the process of building and maintaining a working production system; and, parallels with best-practice software and system development in industry. The use of peer-evaluations and social-network studies enable us to determine how the students interact with and learn from each other across years (sophomores through seniors). This cross year, cross experience-level learning process is essential for maintaining the technical and team continuity of the project. It also prepares students in a very realistic way for the software-development process in industry.","0190-5848;01905848","Electronic:978-1-61284-469-5; POD:978-1-61284-468-8; USB:978-1-61284-467-1","10.1109/FIE.2011.6142974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6142974","peer-based learning;project-based learning;software development;virtual machines","Documentation;Machine learning;Programming;Servers;Software;Teamwork","computer aided instruction;computer science education;educational courses;file servers;social networking (online);software development management;virtual machines","best practice software;complex eStadium system;cross experience level learning process;eStadium game day environment;peer evaluations;per-student virtual machines;production machines;server configuration;social network studies;student learning;student mentoring;team based software-system development;team continuity;technical continuity;vertically integrated project based course","","2","","22","","","12-15 Oct. 2011","","IEEE","IEEE Conference Publications"
"Developing New Fitness Functions in Genetic Programming for Classification With Unbalanced Data","U. Bhowan; M. Johnston; M. Zhang","School of Engineering and Computer Engineering, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20120315","2012","42","2","406","421","Machine learning algorithms such as genetic programming (GP) can evolve biased classifiers when data sets are unbalanced. Data sets are unbalanced when at least one class is represented by only a small number of training examples (called the minority class) while other classes make up the majority. In this scenario, classifiers can have good accuracy on the majority class but very poor accuracy on the minority class(es) due to the influence that the larger majority class has on traditional training criteria in the fitness function. This paper aims to both highlight the limitations of the current GP approaches in this area and develop several new fitness functions for binary classification with unbalanced data. Using a range of real-world classification problems with class imbalance, we empirically show that these new fitness functions evolve classifiers with good performance on both the minority and majority classes. Our approaches use the original unbalanced training data in the GP learning process, without the need to artificially balance the training examples from the two classes (e.g., via sampling).","1083-4419;10834419","","10.1109/TSMCB.2011.2167144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6029340","Classification;fitness function;genetic programming (GP);unbalanced data","Accuracy;Feature extraction;Genetics;Loss measurement;Machine learning;Machine learning algorithms;Training","data handling;genetic algorithms;learning (artificial intelligence);pattern classification","GP learning process;biased classifiers;binary classification;class imbalance;data sets;fitness functions;genetic programming;machine learning algorithms;majority class;minority class;training criteria;unbalanced data;unbalanced training data","","23","","64","","20110926","April 2012","","IEEE","IEEE Journals & Magazines"
"Driver Behavior Classification at Intersections and Validation on Large Naturalistic Data Set","G. S. Aoude; V. R. Desaraju; L. H. Stephens; J. P. How","Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT) , Cambridge, MA, USA","IEEE Transactions on Intelligent Transportation Systems","20120529","2012","13","2","724","736","The ability to classify driver behavior lays the foundation for more advanced driver assistance systems. In particular, improving safety at intersections has been identified as a high priority due to the large number of intersection-related fatalities. This paper focuses on developing algorithms for estimating driver behavior at road intersections and validating them on real traffic data. It introduces two classes of algorithms that can classify drivers as compliant or violating. They are based on (1) support vector machines and (2) hidden Markov models, which are two very popular machine learning approaches that have been used successfully for classification in multiple disciplines. However, existing work has not explored the benefits of applying these techniques to the problem of driver behavior classification at intersections. The developed algorithms are successfully validated using naturalistic intersection data collected in Christiansburg, VA, through the U.S. Department of Transportation Cooperative Intersection Collision Avoidance System for Violations initiative. Their performances are also compared with those of three traditional methods, and the results show significant improvements with the new algorithms.","1524-9050;15249050","","10.1109/TITS.2011.2179537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6145754","Driver behavior;driver warning systems;intention prediction","Classification algorithms;Computational modeling;Hidden Markov models;Machine learning algorithms;Safety;Support vector machines;Vehicles","behavioural sciences computing;hidden Markov models;learning (artificial intelligence);pattern classification;road safety;road traffic;support vector machines;traffic engineering computing","Christiansburg;US Department of Transportation Cooperative Intersection Collision Avoidance System for Violations initiative;Virginia;compliant driver;driver assistance systems;driver behavior classification;hidden Markov model;intersection safety;intersection-related fatality;large naturalistic data set;machine learning approach;road intersection;support vector machines;traffic data;violating driver","","41","","46","","20120203","June 2012","","IEEE","IEEE Journals & Magazines"
"Adaptive Learning in Complex Reproducing Kernel Hilbert Spaces Employing Wirtinger's Subgradients","P. Bouboulis; K. Slavakis; S. Theodoridis","Department of Informatics and Telecommunications, University of Athens, Athens, Greece","IEEE Transactions on Neural Networks and Learning Systems","20120227","2012","23","3","425","438","This paper presents a wide framework for non-linear online supervised learning tasks in the context of complex valued signal processing. The (complex) input data are mapped into a complex reproducing kernel Hilbert space (RKHS), where the learning phase is taking place. Both pure complex kernels and real kernels (via the complexification trick) can be employed. Moreover, any convex, continuous and not necessarily differentiable function can be used to measure the loss between the output of the specific system and the desired response. The only requirement is the subgradient of the adopted loss function to be available in an analytic form. In order to derive analytically the subgradients, the principles of the (recently developed) Wirtinger's calculus in complex RKHS are exploited. Furthermore, both linear and widely linear (in RKHS) estimation filters are considered. To cope with the problem of increasing memory requirements, which is present in almost all online schemes in RKHS, the sparsification scheme, based on projection onto closed balls, has been adopted. We demonstrate the effectiveness of the proposed framework in a non-linear channel identification task, a non-linear channel equalization problem and a quadrature phase shift keying equalization scheme, using both circular and non circular synthetic signal sources.","2162-237X;2162237X","","10.1109/TNNLS.2011.2179810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6126047","Adaptive kernel learning;Wirtinger's calculus;complex kernels;projection;subgradient;widely linear estimation","Calculus;Context;Hilbert space;Kernel;Loss measurement;Machine learning;Signal processing","Hilbert spaces;equalisers;filtering theory;gradient methods;learning (artificial intelligence);quadrature phase shift keying;signal processing","Wirtinger calculus;Wirtinger subgradients;adaptive learning;circular synthetic signal sources;complex reproducing kernel Hilbert spaces;complex valued signal processing;complexification trick;learning phase;loss function;noncircular synthetic signal sources;nonlinear channel equalization problem;nonlinear channel identification task;nonlinear online supervised learning tasks;quadrature phase shift keying equalization scheme;sparsification scheme;wide;y linear estimation filters","","23","","66","","20120109","March 2012","","IEEE","IEEE Journals & Magazines"
"Multiple instance boosting with global smoothness regularization","C. Weng; G. Hua; J. Yuan","School of Electrical & Electronic Engineering, NTU","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","5","In multiple instance learning, the training set consists of labeled bags that include unlabeled instances, and the target is to predict the labels of unseen bags. A bag is labeled positive only if it contains at least one positive instance, otherwise it is a negative bag. Over the past years, many popular machine learning algorithms have been adapted to tackle the multiple instance learning problems. In this paper, to train a discriminative multiple instance classifier which generalize well, we present a boosting approach with global smoothness regularization, in which the weak learners are either hyper balls with the center at the instance of positive bags or random projection decision stumps. Experimental results show that our proposed algorithm is comparable to the classical Diverse Density algorithm on some multiple instance learning benchmark datasets.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6174288","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6174288","","Boosting;Cost function;Machine learning algorithms;Mathematical model;Noise measurement;Prediction algorithms","learning (artificial intelligence);pattern classification","classical diverse density algorithm;global-smoothness regularization;machine learning algorithms;multiple-instance boosting;multiple-instance classifier;multiple-instance learning;positive-bag instance;random projection decision stumps","","0","","19","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Overview on ontology mapping and approach","X. Liu; L. Cao; W. Dai","Hebei Normal University of Science and Technology, Qinhuangdao 066004, China","2011 4th IEEE International Conference on Broadband Network and Multimedia Technology","20120223","2011","","","592","595","This paper begins with the concept of ontology and ontology mapping. On ground of the description of ontology, classification on similarity is given in this paper. They include the approaches based on syntax, instance, constraint, architecture and property relations. And the mapping approaches are also classified according to the mapping technique, such as approaches based on logic inference, statistic, machine learning, graph theory, information flow, modularization, fuzzy conceptual graph, risk decision and formal conceptual analysis. Meanwhile each approach is described briefly. The existing problems and prospect are proposed at last.","","Electronic:978-1-61284-159-5; POD:978-1-61284-158-8","10.1109/ICBNMT.2011.6156003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156003","ontology mapping;similarity;sontology","Context;Learning systems;Machine learning;Ontologies;Probability distribution;Semantics;Statistical analysis","formal concept analysis;fuzzy set theory;graph theory;inference mechanisms;learning (artificial intelligence);logic programming;ontologies (artificial intelligence);statistical analysis","formal conceptual analysis;fuzzy conceptual graph;graph theory;information flow;logic inference;machine learning;mapping technique;modularization;ontology description;ontology mapping;property relations;risk decision;statistics;syntax","","1","","11","","","28-30 Oct. 2011","","IEEE","IEEE Conference Publications"
"Use of Clonal Selection Algorithm as Software Test Data Generation Technique","A. Pachauri; Gursaran","Dept. of Math., Dayalbagh Educ. Inst., Agra, India","2012 Second International Conference on Advanced Computing & Communication Technologies","20120315","2012","","","1","5","Clonal selection algorithm is an algorithm that belongs to the class of immune algorithm inspired form clonal selection principle of biological immune system. Initially clonal selection algorithm was designed for machine learning approach and was used in pattern recognition process of artificial intelligence. The other implementation of clonal selection algorithm is in the field of function optimization, which had gained a tremendous attention of the researchers. We too had used the clonal selection algorithm for the software test data generation technique for branch coverage with some modification according to the requirement.","2327-0632;23270632","Electronic:978-0-7695-4640-7; POD:978-1-4673-0471-9","10.1109/ACCT.2012.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168322","Clonal Selection Algorithm;Path-prefix strategy;Software test data generation","Algorithm design and analysis;Approximation methods;Cloning;Machine learning algorithms;Software;Software algorithms;Testing","biology computing;data handling;learning (artificial intelligence);pattern recognition;program testing","artificial intelligence;biological immune system;clonal selection algorithm;immune algorithm;machine learning approach;pattern recognition process;software test data generation technique","","1","","15","","","7-8 Jan. 2012","","IEEE","IEEE Conference Publications"
"A new bidding strategy in LCS using a decentralized loaning and bid history","A. Workineh; A. Homaifar","Autonomous Control and Information Technology Center, North Carolina A & T State University, Greensboro, NC 27411","2012 IEEE Aerospace Conference","20120419","2012","","","1","8","In a strength based learning classifier systems (LCS), auctioning among classifiers that match to an environmental message has been used as a way of identifying winner classifiers. All classifiers participating in an auction issue a bid proportional to their strength and a winner classifier is allowed to fire and receive a reward or punishment from its environment as a consequence of its action. In this kind of bidding strategy, good classifiers with low strength and little experience have to wait until the strength of less useful classifiers has come down through continuous taxation. This slows down the convergence of the learning system to the optimal solution sets. In addition, offspring classifiers that come from weak parents as a result of randomness in the selection process may inherit a small strength as compared to experienced classifiers in the population. A mutation occurring at a point may however make them better match to more environmental inputs. But due to a low initial strength they have to wait for some time till they mature and try their action. This paper introduced a decentralized loaning approach to mitigate the above shortcomings of the bidding strategy in traditional LCS. Loaning among classifiers in the population is allowed. In direct analogy with real auctions, all classifiers matching the current input compare the average bid history with their potential bid based on their current strength. The average bid history parameter gives general information about the bid market (potential of competent classifiers) and determines the amount of loan a classifier should ask. The results obtained show a significant improvement on the performance of the system.","1095-323X;1095323X","Electronic:978-1-4577-0557-1; POD:978-1-4577-0556-4","10.1109/AERO.2012.6187346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187346","","Accuracy;Equations;Genetic algorithms;History;Learning systems;Machine learning;Mathematical model","learning (artificial intelligence);pattern classification","bid history parameter;bid market;bidding strategy;classifier auction;continuous taxation;decentralized loaning approach;offspring classifiers;randomness;selection process;strength based learning classifier system","","0","","23","","","3-10 March 2012","","IEEE","IEEE Conference Publications"
"An enhanced approach for classifying emotions using customized decision tree algorithm","S. Sriram; Xiaobu Yuan","School of Computer Science, University of Windsor, ON- N9B3P4, Canada","2012 Proceedings of IEEE Southeastcon","20120510","2012","","","1","6","This investigation reports the improved method for the text based emotion classification and prediction using a customized decision tree algorithm. Machine learning techniques such as Decision tree algorithm are widely used in research fields of bioinformatics, data mining, capturing knowledge in expert systems and so on. The emotions can be deducted from the online chat conversation and tagged. In this proposed work, the given dataset is classified using customized decision tree with respect to the two known classes of data. The main motivation behind this customized approach is to provide a simple, effective, less complex and memory optimized prediction model in deducing the classes of the given dataset. The effectiveness of the approach is then obtained by comparing it with the existing methodologies.","1091-0050;10910050","Electronic:978-1-4673-1375-9; POD:978-1-4673-1374-2","10.1109/SECon.2012.6196948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6196948","Classification;Emotions;customized approach;decision tree;predictive model","Accuracy;Classification algorithms;Decision trees;Machine learning;Prediction algorithms;Speech recognition;Training","decision trees;emotion recognition;text detection","bioinformatics;customized decision tree algorithm;data mining;expert systems;machine learning techniques;memory optimized prediction model;online chat conversation;text based emotion classification;text based emotion prediction","","0","","18","","","15-18 March 2012","","IEEE","IEEE Conference Publications"
"Comparing the impacts of dimension reduction methods that use class labels on text classification","G. Biricik","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Y&#x0131;ld&#x0131;z Teknik &#x00DC;niversitesi, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","Classification of datasets that contain samples with numerous features is known as a costly process in time and space. In order to overcome this problem, dimensionality reduction techniques like feature selection and feature extraction are proposed in literature. In this paper, we compare the impacts of abstract feature extraction method and other popular techniques that use class labels for dimensionality reduction on classification performances. For evaluation, we utilize two standard text datasets having high dimensional samples. We compare the impacts of selected methods on performance by applying them on selected datasets and testing on five different classifiers with different design approaches. Results show that using abstract feature extraction method for dimensionality reduction produces much better classification performance, when compared with other selected methods.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204613","","Abstracts;Feature extraction;Kernel;Machine learning;Semantics;Support vector machines;Text categorization","character recognition;feature extraction;text analysis","abstract feature extraction method;class label;dataset classification;dimension reduction method;standard text dataset;text classification","","0","","20","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"Learning-from-signals on edge devices","M. R. Moore; M. A. Buckner","Cognitive Radio Program and the Signals Solution Center at Oak Ridge National Laboratory","IEEE Instrumentation & Measurement Magazine","20120403","2012","15","2","40","44","Machine learning tools are being developed that support increasingly complex learning-fromsignals on ""edge"" devices to meet the challenges of decentralized decision making. Edge devices in this context include any electronically enabled device that can sense, process and make decisions based on locally integrated information. Component systems that use algorithms and other technologies are required to provide sensing, signal processing, learning (model selection) and classification functions for edge devices. This article focuses on the algorithms and technologies for the component systems. It includes an introductory description of the architectures that enable these functions to be ported to edge devices which have limited resources so they can execute some machine learning processes.","1094-6969;10946969","","10.1109/MIM.2012.6174579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6174579","","Decision making;Feature extraction;Image edge detection;Machine learning;Transforms","decision making;learning (artificial intelligence);signal processing","component systems;decision making;edge devices;learning-from-signals;machine learning tools;signal processing","","2","","5","","","April 2012","","IEEE","IEEE Journals & Magazines"
"Multiclass Feature Selection Via Kernel Parameter Optimization","T. Wang; S. Xu","Sch. of Math. & Comput. Sci., Gannan Normal Univ., Ganzhou, China","2012 Fifth International Conference on Intelligent Computation Technology and Automation","20120213","2012","","","213","216","This paper considers feature selection in a multiclass classification scenario where the goal is to determine a subset of available features which is most discriminative and informative for all the classes simultaneously. Based on the data distributions of classes in the feature space, this paper first presents a model selection criterion named multiclass kernel polarization (MKP) to evaluate the goodness of a kernel in multiclass classification scenario, and then optimizes the scale factors assigned to each feature in a kernel by maximizing this criterion to identify the more relevant features. The proposed method is demonstrated with two UCI machine learning benchmark examples.","","Electronic:978-0-7695-4637-7; POD:978-1-4673-0470-2","10.1109/ICICTA.2012.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150030","feature selection;kernel method;multiclass classification;support vector machines (SVMs)","Accuracy;Breast;Kernel;Machine learning;Optimization;Support vector machines;Training","feature extraction;learning (artificial intelligence);optimisation;pattern classification;set theory;support vector machines","UCI machine learning benchmark;data distribution;feature space;features subset;kernel parameter optimization;model selection criterion;multiclass classification scenario;multiclass feature selection;multiclass kernel polarization","","0","","18","","","12-14 Jan. 2012","","IEEE","IEEE Conference Publications"
"Targeted Steganalysis of Edge Adaptive Image Steganography Based on LSB Matching Revisited Using B-Spline Fitting","S. Tan; B. Li","College of Computer Science and Software Engineering, Shenzhen University, China","IEEE Signal Processing Letters","20120419","2012","19","6","336","339","In this letter, the authors point out that the readjusting phase of edge adaptive image steganography based on LSB matching revisited introduces a pulse distortion to the long exponential tail of the histogram of the absolute difference of the pixel pairs. Making use of this observation, a targeted steganalytic method based on B-Spline fitting is proposed. Experimental results show that the proposed method obtains excellent results for detecting stego images with low embedding rate. The dominant performance of our method compared with state-of-the-art blind steganalyzers, such as SPAM and SRM is apparent. Furthermore, our method can accurately estimate the threshold used in the secret data embedding procedure and can separate the stego images with unit block size from those with block sizes greater than one.","1070-9908;10709908","","10.1109/LSP.2012.2194702","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183461","B-spline fitting;LSB matching;edge adaptive image steganography;steganalysis","Algorithm design and analysis;Educational institutions;Feature extraction;Histograms;Image edge detection;Machine learning algorithms;Splines (mathematics)","adaptive signal processing;curve fitting;image coding;splines (mathematics);steganography","B-spline fitting;LSB matching revisited;edge adaptive image steganography;image steganalysis;pulse distortion;secret data embedding procedure;stego images","","12","","11","","20120413","June 2012","","IEEE","IEEE Journals & Magazines"
"A novel approach towards Naïve Bayesian classifier","B. K. Singh; A. Agarwal","","2011 Nirma University International Conference on Engineering","20120216","2011","","","1","4","Bayesian Theory has been an elegant basis for the design of classifiers. There are several classifiers which do not adhere with the Bayesian principle strictly but motivated from the very theory, termed as naive Bayesian methods. The present work proposes a naive Bayesian Classification approach which limits the classification process to the basic operation of the key comparison. Moreover we are able to link the two notions of the probability - frequency in ensemble and idea of reasonable expectation by the means of ordinary algebra.","2375-1282;23751282","Electronic:978-1-4577-2168-7; POD:978-1-4577-2169-4","10.1109/NUiConE.2011.6153232","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6153232","Naïve Bayesian Classification;Notion of Probability","Accuracy;Bayesian methods;Complexity theory;Learning systems;Machine learning;Testing;Training","belief networks;pattern classification;probability","Bayesian principle;Naïve Bayesian classifier;ordinary algebra;probability","","0","","16","","","8-10 Dec. 2011","","IEEE","IEEE Conference Publications"
"Unsupervised feature ranking based on representation entropy","V. M. Rao; V. N. Sastry","Chaitanya Bharathi Institute of Technology, Hyderabad, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","421","425","Feature ranking and selection play an important role in many areas of Machine learning. Most of the work found in the machine learning literature concerns itself with supervised dimensionality reduction where each instance of the dataset is attached with a class label. In this paper, we present an algorithm that ranks the features of an unlabeled dataset based on the concept of representation entropy. Entropy, in its different forms, has been successfully applied to the problem of feature ranking and selection. Representation entropy, used in this paper for the purpose of ranking features is based on the well known concept of principal components. The results obtained by the new algorithm are compared with the Relief-F, SUD algorithm and SVD-entropy based algorithm for various datasets and analyzed.","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194631","classificatio;clustering;feature ranking;principal components;representation entropy;unlabeled data","Classification algorithms;Clustering algorithms;Eigenvalues and eigenfunctions;Entropy;Glass;Iris;Machine learning","entropy;feature extraction;knowledge representation;learning (artificial intelligence);pattern classification;principal component analysis","Relief-F;SUD algorithm;SVD-entropy based algorithm;class label;feature selection;machine learning;principal components;representation entropy;supervised dimensionality reduction;unlabeled dataset;unsupervised feature ranking","","1","","16","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"Toward Intelligent Software Defect Detection - Learning Software Defects by Example","M. J. Benson","Software Eng. Div., NASA Goddard Space Flight Center, Greenbelt, MD, USA","2011 IEEE 34th Software Engineering Workshop","20120209","2011","","","138","142","Source code level software defect detection has gone from state of the art to a software engineering best practice. Automated code analysis tools streamline many of the aspects of formal code inspections but have the drawback of being difficult to construct and either prone to false positives or severely limited in the set of defects that can be detected. Machine learning technology provides the promise of learning software defects by example, easing construction of detectors and broadening the range of defects that can be found. Pinpointing software defects with the same level of granularity as prominent source code analysis tools distinguishes this research from past efforts, which focused on analyzing software engineering metrics data with granularity limited to that of a particular function rather than a line of code.","1550-6215;15506215","Electronic:978-0-7695-4627-8; POD:978-1-4673-0245-6","10.1109/SEW.2011.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6146920","","Feature extraction;Machine learning;Measurement;Presses;Software;Software engineering;Training","learning (artificial intelligence);program diagnostics;software metrics","automated code analysis tool;formal code inspection;intelligent software defect detection;machine learning;software engineering metrics;source code level software defect detection","","1","","22","","","20-21 June 2011","","IEEE","IEEE Conference Publications"
"Revisiting milis multiple instance learning algorithm with a different instance selection mechanism","O. Akın; A. Erdem; E. Erdem","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Hacettepe &#x00DC;niversitesi, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","Multiple instance learning (MIL) is a new paradigm in machine learning that deals with classification of bags of instances, as opposed to the traditional view that aims at learning from single instances. In a typical MIL setting, a negative bag is composed of only negative instances. On the other hand, a bag is considered positive if it contains at least one positive instance. This learning approach provides a natural way of modeling several pattern recognition and computer vision problems, e.g. protein, document and image classification and object recognition, which inherently require learning under ambiguity. In many cases, MIL approaches performs better than the standard single instance learning (SIL) methods. One of the general approaches to MIL is to transform a given MIL problem into a corresponding SIL problem. This transformation is mainly done with selecting a set of representative instances from the training bags, and these group of studies basically differ from each other on how they perform this instance selection step. In this study, we revisit such a MIL approach called MILIS with a different instance selection mechanism. The experimental results show that the proposed approach performs better on MIL benchmark data sets as compared to the original algorithm.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204490","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204490","","Abstracts;Information processing;Machine learning;Pattern recognition;Proteins;Standards;Support vector machines","learning (artificial intelligence)","MILIS multiple instance learning;computer vision problems;document classification;image classification;instance selection mechanism;machine learning;object recognition;pattern recognition;protein;single instance learning","","0","","11","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"Automatic classification of learning objects through dimensionality reduction and feature subset selections in an e-learning system","T. Chellatamilan; R. M. Suresh","Dept. of CSE, Arunai Eng. Coll., Tiruvannamalai, India","2012 IEEE International Conference on Technology Enhanced Education (ICTEE)","20120531","2012","","","1","6","This Research paper focus on the design and development of intelligent, personalized mobile agent for learning object classification and retrieval. We have used JADE (Java Agent Development Environment) platform to launch, migrate, classify and retrieve the learning content based on the customized query by a peer learners in an virtual e-learning environment like MOODLE. In turn the agent collects the user query and migrates into different Learning Object Repository, (LOR), learn and interact with them and retrieves the Learning Objects(LO) along with its Learning Object Metadata (LOM). From the retrieved learning objects the learner applies the machine learning algorithm for the purpose of classifying the LO based on his usefulness/interestingness/learning objective and etc., The retrieval agent has been trained by the machine learning algorithms and then this trained agents now migrates into different such LORs applies the classification in that respective place and retrieves only the relevant and ranked learning objects to the learner based on the learners pre classification techniques and interest. The main drawback in the case of traditional Client-Server based learning environment, the learner client portal takes the query of the learner, and retrieves all the result set irrespective of usefulness/interestingness of the learner. Here the learner spent time to get the irrelevant or non interested content along with the required set itself. The bandwidth also used to the transfer such uninterested content is waste. These two drawbacks can be avoided or rectified through the mobile agent which posses the capability of classification based on feature subset selection techniques like Infogain, entropy and machine learning algorithm then migrates into the different LOR for collecting the relevant LO. As soon as it is once migrated into the LOR, it applies the machine learning algorithm first and then classifies the result to eliminate the non interested content not- to be retrieved and transported to the learner side. The result of experiment using there different classifier, TF-IDF, Bayesian and Fuzzy classifier for the design and development of trained document classifier are Presented. The feature subset selection algorithm can be integrated with this to improve further accuracy of classifications.","","Electronic:978-1-4577-0726-1; POD:978-1-4577-0725-4","10.1109/ICTEE.2012.6208621","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6208621","Intelligent tutor system;Multi agent;Ontology;e-Learning","Abstracts;Bayesian methods;Electronic learning;Entropy;Machine learning;Machine learning algorithms;Mobile agents","Bayes methods;Java;client-server systems;computer aided instruction;document handling;fuzzy set theory;learning (artificial intelligence);meta data;mobile agents;pattern classification;query processing","Bayesian classifier;Infogain;JADE platform;Java agent development environment;LOM;LOR;MOODLE;TF-IDF;client-server based learning environment;dimensionality reduction;document classifier;e-learning system;entropy;feature subset selection technique;fuzzy classifier;intelligent personalized mobile agent;learner client portal;learning object automatic classification;learning object metadata;learning object repository;learning object retrieval;machine learning algorithm;query customization;retrieval agent;virtual e-learning environment","","4","","26","","","3-5 Jan. 2012","","IEEE","IEEE Conference Publications"
"Predicting the churn of telecommunication service users using open source data mining tools","S. M. Sladojevic; D. R. Culibrk; V. S. Crnojevic","Faculty of Technical Sciences, University of Novi Sad, Trg Dositeja Obradovica 6, 21000 Novi Sad, Serbia","2011 10th International Conference on Telecommunication in Modern Satellite Cable and Broadcasting Services (TELSIKS)","20120206","2011","2","","749","752","The paper presents a study focused on the problem of predicting the churn of telecommunication-service users. The transition of customers (users) to competitors is a significant business problem in areas with poor market differentiation of products and services, which is particularly evident in the market of telecommunication services. The paper evaluates the applicability of commonly used methods of data mining, available within a widely used data mining tool, to the problem. Experiments presented in the paper have been conducted based on real-world data provided for research purposes by Orange telecommunications company. Results indicate that boosting of simple classifiers achieves best results and that open-source tools can achieve performance very close to the best proprietary solutions.","","Electronic:978-1-4577-2019-2; POD:978-1-4577-2018-5","10.1109/TELSKS.2011.6143219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143219","Churn;Data Mining;Users","Boosting;Classification algorithms;Communications technology;Data mining;Educational institutions;Machine learning algorithms","data mining;telecommunication computing;telecommunication services","Orange telecommunication company;business problem;market differentiation;open source data mining tools;open-source tools;real-world data;telecommunication service users","","0","","11","","","5-8 Oct. 2011","","IEEE","IEEE Conference Publications"
"Learning from error: A two-level combined model for image classification","Mingyang Jiang; Chunxiao Li; Zirui Deng; Jufu Feng; Liwei Wang","Key Laboratory of Machine Perception, MOE, School of EECS, Peking University, Beijing, China","The First Asian Conference on Pattern Recognition","20120312","2011","","","677","680","We propose an error learning model for image classification. Motivated by the observation that classifiers trained using local grid regions of the images are often biased, i.e., contain many classification error, we present a two-level combined model to learn useful classification information from these errors, based on Bayes rule. We give theoretical analysis and explanation to show that this error learning model is effective to correct the classification errors made by the local region classifiers. We conduct extensive experiments on benchmark image classification datasets, promising results are obtained.","0730-6512;07306512","Electronic:978-1-4577-0121-4; POD:978-1-4577-0122-1","10.1109/ACPR.2011.6166669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166669","","Accuracy;Equations;Hidden Markov models;Machine learning;Mathematical model;Semantics;Training","Bayes methods;image classification","Bayes rule;classification errors correction;error learning model;image classification;local grid region;local region classifier;two-level combined model","","0","","15","","","28-28 Nov. 2011","","IEEE","IEEE Conference Publications"
"Image congealing via efficient feature selection","Ya Xue; X. Liu","Machine Learning Lab, GE Global Research, USA","2012 IEEE Workshop on the Applications of Computer Vision (WACV)","20120305","2012","","","185","192","Congealing for an image ensemble is a joint alignment process to rectify images in the spatial domain such that the aligned images are as similar to each other as possible. Fruitful congealing algorithms were applied to various object classes and medical applications. However, relatively little effort has been taken in the direction of compact and effective feature representations for each image. To remedy this problem, the least-square-based congealing framework is extended by incorporating an unsupervised feature selection algorithm, which substantially removes feature redundancy and leads to a more efficient congealing with even higher accuracy. Furthermore, our novel feature selection algorithm itself is an independent contribution. It is not explicitly linked to the congealing algorithm and can be directly applied to other learning tasks. Extensive experiments are conducted for both the feature selection and congealing algorithms.","1550-5790;15505790","Electronic:978-1-4673-0234-0; POD:978-1-4673-0233-3","10.1109/WACV.2012.6163048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163048","","Accuracy;Clustering algorithms;Cost function;Laplace equations;Machine learning algorithms;Partitioning algorithms;Vectors","feature extraction;image representation;least squares approximations","feature redundancy removal;feature selection;image congealing;image ensemble;image feature representation;image rectification;joint alignment process;least-square-based congealing framework;medical applications;object class;unsupervised feature selection algorithm","","0","","42","","","9-11 Jan. 2012","","IEEE","IEEE Conference Publications"
"Developing an evolvable pattern generator using learning classifier systems","S. Marzukhi; W. N. Browne; M. Zhang","School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand","The 5th International Conference on Automation, Robotics and Applications","20120202","2011","","","163","168","Classifying objects and patterns to certain categories is crucial for both humans and machines. Pattern classification has become an important topic in robotics research as it is applied in many scenarios (e.g. visual object detection in an autonomous robotics). Although autonomous learning of patterns by machines has advanced recently, it still requires humans to set-up the problem at an appropriate level for the learning technique. If the problem is too complex the system does not learn; conversely, too simple and the system does not reach its full potential performance level. In this work, a novel problem domain has been created that can be manipulated autonomously (i.e. scalable and evolvable patterns) to benefit autonomous systems. Experiments confirm that both the problem domain can be evolved and the problem solutions can be learnt lowering the requirement of human intervention in developing autonomous systems.","","Electronic:978-1-4577-0330-0; POD:978-1-4577-0329-4","10.1109/ICARA.2011.6144875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6144875","","Generators;Humans;Machine learning;Pattern recognition;Robots;Testing;Training","learning (artificial intelligence);mobile robots;object detection;pattern classification","autonomous pattern learning;autonomous robotics;autonomous systems;evolvable pattern generator;human intervention;learning classifier systems;learning technique;object classification;pattern classification;robotics research;visual object detection","","0","","24","","","6-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"Multi-Modal Multiple-Instance Learning with the application to the cannabis webpage recognition","Yinjuan Wang; Nianhua Xie; Weiming Hu; Jinfeng Yang","College of aviation automation, Civil Aviation University of China, Tianjin, China","The First Asian Conference on Pattern Recognition","20120312","2011","","","105","109","With the development of the World Wide Web, there exists more and more illicit drug Webpages. Thus, how to screen cannabis Webpages on the internet is a quite important issue. Conventional methods that only use the keyword-based or image-based approaches are not sufficient. We propose a Multi-Modal Multiple-Instance Learning (MMMIL) approach combining both text and image information for cannabis webpage recognition. The main technical contributions of our work are two-fold. First, the text information associated with images is used to build a pre-classifier, which can pre-select pseudo positive training bags from new Webpages to update multi-modal classifier. This can be seen as a pseudo active learning process. Second, we design an efficient instance selection technique by utilizing text information to speed up the training process without compromising the performance. The experiments on a dataset containing over 40,000 images for more than 4,000 Webpages demonstrate the effectiveness and efficiency of the proposed approach.","0730-6512;07306512","Electronic:978-1-4577-0121-4; POD:978-1-4577-0122-1","10.1109/ACPR.2011.6166680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166680","Cannabis Webpage Recognition;MIL;Multi-Modal","Bismuth;Educational institutions;Learning systems;Machine learning;Support vector machines;Training;Vectors","Internet;learning (artificial intelligence);pattern classification;text analysis","World Wide Web;cannabis Web page recognition;illicit drug Web page;image information;image-based approach;instance selection technique;keyword-based approach;multimodal classifier;multimodal multiple-instance learning;preclassifier;pseudoactive learning process;pseudopositive training bag;text information","","0","","12","","","28-28 Nov. 2011","","IEEE","IEEE Conference Publications"
"Weighted Instance Based Learner (WIBL) for user profiling","A. Cufoglu; M. Lohi; C. Everiss","School of Electronic and Computer Science, University of Westminster, 115 New Cavendish Street, W1W 6UW, London, United Kingdom","2012 IEEE 10th International Symposium on Applied Machine Intelligence and Informatics (SAMI)","20120531","2012","","","201","205","With an increase in web-based products and services, user profiling has created opportunities for both businesses and other organizations to provide a channel for user awareness as well as to achieve high user satisfaction. Apart from traditional collaborative and content-based methods, a number of classification and clustering algorithms have been used for user profiling. Instance Based Learner (IBL) classifier is a comprehensive form of the Nearest Neighbour (NN) algorithm and it is suitable for user profiling as users with similar profiles are likely to share similar personal interests and preferences. In IBL every attribute has an equal effect on the classification regardless of their relevance. In this paper, we proposed a weighted classification method, namely Weighted Instance Based Learner (WIBL), to build and handle user profiles. With WIBL, we introduce Per Category Feature (PCF) method to IBL in order to distinguish the effect of attributes on classification. PCF is an attribute weighting method and it assigns weights to attributes using conditional probabilities. The direct use of this method with IBL is not possible. Hence, two possible solutions were also proposed to address this problem. This study is aimed to test the performance of WIBL for user profiling. To validate the performance of WIBL, a series of computer simulations were carried out. These simulations were conducted using a large user profile database that includes 5000 training and 1000 test instances (users). Here, each user is represented with three sets of profile information; demographic, interest and preference data. The results illustrate that WIBL with PCF methods performs better than IBL on user profiling by reducing the error up to 28% on the selected dataset.","","Electronic:978-1-4577-0197-9; POD:978-1-4577-0196-2","10.1109/SAMI.2012.6208957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6208957","","Bayesian methods;Clustering algorithms;Collaboration;Educational institutions;Error analysis;Machine learning;Training","Internet;learning (artificial intelligence);pattern classification;pattern clustering;probability;user modelling","IBL classifier;NN algorithm;PCF method;WIBL;Web-based products;Web-based services;attribute weighting method;classification algorithms;clustering algorithms;computer simulations;conditional probabilities;demographic data;instance based learner classifier;interest data;nearest neighbour algorithm;per category feature method;preference data;profile information;user awareness;user profiling;user satisfaction;weight assignment;weighted instance based learner","","0","","11","","","26-28 Jan. 2012","","IEEE","IEEE Conference Publications"
"On-demand Data Numerosity Reduction for Learning Artifacts","K. Kalegele; H. Takahashi; J. Sveholm; K. Sasai; G. Kitagata; T. Kinoshita","Grad. Sch. of Inf. Sci., Tohoku Univ., Sendai, Japan","2012 IEEE 26th International Conference on Advanced Information Networking and Applications","20120419","2012","","","152","159","In domains in which single agent learning is a more natural metaphor for an artifact-embedded agent, Exemplar-Based Learning (EBL) requires significantly large sets of training examples for it to be applicable. Obviously large sets of training examples contradict resource capabilities of artifacts. To make EBL a possibility for these artifacts, sets of training examples must be reduced in size in a way that does not compromise learning performance in order to relieve artifacts' resources (e.g. memory). In this paper, we investigate training sets requirements for artifacts learning and propose a ranking-based Stratified Ordered Selection (SOS) method to scale them down. Contrary to reduction approaches in mainstream learning, this method has been designed with resource constraint nature of artifacts in mind. Artifacts shall use an intermediary which implements SOS to, dynamically and on-demand, retrieve training subsets based on their resource capacities (e.g. memory, CPU). SOS uses a new Level Order (LO) ranking scheme which has been designed to broaden representation of classes of examples, to quicken data retrieval, and to allow for retrieval of subsets of varying sizes while ensuring same or near same learning performance. We present how SOS evaluates on various well known machine learning datasets and how it compares to some of the best performing data reduction approaches.","1550-445X;1550445X","Electronic:978-0-7695-4651-3; POD:978-1-4673-0714-7","10.1109/AINA.2012.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184865","Artificial Intelligence;Data Reduction;Learning","Accuracy;Binary trees;Educational institutions;Machine learning;Reliability;Training;Training data","data reduction;learning (artificial intelligence);multi-agent systems","agent learning;artifact-embedded agent;artifacts learning;data reduction;data retrieval;exemplar-based learning;learning artifact;level order ranking scheme;machine learning dataset;on-demand data numerosity reduction;ranking-based stratified ordered selection method;resource constraint","","1","","10","","","26-29 March 2012","","IEEE","IEEE Conference Publications"
"Applying Multiclass Bandit algorithms to call-type classification","L. Ralaivola; B. Favre; P. Gotab; F. Bechet; G. Damnati","Aix Marseille Universite - LIF/CNRS, France","2011 IEEE Workshop on Automatic Speech Recognition & Understanding","20120305","2011","","","431","436","We analyze the problem of call-type classification using data that is weakly labelled. The training data is not systematically annotated, but we consider we have a weak or lazy oracle able to answer the question “Is sample x of class q?” by a simple `yes' or `no' answer. This situation of learning might be encountered in many real-world problems where the cost of labelling data is very high. We prove that it is possible to learn linear classifiers in this setting, by estimating adequate expectations inspired by the Multiclass Bandit paradgim. We propose a learning strategy that builds on Kessler's construction to learn multiclass perceptrons. We test our learning procedure against two real-world datasets from spoken langage understanding and provide compelling results.","","Electronic:978-1-4673-0367-5; POD:978-1-4673-0365-1; USB:978-1-4673-0366-8","10.1109/ASRU.2011.6163970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163970","","Equations;Labeling;Machine learning algorithms;Mathematical model;Prediction algorithms;Training;Vectors","learning (artificial intelligence);natural language processing;pattern classification;perceptrons;speech recognition","Kessler construction;call type classification;lazy oracle;linear classifier;multiclass bandit algorithms;multiclass perceptron;spoken dialog systems;training data;weak oracle","","2","","10","","","11-15 Dec. 2011","","IEEE","IEEE Conference Publications"
"Special Questions and techniques","J. M. Prager; E. W. Brown; J. Chu-Carroll","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20120403","2012","56","3.4","11:1","11:13","Jeopardy!™ questions represent a wide variety of question types. The vast majority are Standard Jeopardy! Questions, where the question contains one or more assertions about some unnamed entity or concept, and the task is to identify the described entity or concept. This style of question is a representative of a wide range of common question-answering tasks, and the bulk of the IBM Watson™ system is focused on solving this problem. A small percentage of Jeopardy! questions require a specialized procedure to derive an answer or some derived assertion about the answer. We call any question that requires such a specialized computational procedure, selected on the basis of a unique classification of the question, a Special Jeopardy! Question. Although Special Questions per se are typically less relevant in broader question-answering applications, they are an important class of question to address in the Jeopardy! context. Moreover, the design of our Special Question solving procedures motivated architectural design decisions that are applicable to general open-domain question-answering systems. We explore these rarer classes of questions here and describe and evaluate the techniques that we developed to solve these questions.","0018-8646;00188646","","10.1147/JRD.2012.2187392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6177732","","History;Inference algorithms;Information analysis;Machine learning;Object recognition;Probability;TV","","","","0","","18","","","May-June 2012","","IBM","IBM Journals & Magazines"
"Context-aware prompting from your smart phone","B. Das; B. L. Thomas; A. M. Seelye; D. J. Cook; L. B. Holder; M. Schmitter-Edgecombe","School of Electrical Engineering and Computer Science, Washington State University, USA","2012 IEEE Consumer Communications and Networking Conference (CCNC)","20120412","2012","","","56","57","Individuals with cognitive impairment have difficulty successfully performing activities of daily living, which can lead to decreased independence. In order to help these individuals age in place and decrease caregiver burden, technologies for assistive living have gained popularity over the last decade. This demo illustrates the implementation of a context-aware prompting system augmented by a smart phone to determine prompt situations in a smart home environment. While context-aware systems use temporal and environmental information to determine context, we additionally use ambulatory information from accelerometer data of a phone which also acts as a mobile prompting device.","2331-9852;23319852","Electronic:978-1-4577-2071-0; POD:978-1-4577-2070-3","10.1109/CCNC.2012.6181049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181049","activity recognition;context-aware prompting;smart homes;smart phones","Accelerometers;Context;Legged locomotion;Machine learning;Real time systems;Smart homes;Smart phones","handicapped aids;mobile computing;smart phones","accelerometer data;ambulatory information;assistive living;cognitive impairment;context-aware prompting;smart home environment;smart phone","","2","","5","","","14-17 Jan. 2012","","IEEE","IEEE Conference Publications"
"An efficient algorithm for rough sets positive region","S. Li; Feng Yongbao; Guo Xiaosong","School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an Research Institute of Hi-Tech, China","Proceedings 2011 International Conference on Transportation, Mechanical, and Electrical Engineering (TMEE)","20120514","2011","","","1411","1414","In rough sets theory, attribute reduction is considered as an important preprocessing step for machine learning, pattern recognition, and data mining. The algorithms of attribute reduction and attribute core on rough sets are main content of rough sets theory. Positive region algorithm is an important branch. Many positive region algorithms have been proposed, however the time and space complexity is relatively high. To overcome this shortcoming, we introduce the size of positive region algorithm and positive region algorithm based on the simplification decision table. In order to verify the efficiency of the algorithms, we design several efficient relative core algorithms. Experiments show the proposed methods have lower time complexity and space complexity. It is worth noting that the improvement becomes more profoundly visible when dealing with larger data sets.","","Electronic:978-1-4577-1701-7; POD:978-1-4577-1700-0","10.1109/TMEE.2011.6199471","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6199471","positive region;rough set;simplification decision table;space and time complexity","Algorithm design and analysis;Complexity theory;Educational institutions;Information systems;Machine learning algorithms;Rough sets;Software algorithms","computational complexity;data reduction;decision tables;learning (artificial intelligence);rough set theory","attribute reduction;data mining;machine learning;pattern recognition;positive region algorithm;rough set theory;simplification decision table;space complexity;time complexity","","0","","9","","","16-18 Dec. 2011","","IEEE","IEEE Conference Publications"
"Enhancement of multiple hypothesis tracking algorithm with C4.5 algorithm","Y. Ersoy; M. Efe; B. Nakiboğlu","Ayd&#x0131;n Yaz&#x0131;l&#x0131;m ve Elektronik Sanayi A.&#x015E;., Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","In this paper, the improvement provided by the utilization of C4.5 classification algorithm to the hypothesis generation process of the k-best Multi-Hypothesis Tracker (MHT) is investigated. It has been shown through simulations that the pre-filtering the measurements by the C4.5 algorithm, especially in high clutter scenarios, reduces the number of generated hypothesis by the MHT significantly.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204736","","Algorithm design and analysis;Machine learning;Machine learning algorithms;Radar tracking;Target tracking","computer vision;filtering theory;heuristic programming;image classification;image enhancement","C4.5 classification algorithm;enhancement;high clutter scenarios;multiple hypothesis tracking algorithm;pre-filtering","","0","","12","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
