"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7487165,7486356,7485680,7486476,7485271,7486506,7487116,7486210,7486545,7486460,7486592,7486358,7486461,7485147,7487607,7312936,7486110,7482124,7482110,7439855,7430292,7482805,7450160,7477677,7477448,7477595,7474877,7477679,7477558,7477624,7477625,7479310,7474373,7475384,7468458,7429688,7475867,7474340,7471285,7471715,7472134,7472577,7472768,7466062,7471631,7472174,7472122,7416633,7471613,7471930,7470121,7471897,7472857,7472165,7471892,7472173,7472746,7436783,7327212,7468955,7469130,7467366,7454703,7469174,7468968,7467312,7405343,7426845,7398101,7412749,7399414,7448418,7460397,7460569,7460664,7459357,7459170,7460666,7442576,7458333,7457876,7457870,7457855,7458185,7456692,7457004,7457118,7457147,7457169,7457111,7456783,7264998,7454745,7454554,7104152,7091956,7449810,7449802,7450554,7449601",2017/05/05 22:34:56
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"ZooplanktoNet: Deep convolutional network for zooplankton classification","J. Dai; R. Wang; H. Zheng; G. Ji; X. Qiao","College of Information Science and Engineering, Ocean University of China, Qingdao 266100, China","OCEANS 2016 - Shanghai","20160609","2016","","","1","6","Zooplankton are quite significant to the ocean ecosystem for stabilizing balance of the ecosystem and keeping the earth running normally. Considering the significance of zooplantkon, research about zooplankton has caught more and more attentions. And zooplankton recognition has shown great potential for science studies and mearsuring applications. However, manual recognition on zooplankton is labour-intensive and time-consuming, and requires professional knowledge and experiences, which can not scale to large-scale studies. Deep learning approach has achieved remarkable performance in a number of object recognition benchmarks, often achieveing the current best performance on detection or classification tasks and the method demonstrates very promising and plausible results in many applications. In this paper, we explore a deep learning architecture: ZooplanktoNet to classify zoolankton automatically and effectively. The deep network is characterized by capturing more general and representative features than previous predefined feature extraction algorithms in challenging classification. Also, we incorporate some data augmentation to aim at reducing the overfitting for lacking of zooplankton images. And we decide the zooplankton class according to the highest score in the final predictions of ZooplanktoNet. Experimental results demonstrate that ZooplanktoNet can solve the problem effectively with accuracy of 93.7% in zooplankton classification.","","Electronic:978-1-4673-9724-7; POD:978-1-4673-9725-4","10.1109/OCEANSAP.2016.7485680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7485680","","Ecosystems;Feature extraction;Machine learning;Object recognition;Oceans;Training;Visualization","ecology;feature extraction;geophysical image processing;image classification;microorganisms;oceanography","ZooplanktoNet;data augmentation;deep convolutional network;feature extraction algorithm;object recognition benchmark;ocean ecosystem;zooplankton classification;zooplankton images;zooplankton recognition","","1","","18","","","10-13 April 2016","","IEEE","IEEE Conference Publications"
"Multi-Instance Deep Learning: Discover Discriminative Local Anatomies for Bodypart Recognition","Z. Yan; Y. Zhan; Z. Peng; S. Liao; Y. Shinagawa; S. Zhang; D. N. Metaxas; X. S. Zhou","Department of Computer Science, Rutgers University, Piscataway, NJ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1332","1343","In general image recognition problems, discriminative information often lies in local image patches. For example, most human identity information exists in the image patches containing human faces. The same situation stays in medical images as well. “Bodypart identity” of a transversal slice-which bodypart the slice comes from-is often indicated by local image information, e.g., a cardiac slice and an aorta arch slice are only differentiated by the mediastinum region. In this work, we design a multi-stage deep learning framework for image classification and apply it on bodypart recognition. Specifically, the proposed framework aims at: 1) discover the local regions that are discriminative and non-informative to the image classification problem, and 2) learn a image-level classifier based on these local regions. We achieve these two tasks by the two stages of learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multi-instance learning fashion to extract the most discriminative and and non-informative local patches from the training slices. In the boosting stage, the pre-learned CNN is further boosted by these local patches for image classification. The CNN learned by exploiting the discriminative local appearances becomes more accurate than those learned from global image context. The key hallmark of our method is that it automatically discovers the discriminative and non-informative local patches through multi-instance deep learning. Thus, no manual annotation is required. Our method is validated on a synthetic dataset and a large scale CT dataset. It achieves better performances than state-of-the-art approaches, including the standard deep CNN.","0278-0062;02780062","","10.1109/TMI.2016.2524985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398101","CNN;discriminative local information discovery;multi-instance;multi-stage","Algorithm design and analysis;DICOM;Image analysis;Image recognition;Machine learning;Three-dimensional displays","cardiology;computerised tomography;face recognition;image classification;learning (artificial intelligence);medical image processing","aorta arch slice;body-part recognition;cardiac slice;convolutional neural network;discriminative information;discriminative local anatomies;discriminative local appearances;global image context;human faces;human identity information;image classification problem;image recognition problems;image-level classifier;large scale CT dataset;local image information;local image patches;mediastinum region;multiinstance deep learning;multiinstance learning fashion;multistage deep learning framework;prelearned CNN;pretrain stage;synthetic dataset;transversal slice","","5","","51","","20160203","May 2016","","IEEE","IEEE Journals & Magazines"
"A comparative study of robustness of deep learning approaches for VAD","S. Tong; H. Gu; K. Yu","Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, SpeechLab, Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","5695","5699","Voice activity detection (VAD) is an important step for real-world automatic speech recognition (ASR) systems. Deep learning approaches, such as DNN, RNN or CNN, have been widely used in model-based VAD. Although they have achieved success in practice, they are developed on different VAD tasks separately. Whilst VAD performance under noisy conditions, especially with unseen noise or very low SNR, are of great interest, there has no robustness comparison of different deep learning approaches so far. In this paper, to learn the robustness property, VAD models based on DNN, LSTM and CNN are thoroughly compared at both frame and segment level under various noisy conditions on Aurora 4, a commonly used speech corpus with rich noises. To improve the robustness of deep learning based VAD models, a new noise-aware training (NAT) approach is also proposed. Experiments show that LSTM-based VAD is most robust but the performance degrades dramatically in the conditions with unseen noise or diverse SNR. By incorporating NAT, significant performance gains can be obtained in these conditions.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472768","Deep learning;Robustness;VAD","Machine learning;Neural networks;Noise measurement;Robustness;Signal to noise ratio;Speech;Training","learning (artificial intelligence);recurrent neural nets;signal detection;speech recognition","ASR system;Aurora 4;CNN;DNN;LSTM-based VAD;NAT approach;RNN;Recurrent neural networks;convolutional neural network;deep learning approaches;deep neural networks;frame level;long short-term memory;model-based VAD;noise-aware training approach;noisy conditions;real-world automatic speech recognition systems;segment level;speech corpus;voice activity detection","","","","26","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"A coarse-to-fine deep learning for person re-identification","A. Franco; L. Oliveira","Intelligent Vision Research Lab, Federal University of Bahia","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","7","This paper proposes a novel deep learning architecture for person re-identification. The proposed network is based on a coarse-to-fine learning (CFL) approach, attempting to acquire a generic-to-specific knowledge throughout a transfer learning process. The core of the method relies on a hybrid network composed of a convolutional neural network and a deep belief network denoising autoenconder. This hybrid network is in charge of extracting features invariant to illumination varying, certain image deformations, horizontal mirroring and image blurring, and is embedded in the CFL architecture. The proposed network achieved the best results when compared with other state-of-the-arts methods on i-LIDS, CUHK01 and CUHK03 data sets, and also a competitive performance on VIPeR data set.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477677","","Face;Feature extraction;Lighting;Machine learning;Network topology;Noise measurement;Training","belief networks;computer vision;feature extraction;image denoising;learning (artificial intelligence);neural nets;object recognition","CFL approach;CFL architecture;CUHK01 data set;CUHK03 data set;VIPeR data set;coarse-to-fine deep learning;convolutional neural network;deep belief network denoising autoenconder;deep learning architecture;feature extraction;generic-to-specific knowledge;horizontal mirroring;i-LIDS data set;illumination varation;image blurring;image deformation;person reidentification;transfer learning process","","1","","28","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"A Cell Outage Management Framework for Dense Heterogeneous Networks","O. Onireti; A. Zoha; J. Moysen; A. Imran; L. Giupponi; M. Ali Imran; A. Abu-Dayya","Inst. for Commun. Syst., Univ. of Surrey, Guildford, UK","IEEE Transactions on Vehicular Technology","20160414","2016","65","4","2097","2113","In this paper, we present a novel cell outage management (COM) framework for heterogeneous networks with split control and data planes-a candidate architecture for meeting future capacity, quality-of-service, and energy efficiency demands. In such an architecture, the control and data functionalities are not necessarily handled by the same node. The control base stations (BSs) manage the transmission of control information and user equipment (UE) mobility, whereas the data BSs handle UE data. An implication of this split architecture is that an outage to a BS in one plane has to be compensated by other BSs in the same plane. Our COM framework addresses this challenge by incorporating two distinct cell outage detection (COD) algorithms to cope with the idiosyncrasies of both data and control planes. The COD algorithm for control cells leverages the relatively larger number of UEs in the control cell to gather large-scale minimization-of-drive-test report data and detects an outage by applying machine learning and anomaly detection techniques. To improve outage detection accuracy, we also investigate and compare the performance of two anomaly-detecting algorithms, i.e., k-nearest-neighbor- and local-outlier-factor-based anomaly detectors, within the control COD. On the other hand, for data cell COD, we propose a heuristic Grey-prediction-based approach, which can work with the small number of UE in the data cell, by exploiting the fact that the control BS manages UE-data BS connectivity and by receiving a periodic update of the received signal reference power statistic between the UEs and data BSs in its coverage. The detection accuracy of the heuristic data COD algorithm is further improved by exploiting the Fourier series of the residual error that is inherent to a Grey prediction model. Our COM framework integrates these two COD algorithms with a cell outage compensation (COC) algorithm that can be applied to both planes. Our COC solution utilizes an actor-critic-- ased reinforcement learning algorithm, which optimizes the capacity and coverage of the identified outage zone in a plane, by adjusting the antenna gain and transmission power of the surrounding BSs in that plane. The simulation results show that the proposed framework can detect both data and control cell outage and compensate for the detected outage in a reliable manner.","0018-9545;00189545","","10.1109/TVT.2015.2431371","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7104152","Cell outage compensation (COC);Self-organizing network;cell outage compensation;cell outage detection;cell outage detection (COD);cell outage management;cell outage management (COM);heterogeneous cellular network;self-healing;self-organizing network (SON)","Computer architecture;Data models;Machine learning algorithms;Microprocessors;Phase measurement;Power measurement;Time measurement","cellular radio;learning (artificial intelligence);minimisation;mobility management (mobile radio);quality of service;security of data;telecommunication computing;telecommunication security","COC algorithm;UE data handling;UE-data BS connectivity;actor-critic-based reinforcement learning algorithm;anomaly detection techniques;antenna gain adjustment;capacity optimization;cell outage compensation algorithm;cell outage detection algorithms;cell outage management framework;control base stations;control information transmission management;coverage optimization;data planes;dense heterogeneous networks;energy efficiency demands;grey-prediction-based approach;heuristic data COD algorithm;k-nearest-neighbor-based anomaly detectors;large-scale minimization-of-drive-test report data;local-outlier-factor-based anomaly detectors;machine learning;outage detection accuracy improvement;quality-of-service;split architecture;split control;transmission power adjustment;user equipment mobility management","","3","","49","","20150508","April 2016","","IEEE","IEEE Journals & Magazines"
"Salient Band Selection for Hyperspectral Image Classification via Manifold Ranking","Q. Wang; J. Lin; Y. Yuan","School of Computer Science and the Center for OPTical IMagery Analysis and Learning, Northwestern Polytechnical University, Xi&#x2019;an, China","IEEE Transactions on Neural Networks and Learning Systems","20160516","2016","27","6","1279","1289","Saliency detection has been a hot topic in recent years, and many efforts have been devoted in this area. Unfortunately, the results of saliency detection can hardly be utilized in general applications. The primary reason, we think, is unspecific definition of salient objects, which makes that the previously published methods cannot extend to practical applications. To solve this problem, we claim that saliency should be defined in a context and the salient band selection in hyperspectral image (HSI) is introduced as an example. Unfortunately, the traditional salient band selection methods suffer from the problem of inappropriate measurement of band difference. To tackle this problem, we propose to eliminate the drawbacks of traditional salient band selection methods by manifold ranking. It puts the band vectors in the more accurate manifold space and treats the saliency problem from a novel ranking perspective, which is considered to be the main contributions of this paper. To justify the effectiveness of the proposed method, experiments are conducted on three HSIs, and our method is compared with the six existing competitors. Results show that the proposed method is very effective and can achieve the best performance among the competitors.","2162-237X;2162237X","","10.1109/TNNLS.2015.2477537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436783","Band selection;deep learning;hyperspectral image (HSI) classification;manifold ranking (MR);saliency;stacked autoencoders (SAEs);stacked autoencoders (SAEs).","Adaptation models;Computer vision;Feature extraction;Hyperspectral imaging;Machine learning;Manifolds;Transforms","feature extraction;hyperspectral imaging;image classification;object detection","HSI;band difference measurement;band vectors;hyperspectral image classification;manifold ranking;saliency detection;salient band selection methods","","4","","53","","20160318","June 2016","","IEEE","IEEE Journals & Magazines"
"Linearized Kernel Dictionary Learning","A. Golts; M. Elad","Department of Electrical Engineering, Technion, Haifa, Israel","IEEE Journal of Selected Topics in Signal Processing","20160512","2016","10","4","726","739","In this paper, we present a new approach of incorporating kernels into dictionary learning. The kernel K-SVD algorithm (KKSVD), which has been introduced recently, shows an improvement in classification performance, with relation to its linear counterpart K-SVD. However, this algorithm requires the storage and handling of a very large kernel matrix, which leads to high computational cost, while also limiting its use to setups with small number of training examples. We address these problems by combining two ideas: first, we approximate the kernel matrix using a cleverly sampled subset of its columns using the Nyström method; second, as we wish to avoid using this matrix altogether, we decompose it by SVD to form new “virtual samples,” on which any linear dictionary learning can be employed. Our method, termed “Linearized Kernel Dictionary Learning” (LKDL) can be seamlessly applied as a preprocessing stage on top of any efficient off-the-shelf dictionary learning scheme, effectively “kernelizing” it. We demonstrate the effectiveness of our method on several tasks of both supervised and unsupervised classification and show the efficiency of the proposed scheme, its easy integration and performance boosting properties.","1932-4553;19324553","","10.1109/JSTSP.2016.2555241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454703","Dictionary Learning;KSVD;Kernel Dictionary Learning;Kernels;Supervised Dictionary Learning","Approximation algorithms;Dictionaries;Kernel;Machine learning algorithms;Optimization;Signal processing algorithms;Training","signal classification;singular value decomposition","KKSVD;LKDL;Nyström method;kernel K-SVD algorithm;kernel matrix;linearized kernel dictionary learning scheme;supervised classification;unsupervised classification","","","","57","","20160420","June 2016","","IEEE","IEEE Journals & Magazines"
"Big Data Analytics in Mobile Cellular Networks","Y. He; F. R. Yu; N. Zhao; H. Yin; H. Yao; R. C. Qiu","Department of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Access","20160520","2016","4","","1985","1996","Mobile cellular networks have become both the generators and carriers of massive data. Big data analytics can improve the performance of mobile cellular networks and maximize the revenue of operators. In this paper, we introduce a unified data model based on the random matrix theory and machine learning. Then, we present an architectural framework for applying the big data analytics in the mobile cellular networks. Moreover, we describe several illustrative examples, including big signaling data, big traffic data, big location data, big radio waveforms data, and big heterogeneous data, in mobile cellular networks. Finally, we discuss a number of open research challenges of the big data analytics in the mobile cellular networks.","2169-3536;21693536","","10.1109/ACCESS.2016.2540520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429688","Big data analytics;mobile cellular networks","Big data;Cellular networks;Data analytics;Machine learning;Mobile communication;Random matrix theory","Big Data;cellular radio;learning (artificial intelligence);matrix algebra;telecommunication computing","big data analytics;big heterogeneous data;big location data;big radio waveform data;big signaling data;big traffic data;machine learning;massive data generators;mobile cellular networks;operator revenue maximization;random matrix theory;unified data model","","4","","54","","20160309","2016","","IEEE","IEEE Journals & Magazines"
"Improving occupancy presence prediction via multi-label classification","F. C. Sangogboye; K. Imamovic; M. B. Kjærgaard","SDU Center for Energy Informatics, M&#8856;rsk McKinney M&#8856;ller Institute, University of Southern Denmark","2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)","20160421","2016","","","1","6","Heating and cooling of commercial buildings accounts for a large proportion of worldwide energy consumption. There exists an opportunity to reduce energy waste by improving the scheduling of heating, ventilation, and air conditioning (HVAC) based on occupancy. However, to enable this potential, we require more accurate methods for predicting occupancy to deliver the required level of comfort when rooms are occupied. This paper examines the novel use of multi-label classification (MLC) for predicting occupancy of rooms based on data from motion sensors. Stating the occupancy prediction problem as an MLC problem enables the use of existing MLC algorithms and provides a solid foundation for evaluating the performance of the predictive models. Our implemented algorithms are benchmarked against an existing occupancy prediction technique (PreHeat) on a dataset from two commercial buildings. The results show that PreHeat and Support Vector Machine (SVM) outperforms other algorithms for rooms with high occupancy frequency. Other machine learning algorithms outperform PreHeat and SVM for rooms with low occupancy frequency. In total, SVM provides a more robust performance than other algorithms with a significantly higher count of highest prediction accuracy for observed scenarios. Our experimental results also highlight that prediction performance for commercial buildings depends more on occupancy frequency than occupancy rate, and the occupancy state before the prediction horizon. By presenting more accurate algorithms for occupancy prediction, we hope to foster the development of more energy-efficient HVAC scheduling systems to reduce overall energy consumption.","","Electronic:978-1-5090-1941-0; POD:978-1-5090-1942-7","10.1109/PERCOMW.2016.7457147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457147","","Buildings;Feature extraction;Machine learning algorithms;Prediction algorithms;Predictive models;Sensors;Support vector machines","HVAC;building management systems;home automation;learning (artificial intelligence);pattern classification;support vector machines","MLC;PreHeat;SVM;building cooling;building heating;energy consumption;energy consumption reduction;energy waste reduction;energy-efficient HVAC scheduling systems;heating-ventilation-and-air-conditioning scheduling;machine learning algorithms;motion sensors;multilabel classification;occupancy frequency;occupancy state;performance evaluation;prediction horizon;room occupancy presence prediction improvement;support vector machine","","1","","13","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Fast Object Detection at Constrained Energy","J. Liu; Y. Huang; J. Peng; J. Yao; L. Wang","Jingyu Liu is with National Laboratory of Pattern Recognition, CAS Center for Excellence in Brain Science and Intelligence Technology, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China.(email:jingyu.liu@nlpr.ia.ac.cn)","IEEE Transactions on Emerging Topics in Computing","","2016","PP","99","1","1","Visual computing, e.g., automatic object detection, in mobile devices attracts more and more attention recently, in which fast models at constrained energy cost is a critical problem. In this paper, we introduce our work on designing models based on deep learning for 200 classes object detection in mobile devices, as well as exploring trade-off between accuracy and energy cost. In particular, we investigate several methods of extracting object proposals and integrate them into the fast-RCNN framework for object detection. Extensive experiments are conducted using the Jetson TK1 SOC platform and the Alienware- 15 laptop, including detailed parameters evaluation with respect to accuracy, energy cost and speed. From these experiments, we conclude how to obtain good balance between accuracy and energy cost, which might provide guidance to design effective and efficient object detection models on mobile devices.","2168-6750;21686750","","10.1109/TETC.2016.2577538","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486110","Object detection;constrained energy;fast-RCNN","Feature extraction;Graphics processing units;Machine learning;Mobile handsets;Object detection;Portable computers;Proposals","","","","","","","","20160607","","","IEEE","IEEE Early Access Articles"
"Label Distribution Learning","X. Geng","School of Computer Science and Engineering, Southeast University, Nanjing, China","IEEE Transactions on Knowledge and Data Engineering","20160602","2016","28","7","1734","1748","Although multi-label learning can deal with many problems with label ambiguity, it does not fit some real applications well where the overall distribution of the importance of the labels matters. This paper proposes a novel learning paradigm named label distribution learning (LDL) for such kind of applications. The label distribution covers a certain number of labels, representing the degree to which each label describes the instance. LDL is a more general learning framework which includes both single-label and multi-label learning as its special cases. This paper proposes six working LDL algorithms in three ways: problem transformation, algorithm adaptation, and specialized algorithm design. In order to compare the performance of the LDL algorithms, six representative and diverse evaluation measures are selected via a clustering analysis, and the first batch of label distribution datasets are collected and made publicly available. Experimental results on one artificial and 15 real-world datasets show clear advantages of the specialized algorithms, which indicates the importance of special design for the characteristics of the LDL problem.","1041-4347;10414347","","10.1109/TKDE.2016.2545658","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439855","Multi-label learning;label distribution learning;learning with ambiguity","Algorithm design and analysis;Clustering algorithms;Learning systems;Loss measurement;Machine learning algorithms;Prediction algorithms;Training","data handling;learning (artificial intelligence)","LDL;algorithm adaptation;clustering analysis;general learning framework;label distribution datasets;label distribution learning;multilabel learning;specialized algorithm design","","3","","53","","20160323","July 1 2016","","IEEE","IEEE Journals & Magazines"
"Discovery of facial motions using deep machine perception","A. Ghasemi; S. Denman; S. Sridharan; C. Fookes","Speech, Audio, Image and Video Technology (SAIVT) Laboratory, Queensland University of Technology, Australia","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","7","Deep, intuitive understanding of facial motions has the potential to provide an intelligent facial expression system as well as a unique encoding of the dynamics of facial actions. The most promising existing approaches rely on extracting hand crafted features; and existing approaches typically work best in constrained conditions and do not generalise well to varying environmental conditions which make them poorly suited to applications such as real-time human robot interactions. In this paper, we propose a multi-label deep learning based facial action detector, which along with a linear SVM classifier outperforms state of the art approaches such as HOG and LBP. We show that our approach can be generalized to other datasets by learning inner data structure, encoding facial actions, and providing a hierarchical representation of facial features. Our experimental results also demonstrate the efficiency of using image patches, which results in faster learning convergence while outperforms holistic approaches. We evaluate our proposed frame-work on the DISFA and CK+ datasets.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477448","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477448","","Convolution;Convolutional codes;Face;Feature extraction;Gold;Machine learning;Training","data structures;emotion recognition;face recognition;image classification;image coding;image representation;learning (artificial intelligence);support vector machines","CK+ datasets;DISFA datasets;data structure;deep machine perception;facial action encoding;facial motion discovery;hierarchical facial feature representation;intelligent facial expression system;linear SVM classifier;multilabel deep learning-based facial action detector","","","","39","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"Multiscale fully convolutional network with application to industrial inspection","X. Bian; S. N. Lim; N. Zhou","GE Global Research","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","8","In recent years, deep learning, particularly Convolutional Neural Network (CNN), has shown great efficacy for solving various vision tasks. In image segmentation, it has been demonstrated that a CNN can greatly outperform other approaches. However, special attention has to be paid towards setting various parameters in the CNN that affects the scale of the feature map generated at the last convolutional layer, where scale here refers to the ratio of the number of pixels in the original input image that correspond to each pixel in the feature map. Quite often, the optimal settings are tied to the specific problem on hand and can be fairly challenging to determine. To overcome such an issue, this paper proposes a multiscale Fully Convolutional Network (FCN) that combines networks trained at various scales, thereby allowing for conducting segmentation more generically. Moreover, such a multiscale architecture allows for incremental fine-tuning as more training images become available later on and new networks can be trained and added to the combined network. Such flexibility has great utility in applications such as industrial inspection, where training images may not be readily available initially, but yet requires a high level of accuracy. This paper will validate our findings by reporting the results that we have obtained by applying multiscale FCN to the inspection of aircraft engine part.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477595","","Aircraft propulsion;Blades;Image segmentation;Inspection;Machine learning;Semantics;Training","computer vision;feature extraction;image segmentation;inspection;learning (artificial intelligence);neural nets;production engineering computing","aircraft engine part;deep learning;feature map;image segmentation;industrial inspection;multiscale FCN;multiscale architecture;multiscale fully convolutional neural network","","","","18","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"Using Deep Learning for Energy Expenditure Estimation with wearable sensors","J. Zhu; A. Pande; P. Mohapatra; J. J. Han","Department of Computer Science, University of California at Davis, 95616, United States","2015 17th International Conference on E-health Networking, Application & Services (HealthCom)","20160419","2015","","","501","506","Energy Expenditure (EE) Estimation is an important step in tracking personal activity and preventing chronic diseases such as obesity, diabetes and cardiovascular diseases. Accurate and online EE estimation using small wearable sensors is a difficult task, primarily because most existing schemes work offline or using heuristics. In this work, we focus on accurate EE estimation for tracking ambulatory activities (walking, standing, climbing upstairs or downstairs) of individuals wearing mobile sensors. We use Convolution Neural Networks (CNNs) to automatically detect important features from data collected from triaxial accelerometer and heart rate sensors. Using CNNs, we find a significant improvement in EE estimation compared to other state-of-the-art models. We compare our results against state-of-the-art Activity-Specific Linear Regression as well as Artificial Neural Networks (ANN) based models. Using a universal CNN model, we obtain an overall low Root Mean Square Error (RMSE) of 1.12 which is 30% and 35% lower than existing models. The results were calibrated against a COSMED K4b2 indirect calorimeter readings.","","Electronic:978-1-4673-8325-7; POD:978-1-4673-8326-4","10.1109/HealthCom.2015.7454554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454554","","Accelerometers;Estimation;Feature extraction;Heart rate;Machine learning;Neural networks;Sensors","accelerometers;biomedical equipment;calibration;cardiology;feature extraction;learning (artificial intelligence);medical computing;neural nets;sensors","COSMED K4b2 indirect calorimeter readings;ambulatory activity tracking;calibration;chronic diseases;convolution neural networks;deep learning;energy expenditure estimation;feature detection;heart rate sensors;mobile sensors;personal activity tracking;root mean square error;standing;triaxial accelerometer;walking;wearable sensors","","","","22","","","14-17 Oct. 2015","","IEEE","IEEE Conference Publications"
"A density based cluster extension method","J. Hou; C. Sha; L. Chi; H. Cui","College of Engineering, Bohai University, Jinzhou, China, 121013","2016 IEEE International Conference on Industrial Technology (ICIT)","20160526","2016","","","932","937","Although numerous clustering algorithms can be found in literature, most of existing algorithms require one or more parameters as input, and their clustering performance usually depends heavily on user-specified parameters. Although some methods have been proposed to determine these parameters automatically, the parameter-tuning problem is still open in general. As a graph-theoretic approach to clustering, the dominant set algorithm uses the pariwise data similarity matrix as input and determines the number of clusters automatically. Although the dominant set algorithm does not require any parameter input explicitly, its clustering results have been found to be influenced by a similarity parameter. In this paper we firstly apply histogram equalization transformation to similarity matrices to remove the dependence on clustering results, and then extend the clusters to obtain better clustering quality. Data clustering experiments validate the effectiveness of our algorithm.","","Electronic:978-1-4673-8075-1; POD:978-1-4673-8076-8","10.1109/ICIT.2016.7474877","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474877","","Clustering algorithms;Data mining;Histograms;Machine learning algorithms;Partitioning algorithms;Shape;Tuning","graph theory;matrix algebra;pattern clustering","data clustering experiments;density based cluster extension method;dominant set algorithm;graph-theoretic approach;histogram equalization transformation;pairwise data similarity matrix;parameter-tuning problem;user-specified parameters","","","","30","","","14-17 March 2016","","IEEE","IEEE Conference Publications"
"Improved activity recognition by using grouped activities","A. Jahn; K. David","Chair for Communication Technology (ComTec) Faculty of Electrical Engineering and Computer Science, University of Kassel, Germany","2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)","20160421","2016","","","1","5","The information of a person's activity can be used for a multitude of application. Thus, the activity recognition and the improvement of the activity recognition performance is a focus of research. Unfortunately, activities similar to each other are still likely to be mixed up during the activity recognition, resulting in a decrease in activity recognition performance. We propose a lightweight method to improve the recognition performance. By reevaluating recognized activities, we group similar activities to a new activity. We refer the created activity as grouped activity. We evaluate our method with an activity-set of seven activities and compare the results with two common approaches: the average recognition performance of the individual activities and the recognition performance using a generalized activity. We show an F-Measure improvement of up to 6.6 % by using the grouped activity.","","Electronic:978-1-5090-1941-0; POD:978-1-5090-1942-7","10.1109/PERCOMW.2016.7457111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457111","activity awareness;activity evaluation;activity group;activity recognition;group activities","Accelerometers;Legged locomotion;Machine learning algorithms;Magnetic sensors;Mathematical model","accelerometers;gait analysis;magnetometers;sensor fusion","F-Measure improvement;accelerometer;generalized activity;group similar activities;improved activity recognition;machine learning algorithms;magnetometer;person activity information;sensor fusion","","","","14","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Deep learning based primary user classification in Cognitive Radios","Y. Cui; X. j. Jing; S. Sun; X. Wang; D. Cheng; H. Huang","Key Laboratory of Trustworthy Distributed Computing and service (BUPT), Ministry of Education, Beijing University of Posts and Telecommunications, China","2015 15th International Symposium on Communications and Information Technologies (ISCIT)","20160425","2015","","","165","168","Deep Belief Networks (DBN) is a very powerful algorithm in deep learning. The DBN has been effectively applied in many areas of machine learning, such as computer vision (CV) and natural language processing (NLP). With the help of deep architecture, their accuracy has been largely improved and their human annotation data which traditional machine learning algorithm extremely rely on could be reduced. In Cognitive Radios (CRs), learning is necessary for its cognition, while two of the key challenges are how to classify primary user agents with their performances and predict their behaviors. The CRs' performance has a positive correlation with the hit rate of learning algorithm's classification and prediction results. In this paper, we study the questions of classification and prediction of user agents. We apply the DBN model to improve accuracy rating of user agent's recognition in CRs with user-centered model, it's the first application of deep learning structure in CRs. The DBN model provides a primary user agent's classification, which is the foundation of the prediction to both idle frequency spectrums and time slots. Experimental results show that the cognitive engine finds a much better detection rate than the CRs engine with shallow learning and other traditional strategy. The simulation results are also tested on the WIFI channel with 5GHz and 2.4GHz.","","Electronic:978-1-4673-6820-9; POD:978-1-4673-6821-6; USB:978-1-4673-6819-3","10.1109/ISCIT.2015.7458333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458333","cognitive radio;deep belief networks;deep learning;spectrum sensing","Artificial neural networks;Classification algorithms;Machine learning;Machine learning algorithms;Prediction algorithms;Sensors;Training","cognitive radio;learning (artificial intelligence)","DBN model;WIFI channel;cognitive radios;computer vision;deep belief learning based primary user classification;idle frequency spectrums;machine learning;natural language processing;time slots;user-centered model","","","","12","","","7-9 Oct. 2015","","IEEE","IEEE Conference Publications"
"Towards Deep Developmental Learning","O. Sigaud; A. Droniou","Sorbonne Universit&#x00E9;s UPMC Univ Paris 06, UMR 7222, Paris, France","IEEE Transactions on Cognitive and Developmental Systems","20160608","2016","8","2","99","114","Deep learning techniques are having an undeniable impact on general pattern recognition issues. In this paper, from a developmental robotics perspective, we scrutinize deep learning techniques under the light of their capability to construct a hierarchy of meaningful multimodal representations from the raw sensors of robots. These investigations reveal the differences between the methodological constraints of pattern recognition and those of developmental robotics. In particular, we outline the necessity to rely on unsupervised rather than supervised learning methods and we highlight the need for progress towards the implementation of hierarchical predictive processing capabilities. Based on these new tools, we outline the emergence of a new domain that we call deep developmental learning.","2379-8920;23798920","","10.1109/TAMD.2015.2496248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312936","Affordances;deep learning;developmental robotics;hierarchical predictive processing;sensorimotor contingencies","Biological neural networks;Computer architecture;Machine learning;Neurons;Pattern recognition;Robot sensing systems","pattern recognition;robots;unsupervised learning","deep developmental learning;developmental robotics perspective;general pattern recognition issues;hierarchical predictive processing capabilities;methodological constraints;multimodal representations;raw sensors;unsupervised learning method","","3","","164","","20151030","June 2016","","IEEE","IEEE Journals & Magazines"
"Robust Single Image Super-Resolution via Deep Networks With Sparse Prior","D. Liu; Z. Wang; B. Wen; J. Yang; W. Han; T. S. Huang","Department of Electrical and Computer EngineeringBeckman Institute, University of Illinois at Urbana&#8211;Champaign, Urbana, IL, USA","IEEE Transactions on Image Processing","20160519","2016","25","7","3194","3207","Single image super-resolution (SR) is an ill-posed problem, which tries to recover a high-resolution image from its low-resolution observation. To regularize the solution of the problem, previous methods have focused on designing good priors for natural images, such as sparse representation, or directly learning the priors from a large data set with models, such as deep neural networks. In this paper, we argue that domain expertise from the conventional sparse coding model can be combined with the key ingredients of deep learning to achieve further improved results. We demonstrate that a sparse coding model particularly designed for SR can be incarnated as a neural network with the merit of end-to-end optimization over training data. The network has a cascaded structure, which boosts the SR performance for both fixed and incremental scaling factors. The proposed training and testing schemes can be extended for robust handling of images with additional degradation, such as noise and blurring. A subjective assessment is conducted and analyzed in order to thoroughly evaluate various SR techniques. Our proposed model is tested on a wide range of images, and it significantly outperforms the existing state-of-the-art methods for various scaling factors both quantitatively and perceptually.","1057-7149;10577149","","10.1109/TIP.2016.2564643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7466062","Image super-resolution;deep neural networks;image super-resolution;sparse coding","Degradation;Dictionaries;Image coding;Image resolution;Machine learning;Neural networks;Training","image coding;image resolution;neural nets","cascaded structure;conventional sparse coding;deep learning;deep neural networks;end-to-end optimization;fixed scaling factors;ill-posed problem;incremental scaling factors;key ingredients;low-resolution observation;natural images;robust single image super-resolution;sparse prior;subjective assessment;training data","","4","","50","","20160506","July 2016","","IEEE","IEEE Journals & Magazines"
"Group-Based Alternating Direction Method of Multipliers for Distributed Linear Classification","H. Wang; Y. Gao; Y. Shi; R. Wang","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China.","IEEE Transactions on Cybernetics","","2016","PP","99","1","15","The alternating direction method of multipliers (ADMM) algorithm has been widely employed for distributed machine learning tasks. However, it suffers from several limitations, e.g., a relative low convergence speed, and an expensive time cost. To this end, in this paper, a novel method, namely the group-based ADMM (GADMM), is proposed for distributed linear classification. In particular, to accelerate the convergence speed and improve global consensus, a group layer is first utilized in GADMM to divide all the slave nodes into several groups. Then, all the local variables (from the slave nodes) are gathered in the group layer to generate different group variables. Finally, by using a weighted average method, the group variables are coordinated to update the global variable (from the master node) until the solution of the global problem is reached. According to the theoretical analysis, we found that: 1) GADMM can mathematically converge at the rate O(1/k), where k is the number of outer iterations and 2) by using the grouping methods, GADMM can improve the convergence speed compared with the distributed ADMM framework without grouping methods. Moreover, we systematically evaluate GADMM on four publicly available LIBSVM datasets. Compared with disADMM and stochastic dual coordinate ascent with alternating direction method of multipliers-ADMM, for distributed classification, GADMM is able to reduce the number of outer iterations, which leads to faster convergence speed and better global consensus. In particular, the statistical significance test has been experimentally conducted and the results validate that GADMM can significantly save up to 30% of the total time cost (with less than 0.6% accuracy loss) compared with disADMM on large-scale datasets, e.g., webspam and epsilon.","2168-2267;21682267","","10.1109/TCYB.2016.2570808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482805","Alternating direction method of multipliers (ADMM);distributed linear classification;group-based ADMM (GADMM);support vector machine (SVM)","Convergence;Cybernetics;Machine learning algorithms;Optimization;Peer-to-peer computing;Software;Support vector machines","","","","","","","","20160601","","","IEEE","IEEE Early Access Articles"
"A hybrid method for dimensionality reduction in microarray data based on advanced binary ant colony algorithm","A. Rouhi; H. Nezamabadi-pour","Department of Electrical Engineering, Shahid Bahonar University of Kerman, Kerman, Iran","2016 1st Conference on Swarm Intelligence and Evolutionary Computation (CSIEC)","20160602","2016","","","70","75","The advent and proliferation of high-dimensional data have drawn the attention of researchers toward the subject of feature selection in machine learning and data mining. Increased number of irrelevant and redundant features has decreased the accuracy of classifiers, increased their computational cost and reinforced the ""curse of dimensionality"". This paper proposes a hybrid method, where first a number of filter methods reduce the dimensionality of features and then the advanced binary ant colony (ABACOh) meta-heuristic algorithm runs on the set of reduced features to select the most effective feature subset. Performance of the proposed method is measured by the applying on the five well-known high-dimensional microarray datasets and the results are compared with those of several state-of-the-art methods. The obtained results confirm the effectiveness of the proposed algorithm.","","Electronic:978-1-4673-8737-8; POD:978-1-4673-8738-5","10.1109/CSIEC.2016.7482124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482124","ensemble methods;feature selection;filter methods;high-dimensional data;hybrid methods;meta-heuristic methods","Ant colony optimization;Classification algorithms;Correlation;Filtering algorithms;Information filters;Machine learning algorithms","ant colony optimisation;data mining;feature selection;learning (artificial intelligence)","ABACOh meta-heuristic algorithm;advanced binary ant colony algorithm;computational cost;data mining;dimensionality reduction;feature selection;high-dimensional data;machine learning;microarray data","","","","27","","","9-11 March 2016","","IEEE","IEEE Conference Publications"
"Research of Food Safety Event Detection Based on Multiple Data Sources","F. Li; Y. Lv; Q. Zhu; X. Lin","Eng. Res. Center of Intell. Process Syst. Eng., BUCT, Beijing, China","2015 International Conference on Cloud Computing and Big Data (CCBD)","20160409","2015","","","213","216","Online event detection techniques are usually used in single data source. This paper analyzes event detection in the perspective of multiple data sources, combining news reports and microblogs. Detect events from news, combining microblogs to do event monitoring and early warning. Also improve feature selection methods for multiple data sources event detection. Finally, the methods are applied to the detection of food safety events and the results of the research show that event detection with multiple data sources is meaningful and valuable.","","Electronic:978-1-4673-8350-9; POD:978-1-4673-8351-6","10.1109/CCBD.2015.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450554","event detection;food safety;sentiment analysis;single-pass","Algorithm design and analysis;Clustering algorithms;Crawlers;Event detection;Machine learning algorithms;Safety;Sentiment analysis","Web sites;feature selection;food safety;sentiment analysis","early warning;event monitoring;feature selection method improvement;food safety event detection;microblogs;multiple data sources;news reports;online event detection techniques","","","","9","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios","D. Li; X. Chen; K. Huang","CRIPAC & NLPR, CASIA","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","111","115","In real video surveillance scenarios, visual pedestrian attributes, such as gender, backpack, clothes types, are very important for pedestrian retrieval and person reidentification. Existing methods for attributes recognition have two drawbacks: (a) handcrafted features (e.g. color histograms, local binary patterns) cannot cope well with the difficulty of real video surveillance scenarios; (b) the relationship among pedestrian attributes is ignored. To address the two drawbacks, we propose two deep learning based models to recognize pedestrian attributes. On the one hand, each attribute is treated as an independent component and the deep learning based single attribute recognition model (DeepSAR) is proposed to recognize each attribute one by one. On the other hand, to exploit the relationship among attributes, the deep learning framework which recognizes multiple attributes jointly (DeepMAR) is proposed. In the DeepMAR, one attribute can contribute to the representation of other attributes. For example, the gender of woman can contribute to the representation oflong hair and wearing skirt. Experiments on recent popular pedestrian attribute datasets illustrate that our proposed models achieve the state-of-the-art results.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486476","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486476","","Computational modeling;Hair;Machine learning;Pattern recognition;Surveillance;Training;Visualization","independent component analysis;learning (artificial intelligence);pedestrians;video surveillance","deep learning based single attribute recognition model;independent component;multi attribute learning;pedestrian attribute recognition;pedestrian retrieval;person reidentification;real video surveillance scenarios;visual pedestrian attributes","","1","","21","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Algorithms for ligand based virtual screening in drug discovery","K. Babaria; S. Ambegaokar; S. Das; H. Palivela","IT Department, MPSTME, NMIMS, Mumbai, India","2015 International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)","20160421","2015","","","862","866","Machine learning can play a very important role in various crucial applications like data mining and pattern recognition. Machine learning techniques have been widely used in drug discovery and development, particularly in the areas of chemo-informatics, bioinformatics and other types of pharmaceutical research. It has been demonstrated that they are suitable for large high dimensional data, and the models built with these methods can be used for robust external predictions. This paper discusses on how the machine learning techniques, especially Support Vector Machines, are going to be applied on the data sets with the help of graph kernels. These graph kernels are used to compare substructures of graphs that are computable in polynomial time.","","Electronic:978-1-4673-9223-5; POD:978-1-4673-9224-2; USB:978-1-4673-9222-8","10.1109/ICATCCT.2015.7457004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457004","Kernel;SVM","Classification algorithms;Compounds;Decision trees;Drugs;Kernel;Machine learning algorithms;Support vector machines","bioinformatics;data handling;drugs;graph theory;learning (artificial intelligence);support vector machines","bioinformatics;chemo-informatics;drug development;drug discovery;graph kernels;ligand based virtual screening;machine learning;pharmaceutical research;polynomial time;support vector machines","","","","9","","","29-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"From smart to deep: Robust activity recognition on smartwatches using deep learning","S. Bhattacharya; N. D. Lane","Bell Labs","2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)","20160421","2016","","","1","6","The use of deep learning for the activity recognition performed by wearables, such as smartwatches, is an understudied problem. To advance current understanding in this area, we perform a smartwatch-centric investigation of activity recognition under one of the most popular deep learning methods - Restricted Boltzmann Machines (RBM). This study includes a variety of typical behavior and context recognition tasks related to smartwatches (such as transportation mode, physical activities and indoor/outdoor detection) to which RBMs have previously never been applied. Our findings indicate that even a relatively simple RBM-based activity recognition pipeline is able to outperform a wide-range of common modeling alternatives for all tested activity classes. However, usage of deep models is also often accompanied by resource consumption that is unacceptably high for constrained devices like watches. Therefore, we complement this result with a study of the overhead of specifically RBM-based activity models on representative smartwatch hardware (the Snapdragon 400 SoC, present in many commercial smartwatches). These results show, contrary to expectation, RBM models for activity recognition have acceptable levels of resource use for smartwatch-class hardware already on the market. Collectively, these two experimental results make a strong case for more widespread adoption of deep learning techniques within smartwatch designs moving forward.","","Electronic:978-1-5090-1941-0; POD:978-1-5090-1942-7","10.1109/PERCOMW.2016.7457169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457169","","Computational modeling;Machine learning;Mathematical model;Mobile communication;Pipelines;Sensors;Transportation","Boltzmann machines;learning (artificial intelligence);mobile computing;smart phones;watches;wearable computers","RBM models;RBM-based activity models;RBM-based activity recognition pipeline;Snapdragon 400 SoC;deep learning techniques;indoor-outdoor detection;physical activities;resource consumption;restricted Boltzmann machines;robust activity recognition;smartwatch hardware;smartwatch-centric investigation;transportation mode","","","","34","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Deep learning for HRRP-based target recognition in multistatic radar systems","J. Lundén; V. Koivunen","Aalto University, School of Electrical Engineering, Department of Signal Processing and Acoustics, Espoo, Finland","2016 IEEE Radar Conference (RadarConf)","20160609","2016","","","1","6","In this paper, a deep learning approach is proposed for target recognition based on high range resolution profiles (HRRPs) in multistatic radar systems. The proposed deep learning approach employs deep convolutional neural networks to automatically extract features from the HRRPs. In a multistatic radar system the target can be observed from multiple aspect angles simultaneously which improves the reliability and robustness of target recognition. In this paper, the spatial diversity offered by a multistatic radar system is exploited by averaging the slocal classifier output probabilities from the different monostatic and bistatic transmitter/receiver pairs. The highest global target probability is compared to a threshold to decide whether the target is classified to one of the preknown classes or as unknown. Simulation results show that the proposed deep learning approach has very reliable classification performance even at low signal-to-noise ratios.","","Electronic:978-1-5090-0863-6; POD:978-1-5090-0864-3","10.1109/RADAR.2016.7485271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7485271","","Machine learning;Multistatic radar;Neural networks;Radar cross-sections;Reliability;Target recognition","feature extraction;learning (artificial intelligence);neural nets;probability;radar computing;radar receivers;radar resolution;radar signal processing;radar target recognition;radar transmitters;signal classification","HRRP-based target recognition;bistatic transmitter-receiver pair;deep convolutional neural network;deep learning approach;feature extraction;high range resolution profile;monostatic transmitter-receiver pair;multistatic radar system;signal-to-noise ratio;spatial diversity;target probability;target recognition reliability","","","","18","","","2-6 May 2016","","IEEE","IEEE Conference Publications"
"Anomaly detection in aircraft data using Recurrent Neural Networks (RNN)","A. Nanduri; L. Sherry","Center for Air Transportation Systems Research (CATSR) at George Mason University (GMU), Fairfax, Virginia, USA","2016 Integrated Communications Navigation and Surveillance (ICNS)","20160609","2016","","","5C2-1","5C2-8","Anomaly Detection in multivariate, time-series data collected from aircraft's Flight Data Recorder (FDR) or Flight Operational Quality Assurance (FOQA) data provide a powerful means for identifying events and trends that reduce safety margins. The industry standard “Exceedance Detection” algorithm uses a list of specified parameters and their thresholds to identify known deviations. In contrast, Machine Learning algorithms detect unknown unusual patterns in the data either through semi-supervised or unsupervised learning. The Multiple Kernel Anomaly Detection (MKAD) algorithm based on One-class SVM identified 6 of 11 canonical anomalies in a large dataset but is limited by the need for dimensionality reduction, poor sensitivity to short term anomalies, and inability to detect anomalies in latent features. This paper describes the application of Recurrent Neural Networks (RNN) with Long Term Short Term Memory (LTSM) and Gated Recurrent Units (GRU) architectures which can overcome the limitations described above. The RNN algorithms detected 9 out the 11 anomalies in the test dataset with Precision = 1, Recall = 0.818 and F1 score = 0.89. RNN architectures, designed for time-series data, are suited for implementation on the flight deck to provide real-time anomaly detection. The implications of these results are discussed.","","Electronic:978-1-5090-2149-9; POD:978-1-5090-2150-5","10.1109/ICNSURV.2016.7486356","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486356","","Feature extraction;Kernel;Logic gates;Machine learning algorithms;Recurrent neural networks;Support vector machines;Training","aerospace computing;air safety;recurrent neural nets;support vector machines;time series","FDR;FOQA data;GRU architecture;LTSM;MKAD;RNN;SVM;aircraft data;aircraft flight data recorder;dimensionality reduction;exceedance detection algorithm;flight operational quality assurance;gated recurrent unit architecture;long term short term memory;multiple kernel anomaly detection;multivariate time series data;recurrent neural network","","1","","17","","","19-21 April 2016","","IEEE","IEEE Conference Publications"
"Device-free wireless localization and activity recognition with deep learning","X. Zhang; J. Wang; Q. Gao; X. Ma; H. Wang","Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China 116023","2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)","20160421","2016","","","1","5","Recent advance in device-free wireless localization and activity recognition (DFLAR) technique has made it possible to acquire context information of the target without its participation. This novel technique has great potential for lots of applications, e.g., smart space, smart home, and security safeguard. One fundamental question of DFLAR is how to design discriminative features to characterize the raw wireless signal. Existing works manually design handcraft features, e.g., mean and variance of the raw signal, which is not universal for different activities. Inspired by the deep learning theory, we explore to learn universal and discriminative features automatically with a deep learning model. By merging the learned new features into a softmax regression based machine learning framework, we develop a deep learning based DFLAR system. Experimental evaluations with an 8 wireless nodes testbed confirms that compared with traditional handcraft features, DFLAR system with the learned features could achieve better performance.","","Electronic:978-1-5090-1941-0; POD:978-1-5090-1942-7","10.1109/PERCOMW.2016.7457118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457118","","Communication system security;Cost function;Electrical engineering;Feature extraction;Machine learning;Wireless communication;Wireless sensor networks","RSSI;discrete wavelet transforms;feature extraction;learning (artificial intelligence);regression analysis;signal denoising","DFLAR;DWT;RSSI;deep learning;device-free wireless localization and activity recognition;discrete wavelet transform;raw wireless signal;signal denoising;softmax regression-based machine learning framework","","","","8","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Microblog Dimensionality Reduction—A Deep Learning Approach","L. Xu; C. Jiang; Y. Ren; H. H. Chen","Department of Computer Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","20160602","2016","28","7","1779","1789","Exploring potentially useful information from huge amount of textual data produced by microblogging services has attracted much attention in recent years. An important preprocessing step of microblog text mining is to convert natural language texts into proper numerical representations. Due to the short-length characteristics of microblog texts, using term frequency vectors to represent microblog texts will cause “sparse data” problem. Finding proper representations of microblog texts is a challenging issue. In this paper, we apply deep networks to map the high-dimensional representations of microblog texts to low-dimensional representations. To improve the result of dimensionality reduction, we take advantage of the semantic similarity derived from two types of microblogspecific information, namely the retweet relationship and hashtags. Two types of approaches, including modifying training data and modifying the training objective of deep networks, are proposed to make use of microblog-specific information. Experiment results show that the deep models perform better than traditional dimensionality reduction methods such as latent semantic analysis and latent Dirichlet allocation topic model, and the use of microblog-specific information can help to learn better representations.","1041-4347;10414347","","10.1109/TKDE.2016.2540639","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7430292","Deep autoencoder;Dimension reduction;Microblog mining;Semantic relatedness;Text representation;deep autoencoder;dimension reduction;semantic relatedness;text representation","Electronic mail;Machine learning;Semantics;Tagging;Text mining;Training;Twitter","Web sites;data mining;text analysis","deep learning approach;latent Dirichlet allocation topic model;latent semantic analysis;low-dimensional representations;microblog dimensionality reduction;microblog text mining;natural language texts;numerical representations;sparse data problem;term frequency vectors","","","","36","","20160310","July 1 2016","","IEEE","IEEE Journals & Magazines"
"My camera can see through fences: A deep learning approach for image de-fencing","S. Jonna; K. K. Nakka; R. R. Sahay","School of Information Technology, Indian Institute of Technology Kharagpur, Kharagpur, India","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","261","265","In recent times, the availability of inexpensive image capturing devices such as smartphones/tablets has led to an exponential increase in the number of images/videos captured. However, sometimes the amateur photographer is hindered by fences in the scene which have to be removed after the image has been captured. Conventional approaches to image de-fencing suffer from inaccurate and non-robust fence detection apart from being limited to processing images of only static occluded scenes. In this paper, we propose a semi-automated de-fencing algorithm using a video of the dynamic scene. We use convolutional neural networks for detecting fence pixels. We provide qualitative as well as quantitative comparison results with existing lattice detection algorithms on the existing PSU NRT data set [1] and a proposed challenging fenced image dataset. The inverse problem offence removal is solved using split Bregman technique assuming total variation of the de-fenced image as the regularization constraint.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486506","","Cameras;Databases;Dynamics;Heuristic algorithms;Machine learning;Robustness;Training","cameras;feature extraction;image capture;neural nets","PSU NRT data set;amateur photographer;camera;convolutional neural network;deep learning approach;fence detection;fence pixel detection;fence removal;fenced image dataset;image capture;image de-fencing;inexpensive image capturing device availability;inverse problem;regularization constraint;semiautomated de-fencing algorithm;split Bregman technique;static occluded scene;video capture","","","","21","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Deep clustering: Discriminative embeddings for segmentation and separation","J. R. Hershey; Z. Chen; J. Le Roux; S. Watanabe","Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA 02139, USA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","31","35","We address the problem of ""cocktail-party"" source separation in a deep learning framework called deep clustering. Previous deep network approaches to separation have shown promising performance in scenarios with a fixed number of sources, each belonging to a distinct signal class, such as speech and noise. However, for arbitrary source classes and number, ""class-based"" methods are not suitable. Instead, we train a deep network to assign contrastive embedding vectors to each time-frequency region of the spectrogram in order to implicitly predict the segmentation labels of the target spectrogram from the input mixtures. This yields a deep network-based analogue to spectral clustering, in that the embeddings form a low-rank pair-wise affinity matrix that approximates the ideal affinity matrix, while enabling much faster performance. At test time, the clustering step ""decodes"" the segmentation implicit in the embeddings by optimizing K-means with respect to the unknown assignments. Preliminary experiments on single-channel mixtures from multiple speakers show that a speaker-independent model trained on two-speaker mixtures can improve signal quality for mixtures of held-out speakers by an average of 6dB. More dramatically, the same model does surprisingly well with three-speaker mixtures.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471631","clustering;deep learning;embedding;speech separation","Indexes;Machine learning;Neural networks;Spectrogram;Speech;Time-frequency analysis;Training","optimisation;source separation","contrastive embedding vectors;deep clustering;discriminative embeddings;low-rank pair-wise affinity matrix;segmentation labels;signal quality;single-channel mixtures;source separation;spectrogram;time-frequency region","","","","33","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"LDADEEP+: Latent aspect discovery with deep representations","C. E. Tsai; H. L. Hsieh; W. Hsu","National Taiwan University, Taipei, Taiwan","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","2732","2736","Nowadays, with the success and fast growth of social media communities and mobile devices, people are encouraged to share their multimedia data online. Analyzing and summarizing data into useful information thus becomes increasingly important. For online photo sharing services like Flickr, when users are uploading a batch of daily photos at a time, the tags users provided tend to be rather vague, containing only a small amount of information. For better photo application and understanding, we attempt to automatically discover semantic-rich (hidden) aspects of photos merely by looking at image contents. In this paper, we propose an effective model, which is a combination of LDA model and deep learning representations, to realize the idea of automatic aspect discovery. We then discuss the properties of this aspect discovery model through experiments on event summarization task. In those experiments, we show the high diversity and high quality of aspects discovered by our proposed method. Meanwhile, we conduct an user study to evaluate the quality of the summarized results. Moreover, the proposed method can be further extended to human attribute discovery for a given event. We automatically discover different aspects on our Olympic Games data (e.g. football, ice skating).","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472174","Aspect discovery;LDA;deep representation;event summarization","Buildings;Computational modeling;Feature extraction;Lakes;Machine learning;Media;Semantics","image representation;social networking (online)","automatic aspect discovery;deep learning representations;event summarization task;latent aspect discovery with deep representations","","","","14","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"A clustering algorithm based on integration of K-Means and PSO","H. A. Atabay; M. J. Sheikhzadeh; M. Torshizi","Computer Department, Gonbad Kavous University, Gonbad Kavous, Iran","2016 1st Conference on Swarm Intelligence and Evolutionary Computation (CSIEC)","20160602","2016","","","59","63","Clustering data are one of the key issues in data mining that has attracted much attention. One of the famous algorithms in this field is K-Means clustering that has been successfully applied to many problems. But this method has its own disadvantages, such as the dependence of the efficiency of this method to initialization of cluster centers. To improve the quality of K-Means, hybridization of this algorithm with other methods suggested by many researchers. Particle Swarm Optimization (PSO) is one of Swarm Intelligence (SI) algorithms that has been combined with K-Means in various ways. In this paper, we suggest another way of combining K-Means and PSO, using the strength of both algorithms. Most of the methods introduced in the context of clustering, that hybridized K-Means and PSO, used them sequentially, but in this paper we applied them intertwined. The results of the investigation of this algorithm, on the number of benchmark databases from UCI Machine Learning Repository, reflect the ability of this approach in clustering analysis.","","Electronic:978-1-4673-8737-8; POD:978-1-4673-8738-5","10.1109/CSIEC.2016.7482110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482110","Clustering Analysis;Hybridization;K-Means;Particle Swarm Optimization (PSO)","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Convergence;Linear programming;Machine learning algorithms;Particle swarm optimization","data mining;learning (artificial intelligence);particle swarm optimisation;pattern clustering;swarm intelligence","K-means clustering;PSO;SI algorithms;UCI machine learning repository;clustering data;data mining;particle swarm optimization;swarm intelligence","","","","18","","","9-11 March 2016","","IEEE","IEEE Conference Publications"
"Efficient subspace clustering of large-scale data streams with misses","P. A. Traganitis; G. B. Giannakis","Dept. of ECE & Digital Technology Center, University of Minnesota, USA","2016 Annual Conference on Information Science and Systems (CISS)","20160428","2016","","","590","595","As the amount of data generated and communicated continuously increases, clustering algorithms that are not able to handle this enormous amount of data have to be redesigned. Recent subspace clustering advances, while powerful, are computationally and memory demanding. The present paper introduces an online algorithm that broadens high-performance batch subspace clustering methods, and is able to perform subspace clustering on data arriving sequentially and possibly with misses. Numerical tests on synthetic and real data demonstrate the potential of the proposed approach.","","Electronic:978-1-4673-9457-4; POD:978-1-4673-9458-1","10.1109/CISS.2016.7460569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460569","Online;Subspace clustering;low-rank representation;missing entries;streaming","Clustering algorithms;Complexity theory;Information science;Machine learning algorithms;Optimization;Principal component analysis;Signal processing algorithms","large-scale systems;pattern clustering;vectors","data generation;high-performance batch subspace clustering methods;large-scale data streams;memory demanding","","","","36","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Mobile big data analytics using deep learning and apache spark","M. A. Alsheikh; D. Niyato; S. Lin; H. p. Tan; Z. Han","Nanyang Technological University and the Institute for Infocomm Research","IEEE Network","20160520","2016","30","3","22","29","The proliferation of mobile devices, such as smartphones and Internet of Things gadgets, has resulted in the recent mobile big data era. Collecting mobile big data is unprofitable unless suitable analytics and learning methods are utilized to extract meaningful information and hidden patterns from data. This article presents an overview and brief tutorial on deep learning in mobile big data analytics and discusses a scalable learning framework over Apache Spark. Specifically, distributed deep learning is executed as an iterative MapReduce computing on many Spark workers. Each Spark worker learns a partial deep model on a partition of the overall mobile, and a master deep model is then built by averaging the parameters of all partial models. This Spark-based framework speeds up the learning of deep models consisting of many hidden layers and millions of parameters. We use a context-aware activity recognition application with a real-world dataset containing millions of samples to validate our framework and assess its speedup effectiveness.","0890-8044;08908044","","10.1109/MNET.2016.7474340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474340","","Big data;Computational modeling;Machine learning;Mobile communication;Mobile handsets;Sensors;Sparks","Big Data;iterative methods;learning (artificial intelligence);mobile computing;parallel programming","Apache Spark;context-aware activity recognition application;deep learning;iterative MapReduce computing;mobile Big Data analytics;real-world dataset","","2","","15","","","May-June 2016","","IEEE","IEEE Journals & Magazines"
"Teaching of mathematics in engineering by discussing the different conceptual ideas","S. Malhotra","Department of Mathematics and Humanities, Institute of Technology, Nirma University, Ahmedabad, India","2015 5th Nirma University International Conference on Engineering (NUiCONE)","20160409","2015","","","1","2","Teaching of mathematics in engineering quite often becomes the mere mechanical process. Students of engineering branches lost their interest of mathematics due to the same. In the present work points are given to make the mathematics teaching interesting in engineering by discussing the different conceptual ideas of the topics. The benefits of the learning with the insight of conceptual ideas of mathematics are also derived and attempt is made to encourage mathematics faculties to think ahead and work in the described direction.","","Electronic:978-1-4799-9991-0; POD:978-1-4799-9992-7","10.1109/NUICONE.2015.7449601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449601","Cayley-Hamilton Theorem;Conceptual Ideas;Green's Theorem;Provoke thinking","Calculus;Education;History;Machine learning;Microscopy;Transforms","educational courses;engineering education;mathematics;teaching","conceptual ideas;engineering branches;mathematics faculties;mathematics teaching;mechanical process","","","","4","","","26-28 Nov. 2015","","IEEE","IEEE Conference Publications"
"Robust volume minimization-based matrix factorization via alternating optimization","X. Fu; W. K. Ma; K. Huang; N. D. Sidiropoulos","Department of ECE, University of Minnesota, Minneapolis, MN, USA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","2534","2538","This paper focuses on volume minimization (VolMin)-based structured matrix factorization (SMF), which factors a data matrix into a full-column rank basis and a coefficient matrix whose columns reside in the unit simplex. The VolMin criterion achieves this goal via finding a minimum-volume enclosing convex hull of the data. Recent works showed that VolMin guarantees the identifiability of the factor matrices under mild and realistic conditions, which suit many applications in signal processing and machine learning. However, the existing VolMin algorithms are sensitive to outliers or lack efficiency in dealing with volume-associated cost functions. In this work, we propose a new VolMin-based matrix factorization criterion and algorithm that take outliers into consideration. The proposed algorithm detects outliers and suppress them automatically, and it does so in an algorithmically very simple way. Simulations are used to showcase the effectiveness of the proposed algorithm.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472134","Volume minimization;document clustering;hyperspectral unmixing;nonnegative matrix factorization","Clustering algorithms;Cost function;Machine learning algorithms;Minimization;Robustness;Signal processing algorithms","convex programming;matrix algebra;minimisation;signal processing","SMF;VolMin;alternating optimization;coefficient matrix;data matrix;full-column rank basis;machine learning;robust volume minimization;signal processing;structured matrix factorization;unit simplex;volume associated cost functions","","","","31","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"DeepEmo: Real-world facial expression analysis via deep learning","W. Deng; J. Hu; S. Zhang; J. Guo","Beijing University of Posts and Telecommunications, Beijing, 100876, China","2015 Visual Communications and Image Processing (VCIP)","20160425","2015","","","1","4","Recent automatic facial expression recognition research has focused on optimizing performance on a few databases that were collected under controlled pose and lighting conditions, and has produced nearly perfect accuracy. This paper explores the necessary characteristics of the training dataset, feature representations and machine learning algorithms for a system that operates reliably in more realistic conditions. A new database, Real-world Affective Face Database (RAF-DB), is presented which contains about 30,000 greatly-diverse facial images from social networks. Crowdsourcing results suggest that real-world expression recognition problem is a typical imbalanced multi-label classification problem, and the balanced, single-label datasets currently used in the literature could potentially lead research into misleading algorithmic solutions. A deep learning architecture, DeepEmo, is proposed to address the real-world challenge of emotion recognition by learning the highlevel feature representations which are highly effective for discriminating realistic facial expressions. Extensive experimental results show that the deep learning method is significantly superior to handcrafted features, and with the near-frontal pose constraint, human-level recognition accuracy is achievable.","","Electronic:978-1-4673-7314-2; POD:978-1-4673-7315-9; USB:978-1-4673-7313-5","10.1109/VCIP.2015.7457876","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457876","Deep learning;Expression recognition;emotion recognition;face analysis;human-computer interaction","Databases;Emotion recognition;Face;Face recognition;Machine learning;Support vector machines;Training","emotion recognition;face recognition;feature extraction;human computer interaction;image classification;image representation;learning (artificial intelligence);social networking (online)","DeepEmo;deep learning architecture;emotion recognition;facial expression analysis;facial expression recognition;feature representation;human-computer interaction;human-level recognition;machine learning algorithm;multilabel classification problem;near-frontal pose constraint;social network","","","","13","","","13-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Feature Selection Based on Structured Sparsity: A Comprehensive Study","J. Gui; Z. Sun; S. Ji; D. Tao; T. Tan","Institute of Intelligent Machines, Chinese Academy of Sciences, Hefei 230031, China.","IEEE Transactions on Neural Networks and Learning Systems","","2017","PP","99","1","18","Feature selection (FS) is an important component of many pattern recognition tasks. In these tasks, one is often confronted with very high-dimensional data. FS algorithms are designed to identify the relevant feature subset from the original features, which can facilitate subsequent analysis, such as clustering and classification. Structured sparsity-inducing feature selection (SSFS) methods have been widely studied in the last few years, and a number of algorithms have been proposed. However, there is no comprehensive study concerning the connections between different SSFS methods, and how they have evolved. In this paper, we attempt to provide a survey on various SSFS methods, including their motivations and mathematical representations. We then explore the relationship among different formulations and propose a taxonomy to elucidate their evolution. We group the existing SSFS methods into two categories, i.e., vector-based feature selection (feature selection based on lasso) and matrix-based feature selection (feature selection based on lr,p-norm). Furthermore, FS has been combined with other machine learning algorithms for specific applications, such as multitask learning, multilabel learning, multiview learning, classification, and clustering. This paper not only compares the differences and commonalities of these methods based on regression and regularization strategies, but also provides useful guidelines to practitioners working in related fields to guide them how to do feature selection.","2162-237X;2162237X","","10.1109/TNNLS.2016.2551724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458185","Dimensionality reduction;feature selection;sparse;structured sparsity.","Algorithm design and analysis;Clustering algorithms;Computational modeling;Machine learning algorithms;Pattern recognition;Robustness;Sun","","","","1","","","","20160422","","","IEEE","IEEE Early Access Articles"
"License Plate Detection Based on Sparse Auto-Encoder","R. Yang; H. Yin; X. Chen","Dept. of Electron. Eng. & Inf. Sci., Univ. of Sci. & Technol. of China, Hefei, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","2","","465","469","In modern society, automatic license plate recognition (ALPR) plays an important role in the field of Intelligent Transport Systems (ITS). In order to recognize the license plate efficiently, the location of the license plate must be detected first. In consequence, the detection of the license plate becomes a crucial stage in an ALPR system, affecting the performance of the whole system enormously. In this paper, we propose a novel method based on Sparse Auto-Encoder (SAE) to detect the vehicle license plate. The proposed method consists of three main stages: (1) A block-based image segmentation technique used for dividing the image into several blocks. (2) Deep learning model (SAE) trained for candidate block selection. (3) Accurate extraction of the license plate. Unlike other existing license plate detection methods, the proposed algorithm use a deep learning model to learn the features of the license plate. Experiment results demonstrate that our method can detect various types of license plates with a high accuracy and a relatively short running time.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469174","Sparse AutoEncoder;deep learning;license plate detection","Feature extraction;Image color analysis;Image segmentation;Licenses;Machine learning;Training;Vehicles","automobiles;compressed sensing;feature extraction;image classification;image coding;image segmentation;intelligent transportation systems;learning (artificial intelligence);object detection","ALPR system;ITS;SAE;automatic license plate recognition;block selection;block-based image segmentation technique;deep-learning model;feature learning;intelligent transport systems;license plate extraction;license plate location detection;sparse auto-encoder","","","","15","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Unsupervised Deep Learning Applied to Breast Density Segmentation and Mammographic Risk Scoring","M. Kallenberg; K. Petersen; M. Nielsen; A. Y. Ng; P. Diao; C. Igel; C. M. Vachon; K. Holland; R. R. Winkel; N. Karssemeijer; M. Lillholm","University of Copenhagen, Copenhagen, Denmark","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1322","1331","Mammographic risk scoring has commonly been automated by extracting a set of handcrafted features from mammograms, and relating the responses directly or indirectly to breast cancer risk. We present a method that learns a feature hierarchy from unlabeled data. When the learned features are used as the input to a simple classifier, two different tasks can be addressed: i) breast density segmentation, and ii) scoring of mammographic texture. The proposed model learns features at multiple scales. To control the models capacity a novel sparsity regularizer is introduced that incorporates both lifetime and population sparsity. We evaluated our method on three different clinical datasets. Our state-of-the-art results show that the learned breast density scores have a very strong positive relationship with manual ones, and that the learned texture scores are predictive of breast cancer. The model is easy to apply and generalizes to many other segmentation and scoring problems.","0278-0062;02780062","","10.1109/TMI.2016.2532122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412749","Breast cancer;deep learning;mammograms;prognosis;risk factor;segmentation;unsupervised feature learning","Breast cancer;Computer architecture;Image segmentation;Machine learning;Mammography;Manuals","cancer;image classification;image segmentation;image texture;mammography;medical image processing;risk analysis;tumours;unsupervised learning","breast cancer risk;breast density segmentation;clinical datasets;handcrafted feature extraction;learned features;learned texture scores;mammographic risk scoring;mammographic texture;population sparsity;simple classifier;sparsity regularizer;unlabeled data;unsupervised deep learning","","6","","67","","20160218","May 2016","","IEEE","IEEE Journals & Magazines"
"Multimodal emotion recognition using deep learning architectures","H. Ranganathan; S. Chakraborty; S. Panchanathan","Center for Cognitive Ubiquitous Computing (CUbiC) Arizona State University","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","9","Emotion analysis and recognition has become an interesting topic of research among the computer vision research community. In this paper, we first present the emoF-BVP database of multimodal (face, body gesture, voice and physiological signals) recordings of actors enacting various expressions of emotions. The database consists of audio and video sequences of actors displaying three different intensities of expressions of 23 different emotions along with facial feature tracking, skeletal tracking and the corresponding physiological data. Next, we describe four deep belief network (DBN) models and show that these models generate robust multimodal features for emotion classification in an unsupervised manner. Our experimental results show that the DBN models perform better than the state of the art methods for emotion recognition. Finally, we propose convolutional deep belief network (CDBN) models that learn salient multimodal features of expressions of emotions. Our CDBN models give better recognition accuracies when recognizing low intensity or subtle expressions of emotions when compared to state of the art methods.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477679","","Databases;Emotion recognition;Face;Facial features;Machine learning;Physiology;Three-dimensional displays","audio signal processing;behavioural sciences computing;belief networks;computer vision;emotion recognition;face recognition;image sequences;learning (artificial intelligence);object tracking;research and development;video signal processing","BVP database;CDBN;audio sequences;computer vision research community;convolutional deep belief network models;deep belief network models;deep learning architectures;emotion analysis;facial feature tracking;multimodal emotion recognition;skeletal tracking;video sequences","","","","28","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"Gold classification of COPDGene cohort based on deep learning","J. Ying; J. Dutta; N. Guo; L. Xia; A. Sitek; Q. Li; Q. Li","Nuclear Medicine and Molecular Imaging Radiology Department, Massachusetts General Hospital, Boston, MA, USA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","2474","2478","This study aims to employ deep learning for the development of an automatic classifier for the severity of chronic obstructive pulmonary disease (COPD) in patients. A three-layer deep belief network (DBN) with two hidden layers and one visible layer was employed to generate a model for classification, and the model's robustness against exacerbation was analyzed. Subjects from the COPDGene cohort were staged using the GOLD 2011 guidelines. 10,300 subjects with 361 features each were included in the analysis. After feature selection and parameter optimization, the proposed classification method achieved an accuracy of 97.2% by using a 10-fold cross validation experiment. The most sensitive features as revealed by the DBN weights were consistent with the clinical consensus as per previous studies and clinical diagnosis rules. In summary, we demonstrate that the DBN is a competitive tool for exacerbation risk assessment for patients suffering from, COPD.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472122","Chronic Obstructive Pulmonary Disease (COPD);Deep Belief Networks (DBNs);Global Initiative for Chronic Obstructive Lung Disease (GOLD);classification;deep learning","Diseases;Feature extraction;Gold;Lungs;Machine learning;Medical diagnostic imaging;Training","belief networks;biology computing;diseases;feature selection;learning (artificial intelligence);optimisation;pattern classification","COPD gene cohort;DBN weights;automatic gold classification;chronic obstructive pulmonary disease;deep learning;exacerbation risk assessment;feature selection;parameter optimization;three-layer deep belief network","","","","19","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Guided search for task and motion plans using learned heuristics","R. Chitnis; D. Hadfield-Menell; A. Gupta; S. Srivastava; E. Groshev; C. Lin; P. Abbeel","","2016 IEEE International Conference on Robotics and Automation (ICRA)","20160609","2016","","","447","454","Tasks in mobile manipulation planning often require thousands of individual motions to complete. Such tasks require reasoning about complex goals as well as the feasibility of movements in configuration space. In discrete representations, planning complexity is exponential in the length of the plan. In mobile manipulation, parameters for an action often draw from a continuous space, so we must also cope with an infinite branching factor. Task and motion planning (TAMP) methods integrate logical search over high-level actions with geometric reasoning to address this challenge. We present an algorithm that searches the space of possible task and motion plans and uses statistical machine learning to guide the search process. Our contributions are as follows: 1) we present a complete algorithm for TAMP; 2) we present a randomized local search algorithm for plan refinement that is easily formulated as a Markov decision process (MDP); 3) we apply reinforcement learning (RL) to learn a policy for this MDP; 4) we learn from expert demonstrations to efficiently search the space of high-level task plans, given options that address different (potential) infeasibilities; and 5) we run experiments to evaluate our system in a variety of simulated domains. We show significant improvements in performance over prior work.","","Electronic:978-1-4673-8026-3; POD:978-1-4673-8027-0","10.1109/ICRA.2016.7487165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487165","","Grasping;Learning (artificial intelligence);Machine learning algorithms;Markov processes;Planning;Robots;Trajectory","Markov processes;control engineering computing;decision theory;learning (artificial intelligence);manipulators;mobile robots;path planning;randomised algorithms;search problems","MDP;Markov decision process;TAMP methods;geometric reasoning;guided search;high-level task plans;infinite branching factor;learned heuristics;logical search;mobile manipulation planning;plan refinement;planning complexity;randomized local search algorithm;reinforcement learning;statistical machine learning;task and motion planning","","","","21","","","16-21 May 2016","","IEEE","IEEE Conference Publications"
"Frontal to profile face verification in the wild","S. Sengupta; J. C. Chen; C. Castillo; V. M. Patel; R. Chellappa; D. W. Jacobs","Center for Automation Research, University of Maryland, College Park, MD 20740, USA","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","9","We have collected a new face data set that will facilitate research in the problem of frontal to profile face verification `in the wild'. The aim of this data set is to isolate the factor of pose variation in terms of extreme poses like profile, where many features are occluded, along with other `in the wild' variations. We call this data set the Celebrities in Frontal-Profile (CFP) data set. We find that human performance on Frontal-Profile verification in this data set is only slightly worse (94.57% accuracy) than that on Frontal-Frontal verification (96.24% accuracy). However we evaluated many state-of-the-art algorithms, including Fisher Vector, Sub-SML and a Deep learning algorithm. We observe that all of them degrade more than 10% from Frontal-Frontal to Frontal-Profile verification. The Deep learning implementation, which performs comparable to humans on Frontal-Frontal, performs significantly worse (84.91% accuracy) on Frontal-Profile. This suggests that there is a gap between human performance and automatic face recognition methods for large pose variation in unconstrained images.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477558","","Face;Face recognition;Feature extraction;Machine learning;Measurement;Protocols;Training data","face recognition;learning (artificial intelligence);pose estimation","CFP data set;Fisher vector algorithm;celebrities in frontal-profile;deep learning algorithm;frontal face verification;frontal-frontal verification;pose variation;profile face verification;sub-SML algorithm","","2","","38","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"Research on Gas Recognition Based on Stacked Denoising Autoencoders","W. Yu; C. Gan; W. Lu","Sch. of Comput. Sci. & Inf. Eng., Shanghai Inst. of Technol., Shanghai, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","1","","301","304","The gas data coming from an array of chemical gas sensors is a kind of multivariate time-series. This data set is extremely difficult and complex to interpret for human experts. It needs designing hand-made features when applying traditional shallow machine learning algorithms in gas recognition. A new gas recognition method based on Deep Learning were proposed in this paper. It is one of unsupervised feature learning methods that can extract self-adapting features from the gas data, overcoming the complex process in designing features by hands and making the features more general. In this work, two methods based on UCI Machine learning database respectively were compared in the experiments. One of them is a two-hidden-layer structure of deep neural network-Stacked denoising Autoencoders and another is a kind of shallow machine learning algorithms. The results show that extracting features automaticly using Deep Learning is a simpler and more universal way in gas recognition. The method proposed in this paper not only improves the gas classification accuracy, but also reduces complexity of the process in shallow machine learning alogithms, so it is valuable to be applied in practice.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468955","Deep Learning;Stacked denoising Autoencoders;gas recognition;high-dimensional;time-series signal","Data mining;Feature extraction;Gas detectors;Machine learning;Noise reduction;Support vector machines","computerised instrumentation;feature extraction;gas sensors;neural nets;sensor arrays;time series;unsupervised learning","UCI machine learning database;chemical gas sensor;deep learning;deep neural network;gas classification;gas recognition method;multivariate time-series;self-adapting feature extraction;shallow machine learning algorithm;stacked denoising autoencoder;two-hidden-layer structure;unsupervised feature learning method","","","","9","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"DeepX: A Software Accelerator for Low-Power Deep Learning Inference on Mobile Devices","N. D. Lane; S. Bhattacharya; P. Georgiev; C. Forlivesi; L. Jiao; L. Qendro; F. Kawsar","","2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","20160428","2016","","","1","12","Breakthroughs from the field of deep learning are radically changing how sensor data are interpreted to extract the high-level information needed by mobile apps. It is critical that the gains in inference accuracy that deep models afford become embedded in future generations of mobile apps. In this work, we present the design and implementation of DeepX, a software accelerator for deep learning execution. DeepX signif- icantly lowers the device resources (viz. memory, computation, energy) required by deep learning that currently act as a severe bottleneck to mobile adoption. The foundation of DeepX is a pair of resource control algorithms, designed for the inference stage of deep learning, that: (1) decompose monolithic deep model network architectures into unit- blocks of various types, that are then more efficiently executed by heterogeneous local device processors (e.g., GPUs, CPUs); and (2), perform principled resource scaling that adjusts the architecture of deep models to shape the overhead each unit-blocks introduces. Experiments show, DeepX can allow even large-scale deep learning models to execute efficently on modern mobile processors and significantly outperform existing solutions, such as cloud-based offloading.","","Electronic:978-1-5090-0802-5; POD:978-1-5090-0803-2","10.1109/IPSN.2016.7460664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460664","","Computational modeling;Computer architecture;Inference algorithms;Machine learning;Mobile communication;Program processors;Runtime","inference mechanisms;learning (artificial intelligence);mobile computing;power aware computing","DeepX;cloud-based offloading;heterogeneous local device processors;high-level information extraction;low-power deep learning inference;mobile apps;mobile devices;mobile processors;monolithic deep model network architectures;resource control algorithms;sensor data;software accelerator","","2","","48","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"Partial Copy Detection in Videos: A Benchmark and an Evaluation of Popular Methods","Y. G. Jiang; J. Wang","School of Computer Science, Fudan University, Shanghai, China","IEEE Transactions on Big Data","20160519","2016","2","1","32","42","The goal of partial video copy detection is to find one or more segments of a query video which have (transformed) copies in a large dataset. Previous related research in this field used either small-scale datasets or large datasets with simulated partial copies by imposing several pre-defined transformations (e.g., photometric changes) due to the extremely time-consuming annotation of real copies. It is still unknown how well the techniques developed on simulated datasets perform on real copies, which are much more challenging and too complex to be simulated. In this paper, we introduce a large-scale video copy database (VCDB) with over 100,000 videos, and more than 9,000 copy pairs found by manual annotation. A state-of-the-art system of video copy detection is evaluated on VCDB to show the limitations of existing techniques. We also evaluate deep learning features learned by two neural networks: one is independently trained on a different dataset and the other is tailored to deal with the copy detection task. Our evaluation suggests that all the existing techniques, including the deep learning features, are far from satisfactory in detecting complex real copies.","","","10.1109/TBDATA.2016.2530714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416633","Video copy detection;benchmark dataset;deep learning;frame matching;temporal alignment","Benchmark testing;Feature extraction;Internet;Machine learning;Manuals;TV;Videos","simulated annealing;visual databases","VCDB;extremely time-consuming annotation;partial copy detection;photometric changes;simulated datasets;small-scale datasets","","3","","36","","20160224","March 1 2016","","IEEE","IEEE Journals & Magazines"
"Where does AlphaGo go: from church-turing thesis to AlphaGo thesis and beyond","F. Y. Wang; J. J. Zhang; X. Zheng; X. Wang; Y. Yuan; X. Dai; J. Zhang; L. Yang","Chinese Academy of Sciences (SKL-MCCS, CASIA), Beijing 100190, China","IEEE/CAA Journal of Automatica Sinica","20160519","2016","3","2","113","120","An investigation on the impact and significance of the AlphaGo vs. Lee Sedol Go match is conducted, and concludes with a conjecture of the AlphaGo Thesis and its extension in accordance with the Church-Turing Thesis in the history of computing. It is postulated that the architecture and method utilized by the AlphaGo program provide an engineering solution for tackling issues in complexity and intelligence. Specifically, the AlphaGo Thesis implies that any effective procedure for hard decision problems such as NP-hard can be implemented with AlphaGo-like approach. Deep rule-based networks are proposed in attempt to establish an understandable structure for deep neural networks in deep learning. The success of AlphaGo and corresponding thesis ensure the technical soundness of the parallel intelligence approach for intelligent control and management of complex systems and knowledge automation.","2329-9266;23299266","","10.1109/JAS.2016.7471613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471613","ACP;AlphaGo;AlphaGo Thesis;Church-Turing Thesis;deep learning;deep neural networks;deep rule-based networks;knowledge automation;parallel intelligence;parallel management;parallel ontrol","Complexity theory;Computers;Decision making;Games;Machine learning;Neural networks","Turing machines;computational complexity;learning (artificial intelligence);neural nets","AlphaGo thesis;Church-Turing thesis;Lee Sedol Go match;NP-hard problem;complex system management;deep learning;deep neural networks;deep rule-based networks;hard decision problems;intelligent control;knowledge automation;parallel intelligence approach","","","","","","","April 2016","","IEEE","IEEE Journals & Magazines"
"3View deep canonical correlation analysis for cross-modal retrieval","J. Shao; Z. Zhao; F. Su; T. Yue","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","2015 Visual Communications and Image Processing (VCIP)","20160425","2015","","","1","4","This paper investigates the problem of modeling Internet images and associated text for cross-modal retrieval tasks such as text-to-image search, and image-to-text search. Canonical correlation analysis (CCA), a classic two view approach for mapping text and image into a common latent space, does not make use of the semantic information of text and image pairs. We use CCA to map text, image and semantic information into a common latent space, in which the correlation of the three views is maximized. To improve the performance of CCA, in this paper, 3view-Deep Canonical Correlation Analysis (3view-DCCA), a nonlinear expansion of CCA is proposed to learn the complex nonlinear transformations between the three views. Like most deep learning methods, DCCA is easy to over-fitting. To overcome over-fitting, we add the reconstruct loss of each view into the loss function, which include the correlation loss of every two views and regularization of parameters. Inspired by PageRank, we propose a search-based similarity method to score relevance. The proposed model (3view-DCCA) is evaluated on three publicly available data sets from real scenes. We demonstrate that our deep model performs significantly better than traditional canonical correlation analysis based models and several other deep learning models on cross-modal retrieval tasks.","","Electronic:978-1-4673-7314-2; POD:978-1-4673-7315-9; USB:978-1-4673-7313-5","10.1109/VCIP.2015.7457870","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457870","semantic CCA deep reconstruct search-based","Correlation;Feature extraction;Image reconstruction;Internet;Machine learning;Optimization;Semantics","Internet;correlation methods;image retrieval;learning (artificial intelligence)","3View deep canonical correlation analysis;3view-DCCA;Internet image modelling;PageRank;classic two view approach;complex nonlinear transformation learning;cross-modal retrieval;deep learning methods;latent space;parameter regularization;reconstruct loss;search-based similarity method;semantic information;text mapping","","","","12","","","13-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Batch Mode Active Learning for Regression With Expected Model Change","W. Cai; M. Zhang; Y. Zhang","Cooperative Medianet Innovation Center, Shanghai Jiao Tong University, Shanghai 200240, China.","IEEE Transactions on Neural Networks and Learning Systems","","2016","PP","99","1","14","While active learning (AL) has been widely studied for classification problems, limited efforts have been done on AL for regression. In this paper, we introduce a new AL framework for regression, expected model change maximization (EMCM), which aims at choosing the unlabeled data instances that result in the maximum change of the current model once labeled. The model change is quantified as the difference between the current model parameters and the updated parameters after the inclusion of the newly selected examples. In light of the stochastic gradient descent learning rule, we approximate the change as the gradient of the loss function with respect to each single candidate instance. Under the EMCM framework, we propose novel AL algorithms for the linear and nonlinear regression models. In addition, by simulating the behavior of the sequential AL policy when applied for k iterations, we further extend the algorithms to batch mode AL to simultaneously choose a set of k most informative instances at each query time. Extensive experimental results on both UCI and StatLib benchmark data sets have demonstrated that the proposed algorithms are highly effective and efficient.","2162-237X;2162237X","","10.1109/TNNLS.2016.2542184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454745","Active learning (AL);batch mode;expected model change;linear regression;nonlinear regression.","Algorithm design and analysis;Approximation algorithms;Context modeling;Data models;Linear regression;Machine learning algorithms;Training","","","","","","","","20160420","","","IEEE","IEEE Early Access Articles"
"Learning high-dimensional Mixture Models for fast collision detection in Rapidly-Exploring Random Trees","Jinwook Huh; D. D. Lee","GRASP Laboratory, University of Pennsylvania, Philadelphia, 19104, United States of America","2016 IEEE International Conference on Robotics and Automation (ICRA)","20160609","2016","","","63","69","This paper presents a new approach for fast collision detection in high dimensional configuration spaces for Rapidly-exploring Random Trees (RRT) motion planning. The proposed method is based upon Gaussian Mixture Models (GMM) that are learned using an incremental Expectation Maximization clustering algorithm trained online using exemplars provided by a slow, conventional kinematic-based collision detection routine. The number of collision checks needed can be drastically reduced using a biased random sampling from the learned GMM distribution, and the learned models are continually refined and improved as the RRT planning algorithm proceeds. Our proposed method is demonstrated on several example applications and experimental results show marked improvement in computational efficiency over previous approaches.","","Electronic:978-1-4673-8026-3; POD:978-1-4673-8027-0","10.1109/ICRA.2016.7487116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487116","","Clustering algorithms;Collision avoidance;Heuristic algorithms;Machine learning algorithms;Manipulators;Planning;Probabilistic logic","Gaussian distribution;collision avoidance;expectation-maximisation algorithm;mixture models;pattern clustering;random processes;sampling methods;trees (mathematics)","GMM;Gaussian mixture models;RRT motion planning;biased random sampling;fast collision detection;high dimensional configuration spaces;high-dimensional mixture models;incremental expectation maximization clustering algorithm;kinematic-based collision detection routine;rapidly-exploring random trees motion planning","","","","20","","","16-21 May 2016","","IEEE","IEEE Conference Publications"
"Nonnegative matrix factorization using ADMM: Algorithm and convergence analysis","D. Hajinezhad; T. H. Chang; X. Wang; Q. Shi; M. Hong","Dept. of IMSE. Iowa State Univ. Ames. IA. 50011. USA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","4742","4746","The nonnegative matrix factorization (NMF) has been a popular model for a wide range of signal processing and machine learning problems. It is usually formulated as a nonconvex cost minimization problem. This work settles the convergence issue of a popular algorithm based on the alternating direction method of multipliers proposed in Boyd et al 2011. We show that the algorithm converges globally to the set of KKT solutions whenever certain penalty parameter ρ satisfies ρ > 1. We further extend the algorithm and its analysis to the problem where the observation matrix contains missing values. Numerical experiments on real and synthetic data sets demonstrate the effectiveness of the algorithms under investigation.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472577","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472577","ADMM;Convergence Analysis;Nonconvex Optimization;Nonnegative Matrix Factorization","Algorithm design and analysis;Convergence;Indexes;Machine learning algorithms;Signal processing algorithms;Software algorithms;Zirconium","concave programming;convergence of numerical methods;learning (artificial intelligence);matrix decomposition;minimisation;signal processing","ADMM;alternating direction method of multiplier;convergence analysis;machine learning problem;nonconvex cost minimization problem;nonnegative matrix factorization;observation matrix;signal processing","","1","","20","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"On the importance of normalisation layers in deep learning with piecewise linear activation units","Z. Liao; G. Carneiro","ARC Centre of Excellence for Robotic Vision, University of Adelaide, Australia","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","8","Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets (e.g., CIFAR-10, CIFAR-100, MNIST, and SVHN). The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477624","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477624","","Data models;Ear;Feedforward neural networks;Image color analysis;Machine learning;Training","feedforward neural nets;learning (artificial intelligence);piecewise linear techniques","CIFAR-10 datasets;CIFAR-100 datasets;MNIST datasets;SVHN datasets;batch normalisation units;data points distribution;deep feedforward neural networks;deep learning;implicit regularization scheme;normalisation layers;piecewise linear activation functions;piecewise linear activation units;subnetworks","","","","21","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"Efficient Cloud-Based Framework for Big Data Classification","R. Pakdel; J. Herbert","Dept. of Comput. Sci., Univ. Coll. Cork, Cork, Ireland","2016 IEEE Second International Conference on Big Data Computing Service and Applications (BigDataService)","20160523","2016","","","195","201","Big Data is a term that describes the large volume of data both structured and unstructured that is difficult to process using traditional database and software techniques. Cloud computing is a technology that offers a solution to this problem. We have designed a cloud-based framework for unstructured data analysis that is motivated by the goal of efficient image data analysis. The framework consists of two general stages of feature extraction and machine learning that can be used in training mode and classification mode. The framework uses sampling and feedback mechanisms whereby the system learns which image features are most important, and also learns which algorithm(s) is best (under user criteria of accuracy and speed). This information allows the system to be more efficient by automatically reducing the number of features captured, and number of algorithms being used to evaluate the data. While there is an overhead to the auto-adjusting mechanisms, they do lead to a more efficient solution for big data sets. The solution is evaluated using a leaf images classification problem, and the results shows the improvements in efficiency.","","Electronic:978-1-5090-2251-9; POD:978-1-5090-2252-6","10.1109/BigDataService.2016.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474373","","Big data;Cloud computing;Data models;Feature extraction;Machine learning algorithms;Testing;Training","Big Data;cloud computing;feature extraction;learning (artificial intelligence);sampling methods","autoadjusting mechanism;big data classification;cloud computing;cloud-based framework;feature extraction;feedback mechanism;machine learning;sampling mechanism;training mode","","","","21","","","March 29 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"An imbalanced data classification algorithm of improved autoencoder neural network","C. Zhang; W. Gao; J. Song; J. Jiang","College of Mathematics, Inner Mongolia University for the Nationalities, Tongliao, China","2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)","20160409","2016","","","95","99","Imbalanced data classification problem has always been a hotspot in the field of machine learning research. Pointing to the overfitting and noise problems of oversampling algorithm when synthesizing new minority class samples, the current study proposed a stacked denoising autoencoder neural network (SDAE) algorithm based on cost-sensitive oversampling, combining the cost-sensitive learning with denoising autoencoder neural network. The proposed algorithm can not only oversample minority class sample through misclassification cost, but it can denoise and classify the sampled dataset. Experiment shows that, compared with the traditional stacked autoencoder neural network (SAE) and oversampling autoencoder neural network without denoising process (OS-SAE), the proposed algorithm improves the classification accuracy of minority class of imbalanced datasets.","","CD-ROM:978-1-4673-7778-2; Electronic:978-1-4673-7782-9; POD:978-1-4673-7783-6","10.1109/ICACI.2016.7449810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449810","classification;cost sensitive;imbalanced data;oversampling;stacked denoising autoencoder neural network","Biological neural networks;Cancer;Classification algorithms;Machine learning algorithms;Noise reduction;Training","learning (artificial intelligence);neural nets;pattern classification","SDAE algorithm;cost-sensitive learning;cost-sensitive oversampling;imbalanced data classification algorithm;machine learning;misclassification cost;noise problem;overfitting problem;oversampling algorithm;sampled dataset classification;sampled dataset denoising;stacked denoising autoencoder neural network","","1","","19","","","14-16 Feb. 2016","","IEEE","IEEE Conference Publications"
"The Limitations of Deep Learning in Adversarial Settings","N. Papernot; P. McDaniel; S. Jha; M. Fredrikson; Z. B. Celik; A. Swami","","2016 IEEE European Symposium on Security and Privacy (EuroS&P)","20160512","2016","","","372","387","Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs. In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample. We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.","","Electronic:978-1-5090-1752-2; POD:978-1-5090-1753-9","10.1109/EuroSP.2016.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467366","","Biological neural networks;Distortion;Force;Machine learning;Neurons;Training","computer vision;image classification;learning (artificial intelligence);neural nets","DNN;adversarial samples;adversarial samples:;computer vision;deep neural networks;hardness measure;human subjects;input features;large datasets;target classification;training algorithms;training phase","","5","","37","","","21-24 March 2016","","IEEE","IEEE Conference Publications"
"Visual tracking via multi-task non-negative matrix factorization","Y. Wang; X. Luo; S. Hu","Hisilicon Technologies","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","1516","1520","We propose an online tracking algorithm in which the object tracking is achieved by using subspace learning and non-negative matrix factorization (NMF) under the partile filtering framework. The object appearance is modeled by a non-negative combination of non-negative components learned from examples observed in previous frames. In order to robust tracking an object, group sparsity constraints are included to the non-negativity one. In addition, the Alternating Direction Method of Multipliers (ADMM) algorithm is proposed for efficient model updating. Qualitative and quantitative experiments on a variety of challenging sequences show favorable performance of the proposed algorithm against 9 state-of-the-art methods.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471930","Alternating direction method of multipliers;non-negative matrix factorization;subspace learning","Algorithm design and analysis;Machine learning algorithms;Mathematical model;Principal component analysis;Robustness;Target tracking;Visualization","matrix decomposition;object tracking;particle filtering (numerical methods)","ADMM algorithm;NMF;alternating direction method of multipliers algorithm;group sparsity constraints;nonnegative components;nonnegative matrix factorization;object tracking;online tracking algorithm;partile filtering framework;robust tracking;subspace learning","","","","18","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Unsupervised underwater fish detection fusing flow and objectiveness","D. Zhang; G. Kopanas; C. Desai; S. Chai; M. Piacentino","SRI International, Princeton, NJ 08540","2016 IEEE Winter Applications of Computer Vision Workshops (WACVW)","20160519","2016","","","1","7","Scientists today face an onerous task to manually annotate vast amount of underwater video data for fish stock assessment. In this paper, we propose a robust and unsupervised deep learning algorithm to automatically detect fish and thereby easing the burden of manual annotation. The algorithm automates fish sampling in the training stage by fusion of optical flow segments and objective proposals. We auto-generate large amounts of fish samples from the detection of flow motion and based on the flow-objectiveness overlap probability we annotate the true-false samples. We also adapt a biased training weight towards negative samples to reduce noise. In detection, in addition to fused regions, we used a Modified Non-Maximum Suppression (MNMS) algorithm to reduce false classifications on part of the fishes from the aggressive NMS approach. We exhaustively tested our algorithms using NOAA provided, luminance-only underwater fish videos. Our tests have shown that Average Precision (AP) of detection improved by about 10% compared to non-fusion approach and about another 10% by using MNMS.","","Electronic:978-1-5090-2114-7; POD:978-1-5090-2115-4","10.1109/WACVW.2016.7470121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470121","","Detectors;Fish;Image motion analysis;Machine learning;Manuals;Proposals;Training","image fusion;image motion analysis;image sequences;object detection;probability;unsupervised learning;video signal processing","MNMS algorithm;NOAA;aggressive NMS approach;fish stock assessment;flow motion detection;flow-objectiveness overlap probability;luminance-only underwater fish videos;modified nonmaximum suppression algorithm;optical flow segment fusion;underwater video data;unsupervised deep learning algorithm;unsupervised underwater fish detection","","","","21","","","10-10 March 2016","","IEEE","IEEE Conference Publications"
"Activity Recognition Based on Smartphone and Dual-Tree Complex Wavelet Transform","C. Wang; W. Zhang","Res. Inst. Electron. Sci. & Technol., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","2","","267","270","Smartphone contains many multiple and powerful sensors, which establishes exciting new opportunities for human-computer interaction and data mining. Those sensors placed inside smartphone are used for phone function enhancement initially. In this work, we show how general machine learning algorithms can use labeled accelerometer data to classify motion activities when users hold a smartphone. First we establish an Android-based data collection application to gain persons' motion data via accelerometer placed inside smartphone. Then we collect 6 different motion activities from 3 users. Lastly we use normal machine learning algorithm to classify those collected activities. Previous works only use time-domain features for classification. This leads to low accuracy since activity data contains frequency-domain and orientation information. In this paper, we propose a new method for extracting both time-domain and frequency-domain features. We use dual-tree complex wavelet transform (DT-CWT) as feature extraction tool. Then we use general machine learning algorithm tool WEKA for classification. Results show that our method performs better than other researcher's method which only extracts time-domain feature from accelerometer data in accuracy aspect. Our algorithm acquires accuracy at 86% by using DT-CWT statistical information and orientation feature.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469130","DT-CWT transform;activity recognition;smartphone","Accelerometers;Classification algorithms;Feature extraction;Machine learning algorithms;Time-domain analysis;Wavelet transforms","accelerometers;data mining;feature extraction;human computer interaction;learning (artificial intelligence);pattern classification;smart phones;wavelet transforms","Android-based data collection application;DT-CWT;WEKA;activity recognition;data mining;dual-tree complex wavelet transform;feature extraction tool;frequency-domain features;human-computer interaction;labeled accelerometer data;machine learning algorithms;motion activity classification;phone function enhancement;smartphone;time-domain features","","","","12","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Realistic human action recognition: When deep learning meets VLAD","L. Zhang; Y. Feng; J. Han; X. Zhen","College of Information and Communication Engineering, Harbin Engineering University, Harbin, PRC","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","1352","1356","Human action recognition from realistic scenarios is extremely challenging due to large intra-class variation and complex background clutters. In this paper, by leveraging the strength of deep learning and vector of locally aggregated descriptors (VLAD), we propose a new methods for human action recognition from realistic datasets. We adopt stack convolutional independent subspace analysis (ISA) networks to learn 3D cuboid representation directly from spatio-temporal video data; we propose an improved VLAD by incorporating the spatio-temporal geometrical information to encode the deep learned local features. On two challenging realistic datasets: the YouTube action and HMDB51 datasets, the proposed method achieves state-of-the-art performance with an efficient linear SVM classifier, which is competitive with and even better than existing sophisticated algorithms.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471897","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471897","VLAD;convolutional ISA;deep learning;geometric information","Convolutional codes;Encoding;Kernel;Machine learning;Stacking;Three-dimensional displays;YouTube","convolution;geometry;image recognition;learning (artificial intelligence);vectors","ISA;VLAD vector;deep learning;geometrical information;human action recognition;locally aggregated descriptor;stack convolutional independent subspace analysis","","","","30","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Conditional Deep Learning for energy-efficient and enhanced pattern recognition","P. Panda; A. Sengupta; K. Roy","School of Electrical and Computer Engineering, Purdue University, USA","2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)","20160428","2016","","","475","480","Deep learning neural networks have emerged as one of the most powerful classification tools for vision related applications. However, the computational and energy requirements associated with such deep nets can be quite high, and hence their energy-efficient implementation is of great interest. Although traditionally the entire network is utilized for the recognition of all inputs, we observe that the classification difficulty varies widely across inputs in real-world datasets; only a small fraction of inputs require the full computational effort of a network, while a large majority can be classified correctly with very low effort. In this paper, we propose Conditional Deep Learning (CDL) where the convolutional layer features are used to identify the variability in the difficulty of input instances and conditionally activate the deeper layers of the network. We achieve this by cascading a linear network of output neurons for each convolutional layer and monitoring the output of the linear network to decide whether classification can be terminated at the current stage or not. The proposed methodology thus enables the network to dynamically adjust the computational effort depending upon the difficulty of the input data while maintaining competitive classification accuracy. We evaluate our approach on the MNIST dataset. Our experiments demonstrate that our proposed CDL yields 1.91× reduction in average number of operations per input, which translates to 1.84× improvement in energy. In addition, our results show an improvement in classification accuracy from 97.5% to 98.9% as compared to the original network.","","Electronic:978-3-9815-3707-9; POD:978-1-4673-9228-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459357","Conditional Activation;Deep Learning Convolutional Neural Network;Energy Efficiency;Enhanced Accuracy","Computational modeling;Energy efficiency;Feature extraction;Image recognition;Machine learning;Neurons;Training","computer vision;image classification;learning (artificial intelligence);neural nets","CDL;MNIST dataset;computer vision;conditional deep learning;convolutional layer;deep learning neural networks;energy-efficient pattern recognition;image classification;linear network output monitoring;output neuron linear network cascading","","","","19","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Labelling Topics in Weibo Using Word Embedding and Graph-Based Method","Z. Jin; Q. Li; C. Wang; D. D. Zeng; L. Wang","State Key Lab. of Manage. & Control for Complex Syst., Inst. of Autom., Beijing, China","2016 International Conference on Information Systems Engineering (ICISE)","20160609","2016","","","34","37","Nowadays, in China, Weibo is becoming an increasingly popular way for people to know what is happening in the world. Labelling topics is of much importance for better understanding the semantics of topics. Existing works mainly focus on deriving candidate labels by exploring the use of external knowledge, which may be more appropriate for well formatted and static documents. Recently, it has been a new trend to generate labels for sparse and dynamic microblogging environment using summarization method. The challenges of labelling topics are how to obtain coherent candidate labels and how to rank the labels. In this paper, based on the latest research work in deep learning, we propose a novel and unified model for labelling topics in Weibo, which firstly adopts word embedding and clustering method to learn dense semantic representation of topic words and mine the coherent candidate topic labels, then, generates interpretable labels using a graph-based model. Experimental results show that topics labels discovered by our model not only have high topic coherence, but also are meaningful and interpretable.","","Electronic:978-1-5090-2288-5; POD:978-1-5090-2289-2","10.1109/ICISE.2016.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486210","Weibo;deep learning;graph;labelling topics;microblogs","Coherence;Heuristic algorithms;Labeling;Machine learning;Modeling;Semantics;Xenon","data mining;graph theory;learning (artificial intelligence);pattern clustering;social networking (online)","China;Weibo;clustering method;coherent candidate topic label mining;deep learning;dynamic microblogging environment;graph-based method;sparse microblogging environment;summarization method;topic labelling;topic words dense semantic representation;word embedding","","","","14","","","20-22 April 2016","","IEEE","IEEE Conference Publications"
"Community detection using nonnegative matrix factorization with orthogonal constraint","Y. Qin; C. Jia; Y. Li","Department of Computer and Information Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing 100044, China","2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)","20160409","2016","","","49","54","Community structure is one of the most important properties for understanding the topology and function of a complex network. Recently, the rank reduction technique, non-negative matrix factorization (NMF), has been successfully used to uncover communities in complex networks. In the machine learning literature, the algorithm Alternating Constraint Least Squares (ACLS) is developed to perform NMF with sparsity constraint for clustering data and showed good performance, but it is not used in detecting communities in networks. In this study, we first test the ACLS algorithm on several synthetic and real networks to show its performance on community detection. Then we extend ACLS to orthogonal nonnegative matrix factorization, propose ALSOC, in which orthogonality constraint is added into NMF to discovery communities. The experimental results show that NMF with orthogonality constraint is able to improve the performance of community detection, meanwhile it has ability to maintain the sparsity of matrix factors.","","CD-ROM:978-1-4673-7778-2; Electronic:978-1-4673-7782-9; POD:978-1-4673-7783-6","10.1109/ICACI.2016.7449802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449802","alternating least squares;community detection;nonnegative matrix factorization","Algorithm design and analysis;Clustering algorithms;Complex networks;Linear matrix inequalities;Linear programming;Machine learning algorithms;Partitioning algorithms","learning (artificial intelligence);least squares approximations;matrix decomposition;network theory (graphs);pattern clustering;topology","ACLS algorithm;ALSOC;NMF;alternating constraint least squares;community detection;complex network;machine learning literature;matrix factor sparsity;orthogonal constraint;orthogonal nonnegative matrix factorization;rank reduction technique;topology","","","","42","","","14-16 Feb. 2016","","IEEE","IEEE Conference Publications"
"Exploring deep learning architectures for automatically grading non-native spontaneous speech","J. Tao; S. Ghaffarzadegan; L. Chen; K. Zechner","Educational Testing Service, 660 Rosedale Road, Princeton, NJ 08541, USA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6140","6144","We investigate two deep learning architectures reported to have superior performance in ASR over the conventional GMM system, with respect to automatic speech scoring. We use an approximately 800-hour large-vocabulary non-native spontaneous English corpus to build three ASR systems. One system is in GMM, and two are in deep learning architectures - namely, DNN and Tandem with bottleneck features. The evaluation results show that the both deep learning systems significantly outperform the GMM ASR. These ASR systems are used as the front-end in building an automated speech scoring system. To examine the effectiveness of the deep learning ASR systems for automated scoring, another non-native spontaneous speech corpus is used to train and evaluate the scoring models. Using deep learning architectures, ASR accuracies drop significantly on the scoring corpus, whereas the performance of the scoring systems get closer to human raters, and consistently better than the GMM one. Compared to the DNN ASR, the Tandem performs slightly better on the scoring speech while it is a little less accurate on the ASR evaluation dataset. Furthermore, given the results of the improved scoring performance while using fewer scoring features, the Tandem system shows more robustness for scoring task than the DNN one.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472857","automatic speech recognition;automatic speech scoring;bottleneck features;deep neural network;non-native spontaneous speech","Acoustics;Feature extraction;Hidden Markov models;Machine learning;Speech;Speech recognition;Training","Gaussian processes;learning (artificial intelligence);mixture models;neural nets;speech recognition","DNN learning architecture;GMM;Gaussian mixture model;Tandem learning architecture;automatic grading;automatic speech recognition;automatic speech scoring;bottleneck features;deep learning architecture;large vocabulary English corpus;nonnative spontaneous English corpus;nonnative spontaneous speech","","","","29","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Deep learning using heterogeneous feature maps for maxout networks","Y. Ishii; R. Hagawa; S. Tsukizawa","Panasonic Corporation, 1006 Kadoma, Kadoma City, Osaka 571-8501, Japan","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","459","463","We propose a novel type of maxout that uses filters with kernels of multiple sizes for generating convolved maps. These filters extract the most effective features for recognition from many different variations of texture patterns. A convolved map is generated by convolution between feature maps and filters. If the size of filters is varied, the size of the convolved map will also vary; in which case, since there are no correspondences among the positions of convolved maps, maxout will not work for these kinds of filters. To align the sizes of convolved maps, we converted, in advance, feature maps, which we term `heterogeneous feature maps,' using zero padding. Converting the size of feature maps in this way allows maxout to function, even with filters of different sizes. In this study we demonstrate the classification performances using our proposed maxout on MNIST, CIFAR-10, CIFAR-100, SVHN datasets, and show a 13.17% improvement of accuracy with augmented data.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486545","","Convolution;Error analysis;Feature extraction;Kernel;Machine learning;Neural networks;Training","feature extraction;image classification;image filtering;image texture;learning (artificial intelligence)","CIFAR-10;CIFAR-100;MNIST;SVHN dataset;classification performances;deep learning;feature extraction;feature filter;heterogeneous feature map;maxout network;texture pattern variation;zero padding","","","","13","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Enhancing RGB CNNs with depth","A. Sharma; K. P. Sankar","Xerox Research Centre India","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","031","035","Most current approaches for recognition in RGB-D images fall in either the late fusion or the early fusion category. A drawback of the early fusion scheme is its inapplicability when one of the modalities is absent at test time. On the other hand, a late fusion of features does not allow the correlated nature of modalities to be exploited effectively. Recent approaches using Deep Learning are not immune to these problems either. In this work, we propose a simple, yet elegant method towards combining early and late fusion of colour and depth information when training deep Convolutional Neural Networks (CNNs). We show that when fine-tuning CNNs, an intermediate depth pre-training step provides a significant jump in colour recognition accuracy. The trends are observed consistently over several benchmark RGB-D datasets.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486460","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486460","","Feature extraction;Image color analysis;Machine learning;Object recognition;Testing;Three-dimensional displays;Training","image colour analysis;learning (artificial intelligence);neural nets;object recognition","RGB CNN;RGB-D images;colour recognition accuracy;convolutional neural networks;deep learning;early fusion scheme;object recognition","","","","18","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Mediated experts for deep convolutional networks","S. Agethen; W. H. Hsu","National Taiwan University Graduate Institute of Networking and Multimedia","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","2687","2691","We present a new supervised architecture termed Mediated Mixture-of-Experts (MMoE) that allows us to improve classification accuracy of Deep Convolutional Networks (DCN). Our architecture achieves this with the help of expert networks: A network is trained on a disjoint subset of a given dataset and then run in parallel to other experts during deployment. A mediator is employed if experts contradict each other. This allows our framework to naturally support incremental learning, as adding new classes requires (re-)training of the new expert only. We also propose two measures to control computational complexity: An early-stopping mechanism halts experts that have low confidence in their prediction. The system allows to trade-off accuracy and complexity without further retraining. We also suggest to share low-level convo-lutional layers between experts in an effort to avoid computation of a near-duplicate feature set. We evaluate our system on a popular dataset and report improved accuracy compared to a single model of same configuration.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472165","Deep Learning;Incremental Learning;Mixture of Experts","Complexity theory;Computational modeling;Computer architecture;Machine learning;Neural networks;Neurons;Training","convolution;learning (artificial intelligence)","DCN;MMoE;classification accuracy improvement;computational complexity;deep convolutional networks;early-stopping mechanism;incremental learning;low-level convolutional layers;mediated mixture-of-experts;supervised architecture;trade-off accuracy","","","","11","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Beyond human recognition: A CNN-based framework for handwritten character recognition","L. Chen; S. Wang; W. Fan; J. Sun; S. Naoi","Fujitsu Research & Development Center, Beijing, China","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","695","699","Because of the various appearance (different writers, writing styles, noise, etc.), the handwritten character recognition is one of the most challenging task in pattern recognition. Through decades of research, the traditional method has reached its limit while the emergence of deep learning provides a new way to break this limit. In this paper, a CNN-based handwritten character recognition framework is proposed. In this framework, proper sample generation, training scheme and CNN network structure are employed according to the properties of handwritten characters. In the experiments, the proposed framework performed even better than human on handwritten digit (MNIST) and Chinese character (CASIA) recognition. The advantage of this framework is proved by these experimental results.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486592","","Character recognition;Distortion;Error analysis;Machine learning;Neurons;Training","handwritten character recognition;neural nets;pattern recognition","CNN-based framework;handwritten character recognition;human recognition;pattern recognition;sample generation;training scheme","","2","","23","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Learning to separate vocals from polyphonic mixtures via ensemble methods and structured output prediction","M. McVicar; R. Santos-Rodríguez; T. De Bie","Intelligent Systems Laboratory, Department of Engineering Mathematics, University of Bristol","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","450","454","Separating the singing from a polyphonic mixed audio signal is a challenging but important task, with a wide range of applications across the music industry and music informatics research. Various methods have been devised over the years, ranging from Deep Learning approaches to dedicated ad hoc solutions. In this paper, we present a novel machine learning method for the task, using a Conditional Random Field (CRF) approach for structured output prediction. We exploit the diversity of previously proposed approaches by using their predictions as input features to our method - thus effectively developing an ensemble method. Our empirical results demonstrate the potential of integrating predictions from different previously-proposed methods into one ensemble method, and additionally show that CRF models with larger complexities generally lead to superior performance.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471715","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471715","Singing voice separation;conditional random fields;ensemble method","Computational modeling;Harmonic analysis;Hidden Markov models;Machine learning;Radio frequency;Spectrogram;Time-frequency analysis","audio signal processing;learning (artificial intelligence);source separation","conditional random field approach;deep learning approach;ensemble method;machine learning method;polyphonic mixed audio signal;polyphonic mixtures;structured output prediction","","1","","33","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Research on Chinese Micro-Blog Sentiment Analysis Based on Deep Learning","L. Yanmei; C. Yuda","Wuhan Inst. of Design & Sci., Wuhan, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","1","","358","361","Micro-blog sentiment analysis aims to find user's attitude and opinion of hot events. Most of studies have used SVM, CRF and other traditional algorithms, which based on manual tagging of a lot of emotional characteristics, but paid a high price. To improve this situation, further studied deep learning and Micro-blog sentiment analysis, and proposed a new technical solution. It firstly crawled some data from Micro-blog through crawler, then after corpus pretreatment, as the input sample of Convolutional Neural Network, and built the classifier based on SVM/RNN, finally judged the emotional orientation of each sentence in a given test set. Verified by examples, experimental results show that this solution can effectively improve the accuracy of emotional orientation, validation result is ideal.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468968","Micro-blog;classifier;convolutional Neural Network;deep learning;sentiment analysis","Blogs;Crawlers;Feature extraction;Internet;Machine learning;Sentiment analysis;Training","Web sites;learning (artificial intelligence);neural nets;support vector machines","Chinese microblog sentiment analysis;RNN;SVM;convolutional neural network;corpus pretreatment;data crawler;deep learning;emotional orientation","","","","10","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Part-based deep network for pedestrian detection in surveillance videos","Q. Chen; W. Jiang; Y. Zhao; Z. Zhao","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","2015 Visual Communications and Image Processing (VCIP)","20160425","2015","","","1","4","Accurate pedestrian detection in highly crowded surveillance videos is a challenging task, since the regions of pedestrians in the videos may be largely occluded by other pedestrians. In this paper, we propose an effective part-based deep network cascade (HsNet) to solve this problem. In this model, the part-based scheme effectively restrains the appearance variations of pedestrians caused by heavy occlusion. The deep network captures discriminative information of visible body parts. In addition, the cascade architecture enables very fast detection. We make experiments on one of the largest surveillance video dataset, namely TRECVid SED Pedestrian Dataset (SED-PD). It is shown that in highly crowded surveillance videos, our proposed method achieves very competitive performance compared with state-of-the-art methods. More importantly, our method is significantly faster.","","Electronic:978-1-4673-7314-2; POD:978-1-4673-7315-9; USB:978-1-4673-7313-5","10.1109/VCIP.2015.7457855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457855","Pedestrian detection;body parts;cascade;deep network;occlusion handling","Airports;Deformable models;Machine learning;Proposals;Surveillance;Training;Videos","object detection;pedestrians;video signal processing;video surveillance","HsNet;SEDPD;TRECVid SED pedestrian dataset;heavy occlusion;part-based deep network;pedestrian detection;surveillance video","","","","16","","","13-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Improving Reliability of Monitoring Background EEG Dynamics in Asphyxiated Infants","V. Matić; P. J. Cherian; K. Jansen; N. Koolen; G. Naulaers; R. M. Swarte; P. Govaert; S. Van Huffel; M. De Vos","Department of Electrical Engineering, KU Leuven, Leuven, Belgium","IEEE Transactions on Biomedical Engineering","20160420","2016","63","5","973","983","The goal of this study is to develop an automated algorithm to quantify background electroencephalography (EEG) dynamics in term neonates with hypoxic ischemic encephalopathy. The recorded EEG signal is adaptively segmented and the segments with low amplitudes are detected. Next, depending on the spatial distribution of the low-amplitude segments, the first part of the algorithm detects (dynamic) interburst intervals (dIBIs) and performs well on the relatively artifact-free EEG periods and well-defined burst-suppression EEG periods. However, on testing the algorithm on EEG recordings of more than 48 h per neonate, a significant number of misclassified and dubious detections were encountered. Therefore, as the next step, we applied machine learning classifiers to differentiate between definite dIBI detections and misclassified ones. The developed algorithm achieved a true positive detection rate of 98%, 97%, 88%, and 95% for four duration-related dIBI groups that we subsequently defined. We benchmarked our algorithm with an expert diagnostic interpretation of EEG periods (1 h long) and demonstrated its effectiveness in clinical practice. We show that the detection algorithm effectively discriminates challenging cases encountered within mild and moderate background abnormalities. The dIBI detection algorithm improves identification of neonates with good clinical outcome as compared to the classification based on the classical burst-suppression interburst interval.","0018-9294;00189294","","10.1109/TBME.2015.2477946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7264998","Background electroencephalography (EEG);SVM;background EEG;interburst interval detection;interburst interval detection,;neonatal asphyxia;support vector machine (SVM);wavelets","Asphyxia;Classification algorithms;Electroencephalography;Heuristic algorithms;Machine learning algorithms;Monitoring;Pediatrics","electroencephalography;learning (artificial intelligence);medical signal processing;paediatrics;patient monitoring;signal classification","adaptive segmentation;algorithm detected interburst intervals;applied machine learning classifiers;asphyxiated infants;automated algorithm;background electroencephalography dynamics;burst-suppression EEG periods;classical burstsuppression interburst interval;clinical practice;definite dIBI detections;dubious detections;duration-related dIBI groups;expert diagnostic interpretation;hypoxic ischemic encephalopathy;low-amplitude segments;misclassified number;moderate background abnormalities;monitoring background EEG dynamics reliability;neonates;recorded EEG signal;relatively artifact-free EEG periods;spatial distribution;time 1 h","","","","31","","20150914","May 2016","","IEEE","IEEE Journals & Magazines"
"The BGP Visibility Toolkit: Detecting Anomalous Internet Routing Behavior","A. Lutu; M. Bagnulo; C. Pelsser; O. Maennel; J. Cid-Sueiro","Simula Research Laboratory, Norway","IEEE/ACM Transactions on Networking","20160414","2016","24","2","1237","1250","In this paper, we propose the BGP Visibility Toolkit, a system for detecting and analyzing anomalous behavior in the Internet. We show that interdomain prefix visibility can be used to single out cases of erroneous demeanors resulting from misconfiguration or bogus routing policies. The implementation of routing policies with BGP is a complicated process, involving fine-tuning operations and interactions with the policies of the other active ASes. Network operators might end up with faulty configurations or unintended routing policies that prevent the success of their strategies and impact their revenues. As part of the Visibility Toolkit, we propose the BGP Visibility Scanner, a tool which identifies limited visibility prefixes in the Internet. The tool enables operators to provide feedback on the expected visibility status of prefixes. We build a unique set of ground-truth prefixes qualified by their ASes as intended or unintended to have limited visibility. Using a machine learning algorithm, we train on this unique dataset an alarm system that separates with 95% accuracy the prefixes with unintended limited visibility. Hence, we find that visibility features are generally powerful to detect prefixes which are suffering from inadvertent effects of routing policies. Limited visibility could render a whole prefix globally unreachable. This points towards a serious problem, as limited reachability of a non-negligible set of prefixes undermines the global connectivity of the Internet. We thus verify the correlation between global visibility and global connectivity of prefixes.","1063-6692;10636692","","10.1109/TNET.2015.2413838","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091956","Anomaly detection;BGP;Internet measurement;machine assembly","Communities;Feeds;Internet;Machine learning algorithms;Monitoring;Routing;Writing","Internet;learning (artificial intelligence);telecommunication network routing","AS;BGP visibility scanner;BGP visibility toolkit;alarm system;anomalous Internet routing detection behavior;fine-tuning operation;interdomain prefix visibility;machine learning algorithm","","0","","43","","20150422","April 2016","","IEEE","IEEE Journals & Magazines"
"Modeling deep bidirectional relationships for image classification and generation","T. Nakashika; T. Takiguchi; Y. Ariki","The Univeristy of Electro-Communications, Graduate School of Information Systems","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","1327","1331","This paper presents a novel probabilistic model that represents a joint probability of two visible variables with a deep architecture, called a deep relational model (DRM). The model stacks several layers from one visible layer on to another visible layer, sandwiching hidden layers between them. As with restricted Boltzmann machines (RBMs) and deep Boltzmann machines (DBMs), all connections (weights) between two adjacent layers are undirected. During the maximum-likelihood (ML)-based training, the network attempts to capture latent complex relationships between two visible variables (e.g., an image showing a certain number and its corresponding label) thanks to its deep architecture. Unlike deep neural networks, 1) the proposed DRM is a totally generative model, and 2) the weights can be optimized in a probabilistic manner. This paper presents and discusses the experiments conduced to evaluate our DRM's performance in recognition and generation tasks.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471892","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471892","Image classification;deep learning;generative model;image generation","Data models;Feedforward neural networks;Machine learning;Probabilistic logic;Probability distribution;Training","Boltzmann machines;image classification;maximum likelihood estimation;probability","DBM;DRM;ML-based training;RBM;deep Boltzmann machines;deep architecture;deep relational model;generative model;image classification;image generation;latent complex relationships;maximum-likelihood-based training;probabilistic model;recognition tasks;restricted Boltzmann machines;visible variables","","","","12","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images","K. Sirinukunwattana; S. E. A. Raza; Y. W. Tsang; D. R. J. Snead; I. A. Cree; N. M. Rajpoot","Department of Computer Science, University of Warwick, Coventry, UK","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1196","1206","Detection and classification of cell nuclei in histopathology images of cancerous tissue stained with the standard hematoxylin and eosin stain is a challenging task due to cellular heterogeneity. Deep learning approaches have been shown to produce encouraging results on histopathology images in various studies. In this paper, we propose a Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection. SC-CNN regresses the likelihood of a pixel being the center of a nucleus, where high probability values are spatially constrained to locate in the vicinity of the centers of nuclei. For classification of nuclei, we propose a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei. The proposed approaches for detection and classification do not require segmentation of nuclei. We have evaluated them on a large dataset of colorectal adenocarcinoma images, consisting of more than 20,000 annotated nuclei belonging to four different classes. Our results show that the joint detection and classification of the proposed SC-CNN and NEP produces the highest average F1 score as compared to other recently published approaches. Prospectively, the proposed methods could offer benefit to pathology practice in terms of quantitative analysis of tissue constituents in whole-slide images, and potentially lead to a better understanding of cancer.","0278-0062;02780062","","10.1109/TMI.2016.2525803","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399414","Convolutional neural network;deep learning;histology image analysis;nucleus detection","Cancer;Computer architecture;Feature extraction;Machine learning;Microprocessors;Shape;Tumors","biological organs;biomedical optical imaging;cancer;cellular biophysics;image classification;learning (artificial intelligence);medical image processing;probability;tumours","NEP;SC-CNN;cancerous tissue;cell nuclei classification;cell nuclei detection;cellular heterogeneity;colorectal adenocarcinoma images;dataset;eosin stain;high-probability values;highest average F1 score;histopathology images;joint detection;locality sensitive deep learning;neighboring ensemble predictor;quantitative analysis;routine colon cancer histology images;spatially constrained convolutional neural network;standard hematoxylin;tissue constituents;whole-slide images","","9","","38","","20160204","May 2016","","IEEE","IEEE Journals & Magazines"
"Marginal Space Deep Learning: Efficient Architecture for Volumetric Image Parsing","F. C. Ghesu; E. Krubasik; B. Georgescu; V. Singh; Y. Zheng; J. Hornegger; D. Comaniciu","Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1217","1228","Robust and fast solutions for anatomical object detection and segmentation support the entire clinical workflow from diagnosis, patient stratification, therapy planning, intervention and follow-up. Current state-of-the-art techniques for parsing volumetric medical image data are typically based on machine learning methods that exploit large annotated image databases. Two main challenges need to be addressed, these are the efficiency in scanning high-dimensional parametric spaces and the need for representative image features which require significant efforts of manual engineering. We propose a pipeline for object detection and segmentation in the context of volumetric image parsing, solving a two-step learning problem: anatomical pose estimation and boundary delineation. For this task we introduce Marginal Space Deep Learning (MSDL), a novel framework exploiting both the strengths of efficient object parametrization in hierarchical marginal spaces and the automated feature design of Deep Learning (DL) network architectures. In the 3D context, the application of deep learning systems is limited by the very high complexity of the parametrization. More specifically 9 parameters are necessary to describe a restricted affine transformation in 3D, resulting in a prohibitive amount of billions of scanning hypotheses. The mechanism of marginal space learning provides excellent run-time performance by learning classifiers in clustered, high-probability regions in spaces of gradually increasing dimensionality. To further increase computational efficiency and robustness, in our system we learn sparse adaptive data sampling patterns that automatically capture the structure of the input. Given the object localization, we propose a DL-based active shape model to estimate the non-rigid object boundary. Experimental results are presented on the aortic valve in ultrasound using an extensive dataset of 2891 volumes from 869 patients, showing significant improvements of up to 45.2% o- er the state-of-the-art. To our knowledge, this is the first successful demonstration of the DL potential to detection and segmentation in full 3D data with parametrized representations.","0278-0062;02780062","","10.1109/TMI.2016.2538802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426845","Deep learning;image parsing;marginal space learning;sparse representations;three-dimensional (3D) object detection and segmentation","Context;Feature extraction;Image segmentation;Machine learning;Robustness;Shape;Three-dimensional displays","biomedical ultrasonics;feature extraction;image classification;image sampling;image segmentation;learning (artificial intelligence);medical image processing;pattern clustering;probability;ultrasonic imaging","3D context;DL-based active shape model;anatomical object detection;anatomical pose estimation;annotated image databases;aortic valve;automated feature design;boundary delineation;clinical workflow;clustered high-probability regions;computational efficiency;deep learning network architectures;deep learning systems;diagnosis;extensive dataset;full 3D data detection;full 3D data segmentation;hierarchical marginal spaces;learning classifiers;machine learning methods;marginal space deep learning;nonrigid object boundary;object localization;object parametrization;parametrized representations;patient stratification;representative image features;restricted affine transformation;run-time performance;scanning high-dimensional parametric spaces;scanning hypotheses;segmentation support;sparse adaptive data sampling patterns;therapy planning;two-step learning problem;ultrasound;volumetric medical image data parsing","","6","","46","","20160307","May 2016","","IEEE","IEEE Journals & Magazines"
"ALADDIN: A locality aligned deep model for instance search","W. Jiang; Z. Zhao; F. Su; A. Cai","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","2727","2731","Most instance search systems are based on modeling local features. It remains a challenge to apply deep learning techniques into this task because of the asymmetrical similarity between the query region and dataset images. In this paper, we propose ALADDIN, A Locality Aligned Deep moDel for INstance search. This model deals with the asymmetrical similarity by searching query instances at the scale of aligned target regions instead of the whole image. Towards discriminative region representations, we utilize a deep convolutional network which captures both intra-class and inter-class distinctions of the regions. In addition, we propose a semi-supervised method to collect appropriate data to train the network. Extensive experiments confirm that our method is more suitable for generic instance search than most conventional methods, and outperforms the best CNNs-based method in both accuracy and efficiency.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472173","Deep learning;asymmetrical similarity;instance search;intra-class distinction;object proposal","Feature extraction;Machine learning;Mathematical model;Proposals;Search problems;Training;Training data","convolution;image retrieval;learning (artificial intelligence);object recognition;search problems","ALADDIN;aligned target regions;asymmetrical similarity;dataset images;deep convolutional network;deep learning techniques;discriminative region representations;instance search systems;inter-class distinctions;intra-class distinctions;local features modeling;locality aligned deep model for instance search;query instances;query region;semi-supervised method","","","","24","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images","S. Albarqouni; C. Baur; F. Achilles; V. Belagiannis; S. Demirci; N. Navab","Chair for Computer Aided Medical Procedure (CAMP), Technische Universit&#x00E4;t M&#x00FC;nchen (TUM), Munich, Germany","IEEE Transactions on Medical Imaging","20160502","2016","35","5","1313","1321","The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration.","0278-0062;02780062","","10.1109/TMI.2016.2528120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405343","Aggregation;crowdsourcing;deep learning;gamification;online learning","Biomedical imaging;Computational modeling;Crowdsourcing;Data models;Machine learning;Noise measurement;Robustness","biological organs;cancer;data aggregation;image classification;image denoising;learning (artificial intelligence);medical image processing","biomedical image database;breast cancer histology imaging;conventional machine-learning methods;convolutional neural network;crowd annotation datasets;crowd flower API;crowd sourcing layer;data aggregation;deep CNN learning;ground-truth data;image annotation tasks;learning annotation models;learning process;mitosis detection;noisy annotations;self-implemented web-platform","","9","","38","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Implementing Kernel Methods Incrementally by Incremental Nonlinear Projection Trick","N. Kwak","Graduate School of Convergence Science and Technology, Seoul National University, Seoul 443-270, South Korea.","IEEE Transactions on Cybernetics","","2016","PP","99","1","7","Recently, the nonlinear projection trick (NPT) was introduced enabling direct computation of coordinates of samples in a reproducing kernel Hilbert space. With NPT, any machine learning algorithm can be extended to a kernel version without relying on the so called kernel trick. However, NPT is inherently difficult to be implemented incrementally because an ever increasing kernel matrix should be treated as additional training samples are introduced. In this paper, an incremental version of the NPT (INPT) is proposed based on the observation that the centerization step in NPT is unnecessary. Because the proposed INPT does not change the coordinates of the old data, the coordinates obtained by INPT can directly be used in any incremental methods to implement a kernel version of the incremental methods. The effectiveness of the INPT is shown by applying it to implement incremental versions of kernel methods such as, kernel singular value decomposition, kernel principal component analysis, and kernel discriminant analysis which are utilized for problems of kernel matrix reconstruction, letter classification, and face image retrieval, respectively.","2168-2267;21682267","","10.1109/TCYB.2016.2565683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475867","Incremental kernel methods;incremental nonlinear projection trick;kernel methods;kernel trick;nonlinear projection trick","Eigenvalues and eigenfunctions;Kernel;Machine learning algorithms;Matrix decomposition;Principal component analysis;Training;Training data","","","","","","","","20160520","","","IEEE","IEEE Early Access Articles"
"Intelligent Brain Tumor lesion classification and identification from MRI images using k-NN technique","K. Sudharani; T. C. Sarma; K. Satya Rasad","VNR Vignana Jyothi IET, Hyderabad, Telangana, India","2015 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT)","20160523","2015","","","777","780","The Magnetic Resonance Imaging (MRI), and Computed Tomography (CT) provides scanned images for Brain Tumor detection. Growth of abnormal cells in uncontrolled manner is tumor. The present paper proposed the classification and identification scores of brain tumor by using k-NN algorithm which is based on training of k. In this work Manhattan metric has applied and calculated the distance of the classifier. The algorithm has been implemented using the Lab View.","","Electronic:978-1-4673-9825-1; POD:978-1-4673-9826-8","10.1109/ICCICCT.2015.7475384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475384","CT;Identification score and classification score;LabVIEW;MRI scan;Manhattan distance metric;k-NN","Clustering algorithms;Computed tomography;Conferences;Image segmentation;Machine learning algorithms;Magnetic resonance imaging;Tumors","biomedical MRI;brain;computerised tomography;image classification;medical image processing;nonparametric statistics;regression analysis;tumours;virtual instrumentation","CT images;LabView;MRI images;Manhattan metric;abnormal cell growth;brain tumor detection;classifier distance;computed tomography;image scanning;intelligent brain tumor lesion classification score;intelligent brain tumor lesion identification score;k-NN technique;magnetic resonance imaging","","","","13","","","18-19 Dec. 2015","","IEEE","IEEE Conference Publications"
"Deep learning the dynamic appearance and shape of facial action units","S. Jaiswal; M. Valstar","The University of Nottingham","2016 IEEE Winter Conference on Applications of Computer Vision (WACV)","20160526","2016","","","1","8","Spontaneous facial expression recognition under uncontrolled conditions is a hard task. It depends on multiple factors including shape, appearance and dynamics of the facial features, all of which are adversely affected by environmental noise and low intensity signals typical of such conditions. In this work, we present a novel approach to Facial Action Unit detection using a combination of Convolutional and Bi-directional Long Short-Term Memory Neural Networks (CNN-BLSTM), which jointly learns shape, appearance and dynamics in a deep learning manner. In addition, we introduce a novel way to encode shape features using binary image masks computed from the locations of facial landmarks. We show that the combination of dynamic CNN features and Bi-directional Long Short-Term Memory excels at modelling the temporal information. We thoroughly evaluate the contributions of each component in our system and show that it achieves state-of-the-art performance on the FERA-2015 Challenge dataset.","","Electronic:978-1-5090-0641-0; POD:978-1-5090-0642-7","10.1109/WACV.2016.7477625","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477625","","Computer architecture;Face recognition;Feature extraction;Gold;Machine learning;Neural networks;Shape","emotion recognition;face recognition;feature extraction;learning (artificial intelligence);neural nets;shape recognition","CNN-BLSTM;FERA-2015 Challenge dataset;appearance learning;bidirectional long short-term memory neural network;binary image mask;convolutional neural network;deep learning;dynamic appearance;environmental noise;facial action unit;facial features;facial landmark location;low intensity signals;shape feature encoding;shape learning;spontaneous facial expression recognition;temporal information","","","","29","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"New approaches to incremental learning good classification tests","X. Naidenova; V. Parkhomenko; K. Shvetsov","Military Medical Academy, St. Petersburg, Russia","2016 International Conference on Information Technology for Organizations Development (IT4OD)","20160526","2016","","","1","6","The paper is devoted to incremental inferring of a special kind of logical classification rules called good tests. They are ""good"" because they cover the largest possible number of objects w.r.t. inclusion relation on the set of all subsets of objects. Moreover we are interested in such good tests which are maximally redundant (GMRTs), i.e. their subsets of attributes are closed. Incremental learning allows to have more flexible control of GMRTs inferring than a usual (batch) case of learning. We develop two new generic approaches to infer GMRTs. First approach provides learning with a use of pattern recognition-like processes. Second approach implements an object taxonomic organisation. All considerations are supplied with running examples.","","Electronic:978-1-4673-7689-1; POD:978-1-4673-7690-7","10.1109/IT4OD.2016.7479310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479310","Good classification test;classification;closed sets;cluster;formal concepts;implications;incremental learning;logical rules","Clustering algorithms;Cognition;Electronic mail;Lattices;Machine learning algorithms;Pattern recognition;Training","learning (artificial intelligence);pattern classification;set theory","GMRT;good tests;inclusion relation;incremental learning good classification tests;logical classification rules;object subsets;object taxonomic organisation;pattern recognition-like process","","","","22","","","March 30 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Deep learning for extracting word-level meaning from safety report narratives","A. Chanen","MITRE Corporation, McLean, VA, USA","2016 Integrated Communications Navigation and Surveillance (ICNS)","20160609","2016","","","5D2-1","5D2-15","Much of aviation safety reporting data consists of structured data e.g., digital flight data or radar data. However, safety report narratives, which come in the form of unstructured text data, are indispensable for safety reporting. Structured data alone is inadequate to capture all of the details of an incident while narratives can and do represent a myriad of details in a form that is natural for analysts to work with. However, large-scale analysis of narratives comes with many challenges: 1) it is difficult to employ enough human experts to digest the continuous flow of new incident reports 2) authors of incident reports use many different terms to refer to the same semantic concept, which makes it more difficult to determine if a specific concept occurs in texts 3) authors often make spelling mistakes and 4) authors use a wide variety of abbreviations for terms, some of which are nonstandard. These challenges can be mitigated by the intelligent use of Natural Language Processing (NLP) and Deep Learning techniques to automate parts of narrative processing. Specifically, we show how to use ensembles of word2vec models to automatically find semantically similar terms within safety report corpora and how to use a combination of human expertise and these ensemble models to identify sets of similar terms with greater recall then either method alone. We also show an unsupervised method for comparing several word2vec models trained on the same data in order to estimate reasonable ranges of vector sizes to induce individual word2vec models. This method is based on measuring inter-model agreement on common word2vec similar terms.","","Electronic:978-1-5090-2149-9; POD:978-1-5090-2150-5","10.1109/ICNSURV.2016.7486358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486358","","Data models;Machine learning;Natural language processing;Predictive models;Safety;Semantics;Training","avionics;natural language processing;text analysis;unsupervised learning","NLP;aviation safety reporting data;deep learning techniques;inter-model agreement;large-scale analysis;natural language processing;unsupervised method;word-level meaning;word2vec models","","","","6","","","19-21 April 2016","","IEEE","IEEE Conference Publications"
"Multi-staged deep learning with created coarse and appended fine categories","R. Hagawa; Y. Ishii; S. Tsukizawa","Panasonic Corporation, 1006 Kadoma, Kadoma City, Osaka 571-8501, Japan","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","036","040","This paper proposes a new learning method for Deep Learning based on the concept of a Coarse-to-Fine approach. The Coarse-to-Fine classification improves Deep Learning performance, but it increases network size and presents the problem of close dependence on the accuracy of coarse classification. We tried to avoid this problem by adopting the concept of Curriculum Learning and succeeded in improving the accuracy of Deep Learning. This technique uses learning that employs a single closed image dataset several times in the same network except for the last layer. In this process, coarse labels are given to the images during the pre-training stages and fine labels are given to the same images at the fine-tuning stage. This coarse category pre-training method makes it possible to obtain those features that commonly exist in multiple fine categories. To demonstrate the advantage of this technique, several patterns of a dataset in the quantity of several tens of classes and a single dataset of 100 classes were produced using the ImageNet dataset and compared with the previous technique. The results showed a 5.7% improvement of TOP1 accuracy, with the best case confirmed in the 100-class dataset.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486461","","Convolutional codes;Decision support systems;Image recognition;Learning systems;Machine learning;Neural networks;Pattern recognition","image classification;learning (artificial intelligence)","ImageNet dataset;coarse-to-fine classification;curriculum learning;deep learning performance improvement;fine-tuning stage;multistaged deep learning;pretraining stages;single closed image dataset","","","","16","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"An Adaptive Transcursive Algorithm for Depth Estimation in Deep Learning Networks","U. K. Thikshaja; A. Paul; S. Rho; D. Bhattacharjee","Sch. of Comput. Sci. & Eng., Kyungpook Nat. Univ., Daegu, South Korea","2016 International Conference on Platform Technology and Service (PlatCon)","20160421","2016","","","1","3","Estimation of depth in a Neural Network (NN) or Artificial Neural Network (ANN) is an integral as well as complicated process. In this article, we propose a way of using the transformation of functions combined with recursive nature to have an adaptive, transcursive algorithm to represent the backpropagation concept used in deep learning for a Multilayer Perceptron Network. Each function can be used to represent a hidden layer used in the neural network and they can be made to handle a complex part of the processing. Whenever an undesirable output occurs, we transform (modify) the functions until a desirable output is obtained. We have an algorithm that uses the transcursive model to create an interpretation of the concept of deep learning using multilayer perceptron network (MPN).","","Electronic:978-1-4673-8685-2; POD:978-1-4673-8686-9","10.1109/PlatCon.2016.7456783","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456783","","Artificial neural networks;Backpropagation;Complexity theory;Computer science;Machine learning;Multilayer perceptrons;Training","backpropagation;multilayer perceptrons","ANN;MPN;adaptive transcursive algorithm;artificial neural network;backpropagation concept;deep learning networks;depth estimation;function transformation;multilayer perceptron network","","","","5","","","15-17 Feb. 2016","","IEEE","IEEE Conference Publications"
"Deep segmentation networks using “simple” multi-layered graphical models","R. B. Porter; B. G. Zimmer","Kitware Inc., Santa Fe, NM, 87505, United States","2016 IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)","20160428","2016","","","41","44","This paper provides a new perspective on a number of traditional unsupervised segmentation methods, and a number of more recent segmentation methods, in terms of multi-layered graphical models and supervised learning. This perspective suggests a family of segmentation methods, which we call deep segmentation networks that are different, but complementary, to the typical deep network used for classification. One of the biggest differences in DSNs is the pooling layer. Deep classification networks typically use pre-specified fixed pooling regions, while deep segmentation networks use data adaptive pooling regions. We investigate some of the architectural choices with these new architectures in experiments with benchmark data and suggest directions for future work.","","Electronic:978-1-4673-9919-7; POD:978-1-4673-9920-3; USB:978-1-4673-9918-0","10.1109/SSIAI.2016.7459170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459170","Deep Learning;Graphical Models;Segmentation","Feeds;Graphical models;Image segmentation;Labeling;Machine learning;Semantics;Training","image classification;image segmentation;learning (artificial intelligence)","DSN;data adaptive pooling regions;deep classification networks;deep segmentation networks;pooling layer;prespecified fixed pooling regions;simple multilayered graphical models;supervised learning;unsupervised segmentation methods","","","","15","","","6-8 March 2016","","IEEE","IEEE Conference Publications"
"Performance evaluation of distance measures for preprocessing of set-valued data in feature vector generated from LOD datasets","R. Mahule; A. Garg; N. Kumar; O. P. Vyas","IIIT Allahabad India","2015 IEEE UP Section Conference on Electrical Computer and Electronics (UPCON)","20160421","2015","","","1","5","The linked open data cloud has evolved as a huge repository of data with data from various domains. A lot of work has been done in generating these datasets and enhancing the LOD cloud, whereas a little work is being done in the consumption of the available data from the LOD. There are several types of applications that have been developed using the data from the LOD cloud; of which, one of the areas that has attracted the researchers and developers most is the use of these data for machine learning and knowledge discovery. Using the available, state of the art knowledge discovery and machine learning algorithms requires conversion of the heterogeneous interlinked RDF graph datasets, available in LOD cloud, to a feature vector. This conversion is performed with the subject set as instances; the predicates set as attributes and object set as attribute values in a feature vector. The converted feature vector may contain set-valued attributes as there can be more than one object for a subject with the same predicate name. These set-valued data in the attribute of the feature vector needs to be pre-processed so that the feature vector contains attributes with single values only and can be used directly in machine learning algorithms. The pre-processing approach involves distance calculation and application of Fastmap algorithm for transformation of set-valued data attribute into k columns, which are replaced in the feature vector making the feature vector appropriate to be used as input for knowledge discovery and machine learning. However choosing the most suitable distance measures of the different distance measures available is a problem that needs to be catered. This paper provides a performance study to select the most suitable distance measure that can be used in pre-processing by building the feature vector with the different distance measures for set-valued data attributes and applying transformation with Fastmap. The evaluation of the d- stance measures is done using clustering of the transformed feature vector table with pre-identified class labels and getting micro-precision values for the clustering results. Performing the experimental analysis with LMDB data it has been found that the Hausdorff and RIBL distance measures are the most suitable distance measures that can be used to pre-process the created feature vector with set-valued data from the linked open data cloud.","","Electronic:978-1-4673-8507-7; POD:978-1-4673-8508-4","10.1109/UPCON.2015.7456692","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456692","Linked Open Data;Set-valued data;data mining with RDF data","Couplings;Data mining;Feature extraction;Knowledge discovery;Machine learning algorithms;Resource description framework;Size measurement","cloud computing;data mining;learning (artificial intelligence);pattern clustering;performance evaluation;semantic Web","Fastmap algorithm;Hausdorff distance measures;LMDB data;LOD cloud;LOD datasets;RIBL distance measures;distance calculation;feature vector;heterogeneous interlinked RDF graph datasets;knowledge discovery algorithm;linked open data cloud;machine learning algorithms;performance evaluation;set-valued data preprocessing","","","","13","","","4-6 Dec. 2015","","IEEE","IEEE Conference Publications"
"Cosaliency Detection Based on Intrasaliency Prior Transfer and Deep Intersaliency Mining","D. Zhang; J. Han; J. Han; L. Shao","School of Automation, Northwestern Polytechnical University, Xi&#x2019;an, China","IEEE Transactions on Neural Networks and Learning Systems","20160516","2016","27","6","1163","1176","As an interesting and emerging topic, cosaliency detection aims at simultaneously extracting common salient objects in multiple related images. It differs from the conventional saliency detection paradigm in which saliency detection for each image is determined one by one independently without taking advantage of the homogeneity in the data pool of multiple related images. In this paper, we propose a novel cosaliency detection approach using deep learning models. Two new concepts, called intrasaliency prior transfer and deep intersaliency mining, are introduced and explored in the proposed work. For the intrasaliency prior transfer, we build a stacked denoising autoencoder (SDAE) to learn the saliency prior knowledge from auxiliary annotated data sets and then transfer the learned knowledge to estimate the intrasaliency for each image in cosaliency data sets. For the deep intersaliency mining, we formulate it by using the deep reconstruction residual obtained in the highest hidden layer of a self-trained SDAE. The obtained deep intersaliency can extract more intrinsic and general hidden patterns to discover the homogeneity of cosalient objects in terms of some higher level concepts. Finally, the cosaliency maps are generated by weighted integration of the proposed intrasaliency prior, deep intersaliency, and traditional shallow intersaliency. Comprehensive experiments over diverse publicly available benchmark data sets demonstrate consistent performance gains of the proposed method over the state-of-the-art cosaliency detection methods.","2162-237X;2162237X","","10.1109/TNNLS.2015.2495161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7327212","Cosaliency detection;deep learning;prior transfer;stacked denoising autoencoder (SDAE);stacked denoising autoencoder (SDAE).","Data mining;Encoding;Feature extraction;Machine learning;Robustness;Training;Visualization","data mining;image coding;image denoising;learning (artificial intelligence);object detection","auxiliary annotated datasets;cosaliency detection;data pool;deep intersaliency mining;deep learning models;deep reconstruction residual;intrasaliency prior transfer;publicly available benchmark datasets;saliency detection paradigm;self-trained SDAE;shallow intersaliency;stacked denoising autoencoder","","3","","53","","20151111","June 2016","","IEEE","IEEE Journals & Magazines"
"A Learning to Rank Framework for Developer Recommendation in Software Crowdsourcing","J. Zhu; B. Shen; F. Hu","Sch. of Software Shanghai, Jiao Tong Univ., Shanghai, China","2015 Asia-Pacific Software Engineering Conference (APSEC)","20160512","2015","","","285","292","Recently, crowdsourcing has been widely used in many tasks that computers are not good at such as image recognition, entity resolution or some question answering tasks. A key feature of these tasks is that they are all simple tasks even decision making tasks. People can deal with these tasks with common sense knowledge. However, different from crowdsourcing in a general domain, software crowdsourcing is more complex. Only people with software developing skills can finish these tasks which could take a long time. Thus, an essential component of building a successful software crowdsourcing platform is effective developer recommendation, which aims to match a given task to the right crowdworkers. In order to solve this problem, in this paper, we propose a learning to rank framework. Specifically, we first propose a CRF-based model to extract criterias (i.e. skills and locations) from descriptions. Task characteristics learned from their descriptions and developer' characteristic distributions extracted from their historical tasks are fed into our learning to rank algorithms for developer recommendation together with some other features such as topic-based features. We have evaluated our approach on a large dataset crawled from a real-world software crowdsourcing platform. The experimental results show that our approach is feasible and effective.","","Electronic:978-1-4673-9644-8; POD:978-1-4673-9645-5","10.1109/APSEC.2015.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467312","Developer Recommendation;Software Crowdsourcing;Software Engineering","Crowdsourcing;Data mining;Feature extraction;Hidden Markov models;Labeling;Machine learning algorithms;Software","software engineering","CRF-based model;developer recommendation;software crowdsourcing platform;software engineering;topic-based features","","1","","32","","","1-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"Demonstration Abstract: Accelerating Embedded Deep Learning Using DeepX","N. D. Lane; S. Bhattacharya; P. Georgiev; C. Forlivesi; F. Kawsar","Bell Labs., USA","2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","20160428","2016","","","1","2","Deep learning has revolutionized the way sensor measurements are interpreted and application of deep learning has seen a great leap in inference accuracies in a number of fields. However, the significant requirement for memory and computational power has hindered the wide scale adoption of these novel computational techniques on resource constrained wearable and mobile platforms. In this demonstration we present DeepX, a software accelerator for efficiently running deep neural networks and convolutional neural networks on resource constrained embedded platforms, e.g., Nvidia Tegra K1 and Qualcomm Snapdragon 400.","","Electronic:978-1-5090-0802-5; POD:978-1-5090-0803-2","10.1109/IPSN.2016.7460666","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460666","","Computational modeling;Computer architecture;Image recognition;Machine learning;Mobile communication;Neural networks;Prototypes","embedded systems;learning (artificial intelligence);mobile computing;neural nets;sensors","DeepX;Nvidia Tegra K1;Qualcomm Snapdragon 400;computational power;computational techniques;convolutional neural networks;deep neural networks;embedded deep learning;inference accuracies;mobile platforms;resource constrained embedded platforms;resource constrained wearable platforms;sensor measurements;software accelerator","","","","7","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"q-Space Deep Learning: Twelve-Fold Shorter and Model-Free Diffusion MRI Scans","V. Golkov; A. Dosovitskiy; J. I. Sperl; M. I. Menzel; M. Czisch; P. Sämann; T. Brox; D. Cremers","The Department of Computer Science, Technical University of Munich, Garching, Germany","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1344","1351","Numerous scientific fields rely on elaborate but partly suboptimal data processing pipelines. An example is diffusion magnetic resonance imaging (diffusion MRI), a non-invasive microstructure assessment method with a prominent application in neuroimaging. Advanced diffusion models providing accurate microstructural characterization so far have required long acquisition times and thus have been inapplicable for children and adults who are uncooperative, uncomfortable, or unwell. We show that the long scan time requirements are mainly due to disadvantages of classical data processing. We demonstrate how deep learning, a group of algorithms based on recent advances in the field of artificial neural networks, can be applied to reduce diffusion MRI data processing to a single optimized step. This modification allows obtaining scalar measures from advanced models at twelve-fold reduced scan time and detecting abnormalities without using diffusion models. We set a new state of the art by estimating diffusion kurtosis measures from only 12 data points and neurite orientation dispersion and density measures from only 8 data points. This allows unprecedentedly fast and robust protocols facilitating clinical routine and demonstrates how classical data processing can be streamlined by means of deep learning.","0278-0062;02780062","","10.1109/TMI.2016.2551324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448418","Artificial neural networks;diffusion kurtosis imaging (DKI);diffusion magnetic resonance imaging (diffusion MRI);neurite orientation dispersion and density imaging (NODDI)","Data processing;Diffusion tensor imaging;Fitting;Machine learning;Pipelines;Training","biodiffusion;biomedical MRI;data acquisition;learning (artificial intelligence);medical image processing;neural nets;neurophysiology;optimisation","accurate microstructural characterization;acquisition times;adults;artificial neural networks;children;classical data processing;clinical routine;data points;diffusion MRI data processing;diffusion kurtosis;diffusion magnetic resonance imaging;model-free diffusion MRI scans;neurite orientation dispersion;neuroimaging;noninvasive microstructure assessment method;q-space deep learning;scalar measures;single optimized step;suboptimal data processing pipelines;twelve-fold reduced scan time;twelve-fold shorter diffusion MRI scans","","2","","52","","20160406","May 2016","","IEEE","IEEE Journals & Magazines"
"A comparative study of various clustering techniques on big data sets using Apache Mahout","V. R. Eluri; M. Ramesh; A. S. M. Al-Jabri; M. Jane","Dept. of Information Technology, Shinas College of Technology, Shinas, Oman","2016 3rd MEC International Conference on Big Data and Smart City (ICBDSC)","20160428","2016","","","1","4","Clustering algorithms have materialized as an unconventional tool to precisely examine the immense volume of data produced by present applications. In specific, their main objective is to classify data into clusters such that objects are grouped in the same cluster when they are similar rendering to particular metrics and dissimilar to objects of other groups. From the machine learning perspective clustering can be viewed as unsupervised learning of concepts. Hadoop is a distributed file system and an open-source implementation of MapReduce dealing with big data. Apache Mahout clustering algorithms are implemented on top of Hadoop using MapReduce paradigm. In this paper three clustering algorithms are described: K-means, Fuzzy K-Means (FKM) and Canopy clustering implemented by using Apache Mahout as well as providing a comparison. In addition, we underlined the clustering algorithms that are the preeminent performing for big data.","","Electronic:978-1-4673-9584-7; POD:978-1-4673-9585-4","10.1109/ICBDSC.2016.7460397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460397","Apache Mahout;Canopy clustering;Clustering Algorithm;Fuzzy K-Means;K-means;big data","Big data;Clustering algorithms;Electronic mail;Image segmentation;Information technology;Machine learning algorithms;Smart cities","Big Data;fuzzy set theory;learning (artificial intelligence);network operating systems;pattern clustering","Apache Mahout clustering algorithms;Canopy clustering;FKM;Hadoop;MapReduce dealing;MapReduce paradigm;big data sets;clustering techniques;distributed file system;fuzzy k-means;machine learning perspective clustering;open source;rendering;unsupervised learning","","","","10","","","15-16 March 2016","","IEEE","IEEE Conference Publications"
"Integrated Optimization of Long-Range Underwater Signal Detection, Feature Extraction, and Classification for Nuclear Treaty Monitoring","M. Tuma; V. Rørbech; M. K. Prior; C. Igel","Institute for Neural Computation (INI), Ruhr-University Bochum, Bochum, Germany","IEEE Transactions on Geoscience and Remote Sensing","20160427","2016","54","6","3649","3659","We designed and jointly optimized an integrated signal processing chain for detection and classification of long-range passive-acoustic underwater signals recorded by the global geophysical monitoring network of the Comprehensive Nuclear-Test-Ban Treaty Organization. Starting at the level of raw waveform data, a processing chain of signal detection, feature extraction, and signal classification was designed and jointly optimized to the task. Relevant waveform segments were in a first step identified by a generic, flexibly parameterized detection algorithm on a long- to short-term averages' ratio of the spectral energy. For representation, general-purpose sound processing features, with an added focus on spectral and cepstral features, were extracted from the detected segments. As classifiers, support vector machines with different kernel functions were employed alongside other baseline learning algorithms. The free parameters of the overall toolchain (i.e., trigger algorithm parameters and classifier hyperparameters) were jointly optimized in a cross-validation setting, either according to the cross-validation classification error or the cross-validation area under the receiver operating characteristic curve. Experiments demonstrate that our method outperforms machine learning algorithms task-tailored to a previous, human-expert-designed preprocessing chain. The presented approach can be adapted to a wide range of problems that can benefit from jointly optimizing parameters of preprocessing and classification algorithm.","0196-2892;01962892","","10.1109/TGRS.2016.2522972","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442576","Acoustic signal detection;Adaptive signal processing;Classification algorithms;Pattern recognition;Underwater acoustics","Explosions;Feature extraction;Machine learning algorithms;Monitoring;Optimization;Signal detection;Signal processing algorithms","feature extraction;geophysical signal processing;learning (artificial intelligence);signal classification;signal detection;support vector machines;underwater sound","Comprehensive Nuclear-Test-Ban Treaty Organization;baseline learning algorithm;cepstral feature extraction;classifier hyperparameters;flexibly parameterized detection algorithm;general-purpose sound processing feature;global geophysical monitoring network;human-expert-designed preprocessing chain;integrated signal processing;kernel function;long-range passive-acoustic underwater signal;long-range underwater signal detection;machine learning algorithms;nuclear treaty monitoring;receiver operating characteristic curve;signal classification;spectral feature extraction;support vector machine;trigger algorithm parameters;waveform segments","","","","41","","20160328","June 2016","","IEEE","IEEE Journals & Magazines"
"Big Data Analytics for Classification of Network Enabled Devices","D. Arora; K. F. Li; A. Loffler","Dept. of Electr. & Comput. Eng., Univ. of Victoria, Victoria, BC, Canada","2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)","20160519","2016","","","708","713","As information technology (IT) and telecommunication systems continue to grow in size and complexity, especially with Internet of Things (IoT) gaining popularity, maintaining a secure and seamless exchange of information between devices becomes a challenging task. A large number of devices connected over the Internet leads to an increase in vulnerabilities and security threats, which makes the identification of critical assets necessary. Asset identification helps organizations to identify and to respond quickly to any security breaches. In this paper, machine learning based techniques are used to identify assets based on their connectivity, i.e., servers and endpoints. For the analysis presented in this paper four different machine learning algorithms, K-Nearest Neighbor, Naive Bayes, Support Vector Machines, and Random Forest algorithms are used and the performance of these algorithms is assessed in terms of the F-score calculated for each algorithm. Results show that for a given dataset, amongst all four algorithms, the Random Forest classifier achieved highest accuracy in terms of identifying the assets correctly. However, the Random Forest algorithm is computationally intensive and may not work for large datasets. Naive Bayes algorithm yielded the worst performance and KNearest Neighbor's performance was very close to that achieved by Support Vector Machines. Our results shows that for the given dataset, Support Vector Machine based classifier was found to be a good compromise in terms of accuracy and computational expensiveness.","","Electronic:978-1-5090-2461-2; POD:978-1-5090-2462-9","10.1109/WAINA.2016.131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471285","asset classification;device classification;security;telecommunications","Algorithm design and analysis;Classification algorithms;Machine learning algorithms;Security;Servers;Support vector machines;Training","Bayes methods;Big Data;Internet of Things;learning (artificial intelligence);random processes;security of data;support vector machines","F-score;Internet of Things;IoT;K-nearest neighbor;asset identification;big data analytics;machine learning algorithm;naive Bayes;network enabled device;random forest classifier;security breaches;support vector machine","","","","44","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Radar fall motion detection using deep learning","B. Jokanovic; M. Amin; F. Ahmad","Center for Advanced Communications, Villanova University, Villanova, PA 19085, USA","2016 IEEE Radar Conference (RadarConf)","20160609","2016","","","1","6","Radar has a great potential to be one of the leading technologies to perform in-home monitoring of elderly. Radar signal returns corresponding to human gross-motor activities are nonstationary in nature. As such, time-frequency (TF) analysis plays a fundamental role in revealing constant and higher order velocity components of various parts of the human body under motion which are important for motion discrimination. In this paper, we consider radar for fall detection using TF-based deep learning approach. The proposed approach learns and captures the intricate properties of the TF signatures without human intervention and feeds the underlying features to the classifier. Experimental data is used to demonstrate the effectiveness of the proposed fall detection deep learning approach in comparison with the principal component analysis method and techniques incorporating manual selections of a few dominant features.","","Electronic:978-1-5090-0863-6; POD:978-1-5090-0864-3","10.1109/RADAR.2016.7485147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7485147","","Doppler effect;Feature extraction;Machine learning;Radar;Senior citizens;Spectrogram;Time-frequency analysis","biomedical measurement;geriatrics;learning (artificial intelligence);medical signal processing;principal component analysis;radar signal processing","TF analysis;TF signatures;deep learning;human body;human gross-motor activities;in-home monitoring;motion discrimination;principal component analysis method;radar fall motion detection;radar signal;time-frequency analysis","","1","","30","","","2-6 May 2016","","IEEE","IEEE Conference Publications"
"Spectral–Spatial Feature Extraction for Hyperspectral Image Classification: A Dimension Reduction and Deep Learning Approach","W. Zhao; S. Du","Institute of Remote Sensing and GIS, Peking University, Beijing, 100871, China","IEEE Transactions on Geoscience and Remote Sensing","20160601","2016","54","8","4544","4554","In this paper, we propose a spectral-spatial feature based classification (SSFC) framework that jointly uses dimension reduction and deep learning techniques for spectral and spatial feature extraction, respectively. In this framework, a balanced local discriminant embedding algorithm is proposed for spectral feature extraction from high-dimensional hyperspectral data sets. In the meantime, convolutional neural network is utilized to automatically find spatial-related features at high levels. Then, the fusion feature is extracted by stacking spectral and spatial features together. Finally, the multiple-feature-based classifier is trained for image classification. Experimental results on well-known hyperspectral data sets show that the proposed SSFC method outperforms other commonly used methods for hyperspectral image classification.","0196-2892;01962892","","10.1109/TGRS.2016.2543748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450160","Balanced local discriminant embedding (BLDE);convolutional neural network (CNN);deep learning (DL);dimension reduction (DR);feature extraction","Algorithm design and analysis;Feature extraction;Hyperspectral imaging;Machine learning;Training","feature extraction;hyperspectral imaging;image classification","SSFC framework;balanced local discriminant embedding algorithm;convolutional neural network;deep learning approach;deep learning techniques;dimension reduction approach;fusion feature;high-dimensional hyperspectral data sets;hyperspectral image classification;spectral-spatial feature based classification framework;spectral-spatial feature extraction","","9","","34","","20160408","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Wishart Deep Stacking Network for Fast POLSAR Image Classification","L. Jiao; F. Liu","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi&#x2019;an, China","IEEE Transactions on Image Processing","20160523","2016","25","7","3273","3286","Inspired by the popular deep learning architecture, deep stacking network (DSN), a specific deep model for polarimetric synthetic aperture radar (POLSAR) image classification is proposed in this paper, which is named Wishart DSN (W-DSN). First of all, a fast implementation of Wishart distance is achieved by a special linear transformation, which speeds up the classification of POLSAR image and makes it possible to use this polarimetric information in the following neural network (NN). Then, a single-hidden-layer NN based on the fast Wishart distance is defined for POLSAR image classification, which is named Wishart network (WN) and improves the classification accuracy. Finally, a multi-layer NN is formed by stacking WNs, which is in fact the proposed deep learning architecture W-DSN for POLSAR image classification and improves the classification accuracy further. In addition, the structure of WN can be expanded in a straightforward way by adding hidden units if necessary, as well as the structure of the W-DSN. As a preliminary exploration on formulating specific deep learning architecture for POLSAR image classification, the proposed methods may establish a simple but clever connection between POLSAR image interpretation and deep learning. The experiment results tested on real POLSAR image show that the fast implementation of Wishart distance is very efficient (a POLSAR image with 768 000 pixels can be classified in 0.53 s), and both the single-hidden-layer architecture WN and the deep learning architecture W-DSN for POLSAR image classification perform well and work efficiently.","1057-7149;10577149","","10.1109/TIP.2016.2567069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468458","Deep Stacking Network (DSN);Deep stacking network (DSN);POLSAR image classification;Wishart Deep Stacking Network (W-DSN);Wishart Network (WN);Wishart deep stacking network (W-DSN);Wishart network (WN)","Artificial neural networks;Covariance matrices;Labeling;Machine learning;Stacking;Training","image classification;learning (artificial intelligence);neural nets;radar imaging;radar polarimetry;synthetic aperture radar","POLSAR image classification;W-DSN;Wishart deep stacking network;deep learning architecture;neural network;polarimetric synthetic aperture radar image classification","","1","","38","","20160511","July 2016","","IEEE","IEEE Journals & Magazines"
"TSC-DL: Unsupervised trajectory segmentation of multi-modal surgical demonstrations with Deep Learning","A. Murali; A. Garg; S. Krishnan; F. T. Pokorny; P. Abbeel; T. Darrell; K. Goldberg","EECS & IEOR, University of California, Berkeley USA","2016 IEEE International Conference on Robotics and Automation (ICRA)","20160609","2016","","","4150","4157","The growth of robot-assisted minimally invasive surgery has led to sizable datasets of fixed-camera video and kinematic recordings of surgical subtasks. Segmentation of these trajectories into locally-similar contiguous sections can facilitate learning from demonstrations, skill assessment, and salvaging good segments from otherwise inconsistent demonstrations. Manual, or supervised, segmentation can be prone to error and impractical for large datasets. We present Transition State Clustering with Deep Learning (TSC-DL), a new unsupervised algorithm that leverages video and kinematic data for task-level segmentation, and finds regions of the visual feature space that correlate with transition events using features constructed from layers of pre-trained image classification Deep Convolutional Neural Networks (CNNs). We report results on three datasets comparing Deep Learning architectures (AlexNet and VGG), choice of convolutional layer, dimensionality reduction techniques, visual encoding, and the use of Scale Invariant Feature Transforms (SIFT). We find that the deep architectures extract features that result in up-to a 30.4% improvement in Silhouette Score (a measure of cluster tightness) over the traditional “shallow” features from SIFT. We also present cases where TSC-DL discovers human annotator omissions. Supplementary material, data and code is available at: http://berkeleyautomation.github.io/tsc-dl/.","","Electronic:978-1-4673-8026-3; POD:978-1-4673-8027-0","10.1109/ICRA.2016.7487607","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487607","","Feature extraction;Hidden Markov models;Kinematics;Machine learning;Motion segmentation;Visualization","control engineering computing;convolution;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;medical robotics;neural nets;pattern clustering;robot vision;surgery;transforms;video signal processing","TSC-DL unsupervised algorithm;dimensionality reduction;feature extraction;fixed-camera video;image classification deep convolutional neural networks;learning from demonstrations;multimodal surgical demonstrations;robot-assisted minimally invasive surgery;scale invariant feature transforms;surgical subtask kinematic recordings;task-level segmentation;transition state clustering with deep learning;unsupervised trajectory segmentation;visual encoding;visual feature space","","1","","29","","","16-21 May 2016","","IEEE","IEEE Conference Publications"
"Investigation of speaker embeddings for cross-show speaker diarization","M. Rouvier; B. Favre","Aix-Marseille Universit&#x00E9;, CNRS, LIF UMR 7279, 13000, Marseille, France","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","5585","5589","This paper proposes to investigate speaker embeddings, a representation extracted from hidden layers of deep neural networks trained on a speaker identification task, on cross-show diarization. The new representation brings an improvement over i-vectors, and we show that while shallow hidden layers give best results on the single-show condition, deeper layers yield better performance on cross-show diarization. This confirms that deep representations model higher level features which help generalizing to different acoustic conditions. Experiments, conducted on the French corpus of REPERE, show that the deep speaker embeddings technique decreases DER by 0.82 points.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472746","Deep Neural Network;Speaker Clustering;Speaker Diarization;Speaker Embeddings;i-vectors","Computational modeling;Feature extraction;Machine learning;Neural networks;Neurons;Speech;Training","neural nets;speaker recognition","acoustic conditions;cross-show diarization;deep neural networks;deep speaker embeddings technique;shallow hidden layers;single-show condition;speaker identification task","","","","29","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
