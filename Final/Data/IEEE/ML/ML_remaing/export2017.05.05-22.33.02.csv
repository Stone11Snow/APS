"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7555970,7557980,7346495,7556114,7557169,7554221,7555103,7554612,7552957,7554461,7552806,7554573,7552975,7554805,7552927,7555146,7554408,7552971,7551379,7548933,7549314,7550914,7551621,7551691,7550060,7550929,7550082,7550057,7549324,7551232,7548900,7532860,7532642,7532493,7532890,7533062,7533045,7532915,7533196,7532630,7533024,7532698,7532694,7532635,7532955,7544246,7546697,7546524,7546497,7544381,7543707,7543869,7543899,7544890,7545830,7544368,7545991,7545864,7544745,7546216,7544341,7544365,7546205,7546595,7546403,7544737,7542343,7494596,7541627,7539114,7514991,7537070,7536949,7533739,7532241,7531733,7533931,7535082,7518668,7529850,7527847,7528311,7529322,7529574,7530147,7528188,7529355,7526605,7525775,7526751,7420737,7521594,7524370,7523569,7520947,7521017,7521522,7523365,7523361,7519396",2017/05/05 22:33:02
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars","A. Shafiee; A. Nag; N. Muralimanohar; R. Balasubramonian; J. P. Strachan; M. Hu; R. S. Williams; V. Srikumar","Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA","2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)","20160825","2016","","","14","26","A number of recent efforts have attempted to design accelerators for popular machine learning algorithms, such as those involving convolutional and deep neural networks (CNNs and DNNs). These algorithms typically involve a large number of multiply-accumulate (dot-product) operations. A recent project, DaDianNao, adopts a near data processing approach, where a specialized neural functional unit performs all the digital arithmetic operations and receives input weights from adjacent eDRAM banks. This work explores an in-situ processing approach, where memristor crossbar arrays not only store input weights, but are also used to perform dot-product operations in an analog manner. While the use of crossbar memory as an analog dot-product engine is well known, no prior work has designed or characterized a full-fledged accelerator based on crossbars. In particular, our work makes the following contributions: (i) We design a pipelined architecture, with some crossbars dedicated for each neural network layer, and eDRAM buffers that aggregate data between pipeline stages. (ii) We define new data encoding techniques that are amenable to analog computations and that can reduce the high overheads of analog-to-digital conversion (ADC). (iii) We define the many supporting digital components required in an analog CNN accelerator and carry out a design space exploration to identify the best balance of memristor storage/compute, ADCs, and eDRAM storage on a chip. On a suite of CNN and DNN workloads, the proposed ISAAC architecture yields improvements of 14.8×, 5.5×, and 7.5× in throughput, energy, and computational density (respectively), relative to the state-of-the-art DaDianNao architecture.","1063-6897;10636897","Electronic:978-1-4673-8947-1; POD:978-1-4673-8948-8","10.1109/ISCA.2016.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551379","CNN;DNN;accelerator;analog;memristor;neural","Biological neural networks;Computer architecture;Kernel;Machine learning algorithms;Memristors;Neurons;Pipelines","DRAM chips;digital arithmetic;learning (artificial intelligence);memristor circuits;neural nets","ADC;DaDianNao architecture;ISAAC architecture;analog-to-digital conversion;convolutional neural network accelerator;data encoding;digital arithmetic operations;dot-product operations;eDRAM banks;in-situ analog arithmetic crossbars;in-situ processing approach;machine learning algorithms;memristor crossbar arrays;memristor storage;pipelined architecture design","","4","","","","","18-22 June 2016","","IEEE","IEEE Conference Publications"
"Proposing the Deep Dynamic Bayesian Network as a Future Computer Based Medical System","C. M. Carbery; A. H. Marshall; R. Woods","Centre for Stat. Sci. & Operational Res., Queen's Univ. Belfast, Belfast, UK","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","227","228","The development of new learning models has been of great importance throughout recent years, with a focus on creating advances in the area of deep learning. Deep learning was first noted in 2006, and has since become a major area of research in a number of disciplines. This paper will delve into the area of deep learning to present its current limitations and provide a new idea for a fully integrated deep and dynamic probabilistic system. The new model will be applicable to a vast number of areas initially focusing on applications into medical image analysis with an overall goal of utilising this approach for prediction purposes in computer based medical systems.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545991","deep learning;dynamic Bayesian network;medical systems;probabilistic graphical model","Analytical models;Bayes methods;Biomedical imaging;Computational modeling;Data models;Hidden Markov models;Machine learning","belief networks;learning (artificial intelligence);medical image processing;prediction theory;probability","deep dynamic bayesian network;deep learning;dynamic probabilistic system;future computer based medical systems;integrated deep;medical image analysis;prediction purpose","","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"Multimedia Hashing and Networking","W. Liu; T. Zhang","Tencent AI Lab","IEEE MultiMedia","20160805","2016","23","3","75","79","This department discusses multimedia hashing and networking. The authors summarize shallow-learning-based hashing and deep-learning-based hashing. By exploiting successful shallow-learning algorithms, state-of-the-art hashing techniques have been widely used in high-efficiency multimedia storage, indexing, and retrieval, especially in multimedia search applications on smartphone devices. The authors also introduce Multimedia Information Networks (MINets) and present one paradigm of leveraging MINets to incorporate both visual and textual information to reach a sensible event coreference resolution. The goal is to make deep learning practical in realistic multimedia applications.","1070-986X;1070986X","","10.1109/MMUL.2016.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7535082","Multimedia Information Networks;big data;data analysis;hashing;multimedia;networking","Information retrieval;Learning systems;Machine learning;Multimedia communication;Visualization","file organisation;learning (artificial intelligence);multimedia systems;social networking (online)","MINets;deep-learning-based hashing;multimedia hashing;multimedia information networks;multimedia networking;shallow-learning-based hashing;textual information;visual information","","","","","","","July-Sept. 2016","","IEEE","IEEE Journals & Magazines"
"A Topological Approach to Hardware Bug Triage","R. Angell; B. Oztalay; A. DeOrio","Dept. of Electr. Eng. & Comput. Sci., Univ. of Michigan, Ann Arbor, MI, USA","2015 16th International Workshop on Microprocessor and SOC Test and Verification (MTV)","20160825","2015","","","20","25","Verification is a critical bottleneck in the time to market of a new digital design. As complexity continues to increase, post-silicon validation shoulders an increasing share of the verification/validation effort. Post-silicon validation is burdened by large volumes of test failures, and is further complicated by root cause bugs that manifest in multiple test failures. At present, these failures are prioritized and assigned to validation engineers in an ad-hoc fashion. When multiple failures caused by the same root cause bug are debugged by multiple engineers at the same time, scarce, time-critical engineering resources are wasted. Our scalable bug triage technique begins with a database of test failures. It extracts defining features from the failure reports, using a novel, topology-aware approach based on graph partitioning. It then leverages unsupervised machine learning to extract the structure of the failures, identifying groups of failures that are likely to be the result of a common root cause. With our technique, related failures can be debugged as a group, rather than individually. Additionally, we propose a metric for measuring verification efficiency as a result of bug triage called Unique Debugging Instances (UDI). We evaluated our approach on the industrial-size OpenSPARC T2 design with a set of injected bugs, and found that our approach increased average verification efficiency by 243%, with a confidence interval of 99%.","","Electronic:978-1-5090-0885-8; POD:978-1-5090-0886-5","10.1109/MTV.2015.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548933","","Computer bugs;Debugging;Feature extraction;Hardware;Hardware design languages;Machine learning algorithms;Topology","computer debugging;failure analysis;graph theory;unsupervised learning","OpenSPARC-T2 design;UDI;average verification efficiency;confidence interval;digital design;failure group identification;failure structure extraction;graph partitioning;postsilicon validation;root cause bug debugging;scalable hardware bug triage technique;test failures;topology-aware approach;unique-debugging instances;unsupervised machine learning;verification efficiency measuring metric","","","","","","","3-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"Data-mining a mechanism against cyber threats: A review","S. R. Kumar; J. S. Jassi; S. A. Yadav; R. Sharma","Computer Science & Engineering","2016 International Conference on Innovation and Challenges in Cyber Security (ICICCS-INBUSH)","20160815","2016","","","45","48","Data mining is the process in that analyzing of data from different perspective and summarizes that data into some useful information which can be used to enhance the revenue generation, cost cutting etc. In data mining, cluster formation plays a vital role which is data can be divided into different groups. Clustering is the technique in which grouping is based on similar type of data relevant to different attributes. WEKA is the most important tool of data mining which is used to allocate and clustering of data with use of various machine learning algorithms. The purpose of this paper is to compare different algorithms of machine learning on the subject of types of data set, their size, number of clusters and cyber privacy platform. We also discuss different types of cyber threats in computing world.","","Electronic:978-1-5090-2084-3; POD:978-1-5090-2085-0","10.1109/ICICCS.2016.7542343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542343","Cyber Threats;Intrusion Detection;MAP;WEKA","Algorithm design and analysis;Clustering algorithms;Computer security;Data mining;Machine learning algorithms;Partitioning algorithms","data mining;data privacy;learning (artificial intelligence);pattern clustering;security of data","WEKA tool;cluster formation;cyber privacy platform;cyber threats;data allocation;data analysis;data attributes;data clustering;data set types;data size;data-mining mechanism;machine learning algorithms","","","","","","","3-5 Feb. 2016","","IEEE","IEEE Conference Publications"
"Algorithm derivation and its embedded system realization of speed limit detection for multiple countries","Y. T. Lin; T. Chou; M. S. Vinay; J. I. Guo","Department of Electronic Engineering, National Chiao Tung University, HsinChu, Taiwan, R.O.C.","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","2555","2558","This paper proposes a low-complexity speed limit detection which can not only support different types of speed limit signs for multiple countries, but maintain good detection rate under inclement weathers. The proposed algorithm steps include shape detection to locate speed limit signs, adaptive threshold and digit recognition algorithm which can adapt to different digit fonts to support different types of speed limit signs for multiple countries. We implement the proposed algorithm on both the desktop and the automotive-grade i.MX 6 embedded system. Under D1 resolution (720×480), the proposed system can achieve 150 fps on the desktop and 30 fps on the i.MX 6 embedded system.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7539114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539114","","Automobiles;Embedded systems;Intelligent vehicles;Machine learning algorithms;Real-time systems;Shape","embedded systems;image segmentation;object detection;shape recognition;traffic engineering computing","adaptive threshold;algorithm derivation;automotive-grade i.MX 6 embedded system;desktop i.MX 6 embedded system;digit fonts;digit recognition algorithm;inclement weathers;low-complexity speed limit detection;shape detection;speed limit signs location","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"Visual saliency landmark detection algorithm based on DNN feature extraction","C. Zhao; Y. Zhou; Y. Wei; S. Jiang; C. Yu","Northwestern Polytechnical University, Xi'an 710072, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","5551","5556","The integrated navigation pattern that is formed by the scene matching navigation and the inertial navigation or the satellite navigation is an important development direction of UAV autonomous navigation technology. As for the error identification problem of matching area in the process of scene matching landmark detection, the algorithm of visual saliency landmark detection for scene matching based on deep neural network for feature extraction is proposed. The experiments illustrated that the algorithm can effectively solve the problem of landmark detection in different environments and improve the robustness and effectiveness of landmark detection.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554221","Deep learning;Feature extraction;Landmark detection;Scene matching;Visual saliency","Brightness;Feature extraction;Image color analysis;Machine learning;Neural networks;Unmanned aerial vehicles;Visualization","autonomous aerial vehicles;feature extraction;image matching;natural scenes;neural nets;object detection;robot vision","DNN feature extraction;UAV autonomous navigation;deep neural network;error identification problem;inertial navigation;integrated navigation pattern;landmark detection effectiveness improvement;robustness improvement;satellite navigation;scene matching landmark detection;scene matching navigation;visual saliency landmark detection algorithm","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Big data and deep learning","B. M. Wilamowski; B. Wu; J. Korniak","University of Information Technology and Management, Sucharskiego 2, Rzeszow 35-225, Poland. Dept. of Electrical and Computer Engineering, Auburn University, Auburn, AL 36849, USA","2016 IEEE 20th Jubilee International Conference on Intelligent Engineering Systems (INES)","20160829","2016","","","11","16","Traditional data processing algorithms are usually not capable to process big data. As matter of fact, usually big data is being defined as such which cannot be processed with traditional techniques. At the same time a progress of technology makes that humans are now overwhelm by big data. One way of processing big data is to use deep neural networks, which are difficult to train so often a combination of several learning algorithms are used. This approach however requires a lot of human involvement in design of such systems for very specific cases. In this presentations and universal architectures and training methods are described which can handle very complex systems with minimal human interactions. Another important problem is a visualization of multidimensional data sets in 2 or 3 dimensions so humans can see them. A new very effective visualization algorithm is also presented. The third issue is the pattern clustering. Round clusters can be separated relatively easy. In this presentation new and very fast clustering of complex shape is also presented.","","Electronic:978-1-5090-1216-9; POD:978-1-5090-1217-6; USB:978-1-5090-1215-2","10.1109/INES.2016.7555103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555103","big data;classification;clustering;deep learning;visualization","Big data;Conferences;Data visualization;Decision support systems;Iris recognition;Machine learning;Neurons","Big Data;data visualisation;learning (artificial intelligence);pattern clustering","Big Data;data processing algorithms;deep learning;deep neural networks;multidimensional data set visualization;pattern clustering;visualization algorithm","","","","","","","June 30 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Statistical approach towards malware classification and detection","V. Ghanaei; C. S. Iliopoulos; R. E. Overill","Department of Informatics, King's College London, Strand, London, WC2R 2LS, UK","2016 SAI Computing Conference (SAI)","20160901","2016","","","1093","1099","Anti-virus companies receive extensive quantities of malware variants daily; therefore, it is essential to automatically classify them into their corresponding malware family. Here, we apply an efficient statistical approach to identify and render critical malicious patterns into malware families, which are essential elements of automated classification of known and unknown malware variants in large quantities. Critical malicious patterns are the most frequent basic blocks, which are present most often in one specific malware family, and comparatively less in all other malware families. By computing the distribution frequency of each distinct basic block residing in all the malware families, the importance of being a potential representative of a critical malicious pattern for a specific malware family is measured. This value is carefully computed by considering the population of each malware family, and the distribution frequency ratio of every distinct basic block among the different malware families. The results show that known and unknown malware variants can be effectively and accurately classified into their related malware family using this approach.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7556114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556114","Malicious Features;Malware Classification;Pattern Matching;Shared Code;Statistical","Feature extraction;Machine learning algorithms;Malware;Pattern matching;Semantics;Training","computer viruses;pattern classification;statistical analysis","antivirus companies;automated classification;malicious pattern rendering;malware classification;malware detection;statistical approach","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"iHear Food: Eating Detection Using Commodity Bluetooth Headsets","Y. Gao; N. Zhang; H. Wang; X. Ding; X. Ye; G. Chen; Y. Cao","Dept. of Comput. Sci., Univ. of Massachusetts, Lowell, Lowell, MA, USA","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20160818","2016","","","163","172","Monitoring a person's dietary behavior has many health applications (e.g. weight management). Existing approaches for automatic eating detection using wearable sensors often require custom hardware that may not be practical as their usability and energy efficiency have not been validated. In this paper, we propose to use off-the-shelf Bluetooth headsets to unobtrusively monitor and detect users' eating episodes by analyzing the chewing sound. The challenges of using commodity acoustic hardware include the limited sampling rate that reduces feature fidelity and the impact of environment noise in real-world settings. Our experimental results show that the traditional kernel-based approach using Support Vector Machine (SVM) could achieve 94-95% classification accuracy in lab settings, though the detection performance quickly degraded to 65-76% for in-the-field testing. We then propose a novel Deep Learning based classification technique that drastically improved detection accuracy to 77-94% despite the existence of ambient noise. To the best of our knowledge, this is the first study to use Bluetooth headsets to detect eating episodes and to use Deep Learning to significantly increase classification performance in this context. We believe that the adoption of readily available and low-cost consumer devices provides a foundation for practical deployment of automated dietary monitoring applications.","","Electronic:978-1-5090-0943-5; POD:978-1-5090-0944-2","10.1109/CHASE.2016.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545830","Deep Learning;Eating detection;SVM Kernal","Bluetooth;Feature extraction;Headphones;Machine learning;Microphones;Monitoring;Sensors","Bluetooth;health care;learning (artificial intelligence);mobile computing;patient monitoring;pattern classification;support vector machines;wearable computers","ADM;SVM;automated dietary monitoring;commodity Bluetooth headset;commodity acoustic hardware;deep learning based classification;eating detection;iHearFood;support vector machine;wearable sensor","","","","","","","27-29 June 2016","","IEEE","IEEE Conference Publications"
"Weighting and sampling data for individual classifiers and bagging with genetic algorithms","S. Karakatič; M. Heričko; V. Podgorelec","Institute of Informatics, UM FERI, Smetanova 17, Maribor, Slovenia","2015 7th International Joint Conference on Computational Intelligence (IJCCI)","20160804","2015","1","","180","187","An imbalanced or inappropriate dataset can have a negative influence in classification model training. In this paper we present an evolutionary method that effectively weights or samples the tuples from the training dataset and tries to minimize the negative effects from innaprotirate datasets. The genetic algorithm with genotype of real numbers is used to evolve the weights or occurrence number for each learning tuple in the dataset. This technique is used with individual classifiers and in combination with the ensemble technique of bagging, where multiple classification models work together in a classification process. We present two variations - weighting the tuples and sampling the classification tuples. Both variations are experimentally tested in combination with individual classifiers (C4.5 and Naive Bayes methods) and in combination with bagging ensemble. Results show that both variations are promising techniques, as they produced better classification models than methods without weighting or sampling, which is also supported with statistical analysis.","","Electronic:978-9-8975-8165-6; POD:978-1-5090-1968-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529322","Bagging;Classification;Genetic Algorithm;Instance Selection;Weighting","Artificial neural networks;Bagging;Computational modeling;Genetic algorithms;Machine learning algorithms;Measurement;Training","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Collaborative facial color feature learning of multiple color spaces for face recognition","H. I. Kim; Y. M. Ro","Image and Video Systems Lab, School of Electrical Engineering, KAIST, Republic of Korea","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1669","1673","Facial color is known as playing an important role in face recognition. Color face recognition has been investigated in the last decade. Recently, deep learning has attracted considerable attention due to their high performance in face recognition. The importance of the color in a deep learning framework is not fully investigated yet. In this paper, we have conducted experiments to investigate the effectiveness of facial color in face recognition with deep learning. Through experimental results, we have demonstrated that facial color is helpful for enhancing the recognition performance in deep learning and color space selection is crucial to achieve high performance. Moreover, by fusing features from multiple color spaces, the face recognition accuracy has been considerably improved.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532642","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532642","Color face recognition;color spaces;complementary effect;deep learning;feature fusion","Collaboration;Face;Face recognition;Feature extraction;Gray-scale;Image color analysis;Machine learning","face recognition;image colour analysis;learning (artificial intelligence)","collaborative facial color feature learning;color face recognition;color space selection;deep learning framework;multiple color spaces","","","","24","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"A gradient-based dissipative continuous-time algorithm for distributed optimization","W. Yu; P. Yi; Y. Hong","Key Laboratory of Systems and Control, Academy of Mathematics and System Science, Chinese Academy of Sciences, Beijing, 100190, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","7908","7912","This paper is concerned with solving distributed optimization problem by multi-agent systems with gradient-based dissipative dynamics over undirected graph. The optimization objective function is a sum of local cost functions associated to the individual agents. A novel gradient-based dissipative continuous-time algorithm is proposed to solve the distributed optimization problem, which extends the well-known heavy ball method to distributed optimization. Suppose the local cost functions being strongly convex with locally Lipschitz gradients, by defining suitable Lyapunov functions, then we show that the agents can find the same optimal solution by the proposed algorithm with exponential convergence rate. Specially, the choice of parameters in our algorithm is independent of the communication topology, demonstrating significant advantage over existing algorithms.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554612","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554612","Continuous-time optimization algorithms;dissipativity;distributed optimization;gradient-based algorithms;heavy ball method","Algorithm design and analysis;Convergence;Cost function;Heuristic algorithms;Machine learning algorithms;Multi-agent systems","Lyapunov methods;continuous time systems;convergence;directed graphs;gradient methods;optimisation;topology","Lipschitz gradients;Lyapunov functions;communication topology;distributed optimization problem;exponential convergence rate;gradient-based dissipative continuous-time algorithm;gradient-based dissipative dynamics;optimization objective function;undirected graph","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Methods for churn prediction in the pre-paid mobile telecommunications industry","I. Brânduşoiu; G. Toderean; H. Beleiu","Department of Communications, Technical University of Cluj-Napoca, Romania","2016 International Conference on Communications (COMM)","20160804","2016","","","97","100","Recently, due to the global competition companies active in different industries started to be concerned about the customer churn. With a churn rate of 30%, the telecommunications sector takes the first place on the list. The telecommunications operators need to identify customers who are at risk of churning by implementing predictive models. In this paper, we present an advanced data mining methodology which predicts customer churn in the pre-paid mobile telecommunications industry using a call details records dataset that consists of 3333 customers with 21 attributes each. We first apply the principal component analysis algorithm to reduce the dimensionality of the data and eliminate the problem of multicollinearity. To implement the predictive models, on the resulted principal components and discrete variables we initially propose and then apply three machine learning algorithms: neural networks, support vector machines, and Bayesian networks. To evaluate the models, we use the confusion matrix, the gain measure and the ROC curve.","","DVD:978-1-4673-8196-3; Electronic:978-1-4673-8197-0; POD:978-1-4673-8198-7","10.1109/ICComm.2016.7528311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528311","bayesian networks;call detail records;churn prediction;neural networks;principal component analysis;support vector machines;telecommunications","Bayes methods;Kernel;Machine learning algorithms;Predictive models;Support vector machines;Telecommunications;Training","belief networks;data mining;learning (artificial intelligence);matrix algebra;mobile communication;neural nets;principal component analysis;support vector machines;telecommunication industry","Bayesian networks;ROC curve;advanced data mining methodology;churn prediction methods;confusion matrix;customer churn;machine learning algorithms;multicollinearity problem;neural networks;predictive models;prepaid mobile telecommunications industry;principal component analysis algorithm;support vector machines;telecommunications sector","","","","","","","9-10 June 2016","","IEEE","IEEE Conference Publications"
"Invited — A 2.2 GHz SRAM with high temperature variation immunity for deep learning application under 28nm","C. C. Liu; Y. H. Wang; Y. Li; C. H. Wong; T. P. Chou; Y. K. Chen; M. C. F. Chang","University of California, Los Angeles, Los Angeles, CA, USA","2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)","20160818","2016","","","1","6","With the coming era of Big Data, hardware implementation of machine learning has become attractive for many applications, such as real-time object recognition and face recognition. The implementation of machine learning algorithms needs intensive memory access, and SRAM is critical for the overall performance. This paper proposes a new design of high speed SRAM for machine learning purposes. With fast access time (cycle time: 650 ps, access time: 350 ps), low sensitivity to temperature variation and high configurability (less than 10% performance difference between 125_rcw_tt vs 0_rcw_tt), the proposed SRAM is a better candidate for hardware machine learning system than the conventional SRAM. Compared with Samsung HL 152, our design has smaller size (121×43 um<sup>2</sup> vs 127×44 um<sup>2</sup>) with half the number of pins ports (12 vs 25) and higher speed (2.2GHz vs 0.8GHz).","","Electronic:978-1-4673-8729-3; POD:978-1-4673-8730-9","10.1145/2897937.2903982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544246","Deep Learning;High Speed;SRAM Design;Variation Tolerance","Convolution;Machine learning algorithms;Memory management;Neurons;Random access memory;Temperature measurement;Temperature sensors","SRAM chips;learning (artificial intelligence)","SRAM;deep learning;hardware machine learning system;high temperature variation immunity","","","","","","","5-9 June 2016","","IEEE","IEEE Conference Publications"
"Application of UCT technologies for computer games of Amazon","Q. Jianning; Q. Hongkun; W. Yajie; L. Fei; Q. Shengran","College of Aerospace Engineering, Shenyang Aerospace University, Shenyang 110136","2016 Chinese Control and Decision Conference (CCDC)","20160808","2016","","","6896","6899","This paper simply introduces the game of Amazon and traditional alpha-beta pruning algorithm, mainly introduces the using of UCT algorithm in Amazon, and using MC evaluation to replace traditional evaluation function. We also establish a move table to speed up the search efficiency. This paper compares UCT algorithm with alpha-beta pruning algorithm, and analyses the different performance of each algorithm in different stages of games.","","CD-ROM:978-1-4673-9713-1; Electronic:978-1-4673-9714-8; POD:978-1-4673-9715-5","10.1109/CCDC.2016.7532241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532241","Alpha-Beta Pruning Algorithm;Amazon;Computer Games;UCT Algorithm","Aerospace engineering;Algorithm design and analysis;Computers;Electronic mail;Games;Machine learning algorithms;Monte Carlo methods","computer games;minimax techniques;search problems","Amazon;MC evaluation;UCT technology;computer games;traditional alpha-beta pruning algorithm","","","","","","","28-30 May 2016","","IEEE","IEEE Conference Publications"
"Simplifying deep neural networks for neuromorphic architectures","J. Chung; T. Shin","Department of Electronics Engineering, Incheon National University","2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)","20160818","2016","","","1","6","Deep learning using deep neural networks is taking machine intelligence to the next level in computer vision, speech recognition, natural language processing, etc. Brain-like hardware platforms for the brain-inspired computational models are being studied, but none of such platforms deals with the huge size of practical deep neural networks. This paper presents two techniques, factorization and pruning, that not only compress the models but also maintain the form of the models for the execution on neuromorphic architectures. We also propose a novel method to combine the two techniques. The proposed method shows significant improvements in reducing the number of model parameters over standalone use of each method while maintaining the performance. Our experimental results show that the proposed method can achieve 31 x reduction rate without loss of accuracy for the largest layer of AlexNet.","","Electronic:978-1-4673-8729-3; POD:978-1-4673-8730-9","10.1145/2897937.2898092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544368","Deep Learning;Deep Neural Network;Neuromorphic Computing;Sparse Network","Biological neural networks;Brain modeling;Computational modeling;Computer architecture;Hardware;Machine learning;Neuromorphics","learning (artificial intelligence);neural nets","AlexNet;brain-inspired computational models;brain-like hardware platforms;computer vision;deep learning;deep neural networks;factorization;machine intelligence;natural language processing;neuromorphic architectures;pruning;speech recognition","","1","","","","","5-9 June 2016","","IEEE","IEEE Conference Publications"
"A Deep Learning Method for Microaneurysm Detection in Fundus Images","J. Shan; L. Li","Dept. of Comput. Sci., Pace Univ. New York City, New York, NY, USA","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20160818","2016","","","357","358","Diabetic Retinopathy (DR) is the leading cause of blindness in the working-age population. Microaneurysms (MAs), due to leakage from retina blood vessels, are the early signs of DR. However, automated MA detection is complicated because of the small size of MA lesions and the low contrast between the lesion and its retinal background. Recently deep learning (DL) strategies have been used for automatic feature extraction and classification problems, especially for image analysis. In this paper, a Stacked Sparse Autoencoder (SSAE), an instance of a DL strategy, is presented for MA detection in fundus images. Small image patches are generated from the original fundus images. The SSAE learns high-level features from pixel intensities alone in order to identify distinguishing features of MA. The high-level features learned by SSAE are fed into a classifier to categorize each image patch as MA or non-MA. The public benchmark DIARETDB is utilized to provide the training/testing data and ground truth. Among the 89 images, totally 2182 image patches with MA lesions, serve as positive data, and another 6230 image patches without MA lesions are generated by a randomly sliding window operation, to serve as negative data. Without any blood vessel removal or complicated preprocessing operations, SSAE learned directly from the raw image patches, and automatically extracted the distinguishing features to classify the patches using Softmax Classifier. By employing the fine-tuning operation, an improved F-measure 91.3% and an average area under the ROC curve (AUC) 96.2% were achieved using 10-fold cross-validation.","","Electronic:978-1-5090-0943-5; POD:978-1-5090-0944-2","10.1109/CHASE.2016.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545864","automated microaneurysm detection;deep learning;diabetic retinopathy;feature representation;stacked sparse autoencoder","Biomedical image processing;Conferences;Feature extraction;Lesions;Machine learning","blood vessels;diseases;feature extraction;image classification;learning (artificial intelligence);medical image processing","10-fold cross-validation;DIARETDB public benchmark;DR;F-measure;SSAE;automated MA detection;automatic feature extraction;blindness;classification problems;deep learning method;diabetic retinopathy;fine-tuning operation;fundus images;image analysis;microaneurysm detection;microaneurysms;randomly sliding window operation;retina blood vessels;softmax classifier;stacked sparse autoencoder;working-age population","","","","","","","27-29 June 2016","","IEEE","IEEE Conference Publications"
"Multi-target detection in CCTV footage for tracking applications using deep learning techniques","A. Dimou; P. Medentzidou; F. Á. García; P. Daras","Universidad Polit&#x00E9;cnica de Madrid (GATV), Spain","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","928","932","Real-world CCTV footage often poses increased challenges in object tracking due to Pan-Tilt-Zoom operations, low camera quality and diverse working environments. Most relevant challenges are moving background, motion blur and severe scale changes. Convolutional neural networks, which offer state-of-the-art performance in object detection, are increasingly utilized to pursue a more efficient tracking scheme. In this work, the use of heterogeneous training data and data augmentation is explored to improve their detection rate in challenging CCTV scenes. Moreover, it is proposed to use the objects' spatial transformation parameters to automatically model and predict the evolution of intrinsic camera parameters and accordingly tune the detector for better performance. The proposed approaches are tested on publicly available datasets and real-world CCTV videos.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532493","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532493","CCTV;PTZ;R-CNN;RNN;motion blur;spatial transformer","Cameras;Detectors;Machine learning;Object detection;Training;Training data;Videos","closed circuit television;image motion analysis;learning (artificial intelligence);neural nets;object detection;target tracking","CCTV footage;CCTV videos;convolutional neural networks;deep learning;low camera quality;motion blur;multitarget detection;object detection;object tracking;pan-tilt-zoom operations;tracking applications","","","","19","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"IR based intelligent image processing techniques for medical applications","A. Bandyopadhyay; A. Chaudhuri; H. S. Mondal","ICTS-02, C-DAC, Kolkata, Kolkata, India","2016 SAI Computing Conference (SAI)","20160901","2016","","","113","117","Infrared imaging captures the temperature distribution of the human body surface and is presently employed in various medical applications. Most of the conventional and commercial suites for thermal image processing provide only very basic tools to process thermal images which pose challenge to the medical professionals and analysts to interpret the combination of both functional and morphostructural imaging for solving their medical issues. In this paper, an image processing based advanced machine learning approach is discussed which will provide tremendous help to the users to diagnose infrared image based assumptions either to see which part of the anatomy is affected by a certain disease or to judge the efficacy of the treatment. The system can be used in Infrared image based diabetes screening and cancer detection applications.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7555970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555970","Diabetes &Cancer;Image Processing;Infrared image;Machine vision","Biomedical imaging;Diabetes;Ear;Feature extraction;Machine learning algorithms;Temperature distribution","feature extraction;image capture;infrared imaging;learning (artificial intelligence);medical image processing","IR based intelligent image processing techniques;Infrared image based diabetes screening;cancer detection;functional imaging;human body surface;infrared image diagnosis;infrared imaging;machine learning approach;medical applications;morphostructural imaging;temperature distribution;thermal image processing","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Learning and transferring representations for image steganalysis using convolutional neural network","Y. Qian; J. Dong; W. Wang; T. Tan","Department of Automation, University of Science and Technology of China","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","2752","2756","The major challenge of machine learning based image steganalysis lies in obtaining powerful feature representations. Recently, Qian et al. have shown that Convolutional Neural Network (CNN) is effective for learning features automatically for steganalysis. In this paper, we follow up this new paradigm in steganalysis, and propose a framework based on transfer learning to help the training of CNN for steganalysis, hence to achieve a better performance. We show that feature representations learned with a pre-trained CNN for detecting a steganographic algorithm with a high payload can be efficiently transferred to improve the learning of features for detecting the same steganographic algorithm with a low pay-load. By detecting representative WOW and S-UNIWARD steganographic algorithms, we demonstrate that the proposed scheme is effective in improving the feature learning in CNN models for steganalysis.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532860","Convolutional Neural Network;Steganalysis;deep learning;transfer learning","Convolution;Feature extraction;Kernel;Machine learning;Neural networks;Payloads;Training","feature extraction;feedforward neural nets;image coding;image representation;learning (artificial intelligence);steganography","CNN;automatic feature learning;convolutional neural network;feature learning improvement;feature representations;image steganalysis;machine learning;representative S-UNIWARD steganographic algorithm;representative WOW steganographic algorithm;transfer learning","","","","22","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Deep Feature Extraction and Classification of Hyperspectral Images Based on Convolutional Neural Networks","Y. Chen; H. Jiang; C. Li; X. Jia; P. Ghamisi","Department of Information Engineering, School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","20160811","2016","54","10","6232","6251","Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.","0196-2892;01962892","","10.1109/TGRS.2016.2584107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514991","Convolutional neural network (CNN);deep learning;feature extraction (FE);hyperspectral image (HSI) classification","Data mining;Feature extraction;Hyperspectral imaging;Iron;Machine learning;Training","feature extraction;geophysical techniques;hyperspectral imaging;neural nets","CNN-based FE model;Indian Pines;Kennedy Space Center;University of Pavia;class data modeling;convolutional neural networks;hyperspectral images;pooling layers;regularized deep feature extraction;state-of-the-art methods","","1","","","","20160718","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Back in Black: Towards Formal, Black Box Analysis of Sanitizers and Filters","G. Argyros; I. Stais; A. Kiayias; A. D. Keromytis","Columbia Univ., New York, NY, USA","2016 IEEE Symposium on Security and Privacy (SP)","20160818","2016","","","91","109","We tackle the problem of analyzing filter and sanitizer programs remotely, i.e. given only the ability to query the targeted program and observe the output. We focus on two important and widely used program classes: regular expression (RE) filters and string sanitizers. We demonstrate that existing tools from machine learning that are available for analyzing RE filters, namely automata learning algorithms, require a very large number of queries in order to infer real life RE filters. Motivated by this, we develop the first algorithm that infers symbolic representations of automata in the standard membership/equivalence query model. We show that our algorithm provides an improvement of x15 times in the number of queries required to learn real life XSS and SQL filters of popular web application firewall systems such as mod-security and PHPIDS. % Active learning algorithms require the usage of an equivalence oracle, i.e. an oracle that tests the equivalence of a hypothesis with the target machine. We show that when the goal is to audit a target filter with respect to a set of attack strings from a context free grammar, i.e. find an attack or infer that none exists, we can use the attack grammar to implement the equivalence oracle with a single query to the filter. Our construction finds on average 90% of the target filter states when no attack exists and is very effective in finding attacks when they are present. For the case of string sanitizers, we show that existing algorithms for inferring sanitizers modelled as Mealy Machines are not only inefficient, but lack the expressive power to be able to infer real life sanitizers. We design two novel extensions to existing algorithms that allow one to infer sanitizers represented as single-valued transducers. Our algorithms are able to infer many common sanitizer functions such as HTML encoders and decoders. Furthermore, we design an algorithm to convert the inferred models into BEK programs, which allows for further appl- cations such as cross checking different sanitizer implementations and cross compiling sanitizers into different languages supported by the BEK backend. We showcase the power of our techniques by utilizing our black-box inference algorithms to perform an equivalence checking between different HTML encoders including the encoders from Twitter, Facebook and Microsoft Outlook email, for which no implementation is publicly available.","","Electronic:978-1-5090-0824-7; POD:978-1-5090-0825-4","10.1109/SP.2016.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546497","automata;filters;learning;sanitizers;web security","Algorithm design and analysis;Grammar;HTML;Inference algorithms;Learning automata;Machine learning algorithms;Transducers","Internet;SQL;automata theory;context-free grammars;firewalls;hypermedia markup languages;information filtering;learning (artificial intelligence);query processing;social networking (online)","Facebook;HTML encoders;Mealy machines;Microsoft Outlook email;PHPIDS;RE filters;SQL filters;Twitter;Web application;automata learning algorithms;black box analysis;context free grammar;equivalence checking;filter programs;firewall systems;machine learning;membership/equivalence query model;mod-security;real life XSS;regular expression filters;sanitizer programs;string sanitizers","","1","","","","","22-26 May 2016","","IEEE","IEEE Conference Publications"
"Text detection in manga by combining connected-component-based and region-based classifications","Y. Aramaki; Y. Matsui; T. Yamasaki; K. Aizawa","The University of Tokyo","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","2901","2905","As manga (Japanese comics) have become common content in many countries, it is necessary to search manga by text query or translate them automatically. For these applications, we must first extract texts from manga. In this paper, we develop a method to detect text regions in manga. Taking motivation from methods used in scene text detection, we propose an approach using classifiers for both connected components and regions. We have also developed a text region dataset of manga, which enables learning and detailed evaluations of methods used to detect text regions. Experiments using the dataset showed that our text detection method performs more effectively than existing methods.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532890","Manga;connected components;deep features;detection;text regions","Feature extraction;Machine learning;Optical character recognition software;Proposals;Support vector machines;Text recognition;Training","feature extraction;image classification;text detection","Manga;connected-component-based classifications;region-based classifications;scene text detection;text extraction;text query;text region dataset","","","","18","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"An intelligent self-checkout system for smart retail","B. F. Wu; W. J. Tseng; Y. S. Chen; S. J. Yao; P. J. Chang","","2016 International Conference on System Science and Engineering (ICSSE)","20160825","2016","","","1","4","Most of current self-checkout systems rely on barcodes, RFID tags, or QR codes attached on items to distinguish products. This paper proposes an Intelligent Self-Checkout System (ISCOS) embedded with a single camera to detect multiple products without any labels in real-time performance. In addition, deep learning skill is applied to implement product detection, and data mining techniques construct the image database employed as training dataset. Product information gathered from a number of markets in Taiwan is utilized to make recommendation to customers. The bounding boxes are annotated by background subtraction with a fixed camera to avoid time-consuming process for each image. The contribution of this work is to combine deep learning and data mining approaches to real-time multi-object detection in image-based checkout system.","","Electronic:978-1-4673-8966-2; POD:978-1-4673-8967-9","10.1109/ICSSE.2016.7551621","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551621","Data mining;Deep learning;Multi-object detection;Self-checkout;Smart retail","Cameras;Data mining;Databases;Machine learning;Real-time systems;Shape;Training","data mining;learning (artificial intelligence);object detection;retail data processing","ISCOS;QR codes;RFID tags;Taiwan;background subtraction;barcodes;bounding boxes;data mining;deep learning;image database;image-based checkout system;intelligent self-checkout system;multiple products detection;real-time multiobject detection;smart retail","","","","","","","7-9 July 2016","","IEEE","IEEE Conference Publications"
"Plug-n-learn: Automatic learning of computational algorithms in human-centered Internet-of-Things applications","S. A. Rokni; H. Ghasemzadeh","Embedded and Pervasive Systems Laboratory (EPSL) School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA 99164-2752","2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)","20160818","2016","","","1","6","Wearable technologies play a central role in human-centered Internet-of-Things applications. Wearables leverage computational and machine learning algorithms to detect events of interest such as physical activities and medical complications. A major obstacle in large-scale utilization of current wearables is that their computational algorithms need to be re-built from scratch upon any changes in the configuration of the network. Retraining of these algorithms requires significant amount of labeled training data, a process that is labor-intensive, time-consuming, and infeasible. We propose an approach for automatic retraining of the machine learning algorithms in real-time without need for any labeled training data. We measure the inherent correlation between observations made by an old sensor view for which trained algorithms exist and the new sensor view for which an algorithm needs to be developed. By applying our real-time multi-view autonomous learning approach, we achieve an accuracy of 80.66% in activity recognition, which is an improvement of 15.96% in the accuracy due to the automatic labeling of the data in the new sensor node. This performance is only 7.96% lower than the experimental upper bound where labeled training data are collected with the new sensor.","","Electronic:978-1-4673-8729-3; POD:978-1-4673-8730-9","10.1145/2897937.2898066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544381","","Internet of things;Labeling;Machine learning algorithms;Real-time systems;Training;Training data","Internet of Things;learning (artificial intelligence)","human-centered Internet-of-Things;machine learning;multiview autonomous learning approach;plug-n-learn;wearable technology","","","","","","","5-9 June 2016","","IEEE","IEEE Conference Publications"
"fpgaConvNet: A Framework for Mapping Convolutional Neural Networks on FPGAs","S. I. Venieris; C. S. Bouganis","Dept. of Electr. & Electron. Eng., Imperial Coll. London, London, UK","2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)","20160818","2016","","","40","47","Convolutional Neural Networks (ConvNets) are a powerful Deep Learning model, providing state-of-the-art accuracy to many emerging classification problems. However, ConvNet classification is a computationally heavy task, suffering from rapid complexity scaling. This paper presents fpgaConvNet, a novel domain-specific modelling framework together with an automated design methodology for the mapping of ConvNets onto reconfigurable FPGA-based platforms. By interpreting ConvNet classification as a streaming application, the proposed framework employs the Synchronous Dataflow (SDF) model of computation as its basis and proposes a set of transformations on the SDF graph that explore the performance-resource design space, while taking into account platform-specific resource constraints. A comparison with existing ConvNet FPGA works shows that the proposed fully-automated methodology yields hardware designs that improve the performance density by up to 1.62× and reach up to 90.75% of the raw performance of architectures that are hand-tuned for particular ConvNets.","","Electronic:978-1-5090-2356-1; POD:978-1-5090-2357-8","10.1109/FCCM.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544745","","Computational modeling;Computer architecture;Field programmable gate arrays;Hardware;Machine learning;Matrix decomposition;Space exploration","computational complexity;data flow graphs;electronic design automation;field programmable gate arrays;neural net architecture;pattern classification;performance evaluation;reconfigurable architectures","ConvNet classification;SDF graph;automated design methodology;convolutional neural network mapping;deep learning model;domain-specific modelling framework;fpgaConvNet;performance density improvement;performance-resource design space;platform-specific resource constraints;reconfigurable FPGA-based platforms;streaming application;synchronous dataflow model","","","","","","","1-3 May 2016","","IEEE","IEEE Conference Publications"
"Deep Relative Attributes","X. Yang; T. Zhang; C. Xu; S. Yan; M. S. Hossain; A. Ghoneim","National Lab of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","20160812","2016","18","9","1832","1842","Relative attribute (RA) learning aims to learn the ranking function describing the relative strength of the attribute. Most of current learning approaches learn a linear ranking function for each attribute by use of the hand-crafted visual features. Different from the existing study, in this paper, we propose a novel deep relative attributes (DRA) algorithm to learn visual features and the effective nonlinear ranking function to describe the RA of image pairs in a unified framework. Here, visual features and the ranking function are learned jointly, and they can benefit each other. The proposed DRA model is comprised of five convolutional neural layers, five fully connected layers, and a relative loss function which contains the contrastive constraint and the similar constraint corresponding to the ordered image pairs and the unordered image pairs, respectively. To train the DRA model effectively, we make use of the transferred knowledge from the large scale visual recognition on ImageNet [1] to the RA learning task. We evaluate the proposed DRA model on three widely used datasets. Extensive experimental results demonstrate that the proposed DRA model consistently and significantly outperforms the state-of-the-art RA learning methods. On the public OSR, PubFig, and Shoes datasets, compared with the previous RA learning results [2], the average ranking accuracies have been significantly improved by about 8%, 9%, and 14%, respectively.","1520-9210;15209210","","10.1109/TMM.2016.2582379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7494596","Deep learning;relative attributes (RA)","Feature extraction;Learning systems;Machine learning;Measurement;Neural networks;Object recognition;Visualization","image recognition;learning (artificial intelligence);neural nets","ImageNet;contrastive constraint;convolutional neural layer;deep relative attribute;hand-crafted visual feature;large scale visual recognition;nonlinear ranking function;ordered image pairs;relative loss function;similar constraint","","","","","","20160620","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Performance evaluation of the deep learning approach for traffic flow prediction at different times","Y. Duan; Y. Lv; F. Y. Wang","The State Key Laboratory of Management and Control for Complex Systems Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China","2016 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)","20160825","2016","","","223","227","Traffic flow prediction is very important in the deployment of intelligent transportation system. Based on our previous research on deep learning approach for traffic data prediction, we further evaluates the performance of the SAE model for traffic flow prediction at daytime and nighttime. Through 250 experimental tasks training a SAE model and evaluating its performance at daytime and nighttime with 3 different criteria, we obtain the best combination of hyper parameters for each criterion at different times on weekday and non-weekday, respectively. Experimental results show that the MAE and RMSE at daytime are larger than that at nighttime, while the MRE at daytime are smaller than that at nighttime. For different criteria, the hyper parameters of the SAE model should vary accordingly. The results in this paper indicate that in real applications, traffic flow prediction using the deep learning approach can be a combination of multiple SAE models with different parameters suitable for different periods, which is of significance in future research.","","Electronic:978-1-5090-2927-3; POD:978-1-5090-2928-0; USB:978-1-5090-2926-6","10.1109/SOLI.2016.7551691","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551691","","Data models;Machine learning;Mathematical model;Prediction algorithms;Predictive models;Roads;Training","intelligent transportation systems;learning (artificial intelligence);traffic engineering computing","SAE model hyper parameters;deep learning performance evaluation;intelligent transportation system;task training;traffic data prediction;traffic flow prediction","","","","","","","10-12 July 2016","","IEEE","IEEE Conference Publications"
"Elective Recommendation Support through K-Means Clustering Using R-Tool","Agnivesh; R. Pandey","Amity Inst. of Inf. Technol., Amity Univ., Lucknow, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","851","856","The data generated from both men and machines are exponentially multiplying the size and the structural definition of the data. Such a voluminous, dynamic and unstructured data termed as Big Data is analyzed and maintained and can be used for various purposes and applications. Big Data is generated from sources like social media, cyber physical system and business entities. This enormous data generation leads to problems of data storage and analysis. The Big Data with its diverse features calls for various tools, technologies and algorithms to make an inference which shall render strategically advantage to any entity. A typical data analytical scenario is a multidimensional problem and data clustering can lead to multi spatial analysis. Cluster can be a result of various algorithms. In this paper k means clustering is applied to generate clusters using R statistical tool and recommend elective on the basis of student's performance.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546216","Big Data;Clustering;Elective Recommendation;K-Means;R tool","Algorithm design and analysis;Big data;Classification algorithms;Clustering algorithms;Inference algorithms;Machine learning algorithms;Software algorithms","Big Data;commerce;cyber-physical systems;data analysis;pattern clustering;recommender systems;social networking (online);statistical analysis;storage management","Big Data;K-means clustering;R statistical tool;R-tool;business entities;cyber physical system;data analysis;data generation;data storage;elective recommendation;social media;structural definition","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Variable interactions in risk factors for dementia","J. O'Donoghue; M. Roantree; A. McCarren","Insight Centre for Data Analytics, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland","2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)","20160825","2016","","","1","10","Current estimates predict 1 in 3 people born today will develop dementia, suggesting a major impact on future population health. As such, research needs to connect specialist clinicians, data scientists and the general public. The In-MINDD project seeks to address this through the provision of a Profiler, a socio-technical information system connecting all three groups. The public interact, providing raw data; data scientists develop and refine prediction algorithms; and clinicians use in-built services to inform decisions. Common across these groups are Risk Factors, used for dementia-free survival prediction. Risk interactions could greatly inform prediction but determining these interactions is a problem underpinned by massive numbers of possible combinations. Our research employs a machine learning approach to automatically select best performing hyperparameters for prediction and learns variable interactions in a non-linear survival-analysis paradigm. Demonstrating effectiveness, we evaluate this approach using longitudinal data with a relatively small sample size.","","Electronic:978-1-4799-8710-8; POD:978-1-4799-8711-5","10.1109/RCIS.2016.7549314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549314","","Analytical models;Computational modeling;Dementia;Machine learning algorithms;Mathematical model;Optimization;Predictive models","data mining;learning (artificial intelligence);medical disorders;medical information systems","In-MINDD Profiler;In-MINDD project;dementia-free survival prediction;hyper-parameters;longitudinal data;machine learning approach;nonlinear survival-analysis;risk factors;risk interactions;socio-technical information system;variable interaction learning;variable interaction prediction","","","","","","","1-3 June 2016","","IEEE","IEEE Conference Publications"
"Scalable malware classification with multifaceted content features and threat intelligence","X. Hu; J. Jang; T. Wang; Z. Ashraf; M. P. Stoecklin; D. Kirat","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20160727","2016","60","4","6:1","6:11","Recent years have witnessed the very rapid increase in both the volume and sophistication of malware programs. Malware authors invest heavily in technologies and capabilities to streamline the process of building and mutating existing malware programs to evade traditional protection. One major challenge currently faced by the antivirus industry is to efficiently process the vast amount of incoming suspicious samples. Since most new malware is a variation of an existing malware family with the same forms of malicious behavior, automatic clustering and classification of malware programs into families have become valuable tools for malware analysts. Such grouping criteria not only allow analysts to prioritize the allocation of their investigation efforts but may also be applied to detect new malware samples based on their association with existing families. In this paper, we address the multi-class malware classification challenge from a scalability perspective. We present the design, development, and evaluation of a novel machine learning classifier trained on multifaceted content features (e.g., instruction sequences, strings, section information, and other malware features) as well as threat intelligence gathered from external sources (e.g., antivirus output). Our experiments on a dataset of 21,741 malware samples demonstrate the efficacy and precision of the proposed algorithm and also provide insights into the utility of various features.","0018-8646;00188646","","10.1147/JRD.2016.2559378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523365","","Classification algorithms;Data mining;Feature extraction;Machine learning algorithms;Malware;Resource management;Scalability;Semantics;Signal processing algorithms","","","","","","","","","July-Aug. 2016","","IBM","IBM Journals & Magazines"
"Four-chamber plane detection in cardiac ultrasound images based on improved imbalanced AdaBoost algorithm","Wang Lili; Fu Zhongliang; Tao Pan","Chengdu Inst. of Computer Application, Chinese Academy of Sci., China","2016 IEEE International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)","20160804","2016","","","299","303","An improved imbalanced AdaBoost algorithm called ImAdaBoost was proposed for four-chamber plane detection in cardiac ultrasound images. By assigning dynamic weight adjustment factor to each sample according the precision and true positive rate of weak learner, imbalanced classification problem was converted to cost-sensitive classification problem. Template matching method was used to detect the degree of probe rotation, planes with non-zero degree was discarded to reduce the imbalance. Using multi-instance learning method, the ultrasound image was considered as a bag which was composed of small regions, each region was described by SIFT features, the Bag of Words method was used to map instance features to bag features. ImAdaBoost was used to detect four-chamber planes in cardiac ultrasound images. The experimental results indicate that ImAdaBoost is effective on clinical cardiac ultrasound images. True positive rate is increased while false positive rate is controlled within an acceptable range.","","Electronic:978-1-5090-2594-7; POD:978-1-5090-2595-4","10.1109/ICCCBDA.2016.7529574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529574","bag of words;dynamic cost-sensitive;four-chamberplane detection;image classification;imbalanced AdaBoost;multi-instance learning;transesophageal echocardiography","Classification algorithms;Echocardiography;Heuristic algorithms;Machine learning algorithms;Testing;Training;Ultrasonic imaging","biomedical ultrasonics;image matching;learning (artificial intelligence);medical image processing;transforms","ImAdaBoost;SIFT features;bag of words method;clinical cardiac ultrasound images;dynamic weight adjustment factor;false positive rate;four-chamber plane detection;imbalanced AdaBoost algorithm;imbalanced classification problem;multiinstance learning method;template matching method;true positive rate","","","","","","","5-7 July 2016","","IEEE","IEEE Conference Publications"
"Joint optimization of audible noise suppression and deep neural networks for single-channel speech enhancement","W. Han; X. Zhang; G. Min; M. Sun; J. Yang","Lab of Intelligent Information Processing, PLAUST, Nanjing, China","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Improving the perceptual quality of speech signals is a key yet challenging problem for many real world applications. Taking into account the good performance of deep learning in signal representation, a novel single-channel speech enhancement technique is presented based on joint Deep Neural Networks and audible noise suppression as a whole network architecture. This new deep neural network jointly trains an audible noise suppression function which is used to estimate the magnitude spectrum of the clean speech and shape the spectrum of the audible noise at the same time. Experimental results on TIMIT with 20 noise types at various noise levels demonstrate the superiority of the proposed method over the baselines, no matter whether the noise conditions are included in the training set or not.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552957","Speech enhancement;audible noise suppression;deep neural networks;joint optimization","Acoustic noise;Machine learning;Noise measurement;Signal to noise ratio;Speech;Speech enhancement;Training","neural net architecture;signal representation;speech enhancement","TIMIT;audible noise suppression function;deep neural networks;network architecture;optimization;signal representation;single-channel speech enhancement;speech signals","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Detection and analysis model for grammatical facial expressions in sign language","M. S. Bhuvan; D. V. Rao; S. Jain; T. S. Ashwin; R. M. R. Guddetti; S. P. Kulgod","Department of Information Technology, National Institute of Technology, Karnataka, Surathkal","2016 IEEE Region 10 Symposium (TENSYMP)","20160725","2016","","","155","160","The proposed research explores a relatively new area of expression detection through facial points in a sign language to enhance the computer interaction with the deaf and hard of hearing. The research mainly focuses on facial points collected from Kinect as basis for expression detection as opposed to numerous gesture based studies on sign language. This helps in deploying the applications in smart phones as it is feasible to capture facial point easily rather than hand gestures. Exhaustive experimentation is carried out with ten different machine learning algorithms for detecting nine different types of expression modeled as different binary classification problem for each expression. This is done for user dependent model and user independent model scenarios. The optimal classifier for each expression is found to outperform the current state-of-the-art techniques and has ROC area greater than 0.95 for each expression. It is found that user independent model's performance is comparable to user dependent model, hence is suggested as it is easy and efficient to deploy in practical applications. Finally, the importance of each facial point in detecting each type of expression has been mined, which can be instrumental for future research and for various application using facial points as basis for decision making.","","Electronic:978-1-5090-0931-2; POD:978-1-5090-0932-9","10.1109/TENCONSpring.2016.7519396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519396","","Assistive technology;Gesture recognition;Machine learning algorithms;Manuals;Regions;Vegetation;Videos","face recognition;handicapped aids;human computer interaction;image classification;learning (artificial intelligence);sign language recognition;smart phones","Kinect;binary classification problem;computer interaction;deaf;decision making;facial points;grammatical facial expression detection;machine learning algorithms;sign language;smart phones;user dependent model;user independent model","","","","","","","9-11 May 2016","","IEEE","IEEE Conference Publications"
"Indoor localization of vehicles using Deep Learning","A. K. T. R. Kumar; B. Schäufele; D. Becker; O. Sawade; I. Radusch","Fraunhofer Institute for Open Communication Technologies (FOKUS), Berlin, Germany","2016 IEEE 17th International Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM)","20160728","2016","","","1","6","Modern vehicles are equipped with numerous driver assistance and telematics functions, such as Turn-by-Turn navigation. Most of these systems rely on precise positioning of the vehicle. While Global Navigation Satellite Systems (GNSS) are available outdoors, these systems fail in indoor environments such as a car-park or a tunnel. Alternatively, the vehicle can localize itself with landmark-based positioning and internal car sensors, yet this is not only costly but also requires precise knowledge of the enclosed area. Instead, our approach is to use infrastructure-based positioning. Here, we utilize off-the shelf cameras mounted in the car-park and Vehicle-to-Infrastructure Communication to allow all vehicles to obtain an indoor position given from an infrastructure-based localization service. Our approach uses a Convolutional Neural Network (CNN) with Deep Learning to identify and localize vehicles in a car-park. We thus enable position-based Driver Assistance Systems (DAS) and telematics in an underground facility. We compare the novel Deep Learning classifier to a conventional classifier using Haar-like features.","","Electronic:978-1-5090-2185-7; POD:978-1-5090-2186-4","10.1109/WoWMoM.2016.7523569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523569","","Cameras;Feature extraction;Machine learning;Neural networks;Sensors;Training;Vehicles","indoor navigation;learning (artificial intelligence);neural nets;satellite navigation","CNN;DAS;GNSS;Haar-like feature classifier;car-park;convolutional neural network;deep learning classifier;driver assistance system;global navigation satellite system;indoor environment;indoor position;internal car sensor;landmark-based positioning;off-the shelf camera;telematics function;turn-by-turn navigation;vehicle indoor localization;vehicle-to-infrastructure communication","","","","","","","21-24 June 2016","","IEEE","IEEE Conference Publications"
"Application of deep learning for recognizing infant cries","C. Y. Chang; J. J. Li","National Yunlin University of Science & Technology, Taiwan","2016 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)","20160728","2016","","","1","2","Crying is a way which infants express their needs to their parents. In general, parents often feel worried and anxious when infant crying. For realizing the reason of baby crying, this paper presents an automatic infant crying recognition method. Crying is convert to spectrogram. A convolutional neural networks (CNN) based deep learning is then adopted to train and classify the crying into three categories including hungry, pain, and sleepy. Experimental results shows that the proposed method achieves high classification accuracy.","","Electronic:978-1-5090-2073-7; POD:978-1-5090-2074-4","10.1109/ICCE-TW.2016.7520947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7520947","","Biological neural networks;Convolution;Machine learning;Neurons;Pain;Spectrogram;Speech recognition","audio signal processing;convolution;learning (artificial intelligence);medical signal processing;neural nets;paediatrics","CNN based deep learning;automatic infant crying recognition method;convolutional neural networks;spectrogram","","","","","","","27-29 May 2016","","IEEE","IEEE Conference Publications"
"Fault diagnosis based on deep learning","F. Lv; C. Wen; Z. Bao; M. Liu","Institute of Control Theory and Control Engineering, Zhejiang University, Hangzhou, China","2016 American Control Conference (ACC)","20160801","2016","","","6851","6856","As representation scheme can severely limit the window by which the system observes its world, deep learning for fault diagnosis is put forward in this paper. It is a real time online scheme that can enhance the accuracy of detection, classification and prediction, and efficient for incipient faults that cannot be detected by traditional statistic technology. A stacked sparse auto encoder is used to learn the deep architectures of fault data to minimize the loss of information. Experiment results show that the proposed method not only improves the divisibility between faults and normal process, but also exhibits a better performance on the accuracy of fault classification for the chemical benchmark, Tennessee Eastman Process (TEP) data.","","CD-ROM:978-1-4673-8680-7; Electronic:978-1-4673-8682-1; POD:978-1-4673-8683-8","10.1109/ACC.2016.7526751","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526751","deep learning;fault classification;fault detection;sparse auto encoding","Classification algorithms;Encoding;Fault detection;Fault diagnosis;Machine learning;Support vector machines;Training","chemical engineering computing;chemical industry;encoding;fault diagnosis;learning (artificial intelligence);pattern classification","TEP;Tennessee Eastman process;chemical production system;deep learning;fault data classification;fault diagnosis;sparse autoencoder","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"A Credibility Analysis System for Assessing Information on Twitter","M. Alrubaian; M. Al-Qurishi; M. Hassan; A. Alamri","Majed Alrubaian is with the Research Chair of Pervasive and Mobile Computing, College of Computer and Information Sciences, King Saud University, Riyadh 11543, Saudi Arabia.(Email: malrubaian.c@ksu.edu.sa)","IEEE Transactions on Dependable and Secure Computing","","2017","PP","99","1","1","Information credibility on Twitter has been a topic of interest among researchers in the fields of both computer and social sciences, primarily because of the recent growth of this platform as a tool for information dissemination. Twitter has made it increasingly possible to offer near-real-time transfer of information in a very cost-effective manner. It is now being used as a source of news among a wide array of users around the globe. The beauty of this platform is that it delivers timely content in a tailored manner that makes it possible for users to obtain news regarding their topics of interest. Consequently, the development of techniques that can verify information obtained from Twitter has become a challenging and necessary task. In this paper, we propose a new credibility analysis system for assessing information credibility on Twitter to prevent the proliferation of fake or malicious information. The proposed system consists of four integrated components: a reputation-based component, a credibility classifier engine, a user experience component, and a feature-ranking algorithm. The components operate together in an algorithmic form to analyze and assess the credibility of Twitter tweets and users. We tested the performance of our system on two different datasets from 489,330 unique Twitter accounts. We applied 10-fold cross-validation over four machine learning algorithms. The results reveal that a significant balance between recall and precision was achieved for the tested dataset.","1545-5971;15455971","","10.1109/TDSC.2016.2602338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551232","Credibility;Twitter;classification;feature-ranking;reputation;user experience","Algorithm design and analysis;Classification algorithms;Computational modeling;Earthquakes;Machine learning algorithms;Twitter","","","","","","","","20160824","","","IEEE","IEEE Early Access Articles"
"Invited — Cross-layer approximations for neuromorphic computing: From devices to circuits and systems","P. Panda; A. Sengupta; S. S. Sarwar; G. Srinivasan; S. Venkataramani; A. Raghunathan; K. Roy","School of Electrical and Computer Engineering, Purdue University","2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)","20160818","2016","","","1","6","Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.","","Electronic:978-1-4673-8729-3; POD:978-1-4673-8730-9","10.1145/2897937.2905009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544341","","Approximation algorithms;Artificial neural networks;Biological neural networks;Energy efficiency;Machine learning;Neuromorphics;Neurons","learning (artificial intelligence);neural nets;power aware computing","approximate computing;approximate logic;artificial neural network;deep learning;energy-efficient neuromorphic system;neuromorphic algorithm;neuromorphic computing","","","","","","","5-9 June 2016","","IEEE","IEEE Conference Publications"
"C-Brain: A deep learning accelerator that tames the diversity of CNNs through adaptive data-level parallelization","L. Song; Y. Wang; Y. Han; X. Zhao; B. Liu; X. Li","State Key Laboratory of Computer Architecture Institute of Computing Technology, Chinese Academy of Sciences, Beijing, P.R. China","2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)","20160818","2016","","","1","6","Convolutional neural networks (CNN) accelerators have been proposed as an efficient hardware solution for deep learning based applications, which are known to be both compute-and-memory intensive. Although the most advanced CNN accelerators can deliver high computational throughput, the performance is highly unstable. Once changed to accommodate a new network with different parameters like layers and kernel size, the fixed hardware structure, may no longer well match the data flows. Consequently, the accelerator will fail to deliver high performance due to the underutilization of either logic resource or memory bandwidth. To overcome this problem, we proposed a novel deep learning accelerator, which offers multiple types of data-level parallelism: inter-kernel, intra-kernel and hybrid. Our design can adaptively switch among the three types of parallelism and the corresponding data tiling schemes to dynamically match different networks or even different layers of a single network. No matter how we change the hardware configurations or network types, the proposed network mapping strategy ensures the optimal performance and energy-efficiency. Compared with previous state-of-the-art NN accelerators, it is possible to achieve a speedup of 4.0x-8.3x for some layers of the well-known large scale CNNs. For the whole phase of network forward-propagation, our design achieves 28.04% PE energy saving, 90.3% on-chip memory energy saving on average.","","Electronic:978-1-4673-8729-3; POD:978-1-4673-8730-9","10.1145/2897937.2897995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544365","","Artificial neural networks;Convolution;Hardware;Kernel;Machine learning;Parallel processing;Tin","learning (artificial intelligence);neural nets","C-Brain;CNN accelerator;adaptive data-level parallelization;convolutional neural network;data tiling scheme;deep learning accelerator;onchip memory energy saving","","1","","","","","5-9 June 2016","","IEEE","IEEE Conference Publications"
"Quality scores for deep regression systems","Y. Gurovich; I. Kissos; Y. Hanani","FDNA inc., Herzliya, Israel","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3758","3762","Deep methods based on Convolutional Neural Networks serve as accurate facial points and body parts detectors. However, most methods do not provide a confidence score for the quality of the localization process. In real world applications, such a score could be invaluable. We, therefore, study the problem of estimating the success of the localization process during test time. Our method is based on mapping the network activation features to the area under the point-accuracy-curve. Our method greatly outperforms methods that were recently suggested, such as those which are based on the stability of the detection or on the norm of the representation layer.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7533062","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533062","Deep learning;facial landmark localization;pose estimation;regression","Face;Face recognition;Heating;Machine learning;Mirrors;Neural networks;Pose estimation","convolution;estimation theory;face recognition;feature extraction;neural nets;regression analysis","body part detector;convolutional neural network;deep regression system;facial point detector;localization process;quality score;success estimation","","","","21","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"GEINet: View-invariant gait recognition using a convolutional neural network","K. Shiraga; Y. Makihara; D. Muramatsu; T. Echigo; Y. Yagi","The Institute of Scientific and Industrial Research, Osaka University, 8-1 Mihogaoka, Ibaraki, Japan","2016 International Conference on Biometrics (ICB)","20160825","2016","","","1","8","This paper proposes a method of gait recognition using a convolutional neural network (CNN). Inspired by the great successes of CNNs in image recognition tasks, we feed in the most prevalent image-based gait representation, that is, the gait energy image (GEI), as an input to a CNN designed for gait recognition called GEINet. More specifically, GEINet is composed of two sequential triplets of convolution, pooling, and normalization layers, and two subsequent fully connected layers, which output a set of similarities to individual training subjects. We conducted experiments to demonstrate the effectiveness of the proposed method in terms of cross-view gait recognition in both cooperative and uncooperative settings using the OU-ISIR large population dataset. As a result, we confirmed that the proposed method significantly outperformed state-of-the-art approaches, in particular in verification scenarios.","","Electronic:978-1-5090-1869-7; POD:978-1-5090-1870-3","10.1109/ICB.2016.7550060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550060","","Convolution;Databases;Feature extraction;Gait recognition;Machine learning;Robustness;Training","convolution;gait analysis;image recognition;neural nets","CNN;GEINet;convolutional neural network;gait energy image;gait recognition","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Joint visual denoising and classification using deep learning","G. Chen; Y. Li; S. N. Srihari","Department of Computer Science, SUNY at Buffalo, Buffalo NY 14260","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3673","3677","Visual restoration and recognition are traditionally addressed in pipeline fashion, i.e. denoising followed by classification. Instead, observing correlations between the two tasks, for example clearer image will lead to better categorization and vice visa, we propose a joint framework for visual restoration and recognition for handwritten images, inspired by advances in deep autoencoder and multi-modality learning. Our model is a 3-pathway deep architecture with a hidden-layer representation which is shared by multi-inputs and outputs, and each branch can be composed of a multi-layer deep model. Thus, visual restoration and classification can be unified using shared representation via non-linear mapping, and model parameters can be learnt via backpropagation. Using MNIST and USPS data corrupted with structured noise, the proposed framework performs at least 20% better in classification than separate pipelines, as well as clearer recovered images.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7533045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533045","","Image recognition;Image restoration;Machine learning;Noise measurement;Noise reduction;Training;Visualization","backpropagation;handwritten character recognition;image classification;image denoising;image restoration;text detection","3-pathway deep architecture;MNIST data;USPS data;backpropagation;deep autoencoder;deep learning;handwritten image recognition;hidden-layer representation;image classification;image denoising;joint visual denoising;multimodality learning;nonlinear mapping;pipeline fashion;visual recognition;visual restoration","","","","22","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"A jointly local structured sparse deep learning network for face recognition","R. Wu; S. i. Kamata","Graduate School of Information, Production and Systems, Waseda University, Japan","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3026","3030","In this paper, we proposed an optimized Sparse Deep Learning Network (SDLN) model for Face Recognition (FR). A key contribution of this work is to learn feature coding of human face with a SDLN based on local structured Sparse Representation (SR). In traditional sparse FR methods, different poses and expressions of training samples could have great influence on the recognition results. We consider the SR that should be guided by context constraints which are defined by the correlations of dictionary atoms. The over-complete common dictionary that contains common atom set has been learned from a local region structured sparse encoding process. We obtained over-complete common dictionary and feature coding for each face. As we all know that the deep learning has been widely applied to face feature learning. Using traditional deep learning methods can not contain variations of face identity information. We have to get face features of compatible change in a jointly deep learning network. The proposed SDLN is jointly fine-tuned to optimize for the task of FR. The SDLN achieves high FR performance on the ORL and FERET database.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532915","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532915","Atom decomposition;Face recognition;Over-complete dictionary learning;Restricted boltzmann machine;Sparse deep learning network","Databases;Dictionaries;Face;Feature extraction;Machine learning;Testing;Training","face recognition;feature extraction;learning (artificial intelligence);optimisation","FERET database;ORL database;context constraints;face feature learning;face identity information;face recognition;feature coding;joint local structured sparse deep learning network;local region structured sparse encoding process;local structured sparse representation;optimized SDLN model;optimized sparse deep learning network model;over-complete common dictionary","","","","27","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Comparative Study of Tools and Techniques for Cloud Services QoS Performance Management","A. Bashar","Coll. of Comput. Eng. & Sci., Prince Mohammad Bin Fahd Univ., Al-Khobar, Saudi Arabia","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","796","800","The phenomenal growth of Cloud Computing as an IT service across various organizational domains has resulted in the critical challenge of their performance evaluation. One of the key problems which is being faced by the cloud service providers and the cloud customers is the ability of assessing the QoS and QoE performance of cloud services under various service delivery scenarios. This has created an opportunity for the cloud system researchers to create and develop tools which can achieve the evaluation of the QoS and QoE of the provisioned cloud services. These tools should be designed in such a way that they can simulate and test the cloud services before these services are to be commissioned to the customers, as this will eventually minimize service disruptions and performance degradation issues during the real-time operational phase. However, it is observed that a plethora of such tools and techniques are available in this research domain and this paper is an attempt to critically evaluate and compare them in a organized and methodological manner. Hence the paper, in a novel way, compares the most popular QoS techniques for Cloud Computing system and the appropriate simulation tools. It also provides informed and technically sound recommendations towards the choice of a tool appropriate for the the cloud service providers and their administrators who can immensely benefit by their adoption.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546205","Cloud Computing;Modeling Tools and Simulation Frameworks;QoS Performance Study","Cloud computing;Computational modeling;Hardware;Machine learning algorithms;Predictive models;Quality of service","cloud computing;digital simulation;minimisation;quality of experience;quality of service;real-time systems;software performance evaluation","IT service;QoE performance;cloud computing system;cloud customers;cloud service providers;cloud services QoS performance management techniques;cloud services QoS performance management tools;cloud services simulation;cloud services testing;organizational domains;performance degradation issues;performance evaluation;real-time operational phase;service delivery scenarios;service disruption minimization","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Work mode identification of airborne phased array radar based on the combination of multi-level modeling and deep learning","H. Li; W. D. Jin; H. D. Liu; T. W. Chen","School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","7005","7010","According to the change law of pulse signal in airborne phased array radar under different modes, a new method based on multi-level modeling combined with deep learning is proposed to recognize airborne phased array radar under different modes. Firstly parameters-jointing modeling is proposed to model the emitters at pulse level, pulse group level and the work mode level. Then stacked denoising auto-encoder is introduced to extract features from pulse signal under the work mode level unsupervised. Finally the parameters of the network are optimized by the back propagation algorithm in order to recognize airborne phased array radar under different modes. Qualitative experiments show that compared with the original algorithm based on knowledge base, the new method are able to extract essential characteristics of the input, reduce the dependence on prior knowledge, and achieve a good performance.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554461","airborne radar;multi-level modeling;stacked denoising auto-encoder;unsupervised learning;work mode","Airborne radar;Atmospheric modeling;Machine learning;Noise reduction;Phased arrays;Radar tracking","airborne radar;backpropagation;feature extraction;knowledge based systems;neural nets;phased array radar;radar signal processing","airborne phased array radar recognition;back propagation algorithm;deep learning;emitter modelling;feature extraction;knowledge base;multilevel modeling;parameters-jointing modeling;pulse group level;pulse signal;stacked denoising auto-encoder;work mode identification;work mode level","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Survey on feature subset selection for high dimensional data","A. H. Shahana; V. Preeja","Department of Computer Science and Engineering, SCT College of Engineering, Trivandrum, India","2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT)","20160804","2016","","","1","4","Nowadays high dimensional data plays an important role in many scientific and research applications. A high dimensional data consists of several features or attributes. These data may contain redundant and irrelevant features. In order to reduce the dimensionality of data, these unwanted and redundant features need to be removed. Feature selection techniques are used to identify the redundant and irrelevant features from the original set of data. Feature selection identifies most representative features from a collection of features. This survey explains a novel clustering based feature subset selection algorithm for high dimensional data, FAST. The algorithm involves removal of irrelevant features from a collection of data, construction of minimum spanning tree followed by tree partitioning and finally selecting subset of features.","","DVD:978-1-5090-1276-3; Electronic:978-1-5090-1277-0; POD:978-1-5090-1278-7","10.1109/ICCPCT.2016.7530147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530147","feature clustering;feature selection methods;subset selection","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Filtering algorithms;Machine learning algorithms;Partitioning algorithms;Prediction algorithms","data reduction;feature selection;pattern clustering;set theory;trees (mathematics)","FAST;clustering based feature subset selection algorithm;data collection;data dimensionality reduction;high dimensional data;irrelevant features;minimum spanning tree;redundant features;representative features;research applications;scientific applications;tree partitioning","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Bootstrapping deep feature hierarchy for pornographic image recognition","K. Li; J. Xing; B. Li; W. Hu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, P. R. China","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","4423","4427","Automatically recognizing pornographic images from the Web is a vital step to purify Internet environment. Inspired by the rapid developments of deep learning models, we present a deep architecture of convolutional neural network (CNN) for high accuracy pornographic image recognition. The proposed architecture is built upon existing CNNs which accepts input images of different sizes and incorporates features from different hierarchy to perform prediction. To effectively train the model, we propose a two-stage training strategy to learn the model parameters from scratch and end-to-end. During the training procedure, we also employ a hard negative sampling strategy to further reduce the false positive rate of the model. Experimental results on a large dataset demonstrate good performance of the proposed model and the effectiveness of our training strategies, with a considerable improvement over some traditional methods using hand-crafted features and deep learning method using mainstream CNN architecture.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7533196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533196","Pornographic image recognition;bootstrap;deep learning","Feature extraction;Image color analysis;Image recognition;Machine learning;Shape;Skin;Training","Internet;computer bootstrapping;convolution;image recognition;learning (artificial intelligence);neural nets;sampling methods","CNN;Internet environment;bootstrapping deep feature hierarchy;convolutional neural network;deep learning models;hand-crafted features;hard negative sampling strategy;pornographic image recognition;two-stage training strategy","","","","20","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"A platform and analytics for usage and entitlement analytics","S. N. Chari; T. A. Habeck; I. Molloy; Y. Park; J. R. Rao; W. Teiken","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20160727","2016","60","4","7:1","7:12","As illustrated by recent high-profile cases such as WikiLeaks and Snowden, information exfiltration is one of the key motivations for cyber-attacks. In this paper, we describe our approach to detect misuse of authorizations by insiders based on detection of anomalous user activity. Our system is based on novel machine learning algorithms to build multidimensional user profiles, which are then used to alert administrators upon detection of significant deviation in a user's behavior. Key components to our profiling are generative models of user activity, which are intended to produce the best probabilistic model to explain observed activity. We have deployed these models on a range of applications such as monitoring access to source code repositories, security subsystem activity in mainframe systems, web application logs, and other proprietary applications. Extensive testing of our system with more than six years of user activity, and multiple red-teaming exercises have enabled us to tune our analytics to produce accurate results with very low false positive rates. Our analytic models are currently in use today to monitor a number of sensitive assets within IBM.","0018-8646;00188646","","10.1147/JRD.2016.2560558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523361","","Access control;Analytical models;Authorization;Data models;Intrusion detection;Machine learning;Monitoring;Probabilistic logic;Usage statistics","","","","","","","","","July-Aug. 2016","","IBM","IBM Journals & Magazines"
"Feature Based Performance Evaluation of Support Vector Machine on Binary Classification","S. Sharma; S. K. Srivastava","","2016 Second International Conference on Computational Intelligence & Communication Technology (CICT)","20160818","2016","","","170","173","Classification is a challenging phenomenon. Text classification uses terms as features which can be grouped to vote for belongingness of a class. This paper explores the performance of Support Vector Machine (SVM) on variation of text features. Empirical results support the findings. The reported result shows significant degradation in SVM classifier as we reduce features from 100 to 50 and then to 25. Short text messages (tweets) are used as a data set and balanced binary classes are used with 841 tweets each. We have used radial basis function as a kernel parameter. TP Rate, FP Rate, Precision, Recall, F Measure are used as a measure of performance evaluator. Confusion matrix is used for quick review of classifier and 10 fold cross validation is used for estimation of prediction model.","","CD-ROM:978-1-5090-0208-5; Electronic:978-1-5090-0210-8; POD:978-1-5090-0211-5","10.1109/CICT.2016.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546595","Radial Basis function;SVM;features","Filtering algorithms;Kernel;Machine learning algorithms;Support vector machines;Text categorization;Training data;Twitter","matrix algebra;pattern classification;support vector machines;text analysis","F Measure;FP Rate;Precision;Recall;SVM classifier;Short text messages;TP Rate;balanced binary classes;binary classification;confusion matrix;data set;feature based performance evaluation;kernel parameter;support vector machine;text classification;text features;tweets","","","","","","","12-13 Feb. 2016","","IEEE","IEEE Conference Publications"
"Development of an automated system for building detection from high-resolution satellite images","H. Miyazaki; K. Kuwata; W. Ohira; Z. Guo; X. Shao; Y. Xu; R. Shibasaki","Center for Spatial Information Science, University of Tokyo, Japan","2016 4th International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","20160829","2016","","","245","249","Detail information of human settlements is crucial for development issues, such as public health, energy development, and disaster risk management. While the methodologies of settlement mapping in urban areas have been developed well, there are still few studies on settlement mapping in rural areas and villages, which are important for urban development in regard to connectivity of development impacts. For the settlement mapping of rural areas and villages, we developed a system of automated building detection from high-resolution satellite images which are provided from Bing Maps. The algorithm of building detection is based on the Convolutional Neural Network, a well-known deep learning method for image recognition. Because the amount of satellite images is enormous, we implemented the algorithm with a high-performance computing with massive parallel processing on the Data Integration and Analysis System (DIAS) in the University of Tokyo. We demonstrated the building detection using the developed system for Yangon, Myanmar.","","Electronic:978-1-5090-1479-8; POD:978-1-5090-1480-4","10.1109/EORSA.2016.7552806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552806","building detection;deep learning;high-performance computing;high-resolution satellite images","Earth;Machine learning;Remote sensing;Satellites;Tiles;Training","buildings (structures);image recognition;learning (artificial intelligence);neural nets","DIAS;automated building detection;convolutional neural network;data integration and analysis system;deep learning method;development impacts connectivity;disaster risk management;energy development;high-resolution satellite images;human settlements;image recognition;public health;settlement mapping;urban development","","","","","","","4-6 July 2016","","IEEE","IEEE Conference Publications"
"Data-driven event detection with partial knowledge: A Hidden Structure Semi-Supervised learning method","Y. Zhou; R. Arghandeh; I. Konstantakopoulos; S. Abdullah; C. J. Spanos","Electrical Engineering Computer Sciences, University of California, Berkeley, 94720, USA","2016 American Control Conference (ACC)","20160801","2016","","","5962","5968","Enabled by the advancement of data acquisition and data analysis technologies such as sensor networks and machine learning, recently data-driven event detection has shown its advantage in dealing with complex systems especially those with significant stochastic and dynamic behavior. However, existing methods usually adopt supervised learning framework and depend on explicit expert labeling in the learning phase, which is expensive even impractical in many situations. In this work, we propose a new data-driven event detection method, namely Hidden Structure Semi-Supervised Machine (HS3M), that only requires partial expert knowledge. The key idea is to combine unlabeled data and partly labeled data in a large margin learning objective to bridge the gap between supervised, semi-supervised learning and learning with hidden structures. Difficulties do arise as the incorporation of extra learning terms makes the problem non-convex. To optimize the learning objective we establish a novel global optimization algorithm, namely Parametric Dual Optimization Procedure (PDOP), by showing that the parametrized dual problem has local explicit solutions and the corresponding optimality is convex in hidden variables. The proposed approach is applied to power distribution network event detection, and the result justifies the effectiveness of both HS3M and the new global optimization algorithm.","","CD-ROM:978-1-4673-8680-7; Electronic:978-1-4673-8682-1; POD:978-1-4673-8683-8","10.1109/ACC.2016.7526605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526605","","Computational modeling;Event detection;Fasteners;Kernel;Labeling;Machine learning algorithms;Optimization","concave programming;data acquisition;data analysis;learning (artificial intelligence)","HS<sup>3</sup>M;PDOP;data acquisition advancement;data analysis;data-driven event detection;global optimization algorithm;hidden structure semisupervised learning method;learning phase;parametric dual optimization procedure;partial expert knowledge;power distribution network event detection;supervised learning","","2","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"Deep learning based human behavior recognition in industrial workflows","K. Makantasis; A. Doulamis; N. Doulamis; K. Psychas","Technical University of Crete, School of Production Engineering and Management, Chania, Greece","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1609","1613","We consider the fully automated behavior understanding through visual cues in industrial environments. In contrast to most existing work, which relies on domain knowledge to construct complex handcrafted features from inputs, we exploit a Convolutional Neural Network (CNN), which is a type of deep model and can act directly on the raw inputs, to automate the process of feature construction. Although such models are limited to handle still 2D inputs, in this paper we appropriately transform video input to incorporate temporal information into each frame. This way our model hierarchically constructs features from both spatial and temporal dimensions. We apply our model in real-world environment, on data taken from Nissan factory, and it achieves superior performance without relying on handcrafted features.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532630","Deep learning;behavior understanding;convolutional neural networks;industrial workflow","Computer architecture;Hidden Markov models;Machine learning;Solid modeling;Three-dimensional displays;Two dimensional displays;Visualization","automobile industry;automotive engineering;behavioural sciences computing;image recognition;learning (artificial intelligence);neural nets;production engineering computing;video signal processing","Nissan factory;complex handcrafted feature construction;deep learning based human behavior recognition;fully automated behavior;industrial workflows;spatial dimensions;temporal dimensions","","","","21","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Application of Hierarchical Clustering Algorithm to Evaluate Students Performance of an Institute","S. Rana; R. Garg","Dept. of IT, Panjab Univ., Chandigarh, India","2016 Second International Conference on Computational Intelligence & Communication Technology (CICT)","20160818","2016","","","692","697","Machine Learning is the field of computer science that learns from data by studying algorithms and their constructions. In machine learning, predictions can be made by using certain algorithms for specific inputs. In this paper important classification and clustering algorithms are discussed which can be further applied to BE (Information Technology). Third Semester to evaluate student's performance. The performance of students of Digital Electronics of University Institute of Engineering and Technology (UIET), Panjab University (PU) is calculated by applying Hierarchical Clustering Algorithm. Unsupervised Learning Algorithms like K-Means and Hierarchical clustering are discussed and for supervised learning, Naive Bayes and Logistic Regression are discussed. Further the comparisons between the two supervised algorithms and the two unsupervised algorithms are made.","","CD-ROM:978-1-5090-0208-5; Electronic:978-1-5090-0210-8; POD:978-1-5090-0211-5","10.1109/CICT.2016.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546697","Classification;Clustering;K-Means;Logical Regression;Naïve Bayes;Prediction","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Logistics;Machine learning algorithms;Prediction algorithms;Supervised learning","Bayes methods;educational institutions;pattern classification;pattern clustering;regression analysis;unsupervised learning","BE Third Semester;Digital Electronics;K-means algorithms;Naive Bayes method;Panjab University;UIET;University Institute of Engineering and Technology;classification algorithms;hierarchical clustering algorithm;logistic regression;machine learning;student performance evaluation;supervised learning;unsupervised learning algorithm","","","","","","","12-13 Feb. 2016","","IEEE","IEEE Conference Publications"
"Distributed online optimization of high-order multi-agent systems","Z. Deng; Y. Zhang; Y. Hong","Key Lab of Systems and Control, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","7672","7677","Distributed online optimization problem for continuous-time multi-agent systems with the form of high-order integrator is studied in this paper. In order to minimize the regret, a distributed online optimization algorithm is developed via consensus idea, PI control idea and gradient descent. Moreover, we show that under the proposed algorithm, the regret bound approaches a constant when the operating time tends to infinity.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554573","Distributed online optimization;high-order integrator;multi-agent systems;regret analysis","Algorithm design and analysis;Cost function;Eigenvalues and eigenfunctions;Heuristic algorithms;Machine learning algorithms;Multi-agent systems","PI control;continuous time systems;gradient methods;multi-agent systems;optimisation","PI control idea;consensus idea;continuous-time multiagent systems;distributed online optimization algorithm;gradient descent;high-order integrator;high-order multiagent systems","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Multimodal learning for image popularity prediction on social media","J. Hu; T. Yamasaki; K. Aizawa","Department of Information and Communication Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan","2016 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)","20160728","2016","","","1","2","Billions of photographs are uploaded to the Internet every day through image sharing services, e.g., Flickr, Instagram, etc. The growing size of these social media poses new challenges in social popularity prediction. In this paper, we try to use a multimodal learning approach which uses both tag feature and visual feature for popularity prediction. We compare several multimodal approaches with unimodal approaches in our experiments and show the results.","","Electronic:978-1-5090-2073-7; POD:978-1-5090-2074-4","10.1109/ICCE-TW.2016.7521017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7521017","","Feature extraction;Flickr;Kernel;Machine learning;Media;Predictive models;Visualization","learning (artificial intelligence);social networking (online)","Flickr;Instagram;image popularity prediction;image sharing services;multimodal learning approach;photographs;social media;social popularity prediction;tag feature;unimodal approaches;visual feature","","","","","","","27-29 May 2016","","IEEE","IEEE Conference Publications"
"Deep object tracking with multi-modal data","X. Zhang; Y. Yuan; X. Lu","Center for OPTical IMagery Analysis and Learning (OPTIMAL), State Key Laboratory of Transient Optics and Photonics, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, Shaanxi, P.R. China","2016 International Conference on Computer, Information and Telecommunication Systems (CITS)","20160818","2016","","","1","5","Object tracking is a challenging topic in the field of computer vision since its performance is easily disturbed by occlusion, illumination change, background clutter, scale variation, etc. In this paper, we introduce a robust tracking algorithm that fuses information from both visible images and infrared (IR) images. The proposed tracking algorithm not only incorporates convolutional feature maps from the visible channel, but also employs a scale pyramid representation from IR channel. We estimate the target location by fusing multilayer convolutional feature maps, and predict the target scale from a scale pyramid. The pipeline of the proposed method is as follows. First, the hierarchical convolutional feature maps are obtained from visible images using VGG-Nets. Then, the accurate target location is predicted by the maximum response of correlation filters with the visible image feature maps. Finally, we obtain the precise object scale with a scale pyramid from infrared images where the difference between the target and the background is clear. In order to verify the performance of the proposed method, we capture six video sequences under different conditions. These sequences contain both visible channel and IR channel. Ten state-of-the-art tracking algorithms are compared with our method, and the experimental results show the effectiveness of the proposed tracker.","","Electronic:978-1-5090-0690-8; POD:978-1-5090-0691-5; USB:978-1-5090-3440-6","10.1109/CITS.2016.7546403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546403","","Correlation;Feature extraction;Machine learning;Nonhomogeneous media;Object tracking;Robustness;Target tracking","computer vision;object tracking;self-organising feature maps","VGG-Nets;background clutter;computer vision;deep object tracking;hierarchical convolutional feature maps;illumination change;infrared image;multilayer convolutional feature maps;multimodal data;occlusion;robust tracking algorithm;scale pyramid representation;scale variation;visible image","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"Over-The-Top Catch-up TV content-aware caching","J. Nogueira; D. Gonzalez; L. Guardalben; S. Sargento","Altice Labs, SA, Aveiro, Portugal","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","1012","1017","The migration of popular Catch-up TV services to modern Over-The-Top (OTT) multimedia delivery infrastructures creates a wide set of scalability challenges which are commonly addressed using Content Delivery Networks (CDNs) relying on caching nodes close to users. The use of general-purpose caching nodes, tailored for generic web content, is far from optimal as it does not consider the particularities of Catch-up TV content, namely its dynamic popularity behavior, superstar effects, and relevance decay, as shown in existing scientific literature. Since caches are limited in size and are relatively small when compared to the whole catalog of available Catch-up TV content, which may contain tens of thousands of TV programs, it is crucial to make the most out of the available resources. To address these issues, this paper proposes a novel content-aware cache replacement algorithm, Most Popularly Used (MPU), capable of taking advantage of content demand forecasts built using machine learning models, to significantly outperform traditional cache replacement policies, such as Least Recently Used (LRU), Least Frequently Used (LFU), and First-In-First-Out (FIFO), and approach the optimal theoretical hit-ratio limits. MPU leverages millions of Catch-up TV request logs to validate its results under realistic conditions.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543869","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543869","","Bandwidth;Machine learning algorithms;Multimedia communication;Optimization;Predictive models;Servers;TV","IPTV;learning (artificial intelligence)","CDN;Catch-up TV content;Catch-up TV request logs;Catch-up TV services;MPU;TV programs;Web content;content delivery networks;content demand forecasts;content-aware cache replacement algorithm;machine learning models;most popularly used;over-the-top Catch-up TV content-aware caching;over-the-top multimedia delivery infrastructures","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"A Service Recommendation Algorithm Based on Modeling of Implicit Demands","Y. Zhang; T. Lei; Y. Wang","Inf. Sch., Central Univ. of Finance & Econ., Beijing, China","2016 IEEE International Conference on Web Services (ICWS)","20160901","2016","","","17","24","The results from using the current service recommendation algorithms are still unable to meet the dynamic and diverse demands of users. Therefore, a recommendation algorithm is proposed to take into account the dynamic and diverse demands of users. This algorithm extracts the user-implicit-demand-factors from the Latent Dirichlet Allocation model in the field of machine learning, and uses both explicit and implicit demand as the intermediary variable to generate a service recommendation list for the user. Experimental results on a real-world data set regarding service composition show that the proposed algorithm can represent a variety of user demands, and the performance of the proposed algorithm is better than the existing algorithms in terms of accuracy, novelty and timeliness.","","Electronic:978-1-5090-2675-3; POD:978-1-5090-2676-0","10.1109/ICWS.2016.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557980","Latent Dirichlet Allocation;service computing;service recommendation;user demand modeling","Computational modeling;Facebook;Heuristic algorithms;Machine learning algorithms;Probabilistic logic;Probability distribution;Web services","Web services;query processing;recommender systems","accuracy factor;dynamic-diverse user demands;explicit demand modeling;implicit demand modeling;intermediary variable;latent Dirichlet allocation model;machine learning;novelty factor;real-world data set;service composition;service recommendation list generation;timeliness factor;user-implicit-demand-factor extraction","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Patch-based face hallucination with multitask deep neural network","W. J. Ko; S. Y. Chien","Department of Electrical Engineering, National Taiwan University","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Face hallucination technique generates high-resolution face images from low-resolution ones. In this paper, we propose a patch based multitask deep learning method for face hallucination, which is robust to blurring of images. Our method is based on fully connected feedforward neural network, and the weights of the final layers are fine-tuned separately on different clusters of patches. Experimental results show that our system outperforms the prior state-of-the-art methods by a significant margin, while using less testing computation time.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552975","Face hallucination;deep learning;superresolution","Face;Image reconstruction;Image resolution;Machine learning;Neural networks;Testing;Training","face recognition;feedforward neural nets;image resolution;learning (artificial intelligence)","feedforward neural network;high-resolution face images;multitask deep neural network;patch based multitask deep learning method;patch-based face hallucination","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Deep learning-based soft-sensing method for operation optimization of coke dry quenching process","J. G. Wang; J. H. Zhao; T. Shen; S. W. Ma; Y. Yao; T. Chen; B. Shen; Y. P. Wu","School of Mechatronical Engineering and Automation, Shanghai University, Shanghai Key Lab of Power Station Automation Technology, 200072, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","9087","9092","In the modern industrial process control, the development of distributed control system (DCS) makes the application of data-driven soft-sensing methods available. Deep learning (DL), as a novel training strategy of deep neural networks, has large potential for soft sensor modeling. In comparison with shallow neural network, because DL can make full use of massive process by greedy layer-wise training approach, deep structure of neural network has better representation and generalization ability. Compared with the traditional coke wet quenching, coke dry quenching (CDQ) has the advantage of waste heat recovery, which is advanced, energy saving and environmentally friendly, and is the main coke quenching method adopted in iron and steel plant. A deep learning-based soft-sensing method for operation optimization of coke dry quenching process is put forward in this paper. By defining the economic efficiency, the data with high economic efficiency is used for modeling and optimizing the CDQ operating variable, i.e. supplementary air flow rate (F<sub>SA</sub>). The experimental results show that, adopting the adjusted optimal operation, a remarkable raise (1.58%) of economic efficiency can be acquired on average. Thus, the presented deep learning-based soft-sensing method for operation optimization is effective and feasible for improving the waste heat recovery in CDQ system.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554805","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554805","Soft sensor;coke dry quenching (CDQ);deep learning (DL)","Biological neural networks;Boilers;Machine learning;Optimization;Poles and towers;Training","coke;distributed control;heat recovery;learning systems;neurocontrollers;process control;quenching (thermal);steel manufacture;waste heat","CDQ system;DCS;FSA;coke dry quenching process;data-driven soft-sensing methods;deep learning-based soft-sensing method;deep neural networks;distributed control system;economic efficiency;energy saving;greedy layer-wise training approach;industrial process control;iron plant;operation optimization;soft sensor modeling;steel plant;supplementary air flow rate;waste heat recovery","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"A deep spatial/spectral descriptor of hyperspectral texture using scattering transform","G. Franchi; J. Angulo","MINES ParisTech, PSL-Research University, CMM-Centre de Morphologie Math&#x00E9;matique; France","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3568","3572","A technique to describe the spatial / spectral features of hyperspectral images is introduced. These descriptors aim at representing the content of the image while considering invariances related to the texture and to its geometric transformations, so called spatial invariances. Moreover, we also consider spectral invariances which are related to the composition of the pixels. Our approach is based on the scattering transform, which provides an useful framework for deep learning classification. The goal through these descriptors is to improve pixel-wise classification of hyperspectral images.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7533024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533024","computer vision;deep learning;hyperspectral images;pixel-wise classification;wavelet transform","Hyperspectral imaging;Machine learning;Random variables;Scattering;Testing;Wavelet transforms","feature extraction;hyperspectral imaging;image classification;image representation;image texture;learning (artificial intelligence)","deep learning classification;deep spatial descriptor;hyperspectral images;hyperspectral texture;image representation;pixel-wise classification;scattering transform;spatial features;spatial invariances;spectral descriptor;spectral features","","","","19","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"FSF: Friendship and selfishness forwarding for Delay Tolerant Networks","C. Souza; E. Mota; L. Galvao; P. Manzoni; J. C. Cano; C. T. Calafate","Federal University of Amazonas, Institute of Computing, Manaus, Brazil","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","1200","1207","This paper presents the friendship and selfishness forwarding (FSF) algorithm for Delay Tolerant Networks. This novel solution is based on two social characteristics of nodes: friendship and selfishness. When a contact opportunity arises, FSF analyzes two aspects to make message forwarding decisions: first, FSF assesses the friendship strength among the pair of nodes, then it determines the individual selfishness of the relay node. Unlike other algorithms proposed in the DTN literature, we use a machine learning algorithm to quantify the friendship strength among pairs of nodes in the network. The individual selfishness of the relay node is determined by using a model based on the current level of its resources. The primary goal is to take into account the case where, despite a strong friendship with the message destination, the relay node does not accept processing the message to save its resources. By using trace-driven simulations we show that the FSF algorithm achieves better results in terms of delivery rate, average cost and efficiency.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543899","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543899","","Databases;Delays;Machine learning algorithms;Protocols;Relays;Routing","decision making;delay tolerant networks;learning (artificial intelligence);message passing;routing protocols;telecommunication computing","DTN;FSF algorithm;contact opportunity;delay tolerant networks;friendship and selfishness forwarding algorithm;friendship strength;machine learning algorithm;message destination;message forwarding decision making;relay node;social characteristics;trace-driven simulations","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Deep learning based supervised hashing for efficient image retrieval","V. A. Nguyen; M. N. Do","Advanced Digital Sciences Center (ADSC), Singapore","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Due to its storage and search efficiency, hashing has attracted great attentions in large-scale vision problems such as image retrieval and recognition. This paper presents a novel Deep Learning based Supervised Hashing (DLSH) method by using a deep neural network to better capture the semantic structure of nonlinear and complex data. We consider learning a nonlinear embedding that simultaneously preserves semantic information and produces nearby binary codes for semantically similar data. Specifically, our hashing model is trained to maximize the similarity measure of neighbor pairs while preserving the relative similarity of non-neighbor pairs with a relaxed empirical penalty in the binary space. An effective regularizer for minimizing the quantization loss between the learned embedding and the binary codes is also considered in the optimization to generate better hash code quality. Experimental results have demonstrated the proposed method outperforms the state-of-the-art methods.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552927","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552927","deep learning;image retrieval;semantic hashing","Binary codes;Hamming distance;Machine learning;Neural networks;Optimization;Quantization (signal);Semantics","computer vision;file organisation;image capture;image recognition;image retrieval;learning (artificial intelligence);minimisation;neural nets","binary codes;complex data;deep learning based supervised hashing method;deep neural network;efficient image retrieval;hash code quality;large-scale vision problems;nonlinear embedding learning;nonlinear semantic structure capture;nonneighbor pair similarity;quantization loss minimization;semantic information;semantically similar data","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Target retrieval in large-scale and high-resolution synthetic aperture radar imagery based on deep learning and multi-scale saliency","S. Tu; J. Liao; Y. Su","School of Electronic Science and Engineering, National University of Defense Technology, Changsha 410073, P.R. China","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1948","1952","Document is unavailable: This DOI was registered to an article that was not presented by the author(s) at this conference. As per section 8.2.1.B.13 of IEEE's ""Publication Services and Products Board Operations Manual,"" IEEE has chosen to exclude this article from distribution. We regret any inconvenience.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532698","SAR imagery;deep learning;large-scale;saliency detection;target retrieval","Clutter;Kernel;Machine learning;Synthetic aperture radar;Testing;Training;Two dimensional displays","","","","","","12","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Framework for Network Intrusion Detection in Cloud","M. T. Prwez; K. Chatterjee","Comput. Sci. & Eng., Nat. Inst. of Technol., Patna, Patna, India","2016 IEEE 6th International Conference on Advanced Computing (IACC)","20160818","2016","","","512","516","Due to on-demand, ubiquitous and shared resources facility, the cloud computing attract more user towards its services to use it. Cloud services are provided through the Internet, so there is possibility of attacks over the Internet. User to root, Denial of service(DoS) and Port scanning are the possible attacks over the Internet. These types of attacks are example of network intrusion. There is a need of machine learning techniques based model with high rate of detection and minimal rate of false alarm. For this, An intrusion detection model using an AdaBoost algorithm is proposed. For weak classifiers, we are using decision stumps in the algorithm. Strong classifier are built by merging the weak classifiers.","","Electronic:978-1-4673-8286-1; POD:978-1-4673-8287-8","10.1109/IACC.2016.101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544890","AdaBoost;Cloud computing;Detection rate;False alarm rate Network intrusion detection","Classification algorithms;Cloud computing;Computer crime;Genetic algorithms;Intrusion detection;Machine learning algorithms;Support vector machines","cloud computing;learning (artificial intelligence);pattern classification;security of data","AdaBoost algorithm;DoS;Internet attacks;cloud computing;cloud services;decision stumps;denial of service;false alarm rate;machine learning techniques;network intrusion detection;port scanning;shared resources facility;strong classifier;ubiquitous resources;weak classifiers","","","","","","","27-28 Feb. 2016","","IEEE","IEEE Conference Publications"
"News text classification model based on topic model","Z. Li; W. Shang; M. Yan","School of Computer Science, Communication University of China, Beijing, China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","5","In modern society, some famous news websites such as Sina and Times server to provide information every day for millions of users. But with the continuous development of information technology, the amount of disorder data is increasing. How to organize the text and make automatically text classification has become a challenge. The traditional manual classification of news text not only consumes a lot of human and financial resources, but also hardly achieved classification task quickly. In this paper, the paper mainly makes a research about the news text classification. It proposes a news text classification model based on Latent Dirichlet Allocation (LDA). Due to the dimension of the news texts is too high, this model uses topic model to make text dimension reduced and get features. At the same time, the paper also makes a research on Softmax regression algorithm to solve multi-class of text problems in our life and make it as model's classifier. The paper evaluates proposed model on a real news dataset and the result of the experiment shows the improved model performs relatively well. The model can effectively reduce the features dimension of the news text and get good classification results.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550929","softmax regression;text classification;topic model","Classification algorithms;Data models;Logistics;Machine learning algorithms;Resource management;Text categorization;Training","Web sites;pattern classification;publishing;regression analysis;text analysis","LDA;Softmax regression algorithm;automatical text classification;disorder data;latent dirichlet allocation;news Web sites;news text classification model;news texts dimension reduction;text organization;text problem multiclass solution;topic model","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"No Laughing Matter","G. Booch","","IEEE Software","20160824","2016","33","5","9","11","Computational humor is a technically intriguing problem. And, in the journey to understand the theories, mechanisms, and algorithms that discern and define funny, we learn something about ourselves and what it means to be human. The Web extra at https://youtu.be/jQV9Wj7TI8s is an audio podcast of author Grady Booch reading his column.","0740-7459;07407459","","10.1109/MS.2016.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548900","computational humor;computer science","Computer science;Human factors;Machine learning algorithms","","","","","","","","","Sept.-Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Cyber-healthcare for public healthcare in the developing world","M. Mandava; C. Lubamba; A. Ismail; A. Bagula; H. Bagula","ISAT Laboratory, Computer Science Department, University of The Western Cape (UWC), Private Bag X17, Bellville, 7535, South Africa","2016 IEEE Symposium on Computers and Communication (ISCC)","20160818","2016","","","14","19","The recent advances in sensor/actuator and RFID technologies have spun out a new healthcare model enabling capture and dissemination of patient vital signs over the Internet for ubiquitous monitoring of these patients anytime and from anywhere. This provides new opportunities for enhancing healthcare through participatory consultation, medical diagnosis and many other novel healthcare services. Some of the advantages of this emerging technology referred to in this paper as “Cyber-healthcare” includes low acquisition cost, flexible deployment and improved accuracy resulting from replacing manual operations by fully digitized processes. It is expected that the emerging healthcare technology will change the way healthcare is delivered in both rural and urban settings of the developing world by building upon this technology to leapfrog from poorly prepared to medically equipped environments capable of tackling some of the most challenging medical issues of the developing world such as patients' vital signs capture, patient prioritization and preparedness to virus outbreaks such as Ebola. This paper proposes a Cyber-healthcare system as a first step towards the implementation of least cost digital health systems in the developing countries. We assess the field readiness of the off-the-shelf sensor technology used by the system and evaluate the performance of its underlying patient prioritization module using two machine learning algorithms: 1) multivariate linear regression and 2) support vector machine.","","Electronic:978-1-5090-0679-3; POD:978-1-5090-0680-9","10.1109/ISCC.2016.7543707","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543707","Cyber-healthcare;E-health;Internet-of-Things;Patient prioritization;Situation recognition","Cloud computing;Conferences;Databases;Machine learning algorithms;Medical diagnostic imaging;Public healthcare","Internet;health care;learning (artificial intelligence);medical diagnostic computing;patient monitoring;regression analysis;support vector machines","Ebola;Internet;cyber-health care;least cost digital health systems;machine learning;medical diagnosis;multivariate linear regression;off-the-shelf sensor technology;participatory consultation;patient prioritization;patient vital signs capture;preparedness to virus outbreaks;public health care;support vector machine;ubiquitous patient monitoring","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Identification of nonlinearity in knocking vibration signals of large gas engine by deep learning","J. Z. Szabó; P. Bakucz","Institute of Mechatronics and Vehicle Engineering, Don&#x00E1;t B&#x00E1;nki Faculty of Mechanical and Safety Engineering, &#x00D3;buda University, H-1081 Budapest, N&#x00E9;psz&#x00ED;nh&#x00E1;z u. 8","2016 IEEE 20th Jubilee International Conference on Intelligent Engineering Systems (INES)","20160829","2016","","","39","44","Nonlinear knocking combustion analysis based on vibration measurements of a Deutz MWM 8 cylinder large gas engine will be presented. The knocking nonlinearity is identified by K-entropy and deep learning technique. A framework for determining the knocking nonlinearity of the vibration signals is discussed using deep belief network (DBN) of the knocking probability sequences.","","Electronic:978-1-5090-1216-9; POD:978-1-5090-1217-6; USB:978-1-5090-1215-2","10.1109/INES.2016.7555146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555146","deep learning;gas engine;knocking phenomena;nonlinearity","Combustion;Engines;Machine learning;Neural networks;Signal to noise ratio;Training;Vibrations","belief networks;combustion;entropy;internal combustion engines;learning (artificial intelligence);mechanical engineering computing;probability;signal processing;vibrations","DBN;Deutz MWM 8 cylinder large gas engine;K-entropy;deep belief network;deep learning technique;identification;knocking probability sequence;knocking vibration signals;nonlinear knocking combustion analysis;nonlinearity I;vibration measurement","","","","","","","June 30 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Word recognition with deep conditional random fields","G. Chen; Y. Li; S. N. Srihari","Department of Computer Science, SUNY at Buffalo, Buffalo NY 14260","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1928","1932","Document is unavailable: This DOI was registered to an article that was not presented by the author(s) at this conference. As per section 8.2.1.B.13 of IEEE's ""Publication Services and Products Board Operations Manual,"" IEEE has chosen to exclude this article from distribution. We regret any inconvenience.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532694","","Character recognition;Handwriting recognition;Hidden Markov models;Labeling;Linear programming;Machine learning;Neural networks","","","","1","","22","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Domain adaptation via transferring spectral properties of label functions on graphs","M. Pilancı; E. Vural","Middle East Technical University, Turkey","2016 IEEE 12th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)","20160804","2016","","","1","5","We propose a domain adaptation algorithm that relies on a graph representation of data samples in the source and target domains. The algorithm combines the information of the known class labels in the source and target domains through the Fourier coefficients of the class label function in the two graphs. The proposed method does not require an ordering or a one-to-one mapping between the samples of the source and target domains; instead, it uses only a small set of matched pairs that serve the purpose of “aligning” the source and target Fourier bases. The estimation of the coefficients of the label function in the source and target Fourier bases is then formulated as a simple convex optimization problem. The proposed domain adaptation algorithm is tested in face recognition under varying pose and illumination and is observed to provide significant improvement over reference classification approaches especially when the data distributions in the source and target domains differ significantly.","","Electronic:978-1-5090-1929-8; POD:978-1-5090-1930-4","10.1109/IVMSPW.2016.7528188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528188","Domain adaptation;data classification;graph Fourier basis;graph Laplacian","Coherence;Face;Laplace equations;Lighting;Machine learning algorithms;Manifolds;Training data","Fourier analysis;convex programming;face recognition;graph theory;image classification;image representation","Fourier coefficients;class label function;convex optimization problem;data distributions;data samples;domain adaptation algorithm;face recognition;graph representation;illumination;label function coefficient estimation;label function spectral properties transferring;pose variation;reference classification approaches;source Fourier bases;source domains;target Fourier bases;target domains","","","","","","","11-12 July 2016","","IEEE","IEEE Conference Publications"
"Gender and ethnicity classification using deep learning in heterogeneous face recognition","N. Narang; T. Bourlai","West Virginia University, MILab, LCSEE, 395 Evansdale Drive, Morgantown, 26506-6070, U.S.A.","2016 International Conference on Biometrics (ICB)","20160825","2016","","","1","8","Although automated classification of soft biometric traits in terms of gender, ethnicity and age is a well-studied problem with a history of more than three decades, it is still far from being considered a solved problem for the case of difficult exposure conditions, such as during night-time, in environments with unconstrained lighting, or at large distances from the camera. In this paper, we investigate the advantages and limitations of the automated classification of soft biometric traits in terms of gender and ethnicity in Near-Infrared (NIR) long-range, night-time face images. The impact of soft biometric traits in terms of gender and ethnicity is explored for the purpose of improving cross-spectral face recognition (FR) performance. The main contributions are, (i) a dual database collected in NIR band at night time and at four different distances of 30, 60, 90 and 120 meters is used, (ii) a deep convolution neural network to perform the classification in terms of gender and ethnicity is proposed, (iii) a set of experiments is performed indicating that, the usage of soft biometric traits to perform face matching, resulted in a significantly improved rank-1 identification rate when compared to the original biometric system (scenario dependent).","","Electronic:978-1-5090-1869-7; POD:978-1-5090-1870-3","10.1109/ICB.2016.7550082","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550082","","Convolution;Databases;Face;Face recognition;Machine learning;Testing;Training","face recognition;gender issues;image classification;image matching;infrared imaging;learning (artificial intelligence);neural nets","FR performance;NIR band;NIR long-range;automated classification;cross-spectral face recognition;deep convolution neural network;deep learning;dual database;ethnicity classification;face matching;gender;heterogeneous face recognition;near-infrared long-range images;night-time face images;rank-1 identification rate;soft biometric traits","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"The use of predictive analytics technology to detect credit card fraud in Canada","K. T. Hafiz; S. Aghili; P. Zavarsky","Department of Information Systems Security and Assurance Management, Concordia University of Edmonton, Edmonton, Canada","2016 11th Iberian Conference on Information Systems and Technologies (CISTI)","20160728","2016","","","1","6","Credit card fraud losses in Canada continue to increase despite the availability of various prevention technologies. To reduce financial loss and reputational risks, credit card companies and financial institutions in Canada have adopted fraud monitoring solutions such as Predictive Analytics Technologies (PAT) as part of fraud prevention programs to mitigate credit card fraud. This research paper focuses on the creation of a scorecard from relevant evaluation criteria, features, and capabilities of predictive analytics vendor solutions currently being used to detect credit card fraud. The scorecard provides a side-by-side comparison of five credit card predictive analytics vendor solutions adopted in Canada. From the ensuing research findings, a list of credit card fraud PAT vendor solution challenges, risks, and limitations was outlined.","","Electronic:978-9-8998-4346-2; POD:978-1-5090-1226-8","10.1109/CISTI.2016.7521522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7521522","credit card fraud;credit card fraud detection;credit card fraud red flags;predictive analytics scorecard;predictive analytics technology","Analytical models;Credit cards;Data models;Machine learning algorithms;Monitoring;Predictive models","credit transactions;data analysis;fraud;risk management;security of data","Canada;PAT;credit card companies;credit card fraud detection;credit card fraud losses;credit card fraud mitigation;financial institutions;financial loss reduction;fraud monitoring;fraud prevention technology;predictive analytics technology;reputational risk","","","","","","","15-18 June 2016","","IEEE","IEEE Conference Publications"
"Application and design of advanced algorithms in NoGo game of computer games","J. Tao; G. Wu","School of Mathematics and Computer Science, Jianghan University, Wuhan 430056","2016 Chinese Control and Decision Conference (CCDC)","20160808","2016","","","4275","4278","The Nogo game is a kind of important chess game in computer games. The Nogo game belongs to a kind of variant in go game. Its rules are to eat the pieces or the suicide of one of the pieces as the negative. Through the analysis of Nogo game model, the paper provides practical and effective algorithms for an optimization method based on the upper confidence bound tree search algorithm. During the startup processing of the computer games, the algorithms would choose the high score preference to simulate the whole game in priority, so that it could get better choices for placing the pieces. According to many experimental data and results, the provided algorithms are demonstrated to be feasible and effective in Nogo game.","","CD-ROM:978-1-4673-9713-1; Electronic:978-1-4673-9714-8; POD:978-1-4673-9715-5","10.1109/CCDC.2016.7531733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7531733","Algorithms;Computer Games;Nogo Game;UCB;UCT","Algorithm design and analysis;Computational modeling;Computers;Games;Machine learning algorithms;Monte Carlo methods;Nickel","computer games;game theory;optimisation;tree searching","Nogo game model;chess game;computer games;optimization method;upper confidence bound tree search algorithm","","","","","","","28-30 May 2016","","IEEE","IEEE Conference Publications"
"Performance evaluation of in-memory computing on scale-up and scale-out cluster","Taekyung Yoo; Minsub Yim; Ilgyun Jeong; Yunsu Lee; Seung-Tae Chun","Datastreams Corp., Korea","2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN)","20160811","2016","","","456","461","Apache Spark framework, which is the implementation of Resilient Distributed Datasets(RDD), is used instead of MapReduce on recent data processing models of Hadoop ecosystem. In this paper, we evaluated the performance and resource usage of real world workloads on scale-up and scale-out clusters using the in-memory caching feature of Spark framework. In our experiments, scale-up processed data more efficiently than scale-out in write intensive workloads such as Sort and Scan, whereas scale-out had strength in those utilizing iterative algorithms such as Join, Pagerank and KMeans. Considering the efficiency in physical factors including performance per watt and the physical space each occupies, we show that it is more advantages to use scale up cluster than scale out.","","Electronic:978-1-4673-9991-3; POD:978-1-4673-9992-0; USB:978-1-4673-9990-6","10.1109/ICUFN.2016.7537070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7537070","","Bandwidth;Benchmark testing;Data models;Hardware;Machine learning algorithms;Sparks;Web search","cache storage;iterative methods;pattern clustering;performance evaluation;sorting;storage management","Apache Spark framework;Hadoop ecosystem data processing models;Join;KMeans;Pagerank;RDD;Scan;Sort;in-memory caching feature;in-memory computing;iterative algorithms;performance evaluation;resilient distributed datasets;scale-out cluster;scale-up cluster;write intensive workloads","","","","","","","5-8 July 2016","","IEEE","IEEE Conference Publications"
"Role of voxel selection and ROI in fMRI data analysis","R. Zafar; A. S. Malik; N. Kamel; S. C. Dass","Centre for Intelligent Signal & Imaging Research (CISIR), Department of Electrical & Electronic Engineering, Universiti Teknologi PETRONAS, Perak, Malaysia","2016 IEEE International Symposium on Medical Measurements and Applications (MeMeA)","20160808","2016","","","1","6","Functional magnetic resonance imaging (fMRI) is one of the most popular and reliable modality to measure brain activities. The quality of fMRI data is best among other modalities such as Electroencephalography (EEG) and Magnetoencephalography (MEG). In fMRI, normally number of features are more than the number of instances so it is necessary to select the features and do dimension reduction to remove noisy and redundant data. Many techniques and methods are used to select the significant features (voxels). In this paper, the significant voxels are selected within the anatomical region of interest (ROI) based on the absolute values. In this study, we have predicted the brain states using two machine learning algorithm, i.e, Radial basis function (RBF) network and Naïve Bayes. A visual experiment with two categories is done. In conclusion, it is shown that less number of voxels and specific brain regions can increase the accuracy of prediction.","","Electronic:978-1-4673-9172-6; POD:978-1-4673-9173-3","10.1109/MeMeA.2016.7533739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533739","Classification;Feature selection;Generalized linear model;ROI;fMRI;voxel","Brain;Machine learning algorithms;Neurons;Statistical analysis;Support vector machines;Transmission line matrix methods;Visualization","biomedical MRI;brain;learning (artificial intelligence);medical image processing;neurophysiology;radial basis function networks","Naive Bayes;ROI;anatomical region of interest;brain states;fMRI data analysis;functional magnetic resonance imaging;machine learning algorithm;radial basis function network;redundant data;specific brain regions;voxel selection","","","","","","","15-18 May 2016","","IEEE","IEEE Conference Publications"
"A Collective Communication Layer for the Software Stack of Big Data Analytics","B. Zhang","Sch. of Inf. & Comput., Indiana Univ., Bloomington, IN, USA","2016 IEEE International Conference on Cloud Engineering Workshop (IC2EW)","20160804","2016","","","204","206","The landscape of distributed computing is rapidly evolving, with computers exhibiting increasing processing capabilities with many-core architectures. Almost every field of science is now data driven and requires analysis of massive datasets. The algorithms for analytics such as machine learning can be used to discover properties of a given dataset and make predictions based on it. However, there is still a lack of simple and unified programming frameworks for these data intensive applications, and many existing efforts are designed with specialized means to speed up individual algorithms. In this thesis research, a distributed programming model, MapCollective, is defined so that it can be easily applied to many machine learning algorithms. Specifically, algorithms that fit the iterative computation model can be easily parallelized with a unique collective communication layer for efficient synchronization. In contrast to traditional parallelization strategies that focus on handling high volume input data, a lesser known challenge is that the shared model data between parallel workers, is equally high volume in multidimensions and required to be communicated continually during the entire execution. This extends the understanding of data aspects in computation from in-memory caching of input data (e.g. iterative MapReduce model) to fine-grained synchronization on model data (e.g. MapCollective model). A library called Harp is developed as a Hadoop plugin to demonstrate that sophisticated machine learning algorithms can be simply abstracted with the MapCollective model and conveniently developed on top of the MapReduce framework. K-means and Multi-Dimensional Scaling (MDS) are tested over 4096 threads on the IU Big Red II Supercomputer. The results show linear speedup with an increasing number of parallel units.","","Electronic:978-1-5090-3684-4; POD:978-1-5090-3685-1","10.1109/IC2EW.2016.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527847","","Big data;Biological system modeling;Cloud computing;Computational modeling;Data models;Libraries;Machine learning algorithms","Big Data;cache storage;data analysis;learning (artificial intelligence);multi-threading;parallel algorithms;software libraries;synchronisation","Big Data analytics;Hadoop plugin;Harp library;IU Big Red II Supercomputer;K-means algorithm;MDS;MapCollective model;MapReduce framework;collective communication layer;data intensive applications;distributed computing;distributed programming model;fine-grained synchronization;high volume input data handling;in-memory caching;iterative computation model;machine learning algorithms;many-core architectures;multidimensional scaling;parallel workers;shared model data;software stack;unified programming frameworks","","","","","","","4-8 April 2016","","IEEE","IEEE Conference Publications"
"Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks","N. Papernot; P. McDaniel; X. Wu; S. Jha; A. Swami","Dept. of Comput. Sci. & Eng., Penn State Univ., University Park, PA, USA","2016 IEEE Symposium on Security and Privacy (SP)","20160818","2016","","","582","597","Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content filters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95% to less than 0.5% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also find that distillation increases the average minimum number of features that need to be modified to create adversarial samples by about 800% on one of the DNNs we tested.","","Electronic:978-1-5090-0824-7; POD:978-1-5090-0825-4","10.1109/SP.2016.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546524","","Automobiles;Computational modeling;Computer architecture;Machine learning;Neural networks;Security;Training","learning (artificial intelligence);neural nets;security of data","DNN;adversarial perturbations;adversarial sample creation;deep learning algorithms;deep neural networks;defensive distillation mechanism;machine learning problems;security","","1","","","","","22-26 May 2016","","IEEE","IEEE Conference Publications"
"Comparative analysis of classification algorithms on three different datasets using WEKA","R. Duriqi; V. Raca; B. Cico","University of Pristina, Department of Computer Engineering, Kosovo","2016 5th Mediterranean Conference on Embedded Computing (MECO)","20160801","2016","","","335","338","This paper analyzes the most useful and popular classification algorithms used by the Machine Learning systems, particularly in the artificial intelligent systems. It is focused on the practical applying of classification algorithms, in all three different dataset used throughout this paper. The results of the paper show which algorithm is more convenient for a particular dataset. The common analysis of these datasets including classification algorithms is implemented on the WEKA Tool.","","CD-ROM:978-1-5090-2220-5; Electronic:978-1-5090-2222-9; POD:978-1-5090-2223-6","10.1109/MECO.2016.7525775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7525775","Algorithms;Analysis;Classification;Dataset;Weka","Algorithm design and analysis;Classification algorithms;Computers;Diabetes;Machine learning algorithms;Testing;Training","data mining;learning (artificial intelligence);pattern classification","WEKA tool;artificial intelligent system;classification algorithm;machine learning","","","","","","","12-16 June 2016","","IEEE","IEEE Conference Publications"
"Fine-grained LFW database","Nanhai Zhang; Weihong Deng","Beijing University of Posts and Telecommunications, China","2016 International Conference on Biometrics (ICB)","20160825","2016","","","1","6","Current deep learning methods have achieved human-level performance on Labeled Faces in the Wild (LFW) database, but we think it is because that the limited number of pairs on LFW do not capture the real difficulty of large-scale unconstrained face verification problem. Besides the intra-class variations like pose, illumination, occlusion and expression, highly visually similarity of different persons' faces is an another challenge. It is unavoidable in large dataset and many researchers ignore it. Therefore, in this paper, we firstly select some visually similar pairs in LFW database by combining the deep learning method and human annotation results. Preserving the matched pairs and replacing the mismatched pairs of LFW with the selected similar pairs, we obtain the Fine-grained LFW (FGLFW) database which can better reflect the real difficulty of face verification. Experimental results show that methods achieving not bad performance on LFW drops more than 11% even 25% on FGLFW. It reflects that visually similar pairs are difficult to current methods and our FGLFW database is a quite challenging database. Researchers still have a long way to go for solving face verification problem on such a database.","","Electronic:978-1-5090-1869-7; POD:978-1-5090-1870-3","10.1109/ICB.2016.7550057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550057","","Databases;Face recognition;Lighting;Machine learning;Measurement;Protocols;Training","face recognition;learning (artificial intelligence);visual databases","FGLFW database;Labeled Faces in the Wild database;deep learning;face visual similarity;fine-grained LFW database;human annotation;intraclass variations;large-scale unconstrained face verification problem","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Hybrid Deep Learning for Face Verification","Y. Sun; X. Wang; X. Tang","Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","20160901","2016","38","10","1997","2009","This paper proposes a hybrid convolutional network (ConvNet)-Restricted Boltzmann Machine (RBM) model for face verification. A key contribution of this work is to learn high-level relational visual features with rich identity similarity information. The deep ConvNets in our model start by extracting local relational visual features from two face images in comparison, which are further processed through multiple layers to extract high-level and global relational features. To keep enough discriminative information, we use the last hidden layer neuron activations of the ConvNet as features for face verification instead of those of the output layer. To characterize face similarities from different aspects, we concatenate the features extracted from different face region pairs by different deep ConvNets. The resulting high-dimensional relational features are classified by an RBM for face verification. After pre-training each ConvNet and the RBM separately, the entire hybrid network is jointly optimized to further improve the accuracy. Various aspects of the ConvNet structures, relational features, and face verification classifiers are investigated. Our model achieves the state-of-the-art face verification performance on the challenging LFW dataset under both the unrestricted protocol and the setting when outside data is allowed to be used for training.","0162-8828;01628828","","10.1109/TPAMI.2015.2505293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346495","Convolutional networks;deep learning;face recognition","Computational modeling;Data models;Face;Face recognition;Feature extraction;Machine learning;Sun","","","","1","","","","20151203","Oct. 1 2016","","IEEE","IEEE Journals & Magazines"
"Potential of radar for static object classification using deep learning methods","J. Lombacher; M. Hahn; J. Dickmann; C. Wöhler","Daimler AG, Wilhelm-Runge-Str. 11, 89081 Ulm, Germany","2016 IEEE MTT-S International Conference on Microwaves for Intelligent Mobility (ICMIM)","20160808","2016","","","1","4","A semantic representation of the environment is extremely beneficial in enabling autonomous driving. The objects in the vehicle's surroundings must be recognized and assigned to a proper class. Redundancy is often required for safety-relevant application. This cannot be provided by a single sensor system. This study now demonstrates the potential of radar-based object recognition using deep learning methods.","","Electronic:978-1-5090-2367-7; POD:978-1-5090-2368-4","10.1109/ICMIM.2016.7533931","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533931","","Automobiles;Buildings;Doppler radar;Machine learning;Radar imaging","image classification;learning (artificial intelligence);object recognition;radar computing;radar imaging","autonomous driving;deep learning methods;image-based object recognition;radar-based object recognition;safety-relevant application;semantic representation;static object classification","","","","","","","19-20 May 2016","","IEEE","IEEE Conference Publications"
"clCaffe: OpenCL Accelerated Caffe for Convolutional Neural Networks","J. Bottleson; S. Kim; J. Andrews; P. Bindu; D. N. Murthy; J. Jin","Intel Corp., Folsom, CA, USA","2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","20160804","2016","","","50","57","Recent advances in deep convolutional neural networks enable researchers and developers to apply machine learning to a much broader number of applications. With the proliferation of deep learning applications, widely used deep learning frameworks, such as Caffe, Theano and Torch, have been significantly improved with the support of powerful GPUs and GPU-accelerated libraries. However, lack of frameworks and libraries built on OpenCL could hinder exploration of more diverse compute devices (CPUs, GPUs, DSPs and FPGAs) in future deep learning domains. In this work, we present OpenCL acceleration of a well-known deep learning framework, Caffe, while focusing on the convolution layer which has been optimized with three different approaches, GEMM, spatial domain, and frequency domain. Our work, clCaffe, greatly enhances the ability to leverage deep learning use cases on all types of OpenCL devices, particularly on small form factor devices in which discrete GPUs are rare and integrated GPUs are much more common. Our benchmark shows 2.5× speedup on the Intel integrated-GPU, compared to CPU-only AlexNet on ImageNet dataset. As such, our work provides the deep learning community with the opportunity to embrace a broad range of devices through OpenCL.","","Electronic:978-1-5090-3682-0; POD:978-1-5090-3683-7","10.1109/IPDPSW.2016.182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529850","Caffe;Convolutional Neural Networks;Deep learning framework;Integrated GPU;OpenCL","Acceleration;Computational modeling;Convolution;Frequency-domain analysis;Kernel;Libraries;Machine learning","graphics processing units;image filtering;learning (artificial intelligence);neural nets","CPU-only AlexNet;GEMM;GPU-accelerated libraries;ImageNet dataset;Intel integrated-GPU;OpenCL;clCaffe;convolutional neural networks;deep learning community;discrete GPU;frequency domain;machine learning;spatial domain","","","","","","","23-27 May 2016","","IEEE","IEEE Conference Publications"
"Learning deep filter banks in parallel for texture recognition","A. Shahriari","The Australian National University (ANU) & The Commonwealth Scientific and Industrial Research Organisation (CSIRO), Locked Bag 8001 Canberra ACT 2601 Australia","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","1634","1638","Texture is an important visual clue for various classification and segmentation tasks in the scene understanding challenge. Today, successful deployment of deep learning algorithms for texture recognition leads to tremendous precisions on standard datasets. In this paper, we propose a new learning framework to train deep neural networks in parallel and with variable depth for texture recognition. Our framework learns scales, orientations and resolutions of texture filter banks. Due to the learning of parameters not the filters themselves, computational costs are highly reduced. It is also capable of extracting very deep features through distributed computing architectures. Our experiments on publicly available texture datasets show significant improvements in the recognition performance over other deep local descriptors in recently published benchmarks.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532635","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532635","Deep Learning;Texture Recognition","Feature extraction;Image color analysis;Machine learning;Neural networks;Neurons;Optimization;Standards","channel bank filters;feature extraction;image texture;learning (artificial intelligence);neural nets","classification tasks;deep learning algorithms;deep neural networks;feature extraction;parallel deep filter banks;segmentation tasks;texture filter banks;texture recognition","","","","23","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Chinese text categorization based on deep belief networks","J. Song; S. Qin; P. Zhang","The Faculty of Science and Technology Communication, University of China, Beijing, China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","5","With the rapid development of Internet, text categorization becomes a mission-critical technology that organizes and processes large amounts of data in document. Deep belief networks have powerful abilities of learning and can extract highly distinguishable features from the high-dimensional original feature space. So a new Chinese text categorization algorithm based on deep learning structure and semi-supervised deep belief networks is presented in this paper. We extract original feature with TFIDF-ICF, construct the text classification model based on DBN, and select the number of hidden layers and hidden units. Our experimental results indicated that the performance of text categorization algorithm based on deep belief networks is better than support vector machine.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550914","deep belief networks;restricted boltzmann machine;text categorization","Classification algorithms;Feature extraction;Machine learning;Neural networks;Support vector machines;Text categorization;Training","Internet;belief networks;feature extraction;learning (artificial intelligence);support vector machines;text analysis","Chinese text categorization;Internet;deep learning structure;feature extraction;mission-critical technology;semi-supervised deep belief networks;support vector machine","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Stacked Sparse Autoencoder in PolSAR Data Classification Using Local Spatial Information","L. Zhang; W. Ma; D. Zhang","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi&#x0027;an, China","IEEE Geoscience and Remote Sensing Letters","20160805","2016","13","9","1359","1363","Terrain classification is an important topic in polarimetric synthetic aperture radar (PolSAR) image processing. Among various classification techniques, the stacked sparse autoencoder (SSAE) is a kind of deep learning method that can automatically learn useful features layer by layer in an unsupervised manner. However, the scattering measurements of individual pixels in PolSAR images are affected by the speckle; hence, the performance of pixel-based classification approaches would be poor. In this situation, a novel framework is proposed to learn robust features of PolSAR data. The local spatial information is introduced into SSAE to learn the deep spatial sparse features automatically for the first time. Furthermore, the influences of the neighbor pixels on the central pixel are controlled depending on the spatial distances from the neighbor pixels to the central pixel. Experimental results with fully PolSAR data indicate that the proposed method provides a competitive solution.","1545-598X;1545598X","","10.1109/LGRS.2016.2586109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518668","Deep learning;image classification;local spatial information;polarimetric synthetic aperture radar (PolSAR);sparse;stacked sparse autoencoder (SSAE)","Cost function;Data mining;Feature extraction;Machine learning;Scattering;Speckle;Training","geophysical image processing;image classification;remote sensing by radar;synthetic aperture radar;terrain mapping","PolSAR data classification;PolSAR image processing;PolSAR images;classification techniques;local spatial information;pixel-based classification;polarimetric synthetic aperture radar;stacked sparse autoencoder;terrain classification","","1","","","","20160721","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Deep Learning Guided Partitioned Shape Model for Anterior Visual Pathway Segmentation","A. Mansoor; J. J. Cerrolaza; R. Idrees; E. Biggs; M. A. Alsharid; R. A. Avery; M. G. Linguraru","Children's National Health System, Washington","IEEE Transactions on Medical Imaging","20160729","2016","35","8","1856","1865","Analysis of cranial nerve systems, such as the anterior visual pathway (AVP), from MRI sequences is challenging due to their thin long architecture, structural variations along the path, and low contrast with adjacent anatomic structures. Segmentation of a pathologic AVP (e.g., with low-grade gliomas) poses additional challenges. In this work, we propose a fully automated partitioned shape model segmentation mechanism for AVP steered by multiple MRI sequences and deep learning features. Employing deep learning feature representation, this framework presents a joint partitioned statistical shape model able to deal with healthy and pathological AVP. The deep learning assistance is particularly useful in the poor contrast regions, such as optic tracts and pathological areas. Our main contributions are: 1) a fast and robust shape localization method using conditional space deep learning, 2) a volumetric multiscale curvelet transform-based intensity normalization method for robust statistical model, and 3) optimally partitioned statistical shape and appearance models based on regional shape variations for greater local flexibility. Our method was evaluated on MRI sequences obtained from 165 pediatric subjects. A mean Dice similarity coefficient of 0.779 was obtained for the segmentation of the entire AVP (optic nerve only =0.791) using the leave-one-out validation. Results demonstrated that the proposed localized shape and sparse appearance-based learning approach significantly outperforms current state-of-the-art segmentation approaches and is as robust as the manual segmentation.","0278-0062;02780062","","10.1109/TMI.2016.2535222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420737","Anterior visual pathway;MRI;intensity normalization;partitioned statistical model;shape model;sparse learning","Biomedical optical imaging;Machine learning;Magnetic resonance imaging;Optical imaging;Pathology;Robustness;Shape","biomedical MRI;curvelet transforms;eye;image segmentation;image sequences;medical image processing;paediatrics;statistical analysis","Dice similarity coefficient;MRI sequences;anatomic structures;anterior visual pathway segmentation;conditional space deep learning;cranial nerve systems;deep learning feature representation;deep learning guided partitioned shape model;joint partitioned statistical shape model;low-grade gliomas;optic nerve;pathologic AVP segmentation;pediatric subjects;robust statistical model;shape localization method;sparse appearance-based learning approach;volumetric multiscale curvelet transform-based intensity normalization method","","1","","","","20160226","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Local binary pattern network: A deep learning approach for face recognition","M. Xi; L. Chen; D. Polajnar; W. Tong","Department of Computer Science, University of Northern British Columbia, Canada","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3224","3228","Deep learning is well known as a method to extract hierarchical representations of data. In this paper a novel unsupervised deep learning based methodology, named Local Binary Pattern Network (LBPNet), is proposed to efficiently extract and compare high-level over-complete features in multilayer hierarchy. The LBPNet retains the same topology of Convolutional Neural Network (CNN) - one of the most well studied deep learning architectures - whereas the trainable kernels are replaced by the off-the-shelf computer vision descriptor (i.e., LBP). This enables the LBPNet to achieve a high recognition accuracy without requiring any costly model learning approach on massive data. Through extensive numerical experiments using the public benchmarks (i.e., FERET and LFW), LBPNet has shown that it is comparable to other unsupervised methods.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532955","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532955","Convolutional Neural Network;Deep learning;Local Binary Pattern;PCA","Computer architecture;Face;Face recognition;Feature extraction;Kernel;Machine learning;Principal component analysis","computer vision;face recognition;feature extraction;feedforward neural nets;unsupervised learning","CNN;LBPNet;computer vision descriptor;convolutional neural network;face recognition;hierarchical data representations;high-level over-complete feature extraction;local binary pattern network;multilayer hierarchy;unsupervised deep learning","","","","24","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Towards a Twitter observatory: A multi-paradigm framework for collecting, storing and analysing tweets","I. Basaille; S. Kirgizov; É. Leclercq; M. Savonnet; N. Cullot","Laboratoire LE2I - UMR6306 - CNRS - ENSAM, Univ. Bourgogne Franche-Comt&#x00E9;, 9, Avenue Alain Savary, F-21078 Dijon - France","2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)","20160825","2016","","","1","10","In this article we show how a multi-paradigm framework can fulfil the requirements of tweets analysis and reduce the waiting time for researchers that use computational resources and storage systems to support large-scale data analysis. The originality of our approach is to combine concerns about data harvesting, data storage, data analysis and data visualisation into a framework that supports inductive reasoning in multidisciplinary scientific research. Our main contribution is a polyglot storage system with a generic data model to support logical data independence and a set of tools that can provide a suitable solution for mixing different types of algorithms in order to maximise the extraction of knowledge. We describe the software architecture of our framework, the generic model and we show how it has been used in major projects and what characteristics have been validated.","","Electronic:978-1-4799-8710-8; POD:978-1-4799-8711-5","10.1109/RCIS.2016.7549324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549324","Twitter analysis;knowledge discovery;massive datasets;open source software;polyglot storage","Algorithm design and analysis;Data models;Databases;Machine learning algorithms;Multiplexing;Tensile stress;Twitter","data analysis;data mining;data visualisation;inference mechanisms;social networking (online);software architecture","Twitter observatory;data analysis;data harvesting;data storage;data visualisation;inductive reasoning;knowledge discovery;knowledge extraction;logical data independence;multidisciplinary scientific research;multiparadigm framework;polyglot storage system;software architecture;tweets analysis","","","","","","","1-3 June 2016","","IEEE","IEEE Conference Publications"
"Evaluating Embedded FPGA Accelerators for Deep Learning Applications","G. Hegde; Siddhartha; N. Ramasamy; V. Buddha; N. Kapre","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)","20160818","2016","","","25","25","FPGA-based embedded soft vector processors can exceed the performance and energy-efficiency of embedded GPUs and DSPs for lightweight deep learning applications. For low complexity deep neural networks targeting resource constrained platforms, we develop optimized Caffe-compatible deep learning library routines that target a range of embedded accelerator-based systems between 4 -- 8 W power budgets such as the Xilinx Zedboard (with MXP soft vector processor), NVIDIA Jetson TK1 (GPU), InForce 6410 (DSP), TI EVM5432 (DSP) as well as the Adapteva Parallella board (custom multi-core with NoC). For MNIST (28×28 images) and CIFAR10 (32×32 images), the deep layer structure is amenable to MXP-enhanced FPGA mappings to deliver 1.4 -- 5× higher energy efficiency than all other platforms. Not surprisingly, embedded GPU works better for complex networks with large image resolutions.","","Electronic:978-1-5090-2356-1; POD:978-1-5090-2357-8","10.1109/FCCM.2016.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544737","","Acceleration;Digital signal processing;Field programmable gate arrays;Graphics processing units;Libraries;Machine learning;Vector processors","embedded systems;energy conservation;field programmable gate arrays;learning (artificial intelligence);neural nets;vectors","Adapteva Parallella board;CIFAR10;Caffe-compatible deep learning library;DSP;GPU;InForce 6410;MNIST;NVIDIA Jetson TK1;Xilinx Zedboard;deep neural networks;embedded FPGA accelerators;embedded soft vector processors;energy-efficiency;lightweight deep learning applications","","","","","","","1-3 May 2016","","IEEE","IEEE Conference Publications"
"A classification model for Portuguese documents in the juridical domain","L. Pinto; A. Melgar","Facultad de Ciencias e Ingenier&#237;a, Especialidad de Ingenier&#237;a Inform&#225;tica, Grupo de Investigaci&#243;n en Reconocimiento de Patrones e Inteligencia Artificial Aplicada, Pontificia Universidad Cat&#243;lica del Per&#250; Lima, Per&#250;","2016 11th Iberian Conference on Information Systems and Technologies (CISTI)","20160728","2016","","","1","4","The attorney's office in Brazil, receive daily a lot of notifications. These notifications must be manually analyzed by procurators to determine what kind of document should they prepare to respond. This situation causes in many cases notifications are not answered in time causing these prescribed. All this has motivated the development of this work whose main objective is the development of a computational model to understand the meaning of each notification and indicate what kind of response should be prepared for every situation. For the construction of this model, machine-learning algorithms are used. The problem is modeled as one of classification using free text documents. The texts were extracted from notification documents, which were written in Portuguese. The method to assess the performance of the algorithms was the area under the curve. During the experiment, four algorithms were evaluated, including k-Nearest Neighbor, Support Vector Machine, Naive Bayes and Complement Naive Bayes. The algorithms were trained using a collection of Portuguese documents in the juridical domain, which includes 5471 documents divided into 8 categories. A 25-fold cross validation method was used to measure the unbiased estimate of these prediction models. This paper is a comparative study of machine learning algorithms for the problem of categorization of notifications. As a result of this study, an algorithm model was constructed in order to classify the documents in the corresponding class. The area under the curve value of Support Vector Machine, k-Nearest Neighbor, Naive Bayes and Complement Naive Bayes was 0.846, 0.831, 0.815 and 0.712 respectively. Our study shows that out of these four classification models Support Vector Machine predicts with highest area under the curve value.","","Electronic:978-9-8998-4346-2; POD:978-1-5090-1226-8","10.1109/CISTI.2016.7521594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7521594","classification model;k-nearest;naïve bayes;support vector machine;text categorization Portuguese documents","Classification algorithms;Machine learning algorithms;Prediction algorithms;Support vector machines;Text categorization;Training","Bayes methods;government data processing;law administration;learning (artificial intelligence);pattern classification;support vector machines","Brazil;Portuguese documents;attorney office;complement Naive Bayes;computational model development;document classification;juridical domain;k-nearest neighbor;machine learning algorithms;notification categorization problem;prediction models;support vector machine;text documents;text extraction","","","","","","","15-18 June 2016","","IEEE","IEEE Conference Publications"
"High-level verification of multi-object segmentation","M. Lukac; A. Zhurtanov; A. Ospanova","Department of Computer Science, Nazarbayev University, Astana, Kazakhstan","2016 International Conference on Information and Digital Technologies (IDT)","20160901","2016","","","173","179","In this paper we present a relational analysis and verification of multi-labeled images as a result fo semantic segmentation. In semantic segmentation the result is a set of labeled regions but rarely this result is subject to verification that would allow to determine induce the reliability of this segmentation. We show that using shape measure, co-occurrence statistics and specially crafted weighted function we can estimate the correctness of a semantic segmentation up to 92%.","","Electronic:978-1-4673-8861-0; POD:978-1-4673-8862-7; USB:978-1-4673-8860-3","10.1109/DT.2016.7557169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557169","","Feature extraction;Histograms;Image segmentation;Machine learning algorithms;Semantics;Shape;Support vector machines","image segmentation;reliability;statistical analysis","co-occurrence statistics;crafted weighted function;high-level verification;multilabeled image verification;multiobject segmentation;relational analysis;reliability;semantic segmentation;shape measure","","","","","","","5-7 July 2016","","IEEE","IEEE Conference Publications"
"Deep learning neural network for power system fault diagnosis","Y. Wang; M. Liu; Z. Bao","State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou 310027, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","6678","6683","This paper deals with application of deep learning neural network for power system fault diagnosis. Deep learning is a more effective approach than traditional neural network to solve problems including availability of data, better local optimum, and diffusion of gradients. In the paper, data is extracted from power system dispatching department and preprocessed before training in the deep learning network. Then, processed data is put into auto-encoders and the hidden features are observed in different dimensions so that we can preliminarily judge about the fault. Afterwards, trained stacked auto-encoders (SAE) is used to initialize and train a deep learning neural network (DLNN). The hidden features are observed in different dimensions so that the fault is preliminarily judged. The classifier is the last part of the network to reflect the types and possibility of diagnosis. The method of data availability, preprocess, and modeling is proposed in the paper. The result of simulation proves the feasibility of the approach and the influence factors are shown in the paper.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554408","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554408","Deep Learning;Fault Diagnosis;Neural Network;Power System;Stacked Auto-Encoders","Biological neural networks;Feature extraction;Machine learning;Power system faults;Training","fault diagnosis;neural nets;pattern classification;power engineering computing;power system faults","DLNN;SAE;classifier;data availability;data modeling;data preprocessing;deep learning neural network;power system dispatching department;power system fault diagnosis;stacked auto-encoders","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Recurrent convolutional neural network for video classification","Z. Xu; J. Hu; W. Deng","Beijing University of Posts and Telecommunications, No. 10, Xitu Cheng Road, Haidian District, Beijing, China, 100876","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Video classification is more difficult than image classification since additional motion feature between image frames and amount of redundancy in videos should be taken into account. In this work, we proposed a new deep learning architecture called recurrent convolutional neural network (RCNN) which combines convolution operation and recurrent links for video classification tasks. Our architecture can extract the local and dense features from image frames as well as learning the temporal features between consecutive frames. We also explore the effectiveness of sequential sampling and random sampling when training our models, and find out that random sampling is necessary for video classification. The feature maps from our learned model preserve motion from image frames, which is analogous to the persistence of vision in human visual system. We achieved 81.0% classification accuracy without optical flow and 86.3% with optical flow on the UCF-101 dataset, both are competitive to the state-of-the-art methods.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552971","action recognition;deep learning;recurrent convolutional neural network;video classification","Computer architecture;Convolution;Machine learning;Neural networks;Optical imaging;Redundancy;Training","convolution;feature extraction;image classification;image motion analysis;image sequences;learning (artificial intelligence);recurrent neural nets;sampling methods;video signal processing","RCNN;UCF-101 dataset;convolution operation;deep learning architecture;human visual system;image classification;image frames;motion feature;motion preservation;optical flow;random sampling;recurrent convolutional neural network;recurrent links;sequential sampling;temporal features;video classification;video redundancy","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Automatic detection of books based on Faster R-CNN","Beibei Zhu; Xiaoyu Wu; Lei Yang; Yinghua Shen; Linglin Wu","School of Information Engineering, Communication University of China, Beijing, China","2016 Third International Conference on Digital Information Processing, Data Mining, and Wireless Communications (DIPDMWC)","20160804","2016","","","8","12","Advances have been made continuously in detection networks such as SPPnet and Fast R-CNN. Recently the novel region proposal method RPN shares full-image convolutional features with the detection network and enables a state-of-the-art object detection network Faster R-CNN. In this work we apply Faster R-CNN to train a detection network on our digital image database of books and implement automatic recognition and positioning of books. Experiments show that retrained Faster R-CNN achieves fine detection results in terms of both speed and accuracy, and it also solves the problem of testing negative examples in our previous study. This provides great help for the study of practical book retrieval system.","","CD-ROM:978-1-4673-9378-2; Electronic:978-1-4673-9379-9; POD:978-1-4673-9380-5","10.1109/DIPDMWC.2016.7529355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529355","Faster R-CNN;deep learning;detection of books;object detection","Databases;Feature extraction;MATLAB;Machine learning;Object detection;Proposals;Training","document image processing;feature extraction;image retrieval;learning (artificial intelligence);neural nets;object detection;visual databases","RPN;automatic book detection;automatic book positioning;automatic book recognition;book retrieval system;detection network training;digital image database;faster R-CNN;full-image convolutional features;object detection network;region proposal method;region-based convolutional neural networks","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"A fingerprinting indoor localization algorithm based deep learning","G. Félix; M. Siller; E. N. Álvarez","Electrical Engineering and Computer Science Department, CINVESTAV Unidad Jalisco, Zapopan, M&#x00E9;xico","2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN)","20160811","2016","","","1006","1011","Fingerprinting in essence uses a machine to infer physicals locations from radio map data. This machines are usually either probabilistic and neural networks consisting of one layer. In this propose we use deeper machines (DNN, DBN and GB-DBN) to increase the estimation accuracy and reduce generalization error on dynamic indoor environment. Also we investigated the impact of pre-training algorithm on fingerprinting indoor location systems. Experimental results demonstrate that deep models provide an efficient generalization performance on indoor environments. They have the disadvantage that demand high processing resources when they are trained on off-line phase, however, deep models are swift to predict during on-line phase.","","Electronic:978-1-4673-9991-3; POD:978-1-4673-9992-0; USB:978-1-4673-9990-6","10.1109/ICUFN.2016.7536949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536949","Neural networks;Wireless LAN;deep learning;fingerprinting localization;indoor location;location based service","Biological neural networks;Computer architecture;Fingerprint recognition;Heuristic algorithms;Machine learning;Servers;Training","indoor navigation;neural nets;radionavigation;telecommunication computing","DNN;GB-DBN;deep learning;deep model;dynamic indoor environment;fingerprinting indoor localization algorithm;generalization error reduction;neural networks;pre-training algorithm;probabilistic networks;radio map data","","1","","","","","5-8 July 2016","","IEEE","IEEE Conference Publications"
"Active learning for community detection in stochastic block models","A. Gadde; E. E. Gad; S. Avestimehr; A. Ortega","University of Southern California, Los Angeles, USA","2016 IEEE International Symposium on Information Theory (ISIT)","20160811","2016","","","1889","1893","The stochastic block model (SBM) is an important generative model for random graphs in network science and machine learning, useful for benchmarking community detection (or clustering) algorithms. The symmetric SBM generates a graph with 2n nodes which cluster into two equally sized communities. Nodes connect with probability p within a community and q across different communities. We consider the case of p = a ln(n)/n and q = b ln(n)/n. In this case, it was recently shown that recovering the community membership (or label) of every node with high probability (w.h.p.) using only the graph is possible if and only if the Chernoff-Hellinger (CH) divergence D(a; b) = (√a - √a)<sup>2</sup> ≥ 1. In this work, we study if, and by how much, community detection below the clustering threshold (i.e. D(a; b) <; 1) is possible by querying the labels of a limited number of chosen nodes (i.e., active learning). Our main result is to show that, under certain conditions, sampling the labels of a vanishingly small fraction of nodes (a number sub-linear in n) is sufficient for exact community detection even when D(a; b) <; 1. Furthermore, we provide an efficient learning algorithm which recovers the community memberships of all nodes w.h.p. as long as the number of sampled points meets the sufficient condition. We also show that recovery is not possible if the number of observed labels is less than n<sup>1-D(a;b)</sup>. The validity of our results is demonstrated through numerical experiments.","","Electronic:978-1-5090-1806-2; POD:978-1-5090-1807-9","10.1109/ISIT.2016.7541627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7541627","","Benchmark testing;Clustering algorithms;Information theory;Labeling;Machine learning algorithms;Prediction algorithms;Stochastic processes","graph theory;learning (artificial intelligence);pattern clustering;probability;query processing;random processes;stochastic processes","CH divergence;Chernoff-Hellinger divergence;active learning;clustering threshold;community detection;community membership;community memberships;graph nodes;label querying;probability;random graphs;stochastic block model;sufficient condition;symmetric SBM","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Localization of LTE measurement records with missing information","A. Ray; S. Deb; P. Monogioudis","University of Texas at Austin Austin, TX, USA","IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications","20160728","2016","","","1","9","As cellular networks like 4G LTE networks get more and more sophisticated, mobiles also measure and send enormous amount of mobile measurement data (in TBs/week/metropolitan) during every call and session. The mobile measurement records are saved in data center for further analysis and mining, however, these measurement records are not geo-tagged because the measurement procedures are implemented in mobile LTE stack. Geo-tagging (or localizing) the stored measurement record is a fundamental building block towards network analytics and troubleshooting since the measurement records contain rich information on call quality, latency, throughput, signal quality, error codes etc. In this work, our goal is to localize these mobile measurement records. Precisely, we answer the following question: what was the location of the mobile when it sent a given measurement record? We design and implement novel machine learning based algorithms to infer whether a mobile was outdoor and if so, it infers the latitude-longitude associated with the measurement record. The key technical challenge comes from the fact that measurement records do not contain sufficient information required for triangulation or RF fingerprinting based techniques to work by themselves. Experiments performed with real data sets from an operational 4G network in a major metropolitan show that, the median accuracy of our proposed solution is around 20 m for outdoor mobiles and outdoor classification accuracy is more than 98%.","","Electronic:978-1-4673-9953-1; POD:978-1-4673-9954-8","10.1109/INFOCOM.2016.7524370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7524370","","Machine learning algorithms;Mobile communication;Mobile computing;Radio frequency;Radio transmitters;Robots;Velocity measurement","4G mobile communication;Long Term Evolution;learning (artificial intelligence);mobile computing;records management","4G LTE networks;cellular networks;data center;geo-tagging;machine learning based algorithms;mobile LTE stack;mobile measurement data;mobile measurement records;operational 4G network;outdoor mobiles","","","","","","","10-14 April 2016","","IEEE","IEEE Conference Publications"
