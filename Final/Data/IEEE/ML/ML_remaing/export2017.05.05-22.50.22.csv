"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6001789,6001632,6004393,6001094,5997428,6001186,5997661,5995332,5995413,5995830,5995487,5993703,5995657,5607316,5985890,5989059,5992413,5990948,5990134,5984084,5982307,5982259,5977714,5978793,5976502,5975051,5976909,5972376,5974129,5974891,5976522,5972181,5976521,5976526,5974605,5970609,5968918,5968630,5968490,5968282,5970357,5968653,5962736,5967363,5719548,5967680,5967358,5967816,5967681,5962092,5967348,5967676,5961231,5961317,5960991,5960053,5958896,5958118,5957392,5949916,5949764,5954524,5954773,5952571,5954646,5952067,5949750,5949283,5946520,5949301,5949296,5948469,5946733,5949391,5947214,5946119,5946762,5928709,5946734,5928708,5946064,5948806,5949288,5946917,5946926,5946163,5946929,5948603,5941988,5941782,5942028,5941710,5941667,5934969,5929185,5929581,5929844,5910567,5920956,5929620",2017/05/05 22:50:22
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Using the kernel trick in compressive sensing: Accurate signal recovery from fewer measurements","H. Qi; S. Hughes","Department of Electrical, Computer, and Energy Engineering, University of Colorado at Boulder, USA","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","3940","3943","Compressive sensing accurately reconstructs a signal that is sparse in some basis from measurements, generally consisting of the signal's inner products with Gaussian random vectors. The number of measurements needed is based on the sparsity of the signal, allowing for signal recovery from far fewer measurements than is required by the traditional Shannon sampling theorem. In this paper, we show how to apply the kernel trick, popular in machine learning, to adapt compressive sensing to a different type of sparsity. We consider a signal to be “nonlinearly K-sparse” if the signal can be recovered as a nonlinear function of K underlying parameters. Images that lie along a low-dimensional manifold are good examples of this type of nonlinear sparsity. It has been shown that natural images are as well [1]. We show how to accurately recover these nonlinearly K-sparse signals from approximately 2K measurements, which is often far lower than the number of measurements usually required under the assumption of sparsity in an orthonormal basis (e.g. wavelets). In experimental results, we find that we can recover images far better for small numbers of compressive sensing measurements, sometimes reducing the mean square error (MSE) of the recovered image by an order of magnitude or more, with little computation. A bound on the error of our recovered signal is also proved.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5947214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5947214","Compressive sensing;Kernel methods","Approximation methods;Compressed sensing;Image reconstruction;Kernel;Machine learning algorithms;Principal component analysis;Support vector machines","","","","14","","7","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Data clustering with modified K-means algorithm","R. V. Singh; M. P. S. Bhatia","Department of Computer Science and Engineering, Netaji Subhash Institute of Technology, University Of Delhi, New Delhi, India","2011 International Conference on Recent Trends in Information Technology (ICRTIT)","20110804","2011","","","717","721","This paper presents a data clustering approach using modified K-Means algorithm based on the improvement of the sensitivity of initial center (seed point) of clusters. This algorithm partitions the whole space into different segments and calculates the frequency of data point in each segment. The segment which shows maximum frequency of data point will have the maximum probability to contain the centroid of cluster. The number of cluster's centroid (k) will be provided by the user in the same manner like the traditional K-mean algorithm and the number of division will be k*k (`k' vertically as well as `k' horizontally). If the highest frequency of data point is same in different segments and the upper bound of segment crosses the threshold `k' then merging of different segments become mandatory and then take the highest k segment for calculating the initial centroid (seed point) of clusters. In this paper we also define a threshold distance for each cluster's centroid to compare the distance between data point and cluster's centroid with this threshold distance through which we can minimize the computational effort during calculation of distance between data point and cluster's centroid. It is shown that how the modified k-mean algorithm will decrease the complexity & the effort of numerical calculation, maintaining the easiness of implementing the k-mean algorithm. It assigns the data point to their appropriate class or cluster more effectively.","","Electronic:978-1-4577-0590-8; POD:978-1-4577-0588-5","10.1109/ICRTIT.2011.5972376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5972376","Data Clustering;K-Means","Algorithm design and analysis;Clustering algorithms;Data mining;Equations;Machine learning algorithms;Mathematical model;Partitioning algorithms","data mining;pattern clustering;probability","cluster centroid;computational effort;data clustering;data point frequency;modified K-mean algorithm;numerical calculation;probability;threshold distance","","14","","11","","","3-5 June 2011","","IEEE","IEEE Conference Publications"
"A cooperative coevolution-based pittsburgh learning classifier system embedded with memetic feature selection","Y. Wen; H. Xu","State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China","2011 IEEE Congress of Evolutionary Computation (CEC)","20110714","2011","","","2415","2422","Given that real-world classification tasks always have irrelevant or noisy features which degrade both prediction accuracy and computational efficiency, feature selection is an effective data reduction technique showing promising performance. This paper presents a cooperative coevolution framework to make the feature selection process embedded into the classification model construction within the genetic-based machine learning paradigm. The proposed approach utilizes the divide-and-conquer strategy to manage two populations in parallel, corresponding to the selected feature subsets and the rule sets of classifier respectively, in which a memetic feature selection algorithm is adopted to evolve the feature subset population while a Pittsburgh-style learning classifier system is used to carry out the classifier evolution. These two coevolving populations cooperate with each other regarding the fitness evaluation and the final solution is obtained via collaborations between the best individuals from each population. Empirical results on several benchmark data sets chosen from the UCI repository, together with a non-parametric statistical test, validate that the proposed approach is able to deliver classifiers of better prediction accuracy and higher stability with fewer selected features, compared with the original learning classifier system. In addition, the incorporated feature selection process is shown to help improve the computational efficiency as well.","1089-778X;1089778X","Electronic:978-1-4244-7835-4; POD:978-1-4244-7834-7","10.1109/CEC.2011.5949916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949916","","Accuracy;Biological cells;Genetic algorithms;Genetics;Machine learning;Memetics;Optimization","data reduction;divide and conquer methods;embedded systems;feature extraction;genetic algorithms;learning (artificial intelligence);nonparametric statistics;pattern classification","UCI repository;classification model construction;cooperative coevolution based Pittsburgh learning classifier system;data reduction technique;divide and conquer strategy;feature selection;feature subset population;genetic based machine learning paradigm;learning classifier system;memetic feature selection;nonparametric statistical test;real world classification","","4","","29","","","5-8 June 2011","","IEEE","IEEE Conference Publications"
"Comparison of single and ensemble classifiers in terms of accuracy and execution time","M. F. Amasyali; O. K. Ersoy","Yildiz Technical Uni. Computer, Eng. Dept. 34349 Istanbul, Turkey","2011 International Symposium on Innovations in Intelligent Systems and Applications","20110711","2011","","","470","474","Classification accuracy and execution time are two important parameters in the selection of classification algorithms. In our experiments, 12 different ensemble algorithms, and 11 single classifiers are compared according to their accuracies and train/test time over 36 datasets. The results show that Rotation Forest has the highest accuracy. However, when accuracy and execution time are considered together, Random Forest and Random Committees can be the best choices.","","Electronic:978-1-61284-922-5; POD:978-1-61284-919-5","10.1109/INISTA.2011.5946119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946119","base learners;classifier ensembles;committees of learners;consensus theory;mixture of experts;multiple classifier systems","Accuracy;Classification algorithms;Clustering algorithms;Machine learning;Testing;Training;Vegetation","pattern classification","classifier accuracy;classifier execution time;ensemble classifier;random committees classifier;rotation forest classifier;single classifier","","2","","26","","","15-18 June 2011","","IEEE","IEEE Conference Publications"
"The analysis of youths' searching behavior","C. Li; B. Wu; Y. Li","Beijing Key Laboratory of Intelligent Telecommunications, Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China","2011 Second Worldwide Cybersecurity Summit (WCS)","20110808","2011","","","1","4","In order to create a safe and harmonious cyberspace environment for youth and protect them from the impact of bad information such as pornography, violence and gambling, most of the current solutions are to shield the sites containing this information. However some youth will take the initiative to seek out this bad information. In this paper we propose a method to analyze the searching behavior of youth and then to shield those keywords that may impact their health over time. We suggest that search engine operators provide keywords filtering technology to limit the searching behavior of youth. Operators should return to warning users who search keywords that contain bad information and record the searching log as feedback to parents. Of course parents should provide their IP addresses to the search engine operators first, to allow operators to set their IP addresses within the scope of supervising. Relying on search logs we count and classify keywords to understand the trend of youths' searching behavior and the areas that they often are interested in. Then we cluster the keywords in each area to get some main clusters and frequent keywords. Using this method we can grasp youths' searching behavior and protect them from the impact of bad information effectively.","","Electronic:978-0-615-51608-0; POD:978-1-4577-1449-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5978793","bad informations;classify;cluster;searching behavior;shield","Classification algorithms;Clustering algorithms;Internet;Machine learning algorithms;Search engines;Text categorization;Training","Internet;behavioural sciences computing;information retrieval;pattern classification;pattern clustering;search engines;security of data","IP addresses;Internet era;cyber security;cyberspace environment;gambling;keywords filtering technology;pornography;search engine operators;searching log;youth searching behavior analysis","","0","","4","","","1-2 June 2011","","IEEE","IEEE Conference Publications"
"An Improved Indefinite Kernel Machine Regression Algorithm with Norm-r Loss Function","J. c. Zhou; D. Wang","Dept. of Math., Qiannan Normal Coll. for Nat., Duyun, China","2011 Fourth International Conference on Information and Computing","20110714","2011","","","142","145","Indefinite kernel machine regression algorithm (IKMRA), in which only constrains the minimum total regression error, but each sample point regression error is ignored. Thus the accuracy and the generalization performance of the IKMRA can not be satisfied. In order to improve the precision and the generalization performance of the IKMRA, we proposed that each sample regression error be constrained besides the total regression error. We introduced the norm-r loss function and the slack variables in order to constrain each sample regression error, derived the iterative formula of corresponding gradient decent method and devised the corresponding algorithm. Experimental results show that our improved indefinite kernel machine regression algorithm (IIKMRA) is effective and feasible.","2160-7443;21607443","Paper:978-1-61284-688-0","10.1109/ICIC.2011.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5954524","gradient decent method;indefinite kernel;norm-r loss function;support vetcor regression","Data models;Kernel;Machine learning;Predictive models;Programming;Support vector machines;Training","error analysis;gradient methods;learning (artificial intelligence);regression analysis;support vector machines","gradient decent method;indefinite kernel;iterative formula;norm-r loss function;regression error;slack variables;support vector regression","","1","","6","","","25-27 April 2011","","IEEE","IEEE Conference Publications"
"Distinguishing defined concepts from prerequisite concepts in learning resources","S. Changuel; N. Labroche","Universite Pierre et Marie Curie - Paris 6, CNRS, UMR7606, LIP6, France","2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)","20110711","2011","","","22","29","The objective of any tutoring system is to provide meaningful learning to the learner, thence it is important to know whether a concept mentioned in a document is a prerequisite for studying that document, or it can be learned from it. In this paper, we study the problem of identifying defined concepts and prerequisite concepts from learning resources available on the web. Statistics and machine learning tools are exploited in order to predict the class of each concept. Two groups of features are constructed to categorize the concepts: contextual features and local features. The contextual features enclose linguistic information and the local features contain the concept properties such as font size and font weigh. An aggregation method is proposed as a solution to the problem of the multiple occurrences of a defined concept in a document. This paper shows that best results are obtained with the SVM classifier than with other classifiers.","","Electronic:978-1-4244-9927-4; POD:978-1-4244-9926-7","10.1109/CIDM.2011.5949296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949296","","Feature extraction;HTML;Kinetic energy;Machine learning;Support vector machines;Syntactics;Training","computer aided instruction;learning (artificial intelligence);linguistics","SVM classifier;contextual features;learning resources;local features;machine learning tools;tutoring system","","1","","13","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Optimized ISOMAP algorithm using similarity matrix","C. Pradhan; S. Mishra","School of Computer Engineering, KIIT University, Bhubaneswar, India","2011 3rd International Conference on Electronics Computer Technology","20110707","2011","5","","212","215","Dimension reduction techniques are used to obtain a reduced representation of the data that maintains the integrity of the original data. ISOMAP (Isometric Feature Mapping) is one of the dimension reduction techniques, which is a nonlinear generalization of Classical MDS (Multi-Dimensional Scaling) and works well both for real world and artificial data. It uses k-nearest neighbors concept for creating the neighborhood graph. In this paper, we have considered the similarity among data points as another approach for constructing the neighborhood graph, instead of using the concept of k-nearest neighbors.","","Electronic:978-1-4244-8679-3; POD:978-1-4244-8678-6","10.1109/ICECTECH.2011.5941988","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5941988","Dimension reduction;euclidean distance;geodesic distance;isomap;manifold learning","Data mining;Data visualization;Euclidean distance;Face;Geometry;Machine learning;Manifolds","data mining;data visualisation;learning (artificial intelligence)","ISOMAP algorithm;data mining;data representation;data visualization;dimension reduction technique;isometric feature mapping;k-nearest neighbors concept;manifold learning technique;multidimensional scaling;neighborhood graph;similarity matrix","","0","","6","","","8-10 April 2011","","IEEE","IEEE Conference Publications"
"PAC-Bayesian learning with asymmetric cost (June 2011)","A. J. Llorens; I. J. Wang","The Johns Hopkins University Applied Physics Laboratory, MD 20723 USA","2011 IEEE Statistical Signal Processing Workshop (SSP)","20110728","2011","","","765","768","PAC-Bayes generalization bounds offer a theoretical foundation for learning classifiers with low generalization error and predicting their performance on unseen data. Current formulations implicitly assume that the relative cost of misclassifying a positive or negative example is reflected by the class skew in the training dataset. We present a learning approach based on minimizing an asymmetric generalization bound that enables PAC-Bayesian model selection under a class-specific performance constraint.","2373-0803;23730803","Electronic:978-1-4577-0570-0; POD:978-1-4577-0569-4","10.1109/SSP.2011.5967816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967816","PAC-Bayes;asymmetry;generalization bounds;kernel machines;neyman-pearson","Classification algorithms;Kernel;Machine learning;Minimization;Support vector machines;Training;Training data","Bayes methods;belief networks;learning (artificial intelligence);pattern classification","PAC-Bayesian model selection learning;asymmetric generalization minimization;class skew;data prediction;generalization error;learning classifier;probably approximately correct-Bayesian model selection learning;training dataset","","1","","11","","","28-30 June 2011","","IEEE","IEEE Conference Publications"
"New intelligent diagnosis method to determine thyroid disorders","E. Alkım; E. Gürbüz; E. Kılıç","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Ondokuz May&#x0131;s &#x00DC;niversitesi, Turkey","2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU)","20110623","2011","","","38","41","In this study, the Learning Vector Quantization (LVQ) network model is enhanced with attaching conscience mechanism to be used in diagnosis of thyroid disorders, so that network's disease diagnostic success percentage is increased and the conscience coefficients which is used in the network is obtained in an adaptive manner. It is observed that the LVQ network model created with this new mechanism learns faster than the other networks, besides conscience mechanism increases percentage of network's performance. The results obtained are discussed by comparison with similar studies.","2165-0608;21650608","Electronic:978-1-4577-0463-5; POD:978-1-4577-0462-8","10.1109/SIU.2011.5929581","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929581","","Adaptation model;Artificial neural networks;Conferences;Diseases;Machine learning;Vector quantization","diseases;learning (artificial intelligence);medical diagnostic computing;neural nets;patient diagnosis;vector quantisation","conscience coefficients;intelligent diagnosis method;learning vector quantization network;thyroid disorders","","0","","11","","","20-22 April 2011","","IEEE","IEEE Conference Publications"
"Active learning with optimal distribution for image classification","Weining Wu; Maozu Guo; Yang Liu; Runzhang Xu","School of Computer Science and Technology, Harbin Institute of Technology, Heilongjiang, China","2011 International Conference on Multimedia Technology","20110825","2011","","","132","136","In this paper, we focus on the issue of building up a training set for the task of image classification at minimal labeling costs. It is a topic that has attracted the considerable attention in the recent years. We propose a novel active learning algorithm with optimal distribution. In order to solve the problems of the noisy distribution and the sampling bias in the actively sampling process, the empirical risk on the selected examples is weighted by density ratio, and then the risk on the test examples is estimated using only unlabeled examples and the marginal label distribution. Finally, the optimal training distribution is derived by minimizing the expected error of the risk. Our approach has been demonstrated on the task of image classification on the difficult benchmark PASCAL VOC 2007 dataset.","","Electronic:978-1-61284-774-0; POD:978-1-61284-771-9","10.1109/ICMT.2011.6001789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6001789","image classification;importance weighting;pool-based active learning;risk estimation","Classification algorithms;Databases;Estimation;Image classification;Labeling;Machine learning;Training","image classification;learning (artificial intelligence)","active learning algorithm;active sampling process;benchmark PASCAL VOC 2007 dataset;density ratio;empirical risk;image classification;marginal label distribution;minimal labeling costs;noisy distribution;optimal training distribution;sampling bias","","0","","10","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Content-based information processing-a new challenge","B. Zhang","Information Science & Technology College, Computer Science & Technology Department, Tsinghua National Lab for Information Science & Technology, State Key Lab of Intelligent Technology & Systems, Tsinghua University, Beijing 100084, China","Proceedings of the 30th Chinese Control Conference","20110825","2011","","","40","41","Since a big change of man-machine interaction mode has occurred in web era, information processing faces the challenge. That is, information processing has had to deal with the semantic meaning of the information. Classical information processing approaches only handle the form of information and are irrelevant to its semantic aspects. The urgent affair is to establish a new strategy that can deal with the content of information based on the classical information processing method. In the talk, the difficulty we faced recently and the future research direction in information processing are discussed, expressly; the multi-disciplinary study among neural science, cognitive science, psychology and information science is emphasized.","1934-1768;19341768","Electronic:978-988-17255-9-2; POD:978-1-4577-0677-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6001632","Information processing;Multi-disciplinary study;Semantics","Computers;Information processing;Information science;Learning systems;Machine learning;Semantics;Speech","Internet;cognition;information science;man-machine systems;psychology","Web era;cognitive science;content-based information processing;information science;man-machine interaction mode;multidisciplinary study;neural science;psychology","","0","","4","","","22-24 July 2011","","IEEE","IEEE Conference Publications"
"Improving Readability of Dyslexic Learners through Document Summarization","K. Nandhini; S. R. Balasundaram","Dept. of Comput. Applic., Nat. Inst. of Technol., Tiruchirappalli, India","2011 IEEE International Conference on Technology for Education","20110825","2011","","","246","249","E-Learning that blends the internet, the web and the educational activities, is becoming one of the prominent ways for defining teaching and learning experiences as anywhere anytime process. Any teaching learning process must be designed to suit the needs of all and must consider all types of learners including people with disabilities. One of the major learning disabilities found related to learners is the problem of reading. Especially for dyslexic reading is a severe problem. In this regard, this paper focuses on the design of a summarization tool that provides a summary of reading material which helps the dyslexic to have a first level understanding of the content.","","Electronic:978-0-7695-4534-9; POD:978-1-4577-1521-1","10.1109/T4E.2011.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6004393","Decision Tree Classifier;Dyslexic learner;E-Learning;Reading Problem;Summarization tool","Electronic learning;Feature extraction;Machine learning algorithms;Materials;Visualization;Writing","computer aided instruction;handicapped aids;medical disorders;statistical analysis;teaching;text analysis","Internet;World Wide Web;content understanding;document summarization;dyslexic learner readability improving;dyslexic reading;e-learning;educational activity;frequently occurring words;learning disability;learning experience;people with disability;reading material summary;statistical approach;teaching;text summary","","1","","14","","","14-16 July 2011","","IEEE","IEEE Conference Publications"
"An approach for clustering test data","A. R. Lenz; A. Pozo; S. R. Vergilio","Computer Science Department, Federal University of Paran&#x00E1; - UFPR, CP: 19081, CEP: 81531-970","2011 12th Latin American Test Workshop (LATW)","20110818","2011","","","1","6","The existing test techniques and criteria are considered complementary because they can reveal different kinds of faults and test specific aspects of the program. The functional criteria, such as Category Partition, are difficult to be automated, and are usually manually applied. Structural and fault-based testing criteria generally provide measures to evaluate the test data being used. The existing supporting tools produce a lot of information including: input and produced output, structural coverage, mutation score, faults revealed, etc. However, such information is not linked to functional aspects of the software. In this work, we present an approach based on machine learning clustering techniques that uses the test results for clustering test data. It allows the automation of functional test, since the obtained clusters can be considered equivalence classes. In addition to this, they relate test results from the application of different test techniques. A study case is described, and the use of the clusters is illustrated during regression test for ordering and reduction of test sets.","2373-0862;23730862","Electronic:978-1-4577-1490-0; POD:978-1-4577-1489-4","10.1109/LATW.2011.5985890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5985890","","Clustering algorithms;Decision trees;Machine learning;Software;Testing;Training data;Unsupervised learning","learning (artificial intelligence);pattern clustering;program testing;software fault tolerance","category partition;fault-based testing criteria;faults revealed;functional criteria;functional test automation;input-and-produced output;machine learning clustering techniques;mutation score;software test;structural coverage;structural testing criteria;test data clustering;test techniques","","1","","18","","","27-30 March 2011","","IEEE","IEEE Conference Publications"
"Constructing effective cluster ensembles based on Locally Linear Embedding","Lei Huan; Shan Huang; Jingbo Zhou","Institute of Command Automation, PLA University of Science and Technology, Nanjing, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","1167","1170","This paper studies how to construct cluster ensembles for high dimensional data. We examine a different approach to constructing cluster ensembles. To address high dimensionality, we focus on ensemble construction methods that build on a popular dimension reduction techniques, Locally Linear Embedding (LLE). Our ensemble constructor is based on random projection in LLE subspace. We present evidence showing that ensembles generated by new algorithms perform better than those by Principal Component Analysis with subsampling (PCASS) and Random Projection simply (RP) that proposed before. Experimental results demonstrate the effectiveness of the proposed methods on several real-world data sets.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5974129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974129","cluster ensembles;dimension reduction;locally linear embedding","Algorithm design and analysis;Clustering algorithms;Machine learning;Pattern recognition;Principal component analysis;Spatial databases","pattern clustering;principal component analysis;sampling methods","LLE subspace;cluster ensemble construction;dimension reduction technique;ensemble constructor;high dimensional data;locally linear embedding;principal component analysis;random projection;real-world data sets;subsampling","","0","","13","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"Nonnegative sparse coding for discriminative semi-supervised learning","R. He; W. S. Zheng; B. G. Hu; X. W. Kong","NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China","CVPR 2011","20110822","2011","","","2849","2856","An informative and discriminative graph plays an important role in the graph-based semi-supervised learning methods. This paper introduces a nonnegative sparse algorithm and its approximated algorithm based on the l<sup>0</sup>-l<sup>1</sup> equivalence theory to compute the nonnegative sparse weights of a graph. Hence, the sparse probability graph (SPG) is termed for representing the proposed method. The nonnegative sparse weights in the graph naturally serve as clustering indicators, benefiting for semi-supervised learning. More important, our approximation algorithm speeds up the computation of the nonnegative sparse coding, which is still a bottle-neck for any previous attempts of sparse non-negative graph learning. And it is much more efficient than using l<sup>1</sup>-norm sparsity technique for learning large scale sparse graph. Finally, for discriminative semi-supervised learning, an adaptive label propagation algorithm is also proposed to iteratively predict the labels of data on the SPG. Promising experimental results show that the nonnegative sparse coding is efficient and effective for discriminative semi-supervised learning.","1063-6919;10636919","DVD:978-1-4577-0393-5; Electronic:978-1-4577-0395-9; POD:978-1-4577-0394-2","10.1109/CVPR.2011.5995487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995487","","Clustering algorithms;Databases;Encoding;Machine learning;Prediction algorithms;Sparse matrices;Training","approximation theory;graph theory;iterative decoding;learning (artificial intelligence);pattern clustering;probability;sparse matrices","SPG;adaptive label propagation algorithm;approximation algorithm;clustering indicators;discriminative graph;discriminative semisupervised learning;graph-based semisupervised learning method;informative graph;l<sup>0</sup>-l<sup>1</sup> equivalence theory;l<sup>1</sup>-norm sparsity technique;large scale sparse graph learning;nonnegative sparse coding;nonnegative sparse weights algorithm;sparse nonnegative graph learning;sparse probability graph","","34","","25","","","20-25 June 2011","","IEEE","IEEE Conference Publications"
"Low-rank matrix completion by variational sparse Bayesian learning","S. D. Babacan; M. Luessi; R. Molina; A. K. Katsaggelos","Beckman Institute, University of Illinois at Urbana-Champaign, USA","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","2188","2191","There has been a significant interest in the recovery of low-rank matrices from an incomplete of measurements, due to both theoretical and practical developments demonstrating the wide applicability of the problem. A number of methods have been developed for this recovery problem, however, a principled method for choosing the unknown target rank is generally missing. In this paper, we present a recovery algorithm based on sparse Bayesian learning (SBL) and automatic relevance determination principles. Starting from a matrix factorization formulation and enforcing the low-rank constraint in the estimates as a sparsity constraint, we develop an approach that is very effective in determining the correct rank while providing high recovery performance. We provide empirical results and comparisons with current state-of-the-art methods that illustrate the potential of this approach.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946762","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946762","Bayesian methods;Low-rank matrix completion;automatic relevance determination","Approximation methods;Bayesian methods;Estimation;Machine learning;Noise;Optimization;Sparse matrices","Bayes methods;learning (artificial intelligence);matrix decomposition","SBL;low-rank matrix completion;matrix factorization formulation;recovery problem;sparsity constraint;variational sparse Bayesian learning","","2","","17","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Learning acceleration by policy sharing","K. S. Hwang; Y. J. Chen; W. C. Jiang","Department of Electrical Engineering, National Chung Cheng University, Chiayi, Taiwan","2011 9th World Congress on Intelligent Control and Automation","20110801","2011","","","725","729","Reinforcement learning is one of the more prominent machine learning technologies due to its unsupervised learning structure and ability to continually learn, even in a dynamic operating environment. Applying this learning to cooperative multi-agent systems not only allows each individual agent to learn from its own experience, but also offers the opportunity for the individual agents to learn from the other agents in the system to increase the speed of learning can be accelerated. In the proposed learning algorithm, an agent store its experience in terms of state aggregation implemented with a decision tree, such that policy sharing between multi-agent is eventually accomplished by merging different decision trees between peers. Unlike lookup tables which have homogeneous structure for state aggregations, decision trees carried in agents are with heterogeneous structure. This work executes policy sharing between cooperative agents by means of forming a hyper structure from their trees instead of merging whole trees violently. The proposed scheme initially translates the whole decision tree from an agent to others. Based on the evidence, only partial leaf nodes hold helpful experience for policy sharing. The proposed method inducts a hyper decision tree by a great mount of samples which are sampled from the shared nodes. Results from simulations in multi-agent cooperative domain illustrate that the proposed algorithms perform better than the one without sharing.","","Electronic:978-1-61284-700-9; POD:978-1-61284-698-9","10.1109/WCICA.2011.5970609","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5970609","Cooperation;Mobile robot;Multi-agent;Reinforcement learning;Sharing","Decision trees;Learning;Machine learning;Merging;Mobile robots;Multiagent systems","decision trees;multi-agent systems;peer-to-peer computing;unsupervised learning","cooperative multi-agent systems;decision tree;dynamic operating environment;hyper structure;machine learning;policy sharing;reinforcement learning;shared nodes;unsupervised learning structure","","0","","10","","","21-25 June 2011","","IEEE","IEEE Conference Publications"
"Learning photographic global tonal adjustment with a database of input / output image pairs","V. Bychkovsky; S. Paris; E. Chan; F. Durand","MIT CSAIL","CVPR 2011","20110822","2011","","","97","104","Adjusting photographs to obtain compelling renditions requires skill and time. Even contrast and brightness adjustments are challenging because they require taking into account the image content. Photographers are also known for having different retouching preferences. As the result of this complexity, rule-based, one-size-fits-all automatic techniques often fail. This problem can greatly benefit from supervised machine learning but the lack of training data has impeded work in this area. Our first contribution is the creation of a high-quality reference dataset. We collected 5,000 photos, manually annotated them, and hired 5 trained photographers to retouch each picture. The result is a collection of 5 sets of 5,000 example input-output pairs that enable supervised learning. We first use this dataset to predict a user's adjustment from a large training set. We then show that our dataset and features enable the accurate adjustment personalization using a carefully chosen set of training photos. Finally, we introduce difference learning: this method models and predicts difference between users. It frees the user from using predetermined photos for training. We show that difference learning enables accurate prediction using only a handful of examples.","1063-6919;10636919","DVD:978-1-4577-0393-5; Electronic:978-1-4577-0395-9; POD:978-1-4577-0394-2","10.1109/CVPR.2011.5995332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995332","","Cameras;Ground penetrating radar;Histograms;Machine learning;Measurement;Supervised learning;Training","image reconstruction;learning (artificial intelligence);visual databases","brightness adjustments;compelling renditions;input image pairs;learning photographic global tonal adjustment;output image pairs;photographs adjustment;supervised machine learning;users adjustment","","7","6","17","","","20-25 June 2011","","IEEE","IEEE Conference Publications"
"Learning and coordination: An overview","M. Abramson; R. Mittu","Naval Research Laboratory, USA","2011 International Conference on Collaboration Technologies and Systems (CTS)","20110711","2011","","","343","350","Adaptive learning techniques can automate the large-scale coordination of multi-agent systems and enhance their robustness in dynamic environments. This paper surveys several learning approaches that have been developed to address three different aspects of coordination, namely, learning coordination behavior, team learning, and the integrated learning of trust and reputation in order to facilitate coordination in open systems including collaborative systems where artificial agents and humans interact. Although convergence in multi-agent learning is still an open research question, several applications have emerged using some of the learning techniques presented.","","Electronic:978-1-61284-639-2; POD:978-1-61284-638-5","10.1109/CTS.2011.5928709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928709","Coordination;Multi-agent Learning;Survey","Joints;Learning;Learning systems;Machine learning;Markov processes;Multiagent systems;Training","learning (artificial intelligence);multi-agent systems","adaptive learning;integrated learning;large-scale coordination;learning coordination behavior;multi-agent systems;team learning","","1","","36","","","23-27 May 2011","","IEEE","IEEE Conference Publications"
"Agent self-assessment: Determining policy quality without execution","A. Hans; S. Duell; S. Udluft","Neuroinformatics and Cognitive Robotics Lab, Ilmenau University of Technology, Germany","2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)","20110728","2011","","","84","90","With the development of data-efficient reinforcement learning (RL) methods, a promising data-driven solution for optimal control of complex technical systems has become available. For the application of RL to a technical system, it is usually required to evaluate a policy before actually applying it to ensure it operates the system safely and within required performance bounds. In benchmark applications one can use the system dynamics directly to measure the policy quality. In real applications, however, this might be too expensive or even impossible. Being unable to evaluate the policy without using the actual system hinders the application of RL to autonomous controllers. As a first step toward agent self-assessment, we deal with discrete MDPs in this paper. We propose to use the value function along with its uncertainty to assess a policy's quality and show that, when dealing with an MDP estimated from observations, the value function itself can be misleading. We address this problem by determining the value function's uncertainty through uncertainty propagation and evaluate the approach using a number of benchmark applications.","2325-1824;23251824","Electronic:978-1-4244-9888-8; POD:978-1-4244-9887-1","10.1109/ADPRL.2011.5967358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967358","Markov decision processes;autonomous agent;policy quality;reinforcement learning;robustness;self-assessment;uncertainty propagation","Approximation algorithms;Benchmark testing;Equations;Histograms;Machine learning;Markov processes;Uncertainty","Markov processes;control engineering computing;learning (artificial intelligence);multi-agent systems;optimal control","Markov decision process;agent self-assessment;complex technical system;data-efficient reinforcement learning;discrete MDP;optimal control;policy quality;uncertainty propagation","","0","","18","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Maximum margin structure learning of Bayesian network classifiers","F. Pernkop; M. Wohlmay; M. Mücke","Signal Processing and Speech Communication Laboratory, Graz University of Technology, Austria","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","2076","2079","Recently, the margin criterion has been successfully used for parameter optimization in graphical models. We introduce maximum margin based structure learning for Bayesian network classifiers and demonstrate its advantages in terms of classification performance compared to traditionally used discriminative structure learning methods. In particular, we provide empirical results for generative structure learning and two discriminative structure learning approaches on handwritten digit recognition tasks. We show that maximum margin structure learning outperforms other structure learning methods. Furthermore, we present classification results achieved with different bitwidth for representing the parameters of the classifiers.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946734","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946734","Bayesian network classifiers;custom-precision;discriminative learning;margin learning","Bayesian methods;Handwriting recognition;Learning systems;Machine learning;Niobium;Random variables;Training","Bayes methods;learning (artificial intelligence);pattern classification","Bayesian network classifiers;discriminative structure learning methods;graphical models;handwritten digit recognition tasks;maximum margin structure learning;parameter optimization","","3","","21","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Protecting against evaluation overfitting in empirical reinforcement learning","S. Whiteson; B. Tanner; M. E. Taylor; P. Stone","Informatics Institute, University of Amsterdam, the Netherlands","2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)","20110728","2011","","","120","127","Empirical evaluations play an important role in machine learning. However, the usefulness of any evaluation depends on the empirical methodology employed. Designing good empirical methodologies is difficult in part because agents can overfit test evaluations and thereby obtain misleadingly high scores. We argue that reinforcement learning is particularly vulnerable to environment overfitting and propose as a remedy generalized methodologies, in which evaluations are based on multiple environments sampled from a distribution. In addition, we consider how to summarize performance when scores from different environments may not have commensurate values. Finally, we present proof-of-concept results demonstrating how these methodologies can validate an intuitively useful range-adaptive tile coding method.","2325-1824;23251824","Electronic:978-1-4244-9888-8; POD:978-1-4244-9887-1","10.1109/ADPRL.2011.5967363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967363","","Algorithm design and analysis;Learning;Machine learning;Supervised learning;Tiles;Tuning;Uncertainty","generalisation (artificial intelligence);learning (artificial intelligence)","evaluation overfitting;machine learning;range-adaptive tile coding method;reinforcement learning;remedy generalized methodology","","5","","34","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Competence Development of Pre-Service Teachers with the Support of LeContract","T. Valjataga; K. Tammets; H. Põldoja","Centre for Educ. Technol., Tallinn Univ., Tallinn, Estonia","2011 IEEE 11th International Conference on Advanced Learning Technologies","20110818","2011","","","611","612","Competency-based approach to upgrade one's dispositions has received a lot of attention as an alternative way of evaluating qualifications in various areas. In order to carry out successful study projects and practices that support specific competence advancement a learning contract procedure can be a promising technique. Learning contract procedure has a dual focus here. It explicates learner's perceived learning environment and learner's understanding of how they are going to develop desired competences. This paper interprets learning contract procedure as a response to one's learning progress and the effectiveness of learning environment. This conceptual position paper focuses on preservice teachers and their competence development with the support of learning contracts. Finally the paper proposes to design a web-based tool LeContract.","2161-3761;21613761","Electronic:978-0-7695-4346-8; POD:978-1-61284-209-7","10.1109/ICALT.2011.186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5992413","LeContract;competences;learning contract procedure;personal learning environment","Context;Contracts;Educational technology;Electronic mail;Machine learning;Qualifications","Internet;continuing professional development;educational administrative data processing","LeContract;Web-based tool;learning contract procedure;learning progress;preservice teacher competence development","","0","","11","","","6-8 July 2011","","IEEE","IEEE Conference Publications"
"Reinforcement learning negotiation strategy based on opponent classification","Tianhao Sun; Junkun Deng; Qingsheng Zhu; Feng Cao","College of Computer Science, Chongqing University, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","3987","3989","To help negotiation agent select its best actions and reach its final goal, this paper proposes a reinforcement learning negotiation strategy based on opponent classification. In the middle of negotiation process, negotiation agent makes the best use of the opponent's negotiation history to make a decision of the opponent's type, dynamically adjust the negotiation agent's belief of opponent in time, and get more favorable and better negotiation result. Finally, the algorithm is proved to be effective and practical by experiment.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5974891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974891","Negotiation history;Negotiation strategy;Opponent classification;Reinforcement learning","Computational modeling;Electronic commerce;History;Information technology;Learning;Machine learning;Multiagent systems","learning (artificial intelligence);multi-agent systems;negotiation support systems;pattern classification","negotiation agent;opponent classification;reinforcement learning negotiation strategy","","0","","9","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"Empirical Learning Aided by Weak Domain Knowledge in the Form of Feature Importance","R. A. Iqbal","Dept. of Comput. Sci., American Int. Univ. Bangladesh, Dhaka, Bangladesh","2011 International Conference on Multimedia and Signal Processing","20110718","2011","1","","126","130","Standard hybrid learners that use domain knowledge require stronger knowledge that is hard and expensive to acquire. However, weaker domain knowledge can benefit from prior knowledge while being cost effective. Weak knowledge in the form of feature relative importance (FRI) is presented and explained. Feature relative importance is a real valued approximation of a feature's importance provided by experts. Advantage of using this knowledge is demonstrated by IANN, a modified multilayer neural network algorithm. IANN is a very simple modification of standard neural network algorithm but attains significant performance gains. Experimental results in the field of molecular biology show higher performance over other empirical learning algorithms including standard backpropagation and support vector machines. IANN performance is even comparable to a theory refinement system KBANN that uses stronger domain knowledge.","","Electronic:978-1-61284-314-8; POD:978-1-4799-1686-3","10.1109/CMSP.2011.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5957392","Feature importance;domain knowledge;hybrid learning","Artificial neural networks;Backpropagation;Knowledge based systems;Machine learning;Network topology;Support vector machines;Training","backpropagation;learning (artificial intelligence);neural nets;support vector machines","FRI;empirical learning aided;feature importance form;feature relative importance;molecular biology;multilayer neural network algorithm;standard backpropagation;support vector machines;weak domain knowledge","","4","","17","","","14-15 May 2011","","IEEE","IEEE Conference Publications"
"Fault diagnosis of wind turbine gearbox based on Fisher criterion","J. Yang; D. Fan; Y. Zhou; Y. Liu","Beijing Gold wind Science & Creation Wind power equipment CO. LTD, 100176, China","Proceedings of the 30th Chinese Control Conference","20110825","2011","","","3165","3168","The fault and normal gearboxes are classified and identified by principal components analysis (PCA) and Fisher criterion based on the vibration test and time-domain analysis for several wind turbine gearboxes. First the multi-dimension time-domain feature values are extracted from the gearbox vibration signals and PCA is carried out for dimension compression. Then the feature data which the dimension is reduced are classified and identified by Fisher criterion and the classification threshold is given. The result shows that the sensitivities of different time-domain feature values for the gearbox fault are different. But the differences information of the original feature space is preserved while the dimension is reduced by PCA. The classification for the reduced-dimension feature space is succeeded in the Fisher criterion.","1934-1768;19341768","Electronic:978-988-17255-9-2; POD:978-1-4577-0677-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6001094","Fault Diagnosis;Fisher Criterion;Gearbox;PCA;Wind Turbine","Fault diagnosis;Feature extraction;Machine learning;Principal component analysis;Time domain analysis;Vibrations;Wind turbines","dynamic testing;feature extraction;mechanical engineering computing;principal component analysis;signal processing;wind turbines","Fisher criterion;PCA;classification threshold;dimension compression;fault diagnosis;fault gearboxes;feature extraction;gearbox fault;gearbox vibration signals;multidimension time-domain feature values;normal gearboxes;principal components analysis;reduced-dimension feature space;time-domain analysis;vibration test;wind turbine gearboxes","","0","","8","","","22-24 July 2011","","IEEE","IEEE Conference Publications"
"An approach to feature selection for sentiment analysis","P. Koncz; J. Paralic","Technical University of Kosice/Faculty of Electrical Engineering and Informatics/Department of Cybernetics and Artificial Intelligence, Kosice, Slovakia","2011 15th IEEE International Conference on Intelligent Engineering Systems","20110714","2011","","","357","362","Sentiment analysis deals with methods for automatic analysis of the subjective aspects of the text. In this contribution we first present an overview of main approaches currently used in sentiment analysis. We further focus on feature selection methods for sentiment analysis and propose a new approach to feature selection. Our approach has been experimentally evaluated on movie review dataset. The results show that the proposed method is computationally efficient and in exchange sacrifices only a small amount of accuracy.","1543-9259;15439259","Electronic:978-1-4244-8956-5; POD:978-1-4244-8954-1","10.1109/INES.2011.5954773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5954773","","Accuracy;Computational complexity;Dictionaries;Internet;Machine learning;Support vector machines","behavioural sciences computing;psychology;text analysis","automatic analysis;feature selection;movie review dataset;sentiment analysis;subjective text aspects","","5","","44","","","23-25 June 2011","","IEEE","IEEE Conference Publications"
"A hybrid evaluation metric for optimizing classifier","M. Hossin; M. N. Sulaiman; A. Mustapha; N. Mustapha; R. W. Rahmat","Fac. of Comput. Sci. &amp; Inf. Technol., Univ. Putra Malaysia (UPM), Serdang, Malaysia","2011 3rd Conference on Data Mining and Optimization (DMO)","20110804","2011","","","165","170","The accuracy metric has been widely used for discriminating and selecting an optimal solution in constructing an optimized classifier. However, the use of accuracy metric leads the searching process to the sub-optimal solutions due to its limited capability of discriminating values. In this study, we propose a hybrid evaluation metric, which combines the accuracy metric with the precision and recall metrics. We call this new performance metric as Optimized Accuracy with Recall-Precision (OARP). This paper demonstrates that the OARP metric is more discriminating than the accuracy metric using two counter-examples. To verify this advantage, we conduct an empirical verification using a statistical discriminative analysis to prove that the OARP is statistically more discriminating than the accuracy metric. We also empirically demonstrate that a naive stochastic classification algorithm trained with the OARP metric is able to obtain better predictive results than the one trained with the conventional accuracy metric. The experiments have proved that the OARP metric is a better evaluator and optimizer in the constructing of optimized classifier.","2155-6938;21556938","Electronic:978-1-61284-212-7; POD:978-1-61284-211-0","10.1109/DMO.2011.5976522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5976522","Accuracy metric;Classifier optimization;Hybrid evaluation metric;Precision metric;Recall metric","Accuracy;Classification algorithms;Machine learning;Mathematical model;Measurement;Stochastic processes;Training","optimisation;pattern classification;statistical analysis","OARP;hybrid evaluation metric;optimized accuracy with recall-precision;optimizing classifier;statistical discriminative analysis;stochastic classification algorithm","","0","","12","","","28-29 June 2011","","IEEE","IEEE Conference Publications"
"Bayesian model selection of Stochastic Blockmodels for random graphs","B. Kurt; A. T. Cemgil","Alg&#x0131;sal Zeka Lab., Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Bo&#x011F;azi&#x00E7;i &#x00DC;niversitesi, Turkey","2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU)","20110623","2011","","","1089","1092","A way of solving the problem of which model explains an observation better is Bayesian model selection. In this paper, we applied Bayesian model selection for the simplest graph models: the Erdös-Rényi and Stochastoc Blockmodel graphs. Given the adjacency matrix of a graph, we compared its' marginal likelihood under different models using direct computation, variational methods and Monte Carlo methods. We compared the success of the methods according to their ability to estimate the correct model order. Both methods gave qualitatively similar results but the Monte Carlo method estimated the true Marginal likelihood more accurately.","2165-0608;21650608","Electronic:978-1-4577-0463-5; POD:978-1-4577-0462-8","10.1109/SIU.2011.5929844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929844","","Atmospheric modeling;Bayesian methods;Computational modeling;Conferences;Machine learning;Monte Carlo methods;Signal processing","Bayes methods;Monte Carlo methods;graph theory;random processes;stochastic processes;variational techniques","Bayesian model selection;Erdos-Renyi graph;Monte Carlo method;adjacency matrix;graph model;marginal likelihood;random graph;stochastic blockmodel graph;variational method","","0","","5","","","20-22 April 2011","","IEEE","IEEE Conference Publications"
"Inverse reinforcement learning with Gaussian process","Q. Qiao; P. A. Beling","Department of Systems and Information Engineering, University of Virginia, Charlottesville, 22904, USA","Proceedings of the 2011 American Control Conference","20110818","2011","","","113","118","We present new algorithms for inverse reinforcement learning (IRL, or inverse optimal control) in convex optimization settings. We argue that finite-space IRL can be posed as a convex quadratic program under a Bayesian inference framework with the objective of maximum a posteriori estimation. To deal with problems in large or even infinite state space, we propose a Gaussian process model and use preference graphs to represent observations of decision trajectories. Our method is distinguished from other approaches to IRL in that it makes no assumptions about the form of the reward function and yet it retains the promise of computationally manageable implementations for potential real-world applications. In comparison with an establish algorithm on small-scale numerical problems, our method demonstrated better accuracy in apprenticeship learning and a more robust dependence on the number of observations.","0743-1619;07431619","Electronic:978-1-4577-0081-1; POD:978-1-4577-0080-4","10.1109/ACC.2011.5990948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5990948","","Accuracy;Approximation methods;Bayesian methods;Gaussian processes;Machine learning;Markov processes;Trajectory","belief networks;convex programming;inference mechanisms;learning (artificial intelligence);maximum likelihood estimation;quadratic programming","Bayesian inference framework;Gaussian process model;IRL;apprenticeship learning;convex optimization settings;inverse reinforcement learning;maximum a posteriori estimation;small-scale numerical problems","","3","","13","","","June 29 2011-July 1 2011","","IEEE","IEEE Conference Publications"
"A comparison of Finite State Classifier and Mahalanobis-Taguchi System for multivariate pattern recognition in skin cancer detection","E. A. Cudney; S. M. Corns","Engineering Management & Systems Engineering Department at Missouri University of Science & Technology, Rolla, USA","2011 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20110711","2011","","","1","7","This project presents two methods for image classification for the detection of malignant melanoma: the Mahalanobis-Taguchi System and Finite State Classifiers. The Mahalanobis-Taguchi System is a diagnosis and predictive method for analyzing patterns in multivariate cases, while Finite State Classifiers are a state based machine learning technique. The goal of this study is to compare the ability of the Mahalanobis-Taguchi System and a Finite State Classifier to discriminate using small data sets. We examine the discriminant ability as a function of data set size using publicly available skin lesion image data. While analysis of the data shows a high degree of correlation, the Mahalanobis-Taguchi System performed poorly when trying to discriminate between Malignant Melanoma and benign lesions. Alternately, the Finite State Classifiers developed using evolutionary computation obtained over 85% correct classification of the malignant and benign lesions using the image data sets.","","Electronic:978-1-4244-9897-0; POD:978-1-4244-9896-3","10.1109/CIBCB.2011.5948469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948469","","Cancer;Correlation;Evolutionary computation;Lesions;Machine learning;Malignant tumors;Skin","Taguchi methods;cancer;evolutionary computation;finite state machines;image classification;learning (artificial intelligence);medical image processing;skin","Mahalanobis-Taguchi system;data set size;diagnosis;evolutionary computation;finite state classifier;image classification;machine learning technique;malignant melanoma detection;multivariate pattern recognition;predictive method;skin cancer detection;skin lesion image data","","1","","23","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Classification of customer credit data for intelligent credit scoring system using fuzzy set and MC2 — Domain driven approach","P. Marikkannu; K. Shanmugapriya","Department of Information Technology, Anna University of Technology, Coimbatore, TamilNadu, India","2011 3rd International Conference on Electronics Computer Technology","20110707","2011","3","","410","414","Credit scoring or credit risk assessment is an important research issue in the banking industry. The major challenge of credit scoring is to recruit the profitable customers by predicting the bankrupts. The credit scoring carried out by traditional data driven approaches resulted only in an imprecise solution. Also the domain-driven based multiple criteria and multiple constraint (MC2) level programming approach results only in a satisfying solution. In this paper, a fuzzy set based domain driven approach for classification of customer credit data has been provided. The multiple criteria and multiple constraint level programming are used for scoring the customers based on the classifier. The domain expertise knowledge is used for building the linear combinational sets of attributes for classification. This hybrid approach will identify the class of best, good, satisfactory, bad and worst customers. Experiments conducted on publicly available datasets validated the effectiveness and efficiency of the proposed method.","","Electronic:978-1-4244-8679-3; POD:978-1-4244-8678-6","10.1109/ICECTECH.2011.5941782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5941782","Credit scoring;MC2;classification;domain-driven approach;fuzzy set;linear combination","Banking;Data mining;Data models;Linear programming;Machine learning;Programming","banking;constraint handling;fuzzy set theory","banking industry;bankrupt;credit risk assessment;customer credit data;domain-driven based multiple criteria;fuzzy set;intelligent credit scoring system;multiple constraint level programming;profitable customer","","1","","10","","","8-10 April 2011","","IEEE","IEEE Conference Publications"
"Evolving a Non-playable Character team with Layered Learning","S. Mondesire; R. P. Wiegand","Electrical Engineering and Computer Science, University of Central Florida, Orlando, USA","2011 IEEE Symposium on Computational Intelligence in Multicriteria Decision-Making (MDCM)","20110711","2011","","","52","59","Layered Learning is an iterative machine learning technique used to train agents how to perform tasks. The technique decomposes a task into simpler components and trains the agent to learn how to perform progressively more complex sub-tasks to solve the overall task. Layered Learning has been successfully used to instruct computer programs to solve Boolean-logic problems, teach robots how to walk, and train RoboCup soccer playing agents. The proposed work answers the question of how well does Layered Learning apply to the evolved development of a heterogeneous team of Non-playable Characters (NPCs) in a video game. The work compares the use of Layered Learning against evolving NPCs with monolithic based approaches. Experiment data show that Layered Learning can result in the successful development of NPCs and demonstrates that the approach performs well against monolithic evaluation.","","Electronic:978-1-61284-069-7; POD:978-1-61284-068-0","10.1109/SMDCM.2011.5949283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949283","Decision Making;Genetic Algorithm;Layered Learning","Aggregates;Biological cells;Decision making;Games;Genetic algorithms;Machine learning;Training","computer games;iterative methods;learning (artificial intelligence);software agents","Boolean logic problems;RoboCup soccer playing agents;agent training;iterative machine learning technique;layered learning;nonplayable character team evolution;robots;video game","","1","","10","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Kernel methods and its application in Relation Extraction","Xiaofeng Zhang; Zhiqiang Gao; Man Zhu","School of Computer Science & Engineering, Southeast University, Nanjing, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","1362","1365","Relation extraction aims at discovering relations between entities from free text, and it is a crucial part of information extraction. Recently, kernel methods have seen successfully applied in relation extraction. In this paper, various kernel methods in relation extraction from free text are discussed, including syntactic parsing, kernel functions, as well as their training algorithms. Major difficulties and future research directions are concluded.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5972181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5972181","Kernel Method;Relation Extraction","Convolution;Data mining;Feature extraction;Kernel;Machine learning;Semantics;Syntactics","information retrieval;text analysis","free text;information extraction;kernel functions;relation extraction;syntactic parsing","","0","","25","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"Kernel-based autoregressive modeling with a pre-image technique","M. Kallas; P. Honeine; C. Richard; C. Francis; H. Amoud","Institut Charles Delaunay (UMR CNRS 6279), LM2S, Universit&#x00E9; de Technologie de Troyes, France","2011 IEEE Statistical Signal Processing Workshop (SSP)","20110728","2011","","","281","284","Autoregressive (AR) modeling is a very popular method for time series analysis. Being linear by nature, it obviously fails to adequately describe nonlinear systems. In this paper, we propose a kernel-based AR modeling, by combining two main concepts in kernel machines. One the one hand, we map samples to some nonlinear feature space, where an AR model is considered. We show that the model parameters can be determined without the need to exhibit the nonlinear map, by computing inner products thanks to the kernel trick. On the other hand, we propose a prediction scheme, where the prediction in the feature space is mapped back into the input space, the original samples space. For this purpose, a pre-image technique is derived to predict the future back in the input space. The efficiency of the proposed method is illustrated on real-life time-series, by comparing it to other linear and nonlinear time series prediction techniques.","2373-0803;23730803","Electronic:978-1-4577-0570-0; POD:978-1-4577-0569-4","10.1109/SSP.2011.5967681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967681","autoregressive modeling;kernel machine;pattern recognition;pre-image;prediction","Kalman filters;Kernel;Machine learning;Mathematical model;Predictive models;Support vector machines;Time series analysis","autoregressive processes;time series","feature space;kernel machines;kernel trick;kernel-based AR modeling;kernel-based autoregressive modeling;nonlinear map;nonlinear system;nonlinear time series prediction;pre-image technique;time series analysis","","2","","9","","","28-30 June 2011","","IEEE","IEEE Conference Publications"
"Learning photographic global tonal adjustment with a database of input/output image pairs","V. Bychkovsky; S. Paris; E. Chan; F. Durand","MIT CSAIL","CVPR 2011","20110822","2011","","","97","104","Adjusting photographs to obtain compelling renditions requires skill and time. Even contrast and brightness adjustments are challenging because they require taking into account the image content. Photographers are also known for having different retouching preferences. As the result of this complexity, rule-based, one-size-fits-all automatic techniques often fail. This problem can greatly benefit from supervised machine learning but the lack of training data has impeded work in this area. Our first contribution is the creation of a high-quality reference dataset. We collected 5,000 photos, manually annotated them, and hired 5 trained photographers to retouch each picture. The result is a collection of 5 sets of 5,000 example input-output pairs that enable supervised learning. We first use this dataset to predict a user's adjustment from a large training set. We then show that our dataset and features enable the accurate adjustment personalization using a carefully chosen set of training photos. Finally, we introduce difference learning: this method models and predicts difference between users. It frees the user from using predetermined photos for training. We show that difference learning enables accurate prediction using only a handful of examples.","1063-6919;10636919","DVD:978-1-4577-0393-5; Electronic:978-1-4577-0395-9; POD:978-1-4577-0394-2","10.1109/CVPR.2011.5995413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995413","","Cameras;Ground penetrating radar;Histograms;Machine learning;Measurement;Supervised learning;Training","image reconstruction;learning (artificial intelligence)","brightness adjustments;image content;input image pairs;learning photographic global tonal adjustment;output image pairs;photographs adjustment;supervised machine learning","","8","6","17","","","20-25 June 2011","","IEEE","IEEE Conference Publications"
"The DARPA COORDINATORS program: A retrospective","B. Kohout","Defense Advanced Research Projects Agency, USA","2011 International Conference on Collaboration Technologies and Systems (CTS)","20110711","2011","","","342","342","Summary form only given. The goal of the DARPA COORDINATORS program was to create hand-held coordination assistants that would enable military units to adapt mission plans more rapidly, more accurately, with less cognitive load and with a greater degree of coordinated action. In early 2005, three teams of researchers began a concerted effort to create a distributed cognitive system that could adapt mission plans online via task/resource timing/allocation and contingency selection. This talk will provide a brief overview of the COORDINATORS program, its design and execution, successes, and lessons learned.","","Electronic:978-1-61284-639-2; POD:978-1-61284-638-5","10.1109/CTS.2011.5928708","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928708","","Autonomous agents;Joints;Machine learning;Multiagent systems;Schedules","cognition;cognitive systems;distributed processing;military computing;resource allocation","DARPA Coordinators program;cognitive load;contingency selection;distributed cognitive system;hand held coordination assistant;mission plan;resource allocation","","0","","6","","","23-27 May 2011","","IEEE","IEEE Conference Publications"
"Theoretical analyses on a class of nested RKHS's","A. Tanaka; H. Imai; M. Kudo; M. Miyakoshi","Division of Computer Science, Hokkaido University, N14W9, Kita-ku, Sapporo, 060-0814 Japan","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","2072","2075","One of central topics of kernel machines in the field of machine learning is a model selection, especially a selection of a kernel or its parameters. In our previous work, we discussed a class of kernels forming a class of nested reproducing kernel Hilbert spaces with an invariant metric; and proved that the kernel corresponding to the smallest reproducing kernel Hilbert space, including an unknown true function, gives the optimal model. In this paper, we consider a class of kernels forming a class of nested reproducing kernel Hilbert spaces whose metrics are not always invariant and show that a similar result to the invariant case is not obtained by providing a counter example using a class of Gaussian kernels.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946733","generalization ability;kernel machine;metric;model space;reproducing kernel Hilbert space","Additive noise;Computational modeling;Hilbert space;Kernel;Machine learning;Pattern recognition","Gaussian processes;Hilbert spaces;learning (artificial intelligence)","Gaussian kernels;RKHS;invariant metrics;kernel Hilbert spaces;kernel machines;machine learning;model selection","","2","","15","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Distributed investigations of intrusion detection data on the grid","M. Joldos; I. L. Muntean","Computer Science Dept., Technical University of Cluj-Napoca, Romania","2011 RoEduNet International Conference 10th Edition: Networking in Education and Research","20110822","2011","","","1","4","In this paper we demonstrate the use of grid-based computing in revealing aspects of intrusion detection data which were difficult to reveal some years ago due to constrained computing resources. Exploiting the grids for their computing resources can rapidly turn into a tedious task, entailing solid technical knowledge about the grid. Grid application (and) frameworks are the category of tools that make the use of the grid much simplified for the scientist with interest solely on the computing resources. Mining security data is a task, we believe, that can be better served using the grid. Here, we attempt to reveal new insights in intrusion detection data, such as the well known KDDCUP'99 data set.","2068-1038;20681038","Electronic:978-1-4577-1235-7; POD:978-1-4577-1233-3","10.1109/RoEduNet.2011.5993703","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5993703","Data mining;Grid computing;Intrusion detection;KDD data set","Data mining;Intrusion detection;Legged locomotion;Machine learning;Middleware;Software","data mining;grid computing;security of data","data security mining;grid-based computing;intrusion detection data","","1","","21","","","23-25 June 2011","","IEEE","IEEE Conference Publications"
"Greedy feature selection for ranking","H. Lai; Y. Tang; H. Luo; Y. Pan","School of Information Science and Technology, Sun Yat-sen University, Guangzhou, China 510006","Proceedings of the 2011 15th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20110721","2011","","","42","46","This paper is concerned with a study on the feature selection for ranking. Learning to rank is a useful tool for collaborative filtering and many other collaborative systems, which many algorithms have been proposed for dealing this issue. But feature selection methods receive little attention, despite of their importance in collaborative filtering problems: First, recommender systems always have massive data. Using all these data in learning to rank is unrealistic and impossible. Second, we discuss that not all the features are useful for a user's query. So choosing the most relevant data is necessary and useful. To amend this problem, we describe an algorithm called FBPCRank to choose the most relevant features for ranking. Our method combines two measures of good subsets of features, which not only can decrease the loss objective, but also reduce total similarity scores between any two features. We adopt forward and backward methods to choose the most relative features and use Pearson correlation coefficient to measure the similarity of two features. The experiments indicate that our method can outperform other state-of-the-art algorithms by selecting just small amounts of features.","","Electronic:978-1-4577-0387-4; POD:978-1-4577-0386-7","10.1109/CSCWD.2011.5960053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5960053","","Benchmark testing;Correlation;Feature extraction;Greedy algorithms;Loss measurement;Machine learning;Recommender systems","greedy algorithms;recommender systems","FBPCRank;Pearson correlation coefficient;backward methods;collaborative filtering;collaborative systems;forward methods;greedy feature selection;recommender systems","","2","","15","","","8-10 June 2011","","IEEE","IEEE Conference Publications"
"SVM feature selection for multidimensional EEG data","N. Jrad; R. Phlypo; M. Congedo","Vision and Brain Signal Processing (ViBS), GIPSA-Lab, CNRS UMR 5216, Grenoble Universities, 961 rue de la Houille Blanche, 38402 Cedex, France","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","781","784","In many machine learning applications, like Brain - Computer Interfaces (BCI), only high-dimensional noisy data are available rendering the discrimination task non-trivial. In this work, we focus on feature selection, more precisely on optimal electrode selection and weighting, as an efficient tool to improve the BCI classification procedure. The proposed framework closely integrates spatial feature selection and weighting within the classification task itself. Spatial weights are considered as hyper-parameters to be learned by a Support Vector Machine (SVM). The resulting spatially weighted SVM (sw-SVM) is then designed to maximize the margin between classes whilst minimizing the generalization error. Experimental studies on eight Error Related Potential (ErrP) data sets, illustrate the efficiency of the sw-SVM from a physiological and a machine learning point of view.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946520","Brain Computer Interfaces;Support Vector Machines;feature extraction;spatial filters","Brain computer interfaces;Electrodes;Electroencephalography;Machine learning;Optimization;Support vector machines;Training","biomedical electrodes;brain-computer interfaces;data analysis;electroencephalography;feature extraction;learning (artificial intelligence);medical signal processing;signal classification;support vector machines","BCI classification;SVM feature selection;brain-computer interfaces;data sets;machine learning applications;multidimensional EEG;optimal electrode selection;support vector machine","","1","","11","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"A New Effective Approach for Solving the Rules Conflict Problem","T. Treier","Dept. of Inf., Tallinn Univ. of Technol., Tallinn, Estonia","2011 Third Pacific-Asia Conference on Circuits, Communications and System (PACCS)","20110818","2011","","","1","3","In this paper a new approach for the rules conflict problem is presented. The problem is discussed related to use of inductive learning systems generated rules. The rules conflict problem occurs when two or more rules cover the same test example but predict different classes. The common strategy for preferring one of the conflicting rules is the best rule strategy: for each rule a ""weight"" is calculated by some rule quality measure and the conflicting rule with the highest ""weight"" is chosen. In case of existing ""weight"" functions only training examples are used for calculation. In this paper we introduce a new rule ""weight"" function, called rule reliability, which is calculated on the basis of testing examples. It can reorder rule set so that rules with better classification ""force"" will be used firstly. Effectiveness of the new approach is shown by experiments.","","Electronic:978-1-4577-0856-5; POD:978-1-4577-0855-8","10.1109/PACCS.2011.5990134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5990134","","Accuracy;Computer science;Learning systems;Machine learning;Reliability;Testing;Training","learning by example;problem solving","inductive learning systems generated rules;rule quality measure;rule reliability;rules conflict problem solving;weight functions","","0","","14","","","17-18 July 2011","","IEEE","IEEE Conference Publications"
"Automatic Classification of Change Requests for Improved IT Service Quality","C. Kadar; D. Wiesmann; J. Iria; D. Husemann; M. Lucic","Zurich Res. Lab., IBM, Ruschlikon, Switzerland","2011 Annual SRII Global Conference","20110718","2011","","","430","439","Faulty changes to the IT infrastructure can lead to critical system and application outages, and therefore cause serious economical losses. In this paper, we describe a change planning support tool that aims at assisting the change requesters in leveraging aggregated information associated with the change, like past failure reasons or best implementation practices. The thus gained knowledge can be used in the subsequent planning and implementation steps of the change. Optimal matching of change requests with the aggregated information is achieved through the classification of the change request into about 200 fine-grained activities. We propose to automatically classify the incoming change requests using various information retrieval and machine learning techniques. The cost of building the classifiers is reduced by employing active learning techniques or by leveraging labeled features. Historical tickets from two customers were used to empirically assess and compare the accuracy of the different classification approaches (Lucene index, multinomial logistic regression, and generalized expectation criteria).","2166-0778;21660778","Electronic:978-0-7695-4371-0; POD:978-1-61284-415-2","10.1109/SRII.2011.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5958118","automation;change management;generalized expectation criteria;information retrieval;logistic regression;service quality;text classification","Accuracy;Computational modeling;Data models;Indexes;Information retrieval;Machine learning;Training","DP industry;classification;information retrieval;learning (artificial intelligence);management of change;planning (artificial intelligence)","IT infrastructure;Lucene index;active learning techniques;application outages;change planning support tool;change request optimal matching;change requests automatic classification;economical losses;faulty changes;generalized expectation criteria;improved IT service quality;information retrieval technique;machine learning technique;multinomial logistic regression;subsequent planning","","5","4","23","","","March 29 2011-April 2 2011","","IEEE","IEEE Conference Publications"
"NSSAC: Negative selection-based self adaptive classifier","S. N. S. Fakhari; A. M. E. Moghadam","Department of Electrical and Computer Science, Islamic Azad University, Qazvin, Iran","2011 International Symposium on Innovations in Intelligent Systems and Applications","20110711","2011","","","29","33","In this paper, a novel algorithm for classification called “NSSAC” is proposed, which is based on negative selection method in the human immune system. Artificial immune based classifiers have two important challenges: (1) the recognition distance threshold which choosing an appropriate recognition distance threshold is a difficult task because it necessitates the understanding of the data set in detail, (2) A detector generation algorithm that all classifiers used randomized algorithm to generate memory cell. In this paper for resolve above problems a deterministic algorithm is used to generate memory cell and an adaptive method is used for calculation the recognition distance threshold. Therefore the generated detectors have a good quality of the distribution and on the other hand, NSSAC can be adapted automatically to each data set. The classifier was tested on three benchmark data sets and the results show that our algorithm is useful for classification problems.","","Electronic:978-1-61284-922-5; POD:978-1-61284-919-5","10.1109/INISTA.2011.5946064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946064","Artificial immune system (AIS);classification;detector generation algorithm;negative selection algorithm;recognition distance threshold","Accuracy;Classification algorithms;Detectors;Immune system;Machine learning algorithms;Testing;Training","artificial immune systems;deterministic algorithms;pattern classification","NSSAC;adaptive method;artificial immune based classifiers;detector generation;deterministic algorithm;human immune system;memory cell;negative selection-based self adaptive classifier;randomized algorithm;recognition distance threshold","","0","","14","","","15-18 June 2011","","IEEE","IEEE Conference Publications"
"Multi-class imbalanced learning implemented in network intrusion detection","Zhimin Miao; Luwen Zhao; Weiwei Yuan; Richu Liu","Institute of Communications Engineering, PLA University of Science and Technology, Nan Jing, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","1395","1398","In view of the problems of using traditional machine learning method to detect the network intrusions, a network intrusion detection model based on multi-class imbalanced learning is proposed. Based on the consideration that there is within-class imbalance in large data sets and multi-class data sets, every class of the training data is firstly clustered. Some minimum bounding hyperspheres are formed by Support Vector Date Description (SVDD) according to the clustering results. A test sample is assigned the label of hyperspheres if its distance to the sphere center is smaller than or equal to the radius. The model is testified by experiments on network security data sets.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5975051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975051","Multi-class imbalanced;network intrusion detection;support vector date description","Automation;Intrusion detection;Machine learning;Presses;Programmable logic arrays;Support vector machine classification","learning (artificial intelligence);pattern clustering;security of data","machine learning method;minimum bounding hyperspheres;multiclass imbalanced learning;network intrusion detection model;network security data sets;support vector date description;training data;within-class imbalance","","0","","11","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"An Intrusion Detection Method Based on Multiple Kernel Support Vector Machine","G. Song; J. Guo; Y. Nie","Ningbo Inst. of Technol., Zhejiang Univ., Ningbo, China","2011 International Conference on Network Computing and Information Security","20110711","2011","2","","119","123","Network intrusion data has the characters such as small sample, nonlinear and high dimension, so the detection performance of single kernel support vector machine (SK-SVM) is instability. The choice of kernel function and relative parameters plays an important role in SK-SVM. It greatly influences the generalization performance of SK-SVM. According to the limitation of SK-SVM, in this paper we present an intrusion detection method based on multiple kernel support vector machine (MK-SVM). MK-SVM can calculate the weights of kernel functions and Lagrange multipliers simultaneously through semi-infinite linear programming, and thus achieve the choice of kernel functions and the optimization of classifier. Furthermore, in order to reduce the time and space required of this method, we adopt feature selection and clustering method in the process of input data preprocessing. The experimental results using KDD CUP 1999 show that our method has better adaptability and higher detection accuracy than the method based on SK-SVM.","","Electronic:978-0-7695-4355-0; POD:978-1-61284-347-6","10.1109/NCIS.2011.123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948806","RBF kernel function;feature selection;kernel method;multiple kernel learning;support vector machine","Accuracy;Intrusion detection;Kernel;Machine learning;Optimization;Support vector machines;Training","feature extraction;linear programming;pattern classification;pattern clustering;security of data;support vector machines","KDD CUP 1999;Lagrange multipliers;MK-SVM;SK-SVM;classifier optimization;clustering method;data preprocessing;feature selection;intrusion detection method;kernel function;multiple kernel support vector machine;network intrusion data;semiinfinite linear programming","","0","","12","","","14-15 May 2011","","IEEE","IEEE Conference Publications"
"Prediction of the Distribution of Perceived Music Emotions Using Discrete Samples","Y. H. Yang; H. H. Chen","Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan","IEEE Transactions on Audio, Speech, and Language Processing","20110728","2011","19","7","2184","2196","Typically, a machine learning model of automatic music emotion recognition is trained to learn the relationship between music features and perceived emotion values. However, simply assigning an emotion value to a clip in the training phase does not work well because the perceived emotion of a clip varies from person to person. To resolve this problem, we propose a novel approach that represents the perceived emotion of a clip as a probability distribution in the emotion plane. In addition, we develop a methodology that predicts the emotion distribution of a clip by estimating the emotion mass at discrete samples of the emotion plane. We also develop model fusion algorithms to integrate different perceptual dimensions of music listening and to enhance the modeling of emotion perception. The effectiveness of the proposed approach is validated through an extensive performance study. An average <i>R</i><sup>2</sup> statistics of 0.5439 for emotion prediction is achieved. We also show how this approach can be applied to enhance our understanding of music emotion.","1558-7916;15587916","","10.1109/TASL.2011.2118752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5719548","Arousal;emotion distribution prediction;music emotion recognition;regression;subjectivity;valence","Accuracy;Computational modeling;Feature extraction;Kernel;Machine learning;Predictive models;Training","emotion recognition;information retrieval;learning (artificial intelligence);music;probability;statistical analysis","R2 statistics;automatic music emotion recognition;discrete samples;emotion distribution;emotion perception;emotion plane;machine learning model;model fusion algorithms;music features;music listening;perceived emotion values;perceived music emotions;perceptual dimensions;probability distribution;training phase","","19","","81","","20110224","Sept. 2011","","IEEE","IEEE Journals & Magazines"
"Feature Relevance Network-Based Transfer Learning for Indoor Location Estimation","H. S. Seok; K. B. Hwang; B. T. Zhang","School of Computer Science and Engineering, Seoul National University, Seoul, Korea","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","20110818","2011","41","5","711","719","We present a new machine learning framework for indoor location estimation. In many cases, locations could be easily estimated using various traditional positioning methods and conventional machine learning approaches based on signalling devices, e.g., access points (APs). When there exist environmental changes, however, such traditional methods cannot be employed due to data distribution change. In order to circumvent this difficulty, we introduce feature relevance network-based method, which focuses on interrelatedness among features. Feature relevance networks are connected graphs representing concurrency of the signalling devices such as APs. In the newly created relevance network, a test instance and the prototype of a location are expanded until convergence. The expansion cost corresponds to distance between the test instance and the prototype. Unlike other methods, our model is nonparametric making no assumptions about signal distributions. The proposed method is applied to the 2007 IEEE International Conference on Data Mining Data Mining Contest Task #2 (transfer learning), which is a typical example situation where the training and test datasets have been gathered during different periods. Using the proposed method, we accomplish the estimation accuracy of 0.3238, which is better than the best result of the contest.","1094-6977;10946977","","10.1109/TSMCC.2010.2076277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607316","Feature relevance networks;indoor location estimation;transfer learning","Accuracy;Data mining;Estimation;Machine learning;Prototypes;Training","data mining;learning (artificial intelligence);position measurement;radiocommunication;telecommunication computing","access points;data distribution change;data mining;feature relevance network-based method;feature relevance network-based transfer learning;indoor location estimation;machine learning;positioning methods;signal distributions;signalling device concurrency representation;signalling devices","","6","","30","","20101021","Sept. 2011","","IEEE","IEEE Journals & Magazines"
"The intelligent methods for teaching quality comprehensive assessment","L. Li; S. Wang; C. Leng","School of Foreign Studies, Shanghai Lixin University of Commerce, Shanghai, China, 201620","2011 Chinese Control and Decision Conference (CCDC)","20110801","2011","","","2503","2507","One of the important methods implied into teaching management is the comprehensive assessment of the teaching quality. Currently, this has been held based on weighted sum of those indexes among index system, which can not efficiently make use of the information dependency between historical information and indexes. In solving this dilemma, hierarchical naive Bayesian network was created, which can more efficiently utilize the dependency information between historical information and indexes when the three-class indexes can be either discrete or successive. In doing so, not only can comprehensive assessment of teaching quality realized, but also the quantitative analysis for the index contribution can be reached.","1948-9439;19489439","Electronic:978-1-4244-8738-7; POD:978-1-4244-8737-0","10.1109/CCDC.2011.5968630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5968630","Classifier;Comprehensive assessment;Contribution analysis;Hierarchical naive Bayesian network;Teacher teaching quality","Accuracy;Bayesian methods;Business;Education;Estimation;Indexes;Machine learning","belief networks;teaching","hierarchical naive Bayesian network;historical information;index contribution;index system;information dependency;intelligent method;quality comprehensive assessment;teaching management;teaching quality;three-class index","","0","","8","","","23-25 May 2011","","IEEE","IEEE Conference Publications"
"Predictive Modeling of Material Properties Using GMDH-based Abductive Networks","I. A. Lawal; Y. O. Mohammed","Comput. Sci. & Eng. Dept., Yanbu Univ. Coll., Yanbu Al-Smaiyah, Saudi Arabia","2011 Fifth Asia Modelling Symposium","20110725","2011","","","3","6","Material properties are very important in most material science and engineering computations. A number of modeling and machine learning techniques have been used for the prediction of material properties, including Fuzzy Regression, Adaptive Fuzzy Neural Network, Extreme Learning Machine, and Sensitive Based Linear Learning Method. This paper proposes the application of Abductive Networks to the problem. We studied the performance of various Abductive Network architectures on a dataset used by earlier published work. A Root Means Square Error (RMSE) as low as 15.34MPa was achieved on the predicted tensile strength values, which represent about 50% improvement compared to the performance reported in the literature for other modeling techniques on the same dataset. Moreover, the technique achieves 20% reduction in the number of features required.","2376-1164;23761164","Electronic:978-0-7695-4414-4; POD:978-1-4577-0193-1","10.1109/AMS.2011.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5961231","Abductive Networks;Material properties","Computational modeling;Data models;Fuzzy neural networks;Machine learning;Material properties;Predictive models","fuzzy neural nets;learning (artificial intelligence);materials properties;materials science computing;mean square error methods;regression analysis;tensile strength","GMDH-based abductive networks;adaptive fuzzy neural network;extreme learning machine;fuzzy regression;machine learning techniques;material science;predictive material properties modeling;root means square error;sensitive based linear learning method;tensile strength values","","0","","14","","","24-26 May 2011","","IEEE","IEEE Conference Publications"
"Target classification using knowledge-based probabilistic model","W. Tang; K. Z. Mao; L. O. Mak; G. W. Ng; Z. Sun; J. H. Ang; G. Lim","School of EEE, Nanyang Technological University, Singapore","14th International Conference on Information Fusion","20110808","2011","","","1","8","In past decades, pattern classification has been intensively explored in machine learning. With the in-depth exploration of machine learning in various applications, new challenges arise, which requests researchers to move from data-driven to domain-driven models by integrating domain knowledge, and to move from static to dynamic models to adapt to the changing environment. This paper proposes an intelligent classification system with following features, to address these requests. Firstly, this system integrates both data association and classification modules. The contextual information extracted from input data is saved as learnt knowledge which is then combined with given expert knowledge in classification. The experimental study shows that this learning process helps to reduce the ambiguity of classification. Secondly, the proposed classifier, i.e. knowledge-based naive Bayes, classifies the incoming data based on both expert knowledge and learnt knowledge. Thirdly, a soft-decision mechanism is adopted in classification algorithm, which can effectively handle overlapping data.","","Electronic:978-0-9824438-2-8; POD:978-1-4577-0267-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5977714","data association;soft decision;target classification","Estimation;Knowledge based systems;Libraries;Machine learning;Niobium;Production;Training data","Bayes methods;image classification;learning (artificial intelligence);sensor fusion","classification algorithm;contextual information;data association modules;data classification modules;data-driven models;domain-driven models;dynamic models;expert knowledge;knowledge-based naive Bayes;knowledge-based probabilistic model;learnt knowledge;machine learning;pattern classification;soft-decision mechanism;static models;target classification","","1","","14","","","5-8 July 2011","","IEEE","IEEE Conference Publications"
"Web service schema matching based on characteristic vector","Wang Ke; Ou Wei-Jie; Zeng Cheng; Li De-Yi; Peng Zhi-Yong","National Science Library, Chinese Academy of Sciences, Beijing 100190, China","2011 IEEE 2nd International Conference on Software Engineering and Service Science","20110811","2011","","","274","277","Web service schema matching is the preliminary treatment phase of service composition and service mashup. With the entry and exit of large numbers of services on the Internet, it will be difficult to find and suggest the most relevant service candidates for new composition and mashup. In this work, we present an approach for web service schema matching based on characteristic vector consisted of multi-type service parameter information element. This schema matching approach is different form the main syntactical-based and semantic-based matching approaches, and will predict schema relationship more effectively and adaptable for web service. An experiment on real data shows the effectiveness of this approach.","2327-0586;23270586","Electronic:978-1-4244-9698-3; POD:978-1-4244-9699-0","10.1109/ICSESS.2011.5982307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5982307","schema matching;service composition;service mashup;web services","Databases;Machine learning;Mashups;Ontologies;Semantics","Web services","Web service schema matching;characteristic vector;multitype service parameter information element;semantic-based matching approach;service composition;service mashup;syntactical-based matching approach","","0","","21","","","15-17 July 2011","","IEEE","IEEE Conference Publications"
"A role-based imitation algorithm for the optimisation in dynamic fitness landscapes","E. Cakar; S. Tomforde; C. Müller-Schloer","Institute of Systems Engineering, Leibniz Universit&#x00E4;t Hannover, Hannover, Germany","2011 IEEE Symposium on Swarm Intelligence","20110714","2011","","","1","8","Organic Computing (OC) deals with technical systems consisting of a large number of system elements that can adapt their structure and behaviour to the operational environment in order to accomplish a given goal. In this context, self-adaptation is a key aspect that allows a system to perform in (possibly dynamic) environments without intervention from outside. Establishing self-adaptation in technical systems requires adequate optimisation algorithms that can find high-quality solutions in an acceptable period of time. In this paper, we present a new population-based optimisation algorithm (Role Based Imitation algorithm - RBI) that can be used to establish self-adaptation in OC systems with dynamic fitness landscapes. RBI proposes a novel role assignment strategy for exploring and exploiting agents to find high-quality solutions within a short period of time (i.e., with high convergence speed). We compare RBI with Differential Evolution (DE), Particle Swarm Optimisation (PSO), Evolutionary Algorithm (EA) and Simulated Annealing (SA) in static and dynamic fitness landscapes. Our experiments show that RBI performs better than the competing algorithms especially in noisy and highly dynamic environments.","","Electronic:978-1-61284-052-9; POD:978-1-61284-053-6","10.1109/SIS.2011.5952571","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5952571","Organic Computing;population-based optimisation;static and dynamic fitness landscapes","Benchmark testing;Convergence;Heuristic algorithms;Machine learning algorithms;Noise measurement;Simulated annealing","evolutionary computation;fault tolerant computing;particle swarm optimisation;simulated annealing","DE;EA;PSO;SA;differential evolution;dynamic fitness landscape;evolutionary algorithm;organic computing;particle swarm optimisation;population-based optimisation algorithm;role assignment strategy;role-based imitation algorithm;self-adaptation;simulated annealing","","2","","23","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Neuro-cognitive organization as a side-effect of the evolution of learning ability","S. F. Arnold","Department of Complex Systems Science, Graduate School of Information Science, Nagoya University, Japan","2011 IEEE Symposium on Artificial Life (ALIFE)","20110714","2011","","","100","107","This research explores the relation between environmental organization and cognitive organization. We hypothesize that selection pressure on learning ability indirectly causes selection pressure on alignment of neuro-cognitive and environmental structure, since such alignment implies that small changes in the environment can be handled with small changes in the implementation of behaviour. We indicate reinforcement-free types of learning ability as most strongly reliant on such alignment. We present a model in which a simple form of reinforcement-free learning is evolved in neural networks, and analyze the effect this has on the virtual species' neural organization. We find a higher degree of organization than in a control population without learning ability, and discuss the relation between the observed neural structure and the environmental structure. We discuss our findings in the context of the environmental complexity thesis and the Baldwin effect.","2160-6374;21606374","Electronic:978-1-61284-063-5; POD:978-1-61284-062-8","10.1109/ALIFE.2011.5954646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5954646","Baldwin effect;Evolution of learning ability;environmental complexity thesis;evolution of mind;neuromodulation","Artificial neural networks;Evolution (biology);Learning systems;Machine learning;Neurons;Organisms;Organizations","cognition;cognitive systems;learning (artificial intelligence);neural nets","Baldwin effect;cognitive organization;environmental complexity;environmental organization;learning ability evolution;neural networks;neurocognitive organization;reinforcement-free learning;virtual species","","1","","26","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Fuzzy projective clustering in high dimension data using decrement size of data","S. Mehdi Seyednejad; H. Musavi; S. Mohaddese Seyednejad; T. Darabi","Department of computer &IT engineering, Azad university of Qazvin, Iran","2011 3rd Conference on Data Mining and Optimization (DMO)","20110804","2011","","","160","164","Today, data clustering problems became an important challenge in Data Mining domain. A kind of clustering is projective clustering. Since a lot of researches has done in this article but each of previous algorithms had some defects that we will be indicate in this paper. We propose a new algorithm based on fuzzy sets and at first using this approach detect and eliminate unimportant properties for all clusters. Then we remove outliers, finally we use weighted fuzzy c-mean algorithm according to offered formula for fuzzy calculations. Experimental results show that our approach has more performance and accuracy than similar algorithms.","2155-6938;21556938","Electronic:978-1-61284-212-7; POD:978-1-61284-211-0","10.1109/DMO.2011.5976521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5976521","fuzzy c-mean algorithm;fuzzy set;projective clustering","Accuracy;Algorithm design and analysis;Clustering algorithms;Data mining;Diseases;Machine learning;Partitioning algorithms","data mining;fuzzy set theory;pattern clustering","data clustering problems;data mining domain;fuzzy projective clustering;fuzzy sets;weighted fuzzy c-mean algorithm","","0","","13","","","28-29 June 2011","","IEEE","IEEE Conference Publications"
"Exploiting sensing diversity for confident sensing in wireless sensor networks","M. Keally; G. Zhou; G. Xing; J. Wu","College of William and Mary, USA","2011 Proceedings IEEE INFOCOM","20110630","2011","","","1719","1727","Wireless sensor networks for human health monitoring, military surveillance, and disaster warning all have stringent accuracy requirements for detecting or classifying events while maximizing system lifetime. We define meeting such user accuracy requirements as confident sensing. To perform confident sensing and reduce energy, we must address sensing diversity: sensing capability differences among heterogeneous and homogeneous sensors in a specific deployment. We are among the first to explore the impact of sensing diversity on sensor collaboration, exploit diversity for sensing confidence, and apply diversity exploitation for confident sensing coverage. We show that our diversity-exploiting confident coverage problem is NP-hard for any specific deployment and present a practical solution, Wolfpack. Through a distributed and iterative sensor collaboration approach, Wolfpack maximizes a specific deployment's capability to meet user detection requirements and save energy by powering off unneeded nodes. Using real vehicle detection trace data, we demonstrate that Wolfpack provides confident event detection coverage for 30% more detection locations, using 20% less energy than a state of the art approach.","0743-166X;0743166X","Electronic:978-1-4244-9921-2; POD:978-1-4244-9919-9","10.1109/INFCOM.2011.5934969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5934969","","Accuracy;Collaboration;Event detection;Machine learning;Sensors;Vehicle detection;Vehicles","computational complexity;wireless sensor networks","NP-hard problem;distributed sensor collaboration approach;event detection coverage;heterogeneous sensors;homogeneous sensors;human health monitoring;iterative sensor collaboration approach;military surveillance;sensing diversity;vehicle detection trace data;wireless sensor networks","","6","","39","","","10-15 April 2011","","IEEE","IEEE Conference Publications"
"The complexities involved in the analysis of Fourier Transform Infrared Spectroscopy of breast cancer data with clustering algorithms","S. Naqvi; J. M. Garibaldi","Intelligent Modelling and Analysis (IMA) Research Group, School of Computer Science, University of Nottingham, U.K","2011 3rd Computer Science and Electronic Engineering Conference (CEEC)","20110822","2011","","","80","85","Fourier Transform Infrared Spectroscopy (FTIR) is a relatively new technique that has been frequently applied now a days in cancer pathology including breast cancer. The long term aim of this work is to develop novel techniques using machine learning methods for the analysis of FTIR data sets. This paper presents the preliminary work with a case study of a FTIR data set of breast cancer with two commonly used clustering algorithms of fuzzy c-means and k-means to differentiate between different cancer grades. We also discuss the complexities involved in the analysis of spectral data sets and need to find new methods. Future work will involve efforts towards development of a novel frame work with advanced machine learning methods to extract valuable information from complex spectral data sets.","","Electronic:978-1-4577-1301-9; POD:978-1-4577-1300-2","10.1109/CEEC.2011.5995830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995830","Breast cancer;FCM;FTIR;K-means","Algorithm design and analysis;Breast cancer;Clustering algorithms;Machine learning algorithms;Pathology;Spectroscopy","Fourier transform spectra;cancer;infrared spectra;learning (artificial intelligence);medical computing;pattern clustering","FTIR;Fourier transform infrared spectroscopy;breast cancer data;cancer pathology;fuzzy c-means clustering algorithm;k-means clustering algorithm;machine learning","","0","","20","","","13-14 July 2011","","IEEE","IEEE Conference Publications"
"Rule-based classification by means of bipolar criteria","J. T. Rodríguez; B. Vitoriano; J. Montero","Department of Statistics and Operations Research, Complutense University of Madrid, Spain","2011 IEEE Symposium on Computational Intelligence in Multicriteria Decision-Making (MDCM)","20110711","2011","","","197","204","Classification problems often play an important role in many decision contexts. Therefore, the design of decision support tools to operate in such contexts usually involves the formulation of adequate classification models. Fuzzy rule-based classifiers FRBCS are excellent methodological tools for this purpose due to their interpretability and ability to deal with linguistic knowledge representations. Learning of these rules from data is an increasingly common practice in order to avoid complex knowledge engineering processes. This paper proposes the notions of minor and significant exceptions to a rule in order to extend the notion of counterexample and thus enhance the representational and modelling power of FRBCS. This allows to consider some classes as being dissimilar or opposite, and leads to the introduction of a bipolar approach in rule based learning for classification, as the evaluation of rules in terms of positive and negative evidence is enabled in this way. As a consequence, it is then possible to introduce significant features and requirements of the decision contexts in the underlying classification models in a flexible and practical way. In order to illustrate the usage of the proposed bipolar classification framework, an example of application in the context of humanitarian logistics decision making is described.","","Electronic:978-1-61284-069-7; POD:978-1-61284-068-0","10.1109/SMDCM.2011.5949288","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949288","bipolarity;decision support systems;fuzzy rule based classification","Cognition;Context;Context modeling;Data mining;Humans;Machine learning;Proposals","decision support systems;fuzzy set theory;knowledge based systems;pattern classification","FRBCS;bipolar criteria;decision support tools;fuzzy rule-based classifiers;humanitarian logistics decision making;linguistic knowledge representations;rule based learning","","0","","19","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"RNADPCompare: An algorithm for comparing RNA secondary structures based on image processing techniques","H. H. Tsang; C. Jacob","Department of Computer Science, University of Calgary Calgary, Alberta, Canada T2N 1N4","2011 IEEE Congress of Evolutionary Computation (CEC)","20110714","2011","","","1288","1295","In structural biology, structural chemistry, and bioinformatics, Ribonucleic Acid (RNA) structure comparison is a fundamental problem. It is because structural comparison can facilitate RNA structure prediction and studies in RNA energy landscapes and conformational switches as well. There are many different tools have been proposed for RNA secondary structure comparison. This paper describes and presents a novel algorithm, RNADPCompare, for computing similarity measure of RNA secondary structures. The main idea for this algorithm is to represent the RNA secondary structure as a dot plot, and then process the dot plot as an image. The algorithm will utilize image processing techniques and heuristic understanding of the image properties to compute similarity measure of RNA secondary structures. Since many evolutionary and machine learning algorithms for RNA secondary structure design and prediction rely on good metric for examining structural similarities, therefore this novel metric will make significant contribution to the advances to these algorithms. An evaluation of the algorithm in terms of correlation to the native structure is made. The results from the six sequences of RNA from a variety of sequence lengths and organisms were tested. When comparing with Sfold, the prediction accuracy of using RNADPCompare to compute the difference matrix seems to be very promising. These results demonstrated that RNADPCompare is highly competitive in terms of the processing speed and accuracy when compare to other methods. This supports the use of this algorithm on other research in RNA secondary structure design and prediction.","1089-778X;1089778X","Electronic:978-1-4244-7835-4; POD:978-1-4244-7834-7","10.1109/CEC.2011.5949764","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949764","","Algorithm design and analysis;Correlation;Machine learning algorithms;Prediction algorithms;RNA;Sensitivity","bioinformatics;macromolecules;medical image processing","RNA secondary structure;RNADPCompare;bioinformatics;difference matrix;evolutionary algorithm;image processing technique;machine learning;ribonucleic acid","","0","","34","","","5-8 June 2011","","IEEE","IEEE Conference Publications"
"Trojan characteristics analysis based on Stochastic Petri Nets","H. Gao; Y. Wang; L. Wang; L. Liu; J. Li; X. Cheng","The University of Science and Technology Beijing, 100083, China","Proceedings of 2011 IEEE International Conference on Intelligence and Security Informatics","20110818","2011","","","213","215","Trojan's attack behavior has become increasingly common and diversifiable. How to judge Trojan-like features of the softwares which the users download has become the problem that the users concern about. In this paper, we first capture the software's behavior and related parameters from our virtual software test bed, then a modeling method using Stochastic Petri Nets is proposed, which supports quantitative analysis for the application software's behaviors. Based on the model, the similarity degree between application software and Trojan software is analyzed quantitatively. This analysis show that the model can be used to design an effective anti-Trojan system. The paper concludes with an example to illustrate the effectiveness of the model and analysis method.","","Electronic:978-1-4577-0085-9; POD:978-1-4577-0082-8","10.1109/ISI.2011.5984084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984084","Stochastic Petri Nets;Trojan horse;attack model;remote accesss;security behavior","Analytical models;Machine learning;Monitoring;Software;Stochastic processes;Trojan horses;Visualization","Petri nets;invasive software;program testing;software performance evaluation;stochastic processes","Trojan attack behavior;Trojan characteristics analysis;Trojan software;antiTrojan system;modeling method;software behavior;stochastic Petri nets;virtual software test bed","","2","","5","","","10-12 July 2011","","IEEE","IEEE Conference Publications"
"The Sound Recognition of Artillery Projectile Shape Based on Least Squares Fuzzy Support Vector Machine","G. Songyun; W. Yi; Z. Yaohui","Dept. of Basic Courses, Shenyang Artillery Acad., Shenyang, China","2011 International Conference on Intelligence Science and Information Engineering","20110825","2011","","","253","256","Least squares fuzzy support vector machine is proposed based on the theory of fuzzy support vector classification. Based on the theory of ballistic shock wave, the sound identification of artillery projectile is achieved by training and testing to the two samples data of 130mm and 152mm artillery projectile shock wave.","","Electronic:978-0-7695-4480-9; POD:978-1-4577-0960-9","10.1109/ISIE.2011.101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5997428","least squares fuzzy support vector machine;shock wave;sound recognition","Machine learning;Projectiles;Shape;Shock waves;Support vector machine classification;Training","acoustic signal processing;ballistics;fuzzy set theory;least squares approximations;military computing;projectiles;shock waves;signal classification;support vector machines;weapons","artillery projectile shape;artillery projectile shock wave;ballistic shock wave;fuzzy support vector classification;least squares fuzzy support vector machine;sound identification;sound recognition","","0","","9","","","20-21 Aug. 2011","","IEEE","IEEE Conference Publications"
"Learning vocal tract variables with multi-task kernels","H. Kadri; E. Duflos; P. Preux","Team-Project SequeL, INRIA Lille Nord-Europe, Villeneuve d'Ascq, France","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","2200","2203","The problem of acoustic-to-articulatory speech inversion continues to be a challenging research problem which significantly impacts automatic speech recognition robustness and accuracy. This paper presents a multi-task kernel based method aimed at learning Vocal Tract (VT) variables from the Mel-Frequency Cepstral Coefficients (MFCCs). Unlike usual speech inversion techniques based on individual estimation of each tract variable, the key idea here is to consider all the target variables simultaneously to take advantage of the relationships among them and then improve learning performance. The proposed method is evaluated using synthetic speech dataset and corresponding tract variables created by the TAsk Dynamics Application (TADA) model and compared to the hierarchical ε-SVR speech inversion technique.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946917","Multi-task learning;acoustic-to-articulatory inversion;matrix-valued kernel;vocal tract variables","Hilbert space;Kernel;Machine learning;Mel frequency cepstral coefficient;Speech;Speech recognition","cepstral analysis;speech recognition","ε-SVR speech inversion technique;MFCC;TADA model;acoustic-to-articulatory speech inversion;automatic speech recognition accuracy;automatic speech recognition robustness;learning VT variable;learning vocal tract variable;melfrequency cepstral coefficient;multitask kernel based method;synthetic speech dataset;task dynamics application model","","1","","21","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Fronto-parietal gamma-oscillations are a cause of performance variation in brain-computer interfacing","M. Grosse-Wentrup","Max Planck Institute for Biological Cybernetics, Department Empirical Inference, Spemannstr. 38, 72076 T&#x00FC;bingen, Germany","2011 5th International IEEE/EMBS Conference on Neural Engineering","20110623","2011","","","384","387","In recent work, we have provided evidence that fronto-parietal γ-oscillations of the electromagnetic field of the brain modulate the sensorimotor-rhythm. It is unclear, however, what impact this effect may have on explaining and addressing within-subject performance variations of brain-computer interfaces (BCIs). In this paper, we provide evidence that on a group-average classification accuracies in a two-class motor-imagery paradigm differ by up to 22.2% depending on the state of fronto-parietal γ-power. As such, this effect may have a large impact on the design of future BCI-systems. We further investigate whether adapting classification procedures to the current state of γ-power improves classification accuracy, and discuss other approaches to exploiting this effect.","1948-3546;19483546","Electronic:978-1-4244-4141-9; POD:978-1-4244-4140-2","10.1109/NER.2011.5910567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5910567","","AC motors;Accuracy;Brain computer interfaces;Electroencephalography;Machine learning;Support vector machines;Training","brain-computer interfaces;electroencephalography;handicapped aids;medical signal processing;signal classification","brain;brain-computer interfacing;electromagnetic field;fronto-parietal gamma-oscillations;group-average classification accuracy;performance variations;sensorimotor rhythm;two-class motor-imagery paradigm","","1","","13","","","April 27 2011-May 1 2011","","IEEE","IEEE Conference Publications"
"Selecting the best artificial neural network model from a multi-objective Differential Evolution Pareto front","M. Cruz-Ramírez; J. C. Fernández; F. Fernández-Navarro; J. Sánchez-Monedero; C. Hervás-Martínez","Department of Computer Science and Numerical Analysis, University of C&#x00F3;rdoba., Rabanales Campus, Albert Einstein building, 3rd floor, 14071 - C&#x00F3;rdoba, Spain","2011 IEEE Symposium on Differential Evolution (SDE)","20110714","2011","","","1","8","The objective of this work is to select artificial neural network models (ANN) automatically with sigmoid basis units for multiclassification tasks. These models are designed using a Memetic Pareto Differential Evolution Neural Network algorithm (MPDENN) based on the Pareto dominance concept. We propose different methodologies to obtain the best model from the Pareto front obtained with the MPDENN algorithm. These methodologies are based on choosing the best models for training in both objectives, the Correct Classification Rate and Minimum Sensitivity, and the two models closest to the centroids of two clusters formed with the models of the first and second Pareto fronts. These methodologies are compared with three standard ensembles methodologies with very competitive results.","","Electronic:978-1-61284-072-7; POD:978-1-61284-071-0","10.1109/SDE.2011.5952067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5952067","","Accuracy;Algorithm design and analysis;Artificial neural networks;Clustering algorithms;Machine learning;Neurons;Training","Pareto optimisation;evolutionary computation;neural nets;pattern classification","MPDENN algorithm;Pareto dominance concept;artificial neural network models;correct classification rate;memetic Pareto differential evolution neural network algorithm;minimum sensitivity;multiclassification tasks;multiobjective differential evolution Pareto front;sigmoid basis units","","0","","37","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"Classifying Connectivity Graphs Using Graph and Vertex Attributes","J. Richiardi; S. Achard; E. Bullmore; D. Van De Ville","Med. Image Process. Lab., Ecole Polytech. Federate de Lausanne, Lausanne, Switzerland","2011 International Workshop on Pattern Recognition in NeuroImaging","20110725","2011","","","45","48","Qualitative and quantitative description of functional connectivity graphs using graph attributes is of great interest to neuroscience, and has led to remarkable insights in the field. However, the statistical techniques used have generally been limited to whole-group, post-hoc studies. In this paper, we propose instead a novel approach to perform predictive inference on single subjects. It is based on a lossy embedding of connectivity graphs into a vector space using graph and vertex attributes, followed by the use of statistical machine learning to build a predictive model. The feature space proposed is easily interpretable for neuroscientists, and we illustrate the technique by revealing resting-state difference between young and elderly subjects.","","Electronic:978-0-7695-4399-4; POD:978-1-4577-0111-5","10.1109/PRNI.2011.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5961317","connectivity decoding;graph attributes;graph embedding","Accuracy;Correlation;Lead;Machine learning;Radio frequency;Support vector machine classification","graph theory;inference mechanisms;learning (artificial intelligence);neurophysiology;statistical analysis","functional connectivity graphs;graph attributes;neuroscience;predictive inference;resting state difference;statistical machine learning;vertex attributes","","2","1","15","","","16-18 May 2011","","IEEE","IEEE Conference Publications"
"Learning banknote fitness for sorting","J. M. Geusebroek; P. Markus; P. Balke","Informatics Institute, University of Amsterdam, The Netherlands","2011 International Conference on Pattern Analysis and Intelligence Robotics","20110804","2011","1","","41","46","In this work, a machine learning method is proposed for banknote soiling determination. We apply proven techniques from computer vision to come up with a robust and effective method for automatic sorting of banknotes. The proposed method is evaluated with respect to various invariance classes. The method shows excellent performance on a large validation set of over 8,000 banknotes from the Eurosystem, while being learned on only 300 banknotes per denomination.","","Electronic:978-1-61284-406-0; POD:978-1-61284-407-7","10.1109/ICPAIR.2011.5976909","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5976909","","Color;Feature extraction;Image color analysis;Machine learning;Pixel;Printing;Training","bank data processing;computer vision;learning (artificial intelligence)","automatic sorting;banknote fitness;banknote soiling determination;banknote sorting;computer vision;machine learning","","1","","7","","","28-29 June 2011","","IEEE","IEEE Conference Publications"
"Research on the categorization accuracy of different similarity measures on Chinese texts","X. Li; H. Liu; H. Jia; L. Huang","The School of Information Management, Wuhan University, 430072, China","2011 International Conference on Business Management and Electronic Information","20110623","2011","4","","224","227","This paper works on the most intensively studied algorithm- k Nearest Neighbor algorithm. The purpose is to investigate the performance of different similarity measures in the kNN on Chinese texts. The two measures that we focus on are cosine value and Jensen-Shannon Divergence. We use both the corpus collected from the Sogou, whose data extracts from the website of Sohu.com, and datasets that we have processed from real word. The results of our experiment indicate that difference of similarity metrics significantly affects the categorization accuracy.","","Electronic:978-1-61284-109-0; POD:978-1-61284-108-3","10.1109/ICBMEI.2011.5920956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5920956","Chinese text categorization;KNN algorithm;Similarity;Sougou Corpus","Accuracy;Classification algorithms;Entropy;Libraries;Machine learning algorithms;Support vector machine classification;Text categorization","Web sites;natural language processing;text analysis","Chinese texts;Jensen-Shannon divergence;Sogou;Sohu.com;Web site;categorization accuracy;cosine value;k-nearest neighbor algorithm;similarity measure","","1","","23","","","13-15 May 2011","","IEEE","IEEE Conference Publications"
"Nonparametric Bayesian feature selection for multi-task learning","H. Li; X. Liao; L. Carin","Signal Innovations Group, Inc., Durham, NC 27703, USA","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","2236","2239","We present a nonparametric Bayesian model for multi-task learning, with a focus on feature selection in binary classification. The model jointly identifies groups of similar tasks and selects the subset of features relevant to the tasks within each group. The model employs a Dirchlet process with a beta Bernoulli hierarchical base measure. The posterior inference is accomplished efficiently using a Gibbs sampler. Experimental results are presented on simulated as well as real data.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946926","","Bayesian methods;Equations;Indexes;Machine learning;Mathematical model;Monte Carlo methods;Training","Bayes methods;learning (artificial intelligence);pattern classification","Dirchlet process;Gibbs sampler;beta-Bernoulli hierarchical base measure;multitask learning;nonparametric Bayesian feature selection;posterior inference","","0","","11","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Multi-class least squares classification at binary-classification complexity","Z. Noumir; P. Honeine; C. Richard","Institut Charles Delaunay (CNRS), LM2S, Universit&#x00E9; de technologie de Troyes, 10010 Troyes, France","2011 IEEE Statistical Signal Processing Workshop (SSP)","20110728","2011","","","277","280","This paper deals with multi-class classification problems. Many methods extend binary classifiers to operate a multi-class task, with strategies such as the one-vs-one and the one-vs-all schemes. However, the computational cost of such techniques is highly dependent on the number of available classes. We present a method for multi-class classification, with a computational complexity essentially independent of the number of classes. To this end, we exploit recent developments in multifunctional optimization in machine learning. We show that in the proposed algorithm, labels only appear in terms of inner products, in the same way as input data emerge as inner products in kernel machines via the so-called the kernel trick. Experimental results on real data show that the proposed method reduces efficiently the computational time of the classification task without sacrificing its generalization ability.","2373-0803;23730803","Electronic:978-1-4577-0570-0; POD:978-1-4577-0569-4","10.1109/SSP.2011.5967680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967680","","Complexity theory;Hyperspectral imaging;Kernel;Machine learning;Optimization;Training data","computational complexity;learning (artificial intelligence);least mean squares methods;optimisation;pattern classification","binary-classification complexity;computational complexity;kernel machine;kernel trick;machine learning;multiclass least squares classification;multifunctional optimization","","1","1","13","","","28-30 June 2011","","IEEE","IEEE Conference Publications"
"A data driven rule-base inference approach for classification systems","Shuwei Chen; J. Liu; Hui Wang; J. C. Augusto","School of Computing and Mathematics, University of Ulster at Jordanstown, Newtownabbey, Northern Ireland, UK","2011 IEEE 2nd International Conference on Software Engineering and Service Science","20110811","2011","","","78","81","This paper proposes a generic data driven inference methodology for rule-based classification systems. The generic rule base is in a belief rule base structure, where the consequent of a rule takes the belief distribution form. Other knowledge representation parameters such as the weights of both input attributes and rules are also considered in this framework. In an established rule base, the matching degree of an input between the antecedents of a rule is firstly computed to get the activation weight for the rule. Then a weighted aggregation of the consequents of activated rules is used for the inference process. Two numerical examples are provided to illustrate the proposed method.","2327-0586;23270586","Electronic:978-1-4244-9698-3; POD:978-1-4244-9699-0","10.1109/ICSESS.2011.5982259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5982259","Rule-based systems;aggregation;belief distribution;classification;data driven","Accuracy;Data mining;Feature extraction;Impedance matching;Iris;Machine learning;Pragmatics","inference mechanisms;knowledge based systems;knowledge representation;pattern classification","belief distribution;belief rule base structure;data driven rule-base inference approach;generic rule base;knowledge representation;rule-based classification systems","","1","","10","","","15-17 July 2011","","IEEE","IEEE Conference Publications"
"Assessment of ADHD through a Computer Game: An Experiment with a Sample of Students","F. E. G. Santos; A. P. Z. Bastos; L. C. V. Andrade; K. Revoredo; P. Mattos","Programa de Pos-Graducao em Inf., Univ. Fed. do Estado do Rio de Janeiro UNIRIO, Rio de Janeiro, Brazil","2011 Third International Conference on Games and Virtual Worlds for Serious Applications","20110728","2011","","","104","111","In this paper we argue that through a computer game named Supermarket Game it is possible to perform a test that can aid in the diagnosis of Attention Deficit Hyperactivity Disorder (ADHD). OBJECTIVE: To evaluate the predictive capability of the game to detect ADHD cases through the analysis of its data by data mining techniques. METHOD: Eighty children, classified by teachers according to the DSM-IV symptoms, participated in a playing session with the Supermarket Game. The game captured a features set from each player: Gender, age, points (from eighteen stages) and time (from eighteen stages). Two data mining algorithms were used to classify the data produced by the game according to the disorder: naive Bayes and decision tree. Four hypotheses about the best data configuration were proposed: Numerical attributes with four classes, categorical attributes with four classes, categorical attributes with two classes and attribute selection. The performance metrics used to evaluate the prediction models were sensitivity and specificity. RESULTS: The data analysis with numerical attributes doesn't produce good results. With categorical attributes, an improvement in the decision tree performance was observed. With two classes (i.e. without considering ADHD subtypes) both algorithms achieve good results. The best results were obtained by the attribute selection technique, although this approach should be considered with caution. CONCLUSION: The Supermarket Game seems to be sensitive in the task of identifying children classified as ADHD positive by the teacher, although its capability to classify the disorder subtypes is weak. In future works, other samples of individuals (including from other age groups), and other data mining algorithms should be considered in order to validate this approach.","","Electronic:978-0-7695-4419-9; POD:978-1-4577-0316-4","10.1109/VS-GAMES.2011.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5962092","ADHD;decision tree;naive bayes;serious game","Decision trees;Educational institutions;Games;Machine learning;Predictive models;Sensitivity","computer games;data analysis;data mining;decision trees;psychology","ADHD assessment;DSM-IV symptoms;attention deficit hyperactivity disorder;computer game;data analysis;data mining;decision tree;naive Bayes;prediction models;supermarket game","","1","","28","","","4-6 May 2011","","IEEE","IEEE Conference Publications"
"Performance based pruning and weighted voting with classification ensembles","M. F. Amasyali; O. Ersoy","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Y&#x0131;ld&#x0131;z Teknik &#x00FC;niversitesi, Turkey","2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU)","20110623","2011","","","194","197","Ensemble algorithms have been a very popular research topic because of their high performances. In this work, performance based ensemble pruning and decision weighting methods are investigated on 3 ensemble algorithms (Bagging, Random Subspaces, Random Forest) over 26 classification datasets. According to our experiments; the algorithm including most diversity among its base learners is Random Subspaces. The best performed ensemble algorithm is Random Subspaces with decision weighting.","2165-0608;21650608","Electronic:978-1-4577-0463-5; POD:978-1-4577-0462-8","10.1109/SIU.2011.5929620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929620","","Bagging;Classification algorithms;Conferences;Machine learning;Presses;Signal processing;Signal processing algorithms","decision theory;learning (artificial intelligence);pattern classification","classification ensemble algorithm;decision weighting method;performance based pruning;random subspace;weighted voting","","0","","11","","","20-22 April 2011","","IEEE","IEEE Conference Publications"
"Shop marketing scenario using context based digital personality","S. Biroğul; E. Küçükayvaz; Ö. M. Erol","Caretta Software & Consultancy","2011 International Symposium on Innovations in Intelligent Systems and Applications","20110711","2011","","","536","539","The goal of the CBDP project is to create a platform for the Digital Personality management. The concept of Digital Personality refers to the capacity to capture the user's personality in a digital way. The digital personality depends on the context of its application. This means that the user's preferences, sensors, actuators are different from application domain to application domain. The CBDP project defines different application contexts such as SmartHome, SmartTV, Shop-Marketing, M-Learning. In this paper shop-marketing scenario is defined how to implement into the CBDP framework.","","Electronic:978-1-61284-922-5; POD:978-1-61284-919-5","10.1109/INISTA.2011.5946163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946163","CBDP (Context Based Digital Personality);Ontology;Recommandation Algorithm;Shop-Marketing","Bluetooth;Cognition;Context;Engines;Machine learning;Ontologies;Servers","marketing;ubiquitous computing;user interfaces","CBDP project;context based digital personality;shop marketing;user personality","","0","","7","","","15-18 June 2011","","IEEE","IEEE Conference Publications"
"Bearings fault detection based on semi-supervised SVM Laplacian regularization","X. Tao; S. Song; F. Liu; P. Cao","College of Information and Communication Engineering, Harbin Engineering University, 150001, China","Proceedings of the 30th Chinese Control Conference","20110825","2011","","","4270","4274","In bearings fault detection application, To solve the problems of difficultly obtaining labeled samples and exploiting a large amount of unlabeled samples, a novel semi-supervised Support vector machine fault detection model based on Laplacian regularization is presented in this paper. A smoothness penalty is introduced into the optimization function of regularization network which can exploit the clustering and manifold information of unlabeled samples. The comparisons with other Support vector machine,Fuzzy Support vector machine and Transductive Support vector machine fault detection algorithm are performed. The experiments show that the proposed approach can efficiently utilize the information provided by unlabeled samples to improve the performance of fault detection with labeled training samples of different sizes. The proposed fault detection methods with test samples and without test samples are compared. The results illustrate the investigated techniques with test samples as unlabeled samples can outperform the one without test samples as unlabeled samples.","1934-1768;19341768","Electronic:978-988-17255-9-2; POD:978-1-4577-0677-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6001186","Fault Detection;Laplacian;Regularization;Semi-supervised","Educational institutions;Electronic mail;Fault detection;Laplace equations;Machine learning;Manifolds;Support vector machines","ball bearings;fault diagnosis;fuzzy set theory;mechanical engineering computing;optimisation;support vector machines","bearings fault detection;fault detection methods;fuzzy support vector machine;labeled training samples;manifold information;optimization function;regularization network;semisupervised SVM Laplacian regularization;semisupervised support vector machine fault detection model;smoothness penalty;transductive support vector machine fault detection algorithm;unlabeled samples","","0","","6","","","22-24 July 2011","","IEEE","IEEE Conference Publications"
"A study on Genetic Programming with layered learning and incremental sampling","N. T. Hien; N. X. Hoai; B. McKay","Le Quy Don University, 100 Hoang Quoc Viet St, Hanoi, Vietnam","2011 IEEE Congress of Evolutionary Computation (CEC)","20110714","2011","","","1179","1185","In this paper, we investigate the impact of a layered learning approach with incremental sampling on Genetic Programming (GP). The new system, called GPLL, is tested and compared with standard GP on twelve symbolic regression problems. While GPLL does not differ from standard GP on univariate target functions, it has better training efficiency on problems with bivariate targets. This indicates the potential usefulness of layered learning with incremental sampling in improving the efficiency of GP evolutionary learning.","1089-778X;1089778X","Electronic:978-1-4244-7835-4; POD:978-1-4244-7834-7","10.1109/CEC.2011.5949750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949750","","Accuracy;Genetic programming;Machine learning;Robustness;Testing;Training;Training data","genetic algorithms;learning (artificial intelligence);regression analysis","GP evolutionary learning;genetic programming;incremental sampling;layered learning;symbolic regression problem;univariate target function","","3","","27","","","5-8 June 2011","","IEEE","IEEE Conference Publications"
"Bess or xbest: Mining the Malaysian online reviews","N. Samsudin; M. Puteh; A. R. Hamdan","Faculty of Computer and Mathematical Science, Universiti Teknologi MARA Terengganu, Dungun, 23000, Malaysia","2011 3rd Conference on Data Mining and Optimization (DMO)","20110804","2011","","","38","43","Advancement in information and technology facilities especially the Internet has changed the way we communicate and express opinions or sentiments on services or products that we consume. Opinion mining aims to automate the process of mining opinions into the positive or the negative views. It will benefit both the customers and the sellers in identifying the best product or service. Although there are researchers that explore new techniques of identifying the sentiment polarization, few works have been done on opinion mining created by the Malaysian reviewers. The same scenario happens to micro-text. Therefore in this study, we conduct an exploratory research on opinion mining of online movie reviews collected from several forums and blogs written by the Malaysian. The experiment data are tested using machine learning classifiers i.e. Support VectorMachine, Naïve Baiyes and k-Nearest Neighbor. The result illustrates that the performance of these machine learning techniques without any preprocessing of the micro-texts or feature selection is quite low. Therefore additional steps are required in order to mine the opinions from these data.","2155-6938;21556938","Electronic:978-1-61284-212-7; POD:978-1-61284-211-0","10.1109/DMO.2011.5976502","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5976502","Malaysian;Sentiment mining;movie reviews;opinion mining","Data mining;Machine learning;Motion pictures;Niobium;Noise measurement;Semantics;Support vector machines","Internet;data mining;learning (artificial intelligence);reviews;text analysis","Internet;Malaysian online reviews;machine learning classifiers;micro-text;online movie reviews;opinion mining","","1","","24","","","28-29 June 2011","","IEEE","IEEE Conference Publications"
"An incremental spam detection algorithm","E. Ghanbari; H. Beigy","Department of Computer Engineering, Sharif University of Technology, Tehran, Iran","2011 International Symposium on Artificial Intelligence and Signal Processing (AISP)","20110725","2011","","","31","36","The voluminous of the e-mails are spam. Several algorithms are represented for spam detection based on batch learning. In this paper, a new algorithm based on incremental learning is introduced. The algorithm composes new knowledge from new training data with previous knowledge by combining classifiers based on weighted majority voting. The experiment results show that the proposed algorithm outperforms other related incremental algorithms and non-incremental algorithms.","","Electronic:978-1-4244-9834-5; POD:978-1-4244-9833-8","10.1109/AISP.2011.5960991","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5960991","Spam Detection;ensemble learning;incremental learning","Accuracy;Algorithm design and analysis;Classification algorithms;Electronic mail;Machine learning algorithms;Training;Training data","learning (artificial intelligence);security of data;unsolicited e-mail","batch learning;e-mails;incremental learning;incremental spam detection algorithm;non incremental algorithms;training data;weighted majority voting","","1","","19","","","15-16 June 2011","","IEEE","IEEE Conference Publications"
"An unsupervised center sentence-based clustering approach for rule-based question answering","S. Song; Y. N. Cheah","MIMOS Berhad, Technology Park Malaysia, 57000 Kuala Lumpur, Malaysia","2011 IEEE Symposium on Computers & Informatics","20110721","2011","","","125","129","Question answering (QA) systems have widely employed clustering methods to improve efficiency. However, QA systems with unsupervised automatic statistical processing do not seem to achieve higher accuracies than other approaches. Therefore, with the motivation of obtaining optimal accuracy of retrieved answers under unsupervised automatic processing of sentences, we introduce a syntactic sequence clustering method for answer matching in rule-based QA. Our clustering method called CEnter SEntence-baseD (CESED) Clustering is able to achieve accuracies as high as 84.62% for WHERE-type questions.","","Electronic:978-1-61284-691-0; POD:978-1-61284-689-7","10.1109/ISCI.2011.5958896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5958896","clustering;question answering;structural rule generation","Accuracy;Clustering methods;Machine learning;Natural language processing;Seals;Testing;Training","knowledge based systems;pattern clustering;question answering (information retrieval);statistical analysis;unsupervised learning","CESED;QA systems;answer matching;rule-based question answering;syntactic sequence clustering method;unsupervised automatic statistical processing;unsupervised center sentence-based clustering approach","","0","","17","","","20-23 March 2011","","IEEE","IEEE Conference Publications"
"A novel prediction modeling scheme based on multiple information fusion for day-ahead electricity price","H. Tian; K. Li; B. Meng","Electrical Engineering and Automation Department, Tianjin Polytechnic University, Tianjin, China","2011 Chinese Control and Decision Conference (CCDC)","20110801","2011","","","1801","1805","On the basis of the information fusion idea, a novel multiple information fusion modeling method is proposed. Several artificial neural networks are used to fuse the information of data. And then the results of information fusion by ANNs will be fused again according to their performance. Using the novel multiple information fusion scheme, a new modeling approach is presented to establish the prediction model. The day-ahead electricity price prediction model is tested by the real data. The experiments demonstrate that the new prediction model established by multiple information fusion method has better performance.","1948-9439;19489439","Electronic:978-1-4244-8738-7; POD:978-1-4244-8737-0","10.1109/CCDC.2011.5968490","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5968490","Multiple information fusion;artificial neural network;electricity price;prediction model","Artificial neural networks;Data models;Electricity;Machine learning;Power markets;Prediction algorithms;Predictive models","neural nets;power engineering computing;power markets;sensor fusion","artificial neural networks;day-ahead electricity price;multiple information fusion modeling method;prediction modeling scheme","","0","","18","","","23-25 May 2011","","IEEE","IEEE Conference Publications"
"Improving Scheduling Techniques in Heterogeneous Systems with Dynamic, On-Line Optimisations","M. Bogdanski; P. R. Lewis; T. Becker; X. Yao","Sch. of Comput. Sci., Univ. of Birmingham, Birmingham, UK","2011 International Conference on Complex, Intelligent, and Software Intensive Systems","20110818","2011","","","496","501","Computational performance increasingly depends on parallelism, and many systems rely on heterogeneous resources such as GPUs and FPGAs to accelerate computationally intensive applications. However, implementations for such heterogeneous systems are often hand-crafted and optimised to one computation scenario, and it can be challenging to maintain high performance when application parameters change. In this paper, we demonstrate that machine learning can help to dynamically choose parameters for task scheduling and load-balancing based on changing characteristics of the incoming workload. We use a financial option pricing application as a case study. We propose a simulation of processing financial tasks on a heterogeneous system with GPUs and FPGAs, and show how dynamic, on-line optimisations could improve such a system. We compare on-line and batch processing algorithms, and we also consider cases with no dynamic optimisations.","","Electronic:978-0-7695-4373-4; POD:978-1-61284-709-2","10.1109/CISIS.2011.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989059","Artificial Neural Network;Dynamic Optimisation;FPGA;GPU;Genetic Algorithm;Heterogeneous System;On-Line Learning;Scheduling","Estimation;Field programmable gate arrays;Graphics processing unit;Load modeling;Machine learning;Processor scheduling;Schedules","batch processing (computers);learning (artificial intelligence);scheduling","FPGA;GPU;batch processing algorithm;handcrafted;heterogeneous system;load balancing;machine learning;online optimisation;scheduling technique;task scheduling","","1","","17","","","June 30 2011-July 2 2011","","IEEE","IEEE Conference Publications"
"Feature extraction for multi-label learning in the domain of email classification","J. M. Carmona-Cejudo; M. Baena-García; J. d. Campo-Avila; R. Morales-Bueno","Departamento de Lenguajes y Ciencias de la Computaci&#x00F3;n, University of M&#x00E1;laga (Spain)","2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)","20110711","2011","","","30","36","Multi-label learning is a very interesting field in Machine Learning. It allows to generalise standard methods and evaluation procedures, and tackle challenging real problems where one example can be tagged with more than one label. In this paper we study the performance of different multi-label methods in combination with standard single-label algorithms, using several specific multi-label metrics. What we want to show is how a good preprocessing phase can improve the performance of such methods and algorithms. As we will explain, its main advantage is a shorter time to induce the models, while keeping (even improving) other classification quality measures. We use the GNUsmail framework to do the preprocessing of an existing and extensively used dataset, to obtain a reduced feature space that conserves the relevant information and allows improvements on performance. Thanks to the capabilities of GNUsmail, the preprocessing step can be easily applied to different email datasets.","","Electronic:978-1-4244-9927-4; POD:978-1-4244-9926-7","10.1109/CIDM.2011.5949301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949301","","Companies;Electronic mail;Feature extraction;Loss measurement;Machine learning;Machine learning algorithms","electronic mail;feature extraction;learning (artificial intelligence)","GNUsmail;email classification;feature extraction;machine learning;multilabel learning;standard single-label algorithm","","1","","26","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"A new sampling technique and SVM classification for feature selection in high-dimensional Imbalanced dataset","T. Deepa; M. Punithavalli","Computer Science Department Karpagam University Coimbatore, Tamilnadu, India","2011 3rd International Conference on Electronics Computer Technology","20110707","2011","5","","395","398","Feature selection in high-dimensional Imbalanced dataset (where one class highly outnumbers the other class) is an exigent task in data mining. Feature selection refers to selecting a subset of features from the original dataset. This paper focus on two problems i) Balancing the dataset ii) extracting the features. A new technique called Evolutionary sampling technique [EST] is developed to balance the dataset and Support Vector Machine [SVM] classification is used to calculate the accuracy and also to overcome the over fitting problem while sampling the dataset. The techniques are evaluated on a micro array dataset.","","Electronic:978-1-4244-8679-3; POD:978-1-4244-8678-6","10.1109/ICECTECH.2011.5942028","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5942028","Evolutionary oversampling and Undersampling;Feature selection;Genetic algorithm;Imbalanced dataset;Support vector machine (SVM)","Cancer;Data mining;Earth Observing System;Feature extraction;Genetic algorithms;Machine learning;Support vector machines","data mining;genetic algorithms;pattern classification;sampling methods;support vector machines","SVM classification;data mining;evolutionary sampling technique;feature selection;imbalanced dataset;microarray dataset;support vector machines","","1","","20","","","8-10 April 2011","","IEEE","IEEE Conference Publications"
"Online learning with minority class resampling","M. J. Pekala; A. J. Llorens","Johns Hopkins University Applied Physics Laboratory, USA","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","2248","2251","This paper considers using online binary classification for target detection where the goal is to identify signals of interest within a sequence of received signals generated by a shifting background. In this setting, we assume there is significant class imbalance (100:1 or greater), the sequence of examples is arbitrarily long and the distribution of the majority (negative) class is slowly time-varying. This setting is typical in detection and classification problems in which time-varying effects are caused by some combination of shifting channel characteristics and interferers that enter and exit the scene. We show empirically that the addition of caching and minority class oversampling to online learners improves the g-means performance under these conditions by compensating for class imbalance.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946929","Support vector machine;class imbalance;classification;online learning","Accuracy;Complexity theory;Kernel;Machine learning;Prediction algorithms;Sensitivity;Training","learning (artificial intelligence);object detection;signal classification","g-means performance;interferers;minority class resampling;online binary classification;online learning;target detection;time-varying","","1","","9","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"MKPM: A multiclass extension to the kernel projection machine","S. Takerkart; L. Ralaivola","Institut de Neurosciences Cognitives de la M&#x00E9;diterran&#x00E9;e. CNRS - Aix-Marseille Universit&#x00E9;, 31, chemin Joseph Aiguier. 13009 Marseille, France","CVPR 2011","20110822","2011","","","2785","2791","We introduce Multiclass Kernel Projection Machines (MKPM), a new formalism that extends the Kernel Projection Machine framework to the multiclass case. Our formulation is based on the use of output codes and it implements a co-regularization scheme by simultaneously constraining the projection dimensions associated with the individual predictors that constitute the global classifier. In order to solve the optimization problem posed by our formulation, we propose an efficient dynamic programming approach. Numerical simulations conducted on a few pattern recognition problems illustrate the soundness of our approach.","1063-6919;10636919","DVD:978-1-4577-0393-5; Electronic:978-1-4577-0395-9; POD:978-1-4577-0394-2","10.1109/CVPR.2011.5995657","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995657","","Dynamic programming;Encoding;Kernel;Machine learning;Minimization;Numerical simulation;Training","dynamic programming;pattern classification","MKPM;dynamic programming approach;multiclass extension;multiclass kernel projection machine;optimization problem;pattern recognition problem","","1","","18","","","20-25 June 2011","","IEEE","IEEE Conference Publications"
"Efficient unsupervised feature selection for sparse data","A. Ferreira; M. Figueiredo","Instituto de Telecomunica&#x00E7;&#x00F5;es, and Instituto Superior de Engenharia de Lisboa, Lisboa, Portugal","2011 IEEE EUROCON - International Conference on Computer as a Tool","20110623","2011","","","1","4","Feature selection and feature reduction are central problems in machine learning and pattern recognition. Many datasets have a sparse nature, that is, many features have zero value. For instance, in text classification based on the bag-of-words (BoW) or similar representations, there is usually a large number of features, many of which may be irrelevant (or even detrimental) for classification tasks. This paper proposes a new unsupervised feature selection method for sparse data, suitable for both standard and binarized representations. The method is applicable to supervised, semi-supervised, and unsupervised learning, since it does not use class labels. The experimental results on standard benchmarks show that the proposed method performs better than existing ones on numeric floating-point and binary feature. It yields efficient feature selection, reducing the number of features while simultaneously improving the classification accuracy.","","Electronic:978-1-4244-7487-5; POD:978-1-4244-7486-8","10.1109/EUROCON.2011.5929185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929185","","Error analysis;Machine learning;Pattern recognition;Silicon;Sparse matrices;Support vector machines;TV","data reduction;learning (artificial intelligence);pattern classification;text analysis","bag-of-words;binary feature;classification tasks;feature reduction;machine learning;numeric floating point;pattern recognition;sparse data;text classification;unsupervised feature selection;unsupervised learning","","1","","14","","","27-29 April 2011","","IEEE","IEEE Conference Publications"
"Support vector machine ensemble based on independent component analysis and fuzzy kernel clustering","Y. Ma; X. Kong; X. Wang","School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu, 221116, China","2011 Chinese Control and Decision Conference (CCDC)","20110801","2011","","","752","755","In order to improve the generalization performance of support vector machine (SVM), a support vector machine ensembling method based on independent component analysis (ICA) and fuzzy kernel clustering (FKC) was proposed. The ICA emphasizes the independence between the data characteristics and can effectively obtain a series of independent features, the performance of single SVM can be improved when the SVM was trained on these independent features; The FKC method uses kernel function to expand the feature space, so that the clustering is more accurate and the diversity between sub-SVMs can also be guaranteed. Simulation results on UCI datasets show that the proposed ensembling method can improve the classification precision of SVM and make the ensemble SVM has better generalization property.","1948-9439;19489439","Electronic:978-1-4244-8738-7; POD:978-1-4244-8737-0","10.1109/CCDC.2011.5968282","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5968282","Ensemble learning;Fuzzy kernel clustering;Independent component analysis;Support vector machine","Accuracy;Artificial neural networks;Feature extraction;Independent component analysis;Kernel;Machine learning;Support vector machines","fuzzy set theory;independent component analysis;learning (artificial intelligence);pattern clustering;support vector machines","FKC method;UCI dataset;classification precision;feature space;fuzzy kernel clustering;independent component analysis;subSVM;support vector machine ensembling method","","0","","13","","","23-25 May 2011","","IEEE","IEEE Conference Publications"
"A DFM Model of Mining Product Features from Customer Reviews","S. Li; M. Ji","Coll. of Inf. & Comput. Eng., Northeast Forestry Univ., Harbin, China","2011 International Conference on Control, Automation and Systems Engineering (CASE)","20110825","2011","","","1","5","With the development of e-business, interactions between enterprise and customer have gone into a new phase which network technology is the core competitiveness. Network customer reviews as an important part of network reputation influent consumers ' purchasing decisions, and bring enterprise digital feedback. This paper studied the theoretical framework which based on products feature mining issues from customer reviews, explored to contract a DFM model to strengthen the product features extraction technology. This theoretical model can help researchers acquire supported valuable data for additional researches including the study of behavioral.","","Electronic:978-1-4577-0860-2; POD:978-1-4577-0859-6","10.1109/ICCASE.2011.5997661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5997661","","Data mining;Data models;Digital cameras;Feature extraction;Internet;Machine learning;Semantics","Internet;consumer behaviour;customer satisfaction;data mining;electronic commerce","Chinese e-commerce;DFM model;Internet;consumer purchasing decision;data function method;e-business;enterprise digital feedback;enterprise-customer interaction;network customer review;network reputation;network technology;product feature extraction;product feature mining","","0","","11","","","30-31 July 2011","","IEEE","IEEE Conference Publications"
"Gravitational search algorithm with heuristic search for clustering problems","A. Hatamlou; S. Abdullah; Z. Othman","Data Mining and Optimisation Research Group (DMO), Center for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, 43600 Bangi, Selangor, Malaysia","2011 3rd Conference on Data Mining and Optimization (DMO)","20110804","2011","","","190","193","In this paper, we present an efficient algorithm for cluster analysis, which is based on gravitational search and a heuristic search algorithm. In the proposed algorithm, called GSA-HS, the gravitational search algorithm is used to find a near optimal solution for clustering problem, and then at the next step a heuristic search algorithm is applied to improve the initial solution by searching around it. Four benchmark datasets are used to evaluate and to compare the performance of the presented algorithm with two other famous clustering algorithms, i.e. K-means and particle swarm optimization algorithm. The results show that the proposed algorithm can find high quality clusters in all the tested datasets.","2155-6938;21556938","Electronic:978-1-61284-212-7; POD:978-1-61284-211-0","10.1109/DMO.2011.5976526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5976526","Cluster analysis;Gravitational search algorithm;Heuristic search","Algorithm design and analysis;Clustering algorithms;Heuristic algorithms;Iris;Machine learning algorithms;Partitioning algorithms;Search problems","particle swarm optimisation;pattern clustering;search problems","GSA-HS;cluster analysis;gravitational search algorithm;heuristic search algorithm;particle swarm optimization algorithm","","7","","6","","","28-29 June 2011","","IEEE","IEEE Conference Publications"
"Active learning for personalizing treatment","K. Deng; J. Pineau; S. Murphy","Department of Statistics, University of Michigan, USA","2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)","20110728","2011","","","32","39","The personalization of treatment via genetic biomarkers and other risk categories has drawn increasing interest among clinical researchers and scientists. A major challenge here is to construct individualized treatment rules (ITR), which recommend the best treatment for each of the different categories of individuals. In general, ITRs can be constructed using data from clinical trials, however these are generally very costly to run. In order to reduce the cost of learning an ITR, we explore active learning techniques designed to carefully decide whom to recruit, and which treatment to assign, throughout the online conduct of the clinical trial. As an initial investigation, we focus on simple ITRs that utilize a small number of subpopulation categories to personalize treatment. To minimize the maximal uncertainty regarding the treatment effects for each subpopulation, we propose the use of a minimax bandit model and provide an active learning policy for solving it. We evaluate our active learning policy using simulated data and data modeled after a clinical trial involving treatments for depressed individuals. We contrast this policy with other plausible active learning policies. The techniques presented in the paper may be generalized to tackle problems of efficient exploration in other domains.","2325-1824;23251824","Electronic:978-1-4244-9888-8; POD:978-1-4244-9887-1","10.1109/ADPRL.2011.5967348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967348","","Clinical trials;Learning systems;Loss measurement;Machine learning;Recruitment;Resource management;Uncertainty","learning (artificial intelligence);medical computing;minimax techniques;patient treatment","active learning;clinical research;genetic biomarkers;individualized treatment rules;minimax bandit model;risk category;treatment personalization","","1","","32","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"An E-SMOTE technique for feature selection in High-Dimensional Imbalanced Dataset","T. Deepa; M. Punithavalli","Computer Science, Karpagam University, Coimbatore, Tamilnadu, India","2011 3rd International Conference on Electronics Computer Technology","20110707","2011","2","","322","324","Feature Selection in High-Dimensional Imbalanced Dataset (where one class outnumbers the other class) plays an imperative task in field of Data mining and Bio-informatics. This paper proposes a new technique called E-SMOTE Technique for balancing the dataset and SVM classification for selecting the features. It is evaluated using micro array dataset.","","Electronic:978-1-4244-8679-3; POD:978-1-4244-8678-6","10.1109/ICECTECH.2011.5941710","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5941710","E-SMOTE;Featue Selection;Imbalanced dataset;Support Vector Machine[SVM]","Bioinformatics;Cancer;Data mining;Feature extraction;Genetic algorithms;Machine learning;Support vector machines","bioinformatics;data mining;pattern classification;support vector machines","E-SMOTE technique;SVM classification;bio-informatics;data mining;dataset balancing;feature selection;high-dimensional imbalanced dataset;micro array dataset","","2","","20","","","8-10 April 2011","","IEEE","IEEE Conference Publications"
"Least-squares LDA via rank-one updates with concept drift","Y. R. Yeh; Y. C. F. Wang","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan, 11529","2011 IEEE Statistical Signal Processing Workshop (SSP)","20110728","2011","","","261","264","Standard linear discriminant analysis (LDA) is known to be computationally expensive due to the need to perform eigen-analysis. Based on the recent success of least-squares LDA (LSLDA), we propose a novel rank-one update method for LSLDA, which not only alleviates the computation and memory requirements, and is also able to solve the adaptive learning task of concept drift. In other words, our proposed LSLDA can efficiently capture the information from recently received data with gradual or abrupt changes in distribution. Moreover, our LSLDA can be extended to recognize data with newly-added class labels during the learning process, and thus exhibits excellent scalability. Experimental results on both synthetic and real datasets confirm the effectiveness of our propose method.","2373-0803;23730803","Electronic:978-1-4577-0570-0; POD:978-1-4577-0569-4","10.1109/SSP.2011.5967676","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967676","Linear discriminant analysis;concept drift;least squares solution;rank-one update","Conferences;Covariance matrix;Data mining;Data models;Linear discriminant analysis;Machine learning;Training data","data handling;learning (artificial intelligence);least squares approximations","adaptive learning task;concept drift;learning process;least-squares LDA;rank-one update method;standard linear discriminant analysis","","0","","10","","","28-30 June 2011","","IEEE","IEEE Conference Publications"
"Genetic optimization and hierarchical clustering applied to encrypted traffic identification","C. Bacquet; A. N. Zincir-Heywood; M. I. Heywood","Faculty of Computer Science, Dalhousie University, 6050 University Avenue, Halifax NS, Canada","2011 IEEE Symposium on Computational Intelligence in Cyber Security (CICS)","20110711","2011","","","194","201","An important part of network management requires the accurate identification and classification of network traffic for decisions regarding bandwidth management, quality of service, and security. This work explores the use of a Multi-Objective Genetic Algorithm (MOGA) for both, feature selection and cluster count optimization, for an unsupervised machine learning technique, K-Means, applied to encrypted traffic identification. Specifically, a hierarchical K-Means algorithm is employed, comparing its performance to the MOGA with a non-hierarchical (flat) K-Means algorithm. The latter has already been benchmarked against common unsupervised techniques found in the literature, where results have favored the proposed MOGA. The purpose of this paper is to explore the gains, if any, obtained by increasing cluster purity in the proposed model by means of a second layer of clusters. In this work, SSH is chosen as an example of an encrypted application. However, nothing prevents the proposed model to work with other types of encrypted traffic, such as SSL or Skype. Results show that with the hierarchical MOGA, significant gains are observed in terms of the classification performance of the system.","","Electronic:978-1-4244-9906-9; POD:978-1-4244-9905-2","10.1109/CICYBS.2011.5949391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949391","","Accuracy;Clustering algorithms;Cryptography;Genetic algorithms;Machine learning;Optimization;Payloads","genetic algorithms;pattern clustering;quality of service;telecommunication computing;telecommunication network management;telecommunication traffic;unsupervised learning","QoS;SSL;Skype;bandwidth management;cluster count optimization;encrypted traffic identification;feature selection;hierarchical clustering;k-means algorithm;multiobjective genetic algorithm;network management;network traffic;quality of service;unsupervised machine learning","","7","","26","","","11-15 April 2011","","IEEE","IEEE Conference Publications"
"An Internet Traffic Classification Method Based on Semi-Supervised Support Vector Machine","X. Li; F. Qi; D. Xu; X. s. Qiu","State Key Lab. of Networking & Switching Technol., Beijing Univ. of Posts & Telecommun., Beijing, China","2011 IEEE International Conference on Communications (ICC)","20110728","2011","","","1","5","Identifying and classifying different network applications is very important for trend analysis, dynamic access control, network security and traffic engineering, while traffic classification is able to classify applications effectively. Current popular methods of traffic classification mainly include machine learning algorithm based on supervised or unsupervised and the method based load. In practical applications, the above methods have high complexity or low accuracy degree, so we propose a semi-supervised support vector machine method only based on flow statistics to identify and classify network applications. In this method, SVM, ""constant"" flow and co-training algorithm are the key core to obtain a classifier rapidly. The classifier got by this method has three advantages contrast to the previous classical methods: 1) high classification degree; 2) high generalization performance; 3) rapid computational performance. As a proof of concept, we implement the classification algorithm based on open-resource, and show the characteristics and feasibility of our method in the campus and resident network.","1550-3607;15503607","Electronic:978-1-61284-233-2; POD:978-1-61284-232-5","10.1109/icc.2011.5962736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5962736","","Accuracy;Classification algorithms;Clustering algorithms;Machine learning;Machine learning algorithms;Support vector machines;Training","Internet;computer network security;pattern classification;statistical analysis;support vector machines;telecommunication traffic;unsupervised learning","Internet traffic classification method;cotraining algorithm;dynamic access control;flow statistics;machine learning algorithm;network security;semisupervised support vector machine;traffic engineering","","6","","21","","","5-9 June 2011","","IEEE","IEEE Conference Publications"
"Grid Global Behavior Prediction","J. Montes; A. S´nchez; M. S. Pérez","CeSViMa, Univ. Politec. de Madrid, Madrid, Spain","2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","20110711","2011","","","124","133","Complexity has always been one of the most important issues in distributed computing. From the first clusters to grid and now cloud computing, dealing correctly and efficiently with system complexity is the key to taking technology a step further. In this sense, global behavior modeling is an innovative methodology aimed at understanding the grid behavior. The main objective of this methodology is to synthesize the grid's vast, heterogeneous nature into a simple but powerful behavior model, represented in the form of a single, abstract entity, with a global state. Global behavior modeling has proved to be very useful in effectively managing grid complexity but, in many cases, deeper knowledge is needed. It generates a descriptive model that could be greatly improved if extended not only to explain behavior, but also to predict it. In this paper we present a prediction methodology whose objective is to define the techniques needed to create global behavior prediction models for grid systems. This global behavior prediction can benefit grid management, specially in areas such as fault tolerance or job scheduling. The paper presents experimental results obtained in real scenarios in order to validate this approach.","","Electronic:978-0-7695-4395-6; POD:978-1-4577-0129-0","10.1109/CCGrid.2011.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948603","behavior prediction;grid","Accuracy;Data models;Machine learning algorithms;Monitoring;Predictive models;Time series analysis;Training data","cloud computing;grid computing","cloud computing;distributed computing;grid complexity;grid global behavior prediction;grid management;system complexity","","4","","30","","","23-26 May 2011","","IEEE","IEEE Conference Publications"
"Skewness balancing algorithm for approximation of discrete objects boundaries","Y. M. Belkhouche; B. P. Buckles","University of North Texas, Department of Computer Science and Engineering, USA","2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis","20110801","2011","","","70","74","Object boundary is an important feature for image processing and computer vision applications. In this paper a new method for extracting the non convex boundaries of an object represented by 2D point clouds is established. In order to determine the object boundaries we started by constructing the convex-hull-based Delaunay triangulation using the point clouds. Given the fact that the points are sampled from the object surface using an instrument such as cameras or laser scanners, the distribution of the edges lengths belonging to the objects follows a Gaussian distribution. However this distribution is skewed due to the existence of long edges introduced by the Delaunay triangulation. Removing the skewness will make the convex boundary built by the Delauny algorithm converge to the real boundary of the object. We tested our method using different datasets that includes synthetic data, urban LiDAR (Light Detection and Ranging) data, and binary images. The results show that the proposed method successfully extracts the object boundary.","","Electronic:978-1-4577-1286-9; POD:978-1-4577-1284-5","10.1109/IVMSPW.2011.5970357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5970357","Boundary extraction;Delaunay triangulation;objects representation;skewness balancing","Buildings;Gaussian distribution;Histograms;Image edge detection;Laser radar;Machine learning;Shape","Gaussian distribution;computer vision;feature extraction","2D point clouds;Gaussian distribution;LIDAR;cameras;computer vision;convex-hull-based Delaunay triangulation;discrete objects boundary;feature extraction;image processing;laser scanners;skewness balancing algorithm","","0","","13","","","16-17 June 2011","","IEEE","IEEE Conference Publications"
"A method based on clustering to mine rules","Yijie Dun; Chunyan Jiang","Mathematics and computer science institute, northwest university for nationalities, Lanzhou, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","3810","3813","This paper makes use of knowledge granular to present a new method to mine rules based on granule. First, use the measure to measure the importance of attribute, and get the granularity of the universe, and then repeat this procedure to every granule of the granularity, until the decision attribute has only one value for all granules, then we will describe every granule to get the rule. The analysis of the algorithm and the experiment show that the method presented is effective and reliable.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5974605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974605","Classification Rule;Granularity;Knowledge Discover;clustering","Clustering algorithms;Computer science;Data mining;Decision trees;Machine learning;Presses","data mining;granular computing;pattern clustering","clustering method;decision attribute;knowledge granular;mine rules","","0","","8","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"Bioprocess soft sensing based on multiple kernel support vector machine","C. Jinling; W. Xianfang","School of Computer and Information Technology, Henan Normal University, Xinxiang, P.R. China 453007","2011 Chinese Control and Decision Conference (CCDC)","20110801","2011","","","3984","3988","Soft sensing technology is one of the topics of general interest in study on current process control, which has recently drawn considerable attention worldwide, and has stimulated researchers and engineers to make greater effort to reduce the cost/benefit-ratio for development and manufacture of bio-industrial processes both economically and environmentally. This paper introduced a kind of soft-sensor based on an improved support vector machine (SVM) for a polyacrylonitrile productive process. The improved SVM called the multiple kernel support vector machine was presented, and the mathematical formulation of multiple kernel learning is given. Through the implementation for average molecular weight in polyacrylonitrile productive process, it demonstrates the good performance of the proposed method compared to single kernel.","1948-9439;19489439","Electronic:978-1-4244-8738-7; POD:978-1-4244-8737-0","10.1109/CCDC.2011.5968918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5968918","Bioprocess;Kernel function;Soft sensing;Support vector machine","Artificial neural networks;Biological system modeling;Kernel;Machine learning;Polynomials;Process control;Support vector machines","biosensors;biotechnology;process control;support vector machines","average molecular weight;bioprocess soft sensing;mathematical formulation;multiple kernel learning;multiple kernel support vector machine;polyacrylonitrile productive process;process control;soft sensor;stimulated research","","0","","19","","","23-25 May 2011","","IEEE","IEEE Conference Publications"
"Scaling k-medoid algorithm for clustering large categorical dataset and its performance analysis","R. Joshi; A. Patidar; S. Mishra","MCA, MITM, INDORE, India","2011 3rd International Conference on Electronics Computer Technology","20110707","2011","2","","117","121","Scalable data mining algorithms have become crucial to efficiently support KDD processes on large datasets. The k-medoid is one of the partitioning algorithms used for the purpose of clustering. We show that basic k-medoid algorithm is very much time consuming for large dataset. Instead we present the advanced algorithm which performs much better than known algorithm. In addition to presenting detailed experimental results for advanced k-medoid algorithm, we also conduct an experimental study with real life data sets to demonstrate the effectiveness of our technique. We address the task of scaling up k-medoids based algorithm through the utilization of memoization technique. Experimental results based on several datasets, including synthetic and real data, show that the proposed algorithm may reduce the number of distance calculations by a factor of more lhan a thousand limes when compared to existing algorithms while producing clusters of comparable quality.","","Electronic:978-1-4244-8679-3; POD:978-1-4244-8678-6","10.1109/ICECTECH.2011.5941667","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5941667","Categorical Dataset;Clustering;K-medoid;Memoization","Algorithm design and analysis;Clustering algorithms;Complexity theory;Data mining;Indexes;Machine learning algorithms;Partitioning algorithms","data mining;optimisation;pattern clustering","KDD process;categorical dataset clustering;k-medoid algorithm;memoization technique;partitioning algorithm;scalable data mining algorithm","","1","","7","","","8-10 April 2011","","IEEE","IEEE Conference Publications"
"Decoupling control based on support machines ath-order inversion for the boiler-turbine coordinate systems","Z. l. Liu; E. h. Zheng; J. Sun; L. Chen","China Jiliang University, Hangzhou, CO 310018 P. R. China","2011 Chinese Control and Decision Conference (CCDC)","20110801","2011","","","2620","2623","A boiler-turbine unit is a typical multi-input multi-output (MIMO) industrial control system in power plant, which has nonlinear and couple characteristics. As there exist strong couplings between main steam pressure and power output, we present a new coordinated control strategy: ath-order inverse system method based on Support Vector Machine (SVM). Cascading SVM inversion with the original system can form a pseudo-linear system. Then we can solve the problem of nonlinear system by the traditional linear system methods. Simulations show that this strategy has good control performance and can be implanted for engineering.","1948-9439;19489439","Electronic:978-1-4244-8738-7; POD:978-1-4244-8737-0","10.1109/CCDC.2011.5968653","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5968653","Support vector machines;boiler-turbine;decoupling;inverse system method","Control systems;Couplings;Interconnected systems;MIMO;Machine learning;Mathematical model;Support vector machines","MIMO systems;boilers;control engineering computing;industrial control;support vector machines;turbines","ath-order inverse system method;boiler-turbine coordinate systems;boiler-turbine unit;decoupling control;main steam pressure;multiinput multioutput industrial control system;nonlinear system;power output;power plant;pseudolinear system;support machines ath-order inversion;support vector machine","","2","","14","","","23-25 May 2011","","IEEE","IEEE Conference Publications"
