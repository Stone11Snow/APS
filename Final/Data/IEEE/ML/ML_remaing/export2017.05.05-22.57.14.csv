"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5495015,5495325,5495025,5495605,5497525,5495695,5495065,5495673,5495916,5495097,5495918,5497761,5494932,5495125,5497480,5495551,5494936,5497607,5495085,5495344,5495365,5495703,5494337,5497314,5495887,5497472,5495368,5497346,5495127,5496275,5497596,5494961,5495183,5497618,5496450,5492116,5491886,5493466,5490318,5490138,5490356,5490375,5491291,5490091,5489593,5489509,5485698,5485818,5485910,5485948,5488258,5486811,5486345,5485512,5439692,5488459,5485366,5485271,5486939,5485294,5488305,5486563,5487186,5486837,5486622,5486170,5486331,5486640,5485404,5485316,5486679,5486650,5486241,5486654,5484762,5483745,5484181,5484732,5484800,5484821,5483527,5482727,5481587,5480503,5481797,5480757,5481180,5481228,5481227,5481231,5482296,5481940,5477875,5476537,5478287,5478964,5477905,5478054,5477048,5477817",2017/05/05 22:57:14
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A hierarchical reinforcement learning algorithm based on heuristic reward function","Qicui Yan; Quan Liu; Daojing Hu","School of Computer Science and Technology, Soochow University, Suzhou, Jiangsu, 215006, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","3","","371","376","A hierarchical reinforcement learning method based on heuristic reward function is proposed to solve the problem of “curse of dimensionality”, that is the states space will grow exponentially in the number of features, and low convergence speed. The method can reduce state spaces greatly and can enhance the speed of the study. Choose actions with favorable purpose and efficiency so as to optimize reward function and enhance convergence speed. Apply this method to the Tetris game; the experiment result shows that the method can partly solve the “curse of dimensionality” and can enhance the convergence speed prominent.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486837","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486837","Tetris;curse of dimensionality;heuristic reward function;hierarchical reinforcement learning","Computer science;Control theory;Convergence;Function approximation;Heuristic algorithms;Learning systems;Machine learning;Space technology;State-space methods;Statistics","computer games;convergence;learning (artificial intelligence);optimisation","Tetris game;convergence speed;dimensionality curse;heuristic reward function;hierarchical reinforcement learning algorithm;reward function optimization","","0","","11","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"An improved adaptive Support Vector Machine algorithm with combinational fuzzy C-means clustering","Jun Li; Zhiyu Yu","College of Computer Science, Sichuan University, Chengdu 610065, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","3","","269","272","In order to improve the training efficiency to the data set, an improved adaptive Support Vector Machine (SVM) algorithm with combinational Fuzzy C-means Clustering is proposed. With multi-layer fuzzy C-means clustering algorithm original data are pretreated to remove the training data, which has no contribution to the classification. The remaining data are used to complete the training work for SVM to obtain the optimal hyper-plane. Besides, the parameter adaptive optimization algorithm has both increased the flexibility of parameter selection for SVM and enhanced the convergence speed. In the end, derived from the comparison of testing performance using the data set from the database of Statlog, the experiment result indicates that the proposed algorithm can both shorten the training time and provides high accuracy and excellent generalization, also it can keep the distribution of original data set at the same time.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486622","Fuzzy C-means Clustering;Statlog;Support Vector Machine","Clustering algorithms;Computer science;Educational institutions;Fuzzy sets;Lagrangian functions;Machine learning algorithms;Pattern recognition;Support vector machine classification;Support vector machines;Training data","fuzzy set theory;optimisation;pattern clustering;support vector machines","Statlog database;adaptive support vector machine;combinational fuzzy C-means clustering;multilayer fuzzy C-means clustering;parameter adaptive optimization algorithm","","0","","10","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"Incremental Bayesian classification for Chinese question sentences based on fuzzy feedback","S. Di; H. Li; P. He","School of Computer and Information Engineering, Shijiazhuang Railway Institute, Shijiazhuang, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","1","","V1-401","V1-404","Aiming at problems such as fixed training set and lacking of completed information in traditional Bayesian classification, incremental learning mechanism is introduced. Combining with the characteristics of question sentences in Chinese question answering system, Semi-Naive Bayesian model is used to construct classifier. In order to make prior distribution of samples lean to even distribution, samples whose posterior probability approach 1/n (n: number of classes) were selected and appended into training set. The approaching extent of samples is described by fuzzy set, the fuzzy distinguish result is returned to classifier, therefore a fuzzy feedback mechanism is formed. Incremental Semi-Naive Bayesian classifier based on fuzzy feedback is proposed in this paper. The results of experiments show that this Bayesian classification can improve the accuracy of classifier effectively.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497761","Bayesian classification;Chinese question sentences;fuzzy feedback mechanism;incremental learning","Bayesian methods;Feedback;Feeds;Fuzzy sets;Helium;Machine learning;Rail transportation;Railway engineering;Sampling methods;Uncertainty","Bayes methods;feedback;fuzzy set theory;learning (artificial intelligence);natural language processing;pattern classification;probability","Chinese question answering system;Chinese question sentences;fuzzy feedback;incremental Bayesian classification;incremental learning mechanism;posterior probability approach;semi naive Bayesian classifier","","0","","5","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Latent semantic analysis and keyword extraction for phishing classification","G. L'Huillier; A. Hevia; R. Weber; S. Ríos","Department of Computer Science, University of Chile, Blanco Encalada 2120, Santiago, Chile","2010 IEEE International Conference on Intelligence and Security Informatics","20100614","2010","","","129","131","Phishing email fraud has been considered as one of the main cyber-threats over the last years. Its development has been closely related to social engineering techniques, where different fraud strategies are used to deceit a naïve email user. In this work, a latent semantic analysis and text mining methodology is proposed for the characterisation of such strategies, and further classification using supervised learning algorithms. Results obtained showed that the feature set obtained in this work is competitive against previous phishing feature extraction methodologies, achieving promising results over different benchmark machine learning classification techniques.","","Electronic:978-1-4244-6446-3; POD:978-1-4244-6444-9","10.1109/ISI.2010.5484762","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484762","Latent Semantic Analysis;Phishing detection;Text mining","Algorithm design and analysis;Data mining;Feature extraction;Linear discriminant analysis;Logistics;Machine learning;Machine learning algorithms;Support vector machine classification;Support vector machines;Text mining","computer crime;data mining;feature extraction;fraud;learning (artificial intelligence);pattern classification;text analysis;unsolicited e-mail","email fraud phishing;keyword extraction;latent semantic analysis;machine learning classification techniques;phishing classification;phishing feature extraction methodology;social engineering techniques;supervised learning algorithms;text mining methodology","","6","","12","","","23-26 May 2010","","IEEE","IEEE Conference Publications"
"Spectral clustering for multiclass Erdös-Rényi graphs","M. A. Belabbas","Harvard University, School of Engineering and Applied Sciences, Cambridge, MA 02138, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","5422","5425","In this article, we study the properties of the spectral analysis of multiclass Erdös-Rényi graphs. With a view towards using the embedding afforded by the decomposition of the graph Laplacian for subsequent processing, we analyze two basic geometric properties, namely interclass intersection and interclass distance. We will first study the dyadic two-class case in details and observe the existence of a phase transition for the interclass intersection. We then focus on the general multiclass case, where we introduce an appropriate notion of diagonal concentration and derive a statistical model that allows sampling graphs whose expected diagonal concentration is fixed. The simulations provided yield useful guidelines for practitioners to choose appropriately parameters in the context of spectral clustering.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5494932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5494932","Community detection;Non-Euclidean datasets;Random graph models;Spectral graph theory","Biological system modeling;Biology;Computational modeling;Context modeling;Graph theory;Guidelines;Laplace equations;Machine learning algorithms;Sampling methods;Spectral analysis","graph theory;pattern clustering;spectral analysis","diagonal concentration;geometric property;graph Laplacian decomposition;interclass intersection;multiclass Erdos-Renyi graph;phase transition;sampling graph;spectral analysis;spectral clustering","","0","","13","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Variational nonparametric Bayesian Hidden Markov Model","N. Ding; Z. Ou","Department of Electronic Engineering, Tsinghua University, Beijing, China","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2098","2101","The Hidden Markov Model (HMM) has been widely used in many applications such as speech recognition. A common challenge for applying the classical HMM is to determine the structure of the hidden state space. Based on the Dirichlet Process, a nonparametric Bayesian Hidden Markov Model is proposed, which allows an infinite number of hidden states and uses an infinite number of Gaussian components to support continuous observations. An efficient variational inference method is also proposed and applied on the model. Our experiments demonstrate that the variational Bayesian inference on the new model can discover the HMM hidden structure for both synthetic data and real-world applications.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495125","Hidden Markov Model;Nonparametric Bayesian;Speech Recognition;Variational Inference","Bayesian methods;Gaussian distribution;Graphical models;Hidden Markov models;Large-scale systems;Machine learning;Pattern recognition;Speech recognition;State-space methods","Bayes methods;Gaussian processes;hidden Markov models;inference mechanisms;speech recognition;variational techniques","Dirichlet process;Gaussian component;hidden state space;real world speech recognition application;synthetic data;variational inference method;variational nonparametric Bayesian hidden Markov model","","4","","9","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Semi-supervised cluster ensemble based on binary similarity matrix","H. Wang; J. Qi; W. Zheng; M. Wang","Information Research Institute, SouthWest Jiaotong University, 610031 Chengdu, China","2010 2nd IEEE International Conference on Information Management and Engineering","20100603","2010","","","251","254","The paper introduces a semi-supervised cluster ensemble of pairwised constrains based on the binary similarity matrix. Pairwised constrains are the typical way of semi-supervised learning. Cluster ensemble can increase robustness of clustering and it is helpful for knowledge reuse and distributed computing. The existing algorithms are mostly unsupervised algorithms of cluster ensemble which can't take advantages of known information ofdatasets. As a result the precision, robustness and stability of cluster ensemble are degraded. Semi-supervised cluster ensemble may conquer these disadvantages. The idea is that we use pairwised constrains as semi-supervised learning for semi-supervised cluster ensemble, in this paper there are three works presented. First, we state a semi-supervised cluster ensemble method. Second, the model of semi-supervised cluster ensemble is illustrated in detail. Third, some UCI datasets are chosen for the experiments, and the results show that semi-supervised cluster ensemble works well.","","Electronic:978-1-4244-5264-4; POD:978-1-4244-5263-7","10.1109/ICIME.2010.5478054","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5478054","clustering;semi-supervised cluster ensemble","Clustering algorithms;Data privacy;Distributed computing;Machine learning;Machine learning algorithms;Robust stability;Robustness;Semisupervised learning;Training data;Unsupervised learning","learning (artificial intelligence);matrix algebra;pattern clustering","binary similarity matrix;distributed computing;knowledge reuse;pairwised constraints;semi-supervised cluster ensemble;semi-supervised learning","","3","","8","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Design analysis and implementation for ontology learning model","Qing Yang; Kai-min Cai; Jun-li Sun; Yan Li","Department of Computer Science, Huazhong Normal University, Wuhan, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","3","","V3-164","V3-167","Ontology learning is a technology. Ontology learning can be used to establish ontology automatically or semi-automatically by introducing the ontology engineering and machine learning technology and many other sciences and technologies. The ontology learning technology which is proposed in our paper is to reduce the time of building an entire ontology. Our paper presents an Ontology Learning model which will enhance the efficiency of extraction concept, and enhance the efficiency of ontology building. It includes several aspects, and area concept extraction is the main aspect of all. The model combines personalized recommendation with concept extraction and realizes a more accurate and stable domain concept extraction method. We describe these techniques and report the results of the experiment examining its effectiveness and efficiency.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485818","concept extraction;learning;ontology;personalization ecommendation","Collaboration;Computer science;Data mining;Filtering;Learning systems;Machine learning;Ontologies;Paper technology;Statistical analysis;Sun","learning (artificial intelligence);ontologies (artificial intelligence)","area concept extraction;design analysis;extraction concept;machine learning;ontology building;ontology engineering;ontology learning model;personalized recommendation;stable domain concept extraction","","0","","8","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"A geometric conversion approach for boosting regression problem","Peng Kou; F. Gao; L. Gao","SKLMS, Systems Engineering Institute, Xi'an Jiaotong University, Shaanxi Province, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","1","","V1-595","V1-599","Boosting is one of the most important developments in machine learning recently, AdaBoost is a prevailing boosting algorithm which receives lots of attention for its effectivity and practicality. Currently the research on boosting is dominated by classification problems. On the other hand, the extension of boosting to regression has received less investigation. In this paper, we present a boosting algorithm for regression in a geometric conversion approach. The algorithm first converts the regression problem to a binary classification one by a geometric operation. Employing confidence-rated AdaBoost on converted classification problem, a separating hyperplane ensemble could be obtained, and it could be transformed to a regression function for original regression problem. We prove that this algorithm decreases the training error exponentially fast. Experiments validate that our method is effective.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485948","boosting;ensemble learning;regression estimation","Algorithm design and analysis;Boosting;Convergence;Learning systems;Machine learning;Machine learning algorithms;Support vector machine classification;Support vector machines;Systems engineering and theory","computational geometry;error analysis;learning (artificial intelligence);pattern classification;regression analysis","binary classification problem;confidence-rated AdaBoost;geometric conversion approach;machine learning;regression function;regression problem boosting algorithm;training error","","0","","15","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Segmentation of infrared image using support vector machine","J. Xia; J. Sun; H. Li","Xi'an Research Inst. of Hi-Tech Hongqing Town, Xi'an, Shanxi Province, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","2","","V2-455","V2-458","Segmentation of infrared image is very important in infrared image analysis. Support vector machine (SVM) approach is considered a good candidate because of its good generalization performance, especially when the number of training samples is very small and the dimension of feature space is very high. In this paper, a segmentation algorithm based on SVM for infrared image is presented. The algorithm extracts the target from the infrared image by SVM. The image is divided into the target and background. Aiming at the best performance of infrared image, detailed analysis and comparisons are made by choosing different kernel functions and correlative parameters. Experimental results show that the presented algorithm more effectively and accurately extracts the target than the existing methods. SVM has a good application prospect for the segmentation of infrared image.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497480","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497480","image segmentation;infrared image;support vector machine","Earth;Feature extraction;Image analysis;Image segmentation;Infrared imaging;Kernel;Machine learning;Space technology;Support vector machine classification;Support vector machines","feature extraction;image segmentation;infrared imaging;support vector machines","SVM approach;correlative parameters;infrared image analysis;infrared image segmentation;kernel functions;support vector machine;target extraction","","0","","8","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Training-based demosaicing","H. Siddiqui; H. Hwang","Qualcomm Incorporated, San Diego, CA 92121, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","1034","1037","Typical digital cameras use a single-chip image sensor covered with a mosaic of red, green, and blue color filters for capturing color information. At each pixel location, only one of the three color values is known. The interpolation of the two missing color values at each pixel in a color filter array image (CFA) is called demosaicing. In this paper, we propose a novel training-based approach for computing the missing green pixels in a CFA. The algorithm works by extracting a multi-dimensional feature vector comprising derivatives of various orders computed in a spatial neighborhood of the pixel being interpolated. Using a statistical machine learning framework, the feature vector is then used to predict the optimal interpolation direction for estimating the missing green pixel. The parameters of the statistical model are learned in an offline training procedure using example training images. Once the green channel has been estimated, the red and blue pixels are estimated using bilinear interpolation of the difference (chrominance) channels. Both subjective and objective evaluations show that the proposed demosaic algorithm yields a high output image quality. The algorithm is computationally and memory efficient, and its sequential architecture makes it easy to implement in an imaging system.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495325","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495325","Bayer mosaic;Color filter array;bilateral filter;demosaic;interpolation","Color;Digital cameras;Feature extraction;Image quality;Image sensors;Interpolation;Machine learning;Machine learning algorithms;Pixel;Sensor arrays","cameras;filtering theory;image colour analysis;image segmentation;image sensors;interpolation;learning (artificial intelligence);statistical analysis","blue color filters;color filter array image;difference channel bilinear interpolation;digital cameras;example training images;green color filters;green pixel estimation;image quality;imaging system;multidimensional feature vector extraction;objective evaluations;offline training procedure;optimal interpolation direction prediction;red color filters;single-chip image sensor;statistical machine learning framework;statistical model;subjective evaluations;training-based demosaicing algorithm","","4","","5","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Microwave characterization using ridge polynomial neural networks and least-square support vector machines","T. Hacib; H. Acikgoz; Y. Le Bihan; O. Meyer; L. Pichon","Laboratoire LAMEL, Facult&#233; des Sciences de l'Ing&#233;nieur, Univ. Jijel., BP 98, Ouled Aissa, 18000, Alg&#233;rie","Digests of the 2010 14th Biennial IEEE Conference on Electromagnetic Field Computation","20100607","2010","","","1","1","Motivated by the slow learning properties of multilayer perceptrons which utilize computationally intensive training algorithms and can get trapped in local minima, this work deals with ridge polynomial neural networks (RPNN) and least-square support vector machines (LSSVM) technique. RPNN and LSSVM are combined with the finite element method (FEM), to evaluate the dielectric materials properties. RPNN maintain fast learning properties and powerful mapping capabilities of single layer high order neural networks. LSSVM is a statistical learning method that has good generalization capability and learning performance. Experimental results show that LSSVM can achieve good accuracy and faster speed than those using conventional methods.","","CD:978-1-4244-7061-7; Electronic:978-1-4244-7062-4; Paper:978-1-4244-7059-4","10.1109/CEFC.2010.5481797","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481797","","Computer networks;Dielectric materials;Finite element methods;Machine learning;Multi-layer neural network;Multilayer perceptrons;Neural networks;Polynomials;Statistical learning;Support vector machines","dielectric materials;electrical engineering computing;finite element analysis;learning (artificial intelligence);least squares approximations;neural nets;polynomials;support vector machines","FEM;LSSVM;dielectric materials properties;finite element method;intensive training algorithms;learning properties;least-square support vector machines;microwave characterization;multilayer perceptrons;ridge polynomial neural networks","","0","","2","","","9-12 May 2010","","IEEE","IEEE Conference Publications"
"Learning α-integration with partially-labeled data","H. Choi; S. Choi; A. Katake; Y. Choe","Dept. of Computer Sci. and Eng., Texas A&M Univ., USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2058","2061","Sensory data integration is an important task in human brain for multimodal processing as well as in machine learning for multisensor processing. α-integration was proposed by Amari as a principled way of blending multiple positive measures (e.g., stochastic models in the form of probability distributions), providing an optimal integration in the sense of minimizing the α-divergence. It also encompasses existing integration methods as its special case, e.g., weighted average and exponential mixture. In α-integration, the value of α determines the characteristics of the integration and the weight vector w assigns the degree of importance to each measure. In most of the existing work, however, α and w are given in advance rather than learned. In this paper we present two algorithms, for learning α and w from data when only a few integrated target values are available. Numerical experiments on synthetic as well as real-world data confirm the proposed method's effectiveness.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495025","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495025","α-integration;parameter estimation","Brain modeling;Clustering algorithms;Distributed computing;Humans;Inference algorithms;Machine learning;Parameter estimation;Pattern recognition;Probability distribution;Stochastic processes","learning (artificial intelligence);sensor fusion","human brain;learning α-integration;machine learning;multimodal processing;multisensor processing;partially labeled data;sensory data integration","","1","","17","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Applying log linear model based context dependent machine translation techniques to grapheme-to-phoneme conversion","R. Zhang; B. Zhou","IBM T. J. Watson Research Center, Yorktown Heights, NY 10598, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","4634","4637","Grapheme-to-Phoneme conversion is a challenging task for speech recognition and text-to-speech systems for which the functionality of automatically predicting pronunciations for OOV words is highly desirable. In this paper, Grapheme-to-Phoneme conversion is viewed as a special case of sequence translation problem and we propose to tackle it with phrase based log-linear translation model. We improve standard machine translation method by utilizing context dependent units which lead to a better many-to-many alignment between chunks of graphemes and phonemes. Furthermore, hypotheses combination technique is applied to combine outputs generated by multiple translation models trained with different alignment units. Our proposed approach was evaluated on NetTalk and CMUDict datasets. Significant improvements on conversion accuracy are observed on both sets compared to conventional translation method: phoneme level error rates are reduced relatively by 18.4% and 22.5%, respectively. Our approach also performs better than or as good as previously published data driven methods examined on the same tasks.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495551","Grapheme-to-Phone conversion","Classification tree analysis;Context modeling;Dictionaries;Error analysis;Hidden Markov models;Machine learning algorithms;Prediction methods;Predictive models;Speech recognition;Speech synthesis","language translation;speech recognition;speech synthesis","CMUDict datasets;NetTalk datasets;OOV words;context dependent machine translation techniques;grapheme-to-phoneme conversion;log linear model;multiple translation models;sequence translation problem;speech recognition;text-to-speech systems","","1","","16","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Optimize the obvious: Automatic call flow generation","D. Suendermann; J. Liscombe; R. Pieraccini","SpeechCycle Labs, New York, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","5370","5373","In commercial spoken dialog systems, call flows are built by call flow designers implementing a predefined business logic. While it may appear obvious from this logic how the call flow has to look like, i.e., which pieces of information have to be gathered from the caller or back-end systems and in which sequence, there are, in fact, strong arguments for automating call flow generation: 1) manual generation is time-consuming 2) manual generation is suboptimal and error-prone 3) automatic generation can react on dynamically changing business logic or external factors such as the distribution of callers and call reasons This paper presents a method for automatically deriving a call flow minimizing the average number of user turns given a business logic and a frequency distribution of call reasons. As an example, we applied the method to a call routing application whose manually built call flow is processing about 4 million calls per month and whose call reason distribution served to measure the impact of the automatic call flow generation.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5494936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5494936","automatic call flow generation;spoken dialog systems","Automatic logic units;Business;Decision trees;Design optimization;Fluid flow measurement;Frequency estimation;Logic design;Machine learning;Optimization methods;Routing","telecommunication congestion control","automatic call flow generation;back-end systems;business logic;call flow designers;call reasons frequency distribution;call routing;spoken dialog systems","","1","","9","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Sensitivity of Support Vector Machines to Random Feature Selection in Classification of Hyperspectral Data","B. Waske; S. van der Linden; J. A. Benediktsson; A. Rabe; P. Hostert","Institute of Geodesy and Geoinformation, Faculty of Agricultural, University of Bonn , Bonn, Germany","IEEE Transactions on Geoscience and Remote Sensing","20100617","2010","48","7","2880","2889","The accuracy of supervised land cover classifications depends on factors such as the chosen classification algorithm, adequate training data, the input data characteristics, and the selection of features. Hyperspectral imaging provides more detailed spectral and spatial information on the land cover than other remote sensing resources. Over the past ten years, traditional and formerly widely accepted statistical classification methods have been superseded by more recent machine learning algorithms, e.g., support vector machines (SVMs), or by multiple classifier systems (MCS). This can be explained by limitations of statistical approaches with regard to high-dimensional data, multimodal classes, and often limited availability of training data. In the presented study, MCSs based on SVM and random feature selection (RFS) are applied to explore the potential of a synergetic use of the two concepts. We investigated how the number of selected features and the size of the MCS influence classification accuracy using two hyperspectral data sets, from different environmental settings. In addition, experiments were conducted with a varying number of training samples. Accuracies are compared with regular SVM and random forests. Experimental results clearly demonstrate that the generation of an SVM-based classifier system with RFS significantly improves overall classification accuracy as well as producer's and user's accuracies. In addition, the ensemble strategy results in smoother, i.e., more realistic, classification maps than those from stand-alone SVM. Findings from the experiments were successfully transferred onto an additional hyperspectral data set.","0196-2892;01962892","","10.1109/TGRS.2010.2041784","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5439692","Classifier ensembles;hyperspectral data;multiple classifier systems (MCSs);random feature selection (RFS);support vector machines (SVMs)","Classification algorithms;Hyperspectral imaging;Hyperspectral sensors;Infrared sensors;Kernel;Machine learning algorithms;Remote sensing;Support vector machine classification;Support vector machines;Training data","feature extraction;geophysical image processing;image classification;learning (artificial intelligence);remote sensing;spectral analysis;support vector machines;terrain mapping","high-dimensional data;hyperspectral data classification;hyperspectral imaging;input data characteristics;machine learning algorithm;multimodal class;random feature selection;random forest;remote sensing;spatial information;spectral information;supervised land cover classification;support vector machine","","77","","44","","20100329","July 2010","","IEEE","IEEE Journals & Magazines"
"Prediction of Protein Secondary Structure Based on NMR Chemical Shift Data Using Support Vector Machines","A. Sabouri; A. Ardalan; R. Shahidi-Nejad","Inf. Networking Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA","2010 12th International Conference on Computer Modelling and Simulation","20100607","2010","","","201","205","Protein secondary structure detection is an intricate problem which depends on several parameters of a polypeptide chain and its environment and has a great effect on the accurate determination of protein functionality in living organisms. Statistical learning approaches have been used to tackle the problem extensively and many considerable results have been achieved, which encourages the researchers to continue exploring the track. Support vector machines are among the interesting tools of machine learning, which have been used in different fields of computational molecular biology. This paper aims to combine the power of SVMs with the informative chemical shift data to distinguish the secondary structure of the proteins. The results show a good accuracy of the approach regarding different structures, especially in detection of turns and sheets.","","Electronic:978-1-4244-6615-3; POD:978-1-4244-6614-6","10.1109/UKSIM.2010.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5480503","Chemical Shift;Nuclear Magnetic Resonance;Protein Secondary Structure;Support Vector Machines","Chemicals;Computer networks;Machine learning;Magnetic fields;Nuclear magnetic resonance;Organisms;Predictive models;Proteins;Spectroscopy;Support vector machines","NMR spectroscopy;chemical shift;living systems;molecular biophysics;proteins;statistical analysis;support vector machines","NMR chemical shift data;computational molecular biology;informative chemical shift data;living organism;machine learning;nuclear magnetic resonance;polypeptide chain;protein functionality;protein secondary structure detection;statistical learning;support vector machine","","1","","10","","","24-26 March 2010","","IEEE","IEEE Conference Publications"
"Research on AdaBoost.M1 with Random Forest","Zhenyu Zhang; Xiaoyao Xie","Department of Development Strategy, China Mobile Group Guizhou Co., Ltd, Guiyang, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","1","","V1-647","V1-652","The AdaBoost.M1 is one of the machine learning algorithms. But it will fail if the weak learner cannot achieve at least 50% accuracy when run on these hard distributions. Random Forest is computationally effective and offer good prediction performance. A new approach AdaBoost.M1-RF algorithm, which using Random Forest as weak learner, is proposed in the paper. To evaluate the performance of AdaBoost.M1-RF algorithm, it is compared with other machine learning algorithms.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485910","AdaBoost;AdaBoost.M1;AdaBoost.M1-RF;Random Forest","Boosting;Classification tree analysis;Game theory;Laboratories;Machine learning;Machine learning algorithms;Neural networks;Robustness;Upper bound;Virtual colonoscopy","decision trees;learning (artificial intelligence)","AdaBoost.Ml-RF algorithm;AdaBoostMl;machine learning algorithms;random forest","","1","","21","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"A training algorithm for sparse LS-SVM using Compressive Sampling","J. Yang; A. Bouzerdoum; S. L. Phung","School of Electrical, Computer and Telecommunications Engineering, University of Wollongong, NSW 2522, Australia","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2054","2057","Least Squares Support Vector Machine (LS-SVM) has become a fundamental tool in pattern recognition and machine learning. However, the main disadvantage is lack of sparseness of solutions. In this article Compressive Sampling (CS), which addresses the sparse signal representation, is employed to find the support vectors of LS-SVM. The main difference between our work and the existing techniques is that the proposed method can locate the sparse topology while training. In contrast, most of the traditional methods need to train the model before finding the sparse support vectors. An experimental comparison with the standard LS-SVM and existing algorithms is given for function approximation and classification problems. The results show that the proposed method achieves comparable performance with typically a much sparser model.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495015","Compressive Sampling;Least Squares Support Vector Machine (LS-SVM);Model Selection;OrthogonalMatching Pursuit (OMP);Sparse Approximation","Approximation algorithms;Function approximation;Least squares methods;Machine learning;Machine learning algorithms;Pattern recognition;Sampling methods;Signal representations;Support vector machines;Topology","learning (artificial intelligence);least squares approximations;pattern matching;pattern recognition;signal representation;signal sampling;support vector machines","compressive sampling;least square support vector machine;machine learning;orthogonal matching pursuit;pattern recognition;sparse LS-SVM;sparse signal representation;sparse topology;training algorithm","","8","","12","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Application of mixtures of kernels in diesel cetane number measurement with NIR spectra measurement","GuiJun Yang","Hangzhou Institute of Commerce, Zhejiang Gongshang University, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","1","","V1-263","V1-266","The most usually used least squares support vector machines(LS-SVM) modeling method In near infrared(NIR) spectra measurement are based on a single kernel function. However, the single kernel function can not describe the whole data very well, thus affecting the LS-SVM modeling results. In this paper, we introduced the mixtures of kernels to replace the original single kernel, then the LS-SVM based on the mixtures of kernels was applied to model prediction. It was proved by the experimental results that the algorithm can obviously improve the model prediction performance of diesel cetane number based on the LS-SVM compared with other methods in existence.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5486170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486170","LS-SVM;mixtures of kernels;model prediction;near infrared spectroscopy","Accuracy;Business;Equations;Fuels;Kernel;Least squares methods;Machine learning algorithms;Predictive models;Principal component analysis;Support vector machines","chemical engineering computing;chemical variables measurement;infrared spectroscopy;least mean squares methods;petroleum;support vector machines","LS-SVM modeling;NIR;diesel cetane number measurement;least squares support vector machine;mixtures of kernels;near infrared spectra measurement;single kernel function","","0","","11","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Similarity kernels via bi-clustering for conventional intergovernmental organizations","Minh Tam Le; J. Sweeney; E. Liberty; S. W. Zucker","Dept of Computer Science, Yale University, New Haven, CT 06520-8285, USA","2010 IEEE International Conference on Intelligence and Security Informatics","20100614","2010","","","218","220","Many databases provide tabular data relating objects to entities; for example, which countries belong to certain organizations. We seek to infer implicit organizational variables over such objects (countries) as a function of these properties (organizational memberships), and vice versa. If kernels existed over objects, then machine learning and non-linear dimensionality reduction techniques could be used. But this requires a similarity or distance defined over objects, which does not exist a priori. We are exploring an approach to kernel identification based on bi-clustering in which an average over randomized biclusters approximates a kernel. We claim that such kernels provide a viable alternative to other, more common kernel approaches. Experiments with a database of memberships in conventional intergovernmental organizations supports this claim.","","Electronic:978-1-4244-6446-3; POD:978-1-4244-6444-9","10.1109/ISI.2010.5484732","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484732","","Computer science;Databases;Government;Hamming distance;Information analysis;International relations;Kernel;Machine learning;Mathematics;Pattern analysis","","","","0","","4","","","23-26 May 2010","","IEEE","IEEE Conference Publications"
"Combining pattern recognition algorithms chances and limits","M. Wozniak","Department of Systems and Computer Networks, Wroclaw University of Technology, Poland","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","6","","V6-111","V6-115","Paper presents a brief survey of the main topics connected with Multiple Classifier Systems design task. On the beginning typical topologies are described and then we focus on ensemble and fuser design methods. For the last topic we show the limit of different approaches based on weighted voting.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5486331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486331","combining classifier;ensemble design;fuser design;multiple classifier systems;pattern recognition","Algorithm design and analysis;Buildings;Computer networks;Decision making;Design methodology;Machine learning algorithms;Network topology;Neural networks;Pattern recognition;Voting","pattern classification;pattern recognition","ensemble method;fuser design methods;multiple classifier systems design;pattern recognition algorithms;weighted voting","","2","","32","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Clustering algorithm based on characteristics of density distribution","Zheng Hua; Wang Zhenxing; Zhang Liancheng; Wang Qian","National Digital Switching System Engineering & Technological R&D Center, Zhengzhou, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","2","","431","435","Density-based clustering algorithms, which are important algorithms for the task of class identification in spatial database, have many advantages such as no dependence on the number of clusters, ability to discover clusters with arbitrary shapes and handle noise. However, clustering quality of most density-based clustering algorithms degrades when the clusters are of different densities. To address this issue, this paper brings forward a clustering algorithm based on characteristics of density distribution--CCDD algorithm. Firstly, it divides data space into a number of grids. Secondly, it re-divides data space into many smaller partitions, according to each grid's one-dimensional or multi-dimensional characteristics of density distribution. Finally, it uses an improved DBSCAN algorithm, which chooses different parameters according to each partition's local density, to cluster respectively. The experimental results show that CCDD algorithm, which is superior in quality and efficiency to DBSCAN algorithm, can find clusters with arbitrary shapes and different densities in spatial databases with noise.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486640","DBSCAN algorithm;clustering;data mining;data space partition;density-based clustering;grid","Biomedical optical imaging;Clustering algorithms;Data engineering;Machine learning algorithms;Noise shaping;Optical noise;Partitioning algorithms;Shape;Spatial databases;Switching systems","pattern clustering;visual databases","DBSCAN algorithm;arbitrary shapes;class identification;clustering quality;density distribution;density-based clustering algorithms;spatial databases","","2","","8","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"A reduced listwise approach of learning to rank","Hai-jiang He; Jian-kai Zhu","Department of Computer Science and Technology, Changsha University, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","4","","V4-660","V4-664","Ranking functions determine the relevance of search results in information retrieval systems. Recently learning to rank has become a promising method for constructing a model or a function for ranking objects. Several listwise approaches were proposed as an alternate of learning to rank algorithms, which directly define a loss function on list of objects. Motivated by demonstrating the effectiveness using ListMLE, a new reduced approach called RcList is introduced. A regularization condition is appended to RcList, and imposes constraints on the model parameter space. The unique optimal solution of the optimization object of the RcList is obtained by applying Newton-YUAN method. It is demonstrated the performance benefits of the RcList compared to the ListMLE through experiments on a public dataset LETOR.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485294","information retrieval;learning to rank;listwise;optimization object;regularization","Boltzmann distribution;Computer science;Helium;Information retrieval;Learning systems;Loss measurement;Machine learning;Machine learning algorithms;Optimization methods","information retrieval;optimisation","Newton-YUAN method;information retrieval;model parameter space;optimization;ranking function","","0","","15","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Towards fatigue and intensity measurement framework during continuous repetitive activities","R. Chattopadhyay; G. Pradhan; S. Panchanathan","Center for Cognitive Ubiquitous Computing, School of Computing, Informatics, and Decision Systems Engineering Arizona State University, Tempe, USA","2010 IEEE Instrumentation & Measurement Technology Conference Proceedings","20100617","2010","","","1341","1346","With the recent advancement in the wearable sensor technology there has been many studies about recognizing user's activities, location or environment, but they did not recognize the effect of these activities on the physiological state of the person. The two major physiological aspects associated with any activity are intensity of activity and associated fatigue. Fatigue is an universal human experience that can negatively affect daily life activities. In this paper, we present a framework to measure the level of fatigue and intensity of activity during repetitive daily life activities. The proposed framework acquires and processes time series data from a surface Electromyogram (sEMG) sensor and employs state of art machine learning and data mining techniques to measure the physiological status. We tested this framework using the raw sEMG signals from the hand muscles of 10 subjects, including male and female, of age group around 25 to 45 years, collected during the continuous monitoring of repetitive palm movements at different repetition speeds. The framework graded the levels of fatigue and intensity of activity in a scale of 0 to 1 with an accuracy of 88% with AdaBoost, 94% with SVM, 96% with both HMM and KNN based machine learning techniques.","1091-5281;10915281","Electronic:978-1-4244-2833-5; POD:978-1-4244-2832-8","10.1109/IMTC.2010.5488258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5488258","","Art;Biomedical monitoring;Data mining;Fatigue;Humans;Machine learning;Muscles;Testing;Time measurement;Wearable sensors","data mining;wearable computers","art machine learning;continuous repetitive activities;data mining techniques;fatigue measurement framework;intensity measurement framework;surface electromyogram sensor;time series;wearable sensor technology","","2","","24","","","3-6 May 2010","","IEEE","IEEE Conference Publications"
"An improved method for feature weighting to document categorization","Z. Pei; Y. Zhou; L. Wang; L. Liu; Y. Lu; Y. Kong","College of Computer Science and Technology, Inner Mongolia University for the Nationalites, Tongliao, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","3","","V3-339","V3-343","Based on the significance of feature frequency, an improved weighting method for feature frequency is proposed, which considers the decision-making information in evaluating the contribution of feature frequency to document categorization. Experimental results show that this method could improve the space distribution of the document set. Furthermore, the values of macro accuracy, macro recall rate and macroF1 are all improved significantly.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497607","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497607","document categorization;feature weighting;real rough set;tf.idf","Automation;Computer science;Decision making;Educational institutions;Frequency;Fuzzy sets;Machine learning;Mechanical engineering;Set theory;Workstations","decision making;document handling","decision-making information;document categorization;feature frequency;feature weighting","","0","","10","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Investigating the Use of Semantic-Based Websites to Improve Recommendation Quality","T. Eimuri; S. Salehi","Islamic Azad Univ. of Parand, Parand, Iran","2010 Second International Conference on Computer Research and Development","20100621","2010","","","411","415","In this paper, we aim to investigate the use of semantic-based websites to improve recommendation quality by testing a knowledge based recommendation system whose results completely depends on the product descriptions, on two different databases. In one of our relational MySQL databases, product descriptions are stored in form of RDF files and in the other one the data is stored in human language. We show that, the RS results are more accurate and intelligent when it is working with the semantic based database that stores product information in form of RDF graphs. Since, the well-defined data can help the recommendation system to analyze an extract the data better and make ""smart"" decisions.","","Electronic:978-1-4244-6993-2; POD:978-1-4244-6992-5","10.1109/ICCRD.2010.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5489593","Ecommerce;RDF;Recommendation Systems;Semantic Web;semantic-based websites","Collaboration;Electronic commerce;Filtering;Humans;Machine learning;Ontologies;Relational databases;Resource description framework;Semantic Web;Taxonomy","SQL;Web sites;knowledge based systems;recommender systems;relational databases;semantic Web;software quality","RDF files;knowledge based recommendation system;product descriptions;recommendation quality improvement;relational MySQL databases;semantic based Websites","","0","","12","","","7-10 May 2010","","IEEE","IEEE Conference Publications"
"Adaptation using neural network in frequency selective MIMO-OFDM systems","H. Yigit; A. Kavak","Department of Electronics and Computer Education, Kocaeli University Izmit, Kocaeli, 41380, Turkey","IEEE 5th International Symposium on Wireless Pervasive Computing 2010","20100614","2010","","","390","394","In this paper, we proposed a neural network (NN) framework as a machine learning technique for link adaptation based on adaptive modulation and coding in 802.11n MIMO-OFDM wireless system to predict the best modulation and coding scheme (MCS) index under packet error rate (PER) constraints. Our approach is compared with the k-nearest neighbour (k-NN) algorithm in frequency selective wireless channels. Simulation results validate the implementation of proposed neural network framework in frequency selective channels, and show that the neural network technique outperforms k-NN algorithm especially in terms of PER when low MCS index selection which provide higher communication reliability is exploited.","","Electronic:978-1-4244-6858-4; POD:978-1-4244-6855-3","10.1109/ISWPC.2010.5483745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5483745","","Backpropagation algorithms;Computer networks;Error analysis;Frequency;Machine learning;Machine learning algorithms;Modulation coding;Neural networks;Pervasive computing;Receiving antennas","","","","2","","14","","","5-7 May 2010","","IEEE","IEEE Conference Publications"
"Expectation propagation for estimating the parameters of the beta distribution","Z. Ma; A. Leijon","Sound and Image Processing Lab, KTH - Royal Institute of Technology, Stockholm, Sweden","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2082","2085","Parameter estimation for the beta distribution is analytically intractable due to the integration expression in the normalization constant. For maximum likelihood estimation, numerical methods can be used to calculate the parameters. For Bayesian estimation, we can utilize different approximations to the posterior parameter distribution. A method based on the variational inference (VI) framework reported the posterior mean of the parameters analytically but the approximating distribution violated the correlation between the parameters. We now propose a method via the expectation propagation (EP) framework to approximate the posterior distribution analytically and capture the correlation between the parameters. Compared to the method based on VI, the EP based algorithm performs better with small amounts of data and is more stable.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495085","Beta Distribution;Expectation Propagation;Importance Sampling;Laplace Approximation;Variational Inference","Acoustic propagation;Bayesian methods;Gaussian distribution;Image analysis;Image processing;Inference algorithms;Machine learning;Maximum likelihood estimation;Monte Carlo methods;Parameter estimation","","","","4","","12","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Hierarchical dictionary learning for invariant classification","L. Bar; G. Sapiro","Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","3578","3581","Sparse representation theory has been increasingly used in the fields of signal processing and machine learning. The standard sparse models are not invariant to spatial transformations such as image rotations, and the representation is very sensitive even under small such distortions. Most studies addressing this problem proposed algorithms which either use transformed data as part of the training set, or are invariant or robust only under minor transformations. In this paper we suggest a framework which extracts sparse features invariant under significant rotations and scalings. The algorithm is based on a hierarchical architecture of dictionary learning for sparse coding in a cortical (log-polar) space. The proposed model is tested in supervised classification applications and proved to be robust under transformed data.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495916","Sparse models;classification;dictionary learning;hierarchy;invariance;log-polar","Additive noise;Biological system modeling;Dictionaries;Feature extraction;Machine learning;Robust stability;Robustness;Signal processing algorithms;Testing;Vectors","encoding;signal classification;signal representation","cortical space;hierarchical dictionary learning;invariant classification;log-polar space;sparse coding;sparse features invariant extraction;sparse representation theory;supervised classification","","8","","18","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"An initial attempt for phoneme recognition using Structured Support Vector Machine (SVM)","H. Tang; C. H. Meng; L. S. Lee","Graduate Institute of Electrical Engineering, National Taiwan University, Taiwan","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","4926","4929","Structured Support Vector Machine (SVM) is a recently developed extension of the very successful SVM approach, which can efficiently classify structured pattern with maximized margin. This paper presents an initial attempt for phoneme recognition using structured SVM. We simply learn the basic framework of HMMs in configuring the structured SVM. In the preliminary experiments with TIMIT corpus, the proposed approach was able to offer an absolute performance improvement of 1.33% over HMMs even with a highly simplified initial approach, probably because of the concept of maximized margin of SVM. We see the potential of this approach because of the high generality, high flexibility, and high power of structured SVM.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495097","Hidden Markov Model;Phoneme Recognition;Structured Support Vector Machine","Chaos;Computer science;Hidden Markov models;Machine learning;Machine learning algorithms;Pattern recognition;Power generation;Speech recognition;Support vector machine classification;Support vector machines","hidden Markov models;speech recognition;support vector machines","Hidden Markov Model;TIMIT corpus;phoneme recognition;support vector machine","","4","","8","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Convergence analysis of consensus-based distributed clustering","P. A. Forero; A. Cano; G. B. Giannakis","Dept. of ECE, University of Minnesota, 200 Union Street SE, Minneapolis, 55455, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","1890","1893","This paper deals with clustering of spatially distributed data using wireless sensor networks. A distributed low-complexity clustering algorithm is developed that requires one-hop communications among neighboring nodes only, without local data exchanges. The algorithm alternates iterations over the variables of a consensus-based version of the global clustering problem. Using stability theory for time-varying and time-invariant systems, the distributed clustering algorithm is shown to be bounded-input bounded-output stable with an output arbitrarily close to a fixed point of the algorithm. For distributed hard K-means clustering, convergence to a local minimum of the centralized problem is guaranteed. Numerical examples confirm the merits of the algorithm and its stability analysis.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495344","Clustering methods;Distributed algorithms;Stability;Unsupervised learning","Clustering algorithms;Collaborative work;Convergence;Data mining;Government;Machine learning algorithms;Partitioning algorithms;Prototypes;Stability;Wireless sensor networks","convergence;distributed algorithms;pattern clustering;stability;time-varying systems;wireless sensor networks","bounded input bounded output;convergence;distributed algorithm;distributed data clustering;distributed hard K-means clustering;stability theory;time-invariant systems;time-varying systems;wireless sensor networks","","0","","8","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"The Application of Rough Comprehensive Evaluation Method","L. Wenjun","Dept. of Math. & Comput. Sci., Changsha Univ. of Sci. & Technol., Changsha, China","2010 Asia-Pacific Conference on Wearable Computing Systems","20100607","2010","","","407","410","Firstly, the authors generalize the indiscernible relation to similarity relation, give a definition of λ-discernibility matrix; secondly, according to the properties of λ-discernibility matrix, an algorithm of computing significance of each condition attribute is put forward; thirdly, we give the comprehensive weight of each attribute according to subjective and objective weight; at last, the reasonable and available of this algorithm is accounted for through an example.","","Electronic:978-1-4244-6468-5; POD:978-1-4244-6467-8","10.1109/APWCS.2010.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481180","assessment;rough sets;significance;similarity relation","Decision support systems;Expert systems;Knowledge representation;Machine learning;Machine learning algorithms;Mathematics;Pattern recognition;Set theory;Wearable computers","matrix algebra;rough set theory","comprehensive attribute weight;discernibility matrix;objective weight;rough comprehensive evaluation method;subjective weight","","0","","12","","","17-18 April 2010","","IEEE","IEEE Conference Publications"
"A new feature selection algorithm based on mutual information with pairwise constraints","Song Jing; Yang Ming; Ji Genlin; Cai Wenbin","School of Computer Science and Technology, Nanjing Normal University, 210097, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","3","","483","486","Feature selection plays an important role in the area of machine learning. Class Label is often used as the supervised information for supervised feature selection algorithm while constraints are rarely used. So, an effective feature selection algorithm with pairwise constraints called Constraints Score was proposed. But its performance still is limited by neglecting the correlation between features. In this paper we improve this algorithm by considering the correlation between features and using SVM density estimation, mutual information to measure the correlation and further eliminate the feature redundancy. Experiments show the effectiveness of our improved algorithm.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486811","SVM density estimation;mutual information;semi-feature selection","Computer science;Density measurement;Entropy;Filters;Information security;Machine learning;Machine learning algorithms;Mutual information;Random variables;Support vector machines","constraint handling;data mining;feature extraction;learning (artificial intelligence);support vector machines","SVM density estimation;class label;constraints score;machine learning;mutual information;pairwise constraint;supervised feature selection algorithm;support vector machine","","0","","14","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"Data mining method based on computer forensics-based ID3 algorithm","I. Qin","Department of Information Science and Technology East China University of Political Science and Law Shanghai 200042, China","2010 2nd IEEE International Conference on Information Management and Engineering","20100603","2010","","","340","343","Data mining method based on computer forensics-based ID3 algorithm is presented in the study. Forensics data are unconstant, noisy and dispersive. Based on these characteristic of forensics data, the improved ID3 algorithm from adopting weight and two times information is gained. The examples can be used as the experiment data, and 100 test samples which is independent of training samples are applied to judge error rate of decision tree rules. The experimental results show that the error rate of ID3 is 8.9% and the error rate of improved algorithm is 5.4%, which indicates the accuracy of the proposed method is higher than ID3 algorithm. It can be seen that the improved method used in the computer forensics process is entirely feasible.","","Electronic:978-1-4244-5264-4; POD:978-1-4244-5263-7","10.1109/ICIME.2010.5477817","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477817","ID3;computer forensics;data mining;decision tree;high precision","Algorithm design and analysis;Classification tree analysis;Data mining;Decision trees;Entropy;Error analysis;Forensics;Machine learning algorithms;Mathematical model;Testing","computer forensics;data mining;decision trees","ID3 algorithm;computer forensics;data mining;decision tree rule;error rate","","0","","6","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Overview of Web mining technology and its application in e-commerce","Li Mei; Feng Cheng","School of Computer, Beijing University of Posts and Telecommunications, CHINA","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","7","","V7-277","V7-280","The main purpose of this paper is to study the process of Web mining techniques and its application in e-commerce applications. This paper using the methods that introducing the concept of Web mining, and describing the process of Web data mining in detail: source data collection, data pre-processing, pattern discovery and pattern analysis, using a detailed case of Web mining application in e-commerce: Web mining in the network marketing where web mining is used to determine the objectives of Network Marketing, establish marketing information system, establish personalized service system, etc. Finally it concludes the relationship between Web data mining and e-commerce and how to use Web mining technology in e-commerce.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485404","E-commerce;Web mining;data collection;intelligent business;network marketing","Application software;Cleaning;Data mining;Data preprocessing;Machine learning;Pattern analysis;Telecommunication computing;Web mining;Web pages;Web server","Internet;data mining;electronic commerce","Web data mining;Web mining technology;e-commerce;marketing information system;network marketing;pattern analysis;pattern discovery;source data collection","","4","","6","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Learning from past experiences to enhance decision support in IT change management","M. Rahmouni; C. Bartolini","HP Labs, USA","2010 IEEE Network Operations and Management Symposium - NOMS 2010","20100617","2010","","","408","415","The number of changes that IT departments have to deal with is growing at a fast pace in response to changing business needs of enterprises. As changes are getting executed and deployed, knowledge is being created and stored. It is of paramount importance to the success of the business to re-use that knowledge for future changes. In fact, those who do not learn from past experiences are doomed to repeat the same mistakes as well as not bear the fruit of the ones that were successful. This paper addresses this concern by providing for every change being worked out the most similar past changes. Our solution combines data mining and optimization paradigms to model the problem of finding past similar changes by designing and learning similarity functions. Our approach enhances the efficiency and effectiveness of dealing with changes, by reducing the risk and shortening the time of introducing new changes.","1542-1201;15421201","Electronic:978-1-4244-5367-2; POD:978-1-4244-5366-5; USB:978-1-4244-5367-2; USB:978-1-5090-5692-7","10.1109/NOMS.2010.5488305","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5488305","Data Mining;IT Change Management;Maximum Feasible Subsystem Problem;Optimization","Business;Condition monitoring;Costs;Data mining;Design optimization;Feedback;Knowledge management;Machine learning;Risk management","data mining;decision support systems;information technology;learning (artificial intelligence);management of change;optimisation;strategic planning","IT change management;data mining;decision support;enterprise need;machine learning;optimization paradigm","","2","1","24","","","19-23 April 2010","","IEEE","IEEE Conference Publications"
"Semi-Supervised Fisher Linear Discriminant (SFLD)","S. Remus; C. Tomasi","Clarkson University, Department of Computer Science, PO Box 5815 Potsdam, NY 13699-5815, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","1862","1865","Supervised learning uses a training set of labeled examples to compute a classifier which is a mapping from feature vectors to class labels. The success of a learning algorithm is evaluated by its ability to generalize, i.e., to extend this mapping accurately to new data that is commonly referred to as the test data. Good generalization depends crucially on the quality of the training set. Because collecting labeled data is laborious, training sets are typically small. Furthermore, it is often difficult to represent all possible observation scenarios during training, so that the statistics of the training set end up differing from those of the test data, a problem known as the sample selection bias. To address sample selection bias, we introduce a Semi-Supervised Fisher Linear Discriminant (SFLD) that utilizes additional, unlabeled data to improve generalization for both small and biased training sets. We characterize the conditions under which SFLD helps, and illustrate its benefits through experiments on digit and car recognition applications.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495365","Classification;Fisher Linear Discriminant;Generalization;Sample Selection Bias","Character recognition;Classification algorithms;Computer science;Machine learning;Sampling methods;Statistical analysis;Supervised learning;Testing;Training data;Vectors","generalisation (artificial intelligence);learning (artificial intelligence);pattern classification;statistical analysis","car recognition;class labels;classifier;digit recognition;feature vectors;generalization;mapping;semisupervised Fisher linear discriminant;supervised learning;training set","","1","","15","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"A semantic web-based personalized learning service supported by on-line course resources","C. Huang; Y. Ji; R. Duan","Department of Computer Science, Sun Yat-Sen University, Guangzhou, 510275, China","INC2010: 6th International Conference on Networked Computing","20100614","2010","","","1","7","To provide personalized support in on-line course resources system, a semantic web-based personalized learning service is proposed to enhance the learner's learning efficiency. In this system four most important characteristics are semantically detailed to describe each learning object and learner. Then, a semantic mechanism is designed to compare the learner's personalization parameters with the learning objects' four characteristics, in which the learning resources and learning paths are dynamically recommended according to the knowledge point structures, learner profiles, learning objects by a recommendation algorithm. At the same time, learners can modify their own learning contents during the learning process. Experimental results show that the proposed system can improve learner learning efficiency and effectiveness.","","Electronic:978-89-88678-20-6; POD:978-1-4244-6986-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484800","learner ontology;learning object;learning style;personalized learning;semantic web","Algorithm design and analysis;Artificial intelligence;Computer science;Electronic learning;Information technology;Learning systems;Machine learning;Ontologies;Semantic Web;Sun","","","","1","","11","","","11-13 May 2010","","IEEE","IEEE Conference Publications"
"Thin Cloud Removing Approach of Color Remote Sensing Image Based on Support Vector Machine","J. Kong; G. Hu; D. Liang","Educ. Dept., Anhui Univ., Hefei, China","2010 Asia-Pacific Conference on Wearable Computing Systems","20100607","2010","","","131","135","This paper suggests a thin cloud removing approach of color remote sensing image based on support vector machine in HSI color model. The intensity component is decomposed in multi-scale by using strong edge capture ability of support vector machine, and the coefficients in different scales are obtained. Then abundant high frequency information is obtained by combining with directional filter bank. Reconstructed image is obtained through enhancing coefficients of high frequency and suppressing coefficients of low frequency. The saturation component is processed by exponential expand method, while the hue component is invariant. Experiments show that thin cloud can be removed efficiently by using the method introduced in this paper.","","Electronic:978-1-4244-6468-5; POD:978-1-4244-6467-8","10.1109/APWCS.2010.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481227","HSI;directional filter bank;image enhancement;support vector machine;thin cloud removing","Clouds;Filter bank;Frequency domain analysis;Image fusion;Information filtering;Information filters;Low pass filters;Machine learning;Remote sensing;Support vector machines","image colour analysis;image fusion;image reconstruction;remote sensing;support vector machines","HSI color model;cloud removing approach;color remote sensing image;image reconstruction;support vector machine","","3","","9","","","17-18 April 2010","","IEEE","IEEE Conference Publications"
"Non-convex group sparsity: Application to color imaging","A. Majumdar; R. K. Ward","Department of Electrical and Computer Engineering, University of British Columbia, Canada","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","469","472","This work investigates a group-sparse solution to the under-determined system of linear equations b=Ax where the unknown x is formed of a group of vectors x<sub>i</sub>'s. A group-sparse solution has only a few x<sub>i</sub> vectors as non-zeroes while the rest are zeroes. To seek a group-sparse solution generally a convex optimization problem is solved. Such an optimization criterion is unsuitable when the system is highly under-determined or when some of the vector x<sub>i</sub>'s are themselves sparse. For such cases, we propose an alternate non-convex optimization problem. Simulation results show that the proposed method yields significantly improved results (2 orders of magnitude) over the standard method. We also apply the proposed group-sparse optimization in a novel fashion to the problem of color imaging. The new method shows an improvement of more than 1dB over the standard method.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495703","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495703","color imaging;compressed sensing;group sparsity","Application software;Color;Compressed sensing;Equations;Focusing;Linear regression;Machine learning;Signal processing;Signal processing algorithms;Vectors","concave programming;convex programming;group theory;image colour analysis","color imaging;convex optimization problem;group-sparse solution;linear equation;nonconvex group sparsity;nonconvex optimization problem","","6","","13","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Enhancing Emerging Learning Objects with Contextual Metadata Using the Linked Data Approach","M. Svensson; A. Kurti; M. Milrad","Center for Learning & Knowledge Technol. (CeLeKT), Linnaeus Univ., Va&#x0308;xjo, Sweden","2010 6th IEEE International Conference on Wireless, Mobile, and Ubiquitous Technologies in Education","20100603","2010","","","50","56","The latest developments in mobile technologies have increased the possibility for users to generate digital content at any location and time. In this paper we present our current research efforts related to the ability to enhance digital content that emerge when mobile devices are used to support different learning activities. We believe that these emerging learning objects should be enriched with contextual characteristics in a machine interoperable and interpretable manner in order to preserve the meaning, or semantics, of those features. There are a number of approaches to address this problem but in the present article we focus on exploring the potential added value of using Linked Data to depict emerging learning objects with contextual metadata. Our preliminary findings indicate that Linked Data offers a flexible approach for supporting important aspects of digital content related to data linkage, data merge and semantic interoperability.","","Electronic:978-1-4244-6428-9; POD:978-1-4244-6427-2","10.1109/WMUTE.2010.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5476537","Digital content metadata;Emerging Learning Objects;Linked Data;Semantic Web","Context modeling;Couplings;Digital control;Educational technology;Machine learning;Mobile communication;Semantic Web;Terminology;Video sharing;XML","computer aided instruction;meta data;mobile computing","contextual metadata;digital content;learning objects;linked data approach;machine interoperable manner;machine interpretable manner;mobile technologies","","1","","22","","","12-16 April 2010","","IEEE","IEEE Conference Publications"
"North Atlantic right whale acoustic signal processing: Part II. improved decision architecture for auto-detection using multi-classifier combination methodology","P. J. Dugan; A. N. Rice; I. R. Urazghildiiev; C. W. Clark","Bioacoustics Research Program, Cornell Laboratory of Ornithology, Cornell University, Ithaca, NY 14850 USA","2010 IEEE Long Island Systems, Applications and Technology Conference","20100603","2010","","","1","6","Autonomous signal detection of the North Atlantic right whale (NRW), Eubalaena glacialis, is becoming an important factor in monitoring and conservation for this highly endangered species. Both online and offline systems exist to help study and protect animals within this population. In both cases auto-detection of species-specific calls plays a vital role in localizing individual animal by searching time-frequency passive acoustic data. This research presents an experimental system, referred to as the NRW-CRITIC, for automatic detection of the NRW contact call. In general, the CRITIC uses a combinatorial classifier approach to integrate a series of existing machine learning algorithms; each designed specifically for NRW contact call identification. The proposed configuration consists of several recognition methods running in parallel; these include linear discriminant analysis, artificial neural network (NET) and classification regression tree (CART). This paper presents the details for the NRW-CRITIC and discusses the approach used to combine multiple independent decisions into a single result. A side-by-side performance comparison, between the CRITIC and a well-known method, the feature vector testing (FVT), is summarized. Performance metrics are evaluated based on a large database of acoustic recordings consisting of over 58,000 NRW contact calls from various locations, including two critical habitats, Great South Channel and Cape Cod Bay. Results indicate the FVT algorithm yields a 74.7% detection probability with an error rate of 4.35%. In comparison the CRITIC, operating at similar information level yields a 78.02% detection probability with a 3.25% error rate, exceeding the performance of the FVT. Performance was also measured using data from a multi-channel acoustic array located in Massachusetts Bay. A side-by-side comparison of array presence is discussed for two separate days. Results show that with the FVT and CRITIC operating at 0% error for array pres- - ence, the FVT method had 18,769 and 24,469 false positives for the Massachusetts Bay datasets respectively. With the same 0% error condition the CRITIC provided successful detection with significantly lower number of false positive rates: 1,072 and 2,324 calls, respectively. Future extensions of this experimental work are also discussed.","","Electronic:978-1-4244-5550-8; POD:978-1-4244-5548-5","10.1109/LISAT.2010.5478287","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5478287","Acoustic Monitoring;Automated Detection;Multi-Classifier;Right Whale","Acoustic signal detection;Acoustic signal processing;Animals;Error analysis;Machine learning algorithms;Monitoring;Protection;Signal detection;Time frequency analysis;Whales","acoustic arrays;acoustic signal detection;acoustic signal processing;combinatorial mathematics;learning (artificial intelligence);neural nets;time-frequency analysis","FVT method;NRW contact call identification;NRW-CRITIC;acoustic recordings;artificial neural network;automatic detection;autonomous signal detection;classification regression tree;combinatorial classifier;detection probability;endangered species;feature vector testing;linear discriminant analysis;machine learning algorithm;multichannel acoustic array;multiple independent decisions;north Atlantic right whale acoustic signal processing;time-frequency passive acoustic data","","4","","22","","","7-7 May 2010","","IEEE","IEEE Conference Publications"
"Using semantics to learn about routing data for improved network management in the Future Internet","J. Strassner; S. S. Kim; J. W. K. Hong","Pohang University of Science and Technology","2010 IEEE/IFIP Network Operations and Management Symposium Workshops","20100617","2010","","","275","282","One of the most fundamental management aspects of the Future Internet is the representation of management and operational data. The vast majority of languages and data structures used by network device manufacturers, such as SNMP-based designs and Command Line Interfaces, are data-oriented and are incapable of representing semantics. In addition, such languages have no ability to represent business concepts, such as a Service Level Agreement, or higher-level concepts, such as the ability to maximize revenue for all users. This paper proposes a knowledge representation based on the combination of models, which represent facts, and ontologies, which enable machine-based reasoning and learning based on facts. We then define an approach to route information based on the underlying semantics of data. Our approach to semantic routing can be used for both semantic querying and network management tasks. It is implemented via a set of semantic overlay networks.","","Electronic:978-1-4244-6039-7; POD:978-1-4244-6037-3","10.1109/NOMSW.2010.5486563","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486563","information model;network management;ontology;overlay network;semantics","Data structures;Hardware;IP networks;Internet;Knowledge representation;Machine learning;Manufacturing;Ontologies;Routing;Utility programs","Internet;data structures;programming language semantics;semantic networks;telecommunication network management;telecommunication network routing","Command Line Interfaces;Internet;SNMP-based designs;Service Level Agreement;data structures;higher-level concepts;machine-based reasoning;network device manufacturers;network management tasks;routing data;semantic overlay networks;semantic querying;semantic routing;semantics","","0","","17","","","19-23 April 2010","","IEEE","IEEE Conference Publications"
"A SVM Based Relevance Feedback Algorithm for 3D Model Retrieval","Y. Pan; M. Zhou; Y. Fan; S. Yu","Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China","2010 Asia-Pacific Conference on Wearable Computing Systems","20100607","2010","","","139","142","In this paper, a novel relevance feedback algorithm based on SVM is proposed for 3d model retrieval. It aims to enhance retrieval accuracy in 3D model database systems. During the retrieval process, the system learns from the related samples marked by the user after each feedback, and update the training sample set with the previous returns. Thus an SVM classifier model is established and improved iteratively to retrieve. This method has strong generalization ability when the number of samples is small. In addition, this paper compares the performance of SVM with different kernel functions and the performance of SVM with the same kernel function using different low-level features.","","Electronic:978-1-4244-6468-5; POD:978-1-4244-6467-8","10.1109/APWCS.2010.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481231","relevance feedback;support vector machine;three-dimensional model retrieval","Content based retrieval;Distance measurement;Feedback;Image retrieval;Information retrieval;Kernel;Machine learning;Support vector machine classification;Support vector machines;Wearable computers","computer graphics;database management systems;relevance feedback;support vector machines","3D model database systems;3D model retrieval;SVM based relevance feedback algorithm;kernel function","","0","","11","","","17-18 April 2010","","IEEE","IEEE Conference Publications"
"Towards designing a spatio-temporal neural network for non-modular high content pathological screening","R. Talware; A. Abhyankar","Dept. of E&Tc, Engg, VIIT, Pune, India","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","7","","V7-708","V7-712","Cellular image analysis is being attempted by several Image Processing (IP), statistical approaches and machine learning (ML), Neural Networks (NN) techniques. IP based algorithms are getting trapped into subjectivity due to reasons of cell image properties and methods of extractions and classification techniques. ML based methods are also well explored, but it suffer from large training sets and feature selection to reduce dimensionality of neural network. This paper proposes design and integration of Evolutionary methodologies with temporal networks and on-the-fly learning for getting desired confidence interval with minimal training. IP based method is experimented with morphological feature extraction. Results revels that, utility limited to spatial and noise-free data. This emphasizes the need of evolutionary methodologies with temporal learning and for optimizing weights, structure and learning of NN. Paper presents results extracted from IP algorithm with its shortcoming and proposes framework based on Evolutionary ANN to overcome the subjectivity issue reported in text and experimentation.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485698","cancer;cellular image analysis;evolutionary methodologies;wavelet based framework","Cellular networks;Cellular neural networks;Feature extraction;Image analysis;Image processing;Machine learning;Machine learning algorithms;Neural networks;Optimization methods;Pathology","cellular biophysics;image classification;learning (artificial intelligence);medical image processing;neural nets","cell image properties;cellular image analysis;evolutionary methodology;feature selection;image processing;machine learning;morphological feature extraction;nonmodular high content pathological screening;spatio-temporal neural network;statistical approach;temporal learning;temporal networks","","0","","16","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Visualization and Explanation of Payload-Based Anomaly Detection","K. Rieck; P. Laskov","","2009 European Conference on Computer Network Defense","20100628","2009","","","29","36","The threat posed by modern network attacks requires novel means for detection of intrusions, as regular signature-based systems fail to cope with the amount and diversity of attacks. Recently, several methods for detection of anomalies in network payloads have been proposed to counteract this threat and identify novel attacks during their initial propagation. However, intrusion detection systems must not only flag malicious events but also provide information needed for assessment of security incidents. Previous work on payload-based anomaly detection has largely ignored this need for explainable decisions. In this paper, we present instruments for visualization and explanation of anomaly detection which can guide the decisions of a security operator. In particular, we propose two techniques: feature differences, for identifying relevant string features of detected anomalies, and feature shading, for highlighting of anomalous contents in network payloads. Both techniques are empirically evaluated using real attacks and network traces, whereby their ability to emphasize typical patterns of attacks is demonstrated.","","Electronic:978-1-4244-6050-2; POD:978-1-4244-6049-6","10.1109/EC2ND.2009.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5494337","anomaly detection;network intrusion detection","Computer networks;Computer security;Computer vision;Data security;Information security;Instruments;Intrusion detection;Machine learning;Payloads;Visualization","","","","3","","33","","","9-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Two-dimensional sparse principal component analysis for face recognition","C. Xiao","Faculty of Applied Mathematics, Guangdong University of Technology, Guangzhou, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","2","","V2-561","V2-565","Principal Component Analysis (PCA) is a wellknown and efficient technique for feature extraction and dimension reduction, which has been applied widely in community of machine learning and pattern recognition. But traditional PCA suffers from two disadvantages which restricts it's treatment of two dimensional data, like human faces, fingerprints, palmprints and other biological features which are usually represented by two dimensional image matrices. To perform the traditional PCA, the first work is to transform 2-d image matrices to 1-d vectors. But such matrix-to-vector transformation ignores the underlying local data structure and results in difficulty of dealing with high dimensional vectors. Secondly, transformed features are difficult to explain because each principal component is a linear combination of all original features, which is not appropriate for further data analysis. To overcome above two drawbacks, we proposed a novel approach 2dSPCA, namely two-dimensional Sparse Principal Component Analysis. 2dSPCA directly uses 2-d image instead of 1-d vector to compute covariance matrix, which reserves the local structure of face image and reduces significantly the dimension of covariance matrix, so the results are better for data representation and the computation of eigenvalue decomposition is more efficient. Furthermore, we transform eigenvalue decomposition problem to a ridge regression problem by the image covariance matrix, then imposes l<sub>1</sub> constraint on the regression coefficients to obtain sparse loadings. Since the problem is transformed to a Elastic Net optimization problem, the sparse loadings can be easily solved by LARS-EN algorithm. Sparsity makes the results more interpretable and easier to find the intrinsic relation among variables. We also proposed a supervised algorithm 2dSPCA+LDA to improve the recognition rate. Experimental results on face recognition show that both 2dSPCA and 2dSPCA+LDA achieve comparable or higher performance c- - ompared with 1-d cases.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497525","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497525","dimensionality reduction;face recognition;feature extraction;two-dimensional sparse principal component analysis","Covariance matrix;Eigenvalues and eigenfunctions;Face recognition;Feature extraction;Humans;Machine learning;Pattern analysis;Pattern recognition;Principal component analysis;Vectors","covariance matrices;data analysis;face recognition;feature extraction;optimisation;principal component analysis;regression analysis;sparse matrices","2dSPCA;LARS-EN algorithm;biological features;data analysis;data representation;dimension reduction;eigenvalue decomposition;elastic net optimization problem;feature extraction;fingerprint recognition;human face recognition;image covariance matrix;local data structure;machine learning;matrix-to-vector transformation;palmprint recognition;pattern recognition;regression coefficients;ridge regression problem;sparse loadings;two dimensional image matrices;two-dimensional sparse principal component analysis","","1","","11","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Fuzzy rough set model based on multi-granulations","M. Wu; G. Kou","Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","2","","V2-71","V2-75","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>This paper extends fuzzy rough set model based on single granulation to fuzzy rough set model based on multi-granulations, which is called as MGFRS. The lower and upper approximations of fuzzy sets are defined based multi-equivalence relations, and basic properties are investigated. It is shown that basic properties of fuzzy rough sets and MGRS model are special instance of MGFRS model. At the same time, the proofs of some properties of MGRS model are optimized and some mistakes are corrected. Finally, we propose an approximation measure of fuzzy sets based multi-granulations, and the approximation of a fuzzy set described using multi-granulations is always better than using single granulation.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485316","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485316","MGFRS model;approximation measure;fuzzy rough set;knowledge base;multi-granulations","Computers;Electronic mail;Entropy;Fuzzy set theory;Fuzzy sets;Information science;Machine learning;Pattern recognition;Rough sets;Set theory","fuzzy set theory","MGFRS;fuzzy rough set model;multi-equivalence relations;multigranulations;single granulation","","2","","11","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Shape-based semi-automatic hippocampal subfield segmentation with learning-based bias removal","H. Wang; S. R. Das; J. Pluta; C. Craige; M. Altinay; M. Weiner; S. Mueller; P. A. Yushkevich","Department of Radiology, University of Pennsylvania, Philadelphia, USA","2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro","20100621","2010","","","424","427","We develop a semi-automatic technique for segmentation of hippocampal subfields in T2-weighted in vivo brain MRI. The technique takes the binary segmentation of the whole hippocampus as input, and automatically labels the subfields inside the hippocampus segmentation. Shape priors for the hippocampal subfields are generated from shape-based normalization of whole hippocampi via the continuous medial representation method. To combine the shape priors with appearance features, we use a machine learning based method. The key novelty is that we treat the mistakes made by the shape priors as bias, which can be detected and corrected via learning. The main advantage of this formulation is that it significantly simplifies the learning problem by taking full advantage of current segmentations and focusing on only improving their drawbacks. Experiments show that the bias removal approach achieves significant improvement in all subfields. Our bias removal idea is general, and can be applied to improve other segmentation methods as well.","1945-7928;19457928","Electronic:978-1-4244-4126-6; POD:978-1-4244-4125-9","10.1109/ISBI.2010.5490318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5490318","bias correction;hippocampus;subfield","Biomedical imaging;Hippocampus;Image segmentation;In vivo;Learning systems;Machine learning;Magnetic resonance imaging;Nervous system;Radiology;Shape","biomedical MRI;image segmentation;medical image processing;neurophysiology","T2-weighted in vivo brain MRI;binary segmentation;hippocampus segmentation;learning problem;learning-based bias removal;machine learning based method;medial representation method;shape-based normalization;shape-based semi-automatic hippocampal subfield segmentation;whole hippocampus","","1","","13","","","14-17 April 2010","","IEEE","IEEE Conference Publications"
"Learning for Autonomous Navigation","J. A. Bagnell; D. Bradley; D. Silver; B. Sofman; A. Stentz","Associate research professor at CMU&#x0027;s Robotics Institute and National Robotics Engineering Center (NREC) and is cross-appointed with the Machine Learning Department.","IEEE Robotics & Automation Magazine","20100607","2010","17","2","74","84","Autonomous navigation by a mobile robot through L natural, unstructured terrain is one of the premier k challenges in field robotics. Tremendous advances V in autonomous navigation have been made recently in field robotics. Machine learning has played an increasingly important role in these advances. The Defense Advanced Research Projects Agency (DARPA) UGCV-Perceptor Integration (UPI) program was conceived to take a fresh approach to all aspects of autonomous outdoor mobile robot design, from vehicle design to the design of perception and control systems with the goal of achieving a leap in performance to enable the next generation of robotic applications in commercial, industrial, and military applications. The essential problem addressed by the UPI program is to enable safe autonomous traverse of a robot from Point A to Point B in the least time possible given a series of waypoints in complex, unstructured terrain separated by 0.2-2 km. To accomplish this goal, machine learning techniques were heavily used to provide robust and adaptive performance, while simultaneously reducing the required development and deployment time. This article describes the autonomous system, Crusher, developed for the UPI program and the learning approaches that aided in its successful performance.","1070-9932;10709932","","10.1109/MRA.2010.936946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481587","","Control systems;Defense industry;Electrical equipment industry;Industrial control;Machine learning;Mobile robots;Navigation;Remotely operated vehicles;Robustness;Service robots","learning (artificial intelligence);mobile robots;path planning","Crusher;UGCV-perceptor integration program;autonomous navigation;autonomous outdoor mobile robot design;defense advanced research projects agency;machine learning techniques;robotics;safe autonomous traverse","","13","","32","","","June 2010","","IEEE","IEEE Journals & Magazines"
"Robust and fast Vowel Recognition Using Optimum-Path Forest","J. P. Papa; A. N. Marana; A. A. Spadotto; R. C. Guido; A. X. Falcão","S&#227;o Paulo State University, Computer Science Department, Brazil","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2190","2193","The applications of Automatic Vowel Recognition (AVR), which is a sub-part of fundamental importance in most of the speech processing systems, vary from automatic interpretation of spoken language to biometrics. State-of-the-art systems for AVR are based on traditional machine learning models such as Artificial Neural Networks (ANNs) and Support Vector Machines (SVMs), however, such classifiers can not deal with efficiency and effectiveness at the same time, existing a gap to be explored when real-time processing is required. In this work, we present an algorithm for AVR based on the Optimum-Path Forest (OPF), which is an emergent pattern recognition technique recently introduced in literature. Adopting a supervised training procedure and using speech tags from two public datasets, we observed that OPF has outperformed ANNs, SVMs, plus other classifiers, in terms of training time and accuracy.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495695","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495695","Neural networks;Pattern recognition;Signal classification;Speech recognition","Artificial neural networks;Automatic speech recognition;Biometrics;Machine learning;Natural languages;Robustness;Speech processing;Speech recognition;Support vector machine classification;Support vector machines","biometrics (access control);learning (artificial intelligence);natural language processing;speech processing;speech recognition","automatic interpretation;automatic vowel recognition;biometrics;emergent pattern recognition technique;machine learning model;optimum path forest;speech processing system;supervised training procedure","","2","","19","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Knowledge Sharing and Reuse in Digital Forensics","J. Huang; A. Yasinsac; P. J. Hayes","Sch. of Comput. & Inf. Sci., Univ. of South Alabama, Mobile, AL, USA","2010 Fifth IEEE International Workshop on Systematic Approaches to Digital Forensic Engineering","20100624","2010","","","73","78","Digital investigation involves examining large volumes of data from heterogeneous sources. We offer a framework for facilitating examination and synthesis of this mountain of data using ontology matching and machine learning technology.","","Electronic:978-1-4244-7221-5; POD:978-1-4244-7220-8","10.1109/SADFE.2010.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5491886","and semantic integration;digital forensics;heterogeneous semantics;knowledge sharing;ontology matching","Artificial neural networks;Biological system modeling;Biology computing;Computational modeling;Data mining;Digital forensics;Hard disks;Humans;Machine learning;Ontologies","computer forensics;learning (artificial intelligence);ontologies (artificial intelligence)","digital forensic;digital investigation;knowledge sharing;machine learning;ontology matching","","1","","22","","","20-20 May 2010","","IEEE","IEEE Conference Publications"
"State Machine Inference in Testing Context with Long Counterexamples","M. N. Irfan","Comput. Sci. Lab., Grenoble Universities, St. Martin d'Heres, France","2010 Third International Conference on Software Testing, Verification and Validation","20100603","2010","","","508","511","We are working on the techniques which iteratively learn the formal models from black box implementations by testing. The novelty of the approach addressed here is our processing of the long counterexamples. There is a possibility that the counterexamples generated by a counterexample generator include needless sub sequences. We address the techniques which are developed to avoid the impact of such unwanted sequences on the learning process. The gain of the proposed algorithm is confirmed by considering a comprehensive set of experiments on the finite sate machines.","2159-4848;21594848","Electronic:978-1-4244-6436-4; POD:978-1-4244-6435-7","10.1109/ICST.2010.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477048","black box;counterexample;finite state machine;state machine inference","Computer science;Context modeling;Doped fiber amplifiers;Educational institutions;Indexing;Inference algorithms;Machine learning;Polynomials;Samarium;Software testing","finite state machines;inference mechanisms","black box implementations;finite sate machines;formal models;learning process;state machine inference","","0","","8","","","6-10 April 2010","","IEEE","IEEE Conference Publications"
"Probabilistic branching node detection using AdaBoost and hybrid local features","T. Nuzhnaya; M. Barnathan; H. Ling; V. Megalooikonomou; P. R. Bakic; A. D. A. Maidment","Data Engineering Laboratory (DEnLab), Department of Computer and Information Sciences, Temple University, 1805 N. Broad St. Philadelphia, PA 19122, USA","2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro","20100621","2010","","","221","224","Probabilistic branching node inference is an important step for analyzing branching patterns involved in many anatomic structures. Based on an approach we have developed previously, we investigate combining machine learning techniques and hybrid image statistics for probabilistic branching node inference, using adaptive boosting as a probabilistic inference framework. Then, we use local image statistics at different image scales for feature representation, including the Harris cornerness, Laplacian, eigenvalues of the Hessian, and Harralick texture features. The proposed approach is applied to a breast imaging dataset consisting of 30 images, 7 of which were previously reported. The use of boosting and the Harralick texture feature further improves upon our previous results, highlighting the role of texture in the analysis of the breast ducts and other branching structures.","1945-7928;19457928","Electronic:978-1-4244-4126-6; POD:978-1-4244-4125-9","10.1109/ISBI.2010.5490375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5490375","AdaBoost;Branching Structure;Breast Imaging","Anatomy;Biomedical imaging;Boosting;Breast;Image analysis;Image texture analysis;Machine learning;Statistics;Topology;Visualization","eigenvalues and eigenfunctions;feature extraction;gynaecology;image representation;image texture;inference mechanisms;learning (artificial intelligence);medical image processing;probability","Harralick texture feature;Harris cornerness;Hessian texture feature;adaptive boosting;anatomic structures;branching patterns;breast ducts;eigenvalues;feature representation;hybrid image statistics;image scales;local image statistics;machine learning;probabilistic branching node detection;probabilistic branching node inference","","1","","17","","","14-17 April 2010","","IEEE","IEEE Conference Publications"
"A nullspace analysis of the nuclear norm heuristic for rank minimization","K. Dvijotham; M. Fazel","University of Washington, Department of Computer Science and Engineering, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","3586","3589","The problem of minimizing the rank of a matrix subject to linear equality constraints arises in applications in machine learning, dimensionality reduction, and control theory, and is known to be NP-hard. A popular heuristic minimizes the nuclear norm (sum of the singular values) of the matrix instead of the rank, and was recently shown to give an exact solution in several scenarios. In this paper, we present a new analysis for this heuristic based on a property of the nullspace of the operator defining the constraints, called the spherical section property. We give conditions for the exact recovery of all matrices up to a certain rank, and show that these conditions hold with high probability for operators generated from random Gaussian ensembles. Our analysis provides simpler proofs than existing isometry-based methods, as well as robust recovery results when the matrix is not exactly low-rank.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495918","Matrix rank minimization;compressed sensing;convex optimization","Application software;Collaboration;Compressed sensing;Computer science;Constraint optimization;Constraint theory;Control theory;Machine learning;Robustness;System identification","Gaussian processes;computational complexity;matrix algebra;minimisation;random processes","NP-hard;exact recovery;isometry-based methods;linear equality constraints;matrix subject;nuclear norm heuristic;nullspace analysis;random Gaussian ensembles;rank minimization;spherical section property","","10","","14","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"An Improved method for segmentation of touching symbols in printed mathematical expressions","Dong-Yu Zhang; Xue-Dong Tian; Xin-Fu Li","College of Mathematics and Computer Science, Hehei University, Baoding, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","2","","251","253","The segmentation of touching symbols is one of the key factors which affect the performance of printed mathematical expression recognition system. An Improved method for segmentation of touching symbols in printed mathematical expressions is presented. This method is suitable for different types of touching symbols. Firstly, the outer contour of the symbol image is extracted based on contour tracing algorithm. Next, the concave corner points are detected by corner detection algorithm. These concave corner points are considered as the candidate segmentation points. Finally segmentation paths are constructed to achieve the segmentation of the touching symbol.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486679","Mathematical expression recognition;OCR;Symbol segmentation;Touching symbol segmentation","Character recognition;Computational intelligence;Computer science;Detection algorithms;Educational institutions;Image segmentation;Laboratories;Machine learning;Mathematics;Optical character recognition software","edge detection;feature extraction;image segmentation","concave corner point detection;contour tracing algorithm;corner detection algorithm;printed mathematical expression recognition system;symbol image outer contour extraction;touching symbol segmentation","","1","","8","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"Direction of arrival estimation based on smooth support vector regression","H. Xiang; J. Bin; Z. Jingli; S. Yueguang; Z. Liu","Communication Commanding Academy Wuhan, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","1","","V1-818","V1-822","In this paper, we propose a new approach on direction of arrival (DOA) estimation based on smooth support vector regression. The proposed method can achieve higher accurate estimates for DOA while avoiding the all-direction peak value searching technique used in other traditional DOA estimation methods. Meanwhile, this approach reduces the extensive computations required by conventional super resolution algorithms such as MUSIC and is easier to implement in real-time applications. The proposed method map among the outputs of the array and the DOAs by means of a family of support vector machines. Computer simulation results show the effectiveness of the proposed method.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497314","Direction of Arrival(DOA) estimation;Support Vector Machine(SVM);smooth support vector regression(SSVR)","Constraint optimization;Convergence;Direction of arrival estimation;Helium;Machine learning;Multiple signal classification;Neural networks;Smoothing methods;Sun;Support vector machines","antenna arrays;antenna theory;array signal processing;direction-of-arrival estimation;regression analysis;support vector machines;vectors","DOA;MUSIC;all-direction peak value searching technique;direction of arrival estimation;smooth support vector regression;support vector machines","","1","","13","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Improving activity classification for health applications on mobile devices using active and semi-supervised learning","B. Longstaff; S. Reddy; D. Estrin","Center for Embedded Networked Sensing, University of California Los Angeles, USA","2010 4th International Conference on Pervasive Computing Technologies for Healthcare","20100607","2010","","","1","7","Mobile phones' increasing ubiquity has created many opportunities for personal context sensing. Personal activity is an important part of a user's context, and automatically recognizing it is vital for health and fitness monitoring applications. Recording a stream of activity data enables monitoring patients with chronic conditions affecting ambulation and motion, as well as those undergoing rehabilitation treatments. Modern mobile phones are powerful enough to perform activity classification in real time, but they typically use a static classifier that is trained in advance or require the user to manually add training data after the application is on his/her device. This paper investigates ways of automatically augmenting activity classifiers after they are deployed in an application. It compares active learning and three different semi-supervised learning methods, self-learning, En-Co-Training, and democratic co-learning, to determine which show promise for this purpose. The results show that active learning, En-Co-Training, and democratic co-learning perform well when the initial classifier's accuracy is low (75-80%). When the initial accuracy is already high (90%), these methods are no longer effective, but they do not hurt the accuracy either. Overall, active learning gave the highest improvement, but democratic co-learning was almost as good and does not require user interaction. Thus, democratic co-learning would be the best choice for most applications, since it would significantly increase the accuracy for initial classifiers that performed poorly.","2153-1633;21531633","Electronic:978-963-9799-89-9","10.4108/ICST.PERVASIVEHEALTH2010.8851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482296","","Biomedical monitoring;Cardiac disease;Cardiovascular diseases;Machine learning algorithms;Mobile handsets;Patient monitoring;Semisupervised learning;Smart phones;Training data;User interfaces","learning (artificial intelligence);mobile computing;patient monitoring;patient rehabilitation","active learning;activity classification;democratic co-learning;en-co-training;health applications;mobile devices;patients monitoring;personal context sensing;rehabilitation treatments;semi supervised learning","","21","","17","","","22-25 March 2010","","IEEE","IEEE Conference Publications"
"Algorithm with database technology for computing the core based on Skowron's discernibility matrix","Guiying Wei","School of Economics and Management, University of Science and Technology Beijing, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","2","","380","384","Designing efficient algorithm for computing the core of decision table is a very meaningful work because the core is the foundation of constructing attribute reduction of the decision table and multi-variable decision tree. To improve the efficiency of the algorithm for computing the core based on Skowron's discernibility matrix with database technology, the new simplified decision table of the old decision table is defined. And it is proved that the core of the new simplified decision table based on positive region is the same as the core of the old one based on Skowron's discernibility matrix. Then an efficient algorithm is proposed for computing the new simplicity decision table. On this condition, an efficient algorithm for computing the core based on Skowron's disceribility matrix by using database technology is designed. At the end, an example is used to illustrate the efficiency of the new algorithm.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486650","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486650","complexity;core;database;discernibility matrix;simplified decision table","Algorithm design and analysis;Computational complexity;Data mining;Databases;Decision trees;Expert systems;Machine learning algorithms;Paper technology;Set theory;Technology management","computational complexity;database theory;decision tables;decision trees;matrix algebra;rough set theory","Skowron discernibility matrix;database technology;decision table core attribute reduction;multivariable decision tree;time complexity","","0","","13","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"Theoretical analyses for a class of kernels with an invariant metric","A. Tanaka; M. Miyakoshi","Division of Computer Science, Hokkaido University, N14W9, Kita-ku, Sapporo, 060-0814 Japan","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2074","2077","One of central topics of kernel machines in the field of machine learning is a model selection, especially a selection of a kernel or its parameters. In our previous work, we discussed a class of kernels whose corresponding reproducing kernel Hilbert spaces have an invariant metric and proved that the kernel corresponding to the smallest reproducing kernel Hilbert space, including an unknown true function, gives the optimal model. However, discussions for properties that make the metrics of reproducing kernel Hilbert spaces invariant are insufficient. In this paper, we show a necessary and sufficient condition that makes the metrics of reproducing kernel Hilbert spaces invariant.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495065","generalization ability;kernel machine;metric;reproducing kernel Hilbert space","Computer science;Extraterrestrial measurements;Hilbert space;Information science;Kernel;Machine learning;Pattern recognition;Sampling methods;Sufficient conditions","Hilbert spaces;learning (artificial intelligence)","class of kernels;invariant metric;kernel Hilbert space;kernel machines;machine learning;model selection","","1","","11","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Identifying symptoms of recurrent faults in log files of distributed information systems","T. Reidemeister; M. A. Munawar; P. A. S. Ward","Shoshin Distributed Systems Group, E&CE Department, University of Waterloo, Ontario, Canada","2010 IEEE Network Operations and Management Symposium - NOMS 2010","20100617","2010","","","187","194","The manual process to identifying causes of failure in distributed information systems is difficult and time-consuming. The underlying reason is the large size and complexity of these systems, and the vast amount of monitoring data they generate. Despite its high cost, this manual process is necessary in order to avoid the detrimental consequences of system downtime. Several studies and operator practice suggest that a large fraction of the failures in these systems are caused by recurrent faults. Therefore, significant efficiency gains can be achieved by automating the identification of these faults. In this work we present methods, which draw from the areas of information retrieval as well as machine learning, to automate the task of infering symptoms pertinent to failures caused by specific faults. In particular, we present a method to infer message types from plain-text log messages, and we leverage these types to train classifiers and extract rules to identify symptoms of recurrent faults automatically.","1542-1201;15421201","Electronic:978-1-4244-5367-2; POD:978-1-4244-5366-5; USB:978-1-4244-5367-2; USB:978-1-5090-5692-7","10.1109/NOMS.2010.5488459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5488459","","Condition monitoring;Costs;Data mining;Distributed information systems;Fault diagnosis;Humans;Information retrieval;Machine learning;Management information systems;Performance analysis","computer network management;fault tolerant computing;information retrieval;learning (artificial intelligence)","distributed information systems;efficiency gain;fault diagnosis;information retrieval;log files;machine learning;plain-text log messages;recurrent faults;system downtime","","2","","34","","","19-23 April 2010","","IEEE","IEEE Conference Publications"
"Statistical hypothesis testing with time-frequency surrogates to check signal stationarity","C. Richard; A. Ferrari; H. Amoud; P. Honeine; P. Flandrin; P. Borgnat","Laboratoire Fizeau (UMR CNRS 6525), Observatoire de la C&#244;te d'Azur, Universit&#233; de Nice Sophia-Antipolis, France","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","3666","3669","An operational framework is developed for testing stationarity relatively to an observation scale. The proposed method makes use of a family of stationary surrogates for defining the null hypothesis of stationarity. As a further contribution to the field, we demonstrate the strict-sense stationarity of surrogate signals and we exploit this property to derive the asymptotic distributions of their spectrogram and power spectral density. A statistical hypothesis testing framework is then proposed to check signal stationarity. Finally, some results are shown on a typical model of signals that can be thought of as stationary or nonstationary, depending on the observation scale used.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495887","Time-frequency analysis;probability density function;spectrogram;stationarity test;surrogate","Data mining;Feature extraction;Machine learning;Probability density function;Signal analysis;Signal processing;Spectrogram;Tellurium;Testing;Time frequency analysis","probability;signal processing;time-frequency analysis","power spectral density;signal stationarity;spectrogram;statistical hypothesis testing;strict-sense stationarity;surrogate signals;time-frequency surrogates","","5","","8","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"An extension model of rough set in incomplete information system","Y. Wu; Q. Guo","Department of Computer Science, Zhongshan University, Guangzhou, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","2","","V2-434","V2-438","The rough set theory, based on the original definition of complete information system, is not useful for analyzing the incomplete information system where some values of attributes are unknown. Therefore, it needs to extend the classical rough set model to deal with the incomplete information system. The present extensions mainly have the tolerance relation, the non-symmetric similarity relation, the valued tolerance relation, the limited tolerance relation as well as other improved models based on the above relations. In this paper, we study the non-symmetric relation and the limited tolerance relation. Also, we propose a new extension model of rough set based on the non-symmetric similarity relation and the limited tolerance relation. In addition, we give an example to illustrate the conceptual argument and explain the superiority of the new model. Finally, we provide some properties of the extension model we proposed.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497472","incomplete information system;limited tolerance relation;non-symmetic similarity relation;rough set;tolerance relation","Computer science;Data mining;Information analysis;Information systems;Information technology;Knowledge acquisition;Machine learning;Set theory;Uncertainty;Virtual colonoscopy","information systems;rough set theory","incomplete information system;limited tolerance relation;nonsymmetric similarity relation;rough set extension model;tolerance relation;valued tolerance relation","","0","","12","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"A supervisory approach to semi-supervised clustering","B. Conroy; Y. T. Xi; P. Ramadge","Dept. of Electrical Engineering, Princeton University, N.J., USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","1858","1861","We propose a new approach to semi-supervised clustering that utilizes boosting to simultaneously learn both a similarity measure and a clustering of the data from given instance-level must-link and cannot-link constraints. The approach is distinctive in that it uses a supervising feedback loop to gradually update the similarity while at the same time guiding an underlying unsupervised clustering algorithm. Our approach is grounded in the theory of boosting. We provide three examples of the clustering algorithm on real datasets.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495368","Algorithms;Clustering methods;Learning systems;Pattern classification","Boosting;Classification algorithms;Clustering algorithms;Clustering methods;Feedback loop;Learning systems;Machine learning algorithms;Message passing;Partitioning algorithms;Pattern classification","feedback;pattern clustering;unsupervised learning","data clustering;semi-supervised clustering;supervising feedback loop;unsupervised clustering algorithm","","1","","15","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"A classification method based on PAM algorithm and discrete preprocess","H. Yang; L. Li","School of Business, Guilin University of Electronic Technology, Guilin, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","2","","V2-82","V2-86","Using clustering method to generate training set, and applying rough set theory to discretization preprocess, the classification accuracy can be improve well. This paper applied PAM clustering algorithm to constitute a training set from original sample, used a discrete algorithm that integrates Boolean logic with rough set theory to discretize the training set, and trained classifier by the discrete training set. When classification was carried out in the same data set, experimental results showed that compared to the RDDTE method only based on the PAM algorithm to preprocess, the classification accuracy based on the new method increased 15.5 percentage points at most. Besides, the new method selected a smaller amount of training set.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497346","PAM;cross validation;data discretization;heuristic algorithm","Boolean functions;Clustering algorithms;Clustering methods;Decision trees;Information systems;Information technology;Machine learning algorithms;Production;Set theory;Training data","Boolean functions;pattern classification;pattern clustering;rough set theory","Boolean logic;PAM clustering algorithm;classification method;discrete preprocess;discrete training set;rough set theory","","0","","10","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"A Framework for Malware Detection Using Combination Technique and Signature Generation","M. F. Zolkipli; A. Jantan","Sch. of Comput. Sci., Univ. Sains Malaysia, Minden, Malaysia","2010 Second International Conference on Computer Research and Development","20100621","2010","","","196","199","Malware detection must apply sophisticated technique to minimize malware thread that can break computer operation. Nowadays malware writers try to avoid detection by using several techniques such as polymorphic, hiding and also zero day of attack. However, commercial anti-virus or anti-spyware that used signature-based matching to detects malware cannot solve that kind of attack. In order to overcome this issue, we propose a new framework for malware detection that combines signature-based technique and genetic algorithm technique. This framework consists of three main components such as s-based detection, GA detection and signature generator. These three main components will work together as interrelated process in our propose framework. Result from this study is the new framework that design to solve new launce malware and also to generate signature automatically that can be used on signature-based detection.","","Electronic:978-1-4244-6993-2; POD:978-1-4244-6992-5","10.1109/ICCRD.2010.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5489509","combination technique;genetic algorithm (GA);malware detection;signature-based","Computer networks;Computer science;Computer worms;Data security;Electronic mail;Genetic algorithms;Invasive software;Machine learning;Research and development;Yarn","digital signatures;genetic algorithms;invasive software;pattern matching","anti-spyware;commercial anti-virus;genetic algorithm technique;malware detection;signature based matching;signature generation;signature-based technique","","3","1","13","","","7-10 May 2010","","IEEE","IEEE Conference Publications"
"High Performance Dimension Reduction and Visualization for Large High-Dimensional Data Analysis","J. Y. Choi; S. H. Bae; X. Qiu; G. Fox","Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA","2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing","20100624","2010","","","331","340","Large high dimension datasets are of growing importance in many fields and it is important to be able to visualize them for understanding the results of data mining approaches or just for browsing them in a way that distance between points in visualization (2D or 3D) space tracks that in original high dimensional space. Dimension reduction is a well understood approach but can be very time and memory intensive for large problems. Here we report on parallel algorithms for Scaling by MAjorizing a Complicated Function (SMACOF) to solve Multidimensional Scaling problem and Generative Topographic Mapping (GTM). The former is particularly time consuming with complexity that grows as square of data set size but has advantage that it does not require explicit vectors for dataset points but just measurement of inter-point dissimilarities. We compare SMACOF and GTM on a subset of the NIH PubChem database which has binary vectors of length 166 bits. We find good parallel performance for both GTM and SMACOF and strong correlation between the dimension-reduced PubChem data from these two methods.","","Electronic:978-1-4244-6988-8; POD:978-1-4244-6987-1","10.1109/CCGRID.2010.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5493466","","Clouds;Clustering algorithms;Concurrent computing;Data analysis;Data mining;Data visualization;Grid computing;High performance computing;Machine learning algorithms;Multidimensional systems","","","","5","","22","","","17-20 May 2010","","IEEE","IEEE Conference Publications"
"A New Discretization Approach of Continuous Attributes","E. Xu; S. Liangshan; R. Yongchang; W. Hao; Q. Feng","Electron. & Inf. Eng. Coll., Liaoning Univ. of Technol., Jinzhou, China","2010 Asia-Pacific Conference on Wearable Computing Systems","20100607","2010","","","136","138","To deal with the discretization problem in an information system, a new discretization approach of continuous attributes is proposed in this paper based on the relative entropy and rough set theory. The candidate interval class-information entropy is used to select the threshold boundary for discretization in this method. And the redundant cut points are removed through the inspection of the cut point value of each attribute to discretize the condition attributes and decision attributes in an information system. Experiment results show that the method is simple and effective.","","Electronic:978-1-4244-6468-5; POD:978-1-4244-6467-8","10.1109/APWCS.2010.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481228","cut points;discretization;information system;relative entropy;rough set theory","Data mining;Databases;Educational institutions;Information entropy;Information systems;Inspection;Machine learning;Machine learning algorithms;Set theory;Wearable computers","data mining;entropy;information systems;learning (artificial intelligence);rough set theory","continuous attributes;discretization approach;information system;relative entropy;rough set theory","","0","","5","","","17-18 April 2010","","IEEE","IEEE Conference Publications"
"Research on incremental calculation of maximum distribution reductions for inconsistent information systems","H. T. Chen; H. J. Pan; J. Liu","School of Mathematics, Physics, and Information Science, Zhejiang Ocean University, Zhou Shan, China","INC2010: 6th International Conference on Networked Computing","20100614","2010","","","1","4","Maximum distribution reduction can obtain maximum credibility rules from an inconsistent information system. The paper analyzes various situations may be encountered when incremental objects add to an inconsistent information system, and then provides ways about how to incrementally update discernibility formula. The analysis results show that, in most cases, with the incremental object coming, discernibility formula only need incremental updating, But when incremental object causes values of maximum credibility function of two equivalence classes from different to same, because there is no inverse operation of conjunctive operation, incremental computing can not be performed. Complexity of the problem is analyzed finally.","","Electronic:978-89-88678-20-6; POD:978-1-4244-6986-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484821","Rough set;attributes reduction;inconsistent system;maximum distribution reduction","Data mining;Information analysis;Information science;Information systems;Machine learning algorithms;Mathematics;Oceans;Physics;Rough sets;Set theory","","","","0","","15","","","11-13 May 2010","","IEEE","IEEE Conference Publications"
"Research on Spectral Clustering algorithms and prospects","Shifei Ding; L. Zhang; Y. Zhang","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","6","","V6-149","V6-153","Along with the expansion and in-depth of the application domain of cluster analysis, one kind of new cluster algorithm called Spectral Clustering algorithm has been aroused great concern by scholars, Spectral Clustering algorithm is newly developing technique in the field of machine learning in recent years. Unlike the traditional clustering algorithms, this can solve the clustering of non-convex sphere of sample spaces and has globally optimal solution. This paper introduces the principle, the induction summary to the current research situation of Spectral Clustering algorithm as well as in various application domains. Firstly, the analysis and induction of some Spectral Clustering algorithms have been made from several aspects, such as the ideas of algorithm, key technology, advantage and disadvantage. On the other hand, some typical Spectral Clustering algorithms have been selected to analyze and compare. Finally, it points out the key problems and future directions.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5486345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486345","Laplacian Matri;cluster analysis;eigenvalue;graph partition;spectral clustering","Algorithm design and analysis;Clustering algorithms;Computer science;Data analysis;Electronic mail;Information analysis;Laplace equations;Machine learning;Machine learning algorithms;Partitioning algorithms","graph theory;learning (artificial intelligence);pattern clustering","cluster analysis;graph partition;machine learning;nonconvex sphere clustering;spectral clustering algorithm","","0","","36","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Arff convertor tool for WEKA data mining software","R. Robu; V. Stoicu-Tivadar","Politehnica University from Timisoara, Timisoara, Romania","2010 International Joint Conference on Computational Cybernetics and Technical Informatics","20100621","2010","","","247","251","The paper presents a tool that exports data from different database types into arff format, in order to be used by WEKA data mining and machine learning software. The developed application allows the connection to databases, the visualization of the relationships between tables, the visualization of the structure and of the content of these databases throughout several uniform and dynamic interfaces as well as generating entry files (arff files) for WEKA, that contain data from one or more related tables. In order to use the developed tool, there is no SQL knowledge required. The application determines the numeric, categorical, string and data attributes. For further validation, using the developed application and WEKA, the authors have realized an educational data mining study on a Microsoft Visual Fox Pro database, including data concerning 2100 students. These data have been extracted from the student management application that is working inside Faculty of Automation and Computers of “Politehnica” University from Timisoara.","","Electronic:978-1-4244-7433-2; POD:978-1-4244-7432-5","10.1109/ICCCYB.2010.5491291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5491291","","Application software;Clustering algorithms;Converters;Data mining;Data visualization;Graphics;Instruments;Machine learning;Software tools;Visual databases","","","","0","","9","","","27-29 May 2010","","IEEE","IEEE Conference Publications"
"Selective SVM ensemble based on discretization method","Tie Cai; Xing Wu","Institute of Information Technology, Shenzhen Institute of Information Technology, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","1","","V1-148","V1-151","To improve the classification performance, a novel SVM ensemble learning algorithm based on discretization method and selective ensemble approach is proposed in this paper. This algorithm uses the discretized data sets obtained by the rough sets and Boolean reasoning method to construct individual SVMs with good diversity, which can improve the performance of ensemble learning. After every SVM is trained separately, a selective approach to SVM ensemble is utilized to reduce the ensemble size and improve its performance. Experimental comparison of the proposed algorithm against the traditional ensemble learning methods such as Bagging and Adaboost shows that it leads to small ensembles with better performance.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5486241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486241","discretization;ensemble learning;selective ensemble;support vector machine (SVM)","Bagging;Classification tree analysis;Diversity reception;Information technology;Machine learning;Partitioning algorithms;Production;Support vector machine classification;Support vector machines;Voting","learning (artificial intelligence);support vector machines","Adaboost;Bagging;Boolean reasoning method;SVM ensemble learning algorithm;discretization method;discretized data set;rough set;selective ensemble approach","","0","","12","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Recent advances in Learning Automata systems","B. J. Oommen","School of Computer Science, Carleton University, Ottawa, ON: K1S5B6, Canada","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","1","","V1-724","V1-735","This paper presents an overview of the field of Stochastic Learning Automata (LA), and concentrates, in particular, on the most recent advances in the field. LA, which have been studied for more than three decades, are probabilistic finite state machines that can model how biological systems can learn. The structure of such a machine can be fixed, or it can be changing with time. A LA can also be implemented by using action probability updating rules which may or may not depend on estimates from the Environment being investigated. While, traditionally, these updating rules have worked with the continuous probability space, we will explain how LA can be designed by discretizing the probability space. The paper will describe the design and analysis of both continuous and discretized LA, and will highlight the subtle differences between the corresponding learning machines, their convergence properties, and their learning capabilities. The paper will then discuss the most recent developments such as the Generalized Thathachar-Sastry estimator scheme. The paper also includes a comprehensive list of the applications in which LA have proven their powerful potential.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485366","Continuous Learning Automata;Discretized Learning Automata;Estimator-based Learning Automata;Learning Automata","Biological system modeling;Biological systems;Computer science;Convergence;Gold;Learning automata;Machine learning;Psychology;Stochastic processes;Stochastic systems","finite state machines;learning automata;probabilistic automata","action probability updating rules;biological systems;continuous probability space;generalized Thathachar-Sastry estimator scheme;learning automata systems;probabilistic finite state machines;stochastic learning automata","","8","","63","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Automatic state discovery for unstructured audio scene classification","J. Ramos; S. Siddiqi; A. Dubrawski; G. Gordon; A. Sharma","School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213 USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2154","2157","In this paper we present a novel scheme for unstructured audio scene classification that possesses three highly desirable and powerful features: autonomy, scalability, and robustness. Our scheme is based on our recently introduced machine learning algorithm called Simultaneous Temporal And Contextual Splitting (STACS) that discovers the appropriate number of states and efficiently learns accurate Hidden Markov Model (HMM) parameters for the given data. STACS-based algorithms train HMMs up to five times faster than Baum-Welch, avoid the overfitting problem commonly encountered in learning large state-space HMMs using Expectation Maximization (EM) methods such as Baum-Welch, and achieve superior classification results on a very diverse dataset with minimal pre-processing. Furthermore, our scheme has proven to be highly effective for building real-world applications and has been integrated into a commercial surveillance system as an event detection component.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495605","HiddenMarkovModels;audio classification;topology learning","Data mining;Event detection;Hidden Markov models;Layout;Machine learning algorithms;Robustness;Speech;State-space methods;Surveillance;Topology","audio signal processing;expectation-maximisation algorithm;hidden Markov models;learning (artificial intelligence);surveillance","STACS;automatic state discovery;commercial surveillance system;event detection component;expectation maximization methods;hidden Markov model;machine learning;simultaneous temporal and contextual splitting;unstructured audio scene classification","","1","","12","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Medical image retrieval based on low level feature and high level semantic feature","Qing-zhu Wang; Ke Wang; Xin-zhu Wang","School of Communication Engineering, Jilin University, Changchun, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","7","","V7-430","V7-432","A medical image retrieval system combined of the low-level image feature and high-level semantic is used in the paper witch includes two main parts: image preprocessing and the machine learning. In the first part, feature tree structure is presented to reduce the semantic gap and in the latter part, a novel machine learning method based on SVM is presented to optimize the Network parameters by which improve the effect of semantic annotation and recognition rate. Preliminary test results form clinical images prove feasibility of the retrieval system and support the theory presented in the project.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485512","Feature tree structure;Medicine image retrieval;SVM","Biomedical engineering;Biomedical imaging;Content based retrieval;Image retrieval;Image segmentation;Learning systems;Machine learning;Medical diagnostic imaging;Pathology;Tree data structures","image retrieval;learning (artificial intelligence);medical image processing;support vector machines;tree data structures","SVM;feature tree structure;high level semantic feature;image preprocessing;low level feature;machine learning;medical image retrieval system;recognition rate;semantic annotation;semantic gap","","0","","11","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Normalization of text messages for text-to-speech","D. L. Pennell; Y. Liu","The University of Texas at Dallas, Computer Science Department, 800 West Campbell Road, Richardson, 75080, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","4842","4845","This paper describes a normalization system for text messages to allow them to be read by a TTS engine. To address the large number of texting abbreviations, we use a statistical classifier to learn when to delete a character. The features we use are based on character context, function, and position in the word and containing syllable. To ensure that our system is robust to different abbreviations for a word, we generate multiple abbreviation hypotheses for each word based on the classifier's prediction. We then reverse the mappings to enable prediction of English words from the abbreviations. Our results show that this approach is feasible and warrants further exploration.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495127","abbreviation;text messages;text normalization;text-to-speech","Cellular phones;Computer science;Engines;Hidden Markov models;Machine learning;Natural languages;Robustness;Safety;Speech synthesis;Supervised learning","speech synthesis","English words;character context;character function;character position;multiple abbreviation hypotheses;normalization system;statistical classifier;text messages;text-to-speech engine","","6","3","11","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Dynamic support vector machine by distributing kernel function","S. Guangzhi; D. Lianglong; H. Junchuan; Z. Yanxia","Navy Submarine Academy, Qingdao, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","2","","362","365","A dynamic support vector machine by distributing kernel function is put forward by integrating the target feature with the SVM. It distributes different Gauss kernel function to each training sample by using the distance between the target feature and each training sample. It is trained after the dynamic set is reconstructed according to the distance between the target feature and each training sample. Experiment results show that it is more robust than the traditional SVM.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486654","Gauss kernel function;dynamic support vector machine;support vector machine (SVM);target recognition","Artificial intelligence;Gaussian distribution;Gaussian processes;Kernel;Machine learning;Robustness;Support vector machine classification;Support vector machines;Target recognition;Underwater vehicles","Gaussian processes;support vector machines","Gauss kernel function;distributing kernel function;dynamic set;dynamic support vector machine","","0","","12","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"Automatic semantic image classification and retrieval based on the weighted feature algorithm","Keping Wang; Xiaojie Wang; Ke Zhang; Yixin Zhong","Department of Computer Science, Beijing University of Posts and Telecommunications, 100110, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","2","","87","91","Organizing images into meaningful (semantically) categories using low-level visual features is a challenging and important problem in content-based image retrieval. Clustering algorithms make it possible to represent visual features of images with finite symbols. However, there are two problems in most current image clustering algorithms. One is without considering the choice of the initial cluster centers which have a direct impact on the formation of final clusters, and the other is without considering the relevant features and assigning equal weights to these feature dimensions. According to the two problems we propose a weighted features algorithm. First, we use the labeled image samples to calculate the weight for each feature according to the feature degree of discrete. These weighted features have been used to calculate the initial cluster centers because they can well represent the cluster. Then, we use the weighted features(based on the different image data set) algorithm to discard the irrelevant features and reduce the feature dimensions through the whole clustering process. Experimental results and comparisons are given to illustrate the performance of the new algorithm.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5487186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487186","cluster;content-based image retrieval;semantic image classification;weighted feature","Clustering algorithms;Computer science;Content based retrieval;Image classification;Image retrieval;Machine learning;Machine learning algorithms;Partitioning algorithms;Publishing;Remote sensing","content-based retrieval;feature extraction;image classification;image retrieval;pattern clustering","cluster center;content-based image retrieval;image clustering;image representation;semantic image classification;visual features;weighted features algorithm","","0","","14","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"Video action recognition with spatio-temporal graph embedding and spline modeling","Y. Yuan; H. Zheng; Z. Li; D. Zhang","Dept of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","2422","2425","In recent years, video analysis and event recognition are becoming a popular research topic with wide applications in surveillance and security. In this paper, we proposed a video action appearance modeling based on spatio-temporal graph embedding and video action recognition based on video luminance field trajectory spline modeling and aligned matching. Graphs are computed from spline re-sampling of training video data set. Matching is achieved from minimizing the average projection distance between query clips and training groups. Simulation with the Cambridge hand gesture data set demonstrates the effectiveness of the proposed solution.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5496275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5496275","Appearance modeling;Graph Embedding;Spline Modeling;Video Event Analysis","Computational modeling;Computer vision;Data security;Embedded computing;Humans;Machine learning;Robustness;Spline;Surveillance;Tensile stress","graph theory;image motion analysis;splines (mathematics);video signal processing","Cambridge hand gesture data set;event recognition;graphs;security;spatio temporal graph embedding;spline modeling;spline resampling;surveillance;training video data set;video action appearance modeling;video action recognition;video analysis","","3","","12","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"AVI: Based on the vertical and intersection operation of the improved Apriori algorithm","Y. Zhang; J. Chen","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","2","","V2-718","V2-721","Association Rules is the extraction of data mining in the important research, analysis and research in the Apriori algorithm for association rule, the algorithm for computing efficiency is not high, proposing an improved algorithm AVI (Apriori with vertical and intersection operation) that use itemset union and identification intersection, just scanning the transaction database one time that can get the identity of a set of first-order and large set of vertical. K-order designate the options set for this operation as long as the first order of the large itemsets, scanning the database without having to repeat, thereby improving the efficiency of the mining algorithms.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497596","AVI algorithm;Apriori algorithm;association rules;data mining","Algorithm design and analysis;Association rules;Computer science;Data mining;Electronic mail;Itemsets;Machine learning algorithms;Object oriented databases;Transaction databases;Visual databases","data mining","AVI;apriori with vertical and intersection operation;association rules;computing efficiency;data mining;identification intersection;improved Apriori algorithm;itemset union;scanning;transaction database","","1","","8","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Online adaptive modulation and coding with support vector machines","R. Daniels; R. W. Heath","Wireless Networking and Communication Group, Dept. of Computer and Electrical Engineering The University of Texas at Austin, 1 University Station C0803, Austin, TX 78712, USA","2010 European Wireless Conference (EW)","20100610","2010","","","718","724","Optimizing the performance of adaptive modulation and coding (AMC) in practice has proven challenging. Prior research has struggled to find link quality metrics that are suitable for look-up-tables and simultaneously provide an injective mapping to error rate in wireless links that feature selective channels with hardware nonlinearities and non-Gaussian noise effects. This paper proposes a novel online support vector machine algorithm, compatible with accurate multidimensional link quality metrics, that is able to optimize AMC to the unique (potentially dynamic) hardware characteristics of each wireless device in selective channels. IEEE 802.11n simulations show that our proposed algorithm allows each individual wireless device to optimize the operating point in the rate/reliability tradeoff through frame-by-frame error evaluation. These simulations also show that our algorithm displays identical performance to alternative online AMC algorithms while drastically reducing complexity.","","Electronic:978-1-4244-6001-4; POD:978-1-4244-5999-5","10.1109/EW.2010.5483527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5483527","","Current measurement;Error analysis;Hardware;Machine learning;Machine learning algorithms;Modulation coding;Support vector machine classification;Support vector machines;Training data;Wireless communication","adaptive codes;adaptive modulation;radio links;support vector machines;telecommunication computing;wireless LAN","IEEE 802.11n;adaptive coding;feature selective channels;hardware nonlinearities;injective mapping;look-up-tables;multidimensional link quality metrics;nonGaussian noise effects;online adaptive modulation;support vector machine;wireless device;wireless links","","12","","24","","","12-15 April 2010","","IEEE","IEEE Conference Publications"
"Freeway network traffic management based on distributed reinforcement learning","K. Wen; W. Yang; S. Qu","School of Electronics and Control Engineering, Chang'an University, Xi'an, Shaanxi, China","2010 2nd IEEE International Conference on Information Management and Engineering","20100603","2010","","","684","687","A distributed machine learning approach in traffic flow control and dynamic route guidance is presented. The problem domain, a freeway network traffic flow integration control application considers multiple objectives of system, is formulated as a distributed reinforcement learning problem. The Gini coefficient is adopted in this study as an indicator of equity. The DRL approach was implemented via a multi-agent control architecture where the decision agent was assigned to each of the on-ramp or VMS. The reward of each agent is simultaneously updating a single shared policy. The control strategy's effect is demonstrated through its application to the simple freeway network. Analyses of simulation results using this approach show the equity of the system have a significant improvement over traditional control, especially for the case of traffic peak hour. Using the DRL approach, the Gini coefficient of the network has been reduced by 28.99% compared to traditional method.","","Electronic:978-1-4244-5264-4; POD:978-1-4244-5263-7","10.1109/ICIME.2010.5477875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477875","equity;freeway;guidance;reinforcement learning;traffic control;traffic flow","Analytical models;Communication system traffic control;Control engineering;Control systems;Electronic mail;Engineering management;Machine learning;Telecommunication traffic;Traffic control;Voice mail","control engineering computing;learning (artificial intelligence);multi-agent systems;road traffic;traffic engineering computing","Gini coefficient;distributed machine learning;distributed reinforcement learning;dynamic route guidance;freeway network traffic management;multi-agent control architecture;traffic flow control","","0","","10","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Topology distance for manifold clustering","Yuan Peng; Qiyong Guo; I-Fan Shen; Wenbin Chen","School of Computer Science, Fudan University, Shanghai, China","2010 2nd International Conference on Computer Engineering and Technology","20100617","2010","7","","V7-197","V7-201","Manifold clustering is a widely used techniques in pattern recognition and machine learning. It partition a set of input data into several clusters each of which contains data points from a separate, simple low-dimensional manifold. In order to cluster manifold, we propose a novel distance measure based on topology structure that can efficiently represent the underlying manifold. Under this distance measure, data points belong to the same clusters are more closed and that of the different clusters are farther apart. By using normalized cut on similarity matrix, clusters can be found with ease. Experiments on both synthetic data and real data show that our method is feasible and promising in manifold clustering.","","Electronic:978-1-4244-6349-7; POD:978-1-4244-6347-3","10.1109/ICCET.2010.5485271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485271","distance measure;manifold clustering;manifold distance;topology structure","Clustering algorithms;Computer science;Euclidean distance;Face recognition;Handwriting recognition;Machine learning;Manifolds;Pattern recognition;Speech recognition;Topology","learning (artificial intelligence);pattern clustering;topology","machine learning;manifold clustering;pattern recognition;topology distance","","0","","14","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Feature Selection for Medical Diagnosis Using Fuzzy Artmap Classification and Intersection Conflict","M. Benkaci; B. Jammes; A. Doncescu","LAAS-CNRS Lab., Toulouse, France","2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops","20100607","2010","","","790","795","Studying complex systems including biological systems is a multi-disciplinary research area. It must be derived by the recent explosion of ICT including high-performance computing, high-throughput experiments, the Internet, knowledge discovery and Artificial Intelligence (AI). The goal of this research is to establish a computational architecture and tools to deal with complex systems based on such advanced technologies. Therefore in the case of medical diagnosis based on machine learning model, we need to reduce the number of variables according with their relevance and allowing to take decisions in real-time. This approach is realized in two stages. In the first one, we classify the unfaulty functioning data of system using the fuzzy-ARTMAP classification. In the second stage, a conflict is accounted between features of test data based on the hyper-cubes resulted in the first stage. Two features are in conflict if her intersection does not belong to the model elaborated by fuzzy-ARTMAP classification.","","Electronic:978-1-4244-6702-0; POD:978-1-4244-6701-3","10.1109/WAINA.2010.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5480757","","Application software;Artificial intelligence;Biology computing;Conferences;Fault detection;Fault diagnosis;Fuzzy systems;Intelligent sensors;Machine learning;Medical diagnosis","adaptive resonance theory;fuzzy neural nets;learning (artificial intelligence);medical computing;patient diagnosis;pattern classification","ICT;Internet;artificial intelligence;biological systems;complex systems;feature selection;fuzzy artmap classification;high performance computing;high throughput experiments;hypercubes;knowledge discovery;machine learning;medical diagnosis","","0","","13","","","20-23 April 2010","","IEEE","IEEE Conference Publications"
"The Use of isometric transformations and bayesian estimation in compressive sensing for fMRI classification","A. Carmi; T. N. Sainath; P. Gurfil; D. Kanevsky; D. Nahamoo; B. Ramabhadran","The Signal Processing Group, Department of Engineering, University of Cambridge, UK","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","493","496","Compressive sensing (CS) is a popular technique used to reconstruct a signal from few training examples, a problem which arises in many machine learning applications. In this paper, we introduce a technique to guarantee that our data obeys certain isometric properties. In addition, we introduce a bayesian approach to compressive sensing, which we call ABCS, allowing us to obtain complete statistics for estimated parameters. We apply these ideas to fMRI classification and find that by isometrically transforming our data, significant improvements in classification accuracy can be achieved using the LASSO and Dantzig selector methods, two standard techniques used in CS. In addition, applying the ABCS method offers improvements in classification accuracy over both LASSO and Dantzig. Finally, we find that applying both the ABCS method together with isometric transformations, we are able to achieve an error rate of 0.0%.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495673","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495673","Compressive sensing;bayesian learning;image classification;sparse representation","Aerospace engineering;Bayesian methods;Image coding;Image reconstruction;Image storage;Laplace equations;Machine learning;Parameter estimation;Signal processing;Statistics","Bayes methods;biomedical MRI;medical signal processing;signal reconstruction","ABCS method;Dantzig selector methods;FMRI classification;LASSO;bayesian estimation;compressive sensing;isometric transformations;machine learning;signal reconstruction","","0","1","13","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Are you Awerewolf? Detecting deceptive roles and outcomes in a conversational role-playing game","G. Chittaranjan; H. Hung","Idiap Research Institute, P.O. Box 592, CH-1920 Martigny, Switzerland","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","5334","5337","This paper addresses the task of automatically detecting outcomes of social interaction patterns, using non-verbal audio cues in competitive role-playing games (RPGs). For our experiments, we introduce a new data set which features 3 hours of audio-visual recordings of the popular “Are you a Werewolf?” RPG. Two problems are approached in this paper: Detecting lying or suspicious behavior using non-verbal audio cues in a social context and predicting participants' decisions in a game-day by analyzing speaker turns. Our best classifier exhibits a performance improvement of 87% over the baseline for detecting deceptive roles. Also, we show that speaker turn based features can be used to determine the outcomes in the initial stages of the game, when the group is large.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5494961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5494961","Deception;Nonverbal Behavior;Role Analysis","Acoustic signal detection;Audio recording;Computer science;Electric breakdown;Machine learning;Organizing;Psychology;Signal analysis;Signal processing;Storage automation","audio signal processing;audio-visual systems;behavioural sciences;speaker recognition","RPG;audio-visual recordings;competitive role-playing games;conversational role-playing game;deceptive roles detection;nonverbal audio cues;social interaction patterns","","3","","15","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Learning from other subjects helps reducing Brain-Computer Interface calibration time","F. Lotte; C. Guan","Institute for Infocomm Research (I2R), Singapore","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","20100628","2010","","","614","617","A major limitation of Brain-Computer Interfaces (BCI) is their long calibration time, as much data from the user must be collected in order to tune the BCI for this target user. In this paper, we propose a new method to reduce this calibration time by using data from other subjects. More precisely, we propose an algorithm to regularize the Common Spatial Patterns (CSP) and Linear Discriminant Analysis (LDA) algorithms based on the data from a subset of automatically selected subjects. An evaluation of our approach showed that our method significantly outperformed the standard BCI design especially when the amount of data from the target user is small. Thus, our approach helps in reducing the amount of data needed to achieve a given performance level.","1520-6149;15206149","Electronic:978-1-4244-4296-6; POD:978-1-4244-4295-9","10.1109/ICASSP.2010.5495183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495183","Brain-Computer Interfaces (BCI);regularization;subjectto-subject transfer","Brain computer interfaces;Calibration;Computer interfaces;Covariance matrix;Electroencephalography;Linear discriminant analysis;Machine learning algorithms;Spatial filters;Unsupervised learning;Vectors","brain-computer interfaces;learning (artificial intelligence);statistical analysis","brain computer interface;calibration time;common spatial pattern;linear discriminant analysis;subject data;subject to subject transfer","","39","","11","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"Robust guidewire segmentation through boosting, clustering and linear programming","N. Honnorat; R. Vaillant; N. Paragios","Laboratoire MAS, Ecole Centrale Paris, Ch&#226;tenay-Malabry, France","2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro","20100621","2010","","","924","927","Fluroscopic imaging provides means to assess the motion of the internal structures and therefore is of great use during surgery. In this paper we propose a novel approach for the segmentation of curvilinear structures in these images. The main challenge to be addressed is the lack of visual support due to the low SNR where traditional edge-based methods fail. Our approach combines machine learning techniques, unsupervised clustering and linear programming. In particular, numerous invariant to position/rotation classifiers are combined to detect candidate pixels of curvilinear structure. These candidates are grouped into consistent geometric segments through the use of a state-of-the art unsupervised clustering algorithm. The complete curvilinear structure is obtained through an ordering of these segments using the elastica model in a linear programming framework. Very promising results were obtained on guide wire segmentation in fluoroscopic images.","1945-7928;19457928","Electronic:978-1-4244-4126-6; POD:978-1-4244-4125-9","10.1109/ISBI.2010.5490138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5490138","Boosting;Linear Programming;clustering;fluoroscopic images;guide wire;linear structures;steerable filters","Art;Boosting;Clustering algorithms;Image edge detection;Image segmentation;Linear programming;Machine learning;Machine learning algorithms;Robustness;Surgery","biomedical optical imaging;fluorescence;image resolution;image segmentation;learning (artificial intelligence);medical image processing","boosting;curvilinear structure segmentation;elastica model;fluroscopic imaging;geometric segments;guidewire segmentation;linear programming framework;machine learning techniques;pixels;position-rotation classifiers;state-of-fhe unsupervised clustering algorithm","","2","3","16","","","14-17 April 2010","","IEEE","IEEE Conference Publications"
"Robust ultrasound image analysis using learning","D. Comaniciu","Integrated Data Systems Department, Siemens Corporate Research, 755 College Road East, Princeton, NJ 08540, USA","2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro","20100621","2010","","","280","280","Robust and accurate analysis of clinical ultrasound data is a challenging task due to the complexity of scanned anatomy, noise, shadows, signal dropouts and quantity of the information to be processed. As a result, traditional image analysis relying on the explicit encoding of prior knowledge such as perceptual grouping, variational or generative approaches is usually not enough to capture the complex appearance of ultrasound data. We will discuss a new class of methods that build on recent advances in discriminative machine learning to achieve robust and efficient performance. Image analysis is formulated as a multi-scale learning problem through which object models of increasing complexity are progressively learned. We will demonstrate example applications in Cardiology and OB/GYN.","1945-7928;19457928","Electronic:978-1-4244-4126-6; POD:978-1-4244-4125-9","10.1109/ISBI.2010.5490356","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5490356","Ultrasound;learning;marginal space learning;object detection;probabilistic boosting tree;segmentation","Anatomy;Cardiology;Image analysis;Image coding;Information analysis;Machine learning;Noise robustness;Signal analysis;Signal processing;Ultrasonic imaging","biomedical ultrasonics;cardiology;learning (artificial intelligence);medical image processing;object detection","OB/GYN;cardiology;discriminative machine learning;multiscale learning problem;perceptual grouping;ultrasound image analysis","","0","1","12","","","14-17 April 2010","","IEEE","IEEE Conference Publications"
"Applied granular matrix to attribute reduction algorithm","Z. Luo; G. Cui-cui; M. Lei; H. Lei; P. Jia-wei; S. Yong-chang","School of Computer Science and Technology, Wuhan University of Technology, Wuhan, China","2010 2nd International Conference on Future Computer and Communication","20100628","2010","3","","V3-306","V3-310","Attribute reduction is an important research area of rough set theory. Based on rough set theory, this paper established the granular matrix with the idea of granular computing, proposed and defined the AND operation of granular computing, established the knowledge granulation method based on granular matrix, and puts forward the attribute reduction algorithm based on granular matrix. The attribute reduction, using granular matrix to select the minimal attribute set, is different from the traditional attribute reduction which acquires the attribute core at first and then selects the best attribute set. Theoretical analysis shows that the new algorithm is reliable and valid. The new algorithm could provide a new paradigm for the attribute reduction of granular computing and a feasible method for further research on granular computing.","","Electronic:978-1-4244-5824-0; POD:978-1-4244-5821-9","10.1109/ICFCC.2010.5497618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497618","AND operation;attribute reduction;granular computing;granular matrix;rough set","Algorithm design and analysis;Computer science;Data analysis;Data mining;Information systems;Machine learning;Quaternions;Reliability theory;Robustness;Set theory","matrix algebra;rough set theory","AND operation;attribute reduction;granular computing;granular matrix;knowledge granulation;rough set theory","","0","","13","","","21-24 May 2010","","IEEE","IEEE Conference Publications"
"Visual-Concept Search Solved?","C. G. M. Snoek; A. W. M. Smeulders","University of Amsterdam","Computer","20100607","2010","43","6","76","78","Progress in visual-concept search suggests that machine understanding of images is within reach.","0018-9162;00189162","","10.1109/MC.2010.183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481940","Artificial intelligence;Visual-concept search","Data mining;Feature extraction;Image retrieval;Layout;Legged locomotion;Machine learning;Photonics;Shape;Snow;Testing","","","","14","","","","","June 2010","","IEEE","IEEE Journals & Magazines"
"Missing value estimation for DNA microarray gene expression data with principal curves","J. Shi; Z. Luo","School of Computer, National University of Defense Technology, Hunan Changsha 410073, China","2010 International Conference on Bioinformatics and Biomedical Technology","20100603","2010","","","262","265","Computing analysis of gene expression data has been an essential approach for understanding cellular activities and identifying gene function. However, expression profiles generated by the high-throughput microarray experiments often contain missing values, which significantly affect the performance of subsequent statistical analysis and machine learning algorithms. So there is a great need for estimating these missing values as accurately as possible. Although there have been many estimation algorithms, but each of them has its flaws. This paper proposes an estimation method for missing values based on principal curve which is a nonlinear generalization of the first linear principal component analysis. Through finding the self-consistent smooth one dimensional curves that pass through the `middle' of a multidimensional data set, principal curve can integrate the linear and nonlinear relationships between genes, and reveal the distribution of genes. Based on the framework of all the expression profiles, missing values can be estimated more accurately. To assess the performance of the method, comparisons with recently proposed estimation algorithms are carried out on several microarray data sets. The results shows that our method provides a better solution for the estimation of missing values in DNA microarray gene expression data.","","Electronic:978-1-4244-6778-5; POD:978-1-4244-6775-4","10.1109/ICBBT.2010.5478964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5478964","estimation;microarray;missing value;principal curve","Condition monitoring;DNA computing;Gene expression;Humans;Machine learning algorithms;Matrix decomposition;Multidimensional systems;Pattern analysis;Principal component analysis;Statistical analysis","DNA;bioinformatics;cellular biophysics;lab-on-a-chip;principal component analysis","DNA microarray gene expression;cellular activity;expression profile;gene function identification;linear principal component analysis;machine learning algorithm;missing value estimation;principal curve","","0","","16","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"GTMS: A Simultaneous Mode Seeking and Clustering","P. Padungweang; S. Chiewchanwattana; K. Sunat","Dept. of Comput. Sci., Khon Kaen Univ., Khon Kaen, Thailand","2010 5th International Conference on Future Information Technology","20100610","2010","","","1","6","A mode seeking algorithm not only can automatically find mode of density of a given data but also can be used for data clustering. However, finding the mode of all data points produce redundant computations. In this paper, a simultaneous mode seeking and clustering which is called Generalized Transport Mean Shift (GTMS) algorithm was proposed. An idea of transportation was used for remedying the problem. For each iteration, the ""transporter-trailer"" characteristic was assigned to data points. The data points that tend to be shifted through the same trajectory, by considering shift direction, will be transported by the same transporter. Then they will be excluded from the computation in the next iteration. The transporters were, then, computed for finding a mode of density. The proposed algorithm was evaluated on clustering and image segmentation problems. The experimental results show that GTMS algorithm outperforms existing algorithms in both accuracy and time-consuming. It reduces redundancy computation by excluding data points more than 90% of image segmentation data after the second iteration only.","2159-7006;21597006","Electronic:978-1-4244-6950-5; POD:978-1-4244-6948-2","10.1109/FUTURETECH.2010.5482727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482727","","Clustering algorithms;Computer science;Data engineering;Ellipsoids;Image converters;Image segmentation;Iterative algorithms;Machine learning algorithms;Neural networks;Transportation","image segmentation;iterative methods;pattern clustering","GTMS algorithm;data clustering;density mode;generalized transport mean shift;image segmentation;mode seeking algorithm;transporter-trailer characteristic","","0","","13","","","21-23 May 2010","","IEEE","IEEE Conference Publications"
"Brain-Computer Interfacing [In the Spotlight]","R. P. N. Rao; R. Scherer","An associate professor in the Department of Computer Science and Engineering at the University of Washington, Seattle.","IEEE Signal Processing Magazine","20100614","2010","27","4","152","150","Recently, CNN reported on the future of brain-computer interfaces (BCIs). BCIs are devices that process a user's brain signals to allow direct communication and interaction with the environment. BCIs bypass the normal neuromuscular output pathways and rely on digital signal processing and machine learning to translate brain signals to action (Figure 1). Historically, BCIs were developed with biomedical applications in mind, such as restoring communication in completely paralyzed individuals and replacing lost motor function. More recent applications have targeted nondisabled individuals by exploring the use of BCIs as a novel input device for entertainment and gaming. The task of the BCI is to identify and predict behaviorally induced changes or ""cognitive states"" in a user's brain signals. Brain signals are recorded either noninvasively from electrodes placed on the scalp [electroencephalogram (EEG)] or invasively from electrodes placed on the surface of or inside the brain. BCIs based on these recording techniques have allowed healthy and disabled individuals to control a variety of devices. In this article, we will describe different challenges and proposed solutions for noninvasive brain-computer interfacing.","1053-5888;10535888","","10.1109/MSP.2010.936774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484181","","Brain computer interfaces;Cellular neural networks;Digital signal processing;Electrodes;Electroencephalography;Machine learning;Neuromuscular;Scalp;Signal processing;Signal restoration","brain-computer interfaces;electroencephalography;medical signal processing","EEG;brain signals;brain-computer interface;digital signal processing;electroencephalogram;machine learning;neuromuscular output pathways","","13","","7","","","July 2010","","IEEE","IEEE Journals & Magazines"
"Semi-supervised prostate cancer segmentation with multispectral MRI","Y. Artan; M. A. Haider; D. L. Langer; I. S. Yetik","Medical Imaging Research Center, Illinois Institute of Technology, Chicago, USA","2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro","20100621","2010","","","648","651","Prostate cancer is one of the leading causes of cancer related death for men in the United States. Recently, multispectral magnetic resonance imaging (MRI) has emerged as a promising noninvasive method for the localization of prostate cancer alternative to transrectal ultrasound (TRUS). This paper develops a semi-supervised method for prostate cancer localization using multispectral MRI. Patient-specific contrast can be utilized in this method for improved performance. We also propose to use an anisotropic filtering scheme to suppress the noise in the images. Using multispectral MR images, we demonstrate the effectiveness of this algorithm by testing it on real data sets and compare it to the results of a fully-automated method as well as to the earlier results. Both visual and quantitative comparisons are provided, illustrating the success of the proposed method.","1945-7928;19457928","Electronic:978-1-4244-4126-6; POD:978-1-4244-4125-9","10.1109/ISBI.2010.5490091","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5490091","Anisotropic Diffusion;Magnetic Resonance Imaging;Prostate Cancer Localization;Random Walker Algorithm;Support Vector Machines","Anisotropic filters;Anisotropic magnetoresistance;Biomedical imaging;Humans;Image segmentation;Machine learning;Machine learning algorithms;Magnetic resonance imaging;Prostate cancer;Ultrasonic imaging","biological organs;biomedical MRI;cancer;image denoising;image segmentation;medical image processing","anisotropic filtering;multispectral MRI;multispectral magnetic resonance imaging;noise suppression;patient-specific contrast;prostate cancer segmentation;semisupervised method","","3","","15","","","14-17 April 2010","","IEEE","IEEE Conference Publications"
"Intelligent crawling based on rough set for web resource discovery","L. Hu","Information Engineering, Zhong Shan Torch Polytechnic College, Zhong Shan, China","2010 2nd IEEE International Conference on Information Management and Engineering","20100603","2010","","","624","627","The rapid development of the Internet brings a new problem, which is how to rapidly and effectively retrieve needed web resource from vast number of web pages. The progress of machine learning techniques shows a new direction of solving this problem. In this paper, intelligent crawling algorithm based on rough set is proposed. The algorithm use the hypertext features behavior in order to perform topic specific resource discovery. Our experiment in this regard has provided better Harvest rate and better Target recall for focused crawling.","","Electronic:978-1-4244-5264-4; POD:978-1-4244-5263-7","10.1109/ICIME.2010.5477905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477905","Classification;Intelligent Crawling;Web Resource Discovery","Crawlers;Educational institutions;Information retrieval;Internet;Machine learning algorithms;Search engines;Software libraries;Taxonomy;Uniform resource locators;Web pages","Internet;hypermedia;information retrieval;learning (artificial intelligence);rough set theory","Web resource discovery;hypertext features behavior;intelligent crawling algorithm;machine learning;rough set","","0","","12","","","16-18 April 2010","","IEEE","IEEE Conference Publications"
"Genetic complex multiple kernel for relevance vector regression","Wu Bing; Zhang Wen-Qiong; Hu Zhi-Wei; Liang Jia-Hong","College of Mechanical Engineering and Automation, National University of Defense Technology, Changsha, China","2010 2nd International Conference on Advanced Computer Control","20100617","2010","4","","217","221","Relevance vector machine (RVM) is a state-of-the-art technique for regression and classification, as a sparse Bayesian extension version of the support vector machine. The selection of a kernel and associated parameter is a critical step of RVM application. The real-world application and recent researches have emphasized the requirement to multiple kernel learning, in order to boost the fitting accuracy by adapting better the characteristics of the data. This paper presents a data-driven evolutionary approach, called Genetic Complex Multiple Kernel Relevance Vector Regression (GCMK RVR), which combines genetic programming(GP) and relevance vector regression to evolve an optimal or near-optimal complex multiple kernel function. Each GP chromosome is a tree that encodes the mathematical expression of a complex multiple kernel function. Numerical experiments on several benchmark datasets show that the RVR involving this GCMK perform better than not only the widely used simple kernel, Polynomial, Gaussian RBF and Sigmoid kernel, but also the convex linear multiple kernel function.","","Electronic:978-1-4244-5848-6; POD:978-1-4244-5845-5","10.1109/ICACC.2010.5486939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486939","Genetic Complex Multiple Kernel;Relevance vector regression;genetic programming","Bayesian methods;Biological cells;Educational institutions;Genetic programming;Kernel;Machine learning;Optimization methods;Polynomials;Support vector machine classification;Support vector machines","Bayes methods;belief networks;genetic algorithms;learning (artificial intelligence);numerical analysis;pattern classification;regression analysis;support vector machines","classification method;data driven evolutionary approach;genetic complex multiple kernel;genetic complex multiple kernel relevance vector regression;genetic programming;multiple kernel learning;relevance vector machine;sparse Bayesian extension version;support vector machine","","0","","12","","","27-29 March 2010","","IEEE","IEEE Conference Publications"
"The application of improved boosting algorithm in neural network based on cloud model","Xue Qing Ji","Wuhan University of Technology, China, 430070","2010 International Conference on E-Health Networking Digital Ecosystems and Technologies (EDT)","20100628","2010","2","","530","533","An effective ensemble should consist of a set of networks that are both accurate and diverse. Ensemble learning is an algorithm to improve the generalization ability of the unstable classifier. We propose an improved boosting algorithm based on cloud model for constructing neural network ensemble, where cloud model is used to classify trained networks according to similarity and optimally select the most accurate individual network from each cluster to make up the ensemble. Empirical studies on regression of typical datasets showed that this approach yields significantly smaller ensemble achieving better performance than other traditional ones such as Bagging and Boosting. The bias variance decomposition of the predictive error shows that the success of the proposed approach may lie in its properly tuning the bias/variance trade-off to reduce the prediction error.","","Electronic:978-1-4244-5517-1; POD:978-1-4244-5514-0","10.1109/EDT.2010.5496450","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5496450","boosting;cloud generator;cloud model;neural network ensemble","Application software;Bagging;Boosting;Clouds;Clustering algorithms;Computer science;Ecosystems;Machine learning;Neural networks;Predictive models","generalisation (artificial intelligence);learning (artificial intelligence);neural nets;pattern classification;pattern clustering","bias variance decomposition;boosting algorithm;cloud generator;cloud model;ensemble learning;generalization;neural network ensemble construction","","1","","3","","","17-18 April 2010","","IEEE","IEEE Conference Publications"
"Genetic Clustering Algorithm Based on Dynamic Granularity","J. Zhen; W. Y. Gui","Sch. of Electron. & Inf. Eng., Liaoning Tech. Univ., Huludao, China","2010 International Conference on Computing, Control and Industrial Engineering","20100628","2010","1","","431","434","From the view of granularity, this paper presents a genetic clustering algorithm based on dynamic granularity. In view of a parallel, random search, global optimization and diversity characteristics of genetic algorithm, it is combined with dynamic granularity model. In the process of granularity changing, appropriate granulation can be made by coarsening and refining the granularity, which can ensure clustering efficiency and quality of the algorithm. Experimental data show that the method effectively improves the clustering algorithm based on genetic algorithm local search ability and convergence speed.","","Electronic:978-1-4244-6751-8; POD:978-1-4244-6750-1","10.1109/CCIE.2010.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492116","K-medoids algorithm;dynamic granularity;genetic algorithm;harmony","Clustering algorithms;Clustering methods;Concurrent computing;Genetic algorithms;Genetic engineering;Heuristic algorithms;Industrial electronics;Industrial engineering;Machine learning algorithms;Optimization methods","genetic algorithms;pattern clustering;search problems","diversity characteristics;dynamic granularity;genetic clustering algorithm;granularity changing process;granularity coarsening;granularity refining","","0","","7","","","5-6 June 2010","","IEEE","IEEE Conference Publications"
