"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4906797,4906796,4906750,4839886,4840253,4663615,4815348,4814446,4775901,4815377,4711053,4721436,4814124,4806176,4811596,4811637,4809501,4810577,4809216,4624261,4804817,4609384,4804825,4803920,4531745,4717268,4797802,4785974,4522558,4783565,4685707,4782571,4781118,4780928,4781212,4780972,4779280,4780668,4780099,4777827,4777515,4663936,4772991,4769960,4667545,4767626,4762066,4762143,4731265,4756329,4625983,4741149,4740947,4741145,4739693,4740037,4740796,4736919,4599185,4736532,4739575,4740577,4663851,4740494,4740474,4732851,4479477,4731304,4479479,4722720,4722600,4721828,4728497,4722718,4725505,4720539,4721565,4711422,4711453,4712042,4683348,4699061,4696404,4696499,4696520,4696348,4700324,4694447,4547426,4479474,4522548,4683332,4677352,4682450,4682102,4682164,4682067,4682034,4420086,4670325",2017/05/05 22:17:35
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A feature dependent method for opinion mining and classification","A. Balahur; A. Montoyo","DLSI, Univ. Alicante, Spain","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","Mining the web for customer opinion on different products is both a useful, as well as challenging task. Previous approaches to customer review classification included document level, sentence and clause level sentiment analysis and feature based opinion summarization. In this paper, we present a feature driven opinion summarization method, where the term ldquodrivenrdquo is employed to describe the concept-to-detail (product class to product-specific characteristics) approach we took. For each product class we first automatically extract general features (characteristics describing any product, such as price, size, design), for each product we then extract specific features (as picture resolution in the case of a digital camera) and feature attributes (adjectives grading the characteristics, as for example high or low for price, small or big for size and modern or faddy for design). Further on, we assign a polarity (positive or negative) to each of the feature attributes using a previously annotated corpus and Support Vector Machines Sequential Minimal Optimization machine learning with the Normalized Google Distance. We show how the method presented is employed to build a feature-driven opinion summarization system that is presently working in English and Spanish. In order to detect the product category, we use a modified system for person names classification. The raw review text is split into sentences and depending on the product class detected, only the phrases containing the specific product features are selected for further processing. The phrases extracted undergo a process of anaphora resolution, Named Entity Recognition and syntactic parsing. Applying syntactic dependency and part of speech patterns, we extract pairs containing the feature and the polarity of the feature attribute the customer associates to the feature in the review. Eventually, we statistically summarize the polarity of the opinions different customers expressed about the product on the - - web as percentages of positive and negative opinions about each of the product features. We show the results and improvements over baseline, together with a discussion on the strong and weak points of the method and the directions for future work.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906796","Normalized Google Distance;Opinion mining;SVM machine learning;summarization","Blogs;Digital cameras;Ear;Feature extraction;Internet;Machine learning;Product design;Speech;Support vector machines;Web sites","Internet;classification;data mining;grammars;learning (artificial intelligence);natural language processing;support vector machines","English;Spanish;Worls Wide Web;anaphora resolution;annotated corpus;clause level sentiment analysis;customer opinion;customer review classification;feature attributes;named entity recognition;normalized Google distance;opinion mining;opinion summarization;product category;sequential minimal optimization machine learning;speech patterns;support vector machines;syntactic dependency;syntactic parsing","","6","6","28","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Geometric Mean for Subspace Selection","D. Tao; X. Li; X. Wu; S. J. Maybank","Birkbeck College, University of London, London","IEEE Transactions on Pattern Analysis and Machine Intelligence","20081230","2009","31","2","260","274","Subspace selection approaches are powerful tools in pattern classification and data visualization. One of the most important subspace approaches is the linear dimensionality reduction step in the Fisher's linear discriminant analysis (FLDA), which has been successfully employed in many fields such as biometrics, bioinformatics, and multimedia information management. However, the linear dimensionality reduction step in FLDA has a critical drawback: for a classification task with c classes, if the dimension of the projected subspace is strictly lower than c - 1, the projection to a subspace tends to merge those classes, which are close together in the original feature space. If separate classes are sampled from Gaussian distributions, all with identical covariance matrices, then the linear dimensionality reduction step in FLDA maximizes the mean value of the Kullback-Leibler (KL) divergences between different classes. Based on this viewpoint, the geometric mean for subspace selection is studied in this paper. Three criteria are analyzed: 1) maximization of the geometric mean of the KL divergences, 2) maximization of the geometric mean of the normalized KL divergences, and 3) the combination of 1 and 2. Preliminary experimental results based on synthetic data, UCI Machine Learning Repository, and handwriting digits show that the third criterion is a potential discriminative subspace selection method, which significantly reduces the class separation problem in comparing with the linear dimensionality reduction step in FLDA and its several representative extensions.","0162-8828;01628828","","10.1109/TPAMI.2008.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479477","Arithmetic mean;Fisher's linear discriminant analysis (FLDA);Kullback-Leibler (KL) divergence;Numerical Analysis;Probability and Statistics;geometric mean;machine learning;subspace selection (or dimensionality reduction);visualization.","","Gaussian distribution;covariance matrices;data reduction;feature extraction;geometry;merging;optimisation;pattern classification","Fisher linear discriminant analysis;Gaussian distribution;Kullback-Leibler divergence;covariance matrix;data visualization;feature space;geometric mean maximization;linear dimensionality reduction;pattern classification;subspace selection","Algorithms;Artificial Intelligence;Computer Simulation;Data Interpretation, Statistical;Discriminant Analysis;Models, Theoretical;Pattern Recognition, Automated","334","","44","","20080331","Feb. 2009","","IEEE","IEEE Journals & Magazines"
"Improving face gender classification by adding deliberately misaligned faces to the training data","M. Mayo; E. Zhang","Dept. of Computer Science, University of Waikato, Hamilton, New Zealand","2008 23rd International Conference Image and Vision Computing New Zealand","20090123","2008","","","1","5","A novel method of face gender classifier construction is proposed and evaluated. Previously, researchers have assumed that a computationally expensive face alignment step (in which the face image is transformed so that facial landmarks such as the eyes, nose, chin, etc, are in uniform locations in the image) is required in order to maximize the accuracy of predictions on new face images. We, however, argue that this step is not necessary, and that machine learning classifiers can be made robust to face misalignments by automatically expanding the training data with examples of faces that have been deliberately misaligned (for example, translated or rotated). To test our hypothesis, we evaluate this automatic training dataset expansion method with two types of image classifier, the first based on weak features such as Local Binary Pattern histograms, and the second based on SIFT keypoints. Using a benchmark face gender classification dataset recently proposed in the literature, we obtain a state-of-the-art accuracy of 92.5%, thus validating our approach.","2151-2191;21512191","CD-ROM:978-1-4244-2583-9; POD:978-1-4244-2582-2","10.1109/IVCNZ.2008.4762066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4762066","Gender classification;Local Binary Pattern;SIFT keypoints;Spatial Pyramid;Support Vector Machines;face alignment;face classification;face detection;image classification;machine learning","Automatic testing;Eyes;Face detection;Histograms;Machine learning;Nose;Robustness;Support vector machine classification;Support vector machines;Training data","face recognition;image classification;learning (artificial intelligence)","SIFT keypoints;automatic training dataset expansion method;deliberately misaligned faces;face gender classification;image classifier;local binary pattern;machine learning classifiers","","6","","14","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"Tamper Detection of Relational Database Based on SVR Predictive Difference","H. C. Wu; F. Y. Hsu; H. Y. Chen","Dept. of Comput. Sci. & Inf. Eng., Nat. Taichung Inst. of Technol., Taichung","2008 Eighth International Conference on Intelligent Systems Design and Applications","20081208","2008","3","","403","408","Database authentication verifies valuable content from illicit copying, illegal redistribution and maliciously tamper while it is to be sold or be outsourced to un-trusted parties. This paper exploits the digital watermarking technology for guaranteeing the database integrity underlying distortion free of database content. The proposed scheme employs SVR predictive function to obtain characteristic of the database and uses Huffman coding to encode the characteristic for compressing important payload information. In detection phase, minor and necessary additional payload information of the database is used to accomplish tampering detection.","2164-7143;21647143","POD:978-0-7695-3382-7","10.1109/ISDA.2008.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696499","Database watermarking;fragile watermarking;machine learning;support vector regression;tamper detection","Authentication;Computer science;Cryptography;Data security;Internet;Payloads;Protection;Relational databases;Robustness;Watermarking","regression analysis;relational databases;security of data;support vector machines;watermarking","Huffman coding;database authentication;database content;database integrity;digital watermarking technology;illegal redistribution;illicit copying;relational database;support vector regression;tamper detection;untrusted parties","","0","","20","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"Learning to Rank with Bayesian Evidence Framework","L. Zhang; W. Wang","Coll. of Econ., South-Central Univ. for Nat., Wuhan","2008 International Conference on Computer Science and Software Engineering","20081222","2008","4","","713","716","The problem of ranking has recently gained attention in data learning. The goal ranking is to learn a real-valued ranking function that induces a ranking or ordering over an instance space. In this paper, we apply popular Bayesian techniques on ranking support vector machine. We propose a novel differentiable loss function called trigonometric loss function with the desirable characteristic of natural normalization in the likelihood function, and then set up a Bayesian framework. In this framework, Bayesian inference is used to implement model adaptation, while keeping the merits of ranking SVM. Experimental results on data sets indicate the usefulness of this approach.","","POD:978-0-7695-3336-0","10.1109/CSSE.2008.720","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722718","SVM;machine learning;ranking;trigonometric loss function","Adaptation model;Bayesian methods;Computational complexity;Computer science;Data mining;Design methodology;Educational institutions;Neural networks;Software engineering;Support vector machines","Bayes methods;inference mechanisms;learning (artificial intelligence);support vector machines","Bayesian evidence framework;Bayesian inference;data learning;differentiable loss function;goal ranking;real-valued ranking function;support vector machine;trigonometric loss function","","0","","20","","","12-14 Dec. 2008","","IEEE","IEEE Conference Publications"
"The Separating Capacity of a Multithreshold Threshold Element","R. Takiyama","Department of Visual Communication Design, Kyushu Institute of Design, Minami-ku, Fukuoka 815, Japan.","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090127","1985","PAMI-7","1","112","116","In answer to what represents the intrinsic information-processing capability of the pattern classification system, Cover [1] has defined the separating capacity, and has derived it for the linear machine and the so-called Φ machine. In this paper, the separating capacity of a multithreshold classification element is obtained. It is shown that the capacity of a multithreshold threshold element with k thresholds-k-threshold element-in n-dimensional space is 2(n + k). A linear machine is a special case in the k-threshold element with k = 1; therefore, its capacity becomes 2(n + 1) from the above result. Further, although it is intuitively apparent that the larger the number of thresholds, the more powerful the information-processing capability of the k-threshold element, using the capacity as a measure of this capability, we may now state that the separating power of the k-threshold element increases linearly with respect to k.","0162-8828;01628828","","10.1109/TPAMI.1985.4767626","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4767626","Classifier;learning machine;multithreshold threshold element;parallel hyperplanes;pattern recognition;piecewise linear discriminant function","Machine learning;Nearest neighbor searches;Neural networks;Pattern classification;Pattern recognition;Performance evaluation;Piecewise linear techniques;Polarization;Power measurement;Testing","","","","8","","10","","","Jan. 1985","","IEEE","IEEE Journals & Magazines"
"Kernel Discriminant Analysis for Positive Definite and Indefinite Kernels","E. Pȩkalska; B. Haasdonk","Univeristy of Manchester, Manchester","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090417","2009","31","6","1017","1032","Kernel methods are a class of well established and successful algorithms for pattern analysis thanks to their mathematical elegance and good performance. Numerous nonlinear extensions of pattern recognition techniques have been proposed so far based on the so-called kernel trick. The objective of this paper is twofold. First, we derive an additional kernel tool that is still missing, namely kernel quadratic discriminant (KQD). We discuss different formulations of KQD based on the regularized kernel Mahalanobis distance in both complete and class-related subspaces. Secondly, we propose suitable extensions of kernel linear and quadratic discriminants to indefinite kernels. We provide classifiers that are applicable to kernels defined by any symmetric similarity measure. This is important in practice because problem-suited proximity measures often violate the requirement of positive definiteness. As in the traditional case, KQD can be advantageous for data with unequal class spreads in the kernel-induced spaces, which cannot be well separated by a linear discriminant. We illustrate this on artificial and real data for both positive definite and indefinite kernels.","0162-8828;01628828","","10.1109/TPAMI.2008.290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711053","indefinite kernels;kernel methods;machine learning;pattern recognition;quadratic discriminant","Hilbert space;Kernel;Learning systems;Pattern analysis;Pattern recognition;Principal component analysis;Shape;Statistical learning;Support vector machine classification;Support vector machines","pattern classification","class-related subspaces;classifiers;indefinite kernels;kernel linear discriminants;kernel quadratic discriminants;pattern analysis;pattern recognition techniques;regularized kernel Mahalanobis distance;symmetric similarity measure","Algorithms;Artificial Intelligence;Computer Simulation;Discriminant Analysis;Models, Theoretical;Pattern Recognition, Automated","49","","41","","20081212","June 2009","","IEEE","IEEE Journals & Magazines"
"Learning Sparse CRFs for Feature Selection and Classification of Hyperspectral Imagery","P. Zhong; R. Wang","Sch. of Electron. Sci. & Eng., Nat. Univ. of Defense Technol., Changsha","IEEE Transactions on Geoscience and Remote Sensing","20081209","2008","46","12","4186","4197","Feature selection is an important task in hyperspectral data analysis. This paper presents a sparse conditional random field (SCRF) model to select relevant features for the classification of hyperspectral images and, meanwhile, to exploit the contextual information in the form of spatial dependences in the images. The sparsity arises from the use of a Laplacian prior on the CRF parameters, which encourages the parameter estimates to be either significantly large or exactly zero. To joint the feature selection and classifier design, this paper develops an efficient sparse training method, which divides the training of SCRF into the sparse trainings of two simpler classifiers. Experiments on the real-world hyperspectral image attest to the accuracy, sparsity, and efficiency of the proposed model.","0196-2892;01962892","","10.1109/TGRS.2008.2001921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4683348","Conditional random field (CRF);contextual information;feature selection;hyperspectral image;image classification;machine learning;multinomial logistic regression (MLR);sparse CRF (SCRF)","Context modeling;Data analysis;Hyperspectral imaging;Hyperspectral sensors;Image classification;Image color analysis;Laplace equations;Machine learning;Parameter estimation;Technological innovation","feature extraction;geophysical techniques;geophysics computing;image classification;remote sensing","Laplacian distribution;SCRF model;classifier design;feature selection;hyperspectral data analysis;hyperspectral imagery classification;sparse conditional random field model;sparse training method","","20","","51","","","Dec. 2008","","IEEE","IEEE Journals & Magazines"
"Key Technologies Analysis of Three Sides Chinese Chess Computer Game","Z. Chen; M. Liu; Z. Li; X. Lian","Sch. of Comput. Sci. & Educ. Software, Guangzhou Univ., Guangzhou","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","856","860","The three sides Chinese chess is a novel game which is developed from the traditional Chinese chess. There are not any research results on the three sides Chinese chess computer game. In this paper, the three sides Chinese game is firstly compared with the traditional Chinese chess. Then an algorithm of three sides game searching with pruning is put forward, which is based on a vector evaluation function. In the end, a machine learning algorithm is addressed in detail, which learns from history game processes. Some experiment results also demonstrate the pruning and learning effect.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739693","Chinese chess;game theory;machine learning;searching algorithm","Application software;Computer science;Educational technology;Explosions;History;Information analysis;Information technology;Machine learning;Machine learning algorithms;State-space methods","computer games;learning (artificial intelligence);tree data structures;tree searching","machine learning algorithm;pruning algorithm;three sides Chinese chess computer game;three sides game tree searching algorithm;tree data structure;vector evaluation function","","0","","3","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Model Building Process for Identifying Actionable Static Analysis Alerts","S. Heckman; L. Williams","North Carolina State Univ., Raleigh, NC","2009 International Conference on Software Testing Verification and Validation","20090417","2009","","","161","170","Automated static analysis can identify potential source code anomalies early in the software process that could lead to field failures. However, only a small portion of static analysis alerts may be important to the developer (actionable). The remainder are false positives (unactionable). We propose a process for building false positive mitigation models to classify static analysis alerts as actionable or unactionable using machine learning techniques. For two open source projects, we identify sets of alert characteristics predictive of actionable and unactionable alerts out of 51 candidate characteristics. From these selected characteristics, we evaluate 15 machine learning algorithms, which build models to classify alerts. We were able to obtain 88-97% average accuracy for both projects in classifying alerts using three to 14 alert characteristics. Additionally, the set of selected alert characteristics and best models differed between the two projects, suggesting that false positive mitigation models should be project-specific.","2159-4848;21594848","POD:978-1-4244-3775-7","10.1109/ICST.2009.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815348","false positive mitigation;machine learning;static analysis","Buildings;Data mining;Failure analysis;Inspection;Machine learning;Machine learning algorithms;Predictive models;Programming profession;Software testing;Software tools","learning (artificial intelligence);program diagnostics;software process improvement;source coding","actionable static analysis alerts;automated static analysis;false positive mitigation models;machine learning techniques;open source projects;software process;source code anomalies","","8","","20","","","1-4 April 2009","","IEEE","IEEE Conference Publications"
"An Image Steganographic Scheme Based on Support Vector Regression","H. C. Wu; K. C. Liu; J. D. Chang; C. H. Huang","Grad. Sch. of Comput. Sci. & Inf. Technol., Nat. Taichung Inst. of Technol., Taichung","2008 Eighth International Conference on Intelligent Systems Design and Applications","20081208","2008","3","","519","524","This paper presents a novel image steganographic method that utilizes support vector regression (SVR) to predict the embedded pixel value such that secret data is also embedded into the pixel-value difference between the predicted pixel value and the original pixel value. Due to the significant learning ability in the correlations of training samples by support vector regression, the trained SVR function is obtained by neighboring pixels of the sample pixels to predict the embedded pixel values, and then the proposed scheme uses pixel-value differences to embed the secret data. In the data extraction phase, the proposed scheme uses trained SVR function to predict the embedded pixel value, and the secret data is extracted from pixel-value differences. Experimental results show that SVR is good at learning the correlations of neighboring pixel, and the proposed scheme also has reliable security, high embedding capacity and better image quality for the stego-image.","2164-7143;21647143","POD:978-0-7695-3382-7","10.1109/ISDA.2008.145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696520","Steganography;data hiding;machine learning;pixel-value difference;support vector regression","Biomedical imaging;Cities and towns;Computer science;Cryptography;Data encapsulation;Data mining;Image quality;Internet;Smart pixels;Steganography","image processing;regression analysis;steganography;support vector machines","data extraction;data hiding;image quality;image steganography;learning ability;pixel-value difference;reliable security;stego-image;support vector regression","","0","","18","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"A Comparison between a KNN Based Approach and a PNN Algorithm for a Multi-label Classification Problem","E. Oliveira; P. M. Ciarelli; C. Badue; A. F. D. Souza","Dept. of Inf. Sci., Univ. Fed. do Espirito Santo, Vitoria","2008 Eighth International Conference on Intelligent Systems Design and Applications","20081208","2008","2","","628","633","Techniques for categorization and clustering, range from support vector machines, neural networks to Bayesian inference and algebraic methods. The k-Nearest Neighbor Algorithm (KNN) is a popular example of the latter class of these algorithms. Recently, a slight modification of it has been proposed so that the Multi-Label k-Nearest Neighbor Algorithm (ML-KNN) can deal better with multi-label classification problems. In this paper we are interested in automatic text categorization, which are becoming more and more important as the amount of text in electronic format grows and the access to it becomes more necessary and widespread. We proposed a Probabilistic Neural Network Algorithm (PNN) tailored to also deal with multi-label classification problems, and compared it against the ML-KNN algorithm. Our implementation surpass the ML-KNN algorithm in four metrics typically used in the literature for multi-label categorization problems.","2164-7143;21647143","POD:978-0-7695-3382-7","10.1109/ISDA.2008.364","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696404","Business Activities Classi?cation;Machine Learning;Text classi?cation","Clustering algorithms;Companies;Government;Inference algorithms;Machine learning algorithms;Neural networks;Software libraries;Support vector machine classification;Support vector machines;Text categorization","belief networks;inference mechanisms;neural nets;pattern classification;text analysis","Bayesian inference;algebraic methods;automatic text categorization;multilabel classification problem;multilabel k-nearest neighbor algorithm;neural networks;probabilistic neural network algorithm;support vector machines","","2","","15","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"Unsupervised Learning of Probabilistic Grammar-Markov Models for Object Categories","L. Zhu; Y. Chen; A. Yuille","UCLA, Los Angeles","IEEE Transactions on Pattern Analysis and Machine Intelligence","20081125","2009","31","1","114","128","We introduce a probabilistic grammar-Markov model (PGMM) which couples probabilistic context free grammars and Markov random fields. These PGMMs are generative models defined over attributed features and are used to detect and classify objects in natural images. PGMMs are designed so that they can perform rapid inference, parameter learning, and the more difficult task of structure induction. PGMMs can deal with unknown 2D pose (position, orientation, and scale) in both inference and learning, different appearances, or aspects, of the model. The PGMMs can be learnt in an unsupervised manner where the image can contain one of an unknown number of objects of different categories or even be pure background. We first study the weakly supervised case, where each image contains an example of the (single) object of interest, and then generalize to less supervised cases. The goal of this paper is theoretical but, to provide proof of concept, we demonstrate results from this approach on a subset of the Caltech dataset (learning on a training set and evaluating on a testing set). Our results are generally comparable with the current state of the art, and our inference is performed in less than five seconds.","0162-8828;01628828","","10.1109/TPAMI.2008.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479474","Computer vision;Machine learning;Structural","","Markov processes;context-free grammars;object recognition;random processes;unsupervised learning","Markov random field;object recognition;parameter learning;probabilistic context free grammar;probabilistic grammar-Markov model;unsupervised learning","Algorithms;Artificial Intelligence;Computer Simulation;Image Interpretation, Computer-Assisted;Markov Chains;Models, Statistical;Pattern Recognition, Automated","22","","32","","20080331","Jan. 2009","","IEEE","IEEE Journals & Magazines"
"A review of applications of artificial neural networks in cryptosystems","T. Schmidt; H. Rahnama; A. Sadeghian","Dept. of Computer Science, Ryerson University, Canada","2008 World Automation Congress","20081209","2008","","","1","6","This paper presents a review of the literature on the use of artificial neutral networks in cryptography. Different neural network based approaches have been categorized based on their applications to different components of cryptosystems such as secret key protocols, visual cryptography, design of random generators, digital watermarking, and steganalysis.","2154-4824;21544824","CD-ROM:978-1-889335-37-7; POD:978-1-889335-38-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4699061","Artificial neural networks;Cryptography;Machine learning","Application software;Artificial neural networks;Computer science;Cryptographic protocols;Information security;Neural networks;Protection;Public key;Public key cryptography;Watermarking","cryptography;neural nets","artificial neural network;cryptosystem;digital watermarking;random generator design;secret key protocol;steganalysis;visual cryptography","","0","","34","","","Sept. 28 2008-Oct. 2 2008","","IEEE","IEEE Conference Publications"
"Recurrent neural networks for remaining useful life estimation","F. O. Heimes","BAE Systems, Electronics and Integrated Solutions, Johnson City, NY 13790 USA","2008 International Conference on Prognostics and Health Management","20081212","2008","","","1","6","This paper presents an approach and solution to the IEEE 2008 Prognostics and Health Management conference challenge problem. The solution utilizes an advanced recurrent neural network architecture to estimate the remaining useful life of the system. The recurrent neural network is trained with back-propagation through time gradient calculations, an Extended Kalman Filter training method, and evolutionary algorithms to generate an accurate and compact algorithm. This solution placed second overall in the competition with a very small margin between the first and second place finishers.","","CD-ROM:978-1-4244-1936-4; POD:978-1-4244-1935-7","10.1109/PHM.2008.4711422","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711422","Machine Learning;Prognostics;Recurrent Neural Networks;Remaining Useful Life","Degradation;Life estimation;Machine learning;Machine learning algorithms;Management training;Pollution measurement;Prognostics and health management;Recurrent neural networks;Statistics;Testing","Kalman filters;evolutionary computation;learning (artificial intelligence);nonlinear filters;recurrent neural nets","back-propagation;evolutionary algorithms;extended Kalman Filter training method;machine learning;recurrent neural networks;remaining useful life estimation","","31","","5","","","6-9 Oct. 2008","","IEEE","IEEE Conference Publications"
"Learning Situation Models in a Smart Home","O. Brdiczka; J. L. Crowley; P. Reignier","Palo Alto Res. Center, Palo Alto, CA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20090113","2009","39","1","56","63","This paper addresses the problem of learning situation models for providing context-aware services. Context for modeling human behavior in a smart environment is represented by a situation model describing environment, users, and their activities. A framework for acquiring and evolving different layers of a situation model in a smart environment is proposed. Different learning methods are presented as part of this framework: role detection per entity, unsupervised extraction of situations from multimodal data, supervised learning of situation representations, and evolution of a predefined situation model with feedback. The situation model serves as frame and support for the different methods, permitting to stay in an intuitive declarative framework. The proposed methods have been integrated into a whole system for smart home environment. The implementation is detailed, and two evaluations are conducted in the smart home environment. The obtained results validate the proposed approach.","1083-4419;10834419","","10.1109/TSMCB.2008.923526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4625983","Context awareness;human-centered computing;machine learning;situation modeling;situation split","","home automation;learning (artificial intelligence);ubiquitous computing","context-aware services;intuitive declarative framework;learning situation models;multimodal data;smart environment;smart home;supervised learning;unsupervised extraction","Algorithms;Artificial Intelligence;Behavior;Computer Simulation;Environment;Humans;Markov Chains;Pattern Recognition, Automated;Role;Sociometric Techniques;Video Recording","47","","11","","20080916","Feb. 2009","","IEEE","IEEE Journals & Magazines"
"Self-Learning Disk Scheduling","Y. Zhang; B. Bhargava","Purdue University, West Lafayette","IEEE Transactions on Knowledge and Data Engineering","20081125","2009","21","1","50","65","Performance of disk I/O schedulers is affected by many factors, such as workloads, file systems, and disk systems. Disk scheduling performance can be improved by tuning scheduler parameters, such as the length of read timers. Scheduler performance tuning is mostly done manually. To automate this process, we propose four self-learning disk scheduling schemes: change-sensing Round-Robin, feedback learning, per-request learning, and two-layer learning. experiments show that the novel two-layer learning scheme performs best. It integrates the workload-level and request-level learning algorithms. It employs feedback learning techniques to analyze workloads, change scheduling policy, and tune scheduling parameters automatically. We discuss schemes to choose features for workload learning, divide and recognize workloads, generate training data, and integrate machine learning algorithms into the two-layer learning scheme. We conducted experiments to compare the accuracy, performance, and overhead of five machine learning algorithms: decision tree, logistic regression, naive Bayes, neural network, and support vector machine algorithms. Experiments with real-world and synthetic workloads show that self-learning disk scheduling can adapt to a wide variety of workloads, file systems, disk systems, and user preferences. It outperforms existing disk schedulers by as much as 15.8% while consuming less than 3%-5% of CPU time.","1041-4347;10414347","","10.1109/TKDE.2008.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4547426","Application-transparent adaptation;Input/output;Machine learning;Sequencing and scheduling","","belief networks;disc storage;learning (artificial intelligence);operating systems (computers);scheduling;support vector machines","change-sensing Round-Robin;decision tree;disk I/O schedulers;disk systems;feedback learning;file systems;logistic regression;machine learning algorithms;naive Bayes;neural network;operating system;per-request learning;self-learning disk scheduling;support vector machine algorithms;tuning scheduler parameters;two-layer learning","","11","","60","","20080620","Jan. 2009","","IEEE","IEEE Journals & Magazines"
"Low complexity intra MB encoding in AVC/H.264","R. Jillani; H. Kalva","Florida Atlantic University","IEEE Transactions on Consumer Electronics","20090417","2009","55","1","277","285","In this paper we introduce and evaluate a novel machine learning based approach to reduce the complexity of Intra macroblock (MB) coding. The proposed approach is based on the hypothesis that MB coding mode decisions in H.264/AVC video have a correlation with the intensities of adjacent MBs and sub-MBs. This paper also discusses and analyzes different approaches of using machine learning in Intra prediction. We discuss, amongst other features, slices, Intra prediction scheme for H.264 and data mining. We use data mining algorithms to develop decision trees for H.264 coding mode decisions. The proposed approach reduces the H.264/AVC MB mode computation process into a decision tree lookup with very low complexity. The proposed algorithm is implemented in reference software by modifying the source code and is compared with the JM reference software for H.264/AVC.","0098-3063;00983063","","10.1109/TCE.2009.4814446","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814446","H.264/AVC;data mining;intra prediction;machine learning","Automatic voltage control;Data mining;Decision trees;Encoding;IEC standards;ISO standards;MPEG 4 Standard;Machine learning;Machine learning algorithms;Video coding","data mining;decision trees;learning (artificial intelligence);video coding","AVC/H.264;Intra prediction;JM reference software;data mining;decision tree lookup;intra macroblock encoding;machine learning;video coding","","2","2","16","","","February 2009","","IEEE","IEEE Journals & Magazines"
"Massive Pruning for Building an Operational Set of Association Rules: Metarules for Eliminating Conflicting and Redundant Rules","M. Cadot; A. Lelu","LORIA, Univ. Henri Poincare, Nancy","2009 International Conference on Information, Process, and Knowledge Management","20090213","2009","","","90","98","Extracting a set of association rules (AR) is a common method for representing knowledge embedded in a database. As long as many authors have aimed at improving the individual quality of these rules, not so many have considered their global quality and cohesiveness: Our objective is to provide the user with a set of rules he/she may combine to reason with, a consistent set as regards to ""common sense logic"". As local quality measures offer no warranty in this respect, we have defined patterns of major incoherencies and have associated metarules to them, resulting in a post-treatment cleaning phase for tracking down incoherencies and proposing corrections. We show that on the artificial Lucas0 database of the Causality Challenge, starting from 100 000 rules, we have reduced this rule set by three orders of magnitude, to 69 high-quality condensed rules embedding most of the structure designed by the challenge organizers.","","POD:978-1-4244-3362-9","10.1109/eKNOW.2009.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4782571","Association Rules;Commun Sense Logic;Data Mining;Knowledge discovery;Knowledge extraction;Machine Learning;Massive Pruning;Meta-rules;similarity of rules","Argon;Association rules;Cleaning;Data mining;Databases;Itemsets;Knowledge management;Logic;Phase measurement;Warranties","data mining","artificial Lucas0 database;association rules;common sense logic;conflicting rules;metarules;redundant rules","","0","","22","","","1-7 Feb. 2009","","IEEE","IEEE Conference Publications"
"Two Level Anomaly Detection Classifier","A. Khan; S. Khan","Sch. of Comput., Dublin City Univ., Dublin","2008 International Conference on Computer and Electrical Engineering","20090109","2008","","","65","69","This paper proposes two-level strategy for building the anomaly detection classifier, namely, macro level and micro level classification. The former intend to classify network data on a broader perspective to predict whether it is normal or a potential attack. The later classifies individual anomalies within each category of known attacks. The paper also investigates various feature selection techniques for choosing relevant features and study its effect on the performance of the anomaly detection classifiers. Experiments suggest that employing feature selection along with the proposed approach give anomaly detection rate of up to 99%.","","POD:978-0-7695-3504-3","10.1109/ICCEE.2008.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740947","Feature selection;Intrusion detection;Machine learning;Network anomaly detection","Computer networks;Computer vision;Information security;Information technology;Intrusion detection;Machine learning;Machine learning algorithms;Neural networks;Telecommunication traffic;Traffic control","learning (artificial intelligence);pattern classification;security of data","anomaly detection classifier;feature selection techniques;machine learning;macrolevel classification;microlevel classification;two-level strategy","","1","","17","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Co-EM Support Vector Machine Based Text Classification from Positive and Unlabeled Examples","B. z. Zhang; W. l. Zuo","Coll. of Comput. Sci. & Technol., Jilin Univ., Changchun","2008 First International Conference on Intelligent Networks and Intelligent Systems","20081121","2008","","","745","748","This paper has brought about a novel method based on multi-view algorithms for learning from positive and unlabeled examples (LPU). First we, with an improved 1-DNF method, split the text feature into a positive feature set (PF) and a negative feature set (NF). And we project each text vector on the two feature sets in turn. Then we use the co-EM SVM algorithm, which was previously used for semi-supervised learning. Finally, we select the better classifier for the result. Comprehensive evaluation has been performed on the Reuers-21578 collection which shows that our method is efficient and effective.","","CD-ROM:978-0-7695-3391-9","10.1109/ICINIS.2008.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4683332","Co-EM Support Vector Machine;Learning from Positive and Unlabeled examples;Machine Learning;Semi-Supervised Learning;Text classification","Bayesian methods;Educational institutions;Intelligent networks;Machine learning;Noise measurement;Semisupervised learning;Support vector machine classification;Support vector machines;Text categorization;Yield estimation","learning (artificial intelligence);pattern classification;support vector machines;text analysis","multiview algorithms;negative feature set;positive examples;positive feature set;semisupervised learning;support vector machine;text classification;unlabeled examples","","0","","9","","","1-3 Nov. 2008","","IEEE","IEEE Conference Publications"
"Move Statistics-Based Traffic Classifiers Online","Y. Wang; S. Z. Yu","Dept. of Electron. & Commun. Eng., Sun Yat-Sen Univ., Guangzhou","2008 International Conference on Computer Science and Software Engineering","20081222","2008","4","","721","725","A number of recent works have proposed using data mining and machine learning techniques to classify traffic flows based on statistical flow characteristics. Most of these classifiers work offline, since full-flow statistics are not available until a flow is finished. Therefore, it is usually too late to take actions for online deployment. In this paper, we propose a simple and effective technique to make these classifiers workable online. The idea is that different applications will show distinct traffic patterns from the very beginning of the flow, and so using statistics extracted from the first few packets can distinguish applications. Preliminary result shows that our method can achieve high flow accuracy, just a bit lower than using full-flow statistics. Using fewer packets per flow is promising, since it not only enables early classification and can easily apply to most of the existing classifiers, but also saves memory and computing power.","","POD:978-0-7695-3336-0","10.1109/CSSE.2008.911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722720","machine learning;traffic classification","Computer science;Data engineering;Inspection;Machine learning;Payloads;Software engineering;Statistical distributions;Statistics;Sun;Telecommunication traffic","data mining;learning (artificial intelligence);statistical analysis","data mining;machine learning;statistical flow;traffic classifiers online;traffic flows;traffic patterns","","2","","22","","","12-14 Dec. 2008","","IEEE","IEEE Conference Publications"
"Adapted One-versus-All Decision Trees for Data Stream Classification","S. Hashemi; Y. Yang; Z. Mirzamomen; M. Kangavari","Monash University, Melbourne","IEEE Transactions on Knowledge and Data Engineering","20090324","2009","21","5","624","637","One versus all (OVA) decision trees learn k individual binary classifiers, each one to distinguish the instances of a single class from the instances of all other classes. Thus OVA is different from existing data stream classification schemes whose majority use multiclass classifiers, each one to discriminate among all the classes. This paper advocates some outstanding advantages of OVA for data stream classification. First, there is low error correlation and hence high diversity among OVA's component classifiers, which leads to high classification accuracy. Second, OVA is adept at accommodating new class labels that often appear in data streams. However, there also remain many challenges to deploy traditional OVA for classifying data streams. First, as every instance is fed to all component classifiers, OVA is known as an inefficient model. Second, OVA's classification accuracy is adversely affected by the imbalanced class distribution in data streams. This paper addresses those key challenges and consequently proposes a new OVA scheme that is adapted for data stream classification. Theoretical analysis and empirical evidence reveal that the adapted OVA can offer faster training, faster updating and higher classification accuracy than many existing popular data stream classification algorithms.","1041-4347;10414347","","10.1109/TKDE.2008.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4609384","Data mining;Machine learning","","data analysis;decision trees;learning (artificial intelligence);pattern classification","data stream classification;data training;error correlation;one versus all decision tree","","29","3","31","","20080829","May 2009","","IEEE","IEEE Journals & Magazines"
"A preliminary investigation of monitoring ADLs using wireless kinematic sensors","A. F. Dalton; F. Morgan; G. OLaighin","Department of Electronic Engineering, National University of Ireland, Galway, Ireland","IET Irish Signals and Systems Conference (ISSC 2008)","20090210","2008","","","313","318","The objective of this on-going work is to evaluate the accuracy and reliability of wireless kinematic sensors in identifying basic activities of daily living (ADL). A preliminary trial was conducted consisting of 5 subjects; 3 male (mean: 23.6, SD: 2.41). Four kinematic sensors were placed on the subject; (a) mid sternum, (b) underneath the left armpit, (c) above the right hip and (d) the ankle of the dominant leg. A fifth sensor, the activPALtrade Trio Professional physical activity logger was used for comparison with the kinematic sensors. Each subject performed a range of basic activities' in a controlled laboratory setting. Subjects were then asked to carry out similar self annotated activities in a random order and in an unsupervised environment. Feature sets of mean, standard deviation, frequency-domain entropy, discrete FFT coefficient and signal magnitude area are being calculated. These feature sets will be used to train several classifiers including decision tree's, nearest neighbor, naive Bayes and support vector machines. Several meta-level classifiers will also be evaluated including boosting, bagging and plurality voting. We aim to identify the most reliable classifier and location for the kinematic sensor in indentifying basic ADLs.","0537-9989;05379989","Paper:978-0-86341-931-7","10.1049/cp:20080681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4780972","Activities of Daily Living;Kinematic Sensor;Machine Learning Classifiers","","Bayes methods;decision trees;discrete Fourier transforms;frequency-domain analysis;support vector machines;wireless sensor networks","ADL;activPAL Trio Professional physical activity logger;controlled laboratory setting;daily living activities;decision tree;discrete FFT coefficient;frequency-domain entropy;meta-level classifiers;naive Bayes;nearest neighbor;plurality voting;signal magnitude area;standard deviation;support vector machines;wireless kinematic sensors","","0","","","","","18-19 June 2008","","IET","IET Conference Publications"
"New module of text classification for IDA system","T. Shatovska; I. Kamenieva; I. Tarasov","Kharkov National University of Radioelectronics, 14, Lenina Av., 61166, UKRAINE","2009 10th International Conference - The Experience of Designing and Application of CAD Systems in Microelectronics","20090424","2009","","","481","482","In this article we are comparing Data Mining and Machine learning directions in text classification for IDA system. We will compare two high algorithms Chameleon from Data Mining and SVM (Support vector Machine) from Machine learning. Thus, define the best algorithm for text classification and decide to possibility inclusion SVM and using Chameleon for text classification in IDA system.","","POD:978-966-2191-05-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839886","Chameleon;Data Mining;IDA system;Machine Learning;SVM;Text classification","Classification tree analysis;Clustering algorithms;Data mining;Machine learning;Machine learning algorithms;Partitioning algorithms;Support vector machine classification;Support vector machines;Text categorization;Unsupervised learning","data mining;learning (artificial intelligence);pattern classification;support vector machines","data mining;machine learning;support vector machine;text classification","","0","","12","","","24-28 Feb. 2009","","IEEE","IEEE Conference Publications"
"Multi-instance Learning for Predicting Fraudulent Financial Statements","S. Kotsiantis; D. Kanellopoulos","Dept. of Comput. Sci. & Technol., Univ. of Peloponnese, Tripoli","2008 Third International Conference on Convergence and Hybrid Information Technology","20081118","2008","1","","448","452","This paper explores the effectiveness of multi-instance learning techniques in detecting firms that issue fraudulent financial statements (FFS). For this reason, a number of experiments have been conducted using representative learning algorithms, which were trained using a data set of 164 fraud and non-fraud Greek firms. The results show that MIBoost algorithm with decision stump as base learner had the best accuracy.","","POD:978-0-7695-3407-7","10.1109/ICCIT.2008.150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4682067","classification;data mining;machine learning","Audit Committee;Computer science;Europe;Financial management;Information technology;Mathematics;Quality management;Regulators;Security;Stock markets","financial data processing;learning (artificial intelligence)","MIBoost algorithm;decision stump;fraudulent financial statement prediction;multiinstance learning techniques;nonfraud Greek firms;representative learning algorithms","","0","","24","","","11-13 Nov. 2008","","IEEE","IEEE Conference Publications"
"Using JML Runtime Assertion Checking to Automate Metamorphic Testing in Applications without Test Oracles","C. Murphy; K. Shen; G. Kaiser","Dept. of Comput. Sci., Columbia Univ., New York, NY","2009 International Conference on Software Testing Verification and Validation","20090417","2009","","","436","445","It is challenging to test applications and functions for which the correct output for arbitrary input cannot be known in advance, e.g. some computational science or machine learning applications. In the absence of a test Oracle, one approach to testing these applications is to use metamorphic testing: existing test case input is modified to produce new test cases in such a manner that, when given the new input, the application should produce an output that can be easily be computed based on the original output. That is, if input x produces output f(x), then we create input x' such that we can predict f(x') based on f(x); if the application or function does not produce the expected output, then a defect must exist, and either f(x) or f(x') (or both) is wrong. By using metamorphic testing, we are able to provide built-in ""pseudo-oracles"" for these so-called ""nontestable programs"" that have no test oracles.In this paper, we describe an approach in which a function's metamorphic properties are specified using an extension to the Java modeling language (JML), a behavioral interface specification language that is used to support the ""design by contract"" paradigm in Java applications. Our implementation, called Corduroy, pre-processes these specifications and generates test code that can be executed using JML runtime assertion checking, for ensuring that the specifications hold during program execution. In addition topresenting our approach and implementation, we also describe our findings from case studies in which we apply our technique to applications without test oracles.","2159-4848;21594848","POD:978-1-4244-3775-7","10.1109/ICST.2009.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815377","machine learning;oracle problem;software testing","Application software;Automatic testing;Computer science;Contracts;Data mining;Java;Machine learning;Runtime;Software testing;Specification languages","Java;program testing","JML runtime assertion checking;Java modeling language;behavioral interface specification language;metamorphic testing;pseudo-oracles","","10","","39","","","1-4 April 2009","","IEEE","IEEE Conference Publications"
"Recursive Bayesian Linear Regression for Adaptive Classification","J. T. Chien; J. C. Chen","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan","IEEE Transactions on Signal Processing","20090203","2009","57","2","565","575","This paper presents a new recursive Bayesian linear regression (RBLR) algorithm for adaptive pattern classification. This algorithm performs machine learning in nonstationary environments. A classification model is adopted in model training. The initial model parameters are estimated by maximizing the likelihood function of training data. To activate the sequential learning capability, the randomness of the model parameters is properly expressed by the normal-gamma distribution. When new adaptation data are input, sufficient statistics are accumulated to obtain a new normal-gamma distribution as the posterior distribution. Accordingly, a recursive Bayesian algorithm is established to update the hyperparameters. The trajectory of nonstationary environments can be traced to perform the adaptive classification. Such recursive Bayesian models are used to satisfy the requirements of maximal class margin and minimal training error, which are essential in support vector machines (SVMs). In the experiments on the UCI machine learning repository and the FERET facial database, the proposed algorithm outperforms the state-of-art algorithms including SVMs and relevance vector machines (RVMs). The improvement is not only obtained in batch training but also in sequential adaptation. Face classification performance is continuously elevated by adapting to changing facial conditions.","1053-587X;1053587X","","10.1109/TSP.2008.2008258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663936","Bayesian adaptation;face recognition;machine learning;sequential learning;support vector machine (SVM)","","Bayes methods;learning (artificial intelligence);pattern classification;recursive estimation;regression analysis;support vector machines","adaptive pattern classification;face classification;machine learning;maximal class margin;minimal training error;normal-gamma distribution;recursive Bayesian linear regression;relevance vector machines;sequential learning capability;support vector machines","","8","","27","","20081031","Feb. 2009","","IEEE","IEEE Journals & Magazines"
"Experiments with Compressively Sampled Images and a New Debluring-Denoising Algorithm","S. Jafarpour; A. Pezeshki; R. Calderbank","Dept. of Comput. Sci., Princeton Univ., Princeton, NJ","2008 Tenth IEEE International Symposium on Multimedia","20090109","2008","","","66","73","In this paper we will examine the effect of different parameters in the quality of real compressively sampled images in the compressed sensing framework. We will select a variety of different real images of different types and test the quality of the recovered images, the recovery time, and required resources when different measurement methods with different parameters are used or when different recovering methods are applied. Then we will propose an algorithm to reduce the noise in the recovered images and sharpen them simultaneously. The algorithm exploits a well-known bilateral filtering in order to increase the confidence in margins and edges, and then uses an adaptive unsharp mask method to sharpen the images. The adaptive unsharp mask method extends the ordinary unsharp mask method and uses machine learning square loss minimization and regression in order to learn the optimal unsharping parameters. We will argue why both bilateral filtering and unsharp mask methods should be used in the algorithm simultaneously. Finally, we will show the results of applying the algorithm on real images that are recovered using the compressed sensing method and we will interpret the experimental results.","","CD-ROM:978-0-7695-3454-1","10.1109/ISM.2008.119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4741149","Bilateral Filter;Compressed Sensing;Image Processing;Image debluring;Machine Learning","Adaptive filters;Cameras;Compressed sensing;Filtering algorithms;Image coding;Image sampling;Machine learning;Machine learning algorithms;Minimization methods;Testing","data compression;filtering theory;image coding;image denoising;image restoration;image sampling;learning (artificial intelligence);minimisation;regression analysis","adaptive unsharp mask method;bilateral filtering;image debluring algorithm;image denoising algorithm;image noise reduction;image recovery method;image sharpening;machine learning square loss minimization;real image;regression analysis;sampled image compression","","0","","23","","","15-17 Dec. 2008","","IEEE","IEEE Conference Publications"
"A New Approach to Liquefaction Potential Mapping using Satellite Remote Sensing and Support Vector Machine Algorithm","T. Oommen; L. G. Baise","Member, IEEE, Department of Civil and Environmental Engineering, Tufts University, Medford, MA, USA. Email: thomas.oommen@tufts.edu","IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium","20090210","2008","3","","III - 51","III - 54","Earthquake induced ground shaking in areas with saturated sandy soils pose a major threat to communities due to soil liquefaction. Currently liquefaction potential is assessed on two scales: regionally based on surficial geologic unit or locally based on geotechnical sample data. However, the regional maps fail to capture the variability whereas; the collection of geotechnical data on the local scale is costly. Remote sensing products from air and space borne sensors allow us to explore the land surface parameters at different spatial scales. We explore the use of satellite based remote sensing data (Landsat 7 ETM+), together with other satellite derived products and geologic map at a test site in California. A supervised classification using Support Vector Machine (SVM) yielded an overall classification accuracy of 84% on a test data, indicating that the approach is promising for liquefaction potential mapping.","2153-6996;21536996","CD-ROM:978-1-4244-2808-3; POD:978-1-4244-2807-6","10.1109/IGARSS.2008.4779280","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4779280","Artificial Intelligence;Landsat;Liquefaction;Machine Learning;NDVI;Remote Sensing;Support Vector Machine","Digital elevation models;Earthquakes;Geology;Hazards;Remote sensing;Satellites;Soil;Support vector machine classification;Support vector machines;Testing","earthquakes;liquefaction;remote sensing;soil;support vector machines","California;Landsat 7 ETM+;earthquake;geotechnical data;ground shaking;liquefaction potential mapping;sandy soil;satellite remote sensing;spaceborne sensors;support vector machine","","0","","11","","","7-11 July 2008","","IEEE","IEEE Conference Publications"
"Distributional Smoothing in Bayesian Fault Diagnosis","S. G. W. Butcher; J. W. Sheppard","Johns Hopkins Univ., Baltimore, MD","IEEE Transactions on Instrumentation and Measurement","20090106","2009","58","2","342","349","Previously, we demonstrated the potential value of constructing asset-specific models for fault diagnosis. We also examined the effects of using split probabilities, where prior probabilities come from asset-specific statistics and likelihoods from fleet-wide statistics. In this paper, we build upon that work to examine the efficacy of smoothing probability distributions between asset-specific and fleet-wide distributions to further improve diagnostic accuracy. In the current experiments, we also add environmental differentiation to asset differentiation under the assumption that data are acquired in the context of online health monitoring. We hypothesize that the overall diagnostic accuracy will be increased with the smoothing approach relative to a fleet-wide model or a set of asset-specific models. The hypothesis is largely supported by the results. Future work will concentrate on improving the smoothing mechanism and in the context of small data sets.","0018-9456;00189456","","10.1109/TIM.2008.928874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4599185","Bayesian classifier;diagnosis (fault);machine learning;smoothing","","belief networks;fault diagnosis;learning (artificial intelligence);statistical distributions","Bayesian fault diagnosis;asset-specific statistics;distributional smoothing;fleet-wide statistics;online health monitoring;probability distributions smoothing;split probabilities","","5","","28","","20080815","Feb. 2009","","IEEE","IEEE Journals & Magazines"
"Support Vector Regression for GDOP","W. H. Su; C. H. Wu","Dept. of Inf. Manage., Shu-Te Univ., Kaohsiung","2008 Eighth International Conference on Intelligent Systems Design and Applications","20081208","2008","2","","302","306","Geometric Dilution of Precision (GDOP) is an indicator showing how well the constellation of GPS satellites is organized geometrically. The calculation of GDOP is a time- and power-consuming task which can be done by solving measurement equations with complicated matrix transformation and inversion. This paper presents a support vector regression (SVR) approach for finding regression models which can reasonably eliminate GDOP without complicated matrix inversion. Ten parameters from the measurement matrix are used as inputs to SVR which produces an estimation of GDOP. Using the proposed method, the processing costs for GPS positioning with low GDOP can be reduced. The experimental results show that the proposed method has good performance.","2164-7143;21647143","POD:978-0-7695-3382-7","10.1109/ISDA.2008.196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696348","Geometric Dilution of Precision;Global Positioning System;Support Vector Regression;machine-learning;soft-computing","Clocks;Delay;Equations;Geometry;Global Positioning System;Intelligent systems;Least squares approximation;Neural networks;Satellite navigation systems;Signal processing","Global Positioning System;artificial satellites;electrical engineering computing;matrix algebra;regression analysis;support vector machines","GPS satellites;complicated matrix transformation;geometric dilution of precision;measurement matrix;support vector regression","","2","","11","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"Inducing NNTrees Suitable for Hardware Implementation","H. Hayashi; Q. Zhao","Univ. of Aizu, Aizuwakamatsu","2008 Japan-China Joint Workshop on Frontier of Computer Science and Technology","20090106","2008","","","220","225","Neural network tree (NNTree) is one of the efficient models for pattern recognition. One drawback in using an NNTree is that the system may become very complicated if the dimensionality of the feature space is high. To avoid this problem, we propose in this paper to reduce the dimensionality first using linear discriminant analysis (LDA), and then induce the NNTree. After dimensionality reduction, the NNTree can become much more simpler. The question is, can we still get good NNTrees in the lower dimensional feature space? To answer this question, we conducted experiments on several public databases. Results show that the NNTree obtained after dimensionality reduction usually has less number of nodes, and the performance is comparable with the one obtained without dimensionality reduction.","2159-6301;21596301","POD:978-0-7695-3540-1","10.1109/FCST.2008.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736532","machine learning;multivariate decision trees;neural networks;pattern recognition","Computer science;Hardware;Neural networks","neural nets;pattern recognition;trees (mathematics)","dimensional feature space;dimensionality reduction;linear discriminant analysis;neural network tree;pattern recognition","","0","","12","","","27-28 Dec. 2008","","IEEE","IEEE Conference Publications"
"Improving Medical Decision Making by Self Organizing Intelligent Systems","P. Kokol; P. Povalej; G. Stiglic; D. Dinevski","Univ. of Maribor, Maribor","2008 International Symposium on Computational Intelligence and Design","20081222","2008","2","","267","270","Early and accurate diagnosing of various diseases has proved to be of vital importance in many health care processes. In recent years intelligent systems have been often used for decision support and classification in many scientific and engineering disciplines including health care. However, in many cases the proposed treatment, prediction or diagnose can differ from one intelligent system to another, similar to the real world where different medical specialists may have different opinions. Indeed, in real world specialists' opinions complement one another and when integrated they usually form a better solution. Our novel idea presented in this paper is to mimic this real world situation in the manner to merge different opinions generated by different intelligent systems using the self organizing abilities of cellular automata. We empirically show that classification cellular automata combining many various methods for classifier construction eventually outperforms single classifiers and conventional integration methods in terms of accuracy and class accuracy.","","POD:978-0-7695-3311-7","10.1109/ISCID.2008.212","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725505","cellular automata;classification;machine learning","Competitive intelligence;Computational intelligence;Decision making;Diseases;Intelligent systems;Machine learning;Medical diagnostic imaging;Medical services;Medical treatment;Organizing","cellular automata;health care;medical diagnostic computing;medical expert systems","cellular automata;health care;medical decision making;self organizing intelligent systems","","0","","9","","","17-18 Oct. 2008","","IEEE","IEEE Conference Publications"
"Bayes Vector Quantizer for Class-Imbalance Problem","C. Diamantini; D. Potena","Universit&#224; Politecnica delle Marche, Ancona","IEEE Transactions on Knowledge and Data Engineering","20090324","2009","21","5","638","651","The class-imbalance problem is the problem of learning a classification rule from data that are skewed in favor of one class. On these datasets traditional learning techniques tend to overlook the less numerous class, at the advantage of the majority class. However, the minority class is often the most interesting one for the task at hand. For this reason, the class-imbalance problem has received increasing attention in the last few years. In the present paper we point the attention of the reader to a learning algorithm for the minimization of the average misclassification risk. In contrast to some popular class-imbalance learning methods, this method has its roots in statistical decision theory. A particular interesting characteristic is that when class distributions are unknown, the method can work by resorting to stochastic gradient algorithm. We study the behavior of this algorithm on imbalanced datasets, demonstrating that this principled approach allows to obtain better classification performances compared to the principal methods proposed in the literature.","1041-4347;10414347","","10.1109/TKDE.2008.187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4624261","Classifier design and evaluation;Clustering;Data mining;Machine learning;Mining methods and algorithms;and association rules;classification","Costs;Data mining;Decision theory;Learning systems;Machine learning;Medical diagnosis;Minimization methods;Probability;Risk management;Stochastic processes","Bayes methods;decision theory;gradient methods;learning (artificial intelligence);minimisation;vector quantisation","Bayes vector quantizer;class-imbalance problem;classification rule;learning;minimization;misclassification risk;statistical decision theory;stochastic gradient algorithm","","11","","41","","20080912","May 2009","","IEEE","IEEE Journals & Magazines"
"MC: An Unsupervised Data Preprocessing for Classification","E. Hu; S. Chen; X. Yin","Dept. of Comput. Sci. & Eng., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing, China","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","259","263","The generalization ability of a classifier is often inherently associated with both the intra-class compactness and the inter-class separability. Owing to the fact that some current lower-dimensional manifold embedding techniques as a preprocessing for classification learning often lead to poor performance, in this paper, a new unsupervised data preprocessing technique called as manifold contraction (MC) is proposed for the subsequent classification task. The main contribution of our MC lies in: 1) the intra-manifold scatter becomes smaller while the inter-manifold scatter gets bigger relatively by a proper contraction mapping; 2) different from dimensionality reduction techniques, the estimation of intrinsic dimensionality can be avoided. The final experimental results show that MC preprocessing technique is effective and promising in the subsequent classification task especially in small-size labeled samples case.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739575","classification;data preprocessing;dimensionality reduction;machine learning;manifold contraction","Application software;Computer science;Data engineering;Data preprocessing;Geometry;Information technology;Manifolds;Mathematics;Principal component analysis;Scattering","pattern classification;unsupervised learning","contraction mapping;dimensionality reduction technique;inter-class separability;intra-class compactness;manifold contraction;subsequent classification task;unsupervised data preprocessing","","1","","18","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Continuous-time Hidden Markov models in Network Simulation","T. Bo; T. Xiaobin; Y. Baoqun","Department of Automation, University of Science and Technology of China, Anhui Hefei 230027, China. ttb96620@mail.ustc.edu.cn","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","667","670","The use of continuous-time hidden Markov models for network protocol and application performance evaluation has been validated to simulate network environments. In this paper, we develop a better algorithm to infer the continuous-time hidden Markov model from a series of end-to-end delay and loss observation of probing packets. We prove the algorithm's feasibility by theory deduction and realize numerable validation by comparing the probability of the observed sequence produced by the model inferred by different methods. The algorithm complexity is lower.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810577","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810577","continuous-time hidden Markov model;machining learning algorithm;network simulation;pattern recognition","Analytical models;Computer networks;Delay;Discrete event simulation;Hidden Markov models;Inference algorithms;Machine learning algorithms;Machining;Network topology;Pattern recognition","computer network performance evaluation;hidden Markov models;protocols","application performance evaluation;continuous-time hidden Markov models;end-to-end delay;network protocol;network simulation","","0","","11","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Switching Supervisory Control Using Calibrated Forecasts","I. Al-Shyoukh; J. S. Shamma","Dept. of Mol. & Med. Pharmacology, Univ. of California Los Angeles, Los Angeles, CA","IEEE Transactions on Automatic Control","20090407","2009","54","4","705","716","In this paper, we approach supervisory control as an online decision problem. In particular, we introduce ldquocalibrated forecastsrdquo as a mechanism for controller selection in supervisory control. The forecasted quantity is a candidate controller's performance level, or reward, over finite implementation horizon. Controller selection is based on using the controller with the maximum calibrated forecast of the reward. The proposed supervisor does not perform a pre-routed search of candidate controllers and does not require the presence of exogenous inputs for excitation or identification. Assuming the existence of a stabilizing controller within the set of candidate controllers, we show that under the proposed supervisory controller, the output of the system remains bounded for any bounded disturbance, even if the disturbance is chosen in an adversarial manner. The use of calibrated forecasts enables one to establish overall performance guarantees for the supervisory scheme even though non-stabilizing controllers may be persistently selected by the supervisor because of the effects of initial conditions, exogenous disturbances, or random selection. The main results are obtained for a general class of system dynamics and specialized to linear systems.","0018-9286;00189286","","10.1109/TAC.2009.2014923","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806176","Adaptive control;calibrated forecast;machine learning;supervisory control","Adaptive control;Computer science;Control systems;Game theory;Linear systems;Machine learning;Monitoring;Statistical analysis;Supervisory control;Switches","adaptive control;stability;time-varying systems","adaptive control;bounded disturbance;calibrated forecasts;controller selection;finite implementation horizon;linear systems;nonstabilizing controllers;online decision problem;switching supervisory control","","13","","23","","20090327","April 2009","","IEEE","IEEE Journals & Magazines"
"Turbo Iterative Signal Processing","H. Sun; H. Maitre","Wuhan University, Wuhan; Telecom-ParisTech, Paris","2009 IEEE 13th Digital Signal Processing Workshop and 5th IEEE Signal Processing Education Workshop","20090220","2009","","","495","500","A Turbo iterative method for signal processing is proposed. This method is a kind of multi-systems collaborative signal processing through iteration: several independent systems work in rotation, and each system takes feedback information from the other systems as a priori condition. We have applied such a Turbo iterative signal processing (TISP) method on speech signal enhancement, and on SAR (synthetic aperture radar) image filtering, segmentation and fusion. Some practical results presented in this article show that the Turbo iterative algorithm converges after 5-10 iterations and it improve greatly the signal processing performance. The TISP also shows an effective machine learning method, that is making a discussion between several independent systems through Turbo iteration.","","CD-ROM:978-1-4244-3677-4","10.1109/DSP.2009.4785974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4785974","Iterative signal processing method;Turbo iteration;image processing;machine learning;speech processing","Collaborative work;Feedback;Filtering;Iterative methods;Radar signal processing;Signal processing;Signal processing algorithms;Speech enhancement;Speech processing;Synthetic aperture radar","image fusion;image segmentation;iterative methods;learning (artificial intelligence);speech enhancement;turbo codes","SAR;Turbo iterative signal processing;image filtering;image fusion;image segmentation;machine learning;multi-systems collaborative signal processing;speech signal enhancement;synthetic aperture radar","","4","","13","","","4-7 Jan. 2009","","IEEE","IEEE Conference Publications"
"Identification and detection of electricity customer behaviour irregularities","A. H. Nizar; Z. Y. Dong","","2009 IEEE/PES Power Systems Conference and Exposition","20090424","2009","","","1","10","The present case study focusing on TNB, Malaysia's largest power utility, concentrates on load profiles as manifestations of customer behaviour. The main objective here is to base the investigation on comparing the efficacy of the Support Vector Machine (SVM) technique with the newly emerging techniques of Extreme Learning Machine (ELM) and its OS-ELM variant as means of classification and prediction in this context. Non-technical Losses (NTL) represent a significant proportion of electricity losses in both developing and developed countries. The ELM-based approach presented here uses customer load-profile information to expose abnormal behaviour that is known to be highly correlated with NTL activities. This approach provides a method of data mining for this purpose and it involves extracting patterns of customer behaviour from historical kWh consumption data. The results yield classification classes that are used to reveal whether any significant behaviour that emerges are due to irregularities in consumption. In this paper, ELM and online sequential-ELM (OS-ELM) algorithms are both used to achieve an improved classification performance and to increase accuracy of results. A comparison of this approach with other classification techniques, such as the Support Vector Machine (SVM) algorithm, is also undertaken and the ELM performance and accuracy in NTL analysis is shown to be superior.","","POD:978-1-4244-3810-5","10.1109/PSCE.2009.4840253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4840253","Classification Techniques;Extreme Machine Learning (ELM);Non-Technical Losses (NTL);Support Vector Machine (SVM)","Companies;Data mining;Decision making;Electricity supply industry;Electricity supply industry deregulation;Face detection;Machine learning;Support vector machine classification;Support vector machines;Transaction databases","electricity supply industry;learning (artificial intelligence);power engineering computing;support vector machines","customer load-profile information;electricity customer behaviour irregularities;electricity losses;extreme learning machine;nontechnical losses;power utility;support vector machine","","15","","65","","","15-18 March 2009","","IEEE","IEEE Conference Publications"
"Music Clustering With Features From Different Information Sources","T. Li; M. Ogihara; W. Peng; B. Shao; S. Zhu","Sch. of Comput. Sci., Florida Int. Univ., Miami, FL","IEEE Transactions on Multimedia","20090317","2009","11","3","477","485","Efficient and intelligent music information retrieval is a very important topic of the 21st century. With the ultimate goal of building personal music information retrieval systems, this paper studies the problem of identifying ldquosimilarrdquo artists using features from diverse information sources. In this paper, we first present a clustering algorithm that integrates features from both sources to perform bimodal learning. We then present an approach based on the generalized constraint clustering algorithm by incorporating the instance-level constraints. The algorithms are tested on a data set consisting of 570 songs from 53 albums of 41 artists using artist similarity provided by All Music Guide. Experimental results show that the accuracy of artist similarity identification can be significantly improved.","1520-9210;15209210","","10.1109/TMM.2009.2012942","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4797802","Clustering;different information sources;machine learning;music information retrieval","","information retrieval;learning (artificial intelligence);music;pattern clustering","bimodal learning;information source;instance-level constraint;intelligent music information retrieval;music clustering algorithm","","2","","36","","20090304","April 2009","","IEEE","IEEE Journals & Magazines"
"Thalassemia Screening using Unconstrained Functional Networks Classifier","E. A. El-Sebakhy; M. A. Elshafei","Information and Computer Science Department, Systems Engineering Department, College of Computer Science and Engineering, King Fahd University of Petroleum and Minerals, Dhahran 31261 Saudi Arabia. sebakhy@kfupm.edu.sa; fax: +966-3-860-2174.","2007 IEEE International Conference on Signal Processing and Communications","20081222","2007","","","1027","1030","Thalassemia is a genetic defect that is commonly found in many parts of the world. Number of humans that are suffering from this disease is determined by screening the heterozygous population. This article investigates the thalassemia screening problem using the unconstrained functional networks classifier. The learning algorithm for this new scheme is briefly illustrated. The new intelligent system with only sets of second order linearly independent polynomial functions to approximate the neuron functions is tested using thalassemia screening database. The performance of the new approach is compared with the performance of both multilayer perceptron and support vector machines. The results show that this new framework classifier is reliable, flexible, and outperform the most common existing classifiers.","","CD-ROM:978-1-4244-1236-5; POD:978-1-4244-1235-8","10.1109/ICSPC.2007.4728497","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4728497","Data Mining;Functional Networks;Machine Learning;Minimum Description Length;Neural Networks;Support Vector Machines;Thalassemias Screening","Deductive databases;Diseases;Genetics;Humans;Intelligent systems;Learning systems;Multilayer perceptrons;Neurons;Polynomials;System testing","classification;genetics;learning systems;medical computing;neural nets;pattern classification;polynomials","Thalassemia screening;data mining;genetic defect;intelligent system;learning algorithm;machine learning;minimum description length;neuron functions;second order linearly independent polynomial function;unconstrained functional networks classifier","","0","","10","","","24-27 Nov. 2007","","IEEE","IEEE Conference Publications"
"TRAcME: Temporal Activity Recognition Using Mobile Phone Data","D. Choujaa; N. Dulay","Dept. of Comput., Imperial Coll. London, London","2008 IEEE/IFIP International Conference on Embedded and Ubiquitous Computing","20090120","2008","1","","119","126","The aim of human activity recognition is to identify what a user or a group of users are doing at a given point in time, for example travelling or working. Activity recognition plays an important role in mobile and ubiquitous computing both as a goal in itself and as an intermediate task in the design of advanced applications. Virtually all existing activity recognition systems for mobile phones base their predictions on location cues. This approach forces the user to disclose personal information such as her home or work area. In this paper, we present a novel activity recognition system called TRAcME (temporal recognition of activities for mobile environments) which recognises generic human activities from large windows of context, Allenpsilas temporal relations and anonymous landmarks. Unlike existing systems, TRAcME handles simultaneous activities and outputs activities which are consistent with each other at the scale of a userpsilas day.","","POD:978-0-7695-3492-3","10.1109/EUC.2008.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4756329","Activity recognition;Allen's temporal logic;Context awareness;Machine learning;Mobile phone","Educational institutions;Embedded computing;Fluctuations;Global Positioning System;Humans;Machine learning;Mobile computing;Mobile handsets;Pervasive computing;Ubiquitous computing","learning (artificial intelligence);mobile computing","mobile computing;mobile phone data;temporal activity recognition;ubiquitous computing","","9","","8","","","17-20 Dec. 2008","","IEEE","IEEE Conference Publications"
"Analysis of the degree of importance of information using newspapers and questionnaires","M. Murata; T. Kanamaru; R. Nishimura; K. Torisawa","NICT, Seika, Kyoto, Japan","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","8","Our objective is to estimate and clarify the factors that determine the degree of importance of information by extracting the words that characterize the degree of importance and to construct a system for automatically estimating this degree of importance. We studied the degree of importance of information by using machine learning. We first performed experiments using newspaper documents (D<sub>n</sub>). In this experiment, we assumed that a document on the front page or at the top of the front page is important. We were able to identify important documents with a precision of 0.9 by using machine learning. We found that in the case of a newspaper, the degree of importance can be estimated with high precision. Next, to estimate the degree of importance that people attach to a document, we conducted experiments using questionnaire data (D<sub>q</sub>) as test data. In these experiments, the subjects were asked to identify which document from a pair was more important, and a high accuracy of 94% was obtained with more than 80% of them responding with the same answer. Furthermore, on using newspaper documents (D<sub>n</sub>) as training data, we could obtain (i) the same accuracy by using D<sub>n</sub> only instead of using D<sub>n</sub> with D<sub>q</sub> and (ii) a higher accuracy on using D<sub>n</sub> and D<sub>q</sub> instead of using D<sub>q</sub> only. This observation is useful because preparing questionnaire data (D<sub>q</sub>) can be an expensive process, whereas (D<sub>n</sub>) is free. Finally, we extracted the characteristic words that differentiated important information from less important information by calculating the parameters of the features in machine learning (maximum entropy (ME) method).","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906797","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906797","Degree of importance of information;analysis;machine learning;newspaper;questionnaire","Data mining;Entropy;Information analysis;Kernel;Linearity;Machine learning;Testing;Training data;Web pages","information analysis;learning (artificial intelligence);maximum entropy methods","degree of importance;machine learning;maximum entropy method;newspaper document;questionnaire data","","0","","14","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Geometry-Based Ensembles: Toward a Structural Characterization of the Classification Boundary","O. Pujol; D. Masip","Universitat de Barcelona, Barcelona","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090417","2009","31","6","1140","1146","This article introduces a novel binary discriminative learning technique based on the approximation of the non-linear decision boundary by a piece-wise linear smooth additive model. The decision border is geometrically defined by means of the characterizing boundary points - points that belong to the optimal boundary under a certain notion of robustness. Based on these points, a set of locally robust linear classifiers is defined and assembled by means of a Tikhonov regularized optimization procedure in an additive model to create a final lambda-smooth decision rule. As a result, a very simple and robust classifier with a strong geometrical meaning and non-linear behavior is obtained. The simplicity of the method allows its extension to cope with some of nowadays machine learning challenges, such as online learning, large scale learning or parallelization, with linear computational complexity. We validate our approach on the UCI database. Finally, we apply our technique in online and large scale scenarios, and in six real life computer vision and pattern recognition problems: gender recognition, intravascular ultrasound tissue classification, speed traffic sign detection, Chagas' disease severity detection, clef classification and action recognition using a 3D accelerometer data. The results are promising and this paper opens a line of research that deserves further attention.","0162-8828;01628828","","10.1109/TPAMI.2009.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4775901","Computer vision;Machine learning","","computational complexity;computer vision;image classification;learning (artificial intelligence);piecewise linear techniques;signal detection;spatial reasoning;stability","3D accelerometer data;Tikhonov regularized optimization procedure;UCI database;action recognition;binary discriminative learning technique;characterizing boundary points;classification boundary;computer vision;disease myocardial damage severity detection;face images;gender recognition;geometry-based ensembles;intravascular ultrasound tissue classification;lambda-smooth decision rule;large-scale learning;linear computational complexity;locally robust linear classifiers;machine learning;nonlinear decision boundary approximation;old musical scores clef classification;online learning;pattern recognition;piecewise linear smooth additive model;speed traffic sign detection;wearable device","Algorithms;Artificial Intelligence;Computer Simulation;Models, Theoretical;Pattern Recognition, Automated","10","","22","","20090206","June 2009","","IEEE","IEEE Journals & Magazines"
"Grading Cost Sensitive Models","S. Kotsiantis; D. Kanellopoulos","Dept. of Comput. Sci. & Technol., Univ. of Peloponnese, Tripoli","2008 Third International Conference on Convergence and Hybrid Information Technology","20081118","2008","1","","663","668","A learner induced from an imbalanced dataset has a low error rate for the majority class and an undesirable error rate for the minority class. This paper provides a study on the various methodologies that have tried to handle this problem. Finally, it presents an experimental study of these methodologies with a proposed grading cost-sensitive ensemble and it concludes that this ensemble is a more effective solution to the problem.","","POD:978-0-7695-3407-7","10.1109/ICCIT.2008.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4682102","classification;data mining;imbalanced dataset;machine learning","Bayesian methods;Classification tree analysis;Computer science;Costs;Decision trees;Error analysis;Information technology;Machine learning;Testing;Training data","learning (artificial intelligence);pattern classification","error rate;grading cost-sensitive ensemble;imbalanced dataset","","0","","23","","","11-13 Nov. 2008","","IEEE","IEEE Conference Publications"
"Performance of Inductive Method of Model Self-Organization with Incomplete Model and Noisy Data","N. Ponomareva; M. Alexandrov; A. Gelbukh","Univ. of Wolverhampton, Wolverhampton","2008 Seventh Mexican International Conference on Artificial Intelligence","20081118","2008","","","101","108","Inductive method of model self-organization (IMMSO) developed in 80s by A. Ivakhnenko is an evolutionary machine learning algorithm, which allows selecting a model of optimal complexity that describes or explains a limited number of observation data when any a priori information is absent or is highly insufficient. In this paper, we study the performance of IMMSO to reveal a model in a given class with different volumes of data, contributions of unaccounted components, and levels of noise. As a simple case study, we consider artificial observation data: the sum of a quadratic parabola and cosine; model class under consideration is a polynomial series. The results are interpreted in the terms of signal-noise ratio.","","POD:978-0-7695-3441-1","10.1109/MICAI.2008.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4682450","Data Mining;Inductive Modeling;Machine Learning;Noise Sensibility;Precision","Artificial intelligence;Computer networks;Data mining;Europe;High performance computing;Machine learning algorithms;Noise level;Polynomials;Social network services;Training data","data mining;learning (artificial intelligence)","artificial observation data;evolutionary machine learning algorithm;inductive method performance;model self-organization;noisy data;polynomial series;quadratic parabola;signal-noise ratio","","0","","13","","","27-31 Oct. 2008","","IEEE","IEEE Conference Publications"
"Learning the morphology of Zulu with different degrees of supervision","S. Spiegler; B. Golenia; K. Shalonova; P. Flach; R. Tucker","Department of Computer Science, University of Bristol, UK","2008 IEEE Spoken Language Technology Workshop","20090206","2008","","","9","12","In this paper we compare different levels of supervision for learning the morphology of the indigenous South African language Zulu. After a preliminary analysis of the Zulu data used for our experiments, we concentrate on supervised, semi-supervised and unsupervised approaches comparing strengths and weaknesses of each method. The challenges we face are limited data availability and data sparsity in connection with morphological analysis of indigenous languages. At the end of the paper we draw conclusions for our future work towards a morphological analyzer for Zulu.","","CD-ROM:978-1-4244-3472-5; POD:978-1-4244-3471-8","10.1109/SLT.2008.4777827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777827","degrees of supervision;indigenous languages;machine learning;morphology","Africa;Availability;Computer science;Dictionaries;Humans;Machine learning;Morphology;Natural languages;Speech analysis;Speech synthesis","learning (artificial intelligence);natural languages","South African language Zulu;morphological analysis;supervised learning","","0","","12","","","15-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Cascade Generalization with Classification and Model Trees","S. Kotsiantis; D. Kanellopoulos","Dept. of Comput. Sci. & Technol., Univ. of Peloponnese, Peloponnese","2008 Third International Conference on Convergence and Hybrid Information Technology","20081118","2008","1","","248","253","This paper proposes a cascade generalization technique, which combines the predictions of a classification tree and a model tree algorithm. We performed a comparison with other well known ensembles of decision trees, on standard benchmark datasets and the performance of the proposed technique was greater in most cases.","","POD:978-0-7695-3407-7","10.1109/ICCIT.2008.175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4682034","classification;ensemble of classifiers;supervised machine learning","Bagging;Boosting;Classification tree analysis;Computer science;Decision trees;Information technology;Predictive models;Sampling methods;Training data;Voting","decision trees","cascade generalization;classification tree;decision trees;model trees","","0","","17","","","11-13 Nov. 2008","","IEEE","IEEE Conference Publications"
"Forward Semi-supervised Feature Selection Based on Relevant Set Correlation","B. Wang; Y. Jia; S. Yang","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha","2008 International Conference on Computer Science and Software Engineering","20081222","2008","4","","210","213","Feature selection is among the keys in many applications, especially in mining high-dimensional data. With lack of labeled instances, the learning accuracy may deteriorate using traditional methods. In this paper, we introduce a ldquowrapperrdquo type semi-supervised feature selection approach based on RSC model. It extends the class label from labeled training set to unlabeled data. Additionally, we consider the case of overlapping during the extension. With respect to the experiments, our algorithm is proved to have a promising performance on the improvement of learning accuracy.","","POD:978-0-7695-3336-0","10.1109/CSSE.2008.1386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722600","feature selection;semi machine learning","Application software;Clustering algorithms;Computer science;Data mining;Filters;Kernel;Learning systems;Machine learning;Machine learning algorithms;Software engineering","data mining;feature extraction;learning (artificial intelligence)","high-dimensional data mining;relevant labeled training set correlation model;wrapper-type forward semisupervised feature selection approach","","3","","13","","","12-14 Dec. 2008","","IEEE","IEEE Conference Publications"
"Knowledge-Based Linguistic Annotation of Digital Cultural Heritage Collections","T. Ruotsalo; L. Aroyo; G. Schreiber","Helsinki University of Technology","IEEE Intelligent Systems","20090324","2009","24","2","64","75","A method for automatically annotating objects in digital cultural heritage collections uses structured vocabulary concepts and their metadata schema roles.","1541-1672;15411672","","10.1109/MIS.2009.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804825","Semantic Web;cultural heritage;intelligent Web services;machine learning;natural language processing","Art;Artificial intelligence;Automatic control;Cultural differences;Databases;Humans;Intelligent structures;Licenses;Thesauri;Vocabulary","digital libraries;exhibitions;humanities;information retrieval systems;text analysis;vocabulary","ARIA collection;Rijksmuseum Amsterdam;digital cultural heritage collections;knowledge-based linguistic annotation;metadata schema;structured vocabularies;text description","","10","","15","","","March-April 2009","","IEEE","IEEE Journals & Magazines"
"Supervised Inductive Learning with Lotka-Volterra Derived Models","K. Hovsepian; P. Anselmo; S. Mazumdar","Comput. Sci. Dept., New Mexico Tech., Socorro, NM","2008 Eighth IEEE International Conference on Data Mining","20090210","2008","","","233","242","We present a classification algorithm built on our adaptation of the Generalized Lotka-Volterra model, well-known in mathematical ecology. The training algorithm itself consists only of computing several scalars, per each training vector, using a single global user parameter and then solving a linear system of equations. Construction of the system matrix is driven by our model and based on kernel functions. The model allows an interesting point of view of kernels' role in the inductive learning process. We describe the model through axiomatic postulates. Finally, we present the results of the preliminary validation experiments.","1550-4786;15504786","POD:978-0-7695-3502-9","10.1109/ICDM.2008.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4781118","classification;data mining;model-driven algorithm;supervised inductive machine-learning","Biological system modeling;Classification algorithms;Computer science;Data mining;Equations;Machine learning;Machine learning algorithms;Mathematical model;Support vector machine classification;Support vector machines","Volterra equations;biology computing;ecology;learning by example;pattern classification","axiomatic postulate;classification algorithm;generalized Lotka-Volterra derived model;kernel function;linear equation system matrix;mathematical ecology;supervised inductive learning process;training algorithm","","0","","14","","","15-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Approach to Extracting Central URLs on Catalog Page","H. Bai; J. Wang; Y. Li","Nat. Network New Media Eng. Res. Center, Chinese Acad. of Sci., Beijing","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","388","392","Catalog pages construct the intermediate layer in architecture of a standard Web site; therefore research on information retrieval for this kind of pages can be beneficial to improve Web crawler's efficiency. A page is called ""catalog-style"" if its main body is displayed as a sequence of regular entries, and the central link in each entry apparently contains the pagepsilas major information. Here, we propose a central-URL extraction approach, which can automatically recognize effective information from the main segmentation on catalog-page. Our approach combines machine learning classification and DOM (document object model) tree based analysis. For one page, we represent each block node, mainly DIV and table, by a set of content-based and structure-based features, which can be used as the input of support vector machine to determine whether it belongs to ""main-body"" or not. After identifying the main semantic block, a DOM tree based algorithm that utilizes catalog's heuristic rules is implemented to find the central URLs in the segmentation. The evaluation results show that our approach obtains encouraging results with a high recall/precision ratio. This can be applied in topic-specific search engine development and other Web applications.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732851","Machine Learning;Web Information Retrival;Web Segmentation;Web URL Extraction","Crawlers;Data mining;Information retrieval;Search engines;Service oriented architecture;Support vector machine classification;Support vector machines;Text categorization;Uniform resource locators;Web pages","Internet;cataloguing;document handling;information retrieval;learning (artificial intelligence);pattern classification;search engines;support vector machines;tree data structures","DOM tree based analysis;Web crawler;Web site;catalog page;central URL extraction;content-based feature;document object model;heuristic rule;information retrieval;machine learning classification;structure-based feature;support vector machine;topic-specific search engine development","","0","","6","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Novel Approach to Quantify Novelty Levels Applied on Ubiquitous Music Distribution","M. K. Albertini; K. C. Li; R. F. d. Mello","Inst. of Math. & Comput. Sci., Univ. of Sao Paulo, Sao Paulo","2008 IEEE Asia-Pacific Services Computing Conference","20090210","2008","","","150","155","In order to take advantage and profit with the popularization of digital music, companies started marketing licensed content on high-storage portable media players. The introduction of wireless technology in such players motivates new business opportunities where music distribution is ubiquitous. However, in such high-supply scenario, consumers may have difficulties to find interesting content. In such context, music recommender systems assist consumers in identifying their preferences and in supporting content searches. An important feature in such market is the low attention given to new music styles, what increases the promotion costs. In order to assist consumers who, positive or negatively, pay attention to such novelty factor, this work proposes a novel method to estimate music preference profiles based on acoustic similarity measures. Such profiles are learnt by an artificial neural network, named self-organizing novelty detection neural network architecture (SONDE), which classifies and quantifies the novelty level of music titles regarding the user profile. Based on novelty levels, we suggest a discount rate model to support promotion strategies. The proposed method is evaluated by simulating some scenarios.","","CD-ROM:978-0-7695-3473-2","10.1109/APSCC.2008.238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4780668","Artificial Neural Networks;Machine Learning;Self-Organizing Novelty Detection","Acoustic measurements;Artificial neural networks;Companies;Distributed computing;Marketing and sales;Music;Pervasive computing;Portable computers;Portable media players;Recommender systems","music;neural nets;ubiquitous computing","acoustic similarity measures;artificial neural network;digital music;discount rate model;high-storage portable media players;licensed content;music preference profiles;music recommender systems;novelty levels;self-organizing neural network architecture;self-organizing novelty detection architecture;ubiquitous music distribution","","0","","18","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Kernels for Generalized Multiple-Instance Learning","Q. Tao; S. D. Scott; N. V. Vinodchandran; T. T. Osugi; B. Mueller","GC Image, LLC, Lincoln","IEEE Transactions on Pattern Analysis and Machine Intelligence","20081117","2008","30","12","2084","2098","The multiple-instance learning (MIL) model has been successful in numerous application areas. Recently, a generalization of this model and an algorithm for it were introduced, showing significant advantages over the conventional MIL model on certain application areas. Unfortunately, that algorithm is not scalable to high dimensions. We adapt that algorithm to one using a support vector machine with our new kernel kwedge. This reduces the time complexity from exponential in the dimension to polynomial. Computing our new kernel is equivalent to counting the number of boxes in a discrete, bounded space that contain at least one point from each of two multisets. We show that this problem is #P-complete, but then give a fully polynomial randomized approximation scheme (FPRAS) for it. We then extend k by enriching its representation into a new kernel k<sub>min</sub>, and also consider a normalized version of kwedge that we call k (which may or may not not be a kernel, but whose approximation yielded positive semidefinite Gram matrices in practice). We then empirically evaluate all three measures on data from content-based image retrieval, biological sequence analysis, and the musk data sets. We found that our kernels performed well on all data sets relative to algorithms in the conventional MIL model.","0162-8828;01628828","","10.1109/TPAMI.2007.70846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4420086","Machine learning;generalized multiple-instance learning;kernels;support vector machines","","approximation theory;computational complexity;learning (artificial intelligence);support vector machines","#P-complete;FPRAS;MIL;biological sequence analysis;content-based image retrieval;fully polynomial randomized approximation scheme;generalized multiple-instance learning;musk data sets;support vector machine;time complexity","Algorithms;Artificial Intelligence;Computer Simulation;Models, Theoretical;Pattern Recognition, Automated","3","","59","","20080202","Dec. 2008","","IEEE","IEEE Journals & Magazines"
"Distributed detection of network intrusions based on a parametric model","Y. g. Wang; X. Li; W. Hu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","2069","2074","With the increasing requirements of fast response and privacy protection, how to detect network intrusions in a distributed architecture becomes a hot research area in the development of modern information security systems. However, it is a challenge to build such a system, given the difficulties brought by the mixed-attribute property of network connection data and the constraints on network communication. In this paper, we present a framework for distributed detection of network intrusions based on a parametric model. The parametric model can explicitly reflect the distributions of different intrusion types and handle the mixed-attribute data naturally. Based on the model, we can generate an accurate global intrusion detector with a very low cost of communication among the distributed detection sites, and no sharing of original network data is needed. Experimental results demonstrate the advantages of the proposed framework in the distributed intrusion detection application.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811596","Distributed detection;information security;machine learning","Clustering algorithms;Data mining;Information security;Information systems;Intrusion detection;Machine learning algorithms;Neural networks;Parametric statistics;Protection;Statistical analysis","data privacy;security of data","distributed architecture;information security system;mixed-attribute data;network intrusion detection;parametric model;privacy protection","","1","","29","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Particle swarm optimisation for object classification","H. Evans; M. Zhang","School of Mathematics, Statistics and Computer Science, Victoria University of Wellington, PO Box 600, 6140, New Zealand","2008 23rd International Conference Image and Vision Computing New Zealand","20090123","2008","","","1","6","This paper describes a new approach to the use of particle swarm optimisation (PSO) for object classification problems. Instead of using PSO to evolve only a set of good parameter values for another machine learning method for object classification, the new approach developed in this paper can be used as a stand alone method for classification. Two new methods are developed in the new approach. The first new PSO method treats all different features equally important and finds an optimal partition matrix to separate a data set into distinct class groups. The second new PSO method considers the relative importance of each feature with the noise factor, and evolves a weight matrix to mitigate the effects of noisy partitions and feature dimensions. The two methods are examined and compared with a popular method using PSO combined with the nearest centroid and another evolutionary computing method, genetic programming, on three image data sets of increasing difficulty. The results suggest that the new weighted PSO method outperforms these existing methods on these object classification problems.","2151-2191;21512191","CD-ROM:978-1-4244-2583-9; POD:978-1-4244-2582-2","10.1109/IVCNZ.2008.4762143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4762143","Machine learning;computer vision;feature partitioning;genetic programming;nearest centroid;object classification;particle swarm optimisation","Classification algorithms;Computer vision;Equations;Genetic programming;Learning systems;Machine learning;Machine learning algorithms;Mathematics;Particle swarm optimization;Topology","feature extraction;image classification;object detection;particle swarm optimisation","feature partitioning;noise factor;object classification;optimal partition matrix;particle swarm optimisation;weight matrix","","1","","13","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"Discriminative Training of the Hidden Vector State Model for Semantic Parsing","D. Zhou; Y. He","The University of Reading, Reading","IEEE Transactions on Knowledge and Data Engineering","20081125","2009","21","1","66","77","In this paper, we discuss how discriminative training can be applied to the hidden vector state (HVS) model in different task domains. The HVS model is a discrete hidden Markov model (HMM) in which each HMM state represents the state of a push-down automaton with a finite stack size. In previous applications, maximum-likelihood estimation (MLE) is used to derive the parameters of the HVS model. However, MLE makes a number of assumptions and unfortunately some of these assumptions do not hold. Discriminative training, without making such assumptions, can improve the performance of the HVS model by discriminating the correct hypothesis from the competing hypotheses. Experiments have been conducted in two domains: the travel domain for the semantic parsing task using the DARPA Communicator data and the Air Travel Information Services (ATIS) data and the bioinformatics domain for the information extraction task using the GENIA corpus. The results demonstrate modest improvements of the performance of the HVS model using discriminative training. In the travel domain, discriminative training of the HVS model gives a relative error reduction rate of 31 percent in F-measure when compared with MLE on the DARPA Communicator data and 9 percent on the ATIS data. In the bioinformatics domain, a relative error reduction rate of 4 percent in F-measure is achieved on the GENIA corpus.","1041-4347;10414347","","10.1109/TKDE.2008.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4522548","Language parsing and understanding;Machine learning;Parameter learning","","grammars;hidden Markov models;information retrieval;learning (artificial intelligence);natural language processing","ATIS;Air Travel Information Services;DARPA Communicator data;GENIA corpus;HMM;HVS;MLE;discrete hidden Markov model;discriminative training;hidden vector state model;information extraction task;maximum-likelihood estimation;push-down automaton;semantic parsing","","11","","34","","20080516","Jan. 2009","","IEEE","IEEE Journals & Magazines"
"Toward Automatic Generation of Intrusion Detection Verification Rules","F. Massicotte; Y. Labiche; L. C. Briand","Commun. Res. Centre Canada, Ottawa, ON","2008 Annual Computer Security Applications Conference (ACSAC)","20081222","2008","","","279","288","An Intrusion Detection System (IDS) is a crucial element of a network security posture. One class of IDS, called signature-based network IDSs, monitors network traffic, looking for evidence of malicious behavior as specified in attack descriptions (referred to as signatures). Many studies have reported that IDSs can generate thousands of alarms a day, many of which are false alarms. The problem often lies in the low accuracy of IDS signatures. It is therefore important to have more accurate signatures in order to reduce the number of false alarms. One part of the false alarm problem is the inability of IDSs to verify attacks (i.e. distinguish between successful and failed attacks). If IDSs were able to accurately verify attacks, this would reduce the number of false alarms a network administrator has to investigate. In this paper, we demonstrate the feasibility of using a data mining algorithm to automatically generate IDS verification rules. We show that this automated approach is effective in reducing the number of false alarms when compared to other widely used and maintained IDSs.","1063-9527;10639527","POD:978-0-7695-3447-3","10.1109/ACSAC.2008.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721565","Intrusion Detection;Machine Learning","Application software;Computer security;Databases;Drives;Intrusion detection;Laboratories;Protocols;Software quality;Systems engineering and theory;Telecommunication traffic","data mining;digital signatures;program verification","data mining algorithm;intrusion detection verification rule;malicious behavior;network traffic monitoring;signature-based network security","","4","","22","","","8-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Learning Classifiers from Large Databases Using Statistical Queries","N. Koul; C. Caragea; V. Honavar; V. Bahirwani; D. Caragea","Iowa State Univ., Ames, IA","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","923","926","We describe an approach to learning predictive models from large databases in settings where direct access to data is not available because of massive size of data, access restrictions, or bandwidth requirements. We outline some techniques for minimizing the number of statistical queries needed; and for efficiently coping with missing values in the data. We provide open source implementation of the decision tree and naive Bayes algorithms to demonstrate the feasibility of the proposed approach.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740577","Decision Trees;INDUS;Machine Learning;Missing Values;Naive Bayes;Sufficient Statistics","Bandwidth;Costs;Decision trees;Deductive databases;Humans;Intelligent agent;Predictive models;Relational databases;Statistics;Virtual colonoscopy","Bayes methods;decision trees;learning (artificial intelligence);pattern classification;query processing;very large databases","access restriction;bandwidth requirement;decision tree;large database;learning classifier predictive model;naive Bayes algorithm;statistical queries minimization","","3","","13","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Latent-Space Variational Bayes","J. Sung; Z. Ghahramani; S. Y. Bang","POSTECH, Pohang","IEEE Transactions on Pattern Analysis and Machine Intelligence","20081117","2008","30","12","2236","2242","Variational Bayesian expectation-maximization (VBEM), an approximate inference method for probabilistic models based on factorizing over latent variables and model parameters, has been a standard technique for practical Bayesian inference. In this paper, we introduce a more general approximate inference framework for conjugate-exponential family models, which we call latent-space variational Bayes (LSVB). In this approach, we integrate out model parameters in an exact way, leaving only the latent variables. It can be shown that the LSVB approach gives better estimates of the model evidence as well as the distribution over latent variables than the VBEM approach, but in practice, the distribution over latent variables has to be approximated. As a practical implementation, we present a first-order LSVB (FoLSVB) algorithm to approximate this distribution over latent variables. From this approximate distribution, one can estimate the model evidence and the posterior over model parameters. The FoLSVB algorithm is directly comparable to the VBEM algorithm and has the same computational complexity. We discuss how LSVB generalizes the recently proposed collapsed variational methods [20] to general conjugate-exponential families. Examples based on mixtures of Gaussians and mixtures of Bernoullis with synthetic and real-world data sets are used to illustrate some advantages of our method over VBEM.","0162-8828;01628828","","10.1109/TPAMI.2008.157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4670325","Machine learning;conjugate exponential family;latent variable model;mixture of Gaussians;unsupervised Learning;variational Bayesian inference;variational method","Bayesian methods;Computational complexity;Convergence;Encoding;Gaussian processes;Machine learning;Maximum likelihood estimation;Monte Carlo methods;Predictive models;Statistical analysis","Bayes methods;approximation theory;expectation-maximisation algorithm;inference mechanisms","Bayesian inference;approximate inference method;collapsed variational methods;computational complexity;latent-space variational Bayes;probabilistic models;variational Bayesian expectation-maximization","Algorithms;Artificial Intelligence;Bayes Theorem;Computer Simulation;Models, Theoretical;Pattern Recognition, Automated","14","","26","","","Dec. 2008","","IEEE","IEEE Journals & Magazines"
"Monitoring the Extent and Intensity of Urban Areas Globally using the Fusion of MODIS 500m Resolution Satellite Imagery and Ancillary Data Sources","A. Schneider; M. A. Friedl; D. Potere","Center for Sustainability and the Global Environment, University of Wisconsin-Madison; aschneider4@wisc.edu","IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium","20090210","2008","5","","V - 346","V - 349","Although only a small percentage of global land cover, urban areas significantly alter climate, biogeochemistry, and hydrology at local, regional, and global scales. Despite the fact that three billion people live in cities, information related to global geographic patterns in urban extent and density is poor. Here we present results from efforts to map the global distribution of urban land use at 463 m spatial resolution using remotely sensed data from MODIS. Our approach uses a supervised decision tree classification algorithm that we process using region-specific parameters. The resulting map shows that urban areas occupy only 0.5-1.0 percent of the Earth's land area. Because resource and energy consumption is concentrated in urban areas, the geographic distribution and intensity of urban land use has important implications for models and related studies that require information related to role of humans in the global environment.","2153-6996;21536996","CD-ROM:978-1-4244-2808-3; POD:978-1-4244-2807-6","10.1109/IGARSS.2008.4780099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4780099","Cities;decision trees;land cover;machine learning;urbanization","Cities and towns;Classification tree analysis;Decision trees;Hydrology;Image resolution;MODIS;Monitoring;Satellites;Spatial resolution;Urban areas","decision trees;geographic information systems;geophysical signal processing;image fusion;image resolution;learning (artificial intelligence);remote sensing","MODIS satellite imagery;ancillary data sources;biogeochemistry;climate;energy consumption;global geographic pattern;global land cover;hydrology;image fusion;image resolution;resource consumption;supervised decision tree classification;urban areas;urban land use","","0","","17","","","7-11 July 2008","","IEEE","IEEE Conference Publications"
"Multi target tracking using a compact Q-learning with a teacher","E. M. Saad; M. H. Awadalla; A. M. Hamdy; H. I. Ali","Dept. of Electronics, Communications & Computer Engineering, Faculty of Engineering, Helwan University, Cairo, Egypt","2008 International Conference on Computer Engineering & Systems","20090203","2008","","","173","178","This paper focuses on developing a team of mobile robots capable of learning via human interaction. A modified Q-learning algorithm incorporating a teacher is proposed. The paper first concentrates on simplifying the Q-learning algorithm to be implemented on small and simple team of robots having limited capabilities of memory and computational power. Second it concentrates on the incorporation of a human teacher in the Q-learning algorithm. Experiments using the well-known robot simulator Webots on both single and multi-target tracking tasks have been conducted. The achieved results show the success of the proposed algorithm in the over all system performance.","","CD-ROM:978-1-4244-2116-9; POD:978-1-4244-2115-2","10.1109/ICCES.2008.4772991","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4772991","Human-robot interaction;Machine learning;Q-learning;Reinforcement learning","Education;Educational robots;Hardware;Human robot interaction;Learning systems;Machine learning;Machine learning algorithms;Mobile communication;Mobile robots;Target tracking","human-robot interaction;learning (artificial intelligence);mobile robots;target tracking","compact Q-learning;computational power;human-robot interaction;machine learning;mobile robots;multi target tracking;reinforcement learning;robot simulator Webots","","0","","14","","","25-27 Nov. 2008","","IEEE","IEEE Conference Publications"
"The Unreasonable Effectiveness of Data","A. Halevy; P. Norvig; F. Pereira","Google","IEEE Intelligent Systems","20090324","2009","24","2","8","12","At Brown University, there is excitement of having access to the Brown Corpus, containing one million English words. Since then, we have seen several notable corpora that are about 100 times larger, and in 2006, Google released a trillion-word corpus with frequency counts for all sequences up to five words long. In some ways this corpus is a step backwards from the Brown Corpus: it's taken from unfiltered Web pages and thus contains incomplete sentences, spelling errors, grammatical errors, and all sorts of other errors. It's not annotated with carefully hand-corrected part-of-speech tags. But the fact that it's a million times larger than the Brown Corpus outweighs these drawbacks. A trillion-word corpus - along with other Web-derived corpora of millions, billions, or trillions of links, videos, images, tables, and user interactions - captures even very rare aspects of human behavior. So, this corpus could serve as the basis of a complete model for certain tasks - if only we knew how to extract the model from the data.","1541-1672;15411672","","10.1109/MIS.2009.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804817","Semantic Web;machine learning;very large data bases","Broadcasting;Data mining;Frequency estimation;Humans;Machine learning;Natural language processing;Speech recognition;Tagging;Videos;Web pages","Internet;data handling;natural language processing","Brown Corpus;English words;Web-derived corpora;data unreasonable effectiveness;frequency counts;grammatical errors;hand-corrected part-of-speech tags;incomplete sentences;spelling errors;trillion-word corpus;unfiltered Web pages","","143","20","15","","","March-April 2009","","IEEE","IEEE Journals & Magazines"
"Cascaded Multi-level Promoter Recognition of  E. coli Using Dinucleotide Features","T. S. Rani; R. S. Bapi","Dept. of Comput. & Inf. Sci., Univ. of Hyderabad, Hyderabad, India","2008 International Conference on Information Technology","20081230","2008","","","83","88","Promoter recognition has been attempted using different paradigms such as motif/binding regions alone or whole promoter itself. In an earlier paper, a scheme is proposed to use 2-gram features to represent a promoter. These 2-grams gave a comparable performance with the existing methods in the literature. An in-depth analysis of data sets using 2-grams is performed. The analysis presented a scenario where there is a confusion between a majority of promoters with a minor set of non-promoter and vice versa. In an effort to build a complete classification system, using the majority and minority sets in promoters as well as non-promoters, a multi-level cascading system and Ada-Boost classifier are applied. The results indicate that much further improvement is not possible with the modifications proposed.","","POD:978-0-7695-3513-5","10.1109/ICIT.2008.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731304","Ada-boost classifier;global feature extraction;machine learning techniques;neural networks","Computational intelligence;Data analysis;Feature extraction;Frequency;Gene expression;Information technology;Machine learning;Neural networks;Performance analysis;Switches","biology computing;data analysis;microorganisms;pattern classification","2-gram features;Ada-Boost classifier;E. coli;cascaded multilevel promoter recognition;complete classification system;data analysis;data sets;dinucleotide features;in-depth analysis;majority sets;minority sets;motif/binding regions;multilevel cascading system","","0","","20","","","17-20 Dec. 2008","","IEEE","IEEE Conference Publications"
"Multidimensional Adaptations for Open Learning Management Systems","S. Baldiris; O. C. Santos; D. Huerva; R. Fabregat; J. G. Boticario","Inst. of Inf. & Applic. (IIiA), Univ. de Girona, Girona","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","352","356","Our work is focused on alleviating the workload for designers of adaptive courses on the complexity task of authoring adaptive learning designs adjusted to specific user characteristics and the user context. We propose an adaptation platform that consists in a set of intelligent agents where each agent carries out an independent adaptation task. The agents apply machine learning techniques to support the user modelling for the adaptation process.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740796","Adaptive Hypermedia;Intelligent Agent;Machine Learning;User modelling","Adaptation model;Artificial intelligence;Character generation;Conference management;Context modeling;Intelligent agent;Least squares approximation;Machine learning;Multidimensional systems;Technology management","computer aided instruction;educational courses;learning (artificial intelligence);software agents","adaptive courses;authoring adaptive learning designs;intelligent agents;machine learning techniques;multidimensional adaptations;open learning management systems","","5","","24","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Make3D: Learning 3D Scene Structure from a Single Still Image","A. Saxena; M. Sun; A. Y. Ng","Stanford University, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090321","2009","31","5","824","840","We consider the problem of estimating detailed 3D structure from a single still image of an unstructured environment. Our goal is to create 3D models that are both quantitatively accurate as well as visually pleasing. For each small homogeneous patch in the image, we use a Markov random field (MRF) to infer a set of ""plane parametersrdquo that capture both the 3D location and 3D orientation of the patch. The MRF, trained via supervised learning, models both image depth cues as well as the relationships between different parts of the image. Other than assuming that the environment is made up of a number of small planes, our model makes no explicit assumptions about the structure of the scene; this enables the algorithm to capture much more detailed 3D structure than does prior art and also give a much richer experience in the 3D flythroughs created using image-based rendering, even for scenes with significant nonvertical structure. Using this approach, we have created qualitatively correct 3D models for 64.9 percent of 588 images downloaded from the Internet. We have also extended our model to produce large-scale 3D models from a few images.","0162-8828;01628828","","10.1109/TPAMI.2008.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4531745","Computer vision;Depth cues;Image-based rendering;Machine learning;Scene Analysis;Statistical;Virtual reality;Vision and Scene Understanding;depth cues.;learning depth;monocular vision;scene analysis;vision and scene understanding","","Markov processes;image reconstruction;learning (artificial intelligence)","3D location;3D orientation;3D scene structure;Internet;Make3D;Markov random field;nonvertical structure;plane parameters;still image","Algorithms;Artificial Intelligence;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Photography;Reproducibility of Results;Sensitivity and Specificity","278","9","43","","20080530","May 2009","","IEEE","IEEE Journals & Magazines"
"Two-Phase Chief Complaint Mapping to the UMLS Metathesaurus in Korean Electronic Medical Records","B. Y. Kang; D. W. Kim; H. G. Kim","Dentistry Coll., Seoul Nat. Univ., Seoul","IEEE Transactions on Information Technology in Biomedicine","20090106","2009","13","1","78","86","The task of automatically determining the concepts referred to in chief complaint (CC) data from electronic medical records (EMRs) is an essential component of many EMR applications aimed at biosurveillance for disease outbreaks. Previous approaches that have been used for this concept mapping have mainly relied on term-level matching, whereby the medical terms in the raw text and their synonyms are matched with concepts in a terminology database. These previous approaches, however, have shortcomings that limit their efficacy in CC concept mapping, where the concepts for CC data are often represented by associative terms rather than by synonyms. Therefore, herein we propose a concept mapping scheme based on a two-phase matching approach, especially for application to Korean CCs, which uses term-level complete matching in the first phase and concept-level matching based on concept learning in the second phase. The proposed concept-level matching suggests the method to learn all the terms (associative terms as well as synonyms) that represent the concept and predict the most probable concept for a CC based on the learned terms. Experiments on 1204 CCs extracted from 15 618 discharge summaries of Korean EMRs showed that the proposed method gave significantly improved <i>F</i>-measure values compared to the baseline system, with improvements of up to 73.57%.","1089-7771;10897771","","10.1109/TITB.2008.2007103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663851","Chief compliant (CC);Unified Medical Language System (UMLS);concept indexing;concept mapping;information retrieval;machine learning","","database management systems;diseases;medical computing;medical information systems","CC concept mapping;Korean electronic medical records;UMLS Metathesaurus;biosurveillance;disease outbreaks;term-level matching;terminology database;two-phase chief complaint mapping","Abstracting and Indexing as Topic;Algorithms;Artificial Intelligence;Bayes Theorem;Humans;Korea;Medical Informatics;Medical Records Systems, Computerized;Natural Language Processing;Terminology as Topic;Unified Medical Language System","1","","23","","20081031","Jan. 2009","","IEEE","IEEE Journals & Magazines"
"The relevance of the CLP measure of a VoIP system with Regard to QoV.","D. Riordan; P. Doody","Department of Computing and Mathematics, Institute of Technology, Tralee, Ireland","IET Irish Signals and Systems Conference (ISSC 2008)","20090210","2008","","","49","54","Communication systems are undergoing constant and rapid innovation, both at the design stage and in the field. This in turn has led to an increasing need for fast, efficient, portable and economic methods for the testing of these systems. For voice carrying communication systems the quality of the transmitted voice that the system produces is a large factor in the systems overall performance rating. This measure is known as the 'Quality of Voice' (QoV) and can be evaluated either subjectively or objectively. Speech quality is a complex subjective phenomenon that can be best quantified by subjective testing. A subjective QoV measurement requires a 'listener' to rate a sample of speech produced by the system under test. To achieve accurate results an average rating, or Mean Opinion Score (MOS), must be found from a large panel of listeners. This results in subjective QoV testing being a highly expensive and time consuming process to conduct. This has driven the requirement for automated objective QoV testing systems which can operate efficiently and cost-effectively. The method described here aims to increase the efficiency of a previously established Non-intrusive objective QoV estimation system designed for use with a VoIP based network. The existing system takes as its inputs four operational parameters (Conditional and Unconditional Packet Loss Probabilities, Codec Type and Speaker Gender) of the communication system under test. These parameters are then mapped to a QoV score. This paper will identify the Conditional Loss Probability (CLP) parameter as being of least significance with regard to the QoV score achieved by the VoIP network. A similar QoV estimation system will then be developed with the CLP measure eliminated. This system will be tested to demonstrate that a system taking only three operational parameters of a VoIP system can still maintain a high degree of accuracy.","0537-9989;05379989","Paper:978-0-86341-931-7","10.1049/cp:20080637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4780928","Artificial Neural Networks;Machine Learning;Quality of Voice","","Internet telephony;learning (artificial intelligence);neural nets;probability;signal sampling;speech processing;telecommunication computing","CLP measure;VoIP system;conditional loss probability;machine learning;neural net;speech quality;speech sampling;subjective QoV testing;voice carrying communication system;voice quality","","0","","","","","18-19 June 2008","","IET","IET Conference Publications"
"Study on Preliminary Performance of Algorithms for Network Traffic Identification","Y. Ma; Z. Qian; G. Shou; Y. Hu","Beijing Univ. of Posts & Telecommun. Beijing, Beijing","2008 International Conference on Computer Science and Software Engineering","20081222","2008","1","","629","633","At present, more and more scholars paid attention to accuracy rate of Internet traffic identification, but not on construction model time, test time, CPU utilization, memory consumption, and concision of models description between different algorithms. However, these indicators played a decisive role in performance of practical internet traffic identification system. So, we collected traffic from existing operatorspsila networks, and tested 15 kinds of supervised learning algorithms and so on. The multivariate evaluation method was proposed to assess the test results. The results show that the 15 kinds of algorithms have similar accuracy rate, but their construction model time, test time, and concision of models description are very different. The C4.5 algorithm is the most suitable classification algorithms for network traffic identification.","","POD:978-0-7695-3336-0","10.1109/CSSE.2008.1277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721828","machine learning;multivariate evaluation method;performance;traffic identification","Classification algorithms;Internet;Machine learning;Machine learning algorithms;Software algorithms;Supervised learning;Telecommunication traffic;Testing;Traffic control;Transport protocols","Internet;identification;learning (artificial intelligence);telecommunication traffic","C4.5 algorithm;Internet traffic identification system;multivariate evaluation method;network traffic identification;supervised learning algorithms","","5","","12","","","12-14 Dec. 2008","","IEEE","IEEE Conference Publications"
"Machine Learned Real-Time Traffic Classifiers","Y. Wang; S. Z. Yu","Dept. of Electron. & Commun. Eng., Sun Yat-Sen Univ., Guangzhou","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","3","","449","454","Network traffic classification plays an important role in various network activities. Due to the ineffectiveness of traditional port-based and payload-based methods, recent works proposed using machine learning methods to classify flows based on statistical characteristics. In this study, we evaluate the effectiveness of machine learning techniques on the real-time traffic classification problem. We identify the most suitable ML classifier for network traffic classification by comparing various ML schemes,including both supervised and unsupervised methods. We also apply feature selection to identify significant features. Finally, we simulate real-time classification by using features derived from the first few packets of each flow.The results show that classifiers based on decision tree outperform others on both accuracy and performance; and that classifiers based on early flow properties can achieve high accuracy while reducing the computational complexity.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740037","Traffic classification;early classification;feature selection;machine learning","Classification tree analysis;Clustering algorithms;Information technology;Intelligent networks;Learning systems;Machine learning;Payloads;Protocols;Telecommunication traffic;Traffic control","computational complexity;decision trees;learning (artificial intelligence);pattern classification;telecommunication computing;telecommunication traffic;wide area networks","ML classifier;WAN traffic;computational complexity;decision tree;feature selection;machine learning method;network traffic classification;real-time traffic classifiers;supervised method;unsupervised method","","6","","30","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Syntactic and semantic English-Korean Machine Translation using ontology","Eugene Seo; Il-Sun Song; Su-Kyung Kim; Ho-Jin Choi","School of Engineering, Information and Communications University, Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","03","","2129","2132","This paper presents the syntactic and semantic method for English-Korean machine translation (MT) using ontology for Web-based MT system. We first build word class ontology from the English corpus and calculate the weight of relation between words in the same or different ontologies by counting the frequency of co-occurrence. With our constructed ontologies, we introduce the MT system model including the syntactic and semantic translation module. Each module translates the source language in different way. The syntactic translation module transforms the structure of English into Korean structure. The semantic translation module extracts an exact meaning of a word using ontologies. Through the both translation modules the source language is naturally translated into a target language.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809501","Machine Learning;Machine Translation;Natural Language Process;Ontology","Dictionaries;Frequency;Globalization;Machine learning;Natural language processing;Natural languages;Ontologies;Portals;Search engines;Web pages","language translation;natural language processing;ontologies (artificial intelligence)","Web-based MT system;ontology;semantic English-Korean machine translation;syntactic English-Korean machine translation","","1","","12","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Applications of reinforcement learning in an open railway access market price negotiation","Shun King Wong; Chi Wai Tsang; Tin Kin Ho","Department of Electrical Engineering, The Hong Kong Polytechnic University, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","2309","2314","In an open railway access market price negotiation, it is feasible to achieve higher cost recovery by applying the principles of price discrimination. The price negotiation can be modeled as an optimization problem of revenue intake. In this paper, we present the pricing negotiation based on reinforcement learning model. A negotiated-price setting technique based on agent learning is introduced, and the feasible applications of the proposed method for open railway access market simulation are discussed.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811637","machine learning;railway simulation;reinforcement learning","Costs;Elasticity;Learning;Multiagent systems;Pricing;Problem-solving;Rail transportation;Resource management;Software agents;Tin","learning (artificial intelligence);marketing;optimisation;pricing;railways","agent learning;open railway access market price negotiation;optimization problem;price discrimination;reinforcement learning;revenue intake","","0","","12","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Exploratory Undersampling for Class-Imbalance Learning","X. Y. Liu; J. Wu; Z. H. Zhou","Nat. Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20090317","2009","39","2","539","550","Undersampling is a popular method in dealing with class-imbalance problems, which uses only a subset of the majority class and thus is very efficient. The main deficiency is that many majority class examples are ignored. We propose two algorithms to overcome this deficiency. EasyEnsemble samples several subsets from the majority class, trains a learner using each of them, and combines the outputs of those learners. BalanceCascade trains the learners sequentially, where in each step, the majority class examples that are correctly classified by the current trained learners are removed from further consideration. Experimental results show that both methods have higher Area Under the ROC Curve, F-measure, and G-mean values than many existing class-imbalance learning methods. Moreover, they have approximately the same training time as that of undersampling when the same number of weak classifiers is used, which is significantly faster than other methods.","1083-4419;10834419","","10.1109/TSMCB.2008.2007853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4717268","Class-imbalance learning;data mining;ensemble learning;machine learning;undersampling","","data mining;learning (artificial intelligence)","BalanceCascade;EasyEnsemble;F-measure;G-mean;class-imbalance learning;data mining;machine learning","","234","","47","","20081216","April 2009","","IEEE","IEEE Journals & Magazines"
"Enhancement approaches of covering process for robot behaviors","S. M. Baneamoon; R. A. Salam","School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","2009 4th International Conference on Autonomous Robots and Agents","20090321","2009","","","590","594","In this paper a simulated control system for robot is designed by using distributed learning classifier system to perform complex behaviors. A set of enhanced solutions of cover detectors problem is suggested and compared with each other in order to make the simulated robot more effective in choosing the appropriate behavior (action).","","POD:978-1-4244-2712-3","10.1109/ICARA.2000.4803920","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4803920","covering process;genetic based machine learning;learning clasifier system;machine learning","Computational modeling;Computer simulation;Control system synthesis;Detectors;Distributed computing;Finance;Genetic algorithms;Intelligent robots;Machine learning;Robot control","learning (artificial intelligence);robots","distributed learning classifier system;machine learning;robot behaviors;simulated control system","","3","","13","","","10-12 Feb. 2009","","IEEE","IEEE Conference Publications"
"Outlier Detection with the Kernelized Spatial Depth Function","Y. Chen; X. Dang; H. Peng; H. L. Bart Jr.","Dept. of Comput. & Inf. Sci., Univ. of Mississippi, Oxford, MS","IEEE Transactions on Pattern Analysis and Machine Intelligence","20081230","2009","31","2","288","305","Statistical depth functions provide from the deepest point a center-outward ordering of multidimensional data. In this sense, depth functions can measure the extremeness or outlyingness of a data point with respect to a given data set. Hence, they can detect outliers observations that appear extreme relative to the rest of the observations. Of the various statistical depths, the spatial depth is especially appealing because of its computational efficiency and mathematical tractability. In this article, we propose a novel statistical depth, the kernelized spatial depth (KSD), which generalizes the spatial depth via positive definite kernels. By choosing a proper kernel, the KSD can capture the local structure of a data set while the spatial depth fails. We demonstrate this by the half-moon data and the ring-shaped data. Based on the KSD, we propose a novel outlier detection algorithm, by which an observation with a depth value less than a threshold is declared as an outlier. The proposed algorithm is simple in structure: the threshold is the only one parameter for a given kernel. It applies to a one-class learning setting, in which normal observations are given as the training data, as well as to a missing label scenario, where the training set consists of a mixture of normal observations and outliers with unknown labels. We give upper bounds on the false alarm probability of a depth-based detector. These upper bounds can be used to determine the threshold. We perform extensive experiments on synthetic data and data sets from real applications. The proposed outlier detector is compared with existing methods. The KSD outlier detector demonstrates a competitive performance.","0162-8828;01628828","","10.1109/TPAMI.2008.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479479","Machine learning;Outlier detection;Statistical;Statistical computing;anomaly detection;kernel method;novelty detection;spatial depth;statistical depth function;unsupervised learning.","","learning (artificial intelligence)","anomaly detection;kernel method;kernelized spatial depth function;multidimensional data;outlier detection;statistical depth function;unsupervised learning","Algorithms;Artificial Intelligence;Computer Simulation;Image Interpretation, Computer-Assisted;Models, Theoretical;Pattern Recognition, Automated","29","","78","","20080331","Feb. 2009","","IEEE","IEEE Journals & Magazines"
"Multi-instance Learning for Bankruptcy Prediction","S. Kotsiantis; D. Kanellopoulos","Dept. of Comput. Sci. & Technol., Univ. of Peloponnese, Tripoli","2008 Third International Conference on Convergence and Hybrid Information Technology","20081118","2008","1","","1007","1012","Forecast of corporate bankruptcy is a phenomenon of increasing interest to investors/creditors, borrowing firms and governments. Early identification of firms' impending failure is very desirable. The scope of this paper is to investigate the efficiency of multi-instance learning in such an environment. For this reason, a number of experiments have been conducted using representative learning algorithms, which were trained using a data set of 150 failed and solvent Greek firms in the recent period. It was found that multi-instance learning algorithms could enable experts to predict bankruptcies with satisfying accuracy.","","POD:978-0-7695-3407-7","10.1109/ICCIT.2008.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4682164","classification;data mining;machine learning","Computer science;Context modeling;Government;Information technology;Machine learning;Mathematics;Predictive models;Solvents;Supervised learning;Technology forecasting","investment;learning (artificial intelligence)","bankruptcy prediction;creditors;investors;multiinstance learning;representative learning algorithms","","0","","23","","","11-13 Nov. 2008","","IEEE","IEEE Conference Publications"
"Methodological Approach for Machine based Expression and Gender Classification","G. M. Rao; G. R. Babu; G. V. Kumari; N. K. Chaitanya","Gokaraju Rangaraju Inst. of Eng. & Technol., Hyderabad","2009 IEEE International Advance Computing Conference","20090331","2009","","","1369","1374","Machine based gender classification is one of the challenging problem to the computer science researchers. The effortless ability exhibited by a two year kid for the same needs immense computation power for the computing machines. Many people attempted this problem by using different psychological characteristics such as handwriting, speech recognition, query response etc. These computational intensive techniques are application based and classification efficiency is limited. Some of the face identification systems have used the pixel based information, Eigen faces and geometrical relations of the facial features. We present a neural network-based upright invariant frontal face detection system which can classify the gender based on the facial information. In our approach we club the pixel based and geometric facial features to increase the reliability of classification process. The use of pi-sigma neural network and the cyclic shift invariance technique enhances the robustness of classification process.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809216","CSIT;Face detection;Machine learning;Pattern recognition;Pi-sigma network","Computer networks;Computer science;Computer vision;Eyes;Face detection;Facial features;Human computer interaction;Neural networks;Nose;Pixel","face recognition;feature extraction;gender issues;geometry;image classification;neural nets","computer science researchers;cyclic shift invariance technique;face identification systems;facial features;geometric facial features;machine based expression classification;machine based gender classification;pi-sigma neural network;psychological characteristics;upright invariant frontal face detection system","","1","","22","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Feature Selection in Automatic Music Genre Classification","C. N. Silla Jr.; A. L. Koerich; C. A. A. Kaestner","Comput. Lab. Canterbury, Univ. of Kent, Canterbury","2008 Tenth IEEE International Symposium on Multimedia","20090109","2008","","","39","44","This paper presents the results of the application of a feature selection procedure to an automatic music genre classification system. The classification system is based on the use of multiple feature vectors and an ensemble approach, according to time and space decomposition strategies. Feature vectors are extracted from music segments from the beginning, middle and end of the original music signal (time decomposition). Despite being music genre classification a multi-class problem, we accomplish the task using a combination of binary classifiers, whose results are merged in order to produce the final music genre label (space decomposition). As individual classifiers several machine learning algorithms were employed: naive-Bayes, decision trees, support vector machines and multi-layer perceptron neural nets. Experiments were carried out on a novel dataset called Latin music database, which contains 3,227 music pieces categorized in 10 musical genres. The experimental results show that the employed features have different importance according to the part of the music signal from where the feature vectors were extracted. Furthermore, the ensemble approach provides better results than the individual segments in most cases.","","CD-ROM:978-0-7695-3454-1","10.1109/ISM.2008.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4741145","Audio classification;Machine Learning;Music genre classification;Pattern classification","Classification tree analysis;Decision trees;Feature extraction;Machine learning algorithms;Multi-layer neural network;Multilayer perceptrons;Multiple signal classification;Neural networks;Support vector machine classification;Support vector machines","Bayes methods;audio signal processing;decision trees;feature extraction;learning (artificial intelligence);multilayer perceptrons;music;signal classification;support vector machines","Latin music database;automatic music genre classification system;binary classifier;decision tree algorithm;ensemble approach;feature extraction;feature selection procedure;machine learning algorithm;multiclass problem;multilayer perceptron neural net algorithm;naive-Bayes algorithm;space decomposition strategy;support vector machine algorithm;time decomposition strategy","","6","","23","","","15-17 Dec. 2008","","IEEE","IEEE Conference Publications"
"Learning Web Page Block Functions using Roles of Images","X. Yang; Y. Shi","Department of Computer Science and Technology, Tsinghua University, Beijing, P. R. China. yang-x02@mails.tsinghua.edu.cn","2008 Third International Conference on Pervasive Computing and Applications","20090213","2008","1","","151","156","Making use of block information in Web IR and Data Mining tasks calls for a good understanding of the function of each block. Existing works on classifying block functions and judging block importance have not made full use of the image factor, and only simple image features were considered. We regard image as a strong indicator of Web page blocks with various functions and propose to learn block functions using roles of images as part of block features. Blocks are generated from Web page segmentation and roles of images are automatically decided by image classification. We experiment on 140 Web pages and demonstrate that utilizing roles of images can significantly improve the classification quality of learning Web page block functions. We also measure the usefulness of different roles of images and evaluate the effect of two page segmentation methods.","","CD-ROM:978-1-4244-2021-6; POD:978-1-4244-2020-9","10.1109/ICPCA.2008.4783565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4783565","Block Function;Machine Learning;Role of Image;Web Page Block","Computer science;Data mining;HTML;Handheld computers;Image classification;Image segmentation;Machine learning;Machine learning algorithms;Pervasive computing;Web pages","Web sites;data mining;image classification;image segmentation;learning (artificial intelligence)","Web page block function learning;data mining;image classification;image segmentation;machine learning","","0","","18","","","6-8 Oct. 2008","","IEEE","IEEE Conference Publications"
"Mining Protein Primary Structure Data Using Committee Machines Approach to Predict Protein Contact Map","N. K. Habibi; K. Mahdaviani; M. H. Saraee","Dept. of Electr. & Comput. Eng., Isfahan Univ. of Technol., Isfahan","2008 4th International Conference on Emerging Technologies","20090206","2008","","","280","285","Committee machines approach has shown to be useful in different applications. Protein primary structure data contain valuable information to extract. In this paper we mine these data and predict protein contact map based on committee machines. Contact map is the simplified, two dimensional representation of protein spatial structure. Contact map prediction is of great interest due to its application in fold recognition and predicting protein tertiary structure. The results show that the performance of the committee is considerably better than a single model.","","CD-ROM:978-1-4244-2211-1; POD:978-1-4244-2210-4","10.1109/ICET.2008.4777515","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777515","artificial intelligence;bioinformatics;committee machine;contact map prediction;ensemble learning;machine learning;neural network;protein contact map","Bioinformatics;Contacts;Data mining;Database systems;Genetic mutations;IEEE members;Laboratories;Machine learning;Protein engineering;Protein sequence","biology computing;data mining;prediction theory;proteins","committee machines;contact map prediction;data mining;protein contact map;protein primary structure data;protein spatial structure","","0","","24","","","18-19 Oct. 2008","","IEEE","IEEE Conference Publications"
"Learning the structure of retention data using Bayesian networks","A. McGovern; C. M. Utz; S. E. Walden; D. A. Trytten","School of Computer Science, University of Oklahoma, USA","2008 38th Annual Frontiers in Education Conference","20081222","2008","","","F3D-7","F3D-12","We introduce a novel approach to examining retention data by learning Bayesian Networks automatically from survey data administered to minority students in the College of Engineering at the University of Oklahoma. Bayesian networks provide a human readable model of correlations in large data sets, which enables researchers to improve their understanding of the data without preconceptions. We compare the results of our learned structures with human expectations and interpretation of the data as well as with cross-validation on the data. The average Area Under the Curve of the networks using cross-validation was 0.6. The domain experts believe the methodology of automatically learning such structures is promising and we are continuing to improve the structure learning process.","0190-5848;01905848","CD-ROM:978-1-4244-1970-8; POD:978-1-4244-1969-2","10.1109/FIE.2008.4720539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4720539","Bayesian networks;machine learning;minority students;retention","Bayesian methods;Data engineering;Educational institutions;Engineering education;Humans;Instruments;Logistics;Machine learning;Reliability engineering;Statistical analysis","belief networks;computer aided instruction;data handling;data structures;educational institutions","Bayesian networks;College of Engineering;University of Oklahoma;area under the curve;cross-validation;human readable model;minority students;retention data structure;structure learning process","","0","","26","","","22-25 Oct. 2008","","IEEE","IEEE Conference Publications"
"Bootstrapping word alignment by automatically generated bilingual dictionary","D. Zhu; B. Chang","Institute of Computational Linguistics, Peking University, Beijing, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","This paper presents a new approach to improve the word alignment. Building a bilingual dictionary is one of the main applications for word alignment. However, the research of using the bilingual dictionary to improve the word alignment is not enough. There are two bottlenecks. The first is that large bilingual dictionary is hard to get. The second is that the normal approach of using bilingual dictionary does not make full use of the dictionary. We designed a bootstrapping algorithm to conquer the bottlenecks, achieving a good result.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906750","Bootstrapping;Machine Learning;Word Alignment","Data engineering;Dictionaries;Information retrieval;Libraries;Natural languages;Optical computing;Performance evaluation;Relational databases;Spatial databases;Testing","dictionaries;language translation;natural language processing","automatically generated bilingual dictionary;bootstrapping algorithm;word alignment","","1","","13","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Cost Curve Evaluation of Fault Prediction Models","Y. Jiang; B. Cukic; T. Menzies","Lane Dept. of Comput. Sci. & Electr. Eng., West Virginia Univ., Morgantown, WV","2008 19th International Symposium on Software Reliability Engineering (ISSRE)","20081208","2008","","","197","206","Prediction of fault prone software components is one of the most researched problems in software engineering. Many statistical techniques have been proposed but there is no consensus on the methodology to select the ""best model"" for the specific project. In this paper, we introduce and discuss the merits of cost curve analysis of fault prediction models. Cost curves allow software quality engineers to introduce project-specific cost of module misclassification into model evaluation. Classifying a software module as fault-prone implies the application of some verification activities, thus adding to the development cost. Misclassifying a module as fault free carries the risk of system failure, also associated with cost implications. Through the analysis of sixteen projects from public repositories, we observe that software quality does not necessarily benefit from the prediction of fault prone components. The inclusion of misclassification cost in model evaluation may indicate that even the ""best"" models achieve performance no better than trivial classification. Our results support a recommendation to adopt cost curves as one of the standard methods for software quality model performance evaluation.","1071-9458;10719458","CD-ROM:978-0-7695-3405-3","10.1109/ISSRE.2008.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4700324","classification;machine learning;software quality;verification and validation","Application software;Computer science;Costs;Fault diagnosis;Predictive models;Quality assurance;Reliability engineering;Software quality;Software reliability;Testing","program verification;software cost estimation;software fault tolerance;software quality","cost curve evaluation;fault prediction model;fault prone software component;module misclassification;project-specific cost;software quality;statistical technique","","10","","18","","","10-14 Nov. 2008","","IEEE","IEEE Conference Publications"
"Similarity Learning for Nearest Neighbor Classification","A. M. Qamar; E. Gaussier; J. P. Chevallet; J. H. Lim","Lab. d'Inf. de Grenoble, Univ. Joseph Fourier, Grenoble","2008 Eighth IEEE International Conference on Data Mining","20090210","2008","","","983","988","In this paper, we propose an algorithm for learning a general class of similarity measures for kNN classification. This class encompasses, among others, the standard cosine measure, as well as the Dice and Jaccard coefficients. The algorithm we propose is an extension of the voted perceptron algorithm and allows one to learn different types of similarity functions (either based on diagonal, symmetric or asymmetric similarity matrices). The results we obtained show that learning similarity measures yields significant improvements on several collections, for two prediction rules: the standard kNN rule, which was our primary goal, and a symmetric version of it.","1550-4786;15504786","POD:978-0-7695-3502-9","10.1109/ICDM.2008.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4781212","Data Mining;Machine Learning;Nearest Neighbor Classification;Similarity Learning","Data mining;Databases;Equations;Euclidean distance;Gaussian processes;Machine learning;Measurement standards;Nearest neighbor searches;Pattern recognition;Symmetric matrices","learning (artificial intelligence);matrix algebra;pattern classification","Dice coefficient;Jaccard coefficient;asymmetric matrix;diagonal matrix;kNN classification;nearest neighbor classification;similarity learning;standard cosine measure;symmetric matrix;voted perceptron algorithm","","13","","16","","","15-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Efficient classification scheme based on hybrid global and local properties of feature","H. Lee; Sungjun Hong; Sungje An; E. Kim","School of Electrical and Electronic Engineering, Yonsei University, Biometrics Engineering Research Center (BERC), Seoul, Korea","2008 International Conference on Control, Automation and Systems","20081202","2008","","","2126","2129","This paper proposes a new pattern classification scheme, combining global and local features. The proposed method uses principal component analysis (PCA) for global property and locality preserving projections (LPP) for local property of the pattern. PCA is known for preserving the most descriptive ones after projection while LPP is known for preserving the neighborhood structure of the data set. Our combing method integrates global and local descriptive information and finds a richer set of alternatives beyond PCA and LPP in a 2-D parametric space. In order to find the hybrid features adaptively and find optimal parameters, we employ the genetic algorithm (GA). Experiments are performed with UCI machine learning repository to show the performance of the proposed algorithm.","","CD-ROM:978-89-93215-01-4; POD:978-89-950038-9-3","10.1109/ICCAS.2008.4694447","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4694447","Classification;GA;LPP;PCA;UCI machine learning repository","Automatic control;Automation;Control systems;Genetic algorithms;Genetic mutations;Machine learning;Machine learning algorithms;Pattern classification;Principal component analysis;Robustness","learning (artificial intelligence);pattern classification;principal component analysis","descriptive information;genetic algorithm;locality preserving projections;machine learning;pattern classification scheme;principal component analysis","","0","","8","","","14-17 Oct. 2008","","IEEE","IEEE Conference Publications"
"Semisupervised Multitask Learning","Q. Liu; X. Liao; H. L. Carin; J. R. Stack; L. Carin","Duke University, Durham","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090417","2009","31","6","1074","1086","Context plays an important role when performing classification, and in this paper we examine context from two perspectives. First, the classification of items within a single task is placed within the context of distinct concurrent or previous classification tasks (multiple distinct data collections). This is referred to as multi-task learning (MTL), and is implemented here in a statistical manner, using a simplified form of the Dirichlet process. In addition, when performing many classification tasks one has simultaneous access to all unlabeled data that must be classified, and therefore there is an opportunity to place the classification of any one feature vector within the context of all unlabeled feature vectors; this is referred to as semi-supervised learning. In this paper we integrate MTL and semi-supervised learning into a single framework, thereby exploiting two forms of contextual information. Example results are presented on a ""toy"" example, to demonstrate the concept, and the algorithm is also applied to three real data sets.","0162-8828;01628828","","10.1109/TPAMI.2008.296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721436","Machine learning;Pattern Recognition","","learning (artificial intelligence);pattern classification;statistical analysis","Dirichlet process;classification task;contextual information;multiple distinct data collection;semisupervised multitask learning","Algorithms;Artificial Intelligence;Computer Simulation;Models, Theoretical;Pattern Recognition, Automated","19","","42","","20081222","June 2009","","IEEE","IEEE Journals & Magazines"
"Mining library specifications using inductive logic programming","S. Sankaranarayanan; F. Ivanci; A. Gupta","NEC Labs America, Princeton, NJ, USA","2008 ACM/IEEE 30th International Conference on Software Engineering","20090414","2008","","","131","140","Software libraries organize useful functionalities in order to promote modularity and code reuse. A typical library is used by client programs through an application programming interface (API) that hides its internals from the client. Typically, the rules governing the correct usage of the API are documented informally. In many cases, libraries may have complex API usage rules and unclear documentation. As a result, the behaviour of the library under some corner cases may not be well understood by the programmer. Formal specifications provide a precise understanding of the API behaviour. We propose a methodology for learning interface specifications using Inductive Logic Programming (ILP). Our technique runs several unit tests on the library in order to generate relations describing the operation of the library. The data collected from these tests are used by an inductive learner to obtain rich Datalog/Prolog specifications. Such specifications capture essential properties of interest to the user. They may be used for applications such as reverse engineering the library internals or constructing checks on the application code to enforce proper API usage along with other properties of interest.","0270-5257;02705257","Electronic:978-1-60558-079-1; POD:978-1-4244-4486-1","10.1145/1368088.1368107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814124","datalog;inductive logic programming;machine learning.;software specification;verification","Libraries;Logic programming","application program interfaces;data mining;formal specification;inductive logic programming;software libraries","Datalog-Prolog specification;application programming interface;formal specification;inductive logic programming;software library specification","","8","","23","","","10-18 May 2008","","IEEE","IEEE Conference Publications"
"Pedestrian detection via logistic multiple instance boosting","Junbiao Pang; Qingming Huang; Shuqiang Jiang; Wen Gao","Graduate School of Chinese Academy of Sciences, Beijing, 100190, China","2008 15th IEEE International Conference on Image Processing","20081212","2008","","","1464","1467","Pedestrian detection in still image should handle the large appearance and pose variations arising from the articulated structure and various clothing of human bodies as well as view points. So it is difficult to design effective classifier for this problem. In this paper, we address these variations in detection via multiple instance learning, specifically logistic multiple instance boosting (LMIB). In LMIB, a example is represented as a set of instances, which implicitly encode the variations. Giving different confidence to the instances in a bag, the LMIB will automatically reduce the influence of the variations at training stage. To obtain rapid detection speed, the LMIBs are grouped into the cascaded structure. The proposed detection algorithm is tested on MIT and NRIA human datasets where promising detection results are comparable with the baseline algorithms.","1522-4880;15224880","POD:978-1-4244-1765-0","10.1109/ICIP.2008.4712042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4712042","boosting;machine learning;multiple instance learning;object detection;pedestrian detection","Boosting;Clothing;Detectors;Face detection;Humans;Logistics;Machine learning;Object detection;Shape;Testing","image classification;learning (artificial intelligence);object detection;traffic engineering computing","cascaded structure;image classifier;logistic multiple instance boosting;multiple instance learning;object detection;pedestrian detection;pose variation;still image","","1","1","11","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"SOM Classification Method based on Transduction Scheme","B. Tong; Z. G. Qin; X. X. Ma; Y. Wang; W. F. Jia","School of Computer Science and Engineering, University of Electronic Science & Technology of China, Chengdu 610054, China. E-MAIL: bintong@uestc.edu.cn","2008 International Conference on Apperceiving Computing and Intelligence Analysis","20090202","2008","","","12","15","Transductive confidence machines (TCMs) when used in classification problems can provide us with reliability for every classification. Many machine learning algorithms, such as KNN algorithm, etc., have been incorporated with TCM, while there's no SOM classification method based on TCM. Considering properties of SOM map unit, this paper first designs a novel nonconformity measurement and TCM-SOM classification method; and then its classification accuracy that is much more better than that of SOM and is close or even higher than that of TCM-KNN is also proved by UCI machine learning datasets.","","POD:978-1-4244-3425-1","10.1109/ICACIA.2008.4769960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4769960","Machine learning;TCM-KNN;TCM-SOM;classification","Algorithm design and analysis;Computer science;Design methodology;Electronic mail;Error analysis;Machine learning;Machine learning algorithms;Reliability engineering;Support vector machine classification;Support vector machines","learning (artificial intelligence);pattern classification;self-organising feature maps","KNN algorithm;SOM classification method;UCI machine learning dataset;machine learning algorithm;transductive confidence machine","","1","","7","","","13-15 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Ontology Alignment Based on Parse Tree Kernel for Combining Structural and Semantic Information without Explicit Enumeration of Features","J. W. Son; S. B. Park; S. Y. Park","Dept. of Comput. Eng., Kyungpook Nat. Univ., Daegu","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","468","474","The ontology alignment has two kinds of major problems. First, the features used for ontology alignment are usually defined by experts, but it is highly possible for some critical features to be excluded from the feature set. Second, the semantic and the structural similarities are usually computed independently, and then they are combined in an ad-hoc way where the weights are determined heuristically. This paper proposes the modified parse tree kernel (MPTK) for ontology alignment. In order to compute the similarity between entities in the ontologies, a tree is adopted as a representation of an ontology. After transforming an ontology into a set of trees, their similarity is computed using MPTK without explicit enumeration of features. In computing the similarity between trees,the approximate string matching is adopted to naturally reflect not only the structural information but also the semantic information. According to a series of experiments with a standard data set, the kernel method outperforms other structural similarities such as GMO. In addition, the proposed method shows the state-of-the-art performance in the ontology alignment.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740494","Convolution kernel;Kernel method;Ontology Alignment;Parse tree kernel;machine learning","Intelligent agent;Kernel;Ontologies","grammars;ontologies (artificial intelligence);tree data structures;tree searching","modified parse tree kernel;ontology alignment;semantic information;standard data set;string matching;structural information;structural similarities","","0","","14","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Traffic analysis and classification with bio-inspired and classical algorithms in sensor networks","M. Becker; S. Bohlmann; S. Schaust","Institute of Systems Engineering G. W. Leibniz University of Hannover, Welfengarten 1, 30167, Germany","2008 International Symposium on Performance Evaluation of Computer and Telecommunication Systems","20090202","2008","","","67","73","In this work we evaluate the feasibility of both classical machine learning algorithms and bio-inspired algorithms for misbehavior detection in sensor networks, since recent works in that field seem to concentrate mainly on bio-inspired approaches, without a convincing rational reason. As a first step, we analyze the packet traffic of a simulated sensor network in order to find relevant features that distinguish normal network operation from misbehaving nodes. This kind of data analysis is often missing in previous studies. Using these features acquired by the systematic data analysis we study the suitability of classical machine learning algorithms as well as bio-inspired learning algorithms for the given classification problem. We conclude which algorithms perform best in this special scenario, considering classification success and resource-friendliness of the algorithms. As result we can say that classical algorithms have equal or even better detection capabilities compared to some bio-inspired algorithms. It turns out that it is even possible to detect different levels of misbehavior with nearly 100% accuracy.","","POD:978-1-56555-320-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4667545","Classification Algorithms;Machine Learning;Traffic Analysis;Wireless Sensor Networks","Algorithm design and analysis;Biosensors;Classification algorithms;Data analysis;Intrusion detection;Machine learning;Machine learning algorithms;Monitoring;Sensor systems;Telecommunication traffic","data analysis;learning (artificial intelligence);telecommunication computing;telecommunication traffic;wireless sensor networks","bio-inspired learning algorithms;classification problem;machine learning algorithms;misbehavior detection;packet traffic analysis;simulated sensor network;systematic data analysis","","1","","19","","","16-18 June 2008","","IEEE","IEEE Conference Publications"
"Unsupervised Activity Perception in Crowded and Complicated Scenes Using Hierarchical Bayesian Models","X. Wang; X. Ma; W. E. L. Grimson","MIT, Cambridge","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090123","2009","31","3","539","555","We propose a novel unsupervised learning framework to model activities and interactions in crowded and complicated scenes. Hierarchical Bayesian models are used to connect three elements in visual surveillance: low-level visual features, simple ""atomic"" activities, and interactions. Atomic activities are modeled as distributions over low-level visual features, and multi-agent interactions are modeled as distributions over atomic activities. These models are learnt in an unsupervised way. Given a long video sequence, moving pixels are clustered into different atomic activities and short video clips are clustered into different interactions. In this paper, we propose three hierarchical Bayesian models, Latent Dirichlet Allocation (LDA) mixture model, Hierarchical Dirichlet Process (HDP) mixture model, and Dual Hierarchical Dirichlet Processes (Dual-HDP) model. They advance existing language models, such as LDA [1] and HDP [2]. Our data sets are challenging video sequences from crowded traffic scenes and train station scenes with many kinds of activities co-occurring. Without tracking and human labeling effort, our framework completes many challenging visual surveillance tasks of board interest such as: (1) discovering typical atomic activities and interactions; (2) segmenting long video sequences into different interactions; (3) segmenting motions into different activities; (4) detecting abnormality; and (5) supporting high-level queries on activities and interactions.","0162-8828;01628828","","10.1109/TPAMI.2008.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731265","Algorithms;Applications;Artificial Intelligence;Clustering;Computer vision;Computing Methodologies;Machine learning;Motion;Pattern Recognition;Statistical;Video analysis;Vision and Scene Understanding","","Bayes methods;image segmentation;learning (artificial intelligence);video surveillance","complicated scenes;crowded traffic scenes;dual hierarchical Dirichlet processes model;hierarchical Bayesian models;hierarchical Dirichlet process mixture model;language models;latent dirichlet allocation mixture model;motion segmentation;multiagent interactions;train station scenes;unsupervised activity perception;unsupervised learning framework;video clips;video sequence;visual features;visual surveillance tasks","Algorithms;Artificial Intelligence;Bayes Theorem;Computer Simulation;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Biological;Models, Statistical;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique;Whole Body Imaging","110","1","43","","20081231","March 2009","","IEEE","IEEE Journals & Magazines"
"Online Prediction of Time Series Data With Kernels","C. Richard; J. C. M. Bermudez; P. Honeine","Inst. Charles Delaunay, Univ. de Technol. de Troyes, Troyes","IEEE Transactions on Signal Processing","20090213","2009","57","3","1058","1067","Kernel-based algorithms have been a topic of considerable interest in the machine learning community over the last ten years. Their attractiveness resides in their elegant treatment of nonlinear problems. They have been successfully applied to pattern recognition, regression and density estimation. A common characteristic of kernel-based methods is that they deal with kernel expansions whose number of terms equals the number of input data, making them unsuitable for online applications. Recently, several solutions have been proposed to circumvent this computational burden in time series prediction problems. Nevertheless, most of them require excessively elaborate and costly operations. In this paper, we investigate a new model reduction criterion that makes computationally demanding sparsification procedures unnecessary. The increase in the number of variables is controlled by the coherence parameter, a fundamental quantity that characterizes the behavior of dictionaries in sparse approximation problems. We incorporate the coherence criterion into a new kernel-based affine projection algorithm for time series prediction. We also derive the kernel-based normalized LMS algorithm as a particular case. Finally, experiments are conducted to compare our approach to existing methods.","1053-587X;1053587X","","10.1109/TSP.2008.2009895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685707","Adaptive filters;machine learning;nonlinear systems;pattern recognition","","adaptive filters;learning (artificial intelligence);mathematics computing;pattern recognition;prediction theory;regression analysis;time series","density estimation;dictionaries;kernel-based affine projection algorithm;kernel-based algorithms;machine learning;model reduction criterion;nonlinear problem;pattern recognition;sparse approximation problems;time series","","153","","43","","20081121","March 2009","","IEEE","IEEE Journals & Magazines"
"Application of Random Forest in Predicting Fault-Prone Classes","A. Kaur; R. Malhotra","Univ. Sch. of Inf. Technol., Guru Gobind Singh Indraprastha Univ., Delhi, India","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","37","43","There are available metrics for predicting fault prone classes, which may help software organizations for planning and performing testing activities. This may be possible due to proper allocation of resources on fault prone parts of the design and code of the software. Hence, importance and usefulness of such metrics is understandable, but empirical validation of these metrics is always a great challenge. Random forest (RF) algorithm has been successfully applied for solving regression and classification problems in many applications. This paper evaluates the capability of RF algorithm in predicting fault prone software classes using open source software. The results indicate that the prediction performance of random forest is good. However, similar types of studies are required to be carried out in order to establish the acceptability of the RF model.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736919","Random Forest;fault prediction;machine learning;software metrics;software quality","Application software;Bagging;Information technology;Machine learning algorithms;Open source software;Prediction algorithms;Radio frequency;Software algorithms;Software performance;Software quality","decision trees;public domain software;software fault tolerance;software metrics;software quality","fault prone software class;open source software;random forest algorithm","","2","","60","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Improving preciseness of time to failure predictions: Application to APU starter","S. Letourneau; C. Yang; Z. Liu","Knowledge Discovery Group of the Institute for Information Technology, National Research Council Canada, Ottawa, Ontario, K1A 0R6, USA","2008 International Conference on Prognostics and Health Management","20081212","2008","","","1","7","Despite the availability of huge amounts of data and a variety of powerful data analysis methods, prognostic models are still often failing to provide accurate and precise time to failure estimations. This paper addresses this problem by integrating several machine learning algorithms. The approach proposed relies on a classification system to determine the likelihood of component failures and to provide rough indications of remaining life. It then introduces clustering and SVM-based local regression to refine the time to failure estimations provided by the classification system. The paper illustrates the applicability of the proposed approach through a real world aerospace application and discusses data pre-processing requirements. The preliminary results show that the proposed method can reduce uncertainty in time to failure estimates, which in turn helps augment the usefulness of prognostics.","","CD-ROM:978-1-4244-1936-4; POD:978-1-4244-1935-7","10.1109/PHM.2008.4711453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711453","Classification;Equipment Health Management;Machine Learning;Regression","Availability;Costs;Data analysis;Machine learning algorithms;Power system modeling;Predictive models;Prognostics and health management;Regression analysis;Sensor phenomena and characterization;Uncertainty","aircraft;data analysis;learning (artificial intelligence);regression analysis;structural engineering computing;support vector machines","SVM-based local regression;classification system;data analysis methods;machine learning algorithm;prognostic models;support vector machines","","5","","11","","","6-9 Oct. 2008","","IEEE","IEEE Conference Publications"
"Discriminating Meaningful Web Tables from Decorative Tables Using a Composite Kernel","J. W. Son; J. A. Lee; S. B. Park; H. J. Song; S. J. Lee; S. Y. Park","Dept. of Comput. Eng., Kyungpook Nat. Univ., Daegu","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","368","371","Information extraction from world wide web has been paid great attention to. Since a table is a well-organized and summarized knowledge expression for a domain, it is of great importance to extract information from the tables. However, many tables in web pages are used not to transfer information but to decorate the pages. Therefore, it is one of the most critical tasks in web table mining to discriminate the meaningful tables from the decorative ones. The main obstacle of this task comes from the difficulty of generating relevant features for the discrimination. This paper proposes a novel method to discriminate them using a composite kernel which combines a parse tree kernel and a linear kernel. Since a web table is represented as a parse tree by a HTML parser, the parse tree kernel can be naturally used in determining the similarity between trees, and the linear kernel with content features is used to make up for the weak points of the parse tree kernel. The support vector machines with the composite kernel distinguish with high accuracy the meaningful tables from the decorative ones. A series of experiments show that the proposed method achieves the state-of-the-art performance.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740474","Composite Kernel;Machine Learning;Web Table Discrimination;Web data mining","Intelligent agent;Kernel","Internet;hypermedia markup languages;information retrieval;program compilers;trees (mathematics)","HTML parser;Web tables;World Wide Web;composite kernel;decorative tables;information extraction;parse tree","","3","","10","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Comparison of Feature Extraction Methods for the Classification of Dynamic Activities From Accelerometer Data","S. J. Preece*; J. Y. Goulermas; L. P. J. Kenney; D. Howard","Centre for Rehabilitation & Human Performance Res., Univ. of Salford, Salford","IEEE Transactions on Biomedical Engineering","20090421","2009","56","3","871","879","Driven by the demands on healthcare resulting from the shift toward more sedentary lifestyles, considerable effort has been devoted to the monitoring and classification of human activity. In previous studies, various classification schemes and feature extraction methods have been used to identify different activities from a range of different datasets. In this paper, we present a comparison of 14 methods to extract classification features from accelerometer signals. These are based on the wavelet transform and other well-known time- and frequency-domain signal characteristics. To allow an objective comparison between the different features, we used two datasets of activities collected from 20 subjects. The first set comprised three commonly used activities, namely, level walking, stair ascent, and stair descent, and the second a total of eight activities. Furthermore, we compared the classification accuracy for each feature set across different combinations of three different accelerometer placements. The classification analysis has been performed with robust subject-based cross-validation methods using a nearest-neighbor classifier. The findings show that, although the wavelet transform approach can be used to characterize nonstationary signals, it does not perform as accurately as frequency-based features when classifying dynamic activities performed by healthy subjects. Overall, the best feature sets achieved over 95% intersubject classification accuracy.","0018-9294;00189294","","10.1109/TBME.2008.2006190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663615","Activity classification;ambulatory monitoring;machine learning;wavelet transform","Accelerometers;Feature extraction;Frequency;Humans;Legged locomotion;Medical services;Monitoring;Performance analysis;Robustness;Wavelet transforms","feature extraction;gait analysis;medical signal processing;signal classification;wavelet transforms","accelerometer data;feature extraction methods;healthcare;human activity classification;level walking;nearest-neighbor classifier;stair ascent;stair descent;wavelet transform","Adult;Algorithms;Ankle;Female;Humans;Locomotion;Male;Models, Theoretical;Monitoring, Ambulatory;Movement;Reproducibility of Results;Signal Processing, Computer-Assisted;Thigh","136","1","44","","20081031","March 2009","","IEEE","IEEE Journals & Magazines"
"Model-driven Visual Analytics","S. Garg; J. E. Nam; I. V. Ramakrishnan; K. Mueller","Computer Science Department, Stony Brook University, USA","2008 IEEE Symposium on Visual Analytics Science and Technology","20081118","2008","","","19","26","We describe a visual analytics (VA) infrastructure, rooted on techniques in machine learning and logic-based deductive reasoning that will assist analysts to make sense of large, complex data sets by facilitating the generation and validation of models representing relationships in the data. We use logic programming (LP) as the underlying computing machinery to encode the relations as rules and facts and compute with them. A unique aspect of our approach is that the LP rules are automatically learned, using Inductive Logic Programming, from examples of data that the analyst deems interesting when viewing the data in the high-dimensional visualization interface. Using this system, analysts will be able to construct models of arbitrary relationships in the data, explore the data for scenarios that fit the model, refine the model if necessary, and query the model to automatically analyze incoming (future) data exhibiting the encoded relationships. In other words it will support both model-driven data exploration, as well as data-driven model evolution. More importantly, by basing the construction of models on techniques from machine learning and logic-based deduction, the VA process will be both flexible in terms of modeling arbitrary, user-driven relationships in the data as well as readily scale across different data domains.","","POD:978-1-4244-2935-6","10.1109/VAST.2008.4677352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4677352","Grand Tour;H.5.2 [Information Interfaces and Presentation]: User Interfaces—Graphical user interfaces;High-dimensional Data;I.2.6 [Artificial Intelligence]: Learning—Concept Learning;I.5.3 [Pattern Recognition]: Clustering—Similarity Measures;Knowledge Discovery;Machine Learning;Network Security;Visual Analytics;Visual Clustering","Data analysis;Data security;Data visualization;Humans;Information security;Logic programming;Machine learning;Machinery;Scattering;Visual analytics","data visualisation;inductive logic programming;inference mechanisms;learning (artificial intelligence);user interfaces","encoding;high-dimensional data visualization interface;inductive logic programming;logic-based deductive reasoning;machine learning;model-driven visual analytics","","11","","27","","","19-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Multilevel Training of Binary Morphological Operators","N. S. T. Hirata","University of S&#227;o Paulo, S&#227;o Paulo","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090220","2009","31","4","707","720","The design of binary morphological operators that are translation-invariant and locally defined by a finite neighborhood window corresponds to the problem of designing Boolean functions. As in any supervised classification problem, morphological operators designed from training sample also suffer from overfitting. Large neighborhood tends to lead to performance degradation of the designed operator. This work proposes a multi-level design approach to deal with the issue of designing large neighborhood based operators. The main idea is inspired from stacked generalization (a multi-level classifier design approach) and consists in, at each training level, combining the outcomes of the previous level operators. The final operator is a multi-level operator that ultimately depends on a larger neighborhood than of the individual operators that have been combined. Experimental results show that two-level operators obtained by combining operators designed on subwindows of a large window consistently outperforms the single-level operators designed on the full window. They also show that iterating two-level operators is an effective multi-level approach to obtain better results.","0162-8828;01628828","","10.1109/TPAMI.2008.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4522558","Classifier design and evaluation;Concept learning;Image Processing and Computer Vision;Machine learning;Morphological;Pattern Recognition;Simplification of expressions;Statistical","Biomedical image processing;Boolean functions;Degradation;Geoscience and remote sensing;Industrial relations;Industrial training;Machine learning;Pattern recognition;Probes;Signal processing","Boolean functions;image classification;iterative methods;learning (artificial intelligence);mathematical morphology;mathematical operators","Boolean function;binary morphological operator;finite neighborhood window;image processing;iterative two-level operator;machine learning;multilevel classifier design approach;multilevel training;stacked generalization;supervised classification problem;translation-invariant image operator","","11","","35","","20080516","April 2009","","IEEE","IEEE Journals & Magazines"
