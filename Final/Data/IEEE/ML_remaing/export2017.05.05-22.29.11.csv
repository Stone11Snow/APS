"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7807985,7805431,7804223,7804459,7804906,7804830,7805338,7803357,7803338,7803113,7799852,7798553,7801627,7798085,7798265,7800350,7801952,7800478,7801620,7801215,7798097,7778156,7798541,7725499,7795712,7796889,7795677,7762066,7796930,7796448,7796641,7795391,7797446,7796223,7796963,7797080,7797030,7797053,7796162,7797084,7797085,7779985,7795686,7792435,7793196,7792616,7547913,7792369,7792251,7789771,7789966,7785770,7786237,7785347,7790268,7785430,7786215,7790308,7789584,7790306,7789798,7785387,7789544,7789547,7789586,7790013,7784960,7789677,7785086,7789510,7789680,7755799,4462217,7784628,4462321,4462964,4461934,7783222,4461924,4463141,4462216,7782063,7783759,7784234,7783821,7783434,7784056,7764572,4463134,7783808,7783637,7783289,7783782,7501574,7778092,7778595,7777898,7777780,7779672,7780948",2017/05/05 22:29:11
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Induction of decision trees by looking to data sequentially and using error correction rule","N. Bathaeian; M. Mansoorizadeh","Computer engineering department, Bu-Ali Sina University, Hamedan, I.R. of Iran","2016 Eighth International Conference on Information and Knowledge Technology (IKT)","20161212","2016","","","252","257","Decision trees are common algorithms in machine learning. Traditionally, these algorithms make trees recursively and at each step, they inspect data to induce the part of the tree. However decision trees are famous for their instability and high variance in error. In this paper a solution which adds error correction rule to a traditional decision tree algorithm is examined. In fact an algorithm which we call it, ECD3 is introduced. Algorithm of ECD3 inspects data sequentially in an iterative manner and updates tree only when it finds an erroneous observation. This method was first proposed by Dr. Utgoff but not implemented. In this paper, the method is developed and several experiments are performed to evaluate the method. We found that in most cases, performance of ECD3 is comparable to its predecessors. However ECD3 has some benefits over them. First, sizes of its trees are significantly smaller. Second, on average, variance of error in ECD3 is lower. Furthermore, ECD3 automatically chooses part of data for induction of the tree and sets aside others. This capability can be exploited for prototype selection in various learning algorithms. To explain these observations, we use inductive bias and margin definitions in our theories. We introduce a new definition of margin in ordinary decision trees based on shape, size and splitting criteria in trees. We show that how ECD3 expands the margins and enhances precision over test data.","","Electronic:978-1-5090-4335-4; POD:978-1-5090-4336-1","10.1109/IKT.2016.7777780","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7777780","Decision tree;entropy;error correction rule;induction bias;injecting randomness;margin;sequential reading of data","Classification algorithms;Computers;Decision trees;Error correction;Machine learning algorithms;Training;Vegetation","data analysis;decision trees;error correction;learning (artificial intelligence)","ECD3 algorithm;decision tree induction;error correction rule;error variance;inductive bias;machine learning;margin definitions;sequential data inspection;tree shape;tree size;tree splitting criteria","","","","","","","7-8 Sept. 2016","","IEEE","IEEE Conference Publications"
"Data analytics in smart distribution networks: Applications and challenges","F. C. L. Trindade; L. F. Ochoa; W. Freitas","University of Campinas, Campinas, Brazil","2016 IEEE Innovative Smart Grid Technologies - Asia (ISGT-Asia)","20161226","2016","","","574","579","The large volumes of data that will be produced by ubiquitous sensors and meters in future smart distribution networks represent an opportunity for the use of data analytics to extract valuable knowledge and, thus, improve Distribution Network Operator (DNO) planning and operation tasks. Indeed, applications ranging from outage management to detection of non-technical losses to asset management can potentially benefit from data analytics. However, despite all the benefits, each application presents DNOs with diverse data requirements and the need to define an adequate approach. Consequently, it is critical to understand the different interactions among applications, monitoring infrastructure and approaches involved in the use of data analytics in distribution networks. To assist DNOs in the decision making process, this work presents some of the potential applications where data analytics are likely to improve distribution network performance and the corresponding challenges involved in its implementation.","","Electronic:978-1-5090-4303-3; POD:978-1-5090-5228-8; USB:978-1-5090-4302-6","10.1109/ISGT-Asia.2016.7796448","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796448","Data analytics;distribution networks;operation;planning","Classification algorithms;Clustering algorithms;Data analysis;Machine learning algorithms;Monitoring;Planning;Prediction algorithms","asset management;data analysis;power distribution economics;power distribution planning;power engineering computing","DNO operation task improvement;asset management;data analytics;decision making process;monitoring infrastructure;nontechnical loss detection;outage management;smart distribution network operator planning improvement;valuable knowledge extraction","","","","","","","Nov. 28 2016-Dec. 1 2016","","IEEE","IEEE Conference Publications"
"Video Super-Resolution via Convolution Neural Network","T. H. Wei; J. C. Chen","Dept. of Comput. Sci. & Inf. Eng., Nat. Kaohsiung Univ. of Appl. Sci., Kaohsiung, Taiwan","2016 3rd International Conference on Green Technology and Sustainable Development (GTSD)","20161226","2016","","","168","169","Nowadays, people might need super resolution to obtain high quality images. Super resolution algorithm enhances high frequency information (texture or edges) to improve the image quality. We can do more things with super resolution, such as road surveillance system. The image quality would be degraded by illumination, angle, distance, and other conditions, and it will result in failing to recognize license plate or human face. Interpolation is a traditional method for super resolution, but this method does not ignore high frequency information. Therefore, example-based super-resolution methods were proposed. Besides, deep learning has great performance in many applications. However, for super-resolution, the computational complexity via deep learning algorithm is high and it needs some time to generate a high-resolution image. The time might be acceptable for single image. But what if we have to enhance video, it will take a lot of time to rebuild. Therefore, our research aims to solve this problem. We present a faster super resolution for video based on deep learning. We find the different patches between frame and frame. Add these patches into neural net and rebuild high resolution image to lower the total compute time.","","Electronic:978-1-5090-3638-7; POD:978-1-5090-3639-4","10.1109/GTSD.2016.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796641","Deep learning;Super resolution","Computer vision;Conferences;Image reconstruction;Image resolution;Interpolation;Machine learning;Neurons","image resolution;learning (artificial intelligence);neural nets;video signal processing","computational complexity;convolution neural network;deep learning algorithm;example-based super-resolution methods;high frequency information;image quality;super resolution algorithm;video super-resolution","","","","","","","24-25 Nov. 2016","","IEEE","IEEE Conference Publications"
"Fast Cover Song Retrieval in Advanced Audio Coding Domain Based on Deep Learning Technique","J. T. Fang; Y. R. Chang; P. C. Chang","Ming Chuan Univ., Taoyuan, Taiwan","2016 Data Compression Conference (DCC)","20161219","2016","","","591","591","We proposed a novel deep neural network based cover song retrieval method in AAC domain to reduce the computation complexity. The modified discrete cosine transform coefficients from the AAC were extracted and mapped into the 12-dimensional chroma features. Chroma features were further segmented to preserve the melody of music. Each segment of chroma features was trained and learned to reduce its dimension by using an autoencoder, used for deep learning of artificial neural networks. Experiments were conducted on cover80 database, which was provided by Ellis [3]. The results showed that the mean reciprocal rank increased to 0.46. The performance of the proposed method was compared with other systems, including LabROSA'06 (Tempos 120 and 60), and the method of principal component analysis (PCA) from the cover80. Fig. 1 plots the performances of MRR and similarity matching time. The proposed method improved the MRR performance and reduced approximately 80% of the matching time compared with LabROSA'06 (Tempo 120) [1].","","Electronic:978-1-5090-1853-6; POD:978-1-5090-1854-3","10.1109/DCC.2016.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7786215","","Audio coding;Data compression;Feature extraction;Machine learning;Neural networks;Principal component analysis;Urban areas","audio coding;computational complexity;discrete cosine transforms;learning (artificial intelligence);music;neural nets;principal component analysis","12-dimensional chroma features;AAC domain;MRR;PCA;advanced audio coding domain;artificial neural networks;autoencoder;computational complexity;deep learning technique;deep neural network;fast cover song retrieval method;mean reciprocal rank;modified discrete cosine transform coefficients;music melody;principal component analysis;similarity matching time","","","","","","","March 30 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Integrated remote controller distinguishing home appliances by deep learning","T. Hase; T. Sakao","Ryukoku University, Shiga, Otsu, Japan","2016 IEEE 5th Global Conference on Consumer Electronics","20161229","2016","","","1","3","This paper describes a method for distinguishing various home appliances with separate remote controllers and integrating control with a single remote controller. We propose that images of home appliances can be obtained with a camera, after which the appliances can be distinguished from each other by a convolutional neural network. We developed an experimental system to evaluate our proposed method and demonstrated that the system could distinguish different home appliances with a high accuracy of 99%.","","Electronic:978-1-5090-2333-2; POD:978-1-5090-2334-9","10.1109/GCCE.2016.7800350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7800350","Convolutional Neural Network;Deep Leaning;Home Electronics;User Interface","Cameras;Convolution;Home appliances;Liquid crystal displays;Machine learning;Neural networks;Process control","domestic appliances;feedforward neural nets;home automation;image capture;learning (artificial intelligence)","convolutional neural network;deep learning;home appliances;image capture;integrated remote controller","","","","","","","11-14 Oct. 2016","","IEEE","IEEE Conference Publications"
"Data Compression with Linear Discriminant Analysis","Y. Pei","Comput. Sci. Div., Univ. of Aizu, Aizuwakamatsu, Japan","2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)","20161229","2016","","","136","141","The transform coding is one of data compression techniques that is established in the meaning of certain statistics of data. The conventional principal component analysis method yields the mean square error as the statistic, and it relates to the coding presentation without considering the inner relation of the data statistics. In this paper, we propose to use linear discriminant analysis for data compression to solve this problem. After solving the eigenvalue resolution by establishing between-class scatter matrix and within-class scatter matrix, we compress the data with the eigenvectors obtained by the statistical meaning of linear discriminant analysis, which considers the inner relation of the data. We use two methods for clustering the data into several groups in linear discriminant analysis. One separates them with equal data quantity by their physical storage, the other uses k-means clustering algorithm to decide the elements in each group. We apply our proposal in an image compression application to evaluate and investigate the performance of the proposal. The standard test image, Lenna, and several evaluation metrics, such as mean square error, peak signal-to-noise ratio, compression ratio, structural similarity, and information entropy are introduced in the evaluation. We found that the information entropy obtained with the same number of principal components by our proposal is less than that obtained by the principal component analysis method. It may be useful for machine learning algorithm or computer to recognize or restore the same information with less information uncertainty. We analyse the results arising from the evaluation, and some open topics, remaining works and future opportunities are discussed.","","Electronic:978-1-5090-2678-4; POD:978-1-5090-2679-1","10.1109/SCIS-ISIS.2016.0040","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801627","data compression;linear discriminant analysis;principal component analysis;statistics;transform coding","Clustering algorithms;Image coding;Linear discriminant analysis;Machine learning algorithms;Principal component analysis;Transform coding","data compression;eigenvalues and eigenfunctions;entropy;image coding;learning (artificial intelligence);matrix algebra;pattern clustering;principal component analysis","between-class scatter matrix;compression ratio;data clustering;data compression technique;data quantity;eigenvalue resolution;eigenvectors;evaluation metrics;image compression application;information entropy;information uncertainty;k-means clustering algorithm;linear discriminant analysis;machine learning algorithm;mean square error;peak signal-to-noise ratio;physical storage;standard test image;structural similarity;within-class scatter matrix","","","","","","","25-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Short-term prediction of wind power based on deep Long Short-Term Memory","Qu Xiaoyun; Kang Xiaoning; Zhang Chao; Jiang Shuai; Ma Xiuda","Shaanxi Key Laboratory of Smart Grid, Xi'an Jiaotong University, 710049, China","2016 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)","20161212","2016","","","1148","1152","This paper proposes a wind power prediction model based on the Long Short-Term Memory model, one of the deep learning method. Deep learning conforms to the trend of big data and has powerful capability of learning and generalization for mass data. Principal component analysis (PCA) is used to choose input samples and reduce the dimensions of the input variables of the LSTM prediction model based on numerical weather prediction(NWP) data. Simulation results show that, compared with BP neural network and support vector machine(SVM) model, the LSTM prediction model has higher prediction accuracy and greater potential for engineering applications. It is effective to apply the Long Short-Term Memory model to the field of wind power prediction.","","Electronic:978-1-5090-5418-3; POD:978-1-5090-5419-0","10.1109/APPEEC.2016.7779672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779672","Long Short-Term Memory;deep learning;numerical weather prediction;principal component analysis;wind power prediction","Data models;Machine learning;Neurons;Predictive models;Principal component analysis;Training;Wind power generation","learning (artificial intelligence);load forecasting;numerical analysis;power engineering computing;principal component analysis;wind power plants","BP neural network;LSTM prediction model;NWP;PCA;SVM model;deep learning method;deep long short-term memory model;mass data generalization;numerical weather prediction;principal component analysis;short-term wind power prediction;support vector machine model;wind power prediction model","","","","","","","25-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Robot gains social intelligence through multimodal deep reinforcement learning","A. H. Qureshi; Y. Nakamura; Y. Yoshikawa; H. Ishiguro","Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan","2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)","20170102","2016","","","745","751","For robots to coexist with humans in a social world like ours, it is crucial that they possess human-like social interaction skills. Programming a robot to possess such skills is a challenging task. In this paper, we propose a Multimodal Deep Q-Network (MDQN) to enable a robot to learn human-like interaction skills through a trial and error method. This paper aims to develop a robot that gathers data during its interaction with a human, and learns human interaction behavior from the high dimensional sensory information using end-to-end reinforcement learning. This paper demonstrates that the robot was able to learn basic interaction skills successfully, after 14 days of interacting with people.","","Electronic:978-1-5090-4718-5; POD:978-1-5090-4719-2; USB:978-1-5090-4717-8","10.1109/HUMANOIDS.2016.7803357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803357","","Human-robot interaction;Learning (artificial intelligence);Legged locomotion;Machine learning;Robot sensing systems;Training","human-robot interaction;learning (artificial intelligence);robot programming","MDQN;end-to-end reinforcement learning;human interaction behavior;human-like social interaction skills;multimodal deep q-network;multimodal deep reinforcement learning;robot programming;social intelligence;trial and error method","","","","","","","15-17 Nov. 2016","","IEEE","IEEE Conference Publications"
"A decision model of identifying user travel pattern based on the intelligent terminal sensor data","S. Wang; J. Xiu; C. Liu; Z. Yang","Beijing University of Posts and Telecommunications, Beijing 100876, China","2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS)","20161219","2016","","","490","493","The identification of user travel pattern has important research value for intelligent transportation. Intelligent terminal can supply GPS, acceleration sensors, pressure sensors data which can provide data base for the identification of user travel patterns. This paper research on a user travel pattern decision model based on the sensor data. The decision algorithm adopts decision tree algorithm based on ID3. Experiments data shows that this decision model is effective in identifying the pattern of user's travel.","","CD:978-1-5090-1254-1; Electronic:978-1-5090-1256-5; POD:978-1-5090-1257-2","10.1109/CCIS.2016.7790308","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7790308","Decision tree;ID3 algorithm;Sensor Data;Travel pattern identifying;User travel Pattern","Acceleration;Classification algorithms;Data models;Decision trees;Global Positioning System;Machine learning algorithms;Training","decision making;decision trees;intelligent transportation systems;pattern recognition;sensor fusion","GPS data;ID3 algorithm;acceleration sensor data;acceleration sensors;decision tree;intelligent terminal sensor data;intelligent transportation;pressure sensor data;user travel pattern decision model;user travel pattern identification","","","","","","","17-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Designing a Better Data Representation for Deep Neural Networks and Text Classification","J. D. Prusa; T. M. Khoshgoftaar","Dept. of Comput. & Electr. Eng. & Comput. Sci., Florida Atlantic Univ., Boca Raton, FL, USA","2016 IEEE 17th International Conference on Information Reuse and Integration (IRI)","20161219","2016","","","411","416","Traditional machine learning requires data to be described by attributes prior to applying a learning algorithm. In text classification tasks, many feature engineering methodologies have been proposed to extract meaningful features, however, no best practice approach has emerged. Traditional methods of feature engineering have inherent limitations due to loss of information and the limits of human design. An alternative is to use deep learning to automatically learn features from raw text data. One promising deep learning approach is to use convolutional neural networks. These networks can learn abstract text concepts from character representations and be trained to perform discriminate tasks, such as classification. In this paper, we propose a new approach to encoding text for use with convolutional neural networks that greatly reduces memory requirements and training time for learning from character-level text representations. Additionally, this approach scales well with alphabet size allowing us to preserve more information from the original text, potentially enhancing classification performance. By training tweet sentiment classifiers, we demonstrate that our approach uses less computational resources, allows faster training for networks and achieves similar, or better performance compared to the previous method of character encoding.","","Electronic:978-1-5090-3207-5; POD:978-1-5090-3208-2","10.1109/IRI.2016.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785770","Convolutional Neural Networks;Deep Learning;Text Classification;Tweet Sentiment","Biological neural networks;Encoding;Feature extraction;Machine learning;Semantics;Training","convolution;data structures;learning (artificial intelligence);neural nets;text analysis","abstract text concepts;alphabet size;character encoding;character-level text representations;computational resources;convolutional neural networks;data representation design;deep learning approach;deep neural networks;feature engineering methodologies;machine learning;text classification tasks;tweet sentiment classifiers","","","","","","","28-30 July 2016","","IEEE","IEEE Conference Publications"
"Deep learning application trial to lung cancer diagnosis for medical sensor systems","R. Shimizu; S. Yanagawa; Y. Monde; H. Yamagishi; M. Hamada; T. Shimizu; T. Kuroda","Faculty of Science and Technology, Keio University, Yokohama, Japan","2016 International SoC Design Conference (ISOCC)","20161229","2016","","","191","192","Personal and easy-to-use health checking system is an attractive application of sensor systems. Sensing data analysis for diagnosis is important as well as preparing small and mobile sensor nodes because sensing data include variations and noises reflecting individual difference of people and sensing conditions. Deep Neural Network, or Deep Learning, is a well-known method of machine learning and it is effective for feature extraction from pictures. Then, we thought Deep Learning also can extract features from sensing data. In this paper, we tried to build a diagnosis system of lung cancer based on Deep Learning. Input data of the system was generated from human urine by Gas Chromatography Mass Spectrometer (GC-MS) and our system achieved 90% accuracy in judging whether the patient had lung cancer or not. This system will be useful for pre- and personal diagnosis because collecting urine is very easy and not harmful to human body. We are targeting installation of this system not only to gas chromatography systems but also to some combination of multiple sensors for detecting gases of low concentration.","","Electronic:978-1-5090-3219-8; POD:978-1-5090-3220-4; USB:978-1-5090-3218-1","10.1109/ISOCC.2016.7799852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7799852","Deep Learning;Deep Neural Network;Gas Chromatography Mass Spectrometer(GC-MS);Stacked Autoencoder","Cancer;Feature extraction;Lungs;Machine learning;Medical diagnostic imaging;Neural networks;Sensors","biosensors;cancer;chromatography;learning (artificial intelligence);lung;mass spectrometers;neural nets;patient diagnosis","deep learning application;deep neural network;easy-to-use health checking system;feature extraction;gas chromatography mass spectrometer;gas detection;human urine;lung cancer diagnosis;machine learning;medical sensor systems;mobile sensor nodes;personal diagnosis;personal health checking system;pre-diagnosis;sensing data analysis","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep learning for network analysis: Problems, approaches and challenges","S. Pal; Y. Dong; B. Thapa; N. V. Chawla; A. Swami; R. Ramanathan","Raytheon BBN Technologies, United States","MILCOM 2016 - 2016 IEEE Military Communications Conference","20161226","2016","","","588","593","The analysis of social, communication and information networks for identifying patterns, evolutionary characteristics and anomalies is a key problem for the military, for instance in the Intelligence community. Current techniques do not have the ability to discern unusual features or patterns that are not a priori known. We investigate the use of deep learning for network analysis. Over the last few years, deep learning has had unprecedented success in areas such as image classification, speech recognition, etc. However, research on the use of deep learning to network or graph analysis is limited. We present three preliminary techniques that we have developed as part of the ARL Network Science CTA program: (a) unsupervised classification using a very highly trained image recognizer, namely Caffe; (b) supervised classification using a variant of convolutional neural networks on node features such as degree and assortativity; and (c) a framework called node2vec for learning representations of nodes in a network using a mapping to natural language processing.","","Electronic:978-1-5090-3781-0; POD:978-1-5090-3782-7","10.1109/MILCOM.2016.7795391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795391","","Biological neural networks;Convolution;Erbium;Feature extraction;Machine learning;Measurement","data mining;graph theory;learning (artificial intelligence);military computing;network theory (graphs);neural nets;pattern classification","convolutional neural network;data mining;deep learning;image recognizer;intelligence community;military system;network analysis;node2vec framework;unsupervised classification","","","","","","","1-3 Nov. 2016","","IEEE","IEEE Conference Publications"
"Graphicionado: A high-performance and energy-efficient accelerator for graph analytics","T. J. Ham; L. Wu; N. Sundaram; N. Satish; M. Martonosi","Princeton University","2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)","20161215","2016","","","1","13","Graphs are one of the key data structures for many real-world computing applications and the importance of graph analytics is ever-growing. While existing software graph processing frameworks improve programmability of graph analytics, underlying general purpose processors still limit the performance and energy efficiency of graph analytics. We architect a domain-specific accelerator, Graphicionado, for high-performance, energy-efficient processing of graph analytics workloads. For efficient graph analytics processing, Graphicionado exploits not only data structure-centric datapath specialization, but also memory subsystem specialization, all the while taking advantage of the parallelism inherent in this domain. Graphicionado augments the vertex programming paradigm, allowing different graph analytics applications to be mapped to the same accelerator framework, while maintaining flexibility through a small set of reconfigurable blocks. This paper describes Graphicionado pipeline design choices in detail and gives insights on how Graphicionado combats application execution inefficiencies on general-purpose CPUs. Our results show that Graphicionado achieves a 1.76-6.54x speedup while consuming 50-100x less energy compared to a state-of-the-art software graph analytics processing framework executing 32 threads on a 16-core Haswell Xeon processor.","","Electronic:978-1-5090-3508-3; POD:978-1-5090-3509-0","10.1109/MICRO.2016.7783759","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783759","","Machine learning algorithms;Memory management;Pipelines;Programming;Software;Software algorithms;System-on-chip","data structures;energy conservation;graph theory;parallel processing;power aware computing","16-core Haswell Xeon processor;Graphicionado;data structure-centric datapath specialization;domain-specific accelerator;general purpose processors;general-purpose CPU;graph graph processing;high-performance energy-efficient accelerator;memory subsystem specialization;software graph analytics;vertex programming","","","","","","","15-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep Video Hashing","V. E. Liong; J. Lu; Y. P. Tan; J. Zhou","","IEEE Transactions on Multimedia","","2016","PP","99","1","1","In this work, we propose a new deep video hashing (DVH) method for scalable video search. Unlike most existing video hashing methods which first extract features for each single frame and then use conventional image hashing techniques, our DVH learns binary codes for the entire video with a deep learning framework so that both temporal and discriminative information can be well exploited. Specifically, we fuse the temporal information across different frames within each video to learn the feature representation under two criteria: 1) the distance between a feature pair obtained at the top layer is small if they are in the same class, and large if they are from different classes, and 2) the quantization loss between the real-valued features and the binary codes is minimized. We exploit different deep architectures to utilize spatial-temporal information in different manners and compare them with single frame based deep feature models and state-of-the-art image hashing algorithms. Experimental results on two video databases demonstrate the effectiveness of our proposed method.","1520-9210;15209210","","10.1109/TMM.2016.2645404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797446","Scalable video search;deep learning;video hashing","Binary codes;Computer architecture;Convolutional codes;Feature extraction;Machine learning;Quantization (signal);Visualization","","","","","","","","20161226","","","IEEE","IEEE Early Access Articles"
"Deep Coupled Metric Learning for Cross-Modal Matching","V. E. Liong; J. Lu; Y. P. Tan; J. Zhou","","IEEE Transactions on Multimedia","","2016","PP","99","1","1","In this paper, we propose a new deep coupled metric learning (DCML) method for cross-modal matching, which aims to match samples captured from two different modalities (e.g. texts vs. images, visible vs. near infrared images). Unlike existing cross-modal matching methods which learn a linear common space to reduce the modality gap, our DCML designs two feedforward neural networks which learn two sets of hierarchical nonlinear transformations (one set for each modality) to nonlinearly map samples from different modalities into a shared latent feature subspace, under which the intra-class variation is minimized and the inter-class variation is maximized, and the difference of each data pair captured from two modalities of the same class is minimized, respectively. Experimental results on four different cross-modal matching datasets validate the efficacy of the proposed approach.","1520-9210;15209210","","10.1109/TMM.2016.2646180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801952","Cross-modal matching;coupled learning;deep model;metric learning;multimedia retrieval","Correlation;Kernel;Learning systems;Machine learning;Measurement;Neural networks;Semantics","","","","","","","","20161229","","","IEEE","IEEE Early Access Articles"
"Apparent Age Estimation Using Ensemble of Deep Learning Models","R. C. Malli; M. Aygün; H. K. Ekenel","Istanbul Tech. Univ., Istanbul, Turkey","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","714","721","In this paper, we address the problem of apparent age estimation. Different from estimating the real age of individuals, in which each face image has a single age label, in this problem, face images have multiple age labels, corresponding to the ages perceived by the annotators, when they look at these images. This provides an intriguing computer vision problem, since in generic image or object classification tasks, it is typical to have a single ground truth label per class. To account for multiple labels per image, instead of using average age of the annotated face image as the class label, we have grouped the face images that are within a specified age range. Using these age groups and their age-shifted groupings, we have trained an ensemble of deep learning models. Before feeding an input face image to a deep learning model, five facial landmark points are detected and used for 2-D alignment. We have employed and fine tuned convolutional neural networks (CNNs) that are based on VGG-16 [24] architecture and pretrained on the IMDB-WIKI dataset [22]. The outputs of these deep learning models are then combined to produce the final estimation. Proposed method achieves 0.3668 error in the final ChaLearn LAP 2016 challenge test set [5].","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789584","","Estimation;Face;Face detection;Feature extraction;Machine learning;Standards;Training","age issues;computer vision;face recognition;feedforward neural nets;image classification;learning (artificial intelligence)","2D alignment;ChaLearn LAP 2016 challenge test set;IMDB-WIKI dataset;VGG-16 architecture;age-shifted groupings;apparent age estimation;computer vision;deep learning models;ensemble learning;face image;facial landmark points;fine tuned CNN;fine tuned convolutional neural networks;image classification;object classification","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Transformable semantic map based navigation using autonomous deep learning object segmentation","Y. Furuta; K. Wada; M. Murooka; S. Nozawa; Y. Kakiuchi; K. Okada; M. Inaba","Graduate School of Information Science and Technology, The University of Tokyo 7-3-1, Hongo, Bunkyo-city, Tokyo, 113-8656, Japan","2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)","20170102","2016","","","614","620","For daily assistive robots working in home environment, it is important to use geometry-free representation for navigation which can deal with dynamic environmental changes. In this paper we propose semantic map based navigation which consists of 1) generating deep learning enabled semantic map from annotated world and 2) object based navigation using learned semantic map representation. One point of our proposed framework is to let robots autonomously generate a dataset for deep learning method and transfer existing geometric map based task execution system to semantic map based one which is invariant to changes of object location. Since deep learning for object segmentation technique enables end-to-end learning of object features, it is not necessary to design segmentation and labeling methods for each objects manually. We confirmed the effectiveness of our approach by performing task in dynamic environment and adaptability for two type of robots with experiments.","","Electronic:978-1-5090-4718-5; POD:978-1-5090-4719-2; USB:978-1-5090-4717-8","10.1109/HUMANOIDS.2016.7803338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803338","","Image segmentation;Machine learning;Navigation;Object segmentation;Robot sensing systems","assisted living;image representation;image segmentation;learning (artificial intelligence);service robots","assistive robots;autonomous deep learning object segmentation;dynamic environmental changes;geometric map based task execution;geometry-free representation;home environment;learned semantic map representation;object based navigation;object location;semantic map based navigation;transformable semantic map based navigation","","","","","","","15-17 Nov. 2016","","IEEE","IEEE Conference Publications"
"A discriminative null space based deep learning approach for person re-identification","S. Li; X. Liu; W. Liu; H. Ma; H. Zhang","Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing 100876, China","2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS)","20161219","2016","","","480","484","Person re-identification across multiple camera views is a rather challenging task due to various view points, illuminations, backgrounds and poses. How to extract discriminative features is the most critical way to overcome these challenges. In this paper, we design a discriminative null space based deep learning approach for person re-identification. Firstly, a Siamese Convolutional Neural Network (SCNN) is designed to automatically learn effective semantic features for person re-identification in different camera views. Furthermore, to obtain better recognition performance, we adopt the Null Foley-Sammon Transform (NFST) metric learning approach to combine the low-level, mid-level features and high-level features learned by the SCNN in a new discriminative null space. In this null space, images of the same person are collapsed into a single point thus minimizing the within-class scatter to the extreme and maximizing the relative between-class separation simultaneously. Finally, the comprehensive evaluations demonstrate that our approach outperforms all state-of-the-art methods on the Market-1501, which is the world's largest person re-identification benchmark dataset.","","CD:978-1-5090-1254-1; Electronic:978-1-5090-1256-5; POD:978-1-5090-1257-2","10.1109/CCIS.2016.7790306","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7790306","Metric learning;Null foley-sammon transform;Null space;Person re-identification;SCNN","Cameras;Decision support systems;Feature extraction;Machine learning;Measurement;Null space;Semantics","cameras;feature extraction;feedforward neural nets;learning (artificial intelligence);pose estimation;transforms","Market-1501;NFST metric learning;Null Foley-Sammon transform metric learning;SCNN;Siamese convolutional neural network;automatic semantic feature learning;between-class separation;camera views;discriminative feature extraction;discriminative null space based deep learning;high-level features;low-level features;mid-level features;person reidentification","","","","","","","17-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Performance Evaluation of an Accessory Category Recognition System Using Deep Neural Network","Y. Sakai; T. Oda; M. Ikeda; L. Barolli","Grad. Sch. of Eng., Fukuoka Inst. of Technol., Fukuoka, Japan","2016 19th International Conference on Network-Based Information Systems (NBiS)","20161219","2016","","","437","441","Deep Learning also called Deep Neural Network (DNN) has a deep hierarchy that connect multiple internal layers for feature detection and recognition learning. DNNs are emerging fast and will continue to grow together with feature detection methods. In previous work, we applied deep learning for vegetable object recognition and explored the Convolutional Neural Network (CNN). In this paper, we propose an enhanced accessory category recognition system which is based on CNN. From the evaluation results, we found that for recognition learning process by CNN, seventy thousand iterations were suitable. The results of learning rate was 99.77% and recognition rate was 99.75%, respectively. We observed that our system can be applied also for accessory category recognition.","","Electronic:978-1-5090-0979-4; POD:978-1-5090-0980-0","10.1109/NBiS.2016.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789798","DNN;Deep Neural Network;Object Category Recognition","Biological neural networks;Feature extraction;Image color analysis;Machine learning;Mice;Object detection","feature extraction;feedforward neural nets;learning (artificial intelligence);object recognition;performance evaluation","CNN;DNN;accessory category recognition system;convolutional neural network;deep learning;deep neural network;feature detection;feature recognition learning;performance evaluation","","","","","","","7-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Wearable preimpact fall detector using SVM","T. Zhen; L. Mao; J. Wang; Q. Gao","School of Mechanical and Electrical Engineering, Soochow University, Suzhou; 215021; China","2016 10th International Conference on Sensing Technology (ICST)","20161226","2016","","","1","6","In order to distinguish falls from normal activities exactly, a fall early warning wearable detector combining angle with acceleration features was proposed in this paper. The detector consists of MEMS inertial sensor and smartphone. The application to solve classification algorithm using Support Vector Machine is developed. Experimental trials which young adults participated in involved 250 falls (4 types, forward, backward, left and right) and 250 normal activities (10 types, bowing, jogging, ascending stairs, etc.). The results of experiment showed the detector provided a sensitivity of 99%, a specificity of 96.5% and the average lead-time is 268 ms. The approached detector's feasibility and efficiency in detecting falls from daily events were verified.","","Electronic:978-1-5090-0796-7; POD:978-1-5090-0797-4","10.1109/ICSensT.2016.7796223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796223","SVM;acceleration;angle;fall prevention;smartphone","Acceleration;Accelerometers;Biomedical monitoring;Detectors;Machine learning algorithms;Support vector machines","alarm systems;computerised instrumentation;microsensors;smart phones;support vector machines","MEMS inertial sensor;SVM;classification algorithm;fall early warning wearable preimpact detector;smartphone;support vector machine;time 268 ms","","","","","","","11-13 Nov. 2016","","IEEE","IEEE Conference Publications"
"Classification of Exacerbation Frequency in the COPDGene Cohort Using Deep Learning with Deep Belief Networks","J. Ying; J. Dutta; N. Guo; C. Hu; D. Zhou; A. Sitek; Q. Li","","IEEE Journal of Biomedical and Health Informatics","","2016","PP","99","1","1","This study aims to develop an automatic classifier based on deep learning for exacerbation frequency in patients with chronic obstructive pulmonary disease (COPD). A threelayer deep belief network (DBN) with two hidden layers and one visible layer was employed to develop classification models and the models’ robustness to exacerbation was analyzed. Subjects from the COPDGene cohort were labeled with exacerbation frequency, defined as the number of exacerbation events per year. 10,300 subjects with 361 features each were included in the analysis. After feature selection and parameter optimization, the proposed classification method achieved an accuracy of 91.99%, using a 10-fold cross validation experiment. The analysis of DBN weights showed that there was a good visual spatial relationship between the underlying critical features of different layers. Our findings show that the most sensitive features obtained from the DBN weights are consistent with the consensus showed by clinical rules and standards for COPD diagnostics. We thus demonstrate that DBN is a competitive tool for exacerbation risk assessment for patients suffering from COPD.","2168-2194;21682194","","10.1109/JBHI.2016.2642944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792616","Chronic obstructive pulmonary disease (COPD);Fisher score;deep belief network (DBN);deep learning;exacerbation","Diseases;Electronic mail;Feature extraction;Gold;Hospitals;Lungs;Machine learning","","","","","","","","20161221","","","IEEE","IEEE Early Access Articles"
"Intelligent Arrhythmia Detection and Classification Using ICA","A. Azemi; V. R. Sabzevari; M. Khademi; H. Gholizade; A. Kiani; Z. S. Dastgheib","Senior Member IEEE, Engineering Department, Penn State University, Delaware County Campus, Media, PA 19063. phone: 610-892-1421; fax: 610-892-1490; e-mail: azemi@psu.edu","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","2163","2166","In this paper a novel approach for cardiac arrhythmias detection is proposed. The proposed method is based on using independent component analysis (ICA) and wavelet transform to extract important features. Using the extracted features different machine learning classification schemas, MLP and RBF neural networks and K-nearest neighbor, are used to classify 274 instance signals from the MIT-BIH database. Simulations show that multilayer neural networks with Levenberg-Marquardt (LM) back propagation algorithm provide the optimal learning system. We were able to obtain 98.5% accuracy, which is an improvement in comparison with the similar works","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.259292","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4462217","","Feature extraction;Independent component analysis;Learning systems;Machine learning;Machine learning algorithms;Multi-layer neural network;Neural networks;Spatial databases;Wavelet analysis;Wavelet transforms","backpropagation;electrocardiography;feature extraction;independent component analysis;medical signal detection;medical signal processing;multilayer perceptrons;muscle;radial basis function networks;signal classification;wavelet transforms","ECG;ICA;K-nearest neighbor classification scheme;Levenberg-Marquardt back propagation algorithm;MIT-BIH database;MLP;RBF neural networks;cardiac arrhythmia classification;feature extraction;independent component analysis;intelligent arrhythmia detection;machine learning classification scheme;multilayer neural networks;optimal learning system;wavelet transform","Algorithms;Arrhythmias, Cardiac;Artificial Intelligence;Diagnosis, Computer-Assisted;Electrocardiography;Heart Rate;Humans;Pattern Recognition, Automated;Principal Component Analysis;Reproducibility of Results;Sensitivity and Specificity","4","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"Min Norm Point Algorithm for Higher Order MRF-MAP Inference","I. Shanu; C. Arora; P. Singla","IIIT Delhi, Delhi, India","2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20161212","2016","","","5365","5374","Many tasks in computer vision and machine learning can be modelled as the inference problems in an MRF-MAP formulation and can be reduced to minimizing a submodular function. Using higher order clique potentials to model complex dependencies between pixels improves the performance but the current state of the art inference algorithms fail to scale for larger clique sizes. We adapt a well known Min Norm Point algorithm from mathematical optimization literature to exploit the sum of submodular structure found in the MRF-MAP formulation. Unlike some contemporary methods, we do not make any assumptions (other than submodularity) on the type of the clique potentials. Current state of the art inference algorithms for general submodular function takes many hours for problems with clique size 16, and fail to scale beyond. On the other hand, our algorithm is highly efficient and can perform optimal inference in few seconds even on clique size an order of magnitude larger. The proposed algorithm can even scale to clique sizes of many hundreds, unlocking the usage of really large size cliques for MRF-MAP inference problems in computer vision. We demonstrate the efficacy of our approach by experimenting on synthetic as well as real datasets.","","Electronic:978-1-4673-8851-1; POD:978-1-4673-8852-8","10.1109/CVPR.2016.579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780948","","Computer vision;Inference algorithms;Labeling;Machine learning algorithms;Optimization;Time complexity","Markov processes;computer vision;inference mechanisms;learning (artificial intelligence);maximum likelihood estimation;optimisation;random processes","MRF-MAP formulation;Markov random fields;computer vision;higher order MRF-MAP inference;higher order clique potentials;inference algorithms;machine learning;mathematical optimization;maximum a posteriori;min norm point algorithm;optimal inference;submodular function minimization;submodular structure","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Multiview Boosting With Information Propagation for Classification","J. Peng; A. J. Aved; G. Seetharaman; K. Palaniappan","Montclair State University, Montclair, NJ 07043 USA (e-mail jing.peng@montclair.edu).","IEEE Transactions on Neural Networks and Learning Systems","","2017","PP","99","1","13","Multiview learning has shown promising potential in many applications. However, most techniques are focused on either view consistency, or view diversity. In this paper, we introduce a novel multiview boosting algorithm, called Boost.SH, that computes weak classifiers independently of each view but uses a shared weight distribution to propagate information among the multiple views to ensure consistency. To encourage diversity, we introduce randomized Boost.SH and show its convergence to the greedy Boost.SH solution in the sense of minimizing regret using the framework of adversarial multiarmed bandits. We also introduce a variant of Boost.SH that combines decisions from multiple experts for recommending views for classification. We propose an expert strategy for multiview learning based on inverse variance, which explores both consistency and diversity. Experiments on biometric recognition, document categorization, multilingual text, and yeast genomic multiview data sets demonstrate the advantage of Boost.SH (85%) compared with other boosting algorithms like AdaBoost (82%) using concatenated views and substantially better than a multiview kernel learning algorithm (74%).","2162-237X;2162237X","","10.1109/TNNLS.2016.2637881","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805338","Biometrics;boosting;classification;convergence;data fusion;multiarmed bandits;multiview learning.","Algorithm design and analysis;Approximation algorithms;Boosting;Convergence;Data integration;Diversity reception;Machine learning algorithms","","","","","","","","20170104","","","IEEE","IEEE Early Access Articles"
"Online multi-threshold based soft confidence weighted learning for imbalanced data","X. Cai; L. Ye; R. Zhu; Q. Zhang","Department of Information Engineering, Communication University of China, Beijing, China","2016 6th International Conference on Information Communication and Management (ICICM)","20161215","2016","","","156","161","The paper focuses on the online binary problem in imbalanced data stream. Presently, majority existing works rely on a known distribution in advance of the labeled training data, this paper considers a more challenging setting where no prior knowledge is supplied. A second-order online learning method with multiple thresholds based on F-measure is utilized. The F-measure optimization problem provided foundation and inspiration for threshold selection in this paper. The based learner paired with the highest F-score yielding threshold is selected as the optimal classifier for every observed example. Experimentation on recent benchmark datasets validates the superiority of the proposed approach in both balanced and imbalanced data streams.","","CD:978-1-5090-3493-2; Electronic:978-1-5090-3495-6; POD:978-1-5090-3496-3","10.1109/INFOCOMAN.2016.7784234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7784234","F measure;imbalanced data;multi-threshold;online learning","Algorithm design and analysis;Classification algorithms;Electronic mail;Learning systems;Machine learning algorithms;Optimization;Prediction algorithms","computer aided instruction;optimisation;pattern classification","F-measure optimization problem;imbalanced data;online binary classification;online binary problem;online multithreshold;second-order online learning method;soft confidence weighted learning","","","","","","","29-31 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Distributed Decision Tree Algorithm and Its Implementation on Big Data Platforms","J. Chen; T. Wang; R. Abbey; J. Pingenot","SAS Inst. Inc., Cary, NC, USA","2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20161226","2016","","","752","761","Decision tree algorithms are very popular in the field of data mining. This paper proposes a distributed decision tree algorithm and shows examples of its implementation on big data platforms. The major contribution of this paper is the novel KS-Tree algorithm which builds a decision tree in a distributed environment. KS-Tree is applied to some real world data mining problems and compared with state-of-the-art decision tree techniques that are implemented in R and Apache Spark. The results show that KS-Tree can achieve better results, especially with large data sets. Furthermore, we demonstrate that KS-Tree can be applied to various data mining tasks, such as variable selection.","","Electronic:978-1-5090-5206-6; POD:978-1-5090-5207-3","10.1109/DSAA.2016.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796963","Big data;CHAID;Data Mining;Decision Tree;Distributed Algorithm;KS-Tree","Buildings;Data mining;Data structures;Decision trees;Electronic mail;Machine learning algorithms;Prediction algorithms","Big Data;data mining;decision trees;distributed algorithms;programming languages","Apache Spark;Big Data platforms;KS-tree algorithm;R programming language;data mining;distributed decision tree algorithm","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Repeatable Folding Task by Humanoid Robot Worker Using Deep Learning","P. C. Yang; K. Sasaki; K. Suzuki; K. Kase; S. Sugano; T. Ogata","Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan","IEEE Robotics and Automation Letters","20161226","2017","2","2","397","403","We propose a practical state-of-the-art method to develop a machine-learning-based humanoid robot that can work as a production line worker. The proposed approach provides an intuitive way to collect data and exhibits the following characteristics: task performing capability, task reiteration ability, generalizability, and easy applicability. The proposed approach utilizes a real-time user interface with a monitor and provides a first-person perspective using a head-mounted display. Through this interface, teleoperation is used for collecting task operating data, especially for tasks that are difficult to be applied with a conventional method. A two-phase deep learning model is also utilized in the proposed approach. A deep convolutional autoencoder extracts images features and reconstructs images, and a fully connected deep time delay neural network learns the dynamics of a robot task process from the extracted image features and motion angle signals. The “Nextage Open” humanoid robot is used as an experimental platform to evaluate the proposed model. The object folding task utilizing with 35 trained and 5 untrained sensory motor sequences for test. Testing the trained model with online generation demonstrates a 77.8% success rate for the object folding task.","2377-3766;23773766","","10.1109/LRA.2016.2633383","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7762066","Humanoid robots;learning and adaptive systems;motion control of manipulators;neurorobotics","Data models;Feature extraction;Humanoid robots;Machine learning;Robot sensing systems;Training","data handling;delays;feature extraction;generalisation (artificial intelligence);human-robot interaction;humanoid robots;image reconstruction;industrial robots;learning (artificial intelligence);neurocontrollers;robot dynamics;robot vision;telerobotics;user interfaces","Nextage Open humanoid robot;deep convolutional autoencoder;deep time delay neural network learning;first-person perspective;generalizability;head-mounted display;humanoid robot worker;image feature extraction;image reconstruction;machine-learning-based humanoid robot;production line worker;repeatable folding task;robot task process dynamics;sensory motor sequences;task operating data collection;task performing capability;task reiteration ability;teleoperation;two-phase deep learning;user interface","","","","","","20161129","April 2017","","IEEE","IEEE Journals & Magazines"
"What Would a Data Scientist Ask? Automatically Formulating and Solving Predictive Problems","B. Schreck; K. Veeramachaneni","CSAIL, MIT, Cambridge, MA, USA","2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20161226","2016","","","440","451","In this paper, we designed a formal language, called Trane, for describing prediction problems over relational datasets, implemented a system that allows data scientists to specify problems in that language. We show that this language is able to describe several prediction problems and even the ones on KAGGLE-a data science competition website. We express 29 different KAGGLE problems in this language. We designed an interpreter, which translates input from the user, specified in this language, into a series of transformation and aggregation operations to apply to a dataset in order to generate labels that can be used to train a supervised machine learning classifier. Using a smaller subset of this language, we developed a system to automatically enumerate, interpret and solve prediction problems. We tested this system on the Walmart Store Sales Forecasting dataset found on KAGGLE, enumerated 1077 prediction problems and built models that attempted to solve them, for which we produced 235 AUC scores. Considering that only one out of those 1077 problems was the focus of a 2.5 month long competition on KAGGLE, we expect this system to deliver a thousandfold increase in data scientist's productivity.","","Electronic:978-1-5090-5206-6; POD:978-1-5090-5207-3","10.1109/DSAA.2016.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796930","automation;data science;predictive modeling","Complexity theory;Data models;Indexes;Machine learning algorithms;Prediction algorithms;Predictive models","formal languages;learning (artificial intelligence);pattern classification","KAGGLE;Trane;Walmart store sale forecasting dataset;data science competition Website;data scientists;formal language;supervised machine learning classifier","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Using Deep Learning with Position Specific Scoring Matrices to Identify Efflux Proteins in Membrane and Transport Proteins","S. W. Taju; N. Q. K. Le; Y. Y. Ou","Dept. of Comput. Sci. & Eng., Yuan Ze Univ., Chungli, Taiwan","2016 IEEE 16th International Conference on Bioinformatics and Bioengineering (BIBE)","20161219","2016","","","101","108","In several years, deep learning is a new area of machine learning field, which is the motivation of developing machine learning near to artificial intelligent. The neural networks belongs to deep learning are progressively important ideas in a variety of fields with great performance. Accordingly, utilization of deep learning in bioinformatics to enhance performance is very important. Convolutional neural networks is a network of deep learning which is claimed to be the best model to solve the problem of object recognition and detection utilizing GPU computing. In this study, we try to use CNN to identify efflux proteins in membrane and transport proteins, which is a famous problem in bioinformatics field. We construct the CNN from PSSM profiles with CUDA and Keras package based on Theano backend. Finally this approach achieved a significant improvement after we compare with the previous paper on efflux proteins. The proposed method can serve as an effective tool for identifying efflux proteins and can help biologists understand the functions of the efflux proteins. Moreover this study provides a basis for further research that can enrich a field of applying deep learning in bioinformatics.","","Electronic:978-1-5090-3834-3; POD:978-1-5090-3835-0","10.1109/BIBE.2016.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789966","convolutional neural network;deep learning;efflux;position specific scoring matrices;proteins","Artificial neural networks;Biological neural networks;Biomembranes;Machine learning;Proteins;Shape;Two dimensional displays","bioinformatics;feedforward neural nets;learning (artificial intelligence);molecular biophysics;object recognition;parallel architectures;proteins","CNN;CUDA;Keras package;PSSM profiles;Theano backend;artificial intelligence;bioinformatics;convolutional neural networks;deep learning;efflux protein identification;machine learning;membrane proteins;object detection;object recognition;performance enhancement;position specific scoring matrices;transport proteins","","","","","","","Oct. 31 2016-Nov. 2 2016","","IEEE","IEEE Conference Publications"
"Feature selection for text classification using genetic algorithms","N. Bidi; Z. Elberrichi","University Mustapha Stambouli, University Mustapha Stambouli, Mascara, Algeria","2016 8th International Conference on Modelling, Identification and Control (ICMIC)","20170105","2016","","","806","810","In text classification, feature selection is essential to improve the classification effectiveness. This paper provides an empirical study of a feature selection method based on genetic algorithms for different text representation methods. This feature selection algorithm can accomplish two goals: in one hand is the search of a feature subset such that the performance of classifier is best; in other hands is find a feature subset with the smallest dimensionality which achieves higher accuracy in classification. To evaluate the performance of this approach, three from the best classifiers have been selected: Naive Bayes (NB), Nearest Neighbors (KNN) and Support Vector Machines (SVMs). Our objective is to determine whether the genetic algorithms based feature selection will improve the performances in text classification with smaller size using F-measure. Experimentations were carried out on two benchmark document collections 20Newsgroups, and Reuters-21578. And the results were very interesting.","","Electronic:978-0-9567157-7-7; POD:978-1-5090-1594-8","10.1109/ICMIC.2016.7804223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804223","Genetic algorithms;K-Nearest Neighbors;Naïve Bayes;Support Vectors Machines;Text Classification;feature selection","Algorithm design and analysis;Classification algorithms;Genetic algorithms;Machine learning algorithms;Niobium;Support vector machines;Text categorization","","","","","","","","","15-17 Nov. 2016","","IEEE","IEEE Conference Publications"
"Sparse-reduced computation for large-scale spectral clustering","P. Baumann","Department of Business Administration, University of Bern, Schuetzenmattstrasse 14, 3012, Switzerland","2016 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","20161229","2016","","","1284","1288","Clustering is a fundamental task in machine learning and data analysis. A large number of clustering algorithms has been developed over the past decades. Among these algorithms, the recently developed spectral clustering methods have consistently outperformed traditional clustering algorithms. Spectral clustering algorithms, however, have limited applicability to large-scale problems due to their high computational complexity. We propose a new approach for scaling spectral clustering methods that is based on the idea of replacing the entire data set with a small set of representative data points and performing the spectral clustering on the representatives. The main contribution is a new approach for efficiently identifying the representative data points. First results indicate that the proposed scaling approach achieves high-quality clusterings and is substantially faster than existing scaling approaches.","","Electronic:978-1-5090-3665-3; POD:978-1-5090-3666-0; USB:978-1-5090-3664-6","10.1109/IEEM.2016.7798085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7798085","Big Data;Large-scale Clustering;Sparse-reduced computation;Spectral Clustering;Unsupervised Learning","Algorithm design and analysis;Business;Clustering algorithms;Clustering methods;Laplace equations;Machine learning algorithms;Principal component analysis","computational complexity;data structures;learning (artificial intelligence);pattern clustering","computational complexity;data analysis;data representation;large-scale spectral clustering;machine learning;sparse-reduced computation","","","","","","","4-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep learning vs. wise learning: A critical and challenging overview (Plenary paper)","P. P. Groumpos","Laboratory for Automation and Robotics, Department of Electrical and Computer Engineering, University of Patras, Patras, Greece","2016 7th International Conference on Information, Intelligence, Systems & Applications (IISA)","20161219","2016","","","1","2","In this Plenary paper the most important scientific challenge of knowledge learning is reviewed thought two different approaches: Deep Learning (DL) and Wise Learning (WL).","","Electronic:978-1-5090-3429-1; POD:978-1-5090-3430-7","10.1109/IISA.2016.7785387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785387","Deep Learning;Knowledge Management;Wise Learning","Automation;Biological neural networks;Collaboration;Economics;Fuzzy cognitive maps;Machine learning;Robots","learning (artificial intelligence)","deep learning approach;knowledge learning;wise learning approach","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Early diagnosis of Alzheimer's disease: A multi-class deep learning framework with modified k-sparse autoencoder classification","P. Bhatkoti; M. Paul","School of Computing and Mathematics, Charles Sturt University, Australia","2016 International Conference on Image and Vision Computing New Zealand (IVCNZ)","20170105","2016","","","1","5","Successful, timely diagnosis of neuropsychiatry diseases is key to management. Research efforts in the area of diagnosis of Alzheimer's disease have used various aspects of computer-aided multi-class diagnosis approaches with varied degrees of success. However, there is still need for more efficient and reliable approaches to successful diagnosis of the disease. This research used deep learning framework with modified k-sparse autoencoder (oKSA) classification to locate neutrally degenerated areas of the brain magnetic resonance imaging (MRI), low amyloid beta 1-42 imaging in cerebrospinal fluid (CSF) and positron emission tomography (PET) imaging of amyloid; each with a sample of 150 images. Results show a correlation between computational demarcation of infected regions and the images. Degeneration in the studied areas was evidenced by high phosphorylated t-/p-tau levels in CSF, regional fluorodeoxyglucose PET, and the presence of atrophy patterns. The use of σKSA algorithm in boosting classification helped to improve the classifier performance. The KSA method with deep learning framework is used for the first time to produce accurate results in diagnosis of Alzheimer's disease.","","Electronic:978-1-5090-2748-4; POD:978-1-5090-2749-1; USB:978-1-5090-2747-7","10.1109/IVCNZ.2016.7804459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804459","Alzheimer's;aKSA;deep learning;diagnosis;k-sparse;neuroimaging","Alzheimer's disease;Classification algorithms;Encoding;Feature extraction;Machine learning;Magnetic resonance imaging","biomedical MRI;diseases;image classification;image coding;learning (artificial intelligence);medical image processing;positron emission tomography","σKSA algorithm;CSF;MRI;PET imaging;atrophy patterns;brain magnetic resonance imaging;cerebrospinal fluid;classifier performance;computational demarcation;computer-aided multiclass diagnosis;early Alzheimer's disease diagnosis;infected images;infected regions;low amyloid beta 1-42 imaging;modified k-sparse autoencoder classification;multiclass deep learning;neuropsychiatric disease diagnosis;neutrally degenerated areas;phosphorylated t-/p-tau levels;positron emission tomography;regional hypometabolism fluorodeoxyglucose PET","","","","","","","21-22 Nov. 2016","","IEEE","IEEE Conference Publications"
"Molecular activity prediction using deep learning software library","Y. Kato; S. Hamada; H. Goto","Information and Computer Science, Toyohashi University of Technology, Japan","2016 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA)","20170102","2016","","","1","6","In order to know how work deep learning method in chemoinformatics and bioinformatics problems, we have attempted to predict the molecular activities using the molecular fingerprints (chemical descriptor vectors) provided by the “Merck molecular activity challenge” competition and an open source deep learning library Chainer. Our result has been able to reproduce almost identical increase-decrease tendencies with the correlation R<sub>s</sub><sup>2</sup> of the champion group in the competition. GPU performance was also examined and the speed gain were more than 11 times than only CPU computation.","","Electronic:978-1-5090-1636-5; POD:978-1-5090-1637-2","10.1109/ICAICTA.2016.7803113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803113","Merck Molecular Activity Challange;QSAR;bioinformatics;chemoinformatics;deep neural networks;drug discovery","Biological neural networks;Chemicals;Correlation;Graphics processing units;Machine learning;Training","bioinformatics;graphics processing units;learning (artificial intelligence);public domain software;software libraries","GPU performance;Merck molecular activity challenge competition;bioinformatics;champion group;chemical descriptor vectors;chemoinformatics;identical increase-decrease tendencies;molecular activity prediction;molecular fingerprints;open source deep learning software library Chainer","","","","","","","16-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Multimodal Multi-Stream Deep Learning for Egocentric Activity Recognition","S. Song; V. Chandrasekhar; B. Mandal; L. Li; J. H. Lim; G. S. Babu; P. P. San; N. M. Cheung","Singapore Univ. of Technol. & Design, Singapore, Singapore","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","378","385","In this paper, we propose a multimodal multi-stream deep learning framework to tackle the egocentric activity recognition problem, using both the video and sensor data. First, we experiment and extend a multi-stream Convolutional Neural Network to learn the spatial and temporal features from egocentric videos. Second, we propose a multistream Long Short-Term Memory architecture to learn the features from multiple sensor streams (accelerometer, gyroscope, etc.). Third, we propose to use a two-level fusion technique and experiment different pooling techniques to compute the prediction results. Experimental results using a multimodal egocentric dataset show that our proposed method can achieve very encouraging performance, despite the constraint that the scale of the existing egocentric datasets is still quite limited.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789544","","Machine learning;Optical imaging;Optical network units;Optical sensors;Streaming media;Visualization","image sensors;learning (artificial intelligence);neural nets;video signal processing","accelerometer;egocentric activity recognition;egocentric videos;gyroscope;memory architecture;multimodal multistream deep learning framework;multiple sensor streams;multistream convolutional neural network;sensor data;spatial features;temporal features;video data","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Stochastic-Based Deep Convolutional Networks with Reconfigurable Logic Fabric","M. Alawad; M. Lin","Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL","IEEE Transactions on Multi-Scale Computing Systems","20161221","2016","2","4","242","256","Large-scale convolutional neural network is a fundamental algorithmic building block in many computer vision and artificial intelligence applications that follow the deep learning principle. However, a typically-sized CNN is well known to be computationally intensive. This work presents a novel stochastic-based and scalable hardware architecture and circuit design that computes a large-scale CNN with FPGA. The key idea is to implement all key components of a deep learning CNN, including multi-dimensional convolution, activation, and pooling layers, completely in the probabilistic computing domain in order to achieve high computing robustness, high performance, and low hardware usage. Our approach has three advantages. First, it can achieve significantly lower algorithmic complexity for any given accuracy requirement. For a <inline-formula><tex-math notation=""LaTeX"">$N$</tex-math><alternatives> <inline-graphic xlink:href=""alawad-ieq1-2601326.gif""/></alternatives></inline-formula> dimensional image feature map, we have theoretically proven that a random sample size of <inline-formula><tex-math notation=""LaTeX""> $k^* log (N)$</tex-math><alternatives><inline-graphic xlink:href=""alawad-ieq2-2601326.gif""/></alternatives> </inline-formula> is sufficient to achieve no more than 0.05 error at 95 percent confidence level, where <inline-formula><tex-math notation=""LaTeX"">$k^*$</tex-math><alternatives> <inline-graphic xlink:href=""alawad-ieq3-2601326.gif""/></alternatives></inline-formula> is a constant of 510. This computing complexity, when compared with that of conventional multiplier-based architecture, represents on average 8.97<inline-formula><tex-math notation=""LaTeX"">$times$</tex-math><alternatives> <inline-graphic xlink:href=""alawad-ieq4-2601326.gif""/></alternatives></inline-formula> and 6.98<inline-formula> <tex-math notation=""LaTeX"">$times$</tex-math><alternatives> <inline-graphic xlink:href=""alawad-ieq5-2601326.gif""/></alternatives></inline-formula> performance im- rovement for SCNN and Deep SCNN, respectively. Second, this proposed stochastic-based architecture is highly fault-tolerant because the information to be processed is encoded with a large ensemble of random samples. As such, the local perturbations of its computing accuracy will be dissipated globally, thus becoming inconsequential to the final overall results. More interestingly, our measured results have shown that 0.1 percent degradation in computing accuracy of CNN can actually mitigate the well-known overfitting problem. Overall, being highly scalable and energy efficient, our stochastic-based convolutional neural network architecture is well-suited for a modular vision engine with the goal of performing real-time detection, recognition, and segmentation of mega-pixel images, especially those perception-based computing tasks that are inherently fault-tolerant, while still requiring high energy efficiency.","","","10.1109/TMSCS.2016.2601326","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547913","FPGA;Stochastic convolution;convolutional neural network","Computer architecture;Convolution;Convolutional neural networks;Feature extraction;Field programmable gate arrays;Machine learning;Neural networks;Neuromorphics","","","","","","","","20160819","Oct.-Dec. 1 2016","","IEEE","IEEE Journals & Magazines"
"Deep End2End Voxel2Voxel Prediction","D. Tran; L. Bourdev; R. Fergus; L. Torresani; M. Paluri","","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","402","409","Over the last few years deep learning methods have emerged as one of the most prominent approaches for video analysis. However, so far their most successful applications have been in the area of video classification and detection, i.e., problems involving the prediction of a single class label or a handful of output variables per video. Furthermore, while deep networks are commonly recognized as the best models to use in these domains, there is a widespread perception that in order to yield successful results they often require time-consuming architecture search, manual tweaking of parameters and computationally intensive preprocessing or post-processing methods. In this paper we challenge these views by presenting a deep 3D convolutional architecture trained end to end to perform voxel-level prediction, i.e., to output a variable at every voxel of the video. Most importantly, we show that the same exact architecture can be used to achieve competitive results on three widely different voxel-prediction tasks: video semantic segmentation, optical flow estimation, and video coloring. The three networks learned on these problems are trained from raw video without any form of preprocessing and their outputs do not require post-processing to achieve outstanding performance. Thus, they offer an efficient alternative to traditional and much more computationally expensive methods in these video domains.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789547","","Convolution;Deconvolution;Estimation;Machine learning;Optical imaging;Semantics;Three-dimensional displays","image classification;image colour analysis;image segmentation;video signal processing","deep End2End Voxel2Voxel prediction;deep learning methods;intensive preprocessing;optical flow estimation;output variables;post-processing methods;raw video;single class label;time-consuming architecture search;video analysis;video classification;video coloring;video detection;video domains;video semantic segmentation","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Move prediction in Gomoku using deep learning","K. Shao; D. Zhao; Z. Tang; Y. Zhu","The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China","2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)","20170105","2016","","","292","297","The Gomoku board game is a longstanding challenge for artificial intelligence research. With the development of deep learning, move prediction can help to promote the intelligence of board game agents as proven in AlphaGo. Following this idea, we train deep convolutional neural networks by supervised learning to predict the moves made by expert Gomoku players from RenjuNet dataset. We put forward a number of deep neural networks with different architectures and different hyperparameters to solve this problem. With only the board state as the input, the proposed deep convolutional neural networks are able to recognize some special features of Gomoku and select the most likely next move. The final neural network achieves the accuracy of move prediction of about 42% on the RenjuNet dataset, which reaches the level of expert Gomoku players. In addition, it is promising to generate strong Gomoku agents of human-level with the move prediction as a guide.","","Electronic:978-1-5090-4423-8; POD:978-1-5090-4424-5; USB:978-1-5090-4422-1","10.1109/YAC.2016.7804906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804906","Gomoku;deep convolutional network;deep learning;move prediction","Computers;Games;Machine learning;Network architecture;Neural networks;Supervised learning;Training","computer games;learning (artificial intelligence);multi-agent systems","AlphaGo;Gomoku agents;Gomoku board game;RenjuNet dataset;artificial intelligence research;board game agent intelligence;deep convolutional neural network training;deep learning;expert Gomoku players;move prediction;supervised learning","","","","","","","11-13 Nov. 2016","","IEEE","IEEE Conference Publications"
"Deep learning attack for physical unclonable function","Y. Ikezaki; Y. Nozaki; M. Yoshikawa","Dept. of Information Engineering, Graduate School of Meijo University, 1-501 Shiogamaguchi, Tenpaku-ku, Nagoya, Aichi, Japan","2016 IEEE 5th Global Conference on Consumer Electronics","20161229","2016","","","1","2","The semiconductor counterfeiting has become a serious problem. Several Physical Unclonable Functions (PUFs), which utilizes the variation when manufacturing, are proposed as a countermeasure for imitation electronics. An arbiter PUF is one of the most popular PUFs. The operation of an arbiter PUF can be expressed by using a delay model. An arbiter PUF is reported to be attacked by forcing them to learn the delay model. Almost all of previous studies used SVM for the learning. This study proposes a new attack method using a deep learning technique. Experiments prove the validity of the proposed method.","","Electronic:978-1-5090-2333-2; POD:978-1-5090-2334-9","10.1109/GCCE.2016.7800478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7800478","Phisycal Unclonable Functoin;deep learning;security","Conferences;Counterfeiting;Data models;Feature extraction;Machine learning;Support vector machines","asynchronous circuits;cryptography;learning (artificial intelligence)","arbiter PUF;deep learning attack;delay model;imitation electronics;physical unclonable function;semiconductor counterfeiting","","","","","","","11-14 Oct. 2016","","IEEE","IEEE Conference Publications"
"Fast incremental method for smooth nonconvex optimization","S. J. Reddi; S. Sra; B. Póczos; A. Smola","Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213, USA","2016 IEEE 55th Conference on Decision and Control (CDC)","20161229","2016","","","1971","1977","We analyze a fast incremental aggregated gradient method for optimizing nonconvex problems of the form minΣ<sub>i</sub>f<sub>i</sub>(x). Specifically, we analyze the SAGA algorithm within an Incremental First-order Oracle framework, and show that it converges to a stationary point provably faster than both gradient descent and stochastic gradient descent. We also discuss a Polyak's special class of nonconvex problems for which SAGA converges at a linear rate to the global optimum. Finally, we analyze the practically valuable regularized and minibatch variants of SAGA. To our knowledge, this paper presents the first analysis of fast convergence for an incremental aggregated gradient method for nonconvex problems.","","DVD:978-1-5090-1844-4; Electronic:978-1-5090-1837-6; POD:978-1-5090-1838-3","10.1109/CDC.2016.7798553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7798553","","Complexity theory;Convergence;Gradient methods;Indexes;Machine learning algorithms;Radio frequency","concave programming;convergence of numerical methods;gradient methods","Polyak's nonconvex problems;SAGA algorithm;convergence;fast incremental aggregated gradient method;global optimum;incremental first-order Oracle;linear rate;regularized minibatch variants;smooth nonconvex optimization","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"An-FPGA Based Classification System by Using a Neural Network and an Improved Particle Swarm Optimization Algorithm","T. L. Dang; Y. Hoshino","Sch. of Syst. Eng., Kochi Univ. of Technol., Kochi, Japan","2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)","20161229","2016","","","97","102","This paper presents a development of a soft intelligent system on chip. This system is used to solve the classification problem. In this system, a neural network is trained by the particle swarm optimization (PSO) algorithm. This algorithm is hardware implemented on a real device. An improved version of the standard PSO algorithm called the PSOseed algorithm is also introduced in this paper in order to reduce the possibility when the standard PSO gets stuck in the local minimum. The experimental results show that the neural network trained by the particle swarm optimization algorithm was successful hardware implemented. In addition, the PSOseed algorithm also obtained a better performance than the standard PSO algorithm in our experiments.","","Electronic:978-1-5090-2678-4; POD:978-1-5090-2679-1","10.1109/SCIS-ISIS.2016.0033","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801620","Field-programmable gate array;neural network;particle swarm optimization;soft intelligent systems on chip;velocity control","Artificial neural networks;Hardware;Iris recognition;Machine learning algorithms;Particle swarm optimization;Standards;Training","field programmable gate arrays;neural nets;particle swarm optimisation;system-on-chip","FPGA based classification system;PSOseed algorithm;improved particle swarm optimization algorithm;neural network;soft intelligent system on chip","","","","","","","25-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Robustness of Support Vector Machine-based Classification of Heart Rate Signals","A. Kampouraki; C. Nikou; G. Manis","University of Ioannina, Department of Computer Science, P.O. Box 1186, 45110 Ioannina, Greece, Phone: +30 26510 98802, Fax: +30 26510 98890","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","2159","2162","In this study, we discuss the use of support vector machine (SVM) learning to classify heart rate signals. Each signal is represented by an attribute vector containing a set of statistical measures for the respective signal. At first, the SVM classifier is trained by data (attribute vectors) with known ground truth. Then, the classifier learnt parameters can be used for the categorization of new signals not belonging to the training set. We have experimented with both real and artificial signals and the SVM classifier performs very well even with signals exhibiting very low signal to noise ratio which is not the case for other standard methods proposed by the literature","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.260550","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4462216","","Cities and towns;Heart rate;Heart rate variability;Machine learning;Robustness;Signal analysis;Signal to noise ratio;Statistical learning;Support vector machine classification;Support vector machines","electrocardiography;learning (artificial intelligence);medical signal processing;pattern classification;signal classification;support vector machines","ECG;SVM learning;heart rate signal classification;signal to noise ratio;support vector machine classifier","Algorithms;Arrhythmias, Cardiac;Artificial Intelligence;Diagnosis, Computer-Assisted;Electrocardiography;Heart Rate;Humans;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","2","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"An automatic classification method for environment: Friendly waste segregation using deep learning","S. Sudha; M. Vidhyalakshmi; K. Pavithra; K. Sangeetha; V. Swaathi","ECE, Easwari Engineering College, Chennai, India","2016 IEEE Technological Innovations in ICT for Agriculture and Rural Development (TIAR)","20161229","2016","","","65","70","Recent enforcement of law by the Indian government for the welfare of sanitation workers has raised the need for an automated system in waste management. The existing garbage disposal system in India consists of unclassified waste collected from homes which are then segregated at a station manually. This segregation of solid waste done by manual labor can bring about many health hazards for the waste sorters in addition to being less efficient, time consuming and not completely feasible due to their large amount. In our paper, we have proposed an automated recognition system using Deep learning algorithm in Artificial Intelligence to classify objects as biodegradable and non-biodegradable, where the system once trained with an initial dataset, can identify objects real-time and classify them almost accurately. Biodegradable waste is used to generate power, enrich soil and act as food to animals. This process does not harm the earth making it valuable, ecologically safe and helps us to protect our environment, rich ecosystem and human inhabitants in future.","","Electronic:978-1-5090-0615-1; POD:978-1-5090-0616-8","10.1109/TIAR.2016.7801215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801215","Deep learning;Garbage segregation","Computer architecture;Image recognition;Machine learning;Neurons;Object recognition;Speech recognition;Training","employee welfare;image processing;learning (artificial intelligence);object recognition;occupational health;waste disposal;waste handling","Indian government;artificial intelligence;automated recognition system;automated waste management system;automatic object classification method;biodegradable waste;deep learning algorithm;environment protection;friendly waste segregation;garbage disposal system;health hazards;image analysis;law enforcement;nonbiodegradable object;sanitation worker welfare;solid waste segregation;waste sorters","","","","","","","15-16 July 2016","","IEEE","IEEE Conference Publications"
"The Multimode Blind Equalization Algorithm Based on Gaussian Process Regression","F. Wang; L. Yang; Y. Wang; L. Bai","","2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)","20161215","2016","02","","208","211","A new multimode blind equalizer based on Gaussian process regression(GPR) by incorporating multimode algorithm(MMA)-like error function into the conventional GPR framework is proposed. The MMA algorithm will be introduced to the phase information, error function can be divided into two parts of the real part and imaginary part, so as to solve the problem of the phase rotation. The GPR framework formulates the posterior density function for weights using Bayes' rule under the assumption of Gaussian prior for weights. The proposed blind GPR equalizer is based on linear-in-weights regression model. The simulation results show that the proposed blind GPR equalizer not only without cumbersome cross-validation procedures compared to the state-of-the-art blind support vector machine (SVM) equalizer, but also shows the better performances in terms of intersymbol interference and the constellation diagram than the CMA, MMA, SVR equalizers in linear and complex channels.","","Electronic:978-1-5090-0768-4; POD:978-1-5090-0769-1","10.1109/IHMSC.2016.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783821","GPR;SISO system;blind equalization;multimode signal","Blind equalizers;Convergence;Covariance matrices;Ground penetrating radar;Machine learning algorithms;Support vector machines","Bayes methods;Gaussian processes;blind equalisers;intersymbol interference;regression analysis","Bayes rule;CMA;GPR;Gaussian process regression;MMA algorithm;SVR equalizer;complex channels;constellation diagram;error function;intersymbol interference;linear channels;linear-in-weights regression model;multimode blind equalization algorithm;phase rotation;support vector machine equalizer","","","","","","","27-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Comparison of big data analyses for reliable open source software","Y. Tamura; S. Yamada","Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan","2016 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","20161229","2016","","","1345","1349","Open source software are used in wide ranging areas of software system development, because of the standardization, cost reduction, quick delivery. Many open source software are useful for the software developer and software managers to develop the software system quickly. Also, the open source software are characterized by the bug tracking system (BTS). The BTS's such as Bugzilla are controlled by almost open source projects. In the BTS, many data sets are recorded by project members and software users. In this paper, we compare the methods of big fault data analyses based on the deep learning and neural network. Moreover, we show several numerical examples of big fault data analyses in the actual open source software project. As the effectiveness analysis of the proposed method, the comparison results of recognition rate in terms of the proposed method and the conventional method are shown in this paper.","","Electronic:978-1-5090-3665-3; POD:978-1-5090-3666-0; USB:978-1-5090-3664-6","10.1109/IEEM.2016.7798097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7798097","Big data;deep learning;neural network;open source software;software reliability","Data analysis;Machine learning;Neural networks;Open source software;Software reliability","Big Data;data analysis;learning (artificial intelligence);neural nets;program debugging;public domain software;software engineering","BTS;Big Data analysis;Bugzilla;big fault data analyses;bug tracking system;data set recording;deep learning;neural network;recognition rate;reliable open source software;software system development","","","","","","","4-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"Additional information from voltage dips","A. Bagheri; M. Bollen","Lule&#x00E5; University of Technology, Electric Power Engineering, Skellefte&#x00E5;, Sweden","2016 17th International Conference on Harmonics and Quality of Power (ICHQP)","20161215","2016","","","328","332","This paper presents some methods to extract additional information from voltage dip recordings, beyond residual voltage and duration. Additionally it discusses some issues related to the massive amount of data obtained from modern measurements that, is referred to as Big Data. The paper proposes some Deep Learning based algorithms as good candidates to extract complex features from big data as a step towards additional information. The applications of the information include predicting individual equipment performance, fault type and location, protection operation, and overall load behavior. Individual equipment and overall load include production as well as consumption.","","Electronic:978-1-5090-3792-6; POD:978-1-5090-3793-3","10.1109/ICHQP.2016.7783434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783434","Big Data;Deep learning;Power quality;Voltage dips;distributed generation;fault-ride-through","Big data;Circuit faults;Data mining;Feature extraction;Machine learning;Trajectory;Voltage fluctuations","Big Data;fault location;voltage measurement","Big Data;deep learning based algorithms;fault location;fault protection operation;fault type;residual voltage;voltage dips","","","","","","","16-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Classification of Cancer Stage from Free-text Histology Reports","I. McCowan; D. Moore; M. J. Fry","CSIRO eHealth Research Centre, Brisbane, Australia. iain.mccowan@csiro.au","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","5153","5156","This article investigates the classification of a patient's lung cancer stage based on analysis of their free-text medical reports. The system uses natural language processing to transform the report text, including identification of UMLS terms and detection of negated findings. The transformed report is then classified using statistical machine learning techniques. A support vector machine is trained for each stage category based on word occurrences in a corpus of histology reports for pathologically staged patients. New reports can be classified according to the most likely stage, allowing the collection of population stage data for analysis of outcomes. While the system could in principle be applied to stage different cancer types, the current work focuses on lung cancer due to data availability. The article presents initial experiments quantifying system performance for T and N staging on a corpus of histology reports from more than 700 lung cancer patients","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.259563","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4462964","","Availability;Cancer;Data analysis;Lungs;Machine learning;Natural language processing;Support vector machine classification;Support vector machines;System performance;Unified modeling language","cancer;classification;learning (artificial intelligence);lung;medical information systems;natural language processing;support vector machines;text analysis;tumours","N staging;SVM-based text classification;T staging;UMLS term identification;free-text histology reports;lung cancer stage classification;natural language processing;population stage data;statistical machine learning techniques;support vector machine;unified medical language system","Algorithms;Artificial Intelligence;Histology;Humans;Information Storage and Retrieval;Lung Neoplasms;Natural Language Processing;Neoplasm Staging;Neural Networks (Computer);Pattern Recognition, Automated;ROC Curve;Reproducibility of Results;Sensitivity and Specificity;Software;Unified Medical Language System;Vocabulary, Controlled","5","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"A Performance Case-Study on Memristive Computing-in-Memory Versus Von Neumann Architecture","L. Koskinen; J. Tissari; J. Teittinen; E. Lehtonen; M. Laiho; J. H. Poikonen","Technol. Res. Center, Univ. of Turku, Turku, Finland","2016 Data Compression Conference (DCC)","20161219","2016","","","613","613","Summary form only given. The Von Neumann bottleneck originates from the low bandwidth between processing and memory. One paradigm that could ease the bottleneck is Computing-in-Memory (CiM), where the same elements store logic values and perform logical operations on them in the same physical location. Here, presented are implementations of the K-means clustering algorithm on a Memristive Logic Array-based CiM implementation and a Machine Learning specific Transport-Triggered Architecture (TTA) processor implemented on 28nm FDSOI technology and operating at 0.35V. While running K-means, the Memristive CiM is 5,7 times faster and uses 2,3 times less energy than the TTA processor. However, the average power consumption of the MLA is 2,5 times the power of the TTA.","","Electronic:978-1-5090-1853-6; POD:978-1-5090-1854-3","10.1109/DCC.2016.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7786237","","Bandwidth;Clustering algorithms;Computer architecture;Data compression;Logic arrays;Machine learning algorithms;Silicon-on-insulator","learning (artificial intelligence);logic arrays;memristor circuits;pattern clustering;power consumption","FDSOI technology;K-means clustering algorithm;Memristive Computing-in-Memory;Memristive logic array -based CiM implementation;TTA processor;Von Neumann Architecture;logical operations;machine learning;transport-triggered architecture","","","","","","","March 30 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Structured Output SVM Prediction of Apparent Age, Gender and Smile from Deep Features","M. Uricár; R. Timofte; R. Rothe; J. Matas; L. V. Gool","Dept. of Cybern., CTU in Prague, Prague, Czech Republic","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","730","738","We propose structured output SVM for predicting the apparent age as well as gender and smile from a single face image represented by deep features. We pose the problem of apparent age estimation as an instance of the multi-class structured output SVM classifier followed by a softmax expected value refinement. The gender and smile predictions are treated as binary classification problems. The proposed solution first detects the face in the image and then extracts deep features from the cropped image around the detected face. We use a convolutional neural network with VGG-16 architecture [25] for learning deep features. The network is pretrained on the ImageNet [24] database and then fine-tuned on IMDB-WIKI [21] and ChaLearn 2015 LAP datasets [8]. We validate our methods on the ChaLearn 2016 LAP dataset [9]. Our structured output SVMs are trained solely on ChaLearn 2016 LAP data. We achieve excellent results for both apparent age prediction and gender and smile classification.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789586","","Databases;Estimation;Face;Feature extraction;Machine learning;Support vector machines;Training","face recognition;feature extraction;image classification;learning (artificial intelligence);neural nets;pose estimation;support vector machines","ChaLearn 2015 LAP datasets;ChaLearn 2016 LAP dataset;IMDB-WIKI;VGG-16 architecture;apparent age estimation problem;binary classification problems;convolutional neural network;cropped image;deep feature extraction;deep feature learning;face detection;face image represention;gender classification;multiclass structured output SVM classifier prediction;smile classification;softmax expected value refinement","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Segmentation of the Left Ventricle in Echocardiography Using Contextual Shape Model","G. Belous; A. Busch; D. Rowlands; Y. Gao","Sch. of Eng., Griffith Univ., Brisbane, QLD, Australia","2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20161226","2016","","","1","7","Accurate localization of the left ventricle (LV) boundary from echocardiogram images is of vital importance for the diagnosis and treatment of heart disease. Statistical shape models such as active shape models (ASM) have been commonly used to perform automatic detection of this boundary. Such models perform well when there is low variability in the underlying shape subspace and an accurate initialization can be provided, however in the absence of these conditions results are often much poorer. In the case of LV echocardiogram images, such variability is often encountered in patients with abnormal LV function. In this paper we propose a fully automatic segmentation technique using deep learning in a Bayesian nonparametric framework. Our model uses a dynamic statistical shape model comprised of training shapes from select weighted subsets of the feature subspace. Subsets are chosen during the iterative segmentation process according to a latent temporal component allocation variable, determined from joint deep features and LV landmark information using a Dirichlet process mixture model with Chinese restaurant process prior. Testing is performed on a data set comprising images of the LV acquired from patients exhibiting both normal and abnormal LV function, and the results using our technique compared to both the ASM and other state of the art techniques. Results from this testing show an improvement in the LV localization accuracy, particularly when LV function is abnormal.","","Electronic:978-1-5090-2896-2; POD:978-1-5090-2897-9","10.1109/DICTA.2016.7797080","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797080","","Active shape model;Bayes methods;Image segmentation;Machine learning;Mixture models;Shape;Training","Bayes methods;echocardiography;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;mixture models;patient treatment;shape recognition","ASM;Bayesian nonparametric framework;Chinese restaurant process prior;Dirichlet process mixture model;LV echocardiogram images;active shape models;automatic detection;contextual shape model;deep learning;dynamic statistical shape model;echocardiography;feature subspace;heart disease diagnosis;heart disease treatment;iterative segmentation process;latent temporal component allocation variable;left ventricle localization;left ventricle segmentation;shape subspace;statistical shape models","","","","","","","Nov. 30 2016-Dec. 2 2016","","IEEE","IEEE Conference Publications"
"Deep Learning for Risk Analysis of Specific Cardiovascular Diseases Using Environmental Data and Outpatient Records","H. C. W. Hsiao; S. H. F. Chen; J. J. P. Tsai","Dept. of Bioinf. & Med. Eng., Asia Univ., Taichung, Taiwan","2016 IEEE 16th International Conference on Bioinformatics and Bioengineering (BIBE)","20161219","2016","","","369","372","Cardiovascular diseases are known to be a category of diseases related to heart or blood vessels and ranked the top two and three among ten leading causes of death in Taiwan in 2011, respectively. In this study, environmental and outpatient records within Taichung Area are utilized for risk analysis of four specific categories of cardiovascular diseases using deep learning approach. Autoencoder and Softmax are employed for feature extraction and classification. The output of Softmax for each sample is interpreted as the risk of these four specific categories of cardiovascular diseases. Further analysis is done to unveil the trends with respect to the factors of gender, age, region, and month.","","Electronic:978-1-5090-3834-3; POD:978-1-5090-3835-0","10.1109/BIBE.2016.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7790013","autoencoder;cardiovascular disease;deep learning;risk analysis","Air pollution;Cardiovascular diseases;Heart;Machine learning;Monitoring;Neurons","blood vessels;cardiovascular system;diseases;feature extraction;learning (artificial intelligence);medical computing;pattern classification;risk analysis","Autoencoder;Softmax;Taichung area;blood vessels;cardiovascular diseases;deep learning;environmental records;feature classification;feature extraction;heart;outpatient records;risk analysis","","","","","","","Oct. 31 2016-Nov. 2 2016","","IEEE","IEEE Conference Publications"
"Social Media Mediation System for Elderly People: Message Exchange Learning Type Switching Method","T. Kobayashi; K. Katsuragi; T. Miyazaki; K. Arai; T. Sakai; M. Fujimura","Grad. Sch. of Eng., Nagasaki Univ., Nagasaki, Japan","2016 19th International Conference on Network-Based Information Systems (NBiS)","20161219","2016","","","286","291","We proposed the Social Media Mediation Systemwhich can be used for the interactive communication betweenelderly people and younger generation via existed social media. In this system, we found out the problem that was the difficultyof inputting a message destination address by elderly people. Therefore, we propose a message exchange learning typeswitching method that enables elderly people not to input amessage destination address explicitly. This method is based onthe machine learning algorithm which performs the messagedestination decision according to message contents of elderlypeople. We developed a machine learning algorithm inferenceplatform to find out the suitable machine learning algorithm forthis purpose. Through inference experiments using this platform, we confirmed three machine learning algorithm candidateswhich could be suitable for the message exchange learning typeswitching method.","","Electronic:978-1-5090-0979-4; POD:978-1-5090-0980-0","10.1109/NBiS.2016.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789771","","Information systems;Learning systems;Machine learning algorithms;Mediation;Social network services;Switches","geriatrics;inference mechanisms;interactive systems;learning (artificial intelligence);social networking (online);social sciences computing","elderly people;interactive communication;machine learning algorithm inference platform;message destination address;message exchange learning type switching method;social media mediation system;younger generation","","","","","","","7-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Facial expression recognition with PCA and LBP features extracting from active facial patches","Y. Liu; Y. Cao; Y. Li; M. Liu; R. Song; Y. Wang; Z. Xu; X. Ma","School of Control Science and Engineering, Shandong University, Jinan, China, 250061","2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)","20161215","2016","","","368","373","Facial expression recognition is an important part of Natural User Interface (NUI). Feature extraction is one important step which could contribute to fast and accurate expression recognition. In order to extract more effective features from the static images, this paper proposes an algorithm based on the combination of gray pixel value and Local Binary Patterns (LBP) features. Principal component analysis (PCA) is used to reduce dimensions of the features which are combined by the gray pixel value and Local Binary Patterns (LBP) features. All the features are extracted from the active facial patches. The active facial patches are these face regions which undergo a major change during different expressions. Softmax regression classifier is used to classify the six basic facial expressions, the experimental results on extended Cohn-Kanade (CK+) database gain an average recognition rate of 96.3% under leave-one-out cross validation method which validates every subject in the database.","","Electronic:978-1-4673-8959-4; POD:978-1-4673-8960-0; USB:978-1-4673-8958-7","10.1109/RCAR.2016.7784056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7784056","","Databases;Face;Face recognition;Feature extraction;Machine learning;Mouth;Principal component analysis","face recognition;feature extraction;image classification;principal component analysis;regression analysis","LBP feature extraction;NUI;PCA;active facial patches;facial expression recognition;gray pixel value;leave-one-out cross validation method;local binary patterns;natural user interface;principal component analysis;softmax regression classifier","","","","","","","6-10 June 2016","","IEEE","IEEE Conference Publications"
"Twitter sentiment analysis using various classification algorithms","A. Deshwal; S. K. Sharma","Department of Computer Science & Engineering, KIIT College of Engineering, Gurgaon, India","2016 5th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","20161219","2016","","","251","257","Twitter is a web application built to find out what is happening at any instance through its micro blogging feature, anywhere in the world. Twitter posts are generally short and generated constantly by public and very well-suited for opinion mining. These messages can be classified as containing either positive or a negative sentiment on the basis of certain aspects with respect to a term based query. The past studies of sentiment classification are not very conclusive about which features and supervised classification algorithms are good for designing accurate and efficient sentiment classification system. We propose to combine many feature extraction techniques like emoticons, exclamation and question mark symbol, word gazetteer, unigrams to design more accurate sentiment classification system. This paper presents empirical comparison of six supervised classification algorithms.","","Electronic:978-1-5090-1489-7; POD:978-1-5090-1490-3","10.1109/ICRITO.2016.7784960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7784960","Opinion Mining;Sentiment Analysis;Twitter","Classification algorithms;Computer languages;Data mining;Feature extraction;Machine learning algorithms;Sentiment analysis;Twitter","data mining;feature extraction;pattern classification;sentiment analysis;social networking (online)","Twitter sentiment analysis;classification algorithm;feature extraction;opinion mining","","","","","","","7-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Fusing Aligned and Non-aligned Face Information for Automatic Affect Recognition in the Wild: A Deep Learning Approach","B. K. Kim; S. Y. Dong; J. Roh; G. Kim; S. Y. Lee","Comput. NeuroSystems Lab., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","1499","1508","Face alignment can fail in real-world conditions, negatively impacting the performance of automatic facial expression recognition (FER) systems. In this study, we assume a realistic situation including non-alignable faces due to failures in facial landmark detection. Our proposed approach fuses information about non-aligned and aligned facial states, in order to boost FER accuracy and efficiency. Six experimental scenarios using discriminative deep convolutional neural networks (DCNs) are compared, and causes for performance differences are identified. To handle non-alignable faces better, we further introduce DCNs that learn a mapping from non-aligned facial states to aligned ones, alignment-mapping networks (AMNs). We show that AMNs represent geometric transformations of face alignment, providing features beneficial for FER. Our automatic system based on ensembles of the discriminative DCNs and the AMNs achieves impressive results on a challenging database for FER in the wild.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789677","","Databases;Face;Face recognition;Feature extraction;Machine learning;Neural networks;Training","emotion recognition;face recognition;image fusion;learning (artificial intelligence);neural nets","AMN;DCN;FER accuracy;FER efficiency;aligned face information fusion;alignment-mapping networks;automatic affect recognition;deep learning;discriminative deep convolutional neural networks;face alignment;facial expression recognition systems;facial landmark detection;geometric transformations;nonaligned face information fusion","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Improving Traffic Flow Prediction With Weather Information in Connected Cars: A Deep Learning Approach","A. Koesdwiady; R. Soua; F. Karray","Centre for Pattern Analysis and Machine Intelligence, Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Waterloo, University of Luxembourg, Waterloo, ON, CanadaLuxembourg","IEEE Transactions on Vehicular Technology","20161214","2016","65","12","9508","9517","Transportation systems might be heavily affected by factors such as accidents and weather. Specifically, inclement weather conditions may have a drastic impact on travel time and traffic flow. This study has two objectives: first, to investigate a correlation between weather parameters and traffic flow and, second, to improve traffic flow prediction by proposing a novel holistic architecture. It incorporates deep belief networks for traffic and weather prediction and decision-level data fusion scheme to enhance prediction accuracy using weather conditions. The experimental results, using traffic and weather data originated from the San Francisco Bay Area of California, corroborate the effectiveness of the proposed approach compared with the state of the art.","0018-9545;00189545","","10.1109/TVT.2016.2585575","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7501574","Data fusion;deep learning;intelligent transportation systems (ITS);traffic prediction;weather information","Automobiles;Correlation;Data integration;Machine learning;Meteorology;Roads","belief networks;intelligent transportation systems;learning (artificial intelligence);road traffic;sensor fusion","California;ITS;San Francisco Bay Area;connected car;decision-level data fusion;deep belief network;deep learning approach;holistic architecture;intelligent transportation system;traffic flow prediction;transportation system;weather information;weather prediction","","","","","","20160628","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"Classifier Ensemble Design with Rotation Forest to Enhance Attack Detection of IDS in Wireless Network","B. A. Tama; K. H. Rhee","Lab. of Inf. Security & Internet Applic., Pukyong Nat. Univ., Busan, South Korea","2016 11th Asia Joint Conference on Information Security (AsiaJCIS)","20161215","2016","","","87","91","This paper is devoted to discover the appropriate base classifier algorithms while employing Rotation Forest as an ensemble learning method for intrusion detection system (IDS) in wireless network. Twenty different classification algorithms are involved in the experiment and their detection performances are assessed using the value of area under receiver operating characteristic curve (AUC) performance metric. The performance result of an ensemble learner are evaluated, including its significant improvement while using diverse machine leaning algorithms as base classifiers. From the experimental result and classifier significant test, it can be revealed that the performance of Rotation Forest has brought significant improvement over the base classifiers.","","Electronic:978-1-5090-2285-4; POD:978-1-5090-2286-1","10.1109/AsiaJCIS.2016.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7782063","","Gold;Intrusion detection;Machine learning algorithms;Measurement;Radio frequency;Training;Wireless networks","computer network security;design;learning (artificial intelligence);pattern classification","AUC;IDS;area under receiver operating characteristic curve;attack detection;classifier ensemble design;diverse machine leaning;ensemble learning;intrusion detection system;rotation forest;wireless network","","","","","","","4-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"Feature set tuning in statistical learning network intrusion detection","A. Gouveia; M. Correia","Portugal Telecom, Portugal","2016 IEEE 15th International Symposium on Network Computing and Applications (NCA)","20161212","2016","","","68","75","The detection of security-related events using machine learning approaches has been extensively investigated. In particular, machine learning applied to network intrusion detection systems (NIDS) has attracted a lot of attention due to its good generalization and unknown attack detection capabilities. A number of classification techniques have been used for this purpose, revealing good generalization properties. In this paper we go one step further by evaluating the performance of NIDSs when feature set tuning and reduction are realized. We evaluate a number of state of the art learning algorithms that are raising much interest but have not been used for intrusion detection yet. We compare a representative set of algorithms: Ada, ROC-based learners, two types of Classification Trees, Boosted Logistic Regression, Generalized Linear Models, Gradient Boosting Machines, and Neural Networks. The main objective is to reduce the number of features used - thus also the size of the data processed - to improve speed while maintaining adequate accuracy.","","Electronic:978-1-5090-3216-7; POD:978-1-5090-3217-4","10.1109/NCA.2016.7778595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778595","","Feature extraction;Intrusion detection;Machine learning algorithms;Neural networks;Sensitivity;Tuning","computer network security;learning (artificial intelligence);neural nets;pattern classification;regression analysis","Ada;NIDS;ROC-based learners;boosted logistic regression;classification techniques;classification trees;feature set reduction;feature set tuning;generalization property;generalized linear models;gradient boosting machines;machine learning approach;network intrusion detection systems;neural networks;security-related event detection;statistical learning network intrusion detection","","","","","","","Oct. 31 2016-Nov. 2 2016","","IEEE","IEEE Conference Publications"
"Deep Learning-Based Fast Hand Gesture Recognition Using Representative Frames","V. John; A. Boyali; S. Mita; M. Imanishi; N. Sanma","Toyota Technol. Inst., Nagoya, Japan","2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20161226","2016","","","1","8","In this paper, we propose a vision-based hand gesture recognition system for intelligent vehicles. Vision-based gesture recognition systems are employed in automotive user interfaces to increase the driver comfort without compromising their safety. In our algorithm, the long-term recurrent convolution network is used to classify the video sequences of hand gestures. In the standard long-term recurrent convolution network-based action classifier, multiple frames sampled from the video sequence are given as an input to the network, to perform classification. However, the use of multiple frames increases the computational complexity, apart from reducing the classification accuracy of the classifier. We propose to address these issues by extracting a fewer representative frames from the video sequence, and inputting them to the long-term recurrent convolution network. To extract the representative frames, we propose to use novel tiled image patterns and tiled binary pattern within a semantic segmentation- based deep learning framework, the deconvolutional neural network. The novel tiled image patterns contain multiple non-overlapping blocks and represent the entire gesture-based video sequence within a single tiled image. These image patterns represent the input to the deconvolution network and are generated from the video sequence. The novel tiled binary pattern also contain multiple non-overlapping blocks and represent the representative frames of the video sequence. These binary patterns represent the output of the deconvolution network. The training binary patterns are generated from the training video sequences using the dictionary learning and sparse modeling framework. We validate our proposed algorithm on the public Cambridge gesture recognition dataset. A comparative analysis is performed with baseline algorithms and an improved classification accuracy is observed. We also perform a detailed parametric analysis of the proposed algorithm. We report a gesture cl- ssification accuracy of 91% and report a near real-time computational complexity of $110$~ms per video sequence.","","Electronic:978-1-5090-2896-2; POD:978-1-5090-2897-9","10.1109/DICTA.2016.7797030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797030","","Feature extraction;Gesture recognition;Machine learning;Neural networks;Prediction algorithms;Semantics;Video sequences","computer vision;driver information systems;gesture recognition;image segmentation;image sequences;learning (artificial intelligence);recurrent neural nets;video signal processing","automotive user interfaces;deep learning-based fast hand gesture recognition;dictionary learning;driver comfort;hand gestures;intelligent vehicles;long-term recurrent convolution network;parametric analysis;public Cambridge gesture recognition dataset;representative frames;semantic segmentation;sparse modeling framework;video sequences;vision-based hand gesture recognition system","","","","","","","Nov. 30 2016-Dec. 2 2016","","IEEE","IEEE Conference Publications"
"Deepmotion: a deep convolutional neural network on inertial body sensors for gait assessment in multiple sclerosis*","Gong; Goldman; Lach","Department of Electrical and Computer Engineering, UVA Center for Wireless Health, University of Virginia, Charlottesville, VA, USA","2016 IEEE Wireless Health (WH)","20161215","2016","","","1","8","Walking impairment resulted by various chronic diseases, disorders and injuries have been investigated using recent emerging wearable technology, for instance, gait assessment using inertial body sensors in 6-minute walk (6MW) for persons with Multiple Sclerosis (PwMS) to identify spatiotemporal features useful to assess MS progression. However, most studies to date have investigated the features extracted from movements of the lower limbs and do not provide a holistic gait assessment. A recent pilot study demonstrated that the holistic gait assessment such as evaluating the associations among lower and upper limbs provided better discrimination between healthy controls and PwMS. This paper is motivated by this and further aim to answer the following question: can we identify the temporal gait patterns in terms of the holistic gait assessment? Traditionally this suffers from the statistical property of the causality inference method adopted by previous study. We proposed a deep convolutional neural network (CNN) to learn the temporal and spectral associations among the time-series motion data captured by the inertial body sensors. A simulated model was developed to train the CNN, and then the trained CNN was adopted to assess the gait performance from a pilot dataset with 41 subjects (28 PwMS and 13 healthy controls). Experimental results are reported to illustrate the performance of the proposed approach.","","Electronic:978-1-5090-3090-3; POD:978-1-5090-3091-0","10.1109/WH.2016.7764572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7764572","","Data processing;Legged locomotion;Machine learning;Physiology;Pulse width modulation;Sensor phenomena and characterization","body sensor networks;diseases;gait analysis;inertial systems;injuries;medical disorders;neural nets","Deepmotion;chronic diseases;deep convolutional neural network;disorders;gait assessment;inertial body sensors;injuries;multiple sclerosis;spatiotemporal features;walking impairment;wearable technology","","","","","","","25-27 Oct. 2016","","IEEE","IEEE Conference Publications"
"Hyperparameter Optimization Machines","M. Wistuba; N. Schilling; L. Schmidt-Thieme","Inf. Syst. & Machine Learning Lab., Univ. of Hildesheim, Hildesheim, Germany","2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20161226","2016","","","41","50","Algorithm selection and hyperparameter tuning are omnipresent problems for researchers and practitioners. Hence, it is not surprising that the efforts in automatizing this process using various meta-learning approaches have been increased. Sequential model-based optimization (SMBO) is ne of the most popular frameworks for finding optimal hyperparameter configurations. Originally designed for black-box optimization, researchers have contributed different meta-learning approaches to speed up the optimization process. We create a generalized framework of SMBO and its recent additions which gives access to adaptive hyperparameter transfer learning with simple surrogates (AHT), a new class of hyperparameter optimization strategies. AHT provides less time-overhead for the optimization process by replacing time-and space-consuming transfer surrogate models with simple surrogates that employ adaptive transfer learning. In an empirical comparison on two different meta-data sets, we can show that AHT outperforms various instances of the SMBO framework in the scenarios of hyperparameter tuning and algorithm selection.","","Electronic:978-1-5090-5206-6; POD:978-1-5090-5207-3","10.1109/DSAA.2016.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796889","hyperparameter optimization;meta-learning;transfer learning","Adaptation models;Data models;Machine learning algorithms;Optimization;Prediction algorithms;Transfer functions;Tuning","learning (artificial intelligence);optimisation","AHT;SMBO framework;adaptive hyperparameter transfer learning;black-box optimization;hyperparameter optimization strategies;hyperparameter tuning;meta-learning approaches;sequential model-based optimization","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep Stereo Fusion: Combining Multiple Disparity Hypotheses with Deep-Learning","M. Poggi; S. Mattoccia","Dept. of Comput. Sci. & Eng., Univ. of Bologna, Bologna, Italy","2016 Fourth International Conference on 3D Vision (3DV)","20161219","2016","","","138","147","Stereo matching is a popular technique to infer depth from two or more images and wealth of methods have been proposed to deal with this problem. Despite these efforts, finding accurate stereo correspondences is still an open problem. The strengths and weaknesses of existing methods are often complementary and in this paper, motivated by recent trends in this field, we exploit this fact by proposing Deep Stereo Fusion, a Convolutional Neural Network capable of combining the output of multiple stereo algorithms in order to obtain more accurate result with respect to each input disparity map. Deep Stereo Fusion process a 3D features vector, encoding both spatial and cross-algorithm information, in order to select the best disparity hypothesis among those proposed by the single stereo matchers. To the best of our knowledge, our proposal is the first i) to leverage on deep learning and ii) able to predict the optimal disparity assignments by taking only as input cue the disparity maps. This second feature makes our method suitable for deployment even when other cues (e.g., confidence) are not available such as when dealing with disparity maps provided by off-the-shelf 3D sensors. We thoroughly evaluate our proposal on the KITTI stereo benchmark with respect state-of-the-art in this field.","","Electronic:978-1-5090-5407-7; POD:978-1-5090-5408-4","10.1109/3DV.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785086","","Computer architecture;Encoding;Machine learning;Neurons;Proposals;Three-dimensional displays;Training","convolution;feature extraction;image fusion;image matching;inference mechanisms;learning (artificial intelligence);neural nets;stereo image processing;vectors","3D feature vector;convolutional neural network;deep learning;deep stereo fusion;depth inference;disparity hypothesis;stereo matching","","1","","","","","25-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Traffic speed prediction using deep learning method","Yuhan Jia; Jianping Wu; Yiman Du","Department of Civil Engineering, Tsinghua University, Beijing, 10084, China","2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)","20161226","2016","","","1217","1222","Successful traffic speed prediction is of great importance for the benefits of both road users and traffic management agencies. To solve the problem, traffic scientists have developed a number of time-series speed prediction approaches, including traditional statistical models and machine learning techniques. However, existing methods are still unsatisfying due to the difficulty to reflect the stochastic traffic flow characteristics. Recently, various deep learning models have been introduced to the prediction field. In this paper, a deep learning method, the Deep Belief Network (DBN) model, is proposed for short-term traffic speed information prediction. The DBN model is trained in a greedy unsupervised method and fine-tuned by labeled data. Based on traffic speed data collected from one arterial in Beijing, China, the model is trained and tested for different prediction time horizons. From experiment analysis, it is concluded that the DBN can outperform Back Propagation Neural Network (BPNN) and Auto-Regressive Integrated Moving Average (ARIMA) for all time horizons. The advantages of DBN indicate that deep learning is promising in traffic research area.","","Electronic:978-1-5090-1889-5; POD:978-1-5090-1890-1; USB:978-1-5090-1888-8","10.1109/ITSC.2016.7795712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795712","","Artificial neural networks;Data models;Machine learning;Object oriented modeling;Predictive models;Roads;Training","belief networks;learning (artificial intelligence);statistical analysis;traffic engineering computing","Beijing;China;DBN model;deep belief network model;deep learning method;machine learning techniques;stochastic traffic flow characteristics;time-series speed prediction approaches;traffic management agencies;traffic speed prediction","","","","","","","1-4 Nov. 2016","","IEEE","IEEE Conference Publications"
"Data-driven situation awareness algorithm for vehicle lane change","Dewei Yi; J. Su; C. Liu; W. H. Chen","Department of Aeronautical and Automotive Engineering, Loughborough University, LE11 3TU, U.K.","2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)","20161226","2016","","","998","1003","A good level of situation awareness is critical for vehicle lane change decision making. In this paper, a Data-Driven Situation Awareness (DDSA) algorithm is proposed for vehicle environment perception and projection using machine learning algorithms in conjunction with the concept of multiple models. Firstly, unsupervised learning (i.e., Fuzzy C-Mean Clustering (FCM)) is drawn to categorize the drivers' states into different clusters using three key features (i.e., velocity, relative velocity and distance) extracted from Intelligent Driver Model (IDM). Statistical analysis is conducted on each cluster to derive the acceleration distribution, resulting in different driving models. Secondly, supervised learning classification technique (i.e., Fuzzy k-NN) is applied to obtain the model/cluster of a given driving scenario. Using the derived model with the associated acceleration distribution, Kalman filter/prediction is applied to obtain vehicle states and their projection. The publicly available NGSIM dataset is used to validate the proposed DDSA algorithm. Experimental results show that the proposed DDSA algorithm obtains better filtering and projection accuracy in comparison with the Kalman filter without clustering.","","Electronic:978-1-5090-1889-5; POD:978-1-5090-1890-1; USB:978-1-5090-1888-8","10.1109/ITSC.2016.7795677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795677","Clustering and Classification;Filtering and Prediction;Lane Change;NGSIM dataset","Acceleration;Classification algorithms;Clustering algorithms;Machine learning algorithms;Safety;Sensors;Vehicles","Kalman filters;decision making;driver information systems;fuzzy set theory;intelligent transportation systems;neural nets;pattern classification;pattern clustering;road vehicles;statistical analysis;unsupervised learning","DDSA algorithm;FCM;IDM;Kalman filter;acceleration distribution;data-driven situation awareness algorithm;decision making;fuzzy c-mean clustering;fuzzy k-NN;intelligent driver model;machine learning algorithm;statistical analysis;supervised learning classification;unsupervised learning;vehicle lane change","","","","","","","1-4 Nov. 2016","","IEEE","IEEE Conference Publications"
"An Ensemble Approach for Phenotype Classification Based on Fuzzy Partitioning of Gene Expression Data","A. Dragomir; I. Maraziotis; A. Bezerianos","Department of Medical Physics, University of Patras, 26500 Rio, Greece. email: adragomir@heart.med.upatras.gr","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","5834","5837","We focus on developing a pattern recognition method suitable for performing supervised analysis tasks on molecular data resulting from microarray experiments. Molecular characterization of tissue samples using microarray gene expression profiling is expected to uncover fundamental aspects related to cancer diagnosis and drug discovery. There is therefore a need for reliable, accurate classification methods. With this study we propose a framework for constructing an ensemble of individually trained SVM classifiers, each of them specialized on subsets of the input space. The fuzzy approach used for partitioning the data produces overlapping subsets of the input space that facilitates subsequent classification tasks","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.259348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4463134","","Cancer;Data analysis;Diseases;Gene expression;Machine learning;Performance analysis;Space technology;Support vector machine classification;Support vector machines;Training data","biological tissues;biology computing;data analysis;fuzzy set theory;learning (artificial intelligence);molecular biophysics;pattern classification;support vector machines","SVM classifiers;cancer diagnosis;drug discovery;fuzzy partitioning;microarray gene expression data;molecular characterization;overlapping subsets;pattern recognition method;phenotype classification;supervised analysis tasks;tissue samples","Algorithms;Cluster Analysis;Computational Biology;Drug Design;Fuzzy Logic;Gene Expression Profiling;Gene Expression Regulation, Neoplastic;Humans;Internet;Models, Statistical;Models, Theoretical;Neoplasms;Oligonucleotide Array Sequence Analysis;Pattern Recognition, Automated;Phenotype","1","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"Oving K-Means Clustering using discretization technique in Network Intrusion Detection System","H. M. Tahir; A. M. Said; N. H. Osman; N. H. Zakaria; P. N. '. M. Sabri; N. Katuk","School of Computing, Universiti Utara Malaysia, Malaysia","2016 3rd International Conference on Computer and Information Sciences (ICCOINS)","20161215","2016","","","248","252","Network Intrusion Detection Systems (NIDSs) have always been designed to enhance and improve the network security issue by detecting, identifying, assessing and reporting any unauthorized and illegal network connections and activities. The purpose of this research is to improve on the existing Anomaly Based Intrusion Detection (ABID) method using K-Means clustering technique as to maximize the detection rate and accuracy while minimizing the false alarm. The problem with outliers may disturb the K-Means clustering process as it might be avoided in the clustering process from mixing with the normal data that make the NIDSs become less accurate. Thus this research aims to improve the performance of the ABID systems that balance the loss of information or ignored data in clustering. An integrated machine learning algorithm using K-Means Clustering with discretization technique and Naïve Bayes Classifier (KMC-D+NBC) is proposed against ISCX 2012 Intrusion Detection Evaluation Dataset. The outcome depicts that the proposed method generates better detection rate and accuracy up to 99.3% and 99.5% respectively and reduces the false alarm to 1.2% with better efficiency of 0.03 seconds time taken to build model.","","Electronic:978-1-5090-2549-7; POD:978-1-5090-2550-3; USB:978-1-5090-5144-1","10.1109/ICCOINS.2016.7783222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783222","Discretization Technique;Intrusion Detection System;K-Means Clustering;Naïve Bayes Classifier","Algorithm design and analysis;Clustering algorithms;Computers;Data mining;Intrusion detection;Machine learning algorithms;Training data","computer network security;learning (artificial intelligence);pattern classification;pattern clustering","ABID systems;NIDS;Naïve Bayes classifier;discretization technique;false alarm minimization;illegal network activities;illegal network connections;integrated machine learning;k-means clustering;network intrusion detection system;network security;unauthorized network activities;unauthorized network connections","","","","","","","15-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Impact of Automatic Feature Extraction in Deep Learning Architecture","F. Shaheen; B. Verma; M. Asafuddoula","Centre for Intell. Syst., Central Queensland Univ., Brisbane, QLD, Australia","2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20161226","2016","","","1","8","This paper presents the impact of automatic feature extraction used in a deep learning architecture such as Convolutional Neural Network (CNN). Recently CNN has become a very popular tool for image classification which can automatically extract features, learn and classify them. It is a common belief that CNN can always perform better than other well-known classifiers. However, there is no systematic study which shows that automatic feature extraction in CNN is any better than other simple feature extraction techniques, and there is no study which shows that other simple neural network architectures cannot achieve same accuracy as CNN. In this paper, a systematic study to investigate CNN's feature extraction is presented. CNN with automatic feature extraction is firstly evaluated on a number of benchmark datasets and then a simple traditional Multi-Layer Perceptron (MLP) with full image, and manual feature extraction are evaluated on the same benchmark datasets. The purpose is to see whether feature extraction in CNN performs any better than a simple feature with MLP and full image with MLP. Many experiments were systematically conducted by varying number of epochs and hidden neurons. The experimental results revealed that traditional MLP with suitable parameters can perform as good as CNN or better in certain cases.","","Electronic:978-1-5090-2896-2; POD:978-1-5090-2897-9","10.1109/DICTA.2016.7797053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797053","","Biological neural networks;Computer architecture;Feature extraction;Image classification;Machine learning;Neurons;Training","convolution;feature extraction;image classification;learning (artificial intelligence);multilayer perceptrons","CNN;MLP;convolutional neural network;deep learning architecture;feature extraction;image classification;multilayer perceptron","","","","","","","Nov. 30 2016-Dec. 2 2016","","IEEE","IEEE Conference Publications"
"The Learning Effect of Different Hidden Layers Stacked Autoencoder","Q. Xu; C. Zhang; L. Zhang; Y. Song","Scholl of Mech., Electr. & Eng., Shandong Univ. (Weihai), Weihai, China","2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)","20161215","2016","02","","148","151","Stacked autoencoder is a typical deep neural network. The hidden layers will compress the input data with a better representation than the raw data. Stacked autoencoder has several hidden layers. However, the number of hidden layers is always experiential. In this paper, different hidden layers number autoencoders are discussed. Different depths of stacked autoencoder have different learning capability. The deeper stacked autoencoders have better learning capability which needs more training iterations and time.","","Electronic:978-1-5090-0768-4; POD:978-1-5090-0769-1","10.1109/IHMSC.2016.280","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783808","Autoencoder;deep learning;different hidden layers","Cost function;Machine learning;Neural networks;Training;Unsupervised learning;Visualization","graph theory;learning (artificial intelligence);network theory (graphs);neural nets","deep neural network;hidden layer;learning effect;stacked autoencoder","","","","","","","27-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Deep Learning With Grouped Features for Spatial Spectral Classification of Hyperspectral Images","X. Zhou; S. Li; F. Tang; K. Qin; S. Hu; S. Liu","Chongqing Engineering Laboratory of High Performance Integrated Circuits, College of Communication Engineering, Chongqing University, Chongqing, China","IEEE Geoscience and Remote Sensing Letters","20161229","2017","14","1","97","101","This letter presents a novel deep learning algorithm for feature extraction from the hyperspectral images. The proposed method takes advantage of the knowledge that the features of the spatial-spectral data naturally fall into an array of groups with respect to different spectral bands. Aiming to reduce the influence of redundant spectral bands adaptively using unlabeled hyperspectral data, we incorporate the group information in the training algorithm of the deep neural network via a regularized weight-decay process. Experiments over different benchmarks of hyperspectral images show that the proposed method provides competitive solution with the state-of-the-art approaches.","1545-598X;1545598X","","10.1109/LGRS.2016.2630045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778156","Deep belief network (DBN);deep learning;grouped features;hyperspectral images (HSIs);unlabeled samples","Data models;Feature extraction;Hyperspectral imaging;Machine learning;Standards;Training","feature extraction;geophysical image processing;hyperspectral imaging;image classification;neural nets;remote sensing","deep learning algorithm;deep neural network;feature extraction;hyperspectral image spatial spectral classification;regularized weight-decay process;spatial-spectral data;spectral bands;unlabeled hyperspectral data","","","","","","20161208","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"A Comprehensive Analysis of Deep Learning Based Representation for Face Recognition","M. M. Ghazi; H. K. Ekenel","Fac. of Eng. & Natural Sci., Sabanci Univ., Istanbul, Turkey","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","102","109","Deep learning based approaches have been dominating the face recognition field due to the significant performance improvement they have provided on the challenging wild datasets. These approaches have been extensively tested on such unconstrained datasets, on the Labeled Faces in the Wild and YouTube Faces, to name a few. However, their capability to handle individual appearance variations caused by factors such as head pose, illumination, occlusion, and misalignment has not been thoroughly assessed till now. In this paper, we present a comprehensive study to evaluate the performance of deep learning based face representation under several conditions including the varying head pose angles, upper and lower face occlusion, changing illumination of different strengths, and misalignment due to erroneous facial feature localization. Two successful and publicly available deep learning models, namely VGG-Face and Lightened CNN have been utilized to extract face representations. The obtained results show that although deep learning provides a powerful representation for face recognition, it can still benefit from preprocessing, for example, for pose and illumination normalization in order to achieve better performance under various conditions. Particularly, if these variations are not included in the dataset used to train the deep learning model, the role of preprocessing becomes more crucial. Experimental results also show that deep learning based representation is robust to misalignment and can tolerate facial feature localization errors up to 10% of the interocular distance.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789510","","Databases;Face;Face recognition;Feature extraction;Lighting;Machine learning;Training","face recognition;feature extraction;image representation;learning (artificial intelligence);neural nets","VGG-Face;Wild Faces;YouTube Faces;deep learning based face representation;face recognition;facial feature localization;facial feature localization errors;illumination normalization;interocular distance;lightened CNN;lower face occlusion;upper face occlusion;varying head pose angles","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"SILEA: A system for inductive LEArning","A. Aksoy; M. H. Gunes","Computer Science and Engineering Department, University of Nevada, Reno","2016 7th International Conference on Information, Intelligence, Systems & Applications (IISA)","20161219","2016","","","1","8","This paper presents SILEA (a System for Inductive LEArning), an efficient inductive learning algorithm for rule extraction. SILEA is a covering algorithm which extracts IF-THEN rules from a collection of examples in a reliable way. The algorithm eliminates exhaustive feature selection by reducing the number of attributes(features) to be considered for each necessary iteration of rule extraction. For every iteration, depending on the number of conditions, it prioritizes numerous attributes over the others to reduce the large number of attribute combinations. This prioritization, however, needs to be done attentively to prevent loss in performance or possibly improve it. SILEA employs the entropy measure for such purpose. As the entropy value decreases for an attribute, its predictability increases. SILEA favors the lower entropy-valued attributes for rule extraction. Another important factor in preserving or improving the performance of the algorithm is the rule extraction and selection procedure. SILEA induces every possible rule for the given combination and selects the most classifying ones among them. It also eliminates rules which might become obsolete by the existence of rules with higher classification performance. In conjunction of these two features, i.e., entropy based attribute prioritization and redundant rule elimination, SILEA extracts rules both accurately and efficiently. The paper describes how the algorithm functions along with its features and discusses its performance compared to some of the well-known algorithms in the field on a number of different data sets.","","Electronic:978-1-5090-3429-1; POD:978-1-5090-3430-7","10.1109/IISA.2016.7785430","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785430","","Classification algorithms;Complexity theory;Entropy;Feature extraction;Machine learning algorithms;Measurement;Quantization (signal)","knowledge based systems;learning by example","SILEA;entropy based attribute prioritization;entropy-valued attributes;machine learning techniques;redundant rule elimination;rule extraction procedure;rule selection procedure;system-for-inductive learning","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Deep Convolutional Neural Networks for Predominant Instrument Recognition in Polyphonic Music","Y. Han; J. Kim; K. Lee","Music and Audio Research Group, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20161216","2017","25","1","208","221","Identifying musical instruments in polyphonic music recordings is a challenging but important problem in the field of music information retrieval. It enables music search by instrument, helps recognize musical genres, or can make music transcription easier and more accurate. In this paper, we present a convolutional neural network framework for predominant instrument recognition in real-world polyphonic music. We train our network from fixed-length music excerpts with a single-labeled predominant instrument and estimate an arbitrary number of predominant instruments from an audio signal with a variable length. To obtain the audio-excerpt-wise result, we aggregate multiple outputs from sliding windows over the test audio. In doing so, we investigated two different aggregation methods: one takes the class-wise average followed by normalization, and the other perform temporally local class-wise max-pooling on the output probability prior to averaging and normalization steps to minimize the effect of averaging process suppresses the activation of sporadically appearing instruments. In addition, we conducted extensive experiments on several important factors that affect the performance, including analysis window size, identification threshold, and activation functions for neural networks to find the optimal set of parameters. Our analysis on the instrument-wise performance found that the onset type is a critical factor for recall and precision of each instrument. Using a dataset of 10k audio excerpts from 11 instruments for evaluation, we found that convolutional neural networks are more robust than conventional methods that exploit spectral features and source separation with support vector machines. Experimental results showed that the proposed convolutional network architecture obtained an F1 measure of 0.619 for micro and 0.513 for macro, respectively, achieving 23.1% and 18.8% in performance improvement compared with the state-of-the-art algorithm.","2329-9290;23299290","","10.1109/TASLP.2016.2632307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7755799","Convolutional neural networks;deep learning;instrument recognition;multi-layer neural network;music information retrieval","Convolution;Instruments;Machine learning;Music;Neural networks;Speech;Speech recognition","audio signal processing;music;neural nets;source separation;support vector machines","activation function;analysis window size;audio signal;deep convolutional neural network;fixed-length music excerpt;identification threshold;music information retrieval;predominant instrument recognition;real-world polyphonic music;sliding window;source separation;spectral feature exploitation;support vector machine;temporally local class-wise max-pooling;test audio","","","","","","20161123","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Convolutional neural network for video fire and smoke detection","S. Frizzi; R. Kaabi; M. Bouchouicha; J. M. Ginoux; E. Moreau; F. Fnaiech","Universit&#x00E9; de Toulon, D&#x00E9;partement G&#x00E9;nie Biologie- IUT, 83957 La Garde, France","IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society","20161222","2016","","","877","882","Research on video analysis for fire detection has become a hot topic in computer vision. However, the conventional algorithms use exclusively rule-based models and features vector to classify whether a frame is fire or not. These features are difficult to define and depend largely on the kind of fire observed. The outcome leads to low detection rate and high false-alarm rate. A different approach for this problem is to use a learning algorithm to extract the useful features instead of using an expert to build them. In this paper, we propose a convolutional neural network (CNN) for identifying fire in videos. Convolutional neural network are shown to perform very well in the area of object classification. This network has the ability to perform feature extraction and classification within the same architecture. Tested on real video sequences, the proposed approach achieves better classification performance as some of relevant conventional video fire detection methods and indicates that using CNN to detect fire in videos is very promising.","","Electronic:978-1-5090-3474-1; POD:978-1-5090-3475-8","10.1109/IECON.2016.7793196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7793196","Fire and smoke detection;convolutional neural network;deep learning;dropout;feature maps;max pooling","Biological neural networks;Classification algorithms;Feature extraction;Fires;Image color analysis;Machine learning","computer vision;convolution;feature extraction;image classification;image sequences;learning (artificial intelligence);neural nets;video signal processing","computer vision;convolutional neural network;false-alarm rate;feature extraction;features vector;fire identification;learning algorithm;object classification;rule-based models;smoke detection;video analysis;video fire detection methods;video sequences","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"Using big steps in coordinate descent primal-dual algorithms","P. Bianchi; O. Fercoq","LTCI, CNRS, T&#x00E9;l&#x00E9;com ParisTech, Universit&#x00E9; Paris-Saclay, 75013, France","2016 IEEE 55th Conference on Decision and Control (CDC)","20161229","2016","","","1895","1899","The Vũ-Condat algorithm is a standard method for finding a saddle point of a Lagrangian involving a differentiable function. Recent works have tried to adapt the idea of random coordinate descent to this algorithm, with the aim to efficiently solve some regularized or distributed optimization problems. A drawback of these approaches is that the admissible step sizes can be small, leading to slow convergence. In this paper, we introduce a coordinate descent primal-dual algorithm which is provably convergent for a wider range of step size values than previous methods. In particular, the condition on the step-sizes depends on the coordinate-wise Lipschitz constant of the differentiable function's gradient. We discuss the application of our method to distributed optimization and large scale support vector machine problems.","","DVD:978-1-5090-1844-4; Electronic:978-1-5090-1837-6; POD:978-1-5090-1838-3","10.1109/CDC.2016.7798541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7798541","","Convergence;Cost function;Machine learning algorithms;Minimization;Standards;Support vector machines","optimisation;support vector machines","Lagrangian;Vũ-Condat algorithm;big steps;coordinate descent primal-dual algorithms;coordinate-wise Lipschitz constant;differentiable function;distributed optimization problems;support vector machine","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"FPGA-Based Accelerator for Deep Convolutional Neural Networks for the SPARK Environment","R. Morcel; M. Ezzeddine; H. Akkary","Electr. & Comput. Eng. Dept., American Univ. of Beirut, Beirut, Lebanon","2016 IEEE International Conference on Smart Cloud (SmartCloud)","20161226","2016","","","126","133","Deep Convolutional Neural Networks are known for their high performance. However, their complexity is one of their most challenging aspects. In this paper, we propose a design of an FPGA-based accelerator for the distributed training of convolutional neural networks. The accelerator is intended for use in the SPARK run time environment to accelerate the training of deep convolutional neural networks in the data center. Our accelerator is very energy efficient and achieves 40 to 250 times speedup in the computation of the multi-layer convolution operation, a key operation in the training/inference of deep networks.","","Electronic:978-1-5090-5263-9; POD:978-1-5090-5264-6","10.1109/SmartCloud.2016.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796162","Convolutional Neural Networks;Data Center;FPGA;Reconfigurable Computing;SPARK","Acceleration;Biological neural networks;Feature extraction;Machine learning algorithms;Sparks;Training","field programmable gate arrays;learning (artificial intelligence);neural nets","FPGA-based accelerator;SPARK runtime environment;data center;deep convolutional neural networks;deep network inference;deep network training;field programmable gate array;multilayer convolution operation","","","","","","","18-20 Nov. 2016","","IEEE","IEEE Conference Publications"
"A Semi-supervised SVM Learning Algorithm for Joint Feature Extraction and Classification in Brain Computer Interfaces","Y. Li; C. Guan","Institute for Infocomm Research, Singapore 119613. yqli2@i2r.a-star.edu.sg","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","2570","2573","In machine learning based Brain Computer Interfaces (BCIs), it is a challenge to use only a small amount of labelled data to build a classifier for a specific subject. This challenge was specifically addressed in BCI Competition 2005. Moreover, an effective BCI system should be adaptive to tackle the dynamic variations in brain signal. One of the solutions is to have its parameters adjustable while the system is used online. In this paper we introduce a new semi-supervised support vector machine (SVM) learning algorithm. In this method, the feature extraction and classification are jointly performed in iterations. This method allows us to use a small training set to train the classifier while maintaining high performance. Therefore, the tedious initial calibration process is shortened. This algorithm can be used online to make the BCI system robust to possible signal changes. We analyze two important issues of the proposed algorithm, the robustness of the features to noise and the convergence of algorithm. We applied our method to data from BCI competition 2005, and the results demonstrated the validity of the proposed algorithm","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.260327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4462321","","Adaptive systems;Algorithm design and analysis;Brain computer interfaces;Calibration;Feature extraction;Machine learning;Machine learning algorithms;Noise robustness;Support vector machine classification;Support vector machines","electroencephalography;feature extraction;learning (artificial intelligence);man-machine systems;medical signal processing;support vector machines","BCI;brain computer interface;feature classification;feature extraction;semisupervised SVM learning algorithm;support vector machine;training set","Algorithms;Artificial Intelligence;Brain Mapping;Electroencephalography;Evoked Potentials, Motor;Humans;Imagination;Motor Cortex;Pattern Recognition, Automated;User-Computer Interface","7","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"RadSS: A radiolarian classifier using support vector machines","L. A. Apostol; E. Márquez; P. Gasmen; G. Solano","University of the Philippines, Manila","2016 7th International Conference on Information, Intelligence, Systems & Applications (IISA)","20161219","2016","","","1","6","Radiolarian assemblages have played a significant role as a biostratigraphic and paleoenvironmental tool used in the geological settings. These species can be used in studying sediments lacking calcareous fossils. Easy identification of these species would allow micropaleontologists to proceed further into studying the structure and way of living of these Radiolarians. RaDSS is a decision support system that could help researchers in classifying microphotographs of Radiolarian species through image processing and machine learning algorithms such as SVM.","","Electronic:978-1-5090-3429-1; POD:978-1-5090-3430-7","10.1109/IISA.2016.7785347","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785347","Decision support system;Image processing;Radiolarians;Support Vector Machines","Feature extraction;Geology;Machine learning algorithms;Shape;Support vector machines;Training","biology computing;decision support systems;geology;image classification;learning (artificial intelligence);support vector machines","RadSS;Radiolarian assemblages;Radiolarian species microphotograph classification;SVM;biostratigraphic tool;decision support system;geological settings;image processing algorithm;machine learning algorithm;paleoenvironmental tool;radiolarian classifier;support vector machines","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"SLNSW-UTS: A Historical Image Dataset for Image Multi-Labeling and Retrieval","J. Zhang; J. Zhang; J. Lu; C. Shen; K. Curr; R. Phua; R. Neville; E. Edmonds","Global Big Data Technol. Centre, Univ. of Technol. Sydney, Sydney, NSW, Australia","2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20161226","2016","","","1","6","This paper introduces a dataset of historical images created by the State Library of New South Wales and the University of Technology Sydney (UTS). The dataset has a total of 29713 images with 119 unique labels. Each image contains multiple labels. We use a CNN-based framework to explore the feasibility of our dataset in image multi-labeling and retrieval research, and extract semantic level image features for future research use. The experiment results illustrate that effective deep learning models can be trained on our dataset. We also introduce five applications that can be studied on our historical image dataset.","","Electronic:978-1-5090-2896-2; POD:978-1-5090-2897-9","10.1109/DICTA.2016.7797084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797084","","Automobiles;Feature extraction;Libraries;Machine learning;Neural networks;Semantics;Training","academic libraries;image retrieval;research libraries","CNN-based framework;SLNSW-UTS;State Library of New South Wales;University of Technology Sydney;deep learning models;historical image dataset;historical images;image multilabeling;image retrieval;retrieval research;semantic level image features","","","","","","","Nov. 30 2016-Dec. 2 2016","","IEEE","IEEE Conference Publications"
"Constraint data mining using apriori algorithm with AND operation","S. K. Shankar; A. Kaur","Department of Computer Science and Engineering Lovely Professional University, Phagwara, Punjab, India","2016 IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","20170109","2016","","","1025","1029","Data mining is one of the most important steps in knowledge discovery. Apriori algorithm is the most used one in this process. The major drawback with Apriori algorithm is of time and space. It generates numerous uninteresting itemsets which lead to generate various rules which are of completely of no use. The two factors considered for association rules generation are Minimum Support Threshold and Minimum Confidence Threshold. However, constraint mining reduces these two limitations of Apriori algorithm to a considerable extent. This paper uses constraint mining and AND operation between MST and MCT to prune itemsets generated in each iteration. The overall performance has been increased and simulated in this paper through various figures from simulation result.","","Electronic:978-1-5090-0774-5; POD:978-1-5090-0775-2","10.1109/RTEICT.2016.7807985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807985","MCT;MST;apriori algorithm;constrained data mining;constraint data mining;data mining","Algorithm design and analysis;Conferences;Data mining;Fuzzy logic;Genetic algorithms;Itemsets;Machine learning algorithms","constraint handling;data mining","AND operation;MCT;MST;apriori algorithm;association rules generation;constraint data mining;knowledge discovery;minimum confidence threshold;minimum support threshold","","","","","","","20-21 May 2016","","IEEE","IEEE Conference Publications"
"Authorship categorization of public domain literature","T. Boran; J. Voss; M. S. Hossain","Computer Science Department, Southern Connecticut State University, New Haven, CT 06515","2016 IEEE 7th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","20161212","2016","","","1","7","We defined a set of quantifiable features for authorship categorization. We performed our experiments on public domain literature - all books analyzed were obtained in plain text format through Project Gutenberg's online repository of classic books. We tested three machine learning algorithms: Artificial Neural Network, Naïve Bayes Classifier, and Support Vector Machine with our features. We found that certain features, such as punctuation and various suffixes result in a higher accuracy. In addition, the Support Vector Machine classifier produces repeatedly higher accuracies than other classifiers and seems to be a far superior method of classification in terms of authorship categorization.","","Electronic:978-1-5090-1496-5; POD:978-1-5090-1497-2","10.1109/UEMCON.2016.7777898","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7777898","Authorship categorization;classification;public domain literature;support vector machine","Artificial neural networks;Classification algorithms;Computer science;Electronic mail;Feature extraction;Machine learning algorithms;Support vector machines","Bayes methods;electronic publishing;literature;neural nets;pattern classification;support vector machines","Naive Bayes classifier;Project Gutenberg online repository;artificial neural network;authorship categorization;machine learning algorithms;plain text format;public domain literature;quantifiable feature set;support vector machine classifier","","","","","","","20-22 Oct. 2016","","IEEE","IEEE Conference Publications"
"The Deep Learning Vision for Heterogeneous Network Traffic Control: Proposal, Challenges, and Future Perspective","N. Kato; Z. M. Fadlullah; B. Mao; F. Tang; O. Akashi; T. Inoue; K. Mizutani","","IEEE Wireless Communications","","2017","PP","99","2","9","Recently, deep learning, an emerging machine learning technique, is garnering a lot of research attention in several computer science areas. However, to the best of our knowledge, its application to improve heterogeneous network traffic control (which is an important and challenging area by its own merit) has yet to appear because of the difficult challenge in characterizing the appropriate input and output patterns for a deep learning system to correctly reflect the highly dynamic nature of large-scale heterogeneous networks. In this vein, in this article, we propose appropriate input and output characterizations of heterogeneous network traffic and propose a supervised deep neural network system. We describe how our proposed system works and how it differs from traditional neural networks. Also, preliminary results are reported that demonstrate the encouraging performance of our proposed deep learning system compared to a benchmark routing strategy (Open Shortest Path First (OSPF)) in terms of significantly better signaling overhead, throughput, and delay.","1536-1284;15361284","","10.1109/MWC.2016.1600317WC","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792369","","Google;Heterogeneous networks;Machine learning;Neural networks;Routing;Speech recognition;Telecommunication traffic","","","","","","","","20161220","","","IEEE","IEEE Early Access Articles"
"ANASTASIA: ANdroid mAlware detection using STatic analySIs of Applications","H. Fereidooni; M. Conti; D. Yao; A. Sperduti","Univ. of Padua, Padua, Italy","2016 8th IFIP International Conference on New Technologies, Mobility and Security (NTMS)","20161222","2016","","","1","5","The number of malware applications targeting the Android operating system has significantly increased in recent years. Malicious applications pose a significant threat to Android platform security. We propose ANASTASIA, a system to detect malicious Android applications through statically analyzing applications' behaviors. ANASTASIA provides a more complete coverage of security behaviors when compared to state-of-the-art solutions. We utilize a large number of statically extracted features from various security behavioral characteristics of an application. We built a Machine Learning-based detection framework with high performance detection and acceptable false positive rate. The significance of our work is to develop a lightweight malware detection system for Android-powered smartphones that leverages robust, effective, and efficient features. Besides, in order to assess our solution, we used a reliable, large-scale, and updated malware data-set in terms of diversity and number of malware applications. We evaluated the performance of our proposal on large-scale malware data-set (including 18,677 malware and 11,187 benign apps). Our experimental results show a true positive rate of 97.3% and a false negative rate of 2.7%. These results are better than what are reported by state-of-the-art Android malware detection methods.","","Electronic:978-1-5090-2914-3; POD:978-1-5090-2915-0","10.1109/NTMS.2016.7792435","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792435","","Androids;Feature extraction;Humanoid robots;Machine learning;Malware;Security;Smart phones","Android (operating system);feature extraction;invasive software;learning (artificial intelligence);program diagnostics;smart phones","ANASTASIA;Android malware detection using static analysis of applications;Android operating system;Android platform security;Android-powered smartphones;application behavior analysis;feature extraction;machine learning-based detection;malware dataset","","","","","","","21-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"On Distributed Deep Network for Processing Large-Scale Sets of Complex Data","Q. Chao; G. Xiao-Guang; C. Da-Qing","Sch. of Electron. & Inf., Northwestern Polytech. Univ., Xi'an, China","2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)","20161215","2016","01","","395","399","Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with hundreds of parameters using distributed CPU cores. We have developed Bagging-Down SGD algorithm to solve the distributing problems. Bagging-Down SGD introduces the parameter server adding on the several model replicas, and separates the updating and the training computing to accelerate the whole system. We have successfully used our system to train a distributed deep network, and achieve stateof-the-art performance on MINIST, a visual handwriting font library. We show that these techniques dramatically accelerate the training of this kind of distributed deep network.","","Electronic:978-1-5090-0768-4; POD:978-1-5090-0769-1","10.1109/IHMSC.2016.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783637","Bagging-Down SGD;Distributed Deep Network;Parameter server","Computational modeling;Data models;Machine learning;Monitoring;Servers;Speech recognition;Training","data handling;gradient methods;microprocessor chips;stochastic processes;unsupervised learning","Bagging-Down SGD algorithm;MINIST;deep learning;distributed CPU cores;distributed deep network;large-scale complex data set processing;model replicas;parameter server;unsupervised feature learning;visual handwriting font library","","","","","","","27-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Dense Semantic Labeling of Subdecimeter Resolution Images With Convolutional Neural Networks","M. Volpi; D. Tuia","MultiModal Remote Sensing Group, University of Zurich, Z&#x00FC;rich, Switzerland","IEEE Transactions on Geoscience and Remote Sensing","20161229","2017","55","2","881","893","Semantic labeling (or pixel-level land-cover classification) in ultrahigh-resolution imagery (<;10 cm) requires statistical models able to learn high-level concepts from spatial data, with large appearance variations. Convolutional neural networks (CNNs) achieve this goal by learning discriminatively a hierarchy of representations of increasing abstraction. In this paper, we present a CNN-based system relying on a downsample-then-upsample architecture. Specifically, it first learns a rough spatial map of high-level representations by means of convolutions and then learns to upsample them back to the original resolution by deconvolutions. By doing so, the CNN learns to densely label every pixel at the original resolution of the image. This results in many advantages, including: 1) the state-of-the-art numerical accuracy; 2) the improved geometric accuracy of predictions; and 3) high efficiency at inference time. We test the proposed system on the Vaihingen and Potsdam subdecimeter resolution data sets, involving the semantic labeling of aerial images of 9- and 5-cm resolution, respectively. These data sets are composed by many large and fully annotated tiles, allowing an unbiased evaluation of models making use of spatial information. We do so by comparing two standard CNN architectures with the proposed one: standard patch classification, prediction of local label patches by employing only convolutions, and full patch labeling by employing deconvolutions. All the systems compare favorably or outperform a state-of-the-art baseline relying on superpixels and powerful appearance descriptors. The proposed full patch labeling CNN outperforms these models by a large margin, also showing a very appealing inference time.","0196-2892;01962892","","10.1109/TGRS.2016.2616585","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725499","Aerial images;classification;convolutional neural networks (CNNs);deconvolution networks;deep learning;semantic labeling;subdecimeter resolution","Data models;Feature extraction;Image resolution;Labeling;Machine learning;Remote sensing;Semantics","geophysical image processing;image classification;land cover;neural nets;remote sensing;semantic Web","CNN-based system;Potsdam subdecimeter resolution dataset;Vaihingen subdecimeter resolution dataset;aerial images;convolutional neural network;patch labeling;pixel-level land cover classification;semantic labeling;standard patch classification;statistical model;subdecimeter resolution images;ultrahigh-resolution imagery","","","","","","20161028","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"A supervised no-reference QOE assessment model on IPTV services","Q. Chen; Y. Jin; T. Yang","State Key Laboratory of Network and Switching Technology, Beijing 100876, China","2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS)","20161219","2016","","","272","277","This paper presents a supervised no-reference model for QoE assessment on IPTV services. MOS_V (Mean Opinion Score for Video) which has five levels is recommended as subjective assessment indicator, while MDI (media delivery index), PCR (program clock reference) as well as MR (media rate) are recommended as objective assessment indicators. Collecting and using both of them to build the prediction model is remarkable. The basic decision classification trees in C4.5 algorithm and Random Forests are chosen to build the model. Based on them, two innovative measures are proposed to improve model accuracy. Considering uneven rating levels of people, an adaptive rating modification algorithm is put forward for MOS_V to adjust all rating levels to the same value coordinate system. Besides, owing to coarse granularity of traditional MOS_V, we adjust classification width and fault tolerance rate correspondingly. The experimental results show that the model outperforms traditional methods which only apply machine learning methods in prediction accuracy.","","CD:978-1-5090-1254-1; Electronic:978-1-5090-1256-5; POD:978-1-5090-1257-2","10.1109/CCIS.2016.7790268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7790268","Adaptive rating modification;Classification width adjustment;IPTV;MOS_V;QoE Assessment","Adaptation models;Classification algorithms;IPTV;Learning systems;Machine learning algorithms;Prediction algorithms;Streaming media","IPTV;decision trees;fault tolerant computing;learning (artificial intelligence);pattern classification;quality of experience","C4.5 algorithm;IPTV services;MDI;MOS-V;MR;PCR;adaptive rating modification algorithm;classification width;coarse granularity;decision classification trees;fault tolerance rate;machine learning method;mean opinion score-for-video;media delivery index;media rate;objective assessment indicators;program clock reference;subjective assessment indicator;supervised no-reference QOE assessment model;uneven people rating level;value coordinate system","","","","","","","17-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Boost up the detection sensitivity of ASL perfusion fMRI through support vector machine","Z. Wang; A. R. Childress; J. A. Detre","Center for Functional Neuroimaging, Department of Neurology, Philadelphia, PA 19104.","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","1006","1009","Data analysis is challenging in arterial spin labeling (ASL) perfusion fMRI due to the intrinsic low SNR of ASL data. To boost up the detection sensitivity, this paper presented a multivariate method based group analysis approach to analyze ASL perfusion fMRI data. A spatial discriminance map (SDM) was first extracted for each subject by support vector machine learning (SVM) algorithm; a population inference about the discriminance was then given by a random effect analysis (RFX) on these individual SDMs. Evaluations were performed using 7 subjects' fingertapping ASL perfusion fMRI data, yielding similar activation patterns with enhanced sensitivity compared to the standard GLM based group analysis","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.260382","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4461924","","Algorithm design and analysis;Data analysis;Data mining;Inference algorithms;Labeling;Machine learning;Machine learning algorithms;Pattern analysis;Performance evaluation;Support vector machines","biomedical MRI;blood vessels;brain;inference mechanisms;learning (artificial intelligence);medical computing;neurophysiology;support vector machines","ASL perfusion fMRI;GLM;SNR;arterial spin labeling;detection sensitivity;fingertapping;group analysis approach;multivariate method;population inference;random effect analysis;spatial discriminance map;support vector machine","Algorithms;Artificial Intelligence;Brain;Brain Mapping;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Magnetic Resonance Imaging;Pattern Recognition, Automated;Perfusion;Reproducibility of Results;Sensitivity and Specificity;Spin Labels","","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"A comparison of deep learning and hand crafted features in medical image modality classification","S. Khan; S. P. Yong","Computer and Information Sciences Department, Universiti Teknologi PETRONAS, Malaysia","2016 3rd International Conference on Computer and Information Sciences (ICCOINS)","20161215","2016","","","633","638","Modality corresponding to medical images is a vital filter in medical image retrieval systems, as radiologists or physicians are interested in only one of radiology images e.g CT scan, MRI, X-ray. Various handcrafted feature schemes have been proposed for medical image modality classification. On the other hand not enough attempts have been made for deep learned feature extraction. A comparative evaluation of both handcrafted and deep learned features for medical image modality classification is presented in this paper. The experiments are performed on IMAGECLEF 2012 data. After carrying out the experiments it is shown that the handcrafted features outperforms the deep learned features and shows the potential of handcrafted feature extraction models in the medical image field.","","Electronic:978-1-5090-2549-7; POD:978-1-5090-2550-3; USB:978-1-5090-5144-1","10.1109/ICCOINS.2016.7783289","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783289","Feature representations;deep learned features;handcrafted features;modality classification","Biomedical imaging;Computer architecture;Computers;Feature extraction;Machine learning;Visualization","feature extraction;image classification;image retrieval;learning (artificial intelligence);medical image processing;radiology","IMAGECLEF 2012 data;deep learned feature extraction;hand crafted features;handcrafted feature extraction models;medical image modality classification;medical image retrieval systems;radiology images","","","","","","","15-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Sparse Wavelet Auto-Encoders for Image Classification","S. Hassairi; R. Ejbali; M. Zaied","REGIM-Lab., Univ. of Sfax, Sfax, Tunisia","2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20161226","2016","","","1","6","The goal of the Deep learning methods is learning feature hierarchies with features from higher levels to lower level features of the hierarchy. The major contribution of this paper is to show how to extract features and train an image classification system on large-scale datasets. This method is an improvement of our recent work. The training is carried out by the combination of the most used methods for image classification: Deep Learning and the Wavelet Network. Some algorithms of DL like the sparse coding and the stacked autoencoders are used in our approach. For the WN, the Fast Wavelet Transform and the Best Contribution Algorithm are utilized. The ImageNet dataset used in the test phase in which we used many criteria such as the number of the hidden layers and the number of images that we specified for the training shows great efficiency of our model for image classification compared to another approach.","","Electronic:978-1-5090-2896-2; POD:978-1-5090-2897-9","10.1109/DICTA.2016.7797085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797085","","Classification algorithms;Encoding;Feature extraction;Image classification;Machine learning;Training;Wavelet transforms","feature extraction;image classification;learning (artificial intelligence);wavelet neural nets;wavelet transforms","ImageNet dataset;best contribution algorithm;deep learning method;fast wavelet transform;feature extraction;feature hierarchy learning;image classification system training;sparse coding;sparse wavelet autoencoder;stacked autoencoders;wavelet network","","","","","","","Nov. 30 2016-Dec. 2 2016","","IEEE","IEEE Conference Publications"
"Semantic video search by automatic video annotation using TensorFlow","K. Ashangani; K. U. Wickramasinghe; D. W. N. De Silva; V. M. Gamwara; A. Nugaliyadde; Y. Mallawarachchi","Department of Information Technology, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka","2016 Manufacturing & Industrial Engineering Symposium (MIES)","20161226","2016","","","1","4","The paper discusses a tool for video structure analysis, feature extraction, classification and semantic querying suitable for an extremely broad scale of video data set. The tool analyses the video structure to detect shot boundaries where shots in each video are identified using image duplication techniques. A single frame from each shot is passed to a deep learning model implemented using TensorFlow, that is trained for feature extraction and classification of objects in each frame. Subsequently, an automatic textual annotation is generated for each video and finally with the aid of ontology, semantic searching is done using NLP, which allows receiving an efficient result other than manual video annotation of a large scale dataset. While maintaining accurate querying with automatic video content analysis and annotation with semantic searching with around seventy-four percent accuracy rate, this becomes a useful tool in video tagging and annotation.","","Electronic:978-1-5090-3629-5; POD:978-1-5090-3630-1","10.1109/MIES.2016.7779985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779985","Deep Learning;Ontology;Tensorflow;Video Structure Analysis","Animals;Fingerprint recognition;Machine learning;Neural networks;Object detection;Ontologies;Semantics","feature extraction;image annotation;ontologies (artificial intelligence);video signal processing","TensorFlow;automatic textual annotation;automatic video content analysis;automatic video content annotation;deep learning;emantic video search;feature classification;feature extraction;image duplication;large scale dataset;ontology;semantic querying;semantic searching;shot boundaries;video data set;video structure analysis","","","","","","","22-22 Oct. 2016","","IEEE","IEEE Conference Publications"
"Optimization Research and Application of Unbalanced Data Set Multi-classification Algorithm","L. Ren; W. Zhou","Sch. of Mechatron. Eng. & Autom., Shanghai Univ., Shanghai, China","2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)","20161215","2016","02","","39","42","This paper studied multi-classification algorithm of unbalanced data. The conventional classifier often directly expands dichotomy algorithm to multi-classification in dealing with unbalanced data multi-classification without paying attention to the relationship among data. According to the effect of data relationship on SVM algorithm improvement, this paper proposed a spatial extension-based SVM algorithm, which can optimize classifier and improve classification accuracy of minority sample data. Finally, the validity of modified algorithm was verified through data set.","","Electronic:978-1-5090-0768-4; POD:978-1-5090-0769-1","10.1109/IHMSC.2016.272","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783782","SVM;data mining;multi-classification;unbalanced data set","Algorithm design and analysis;Classification algorithms;Data mining;Indexes;Machine learning algorithms;Support vector machines;Training","pattern classification;support vector machines","minority sample data;spatial extension-based SVM algorithm;support vector machine;unbalanced data set multiclassification algorithm","","","","","","","27-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Global convergence rate of incremental aggregated gradient methods for nonsmooth problems","N. D. Vanli; M. Gurbuzbalaban; A. Ozdaglar","Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, 02139, USA","2016 IEEE 55th Conference on Decision and Control (CDC)","20161229","2016","","","173","178","We analyze the proximal incremental aggregated gradient (PIAG) method for minimizing the sum of a large number of smooth component functions f(x) = Σ<sub>i=1</sub><sup>m</sup> f<sub>i</sub>(x) and a convex function r(x). Such composite optimization problems arise in a number of machine learning applications including regularized regression problems and constrained distributed optimization problems over sensor networks. Our method computes an approximate gradient for the function f(x) by aggregating the component gradients evaluated at outdated iterates over a finite window K and uses a proximal operator with respect to the regularization function r(x) at the intermediate iterate obtained by moving along the approximate gradient. Under the assumptions that f(x) is strongly convex and each f<sub>i</sub>(x) is smooth with Lipschitz gradients, we show the first linear convergence rate result for the PIAG method and provide explicit convergence rate estimates that highlight the dependence on the condition number of the problem and the size of the window K over which outdated component gradients are evaluated.","","DVD:978-1-5090-1844-4; Electronic:978-1-5090-1837-6; POD:978-1-5090-1838-3","10.1109/CDC.2016.7798265","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7798265","","Additives;Algorithm design and analysis;Convergence;Gradient methods;Linear programming;Machine learning algorithms","convergence of numerical methods;gradient methods;mathematical operators;minimisation","Lipschitz gradients;PIAG method;composite optimization problems;convex function;distributed optimization problems;global convergence rate;linear convergence rate;machine learning;proximal incremental aggregated gradient method;proximal operator;regression problems;regularization function;sensor networks","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"Cancer Classification Using Loss of Heterozygosity Data Derived from Single-Nucleotide Polymorphism Genotyping Arrays","Y. Wang","Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX 75205, USA. yuhangw@engr.smu.edu","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","5864","5867","Single-Nucleotide Polymorphism (SNP) array is a recently introduced technology that genotypes more than 10,000 human SNPs on a single array. It has been shown that genome-wide Loss of Heterozygosity (LOH) calls can be derived by analyzing the genotypes calls measured by SNP arrays using paired tumor and normal tissue samples. The goal of this study is to evaluate the possibility of cancer classification using LOH calls. As a proof of concept, we applied 16 different combinations of classification algorithms and feature selection algorithms to a public data set that contains LOH calls of 10,043 SNP loci obtained from 10 breast cancer patients and 5 small cell lung cancer (SCLC) patients. Performance was measured in terms of the leave-one-out cross-validation (LOOCV) classification accuracy. Experimental results suggest that LOH calls derived from SNP arrays can be an excellent indicator of cancer type","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.260116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4463141","","Bioinformatics;Cancer;Classification algorithms;Gene expression;Genomics;Humans;Loss measurement;Machine learning;Machine learning algorithms;Neoplasms","cancer;cellular biophysics;genetics;gynaecology;learning (artificial intelligence);medical computing;molecular biophysics;pattern classification;polymorphism;support vector machines;tumours","breast cancer classification;feature selection algorithm;genome;genotype analysis;human single-nucleotide polymorphism genotyping arrays;leave-one-out cross-validation classification accuracy;loss-of-heterozygosity data;machine learning;normal tissue samples;paired tumor;public data set;small cell lung cancer patient;support vector machine","Algorithms;Bayes Theorem;Breast Neoplasms;Carcinoma, Small Cell;Computational Biology;Genome;Genotype;Humans;Loss of Heterozygosity;Lung Neoplasms;Models, Statistical;Neoplasms;Polymorphism, Single Nucleotide;Reproducibility of Results;Software","1","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"Detecting Packed Executable File: Supervised or Anomaly Detection Method?","N. Hubballi; H. Dogra","Sch. of Eng., Discipline of Comput. Sci. & Eng., Indian Inst. of Technol. Indore, Indore, India","2016 11th International Conference on Availability, Reliability and Security (ARES)","20161215","2016","","","638","643","Executable packing is an evasion technique used to propagate malware in the wild. Packing uses compression and/or encryption to thwart static analysis. There are universal unpackers available which can extract original binary from any type of packer, however they are computationally expensive as they are based on dynamic analysis which requires malware execution. A possible approach is to use machine learning techniques for classifying whether an executable is packed or not packed. Although supervised machine learning methods are good at learning packer specific features, these require collecting data from each packer and extracting features specific to it which may not be feasible practically. In this paper we propose a semi-supervised technique and an anomaly based detection method to identify packed executable files. We measure the distance between representative generated from a packed and non-packed binary training data and estimate the class based on its nearest distance in semi-supervised method. In anomaly detection we generate a representative cluster from known non-packed samples and find the radius of cluster and compare the distance of a test executable with that of radius to decide either it as normal or packed one. We experiment with few distance measures and report detection performance of these methods on two datasets.","","Electronic:978-1-5090-0990-9; POD:978-1-5090-0991-6; USB:978-1-5090-0989-3","10.1109/ARES.2016.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7784628","","Cryptography;Entropy;Feature extraction;Machine learning algorithms;Malware;Mathematical model;Training","cryptography;invasive software;learning (artificial intelligence)","anomaly detection method;dynamic analysis;encryption;malware execution;nonpacked binary training data;packed binary training data;packed executable file detection;representative cluster;semi-supervised technique;static analysis;supervised detection method;supervised machine learning methods","","","","","","","Aug. 31 2016-Sept. 2 2016","","IEEE","IEEE Conference Publications"
"Towards an “In-the-Wild” Emotion Dataset Using a Game-Based Framework","W. Li; F. Abtahi; C. Tsangouri; Z. Zhu","Dept. of Electr. Eng., CUNY City Coll., New York, NY, USA","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","1526","1534","In order to create an ""in-the-wild"" dataset of facial emotions with large number of balanced samples, this paper proposes a game-based data collection framework. The framework mainly include three components: a game engine, a game interface, and a data collection and evaluation module. We use a deep learning approach to build an emotion classifier as the game engine. Then a emotion web game to allow gamers to enjoy the games, while the data collection module obtains automatically-labelled emotion images. Using our game, we have collected more than 15,000 images within a month of the test run and built an emotion dataset ""GaMo"". To evaluate the dataset, we compared the performance of two deep learning models trained on both GaMo and CIFE. The results of our experiments show that because of being large and balanced, GaMo can be used to build a more robust emotion detector than the emotion detector trained on CIFE, which was used in the game engine to collect the face images.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789680","","Data collection;Detectors;Emotion recognition;Face;Games;Machine learning;Weapons","computer games;data handling;emotion recognition;face recognition;image classification","CIFE;GaMo;deep learning approach;emotion classifier;face images;facial emotions;game engine;game interface;game-based data collection framework;in-the-wild emotion dataset;robust emotion detector","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Stereoscopic images quality assessment based on deep learning","K. Wang; J. Zhou; N. Liu; X. Gu","Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","2016 Visual Communications and Image Processing (VCIP)","20170105","2016","","","1","4","With the popularity of stereoscopic 3D (S3D) images and videos, many advanced objective quality assessment methods have been proposed to evaluate viewers' Quality of Experience (QoE). Among them, most algorithms take advantages of the disparity maps to extract useful features. On the other hand, deep learning has been one of the hottest research topics during these years, but limited efforts focused on the field in objective quality evaluation of S3D images. In this paper, we propose a S3D image quality assessment (S3D IQA) method based on deep learning. In this method, the Convolutional Restricted Boltzmann Machines (CRBM) combined with Factored Third-Order RBM (FTO-RBM) is considered as learning model to extract feature maps from pre-processed left and right images automatically. Then an improved traversal algorithm based on two pooling strategies is put forward to optimize extracted feature maps, which improves the final quality assessment performance significantly. Experimental results show that our S3D IQA method achieves good performance on 3D databases tested.","","Electronic:978-1-5090-5316-2; POD:978-1-5090-5317-9","10.1109/VCIP.2016.7805431","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805431","Convolutional Restricted Boltzmann Machines (CRBM);Deep Learning;Factored Third-Order RBM (FTO-RBM);Optimized Feature Maps;Stereoscopic Image Quality Assessment","Data preprocessing;Databases;Feature extraction;Image quality;Machine learning;Three-dimensional displays;Training","Boltzmann machines;feature extraction;learning (artificial intelligence);quality of experience;stereo image processing;visual perception","3D databases;CRBM;FTO-RBM;QoE;S3D IQA method;S3D image quality assessment method;advanced objective quality assessment methods;convolutional restricted Boltzmann machines;deep learning;disparity maps;factored third-order RBM;feature map extraction;improved traversal algorithm;pooling strategies;quality assessment performance improvement;quality of experience;stereoscopic 3D images;stereoscopic 3D videos;stereoscopic image quality assessment","","","","","","","27-30 Nov. 2016","","IEEE","IEEE Conference Publications"
"Travel time prediction with LSTM neural network","Yanjie Duan; Yisheng Lv; Fei-Yue Wang","The State Key Laboratory of Management and Control for Complex Systems Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China","2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)","20161226","2016","","","1053","1058","Travel time is one of the key concerns among travelers before starting a trip and also an important indicator of traffic conditions. However, travel time acquisition is time delayed and the pattern of travel time is usually irregular. In this paper, we explore a deep learning model, the LSTM neural network model, for travel time prediction. By employing the travel time data provided by Highways England, we construct 66 series prediction LSTM neural networks for the 66 links in the data set. Through model training and validation, we obtain the optimal structure within the setting range for each link. Then we predict multi-step ahead travel times for each link on the test set. Evaluation results show that the 1-step ahead travel time prediction error is relatively small, the median of mean relative error for the 66 links in the experiments is 7.0% on the test set. Deep learning models considering sequence relation are promising in traffic series data prediction.","","Electronic:978-1-5090-1889-5; POD:978-1-5090-1890-1; USB:978-1-5090-1888-8","10.1109/ITSC.2016.7795686","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795686","","Logic gates;Machine learning;Predictive models;Real-time systems;Recurrent neural networks;Roads","intelligent transportation systems;learning (artificial intelligence);neural nets;prediction theory;traffic information systems","ITS;LSTM neural network;deep learning model;intelligent transportation system;traffic information;travel time prediction","","","","","","","1-4 Nov. 2016","","IEEE","IEEE Conference Publications"
"Image understanding for global lifelog media cloud","H. Song; Y. H. Lee; M. S. Ko; I. K. Choi; J. Yoo","Korea Electronics Technology Institute","2016 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)","20170105","2016","","","1","2","We implemented media lifelog system with highlighting system with image analysis, video analysis and audio segmentation modules. Image analysis module has image classification, saliency region detection, face detection and facial expression recognition process. Video analysis module has cut detection and key frame detection process. And the result images of key frame detection is used as the input of image analysis module. Audio analysis module has audio segmentation process. ImageNet data is used for training and test database. The image classification accuracy is 83%. Automatic cut detection F1 score is 0.70. Cut detection F1 score is 0.80. Audio segmentation F score is 0.53. And facial expression recognition precision rate is 94.8% at 0.756 sec on a mobile phone.","","Electronic:978-1-5090-2743-9; POD:978-1-5090-2744-6","10.1109/ICCE-Asia.2016.7804830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804830","Contents understanding;Deep learning;Expression recognition;Media cloud;Saliency","Face recognition;Image classification;Image segmentation;Machine learning;Media;Speech recognition","audio signal processing;face recognition;image classification;image segmentation;video signal processing","ImageNet data;audio segmentation modules;audio segmentation process;automatic cut detection F1 score;face detection process;facial expression recognition process;global lifelog media cloud;image analysis;image classification;image understanding;key frame detection process;media lifelog system;saliency region detection;video analysis module","","","","","","","26-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Diagnosis of Brain Abnormality Using both Structural and Functional MR Images","Y. Fan; H. Rao; J. Giannetta; H. Hurt; J. Wang; C. Davatzikos; D. Shen","Section of Biomedical Image Analysis (SBIA), Department of Radiology, University of Pennsylvania, 3600 Market Street, Suite 380, Philadelphia, PA 19104, USA. e-mail: yong.fan@uphs.upenn.edu","2006 International Conference of the IEEE Engineering in Medicine and Biology Society","20161215","2006","","","1044","1047","A number of neurological diseases are associated with structural and functional alterations in the brain. This paper presents a method of using both structural and functional MR images for brain disease diagnosis, by machine learning and high-dimensional template warping. First, a high-dimensional template warping technique is used to compute morphological and functional representations for each individual brain in a template space, within a mass preserving framework. Then, statistical regional features are extracted to reduce the dimensionality of morphological and functional representations, as well as to achieve the robustness to registration errors and inter-subject variations. Finally, the most discriminative regional features are selected by a hybrid feature selection method for brain classification, using a nonlinear support vector machine. The proposed method has been applied to classifying the brain images of prenatally cocaine-exposed young adults from those of socioeconomically matched controls, resulting in 91.8% correct classification rate using a leave-one-out cross-validation. Comparison results show the effectiveness of our method and also the importance of simultaneously using both structural and functional images for brain classification","1557-170X;1557170X","CD:1-4244-003303; Paper:1-4244-0032-5","10.1109/IEMBS.2006.259260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4461934","","Brain;Diseases;Feature extraction;Image analysis;Image classification;Machine learning;Pediatrics;Principal component analysis;Support vector machine classification;Support vector machines","biomedical MRI;brain;diseases;feature extraction;image classification;image registration;image representation;learning (artificial intelligence);medical image processing;neurophysiology;statistical analysis;support vector machines","brain abnormality diagnosis;brain classification;functional MR images;functional representations;high-dimensional template warping technique;hybrid feature selection method;inter-subject variations;leave-one-out cross-validation;machine learning;morphological representations;neurological diseases;nonlinear support vector machine;prenatally cocaine-exposed adults;registration errors;socioeconomically matched controls;statistical regional feature extraction;structural MR images","Adolescent;Brain;Brain Diseases;Cocaine;Female;Humans;Image Interpretation, Computer-Assisted;Magnetic Resonance Imaging;Male;Pattern Recognition, Automated;Pregnancy;Prenatal Exposure Delayed Effects;Reproducibility of Results;Sensitivity and Specificity","1","","","","","Aug. 30 2006-Sept. 3 2006","","IEEE","IEEE Conference Publications"
"Correction to “Scalable High-Performance Image Registration Framework by Unsupervised Deep Feature Representations Learning” [Jul 16 1505-1516]","G. Wu; M. Kim; Q. Wang; B. C. Munsell; D. Shen","Department of Radiology and BRIC, The University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Biomedical Engineering","20161220","2017","64","1","250","250","Presents corrections to the paper, ""Scalable high performance image registration framework by unsupervised deep feature representations"", (Wu, G. et al.), IEEE Trans. Biomed. Eng., vol. 63, no. 7, pp. 1505–1516, Jul. 2016.","0018-9294;00189294","","10.1109/TBME.2016.2633139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792251","","Image registration;Machine learning;Scalability;Unsupervised learning","","","","","","","","","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"A deep learning approach to flight delay prediction","Y. J. Kim; S. Choi; S. Briceno; D. Mavris","Aerospace Systems Design Laboratory, Georgia Institute of Technology, Atlanta, Georgia 30332-0150","2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)","20161212","2016","","","1","6","Deep learning has achieved significant improvement in various machine learning tasks including image recognition, speech recognition, machine translation and etc. Inspired by the huge success of the paradigm, there have been lots of tries to apply deep learning algorithms to data analytics problems with big data including traffic flow prediction. However, there has been no attempt to apply the deep learning algorithms to the analysis of air traffic data. This paper investigates the effectiveness of the deep learning models in the air traffic delay prediction tasks. By combining multiple models based on the deep learning paradigm, an accurate and robust prediction model has been built which enables an elaborate analysis of the patterns in air traffic delays. In particular, Recurrent Neural Networks (RNN) has shown its great accuracy in modeling sequential data. Day-to-day sequences of the departure and arrival flight delays of an individual airport have been modeled by the Long Short-Term Memory RNN architecture. It has been shown that the accuracy of RNN improves with deeper architectures. In this study, four different ways of building deep RNN architecture are also discussed. Finally, the accuracy of the proposed prediction model was measured, analyzed and compared with previous prediction methods. It shows best accuracy compared with all other methods.","","Electronic:978-1-5090-2523-7; POD:978-1-5090-2524-4","10.1109/DASC.2016.7778092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778092","","Airports;Atmospheric modeling;Computational modeling;Computer architecture;Delays;Machine learning;Meteorology","Big Data;air traffic;data analysis;learning (artificial intelligence);recurrent neural nets","Big Data;air traffic data analysis;air traffic delay prediction tasks;data analytics;day-to-day sequences;deep RNN architecture;deep learning;flight delay prediction;long short-term memory RNN architecture;machine learning;recurrent neural networks;robust prediction model;sequential data modeling;traffic flow prediction","","","","","","","25-29 Sept. 2016","","IEEE","IEEE Conference Publications"
