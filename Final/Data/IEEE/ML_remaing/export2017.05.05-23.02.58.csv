"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5360321,5359987,5358124,5358602,5358047,5367170,5362958,5360534,5358538,5361697,5367049,5362179,5365565,5357937,5363472,5358491,5364212,5366987,5359226,5360015,5358517,5360610,5360328,5360434,5359900,5364622,5366324,5360429,5366846,5362087,5360428,5360427,5362940,5360426,5365980,5360425,5364346,5367097,5358999,5365592,5358633,5366474,5358581,5360423,5360243,5357671,5360285,5358540,5358597,5360295,5358025,5358527,5360422,5358086,5357670,5364082,5360305,5363512,5357684,5365744,5362943,5360432,5364976,5360522,5364117,5364122,5358028,5360442,5364487,5358815,5360345,5360421,5363636,5360241,5362266,5358501,5361712,5360252,5366129,5366552,5359961,5359556,5360430,5364285,5358210,5363204,5365023,5360526,5366522,5358931,5365100,5365060,5358850,5362950,5364011,5360290,5362691,5360591,5358919,5360296",2017/05/05 23:02:58
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Compressed Spectral Clustering","B. Zhao; C. Zhang","Dept. of Autom., Tsinghua Univ., Beijing, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","344","349","Compressed sensing has received much attention in both data mining and signal processing communities. In this paper, we provide theoretical results to show that compressed spectral clustering, separating data samples into different clusters directly in the compressed measurement domain, is possible. Specifically, we provide theoretical bounds guaranteeing that if the data is measured directly in the compressed domain, spectral clustering on the compressed data works almost as well as that in the data domain. Moreover, we show that for a family of well-known compressed sensing matrices, compressed spectral clustering is universal, i. e., clustering in the measurement domain works provided that the data are sparse in some, even unknown, basis. Finally, experimental results on both toy and real world data sets demonstrate that compressed spectral clustering achieves comparable clustering performance with traditional spectral clustering that works directly in the data domain, with much less computational time.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360429","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","data compression;data mining;pattern clustering","compressed sensing;compressed spectral clustering;data mining","","1","","17","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Evaluation for Network Loads Using Data Fusion","X. Li; Y. Guan; H. Yuan","Coll. of Inf. Eng., Capital Normal Univ., Beijing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","A solution to evaluate network workload by data fusion is put forward, which can be for surveillance the traffic of interconnected communications network in order to keep the network working well by identifying potentially serious problems in the early stages and evaluating network performance. Through fusing the historic network traffic data and network online traffic data, which is based on least squares- SVM and D-S evidence theory, we have been able to identify several network trends of specific chronic problems effectively and provide insights to Internet Service Providers (ISP) for engineering their network traffic, and planning the capacity accordingly. Evaluation experiments indicate that the merging techniques yield improvements in the accuracy and effectiveness.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366846","","Capacity planning;Communication networks;Data engineering;Educational institutions;Machine learning;Payloads;Support vector machines;Surveillance;Telecommunication traffic;Web and internet services","Internet;computer network performance evaluation;inference mechanisms;least squares approximations;sensor fusion;support vector machines;telecommunication traffic","D-S evidence theory;Internet service providers;data fusion;interconnected communications network;least squares-SVM;network loads;network online traffic data;network performance;traffic surveillance","","0","","10","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Active Neighborhood Selection for Locally Linear Embedding","X. Yu; H. Li","Sch. of Math. & Comput. Sci., Harbin Univ., Harbin, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","219","222","In this paper, we propose metric locally linear embedding (LLE) to handling the problem of multiple manifolds through learning neighborhood. LLE succeeds in extracting the low-dimensional representation of data in a single manifold, but fails in the case of multiple manifolds. This paper makes use of the strategy of active neighborhood selection to extend LLE. The strategy requires partial information of similarity among data to find an appropriate Mahalanobis distance to replace Euclidean distance. The use of new distance metric aims to diminish the distance of data points within the same manifold and enlarge the distance between different manifolds, while preserving the intrinsic structure of each manifold as faithfully as possible. Experimental results demonstrate that metric LLE usually performs better than LLE in feature extraction.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362087","LLE;distance learning;manifold learning;neighborhood selection","Computer aided instruction;Embedded computing;Euclidean distance;Knowledge acquisition;Machine learning;Manifolds;Mathematical model;Mathematics;Matrix decomposition;Nearest neighbor searches","data structures;feature extraction;learning (artificial intelligence)","Euclidean distance;Mahalanobis distance;active neighborhood selection;feature extraction;learning neighborhood;locally linear embedding;low-dimensional data representation;multiple manifolds","","1","","8","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Efficient Incremental Mining of Qualified Web Traversal Patterns without Scanning Original Databases","J. C. Ying; V. S. Tseng; P. S. Yu","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","338","343","Discovering web traversal patterns is an important issue in web usage mining with various applications like navigation prediction and improvement of website management. Since web data grows so rapidly and some web data may become out of date over time, we need not only consider the new data but also delete the old one to re-mine new web traversal patterns. To reduce the overhead of re-mining the web traversal patterns from the whole web data, an incremental mining approach is needed by using the previous mining results and computing new patterns just from the inserted or deleted part of the web data. In this paper, we propose an efficient incremental web traversal pattern mining algorithm named IncWTP_PLM (Incremental mining of Web Traversal Patterns by using Projected-database Link Matrix). Meanwhile, a special data structure named Projected-database Link Matrix is proposed to avoid scanning original database. Besides, the website structure is also considered in IncWTP_PLM such that each web traversal pattern discovered is qualified. The experimental results show that our algorithm outperforms other approaches substantially in terms of efficiency.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360428","","Cloud computing;Clustering algorithms;Computer networks;Costs;Data mining;Data processing;Databases;Decision trees;Machine learning algorithms;Training data","Internet;Web sites;data mining;data structures;database management systems","incremental mining;navigation prediction;projected-database link matrix;special data structure;web data;web traversal patterns;web usage mining;website management;website structure","","2","","11","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Efficient Dense Structure Mining Using MapReduce","S. Yang; B. Wang; H. Zhao; B. Wu","Sch. of Comput. Sci., Beijing Univ. of Posts & Telecommun., Beijing, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","332","337","Structure mining plays an important part in the researches in biology, physics, Internet and telecommunications in recently emerging network science. As a main task in this area, the problem of structure mining on graph has attracted much interest and been studied in variant avenues in prior works. However, most of these works mainly rely on single chip computational capacity and have been constrained by local optimization. Thus it is an impossible mission for these methods to process massive graphs. In this paper, we propose an unified distributed method in solving some critical graph mining problems on top of a cluster system with the help of MapReduce. These problems include graph transformation, subgraph partition, maximal clique enumeration, connected component finding and community detection. All of these methods are implemented to fully utilize MapReduce execution mechanism, namely the Â¿map-reduceÂ¿ process. Moreover, considering how our algorithms can be applied in further Â¿cloudÂ¿ service, we employ several large scale datasets to demonstrate the efficiency and scalability of our solutions.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360427","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","data mining;distributed processing;graph grammars;graph theory","MapReduce execution mechanism;cloud service;cluster system;community detection;connected component finding;critical graph mining problems;dense structure mining;graph transformation;map-reduce process;maximal clique enumeration;subgraph partition","","8","","11","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Heuristic Method to Isolate the State Space","Z. Jin; W. Liu; J. Jin","Sch. of Inf. Sci. & Eng., Yunnan Univ., Kunming, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Large and complex problem can be solved easily and quickly by decomposing it to be small sub-problems. We propose a heuristic method to isolate the larger state space into some smaller state spaces for decomposing learning task. During the learning process, after remove the state loops in these learned episodes, we find some states are critical for agent can reach goal state. These critical states have two characteristics: 1) they have high probability appeared in all these acyclic episodes; 2) they are the gates for agent can move from a part of state space enter another part of state space. These critical states are called as gate states. So when we block all these gate states, the original larger state space is isolated naturally into some smaller state spaces. Although we can not ensure the isolation is absolutely complete, because the isolation is based on the episodes have been learned. But this method indeed gives agent the capability to decompose its state space according to the knowledge it learned. The experiments on grid-world problem also show the isolation tend to be complete along with the increase of training episodes.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5362940","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362940","","Face;Humans;Information science;Machine learning;Neural networks;State-space methods","learning (artificial intelligence);probability","acyclic episodes;gate states;grid-world problem;heuristic method;probability;reinforcement learning;state space isolation","","0","","11","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Greedy is not Enough: An Efficient Batch Mode Active Learning Algorithm","Z. Xu; C. Hogan; R. Bauer","eBay Inc., San Jose, CA, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","326","331","Active learning algorithms actively select training examples to acquire labels from domain experts, which are very effective to reduce human labeling effort in the context of supervised learning. To reduce computational time in training, as well as provide more convenient user interaction environment, it is necessary to select batches of new training examples instead of a single example. Batch mode active learning algorithms incorporate a diversity measure to construct a batch of diversified candidate examples. Existing approaches use greedy algorithms to make it feasible to the scale of thousands of data. Greedy algorithms, however, are not efficient enough to scale to even larger real world classification applications, which contain millions of data. In this paper, we present an extremely efficient active learning algorithm. This new active learning algorithm achieves the same results as the traditional greedy algorithm, while the run time is reduced by a factor of several hundred times. We prove that the objective function of the algorithm is submodular, which guarantees to find the same solution as the greedy algorithm. We evaluate our approach on several largescale real-world text classification problems, and show that our new approach achieves substantial speedups, while obtaining the same classification accuracy.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360426","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","greedy algorithms;learning (artificial intelligence)","active learning algorithm;batch mode learning;greedy algorithms;supervised learning;text classification problems","","0","","14","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Extract Medical Interpretation Based on Shallow Syntactic Analysis","C. Ding; W. Wang; L. Lu","Coll. of Comput. Sci., Yangtze Univ., Jingzhou, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Knowledge extraction provides the potential for producing high quality representation of the document and can help storing, retrieving, sharing, and management of explicit biomedical knowledge. This article addresses the task of mining binary relationships between concepts from biomedical literature for scientific discovery from medical literature. The UMLS has defined the domain entities and the internal relation network between them. The expert is then guided in construct the relation template by define the syntactic and semantic constraints with the help of the pre-established domain ontology. We present the technologies in finding the possible knowledge from plain text based on some grammar analysis. Medical concepts with the similar role are grouped as a union to improve the recall and decrease the useless calculate. The medical relations are extracted according the syntactic and semantic mapping. Experiment show that the biomedical extraction system get better performance.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365980","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365980","","Bioinformatics;Biomedical computing;Computer science;Data mining;Educational institutions;Knowledge management;Machine learning;Ontologies;Quality management;Unified modeling language","data mining;document handling;grammars;medical computing","UMLS;binary relationships;biomedical knowledge;biomedical literature;data mining;domain ontology;grammar analysis;high quality representation;knowledge extraction;medical interpretation;scientific discovery;semantic constraint;shallow syntactic analysis;syntactic constraint","","0","","11","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Fast Induction of Multiple Decision Trees in Text Categorization from Large Scale, Imbalanced, and Multi-label Data","P. Vateekul; M. Kubat","Dept. of Electr. & Comput. Eng., Univ. of Miami, Coral Gables, FL, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","320","325","The paper focuses on automated categorization of text documents, each labeled with one or more classes and described by tens of thousands of features. The computational costs of induction in such domains are so high as almost to disqualify the use of decision trees; the reduction of these costs is thus an important research issue. Our own solution, FDT (""fast decision-tree induction""), uses a two-pronged strategy: (1) feature-set pre-selection, and (2) induction of several trees, each from a different data subset, with the combination of the results from multiple trees with a data-fusion technique tailored to domains with imbalanced classes.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360425","","Cloud computing;Clustering algorithms;Computer networks;Costs;Data mining;Data processing;Decision trees;Large-scale systems;Machine learning algorithms;Text categorization","decision trees;text analysis","data fusion technique;fast decision-tree induction;feature-set pre-selection;imbalanced classes;large-scale data;multi-label data;multiple decision trees;text categorization","","2","","11","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Learning Link-Based Classifiers from Ontology-Extended Textual Data","C. Caragea; D. Caragea; V. Honavar","Comput. Sci. Dept., Iowa State Univ., Ames, IA, USA","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","354","361","Real-world data mining applications call for effective strategies for learning predictive models from richly structured relational data. In this paper, we address the problem of learning classifiers from structured relational data that are annotated with relevant meta data. Specifically, we show how to learn classifiers at different levels of abstraction in a relational setting, where the structured relational data are organized in an abstraction hierarchy that describes the semantics of the content of the data. We show how to cope with some of the challenges presented by partial specification in the case of structured data, that unavoidably results from choosing a particular level of abstraction. Our solution to partial specification is based on a statistical method, called shrinkage. We present results of experiments in the case of learning link-based Naive Bayes classifiers on a text classification task that (i) demonstrate that the choice of the level of abstraction can impact the performance of the resulting link-based classifiers and (ii) examine the effect of partially specified data.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364346","link-based classifier;ontology-extended data sources","Application software;Artificial intelligence;Computer science;Data mining;Machine learning;Ontologies;Predictive models;Statistical analysis;Text categorization;Yield estimation","Bayes methods;data mining;meta data;ontologies (artificial intelligence)","Naive Bayes classifiers;abstraction hierarchy;learning link-based classifiers;meta data;ontology-extended textual data;real-world data mining applications;shrinkage;statistical method;structured relational data;text classification task","","1","","19","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Parameter Optimization of ϵ-Support Vector Machine by Genetic Algorithm","Q. Yu; B. Zhang; J. Wang","Tianjin Key Lab. of Intell. Comput. & Novel Software Technol., Tianjin Univ. of Technol., Tianjin, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","540","542","The ϵ-support vector regression machine is a promising artificial intelligence technique, in which the regression algorithm has already been used in solving the nonlinear function approach successfully. Most users select parameters for an SVM by rule of thumb, so they frequently fail to generate the optimal parameters effect for the function. This has restricted effective use of SVM to a great degree. In this paper, the authors use genetic algorithm to solve the SVM parameters optimization problem. Simulation result shows that the method has high precision and possesses certain practical application significance.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367097","GA;e-SVM;parameter optimization;prediction","Application software;Artificial intelligence;Computational modeling;Genetic algorithms;Laboratories;Machine intelligence;Machine learning;Software algorithms;Support vector machines;Thumb","artificial intelligence;genetic algorithms;regression analysis;support vector machines","ϵ-support vector regression machine;SVM parameters optimization problem;artificial intelligence technique;genetic algorithm;nonlinear function approach;parameter optimization","","1","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Crack Defects Detection in Radiographic Weldment Images using FSVM and Beamlet Transform","Z. Sun; D. Ruan; Y. Ma; X. Hu; X. g. Zhang","Coll. of Mech. & Electr. Eng., China Univ. of Min. & Technol., Xuzhou, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","3","","402","406","In order to solve the problem of crack defects detection in radiographic weldment images, this paper proposes a new detection method using fuzzy support vector machine (FSVM) and Beamlet transform. FSVM gives small weights to samples which contain noise and isolated points, which overcomes the disadvantage that SVM is sensitive to noise and isolated points in samples on some extent. Firstly, wavelet transform and morphological method are applied to denoise and eliminate the image background, which will enhance the defect features; Secondly, FSVM is used to recognize and locate the rough region containing crack defects; Finally, the crack defects are extracted through Beamlet transform in the rough region. The experimental results show that the proposed method can detect the crack defects in weldment images successfully.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358999","FSVM;beamlet;crack defects;radiographic weldment images","Data mining;Fuzzy systems;Image recognition;Kernel;Machine learning;Radiography;Support vector machine classification;Support vector machines;Wavelet transforms;Welding","crack detection;image denoising;maintenance engineering;mechanical engineering computing;support vector machines;wavelet transforms;welding","FSVM;beamlet transform;crack defects detection;fuzzy support vector machine;image background;image denoising;radiographic weldment images","","2","","7","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Novel Reconstruction Strategy of Half-Versus-Half for Multi-Class SVMs","X. Wang","Key Lab. of Numerical Control of Jiangxi Province, Jiujiang Univ., Jiujiang, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Support vector machine (SVM) for pattern recognition is a binary classifier. When dealing with multi-class tasks, a popular and applicable way is to decompose the original problem into a set of binary sub-problems. This paper presents a novel half-versus-half (HVH) decomposition scheme. Unlike the conventional implementation methods, HVH is built via dividing the training dataset of K-classes into two comparable sub-sets of classes, which can consider the multi-classification as a decision-making table. The structure of HVH requires at most log<sub>2</sub>(K) binary SVMs, which is far less than that of conventional methods. Experiments are performed on several benchmark datasets, and the results show that HVH has advantages over conventional methods in complexity and testing speed.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365592","","Benchmark testing;Computer numerical control;Kernel;Machine learning;Matrix decomposition;Pattern recognition;Performance evaluation;Reconstruction algorithms;Support vector machine classification;Support vector machines","decision making;pattern classification;support vector machines","binary classifier;decision-making table;half-versus-half decomposition;multiclass SVM;multiclass task;pattern recognition;reconstruction strategy;support vector machine","","0","","10","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Derivations of Normalized Mutual Information in Binary Classifications","Y. Wang; B. G. Hu","Beijing Grad. Sch., Chinese Acad. of Sci., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","155","163","Although the conventional performance indexes, such as accuracy, are commonly used in classifier selection or evaluation, information-based criteria, such as mutual information, are becoming popular in feature/model selections. In this work, we analyze the classifier learning model with the maximization normalized mutual information (NI) criterion, which is novel and well defined in a compact range for classifier evaluation. We derive close-form relations of normalized mutual information with respect to accuracy, precision, and recall in binary classifications. By exploring the relations among them, we reveal that NI is actually a set of nonlinear functions, with a concordant power-exponent form, to each performance index. The relations can also be expressed with respect to precision and recall, or to false alarm and hitting rate (recall).","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358633","binary classification;entropy;model evaluation;nonlinear functions;normalized mutual information","Bayesian methods;Bonding;Entropy;Fuzzy systems;Information analysis;Laboratories;Machine learning;Mutual information;Pattern recognition;Performance analysis","information theory;nonlinear functions;pattern classification;performance index","binary classification;classifier evaluation;classifier learning model;classifier selection;information based criteria;maximization normalized mutual information;nonlinear functions;performance index;power-exponent form","","2","","31","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Three-Level Hybrid Intrusion Detection System","H. Lu; J. Xu","Dept. of Comput. Sci., East China Normal Univ., Shanghai, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","With increasing connectivity between computers, the need to keep networks secure becomes more and more vital. Intrusion detection systems have become an essential component of network security to supplement existing defenses. This paper proposes a novel intrusion detection system, which combines the supervised classifiers and unsupervised clustering to detect intrusions. Decision tree, naive Bayes and Bayesian clustering are used at different levels. We also have made improvements to the Na'ive Bayes algorithm by choosing different attributes for different classes. The experiments demonstrate the effectiveness of the proposed approach, especially for U2R and R2L type attacks. The detection rate is significantly improved.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366474","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366474","","Bayesian methods;Classification tree analysis;Clustering algorithms;Computer networks;Computer science;Decision trees;Information security;Internet;Intrusion detection;Machine learning algorithms","Bayes methods;decision trees;pattern clustering;security of data","Bayesian clustering;decision tree;naive Bayes;supervised classifiers;three-level hybrid intrusion detection system;unsupervised clustering","","3","","24","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"The Hybrid Credit Scoring Strategies Based on KNN Classifier","F. C. Li","Dept. of Inf. Manage., Jen Teh Junior Coll., MiaoLi, Taiwan","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","330","334","The development of credit scoring model has been regarded as a critical topic. This study proposed four approaches combining with the KNN (K-nearest neighbor) classifier for features selection that retains sufficient information for classification purpose. Two UCI data sets and different models combined with KNN classifier were constructed by selecting features. KNN classifier combines with conventional statistical LDA, Decision tree, Rough set and F-score approaches as features preprocessing step to optimize feature space by removing both irrelevant and redundant features. The procedure of the proposed algorithm is described first and then evaluated by their performances. The results are compared in combination with KNN classifier and nonparametric Wilcoxon signed rank test will be held to show if there has any significant difference between these approaches. Our results suggest that hybrid credit scoring models are robust and effective in finding optimal subsets and the compound procedure is a promising method to the fields of data mining.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358581","Decision tree;F-score;K Nearest Neighbor;Linear discriminate analysis;Rough set","Data mining;Decision making;Decision trees;Educational institutions;Expert systems;Fuzzy systems;Information management;Linear discriminant analysis;Machine learning;Testing","data mining;decision trees;finance;pattern classification;rough set theory;statistical analysis","F-score approach;K-nearest neighbor classifier;KNN classifier;credit scoring;data mining;decision tree;features selection;rough set theory;statistical LDA","","2","","16","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Estimating the Parameters of Randomly Interleaved Markov Models","D. Gillblad; R. Steinert; D. R. Ferreira","Swedish Inst. of Comput. Sci., Kista, Sweden","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","308","313","Sequences that can be assumed to have been generated by a number of Markov models, whose outputs are randomly interleaved but where the actual sources are hidden, occur in a number of practical situations where data is captured as an unlabeled stream of events. We present a practical method for estimating model parameters on large data sets under the assumption that all sources are identical. Results on representative examples are presented, together with a discussion on the accuracy and performance of the proposed estimation algorithms. Finally, we describe a real-world case study where we apply the technique to the sequence of events recorded in the technical support database of an IT vendor.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360423","","Cloud computing;Clustering algorithms;Computer networks;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Parameter estimation;Training data","Markov processes;parameter estimation;very large databases","IT vendor;parameter estimation;randomly interleaved Markov models;technical support database","","2","","18","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Linear-Time Graph Kernel","S. Hido; H. Kashima","IBM Res., Tokyo, Japan","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","179","188","The design of a good kernel is fundamental for knowledge discovery from graph-structured data. Existing graph kernels exploit only limited information about the graph structures but are still computationally expensive. We propose a novel graph kernel based on the structural characteristics of graphs. The key is to represent node labels as binary arrays and characterize each node using logical operations on the label set of the connected nodes. Our kernel has a linear time complexity with respect to the number of nodes times the average number of neighboring nodes in the given graphs. The experimental result shows that the proposed kernel performs comparable and much faster than a state-of-the-art graph kernel for benchmark data sets and shows high scalability for new applications with large graphs.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360243","","Chemical compounds;Computational efficiency;Data mining;Informatics;Kernel;Logic arrays;Machine learning;Polynomials;Scalability;Time measurement","computational complexity;data mining;graph theory","benchmark data sets;binary arrays;graph-structured data;knowledge discovery;linear time complexity;linear-time graph kernel;logical operations","","12","4","17","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Face recognition base on a new design of classifier with SIFT keypoints","T. Liu; S. H. Kim; H. S. Lee; H. H. Kim","Dept. Computer Engineering, Kyung Hee University, Yongin-Si, Korea","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","366","370","This paper investigates a new face recognition system based on an efficient design of classifier using SIFT (scale invariant feature transform) feature keypoint. This proposed system takes the advantage of SIFT feature which possess strong robustness to the expression, accessory, pose and illumination variations. One MLP (multi layer perceptron) based network is adopted as classifier of SIFT keypoint feature. The proposed classifier classifies each keypoint into face ID then an ID index histogram counting method is applied as the identification method to recognize face images. Also a bootstrapping method is investigated to select training images during training MLP. The performance of face recognition in some challenging databases is improved efficiently. Experiments on ORL and Yale face database show that the best recognition rate reaches 98% and 98.6%.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357671","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357671","Face Recognition;MLP;SIFT","Computer science education;Face detection;Face recognition;Histograms;Image databases;Image recognition;Lighting;Machine learning;Robustness;Spatial databases","face recognition;feature extraction;image classification;multilayer perceptrons","ID index histogram counting;SIFT keypoint;accessory variation;bootstrapping method;classifier;expression variation;face ID;face recognition;identification method;illumination variation;multilayer perceptron;pose variation;scale invariant feature transform","","1","","14","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Online System Problem Detection by Mining Patterns of Console Logs","W. Xu; L. Huang; A. Fox; D. Patterson; M. Jordan","EECS Dept., UC Berkeley, Berkeley, CA, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","588","597","We describe a novel application of using data mining and statistical learning methods to automatically monitor and detect abnormal execution traces from console logs in an online setting. Different from existing solutions, we use a two stage detection system. The first stage uses frequent pattern mining and distribution estimation techniques to capture the dominant patterns (both frequent sequences and time duration). The second stage use principal component analysis based anomaly detection technique to identify actual problems. Using real system data from a 203-node Hadoop cluster, we show that we can not only achieve highly accurate and fast problem detection, but also help operators better understand execution patterns in their system.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360285","console logs;logs;monitoring;pattern mining;problem detection;system management","Computerized monitoring;Condition monitoring;Data mining;Machine learning;Principal component analysis;Software maintenance;Statistical learning;USA Councils;Web and internet services;Web server","data mining;learning (artificial intelligence);statistical analysis","203-node Hadoop cluster;anomaly detection;console logs;data mining patterns;distribution estimation;execution patterns;frequent pattern mining;online setting;online system problem detection;principal component analysis;real system data;stage detection system;statistical learning method","","18","2","32","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Collaborative Optimization of Clustering by Fuzzy c-means and Weight Determination by ReliefF","L. Zhang; D. Li; C. Zhong","Sch. of Electron. & Inf. Eng., Dalian Univ. of Technol., Dalian, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","454","459","The ReliefF algorithm is an important attribute weighting approach, which is built on the basis of classification labels. And the attribute weights of weighted FCM (WFCM), a popular fuzzy clustering algorithm, can be gotten by ReliefF. In the light of the idea of collaborative learning, a collaborative optimization of clustering by fuzzy c-means and weight determination by ReliefF (Co-WFCM) is introduced in this paper, in which FCM/WFCM and ReliefF who act as unsupervised and supervised learners are trained reciprocally. Experimental results show that the algorithm is helpful to get more satisfying clustering results and more rational attribute weights in some cases. And on the other hand, some suggestions for applicability of the ReliefF+FCM/WFCM algorithm framework can be given by analysis of the attribute weight sequences.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358540","Attribute Weighting;Collaborative Optimization;Fuzzy Clustering;Fuzzy c-Means;ReliefF","Clustering algorithms;Collaborative work;Educational technology;Euclidean distance;Filters;Fuzzy systems;International collaboration;Knowledge engineering;Machine learning algorithms;Partitioning algorithms","fuzzy set theory;groupware;optimisation;pattern clustering","ReliefF algorithm;attribute weighting approach;collaborative optimization;fuzzy c-means clustering;unsupervised-supervised learners;weight determination","","0","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Study on Multi-label Text Classification Based on SVM","Y. p. Qin; X. k. Wang","Coll. of Inf. Sci. & Technol., Bohai Univ., Jinzhou, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","300","304","Two multi-label text classification algorithms are proposed. Firstly, one-against-rest method is used to train sub-classifiers. For the text to be classified, the sub-classifiers are used to obtain the membership vector, and then confirm the classes of the text. Secondly, hyper-sphere support vector machine is used to obtain the smallest hyper-spheres in feature space that contains most texts of the class, which can divide the class texts from others. For the text to be classified, the distances from it to the centre of every hyper-sphere are used to confirm the classes of the text. The experimental results show that the algorithms have high performance on recall, precision, and F1.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358597","","Classification algorithms;Databases;Educational institutions;Fuzzy systems;Information science;Machine learning algorithms;Support vector machine classification;Support vector machines;Technology management;Text categorization","support vector machines;text analysis","hypersphere support vector machine;membership vector;multi label text classification algorithms;one-against-rest method","","1","","12","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"An L-infinity Norm Visual Classifier","A. Anand; L. Wilkinson; D. N. Tuan","Univ. of Illinois at Chicago, Chicago, IL, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","687","692","We introduce a mathematical framework, based on the L<sup>∞</sup> norm distance metric, to describe human interactions in a visual data mining environment. We use the framework to build a classifier that involves an algebra on hyper-rectangles. Our classifier, called VisClassifier, generates set-wise rules from simple gestures in an exploratory visual GUI. Logging these rules allows us to apply our analysis to a new sample or batch of data so that we can assess the predictive power of our visual-processing motivated classifier. The accuracy of this classifier on widely-used benchmark datasets rivals the accuracy of competitive classifiers.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360295","Visual data mining;supervised classification","Algebra;Classification algorithms;Clustering algorithms;Computer errors;Data mining;Graphical user interfaces;Humans;Machine learning;Partitioning algorithms;Pattern recognition","data mining;graphical user interfaces;pattern classification","L<sup>∞</sup> norm distance metric;L<sup>∞</sup> norm visual classifier;VisClassifier;exploratory visual GUI;human interaction;mathematical framework;set wise rules generation;visual data mining environment;visual processing motivated classifier","","1","","31","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Inductive transfer through neural network error and dataset regrouping","Wei Liu; Huaxiang Zhang; Jianbo Li","College of Information Science and Engineering, Shandong Normal University, Jinan, China 250014","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","777","781","A new inductive transfer-learning algorithm called NEDRT is presented in this paper in order to improve the classification accuracy of a domain task by using the knowledge learned from labeled data generated from a different domain. NEDRT introduces a novel error function for a constructed neural network by summing a weighted squared difference between the real output and the neural network output for each instance of label training data from the source domain and the target domain. Each weight could be regarded as an instance's contribution degree to transfer, The source data set is partitioned into different sunsets to minimize the imbalance between the target data and source data, and each subset is combined with the target data to form a new training data set. These newly obtained training data sets are used to construct classifiers for the target task. Experimental results of knowledge transfer on UCI data sets and text data sets show that NEDRT performs well.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358025","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358025","error;imbalance;inductive;neural network;regroup","Data engineering;Educational institutions;Information science;Knowledge engineering;Knowledge transfer;Machine learning;Neural networks;Performance gain;Testing;Training data","data handling;neural nets","NEDRT;UCI data sets;classification accuracy;dataset regrouping;inductive transfer-learning algorithm;neural network error;weighted squared difference","","0","","10","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Novel Support Vector Clustering with Label Assignment in Enriched Neighborhood","L. Ping; G. Dajin; H. Fujiang; R. Xiangsheng; Y. Xiangyang","Sch. of Comput. Sci., Xuzhou Normal Univ., Xuzhou, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","500","504","Support vector clustering (SVC) is an appealing approach that can detect cluster boundaries. In spite of its popularization in applications, it sees the critical bottleneck in cluster labeling. This paper presents a novel support vector clustering algorithm (NSVC) to go a further step in clustering labeling. NSVC consists of three phases: extract data representatives (DRs); cluster DRs; label non-DR data. The objective of traditional SVC is used by NSVC for finding DRs, but the kernel scale of the objective is modified. DRs are grouped by spectrum analysis (SA) method, which simultaneously develops an informative metric. Non-DR data are labeled by a weighted kNN procedure that works in query's neighborhood, which is formulated with the new metric and then enriched by the convex hull skill. Experiments on real datasets demonstrate the improvement of NSVC over its peers and the competitive performance with the state of the arts.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.702","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358527","","Clustering algorithms;Computer science;Data mining;Educational institutions;Fuzzy systems;Kernel;Labeling;Logistics;Machine learning algorithms;Static VAr compensators","data structures;feature extraction;pattern clustering","cluster labeling;data representative extraction;neighborhood label assignment;novel support vector clustering algorithm;spectrum analysis method","","0","","16","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Scalable Attribute-Value Extraction from Semi-structured Text","Y. W. Wong; D. Widdows; T. Lokovic; K. Nigam","Google Inc., Pittsburgh, PA, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","302","307","This paper describes a general methodology for extracting attribute-value pairs from Web pages. It consists of two phases: candidate generation, in which syntactically likely attribute-value pairs are annotated; and candidate filtering, in which semantically improbable annotations are removed. We describe three types of candidate generators and two types of candidate filters, all of which are designed to be massively parallelizable. Our methods can handle 1 billion Web pages in less than 6 hours with 1,000 machines. The best generator and filter combination achieves 70% F-measure compared to a hand-annotated corpus.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360422","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","data mining;information resources","F-measure;Web pages;candidate filtering;candidate generation;scalable attribute-value extraction;semistructured text","","3","2","28","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Establishing adaptation loop in interaction between human user and adaptive agent","Y. Xu; Y. Ohmoto; K. Ueda; T. Komatsu; T. Okadome; K. Kamei; S. Okada; Y. Sumi; T. Nishida","Graduate School of Informatics, Kyoto University, Yoshida-Honmachi, Sakyo-ku, 606-8501, Japan","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","3","","647","651","In order to develop an adaptive agent that a human user may feel easy to adapt to, it is useful to establish an adaption loop between the user and the agent. A mutual adaptation phenomenon often occurs during establishment of such an adaption loop. Aiming to disclose the essence of mutual adaptation, we designed a waiter agent task and conducted an experiment with respect to human-agent mutual adaptation. Results of the experiment imply that not only response behavior of the agent, but also type of human user affect the establishment of the adaptation loop.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358086","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358086","","Animals;Cognitive robotics;Education;Educational robots;Horses;Humans;Intelligent agent;Laboratories;Machine learning;Robot kinematics","human computer interaction;software agents","adaption loop;adaptive agent;human user interaction;mutual adaptation phenomenon","","0","","7","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Pattern recognition using interval-valued intuitionistic fuzzy set and its similarity degree","Yingjun Zhang; Peijun Ma; Xiaohong Su","School of Computer Science and Technology, Harbin Institute of Technology, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","361","365","Pattern recognition under fuzzy environments is an interesting and important research topic which has been receiving more and more attention in recent years. Aiming at this kind of pattern recognition problems, fuzzy theories have been applied to the field widely and effectively. Especially interval-valued intuitionistic fuzzy sets (IVIFSs) can give not only a membership degree, but also a non-membership degree, which is more or less independent. Meanwhile the membership degree and non-membership degree are denoted by an interval which makes the IVIFSs can represent the dynamic character of features. Therefore in this paper, depending on IVIFSs and corresponding similarity degree (or distance measure) we construct a kind of novel pattern recognition approach. This approach chooses different weight for each feature according to its dissimilarity with other features. Thus the approach can show the corresponding influence and importance of different features. Finally, we utilize concrete examples to validate the proposed approach.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357670","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357670","distance measure;interval-valued intuitionistic fuzzy sets (IVIFSs);intuitionistic fuzzy set (IFS);pattern recognition;similarity degree","Color;Computer science;Concrete;Fuzzy set theory;Fuzzy sets;Fuzzy systems;Image segmentation;Machine learning;Medical diagnosis;Pattern recognition","formal logic;fuzzy set theory;pattern recognition","interval-valued intuitionistic fuzzy set;pattern recognition","","1","","12","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Group Structure Influence on Group Lasso Consistency","M. Wang; S. Liao","Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China","2009 Fifth International Conference on Natural Computation","20091228","2009","6","","493","497","Group Lasso is a recently proposed regression method that can be used to select group variables. When studying the consistency condition of the regularization path of group Lasso, we assume that the groupings of the univariate variables are known and fixed, that is, the group structure is given. In this paper, we address the issue of the influence of group structure on the group Lasso consistency. Based on the analysis of the consistency condition, we argue that the sparsity patterns is the determinant, the different group structures can lead to different consistencies, and the degree of the correlation between the relevant groups and the irrelevant groups is the key factor. Experimental results also demonstrate that the group Lasso is consistent under low correlation conditions.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364082","Group Lasso;Lasso;regularization","Analysis of variance;Computer science;Information technology;Input variables;Machine learning;Pattern analysis;Petroleum;Polynomials;Sufficient conditions;Symmetric matrices","regression analysis","consistency condition;group lasso consistency;group structure influence;group variables;regression method;regularization path;sparsity patterns;univariate variables","","0","","10","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Accelerated Gradient Method for Multi-task Sparse Learning Problem","X. Chen; W. Pan; J. T. Kwok; J. G. Carbonell","Sch. of Comput. Sci., Carnegie Mellon Univ. Pittsburgh, Pittsburgh, PA, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","746","751","Many real world learning problems can be recast as multi-task learning problems which utilize correlations among different tasks to obtain better generalization performance than learning each task individually. The feature selection problem in multi-task setting has many applications in fields of computer vision, text classification and bio-informatics. Generally, it can be realized by solving a L-1-infinity regularized optimization problem. And the solution automatically yields the joint sparsity among different tasks. However, due to the nonsmooth nature of the L-1-infinity norm, there lacks an efficient training algorithm for solving such problem with general convex loss functions. In this paper, we propose an accelerated gradient method based on an ``optimal'' first order black-box method named after Nesterov and provide the convergence rate for smooth convex loss functions. For nonsmooth convex loss functions, such as hinge loss, our method still has fast convergence rate empirically. Moreover, by exploiting the structure of the L-1-infinity ball, we solve the black-box oracle in Nesterov's method by a simple sorting scheme. Our method is suitable for large-scale multi-task learning problem since it only utilizes the first order information and is very easy to implement. Experimental results show that our method significantly outperforms the most state-of-the-art methods in both convergence speed and learning accuracy.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360305","L-1-infinity regularization;gradient descend;multi-task learning;optimal method","Acceleration;Application software;Computer science;Convergence;Data engineering;Data mining;Gradient methods;Large-scale systems;Machine learning;Optimization methods","gradient methods;learning (artificial intelligence)","L-1-infinity regularized optimization problem;Nesterov method;accelerated gradient method;bioinformatics;computer vision;feature selection problem;first order black-box method;multitask sparse learning problem;optimal first order black-box method;text classification","","43","","26","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Learning communities supported by autonomic recommendation mechanism","S. N. Brandao; R. T. Silva; J. M. Souza","COPPE/UFRJ - Computer Science Department, Graduate School of Engineering , Federal University of Rio de Janeiro, Brazil","2009 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing","20091228","2009","","","1","10","Peer-to-peer (P2P) offers good solutions for many applications such as large data sharing and collaboration. Thus, it appears as a powerful paradigm to develop scalable distributed applications, as reflected by the increasing number of emerging projects based on this technology. However, building trustworthy P2P collaborative tool is difficult because they must be deployed on a large number of autonomous nodes, which may be part of the virtual community and to make the collaboration effectively happen among the nodes. Within this scenario, this article presents an autonomic recommendation mechanism of knowledge chains, which is based on the apprentice profile and his current knowledge to recommend the best learning strategy after the analysis of the learning community in this peer-to-peer environment.","","CD-ROM:978-963-9799-76-9","10.4108/ICST.COLLABORATECOM2009.8348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363512","Autonomic Computing;E-learning Systems;Peer-to-Peer Architecture;Personal Knowledge Management","Application software;Collaboration;Collaborative tools;Computer science;Data engineering;Machine learning;Mathematics;Peer to peer computing;Power engineering and energy;Protocols","computer aided instruction;groupware;peer-to-peer computing","autonomic recommendation mechanism;collaborative tool;learning communities;peer-to-peer environment;scalable distributed applications","","0","","23","","","11-14 Nov. 2009","","IEEE","IEEE Conference Publications"
"A new SVM-RFE approach towards ranking problem","Qifeng Zhou; Wencai Hong; Guifang Shao; Weiyou Cai","Automation Department, Xiamen University, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","270","273","Support vector machine recursive feature elimination (SVM-RFE) is a simple and efficient feature selection algorithm which has been used in many fields. Just like SVM itself, SVM-RFE was originally designed to solve binary feature selection problems. In this paper, we propose a new recursive feature elimination method based on SVM for ranking problem. As against standard approaches of treating ranking as a multiclass classification problem, our approach enables the use of standard binary SVM-RFE algorithms for ranking problems. We evaluate our algorithm on both public dataset and for a real world credit evaluating problem. The results obtained demonstrate the superiority of our algorithm over extended SVM-RFE to solve multiclass problems using ensemble techniques.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357684","Recursive Feature Elimination;SVM;ranking problem","Automation;Machine learning;Mechanical engineering;Sorting;Support vector machine classification;Support vector machines;Testing;Training data","support vector machines","SVM-RFE approach;binary feature selection;credit evaluating problem;ensemble techniques;feature selection algorithm;multiclass classification problem;ranking problem;support vector machine recursive feature elimination","","1","","10","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"A Smoothing Function for 1-norm Support Vector Machines","W. Ruo-Peng; X. Hong-Min","Dept. of Math. & Phys., Beijing Inst. of Petro-Chem. Technol., Beijing, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","450","454","In this paper, a novel smoothing function method for the 1-norm support vector regression (SVR for short) is proposed and an attempt to overcome some drawbacks of former method which are complex, subtle, and sometimes difficult to implement. The model of smoothing support vector machine (SVM) based on 1-norm is provided from the optimization problem, yet it is discrete programming. With the smoothing technique and optimality knowledge, the discrete programming is changed into a continuous programming. Experimental results show that the algorithm is easy to implement and this method is fast and insensitive to initial point. Theory analysis illustrate that smoothing function method for 1-norm SVM are feasible and effective.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365744","Support Vector Machine (SVM);algorithm;optimization;smoothing function","Equations;Kernel;Machine learning algorithms;Mathematics;Neural networks;Physics computing;Predictive models;Smoothing methods;Support vector machine classification;Support vector machines","optimisation;regression analysis;support vector machines","1-norm support vector regression;continuous programming;discrete programming;optimization problem;smoothing function;support vector machines","","0","","12","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Method Based on Generation Models for Analyzing Sentiment-Topic in Texts","N. Fan; W. d. Cai; Y. Zhao","Coll. of Comput. Sci., Northwestern Polytech. Univ., Xi'an, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","5","This paper proposes a method based on generation model for sentiment analysis and topic identification in texts. Firstly sentiment and topic of training texts are labeled by hand and sentiment models and topic models are established. Secondly compute the Kullback-Leibler divergence between a testing text and sentiment models in order to determine sentiment of the text. Similarly, calculate the Kullback-Leibler divergence between the testing text and topic model, so the topic of text can be identified. The unigram and bigram of words are employed as the model parameters, and correspondingly maximum likelihood estimation and some smoothing techniques are used to estimate these parameters. Empirical experiments on product reviews corpus show that this language modeling approach performs better than SVM and obtains improvement on precision. Moreover this method is better than SVM in robustness.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5362943","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362943","","Computer aided instruction;Computer science;Data mining;Educational institutions;Information analysis;Machine learning algorithms;Maximum likelihood estimation;Support vector machine classification;Support vector machines;Testing","data mining;maximum likelihood estimation;text analysis","Kullback-Leibler divergence;language modeling;maximum likelihood estimation;sentiment-topic analysis;smoothing technique;topic identification;word bigram;word unigram","","0","","9","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Nonsmooth Bilevel Programming for Hyperparameter Selection","G. M. Moore; C. Bergeron; K. P. Bennett","Dept. of Math. Sci., Rensselaer Polytech. Inst., Troy, NY, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","374","381","We propose a nonsmooth bilevel programming method for training linear learning models with hyperparameters optimized via T-fold cross-validation (CV). This algorithm scales well in the sample size. The method handles loss functions with embedded maxima such as in support vector machines. Current practice constructs models over a predefined grid of hyperparameter combinations and selects the best one, an inefficient heuristic. Innovating over previous bilevel CV approaches, this paper represents an advance towards the goal of self-tuning supervised data mining as well as a significant innovation in scalable bilevel programming algorithms. Using the bilevel CV formulation, the lower-level problems are treated as unconstrained optimization problems and are replaced with their optimality conditions. The resulting nonlinear program is nonsmooth and nonconvex. We develop a novel bilevel programming algorithm to solve this class of problems, and apply it to linear least-squares support vector regression having hyperparameters C (tradeoff) and e (loss insensitivity). This new approach outperforms grid search and prior smooth bilevel CV methods in terms of modeling performance. Increased speed foresees modeling with an increased number of hyperparameters.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360434","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","data mining;learning (artificial intelligence);optimisation;regression analysis;support vector machines","T-fold cross-validation;hyperparameter combinations grid;linear learning training models;linear least-squares support vector regression;loss functions;nonlinear program;nonsmooth bilevel programming;self-tuning supervised data mining;support vector machines;unconstrained optimization problems","","2","","19","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"GLSVM: Integrating Structured Feature Selection and Large Margin Classification","H. Fei; B. Quanz; J. Huan","EECS Dept., Univ. of Kansas, Lawrence, KS, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","362","367","High dimensional data challenges current feature selection methods. For many real world problems we often have prior knowledge about the relationship of features. For example in microarray data analysis, genes from the same biological pathways are expected to have similar relationship to the outcome that we target to predict. Recent regularization methods on support vector machine (SVM) have achieved great success to perform feature selection and model selection simultaneously for high dimensional data, but neglect such relationship among features. To build interpretable SVM models, the structure information of features should be incorporated. In this paper, we propose an algorithm GLSVM that automatically perform model selection and feature selection in SVMs. To incorporate the prior knowledge of feature relationship, we extend standard 2 norm SVM and use a penalty function that employs a L<sub>2</sub> norm regularization term including the normalized Laplacian of the graph and L<sub>1</sub> penalty. We have demonstrated the effectiveness of our methods and compare them to the state-of-the-art using two real-world benchmarks.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360432","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","Laplace equations;pattern classification;support vector machines","GLSVM;biological pathways;feature selection;genes;high dimensional data;margin classification;microarray data analysis;norm regularization term;normalized Laplacian;penalty function;support vector machine","","0","","31","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Measures for Unsupervised Fuzzy-Rough Feature Selection","N. M. Parthaláin; R. Jensen","Dept. of Comput. Sci., Aberystwyth Univ., Aberystwyth, UK","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","560","565","For supervised learning, feature selection algorithms attempt to maximise a given function of predictive accuracy. This function usually considers the ability of feature vectors to reflect decision class labels. It is therefore intuitive to retain only those features that are related to or lead to these decision classes. However, in unsupervised learning, decision class labels are not provided, which poses questions such as; which features should be retained? and, why not use all of the information? The problem is that not all features are important. Some of the features may be redundant, and others may be irrelevant and noisy. In this paper, some new fuzzy-rough set-based approaches to unsupervised feature selection are proposed. These approaches require no thresholding or domain information, and result in a significant reduction in dimensionality whilst retaining the semantics of the data.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364976","Feature selection;fuzzy-rough sets;unsupervised","Accuracy;Application software;Computer science;Data mining;Intelligent systems;Machine learning;Set theory;Supervised learning;Uncertainty;Unsupervised learning","fuzzy set theory;unsupervised learning","decision class labels;dimensionality whilst retaining;feature vectors;fuzzy rough feature selection;predictive accuracy function;reflect decision class;semantics data;significant reduction result;thresholding domain information;unsupervised learning","","3","","17","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Integrating Knowledge in Search of Biologically Relevant Genes","Z. Zhao; S. Sharma; N. Agarwal; H. Liu; J. Wang; Y. Chang","Dept. of Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","88","93","Gene selection aims at detecting biologically relevant genes to assist biologists' research. The cDNA microarray data used in gene selection is usually ""wide"". With more than ten thousand genes, but only less than a hundred of samples, many biologically irrelevant genes can gain their statistical relevance by sheer randomness. Moreover, even for genes that are biologically relevant, biologists often prefer the ""trigger"" to the ""fire"". Addressing these problems goes beyond what the cDNA microarray can offer and necessitates the use of additional information. Recent developments in bioinformatics have made various knowledge sources available, such as the KEGG pathway repository and gene ontology database. Integrating different types of knowledge for gene selection could provide more information about genes and samples. In this work, we propose a novel framework to integrate different types of knowledge for identifying biologically relevant genes. The framework converts different types of external knowledge to its internal knowledge, which can be used to rank genes. Upon obtaining the ranking lists, it aggregates them via a probabilistic model and generates a final ranking list. Experimental results from our study on acute lymphoblastic leukemia demonstrate the novelty and efficacy of the proposed framework and show that using different types of knowledge together can help detect biologically relevant genes.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360522","","Bioinformatics;Biological processes;Biology;Clustering algorithms;Data mining;Databases;Fires;Machine learning algorithms;Ontologies;Pediatrics","biology computing;genetics;ontologies (artificial intelligence);probability","KEGG pathway repository;acute lymphoblastic leukemia;biologically relevant genes;cDNA microarray data;gene ontology database;gene selection;probabilistic model;statistical relevance","","0","","18","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Inductive Query Answering and Concept Retrieval Exploiting Local Models","C. d'Amato; N. Fanizzi; F. Esposito; T. Lukasiewicz","Comput. Sci. Dept., Univ. of Bari, Bari, Italy","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","1209","1214","We present a classification method, founded in the instance-based learning and the disjunctive version space approach, for performing approximate retrieval from knowledge bases expressed in Description Logics. It is able to supply answers, even though they are not logically entailed by the knowledge base (e.g. because of its incompleteness or when there are inconsistent assertions). Moreover, the method may also induce new knowledge that can be employed to make the ontology population task semiautomatic. The method has been experimentally tested showing that it is sound and effective.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364117","Classification;Description Logics;Dissimilarity Measure;Inductive Learning;Query Answering;Semantic Web","Acoustic testing;Application software;Computer science;Intelligent systems;Laboratories;Logic design;Machine learning;Neural networks;Ontologies;Semantic Web","formal logic;information retrieval;learning (artificial intelligence);pattern classification","approximate retrieval;classification method;concept retrieval;description logics;disjunctive version space approach;inductive query answering;instance based learning;knowledge bases;local models","","0","","17","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Order Independent Incremental Evolving Fuzzy Grammar Fragment Learner","N. M. Sharef; T. Martin; Y. Shen","Dept. of Comput. Sci., Univ. of Putra Malaysia, Malaysia","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","1221","1226","It is generally known that most incremental learning systems are order dependent, i.e provide results that depend on the particular order of the data presentation. Our previous work has developed an incremental soft computing algorithm which can be applied to learn text fragment patterns in semi-structured texts. A set of fuzzy grammar fragments is evolved, able to recognize the string set used as examples and any similar strings. Slight modification of the grammar fragments is performed to learn new patterns. This paper investigates the theoretical aspects of order-independence in the algorithm and shows that equivalent grammar fragments are produced irrespective of the order in which illustrative examples are presented.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364122","fuzzy evolving;fuzzy grammar fragment;incremental learning;independent incremental learner;text fragment learning","Application software;Artificial intelligence;Computer science;Costs;Fuzzy systems;Humans;Information technology;Intelligent systems;Learning systems;Machine learning","fuzzy set theory;grammars;learning (artificial intelligence)","fuzzy grammar fragment learner;incremental learning system;order-independence;text fragment learning","","3","","13","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"The adaptive learning mechanism design for game agents' real-time behavior control","Y. She; P. Grogono","Department of Computer Science and Software Engineering, Faculty of Engineering and Computer Science, Concordia University, Montreal, Quebec, Canada","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","792","796","In this paper, we present an approach of adaptive learning mechanism for game agents' real-time behavior control. This approach mainly focuses on how to generate game agent's adaptability in real-time. It is possible to apply our approach in complicated game character interactions by following the framework discussed in this paper. We consider the layered architecture, the behavior pattern and the adaptive mechanism design to be the three key points of our approach. We provide a brief example of how to apply adaptive learning in game agents' behavior processing. From this example, we demonstrate that the planning and learning process is fast enough to have 3D model rendered in time.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358028","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358028","","Adaptive control;Adaptive systems;Artificial intelligence;Computer science;Content addressable storage;Learning systems;Machine learning;Personal communication networks;Programmable control;Real time systems","adaptive systems;computer games;learning (artificial intelligence);multi-agent systems","adaptive learning mechanism design;behavior pattern;game agents adaptability;game agents real-time behavior control;game character interaction","","0","","13","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Set-Based Boosting for Instance-Level Transfer","E. Eaton; M. desJardins","Artificial Intell. Lab., Lockheed Martin Adv. Technol. Labs., Cherry Hill, NJ, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","422","428","The success of transfer to improve learning on a target task is highly dependent on the selected source data. Instance-based transfer methods reuse data from the source tasks to augment the training data for the target task. If poorly chosen, this source data may inhibit learning, resulting in negative transfer. The current best performing algorithm for instance-based transfer, TrAdaBoost, performs poorly when given irrelevant source data. We present a novel set-based boosting technique for instance-based transfer. The proposed algorithm, TransferBoost, boosts both individual instances and collective sets of instances from each source task. In effect, TransferBoost boosts each source task, assigning higher weight to those source tasks which show positive transferability to the target task, and then adjusts the weights of the instances within each source task via AdaBoost. The results demonstrate that TransferBoost significantly improves transfer performance over existing instance-based algorithms when given a mix of relevant and irrelevant source data.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360442","","Boosting;Costs;Data mining;Investments;Iterative algorithms;Knowledge transfer;Laboratories;Machine learning algorithms;Training data;USA Councils","learning (artificial intelligence)","TrAdaBoost algorithm;TransferBoost algorithm;instance based transfer;set based boosting method","","3","","18","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Entity-Relation Extraction for Chinese Based on Pattern Evolution and PageRank","Y. Liu; R. Chen; H. Yang","Sch. of Inf. Sci. & Technol., Dalian Maritime Univ., Dalian, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Based on DIPRE, we use such knowledge as synonymy relation and hyponymy relation to evolve the extraction pattern in order to make the extraction pattern set become more expressive. Additionally, we use PageRank algorithm for reference to rank these entity-pairs in final result set so that the result set is global optimum. Experiments reveal that the new algorithm may not only enhance recall rate but greatly enhance precision rate.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5364487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364487","","Clustering algorithms;Data mining;Information science;Iterative methods;Kernel;Learning systems;Machine learning algorithms;Tagging;Tree graphs;World Wide Web","feature extraction;pattern recognition","Chinese based;DIPRE;enhance precision rate;enhance recall rate;entity relation extraction;extraction pattern set;global optimum result set;hyponymy relation;pagerank algorithm;pattern evolution;synonymy relation knowledge","","1","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Prioritizing Use Cases to Aid Ordering of Scenarios","S. P. G.; H. Mohanty","Dept. of Comput. & Inf. Sci., Univ. of Hyderabad, Hyderabad, India","2009 Third UKSim European Symposium on Computer Modeling and Simulation","20091228","2009","","","136","141","Models are used as the basis for design and testing of software. The unified modeling language (UML) is used to capture and model the requirements of a software system. One of the major requirements of a development process is to detect defects as early as possible. Effective prioritization of scenarios helps in early detection of defects as well maximize effort and utilization of resources. Use case diagrams are used to represent the requirements of a software system. In this paper, we propose using data captured from the primitives of the use case diagrams to aid in prioritization of scenarios generated from activity diagrams. Interactions among the primitives in the diagrams are used to guide prioritization. Customer prioritization of use cases is taken as one of the factors. Preliminary results on a case study indicate that the technique is effective in prioritization of test scenarios.","","POD:978-1-4244-5345-0","10.1109/EMS.2009.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358815","UML;activity diagram;prioritization;scenarios;use case diagram","Computational modeling;Computer simulation;Costs;Fault detection;Machine learning algorithms;Performance evaluation;Software systems;Software testing;Unified modeling language;Visualization","Unified Modeling Language;program testing","customer prioritization;software design;software testing;unified modeling language;use case diagram","","1","","15","","","25-27 Nov. 2009","","IEEE","IEEE Conference Publications"
"A Global-Model Naive Bayes Approach to the Hierarchical Prediction of Protein Functions","C. N. Silla Jr.; A. A. Freitas","Sch. of Comput. & Centre for Biomed. Inf., Univ. of Kent, Canterbury, UK","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","992","997","In this paper we propose a new global-model approach for hierarchical classification, where a single global classification model is built by considering all the classes in the hierarchy - rather than building a number of local classification models as it is more usual in hierarchical classification. The method is an extension of the flat classification algorithm naive Bayes. We present the extension made to the original algorithm as well as its evaluation on eight protein function hierarchical classification datasets. The achieved results are positive and show that the proposed global model is better than using a local model approach.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360345","bayesian classification;hierarchical classification;protein function prediction","Bioinformatics;Biomedical computing;Biomedical informatics;Classification algorithms;Classification tree analysis;Data mining;Machine learning algorithms;Predictive models;Proteins;Testing","belief networks;bioinformatics","global classification model;hierarchical classification;local classification models;naive Bayes approach;protein functions prediction","","7","","18","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Toolkit-Based High-Performance Data Mining of Large Data on MapReduce Clusters","D. Wegener; M. Mock; D. Adranale; S. Wrobel","Fraunhofer Inst. Intell. Anal. & Inf. Syst. IAIS, St. Augustin, Germany","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","296","301","The enormous growth of data in a variety of applications has increased the need for high performance data mining based on distributed environments. However, standard data mining toolkits per se do not allow the usage of computing clusters. The success of MapReduce for analyzing large data has raised a general interest in applying this model to other, data intensive applications. Unfortunately current research has not lead to an integration of GUI based data mining toolkits with distributed file system based MapReduce systems. This paper defines novel principles for modeling and design of the user interface, the storage model and the computational model necessary for the integration of such systems. Additionally, it introduces a novel system architecture for interactive GUI based data mining of large data on clusters based on MapReduce that overcomes the limitations of data mining toolkits. As an empirical demonstration we show an implementation based on Weka and Hadoop.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360421","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","data mining;graphical user interfaces","MapReduce clusters;MapReduce system;computational model;computing clusters;data analysis;data intensive application;distributed environment;distributed file system;graphical user interfaces;interactive GUI;standard data mining toolkit;system architecture;toolkit-based high performance data mining","","16","3","14","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Clonal Selection Algorithm for Global Optimization Problems","X. Liu; L. Shi; R. Chen; H. Chen","Educ. Center of Modern Technol., Hunan Univ. of Commerce, Changsha, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","In order to increase the diversity of immune algorithm when solving high-dimensional global optimization problems, a novel clonal selection algorithm with randomized clonal expansion strategy(RCSA) is proposed. The main characteristic of RCSA is clonal expansion. In addition, a novel performance evaluation criterion is constructed in this paper, by which the performance of different population-based algorithms can be compared easily. In the experimental study, firstly we obtain an appropriate value of the ratio of clonal expansion through some traditional test functions. Next several conventional clonal selection algorithms are used to validate the performance of proposed RCSA. The experimental results of the RCSA are significantly better than that of the conventional CSAs.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5363636","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363636","","Ant colony optimization;Application software;Artificial immune systems;Business;Cloning;Educational technology;Genetic mutations;Immune system;Machine learning algorithms;Testing","artificial immune systems","clonal selection algorithm;global optimization problem;high-dimensional global optimization;immune algorithm;performance evaluation criterion;population based algorithm;randomized clonal expansion strategy","","1","","11","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Learning the Shared Subspace for Multi-task Clustering and Transductive Transfer Classification","Q. Gu; J. Zhou","Dept. of Autom., Tsinghua Univ., Beijing, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","159","168","There are many clustering tasks which are closely related in the real world, e.g. clustering the Web pages of different universities. However, existing clustering approaches neglect the underlying relation and treat these clustering tasks either individually or simply together. In this paper, we will study a novel clustering paradigm, namely multi-task clustering, which performs multiple related clustering tasks together and utilizes the relation of these tasks to enhance the clustering performance. We aim to learn a subspace shared by all the tasks, through which the knowledge of the tasks can be transferred to each other. The objective of our approach consists of two parts: (1) Within-task clustering: clustering the data of each task in its input space individually; and (2) Cross-task clustering: simultaneous learning the shared subspace and clustering the data of all the tasks together. We will show that it can be solved by alternating minimization, and its convergence is theoretically guaranteed. Furthermore, we will show that given the labels of one task, our multi-task clustering method can be extended to transductive transfer classification (a.k.a. cross-domain classification, domain adaption). Experiments on several cross-domain text data sets demonstrate that the proposed multi-task clustering outperforms traditional single-task clustering methods greatly. And the transductive transfer classification method is comparable to or even better than several existing transductive transfer classification approaches.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360241","cross domain classification;domain adaption;multi-task clustering;multi-task learning;transductive transfer classification;transfer learning","Automation;Clustering methods;Convergence;Data mining;History;Information science;Intelligent systems;Laboratories;Machine learning;Web pages","learning (artificial intelligence);minimisation;pattern clustering","clustering performance;cross-domain classification;cross-task clustering;data clustering;domain adaption;learning;minimization;multitask clustering;transductive transfer classification;within-task clustering","","47","","39","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"The Application Research of Topic Word List In Text Automatic Classification","H. Huang; Q. Liu; L. Wu; T. Huang; S. Yuan","Eng. & Res. Center for Inf. Technol. on Educ., Huazhong Normal Univ., Wuhan, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","111","114","When the traditional text classification technologies classify academic dissertations, the dimension of extracted feature terms is high, and they can't represent the theme of thesis. it makes the efficiency is very low and the accuracy rate is not high. The topic words are small in quantity and can reflect the theme of thesis well. Accordingly, the paper proposes to extract the topic words with topic word list and uses topic words as feature terms. Then using the Bayesian classification method classifies vast texts. The experiments show that the Bayesian classification method using topic words as feature terms can greatly reduce the dimension and improve the efficiency of classification, when the dimension of feature terms is equivalent, the accuracy of Bayesian classification method using topic words as feature terms is also higher than the traditional Bayesian text classification methods.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362266","Bayes Classification;Text Classification;topic word","Bayesian methods;Classification algorithms;Data mining;Feature extraction;Information technology;Machine learning algorithms;Support vector machine classification;Support vector machines;Terminology;Text categorization","text analysis;word processing","Bayesian classification method;Bayesian text classification methods;academic dissertations;feature terms extraction;text automatic classification;topic word list","","0","","4","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Privacy-Preserving Query Checking in Query Middleware","N. Hu","Sch. of Inf. Manage., Shanghai Finance Univ., Shanghai, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","590","594","With the development of the grid technology used in business field, it becomes more and more important to preserve privacy in information sharing field. This paper proposes a privacy-preserving query middleware PPQM based on credible third party in grid database, and fulfill privacy-preserving checking algorithm in PPQM to make privacy-preserving optimization of query plan before query assignment, through experiments, PPQM can effectively preserve private information and improve secure query efficiency in the application of commercial environment.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358501","Grid;Privacy Preserve;Query Plan","Access control;Costs;Data mining;Data privacy;Databases;Machine learning algorithms;Middleware;Ontologies;Query processing;Scheduling algorithm","data privacy;grid computing;information networks;middleware;query processing","grid database;information sharing privacy;privacy preserving query checking;privacy preserving query middleware;query assignment;query plan;secure query efficiency improvement","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Vietnamese Noun Phrase Chunking Based on Conditional Random Fields","N. T. H. Thao; N. P. Thai; N. L. Minh; H. Q. Thuy","Coll. of Technolgy, Vietnam Nat. Univ., Hanoi, Vietnam","2009 International Conference on Knowledge and Systems Engineering","20091228","2009","","","172","178","Noun phrase chunking is an important and useful task in many natural language processing applications. It is studied well for English, however with Vietnamese it is still an open problem. This paper presents a Vietnamese noun phrase chunking approach based on conditional random fields (CRFs) models. We also describe a method to build Vietnamese corpus from a set of hand annotated sentences. For evaluation, we perform several experiments using different feature settings. Outcome results on our corpus show a high performance with the average of recall and precision 82.72% and 82.62% respectively.","","POD:978-1-4244-5086-2","10.1109/KSE.2009.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361712","","Data mining;Educational institutions;Knowledge engineering;Machine learning;Natural language processing;Natural languages;Performance evaluation;Systems engineering and theory;Terminology;Writing","natural language processing;random processes;text analysis","Vietnamese corpus;Vietnamese noun phrase chunking;conditional random field model;hand annotated sentences;natural language processing","","3","","24","","","13-17 Oct. 2009","","IEEE","IEEE Conference Publications"
"Semi-supervised Density-Based Clustering","L. Lelis; J. Sander","Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","842","847","Most of the effort in the semi-supervised clustering literature was devoted to variations of the K-means algorithm. In this paper we show how background knowledge can be used to bias a partitional density-based clustering algorithm. Our work describes how labeled objects can be used to help the algorithm detecting suitable density parameters for the algorithm to extract density-based clusters in specific parts of the feature space. Considering the set of constraints estabilished by the labeled dataset we show that our algorithm, called SSDBSCAN, automatically finds density parameters for each natural cluster in a dataset. Four of the most interesting characteristics of SSDBSCAN are that (1) it only requires a single, robust input parameter, (2) it does not need any user intervention, (3) it automatically finds the noise objects according to the density of the natural clusters and (4) it is able to find the natural cluster structure even when the density among clusters vary widely. The algorithm presented in this paper is evaluated with artificial and real-world datasets, demonstrating better results when compared to other unsupervised and semi-supervised density-based approaches.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360321","Semi-supervised;density-based clustering","Clustering algorithms;Data mining;Indium phosphide;Machine learning;Machine learning algorithms;Noise figure;Noise robustness;Object detection;Partitioning algorithms;Semisupervised learning","data handling;learning (artificial intelligence)","K-means algorithm;labeled dataset;natural cluster structure;partitional density-based clustering algorithm;semisupervised density-based clustering","","13","","10","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"CoCoST: A Computational Cost Efficient Classifier","L. Li; U. Topkara; B. Coskun; N. Memon","Comput. Sci. & Eng. Dept., NYU, Brooklyn, NY, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","268","277","Computational cost of classification is as important as accuracy in on-line classification systems. The computational cost is usually dominated by the cost of computing implicit features of the raw input data. Very few efforts have been made to design classifiers which perform effectively with limited computational power; instead, feature selection is usually employed as a pre-processing step to reduce the cost of running traditional classifiers. We present CoCoST, a novel and effective approach for building classifiers which achieve state-of-the-art classification accuracy, while keeping the expected computational cost of classification low, even without feature selection. CoCost employs a wide range of novel cost-aware decision trees, each of which is tuned to specialize in classifying instances from a subset of the input space, and judiciously consults them depending on the input instance in accordance with a cost-aware meta-classifier. Experimental results on a network flow detection application show that, our approach can achieve better accuracy than classifiers such as SVM and random forests, while achieving 75%-90% reduction in the computational costs.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360252","Cost Efficient Decision Tree;Inverse-Boosting;Meta-Classifier;Suppressed Cost","Classification tree analysis;Computational efficiency;Computer science;Costs;Data engineering;Data mining;Decision trees;Feature extraction;Machine learning;Testing","decision trees;learning (artificial intelligence);support vector machines","CoCoST;SVM;computational cost efficient classifier;cost-aware decision trees;feature selection;network flow detection;online classification systems","","2","","27","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Fitness Sharing Based on Angular Distances","H. Berg","Fac. of Comput. Sci., Ostfold Univ. Coll., Halden, Norway","2009 Fifth International Conference on Natural Computation","20091228","2009","4","","237","243","It is commonly believed that diversity is crucial for an evolutionary system to succeed, especially when the problem to be solved contains local optima from which the population cannot easily escape. There exist numerous methods to maintain the diversity of an evolving population, but it is not always clear what kind of diversity is helpful in a given situation. In this paper we show that striving to maintain high angular distances between the fitness vectors of the individuals in a population leads to better results in most cases considered. Without increased computational costs, our angular sharing scheme enables the evolutionary system in most cases to find better solutions than other sharing schemes investigated.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366129","Diversity;Evolution Strategies;Evolutionary Computation;Fitness Sharing","Computational efficiency;Computer science;Educational institutions;Encoding;Evolutionary computation;Machine learning;Measurement standards;Performance evaluation;Robustness;Search methods","evolutionary computation","angular distances;angular sharing scheme;diversity;evolutionary system;fitness sharing scheme","","0","","30","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Using SVM to Learn the Efficient Set in Multiple Objective Discrete Optimization","H. Z. Zheng; X. D. Zhang; H. Y. Guo","Coll. of Comput. Sci. & Technol., Harbin Inst. of Technol., Weihai, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","6","","489","493","It proposed an idea of using support vector machines (SVMs) to learn the efficient set of a multiple objective discrete optimization (MODO) problem. We conjecture that a surface generated by SVM could provide a good approximation of the efficient set. As the efficient set is learned at a single SVM implementation by using a group of seeds that symbolize efficient and dominated solutions. To be able to observe whether learning the efficient set via SVMs might have practical implications, we incorporate the SVM-induced efficient set into a GA as a fitness function. We implement our SVM-guided GA on the multiple objective knapsack and assignment problems. We observe that using SVM improves the performance of the GA compared to a benchmark distance based fitness function and may provide competitive results. Our approach is a general one and can be applied to any MODO problem with any number of objective functions.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359900","Efficient Set;MODO;SVM","Computer science;Educational institutions;Fuzzy systems;Machine learning;Mathematical programming;Risk management;Space technology;Statistical learning;Support vector machine classification;Support vector machines","genetic algorithms;knapsack problems;learning (artificial intelligence);support vector machines","GA;SVM;assignment problems;efficient set;fitness function;genetic algorithm;knapsack problems;learning;multiple objective discrete optimization;support vector machine","","0","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Learning Algorithm of LS-SVM Based on Quadratic Renyi-Entropy and Empirical Analysis","G. Zhao; Z. Juan","Sch. of Accounting, Shandong Univ. of Finance, Jinan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","6","This paper applies quadratic Renyi entropy to enterprise financial distress prediction and puts forward a learning algorithm of least squares support vector machines (LS-SVM) based on quadratic Renyi entropy. By respectively analysis and comparison of the algorithm with the traditional LS-SVM, the standard SVM, MLR and BP-ANN, we can see that this algorithm is significantly superior to other algorithms and has good stability, whether in the aspect of the number of training samples or the operation time. Empirical analysis shows that it is successful to apply quadratic Renyi entropy to enterprise financial distress prediction fields. At the same time, through doing test of significance and making factor analysis to initial input variable, the number of input variables decreases, but the prediction accuracy rate reaches 88%. So the method of factor analysis proves to be effective in this paper.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5364622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364622","","Accuracy;Algorithm design and analysis;Entropy;Forward contracts;Input variables;Least squares methods;Machine learning;Stability analysis;Support vector machines;Testing","entropy;financial management;least squares approximations;support vector machines","BP-ANN algorithm;LS-SVM learning algorithm;artificial neural nets;backpropagation;financial distress prediction;least squares support vector machines;quadratic Renyi entropy","","0","","11","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Rejecting Mismatches between Fish-Eye Camera Images by RVM","X. Li; X. Li; X. Cheng","Sch. of Math. Sci., South China Normal Univ., Guangzhou, China","2009 Fifth International Conference on Natural Computation","20091228","2009","5","","293","295","Establishing reliable correspondence points is a fundamental problem in computer vision. In this work, we studied mismatch-rejecting between two fish-eye camera image by RVM learnings. The fundamental idea that, for given two fish-eye images of a scene, the corresponding points constitute a manifold in joint-image space R<sup>4</sup>, and outliers can be detected by checking whether they are consistent with the upward views of the manifold. Experiments on real image pairs demonstrate the excellent performance and feasibility of our proposed method.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366552","correspondence problem;fish-eye images;reject mismatches","Cameras;Computer vision;Educational institutions;Layout;Learning systems;Machine learning;Mobile robots;Navigation;Robot vision systems","cameras;computer vision;learning (artificial intelligence)","RVM;computer vision;fish-eye camera images;joint-image space R<sup>4</sup>;panoramic vision techniques","","0","","18","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Knowledge Discovery from Text Learning for Ontology Modeling","E. H. Y. Lim; J. N. K. Liu; R. S. T. Lee","Dept. of Comput., Hong Kong Polytech. Univ., Hong Kong, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","7","","227","231","This paper presents a methodology of knowledge discovery from text learning for ontology modeling. Knowledge written in text is always hard to be extracted by automated process, and most existing ontologies are defined manually. Those ontologies are not comprehensive enough to express most human knowledge in the real world. Therefore, the most efficient way to identify knowledge is discovering it from rich text. In this paper, we proposed a statistical based method to measure the relation of appearing frequency of word in text. The method identifies and discovers knowledge by automated process. We also defined ontology model - ontology graph, to express knowledge, the graph facilitates machine and human processing. The extracted knowledge in the graph format can aid user to revise and define ontology knowledge more effectively and accurately.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359987","knowledge discovery;ontology;text learning","Content management;Frequency measurement;Fuzzy systems;Humans;Intelligent systems;Knowledge representation;Learning systems;Machine learning;Natural languages;Ontologies","data mining;learning (artificial intelligence);ontologies (artificial intelligence);text analysis","knowledge discovery;ontology modeling;statistical based method;text learning","","1","","11","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Attribute Reduction of Fuzzy Data Using a Pseudometric Based Resemblance Relation","M. Li; J. Wang; D. Wang","Sch. of Econ. & Manage., Univ. of Sci. & Technol. Beijing, Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","7","","112","116","The problem of attribute reduction has been proved to be NP-hard problem. We present an extension of attribute reduction algorithm to a general type of fuzzy data, in which a pseudometric based resemblance relation is introduced to model approximate equality between objects in the universe instead of fuzzy equivalence relation. We also give an extended quality of classification, which is used as a denominator in the reduction process. An example is given to illustrate the presented algorithm.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.514","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359961","","Conference management;Fuzzy sets;Fuzzy systems;Knowledge management;Machine learning;Mathematics;Power generation economics;Rough sets;Technology management;Uncertainty","approximation theory;computational complexity;fuzzy set theory;pattern classification","NP-hard problem;attribute reduction algorithm;classification quality;fuzzy data;model approximate equality;pseudometric based resemblance relation","","0","","22","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Ensemble learning for question classification","Lei Su; Hongzhi Liao; Zhengtao Yu; Quan Zhao","School of Software, Yunnan University, Kunming 650091, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","3","","501","505","In this paper, a new method for question classification is proposed, which employs ensemble learning algorithms to train multiple question classifiers. These component learners are combined to produce the final hypothesis. In detail, the feature spaces are obtained through extracting high-frequency keywords from questions corpus and the method of word semantic similarity is performed to adjust the feature weights. The ensemble methods, Bagging and AdaBoost, are applied to construct an ensemble of decision trees to tackle the problem of question classification respectively. Experiments on the Chinese question system of tourism domain show that the ensemble methods could effectively improve the classification accuracy.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358124","bagging;boosting;ensemble learning;question classification;word semantic similiarity","Automation;Bagging;Boosting;Classification tree analysis;Decision trees;Feature extraction;Machine learning;Machine learning algorithms;Neural networks;Voting","decision trees;learning (artificial intelligence);pattern classification","AdaBoost ensemble method;Bagging ensemble method;Chinese question system;decision tree;ensemble learning algorithm;final hypothesis production;high frequency keywords extraction;multiple question classifier;question classification;questions corpus;word semantic similarity","","1","","14","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Adaptivity in Entity Subscription Services","G. Giannakopoulos; T. Palpanas","DISI, Univ. of Trento, Trento, Italy","2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns","20091228","2009","","","61","66","Real-word entities can be mapped to unique entity identifiers through an Entity Name System (ENS), to systematically support the re-use of these identifiers and disambiguate references to real world entities in the Web. An entity subscription service informs subscribed users of changes in the descriptive data of an entity, which is a set of attribute name-value pairs. We study the design, implementation and application of an adaptable push-policy subscription service, within a large-scale ENS. The subscription system aims to deliver ranked descriptions of the changes on entities, following user preferences through a feedback-driven adaptation process. The adaptation is based on both the content and the type of each entity change. We evaluate the learning curve of the system and the utility of the content-type discrimination. The experiments demonstrate good results, especially in the system's content-aware adaptation aspect.","","POD:978-1-4244-5166-1","10.1109/ComputationWorld.2009.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359556","Adaptive systems;Artificial intelligence;User modeling","Artificial intelligence;Cities and towns;Concrete;Electronic mail;Large-scale systems;Machine learning;Scalability;Subscriptions;Web sites;World Wide Web","Web services;adaptive systems;user modelling","Web;attribute name value pairs;content aware adaptation aspect;content type discrimination;entity name system;entity subscription services adaptivity;push policy subscription service;real word entities;unique entity identifiers","","2","","21","","","15-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"Mining of Attribute Interactions Using Information Theoretic Metrics","P. Chanda; Y. R. Cho; A. Zhang; M. Ramanathan","Dept. of Comput. Sci. & Eng., State Univ. of New York, Buffalo, NY, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","350","355","Knowledge of the statistical interactions between the attributes in a data set provides insight into the underlying structure of the data and explains the relationships (independence, synergy, redundancy) between the attributes. In a supervised learning problem, normally, a small subset of the classifying attributes are actually associated with the class label. Interaction information among the attributes captures the multivariate dependencies (synergy and redundancy) among the attributes and the class label. Mining the significant statistical interactions that contain information about the class label is a computationally challenging task - the number of possible interactions increases exponentially and most of these interactions contain redundant information when a number of correlated attributes are present. In this paper, we present a data mining method (named IM or Interaction Mining) to mine non-redundant attribute sets that have significant interactions with the class label. We further demonstrate that the mined statistical interactions are useful for improved feature selection as they successfully capture the multivariate inter-dependencies among the attributes.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360430","","Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data","data mining;information theory;learning (artificial intelligence);statistics","data attributes;information theory;redundancy dependency;statistical interactions mining;supervised learning;synergy dependency","","2","","15","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Feature Selection Method Using Weighted Clusterer Ensemble","S. Xiong; Y. Luo","Dept. of Inf., Hunan Univ. of Commerce, Changsha, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Processing applications with a large number of dimensions has been a challenge to the data mining community. Feature selection is an effective dimensionality reduction technique. However, there are only a few methods proposed for feature selection for clustering. In this paper, a new feature selection algorithm for unsupervised learning is introduced. It is based on the assumption that, in absence of class labels, the weighted clusterer ensemble result can be employed as a heuristic to guide the feature selection. Therefore, the ReliefF algorithm is then used to assign the rankings for every feature. The main advantage of the proposed method in comparison to conventional schemes in unsupervised feature selection is that it is dimensionality unbiased. Our experiments with several data sets demonstrate that the proposed algorithm is able to detect completely irrelevant features and to remove some additional features without significantly hurting the performance of the clustering algorithm.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5364285","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364285","","Business;Clustering algorithms;Computer networks;Computer vision;Data mining;Filters;Machine learning;Neural networks;Robust stability;Unsupervised learning","data mining;feature extraction;pattern clustering;unsupervised learning","ReliefF algorithm;clustering algorithm;data mining;dimensionality reduction;feature ranking;feature selection;unsupervised learning;weighted clusterer ensemble","","0","","13","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Limited Tolerance Relation-Based Decision Tree Algorithm","T. L. Wang; L. Wang; G. P. Xia; Y. C. Xu","Sch. of Econ. & Manage., Beihang Univ., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","221","226","In this research, we study how to generate a decision tree from dataset with unknown values, and proposed a decision tree learning algorithm (LTR-C4.5). The algorithm based on limited tolerance relation and C4.5. Algorithm LTR-C4.5 is composed by two function modules: filling the unknown values and generating a decision tree. The algorithm recursive calls the two function modules when handling incomplete training samples. The outstanding feature of LTR-C4.5 is that it doesn't demand to fill all unknown values before generating a decision tree. Some experiments are used to simulation the algorithm and compared it to other methods.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358602","LTR-C4.5;decision tree;limited tolerance relation;missing values","Classification tree analysis;Conference management;Decision trees;Economic forecasting;Filling;Fuzzy systems;Knowledge management;Machine learning;Machine learning algorithms;Partitioning algorithms","decision trees;learning (artificial intelligence)","LTR-C4.5;function modules;limited tolerance relation-based decision tree algorithm","","0","","10","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"An intelligent model selection scheme based on particle swarm optimization","Jingtao Huang; Xiaomei Chi; Jianwei Ma","Electronic and Information Engineering College, Henan University of Science and Technology, Luoyang, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","882","886","To improve the learning efficiency of support vector machine, an intelligent model selection scheme based on particle swarm optimization (PSO) was presented to optimize the hyper-parameters. By taking the model selection problem as a multi-object optimization problem, one can obtain a solution set known as Pareto front; each one model in this set is non-dominated. PSO was used to solve the above multi-objective optimization problem and then the model set was obtained. The scheme was tested on several datasets, the results show that Pareto front can be obtained in one trial and the effect of every single parameter can be displayed more directly.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358047","Pareto front;intelligent model selection;multi-object optimization;particle swarm optimization(PSO);support vector machine","Computer errors;Educational institutions;Learning systems;Machine intelligence;Machine learning;Pareto optimization;Particle swarm optimization;Statistical learning;Support vector machine classification;Support vector machines","learning (artificial intelligence);particle swarm optimisation;support vector machines","Pareto front;hyperparameters;intelligent model selection;learning efficiency;multiobject optimization problem;multiobjective optimization;particle swarm optimization;support vector machine","","0","","20","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Adaptive danger area based Danger Model Immune Algorithm","Q. Xu; X. Meng; N. Wang; C. Zhang","Information science and Technology College, Dalian Maritime University, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","3","","109","112","Danger Model Immune Algorithm(DMIA) is an algorithm based on the danger theory of biological immune system. In the basic algorithm, the danger area is fixed through the initial setting. It is an important parameter which will affect the capability of algorithm. In this paper, propose an adaptive danger area DMIA. The radius of danger area is decrease gradually according to the iteration steps. The simulation results indicate that the adaptive danger area DMIA is valid and has better optimization capability.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358210","Adaptive danger area;Danger Model Immune Algorithm;danger signal;optimization","Artificial immune systems;Biological system modeling;Biology;Character recognition;Educational institutions;Electronic mail;Immune system;Information science;Machine learning;Navigation","artificial immune systems;genetic algorithms","adaptive danger area;biological immune system;danger model immune algorithm;optimization capability","","0","","12","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Incorporating Method of Invariance and SVM Based on the Best Approximate Point","G. Zhang; W. Wang; P. Wang","Sch. of Comput. & Inf. Technol., Shanxi Univ., Taiyuan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","One of key points in developing support vector machine (SVM) is the incorporating prior knowledge of learning task into SVM. A very common type of a prior knowledge is invariance of the input data. The research on incorporating method of invariance and SVM is an important focus for SVM in recent years, and it can help to improve the generalization performance efficiently. This paper describes and reviews the popular methods for incorporating invariance into SVM, and discusses their respective merits. Especially, it presents a new incorporating approach, which represents the trajectory manifold of invariance transformation by the best approximate point. And simulation experiments show this approach has some desirable theoretical properties. Comparing with the traditional SVM and Virtual SV (VSV) based on MNIST handwritten digit database, the presented approach can greatly improve the generalization performance of SVM.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5367170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367170","","Computational modeling;Cost function;Databases;Euclidean distance;Information technology;Machine learning;Manifolds;Pixel;Support vector machine classification;Support vector machines","approximation theory;learning (artificial intelligence);support vector machines","MNIST handwritten digit database;SVM;best approximate point;generalization performance;invariance transformation;learning task;support vector machine;trajectory manifold;virtual SV","","0","","15","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Application of Support Vector Machine in Structure Damage Identification","Y. Yang; T. y. Liu","Key Lab. of Fiber Opt. Sensing Technol., Wuhan Univ. of Technol., Wuhan, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","3","Since the security accident of structures occurred continually in recent years, the damage identification is paid close attention by scholars. The support vector machine (SVM) as a new method of statistical theory is applied to identify structural damage in this paper. The relative change quantity of modal flexibility, used as the characteristic index of damage identification, is input in SVM classifier to identify the location and degree of structural damage. A simulative simply supported beam is set up and input with different level noises. The analysis results indicate that this method is feasible to identify the location and degree of structure damage with low noise.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5363204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363204","","Accidents;Classification algorithms;Educational technology;Equations;Kernel;Machine learning algorithms;Monitoring;Optical fibers;Support vector machine classification;Support vector machines","accidents;condition monitoring;structural engineering computing;support vector machines","SVM classifier;civil engineering structure damage;modal flexibility;structure damage identification;structures security accident;support vector machine","","0","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Research on the Algorithm of Concept Lattice Isomorphic Judgment Based on Mapping of Equivalence Class","D. J. Han; L. Li; X. J. Shen","Software Res. Inst., Sun Yat-Sen Univ., Guangzhou, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Concept lattice has many applications and isomorphic judgment of concept lattice is important in some fields. This paper presents a novel algorithm of complete lattice isomorphic judgment. The algorithm, first, introduces a layer computing method which divides the nodes into four types according to their indegree and outdegree. Then the equivalence classes are created. Second, taking equivalence classes as least unit, our algorithm creates a mapping between the nodes of two equivalence classes and executes the process of isomorphic judgment using heuristic information of nodes which are extracted from complete lattice. Our algorithm has lower time complexity. And experiment result shows that our algorithm is efficient.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365023","","Application software;Computer science;Data mining;Database systems;Knowledge engineering;Lattices;Libraries;Machine learning;Software algorithms;Sun","computational complexity;equivalence classes;knowledge engineering","concept lattice;equivalence class;isomorphic judgment;knowledge system;layer computing;time complexity","","1","","5","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Detecting and Interpreting Variable Interactions in Observational Ornithology Data","D. Sorokina; R. Caruana; M. Riedewald; W. Hochachka; S. Kelling","SCS Carnegie Mellon Univ., Pittsburgh, PA, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","64","69","In this paper we demonstrate a practical approach to interaction detection on real data describing the abundance of different species of birds in the prairies east of the southern Rocky Mountains. This data is very noisy-predictive models built from it perform only slightly better than baseline. Previous approaches for interaction detection, including a recently proposed algorithm based on Additive Groves, often do not work well on such noisy data for a number of reasons. We describe the issues that appear when working with such data sets and suggest solutions to them. In the end, we discuss results of our analysis for several bird species.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360526","","Additive noise;Birds;Conferences;Data mining;Decision making;Detection algorithms;Machine learning;Performance analysis;Predictive models;Radiofrequency interference","data mining","Additive Groves;bird species;noisy data;noisy-predictive models;observational ornithology data;southern Rocky Mountains;variable interaction detection","","3","","12","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Support Vector Machine (SVM) and Traditional Chinese Medicine: Syndrome Factors Based an SVM from Coronary Heart Disease Treated by Prominent Traditional Chinese Medicine Doctors","J. Wang; Q. He; K. w. Yao; W. Rong; Y. Xing; Z. Yue","Cardiovascular Dept., China Acad. of Chinese Med. Sci., Beijing, China","2009 Fifth International Conference on Natural Computation","20091228","2009","2","","176","180","Support vector machines (SVM) have been widely used in many scientific research fields. This paper introduces an original study about the treating experiences of prominent traditional Chinese medicine (TCM) doctors on coronary heart disease (CHD) using SVM, and to investigate the general laws of prominent TCM doctors for treating CHD. A database of diagnosing and treating CHD was set up on the basis of 115 typical medical records. The syndrome factors and relevant studies were analyzed by SVM (data mining software Weka 3.4 is used). The quantitative diagnosis was confirmed and CHD characteristics were explained. The laws of medicate administration for 8 syndrome factors were summed up from prominent TCM doctors. Application of SVM will help to reveal innate regularity of experience of prominent TCM doctors, and deeply understand the academic thinking of them, in order to improve the level of treatment for CHD with TCM.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366522","Support vector machines;traditional Chinese medicine","Cardiac disease;Cardiology;Data preprocessing;Databases;Helium;Machine learning;Medical diagnostic imaging;Medical treatment;Myocardium;Support vector machines","cardiology;data mining;diseases;medical diagnostic computing;patient diagnosis;patient treatment;support vector machines","Weka 3.4;coronary heart disease diagnosis;data mining software;medicate administration;quantitative diagnosis;support vector machine;syndrome factors;traditional Chinese medicine","","0","","5","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Tolerance Rough Set-Inductive Logic Programming (RS-ILP)","R. Wang; P. Tang; C. Li; H. Liu","Dept. of Comuter Sci., Guangxi Univ. of Technol., Liuzhou, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","3","","179","183","Inductive Logic Programming (ILP) is one of the main approaches to relational learning, with the stronger expressive power and the ease of using background knowledge. However, compared with the traditional attribute-value learning methods, it is much less mature for ILP to deal with imperfect data. This paper applies the Tolerance Rough Set to ILP to further extend the RS-ILP model. We first investigate a new kind of Tolerance Rough Set model, which can deal with imperfect data (nominal and numerical) consistently, and then propose a Tolerance RS-ILP model, in which the tolerance rough problem settings are given, which can handle missing data, indiscernible data, and have a certain abilities to deal with noise data and imperfect output.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358931","","Artificial intelligence;Cognitive science;Data analysis;Data mining;Fuzzy systems;Learning systems;Logic programming;Machine learning;Mathematical model;Set theory","inductive logic programming;learning (artificial intelligence);rough set theory","attribute-value learning;inductive logic programming;nominal data;numerical data;relational learning;tolerance rough set model","","0","","10","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Battlefield Target Identification Based on Improved Grid-Search SVM Classifier","J. Li; C. Zhang; Z. Li","Sch. of Electron. & Inf., Northwestern Polytech. Univ., Xi'an, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Choosing the kernel and error penalty parameters for support vector machine (SVM) is very important for the performance of classifiers. An improved grid-search algorithm is proposed to choose the optimal parameters of SVM. The battlefield multi-target SVM classifier is designed using this algorithm. Also three classifiers including k-nearest neighborhood classifier, improved BP neural network classifier and SVM classifier are used to do the comparison experiments of targets classification. Result shows that the improved grid-search algorithm can reduce the SVM classifier's computational complexity effectively and improve its performance and classification accuracy.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365100","","Acoustic waves;Algorithm design and analysis;Computational complexity;Frequency;Kernel;Machine learning algorithms;Neural networks;Support vector machine classification;Support vector machines;Unmanned aerial vehicles","acoustic signal processing;backpropagation;computational complexity;military computing;neural nets;signal classification;support vector machines;target tracking","battlefield passive acoustic target identification;computational complexity;error penalty parameter;grid-search support vector machine classifier;improved BP neural network classifier;k-nearest neighborhood classifier;kernel parameter;targets classification","","1","","8","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Clustering for Complex and Massive Data","H. D. Meng; Y. C. Song; F. Y. Song; S. L. Wang","Inner Mongolia Univ. of Sci. & Technol., Baotou, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","For applications of clustering algorithms, the key techniques are to handle complicatedly distributed clusters and process massive data effectively and efficiently. On the basis of analysis and research of traditional clustering algorithms, a clustering algorithm based on density and adaptive density-reachable is presented in this paper, which can handle clusters of arbitrary shapes, sizes and densities. For very large databases, such as spatial database and multimedia database, the traditional clustering algorithms are of limitations in validity and scalability. According to the notion of clustering feature of BIRCH, an incremental clustering algorithm is designed and implemented, which solves the problems of effectiveness, space and time complexities of clustering algorithms for very large spatial databases.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365060","","Algorithm design and analysis;Clustering algorithms;Machine learning algorithms;Multimedia databases;Noise shaping;Partitioning algorithms;Sampling methods;Scalability;Shape;Spatial databases","computational complexity;pattern clustering;very large databases;visual databases","BIRCH;distributed clusters;incremental clustering algorithm;massive data clustering;multimedia database;space complexity;time complexity;very large spatial databases","","0","","11","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Efficient Web Service Annotation Method Utilizing Concept Mapping and Interface Expansion","G. Zou; Y. Xiang; Y. Gan; H. Sun; Z. Liu","Dept. of Comput. Sci. & Technol., Tongji Univ., Shanghai, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","2","","183","187","With the number of services published on the Internet growing at an explosive speed, it is difficult for service requesters to discover satisfactory web services. The reason for this phenomenon is that traditional service organization mode lacks semantic information metadata, which results in low discovery effect. In this paper, we firstly give a service description model and then present an overall framework for service semantic annotation. Based on constructed domain ontology, mapping function of interface concept set and service interface expansion algorithm are proposed respectively. Finally, web services annotation algorithm is presented. Extensible experiment results demonstrate that annotated web services by our proposed method can more satisfy requirements of service requesters than keyword-based described web services. It can achieve higher service discovery effectiveness.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.297","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358850","Web service;domain ontology;service annotation","Computer science;Dictionaries;Explosives;Fuzzy systems;Information resources;Machine learning;Ontologies;Web and internet services;Web services;XML","Internet;Web services;ontologies (artificial intelligence);user interfaces","Internet;concept mapping utilization;domain ontology;semantic information metadata;service description model;service interface expansion algorithm;service semantic annotation;web service annotation method","","0","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Based Hybrid Method for Chinese Location Recognition","S. Zhang","Dept. of Electron. & Commun. Eng., North China Electr. Power Univ., Baoding, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","This paper proposed a hybrid method of the Chinese location recognition which combines conditional random fields model and pattern-selection. The conditional random fields model is used based on statistic method, some interesting features have been proposed, the new probabilistic feature is proposed, which are used instead of binary feature functions, however, it is one of the several differences between this model and the most of the previous CRFs-based model, we also explore several new features in our model, which includes semantic information, local features, global features, diffusion feature, related features etc. The pattern selection is used for revising experimental results. Combined the rule-based and statistic-based, we evaluate this approach on large-scale corpus with open test method using People's Daily (January, 1998), the evaluation results show that our approach based on hybrid method significantly outperforms previous approaches.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5362950","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362950","","Character recognition;Hidden Markov models;Humans;Large-scale systems;Machine learning;Pattern recognition;Power engineering and energy;Statistics;Testing;Text recognition","pattern recognition;random processes","Chinese location recognition;binary feature functions;conditional random fields model;diffusion feature;hybrid method;pattern selection;probabilistic feature;semantic information;statistic method","","0","","6","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"General Purpose Input Variables Extraction: A Genetic Algorithm Based Procedure GIVE A GAP","S. Cateni; V. Colla; M. Vannucci","Scuola Superiore S. Anna, Pontedera, Italy","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","1278","1283","The paper presents an application of genetic algorithms to the problem of input variables selection for the design of neural systems. The basic idea of the proposed method lies in the use of genetic algorithms in order to select the set of variables to be fed to the neural networks. However, the main concept behind this approach is far more general and does not depend on the particular adopted model: it can be used for a wide category of systems, also non-neural, and with a variety of performance indicators. The proposed method has been tested on a simple case study, in order to demonstrate its effectiveness. The results obtained in the processing of experimental data are presented and discussed.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364011","genetic algorithm;neural network;variables selection","Algorithm design and analysis;Data mining;Feature extraction;Filters;Genetic algorithms;Input variables;Machine learning;Neural networks;Principal component analysis;Testing","genetic algorithms;neural nets","genetic algorithm;input variables selection;neural network design","","4","","31","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Maximum Margin Clustering with Multivariate Loss Function","B. Zhao; J. Kwok; C. Zhang","Dept. of Autom., Tsinghua Univ., Beijing, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","637","646","This paper presents a simple but powerful extension of the maximum margin clustering (MMC) algorithm that optimizes multivariate performance measure specifically defined for clustering, including normalized mutual information, rand index and F-measure. Different from previous MMC algorithms that always employ the error rate as the loss function, our formulation involves a multivariate loss function that is a non-linear combination of the individual clustering results. Computationally, we propose a cutting plane algorithm to approximately solve the resulting optimization problem with a guaranteed accuracy. Experimental evaluations show clear improvements in clustering performance of our method over previous maximum margin clustering algorithms.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360290","maximum margin clustering;multivariate performance measure","Clustering algorithms;Data mining;Error analysis;Labeling;Laboratories;Loss measurement;Machine learning algorithms;Mutual information;Performance loss;Support vector machines","data mining;learning (artificial intelligence)","F-measure;maximum margin clustering;multivariate loss function;normalized mutual information;rand index","","2","","29","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Improved BP Neural Network Model Based on Quasic-Newton Algorithm","N. Huang; L. Lin","Coll. of Inf. & Control Eng., Jilin Inst. of Chem. Technol., Jilin, China","2009 Fifth International Conference on Natural Computation","20091228","2009","2","","352","356","Aiming at the low learning rate, bad stability and local minimum problems in standard and some improved BP neural network, in this paper we proposes a novel BP neural network model which concentrates on two aspects: the choice of learning rate and the learning algorithm. In the new model we use Quasic-Newton algorithm to replace gradient descent algorithm or other learning algorithms, thus the new model not only avoids the local minimum problem but also mends the learning rate. On the other hand, the choice of the learning factor includes two keys, the expertise and the final output of neural network. By means of the two keys, we propose a kind of self-adaptive learning factor which can improve the learning ability and real-time learning ability of neural network. At last, several classical examples are utilized to validate the proposed new BP neural network. The simulations show the feasibility and validity of the proposed BP neural network compared with BP neural network based on gradient descent algorithm or Levenberg-Marquardt algorithm.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362691","BP neural network;Quasic-Newton algorithm;learning rate;local minimum;self-adaptive learning rate","Chemical technology;Computer networks;Control engineering;Educational institutions;Fuzzy control;Fuzzy neural networks;Machine learning algorithms;Mathematics;Neural networks;Stability","Newton method;backpropagation;neural nets","Levenberg-Marquardt algorithm;Quasic-Newton algorithm;backpropagation neural network model;gradient descent algorithm;improved BP neural network model;learning algorithm;low learning rate;self-adaptive learning factor","","5","","7","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Multi-class Classification for Wuhan Area's TM Image Based on Support Vector Machine","L. Liu; Z. Huang; X. Tan; Z. Zeng","Digital Eng. & Simulation Res. Center, Huazhong Univ. of Sci. & Technol., Wuhan, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","5","","401","404","This paper proposes a multi-class classification method based on Support Vector Machine (SVM), with an emphasis on classes of Wuhan area's water resources. First, this method builds a SVM model by selecting proper testing sample data of Wuhan area's TM image. Then, the image is classified as 5 classes based on the algorithm of SVM model. The experimental results show that this method has obvious advantages in accuracy, compared with the traditional method-Maximum likelihood, especially on classes of water resources.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360591","Support Vector Machine (SVM);Wuhan area's TM image;image classification","Fuzzy systems;Image classification;Lakes;Machine learning algorithms;Quadratic programming;Remote sensing;Satellites;Support vector machine classification;Support vector machines;Water resources","geography;image classification;support vector machines;water resources","TM image;Wuhan area;multiclass classification;support vector machine;water resources","","0","","12","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Exploring an Improved Decision Tree Based Weights","W. Guo; J. Yin; Z. Yang; X. Yang; L. Huang","Sch. of Inf. Sci. & Technol., Sun Yat-sen Univ., Guangzhou, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","139","143","Although decision tree learning has achieved great success in building classifier, most existing methods don't pay attention to unequal weights between different instances from training and testing data sets. However, many real world data sets are imbalanced in nature. In this paper, we introduce a new improved decision tree based weights, which considers imbalanced weights between different instances, to address the class imbalanced problems. The proposed decision tree algorithm is simple and more effective in implementation than previous decision trees. Also, the new proposed algorithm will be compared with C4.5 (a novel decision tree algorithm) experimentally and the experiment results testify that our proposed algorithm outperforms C4.5 significantly, in terms of the improvement of the classification accuracy in UCI data sets.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362958","cost-sensitive learning;imbalanced data;weight gain ratio;weight information entropy","Classification algorithms;Classification tree analysis;Decision trees;Hospitals;Information science;Machine learning;Machine learning algorithms;Medical tests;Sun;Testing","decision making;learning (artificial intelligence)","C4.5 algorithm;decision tree learning method;testing data set;training data set;weights decision tree","","1","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Building Classifiers with Independency Constraints","T. Calders; F. Kamiran; M. Pechenizkiy","Eindhoven Univ. of Technol., Eindhoven, Netherlands","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","13","18","In this paper we study the problem of classifier learning where the input data contains unjustified dependencies between some data attributes and the class label. Such cases arise for example when the training data is collected from different sources with different labeling criteria or when the data is generated by a biased decision process. When a classifier is trained directly on such data, these undesirable dependencies will carry over to the classifier's predictions. In order to tackle this problem, we study the classification with independency constraints problem: find an accurate model for which the predictions are independent from a given binary attribute. We propose two solutions for this problem and present an empirical validation.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360534","","Conferences;Constraint optimization;Data mining;Electronic mail;Labeling;Machine learning;Machine learning algorithms;Prediction algorithms;Predictive models;Training data","learning (artificial intelligence);pattern classification","biased decision process;classification;classifier learning;classifier prediction;classifier training;data attributes;data contains;independency constraints problem;labeling criteria;training data","","6","","7","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Novel Clustering Algorithms Based on Improved Artificial Fish Swarm Algorithm","Y. Cheng; M. Jiang; D. Yuan","Sch. of Inf. Sci. & Eng., Shandong Univ., Jinan, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","3","","141","145","An improved artificial fish swarm algorithm (IAFSA) is proposed, and its complexity is much less than the original algorithm (AFSA) because of a new proposed fish behavior. Based on IAFSA, two novel algorithms for data clustering are presented. One is the improved artificial fish swarm clustering (IAFSC) algorithm, the other is a hybrid fuzzy clustering algorithm that incorporates the fuzzy c-means (FCM) into the IAFSA. The performance of the proposed algorithms is compared with that of the particle swarm optimization (PSO), k-means and FCM respectively on Iris testing data. Simulation results show that the performance of the proposed algorithms is much better than that of the PSO, K-means and FCM. And the proposed hybrid fuzzy clustering algorithm avoids the FCM's weakness such as initialization value problem and local minimum problem.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.534","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358919","artificial fish swarm algorithm;data clustering;fuzzy C-means","Ant colony optimization;Artificial intelligence;Clustering algorithms;Data analysis;Iterative algorithms;Machine learning algorithms;Marine animals;Particle swarm optimization;Robustness;Testing","artificial life;fuzzy set theory;particle swarm optimisation;pattern clustering","clustering algorithms;data clustering;fish behavior;fuzzy c-means;hybrid fuzzy clustering algorithm;improved artificial fish swarm algorithm;improved artificial fish swarm clustering;iris testing data;k-means;particle swarm optimization","","6","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Outlier Detection Using Inductive Logic Programming","F. Angiulli; F. Fassetti","DEIS, Univ. of Calabria, Rende, Italy","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","693","698","We present a novel definition of outlier in the context of inductive logic programming. Given a set of positive and negative examples, the definition aims at singling out the examples showing anomalous behavior. We note that the task here pursued is different from noise removal, and, in fact, the anomalous observations we discover are different in nature from noisy ones. We discuss pecularities of the novel approach, present an algorithm for detecting outliers, discuss some examples of knowledge mined, and compare it with alternative approaches.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360296","Inductive Logic Programming;Outlier detection","Data mining;Encoding;Knowledge representation;Learning systems;Logic programming;Machine learning;Supervised learning","inductive logic programming;security of data","anomalous observations;inductive logic programming;noise removal;outlier detection","","2","","8","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Clustering Ensemble for Unsupervised Feature Selection","Y. Luo; S. Xiong","Dept. of Inf., Hunan Univ. of Commerce, Changsha, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","445","448","A new feature selection algorithm for unsupervised learning is proposed. It is based on the assumption that, in absence of class labels, the clustering ensemble result can be employed as a heuristic to guide the feature selection. Therefore, a modified RReliefF algorithm is then used to assign the rankings for every feature. The main advantage of the proposed unsupervised feature selection algorithm in comparison to conventional schemes is that it is dimensionality unbiased. Our experiments with several data sets demonstrate that the proposed algorithm is able to detect completely irrelevant features and to remove some additional features without significantly hurting the performance of the clustering algorithm.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358538","clustering ensemble;feature selection;unsupervised learning","Business;Clustering algorithms;Computer vision;Data mining;Filters;Fuzzy systems;Machine learning;Machine learning algorithms;Robust stability;Unsupervised learning","algorithm theory;learning (artificial intelligence);pattern clustering","RReliefF algorithm;clustering ensemble;clustering ensemble result;feature selection algorithm;proposed unsupervised feature selection;significantly hurting performance;unsupervised feature selection","","3","","11","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Using Hyperlink Texts to Improve Quality of Identifying Document Topics Based on Wikipedia","D. T. Huynh; T. H. Cao; P. H. T. Pham; T. N. Hoang","Fac. of Comput. Sci. & Eng., Ho Chi Minh City Univ. of Technol., Ho Chi Minh City, Vietnam","2009 International Conference on Knowledge and Systems Engineering","20091228","2009","","","249","254","This paper presents a method to identify the topics of documents based on Wikipedia category network. It is to improve the method previously proposed by Schonhofen by taking into account the weights of words in hyperlink texts in Wikipedia articles. The experiments on computing and team sport domains have been carried out and showed that our proposed method outperforms the Schonhofen's one.","","POD:978-1-4244-5086-2","10.1109/KSE.2009.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361697","Document topic identification;Wikipedia category network","Computer science;Crawlers;Humans;Knowledge engineering;Machine learning;Machine learning algorithms;Ontologies;Systems engineering and theory;Web sites;Wikipedia","information retrieval;text analysis","Wikipedia articles;Wikipedia category network;computing domains;document topic identification;hyperlink texts;team sport domains","","1","","10","","","13-17 Oct. 2009","","IEEE","IEEE Conference Publications"
"Linear Support Vector Machine Based on Variational Inequality","X. Haiyan; Z. Depeng; W. Zhiping; T. Xin","Sch. of Navig., Dalian Maritime Univ., Dalian, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","526","530","In order to decrease computational complexity and increase the speed of computerized implementation algorithm while solving quadratic programming problems, this paper puts forward and presents experimental results for an effective training method of Linear support vector machine based on variational inequality (VILSVM). The method is to transform the convex quadratic programming problem into the solving problem of variational inequality during the training process of linear supporting vector, obtaining the optimal separating hyperplane by means of solving problem of variational inequality. During the solving process, it will not generate high-memory data, so that the training and test speed of supporting vector machine in classification could be increased. The transformation formula and the specific algorithm were given in this paper. VILSVM was applied into the multidimensional iris training samples. The simulation result shows that VILSVM has high generalization ability and can identify accurately test sample. In addition, it has faster rate of convergence than traditional supporting vector machine with 88% time reduction averagely.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367049","Support vector machine;liner classification;separating hyperplane;variational inequality","Computational complexity;Kernel;Linear programming;Machine learning;Machine learning algorithms;Mathematics;Quadratic programming;Support vector machine classification;Support vector machines;Testing","support vector machines;variational techniques","computational complexity;convex quadratic programming problem;hyperplane;linear support vector machine;multidimensional iris training samples;variational inequality","","0","","16","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Support Vector Machines Improved by Artificial Immunisation Algorithm for Intrusion Detection","Z. Chen; G. Zhang","Dept. of Comput. Sci. & Technol., North China Inst. of Sci. & Technol., Beijing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","In this paper, a new intrusion detection method based on support vector machines improved by artificial immunization algorithm is presented. Support vector machines (SVM) has been well recognized as a powerful computational tool for problems with nonlinearity had high dimensionalities. Right setting parameters are very crucial to learning results and generalization ability of SVM. But empirical parameters are used frequently in SVM RFE, this has hampered its efficiency in practical application. Artificial immunisation algorithm (AIA) is a new intelligent algorithm which integrates global search with local search, and can effectively overcome the prematurity and slow convergence speed of traditional genetic algorithm. To improve the capability of the SVM classifier, The artificial immunisation algorithm is applied to optimize the parameter of SVM in this paper. The experimental result shows that the intrusion detection based on support vector machines improved by artificial immunisation algorithm can give higher recognition accuracy than the general SVM.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366324","","Computer science;Data security;Educational institutions;Information science;Intrusion detection;Machine learning algorithms;Power engineering and energy;Power engineering computing;Support vector machine classification;Support vector machines","genetic algorithms;security of data;support vector machines","SVM;artificial immunisation algorithm;genetic algorithm;intrusion detection;support vector machines","","1","","15","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Improved Adaptive Boosting Algorithm for Neural Network Ensemble Based on Multi-dimensional Cloud Model","Z. Gan; N. Xiao","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","170","173","AdaBoosting is widely used in neural network ensemble as a variety of boosting algorithm. However, with the learning pattern of focusing on hard sample, AdaBooting makes neural network fall into degradation easily. Additionally, in neural network ensemble the weight of individual neural network only takes into account the misclassifying rate. In fact, due to the characteristic of neural network's tendency of learning hard samples in Adaboosting algorithm, the predictive accuracy of individual neural network's training for a particular sample space is much higher than for the whole sample space. This paper proposes an improved AdaBoosting algorithm called Cloud-AdaBoosting. In this method, it is introduced the concept of cloud model and applied the technique of filling training set with similar samples generated by cloud generator to overcome the degradation phenomena resulted from the tendency of learning hard samples. Through calculating the certainty degree of each test sample relative to neural network, it is adjusted dynamically the weight of whole neural network output by individual neural network which can reflect the prediction ability of a part of samples in neural network ensemble, and then enhance the whole prediction performance of the ensemble. The experiment results show that the proposed algorithm is efficient to increase the prediction accuracy of neural network ensemble.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362179","boosting;cloud generator;cloud model;neural network ensemble","Accuracy;Boosting;Clouds;Computer networks;Degradation;Gallium nitride;Knowledge acquisition;Machine learning;Machine learning algorithms;Neural networks","learning (artificial intelligence);neural nets","AdaBoosting;Cloud-AdaBoosting;adaptive boosting algorithm;multidimensional cloud model;neural network;prediction accuracy","","0","","9","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Generalization Performance of ERM Algorithm with Geometrically Ergodic Markov Chain Samples","J. Xu; B. Zou; J. Wang","Fac. of Math. & Comput. Sci., Hubei Univ., Wuhan, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","154","158","The previous works describing the generalization ability of learning algorithms are based on independent and identically distributed (i.i.d.) samples. In this paper we go far beyond this classical framework by studying the learning performance of the empirical risk minimization (ERM) algorithm with Markov chain samples. We obtain the bound on the rate of uniform convergence of the ERM algorithm with geometrically ergodic Markov chain samples, as an application of our main result we establish the bounds on the generalization performance of the ERM algorithm, and show that the ERM algorithm with geometrically ergodic Markov chain samples is consistent. These results obtained in this paper extend the previously known results of i.i.d. observations to the case of Markov dependent samples.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365565","ERM;Generalization performance;Markov chain","Algorithm design and analysis;Computer science;Convergence;Distributed computing;Machine learning;Machine learning algorithms;Mathematics;Risk management;Speech analysis;Statistical distributions","Markov processes;convergence;generalisation (artificial intelligence);learning (artificial intelligence);minimisation;risk analysis","ERM algorithm;empirical risk minimization algorithm;generalization performance;geometrically ergodic Markov chain samples;learning algorithms;uniform convergence","","0","","10","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Automatic construct of options in RL","Xu Ming-Liang; Sun Jun; Xu Wen-bo","School of Information Technology, Jiangnan University, Wuxi 214122, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","47","50","The taboo state is introduced in environment to discovery sub-goal. Agent samples trajectories from starting state to goal state, which contain different bottlenecks. Then the different tasks are submitted to agent. According to whether the task is accomplished or not, the bottlenecks among them are discovered. The appropriate bottlenecks are selected as sub-goal of options to be constructed according to the adjacent relationship among them. Simultaneously agent can obtain the initial set and the policies of options. Grid-world tasks illustrate that the agent can automatically construct useful options online with the proposed method, which have capability of accelerating learning and the transference of knowledge among those similar learning tasks.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357937","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357937","Q-learning;hierarchical reinforcement learning;option;subgoal;taboo search","Accelerated aging;Algorithm design and analysis;Artificial intelligence;Automatic control;Decision making;Frequency;Information technology;Machine learning;Sun;Testing","decision making;grid computing;learning (artificial intelligence);multi-agent systems","grid-world tasks;knowledge transference;learning tasks;machine learning framework;reinforcement learning;sequential decision making problems;taboo state","","0","","12","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Unsupervised and Semi-Supervised Bounded V-Support Vector Machines with Polyhedral Perturbations","K. Zhao; Y. Liu; N. Deng","Logistics Sch., Beijing Wuzi Univ., Beijing, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Support vector machines (SVMs) have been dominant learning techniques for more than ten years, and mostly applied to supervised learning problems. These years two-class unsupervised and semi-supervised classification algorithms based on bounded C-SVMs, bounded j/-SVMs and Lagrangian SVMs (LSVMs) respectively, which are relaxed to semi-definite programming (SDP), get good classification results. These support vector methods implicitly assume that training data in the optimization problems to be known exactly. But in practice, the training data are usually subjected to measurement noise. Zhao et al proposed robust version to bounded C- SVMs, bounded v-SVMs and Lagrangian SVMs (LSVMs) respectively with perturbations in convex polyhedrons and ellipsoids. The region of perturbation in the methods mentioned above is not general, and there are many perturbations in non-convex regions in practice. Therefore we proposed unsupervised and semisupervised classification problems based on bounded v-support vector machines with general polyhedral perturbations. But the problem has difficulty to compute, we will find its semidefinite relaxation that can approximate it well. Numerical results confirm the robustness of the proposed method.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5363472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363472","","Classification algorithms;Lagrangian functions;Machine learning;Noise measurement;Noise robustness;Optimization methods;Supervised learning;Support vector machine classification;Support vector machines;Training data","perturbation techniques;support vector machines;unsupervised learning","Lagrangian SVM;SVM;dominant learning techniques;ellipsoids;general polyhedral perturbations;polyhedral perturbations;semidefinite programming;semidefinite relaxation;semisupervised bounded v-support vector machines","","0","","22","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Classification Algorithm of Continuous Domain Decision Table","W. Liu","Dept. of Math. & Comput. Sci., Changsha Univ. of Sci. & Technol., Changsha, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","3","","3","6","First, the definition of similarity degree of objects in continuous domain decision table is given; then, according to fuzzy clustering, an attribute reduct and attribute significance algorithm of continuous domain decision table is put forward; thirdly, a classification algorithm is proposed according to the principle of maximum membership degree; at last, the validity of this classification algorithm is accounted for through an example.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.571","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358491","attribute value;classification;decision class;membership degree;rough set","Cities and towns;Classification algorithms;Clustering algorithms;Decision support systems;Fuzzy systems;Machine learning;Machine learning algorithms;Mathematics;Pattern recognition;Set theory","decision tables;fuzzy set theory;pattern classification;pattern clustering","classification algorithm;continuous domain decision table;fuzzy clustering;maximum membership degree","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Predicting Academic Achievement Using Multiple Instance Genetic Programming","A. Zafra; C. Romero; S. Ventura","Dept. of Comput. Sci. & Numerical Anal., Univ. of Cordoba, Cordoba, Spain","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","1120","1125","The ability to predict a student's performance could be useful in a great number of different ways associated with university-level learning. In this paper, a grammar guided genetic programming algorithm, G3P-MI, has been applied to predict if the student will fail or pass a certain course and identifies activities to promote learning in a positive or negative way from the perspective of MIL. Computational experiments compare our proposal with the most popular techniques of multiple instance learning (MIL). Results show that G3P-MI achieves better performance with more accurate models and a better trade-off between such contradictory metrics as sensitivity and specificity. Moreover, it adds comprehensibility to the knowledge discovered and finds interesting relationships that correlate certain tasks and the time devoted to solving exercises with the final marks obtained in the course.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364212","Eduational Data Mining;Genetic Programming;Multiple Instance Learning","Application software;Genetic programming;Intelligent systems;Machine learning;Machine learning algorithms;Neural networks;Proposals;Sensitivity and specificity;Supervised learning;System analysis and design","computer aided instruction;genetic algorithms","G3P-MI;academic achievement prediction;grammar guided genetic programming algorithm;multiple instance genetic programming;multiple instance learning;student performance prediction;university-level learning","","0","","20","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Research of Blind Images Separation Algorithm Based on Kernel Space","L. Chen; L. Zhang; Y. Guo; T. Liu","Sch. of Electron. Inf. Eng., Tianjin Univ., Tianjin, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","556","559","Principle of blind source separation (BSS) and kernel function method is introduced. Kernel method is a kind of new learning algorithm concerned by many scholars. More excellent new algorithm can be got by kernelizing the original algorithm using kernel trick. Kernelized blind source separation algorithm based on second-order statistics are expatiated and a new blind images separation algorithm using the kernel trick originally applied in support vector machine (SVM) is proposed. The result of experiment on realistic natural images shows that the blind images separation algorithm based on kernel space can separate mixed natural images successfully.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.279","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366987","blind source separation;independent component analysis;kernel trick;support vector machine","Blind source separation;Independent component analysis;Kernel;Machine learning algorithms;Neural networks;Signal processing;Signal processing algorithms;Source separation;Space technology;Support vector machines","blind source separation;image processing;learning (artificial intelligence);support vector machines","blind images separation algorithm;kernel function method;kernel trick;kernelized blind source separation algorithm;learning algorithm;second-order statistics;support vector machine","","0","","12","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Novel Attribute Reduction Algorithm of Decomposition Based on Rough Sets","N. Jiao; D. Miao; H. Zhang","Dept. of Comput. Sci. & Tech., Tongji Univ., Shanghai, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","4","","515","519","Attribute reduction is a key task for the research of rough sets. However, when dealing with large-scale data, many existing proposals based on rough set theory get worse performance. In this paper, we propose a novel attribute reduction algorithm of decomposition based on rough sets. The idea of decomposition is to break down a complex table into a super-table and several sub-tables that are simpler, more manageable and solvable by using existing induction methods, then joining them together in order to solve the original table. Compared with the traditional methods, experiments with some standard datasets from UCI database are done and experimental results illustrate that the algorithm of this paper improve computational efficiency.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359226","","Computational efficiency;Computer science;Data mining;Databases;Fuzzy systems;Large-scale systems;Machine learning;Machine learning algorithms;Rough sets;Set theory","data reduction;rough set theory","attribute reduction;induction method;large-scale data;rough set theory","","1","","17","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Email Users Churn Analysis Based on PMCLP and Decision Tree","A. Li; Z. Lin","Sch. of Manage. Sci. & Eng., Central Univ. of Finance & Econ., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","7","","348","350","The Web sites often attract people to be their customers, and email is one important tool to deal with that. Thus, the numbers of email users for one website is often an index to show the attraction of people to one website. In this issue, the churn analysis is essential for the website to predict and describe who will leave or give up the use of the email. In this paper, Email users churn analysis is predicted and described by PMCLP (penalized multi-criteria linear programming) and decision tree method. In data mining and machine learning, PMCLP is a classification method with penalized multi-criteria linear programming and Decision tree is often used to deal with classification problem with a descriptive outcome. The first method shows its performance in the prediction result and the second method shows its performance in the predict result description.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360015","","Classification tree analysis;Data mining;Decision trees;Economic forecasting;Engineering management;Finance;Financial management;Internet;Linear programming;Machine learning","Web sites;customer services;decision trees;electronic mail;linear programming","Email;PMCLP;Web sites;churn analysis;decision tree;penalized multi-criteria linear programming","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Multiscale Spectral Clustering Using Random Walk Based Similarity Measure","H. Xu; Z. Tian; M. Ding; X. Wen","Sch. of Comput. Sci., Northwestern Polytech. Univ., Xi'an, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","561","565","This paper presents a new concept on characterizing the similarity between nodes of a weighted undirected graph with application to multiscale spectral clustering. The contribution may be divided into three parts. First, the generalized mean first-passage time (GMFPT) and the generalized mean recurrence time (GMRT) are proposed based on the multi-step transition probability of the random walk on graph. The GMFPT can capture similarities at different scales in data sets as the number of step of transition probability varies. Second, an efficient computational technique is proposed to present the GMFPT in term of the element of the generalized fundamental matrix. Third, a multiscale algorithm is derived based on the weight matrix-based spectral clustering. Finally, Experimental results demonstrate the effectiveness of the proposed method.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358517","","Algorithm design and analysis;Application software;Clustering algorithms;Clustering methods;Computer science;Fuzzy systems;Joining processes;Machine learning;Machine learning algorithms;Virtual manufacturing","graph theory;pattern clustering;probability","generalized fundamental matrix;generalized mean first-passage time;generalized mean recurrence time;multiscale spectral clustering;multistep transition probability;weight matrix-based spectral clustering;weighted undirected graph","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Fast Face Detection Method Based on Improved Sample Selection","W. Li; L. Li","Coll. of Comput. Sci. & Technol., Chongqing Univ. of Posts & Telecommun., Chongqing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","5","","302","306","AdaBoost algorithm is an efficient face detection method whose effectiveness is mainly influenced by the selection of weak classifier during the early process of training. To some extent, the selection of weak classifier depends on the selected sample set. Thus the training sample set is one of the most important factors in face detection. In this paper, the relationship between cascade classifier and weak classifier is analyzed in detail. Based on the factors of detection rate, undetected rate and false detection rate, an improved sample selection method is present and a fast face detection method which is divided into training and detection is proposed. The method is capable of optimizing the proportion of training samples and merging the detection window. The experimental results show that the proposed method is more effective than traditional ones.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360610","AdaBoost algorithm;Cascade classifier;Face detection;Sample selection","Computer science;Educational institutions;Error analysis;Face detection;Fuzzy systems;Machine learning;Machine learning algorithms;Merging;Negative feedback;Optimization methods","face recognition;pattern classification","AdaBoost algorithm;detection rate;detection window;face detection method;false detection rate;improved sample selection;training sample set;undetected rate;weak classifier selection","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A New Clustering Algorithm Based on Regions of Influence with Self-Detection of the Best Number of Clusters","F. Muhlenbach; S. Lallich","Lab. Hubert Curien, Univ. de Lyon, St. Etienne, France","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","884","889","Clustering methods usually require to know the best number of clusters, or another parameter, e.g. a threshold, which is not ever easy to provide. This paper proposes a new graph-based clustering method called GBC which detects automatically the best number of clusters, without requiring any other parameter. In this method based on regions of influence, a graph is constructed and the edges of the graph having the higher values are cut according to a hierarchical divisive procedure. An index is calculated from the size average of the cut edges which self-detects the more appropriate number of clusters. The results of GBC for 3 quality indices (Dunn, Silhouette and Davies-Bouldin) are compared with those of K-Means, Ward's hierarchical clustering method and DBSCAN on 8 benchmarks. The experiments show the good performance of GBC in the case of well separated clusters, even if the data are unbalanced, non-convex or with presence of outliers, whatever the shape of the clusters.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360328","clustering;neighborhood graph","Bioinformatics;Clustering algorithms;Clustering methods;Data mining;Image edge detection;Iterative algorithms;Machine learning;Partitioning algorithms;Shape;Tree graphs","unsupervised learning","DBSCAN;Davies-Bouldin indices;Dunn indices;K-means;Silhouette indices;Ward hierarchical clustering method;graph-based clustering method;hierarchical divisive procedure;unsupervised machine learning task","","7","","28","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
