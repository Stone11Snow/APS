"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6033249,6033508,6033545,6033198,6033446,6033242,6033197,6033373,6032400,6033343,6033302,6034315,6032983,6033406,6033333,6032769,5982410,5975223,6033214,6030187,6031363,6030203,6027539,6027481,6027529,6024359,5677521,6024526,6025669,6022044,6021634,6022279,6021621,6023590,6022245,6022112,6023646,6022342,6022084,6022045,6019682,6019798,6019745,6019483,6019661,6019670,6018724,6019754,6019894,6019921,6019836,6019796,6019559,6019630,6019723,6019889,6019895,6019641,6019654,6019690,6019643,5740992,6019625,6019826,6019717,6019687,6016585,5740361,6016122,6013816,6014694,6014761,6010676,6010428,6011475,6009556,6009613,6011460,6011454,6010707,6008858,6007485,6007633,6007844,6008227,6007504,6007519,6008141,6005081,6005682,5957304,6005070,6006109,5763754,6004768,6002413,5999503,6001124,6000344,6002468",2017/05/05 22:49:25
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Mental state detection and tagging in nursing records","A. Scheidel; A. Zufri; K. Hashimoto","Grad. Sch. of Inf. Sci., Tohoku Univ., Sendai, Japan","2011 Seventh International Conference on Natural Computation","20110919","2011","2","","913","916","Staff at geriatric care facilities compile nursing records, containing information from patients' vital signs or treatments suggested by doctors, to comments about patients interactions with the nursing staff, their families and other patients. Especially the latter type of entries often seems to include clues to patients' emotional well-being. Following the assumption that physical and mental health exert a mutual influence on each other, the authors believe that explicitly monitoring patients' emotions and moods can enhance the understanding of changes in physical health. It may also assist nurses in, e.g., preventing negative emotional states like persistent depression affecting patients' overall health for the worse. This paper proposes a strategy to use machine learning techniques to detect and classify emotion in nursing records. Since a first annotation step revealed that entries containing direct speech seem to be especially “emotionally salient”, special focus of our future work will be on those entries.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022279","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022279","","Face;Geriatrics;Machine learning;Mood;Speech;Training","learning (artificial intelligence);medical administrative data processing;medical computing;patient treatment;records management","geriatric care facilities;machine learning;mental state detection;nursing records;nursing staff;patient treatment;patients vital signs;physical health;tagging","","0","","7","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Minority split and gain ratio for a class imbalance","K. Boonchuay; K. Sinapiromsaran; C. Lursinsap","Dept. of Math., Chulalongkorn Univ., Bangkok, Thailand","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","2060","2064","A decision tree is one of most popular classifiers that classifies a balanced data set effectively. For an imbalanced data set, a standard decision tree tends to misclassify instances of a class having tiny number of samples. In this paper, we modify the decision tree induction algorithm by performing a ternary split on continuous-valued attributes focusing on distribution of minority class instances. The algorithm uses the minority variance to rank candidates of the high gain ratio, then it chooses the candidate with the minimum minority entropy. From our experiments with data sets from UCI and Statlog repository, this method achieves the better performance comparing with C4.5 using only gain ratio for imbalanced data sets.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019836","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019836","Class imbalance;Classification;Decision tree;Gain Ratio;Minority split","Accuracy;Classification algorithms;Decision trees;Entropy;Impurities;Machine learning;Training","decision trees;entropy;pattern classification","Statlog repository;UCI repository;balanced data set;class imbalance;decision tree induction algorithm;imbalanced data set;minimum minority entropy;minority class instance distribution;minority gain ratio;minority split ratio","","1","","18","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"An Energy-Efficient Kernel Framework for Large-Scale Data Modeling and Classification","P. D. Yoo; J. W. P. Ng; A. Y. Zomaya","Dept. Comput. Eng., Khalifa Univ. of Sci., Technol. & Res. (KUSTAR), Abu Dhabi, United Arab Emirates","2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum","20110901","2011","","","404","408","Energy-efficient computing has now become a key challenge not only for data-center operations, but also for many other energy-driven systems, with the focus on reducing of all energy-related costs, and operational expenses, as well as its corresponding and environmental impacts. Intelligent machine-learning systems are typically performance driven. For instance, most non-parametric model-free approaches are often known to require high computational cost in order to find the global optima. Designing more accurate machine-learning systems to satisfy the market needs will hence lead to a higher likelihood of energy waste due to the increased computational cost. This paper thus introduces an energy-efficient framework for large-scale data modeling and classification. It can achieve a test error comparable to or better than the state-of-the-art machine-learning models, while at the same time, maintaining a low computational cost when dealing with large-scale data. The effectiveness of the proposed approaches has been demonstrated by our experiments with two large-scale KDD datasets: Mtv-1 and Mtv-2.","1530-2075;15302075","Electronic:978-1-61284-424-4; POD:978-1-61284-425-1","10.1109/IPDPS.2011.178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6008858","","Distributed processing;Electromyography;Energy efficiency;Machine learning","energy conservation;learning (artificial intelligence);pattern classification","Mtv-1 dataset;Mtv-2 dataset;data classification;data modeling;data-center operation;energy-efficient computing;energy-efficient kernel framework;intelligent machine learning system","","0","","18","","","16-20 May 2011","","IEEE","IEEE Conference Publications"
"SVM classifier based face detection system using BDIP and BVLC moments","T. D. Nguyen; Q. Tran Thanh; T. M. Duc; T. Nguyen Quynh; T. M. Hoang","Sch. of Electron. &amp; Telecommun., Hanoi Univ. or Sci. &amp; Technol., Hanoi, Vietnam","The 2011 International Conference on Advanced Technologies for Communications (ATC 2011)","20110926","2011","","","264","267","In this paper, a support vector machine (SVM) classifier has been used to detect a face in an authentication application. A face candidate is first allocated from the input frame and then normalized to 200×200 pixels images. The textureness of candidates is then measured by the combination of BDIP and BVLC moments and classified into face and non-face ones by a SVM classifier which is known as efficient classification tool. In SVM learning, a DB of 2500 faces and 2500 non-faces has been created under different light conditions and face expressions. The experiments showed that the effectiveness of the used features for SVM based classification issue in the face-detection system.","2162-1020;21621020","Electronic:978-1-4577-1207-4; POD:978-1-4577-1206-7","10.1109/ATC.2011.6027481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6027481","BDIP;BVLC;SVM;texture features","Authentication;Computers;Educational institutions;Face;Machine learning;Multiplexing;Support vector machines","authorisation;face recognition;image texture;learning (artificial intelligence);support vector machines","BDIP moments;BVLC moments;SVM classifier;SVM learning;authentication application;face detection system;face-detection system;image texture;nonface images;support vector machine","","1","","19","","","2-4 Aug. 2011","","IEEE","IEEE Conference Publications"
"Link prediction by de-anonymization: How We Won the Kaggle Social Network Challenge","A. Narayanan; E. Shi; B. I. P. Rubinstein","Department of Computer Science, Stanford University, USA","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","1825","1834","This paper describes the winning entry to the IJCNN 2011 Social Network Challenge run by Kaggle.com. The goal of the contest was to promote research on real-world link prediction, and the dataset was a graph obtained by crawling the popular Flickr social photo sharing website, with user identities scrubbed. By de-anonymizing much of the competition test set using our own Flickr crawl, we were able to effectively game the competition. Our attack represents a new application of de-anonymization to gaming machine learning contests, suggesting changes in how future competitions should be run. We introduce a new simulated annealing-based weighted graph matching algorithm for the seeding step of de-anonymization. We also show how to combine de-anonymization with link prediction-the latter is required to achieve good performance on the portion of the test set not de-anonymized-for example by training the predictor on the de-anonymized portion of the test set, and combining probabilistic predictions from de-anonymization and link prediction.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033446","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033446","","Accuracy;Electronic mail;Image edge detection;Machine learning;Simulated annealing;Social network services;Training","graph theory;learning (artificial intelligence);simulated annealing;social networking (online)","Flickr social photo sharing Website;IJCNN 2011 social network challenge;Kaggle social network challenge;deanonymization;machine learning;realworld link prediction;simulated annealing-based weighted graph matching algorithm","","20","","30","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"A hyper ellipsoidal incremental learning algorithm","Y. Qin; S. Lun; Q. Leng; Y. Guo","Coll. of Eng., Bohai Univ., Jinzhou, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1500","1503","A sample and class incremental learning algorithm based on hyper ellipsoidal is proposed. For every class, the smallest hyper ellipsoidal that surrounds most samples of the class is structured, which can divide the class samples from others. In the process of incremental learning, only the hyper ellipsoidal of every new class is trained and the history hyper ellipsoidals that increment new samples are retrained. For the sample to be classified, its class be confirmed by the hyper ellipsoidal that surrounds it. If the sample is not surrounded by all hyper ellipsoidals, the membership is used to confirmed its class. The experiments are done on Reuters 21578, and the experiment results show that the algorithm has a higher performance on classification speed and classification precision compare with hyper sphere algorithm.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019921","extension factor;hyper ellipsoidal;incremental learning","Classification algorithms;Machine learning;Machine learning algorithms;Support vector machines;Testing;Text categorization;Training","learning (artificial intelligence);pattern classification;text analysis","Reuters 21578;classification precision;classification speed;hyper ellipsoidal incremental learning algorithm","","0","","20","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Unsupervised and transfer learning challenge","I. Guyon; G. Dror; V. Lemaire; G. Taylor; D. W. Aha","Clopinet, 955 Creston Road, Berkeley, CA 94708, USA","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","793","800","We organized a data mining challenge in “unsupervised and transfer learning” (the UTL challenge), in collaboration with the DARPA Deep Learning program. The goal of this year's challenge was to learn good data representations that can be re-used across tasks by building models that capture regularities of the input space. The representations provided by the participants were evaluated by the organizers on supervised learning “target tasks”, which were unknown to the participants. In a first phase of the challenge, the competitors were given only unlabeled data to learn their data representation. In a second phase of the challenge, the competitors were also provided with a limited amount of labeled data from “source tasks”, distinct from the “target tasks”. We made available large datasets from various application domains: handwriting recognition, image recognition, video processing, text processing, and ecology. The results indicate that learned data representation yield results significantly better than what can be achieved with raw data or data preprocessed with standard normalizations and functional transforms. The UTL challenge is part of the IJCNN 2011 competition program<sup>1</sup>. The website of the challenge remains open for submission of new methods beyond the termination of the challenge as a resource for students and researchers<sup>2</sup>.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033302","","Humans;Kernel;Machine learning;Measurement;Supervised learning;Training;Unsupervised learning","data mining;data structures;unsupervised learning","DARPA deep learning program;UTL challenge;Website;data mining;data representations;ecology;handwriting recognition;image recognition;text processing;unsupervised and transfer learning;video processing","","3","","27","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Attribute reduction algorithm of rough set fused with ant colony algorithm","X. Qing; H. Tao; C. Bowei","Simulation Center, Acad. of Armored Force Eng., Beijing, China","Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology","20110919","2011","5","","2385","2387","This paper fused rough set theory and ant colony algorithm. The attribute core was determined through the correlative algorithms of rough set, which could be used as initial node of ant colony algorithm, then the time complexity and search space were reduced. The search capacity was used to get the lease combination of these nodes, which is the minimal attribute set, and the NP-hard problem in attribute reduction by using rough set was avoided. The result of experiment showed the feasibility and validity of this algorithm.","","DVD:978-1-61284-086-4; Electronic:978-1-61284-088-8; POD:978-1-61284-087-1","10.1109/EMEIT.2011.6023590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6023590","ant colony algorithm;attribute reduction;rough set","Algorithm design and analysis;Cities and towns;Complexity theory;Heuristic algorithms;Machine learning algorithms;Search problems;Set theory","computational complexity;optimisation;rough set theory","NP-hard problem;ant colony algorithm;attribute reduction algorithm;rough set theory;time complexity reduction","","0","","10","","","12-14 Aug. 2011","","IEEE","IEEE Conference Publications"
"Hierarchical classification model based on MD feature selection method","M. Liu; X. Lu; J. Song; X. Wu","Sch. of Stat., Central Univ. of Finance &amp; Econ., Beijing, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1812","1815","When dealing with large amounts of textual information, we may require an automatic system to organize them into known taxonomies which are arranged in a hierarchy. This learning task is called hierarchical classification. In such case, usually there are huge numbers of terms. We need apply certain techniques to remove irrelevant and redundant features for saving computation time without losing too much classification accuracy. In this article, we will first propose a new feature selection method called MD. After that a new hierarchical classification method based on MD is proposed and compared with existing methods on a real dataset.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019796","Feature selection;Hierarchical classification;MD method","Accuracy;Classification algorithms;Decision trees;Educational institutions;Keyboards;Loss measurement;Machine learning","learning (artificial intelligence);pattern classification","MD feature selection method;hierarchical classification;learning task;textual information","","0","","8","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A reduction algorithm based on trie tree of inconsistent system","Xiaofan Zhang; Yujun Fan","School of Mechatronic Engineering, Wuhan University of Technology, China","2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)","20110905","2011","","","6935","6939","Attribute reduction is one of the vital research contents of Rough Sets. A method of calculating positive region based on the trie tree has been proposed in the paper. And the time complexity is O (| C || U |). A complete attribute reduction algorithm has been designed according to the method of calculating positive region. The experiment results show that the reduction algorithm is effective, and it is applicable to the reduction of mass data.","","Electronic:978-1-4577-0536-6; POD:978-1-4577-0535-9","10.1109/AIMSEC.2011.6011475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6011475","Inconsistency;Rough Sets;Trie tree;reduction","Algorithm design and analysis;Complexity theory;Computers;IP networks;Information systems;Machine learning algorithms;Rough sets","computational complexity;data reduction;rough set theory;trees (mathematics)","attribute reduction algorithm;inconsistent system;mass data reduction;rough sets;time complexity;trie tree;vital research content","","0","","6","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"Kernelized Fuzzy Rough Sets and Their Applications","Q. Hu; D. Yu; W. Pedrycz; D. Chen","Harbin Institute of Technology, Harbin and The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Knowledge and Data Engineering","20110922","2011","23","11","1649","1667","Kernel machines and rough sets are two classes of commonly exploited learning techniques. Kernel machines enhance traditional learning algorithms by bringing opportunities to deal with nonlinear classification problems, rough sets introduce a human-focused way to deal with uncertainty in learning problems. Granulation and approximation play a pivotal role in rough sets-based learning and reasoning. However, a way how to effectively generate fuzzy granules from data has not been fully studied so far. In this study, we integrate kernel functions with fuzzy rough set models and propose two types of kernelized fuzzy rough sets. Kernel functions are employed to compute the fuzzy T-equivalence relations between samples, thus generating fuzzy information granules in the approximation space. Subsequently fuzzy granules are used to approximate the classification based on the concepts of fuzzy lower and upper approximations. Based on the models of kernelized fuzzy rough sets, we extend the measures existing in classical rough sets to evaluate the approximation quality and approximation abilities of the attributes. We discuss the relationship between these measures and feature evaluation function ReliefF, and augment the ReliefF algorithm to enhance the robustness of these proposed measures. Finally, we apply these measures to evaluate and select features for classification problems. The experimental results help quantify the performance of the KFRS.","1041-4347;10414347","","10.1109/TKDE.2010.260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677521","Rough set;feature evaluation;feature selection.;fuzzy rough set;kernel","Approximation methods;Classification algorithms;Data models;Fuzzy sets;Kernel;Machine learning;Rough sets","approximation theory;fuzzy set theory;learning (artificial intelligence);pattern classification;rough set theory","ReliefF algorithm;approximation abilities;approximation quality;classical rough sets;exploited learning technique;feature evaluation function ReliefF;fuzzy T-equivalence relations;fuzzy information granules;generate fuzzy granule;integrate kernel functions;kernel machine;kernelized fuzzy rough set;nonlinear classification problem;traditional learning algorithm","","38","","55","","20101230","Nov. 2011","","IEEE","IEEE Journals & Magazines"
"Neural network based Support Vector Machine in financial default forecast","J. Bozsik; M. Kozma","Department of Software Technology and Methodology, E&#x00F6;tv&#x00F6;s Lor&#x00E1;nd University, P&#x00E1;zm&#x00E1;ny P&#x00E9;ter s&#x00E9;t&#x00E1;ny 1/C, H-1117 Budapest, Hungary","2011 IEEE 9th International Symposium on Intelligent Systems and Informatics","20111003","2011","","","163","167","An Artificial Intelligence based classification system will be introduced that can be helpful in separating financial ratios into two classes. The main goal was to develop a Support Vector Machine based implementation that can draw reasonably accurate conclusions even from an extensive data set. In addition, the scalability and configurability of the algorithm were important aspects too. In this article the structure of the Support Vector Machine implementation will be presented, covering the unique characteristics of the development, the problems which occurred during the construction of the model, and the solutions for these problems. The operation of the system will be presented through various tests, and it will be shown how the different parameters can describe the behaviour of the algorithm.","1949-047X;1949047X","Electronic:978-1-4577-1974-5; POD:978-1-4577-1975-2","10.1109/SISY.2011.6034315","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034315","","Accuracy;Biological neural networks;Kernel;Machine learning;Neurons;Support vector machines;Training","artificial intelligence;economic forecasting;financial data processing;neural nets;pattern classification;support vector machines","artificial intelligence based classification system;financial default forecast;financial ratios;neural network based support vector machine","","3","","7","","","8-10 Sept. 2011","","IEEE","IEEE Conference Publications"
"A sequential learning algorithm for meta-cognitive neuro-fuzzy inference system for classification problems","S. Suresh; K. Subramanian","School of Computer Engineering, Nanyang Technological University, Singapore","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","2507","2512","A neuro-fuzzy classifier based on the meta-cognitive principle of human self-regulated learning (Mc-FIS) is proposed in this paper. The network decides what-to-learn, when-to-learn and how-to-learn based on the current information present in the classifier and the new information present in the sample. The classifier utilizes self-regulating error based criterion to decide which sample to learn and when to learn. A rule is pruned if its significance is below a particular threshold, based on class specific information. This results in a compact network and sample deletion helps overfitting. Class specific information is used in executing the above tasks. The algorithm is evaluated on balanced and unbalanced benchmark problems from UCI machine learning repository. The results clearly indicate the superiority of the developed algorithm.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033545","","Fuzzy neural networks;Glass;Machine learning algorithms;Neurons;Testing;Training;Vehicles","cognitive systems;fuzzy reasoning;learning (artificial intelligence);pattern classification","Mc-FIS;UCI machine learning;classification problems;human self-regulated learning;metacognitive neuro-fuzzy inference system;metacognitive principle;neuro-fuzzy classifier;sequential learning","","7","","21","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Incremental learning based on ensemble pruning","Q. L. Zhao; Y. H. Jiang; Ming Xu","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","1","","377","381","Bagging, a widely used ensemble method, is simple and fast, and can generate heterogeneous base classifiers. This research proposes an incremental learning algorithm, PBagging++, based on ensemble pruning. In the algorithm, Bagging is adopted to generate a set of heterogeneous classifiers for each incremental data set. Then an ensemble pruning method is used to select base classifiers from the generated ones and add them to the target ensemble. The new target ensemble will perform the prediction on new instances. Experimental results show that ensemble pruning is an effective way to improve the predictive performance for ensemble based incremental learning.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019559","PBagging++;bagging;ensemble pruning;incremental learning","Accuracy;Bagging;Classification algorithms;Learning systems;Machine learning;Prediction algorithms;Training","learning (artificial intelligence);pattern classification","PBagging++ algorithm;ensemble pruning method;heterogeneous base classifier;incremental data set;incremental learning algorithm;target ensemble","","1","","22","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Identifying Scanning Activities in Honeynet Data Using Data Mining","M. H. Sqalli; S. Arshad; M. Khalaf; K. Salah","Coll. of Comput. Sci. & Eng., King Fahd Univ. of Pet. & Miner., Dhahran, Saudi Arabia","2011 Third International Conference on Computational Intelligence, Communication Systems and Networks","20110829","2011","","","178","183","Businesses attract different types of attacks mostly due to the financial benefits associated with gaining unauthorized access. As a first step to launching attacks, attackers scan production networks looking for open services and vulnerable software. These scanning or enumeration activities, if monitored properly, can be used as early warning systems against a much sophisticated and dedicated attack. Honey nets are deployed for the purpose of tracking malicious activities and learn about hackers' origin, methods and attacks. However, today's Honey nets produce an enormous amount of data which becomes a challenge to analyze. In this paper, we attempt to separate and identify scanning traffic from other types of traffic. To accomplish this, we have developed a tool that utilizes known data mining techniques to find the scanning activities in Honey net data, which is an aggregate traffic data collected by multiple Honey pots. Being able to identify scanning activities will allow security analysts to focus more on other types of traffic, and hence be able to study and analyze other types of attacks.","","Electronic:978-0-7695-4482-3; POD:978-1-4577-0975-3","10.1109/CICSyN.2011.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005682","Data Mining;Honeynet;Intrusion Detection;Scanning","Data mining;Feature extraction;IP networks;Machine learning;Probes;Servers;Time series analysis","alarm systems;computerised monitoring;data mining;security of data","Honey pots;Honeynet data;aggregate traffic data;business;data mining;early warning system;enumeration activity;financial benefits;hacker origin;malicious activity tracking;open services;production network scanning activity;security analysts;unauthorized access;vulnerable software","","0","","23","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"On improving trust-region variable projection algorithms for separable nonlinear least squares learning","E. Mizutani; J. Demmel","Department of Industrial Management, National Taiwan University of Science and Technology, Taipei, Taiwan","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","397","404","In numerical linear algebra, the variable projection (VP) algorithm has been a standard approach to separable “mixed” linear and nonlinear least squares problems since early 1970s. Such a separable case often arises in diverse contexts of machine learning (e.g., with generalized linear discriminant functions); yet VP is not fully investigated in the literature. We thus describe in detail its implementation issues, highlighting an economical trust-region implementation of VP in the framework of a so-called block-arrow least squares (BA) algorithm for a general multiple-response nonlinear model. We then present numerical results using an exponential-mixture benchmark, seven-bit parity, and color reproduction problems; in some situations, VP enjoys quick convergence and attains high classification rates, while in some others VP works poorly. This observation motivates us to investigate original VP's strengths and weaknesses compared with other (full-functional) approaches. To overcome the limitation of VP, we suggests how VP can be modified to be a Hessian matrix-based approach that exploits negative curvature when it arises. For this purpose, our economical BA algorithm is very useful in implementing such a modified VP especially when a given model is expressed in a multi-layer (neural) network for efficient Hessian evaluation by the so-called second-order stagewise backpropagation.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033249","","Backpropagation;Barium;Jacobian matrices;Machine learning;Machine learning algorithms;Symmetric matrices;Vectors","Hessian matrices;backpropagation;least squares approximations;linear algebra;multilayer perceptrons","BA algorithm;Hessian matrix;block-arrow least square algorithm;color reproduction problem;economical trust-region implementation;exponential-mixture benchmark;linear least square problem;machine learning context;multilayer network;multiple-response nonlinear model;nonlinear least square learning;numerical linear algebra;second-order stagewise backpropagation;trust-region variable projection algorithm","","2","","18","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Long term bank failure prediction using Fuzzy Refinement-based Transductive Transfer learning","V. Behbood; J. Lu; G. Zhang","Decision Systems & E-Service Intelligence Research Laboratory, Centre for Quantum Computing and Intelligent System, School of Software, Faculty of Engineering and Information Technology, University of Technology Sydney, POBOX123, Broadway, NSW 2007, Australia","2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)","20110901","2011","","","2676","2683","Machine learning algorithms, which have been considered as robust methods in different computational fields, assume that the training and test data are drawn from the same distribution. This assumption may be violated in many real world applications like bank failure prediction because training and test data may come from different time periods or domains. An efficient novel algorithm known as Fuzzy Refinement (FR) is proposed in this paper to solve this problem and improve the performance. The algorithm utilizes the fuzzy system and similarity concept to modify the instances' labels in target domain which was initially predicted by shift-unaware Fuzzy Neural Network (FNN) proposed by [1]. The experiments are performed using bank failure financial data of United States to evaluate the algorithm performance. The results address a significant improvement in the predictive accuracy of FNN due to applying the proposed algorithm.","1098-7584;10987584","Electronic:978-1-4244-7317-5; POD:978-1-4244-7315-1; USB:978-1-4244-7316-8","10.1109/FUZZY.2011.6007633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007633","Bank Failure Prediction;Fuzzy Neural Network;Fuzzy Sets;Long Term Prediction;Transfer Learning","Accuracy;Fuzzy neural networks;Inference algorithms;Machine learning algorithms;Pragmatics;Prediction algorithms;Training","banking;fuzzy set theory;learning (artificial intelligence)","fuzzy refinement;fuzzy system;long term bank failure prediction;machine learning;shift-unaware fuzzy neural network;transductive transfer learning","","5","","20","","","27-30 June 2011","","IEEE","IEEE Conference Publications"
"Improving question retrieval in community question answering with label ranking","W. Wang; B. Li; I. King","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","349","356","Community question answering services (CQA), which provides a platform for people with diverse backgrounds to share information and knowledge, has become an increasingly popular research topic recently as made popular by sites such as Yahoo! Answers<sup>1</sup>, answerbag<sup>2</sup>, zhidao<sup>3</sup>, etc. Question retrieval (QR) in CQA can automatically find the most relevant and recent questions that have been solved by other users. Current QR approaches typically consider using diverse retrieval models, but they fail to analyze users' intention. User intentions such as finding facts, interacting with others, seeking reasons, etc. reflect what the users really want to know. Hence, we propose to integrate user intention analysis into QR. Firstly, we classify questions into different and multiple types of users' intentions. Another practical problem is that there naturally exist some preferences among the possible questions types. The more relevant type should be ranked higher than types which are not so relevant. Therefore, we propose to utilize a novel label ranking method, which is a machine learning algorithm that aims to predict a ranking among all the possible labels, to perform question classification. Secondly, based on the result of question classification, we integrate user intentions with translation-based language models to explore whether a user's intention does help to improve the performance. We conduct a series of experiments with Yahoo data, and the experimental results demonstrate that our proposed improved question retrieval can indeed enhance the performance of traditional question retrieval model.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033242","","Data models;History;Machine learning algorithms;Prediction algorithms;Support vector machines;Training;Training data","Internet;information retrieval;learning (artificial intelligence)","CQA;QR;Yahoo data;community question answering services;label ranking method;machine learning algorithm;question classification;question retrieval improvement;user intention analysis","","1","","21","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"A multiple-stage classifier for identifying unknown Internet traffic","W. Lu; A. A. Ghorbani","Computer Science Department Keene State College, USNH, Keene USA","Proceedings of 2011 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing","20111003","2011","","","725","729","Accurate and timely classification of network traffic has received a lot of attention recently due to its important roles in many subjects such as QoS provisioning, traffic engineering, network intrusion detection and prevention. In this paper, we present a multiple-stage framework to classify the unknown network traffic in which we first use the well-known port numbers and static payload signatures to identify the most popular network applications and then a deep payload inspection technique is proposed to classify those applications with ephemeral connections. For the rest unknown traffic we applied the traditional k-means algorithm to classify them into existing known application communities. During the experimental evaluation, we verify our algorithm with the network flows collected on a campus-wide WiFi ISP network over one hour and evaluation results show a high detection accuracy approaching to 97%.","1555-5798;15555798","Electronic:978-1-4577-0253-2; POD:978-1-4577-0252-5; USB:978-1-4577-0251-8","10.1109/PACRIM.2011.6032983","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032983","","Classification algorithms;Clustering algorithms;Communities;Internet;Machine learning;Payloads;Protocols","Internet;telecommunication traffic;wireless LAN","Internet traffic;campus-wide WiFi ISP network;deep payload inspection technique;ephemeral connection;k-means algorithm;multiple-stage classifier;port number;static payload signature","","0","","21","","","23-26 Aug. 2011","","IEEE","IEEE Conference Publications"
"Application of Multiple-Instance Learning for Hyperspectral Image Analysis","J. Bolton; P. Gader","University of Florida, Gainesville, FL, USA","IEEE Geoscience and Remote Sensing Letters","20110825","2011","8","5","889","893","Multiple-instance learning (MIL) is a learning paradigm used for learning a target concept in the presence of noise or with an uncertainty in target information including class labels. Due to the difficult situations in which hyperspectral images (HSIs) are collected, research in this area is extremely relevant and directly applicable. In the following, an MIL framework is proposed for target spectra learning for HSI analysis. MIL techniques are compared to their non-MIL counterparts (standard machine learning techniques). Experimental results indicate that MIL can learn target spectra with a lack of target information and, furthermore, result in improved classifiers.","1545-598X;1545598X","","10.1109/LGRS.2011.2135330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763754","Hyperspectral image (HSI) analysis;land-mine detection;multiple-instance (MI) learning (MIL);random-set framework;random-set framework for MIL (RSF-MIL)","Hyperspectral imaging;Machine learning;Noise measurement;Testing;Training","geophysical image processing;geophysical techniques;landmine detection","MIL framework;class labels;hyperspectral image analysis;land-mine detection;multiple-instance learning;random-set framework;standard machine learning techniques;target information;target spectra learning","","7","","17","","20110505","Sept. 2011","","IEEE","IEEE Journals & Magazines"
"On the behavior of feature selection methods dealing with noise and relevance over synthetic scenarios","V. Bolón-Canedo; N. Sánchez-Maroño; A. Alonso-Betanzos","Department of Computer Science, University of A Coru&#x00F1;a, Spain","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","1530","1537","Adequate identification of relevant features is fundamental in real world scenarios. The problem is specially important when the datasets have a much larger number of features than samples. However, in most cases, the relevant features in real datasets are unknown. In this paper several synthetic datasets are employed to test the effectiveness of different feature selection methods over different artificial classification scenarios, such as altered features (noise), presence of a crescent number of irrelevant features and a small ratio between number of samples and number of features. Six filters and two embedded methods are tested over five synthetic datasets, so as to be able to choose a robust and noise tolerant method, paving the way for its application to real datasets in the classification domain.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033406","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033406","","Correlation;Feature extraction;Light emitting diodes;Machine learning;Noise;Redundancy;Training","pattern classification","artificial classification scenarios;classification domain;embedded method;feature selection method;noise tolerant method;real datasets;real world scenarios;synthetic datasets;synthetic scenario","","2","","31","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Implementing autonomous shaping by critical states","J. Song; Z. Jin","Yunnan Jiao Tong Vocational &amp; Tech. Coll., Kunming, China","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","1","","276","279","Shaping is a powerful method for speeding up reinforcement learning, but the major drawback that shaping reward depends on external observer limits its application and requires significant effort. We implement an autonomous shaping reinforcement learning method by making agent can discover autonomously critical states from prior experience and use them to shape later learning. The critical state is a state that has high probability to exist in all these acyclic state trajectories that from the start state to the goal state, that means, if agent wants to reach the goal state, then it would have high likelihood to pass the critical states. So the critical states can be used to shape agent for reaching the goal state faster. The experiments on Maze problem show our method can significant improve agent's performance. The more important is we make agent can shape its later learning by its prior experience.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030203","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030203","critical State;prior experience;reinforcement learning;shaping;speeding up learning","Learning;Learning systems;Machine learning;Observers;Shape;Training;Trajectory","learning (artificial intelligence);probability","Maze problem;acyclic state trajectory;agent learning;agent performance;autonomous critical state discovery;autonomous shaping;external observer;probability;reinforcement learning","","0","","12","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Classifier combination for telegraphese restoration","L. W. Santoso","Department of Computer Science, Petra Christian University, Siwalankerto 121-131 Surabaya, Indonesia","2011 International Conference on Uncertainty Reasoning and Knowledge Engineering","20110901","2011","1","","79","82","This paper presents a classifier combination to solve telegraphese restoration problem. By implementing more than one classifier, it can support other classifier, and finally it can improve the performance. Using supplied development data, training data and testing data, the best model had an accuracy F = 79 %.","","Electronic:978-1-4244-9984-7; POD:978-1-4244-9985-4","10.1109/URKE.2011.6007844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007844","Classifier combination;Penn Treebank tagset;chunk parsing;telegraphese restoration","Accuracy;Classification algorithms;Machine learning;Machine learning algorithms;Speech;Tagging;Training","learning (artificial intelligence);pattern classification","classifier combination;development data supply;telegraphese restoration;testing data;training data","","0","","7","","","4-7 Aug. 2011","","IEEE","IEEE Conference Publications"
"Semi-supervised fuzzy learning in text categorization","X. Pan; S. Zhang","Sch. of Electr. &amp; Inf. Technol., Changchun Inst. of Technol., Changchun, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1057","1060","Semi-supervised learning has attracted a lot of attention in recent years. Different from traditional supervised learning. Semi-supervised learning makes use of both labeled and unlabeled samples. In text categorization, traditional classifier prefer lots of samples and each category have same number of simples, but collecting labeled examples costs human efforts and certain category may be can't find abundance samples; this situation would lead to low classification accuracy. In this paper, we proposed a semi-supervised text classifier based on fuzzy c-means algorithm. Experiment show that our method has better performance in small samples and unbalance samples.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019630","Fuzzy C-Means;Semi-supervised;Text Categorization;Unlabeled samples","Accuracy;Classification algorithms;Computational modeling;Machine learning;Support vector machine classification;Text categorization;Training","data mining;fuzzy reasoning;pattern classification;text analysis","classification accuracy;fuzzy c-means algorithm;semi supervised fuzzy learning;semi supervised text classifier;text categorization;unlabeled samples","","0","","8","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Harmonic current estimation using blind signal processing techniques","P. Supriya; T. N. PadmanabhanNambiar","Dept. of Electr. &amp; Electron. Eng., Amrita Vishwa Vidyapeetham, Coimbatore, India","2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies","20110922","2011","","","116","120","Blind Source Separation methods are used for feature extraction in biomedical and image processing applications. An increased use of non-linear loads results in generation of harmonics, which cannot be easily identified in electric power systems. Using blind source separation methods like fastICA and efficient fastICA the harmonic currents are estimated in an interconnected system. In this work, a performance evaluation between these two methods for harmonic state estimation is done in the form of recording and analyzing the miniscule error that exists between the actual and estimated harmonic currents. The graphical results of a simple five bus system for the two methods are also discussed.","","Electronic:978-1-61284-653-8; POD:978-1-61284-654-5","10.1109/ICSCCN.2011.6024526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6024526","Efficient variant fastICA;FastICA;Harmonic State estimation;Mixing/Demixing matrix","Error analysis;Harmonic analysis;Machine learning;Reliability theory","blind source separation;independent component analysis;power system harmonics;power system interconnection;power system state estimation","biomedical application;blind signal processing techniques;blind source separation methods;electric power systems;fastICA;feature extraction;harmonic current estimation;harmonic generation;harmonic state estimation;image processing application;independent component analysis;interconnected system;performance evaluation","","3","","6","","","21-22 July 2011","","IEEE","IEEE Conference Publications"
"Towards an enhanced framework for learning semantic relation classification","A. S. Hassan; N. Kulathuramaiyer","Sultan Qaboos University, Oman","2011 7th International Conference on Information Technology in Asia","20110825","2011","","","1","6","Most of the research in this area depends on NLP techniques, machine learning, and statistical approaches, but the challenging issue here is to provide a general learning framework in an automated way that make use of different kinds of contextual knowledge, and to make use of that framework to enrich the ontology with new relations, hence facilitate ontology acquisition. We have developed a unique framework for acquiring ontology relations from a large collection of domain independent texts. Our experiments on the proposed approach have shown promising results, even at an early state. The main contribution of this work lies in the semantic validation of causation relationships based on thorough corpus linguistics.","","Electronic:978-1-61284-130-4; POD:978-1-61284-128-1","10.1109/CITA.2011.5999503","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999503","lexical relations;ontology acquisition;ontology learning","Asia;Classification algorithms;Data mining;Machine learning;Ontologies;Semantics;Syntactics","knowledge acquisition;natural language processing;ontologies (artificial intelligence);pattern classification;text analysis","NLP techniques;contextual knowledge;corpus linguistics;domain independent texts;machine learning;ontology acquisition;semantic relation classification learning","","0","","10","","","12-13 July 2011","","IEEE","IEEE Conference Publications"
"Learning with few examples: An empirical study on leading classifiers","C. Salperwyck; V. Lemaire","&#x2018;Profiling and Datamining&#x2019;, Orange Labs, 2 avenue Pierre Marzin, 22300 Lannion, France","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","1010","1019","Learning algorithms proved their ability to deal with large amount of data. Most of the statistical approaches use defined size learning sets and produce static models. However in specific situations: active or incremental learning, the learning task starts with only very few data. In that case, looking for algorithms able to produce models with only few examples becomes necessary. The literature's classifiers are generally evaluated with criterion such as: accuracy, ability to order data (ranking)... But this classifiers' taxonomy can dramatically change if the focus is on the ability to learn with just few examples. To our knowledge, just few studies were performed on this problem. The study presented in this paper aims to study a larger panel of both algorithms (9 different kinds) and data sets (17 UCI bases).","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033333","","Algorithm design and analysis;Benchmark testing;Decision trees;Logistics;Machine learning;Support vector machines;Training","learning (artificial intelligence);pattern classification;statistical analysis","active learning;incremental learning;leading classifiers;learning algorithms;statistical approaches","","4","","41","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"A novel approach of finding frequent itemsets in high speed data streams","B. Chandra; S. Bhaskar","Dept. of Mathemtics, Indian Inst. of Technol., New Delhi, India","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","1","","40","44","The paper proposes a novel methodology of finding frequent itemsets in data stream. Fuzzification of support of closed frequent itemsets in conjunction with jumping window has been used for finding frequent itemsets. Fuzzification of support of closed frequent itemsets helps in preserving information regarding the frequent itemsets at different point in time in the data stream. Use of jumping window over the high speed data stream improves the speed of the proposed algorithm. Effectiveness of the proposed algorithm is shown by comparing its performance with the widely known MOMENT algorithm on both IBM synthetic datasets and benchmark datasets taken from UCI Machine Learning Repository.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019483","λ - cutset;Closed frequent itemsets;Fuzzy membership value;Jumping window;L-function;R-function","Accuracy;Association rules;Benchmark testing;Itemsets;Machine learning algorithms","data mining;fuzzy systems;learning (artificial intelligence)","IBM synthetic datasets;MOMENT algorithm;UCI machine learning repository;frequent itemset finding;fuzzification;high speed data stream;information preservation;window jumping","","0","1","16","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A heuristic method for deriving range-based classification rules","A. Tziatzios; J. Shao; G. Loukides","Sch. of Comput. Sci. &amp; Inf., Cardiff Univ., Cardiff, UK","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","925","929","The ability to learn classification rules from data is important and useful in a range of applications. While many methods to facilitate this task have been proposed, few can derive classification rules that involve ranges (numerical intervals). In this paper, we consider how range-based classification rules may be derived from numerical data and propose a new method inspired by classification association rule mining. This method searches for associated ranges in a similar way to how associated itemsets are searched in categorical attributes in association rule mining, but uses class values to guide the search, so that only those ranges that are relevant to the derivation of classification rules are found. Our preliminary experiments demonstrate the effectiveness of our method.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019723","","Accuracy;Association rules;Density measurement;Educational institutions;Machine learning;Training data","data mining;pattern classification","association rule mining;classification rule learning;itemset categorical attribute;numerical data;range-based classification rule","","0","","9","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"SortNet: Learning to Rank by a Neural Preference Function","L. Rigutini; T. Papini; M. Maggini; F. Scarselli","Dipartimento di Ingegneria dell'Informazione, Universit&#x00E0; degli Studi di Siena, Siena, Italy","IEEE Transactions on Neural Networks","20110829","2011","22","9","1368","1380","Relevance ranking consists in sorting a set of objects with respect to a given criterion. However, in personalized retrieval systems, the relevance criteria may usually vary among different users and may not be predefined. In this case, ranking algorithms that adapt their behavior from users' feedbacks must be devised. Two main approaches are proposed in the literature for learning to rank: the use of a scoring function, learned by examples, that evaluates a feature-based representation of each object yielding an absolute relevance score, a pairwise approach, where a preference function is learned to determine the object that has to be ranked first in a given pair. In this paper, we present a preference learning method for learning to rank. A neural network, the comparative neural network (CmpNN), is trained from examples to approximate the comparison function for a pair of objects. The CmpNN adopts a particular architecture designed to implement the symmetries naturally present in a preference function. The learned preference function can be embedded as the comparator into a classical sorting algorithm to provide a global ranking of a set of objects. To improve the ranking performances, an active-learning procedure is devised, that aims at selecting the most informative patterns in the training set. The proposed algorithm is evaluated on the LETOR dataset showing promising performances in comparison with other state-of-the-art algorithms.","1045-9227;10459227","","10.1109/TNN.2011.2160875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5957304","Learning to rank;neural networks;preference learning;selective learning","Approximation algorithms;Approximation methods;Artificial neural networks;Machine learning;Neurons;Sorting;Training","learning (artificial intelligence);neural nets;relevance feedback;sorting","LETOR dataset;SortNet;active learning procedure;classical sorting algorithm;comparative neural network;feature based representation;global ranking;neural preference function;personalized retrieval system;preference learning method;relevance ranking;scoring function","Algorithms;Cluster Analysis;Feedback;Humans;Information Storage and Retrieval;Learning;Neural Networks (Computer);Pattern Recognition, Automated","6","","33","","20110718","Sept. 2011","","IEEE","IEEE Journals & Magazines"
"A feature selection based on deviation from feature centroid for text categorization","J. Yang; Z. Liu","College of Information Engineering, Northeast Dianli University, Jilin, Jilin, China","2011 2nd International Conference on Intelligent Control and Information Processing","20110901","2011","1","","180","184","Text categorization is very vital in assisting people to process automatically the information which increases exponentially. But the high dimensionality of the vector space is a big hurdle in applying many sophisticated learning algorithms in text categorization. So feature selection has become a research focus in text categorization. In this paper, we proposed a new feature selection, named FCFS, which uses deviation from the feature centroid over all categories as the score of a feature. We compare the proposed method with four well known feature selections using two classification algorithms on three datasets. The experiments show that proposed method is significantly better than information gain, orthogonal centroid feature selection, mutual information and odds rate in terms of accuracy when Naïve Bayes classifier and Support Vector machines are used.","","DVD:978-1-4577-0815-2; Electronic:978-1-4577-0816-9; POD:978-1-4577-0813-8","10.1109/ICICIP.2011.6008227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6008227","feature selection;feature vector space;text categorization","Accuracy;Machine learning;Mutual information;Support vector machine classification;Text categorization;Training","Bayes methods;feature extraction;learning (artificial intelligence);pattern classification;support vector machines;text analysis","FCFS;Naive Bayes classifier;feature selection;information gain;learning algorithm;orthogonal centroid feature selection;support vector machine;text categorization;vector space","","0","","11","","","25-28 July 2011","","IEEE","IEEE Conference Publications"
"Frontiers of information technology","D. E. Dillenberger; D. Gil; S. V. Nitta; M. B. Ritter","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20111003","2011","55","5","1:1","1:13","Every year, the IBM Research Division undertakes a year-long process to analyze and map out important trends and future directions shaping the advances and the applications of information technology (IT). The results are summarized in a document called the Global Technology Outlook (GTO), which influences IBM's strategy and technology roadmaps. Coinciding with the IBM Centennial, a special chapter was commissioned in the 2011 GTO, which was designed to both reflect on the historical evolution of computers and computation as well as to look a few decades ahead to explore the new frontiers of IT. This paper presents the results of this study. It provides a vision of the future in which advances in technology will enable the creation of a new class of “learning” systems, i.e., designed with people as an integral and central element of the process, and which are explicitly aimed to enhance human cognition. These systems will learn from both structured and unstructured data, find important correlations, create hypotheses for these correlations, and suggest and measure actions to enable better outcomes for users. Systems with these capabilities will transform our view of computers from “calculators” to “machines that learn,” which is a shift that will radically alter our expectations of what computing ought to do for us as humans and that will equip us to successfully navigate the increasing complexity of our globally interconnected world.","0018-8646;00188646","","10.1147/JRD.2011.2163275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032769","","Feature extraction;Information technology;Learning systems;Machine learning;Technological innovation","","","","1","","","","","Sept.-Oct. 2011","","IBM","IBM Journals & Magazines"
"A comparative study of feature ranking methods as dimension reduction technique in Genome-Wide Association Study","C. H. Ayuningtyas; G. A. Putri Saptawati; T. L. E. R. Mengko","Sch. of Electr. Eng. &amp; Inf., Inst. Teknol. Bandung, Bandung, Indonesia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","5","In the recent years, Genome-Wide Association Study (GWAS) has been performed by many scientist around the world to find association between genetic profiles of different individuals with the risk of developing certain diseases. GWAS are performed using the Single Nucleotide Polymorphism (SNP) data which represents the genotypes of two different groups of individuals: the case group of individuals with the disease and the control group of individuals without the disease. The very high dimensional SNP data poses challenges in analyzing GWAS result. This issue can be tackled by performing feature ranking to remove non-relevant features for reducing the dimension of the original data. This work compares several feature ranking methods including the chi-square statistics, information gain, recursive feature elimination and Relief algorithm by analyzing the performance of different learning machines combined with the feature ranking. The highest performance is gained by combining recursive feature elimination with linear SVM while the worst performance is shown by the Relief algorithm. The experiments show that the classifiers generally benefit from the feature selection, but that the highest ranked features are not the best classifier.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021621","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021621","GWAS;SNP;classification;dimension reduction;feature ranking;feature selection","Accuracy;Bioinformatics;Classification algorithms;Diseases;Machine learning;Support vector machines;Training","diseases;feature extraction;genetics;genomics;medical computing","GWAS;SNP;chi-square statistics;dimension reduction;diseases;feature ranking methods;genetic profiles;genome-wide association study;relief algorithm;single nucleotide polymorphism","","0","","15","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"A combined method for automatic domain-specific Terminology extraction","L. Liu; Q. Qi","Sch. of Comput. Sci. &amp; Technol., Beijing Inst. of Technol., Beijing, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1734","1737","In this paper we present a Terminology extraction algorithm combining with machine learning and corpus-based statistical model. We collect a balanced corpus with all the possible nominal terms of every domain annotated, and take this corpus as training corpus. After selecting training features for terms, we use SVM to recognize terminological candidates in target corpus. Then we calculate the Domain Relevance (DR) and Domain Consensus (DC) scores for the terminological candidates to acquire domain-specific Terminologies. We make 4 experiments on Tourism corpus and short sentences with two kinds of balanced training corpora. Furthermore, we evaluate the precision and recall of our Terminology extraction algorithm by comparing the words in a golden standard with the words extracted by our system. The experiments show that our algorithm can get improved result in automatic extraction of nominal domain-specific Terminologies. A detailed analysis shows the advantages and disadvantages of our algorithm.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019798","GATE;SVM;Terminology;domain consensus;domain relevance","Algorithm design and analysis;Feature extraction;Machine learning;Machine learning algorithms;Support vector machines;Terminology;Training","learning (artificial intelligence);ontologies (artificial intelligence);statistical analysis;support vector machines","SVM;automatic domain-specific terminology extraction algorithm;balanced training corpora;corpus-based statistical model;domain consensus score;domain relevance score;machine learning;ontology learning;support vector machine;tourism corpus;training feature selection","","0","","10","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Traffic flow management in next generation service provider networks — Are we there yet?","R. Goss; R. Botha","Inst. for ICT Advancement, Nelson Mandela Metropolitan Univ., Port Elizabeth, South Africa","2011 Information Security for South Africa","20110926","2011","","","1","6","For years a number of savvy Internet users have avoided firewalls and traffic engineering measures by directing traffic through ports seemingly unrelated to the application. These ports are those often marked by firewall administrators as “safe” or those given a higher priority on quality of service systems. This problem has been effectively managed by implementing deep packet inspection techniques, giving the administrators a view into the underlying layer 7 protocol of each flow. The reliance on transit payload to be in plain text format in order to reliably match the underlying content has put this method of classification at a major disadvantage. The use of encryption by users to render the contents of a data packet opaque is, therefore, of major concern to network administrators who rely heavily on deep packet inspection. Without the ability to interrogate the underlying payload of traffic flows, a new method to identify this type of traffic needs to be discovered in order to retain control of the network. As an increasing number of users turn to IP tunneling to secure their data transfers, network service providers need to ensure their systems are ready to handle this type of traffic. A failure to do so would result in them facing the reality of a badly managed network. This paper highlights the challenges faced by network service providers in opaque traffic classification for both existing and future, next generation networks. It investigates and evaluates the various solutions implemented in order to manage network traffic “in the dark”.","2330-9881;23309881","Electronic:978-1-4577-1483-2; POD:978-1-4799-1696-2","10.1109/ISSA.2011.6027529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6027529","Deep Packet Inspection;Encryption;IPv6;Network Flow Classification;Service Providers;VPN","Encryption;IP networks;Internet;Machine learning algorithms;Payloads;Protocols","IP networks;Internet;computer network security;cryptography;quality of service;telecommunication traffic","IP tunneling;data packet opaque;deep packet inspection technique;encryption;next generation service provider network;opaque traffic classification;quality of service system;traffic flow management","","0","","19","","","15-17 Aug. 2011","","IEEE","IEEE Conference Publications"
"Transfer learning capability of Evolving Logic Network","M. S. Park","Human-centered Interaction and Robotics Research Center in Korea Institute of Science and Technology (KIST), Korea","2011 IEEE International Conference on Information Reuse & Integration","20110905","2011","","","258","262","This paper proposes a new kind of transfer learning scheme based on ELN and its learning algorithm. ELN was originally proposed as only a fast incremental learning scheme, which resolves a stability-plasticity dilemma and achieves its fast learning speed by storing and reusing old knowledge in learning of new knowledge. Its knowledge management was originally designed for incrementally learning multiple data sets of a single problem; however, it can also be used in transfer learning for multiple problems. ELN learning algorithm can store the old knowledge in a form of sub-maximally consistent regions and get new knowledge for a new problem by combining this old knowledge, obtained from the previous learned problems. With this reuse of old knowledge, new knowledge can be learned more easily, that is, with a smaller number of learning steps and from a smaller number of data, as more problems become learned and more knowledge becomes accumulated. To validate the ELN learning as a transfer learning, we conducted some experiments and investigated the learning performance improvement as more problems are learned.","","Electronic:978-1-4577-0966-1; POD:978-1-4577-0964-7; USB:978-1-4577-0965-4","10.1109/IRI.2011.6009556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6009556","","Acceleration;Accuracy;Data models;Input variables;Machine learning;Performance analysis;Training data","knowledge management;learning (artificial intelligence);logic programming","evolving logic network;incremental learning;knowledge management;knowledge reuse;stability-plasticity dilemma;transfer learning capability","","0","","6","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Study on the classification of data streams with concept drift","Z. Ouyang; Y. Gao; Z. Zhao; T. Wang","Coll. of Sci., Nat. Univ. of Defense Technol., Changsha, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1673","1677","Data streams mining has become a novel research topic of growing interest in knowledge discovery. Because of the high speed and huge size of data set in data streams, the traditional classification technologies are no longer applicable. In recent years a great deal of research has been done on this problem, most intends to efficiently solve the data streams mining problem with concept drift. This paper presents the state-of-the-art in this field with growing vitality and introduces the methods for detecting concept drift in data stream, then gives a critical summary of existing approaches to the problem, including Stagger, FLORA, MetaL(B), MetaL(IB), CD3, CD4, CD5, OLIN, CVFDT and different ensemble classifiers. At last, this paper explores the challenges and future work in this field.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019889","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019889","classification;concept drift;data streams;mining","Accuracy;Classification algorithms;Data mining;Data models;Decision trees;Machine learning;Training","data mining;pattern classification","concept drift;data stream classification;data stream mining;ensemble classifiers;knowledge discovery","","5","","37","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A new rule ranking model for Associative Classification using a hybrid Artificial Intelligence technique","M. M. Najeeb; A. E. Sheikh; M. Nababteh","Faculty of Information Systems and Technology, The Arab Academy for Banking & Financial Sciences, Amman, Jordan","2011 IEEE 3rd International Conference on Communication Software and Networks","20110908","2011","","","231","235","Rule ranking is a crucial step in Associative Classification (AC), AC algorithms proposed many ranking methods which aim to improve the accuracy of the classifier. In this paper we propose a new model in rule ranking, namely Hybrid-RuleRank, which employs a hybrid Artificial Intelligence (AI) technique that combines Simulated Annealing (SA) with Genetic Algorithm (GA), the new model tested against 11 data sets from UCI Machine Learning Repository, and the experimental results show that our model enhances the accuracy of the classifier.","","Electronic:978-1-61284-486-2; POD:978-1-61284-485-5","10.1109/ICCSN.2011.6013816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6013816","Artificial Intelligence;Associative Classification;Genetic Algorithm;Simulated Annealing","Accuracy;Annealing;Biological system modeling;Breast;Iris;Machine learning;Prediction methods","data mining;genetic algorithms;learning (artificial intelligence);pattern classification;simulated annealing","AI;GA;Hybrid-RuleRank;SA;UCI machine learning repository;associative classification;data mining;genetic algorithm;hybrid artificial intelligence technique;rule ranking model;simulated annealing","","3","","29","","","27-29 May 2011","","IEEE","IEEE Conference Publications"
"Reduced error specialization based on the information content of rule set","D. Hu; X. Yu; Y. Feng","Coll. of Inf. Sci. &amp; Technol., Beijing Normal Univ., Beijing, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1485","1489","Except for over-fitting, excessive generalization should lead to high error rate of the learnt rule set, which is seldom discussed by literatures. When excessive generalization is occurred, the rule set will give multiple classification for a particular instance. The errors caused by generalization actually result in the increased inner conflict of the generalized rule set. In this paper, the inner conflict of rule set is defined based on the expanded knowledge of rules and a novel algorithm named RES(reduced error specialization) is proposed for the error rate reduction of rule sets. The best merit of RES is that it can eliminate the inner conflict of a rule set completely while the unknown knowledge of the rule set is unchanged. This fact will guarantee the error rate of the rule set on every test data will be determinedly reduced.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019895","","Data mining;Educational institutions;Error analysis;Machine learning;Training;USA Councils","data mining;error statistics;learning (artificial intelligence);pattern classification","RES;error rate reduction;information content;knowledge rule;multiple classification;reduced error specialization","","0","","16","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Influence of the space segmentation and its adaptive automation for reinforcement learning","A. Notsu; Y. Komori; K. Honda; H. Ichihashi","Osaka Prefecture University, 1-1 Gakuencho, Nakaku, Sakai, Osaka 599-8531, Japan","2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)","20110901","2011","","","1079","1083","We performed a single pendulum simulation and observed the influence of the situation space segmentation pattern in reinforcement learning processes in order to propose a new adaptive automation for situation space segmentation. Usually, in real-world reinforcement learning processes, infinite states and actions and the uncertainty of the optimum solution make the learning process more difficult than the finite Markov decision process. In a numerical experiment, a single pendulum simulation is performed in order to demonstrate the influence and adaptability of the proposed method.","1098-7584;10987584","Electronic:978-1-4244-7317-5; POD:978-1-4244-7315-1; USB:978-1-4244-7316-8","10.1109/FUZZY.2011.6007504","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007504","reinforcement learning;space segmentation","Adaptation models;Adaptive systems;Automation;Learning;Machine learning;Markov processes;Presses","learning (artificial intelligence);pendulums","adaptive automation;infinite states;reinforcement learning;single pendulum simulation;situation space segmentation pattern","","0","","6","","","27-30 June 2011","","IEEE","IEEE Conference Publications"
"An enhanced fuzzy c-means clustering using relational information","J. P. Mei; L. Chen","Div. of Inf. Eng., Nanyang Technol. Univ., Singapore, Singapore","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1090","1094","Most of existing fuzzy clustering approaches cluster objects based on the vector representation or their pairwise relation. In this paper, we propose a new approach called LinkFCM to make use of both types of data by adding an additional term into fuzzy c-means type objective functions. This new term measures the total within cluster association. The LinkFCM is useful for clustering many real-world data, such as Webpages, where together with the content of each Webpage, we may also know the inter-links. Moreover, when the relational data is the user specified pairwise constraints, the proposed approach becomes a semi-supervised fuzzy clustering. We will show that the term measuring the violation of constraints in some existing semi-supervised fuzzy clustering approaches is a special case of the second term in LinkFCM. Experimental study is conducted on real-word data where the relation matrix is constructed under two scenarios: in the first scenario, the relation matrix records the link information between each pair of objects, and in the second scenario, the relation matrix records user specified pairwise constraints. The experimental results show the effectiveness of the proposed LinkFCM in both cases.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019641","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019641","","Abstracts;Accuracy;Clustering algorithms;Couplings;Euclidean distance;Machine learning;Support vector machines","Web sites;fuzzy set theory;learning (artificial intelligence);pattern clustering;relational databases","LinkFCM;Web page;enhanced fuzzy c-means clustering;fuzzy c-means type objective function;relation matrix;relational information;semisupervised fuzzy clustering;user specified pairwise constraint;vector representation","","0","","14","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Semi-supervised Chinese contextual polarity classification with automatic feature selection","G. Xu; H. Wang","Key Lab. of Comput. Linguistics, Peking Univ., Beijing, China","2011 Seventh International Conference on Natural Computation","20110919","2011","2","","1019","1023","Common approaches to the tasks of sentiment analysis start with a list of words with prior polarities, which are context-free. However, a word can exhibit different polarities in different contexts, which are termed as contextual polarities. In this paper, viewing polarities of words as properties of word senses, we treat the Chinese contextual polarity classification as word sense disambiguation (WSD), and manually labeled a Chinese dataset for training and testing. Due to the insufficiency of labeled data, semi-supervised methods are adopted; to find the effective features for the contextual polarity classification, two automatic feature selection algorithms are proposed. We combine the semi-supervised methods with automatic feature selection algorithms in order to utilize the strengths of both. The experimental results show that the semi-supervised methods, automatic feature selection, and the combination of both help to improve the Chinese contextual polarity classification above a supervised baseline model.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022245","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022245","automatic feature selection;contextual polarity;prior polarity;semi-supervised learning;word sense disambiguation","Accuracy;Classification algorithms;Computational linguistics;Machine learning;Niobium;Support vector machines;Training","feature extraction;natural language processing;pattern classification","automatic feature selection;contextual polarities;labeled data insufficiency;semi supervised Chinese contextual polarity classification;sentiment analysis;supervised baseline model;viewing polarities;word sense disambiguation","","2","","15","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Concentration estimation of regularized ranking algorithm","Hong Chen; Yanfang Tao; Weijun Lu","College of Science, Huazhong Agricultural University, Wuhan 430070, China","2011 International Conference on Multimedia Technology","20110825","2011","","","2438","2439","The problem of ranking has recently gained much attention in machine learning. In this paper, we investigate the generalization performance of the regularized ranking algorithm associated with least square ranking loss in a reproducing kernel Hilbert space. Based on the stability analysis, we obtain sample error bounds for this algorithm.","","Electronic:978-1-61284-774-0; POD:978-1-61284-771-9","10.1109/ICMT.2011.6002413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6002413","error estimation;ranking;stability","Algorithm design and analysis;Classification algorithms;Kernel;Machine learning;Machine learning algorithms;Stability analysis;Zinc","Hilbert spaces;generalisation (artificial intelligence);information retrieval;learning (artificial intelligence);least squares approximations","concentration estimation;error bounds;generalization performance;information retrieval;kernel Hilbert space;least square ranking loss;machine learning;regularized ranking algorithm;stability analysis","","1","","11","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Determining software trustworthiness in an environmental context","G. Hurlburt; J. Voas; C. Michael","Change Index Inc., Tall Timbers, MD, USA","2011 IEEE Conference on Prognostics and Health Management","20110922","2011","","","1","4","A kernel is simply a similarity measure that can be applied to input data in the original representation; for example if the data is originally represented as numbers, then the absolute value of the difference between two numbers can be used as a kernel function. However the learning algorithm itself this algorithm is the kernel machine [4] - never sees the data in its original form. Instead, the algorithm only sees the values of various kernel functions that have been applied to the original data. This decouples the data representation from the learning algorithm itself, and thus allows the same machine learning principles to be applied to a wide variety of data types. The advent of kernel machines [2, 3] greatly simplified learning problems where the input data comes in the form strings. String kernels, which are just similarity measures on strings, can be used to train a kernel machine on string data, simply by replacing its existing kernel function with a string kernel function. There are numerous string kernels, but the emphasis is on efficiency. For example, the well-known Levenshtein distance (a.k.a. the edit-distance between two strings) could be used as the basis of a string kernel, but usually this is not done because the edit distance takes quadratic time to compute. One way to construct linear-time string kernels is to use suffix trees [1], which can be used to obtain measures like the longest common substring of two strings, or to get a measure that is close to the number of common substrings.","","Electronic:978-1-4244-9827-7; POD:978-1-4244-9828-4","10.1109/ICPHM.2011.6024359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6024359","String Kernels;software environments;trusworthiness","Humans;Kernel;Machine learning;Monitoring;Semantics;Software systems","learning (artificial intelligence);programming environments","Levenshtein distance;data representation;edit distance;kernel machine;learning algorithm;linear-time string kernel;similarity measure;software environment;software trustworthiness;string kernel function;suffix trees","","0","","4","","","20-23 June 2011","","IEEE","IEEE Conference Publications"
"Build decision tree on support vector machine","D. Zhang; X. B. Jin","Sch. of Inf. Sci. &amp; Eng., Henan Univ. of Technol., Zhengzhou, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","997","1001","C4.5 is a popular classification method which can give the explainable and intuitional classification rules. But it is prone to overfitting due to the data noise or the distribution of the instances. In this paper, we proposed a new decision tree method with the support vector machine (SVM-DTR), which make the surface of the decision tree to discriminate the instances from the different categories as far as possible. SVMis used to measure the importance of the attribute on the fact that the cosine of the angle between the attribute axis and the normal of the decision surface can quantize its significance. Similar as the C4.5, each time we choose the most important attribute as the root of the sub-tree. We analyze the influence of the kernel width to the magnitude of the gradient and obtain the empirical settings about the kernel width from the experiments. The comparisons between the SVM-DTR and the C4.5 on 5 datasets from UCI machine learning repository show that SVM-DTR achieve the better performance than C4.5.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019745","","Decision trees;Educational institutions;Kernel;Machine learning;Spirals;Support vector machines;Training","decision trees;gradient methods;learning (artificial intelligence);pattern classification;support vector machines","C4.5;SVM-DTR;UCI machine learning;data noise;decision tree method with the support vector machine;explainable classification rules;gradient methods;intuitional classification rules","","0","","19","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Learning preference relations using Support Vector Regression","J. Tan; R. Wang","Inst. of Math., Hefei Univ. of Technol., Hefei, China","2011 Seventh International Conference on Natural Computation","20110919","2011","1","","362","366","In this paper we propose a novel approach of learning preference relations using Support Vector Regression (SVR). It answers the problem of consistent ranking and improves the ability of generalization to ranking for the property of SVR method. Meanwhile, the Wilcoxon-Mann-Whitney (WMW) statistic is introduced to evaluate the result of the ranking algorithm. The experiments on an artificial dataset and some benchmark datasets show the effectiveness of the proposed algorithm. An application to ranking in web searching system based on the proposed method is also demonstrated.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022112","Preference relations;Ranking;SVR;WMW","Benchmark testing;Kernel;Machine learning;Support vector machines;Training;Web search","regression analysis;search engines;support vector machines","Web searching system ranking;Wilcoxon-Mann-Whitney statistic;consistent ranking problem;learning preference relation;support vector regression","","0","","10","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"An adaptive multi-agent memetic system for personalizing e-learning experiences","G. Acampora; M. Gaeta; E. Muñoz; A. Vitiello","Dept. of Computer Science, University of Salerno, Fisciano, Italy 84084","2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)","20110901","2011","","","123","130","The rapid changes in modern knowledge, due to exponential growth of information sources, are complicating learners' activity. For this reason, novel approaches are necessary to obtain suitable learning solutions able to generate efficient, personalized and flexible learning experiences. From this point of view, the use of different cooperative intelligent agents can be exploited to analyze learner's preferences and generate high quality learning presentations which provide attractive learning solutions. In particular, to achieve this goal this paper exploits an ontological representation of the learning environment and an adaptive memetic algorithm based on a cooperative multi-agent framework. In this framework different agents analyze the e-learning instance and solve it in a parallel way, cooperating among them. This cooperation is performed by jointly exploiting data mining, via fuzzy decision trees, together with a decision making framework exploiting fuzzy methodologies. As will be shown in the experimental results section, this multi-agent strategy is capable of speeding up the convergence to high-quality personalized e-learning experiences.","1098-7584;10987584","Electronic:978-1-4244-7317-5; POD:978-1-4244-7315-1; USB:978-1-4244-7316-8","10.1109/FUZZY.2011.6007519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007519","Adaptive Memetic Algorithms;E-learning;Multi-Agent Systems","Adaptation models;Decision trees;Electronic learning;Machine learning;Memetics;Optimization","computer aided instruction;data mining;decision trees;fuzzy set theory;multi-agent systems","adaptive multiagent memetic system;cooperative intelligent agents;cooperative multiagent framework;data mining;e-learning experiences personalization;flexible learning experiences;fuzzy decision trees;information sources;learning presentations;learning solutions","","0","","12","","","27-30 June 2011","","IEEE","IEEE Conference Publications"
"Support vectors classification and incremental learning","F. Zhu; N. Ye; S. Xu; X. Gu","Sch. of Inf. Technol., Nanjing Forestry Univ., Nanjing, China","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","1","","206","210","According to whether the slack variable of the support vector is equal to zero, the support vector is divided into two categories, one is linear separable support vector and the other is non-linear separable support vector, in this paper. Using linear separable support vector set instead of support vector set in the incremental learning, Simple ISVM 1 (Simple Incremental Support Vector Machine Algorithm) is proposed. Because the linear separable support vectors are far less than support vectors, the speed of Simple ISVM 1 is fast than SVM-Inc.[1]. But the accuracy is slightly worse than SVM - Inc. For improving the accuracy of Simple ISVM 1, generalized linear separable support vector set is used to replace linear separable support vector set in incremental learning. The Simple IS VM 2 (Simple Incremental Support Vector Machine 2) is proposed. The generalized support vector is the support vector whose slack variable is less than a positive constant. Set a proper threshold, the accuracy of Simple ISVM 2 can be no less than SVM-Inc.[1] and the speed is fast than SVM-Inc. Empirical results show that the linear separable support vector set(or generalized separable support vector set) is the minimum subset which can approximately represent the historical set in the incremental learning, which is smaller than the support vector set.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030187","Incremental learning;KTT conditions;SVM;Simple ISVM;slack variable","Accuracy;Diabetes;Machine learning;Support vector machine classification;Training;Vectors","learning (artificial intelligence);support vector machines","incremental learning;nonlinear separable support vector;simple ISVM 2;simple incremental support vector machine algorithm;slack variable;support vector classification","","1","","12","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Investigation of evolutionary feature subset selection in multi-temporal datasets for harmful algal bloom detection","B. Gokaraju; S. S. Durbha; R. L. King; N. H. Younan","Geosystems Research Institute (GRI), Center for Advanced Vehicular Systems (CAVS) Mississippi State University, Mississippi State, MS 39762-9571, USA","2011 6th International Workshop on the Analysis of Multi-temporal Remote Sensing Images (Multi-Temp)","20110829","2011","","","149","152","In the present study we investigate the evolutionary feature subset selection using wrapper based genetic algorithms on Multi-temporal datasets. Feature subset selection helps in reducing the original feature dimension and also yields high performance. The evolutionary strategy attains a global optimum by reducing the computations iteratively and by traversing intelligently in the entire feature space. This method gave a very high performance improvement up to 0.97 kappa accuracy with a best reduced feature dimension for harmful algal bloom detection.","","Electronic:978-1-4577-1203-6; POD:978-1-4577-1202-9","10.1109/Multi-Temp.2011.6005070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005070","Feature Selection;Genetic Algorithms;Multi-Temporal;Support Vector Machines","Accuracy;Computational modeling;Data mining;Feature extraction;Genetic algorithms;Indexes;Machine learning","data mining;genetic algorithms;geophysical image processing;microorganisms;oceanographic techniques;remote sensing;support vector machines","evolutionary feature subset selection;feature space;harmful algal bloom detection;multitemporal datasets;original feature dimension reduction;wrapper based genetic algorithms","","0","","5","","","12-14 July 2011","","IEEE","IEEE Conference Publications"
"Adaptation of Gaussian ARD kernel for multiclass classification","T. Wang","Sch. of Math. &amp; Comput. Sci., Gannan Normal Univ., Ganzhou, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","983","986","The problem of optimizing Gaussian Automatic Relevance (ARD) kernel in a multiclass setting is considered. Unlike the conventional Gaussian kernel with a single width parameter, the Gaussian ARD kernel adopts multiple widths corresponding to the input features. We first present a model selection criterion named kernel distance-based class separability (KDCS) to evaluate the goodness of a kernel in multiclass classification scenario, then propose a gradient-based optimization algorithm to tune the width parameters of Gaussian ARD kernel via maximizing the KDCS criterion. This method is essentially a feature weighting method since each learned parameter indicates the relative importance of the corresponding feature. The proposed method is demonstrated with some UCI machine learning benchmark examples.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019661","auto relevance determination (ARD);feature weighting;model selection;multiclass classification;support vector machines (SVMs)","Ionosphere;Kernel;Machine learning;Optimization;Support vector machine classification;Training","gradient methods;learning (artificial intelligence);optimisation;pattern classification;support vector machines","Gaussian ARD kernel adaptation;Gaussian automatic relevance kernel optimization;KDCS criterion maximization;UCI machine learning;feature weighting method;gradient-based optimization algorithm;kernel distance-based class separability;model selection criterion;multiclass classification;width parameters","","0","","16","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A new LogitBoost algorithm for multiclass unbalanced data classification","J. Song; X. Lu; M. Liu; X. Wu","Sch. of Stat., Capital Univ. of Econ. &amp; Bus., Beijing, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","974","977","LogitBoost algorithm is an extension of Adaboost algorithm. It replaces the exponential loss of Adaboost algorithm to conditional Bernoulli likelihood loss. LogitBoost-J algorithm further extends the LogitBoost to multiclass situation. But like LogitBoost algorithm and Adaboost algorithm, LogitBoost-J algorithm is not suitable for unbalanced data classification. This paper proposes a new LogitBoost algorithm for multiclass unbalanced data classification. The experiment on practical data shows that this new algorithm performs better than LogitBoost-J algorithm and is competitive to BABoost algorithm.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019654","LogitBoost;Multiclass;Unbalanced data","Blogs;Boosting;Classification algorithms;Educational institutions;Glass;Machine learning algorithms;Prediction algorithms","learning (artificial intelligence);pattern classification","Adaboost algorithm;BABoost algorithm;LogitBoost-J algorithm;conditional Bernoulli likelihood loss;multiclass unbalanced data classification","","0","","19","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A low-order model of biological neural networks for hierarchical or temporal pattern clustering, detection and recognition","J. T. H. Lo","Department of Mathematics and Statistics, University of Maryland Baltimore County, Maryland 21250, U.S.A.","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","37","44","A low-order model (LOM) of biological neural networks, which is biologically plausible, is herein reported. LOM is a recurrent hierarchical network composed of novel models of dendritic trees for encoding information, spiking neurons for computing subjective probability distributions and generating spikes, nonspiking neurons for transmitting inhibitory graded signals to modulate their neighboring spiking neurons, unsupervised and supervised covariance learning and accumulation learning mechanisms, synapses, a maximal generalization scheme, and feedback connections with different delay durations. An LOM with a main network that learns without supervision and clusters similar patterns, and offshoot structures that learn with supervision and assign labels to clusters formed in the main network is proposed as a learning machine that learns and retrieves easily, generalizes maximally on corrupted, distorted and occluded temporal and spatial patterns, and utilizes fully the spatially and temporally associated information.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033197","","Biological information theory;Biological neural networks;Biological system modeling;Covariance matrix;Integrated circuit modeling;Machine learning;Neurons","biology computing;learning (artificial intelligence);neural nets;pattern clustering;probability","LOM;accumulation learning mechanisms;biological neural networks;delay durations;dendritic trees;feedback connections;low order model;probability distributions;spiking neurons;supervised covariance learning;temporal pattern clustering","","0","","13","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Information extraction from scientific paper using rhetorical classifier","M. L. Khodra; D. H. Widyantoro; E. A. Aziz; R. T. Bambang","Sch. of Electr. Eng., Bandung Inst. of Technol., Bandung, Indonesia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","5","Time constraints often lead a reader of scientific paper to read only the title and abstract of the paper, but reading these parts is often ineffective. This study aims to extract information automatically in order to help the readers get structured information from a scientific paper. The information extraction is done by rhetorical classification of each sentence in a scientific paper. Rhetoric information is the intention to be conveyed to the reader by the author of the paper. This research used corpus-based approach to build rhetorical classifier. Since there was a lack of rethorical corpus, we constructed our own corpus, which is a collection of sentences that have been labeled with rhetorical information. Each sentence represented as a vector of content, location, citation, and meta-discourses features. This collection of feature vectors is used to build rhetorical classifiers by using machine learning techniques. Experiments were conducted to select the best learning techniques for rhetorical classifier. Training set consists of 7239 labeled sentences, and the testing set consists of 3638 labeled sentences. We used WEKA (Waikato Environment for Knowledge Analysis) and LibSVM libraries. Learning techniques being considered were Naive Bayes, C4.5, Logistic, Multi-Layer Perceptron, PART, Instance-based Learning, and Support Vector Machines (SVM). The best performers are the SVM and Logistic classifier with accuracy of 0.51. By applying one-against-all strategy, the SVM accuracy can be improved to 0.60.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021634","SVM classifier;information extraction;rhetorical classifier;rhetorical corpus;scientific paper","Accuracy;Data mining;Feature extraction;Logistics;Machine learning;Support vector machines;Training","Bayes methods;information retrieval;learning (artificial intelligence);multilayer perceptrons;pattern classification;support vector machines","C4.5 learning technique;LibSVM libraries;PART;Waikato environment for knowledge analysis;corpus-based approach;feature vectors;information extraction;instance-based learning;logistic learning technique;machine learning techniques;multilayer perceptron;naive Bayes;rhetoric information;rhetorical classifier;scientific paper;sentence rhetorical classification;support vector machines","","1","","24","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"Learning capabilities of agents in social systems","N. T. Le; L. Märtin; N. Pinkwart","Nieders&#x00E4;chsische Technische Hochschule, Braunschweig, Clausthal-Zellerfeld, Hannover, Germany","2011 IEEE International Conference on Information Reuse & Integration","20110905","2011","","","539","544","In a social computational system, there exist not only social interactions between software agents but also between humans and agents. Through interactions with humans, agents can acquire more knowledge, e.g., in problem solving. Usually, agents are hard-coded with anticipated abilities and their knowledge cannot evolve dynamically. In this paper, we propose a strategy-based approach to enable agents learning from humans in conflict situations. The learning process consists of four phases: 1) the conflict between a human and an agent is detected, 2) the human initiates a communication with the agent and proposes a strategy to solve the conflict, 3) the human's strategy is evaluated, and 4) the agent applies the most effective strategy in a new similar situation. The contribution of the paper is two-fold: it presents a new agent learning approach in the area of multi-agent learning and proposes a way of cooperation between humans and agents in a social computational system to evolve agents' abilities.","","Electronic:978-1-4577-0966-1; POD:978-1-4577-0964-7; USB:978-1-4577-0965-4","10.1109/IRI.2011.6009613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6009613","","Airports;Humans;Learning systems;Machine learning;Problem-solving;Radiation detectors;Vehicles","knowledge acquisition;learning (artificial intelligence);multi-agent systems;social aspects of automation;software agents","agent learning approach;knowledge acquisition;learning capabilities;multiagent learning;problem solving;social computational system;social interactions;software agents;strategy-based approach","","0","","18","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"The application of C4.5 algorithm based on SMOTE in financial distress prediction model","Zi-nan Chang","Department of Information Technology, Jinling Institute of Technology, Nanjing, China","2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)","20110905","2011","","","5852","5855","Datasets used in financial distress forecast are unbalanced. The traditional method gets lower predict accuracy especially in small samples of unbalanced datasets. The datasets are balanced with SMOTE method and then classified with the classical decision tree algorithm C4.5. The results show that the prediction model based on C4.5 algorithm gets the better performance.","","Electronic:978-1-4577-0536-6; POD:978-1-4577-0535-9","10.1109/AIMSEC.2011.6011460","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6011460","Decision Tree;financial distress prediction;smote;unbalanced dataset","Accuracy;Algorithm design and analysis;Classification algorithms;Decision trees;Machine learning;Prediction algorithms;Predictive models","data mining;decision trees;financial management","C4.5 algorithm;SMOTE method;decision tree algorithm;financial distress prediction model","","2","","6","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"Attribute reduction algorithm on relative distribution granularity","Xiaofan Zhang; Yujun Fan","School of Mechatronic Engineering, Wuhan University of Technology, China","2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)","20110905","2011","","","6984","6989","In this paper, we introduce the concept of relative distribution function and relative distribution granularity in decision table information system. And we use the difference between relative distribution as the heuristic information, then it provides the attribute reduction algorithm based on relative distribution granularity of decision table information system, and it uses UCI data sets to validate the algorithm. The experimental result shows that this algorithm is effective and efficient.","","Electronic:978-1-4577-0536-6; POD:978-1-4577-0535-9","10.1109/AIMSEC.2011.6011454","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6011454","Attribute reduction;Decision table information system;Relative distribution granularity","Algorithm design and analysis;Atmospheric measurements;Complexity theory;Distribution functions;Information systems;Machine learning algorithms;Software algorithms","data reduction;decision tables;information systems","UCI data sets;attribute reduction algorithm;decision table information system;heuristic information;relative distribution function;relative distribution granularity","","0","","6","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"Kernel based empirical mode decomposition and its application in gait signal de-noise","S. Wen; F. Wang; C. Wu","College of Information Science and Engineering, Northeastern University, Shenyang 110819, China","Proceedings of the 30th Chinese Control Conference","20110825","2011","","","3221","3225","Gait signal analysis of quantitative has been a challenging task over the past decades for its non-linear and non-stationary nature. Empirical Mode Decomposition (EMD) is a data-driven signal analysis method developed by Norden. E. Huang, it is especially suitable for non-linear non-stationary signal processing. It has been successfully applied in many problems, but the envelop algorithm using traditional cubic spline interpolation by Norden. E. Huang have border swing problem and extra oscillations, it is because that the cubic spline interpolation couldn't adapt to the nature of the signal envelop, inspired by the ideas from machine learning, a new algorithm which is improved kernel ridge regression to estimate envelop of signal using the extrema is proposed in this paper. The new algorithm can used to recover the corrupted test signal. Numerical simulations show higher performance of the proposed algorithm than the traditional one.","1934-1768;19341768","Electronic:978-988-17255-9-2; POD:978-1-4577-0677-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6001124","Empirical Mode Decomposition;Gait Signal De-noise;Kernel","Conferences;Filtering;Interpolation;Kernel;Machine learning algorithms;Signal processing algorithms;Spline","bioelectric phenomena;gait analysis;interpolation;learning (artificial intelligence);medical signal processing;regression analysis;signal denoising;singular value decomposition;splines (mathematics)","border swing problem;cubic spline interpolation;data-driven signal analysis;gait signal analysis;gait signal de-noise;kernel based empirical mode decomposition;kernel ridge regression;machine learning;nonlinear nonstationary signal processing;numerical simulations;oscillations","","0","","14","","","22-24 July 2011","","IEEE","IEEE Conference Publications"
"An enhanced EM method of semi-supervised classification based on Naive Bayesian","H. Wen; N. f. Xiao; Z. Li","Sch. of Comput. Sci. &amp; Eng., Univ. of Technol., Guangzhou, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","987","991","Semi-supervised learning (SSL) based on Naïve Bayesian and Expectation Maximization (EM) combines small limited numbers of labeled data with a large amount of unlabeled data to help train classifier and increase classification accuracy. With the aim of improving the efficiency problem of the basic EM algorithm, an enhanced EM method is proposed. Firstly, a feature selection function of strong category information is constructed to control the dimension of feature vector and preserve useful feature terms. Secondly, an intermediate classifier gradually transfers unlabeled documents of maximum posterior category probability to labeled collection during each iteration process of the EM algorithm. The iteration number of the enhanced EM is obviously less than the basic EM. Finally, experiments shows that the improved method obtains very effective performance in terms of macro average accuracy and algorithm efficiency.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019690","Naïve Bayesian;Semi-supervised classification;enhanced EM;feature selection","Accuracy;Bayesian methods;Classification algorithms;Educational institutions;Machine learning;Mathematical model;Text categorization","Bayes methods;expectation-maximisation algorithm;learning (artificial intelligence);text analysis","algorithm efficiency;automatic text classification;category information;expectation maximization method enhancement;feature selection function;feature terms;feature vector;intermediate classifier;iteration process;macro average accuracy;maximum posterior category probability;naive Bayesian;semisupervised learning","","0","","14","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"An improved cohesion self-merging clustering algorithm","C. Ye; C. Zhong","Coll. of Sci. &amp; Technol., Ningbo Univ., Ningbo, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1095","1098","Hybrid clustering algorithms have long been focused on in machine learning research community. The most important components of this kind of algorithm are the split and merge criteria. The cohesion-based self-merging is an interesting hybrid clustering algorithm proposed in the literature. Although the algorithm has a good performance, it suffers from instability of its results. To alleviate the instability and make it more efficient, in this paper, we improve the two components of it. For the split component, an optimal method of determining initial prototypes for K-means is presented, for the merge component, the cohesion criterion is improved. The experimental results demonstrate the efficiency of the proposed method.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019670","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019670","","Clustering algorithms;Frequency modulation;Iris;Machine learning algorithms;Partitioning algorithms;Pattern recognition;Prototypes","learning (artificial intelligence);pattern clustering","cohesion criterion;cohesion selfmerging clustering algorithm;hybrid clustering algorithms;k-means initial prototype determination;machine learning research community;merge component;merge criteria;split component;split criteria","","0","","18","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A new method for filling missing values by gray relational analysis","Bingwei Han; Shuangjiu Xiao; Lu Liu; Zhijing Wu","Digital Art Lab, School of Software, Shanghai Jiao Tong University, China","2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)","20110905","2011","","","2721","2724","In Data Mining and Machine Learning, the missing attribute will have a negative impact on the learning results. The filling of missing values is a very challenging work. In this paper, a new algorithm based on gray relational analysis is presented, which takes the differences of the relationships between the properties into account. When calculating the gray relational grade, the weights of attributes will be considered. The experimental results demonstrate that this method performs well when filling the discrete missing values.","","Electronic:978-1-4577-0536-6; POD:978-1-4577-0535-9","10.1109/AIMSEC.2011.6010428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6010428","gray relational analysis;missing values;mutual information","Algorithm design and analysis;Data mining;Decision trees;Filling;Machine learning;Mutual information;Rain","data mining;learning (artificial intelligence)","attributes weight;data mining;filling missing values;grey relational analysis;machine learning;missing attribute;relational grade","","0","","9","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"A virus detection scheme based on features of Control Flow Graph","Zongqu Zhao","School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China","2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)","20110905","2011","","","943","947","For the well-known reasons, the virus detection schemes based on signature manifest unsatisfactory performance when they dispose the previously unknown virus. Recently, machine learning methods were introduced to build new ways for virus detection. They adopted classification algorithms to learn patterns in the binary code files in order to classify unknown files. In this paper, we present a graph features based method, which can be used in the process of machine learning, and design a virus detection model based on our feature method. The features are extracted from Control Flow Graph (CFG) of executable. We follow a threefold research methodology in our detection model: (1) create the CFG of the executables, (2) extract features from the CFG and create training data, (3) generate classifiers according to specific machine learning algorithms, and detect virus with these classifiers. For the sake of fixed sum of features, our model avoids situation that too much features could be found in other feature methods and leaves the filter step out of it, so it presents the efficient and scalability. With our experiments, we were able to achieve as high as 95.9% detection rate and as low as 5.9% false positive rate on novel malware.","","Electronic:978-1-4577-0536-6; POD:978-1-4577-0535-9","10.1109/AIMSEC.2011.6010676","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6010676","control flow graph;data mining;virus detection","Accuracy;Bagging;Data mining;Feature extraction;Machine learning;Malware;Software","computer viruses;digital signatures;flow graphs;learning (artificial intelligence);pattern classification","binary code files;classification algorithms;classifier generation;control flow graph features;executable CFG;feature extraction;graph features based method;machine learning methods;malware;training data creation;virus detection scheme","","3","","11","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"The flexible integration of inference algorithm based on users' preference","Y. Wang; H. Bu; Y. Qiu","Coll. of Comput., Wuhan Univ., Wuhan, China","Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology","20110919","2011","5","","2671","2674","The core problem with the current personalized recommendation system is incomplete description of users' preference. Different from the commonly-used methods in which the system enquires users to inform users' preference, this paper proposes a method that is flexible integration of inference from semantic information of noumenon. Through inference it will effectively improve the users' preference data. Experimental results show the effectiveness and feasibility of the method.","","DVD:978-1-61284-086-4; Electronic:978-1-61284-088-8; POD:978-1-61284-087-1","10.1109/EMEIT.2011.6023646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6023646","AI;personalization;the flexible integration of inference;users' preference","Databases;Educational institutions;Equations;Inference algorithms;Machine learning;Mathematical model;Semantics","Internet;human computer interaction;inference mechanisms;recommender systems","Internet;inference algorithm;personalized recommendation system;users preference","","0","","12","","","12-14 Aug. 2011","","IEEE","IEEE Conference Publications"
"Train Fuzzy Cognitive Maps by gradient residual algorithm","H. Zhang; Z. Shen; C. Miao","School of Computer Engineering, Nanyang Technological University, Singapore","2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)","20110901","2011","","","1815","1821","Fuzzy Cognitive Maps (FCM) is a popular technique for describing dynamic systems. A FCM for a dynamic system is a signed graph consisted of relevant concepts and causal relationships/weights between the concepts in the system. With suitable weights defined by experts in the related areas, the inference of the FCM can provide meaningful modeling of the system. Thus correctness of the weights is crucial to the success of a FCM system. Normally the weights are set by experts in the related areas. Considering the possible inefficiency and subjectivity of experts when judging the weights, it is an appealing idea to generate weights automatically according to the samples obtained through observation of the system. Some training algorithms were proposed. However, to our best knowledge, few learning algorithm has been reported to generate weight matrix based on sample sequences with continuous values. In this paper, we introduce a new learning algorithm to train the weights of FCM. In the proposed algorithm, the weights are updated by gradient descent on a squared Bellman residual, which is an accepted method in machine learning. The experiment results show that given sufficient training samples, the correct weights can be approximated by the algorithm. The algorithm proposes a new way for FCM research and applications.","1098-7584;10987584","Electronic:978-1-4244-7317-5; POD:978-1-4244-7315-1; USB:978-1-4244-7316-8","10.1109/FUZZY.2011.6007485","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007485","Fuzzy cognitive maps","Algorithm design and analysis;Approximation algorithms;Equations;Heuristic algorithms;Machine learning algorithms;Mathematical model;Training","cognitive systems;fuzzy set theory;gradient methods;learning (artificial intelligence)","FCM inference;FCM system;dynamic system;fuzzy cognitive map;gradient descent;gradient residual algorithm;learning algorithm;machine learning;signed graph;squared Bellman residual;system modeling;weight matrix","","1","","19","","","27-30 June 2011","","IEEE","IEEE Conference Publications"
"Regularization based ordering for ensemble pruning","G. Zhang; J. Yin; S. Zhang; L. Cheng","Dept. of Comput. Sci., SUN YAT-SEN Unversity, Guangzhou, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1325","1329","In ensemble learning, several base learners are combined together in some way to get a stronger learner. Good ensembles are often much more accurate than individual learners that make them up. Ensemble pruning searches for a good subset of ensemble members that performs as well as, or better than the original ensemble. We analyze accuracy, diversity and generalization ability of base learners for classification, then prove that ensemble constructed by learners of better generalization ability performs better in generalization. Then we use Graph Laplacian to evaluate generalization ability of learners on data sets and propose an efficient hybrid metric based individual contribution estimating method that fully reflects performance of member classifiers. A multi-objective sort method is used to get the best order under hybrid metric. Experimental results show that the proposed method is effective.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019643","ensemble learning;ensemble pruning;generalization;graph laplacian","Accuracy;Algorithm design and analysis;Classification algorithms;Error analysis;Laplace equations;Machine learning;Measurement","graph theory;learning (artificial intelligence);pattern classification","efficient hybrid metric;ensemble learning;ensemble pruning;graph Laplacian;individual contribution estimating method;multiobjective sort method;regularization based ordering","","0","","21","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A new short-text categorization algorithm based on improved KSVM","Z. Su-zhi; S. Pei-feng","College of Computer and Communication Engineering, Zhengzhou University of Light Industry, Zhengzhou, China","2011 IEEE 3rd International Conference on Communication Software and Networks","20110908","2011","","","154","157","A hybrid KSVM categorization algorithm is proposed in this paper, due to the fact that SVM algorithm classifies some tested temples in error nearby the optimal hyper-surface. In the classifying phase, the algorithm computes the distance from the tested sample to the optimal hyper-surface of SVM in the feature space, and chooses different algorithms for different distances. Then we apply this algorithm to short text categorization. The experimental results show that this algorithm, compared with traditional algorithms, greatly improved the classification accuracy of short text.","","Electronic:978-1-61284-486-2; POD:978-1-61284-485-5","10.1109/ICCSN.2011.6014694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6014694","KNN;KSVM;SVM;short text","Classification algorithms;Helium;Machine learning;Support vector machines","pattern classification;support vector machines;text analysis","KNN;SVM algorithm;classifying phase;hybrid KSVM categorization algorithm;k nearest neighbor;short-text categorization algorithm;support vector machine","","1","","8","","","27-29 May 2011","","IEEE","IEEE Conference Publications"
"An approach of color recognition based on SVM","X. Qi; J. Ji; X. Han","Sch. of Inf. &amp; Electr. Eng., Shenyang Agric. Univ., Shenyang, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1925","1928","This paper presented an intelligent approach of color recognition with support vector machine (SVM) in the HSI color space, which is in accord with human visual perception characteristics. Based on the structural risk minimization principle, SVM can solve small-sample learning problems and avoid the over-learning as well as easily falling into local minima problems during the training process. Experimental results show that the proposed method can be used to recognize typical colors effectively.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019894","HSI;SVM;color recognizion;corlor space","Educational institutions;Humans;Image color analysis;Kernel;Machine learning;Support vector machines;Training","image colour analysis;image recognition;support vector machines;visual perception","HSI color space;SVM;color recognition;human visual perception;learning;local minima;over-learning;structural risk minimization principle;support vector machine","","0","","12","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A study on the intelligent method for detection of computer viruses","L. Ren","Tianjin Institute of Urban Construction, Tianjin City, P.R. China","2011 IEEE 2nd International Conference on Computing, Control and Industrial Engineering","20110901","2011","2","","370","373","This paper makes a virus detection study based on the D-S theory of evidence, which applies to two types of classifiers, support vector machines and probabilistic neural networks to detect the virus. Then, the D-S theory of evidence is used to combine the contribution of each individual classifier to obtain the final decision. The experiment tests and result analyses demonstrate that it is efficient for unknown viruses and variant viruses to improve accuracy rate of integration virus detector by using D-S theory to create the isomeric classifier.","","Electronic:978-1-4244-9600-6; POD:978-1-4244-9599-3","10.1109/CCIENG.2011.6008141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6008141","D-S theory of evidence;classifier;computer viruses;credit distribution;virus detection","Bagging;Classification algorithms;Machine learning;Probabilistic logic;Support vector machines;Training;Viruses (medical)","computer viruses;inference mechanisms;neural nets;pattern classification;support vector machines","D-S theory of evidence;computer virus detection;intelligent method;isomeric classifier;probabilistic neural networks;support vector machines","","0","","6","","","20-21 Aug. 2011","","IEEE","IEEE Conference Publications"
"Bag-level active multi-instance learning","J. Fu; J. Yin","Sch. of Inf. Sci. &amp; Technol., SUN YAT-SEN Univ., Guangzhou, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1307","1311","Multi-Instance Learning (MIL) is a special scheme in machine learning. In recent research it is successfully applied in text classification problem. However, MIL is naturally semi-supervised since the instances labels are unknown for positive bags, which would cut down the accuracy of predictors, or require more computational cost to reduce uncertainty, or to guess such labels at a high probability. In this paper, we attempt to tackle MIL problem by introducing active learning, which is another learning scheme attracted much research interests. Active learning relies on an oracle that can give ground truth labels as required. The proposed method is based on query for bags and it adopts a Fisher Information Matrix (FIM) based method to construct the criteria of query for oracle. We launch experiment on a famous text classification data set - 20 group news. Compared to the randomly selected query strategy as a baseline method and recent methods, the proposed method is of higher accuracy and outperforms others.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019682","active learning;fisher information matrix;multi-instance learning;text classification","Bismuth;Machine learning;Measurement;Silicon;Text categorization;Training;Uncertainty","learning (artificial intelligence);matrix algebra;query processing;text analysis","active learning;bag-level active multi-instance learning;fisher information matrix based method;ground truth labels;machine learning;oracle;positive bags;query strategy;text classification data set","","2","","20","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Informed software installation through License Agreement Categorization","A. Borg; M. Boldt; N. Lavesson","Sch. of Comput., Blekinge Inst. of Technol., Karlskrona, Sweden","2011 Information Security for South Africa","20110926","2011","","","1","8","Spyware detection can be achieved by using machine learning techniques that identify patterns in the End User License Agreements (EULAs) presented by application installers. However, solutions have required manual input from the user with varying degrees of accuracy. We have implemented an automatic prototype for extraction and classification and used it to generate a large data set of EULAs. This data set is used to compare four different machine learning algorithms when classifying EULAs. Furthermore, the effect of feature selection is investigated and for the top two algorithms, we investigate optimizing the performance using parameter tuning. Our conclusion is that feature selection and performance tuning are of limited use in this context, providing limited performance gains. However, both the Bagging and the Random Forest algorithms show promising results, with Bagging reaching an AUC measure of 0.997 and a False Negative Rate of 0.062. This shows the applicability of License Agreement Categorization for realizing informed software installation.","2330-9881;23309881","Electronic:978-1-4577-1483-2; POD:978-1-4799-1696-2","10.1109/ISSA.2011.6027539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6027539","EULA analysis;Parameter tuning;Spyware;automated detection","Licenses;Machine learning;Machine learning algorithms;Software;Spyware;Tuning","bagging;category theory;invasive software;learning (artificial intelligence);software engineering","AUC measure;EULA;automatic prototype;bagging algorithm;data set;end user license agreement;feature selection;informed software installation;license agreement categorization;machine learning technique;parameter tuning;performance tuning;random forest algorithm;spyware detection","","0","","23","","","15-17 Aug. 2011","","IEEE","IEEE Conference Publications"
"Inconsistency-induced learning: A step toward perpetual learners","D. Zhang; M. Lu","Department of Computer Science, California State University, Sacramento, 95819-6021, USA","Cognitive Informatics & Cognitive Computing (ICCI*CC ), 2011 10th IEEE International Conference on","20110908","2011","","","59","66","One of the long-term research questions in machine learning is how to build never-ending learners. The state-of-the-practice in the field of machine learning thus far is still dominated by the one-time learner paradigm: some learning algorithms are utilized on data sets to produce certain results, and then the learner is put away and the results are put to work. Such a learn-once-apply-next (or LOAN) approach may not be adequate in dealing with many real world problems and is in sharp contrast with human's life-long learning process. On the other hand, learning is often brought on through some stimulus. In this paper, we describe a framework for inconsistency-induced learning. The framework relies on utilizing inconsistency as learning stimulus and inconsistency resolution as impetus for continuous learning. The framework hinges on recognizing inconsistency in information or knowledge, identifying the cause of inconsistency, revising beliefs to explain, resolve, or accommodate inconsistency. The perpetual learning process is triggered by an agent encountering some antagonistic circumstance, and is embodied in the continuous inconsistency-induced belief revisions. Though there can be other stimuli to learning, we believe that inconsistency-induced learning can be an important step toward building perpetual learning agents.","","Electronic:978-1-4577-1697-3; POD:978-1-4577-1695-9","10.1109/COGINF.2011.6016122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016122","inconsistency;inconsistency-induced learning;perpetual learning agents","Buildings;Humans;Machine learning;Problem-solving;Refining;Semantics;Shape","continuing professional development;learning (artificial intelligence);multi-agent systems","LOAN approach;continuous inconsistency-induced belief revisions;continuous learning;data sets;inconsistency resolution;inconsistency-induced learning;learn-once-apply-next approach;learning algorithms;learning stimulus;life-long learning process;machine learning;never-ending learners;one-time learner paradigm;perpetual learners;perpetual learning agents;perpetual learning process","","3","","16","","","18-20 Aug. 2011","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Shaping agent by critical states","Jiong Song; J. Zhao","Yunnan Jiao Tong Vocational & Tech. Coll., Kunming, China","2011 Seventh International Conference on Natural Computation","20110919","2011","3","","1314","1317","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>Shaping is a promising technique for scaling Reinforcement Learning to large and complex problems. But the design and tune of shaping reward are difficult and problem-oriented. We propose an approach to make agent can shape itself by critical states, which are found by agent itself from prior learning. We accumulate the state trajectories that agent experienced in every training episode, and eliminate the state loops existed in the original state trajectories, then the acyclic state trajectories are used to find the critical states. The critical state is a state that has high probability to appear in all these acyclic state trajectories, that means, if agent wants to reach the goal state, then it would have high probability to pass the critical states. So the critical states can be used to shape agent reaching the goal state faster. The Grid-World problem is used to illustrate the applicability and effectiveness of our approach. The more important is our approach makes agent can shape itself by what it learned.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022342","","Algorithm design and analysis;Humans;Learning;Machine learning;Shape;Training;Trajectory","grid computing;learning (artificial intelligence);probability;software agents","acyclic state;critical states;grid-world problem;probability;reinforcement learning scaling;shaping agent;state loop elimination","","0","","12","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"The generalization performance of learning algorithms derived simultaneously through algorithmic stability and space complexity","J. Xu; B. Zou","Fac. of Math. &amp; Comput. Sci., Hubei Univ., Wuhan, China","2011 Seventh International Conference on Natural Computation","20110919","2011","1","","288","292","A main issue in machine learning theoretical research is to analyze the generalization performance of learning algorithms. The previous results describing the generalization performance of learning algorithms are based on either complexity of hypothesis space or stability property of learning algorithms. In this paper we go far beyond these classical frameworks by establishing the first generalization bounds of learning algorithms in terms of uniform stability and the covering number of function space for regularized least squares regression and SVM regression. To have a better understanding the results obtained in this paper, we compare the obtained generalization bounds with previously known results.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022044","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022044","","Complexity theory;Kernel;Learning systems;Machine learning;Machine learning algorithms;Stability analysis;Support vector machines","computational complexity;learning (artificial intelligence);least squares approximations;regression analysis;support vector machines","SVM regression;algorithmic stability;hypothesis space;learning algorithm generalization performance;learning algorithm stability;machine learning;regularized least squares regression;space complexity;support vector machines","","0","","28","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Reinforcement learning model, algorithms and its application","W. Qiang; Z. Zhongli","Comput. Sci. Dept. , Jilin Technol. Coll. of Electron. Inf., Jilin, China","2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)","20110922","2011","","","1143","1146","Reinforcement learning comes from the animal learning theory. RL does not need prior knowledge, it can autonomously get optional policy with the knowledge obtained by trial-and-error and continuously interacting with dynamic environment. Its characteristics of self improving and online learning make reinforcement learning become one of intelligent agent's core technologies. In this paper, we firstly survey the model and theory of reinforcement learning. Then, we roundly present the main reinforcement learning algorithms, including Sarsa, temporal difference, Q-learning and function approximation. Finally, we briefly introduce some applications of reinforcement learning and point out some future research directions of reinforcement learning.","","Electronic:978-1-61284-722-1; POD:978-1-61284-719-1","10.1109/MEC.2011.6025669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025669","Q-learning;Reinforcement Learning;Sarsa;function approximation;temporal difference","Algorithm design and analysis;Function approximation;Heuristic algorithms;Intelligent agents;Learning;Learning systems;Machine learning","approximation theory;learning (artificial intelligence)","Q-learning;animal learning theory;function approximation;reinforcement learning","","2","","20","","","19-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Getting More From the Semiconductor Test: Data Mining With Defect-Cluster Extraction","M. P. L. Ooi; E. K. J. Joo; Y. C. Kuang; S. Demidenko; L. Kleeman; C. W. K. Chan","Monash University Sunway Campus, Selangor, Malaysia","IEEE Transactions on Instrumentation and Measurement","20110912","2011","60","10","3300","3317","High-volume production data shows that dies, which failed probe test on a semiconductor wafer, have a tendency to form certain unique patterns, i.e., defect clusters. Identifying such clusters is one of the crucial steps toward improvement of the fabrication process and design for manufacturing. This paper proposes a new technique for defect-cluster identification that combines data mining with a defect-cluster extraction using a Segmentation, Detection, and Cluster-Extraction algorithm. It offers high defect-extraction accuracy, without any significant increase in test time and cost.","0018-9456;00189456","","10.1109/TIM.2011.2122430","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740361","Data mining;defect-cluster extraction;probe testing;segmentation;semiconductor manufacturing","Clustering algorithms;Data mining;Machine learning algorithms;Manufacturing;Noise;Production","data mining;production engineering computing;semiconductor device testing;semiconductor industry","cluster-extraction algorithm;data mining;defect-cluster extraction;defect-cluster identification;defect-extraction accuracy;detection algorithm;dies;high-volume production data;segmentation algorithm;semiconductor test;semiconductor wafer","","11","","34","","20110328","Oct. 2011","","IEEE","IEEE Journals & Magazines"
"Network-based learning through particle competition for data clustering","T. C. Silva; L. Zhao","Department of Computer Sciences, Institute of Mathematics and Computer Science (ICMC), University of S&#x00E3;o Paulo (USP), Av. Trabalhador S&#x00E3;o-carlense, 400, 13560-970, S&#x00E3;o Carlos, SP, Brazil","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","45","52","Complex network provides a general scheme for machine learning. In this paper, we propose a competitive learning mechanism realized on large scale networks, where several particles walk in the network and compete with each other to occupy as many nodes as possible. Each particle can perform a random walk by choosing any neighbor to visit, a deterministic walk by choosing to visit the node with the highest domination, or a combination of them. A computational complexity analysis is developed of the proposed algorithm. Computer simulations performed on several real-world data sets, including a large scale data set, reveal attractive results when the model is applied for data clustering problems.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033198","","Algorithm design and analysis;Analytical models;Computational complexity;Computational modeling;Machine learning;Mathematical model;Neural networks","complex networks;computational complexity;deterministic algorithms;learning (artificial intelligence);pattern clustering;random processes","competitive learning mechanism;complex network;computational complexity analysis;computer simulation;data clustering;deterministic walk;large scale networks;machine learning;network based learning;particle competition;random walk;real-world data sets","","0","","18","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"ECOGEM: A European Framework-7 Project","J. Jiang; J. Charles; K. Demestichas","A consulting professor at Chinese Academy of Sciences and Southwest University, China.","IEEE Vehicular Technology Magazine","20110825","2011","6","3","22","26","In this article, we describe a new European Framework 7-funded research project, EcoGem, and introduce a new concept of experience sharing and intelligent optimization of route planning via machine-learning approaches. EcoGem combines machine-learning techniques with communication technologies to produce an advanced driver assistance system (ADAS), which has a range of novel functionalities, including: 1) automatic generation of code-based traffic indication to allow other EcoGem-enabled fully electric vehicles (FEVs) to share the experience for every section of route (journey) traveled, 2) automatic learning from the past and online experience to intelligently optimize route planning and energy consumption, and 3) automatic and instant update of the route planning and optimisation process via ongoing experience shared by EcoGem-eneabled FEVs.","1556-6072;15566072","","10.1109/MVT.2011.941900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6004768","","Artificial intelligence;Machine learning;Optimization;Product development;Research and development","driver information systems;electric vehicles;learning (artificial intelligence);optimisation;power engineering computing","EcoGem-enabled fully electric vehicles;EcoGem-eneabled FEV;European framework-7 project;advanced driver assistance system;code-based traffic indication;communication technology;energy consumption;machine-learning techniques;route planning intelligent optimization","","5","","14","","","Sept. 2011","","IEEE","IEEE Journals & Magazines"
"HOG and color based adaboost pedestrian detection","Q. Liu; Y. Qu","Sch. of Autom., Wuhan Univ. of Technol., Wuhan, China","2011 Seventh International Conference on Natural Computation","20110919","2011","1","","584","587","Pedestrian detection is one of the most important research areas in intelligent video surveillance. How to detect the pedestrian fast and accurately is the main target. This research is based on the feature extraction method proposed in paper. aiming at its defect in speed, we introduce the boosted cascade method to train the classifier, realize the Gentle Adaboost using linear SVM. We only need 3 hours to finish the training procedure, this method not only improves the detection accuracy, it also boosts the detection speed greatly. Our test on INRIA shows the effectiveness of the method.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022084","boosted cascade;gentle adaboost;pedestrian detection","Boosting;Classification algorithms;Educational institutions;Feature extraction;Machine learning algorithms;Support vector machines;Training","feature extraction;object detection;pattern classification;support vector machines;traffic engineering computing;video surveillance","HOG;boosted cascade method;classifier;color based Adaboost pedestrian detection;feature extraction;gentle Adaboost;intelligent video surveillance;linear SVM","","1","","5","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Deep Learning Regularized Fisher Mappings","W. K. Wong; M. Sun","Institute of Textiles and Clothing, Hong Kong Polytechnic University, Kowloon, Hong Kong","IEEE Transactions on Neural Networks","20111003","2011","22","10","1668","1675","For classification tasks, it is always desirable to extract features that are most effective for preserving class separability. In this brief, we propose a new feature extraction method called regularized deep Fisher mapping (RDFM), which learns an explicit mapping from the sample space to the feature space using a deep neural network to enhance the separability of features according to the Fisher criterion. Compared to kernel methods, the deep neural network is a deep and nonlocal learning architecture, and therefore exhibits more powerful ability to learn the nature of highly variable datasets from fewer samples. To eliminate the side effects of overfitting brought about by the large capacity of powerful learners, regularizers are applied in the learning procedure of RDFM. RDFM is evaluated in various types of datasets, and the results reveal that it is necessary to apply unsupervised regularization in the fine-tuning phase of deep learning. Thus, for very flexible models, the optimal Fisher feature extractor may be a balance between discriminative ability and descriptive ability.","1045-9227;10459227","","10.1109/TNN.2011.2162429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5982410","Deep learning architecture;Fisher criterion;feature extraction;regularization","Computer architecture;Feature extraction;Kernel;Learning systems;Machine learning;Neurons;Training","feature extraction;image classification;neural nets;unsupervised learning","Fisher criterion;RDFM;class separability;classification tasks;deep neural network;descriptive ability;discriminative ability;feature space;fine tuning phase;nonlocal learning architecture;optimal Fisher feature extractor;regularized deep Fisher mapping;unsupervised regularization","Algorithms;Artificial Intelligence;Humans;Neural Networks (Computer);Pattern Recognition, Automated;Software;Software Design","12","","37","","20110811","Oct. 2011","","IEEE","IEEE Journals & Magazines"
"The vulnerabilities and status of CAPTCHAs","F. Guo; Y. Li; M. Wang; H. Yan","College of Computer and Communication Engineering, Zhengzhou University of Light Industry, Zhengzhou, China","2011 IEEE 3rd International Conference on Communication Software and Networks","20110908","2011","","","448","452","This project's purpose is to give some ideas of Completely Automated Turing Test to Tell Computers and Humans Apart(CAPTCHA), an automatically Turing test which tell human and machine apart, vulnerabilities and its state of the art. As you know, CAPTCHAs are popular in network security area and has been lasting for nearly ten years. However, more and more schemes are suffering successful attacks. Evan Google and Microsoft products cannot slip through those annoying things. The situation of CAPTCHAs seems to be worse and worse. People worry about that and some of them have beginning to believe CAPTCHAs are not as useful as they were stated. Of course, the alternatives of CAPTCHAs are tirelessly emerged one by one. I am also not sure where will CAPTCHAs go tomorrow, but at least as the beginning stated CAPTCHAs are based on hardness AI problems. So, there are still a lot of those kinds of problems can be used and this ""arm race"" will continue for a long time. Furthermore, we should remember that, the basic idea of CAPTCHAs is tell human and machine apart. So, either the new CAPTCHAs or those alternatives should be created from this basic idea.","","Electronic:978-1-61284-486-2; POD:978-1-61284-485-5","10.1109/ICCSN.2011.6014761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6014761","Completely Automated Turing Test to Tell Computers and Humans Apart;automatically Turing test;network security;schemes","Cryptography;Decoding;Dictionaries;Machine learning","Turing machines;artificial intelligence;computer network security;search engines","CAPTCHA;Evan Google;Microsoft products;automatically Turing test;completely automated turing test to tell computers and humans apart;hardness AI problems;network security area;vulnerability","","0","","14","","","27-29 May 2011","","IEEE","IEEE Conference Publications"
"Regression Reformulations of LLE and LTSA With Locally Linear Transformation","S. Xiang; F. Nie; C. Pan; C. Zhang","Nat. Lab. of Pattern Recognition, Chinese Acad. of Sci., Beijing, China","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20110915","2011","41","5","1250","1262","Locally linear embedding (LLE) and local tangent space alignment (LTSA) are two fundamental algorithms in manifold learning. Both LLE and LTSA employ linear methods to achieve their goals but with different motivations and formulations. LLE is developed by locally linear reconstructions in both high- and low-dimensional spaces, while LTSA is developed with the combinations of tangent space projections and locally linear alignments. This paper gives the regression reformulations of the LLE and LTSA algorithms in terms of locally linear transformations. The reformulations can help us to bridge them together, with which both of them can be addressed into a unified framework. Under this framework, the connections and differences between LLE and LTSA are explained. Illuminated by the connections and differences, an improved LLE algorithm is presented in this paper. Our algorithm learns the manifold in way of LLE but can significantly improve the performance. Experiments are conducted to illustrate this fact.","1083-4419;10834419","","10.1109/TSMCB.2011.2123886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740992","Improved locally linear embedding (LLE) (ILLE);LLE;local tangent space alignment (LTSA);regression reformulation","Algorithm design and analysis;Learning;Linear regression;Machine learning","learning (artificial intelligence);regression analysis","LLE;LTSA;linear reconstructions;local tangent space alignment;locally linear alignments;locally linear embedding;locally linear transformation;manifold learning;regression reformulation;tangent space projections","","18","","65","","20110405","Oct. 2011","","IEEE","IEEE Journals & Magazines"
"Incremental Learning of Concept Drift in Nonstationary Environments","R. Elwell; R. Polikar","Signal Processing & Pattern Recognition Laboratory, Electrical & Computer Engineering Department, Rowan University, Glassboro, NJ, USA","IEEE Transactions on Neural Networks","20111003","2011","22","10","1517","1531","We introduce an ensemble of classifiers-based approach for incremental learning of concept drift, characterized by nonstationary environments (NSEs), where the underlying data distributions change over time. The proposed algorithm, named Learn<sup>++</sup>.NSE, learns from consecutive batches of data without making any assumptions on the nature or rate of drift; it can learn from such environments that experience constant or variable rate of drift, addition or deletion of concept classes, as well as cyclical drift. The algorithm learns incrementally, as other members of the Learn<sup>++</sup> family of algorithms, that is, without requiring access to previously seen data. Learn<sup>++</sup>.NSE trains one new classifier for each batch of data it receives, and combines these classifiers using a dynamically weighted majority voting. The novelty of the approach is in determining the voting weights, based on each classifier's time-adjusted accuracy on current and past environments. This approach allows the algorithm to recognize, and act accordingly, to the changes in underlying data distributions, as well as to a possible reoccurrence of an earlier distribution. We evaluate the algorithm on several synthetic datasets designed to simulate a variety of nonstationary environments, as well as a real-world weather prediction dataset. Comparisons with several other approaches are also included. Results indicate that Learn<sup>++</sup>.NSE can track the changing environments very closely, regardless of the type of concept drift. To allow future use, comparison and benchmarking by interested researchers, we also release our data used in this paper.","1045-9227;10459227","","10.1109/TNN.2011.2160459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975223","Concept drift;incremental learning;learning in nonstationary environments;multiple classifier systems","Algorithm design and analysis;Heuristic algorithms;Humans;Knowledge based systems;Machine learning;Training;Tuning","learning (artificial intelligence);pattern classification","Learn<sup>++</sup>.NSE algorithm;classifier-based approach;concept drift learning;dynamically weighted majority voting;incremental learning;nonstationary environment characteristics","Algorithms;Artificial Intelligence;Automatic Data Processing;Environment;Humans;Learning;Models, Neurological;Neural Networks (Computer);Nonlinear Dynamics","141","1","63","","20110804","Oct. 2011","","IEEE","IEEE Journals & Magazines"
"A feature selection technique based on equivalent relation","Meng Wang; Shudong Sun; Ganggang Niu; Yuanzhi Tu; Shihui Guo","Institute of System Integration and Engineering Management, Northwestern Polytechnical University, Xi'an, China","2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)","20110905","2011","","","911","914","Traditional feature selection for classification can only treat with decision tables. The paper proposes a feature selection technique based on equivalent relation, which works well for both decision tables and information systems. The approach can compute the significance attribute from a database. The measure also takes into account the attribute support degree in decision tables. The experiment results confirm that the performance of the approach is efficient.","","Electronic:978-1-4577-0536-6; POD:978-1-4577-0535-9","10.1109/AIMSEC.2011.6010707","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6010707","attribute significance;equivalent relation;feature selection;information system","Accuracy;Classification algorithms;Information systems;Machine learning;Pain;Pattern recognition;Search methods","decision tables;feature extraction;pattern classification","decision tables;equivalent relation;feature classification;feature selection technique;information systems","","0","","14","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"A Fuzzy K-modes-based Algorithm for Soft Subspace Clustering","T. Ji; X. Bao; Y. Wang; D. Yang","Sch. of Electron. Eng. &amp; Comput. Sci., Peking Univ., Beijing, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1080","1084","This paper proposes a Fuzzy K-modes-based Algorithm for Soft Subspace Clustering, which adopts some fuzzy techniques for subspace clustering on mixed features. In order to obtain better clustering result, the proposed algorithm focuses on not only the intra-similarity of clusters, but also the optimization of the subspace where the cluster is situated. Experimental results show that the proposed FKSSC algorithm is efficient and effective in clustering both categorical and numeral data sets in high dimensional space.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019625","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019625","Fuzzy techniques;High-dimensional data;Mixed features;Soft Subspace Clustering","Clustering algorithms;Machine learning algorithms;Optimization;Power capacitors;Runtime;Size measurement","fuzzy set theory;optimisation;pattern clustering","FKSSC algorithm;categorical data sets;cluster intrasimilarity;fuzzy k-mode based algorithm;numeral data sets;soft subspace clustering;subspace optimization","","0","","20","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Autonomous Shaping by High Density Visited States","J. Song; Z. Jin","Yunnan Jiao Tong Vocational & Tech. Coll., Kunming, China","2011 International Conference on Internet Technology and Applications","20110829","2011","","","1","4","Shaping is an effective method to reduce the state space that agent has to explore. But the shaping signal usually is provided by external observer, which requires lots of efforts, and weakens agent's autonomy. We propose an approach to make agent can autonomously shape itself by high density visited states. By gathering state trajectories that agent passed in training episodes, and eliminating the state loops in these state trajectories, then agent can find the high density visited states from these acyclic state trajectories. A high density visited state means agent has high frequency to pass it when agent wants to achieve the goal. So the high density visited state can be used to shape agent's exploration and make it reaching the goal faster. The experiment results on the Maze problem illustrated our approach being very effective. The major contribution is we make agent can autonomously shape itself by its experience.","","Electronic:978-1-4244-7255-0; POD:978-1-4244-7253-6","10.1109/ITAP.2011.6006109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6006109","","Indexes;Learning;Machine learning;Observers;Shape;Training;Trajectory","learning (artificial intelligence)","acyclic state trajectories;agent exploration;autonomous shaping;external observer;high density visited states;maze problem","","0","","10","","","16-18 Aug. 2011","","IEEE","IEEE Conference Publications"
"Tennis computer game with brain control using EEG signals","E. Lopetegui; B. G. Zapirain; A. Mendez","Deusto Institute of Technology. Deustotech - LIFE Unit. University of Deusto, Avda/Universidades 24. 48007. Bilbao. Spain","2011 16th International Conference on Computer Games (CGAMES)","20110825","2011","","","228","234","This paper presents a game designed to improve the quality of life of people with severe disabilities for using a computer mouse or keyboard. The game has been designed using biofeedback and BCI technology included in a machine learning algorithm and integrated into a game interface using the SDL library. The results have been entirely satisfactory because the success rate in trained patients is over the 80% and the game has been qualified by them as friendly. Next step will be to develop the graphics in 3D instead of 2D. The social benefits of this type of application can affect diseases involving movement difficulties for controlling keyboard and mouse of a computer, or even rare diseases like congenital double athetosis.","","Electronic:978-1-4577-1452-8; POD:978-1-4577-1451-1","10.1109/CGAMES.2011.6000344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6000344","BCI Technology;EEG;communication problems;serious game","Biological control systems;Computers;Digital filters;Electroencephalography;Games;Low pass filters;Machine learning algorithms","brain-computer interfaces;computer games;computer graphics;diseases;electroencephalography;keyboards;learning (artificial intelligence);medical signal processing;mouse controllers (computers);specification languages;sport","3D graphics;BCI technology;EEG signals;SDL library;biofeedback;brain control;computer keyboard;computer mouse;congenital double athetosis;disabilities;diseases;game interface;machine learning;movement difficulties;patients;social benefits;tennis computer game","","5","","19","","","27-30 July 2011","","IEEE","IEEE Conference Publications"
"Speeding up local and global learning of M<sup>4</sup>","Z. Zhang; X. Luo; S. Wang","Sch. of Digital Media, Jiangnan Univ., Wuxi, China","2011 Seventh International Conference on Natural Computation","20110919","2011","1","","383","387","We construct a novel large margin classifier called the Collaborative Classification Machine with Local and Global Information (C<sup>2</sup>M) for speeding up the recently proposed Maxi-Min Margin Machine (M<sup>4</sup>). We divide the whole global data used in M<sup>4</sup> into two independent models, and the final decision boundary is obtained by collaboratively combining the two hyperplanes learned from the two independent models. The proposed C<sup>2</sup>M model can be individually solved as a Quadratic Programming (QP) problem. The total training time complexity is O(2N<sup>3</sup>) which is faster than O(N<sup>4</sup>) of M<sup>4</sup>. We describe the definition of the C<sup>2</sup>M model, provide the geometrical interpretation and present theoretical justifications. Experiments on toy and real-world data sets demonstrate that the C<sup>2</sup>M is more robust and time saving than M<sup>4</sup> as a local and global classification machine.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022045","Classification;Support Vector Machine;collaborative learning;local and global learning","Accuracy;Collaboration;Machine learning;Optimization;Robustness;Support vector machines;Training","computational complexity;learning (artificial intelligence);minimax techniques;pattern classification;quadratic programming","C<sup>2</sup>M model;QP problem;collaborative classification machine;decision boundary;geometrical interpretation;global information;global learning;large margin classifier;local information;local learning;maxi-min margin machine;quadratic programming;time complexity","","0","","13","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Hybrid Systems in Robotics","J. Ding; J. H. Gillula; H. Huang; M. P. Vitus; W. Zhang; C. J. Tomlin","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA 94720-1770, USA.","IEEE Robotics & Automation Magazine","20110912","2011","18","3","33","43","Robotics has provided the motivation and inspiration for many innovations in planning and control. From nonholonomic motion planning [1] to probabilistic road maps [2], from capture basins [3] to preimages [4] of obstacles to avoid, and from geometric nonlinear control [5], [6] to machine-learning methods in robotic control [7], there is a wide range of planning and control algorithms and methodologies that can be traced back to a perceived need or anticipated benefit in autonomous or semiautonomous systems.","1070-9932;10709932","","10.1109/MRA.2011.942113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016585","","Hybrid intelligent systems;Machine learning;Motion planning;Robot control","collision avoidance;mobile robots","capture basins;geometric nonlinear control;hybrid systems;machine-learning methods;nonholonomic motion planning;obstacle avoidance;probabilistic road maps;robotic control;semiautonomous systems","","9","","41","","","Sept. 2011","","IEEE","IEEE Journals & Magazines"
"Question classification using MultiBoost","L. Su; Z. Yu; J. Guo; C. Mao; Y. Liao","Sch. of Inf. Eng. &amp; Autom., Kunming Univ. of Sci. &amp; Technol., Kunming, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1831","1835","In this paper, a new method for question classification is proposed, which employs ensemble learning algorithms MultiBoost to train multiple question classifiers. These component learners are combined to produce the final hypothesis. In detail, the feature spaces are obtained through extracting high-frequency keywords from questions corpus and the method of word semantic similarity is performed to adjust the feature weights. Then, the question classifiers are trained from this vector space. The ensemble method, MultiBoost, is applied to construct an ensemble of classifiers to tackle the problem of question classification. Experiments on the Chinese question system of tourism domain show that the ensemble methods could effectively improve the classification accuracy.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019826","Ensemble learning;MultiBoost;Question classification;Word semantic similarity","Accuracy;Bagging;Classification algorithms;Feature extraction;Machine learning;Semantics;Training","learning (artificial intelligence);pattern classification;question answering (information retrieval);text analysis;travel industry;word processing","Chinese question system;MultiBoost;ensemble learning algorithm;feature spaces;feature weights;high-frequency keyword extraction;question classification;question corpus;tourism domain;word semantic similarity","","0","","14","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A Fast Learning Complex-valued Neural Classifier for real-valued classification problems","R. Savitha; S. Suresh; N. Sundararajan","School of Computer Engineering, Nanyang Technological University, Singapore","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","2243","2249","This paper presents a fast learning fully complex-valued classifier to solve real-valued classification problems, called the `Fast Learning Complex-valued Neural Classifier' (FLCNC). The FLCNC is a single hidden layer network with a non-linear, real to complex transformed input layer, a hidden layer with a fully complex activation function and a linear output layer. The neurons in the input layer convert the real-valued input features to the Complex domain using an unique non-linear transformation. At the hidden layer, the complex-valued transformed input features are mapped onto a higher dimensional Complex plane using a fully complex-valued activation function of the type of `sech'. The parameters of the input and hidden neurons of the FLCNC are chosen randomly and the output parameters are estimated analytically which makes the FLCNC to perform fast classification. Moreover, the unique nonlinear input transformation and the orthogonal decision boundaries of the complex-valued neural network help the FLCNC to perform accurate classification. Performance of the FLCNC is demonstrated using a set of multi-category and binary real valued classification problems with both balanced and unbalanced data sets from the UCI machine learning repository. Performance comparison with existing complex-valued and real-valued classifiers show the superior classification performance of the FLCNC.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033508","","Accuracy;Benchmark testing;Biological neural networks;Machine learning;Neurons;Support vector machines;Training","learning (artificial intelligence);neural nets;parameter estimation;pattern classification","FLCNC;UCI machine learning repository;artificial neural networks;complex plane;fast learning complex-valued neural classifier;fast learning fully complex-valued classifier;fully complex activation function;nonlinear input transformation;orthogonal decision boundaries;output parameter estimation;real-valued classification problems;sech;unbalanced data sets","","14","","28","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Probability adjustment Naïve Bayes algorithm based on nondomain-specific sentiment and evaluation word for domain-transfer sentiment analysis","W. Fan; S. Sun; G. Song","Sch. of Comput. Sci., Commun. Univ. of China, Beijing, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1043","1046","In the research of sentiment analysis, some supervised learning algorithms play an important role. Among them, Naïve Bayes is often used in engineering application due to its low computational and space complexity. While traditional Naïve Bayes algorithm has been shown to perform very well in domain-specific sentiment classification, it often performs badly in domain-transfer problem. So we propose a probability adjust Naïve Bayes algorithm (PANB) to solve this problem. We use polarity D-value PointWise Mutual Information (PDPMI) method to obtain nondomain-specific words and their weight score, and then use the weight score to adjust probability of feature in training step. The result of experiment shows that our approach usually achieves better performance than traditional Naïve Bayes classifier.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019717","PANB;PDPMI;domain-transfer;sentiment analysis;sentiment and evaluation word","Algorithm design and analysis;Classification algorithms;Educational institutions;Machine learning;Mutual information;Quality control;Training","Bayes methods;Internet;computational complexity;learning (artificial intelligence)","PANB;PDPMI;World Wide Web;computational complexity;domain transfer sentiment analysis;nondomain specific sentiment;polarity D-value pointwise mutual information;probability adjustment Naïve Bayes algorithm;space complexity;supervised learning algorithms;word evaluation","","0","","10","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Intelligent email summarisation system (IESS)","T. Ayodele; S. Zhou; R. Khusainov","Dept. of Electron. &amp; Comput. Eng., Univ. of Portsmouth, Portsmouth, UK","2010 International Conference on Information Society","20110915","2010","","","330","335","Many email users, especially business men, managers and academician receive many email messages that require sorting out within a short period of time. While most mail summarisation applications allow dialogue structure of emails, users to summarise messages into percentages or numbers of sentences. In practice this task tends to be tedious and solutions available today often require programming skills on the part of the email users. The users define rules for summarising messages. For each message, the user must first decide which message is most important. Then, the user must inform the mail summariser of that choice by selecting the appropriate icon or menu item from among what is typically a set of several dozen choices. The combined effort of choosing a message and conveying that choice to the application often discourages users from summarising their mails, resulting in unmanageable inboxes that contain hundreds or even thousands of un-précised and unnecessary messages. Intelligent email summarisation system (IESS), encourages users to have summative messages by simplifying the content of the mail. Using unsupervised machine learning techniques in combination with automated word and phrases modeller to intelligently provide a précis summary of each email messages is developed to reduce the burden of email users.","","Electronic:978-0-9564263-3-8; POD:978-1-4577-1823-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6018724","","Electronic mail;Feature extraction;Humans;Machine learning;Postal services","electronic mail;electronic messaging;interactive systems;text analysis;unsupervised learning","academician;automated word-phrases;business men;dialogue structure;intelligent email summarisation system;mail summariser;programming skills;unsupervised machine learning techniques","","0","","8","","","28-30 June 2010","","IEEE","IEEE Conference Publications"
"CN2-R: Faster CN2 with randomly generated complexes","J. Zuters","Fac. of Comput., Univ. of Latvia, Riga, Latvia","2011 16th International Conference on Methods & Models in Automation & Robotics","20110929","2011","","","306","309","Among the rule induction algorithms, the classic CN2 is still one of the most popular ones; a great amount of enhancements and improvements to it is to witness this. Despite the growing computing capacities since the algorithm was proposed, one of the main issues is resource demand. The proposed modification, CN2-R, substitutes the star concept of the original algorithm with a technique of randomly generated complexes in order to substantially improve on running times without significant loss in accuracy.","","Electronic:978-1-4577-0914-2; POD:978-1-4577-0912-8","10.1109/MMAR.2011.6031363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031363","","Accuracy;Algorithm design and analysis;Classification algorithms;Complexity theory;Iris;Machine learning;Machine learning algorithms","knowledge based systems;learning (artificial intelligence)","CN2-R;faster CN2;randomly generated complex;resource demand;rule induction algorithm","","0","","6","","","22-25 Aug. 2011","","IEEE","IEEE Conference Publications"
"Effect of the learning algorithm on the accuracy of sub-pixel land use classifications with multilayer perceptrons","S. Heremans; J. Van Orshoven","Katholieke Universiteit Leuven, Department of Earth and Environmental Sciences, Celestijnenlaan 200E, 3001-Leuven, Belgium","2011 6th International Workshop on the Analysis of Multi-temporal Remote Sensing Images (Multi-Temp)","20110829","2011","","","193","196","Timely and accurate information on the location and the extent of land use types is high up the agenda of several governmental and scientific organizations. Remote sensing, through image classification at the sub-pixel level, is an attractive source of this type of information. The remote sensing community has recognized the multilayer perceptron (MLP) as a popular machine learning technique for performing land use classifications, both at the pixel and at the sub-pixel level. However, theoretical advances in the machine learning community are not easily adopted by the classification practice. An example is the continued use of the gradient descent algorithm for MLP training. In this paper, the accuracy of this standard first order learning algorithm was compared to that of five alternative, second order learning algorithms for performing a sub-pixel classification of land use in Flanders. The result are clear: all second order algorithms perform markedly better than gradient descent, thereby illustrating the importance of translating theoretical advances in MLP training to the classification practice.","","Electronic:978-1-4577-1203-6; POD:978-1-4577-1202-9","10.1109/Multi-Temp.2011.6005081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005081","Multilayer perceptron;learning algorithm;sub-pixel land use classification","Accuracy;Agriculture;Classification algorithms;Machine learning;Machine learning algorithms;Remote sensing;Training","geophysical image processing;image classification;learning (artificial intelligence);multilayer perceptrons;terrain mapping","Belgium;Flanders;first order learning algorithm;gradient descent algorithm;image classification;machine learning community;machine learning technique;multilayer perceptron analysis;remote sensing community;second all order learning algorithm;subpixel land use classification","","0","","22","","","12-14 July 2011","","IEEE","IEEE Conference Publications"
"Towards Training Set Reduction for Bug Triage","W. Zou; Y. Hu; J. Xuan; H. Jiang","Sch. of Software, Dalian Univ. of Technol., Dalian, China","2011 IEEE 35th Annual Computer Software and Applications Conference","20111003","2011","","","576","581","Bug triage is an important step in the process of bug fixing. The goal of bug triage is to assign a new-coming bug to the correct potential developer. The existing bug triage approaches are based on machine learning algorithms, which build classifiers from the training sets of bug reports. In practice, these approaches suffer from the large-scale and low-quality training sets. In this paper, we propose the training set reduction with both feature selection and instance selection techniques for bug triage. We combine feature selection with instance selection to improve the accuracy of bug triage. The feature selection algorithm X<sup>2</sup>-test, instance selection algorithm Iterative Case Filter, and their combinations are studied in this paper. We evaluate the training set reduction on the bug data of Eclipse. For the training set, 70% words and 50% bug reports are removed after the training set reduction. The experimental results show that the new and small training sets can provide better accuracy than the original one.","0730-3157;07303157","Electronic:978-0-7695-4439-7; POD:978-1-4577-0544-1","10.1109/COMPSAC.2011.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032400","bug triage;feature selection;instance selection;software quality;training set reduction","Accuracy;Computer bugs;Educational institutions;Machine learning algorithms;Software;Text categorization;Training","iterative methods;program debugging;software maintenance","bug data;bug fixing;bug triage;feature selection algorithm;instance selection algorithm;iterative case filter;training set reduction","","7","","17","","","18-22 July 2011","","IEEE","IEEE Conference Publications"
"Multi-task beta process sparse kernel machines","J. Gao","School of Computing and Mathematics, Charles Sturt University, Bathurst, NSW 2795, Australia","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","153","158","In this paper we propose a nonparametric extension to the sparse kernel machine using a beta process prior. The extended beta process sparse kernel machine (BPSKM) allows for a sparse model to be constructed from a set of training data. The recent research on beta process reveals elegant property of Bayesian conjugate prior which is utilized to derive a variational Bayes inference algorithm. The performance of the proposed algorithm has been investigated on both synthetic and real-life data sets.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033214","","Bayesian methods;Data models;Kernel;Machine learning;Sparse matrices;Training;Training data","Bayes methods;inference mechanisms;learning (artificial intelligence);multiprogramming;sparse matrices","Bayesian conjugate prior;multitask beta process sparse kernel machine;nonparametric extension;real-life data set;variational Bayes inference algorithm","","0","","23","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"A fast exact k-nearest neighbors algorithm for high dimensional search using k-means clustering and triangle inequality","X. Wang","Department of Mathematics and Computer Science, Northwest Nazarene University, Nampa, ID 83642 USA","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","1293","1299","The k-nearest neighbors (k-NN) algorithm is a widely used machine learning method that finds nearest neighbors of a test object in a feature space. We present a new exact k-NN algorithm called kMkNN (k-Means for k-Nearest Neighbors) that uses the k-means clustering and the triangle inequality to accelerate the searching for nearest neighbors in a high dimensional space. The kMkNN algorithm has two stages. In the buildup stage, instead of using complex tree structures such as metric trees, kd-trees, or ball-tree, kMkNN uses a simple k-means clustering method to preprocess the training dataset. In the searching stage, given a query object, kMkNN finds nearest training objects starting from the nearest cluster to the query object and uses the triangle inequality to reduce the distance calculations. Experiments show that the performance of kMkNN is surprisingly good compared to the traditional k-NN algorithm and tree-based k-NN algorithms such as kd-trees and ball-trees. On a collection of 20 datasets with up to 10<sup>6</sup> records and 10<sup>4</sup> dimensions, kMkNN shows a 2- to 80-fold reduction of distance calculations and a 2- to 60-fold speedup over the traditional k-NN algorithm for 16 datasets. Furthermore, kMkNN performs significant better than a kd-tree based k-NN algorithm for all datasets and performs better than a ball-tree based k-NN algorithm for most datasets. The results show that kMkNN is effective for searching nearest neighbors in high dimensional spaces.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033373","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033373","","Acceleration;Algorithm design and analysis;Classification algorithms;Clustering algorithms;Machine learning algorithms;Search problems;Training","learning (artificial intelligence);pattern clustering;trees (mathematics)","ball-tree;complex tree structures;exact k-NN algorithm;exact k-nearest neighbors algorithm;feature space;high dimensional search;k-means clustering method;k-means for k-nearest neighbors;kd-trees;machine learning method;metric trees;tree-based k-NN algorithms;triangle inequality","","6","","24","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Uncertainty sampling methods for selecting datasets in active meta-learning","R. B. C. Prudêncio; C. Soares; T. B. Ludermir","Center of Informatics, Federal University of Pernambuco, Cidade Universit&#x00E1;ria - CEP 50732-970 - Recife (PE) - Brazil","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","1082","1089","Several meta-learning approaches have been developed for the problem of algorithm selection. In this context, it is of central importance to collect a sufficient number of datasets to be used as meta-examples in order to provide reliable results. Recently, some proposals to generate datasets have addressed this issue with successful results. These proposals include datasetoids, which is a simple manipulation method to obtain new datasets from existing ones. However, the increase in the number of datasets raises another issue: in order to generate meta-examples for training, it is necessary to estimate the performance of the algorithms on the datasets. This typically requires running all candidate algorithms on all datasets, which is computationally very expensive. In a recent paper, active meta-learning has been used to address this problem. An uncertainty sampling method for the k-NN algorithm using a least confidence score based on a distance measure was employed. Here we extend that work, namely by investigating three hypotheses: 1) is there advantage in using a frequency-based least confidence score over the distance-based score? 2) given that the meta-learning problem used has three classes, is it better to use a margin-based score? and 3) given that datasetoids are expected to contain some noise, are better results achieved by starting the search with all datasets already labeled? Some of the results obtained are unexpected and should be further analyzed. However, they confirm that active meta-learning can significantly reduce the computational cost of meta-learning with potential gains in accuracy.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033343","","Computational efficiency;Entropy;Machine learning;Machine learning algorithms;Sampling methods;Training;Uncertainty","data analysis;learning (artificial intelligence);sampling methods","active meta-learning;algorithm selection problem;dataset selection;datasetoids;distance measure;frequency-based least confidence score;k-NN algorithm;margin-based score;uncertainty sampling method","","2","","18","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Convergence of coefficient regularized fully online algorithm","Ming-Dang Tian; Bao-Huai Sheng","Department of Mathematics, Shaoxing University, Zhejiang, CHINA","2011 International Conference on Multimedia Technology","20110825","2011","","","2059","2065","Abstract-This paper gives the convergence of coefficient regularized fully online nonsmooth classification algorithm. With the strongly convex loss function based on the Euclidean Space and the parameter λ<sub>t</sub> changes with learning step give a better convergence rate than the usual convex loss functions.","","Electronic:978-1-61284-774-0; POD:978-1-61284-771-9","10.1109/ICMT.2011.6002468","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6002468","binary classification;convergence analysis;learning rates;online algorithm","Approximation algorithms;Classification algorithms;Convergence;Equations;Hilbert space;Kernel;Machine learning algorithms","convex programming;learning (artificial intelligence);pattern classification","Euclidean Space;coefficient regularized fully online algorithm convergence;convex loss function;machine learning method;nonsmooth classification algorithm","","0","","8","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"A new feature selection method based on clustering","H. Liu; Y. Mo; J. Wang; J. Zhao","Dept. of Comput. Sci., Zhejiang Normal Univ., Jinhua, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","965","969","Feature selection is an effective technique to put the high dimension of data down, which is prevailing in many application domains, such as text categorization and bio-informatics, and can bring many advantages, such as improving efficiency and avoiding over-fitting, to learning algorithms. Currently, many efforts have been attempted in this field and various feature selection methods have been developed and proved to be very competitive. Unlike other selection methods, in this paper we propose a new method to select important features using a manner of feature clustering. The main character of our method is that it works like data clustering in an agglomerative way. In this method, each feature is considered as a data point clustered with between-cluster and within-cluster distances. As a result, the selected feature subset has minimal redundancy among its members and maximal relevance with the class labels. Our performance evaluations on seven benchmark datasets show that the classification performance achieved by our proposed method is better than other feature selection methods.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019687","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019687","","Accuracy;Clustering algorithms;Machine learning;Measurement;Mutual information;Pattern recognition;Redundancy","learning (artificial intelligence);pattern classification;pattern clustering","between-cluster distance;bioinformatics;data clustering;feature clustering;feature selection method;learning algorithms;text categorization;within-cluster distances","","1","","23","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Concept based modeling approach for blog classification using fuzzy similarity","R. K. Ayyasamy; B. Tahayna; S. M. Alhashmi; S. Eu-Gene","Sch. of Inf. Technol., Monash Univ., Bandar Sunway, Malaysia","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","2","","1007","1011","As information technology is developing in a faster pace, there is a steep increase in social networking where the user can share their knowledge, views, criticism through various ways such as blogging, facebook, microblogging, news, forums, etc. Among these various ways, blogs play a different role as it is a personal site for each user, and blogger writes lengthy posts on various topics. Several research works are carried out, to classify blogs based on machine learning techniques. In this paper, we describe a method for classifying blog posts automatically using fuzzy similarity. We perform, experiments using TREC dataset and applied our approach to six different fuzzy similarity measures. Experimental results proved that Einstein fuzzy similarity measures performs better than the other measures.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019754","blog classification;fuzzy similarity;wikipedia","Blogs;Electronic publishing;Encyclopedias;Internet;Machine learning;Text categorization","Internet;fuzzy reasoning;learning (artificial intelligence);pattern classification;social networking (online)","Einstein fuzzy similarity;TREC dataset;blog classification;concept based modeling approach;fuzzy similarity;machine learning techniques;social networking","","0","","24","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
