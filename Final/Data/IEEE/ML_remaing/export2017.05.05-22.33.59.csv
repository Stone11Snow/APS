"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7520452,7520541,7470553,7519735,7520547,7515969,7518347,7516081,7515884,7516235,7516046,7518453,7515919,7518289,7514414,7518283,7448943,7517319,7513866,7514619,7514608,7514941,7510964,7510732,7510831,7509796,7508798,7508071,7507155,7502343,7508131,7506659,7507143,7506732,7507375,7477319,7477328,7477477,7477459,7504034,7506134,7452659,7503401,7503289,7502793,7502944,7501699,7500237,7169562,7500246,7501926,7501830,7498962,7480758,7479502,7496197,7496053,7495589,7495514,7496193,7495831,7495698,7495970,7496039,7496171,7496072,7496073,7498445,7496046,7495681,7496054,7498518,7496020,7495870,7314894,7493969,7458200,7493964,7495045,7493906,7494226,7493382,7492646,7492647,7491575,7493399,7493362,7492799,7493520,7493240,7492800,7492580,7490132,7490053,7490128,7489548,7486563,7487381,7486355,7485675",2017/05/05 22:33:59
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Multi features combination for automated zooplankton classification","R. Wang; J. Dai; H. Zheng; G. Ji; X. Qiao","College of Information Science and Engineering, Ocean University of China, Qingdao 266100, China","OCEANS 2016 - Shanghai","20160609","2016","","","1","5","Zooplankton are the key components of marine food webs. The abundance of it influences the ocean ecological balance. To efficiently monitor species richness of zooplankton and protect marine environment, marine biologists and computer vision experts started to research automated zooplankton classification system with computer vision technologies. Most current research focuses on achieving high classification accuracy. In this paper, we propose a new system based on multi features combination to enhance the zooplankton classification performance. In our system, the geometric and grayscale features, Local Binary Patterns features, and Inner-distance Shape Context features are extracted as low-level features. According to the properties of machine learning algorithms, an appropriate algorithm is chosen to generate middle-level features by processing all kinds of low-level features. After that, we concatenate middle-level features and apply Support Vector Machine to get the final classifier. By combining different types of features, the system we proposed can capture richer biomorphic information than those with a few features. And the experimental results also show that our system achieves better classification performance.","","Electronic:978-1-4673-9724-7; POD:978-1-4673-9725-4","10.1109/OCEANSAP.2016.7485675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7485675","","Computer vision;Context;Feature extraction;Gray-scale;Machine learning algorithms;Shape;Support vector machines","environmental monitoring (geophysics);feature extraction;geophysical image processing;image classification;learning (artificial intelligence);microorganisms;support vector machines","automated zooplankton classification;biomorphic information;computer vision technology;inner-distance shape context feature extraction;local binary pattern feature feature extraction;machine learning algorithm;marine environment protection;marine food web;multifeatures combination;ocean ecological balance;support vector machine;zooplankton species richness monitoring","","","","10","","","10-13 April 2016","","IEEE","IEEE Conference Publications"
"Deep learning: Architectures, algorithms, applications","R. Memisevic","University of Montreal","2015 IEEE Hot Chips 27 Symposium (HCS)","20160707","2015","","","1","127","This article consists of a collection of slides from the author's conference presentation. Some of the topics covered include: Machine learning 101: Neural nets, backprop, RNNs; Applications; Structured prediction; Unsupervised learning; ""Neural Programs""; Architecture exploration; Towards hardware-friendlier DL; and Software.","","Electronic:978-1-4673-8885-6; POD:978-1-4673-8886-3","10.1109/HOTCHIPS.2015.7477319","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477319","","Artificial neural networks;Learning (artificial intelligence);Machine learning;Recurrent neural networks;Unsupervised learning","neural nets;recurrent neural nets;unsupervised learning","RNN;deep learning algorithms;deep learning applications;deep learning architecture;hardware-friendlier DL;neural programs;unsupervised learning","","","","","","","22-25 Aug. 2015","","IEEE","IEEE Conference Publications"
"Similarity-Based Malware Classification Using Hidden Markov Model","M. Imran; M. T. Afzal; M. A. Qadir","","2015 Fourth International Conference on Cyber Security, Cyber Warfare, and Digital Forensic (CyberSec)","20160616","2015","","","129","134","The problem of malware classification has gained the attention of cyber security community due to the following facts: (1) thousands of new malware are generated every day (2) the global losses caused by malware are in billions of dollars every year. In this paper a novel malware classification scheme is proposed that is based on Hidden Markov Models (HMMs) and discriminative classifiers. Sequences of system calls generated by malware during execution are represented as observation sequences to train the HMMs. Individual malware samples are then evaluated against these models to generate similarity vectors, which are used to predict the class label for an unknown sample by training a discriminative classifier. Our novel combination of HMMs, dynamic program features and discriminative classifier has shown promising results in experiments performed using system call logs of real malware.","","Electronic:978-1-4673-8499-5; POD:978-1-4673-8500-8","10.1109/CyberSec.2015.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7491575","Hidden Markov Model;Malware classification;similarity-based classification","Computer security;Computers;Feature extraction;Hidden Markov models;Machine learning algorithms;Malware;Training","dynamic programming;hidden Markov models;invasive software;pattern classification;vectors","HMM;cyber security community;discriminative classifiers;dynamic program features;hidden Markov model;malware;similarity vectors;similarity-based malware classification;system call logs","","","","27","","","29-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"Cognitive security: securing the burgeoning landscape of mobile networks","Y. Zheng; A. Moini; W. Lou; Y. T. Hou; Y. Kawamoto","Virginia Tech","IEEE Network","20160718","2016","30","4","66","71","The rapid proliferation of personal wearable as well as embedded devices point to the emergence of networks of unprecedented size and complexity in the near future. Unfortunately, traditional network security solutions fall short of addressing the unique security requirements of the emerging environment given their general emphasis on administratively managed, preconfigured security context and strong physical security mechanisms. To cope with the security challenges of this emerging environment, novel cognitive-inspired security architectures have been proposed that emphasize dynamic, autonomous trust management. Cognitive security systems take advantage of sensing and computing capabilities of smart devices to analyze raw sensor data and apply machine learning techniques to make security decisions. In this article, we present a canonical representation of cognitive security architectures and examine the practicality of using these architectures to address the security challenges of rapidly growing networks of mobile/embedded autonomous devices including the ability to identify threats simply based on symptoms, without necessarily understanding attack methods. Using authentication as the main focus, we introduce our canonical representation and define various categories of contextual information commonly used by cognitive security architectures to handle authentication requirements, and highlight key advantages and disadvantages of each category. We then examine three grand challenges facing the cognitive security research including the tension between automation and security, the unintended consequences of using machine learning techniques as a basis for making security decisions, and the revocation problem in the context of cognitive security. We conclude by offering some insight into solution approaches to these challenges.","0890-8044;08908044","","10.1109/MNET.2016.7513866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7513866","","Authentication;Cognitive radio;Learning (artificial intelligence);Machine learning;Mobile communication;Network security;Wireless networks","cognitive radio;learning (artificial intelligence);mobile radio;telecommunication security","autonomous trust management;cognitive security architectures;embedded devices;machine learning techniques;mobile networks;mobile/embedded autonomous devices;network security;personal wearable;sensor data;smart devices","","","","","","","July-August 2016","","IEEE","IEEE Journals & Magazines"
"An In-Depth Context-Awareness Framework for Pervasive Video Cloud","W. Zhang; P. Duan; L. Chen","Dept. of Software Eng., China Univ. of Pet., Qingdao, China","2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)","20160721","2015","","","543","549","We claim that context-awareness for big data should be more in-depth than that of classical one, due to complexities of big data. Intelligent video data processing based on video cloud plays an important role for some applications such as public security and transportation. The existing work on context-awareness can not work properly on pervasive video cloud due to the intrinsic complexities of big video data. Therefore, in this paper we propose an in-depth context-awareness framework for pervasive video cloud in order to know the underlying contexts in big video data, based on deep learning techniques. We have conducted initial evaluations to show the effectiveness of the proposed approach, including the prediction of workload for cloud nodes, and the recognition of targets in the video at real time.","","Electronic:978-1-4673-7211-4; POD:978-1-4673-7212-1","10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518289","","Cloud computing;Context;Feature extraction;Image recognition;Machine learning;Sparks;Vehicles","Big Data;cloud computing;learning (artificial intelligence);object detection;ubiquitous computing;video signal processing","big video data;cloud nodes;context-awareness framework;deep learning techniques;pervasive video cloud;target recognition;workload prediction","","","","","","","10-14 Aug. 2015","","IEEE","IEEE Conference Publications"
"A silicon anti-virus engine","A. Tang; J. Demme; S. Sethumadhavan; S. Stolfo","","2015 IEEE Hot Chips 27 Symposium (HCS)","20160707","2015","","","1","1","This article consists of a single slide from the authors' conference presentation. The topics include: Growing Malware Threats; Limitations of Software Anti-Virus; Catching Seen Malware; and Catching Unseen Malware.","","Electronic:978-1-4673-8885-6; POD:978-1-4673-8886-3","10.1109/HOTCHIPS.2015.7477477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477477","","Feature extraction;Linux;Machine learning;Malware;Spyware;Supervised learning;Trojan horses;Unsupervised learning","computer viruses","malware threats;silicon antivirus engine;software antivirus;unseen malware","","","","","","","22-25 Aug. 2015","","IEEE","IEEE Conference Publications"
"Multi-modality stacked deep polynomial network based feature learning for Alzheimer's disease diagnosis","X. Zheng; J. Shi; Y. Li; X. Liu; Q. Zhang","School of Communication and Information Engineering, Shanghai University","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","851","854","Feature representation is the critical factor for the computer-aided Alzheimer's disease (AD) diagnosis. Deep polynomial network (DPN) is a novel deep learning algorithm, which can effectively learn feature representation from small samples. In this work, a stacked DPN (S-DPN) algorithm is proposed to further improve feature representation. We then propose a multi-modality S-DPN (MM-S-DPN) algorithm to fuse multi-modality neuroimaging data and learn more discriminative and robust feature representation for AD classification. Experiments are performed on ADNI dataset with MRI and PET images as multi-modality data. The results indicate that S-DPN is superior to DPN and stacked auto-encoder algorithms. Moreover, MM-S-DPN achieves best performance compared with single-modality S-DPN and other multi-modality feature learning based algorithms.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493399","Alzheimer's Disease;Deep Learning;Multi-modality Stacked Deep Polynomial Network","Classification algorithms;Diseases;Machine learning;Magnetic resonance imaging;Neuroimaging;Positron emission tomography;Training","","","","1","","12","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Disease Diagnosis Supported by Hierarchical Temporal Memory","Y. Fu; X. Guo; Y. Xie; D. Zhang; H. Li","Beijing Key Lab. of Knowledge Eng. for Mater. Sci., Univ. of Sci. & Technol. Beijing, Beijing, China","2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)","20160721","2015","","","863","870","Hierarchical Temporal Memory (HTM) is an advanced machine learning technique that aims to capture the structural and algorithmic properties of the neocortex. It is an online machine learning method and can make predictions and classifications. This paper is an application of the HTM theory. We use the HTM theory to diagnose diseases. First, we encode the cases of the patients into the format that can be recognized by the HTM. Second, we train the HTM by using the encoded cases. At last, we can predict the disease of a patient according to the symptoms. We do experiments on real nephrosis diagnostic datasets. The experimental results show that we can predict the diseases accurately and efficiently.","","Electronic:978-1-4673-7211-4; POD:978-1-4673-7212-1","10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518347","Classification;Disease Diagnosis;Hierarchical Temporal Memory;Prediction","Diseases;Encoding;Joining processes;Libraries;Machine learning algorithms;Neurons","diseases;learning (artificial intelligence);medical computing;patient diagnosis;pattern classification;storage management","HTM theory;advanced machine learning technique;algorithmic properties;case encoding;disease diagnosis;hierarchical temporal memory;neocortex;nephrosis diagnostic datasets;online machine learning method;structural properties","","","","","","","10-14 Aug. 2015","","IEEE","IEEE Conference Publications"
"Challenges in Perception and Decision Making for Intelligent Automotive Vehicles: A Case Study","B. Okumura; M. R. James; Y. Kanzawa; M. Derry; K. Sakai; T. Nishi; D. Prokhorov","Toyota Motor Corporation, Toyota, Aichi, Japan","IEEE Transactions on Intelligent Vehicles","20160720","2016","1","1","20","32","This paper overviews challenges in perception and decision making for intelligent, or highly automated, automotive vehicles. We illustrate our development of a complete perception and decision making system which addresses various challenges and propose an action planning method for highly automated vehicles which can merge into a roundabout. We use learning from demonstration to construct a classifier for high-level decision making, and develop a novel set of formulations that is suited to this challenging situation: multiple agents in a highly dynamic environment with interdependencies between agents, partial observability, and a limited amount of training data. Having limited amount of labeled training data is highly constraining, but a very real issue in real-world applications. We believe that our formulations are also well suited to other automated driving scenarios.","2379-8858;23798858","","10.1109/TIV.2016.2551545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448943","Autonomous driving;classifier;finite state machine;high-definition lidar;high-fidelity map;learning from demonstration;robot;roundabout;state representation","Automata;Decision making;Laser radar;Machine learning;Robot sensing systems;Support vector machine classification","automobiles;intelligent transportation systems;learning (artificial intelligence);pattern classification","action planning method;agent interdependencies;automated driving scenarios;decision making;dynamic environment;intelligent-highly automated-automotive vehicles;labeled training data;learning-from-demonstration;partial-observability;pattern classifier;perception;roundabout","","1","","48","","20160407","March 2016","","IEEE","IEEE Journals & Magazines"
"Place Classiﬁcation with a Graph Regularized Deep Neural Network","Y. Liao; S. Kodagoda; Y. Wang; L. Shi; Y. Liu","Yiyi Liao is with the State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, 310027, China. (email: yyliao@iipc.zju.edu.cn)","IEEE Transactions on Cognitive and Developmental Systems","","2016","PP","99","1","1","Place classification is a fundamental ability that a robot should possess to carry out effective human-robot interactions. In recent years, there is a high exploitation of Artificial Intelligence algorithms in robotics applications. Inspired by the recent successes of deep learning methods, we propose an end-to-end learning approach for the place classification problem. With deep architectures, this methodology automatically discovers features and contributes in general to higher classification accuracies. The pipeline of our approach is composed of three parts. Firstly, we construct multiple layers of laser range data to represent the environment information in different levels of granularity. Secondly, each layer of data is fed into a deep neural network for classification, where a graph regularization is imposed to the deep architecture for keeping local consistency between adjacent samples. Finally, the predicted labels obtained from all layers are fused based on confidence trees to maximize the overall confidence. Experimental results validate the effectiveness of our end-to-end place classification framework in which both the multi-layer structure and the graph regularization promote the classification performance. Furthermore, results show that the features automatically learned from the raw input range data can achieve competitive results to the features constructed based on statistical and geometrical information.","2379-8920;23798920","","10.1109/TCDS.2016.2586183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7501830","Place classification;deep learning;graph regularization","Feature extraction;Lasers;Machine learning;Robot kinematics;Robot sensing systems","","","","","","","","20160629","","","IEEE","IEEE Early Access Articles"
"Toward accelerating deep learning at scale using specialized hardware in the datacenter","K. Ovtcharov; O. Ruwase; J. Y. Kim; J. Fowers; K. Strauss; E. S. Chung","","2015 IEEE Hot Chips 27 Symposium (HCS)","20160707","2015","","","1","38","Presents a collection of slides covering the following topics: FPGA; data center; deep learning; cloud specialization tradeoff; and deep convolutional neural network.","","Electronic:978-1-4673-8885-6; POD:978-1-4673-8886-3","10.1109/HOTCHIPS.2015.7477459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477459","","Acceleration;Energy efficiency;Field programmable gate arrays;Hardware;Machine learning;Neural networks;Reconfigurable architectures","cloud computing;computer centres;convolution;field programmable gate arrays;learning (artificial intelligence);neural nets","FPGA;cloud specialization tradeoff;data center;deep convolutional neural network;deep learning","","","","","","","22-25 Aug. 2015","","IEEE","IEEE Conference Publications"
"Template attacks using classification algorithms","E. Özgen; L. Papachristodoulou; L. Batina","Technische Universiteit Eindhoven, P.O. Box 513, 5600 MB Eindhoven, The Netherlands","2016 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)","20160623","2016","","","242","247","Template attacks constitute a powerful side-channel attack technique that is shown to be efficient in breaking many secure cryptographic implementations. This type of attack consists of two phases, the profiling of the device (template building) and the template matching phase. Template matching can create a significant overhead in the performance of the attack, due to the large amount of data that needs to be processed for every possible value. On the other hand, machine learning techniques are developed to provide efficient pattern recognition and feature extraction algorithms, mainly used in artificial intelligence. In this work, we combine techniques from machine learning with template attacks, in order to improve the efficiency of template attacks focusing on the template matching phase. More precisely, we compare three classification algorithms on a template data set built during the execution of a regular scalar multiplication algorithm (double-and-add-always) of mbedTLS (formerly PolarSSL). As a result, we are able to retrieve scalar bits with 20 templates per bit.","","Electronic:978-1-4673-8826-9; POD:978-1-4673-8827-6","10.1109/HST.2016.7495589","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495589","","Algorithm design and analysis;Elliptic curve cryptography;Elliptic curves;Feature extraction;Machine learning algorithms;Support vector machines","cryptography;feature extraction;learning (artificial intelligence);pattern classification;pattern matching","artificial intelligence;classification algorithms;cryptographic implementation;device profiling phase;double-and-add-always algorithm;feature extraction algorithm;machine learning techniques;mbedTLS algorithm;pattern recognition algorithm;regular scalar multiplication algorithm;side-channel attack technique;template attacks;template building phase;template matching phase","","","","23","","","3-5 May 2016","","IEEE","IEEE Conference Publications"
"A Table Detection Method for PDF Documents Based on Convolutional Neural Networks","L. Hao; L. Gao; X. Yi; Z. Tang","Inst. of Comput. Sci. & Technol., Peking Univ., Beijing, China","2016 12th IAPR Workshop on Document Analysis Systems (DAS)","20160613","2016","","","287","292","Because of the better performance of deep learning on many computer vision tasks, researchers in the area of document analysis and recognition begin to adopt this technique into their work. In this paper, we propose a novel method for table detection in PDF documents based on convolutional neutral networks, one of the most popular deep learning models. In the proposed method, some table-like areas are selected first by some loose rules, and then the convolutional networks are built and refined to determine whether the selected areas are tables or not. Besides, the visual features of table areas are directly extracted and utilized through the convolutional networks, while the non-visual information (e.g. characters, rendering instructions) contained in original PDF documents is also taken into consideration to help achieve better recognition results. The primary experimental results show that the approach is effective in table detection.","","Electronic:978-1-5090-1792-8; POD:978-1-5090-1793-5","10.1109/DAS.2016.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490132","convolutional neural networks;deep learning;document analysis;table detection","Layout;Machine learning;Neural networks;Portable document format;Proposals;Text analysis","computer vision;document handling;learning (artificial intelligence);neural nets","PDF documents;computer vision tasks;convolutional neural networks;deep learning models;document analysis;table detection method","","","","14","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"A spectral filtering based deep learning for detection of logo and stamp","A. V. Nandedkar; J. Mukherjee; S. Sural","School of Information Technology, IIT Kharagpur, India","2015 Fifth National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG)","20160613","2015","","","1","4","This paper presents a novel spectral filtering based deep learning algorithm (SFDL) for detecting logos and stamps in a scanned document image. In a document image, textual contents are main source of high spatial frequency components. Accordingly, the high frequency filtering is used to suppress the text symbols. In the next step, segmentation process is used for localizing the candidate regions of interests such as logos and stamps. Preprocessing of these candidate regions is essential before classification. The proposed preprocessing includes steps such as region fusion, resizing and key point based pooling. Finally, the preprocessed candidate regions are classified using deep convolutional neural network. The main advantage of the SFDL is its capability to detect logos without prior information or assumption about their locations in a document. The performance of the proposed SFDL algorithm is evaluated using publicly accessible document image database StaVer. It is observed that SFDL performs satisfactorily for detecting logo and stamp. The precision and recall measures of the proposed SFDL are compared with existing techniques. Experimental results show that recall and precision of logo detection are 86.8%, 97.2%, respectively. Similarly, recall and precision for stamp detection are 85.3% and 94.8%.","","Electronic:978-1-4673-8564-0; POD:978-1-4673-8565-7","10.1109/NCVPRIPG.2015.7490053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490053","","Colored noise;Feature extraction;Image color analysis;Image segmentation;Machine learning;Neural networks;Training","convolution;document image processing;feature extraction;image classification;image filtering;image segmentation;learning (artificial intelligence);neural nets;text detection;visual databases","SFDL algorithm;candidate region classification;deep convolutional neural network;document image database;document image logo detection;document image stamp detection;segmentation process;spectral filtering based deep learning algorithm;text symbol suppression","","","","13","","","16-19 Dec. 2015","","IEEE","IEEE Conference Publications"
"A study on improvement of airway segmentation using Hybrid method","M. Qier; T. Kitasaka; Y. Nimura; M. Oda; K. Mori","Nagoya University, Aichi Institute of Technology, Nagoya, Japan Toyota, Japan","2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)","20160609","2015","","","549","553","This paper presents a method for extracting an airway region from 3D chest CT volumes that uses a combination of tube enhancement filters, voxel classification based on machine learning methods and graph-cut algorithm. Lots of previous methods utilize region growing or level set algorithms without any prior knowledge of bronchi, which always fail when they reach to the peripheral bronchi. In this paper, a method of extraction based on airway shape and machine learning is proposed. The proposed method detects candidate voxels of bronchial regions by using two types of enhancement filters, and a classifier model is built for selecting the proper candidates regions based on intensity and shape features and finally the selected candidate voxels are connected by graph-cut algorithm. We applied this method on six cases of 3D chest CT volumes. The results show that this method can extract the smaller airway branches without leaking into the lung parenchyma areas.","","Electronic:978-1-4799-6100-9; POD:978-1-4799-6101-6; USB:978-1-4799-6099-6","10.1109/ACPR.2015.7486563","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486563","","Classification algorithms;Decision support systems;Feature extraction;Filtering algorithms;Machine learning algorithms;Respiratory system;Three-dimensional displays","computerised tomography;feature extraction;graph theory;image classification;image enhancement;image filtering;image segmentation;learning (artificial intelligence);lung;medical image processing;shape recognition","3D chest CT volume;airway region extraction;airway segmentation improvement;airway shape;bronchial regions candidate voxel detection;classifier model;graph-cut algorithm;hybrid method;lung parenchyma area;machine learning method;shape feature;tube enhancement filter;voxel classification","","","","12","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"A deep learning approach for VM workload prediction in the cloud","F. Qiu; B. Zhang; J. Guo","Software College, Northeastern University, Shenyang, China","2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20160721","2016","","","319","324","In order to manage the resources in cloud efficiently, ensure the performance of cloud services and reduce the power consumption, it is critical to predict the workload of virtual machines (VM) accurately. In this paper, a new approach for VM workload prediction based on deep learning was proposed. A deep learning prediction model was designed with a deep belief network (DBN) composed of multiple-layered restricted Boltzmann machines (RBMs) and a regression layer. The DBN is used to extract the high level features from all VMs workload data and the regression layer is used to predict the workload of the VMs in the future. With little prior knowledge, DBN could learn the features efficiently for the VM workload prediction in an unsupervised fashion. Experimental results show that the proposed approach improves the workload prediction performance compared with other widely used workload prediction approaches.","","Electronic:978-1-5090-2239-7; POD:978-1-5090-0804-9","10.1109/SNPD.2016.7515919","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515919","deep belief networks;deep learning;restricted Boltzmann machine;workload prediction","Cloud computing;Correlation;Data models;Machine learning;Predictive models;Resource management;Training","Boltzmann machines;belief networks;cloud computing;learning (artificial intelligence);regression analysis;virtual machines","DBN;VM workload prediction;cloud computing;deep belief network;deep learning prediction model;multiple-layered restricted Boltzmann machines;regression layer;virtual machines","","","","","","","May 30 2016-June 1 2016","","IEEE","IEEE Conference Publications"
"Clustering analysis of malware behavior using Self Organizing Map","R. S. Pirscoveanu; M. Stevanovic; J. M. Pedersen","Department of Electronic Systems, Aalborg University, Denmark","2016 International Conference On Cyber Situational Awareness, Data Analytics And Assessment (CyberSA)","20160704","2016","","","1","6","For the time being, malware behavioral classification is performed by means of Anti-Virus (AV) generated labels. The paper investigates the inconsistencies associated with current practices by evaluating the identified differences between current vendors. In this paper we rely on Self Organizing Map, an unsupervised machine learning algorithm, for generating clusters that capture the similarities between malware behavior. A data set of approximately 270,000 samples was used to generate the behavioral profile of malicious types in order to compare the outcome of the proposed clustering approach with the labels collected from 57 Antivirus vendors using VirusTotal. Upon evaluating the results, the paper concludes on shortcomings of relying on AV vendors for labeling malware samples. In order to solve the problem, a cluster-based classification is proposed, which should provide more accurate results based on the clusters created by competitive and cooperative algorithms like Self Organizing Map that better describe the behavioral profile of malware.","","Electronic:978-1-5090-0703-5; POD:978-1-5090-0704-2","10.1109/CyberSA.2016.7503289","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7503289","Anti-Virus labels;Behavioral Clustering;Dynamic Analysis;Malware;Self Organizing Map","Clustering algorithms;Labeling;Machine learning algorithms;Trojan horses;Unsupervised learning","invasive software;learning (artificial intelligence);pattern clustering;self-organising feature maps","AV generated labels;VirusTotal;antivirus generated labels;behavioral profile;clustering analysis;malicious types;malware behavioral classification;malware samples;self organizing map;unsupervised machine learning algorithm","","","","17","","","13-14 June 2016","","IEEE","IEEE Conference Publications"
"Deep learning vs spectral clustering into an active clustering with pairwise constraints propagation","N. Voiron; A. Benoit; P. Lambert; B. Ionescu","LISTIC, Universit Savoie Mont Blanc, 74940, Annecy le Vieux, France","2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI)","20160630","2016","","","1","6","In our data driven world, categorization is of major importance to help end-users and decision makers understanding information structures. Supervised learning techniques rely on annotated samples that are often difficult to obtain and training often overfits. On the other hand, unsupervised clustering techniques study the structure of the data without disposing of any training data. Given the difficulty of the task, supervised learning often outperforms unsupervised learning. A compromise is to use a partial knowledge, selected in a smart way, in order to boost performance while minimizing learning costs, what is called semi-supervised learning. In such use case, Spectral Clustering proved to be an efficient method. Also, Deep Learning outperformed several state of the art classification approaches and it is interesting to test it in our context. In this paper, we firstly introduce the concept of Deep Learning into an active semi-supervised clustering process and compare it with Spectral Clustering. Secondly, we introduce constraint propagation and demonstrate how it maximizes partitioning quality while reducing annotation costs. Experimental validation is conducted on two different real datasets. Results show the potential of the clustering methods.","","Electronic:978-1-4673-8695-1; POD:978-1-4673-8696-8","10.1109/CBMI.2016.7500237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7500237","","Clustering algorithms;Clustering methods;Computer architecture;Context;Machine learning;Neurons;Training","constraint handling;learning (artificial intelligence);pattern clustering","active semisupervised clustering process;annotation cost reduction;deep-learning;learning cost minimization;pairwise constraint propagation;partial-knowledge;partitioning quality maximization;performance improvement;semisupervised learning;spectral clustering;supervised learning technique","","","","20","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"Deformable part model and deep learning comparison on victim detection","F. Çakmak; E. Uslu; N. Altuntaş; S. Marangoz; M. Balcılar; M. F. Amasyalı; S. Yavuz","Bilgisayar M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, Y&#305;ld&#305;z Teknik &#220;niversitesi, &#304;stanbul, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1513","1516","Object detection problem is a considerable research field that is being developed through continuous research. Simulated victims (dolls) detection performances of 2 different methods are given in the scope of this work. While deformable part model method is performing high accuracy and speed to detect object, with growing and remarkable popularity, deep learning method is noteworthy with higher performance results. This work mentions about the advantages and disadvantages of both methods and gives experimental results on a simulated environment.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496039","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496039","deep learning;deformable part model;object deteciton;victim detection","Analytical models;Computational modeling;Deformable models;Machine learning;Neural networks;Object detection;Robots","learning (artificial intelligence);object detection","deep learning comparison;deformable part model;object detection;simulated victims detection","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Visual object tracking with autoencoder representations","B. Beşbınar; A. A. Alatan","Elektrik ve Elektronik M&#252;hendisli&#287;i, Orta Do&#287;u Teknik &#220;niversitesi, Ankara, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","2041","2044","Deep learning is the discipline of training computational models that are composed of multiple layers and these methods have recently improved the state of the art in many areas as a virtue of large labeled datasets, increase in the computational power of current hardware and unsupervised training methods. Although such a dataset may not be available for lots of application areas, the representations obtained by the well-designed networks that have a large representation capacity and trained with enough data are claimed to have the ability to generalize for transfer learning. As an example application, in this work, we investigate the use of stacked autoencoders for visual object tracking, which is a challenging yet very important task in computer vision. Training of autoencoders is achieved via an auxiliary dataset and the resultant representations are utilized within the tracking-by-detection framework. Experiments, realized using a challenge toolkit, indicate that exploiting the intricate structure in auxiliary dataset via hierarchical representations contributes to the solution of visual object tracking problem.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496171","autoencoders;deep learning;particle filter;visual object tracking","Computational modeling;Computer vision;Decision support systems;Machine learning;Object tracking;Training;Visualization","computer vision;encoding;object tracking;unsupervised learning","autoencoder representations;auxiliary dataset;challenge toolkit;computational power;computer vision;current hardware;deep learning;hierarchical representations;intricate structure;large labeled datasets;representation capacity;stacked autoencoders;tracking-by-detection framework;training computational models;unsupervised training;visual object tracking","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Semi-supervised classification of hyperspectral images with small sample sizes","M. S. Aydemir; G. Bilgin","B&#304;LGEM, T&#220;B&#304;TAK, 41470 Kocaeli, Turkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","681","684","In the classification of hyperspectral images with supervised methods, acquisition of ground-truth information for a hyperspectral image is a challenging process in terms of time and cost. Besides, amount of the labeled data also affects the performance of classifiers. In this study, as a solution to this problem, a hyperspectral image classifier is proposed with semi-supervised learning, support vector machine classifier and deep learning. In the first phase to improve the classification performance, limited number of training data is increased by semisupervised learning methodology. Then, the classification process is performed with support vector machines and convolutional neural networks. According to the acquired classification results, a close classification performance is obtained by the system with small number of training data to the supervised classification. Furthermore, deep neural network has reached more successful results than support vector machines.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7495831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495831","Hyperspectral images;convolutional neural networks;deep learning;deep neural networks;semi-supervised learning","Hyperspectral imaging;Machine learning;Neural networks;Semisupervised learning;Supervised learning;Support vector machines;Training data","hyperspectral imaging;image classification;learning (artificial intelligence);neural nets;support vector machines","convolutional neural networks;deep learning;ground-truth information;hyperspectral image classification;semisupervised classification;semisupervised learning;small sample sizes;support vector machine classifier","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Deep learning based autonomous direction estimation","H. Yalçın; M. H. Cılasun","G&#246;rsel Zeka Laboratuar&#305;, Elektronik ve Haberle&#351;me M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, &#304;stanbul Teknik &#220;niversitesi, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1645","1648","Outdoor mapping and localization based on appearance is especially challenging since usually separate processes of mapping and localization are required at different times of day. The problem is harder in the outdoors where continuous change in sun angle can drastically affect the appearance of a scene. In this work, we propose a method for instantaneous visual direction determination for the autonomous mobile platforms assuming the mobile platform travels along a routine route. We propose a deep convolutional neural network based algorithm for classification of instantaneous images of the path to be followed. The model is tested on SeqSlam dataset and a success performance of %78.5 is achieved. Hidden layer weights are analyzed to ensure that the learning is actually achieved. Experimental results suggest that deep neural networks yield high recognition rates of images to be used for autonomous movement. Approach will be tested on a novel dataset and its performance will be realized in realtime as future work.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496072","appearance based localization and mapping;autonomous direction determination;deep learning;deep neural networks","Machine learning;Mathematical model;Mobile robots;Neural networks;Simultaneous localization and mapping;Wheelchairs","image classification;learning (artificial intelligence);neural nets","SeqSlam dataset;autonomous direction estimation;autonomous mobile platforms;autonomous movement;deep convolutional neural network;deep learning;hidden layer weights;image recognition;instantaneous image classification;instantaneous visual direction determination;localization process;mapping process;outdoor localization;outdoor mapping;routine route","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"A review on advances in deep learning","Soniya; S. Paul; L. Singh","Dept. of Physics and Computer Science, Dayalbagh Educational Institute, Dayalbagh, Agra 282005","2015 IEEE Workshop on Computational Intelligence: Theories, Applications and Future Directions (WCI)","20160623","2015","","","1","6","Over the years conventional neural networks has shown state-of-art performance on many problems. However, their performance on recognition system is still not widely accepted in the machine learning community because these networks are unable to handle selectivity-invariance dilemma and also suffer from the problem of vanishing gradients. Some of these issues have been addressed by deep learning. Deep learning approaches attempt to disentangle intricate aspects of input by creating multiple levels of representation. These approaches have shown astonishing results in problem domains like recognition system, natural language processing, medical sciences, and in many other fields. The paper presents an overview of different deep learning approaches in a nutshell and also highlights some limitations which are restricting performance of deep neural networks in order to handle more realistic problems.","","Electronic:978-1-4673-8215-1; POD:978-1-4673-8219-9","10.1109/WCI.2015.7495514","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495514","conventional neural networks;deep learning;deep neural networks","Biological neural networks;Computer architecture;Feature extraction;Machine learning;Supervised learning;Unsupervised learning","","","","","","80","","","14-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Reliable and Reconfigurable Signal Processing Framework for Estimation of Metabolic Equivalent of Task in Wearable Sensors","P. Alinia; R. Saeedi; R. Fallahzadeh; A. Rokni; H. Ghasemzadeh","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA","IEEE Journal of Selected Topics in Signal Processing","20160725","2016","10","5","842","853","Wearable motion sensors are widely used to estimate metabolic equivalent of task (MET) values associated with physical activities. However, one major obstacle in widespread adoption of current wearables is that any changes in configuration of the network requires new data collection and re-training of the underlying signal processing algorithms. For any wearable-based MET estimation framework to be considered a viable platform, it needs to be reconfigurable, reliable, and power-efficient. In this paper, we aim to address the issues of sensor misplacement, power efficiency, and new sensor addition and propose a reliable and reconfigurable MET estimation framework. We introduce a power-aware sensor localization approach that allows users to wear the sensors on different body locations without need for adhering to a specific installation protocol. Furthermore, we propose a novel transductive transfer learning approach, which gives end-users the ability to add new sensors to the network without need for collecting new training data. This is accomplished by transferring the knowledge of already trained sensors to the untrained sensors in real-time. Our experiments demonstrate that our sensor localization algorithm achieves an accuracy of 90.8% in detecting location of the wearable sensors. The integrated model of sensor localization and MET calculation achieves an R<sup>2</sup> of 0.8 in estimating MET values using a regression-based model. Furthermore, our transfer learning algorithm improves the R<sup>2</sup> value of MET estimation up to 60%.","1932-4553;19324553","","10.1109/JSTSP.2016.2569472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470553","Metabolic equivalent of task (MET);motion sensors;node localization;physical activities;sensor misplacement;transfer learning","Estimation;Machine learning algorithms;Reliability;Signal processing algorithms;Standards;Wearable sensors","body sensor networks;learning (artificial intelligence);medical signal processing;sensor placement;wearable computers","body locations;metabolic equivalent of task estimation;power efficiency;power-aware sensor localization;reconfigurable signal processing framework;reliable signal processing framework;sensor misplacement;transductive transfer learning approach;wearable motion sensors;wearable-based MET estimation framework","","1","","","","20160517","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"g-BSAFCM: A new hybrid clustering algorithm","G. Toz; P. Erdoğmuş","Elektrik ve Elektronik ve Bilgisayar M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, D&#252;zce &#220;niversitesi, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","145","148","Clustering is dividing a dataset into subsets that has similar characteristics. In this study, fuzzy c-means clustering algorithm (FCM) and a new evolutionary optimization algorithm, Backtracking Search (BSA) algorithm, were combined and a new hybrid clustering algorithm (BSAFCM) was proposed. Moreover, the local search abilities of the new algorithm was improved and the new algorithm was named as g-BSAFCM. Three benchmark datasets from UCI Machine Learning Repository database were clustered by using the developed algorithms and FCM. According to the results g-BSAFCM has achieved better results than FCM and BSAFCM.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7495698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495698","BSA;FCM;clustering","Breast cancer;Clustering algorithms;Indexes;Iris;Lungs;Machine learning algorithms","evolutionary computation;learning (artificial intelligence);pattern clustering","UCI Machine Learning Repository database;backtracking search algorithm;evolutionary optimization algorithm;fuzzy c-means clustering algorithm;g-BSAFCM;hybrid clustering algorithm","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"RHadoop-based fuzzy data mining: Architecture, design and system implementation","P. Sun; L. Xu; H. Fan","School of Software Engineering, Tongji University, Shanghai, China","2016 IEEE International Conference on Big Data Analysis (ICBDA)","20160714","2016","","","1","5","Data mining is a challenge for end-users, which requires knowledge and skills on business domains, data mining algorithms and software development. In response to the challenge, we have proposed, designed and implemented a novel data mining system named RFDM (RHadoop-based Fuzzy Data Mining), which supports fuzzy data mining process and experience with user convenience and reduced cost. The system is capable of supporting fully-automated data mining life-cycle activities, with limited user interactions in dataset uploading and data mining configuration. In addition, a RHadoop-based framework has been integrated, which meets the requirements of large-scale datasets in data mining. Experiments have indicated that the RFDM system achieves enhanced performance while supporting fuzzy data mining.","","CD-ROM:978-1-4673-9589-2; Electronic:978-1-4673-9591-5; POD:978-1-4673-9592-2","10.1109/ICBDA.2016.7509796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7509796","MapReduce;RHadoop;data mining;fuzzy;large-scale","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Data mining;Data models;Machine learning algorithms;Training","business data processing;data handling;data mining;fuzzy set theory;parallel processing","RFDM;RHadoop-based fuzzy data mining;business domains;data mining algorithms;fully-automated data mining life-cycle activities;fuzzy data mining process;software development;user convenience","","","","","","","12-14 March 2016","","IEEE","IEEE Conference Publications"
"Hyperspectral data classification using deep convolutional neural networks","M. Salman; S. E. Yüksel","T&#252;bitak Bilgem &#304;LTAREN, Ankara, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","2129","2132","In the last five years, deep learning has been gaining a large amount of interest in the computer vision community due to its capability to perform feature learning and classification at the same time. However, the studies using deep learning for hyperspectral imaging are still very few. In this paper, a deep convolutional neural network structure to classify hyperspectral data is proposed. The results are compared to the support vector machine and K-nearest neighbourhood algorithms and it has been shown that deep learning with the proposed architecture is much more successful in hyperspectral data classification.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496193","classification;deep learning;feature extraction;hyperspectral image classification","Hyperspectral imaging;Image classification;Machine learning;Neural networks;Support vector machines","","","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Detection of Application Layer DDoS attack by feature learning using Stacked AutoEncoder","S. Yadav; S. Subramanian","Department of Computer Science and Engineering, National Institute of Technology, Tiruchirappalli, Tamil Nadu, India","2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT)","20160718","2016","","","361","366","An Application Layer Distributed Denial of Service Attack (DDoS) is one of the biggest concerns for web security. Many detection methods are designed to mitigate DDoS attack based on IP and TCP layer instead of the Application layer. These methods are not suitable for detection of Application layer DDoS attack since most of the IP and TCP layer DDoS attacks are based on request flooding attack. But Application layer DDoS attacks consist of request flooding, session flooding, and asymmetric attack. The solutions available to detect Application layer DDoS attack, detect only limited number of Application layer DDoS attacks. The solutions that detect all types of Application layer DDoS attacks have huge algorithm complexity. One of the major challenges in the detection of an Application layer DDoS attack is the non-availability of features to detect such attacks. Hence it is difficult to model normal user behavior from attack behavior. In this paper, Deep learning architecture is introduced to learn deep features of Application layer DDoS attack. Deep learning architecture consist of very deep neural network, typically more than three layers. In the proposed work the concept of AutoEncoder is applied, which is one of the deep learning based models that learns deep useful features in the Application layer DDoS attack dataset. The Stacked AutoEncoder deep learning architecture, is aimed to receive high level features. The performance of the proposed method was evaluated in terms of the metrics such as false positive rate and detection rate. Comparison of the proposed method with the existing methods reveals that the proposed method performs better than the existing methods.","","Electronic:978-1-5090-0082-1; POD:978-1-5090-0083-8","10.1109/ICCTICT.2016.7514608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514608","Application Layer DDoS Attack;AutoEncoder;DDoS;Deep learning;Feature learning;Stacked AutoEncoder","Computer crime;Feature extraction;Floods;IP networks;Machine learning;Pattern recognition;Web servers","computer network security;learning (artificial intelligence);neural nets","IP layer;Stacked AutoEncoder;TCP layer;Web security;application layer DDoS attack detection;application layer distributed denial of service attack;deep learning architecture;feature learning;very deep neural network","","","","","","","11-13 March 2016","","IEEE","IEEE Conference Publications"
"Hybrid approach for automatic segmentation of fetal abdomen from ultrasound images using deep learning","H. Ravishankar; S. M. Prabhu; V. Vaidya; N. Singhal","GE Global Research, Bangalore, India","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","779","782","In this paper, we propose a hybrid approach combining traditional texture analysis methods with deep learning for the automatic detection and measurement of abdominal contour from 2-D fetal ultrasound images. Following a learning-based procedure for region of interest (ROI) localization to segment the abdominal boundary, we show that convolutional neural networks (CNNs) outperform other state-of-the-art texture features and conventional classifiers, in addressing the binary classification problem of distinguishing between abdomen versus non-abdomen regions. However, we obtain significantly better segmentation results in identifying the best ROI containing fetal abdomen, when the predictions from CNN are combined with those from gradient boosting machine (GBM) using histogram of oriented gradient (HOG) features. We trained our method on a set of 70 images and tested them on another distinct set of 70 images. We obtained a mean DICE similarity coefficient of 0.90, which shows excellent overlap with the ground truth. We report that the mean computed gestational age difference between our segmentation results and the ground truth, is within two weeks for 90% (and within one week for 70%) of the testing cases.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493382","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493382","","Abdomen;Feature extraction;Image segmentation;Machine learning;Training;Ultrasonic imaging;Ultrasonic variables measurement","","","","","","14","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Optimized Structure of the Traffic Flow Forecasting Model With a Deep Learning Approach","H. F. Yang; T. S. Dillon; Y. P. P. Chen","Department of Computer Science Information Technology, La Trobe University, Melbourne, VIC 3086, Australia.","IEEE Transactions on Neural Networks and Learning Systems","","2016","PP","99","1","11","Forecasting accuracy is an important issue for successful intelligent traffic management, especially in the domain of traffic efficiency and congestion reduction. The dawning of the big data era brings opportunities to greatly improve prediction accuracy. In this paper, we propose a novel model, stacked autoencoder Levenberg-Marquardt model, which is a type of deep architecture of neural network approach aiming to improve forecasting accuracy. The proposed model is designed using the Taguchi method to develop an optimized structure and to learn traffic flow features through layer-by-layer feature granulation with a greedy layerwise unsupervised learning algorithm. It is applied to real-world data collected from the M6 freeway in the U.K. and is compared with three existing traffic predictors. To the best of our knowledge, this is the first time that an optimized structure of the traffic flow forecasting model with a deep learning approach is presented. The evaluation results demonstrate that the proposed model with an optimized structure has superior performance in traffic flow forecasting.","2162-237X;2162237X","","10.1109/TNNLS.2016.2574840","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517319","Deep learning;forecasting;neural network (NN) applications;stacked denoising autoencoders.","Artificial neural networks;Computational modeling;Data models;Forecasting;Machine learning;Prediction algorithms;Predictive models","","","","","","","","20160720","","","IEEE","IEEE Early Access Articles"
"Demonstration of Convolution Kernel Operation on Resistive Cross-Point Array","L. Gao; P. Y. Chen; S. Yu","School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Electron Device Letters","20160624","2016","37","7","870","873","Convolution is the key operation in the convolutional neural network, one of the most popular deep learning algorithms. The implementation of the convolution kernel on the resistive cross-point array is different than the implementation of the matrix-vector multiplication in prior works. In this letter, we propose a dimensional reduction of 2-D kernel matrix into 1-D column vector, i.e., a column of the array, and enable the parallel readout of multiple 2-D kernels simultaneously. As a proof-of-concept demonstration, we use the Prewitt kernels to detect both horizontal and vertical edges of the 20 × 20 pixels of black and-white MNIST handwritten digits. The experiments were performed on the fabricated 12 × 12 resistive cross-point array based on the Pt/HfO<sub>x</sub>/TiN structure. The experimental results of the Prewitt kernel operation perfectly matches the simulation results, indicating the feasibility of the proposed implementation methodology of the convolution kernel on resistive cross-point array.","0741-3106;07413106","","10.1109/LED.2016.2573140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479502","Convolution kernel;convolution kernel;cross-point array;neuromorphic computing;resistive memory","Convolution;Image edge detection;Kernel;Machine learning;Neurons;Object recognition","convolution;handwriting recognition;image classification;learning (artificial intelligence);matrix algebra;neural nets;vectors","1D column vector;2D kernel matrix;MNIST handwritten digit;Prewitt kernel;classification layer;convolution kernel operation;convolutional neural network;deep learning algorithm;dimensional reduction;proof-of-concept demonstration;resistive cross-point array","","","","18","","20160526","July 2016","","IEEE","IEEE Journals & Magazines"
"Eye detection by using deep learning","Ş. Karahan; Y. S. Akgül","Bilgisayar M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, Gebze Teknik &#220;niversitesi, Kocaeli, 41400, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","2145","2148","In recent years, deep learning algorithm has been one of the most used method in machine learning. Success rate of the most popular machine learning problems has been increased by using it. In this work, we develop an eye detection method by using a deep neural network. The designed network, which is accepted as an input by Caffe, has 3 convolution layers and 3 max pooling layers. This model has been trained with 16K positive and 52K negative image patches. The last layer of the network is the classification layer which operates a softmax algorithm. The trained model has been tested with images, which were provided on FDDB and CACD datasets, and also compared with Haar eye detection algorithm. Recall value of the method is higher than the Haar algorithm on the two datasets. However, according to the precision rate, the Haar algorithm is successful on FDDB dataset.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496197","Caffe;Deep Learning;Digits;Eye Detection","Algorithm design and analysis;Classification algorithms;Convolution;Face recognition;Hidden Markov models;Machine learning;Neural networks","eye;gaze tracking;image classification;neural nets","CACD dataset;FDDB dataset;Haar algorithm;Haar eye detection algorithm;classification layer;convolution layers;deep learning algorithm;deep neural network;eye detection method;image patches;machine learning;max pooling layers;recall value;softmax algorithm","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"The hidden layer design for staked denoising autoencoder","Qianqian Hao; Hua Zhang; Jinkou Ding","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20160620","2015","","","150","153","Deep learning can achieve the complex function approximation and the characteristics of the input data by studying a deep nonlinear network. At present, one of the most important problems in the study of deep learning is how to construct a reasonable structure. This paper studies the deep learning model of stacked denoising autoencoder (SDA) and the remaining task is to construct its reasonable model. We introduce three effective methods to construct the structure of the SDA. Numerical experiments imply that the structure obtained by the golden section principle performs the best.","","Electronic:978-1-4673-8266-3; POD:978-1-4673-8267-0","10.1109/ICCWAMTIP.2015.7493964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493964","Deep Learning;Hidden Layer;SDA;golden section;nonlinear network","Data models;Machine learning;Mathematical model;Neural networks;Noise reduction;Numerical models;Training","learning (artificial intelligence);neural nets","SDA structure;complex function approximation;deep learning model;deep nonlinear network;golden section principle;hidden layer design;input data characteristics;multilayer neural network;stacked denoising autoencoder;staked denoising autoencoder","","","","12","","","18-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"ModDrop: Adaptive Multi-Modal Gesture Recognition","N. Neverova; C. Wolf; G. Taylor; F. Nebout","INSA-Lyon, LIRIS, UMR5205, F-69621, Universit&#233; de Lyon, CNRS, France","IEEE Transactions on Pattern Analysis and Machine Intelligence","20160630","2016","38","8","1692","1706","We present a method for gesture detection and localisation based on multi-scale and multi-modal deep learning. Each visual modality captures spatial information at a particular spatial scale (such as motion of the upper body or a hand), and the whole system operates at three temporal scales. Key to our technique is a training strategy which exploits: i) careful initialization of individual modalities; and ii) gradual fusion involving random dropping of separate channels (dubbed ModDrop) for learning cross-modality correlations while preserving uniqueness of each modality-specific representation. We present experiments on the ChaLearn 2014 Looking at People Challenge gesture recognition track, in which we placed first out of 17 teams. Fusing multiple modalities at several spatial and temporal scales leads to a significant increase in recognition rates, allowing the model to compensate for errors of the individual classifiers as well as noise in the separate channels. Furthermore, the proposed ModDrop training technique ensures robustness of the classifier to missing signals in one or several channels to produce meaningful predictions from any number of available modalities. In addition, we demonstrate the applicability of the proposed fusion scheme to modalities of arbitrary nature by experiments on the same dataset augmented with audio.","0162-8828;01628828","","10.1109/TPAMI.2015.2461544","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169562","Gesture recognition;convolutional neural networks;deep learning;multi-modal learning","Context;Feature extraction;Joints;Machine learning;Streaming media;Training","audio streaming;gesture recognition;learning (artificial intelligence);pattern classification;random processes;sensor fusion","ModDrop training technique;adaptive multimodal gesture recognition;classifier robustness;cross-modality correlations;dubbed ModDrop;gesture detection;gesture localisation;gradual fusion;modality-specific representation;multiple modality fusion;multiscale multimodal deep learning;random dropping;spatial information;spatial scales;temporal scales;training strategy;visual modality","","3","","65","","20150728","Aug. 1 2016","","IEEE","IEEE Journals & Magazines"
"Deep Learning of Transferable Representation for Scalable Domain Adaptation","M. Long; J. Wang; Y. Cao; J. Sun; P. S. Yu","School of Software, Tsinghua National Laboratory for Information Science and Techonolgy (TNList), Tsinghua University, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","20160706","2016","28","8","2027","2040","Domain adaptation generalizes a learning model across source domain and target domain that are sampled from different distributions. It is widely applied to cross-domain data mining for reusing labeled information and mitigating labeling consumption. Recent studies reveal that deep neural networks can learn abstract feature representation, which can reduce, but not remove, the cross-domain discrepancy. To enhance the invariance of deep representation and make it more transferable across domains, we propose a unified deep adaptation framework for jointly learning transferable representation and classifier to enable scalable domain adaptation, by taking the advantages of both deep learning and optimal two-sample matching. The framework constitutes two inter-dependent paradigms, unsupervised pre-training for effective training of deep models using deep denoising autoencoders, and supervised fine-tuning for effective exploitation of discriminative information using deep neural networks, both learned by embedding the deep representations to reproducing kernel Hilbert spaces (RKHSs) and optimally matching different domain distributions. To enable scalable learning, we develop a linear-time algorithm using unbiased estimate that scales linearly to large samples. Extensive empirical results show that the proposed framework significantly outperforms state of the art methods on diverse adaptation tasks: sentiment polarity prediction, email spam filtering, newsgroup content categorization, and visual object recognition.","1041-4347;10414347","","10.1109/TKDE.2016.2554549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452659","Domain adaptation;deep learning;denoising autoencoder;multiple kernel learning;neural network;two-sample test","Adaptation models;Kernel;Labeling;Machine learning;Neural networks;Noise reduction;Object recognition","data mining;learning (artificial intelligence);neural nets","RKHS;abstract feature representation learning;cross-domain data mining;cross-domain discrepancy;deep denoising autoencoders;deep learning;deep neural networks;email spam filtering task;labeled information reuse;labeling consumption mitigation;linear-time algorithm;newsgroup content categorization task;optimal two-sample matching;reproducing kernel Hilbert spaces;scalable domain adaptation;scalable learning;sentiment polarity prediction task;transferable representation learning;visual object recognition task","","1","","49","","20160414","Aug. 1 2016","","IEEE","IEEE Journals & Magazines"
"Student performance analysis using clustering algorithm","I. Singh; A. S. Sabitha; A. Bansal","ASET, CSE, Amity University Uttar Pradesh, Noida, India","2016 6th International Conference - Cloud System and Big Data Engineering (Confluence)","20160709","2016","","","294","299","University and technical organizations are facing high competition and their challenge is in analyzing their performance. The major challenges are in admission, student placement and in the curriculum. The two most important process during which data's are collected and analyzed are admission and placement. The ranking of the university depends on academic performance and placement of the student. Apart from academic performance there are various other factors which help in understanding the overall performance of the student. In this research work, the data mining technique is used to understand the performance of student and group the students under various categories as a student need to consistently improve to compete in today's world.","","CD-ROM:978-1-4673-8202-1; Electronic:978-1-4673-8203-8; POD:978-1-4673-8204-5","10.1109/CONFLUENCE.2016.7508131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508131","K-means algorithm;cluster analysis;data mining;overall performance;silhouette measure;student performance","Algorithm design and analysis;Big data;Clustering algorithms;Data mining;Decision trees;Machine learning algorithms;Performance analysis","data mining;educational administrative data processing;pattern clustering","clustering algorithm;data mining technique;student performance analysis","","","","","","","14-15 Jan. 2016","","IEEE","IEEE Conference Publications"
"Comparing dataset characteristics that favor the Apriori, Eclat or FP-Growth frequent itemset mining algorithms","J. Heaton","College of Engineering and Computing, Nova Southeastern University, Ft. Lauderdale, FL 33314, United States","SoutheastCon 2016","20160709","2016","","","1","7","Frequent itemset mining is a popular data mining technique. Apriori, Eclat, and FP-Growth are among the most common algorithms for frequent itemset mining. Considerable research has been performed to compare the relative performance between these three algorithms, by evaluating the scalability of each algorithm as the dataset size increases. While scalability as data size increases is important, previous papers have not examined the performance impact of similarly sized datasets that contain different itemset characteristics. This paper explores the effects that two dataset characteristics can have on the performance of these three frequent itemset algorithms. To perform this empirical analysis, a dataset generator is created to measure the effects of frequent item density and the maximum transaction size on performance. The generated datasets contain the same number of rows. This provides some insight into dataset characteristics that are conducive to each algorithm. The results of this paper's research demonstrate Eclat and FP-Growth both handle increases in maximum transaction size and frequent itemset density considerably better than the Apriori algorithm.","","Electronic:978-1-5090-2246-5; POD:978-1-5090-2247-2","10.1109/SECON.2016.7506659","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506659","","Algorithm design and analysis;Clustering algorithms;Data mining;Itemsets;Machine learning algorithms;Random access memory","data mining","Apriori algorithm;Eclat algorithm;FP-growth frequent itemset mining algorithms;data mining technique;dataset characteristics;dataset generator;frequent itemset density;maximum transaction size","","","","","","","March 30 2016-April 3 2016","","IEEE","IEEE Conference Publications"
"Online adaptive hierarchical space partitioning classifier","O. F. Kılıç; N. D. Vanlı; H. Özkan; İ. Delibalta; S. S. Kozat","Elektrik ve Elektronik M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, &#304;hsan Dogramac&#305; Bilkent &#220;niversitesi, Ankara, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1237","1240","We introduce an on-line classification algorithm based on the hierarchical partitioning of the feature space which provides a powerful performance under the defined empirical loss. The algorithm adaptively partitions the feature space and at each region trains a different classifier. As a final classification result algorithm adaptively combines the outputs of these basic models which enables it to create a linear piecewise classifier model that can work well under highly non-linear complex data. The introduced algorithm also have scalable computational complexity that scales linearly with dimension of the feature space, depth of the partitioning and number of processed data. Through experiments we show that the introduced algorithm outperforms the state-of-the-art ensemble techniques over various well-known machine learning data sets.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7495970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495970","adaptive trees;classification;computational efficiency;on-line learning","Adaptation models;Classification algorithms;Computational complexity;Computational modeling;Data models;Machine learning algorithms;Partitioning algorithms","computational complexity;learning (artificial intelligence);pattern classification;piecewise linear techniques;signal classification","computational complexity;empirical loss;linear piecewise classifier model;machine learning;nonlinear complex data;online adaptive hierarchical space partitioning classifier;online classification algorithm","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Contents","","","Journal of Systems Engineering and Electronics","20160721","2016","27","2","1","2","","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514414","","Adaptive systems;Algorithm design and analysis;Machine learning algorithms;Optimization;Scheduling;Software algorithms","","","","","","","","","April 20 2016","","BIAI","BIAI Journals & Magazines"
"A hybrid method for bilingual text sentiment classification based on deep learning","G. Liu; X. Xu; B. Deng; S. Chen; L. Li","School of Computer and Information Science, Southwest University, Chongqing, China","2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20160721","2016","","","93","98","Text sentiment classification has occupied a pivotal position in sentiment analysis research, it offers important opinion mining functions. Nowadays, with explosion of information, many researchers are focusing on sentiment classification research on massive amounts of data. However, the traditional machine learning methods cannot acquire text semantic information and most research achievements are about single language, in this paper, a hybrid method which integrates the deep learning features and shallow learning features is proposed. The hybrid method can not only realize single language text sentiment classification but realize bilingual text sentiment classification as well. Models such as recurrent neural networks (RNNs) with long short term memory(LSTM), Naïve Bayes Support Vector Machine (NB-SVM), word vectors and bag-of-words are explored. Firstly, these models are studied separately in sentiment classification task. The paper then integrates the above methods as a whole to complete the task. Different combination strategies are discussed regarding the contribution of each method. The experiments show that the accuracy can reach 89% and the hybrid method performs much better than any other method individually. The proposed method achieves a performance close to the state-of-the-art methods based on the had-engineered features. What's more, the hybrid model can learn more linguistic phenomena with the growth of the accuracy of emotional tendency discrimination when more background knowledge is available.","","Electronic:978-1-5090-2239-7; POD:978-1-5090-0804-9","10.1109/SNPD.2016.7515884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515884","deep learning;neural network;opinion mining;sentiment analysis;text sentiment classification","Computational modeling;Machine learning;Neural networks;Semantics;Sentiment analysis;Support vector machines;Training","data mining;learning (artificial intelligence);pattern classification;recurrent neural nets;sentiment analysis;support vector machines;word processing","LSTM;NB-SVM;RNN;bag-of-words;bilingual text sentiment classification;deep learning feature;hybrid method;long short term memory;naïve Bayes support vector machine;opinion mining;recurrent neural network;sentiment analysis;shallow learning feature;word vector","","","","","","","May 30 2016-June 1 2016","","IEEE","IEEE Conference Publications"
"Single-Sample Face Recognition Based on LPP Feature Transfer","J. Pan; X. S. Wang; Y. H. Cheng","School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Access","20160624","2016","4","","2873","2884","Due to its wide applications in practice, face recognition has been an active research topic. With the availability of adequate training samples, many machine learning methods could yield high face recognition accuracy. However, under the circumstance of inadequate training samples, especially the extreme case of having only a single training sample, face recognition becomes challenging. How to deal with conflicting concerns of the small sample size and high dimensionality in one-sample face recognition is critical for its achievable recognition accuracy and feasibility in practice. Being different from the conventional methods for global face recognition based on generalization ability promotion and local face recognition depending on image segmentation, a single-sample face recognition algorithm based on locality preserving projection (LPP) feature transfer is proposed here. First, transfer sources are screened to obtain the selective sample source using the whitened cosine similarity metric. Second, we project the vectors of source faces and target faces into feature subspace by LPP, respectively, and calculate the feature transfer matrix to approximate the mapping relationship on source faces and target faces in subspace. Then, the feature transfer matrix is used on training samples to transfer the original macro characteristics to target macro characteristics. Finally, the nearest neighbor classifier is used for face recognition. Our results based on popular databases FERET, ORL, and Yale demonstrate the superiority of the proposed LPP feature transfer-based one-sample face recognition algorithm when compared with popular single-sample face recognition algorithms, such as (PC)<sup>2</sup>A and Block FLDA.","2169-3536;21693536","","10.1109/ACCESS.2016.2574366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7480758","Feature extraction;face recognition;locality preserving projection;one-sample;transfer learning","Accuracy;Face recognition;Feature extraction;Image recognition;Learning systems;Machine learning;Training;Transfer learning","face recognition;image segmentation;learning (artificial intelligence);matrix algebra","LPP feature transfer;feature transfer matrix;generalization ability promotion;global face recognition;image segmentation;local face recognition;locality preserving projection feature transfer;machine learning methods;nearest neighbor classifier;selective sample source;single-sample face recognition algorithm;whitened cosine similarity metric","","","","55","","20160530","2016","","IEEE","IEEE Journals & Magazines"
"Retinal vessel segmentation via deep learning network and fully-connected conditional random fields","H. Fu; Y. Xu; D. W. K. Wong; J. Liu","Ocular Imaging Department, Institute for Infocomm Research, Agency for Science, Technology and Research (A&#8727;STAR), Singapore","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","698","701","Vessel segmentation is a key step for various medical applications. This paper introduces the deep learning architecture to improve the performance of retinal vessel segmentation. Deep learning architecture has been demonstrated having the powerful ability in automatically learning the rich hierarchical representations. In this paper, we formulate the vessel segmentation to a boundary detection problem, and utilize the fully convolutional neural networks (CNNs) to generate a vessel probability map. Our vessel probability map distinguishes the vessels and background in the inadequate contrast region, and has robustness to the pathological regions in the fundus image. Moreover, a fully-connected Conditional Random Fields (CRFs) is also employed to combine the discriminative vessel probability map and long-range interactions between pixels. Finally, a binary vessel segmentation result is obtained by our method. We show that our proposed method achieve a state-of-the-art vessel segmentation performance on the DRIVE and STARE datasets.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493362","Conditional Random Fields;Convolutional Neural Networks;Vessel segmentation","Computer architecture;Image segmentation;Machine learning;Neural networks;Pathology;Retinal vessels","blood vessels;eye;image segmentation;medical image processing;neural nets","DRIVE dataset;STARE dataset;binary vessel segmentation;boundary detection;convolutional neural networks;deep learning network;fully-connected conditional random fields;fundus image;pathological region;retinal vessel segmentation;vessel probability map","","2","","18","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"A comparative study of Named Entity Recognition for Arabic using ensemble learning approaches","I. El Bazi; N. Laachfoubi","Computer, Networks, Mobility and Modeling Laboratory, FST, Hassan 1st University, Settat, Morocco","2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)","20160709","2015","","","1","6","The ensemble learning has been successfully applied to many Natural Language Processing (NLP) tasks. For the Arabic Named Entity Recognition (NER) task, most studies in the literature have only focused on traditional classification methods and until now no one to the best of our knowledge has studied the ensemble learning for the Arabic NER task. In this paper, we apply six ensemble learning approaches to the Arabic NER task and we present a comparative study between these six ensemble learning approaches and six traditional classification approaches on two Arabic NER datasets (ANERcorp and AQMAR). The empirical results show that the ensemble learning methods significantly outperform the traditional classification methods. The Random Forests method achieves the best F1-measure results of 86.57% and 82.51% on each dataset, respectively.","","Electronic:978-1-5090-0478-2; POD:978-1-5090-0479-9; USB:978-1-5090-0477-5","10.1109/AICCSA.2015.7507143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507143","Arabic;Ensemble Learning;Named Entity;Named Entity Recognition;Natural Language Processing;WEKA","Algorithm design and analysis;Bagging;Decision trees;Learning systems;Machine learning algorithms;Measurement;Prediction algorithms","learning (artificial intelligence);linguistics;natural language processing;pattern classification","Arabic NER;Arabic named entity recognition;NLP;ensemble learning approaches;natural language processing;random forest method","","","","","","","17-20 Nov. 2015","","IEEE","IEEE Conference Publications"
"ATLANTIC: A framework for anomaly traffic detection, classification, and mitigation in SDN","A. Santos da Silva; J. A. Wickboldt; L. Z. Granville; A. Schaeffer-Filho","Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil","NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium","20160704","2016","","","27","35","Anomaly traffic detection and classification mechanisms need to be flexible and easy to manage in order to detect the ever growing spectrum of anomalies. Detection and classification are difficult tasks because of several reasons, including the need to obtain an accurate and comprehensive view of the network, the ability to detect the occurrence of new attack types, and the need to deal with misclassification. In this paper, we argue that Software-Defined Networking (SDN) form propitious environments for the design and implementation of more robust and extensible anomaly classification schemes. Different than other approaches from the literature, which individually tackle either anomaly detection or classification or mitigation, we present a management framework to perform these tasks jointly. Our proposed framework is called ATLANTIC and it combines the use of information theory to calculate deviations in the entropy of flow tables and a range of machine learning algorithms to classify traffic flows. As a result, ATLANTIC is a flexible framework capable of categorizing traffic anomalies and using the information collected to handle each traffic profile in a specific manner, e.g., blocking malicious flows.","","Electronic:978-1-5090-0223-8; POD:978-1-5090-0224-5","10.1109/NOMS.2016.7502793","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502793","Anomaly detection;Network Management;OpenFlow;Software-Defined Networking","Computer architecture;Computer crime;Entropy;Information theory;Machine learning algorithms;Monitoring;Support vector machines","computer network management;learning (artificial intelligence);software defined networking;telecommunication traffic","ATLANTIC framework;SDN;flow table entropy;framework for anomaly traffic detection classification and mitigation;information theory;machine learning algorithm;management framework;software-defined networking;traffic anomalies","","","","26","","","25-29 April 2016","","IEEE","IEEE Conference Publications"
"Speeding up online training of L1 Support Vector Machines","G. Melki; V. Kecman","Computer Science Department, Virginia Commonwealth University, Richmond, USA","SoutheastCon 2016","20160709","2016","","","1","6","Paper proposes a novel experimental environment for solving a classic nonlinear Soft Margin L1 Support Vector Machine (SVM) problem using a Stochastic Gradient Descent (SGD) algorithm. Our implementation has a unique method of random sampling and alpha calculations. The developed code produces a competitive accuracy as well as very fast training of SVMs (small CPU time). The SGD model's performance is compared to the solutions of the L2 SVM obtained by software for Minimal Norm (MN-SVM) and Non-Negative Iterative Single Data Algorithm (NN-ISDA). The latter two algorithms have shown excellent performances on large datasets; which is why we chose to have our implementation of the SGD algorithm compete with them. All experiments have been done under strict double (nested) cross-validation, and the results are reported in terms of accuracy and CPU times used by the three methods.","","Electronic:978-1-5090-2246-5; POD:978-1-5090-2247-2","10.1109/SECON.2016.7506732","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506732","classification;large scale learning;soft-margin support vector machines;stochastic gradient descent;support vector machines","Data models;Kernel;Machine learning algorithms;Software algorithms;Stochastic processes;Support vector machines;Training","gradient methods;learning (artificial intelligence);stochastic processes;support vector machines","L2 SVM;MN-SVM;NN-ISDA;SGD algorithm;alpha calculations;minimal norm software;nonlinear soft margin L1 SVM problem;nonnegative iterative single data algorithm;online training;random sampling;stochastic gradient descent algorithm;support vector machines","","","","","","","March 30 2016-April 3 2016","","IEEE","IEEE Conference Publications"
"Unsupervised Word Clustering Using Deep Features","M. Kulkarni; S. S. Karande; S. Lodha","TCS Innovation Labs., Pune, India","2016 12th IAPR Workshop on Document Analysis Systems (DAS)","20160613","2016","","","263","268","Digitization is crucial especially in the Indian context. OCR engines fail on Indian scripts mainly because character segmentation is non-trivial. Even word based recognition approaches suffer from the issues such as time degradations, word segmentation errors, font style/size variations. In this paper, we propose a deep learning architecture based approach for unsupervised word clustering. An edge responsive untrained Convolutional Neural Network (CNN) is used as a feature extractor. Graph connected component analysis is applied on the similarity graph computed from the word features. Our approach inherently detects similar shape patterns at word level and hence, it is language agnostic. We validated our approach against multiple state of art word matching techniques. Experimental results show that our approach significantly outperforms all of them on variety of data sets. In addition, the approach is observed to be robust to word segmentation errors, font style/size variations.","","Electronic:978-1-5090-1792-8; POD:978-1-5090-1793-5","10.1109/DAS.2016.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490128","Deep learning;word clustering","Computer architecture;Convolution;Feature extraction;Machine learning;Neural networks;Object recognition;Training","convolution;document image processing;feature extraction;graph theory;image segmentation;learning (artificial intelligence);natural language processing;neural nets;optical character recognition;pattern clustering","Indian scripts;OCR engines;character segmentation;deep features;deep learning architecture;digitization;edge responsive untrained convolutional neural network;feature extraction;font size variations;font style variations;graph connected component analysis;similarity graph;unsupervised word clustering;word based recognition;word segmentation errors","","","","21","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"Traffic signal timing via deep reinforcement learning","L. Li; Y. Lv; F. Y. Wang","Department of Automation, Tsinghua University, Beijing 100084, China","IEEE/CAA Journal of Automatica Sinica","20160712","2016","3","3","247","254","In this paper, we propose a set of algorithms to design signal timing plans via deep reinforcement learning. The core idea of this approach is to set up a deep neural network (DNN) to learn the Q-function of reinforcement learning from the sampled traffic state/control inputs and the corresponding traffic system performance output. Based on the obtained DNN, we can find the appropriate signal timing policies by implicitly modeling the control actions and the change of system states. We explain the possible benefits and implementation tricks of this new approach. The relationships between this new approach and some existing approaches are also carefully discussed.","2329-9266;23299266","","10.1109/JAS.2016.7508798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508798","Traffic control;deep learning;deep reinforcement learning;reinforcement learning","Analytical models;Learning (artificial intelligence);Machine learning;Mathematical model;Neural networks;Optimization;Timing","learning (artificial intelligence);neural nets;road traffic control;traffic engineering computing","DNN;Q-function;deep neural network;deep reinforcement learning;signal timing policies;traffic signal timing;traffic system performance output","","","","","","","July 10 2016","","IEEE","IEEE Journals & Magazines"
"The modularity-based Hierarchical tree algorithm for multi-class classification","C. Gu; B. Zhang; X. Wan; M. Huang; G. Zou","School of Computer Engineering & Science, Shanghai University, 200444, China","2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20160721","2016","","","625","629","Multi-class classification problem is still a research hotspot in machine learning, and researchers dedicate themselves to create new algorithms with higher efficiency and accuracy. A Modularity-based Hierarchical Classification Tree (MHCT) is proposed in this paper, which derived from the idea of community detection, and the structure of the tree is similar to the hierarchical cluster tree. This classification approach is a supervised learning method combined with modularity for its convergence indicator. After the building process of the tree from bottom to top, several classifier predictors are created in the training step. Finally, the comparison experiments are conducted between our methods and other two kinds of popular multi-class classification algorithms (i.e. support vector machine and decision tree), using ten benchmark datasets from UCI (University of California, Irvine) machine learning repository. In this work, the experimental results indicate that the proposed methods have drastically reduced the excessive training time while maintaining accuracy is comparable to the other algorithms.","","Electronic:978-1-5090-2239-7; POD:978-1-5090-0804-9","10.1109/SNPD.2016.7515969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515969","Hierarchical Tree;Modularity;Multi-class Classification","Algorithm design and analysis;Decision trees;Feature extraction;Machine learning algorithms;Prediction algorithms;Support vector machines;Training","decision trees;learning (artificial intelligence);pattern classification;support vector machines","MHCT;UCI machine learning repository;University of California Irvine;community detection;convergence indicator;decision tree;hierarchical cluster tree;machine learning;modularity-based hierarchical tree algorithm;multiclass classification algorithm;supervised learning method;support vector machine","","","","","","","May 30 2016-June 1 2016","","IEEE","IEEE Conference Publications"
"Communication-Avoiding Parallel Sparse-Dense Matrix-Matrix Multiplication","P. Koanantakool; A. Azad; A. Buluç; D. Morozov; S. Y. Oh; L. Oliker; K. Yelick","Comput. Res. Div., Lawrence Berkeley Nat. Lab., Berkeley, CA, USA","2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","20160721","2016","","","842","853","Multiplication of a sparse matrix with a dense matrix is a building block of an increasing number of applications in many areas such as machine learning and graph algorithms. However, most previous work on parallel matrix multiplication considered only both dense or both sparse matrix operands. This paper analyzes the communication lower bounds and compares the communication costs of various classic parallel algorithms in the context of sparse-dense matrix-matrix multiplication. We also present new communication-avoiding algorithms based on a 1D decomposition, called 1.5D, which - while suboptimal in dense-dense and sparse-sparse cases - outperform the 2D and 3D variants both theoretically and in practice for sparse-dense multiplication. Our analysis separates one-time costs from per iteration costs in an iterative machine learning context. Experiments demonstrate speedups up to 100x over a baseline 3D SUMMA implementation and show parallel scaling over 10 thousand cores.","1530-2075;15302075","Electronic:978-1-5090-2140-6; POD:978-1-5090-2141-3","10.1109/IPDPS.2016.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516081","Parallel algorithms;communication-avoiding algorithms;linear algebra;sparse-dense matrix-matrix multiplication","Algorithm design and analysis;Covariance matrices;Machine learning algorithms;Parallel algorithms;Partitioning algorithms;Sparse matrices;Three-dimensional displays","iterative methods;learning (artificial intelligence);matrix multiplication;parallel algorithms;sparse matrices","1D decomposition;SUMMA;communication cost;communication lower bound;communication-avoiding algorithm;communication-avoiding parallel sparse-dense matrix-matrix multiplication;dense matrix operand;dense-dense matrix multiplication;graph algorithm;iteration cost;iterative machine learning;parallel algorithm;parallel scaling;sparse matrix operand;sparse-sparse matrix multiplication","","","","","","","23-27 May 2016","","IEEE","IEEE Conference Publications"
"Making the Case for Feature-Rich Memory Systems: The March Toward Specialized Systems","R. Balasubramonian","University of Utah, Utah USA","IEEE Solid-State Circuits Magazine","20160620","2016","8","2","57","65","Many emerging workloads are constrained by the high cost of data access. Innovation in the memory system may soon be the primary driver of the computing economy. The result will be a memory system that is specialized, not commoditized. This article discusses the features that can be meaningfully added to memory devices. Not only do these features execute parts of an application, they may also take care of auxiliary operations that maintain high efficiency, reliability, and security.","1943-0582;19430582","","10.1109/MSSC.2016.2546198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495045","","Bandwidth;Computer architecture;Costs;Data processing;Machine learning algorithms;Performance evaluation;Technological innovation","","","","","","","","","Spring 2016","","IEEE","IEEE Journals & Magazines"
"Human activity recognition using deep belief networks","H. Yalçın","G&#246;rsel Zeka Laboratuar&#305; Elektronik ve Haberle&#351;me M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, &#304;stanbul Teknik &#220;niversitesi, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1649","1652","Human activity recognition using new generation depth sensors are particularly important for application that require human activity recognition. In this paper, a deep learning based algorithm is developed human activity recognition using RGB-D video sequences. Based on the assumption that every human activity is composed of many smaller actions, a temporal structure is being learnt in order to improve the classification of human activities. Since our approach is an attempt to develop a deep learning structure to the problem, it can be considered as a deep structural arhitecture. A deep neural network is obtained manipulating the activitation functions which yield hidden variables at every hidden layer. Our approach outperforms the methods that are constructed upon engineered features, since it uses the skeleton coordinates extracted from depth images. Tested on a new dataset, it is observed that our appproach outputs better recognition rates compared to those of other state-of-art methods.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496073","Deep Neural Networks;human activity recognition","Feature extraction;Machine learning;Neural networks;Robots;Three-dimensional displays","belief networks;image sequences;learning (artificial intelligence);neural nets;video signal processing","RGB-D video sequence;deep belief network;deep learning algorithm;deep neural network;depth sensor;human activities classification;human activity recognition;skeleton coordinate","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Balancing inverted pendulum using reinforcement algorithms","R. Özakar; G. T. Özyer; B. Özyer","Bilgisayar M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, Erzurum Teknik &#220;niversitesi, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1569","1572","With the advancements in technology, robots has become systems that can learn and achieve complex behaviors in real life with the help of machine learning algorithms. Among those algorithms, reinforcement learning algorithms are widely used in robotics to teach the systems by trials and errors. In this work, our goal is to use the two different reinforcement algorithms, Q-learning and Adaptive Heuristic Critic (AHC) algorithm, on well-known cart-pole balancing problem and examine the performance results. We used Box2d physics engine simulator to simulate the cart-pole model and the environment. Observing the experimental results, AHC algorithm was able to balance the system for more step counts than Q-learning algorithm.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496053","inverted pendulum;reinforcement learning","Adaptation models;Amplitude shift keying;Benchmark testing;Heuristic algorithms;Learning (artificial intelligence);Machine learning algorithms;Robots","learning (artificial intelligence);mobile robots;nonlinear systems;pendulums","AHC algorithm;Box2d physics engine simulator;Q-learning algorithm;adaptive heuristic critic algorithm;cart-pole balancing problem;complex behaviors;inverted pendulum balancing;machine learning algorithms;reinforcement learning algorithms","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Understand scene categories by objects: A semantic regularized scene classifier using Convolutional Neural Networks","Yiyi Liao; S. Kodagoda; Yue Wang; Lei Shi; Yong Liu","State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, 310027, China","2016 IEEE International Conference on Robotics and Automation (ICRA)","20160609","2016","","","2318","2325","Scene classification is a fundamental perception task for environmental understanding in today's robotics. In this paper, we have attempted to exploit the use of popular machine learning technique of deep learning to enhance scene understanding, particularly in robotics applications. As scene images have larger diversity than the iconic object images, it is more challenging for deep learning methods to automatically learn features from scene images with less samples. Inspired by human scene understanding based on object knowledge, we address the problem of scene classification by encouraging deep neural networks to incorporate object-level information. This is implemented with a regularization of semantic segmentation. With only 5 thousand training images, as opposed to 2.5 million images, we show the proposed deep architecture achieves superior scene classification results to the state-of-the-art on a publicly available SUN RGB-D dataset. In addition, performance of semantic segmentation, the regularizer, also reaches a new record with refinement derived from predicted scene labels. Finally, we apply our model trained on SUN RGB-D dataset to a set of images captured in our university using a mobile robot, demonstrating the generalization ability of the proposed algorithm.","","Electronic:978-1-4673-8026-3; POD:978-1-4673-8027-0","10.1109/ICRA.2016.7487381","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487381","","Image segmentation;Machine learning;Neural networks;Robots;Semantics;Sun;Training","image segmentation;learning (artificial intelligence);neurocontrollers;object detection;robot vision","convolutional neural networks;iconic object images;machine learning technique;object knowledge;object level information;robotics;robotics applications;semantic regularized scene classifier;semantic segmentation;understand scene categories","","","","22","","","16-21 May 2016","","IEEE","IEEE Conference Publications"
"Experimenting with musically motivated convolutional neural networks","J. Pons; T. Lidy; X. Serra","Music Technology Group, Universitat Pompeu Fabra, Barcelona","2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI)","20160630","2016","","","1","6","A common criticism of deep learning relates to the difficulty in understanding the underlying relationships that the neural networks are learning, thus behaving like a black-box. In this article we explore various architectural choices of relevance for music signals classification tasks in order to start understanding what the chosen networks are learning. We first discuss how convolutional filters with different shapes can fit specific musical concepts and based on that we propose several musically motivated architectures. These architectures are then assessed by measuring the accuracy of the deep learning model in the prediction of various music classes using a known dataset of audio recordings of ballroom music. The classes in this dataset have a strong correlation with tempo, what allows assessing if the proposed architectures are learning frequency and/or time dependencies. Additionally, a black-box model is proposed as a baseline for comparison. With these experiments we have been able to understand what some deep learning based algorithms can learn from a particular set of data.","","Electronic:978-1-4673-8695-1; POD:978-1-4673-8696-8","10.1109/CBMI.2016.7500246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7500246","","Computer architecture;Instruments;Machine learning;Music;Neural networks;Shape;Time-frequency analysis","audio signal processing;filtering theory;learning (artificial intelligence);music;neural net architecture;signal classification","audio recording dataset;audio tempo;ballroom music;black-box model;convolutional filters;deep learning;learning frequency dependencies;learning time dependencies;music class prediction;music signal classification tasks;musical concepts;musically-motivated convolutional neural network architecture","","","","23","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"A method of automatic feature extraction from massive vibration signals of machines","F. Jia; Y. Lei; S. Xing; J. Lin","State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an 710049, China","2016 IEEE International Instrumentation and Measurement Technology Conference Proceedings","20160725","2016","","","1","6","In the studies of intelligent fault diagnosis of machines, lots of effort goes into designing effective feature extraction algorithms. Such processes would consume plenty of human labor, especially when dealing with massive vibration signals. So it is interesting to automatically extract features using machine learning techniques, instead of manually extracting them. To deal with the problem, this paper presents a new automatic feature extraction method of machines. The proposed method first learns features from the vibration signals by K-means, and then maps the learned features into a salient low-dimensional feature space using t-distributed stochastic neighbor embedding (t-SNE). Through the feature extraction results of a bearing dataset, it is verified that the proposed method is able to effectively learn the features from the raw vibration signals and is superior to the manual features like time-domain features and wavelet features. Therefore, the proposed method has potential to be a tool in the automatic data mining of intelligent fault diagnosis.","","Electronic:978-1-4673-9220-4; POD:978-1-4673-9221-1","10.1109/I2MTC.2016.7520452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7520452","automatic feature extraction;intelligent fault diagnosis;k-means;t-SNE","Algorithm design and analysis;Fault diagnosis;Feature extraction;Machine learning algorithms;Manganese;Support vector machines;Vibrations","data mining;design engineering;electric machines;fault diagnosis;feature extraction;learning (artificial intelligence);mechanical engineering computing;signal processing;stochastic processes;time-domain analysis;vibrations;wavelet transforms","K-means vibration signal;automatic data mining;automatic feature extraction algorithm;bearing dataset;intelligent fault diagnosis;machine learning technique;salient lowdimensional feature space;t-SNE;t-distributed stochastic neighbor embedding;time-domain feature;wavelet feature","","","","","","","23-26 May 2016","","IEEE","IEEE Conference Publications"
"A novel approach for website aesthetic evaluation based on convolutional neural networks","M. G. Khani; M. R. Mazinani; M. Fayyaz; M. Hoseini","AmirKabir University of Technology, Tehran, Iran","2016 Second International Conference on Web Research (ICWR)","20160623","2016","","","48","53","In this paper we propose a website aesthetic evaluation method. For achieving better performance, we have applied convolutional neural networks, which are one of the methods of deep learning research area. Using deep learning and convolutional neural networks for feature representation is one of the main tips that makes difference between our work and previous ones. Our system takes a screenshot of the website as input, and finally reports it is a good or bad website based on users' country or not. For evaluation process, we represent the website screenshot using MemNet convolutional neural network. Then we decrease the extracted features dimension using principal component analysis algorithm. Finally, we classify them using a SVM classifier, which trained, based on users' ratings. Furthermore, aesthetics evaluation in this research is language independent. It means the website's language is not important and our method works for all languages.","","Electronic:978-1-5090-2166-6; POD:978-1-5090-2167-3","10.1109/ICWR.2016.7498445","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498445","Aesthetics;Convolutional Neural Network;Deep Learning;Website","Complexity theory;Feature extraction;Image color analysis;Machine learning;Neural networks;Support vector machines;Visualization","Web sites;learning (artificial intelligence);neural nets;pattern classification;principal component analysis;support vector machines","MemNet convolutional neural network;SVM classifier;Web site aesthetic evaluation;Web site screenshot;aesthetics evaluation;convolutional neural networks;deep learning research area;feature representation;principal component analysis algorithm","","","","24","","","27-28 April 2016","","IEEE","IEEE Conference Publications"
"Software Reliability Model Selection Based on Deep Learning","Y. Tamura; M. Matsumoto; S. Yamada","Grad. Sch. of Sci. & Eng., Yamaguchi Univ., Ube, Japan","2016 International Conference on Industrial Engineering, Management Science and Application (ICIMSA)","20160707","2016","","","1","5","In the past, many software reliability models have been proposed by several researchers. Several model selection criteria such as Akaike's information criterion, mean square errors, predicted relative error and so on, are used for the selection of optimal software reliability models. These assessment criteria can be useful for the software managers to assess the past trend of fault data. However, it is very important to assess the prediction accuracy of model after the end of fault data in the actual software project. In this paper, we propose a method of optimal software reliability model selection based on the deep learning. Also, we show several numerical examples of software reliability assessment in the actual software projects. Moreover, we compare the methods to estimate the cumulative numbers of detected faults based on the deep learning by using the fault data sets of actual software projects.","","Electronic:978-1-5090-1671-6; POD:978-1-5090-1672-3","10.1109/ICIMSA.2016.7504034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504034","","Data models;Machine learning;Mathematical model;Neural networks;Numerical models;Software;Software reliability","learning (artificial intelligence);project management;software management;software reliability","Akaike information criterion;deep learning;fault data;mean square errors;optimal software reliability model selection;predicted relative error;software projects;software reliability assessment","","1","","","","","23-26 May 2016","","IEEE","IEEE Conference Publications"
"Generating Flight Operations Quality Assurance (foqa) data from the X-Plane Simulation","A. Nanduri; L. Sherry","Center for Air Transportation Systems Research (CATSR) at George Mason University (GMU), Fairfax, Virginia, USA","2016 Integrated Communications Navigation and Surveillance (ICNS)","20160609","2016","","","5C1-1","5C1-9","Analysis of Flight Operations Quality Assurance (FOQA) data from millions of flights from at least 10 U.S. airlines has enabled researchers, using data mining and machine learning algorithms, to identify abnormal scenarios that maybe precursors to accidents and incidents. Innovation of these algorithms is hindered by restricted access to the FOQA data to comply with confidentiality, proprietary and security policies. This paper describes a method to generate larges sets of FOQA-like data for development and testing of machine learning and data mining algorithms. This data is not restricted and can be made publicly available. The data is generated using a C++ plug-in to the X-Plane Simulation. The plug-in manipulates the simulation set-up configuration, the pilot commands, and coordinates a Monte Carlo shell to run multiple runs. An example for generating data for CAT III ILS approach for KSFO Runway 28L and 28R is described. Implications of this capability, limitations and future work are discussed.","","Electronic:978-1-5090-2149-9; POD:978-1-5090-2150-5","10.1109/ICNSURV.2016.7486355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486355","","Aerospace control;Aircraft;Aircraft propulsion;Atmospheric modeling;Data mining;Gears;Machine learning algorithms","C++ language;Monte Carlo methods;aerospace computing;data mining;learning (artificial intelligence);quality assurance","C++ plug-in;CAT III ILS approach;FOQA;KSFO Runway 28L;KSFO Runway 28R;Monte Carlo shell;US airlines;X-plane simulation;data mining;flight operations quality assurance;innovation;machine learning algorithms;security policies","","1","","5","","","19-21 April 2016","","IEEE","IEEE Conference Publications"
"Scalable High-Performance Image Registration Framework by Unsupervised Deep Feature Representations Learning","G. Wu; M. Kim; Q. Wang; B. C. Munsell; D. Shen","Department of Radiology and BRIC, The University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Biomedical Engineering","20160621","2016","63","7","1505","1516","Feature selection is a critical step in deformable image registration. In particular, selecting the most discriminative features that accurately and concisely describe complex morphological patterns in image patches improves correspondence detection, which in turn improves image registration accuracy. Furthermore, since more and more imaging modalities are being invented to better identify morphological changes in medical imaging data, the development of deformable image registration method that scales well to new image modalities or new image applications with little to no human intervention would have a significant impact on the medical image analysis community. To address these concerns, a learning-based image registration framework is proposed that uses deep learning to discover compact and highly discriminative features upon observed imaging data. Specifically, the proposed feature selection method uses a convolutional stacked autoencoder to identify intrinsic deep feature representations in image patches. Since deep learning is an unsupervised learning method, no ground truth label knowledge is required. This makes the proposed feature selection method more flexible to new imaging modalities since feature representations can be directly learned from the observed imaging data in a very short amount of time. Using the LONI and ADNI imaging datasets, image registration performance was compared to two existing state-of-the-art deformable image registration methods that use handcrafted features. To demonstrate the scalability of the proposed image registration framework, image registration experiments were conducted on 7.0-T brain MR images. In all experiments, the results showed that the new image registration framework consistently demonstrated more accurate registration results when compared to state of the art.","0018-9294;00189294","","10.1109/TBME.2015.2496253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314894","Deep learning;Deformable image registration;deep learning;deformable image registration;hierarchical feature representation","Biomedical imaging;Feature extraction;Image registration;Machine learning;Three-dimensional displays;Unsupervised learning","","","","2","","70","","20151102","July 2016","","IEEE","IEEE Journals & Magazines"
"Comparing clustering algorithms on wisconsin data set","M. Erken","Havac&#305;l&#305;k ve Uzay Teknolojileri Enstit&#252;s&#252;, Hava Harp Okulu, &#304;stanbul, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1541","1544","Amount and diversity of data produced and processed has been dramatically increased parallel to improvements in technology. Unfortunately produced data usually don't have any labels which may make the classification and building information process more easily. This resulted with higher importance on data clustering for builing information. In this work K-Means, Spectral Clustering and Girvan-Newman algorithms has been studied and compared on Breaast Cancer Wisconsin Data Set (BCWDS).","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496046","Clustering;Girvan-Newman;K-Means;Spectral Clustering","Algorithm design and analysis;Art;Cancer;Clustering algorithms;Conferences;Machine learning algorithms;Reactive power","","","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Robust transfer learning in multi-robot systems by using sparse autoencoder","L. V. Utkin; S. G. Popov; Y. A. Zhuk","Telematics Department, Peter the Great Saint-Petersburg Polytechnic University, Russia","2016 XIX IEEE International Conference on Soft Computing and Measurements (SCM)","20160725","2016","","","224","227","Robust algorithms for transfer learning in multirobot systems based on elements of the deep learning are proposed in the paper. The algorithms are based on using the sparse autoencoder. The main ideas underlying the algorithms are to extend the set of set-valued observations by training examples having uncertain weights and to apply the robust minimax strategy in order to find an optimal autoencoder for dealing with set-valued observations. An interesting scheme for transfer learning is considered for which source learning set is reconstructed by means of the sparse autoencoder trained on the target learning set.","","Electronic:978-1-4673-8919-8; POD:978-1-4673-8920-4","10.1109/SCM.2016.7519735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519735","deep learning;extreme points;minimax strategy;multi-robot system;sparse autoencoder;transfer learning","Machine learning;Robots;Robustness;Sensors;Training;Training data;Uncertainty","learning (artificial intelligence);minimax techniques;multi-robot systems;neural nets;robust control;set theory","deep-learning;multirobot systems;optimal autoencoder;robust minimax strategy;robust transfer learning;set-valued observations;source learning set;sparse autoencoder;target learning set;uncertain weights","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Predicting future place of visit using user's personality profile","A. Chauhan; D. Toshniwal; R. Tejwani","Computer Engineering and Engineering, Indian Institute of Technology, Roorkee, India","2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT)","20160718","2016","","","427","432","There has been much effort on predicting users' location (country or region) using social media sites, like Twitter. However, exciting work has not addressed the prediction of users' place of visit at finer granularity like restaurant or park. To address this problem, in this paper, we present the methodology of predicting user's place of visit using: (i) personality attributes of users obtained from her tweets using SystemU; and (ii) time and day at which prediction is to be made. Based on these features, we build a model that predicts the likelihood of a user's place of visit at given time and day. We performed extensive experiments involving, real data derived from twitter timelines of more than 3000 users. Models are trained using different machine learning algorithms and results demonstrate the effectiveness of work with accuracy more than 80% for top 5 predictions.","","Electronic:978-1-5090-0082-1; POD:978-1-5090-0083-8","10.1109/ICCTICT.2016.7514619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514619","","Feature extraction;Google;Machine learning algorithms;Predictive models;Testing;Training;Twitter","learning (artificial intelligence);social networking (online)","SystemU;Twitter;machine learning algorithms;personality profile;social media sites","","","","","","","11-13 March 2016","","IEEE","IEEE Conference Publications"
"Visualizing extracted feature by deep learning in P300 discrimination task","K. Kawasaki; T. Yoshikawa; T. Furuhashi","Graduate School of Engineering, Nagoya University, Japan","2015 7th International Conference of Soft Computing and Pattern Recognition (SoCPaR)","20160616","2015","","","149","154","P300 speller is a system that allows users to input words using electroencephalogram (EEG). A component called P300 is used to interpret the EEG in P300 speller. In order to make a high performance P300 speller, it is essential to discriminate P300 from nonP300 precisely and automatically. In this study, deep learning (DL) is used to discriminate P300. The experimental result shows that DL was possible to discriminate P300 in EEG data, especially in the higher level layer. Furthermore, this study refers to the extracted feature by DL. We can see that DL learns feature from the waveforms correctly to discriminate P300 from others.","","Electronic:978-1-4673-9360-7; POD:978-1-4673-9361-4","10.1109/SOCPAR.2015.7492799","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492799","","Data mining;Data visualization;Electroencephalography;Feature extraction;Indexes;Machine learning;Principal component analysis","brain-computer interfaces;data visualisation;electroencephalography;feature extraction;learning (artificial intelligence)","DL;EEG;P300 discrimination task;P300 speller;brain-computer interfaces;deep learning;electroencephalogram;feature extraction","","","","9","","","13-15 Nov. 2015","","IEEE","IEEE Conference Publications"
"Superior vision: Always on human-like vision for intelligent devices","V. Mureşan","Movidius SRL, Timisoara, Gh Lazar Street, Nb 24, Romania","2016 IEEE 11th International Symposium on Applied Computational Intelligence and Informatics (SACI)","20160709","2016","","","229","230","Summary form only given. We live in a world of intelligent robots, drones and mobile phones/assistants. The technologies behind these products are heralded by a new wave of deep learning applications ported on mobile devices. The robotic and vision technologies behind these products will shift the applications of electronic devices to a more superior level of intelligence that will change our world. From a hardware point of view, these devices will become a hub of learning sensors that will be able to capture and learn from their surrounding environment and their context. On top of the aforementioned deep learning technologies, the most important sense for these devices will be their vision capabilities. To make this sense as close as possible to human vision, will require advanced technology to capture, process, understand and provide analytics in real time to enable their applications make critical “educated: decisions”. “Always on” vision capabilities are envisaged as the paradigm for the next generation of mobile This Keynote will cover in this context the state of the art in the domain of vision with the latest image processing, computer vision and deep learning algorithms implemented on various low-power processing architectures.","","Electronic:978-1-5090-2380-6; POD:978-1-5090-2381-3; USB:978-1-5090-2379-0","10.1109/SACI.2016.7507375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507375","","Computational intelligence;Context;Informatics;Intelligent robots;Machine learning;Mobile communication;Niobium","intelligent robots;learning (artificial intelligence);robot vision","computer vision;deep learning applications;drones;electronic devices;image processing;intelligent devices;intelligent robots;low-power processing architectures;mobile assistants;mobile phones","","","","","","","12-14 May 2016","","IEEE","IEEE Conference Publications"
"Tutorials","","","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","20","22","Provides an abstract for each of the tutorial presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7495681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495681","","Computer vision;Computers;Field programmable gate arrays;Machine learning;Signal processing;Wireless communication;Wireless sensor networks","","","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Pedestrian recognition method based on depth hierarchical feature representation","Rui Sun; Guang-Hai Zhang; Jun Gao","School of Computer and Information, Hefei University of Technology, 230009, China","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20160620","2015","","","173","178","For feature representation of pedestrian recognition, a hybrid hierarchical feature representation method which combines representation ability of bag of words model and depth layered with learning adaptability is presented. This method first uses HOG local descriptor for local features extraction, and then encoding the feature by a depth of layered coding method, the layered coding method by spatial aggregating restricted Boltzmann machine (RBM). For each coding layer, we steer the unsupervised RBM learning and apply supervised fine-tuning to enhance the visual features representation in classification task. Finally, we learn high-level image feature representation by the positive and negative max pooling, and then classify with the linear support vector machine, feature extraction of depth architectures effectively improve the accuracy of subsequent recognition. Experimental results show that the proposed method has a high recognition rate.","","Electronic:978-1-4673-8266-3; POD:978-1-4673-8267-0","10.1109/ICCWAMTIP.2015.7493969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493969","Hybrid structure;deep learning;depth hierarchical coding;positive and negative max pooling;restricted Boltzmann machine (RBM)","Dictionaries;Encoding;Feature extraction;Machine learning;Support vector machines;Training;Visualization","Boltzmann machines;feature extraction;image classification;image representation;pedestrians;support vector machines;unsupervised learning","HOG local descriptor;bag of words model;classification task;coding layer;depth architectures;depth hierarchical feature representation;feature encoding;high-level image feature representation;hybrid hierarchical feature representation;layered coding method;learning adaptability;linear support vector machine;local features extraction;negative max pooling;pedestrian recognition method;positive max pooling;spatial aggregating restricted Boltzmann machine;supervised fine-tuning;unsupervised RBM learning;visual features representation","","","","13","","","18-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Hybrid Vertex Outlier Detection Method Based on Distributed Representation and Local Outlier Factor","Z. Li; L. Zeng","Coll. of Inf. Syst. & Manage., Nat. Univ. of Defense Technol., Changsha, China","2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)","20160721","2015","","","512","516","Outlier detection is a basic task in network analysis, which is useful in many applications such as intrusion detection, criminal investigation, and information filtering. In this paper we proposed a hybrid outlier detection methods in complex networks based on Vertex Distributed Representation and Local Outlier Factor, with the aim to find abnormal vertexes that are apart from the group or community in complex networks. The proposed outlier detection method based on Vertex Distributed Representation (VDR) and Local Outlier Factor (LOF) is named as VDR-LOF. VDR-LOF maps vertexes or edges into a density continuous real-valued space, and then uses LOF algorithm to detection the outliers. We conducted experiments on American College Football Network and Enron Email Network, visualized the original networks and its corresponding feature map in 2D space, then we found the vertex outliers in the network.","","Electronic:978-1-4673-7211-4; POD:978-1-4673-7212-1","10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518283","Deep Learning;Distributed Representation;Local Outlier Factor;Outlier Detection","Complex networks;Electronic mail;Feature extraction;Image edge detection;Linear programming;Machine learning;Visualization","complex networks;network theory (graphs)","American College Football Network;Enron Email Network;LOF algorithm;VDR-LOF;complex networks;criminal investigation;density continuous real-valued space;hybrid vertex outlier detection method;information filtering;intrusion detection;local outlier factor;network analysis;vertex distributed representation","","","","","","","10-14 Aug. 2015","","IEEE","IEEE Conference Publications"
"Deep architecture using Multi-Kernel Learning and multi-classifier methods","I. Rebai; Y. BenAyed; W. Mahdi","Multimedia InfoRmation system and Advanced Computing Laboratory, University of Sfax, Tunisia","2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)","20160709","2015","","","1","6","Kernel Methods have been successfully applied in different tasks and used on a variety of data sample sizes. Multiple Kernel Learning (MKL) and Multilayer Multiple Kernel Learning (MLMKL), as new families of kernel methods, consist of learning the optimal kernel from a set of predefined kernels by using an optimization algorithm. However, learning this optimal combination is considered to be an arduous task. Furthermore, existing algorithms often do not converge to the optimal solution (i.e., weight distribution). They achieve worse results than the simplest method, which is based on the average combination of base kernels, for some real-world applications. In this paper, we present a hybrid model that integrates two methods: Support Vector Machine (SVM) and Multiple Classifier (MC) methods. More precisely, we propose a multiple classifier framework of deep SVMs for classification tasks. We adopt the MC approach to train multiple SVMs based on multiple kernel in a multi-layer structure in order to avoid solving the complicated optimization tasks. Since the average combination of kernels gives high performance, we train multiple models with a predefined combination of kernels. Indeed, we apply a specific distribution of weights for each model. To evaluate the performance of the proposed method, we conducted an extensive set of classification experiments on a number of benchmark data sets. Experimental results show the effectiveness and efficiency of the proposed method as compared to various state-of-the-art MKL and MLMKL algorithms.","","Electronic:978-1-5090-0478-2; POD:978-1-5090-0479-9; USB:978-1-5090-0477-5","10.1109/AICCSA.2015.7507155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507155","Deep Multiple Kernel Learning;Kernel methods;Multiple Classifier;Support Vector Machine","Computer architecture;Kernel;Machine learning;Nonhomogeneous media;Optimization;Support vector machines;Training","learning (artificial intelligence);optimisation;pattern classification;support vector machines","MC methods;MKL;MLMKL;SVM;data sample sizes;deep architecture;multiclassifier methods;multikernel learning;multilayer multiple kernel learning;multilayer structure;multiple classifier methods;multiple kernel learning;optimization algorithm;support vector machine","","","","","","","17-20 Nov. 2015","","IEEE","IEEE Conference Publications"
"Identifying activity boundaries for activity recognition in smart environments","Y. Wang; Z. Fan; A. Bandara","Toshiba Research Europe, Telecommunications Research Laboratory, 32 Queen Square, Bristol, BS1 4ND, UK","2016 IEEE International Conference on Communications (ICC)","20160714","2016","","","1","6","Activity recognition in smart environments is an important technology for assisted living and e-health. Recently there are growing interests in applying machine learning algorithms to activity recognition tasks. In this paper, we combine support vector machine (SVM) and association rule learning to improve the performance of activity recognition based on streaming sensor data in smart homes. The proposed approach allows us to accurately identify the activity boundaries, hence reducing activity recognition errors in the system.","","Electronic:978-1-4799-6664-6; POD:978-1-4799-6665-3","10.1109/ICC.2016.7510732","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7510732","","Data mining;Itemsets;Machine learning algorithms;Sparse matrices;Support vector machines;Training","assisted living;data mining;learning (artificial intelligence);medical computing;pattern recognition;support vector machines","SVM;activity boundary identification;activity recognition error reduction;activity recognition performance improvement;assisted living;e-health;machine learning algorithm;smart environment;smart homes;streaming sensor data;support vector machine","","","","","","","22-27 May 2016","","IEEE","IEEE Conference Publications"
"N-opcode analysis for android malware classification and categorization","B. Kang; S. Y. Yerima; K. Mclaughlin; S. Sezer","Centre for Secure Information Technologies (CSIT) Queen's University Belfast Belfast, Northern Ireland, United Kingdom","2016 International Conference On Cyber Security And Protection Of Digital Services (Cyber Security)","20160709","2016","","","1","7","Malware detection is a growing problem particularly on the Android mobile platform due to its increasing popularity and accessibility to numerous third party app markets. This has also been made worse by the increasingly sophisticated detection avoidance techniques employed by emerging malware families. This calls for more effective techniques for detection and classification of Android malware. Hence, in this paper we present an n-opcode analysis based approach that utilizes machine learning to classify and categorize Android malware. This approach enables automated feature discovery that eliminates the need for applying expert or domain knowledge to define the needed features. Our experiments on 2520 samples that were performed using up to 10-gram opcode features showed that an f-measure of 98% is achievable using this approach.","","Electronic:978-1-5090-0709-7; POD:978-1-5090-0710-3","10.1109/CyberSecPODS.2016.7502343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502343","Android malware;Dalvik bytecode;malware categorization;malware classification;n-gram;n-opcode","Androids;Entropy;Feature extraction;Humanoid robots;Machine learning algorithms;Malware;Support vector machines","Android (operating system);invasive software;learning (artificial intelligence);mobile computing;pattern classification","10-gram opcode features;Android malware categorization;Android malware classification;Android malware detection;Android mobile platform;automated feature discovery;machine learning;n-opcode analysis;sophisticated detection avoidance;third party app markets","","","","","","","13-14 June 2016","","IEEE","IEEE Conference Publications"
"PANDA: Extreme Scale Parallel K-Nearest Neighbor on Distributed Architectures","M. M. A. Patwary; N. R. Satish; N. Sundaram; J. Liu; P. Sadowski; E. Racah; S. Byna; C. Tull; W. Bhimji; Prabhat; P. Dubey","","2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","20160721","2016","","","494","503","Computing k-Nearest Neighbors (KNN) is one of the core kernels used in many machine learning, data mining and scientific computing applications. Although kd-tree based O(log n) algorithms have been proposed for computing KNN, due to its inherent sequentiality, linear algorithms are being used in practice. This limits the applicability of such methods to millions of data points, with limited scalability for Big Data analytics challenges in the scientific domain. In this paper, we present parallel and highly optimized kd*tree based KNN algorithms (both construction and querying) suitable for distributed architectures. Our algorithm includes novel approaches for pruning search space and improving load balancing and partitioning among nodes and threads. Using TB-sized datasets from three science applications: astrophysics, plasma physics, and particle physics, we show that our implementation can construct kd-tree of 189 billion particles in 48 seconds on utilizing ~50,000 cores. We also demonstrate computation of KNN of 19 billion queries in 12 seconds. We demonstrate almost linear speedup both for shared and distributed memory computers. Our algorithms outperforms earlier implementations by more than order of magnitude, thereby radically improving the applicability of our implementation to state-of-the-art Big Data analytics problems.","1530-2075;15302075","Electronic:978-1-5090-2140-6; POD:978-1-5090-2141-3","10.1109/IPDPS.2016.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516046","Big Data Analytics;Classification;KNN;Parallel Algorithms;and Load Balancing;kd-tree","Complexity theory;Computational modeling;Distributed databases;Machine learning algorithms;Partitioning algorithms;Physics;Plasmas","Big Data;computational complexity;data analysis;data mining;learning (artificial intelligence);pattern classification;physics computing;resource allocation","Big Data analytics;KNN algorithms;O(log n) algorithms;PANDA;astrophysics;data mining;distributed architectures;distributed memory computers;extreme scale parallel K-nearest neighbor;kd-tree;linear algorithms;load balancing;machine learning;particle physics;plasma physics;pruning search space;scientific computing applications","","","","","","","23-27 May 2016","","IEEE","IEEE Conference Publications"
"Deep learning for human activity recognition: A resource efficient implementation on low-power devices","D. Ravi; C. Wong; B. Lo; G. Z. Yang","The Hamlyn Centre, Imperial College London, London","2016 IEEE 13th International Conference on Wearable and Implantable Body Sensor Networks (BSN)","20160721","2016","","","71","76","Human Activity Recognition provides valuable contextual information for wellbeing, healthcare, and sport applications. Over the past decades, many machine learning approaches have been proposed to identify activities from inertial sensor data for specific applications. Most methods, however, are designed for offline processing rather than processing on the sensor node. In this paper, a human activity recognition technique based on a deep learning methodology is designed to enable accurate and real-time classification for low-power wearable devices. To obtain invariance against changes in sensor orientation, sensor placement, and in sensor acquisition rates, we design a feature generation process that is applied to the spectral domain of the inertial data. Specifically, the proposed method uses sums of temporal convolutions of the transformed input. Accuracy of the proposed approach is evaluated against the current state-of-the-art methods using both laboratory and real world activity datasets. A systematic analysis of the feature generation parameters and a comparison of activity recognition computation times on mobile devices and sensor nodes are also presented.","","Electronic:978-1-5090-3087-3; POD:978-1-5090-3088-0","10.1109/BSN.2016.7516235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516235","ActiveMiles;Deep Learning;HAR;Low-Power Devices","Convolution;Data mining;Feature extraction;Machine learning;Spectrogram;Time-frequency analysis","convolution;feature extraction;image recognition;learning (artificial intelligence);sensor placement","contextual information;deep learning;feature generation;human activity recognition;inertial sensor data;low-power wearable devices;machine learning;mobile devices;offline processing;resource efficient implementation;sensor acquisition rates;sensor nodes;sensor placement;spectral domain;temporal convolutions","","","","","","","14-17 June 2016","","IEEE","IEEE Conference Publications"
"A scalable GPU-enabled framework for training deep neural networks","B. Del Monte; R. Prodan","Department of Computer Science, University of Salerno, Italy","2016 2nd International Conference on Green High Performance Computing (ICGHPC)","20160709","2016","","","1","8","In the last fifteen years, Big Data created a new generation of data analysis problems, which does not only involve the problems themselves but also the way these data are handled. Since managing terabytes of data without a proper infrastructure is unfeasible, a smart way to process these data is also necessary. A solution to this aspect deals with the creation of general algorithms that learn from observations. In this context, Deep Learning promises general, powerful, and fast machine learning algorithms, moving them one step closer to artificial intelligence. Nevertheless, fitting a deep learning model may require an huge amount of time, thus, the need of scalable infrastructures for processing large scale data sets has become ever more meaningful. In this paper, we present a framework for training these deep neural networks using heterogeneous computing resources of either grid or cloud infrastructures. The framework lets the end-users define the deep architecture they need for processing their own Big Data, while dealing with the execution of the learning algorithms on a distributed set of nodes (through Apache Flink) as well as with offloading the computation on multiple Graphics Processing Units.","","CD-ROM:978-1-4673-6614-4; Electronic:978-1-4673-6615-1; POD:978-1-4673-6616-8","10.1109/ICGHPC.2016.7508071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508071","","Computational modeling;Computer architecture;Graphics processing units;Instruction sets;Machine learning;Neural networks;Training","cloud computing;data analysis;graphics processing units;grid computing;learning (artificial intelligence);neural nets","Apache Flink;Big Data;GPU-enabled framework;artificial intelligence;cloud infrastructure;data analysis problems;data handling;deep architecture;deep learning;deep neural network training;graphics processing units;grid infrastructure;heterogeneous computing resources;machine learning","","","","","","","26-27 Feb. 2016","","IEEE","IEEE Conference Publications"
"A Novel Sparse Representation Classification Face Recognition Based on Deep Learning","J. Zeng; Y. Zhai; J. Gan","Sch. of Inf. Eng., Wuyi Univ., Jiangmen, China","2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)","20160721","2015","","","1520","1523","The existing face recognition under pose and illumination variations is a challenging problem. A novel sparse recognition face recognition algorithm based on deep learning is presented in this paper. The deep learning network extracted global and local information, the deep learning network adopted the supervised Convolution restricted Boltzmann machine. The features extracted could recover the face image and reduce intraidentity variances, while maintaining discriminativeness between identities. The algorithm obtained the feature by the deep network and realized fast sparse classification by smoothed l0 norm. Experimental results on FERET face database show that the proposed algorithm can improve recognition rate and recognition speed when dealing with various conditions such as pose variation.","","Electronic:978-1-4673-7211-4; POD:978-1-4673-7212-1","10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518453","face recognition; deep learning; feature extraction;","Classification algorithms;Face;Face recognition;Feature extraction;Image recognition;Lighting;Machine learning","face recognition;image representation;learning (artificial intelligence);pose estimation","Boltzmann machine;FERET face database;deep learning;deep learning network;deep network;face image;illumination variations;novel sparse representation classification face recognition;pose variation;pose variations;sparse classification","","","","","","","10-14 Aug. 2015","","IEEE","IEEE Conference Publications"
"Deep vessel tracking: A generalized probabilistic approach via deep learning","A. Wu; Z. Xu; M. Gao; M. Buty; D. J. Mollura","Department of Radiology and Imaging Sciences, National Institutes of Health, Bethesda, MD 20892","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1363","1367","Analysis of vascular geometry is important in many medical imaging applications, such as retinal, pulmonary, and cardiac investigations. In order to make reliable judgments for clinical usage, accurate and robust segmentation methods are needed. Due to the high complexity of biological vasculature trees, manual identification is often too time-consuming and tedious to be used in practice. To design an automated and computerized method, a major challenge is that the appearance of vasculatures in medical images has great variance across modalities and subjects. Therefore, most existing approaches are specially designed for a particular task, lacking the flexibility to be adapted to other circumstances. In this paper, we present a generic approach for vascular structure identification from medical images, which can be used for multiple purposes robustly. The proposed method uses the state-of-the-art deep convolutional neural network (CNN) to learn the appearance features of the target. A Principal Component Analysis (PCA)-based nearest neighbor search is then utilized to estimate the local structure distribution, which is further incorporated within the generalized probabilistic tracking framework to extract the entire connected tree. Qualitative and quantitative results over retinal fundus data demonstrate that the proposed framework achieves comparable accuracy as compared with state-of-the-art methods, while efficiently producing more information regarding the candidate tree structure.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493520","Deep Learning;Generalized Probabilistic Tracking;Nearest Neighbor Search;Principal Component Analysis;Vascular Structure","Biomedical imaging;Dictionaries;Image segmentation;Machine learning;Probabilistic logic;Robustness","","","","","","10","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Online experts for admission control in SDN","S. Paris; J. Leguay; L. Maggi; M. Draief; S. Chouvardas","Mathematical and Algorithmic Science Lab, France Research Center, Huawei Technologies Co. Ltd., Boulogne-Billancourt, France","NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium","20160704","2016","","","1003","1004","SDN unleashes the potential to perform computational intensive machine learning algorithms to solve complex routing problems. This demo presents an architecture for the SDN controller that integrates several online routing algorithms for the real-time admission control of new connection requests. The demonstrator permits to compare the evolution of the network according to the admission decisions taken by different online algorithms and to simulate future scenarios to support strategic decisions aimed at improving the infrastructure.","","Electronic:978-1-5090-0223-8; POD:978-1-5090-0224-5","10.1109/NOMS.2016.7502944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502944","Admission Control;Online Algorithms;Software Defined Networking","Admission control;Algorithm design and analysis;Computer architecture;Graphical user interfaces;Machine learning algorithms;Real-time systems;Routing","expert systems;learning (artificial intelligence);software defined networking;telecommunication congestion control;telecommunication network routing","SDN controller;admission decisions;complex routing problems;computational intensive machine learning algorithms;connection requests;online experts;online routing algorithms;real-time admission control;strategic decisions","","","","6","","","25-29 April 2016","","IEEE","IEEE Conference Publications"
"Comments and Corrections","C. Chen; J. Zhang; Y. Xie; Y. Xiang; W. Zhou; M. M. Hassan; A. AlElaiwi","School of Information Technology, Deakin University, Melbourne, Australia","IEEE Transactions on Computational Social Systems","20160620","2016","3","1","42","42","Presents correcttions to the paper, “A performance evaluation of machine learning-based streaming spam tweets detection,” (Chen ], C.; et al) , IEEE Trans. Comput. Social Syst., vol. 2, no. 3, pp. 65–76, Sep. 2015.","2329-924X;2329924X","","10.1109/TCSS.2016.2549603","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458200","","Information technology;Machine learning","","","","","","1","","20160422","March 2016","","IEEE","IEEE Journals & Magazines"
"A 803 GOp/s/W Convolutional Network Accelerator","L. Cavigelli; L. Benini","Lukas Cavigelli is with the Department of Electrical Engineering and Information Technology, ETH Zurich, 8092 Zurich, Switzerland.(email: cavigelli@iis.ee.ethz.ch)","IEEE Transactions on Circuits and Systems for Video Technology","","2016","PP","99","1","1","An ever increasing number of computer vision and image/video processing challenges are being approached using deep convolutional neural networks, obtaining state-of-the-art results in object recognition and detection, semantic segmentation, action recognition, optical flow and super resolution. Hardware acceleration of these algorithms is essential to adopt these improvements in embedded and mobile computer vision systems. We present a new architecture, design and implementation as well as the first reported silicon measurements of such an accelerator, outperforming previous work in terms of power-, area- and I/Oefficiency. The manufactured device provides up to 196 GOp/s on 3.09mm2 of silicon in UMC 65nm technology and can achieve a power efficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make it the first architecture scalable to TOp/s performance.","1051-8215;10518215","","10.1109/TCSVT.2016.2592330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514941","Computer Vision;Convolutional Networks;VLSI","Computer architecture;Computer vision;Feature extraction;Machine learning;Mobile communication;Neural networks;Throughput","","","","1","","","","20160718","","","IEEE","IEEE Early Access Articles"
"A deep learning approach to EEG based epilepsy seizure determination","M. H. Cılasun; H. Yalçın","G&#246;rsel Zeka Laboratuar&#305;, Elektronik ve Haberle&#351;me M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, &#304;stanbul Teknik &#220;niversitesi, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1573","1576","Epilepsy is a common chronic neurological disorder. Epilepsy seizures are the result of the transient and unexpected electrical disturbance of the brain. About fifty million people worldwide have epilepsy, and nearly two out of every three new cases are discovered in developing countries. The detection of epilepsy is possible by analyzing EEG signals. Many researchers have been working on developing a variety of methods for the analysis the EEG signal. In this work, a deep convolutional neural network approach is implemented to detect epilepsy seizure based on EEG signals. Our approach outperforms the previous work used in the analysis of EEG signals, since it eliminates the need for application of preprocessing and dimensionality reduction steps on the data. Experimental results suggest that deep learning networks stand out as a promising approach for neurological diagnosis on EEG data.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496054","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496054","deep learning;deep neural networks;electroencephalogram (EEG);epilepsy seizure detection","Brain modeling;Electroencephalography;Epilepsy;Machine learning;Neural networks;Neuroscience;Wavelet transforms","electroencephalography;medical signal processing","EEG signals;common chronic neurological disorder;deep learning approach;dimensionality reduction steps;electrical disturbance;epilepsy detection;epilepsy seizure determination;neurological diagnosis;transient disturbance","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Clinical decision support for Alzheimer's disease based on deep learning and brain network","C. Hu; R. Ju; Y. Shen; P. Zhou; Q. Li","School of Engineering and Applied Sciences, Harvard University","2016 IEEE International Conference on Communications (ICC)","20160714","2016","","","1","6","Modern e-health systems have undergone rapid development thanks to the advances in communications, computing and machine learning technology. Especially, deep learning has great superiority in image analysis and disease prediction. In this paper, we use Alzheimer's Disease (AD) as an example to show advantages of deep learning in diagnosing brain diseases and providing clinical decision support. Firstly, we convert raw functional magnetic resonance imaging (fMRI) to a matrix to represent activity of 90 brain regions. Secondly, to represent the functional connectivity between different brain regions, a correlation matrix is obtained by calculating the correlation between each pair of brain regions. In the next, a targeted autoencoder network is built to classify the correlation matrix, which is sensitive to AD. Finally, the experiment results show that our proposed method for AD prediction achieves much better effects than traditional means. It finds the correlations between different brain regions efficiently, provides strong reference for AD prediction. Compared to Support Vector Machine (SVM), about 25% improvement is gained in prediction accuracy. The e-health field becomes more complete and effective owing to that. Our work helps predict AD at an early stage and take measures to slow down or even prevent the onset of it.","","Electronic:978-1-4799-6664-6; POD:978-1-4799-6665-3","10.1109/ICC.2016.7510831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7510831","","Correlation;Cost function;Diseases;Machine learning;Positron emission tomography;Support vector machines;Time series analysis","biomedical MRI;brain;decision support systems;diseases;learning (artificial intelligence);matrix algebra;medical image processing","AD prediction;Alzheimer's Disease;brain diseases diagnosing;brain network;clinical decision support;correlation matrix;deep learning;disease prediction;e-health field;fMRI;functional connectivity;image analysis;modern e-health systems;raw functional magnetic resonance imaging;targeted autoencoder network","","","","","","","22-27 May 2016","","IEEE","IEEE Conference Publications"
"Food calorie measurement using deep learning neural network","P. Pouladzadeh; P. Kuhad; S. V. B. Peddi; A. Yassine; S. Shirmohammadi","Distributed and Collaborative Virtual Environments Research (DISCOVER) Lab, University of Ottawa, Ottawa, Canada","2016 IEEE International Instrumentation and Measurement Technology Conference Proceedings","20160725","2016","","","1","6","Accurate methods to measure food and energy intake are crucial for the battle against obesity. Providing users/patients with convenient and intelligent solutions that help them measure their food intake and collect dietary information are the most valuable insights toward long-term prevention and successful treatment programs. In this paper, we propose an assistive calorie measurement system to help patients and doctors succeed in their fight against diet-related health conditions. Our proposed system runs on smartphones, which allow the user to take a picture of the food and measure the amount of calorie intake automatically. In order to identify the food accurately in the system, we use deep convolutional neural networks to classify 10000 high-resolution food images for system training. Our results show that the accuracy of our method for food recognition of single food portions is 99%. The analysis and implementation of the proposed system are also described in this paper.","","Electronic:978-1-4673-9220-4; POD:978-1-4673-9221-1","10.1109/I2MTC.2016.7520547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7520547","calorie measurement;deep neural network;food recognition;graph cut;segmentation","Image segmentation;Machine learning;Neural networks;Obesity;Smart phones;Solid modeling;Training","chemical variables measurement;food processing industry;neural nets;smart phones","assistive calorie measurement system;deep convolutional neural networks;deep learning neural network;diet-related health conditions;doctors;food calorie measurement;food recognition;high-resolution food images;patients;single food portions;smartphones;system training","","","","","","","23-26 May 2016","","IEEE","IEEE Conference Publications"
"Detection of age-related macular degeneration via deep learning","P. Burlina; D. E. Freund; N. Joshi; Y. Wolfson; N. M. Bressler","Applied Physics Laboratory, Johns Hopkins University","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","184","188","Age-related macular generation (AMD) - when left untreated - is the main cause of blindness for individuals over the age of 50. With the US population now counting over 100 million individuals over 50, it is imperative to develop methods that can effectively determine which individuals with an earlier, often asymptomatic stage, are at risk of developing the advanced stage that can cause severe vision loss. This paper studies the appropriateness of the transfer of image features computed from pre-trained deep neural networks to the problem in AMD detection. Tests using over 5600 images from the NIH AREDS dataset (the largest dataset used thus far for AMD image analysis studies) show good preliminary results (between nearly 92% and 95% accuracy).","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493240","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493240","Age-related macular degeneration;deep learning;pre-trained networks","Blindness;Classification algorithms;Feature extraction;Machine learning;Retina;Sensitivity;Support vector machines","biomedical optical imaging;feature extraction;learning (artificial intelligence);medical image processing;neural nets;vision defects","AMD detection;AMD image analysis;NIH AREDS dataset;age-related macular degeneration;asymptomatic stage;blindness;deep learning;image features;pretrained deep neural networks;severe vision loss","","","","11","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Deep neural network language model research and application overview","Fu-Lian Yin; Xing-Yi Pan; Xiao-Wei Liu; Hui-Xin Liu","Department of Information and Engineering, Faculty of Science and Technology, Communication University of China, Beijing, 100024, China","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20160620","2015","","","55","60","Research of the neural network language model in NLP is reviewed. In this paper, the neural network language models are classified into early shallow language models and deep neural network models based on deep learning. This paper emphatically introduces progress of the deep neural network language models, and summarizes the status of deep neural network research's development. Finally, the existing problems and deficiencies are put forward.","","Electronic:978-1-4673-8266-3; POD:978-1-4673-8267-0","10.1109/ICCWAMTIP.2015.7493906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493906","Deep Learning;Deep Neural Network Language Model;Natural Language Processing;Sentiment Analysis;Word Embedding","Analytical models;Computational modeling;Machine learning;Neural networks;Semantics;Syntactics;Training","learning (artificial intelligence);natural language processing;neural nets","NLP;deep learning;deep neural network language model;shallow language model","","","","24","","","18-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"Introducing a Novel Smart Design Framework for a Reconfigurable Multi-Processor Systems-on-Chip (MPSoC) Architecture","A. Dutta; M. Bayoumi","Univ. of Louisiana at Lafayette, Lafayette, LA, USA","2016 IEEE International Conference on Smart Computing (SMARTCOMP)","20160630","2016","","","1","3","In this work, a smart designing framework for a Systems- on-Chip has been proposed. We examined a reconfigurable MPSoC architecture which incorporates one Processor-FPGA core to ensure flexibility and better design parameters. The objective of this work is to propose and develop a smart framework which initiates this philosophy: the system would build a better system by itself. The system would learn about usage statistics by using an android application. Then the system would form a decision function and classify the user with the help of support vector machine-based machine learning algorithm. According to user's preference, it would re-design the reconfigurable MPSoC to ensure customized and superior user experience. The machine learning algorithm runs on cloud for saving computing power and resources. An image processing task has been performed as a case-study on a FPGA-SoC platform and on GPU as a proof of concept to ensure current standards. As of our knowledge, this is a novel and competent approach of designing system for hand-held devices which enables customization of the device after the manufacturer's end.","","Electronic:978-1-5090-0898-8; POD:978-1-5090-0899-5","10.1109/SMARTCOMP.2016.7501699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7501699","","Androids;Classification algorithms;Computer architecture;Field programmable gate arrays;Machine learning algorithms;Support vector machines;Training","Android (operating system);cloud computing;field programmable gate arrays;graphics processing units;human factors;image processing;learning (artificial intelligence);multiprocessing systems;power aware computing;reconfigurable architectures;support vector machines;system-on-chip","FPGA-SoC platform;GPU;android application;computing power;computing resources;customized user experience;decision function;design parameters;device customization;hand-held devices;image processing;multiprocessor systems-on-chip architecture;processor-FPGA core;reconfigurable MPSoC architecture;reconfigurable MPSoC redesign;smart designing framework;support vector machine-based machine learning algorithm;usage statistics;user classification","","","","6","","","18-20 May 2016","","IEEE","IEEE Conference Publications"
"Deep learning & convolutional networks","Y. LeCun","Facebook AI Research & Center for Data Science, NYU","2015 IEEE Hot Chips 27 Symposium (HCS)","20160707","2015","","","1","95","Presents a collection of slides covering the following topics: deep learning; convolutional neural network; image recognition; speech recognition; language translation; reasoning; unsupervised learning; and intelligent machine.","","Electronic:978-1-4673-8885-6; POD:978-1-4673-8886-3","10.1109/HOTCHIPS.2015.7477328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477328","","Face detection;Feature extraction;Machine learning;Natural language processing;Object recognition;Pattern recognition;Pose estimation;Speech recognition;Supervised learning","convolution;image recognition;inference mechanisms;language translation;neural nets;speech recognition;unsupervised learning","convolutional neural network;deep learning;image recognition;intelligent machine;language translation;reasoning;speech recognition;unsupervised learning","","","","","","","22-25 Aug. 2015","","IEEE","IEEE Conference Publications"
"DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection","W. Ouyang; X. Zeng; X. Wang; S. Qiu; P. Luo; Y. Tian; H. Li; S. Yang; Z. Wang; H. Li; C. C. Loy; K. Wang; J. Yan; X. Tang","Wanli Ouyang is with the Department of Electronic Engineering at the Chinese University of Hong Kong, Hong Kong.","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2016","PP","99","1","1","In this paper, we propose deformable deep convolutional neural networks for generic object detection. This new deep learning object detection framework has innovations in multiple aspects. In the proposed new deep architecture, a new deformation constrained pooling (def-pooling) layer models the deformation of object parts with geometric constraint and penalty. A new pre-training strategy is proposed to learn feature representations more suitable for the object detection task and with good generalization capability. By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of model averaging. The proposed approach improves the mean averaged precision obtained by RCNN [16], which was the state-of-the-art, from 31% to 50.3% on the ILSVRC2014 detection test set. It also outperforms the winner of ILSVRC2014, GoogLeNet, by 6.1%. Detailed component-wise analysis is also provided through extensive experimental evaluation, which provides a global view for people to understand the deep learning object detection pipeline.","0162-8828;01628828","","10.1109/TPAMI.2016.2587642","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506134","CNN;convolutional neural networks;deep learning;deep model;object detection","Context modeling;Deformable models;Machine learning;Neural networks;Object detection;Training;Visualization","","","","","","","","20160707","","","IEEE","IEEE Early Access Articles"
"Strategies for determining effective step size of the backpropagation algorithm for on-line learning","Y. Kaneda; Q. Zhao; Y. Liu; Y. Pei","Dept. of Computer and Information Systems, The University of Aizu, Aizu-Wakamatsu, Fukushima, Japan","2015 7th International Conference of Soft Computing and Pattern Recognition (SoCPaR)","20160616","2015","","","155","160","In this paper, we investigate proper strategies for determining the step size of the backpropagation (BP) algorithm for on-line learning. It is known that for off-line learning, the step size can be determined adaptively during learning. For on-line learning, since the same data may never appear again, we cannot use the same strategy proposed for off-line learning. If we do not update the neural network with a proper step size for on-line learning, the performance of the network may not be improved steadily. Here, we investigate four strategies for updating the step size. They are (1) constant, (2) random, (3) linearly decreasing, and (4) inversely proportional, respectively. The first strategy uses a constant step size during learning, the second strategy uses a random step size, the third strategy decreases the step size linearly, and the fourth strategy updates the step size inversely proportional to time. Experimental results show that, the third and the fourth strategies are more effective. In addition, compared with the third strategy, the fourth one is more stable, and usually can improve the performance steadily.","","Electronic:978-1-4673-9360-7; POD:978-1-4673-9361-4","10.1109/SOCPAR.2015.7492800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492800","Backpropagation Algorithm;Decision Boundary Making;Multilayer Percep-tron;On-Line Learning","Authentication;Computational modeling;Data models;Databases;Machine learning algorithms;Mathematical model;Neurons","backpropagation;learning (artificial intelligence);multilayer perceptrons","BP algorithm;backpropagation algorithm;constant step size;effective step size;inversely-proportional step size;linearly-decreasing step size;online learning;random step size","","","","5","","","13-15 Nov. 2015","","IEEE","IEEE Conference Publications"
"Fault diagnosis for discrete monitoring data based on fusion algorithm","He Sijie; Peng Yu; Liu Datong","Department of Automatic Test and Control, Harbin Institute of Technology, 150080, China","2015 12th IEEE International Conference on Electronic Measurement & Instruments (ICEMI)","20160620","2015","01","","125","130","Fault diagnosis has a significant role in enhancing the safety, reliability, and availability of complex systems. However, the problem of enormous condition monitoring data and multiple failure modes makes the diagnostics great challenge. The imbalance between normal and fault monitoring data will increase the false alarm rate and the false negative rate. On the other hand, discrete monitoring data such as events are frequent and critical to fault diagnosis of complex systems. In this work, we propose a fusion fault diagnostic method which combines Naïve Bayes with AdaBoost ensemble algorithm. This integrated method is appropriate for discrete data and improves the adaptability for imbalanced condition monitoring data. Experimental results based on PHM 2013 dataset show that fault diagnosis performance using the fusion method can be ameliorated.","","CD-ROM:978-1-4799-7618-8; Electronic:978-1-4799-7071-1; POD:978-1-4799-7072-8","10.1109/ICEMI.2015.7494226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7494226","AdaBoost;Fault diagnosis;Naïve Bayes;discrete monitoring data;fusion algorithm","Classification algorithms;Fault diagnosis;Machine learning algorithms;Monitoring;Prediction algorithms;Prognostics and health management;Training","condition monitoring;fault diagnosis;learning (artificial intelligence);production engineering computing;sensor fusion","AdaBoost ensemble algorithm;PHM 2013 dataset;discrete monitoring data;false alarm rate;false negative rate;fault diagnosis;fusion algorithm;fusion fault diagnostic method;imbalanced condition monitoring data;naive Bayes algorithm","","","","17","","","16-18 July 2015","","IEEE","IEEE Conference Publications"
"On user-centric analysis and prediction of QoE for video streaming using empirical measurements","M. Plakia; M. Katsarakis; P. Charonyktakis; M. Papadopouli; I. Markopoulos","Department of Computer Science, University of Crete, Institute of Computer Science, Foundation for Research and Technology-Hellas, Greece","2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX)","20160627","2016","","","1","6","Assessing the impact of different network conditions on user experience is important for improving the telecommunication services. We have developed a modular framework that includes monitoring and data collection tools and algorithms for user-centric analysis and prediction of the QoE in video streaming. The MLQoE employs several machine learning (ML) algorithms and tunes their hyper-parameters. It dynamically selects the ML algorithm that exhibits the best performance and its parameters automatically based on the input (e.g., network and systems metrics). We applied the MLQoE for predicting the QoE of the video streaming service in the context of two field studies, one performed in the production environment of a large telecom operator and the other at our Institute. The analysis indicated the parameters with the dominant impact on the perceived QoE and revealed that the QoE vary across users. This motivates the use of customized adaptation mechanisms in video streaming under network performance degradation. The MLQoE results in fairly accurate predictions e.g., a median error in predicting the QoE of 0.0991 and 0.5517 in the first (second) field study, respectively, on the MOS scale.","","Electronic:978-1-5090-0354-9; POD:978-1-5090-0355-6; USB:978-1-5090-0353-2","10.1109/QoMEX.2016.7498962","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498962","","Delays;Machine learning algorithms;Monitoring;Packet loss;Prediction algorithms;Streaming media","learning (artificial intelligence);quality of experience;video streaming","MLQoE;MOS scale;data collection tools;empirical measurements;machine learning algorithms;telecommunication services;user centric analysis;user centric prediction;video streaming","","","","29","","","6-8 June 2016","","IEEE","IEEE Conference Publications"
"Performance comparison of Support Vector Regression and Relevance Vector Regression for facial expression recognition","G. Gupta; N. Rathee","Department of Electronics and Communication Engineering, Maharaja Surajmal Institute of Technology, Delhi, India","2015 International Conference on Soft Computing Techniques and Implementations (ICSCTI)","20160613","2015","","","1","6","This paper compares the performance of Relevance Vector Regression and Support Vector Regression for the purpose of facial expression recognition. The Support Vector Machine (SVM) is a state-of-the-art technique for regression and classification, but lacks the probabilistic treatment which is overcome by Relevance Vector Machine (RVM). Though SVM's have a good generalization performance, but their results are in general less sparse. This sometimes results in almost all of the training data to be used as Support Vectors. Comparing with RVM, the results obtained are relatively more sparse than SVM which results in lesser number of Relevance Vectors ultimately leading to lesser computation overhead. The above models are compared for facial expression recognition on Cohn Kanade database. Local Binary Pattern features are extracted from facial images. These are preprocessed for illumination and size, and also for dimensionality reduction before being used for training the RVM and SVM models. The paper concludes with a comparison of the SVM and RVM on the basis of test results.","","CD-ROM:978-1-4673-6790-5; Electronic:978-1-4673-6792-9; POD:978-1-4673-6793-6","10.1109/ICSCTI.2015.7489548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489548","Facial Expression Recognition;Local Binary Pattern;RVM(Relevance Vector Maching);Regression;Relevance Vector Regression;SVM(Support Vector Maching);Support Vector Regression","Face recognition;Feature extraction;Image resolution;Machine learning algorithms;Support vector machines;Testing;Training","emotion recognition;face recognition;feature extraction;image classification;probability;regression analysis;support vector machines","Cohn Kanade database;RVM models;SVM models;facial expression recognition;facial images;local binary pattern feature extraction;probabilistic treatment;relevance vector regression;support vector regression","","","","19","","","8-10 Oct. 2015","","IEEE","IEEE Conference Publications"
"A model-free localization method for sensor networks with sparse anchors","M. X. Cheng; W. B. Wu","Missouri University of Science and Technology, Rolla, MO 65401","2016 IEEE International Conference on Communications (ICC)","20160714","2016","","","1","7","This paper considers the problem of sensor node localization, where a total of n anchor nodes are used to determine the locations of other nodes based on the received signal strengths. Challenges arise when anchor nodes are sparse and locations of them are not at grid positions. A range-based machine learning algorithm is developed to tackle the challenges. Instead of using samples to calibrate the parameters of a chosen signal model, we use machine learning to estimate the signal propagation function and its parameters at the same time. It overcomes the model dependency issue of existing range-based algorithms, and avoids the insufficient support issue of support vector machine methods. Simulation results show that the proposed algorithm has good adaptability to different signal characteristics, network deployment, and device variability. It significantly outperforms existing methods, especially when the anchor nodes are sparsely and irregularly deployed.","","Electronic:978-1-4799-6664-6; POD:978-1-4799-6665-3","10.1109/ICC.2016.7510964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7510964","","Computational modeling;Distance measurement;Estimation;Machine learning algorithms;Prediction algorithms;Receivers;Support vector machines","RSSI;learning (artificial intelligence);radiowave propagation;sensor placement;support vector machines;wireless sensor networks","anchor nodes;model-free localization method;network deployment;range-based machine learning algorithm;received signal strengths;sensor networks;sensor node localization;signal model;signal propagation function;sparse anchors;support vector machine methods","","","","","","","22-27 May 2016","","IEEE","IEEE Conference Publications"
"Is noise always harmful? Visual learning from weakly-related data","S. h. Zhong; Y. Liu; K. A. Hua; S. Wu","College of Computer Science and Software Engineering, Shenzhen University, China","2015 International Conference on Orange Technologies (ICOT)","20160623","2015","","","181","184","Noise exists universally in multimedia data, especially in Internet era. For example, tags from web users are often incomplete, arbitrary, and low relevant with the visual information. Intuitively, noise in the dataset is harmful to learning tasks, which implies that huge volumes of image tags from social media can't be utilized directly. To collect the reliable training dataset, labor-intensive manual labeling and various learning based outlier detection techniques are widely used. This paper intends to discuss whether such kind of preprocessing is always needed. We focus on a very normal case in image classification that the available dataset includes a large amount of images weakly related to any target classes. We use deep models as the platform and design a series of experiments to compare the semi-supervised learning performance with/without weakly related unlabeled data. Fortunately, we validate that weakly related data is not always harmful, which is an encouraging finding for research on web image learning.","","Electronic:978-1-4673-8237-3; POD:978-1-4673-8238-0","10.1109/ICOT.2015.7498518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498518","Weakly-related data;deep learning;semi-supervised learning","Data models;Erbium;Machine learning;Multimedia communication;Standards;Training;Training data","","","","","","18","","","19-22 Dec. 2015","","IEEE","IEEE Conference Publications"
"Human physical activity recognition based on computer vision with deep learning model","L. Mo; F. Li; Y. Zhu; A. Huang","School of Instrument Science and Engineering, Southeast University, Nanjing, 210096, China","2016 IEEE International Instrumentation and Measurement Technology Conference Proceedings","20160725","2016","","","1","6","Human activity recognition is an active research area in the computer science because it is widely used in the fields of the security monitoring, health assessment, human machine interaction and other human related content searching. In this paper, a computer vision model based on the deep learning algorithm is proposed, which can recognize the human physical activity based on the skeleton data of the human body from the sensor of Microsoft Kinect. This model uses the human skeletons data from the CAD-60 dataset to recognize the human physical activity without using any prior knowledge. It can reduce the works on the stage of data preprocessing and feature extraction. It can also improve the generalization performance and robustness of the model, and give a better understanding of the human physical activity. Different tricks which can improve the performance of the neural networks, such as some regularization methods and other activation functions are tested. Finally, a convolutional neural network is used for the feature extraction, and a multilayer perceptron is used as the following classifier. The model can recognize twelve types of activities and the accuracy rate is 81.8%. It demonstrates that it is very effective to use the convolutional neural network to supervised learning and this model applies to human physical activity recognition.","","Electronic:978-1-4673-9220-4; POD:978-1-4673-9221-1","10.1109/I2MTC.2016.7520541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7520541","Kinect;convolutional neural networks;deep learning;human physical activity recognition","Biological neural networks;Computational modeling;Feature extraction;Machine learning;Neurons;Skeleton;Training","computer vision;feature extraction;learning (artificial intelligence);motion measurement;multilayer perceptrons;pattern recognition","Microsoft Kinect;computer vision model;convolutional neural network;data preprocessing;deep learning algorithm;feature extraction;human physical activity recognition;multilayer perceptron;supervised learning","","","","","","","23-26 May 2016","","IEEE","IEEE Conference Publications"
"Fabric defect detection using deep learning","A. Şeker; K. A. Peker; A. G. Yüksek; E. Delibaş","Bilgisayar M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, Cumhuriyet &#220;niversitesi, Sivas, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1437","1440","Fabric defect detection have importance in terms of sectoral quality. Automatic systems are developed on the defect detection, in this regard many methods are tried to obtain high precision with image processing studies. In this study, deep learning which distinguishes with multi-layer architectures and reveals high achievement is applied to fabric defect detection. Autoencoder -a deep learning algorithm- that aimed to represent input data via compression or decompression is tried to detect defect of fabrics and it gains acceptable success. The vital goal of this study is to increase achievement of feature extraction by tuning up the autoencoder's input value and hyper parameters.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496020","autoencoder;deep learning;fabric defect detection;feature extraction","Computer vision;Fabrics;Feature extraction;Google;Machine learning;Neural networks;Pattern recognition","data compression;fabrics;feature extraction;image coding","autoencoder;automatic systems;compression;decompression;deep learning algorithm;fabric defect detection;feature extraction;image processing;multilayer architectures;sectoral quality","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"A novel approach for Sentimental Analysis and Opinion Mining based on SentiWordNet using web data","S. Ahmed; A. Danti","Department of Computer Applications, Jawaharlal Nehru National College of Engineering, Shimoga, Karnataka, India","2015 International Conference on Trends in Automation, Communications and Computing Technology (I-TACT-15)","20160616","2015","","","1","5","Opinion mining is an art of tracking the mood of the public about a particular product or topic from a huge set of opinions or reviews publically available in web. In this work, a novel approach is proposed based on SentiWordNet, which generates count of score words into seven categories such as strong-positive, positive, weak-positive, neutral, weak-negative, negative and strong-negative words for the opinion mining task and evaluated using machine learning algorithms like Naïve Bayes, SVM and Multilayer Perception (MLP). The web data is collected using web crawler applied with different pre-processing techniques which include removal of stop-words from online reviews, then stemming is performed using Porter Stemmer algorithm, and then reviews are tagged using Stanford POS tagger. The proposed approach is experimented on movie and product web domains and obtained higher success rate in terms of accuracy measured by various tools like Kappa statistics with an accuracy of 77.7% and has lower error rates. Weighted average of different accuracy measures like Precision, Recall, TP Rate, F-Measure rate depicts higher efficiency rate and lower FP Rate for Naïve Bayes and MLP models. The experimental results of Ten-Fold cross validation on the training data shows that Naïve Bayes & MLP outperforms the SVM model. Thus, the former are used for the Sentimental Analysis of web data. The results demonstrate that the proposed novel approach has higher efficacy and it can be successfully used in Opinion Mining for the task of decision making by any web user.","","CD-ROM:978-1-4673-6666-3; Electronic:978-1-4673-6667-0; POD:978-1-4673-6668-7","10.1109/ITACT.2015.7492646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492646","Opinion mining;POS tagging;Porter Stemmer;Score Count;Sentiment Analysis","Data mining;Machine learning algorithms;Motion pictures;Sentiment analysis;Support vector machines;Tagging;Weight measurement","","","","","","9","","","21-22 Dec. 2015","","IEEE","IEEE Conference Publications"
"Bench marking of classification algorithms: Decision Trees and Random Forests - a case study using R","M. V. Datla","Department of Computer Science Engineering, Manipal Institute of Technology, 576104, India","2015 International Conference on Trends in Automation, Communications and Computing Technology (I-TACT-15)","20160616","2015","","","1","7","Decision Trees and Random Forests are leading Machine Learning Algorithms, which are used for Classification purposes. Through the course of this paper, a comparison is made of classification results of these two algorithms, for classifying data sets obtained from Kaggle's Bike Sharing System and Titanic problems. The solution methodology deployed is primarily broken into two segments. First, being Feature Engineering where the given instance variables are made noise free and two or more variables are used together to give rise to a valuable third. Secondly, the classification parameters are worked out, consisting of correctly classified instances, incorrectly classified instances, Precision and Accuracy. This process ensured that the instance variables and classification parameters were best treated before they were deployed with the two algorithms i.e. Decision Trees and Random Forests. The developed model has been validated by using Systems data and the Classification results. From the model it can safely be concluded that for all classification problems Decision Trees is handy with small data sets i.e. less number of instances and Random Forests gives better results for the same number of attributes and large data sets i.e. with greater number of instances. R language has been used to solve the problem and to present the results.","","CD-ROM:978-1-4673-6666-3; Electronic:978-1-4673-6667-0; POD:978-1-4673-6668-7","10.1109/ITACT.2015.7492647","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492647","Decision Trees;Feature Engineering;Instance Variables;R language;Random Forests","Algorithm design and analysis;Classification algorithms;Data models;Decision trees;Machine learning algorithms;Training;Vegetation","","","","","","5","","","21-22 Dec. 2015","","IEEE","IEEE Conference Publications"
"Feature optimization on stock market predictor","R. Iacomin","Faculty of Automatics and Computer Science, University Politehnica of Bucharest, Romania","2016 International Conference on Development and Application Systems (DAS)","20160616","2016","","","243","247","This case study explains why a stock market predictor should have feature optimization methods to give a precise prediction of the trend. Having a large number of features might not be a good thing in stock market, thus it is important to know the most important feature and the number of them to use for the predictor. The result of this document shows that by generating multiple Support Vector Machines predictors fluctuating the number of features can decide the best predictor made from the most important features.","","DVD:978-1-5090-1992-2; Electronic:978-1-5090-1993-9; POD:978-1-5090-1994-6","10.1109/DAAS.2016.7492580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492580","Feature Optimization;Feature Selection;Support Vector Machines","Eigenvalues and eigenfunctions;Machine learning algorithms;Market research;Optimization;Principal component analysis;Stock markets;Support vector machines","","","","","","7","","","19-21 May 2016","","IEEE","IEEE Conference Publications"
"Recognition of radio signals with deep learning Neural Networks","G. Işık; H. Artuner","Bilgisayar M&#252;hendisli&#287;i B&#246;l&#252;m&#252;, Hacettepe &#220;niversitesi, Ankara, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","837","840","Nowadays, the use of Artificial Neural Networks shows continuity in many different applications. In particular, the use of deep learning type neural networks, seen as impractical previously, is increasing by processing power growth. Software Defined Radio (SDR) is another hot topic called as Digital Radio concept. With a growing interest in the environment was formed especially by radio amateurs. Analyzing signals and making sense out of them by SDR is accepted in many areas. In this study, design and implementation of a sample work has been subjected for identification of received radio signals on SDR with deep learning neural networks. (DLNN).","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7495870","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495870","Deep Learning Neural Networks;Radio Signal Analysis;Software Defined Radio","Computational modeling;Convolution;Machine learning;Neural networks;Software radio;Speech recognition","","","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"IP Prefix Hijack Detection Using BGP Attack Signatures and Connectivity Tracking","H. Alshamrani; B. Ghita","Centre for Security, Commun. & Network Res., Plymouth Univ., Plymouth, UK","2016 International Conference on Software Networking (ICSN)","20160630","2016","","","1","7","In spite of significant on-going research, the Border Gateway Protocol (BGP) still suffers vulnerability issues specially regarding impersonating the ownership of IP prefixes of ASes (Autonomous Systems). In this context, a number of research studies focused on securing the BGP through historical-based and statistical-based behavioural models. This paper proposes a novel method aiming to detect IP prefix hijacking incidents based on tracking the behaviour of suspicious ASes. The detection method uses signaturebased technique as a pre- process phase to separate suspicious announces (BGP updates) from benign announces. From a processing perspective, the outputs of signature-based algorithm are used as inputs for the detection method. Nine feature will be extracted from the ASpath attributes of potentially suspicious ASes. The features are considered a combination of the behavioral characteristics of the routers in relation to their connectivity. Based on these features and the best five supervised learning classifiers, we identify the hijacks. Under different learning algorithms, the detection method is able to detect the hijacks with a high accuracy especially with J48, which can detect the hijacks with 96%.","","Electronic:978-1-5090-1676-1; POD:978-1-5090-1677-8","10.1109/ICSN.2016.7501926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7501926","","Classification algorithms;Feature extraction;IP networks;Machine learning algorithms;Protocols;Security;Stability analysis","IP networks;computer network security;digital signatures;feature extraction;learning (artificial intelligence);pattern classification;routing protocols","ASpath attributes;BGP attack signatures;BGP updates;J48;autonomous systems IP prefix hijack detection;border gateway protocol;connectivity tracking;feature extraction;historical-based behavioural models;router behavioral characteristics;signature-based technique;statistical-based behavioural models;supervised learning classifiers;suspicious ASes behaviour tracking","","","","20","","","23-26 May 2016","","IEEE","IEEE Conference Publications"
"Design of self-adjusting algorithm for data-intensive MapReduce applications","A. N. Nagiwale; M. R. Umale","Computer Engineering, Lokamanya Tilak College of Engineering, Navi Mumbai, India","2015 International Conference on Energy Systems and Applications","20160704","2015","","","506","510","MapReduce framework is suitable for dataintensive applications for large scale processing, but these classes of applications like machine learning algorithms, graph algorithms, sentiment analysis algorithms, etc. have dealt with skewness, diversity of data to adapt changes in real time. For example, it is difficult to adapt to real time changes in training data/corpus for big data applications like Sentiment Analysis, Email spam detection, and log file analysis. To achieve this goal, we have proposed an algorithm that is based on concepts of functional programming and self-adjusting computations that supports effectively accepting changes for system ranging from making training set/ language corpus domain-specific, amortized analysis of algorithm to change in storage, network and architecture design for distributed systems. For experimental purposes, we have implemented Selfie, self -adjusting algorithm with Splay tree for Twitter Sentiment analysis, which makes system responsible for skewness in access pattern and diversity in trends. Proposed algorithm can be helpful for other iterative and interactive applications that faces machine learning challenges like feature generation and selection, over-fitting, explain and improve models to effectively deal with large dynamic data sets.","","Electronic:978-1-4673-6817-9; POD:978-1-4673-6818-6","10.1109/ICESA.2015.7503401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7503401","Apache Spark;Map Reduce;Self Adjusting Algorithm;Splay Tree","Algorithm design and analysis;Classification algorithms;Machine learning algorithms;Market research;Sentiment analysis;Twitter;Vegetation","data handling;learning (artificial intelligence);sentiment analysis;social networking (online)","Splay tree;Twitter sentiment analysis;big data applications;data-intensive MapReduce applications;functional programming;interactive applications;iterative applications;machine learning challenges;self-adjusting algorithm design;self-adjusting computations","","","","10","","","Oct. 30 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
