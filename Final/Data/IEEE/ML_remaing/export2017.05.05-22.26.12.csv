"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7869816,7882683,7881687,7882698,7877588,7877043,7878133,7878004,7879726,7877180,7877992,7877426,7877973,7877991,7879824,7878006,7866821,7876395,7875959,7876261,7876831,7875981,7872787,7742965,7872723,7872795,7873646,7872720,7871077,7872382,7870486,7870903,7869051,7871042,7869522,7869011,7870355,7870481,7870478,7502111,7868328,7868428,7867661,7866212,7868522,7868686,7868785,7866761,7866113,7847321,7868684,7867019,7868782,7866501,7868559,7868598,7868164,7868601,7867444,7775001,7745891,7829262,7863731,7864224,7863033,7863267,7827114,7862399,7862064,7860230,7860982,7860390,7862024,7860227,7860398,7860387,7738435,7858158,7858486,7858565,7505926,7778999,7854334,7853982,7855589,7853004,7852818,7853957,7857267,7852614,7852757,7852722,7852742,7856803,7733055,7854627,7849837,7851968,7850255,7852328",2017/05/05 22:26:12
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"From concrete to abstract: Multilayer neural networks for disaster victims detection","I. A. Sulistijono; A. Risnumawan","Graduate School of Engineering Technology Politeknik Elektronika Negeri Surabaya (PENS), Kampus PENS, Surabaya, Indonesia","2016 International Electronics Symposium (IES)","20170223","2016","","","93","98","Search-and-rescue (SAR) team main objective is to quickly locate victims in post-disaster scenario. In such disaster scenario, images are usually complex containing highly cluttered background such as debris, soil, gravel, ruined building, and clothes, which are difficult to distinguish from the victims. Previous methods which only work on nearly uniform background taken from either indoor or yard are not suitable and can deteriorate the detection system. In this paper, we demonstrate the feasibility of multilayer neural network for disaster victims detection on highly cluttered background. Theoretical justification from which deep learning learns from concrete to object abstraction is established. In order to build a more discriminative system, this theoretical justification then leads us to perform pretraining using data-rich datasheet followed by finetuning only on the last layers using data-specific datasheet while keeping the other layers fixed. A new Indonesian disaster victims datasheet is also provided. Experimental results show the efficiency of the method for disaster victims detection in highly cluttered background.","","CD:978-1-5090-1638-9; Electronic:978-1-5090-1640-2; POD:978-1-5090-1641-9","10.1109/ELECSYM.2016.7860982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860982","Disaster victims detection;cluttered background;concrete to abstraction;deep learning;multilayer neural networks","Concrete;Entropy;Machine learning;Neural networks;Nonhomogeneous media;Robots;Sensors","disasters;emergency management;image classification;learning (artificial intelligence);multilayer perceptrons;visual databases","Indonesian disaster victim datasheet;SAR team;cluttered background;concrete-to-object abstraction;data-rich datasheet;data-specific datasheet;deep learning;disaster victim detection;multilayer neural networks;postdisaster scenario;search-and-rescue team","","","","","","","29-30 Sept. 2016","","IEEE","IEEE Conference Publications"
"Developing a citizen science web portal for manual and automated ecological image detection","M. Mattingly; A. Barnas; S. Ellis-Felege; R. Newman; D. Iles; T. Desell","Department of Computer Science, University of North Dakota, Grand Forks, North Dakota 58202","2016 IEEE 12th International Conference on e-Science (e-Science)","20170306","2016","","","223","232","Image recognition is challenging in the field of wildlife ecology as samples of a specific species can be rare, making manual detection cumbersome. With over 2,060,000 images taken from motion-sensor trail cameras and unmanned aerial vehicle flights, a touch enabled web interface has been developed to allow citizen scientists and ecologists to categorize positive samples. To minimize categorization errors, the same images are shown to multiple separate users. The observations of each user are then compared using two novel validation strategies: percentage of overlapping area and maximum corner distance. Two novel methods for the extraction of final images from validated results are presented and compared as well: average corner points and area intersection. These methods were evaluated using a set of 142 images with a total of 811 observations of objects generated by citizen scientists that were manually inspected for ground truth. Results show that for this research a maximum corner distance of 10 pixels and the use of area intersection provided the best extracted imagery for future use as training and testing data by computer vision methods.","","Electronic:978-1-5090-4273-9; POD:978-1-5090-4274-6; USB:978-1-5090-4272-2","10.1109/eScience.2016.7870903","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870903","","Cameras;Libraries;Machine learning algorithms;Monitoring;Snow;Training;Wildlife","ecology;feature extraction;image recognition;portals;zoology","area intersection;automated ecological image detection;average corner points;categorization errors;citizen ecologists;citizen science Web portal;citizen scientists;image extraction;image recognition;motion-sensor trail cameras;touch enabled Web interface;unmanned aerial vehicle flights;wildlife ecology","","","","","","","23-27 Oct. 2016","","IEEE","IEEE Conference Publications"
"Answer Selection in Community Question Answering via Attentive Neural Networks","Y. Xiang; Q. Chen; X. Wang; Y. Qin","Intelligent Computing Research Center, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, China","IEEE Signal Processing Letters","20170314","2017","24","4","505","509","Answer selection in community question answering (cQA) is a challenging task in natural language processing. The difficulty lies in that it not only needs the consideration of semantic matching between question answer pairs but also requires a serious modeling of contextual factors. In this letter, we propose an attentive deep neural network architecture so as to learn the deterministic information for answer selection. The architecture can support various input formats through the organization of convolutional neural networks, attention-based long short-term memory, and conditional random fields. Experiments are carried out on the SemEval-2015 cQA dataset. We attain 58.35% on macroaveraged F<sub>1</sub>, which outperforms the Top-1 system in the shared task by 1.16% and improves the state-of-the-art deep-neural-network-based method by 2.21%.","1070-9908;10709908","","10.1109/LSP.2017.2673123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866821","Attention mechanism;answer selection;community question answering (cQA);deep neural networks (DNNs)","Computer architecture;Context modeling;Convolution;Knowledge discovery;Labeling;Machine learning;Neural networks","feedforward neural nets;learning (artificial intelligence);natural language processing;query processing","SemEval-2015 cQA dataset;answer selection;attention-based long short-term memory;attentive deep neural network architecture;community question answering;conditional random fields;contextual factors modeling;convolutional neural networks;natural language processing;question answer pairs;semantic matching","","","","","","20170302","April 2017","","IEEE","IEEE Journals & Magazines"
"Accurate visual tracking by combining Bayesian and evolutionary optimization framework","G. Jati; A. A. S. Gunawan; W. Jatmiko; A. Febrian","Faculty of Computer Science, Universitas Indonesia, Indonesia","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","523","528","Visual tracking is the process of locating, identifying, and determining of an object within video frames. From a Bayesian perspective, this is done by estimating the posterior density function. On the other hand, evolutionary optimization perspective would like to generate and select sufficiently optimize solution using two major components: diversification and intensification. This research will develop visual tracking algorithm using a Bayesian approach with evolutionary optimization in order to perform accurate tracking. The main idea is to combine Particle Markov Chain Monte Carlo (Particle-MCMC) as representation of Bayesian approach, with evolutionary optimization that is Particle Swarm Optimization (PSO) in each video frame. The visual tracking is regulated by Particle-MCMC filter algorithm and PSO will work within this filter to get more accurate tracking. Based on the dataset groundtruth, we found the accuracy of tracking can be increased considerably comparing to our previous research.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872795","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872795","","Bayes methods;Feature extraction;Machine learning;Monte Carlo methods;Optimization;Particle filters;Particle swarm optimization","Bayes methods;Markov processes;Monte Carlo methods;estimation theory;evolutionary computation;object tracking;particle filtering (numerical methods);particle swarm optimisation;video signal processing","Bayesian framework;diversification;evolutionary optimization framework;intensification;particle Markov chain Monte Carlo filter algorithm;particle swarm optimization;particle-MCMC filter algorithm;posterior density function estimation;video frames;visual tracking","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"CKIP Valence-Arousal Predictor for IALP 2016 Shared Task","H. Y. Wang; W. Y. Ma","Institute of Information Science, Academia Sinica, Nankang, Taipei, Taiwan","2016 International Conference on Asian Language Processing (IALP)","20170313","2016","","","164","167","Sentiment analysis is an important task in natural language processing and computational linguistics. Automatic sentiment analysis has been widely applied to opinion reviews and social media for a variety of applications, such as marketing and customer services. The dimensional approach can provide more fine-grained sentiment analysis in which each vocabulary is assigned two continuous numerical values - valence and arousal. Our goal is to predict the both values for the unseen vocabularies. In this paper we propose a combination of three rating predictors - E-HowNet knowledge based, word embedding based and single character based predictors to predict Chinese vocabularies. In the IALP 2016 Shared Task (Dimensional Sentiment Analysis for Chinese Words), out of 32 teams, our system ranks top1 on the prediction of valence, and ranks top14 on the prediction of arousal.","","Electronic:978-1-5090-0922-0; POD:978-1-5090-0923-7; USB:978-1-5090-0921-3","10.1109/IALP.2016.7875959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875959","Deep Learning;Dimensional Approach;Knowledge Base;Sentiment Analysis;Word Embedding","Information science;Knowledge based systems;Machine learning;Sentiment analysis;Testing;Training;Vocabulary","computational linguistics;data mining;sentiment analysis;social networking (online);vocabulary;word processing","CKIP valence-arousal predictor;Chinese vocabularies;Chinese words;E-HowNet knowledge based;IALP 2016 shared task;arousal numerical values;automatic sentiment analysis;computational linguistics;dimensional sentiment analysis;natural language processing;opinion mining;opinion reviews;rating predictors;single character based predictors;social media;valence numerical values;word embedding based","","","","","","","21-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"Feature extraction of protein secondary structure using 2D convolutional neural network","Y. Liu; Y. Chen; J. Cheng","Institute of Intelligent Information Processing, Qilu University Of Technology, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","20170216","2016","","","1771","1775","In this paper we propose a approach using 2D convolutional neural network(CNN) for the prediction of protein secondary structure. A representation of two dimensional PSSM is directly used to convolve with filters to extract the features. This new representation reflects not only the evolutionary information but also the sequence interaction of residue. The architecture of convolutional neural network has two convolutional layers and one max-pooling layer. The feature maps extracted from second convolutional layer are used to feed to Bayes classifier, in order to build prediction model. The Q3 accuracy 77.7% of 25PDB dataset is achieved based on 3 fold cross validation experiments using CNN features. The performance based on CNN features is better than 73.8% of 25PDB dataset using the original features. Experimental results illustrate that CNN features improve the prediction performance and have the potential ability of the invariance against mutation, insertion, deletion of residue.","","Electronic:978-1-5090-3710-0; POD:978-1-5090-3711-7; USB:978-1-5090-3709-4","10.1109/CISP-BMEI.2016.7853004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7853004","convolution neural network;feature extraction;protein secondary structure","Amino acids;Feature extraction;Filter banks;Machine learning;Neural networks;Protein engineering;Proteins","Bayes methods;biology computing;feature extraction;neural nets;proteins","2D PSSM;2D convolutional neural network;Bayes classifier;CNN features;convolutional layers;evolutionary information;feature extraction;feature maps;max-pooling layer;mutation;prediction model;protein secondary structure","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"Pedestrian detection based on deep learning model","Hailong Li; Zhendong Wu; Jianwu Zhang","School of Communication Engineering, Hangzhou Dianzi University, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","20170216","2016","","","796","800","Pedestrian detection remains an important task in the theory research and practical application of objects detection. Traditional pedestrian detection algorithms require experts design features to describe the pedestrian characteristics and combine with the classifiers. In recent years, deep learning and especially Convolutional Neural Networks (CNN) have made great success on image and audio, which is the important component of deep learning. Artificial designed methods of feature extracting has an imperfect description of pedestrian in the complex background. In this paper, we propose a pedestrian detection method based on deep convolutional neural network with multi-layers. It can make full use of the advantages of deep convolutional neural network and extract features from the database of pedestrian detection. At the stage of region proposal, to solve the problem of too much redundant windows generated by traditional methods, we use the edge boxes algorithm instead of sliding window algorithm to extract windows. At last, we get a smaller number of windows with high-quality, which is of great importance for the subsequent classification task. At the end of the paper, we carried out multi-sets of comparison experiments in this system. Experiments show that the pedestrian detection system based on deep learning outperforms the traditional methods based on both handcrafted and learned features.","","Electronic:978-1-5090-3710-0; POD:978-1-5090-3711-7; USB:978-1-5090-3709-4","10.1109/CISP-BMEI.2016.7852818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852818","Convolution Neural Network (CNN);Deep Learning;Feature Extracting;Pedestrian Detection","Classification algorithms;Convolution;Feature extraction;Image edge detection;Machine learning;Neural networks;Proposals","feedforward neural nets;image classification;learning (artificial intelligence);object detection;pedestrians","CNN;classification task;deep convolutional neural network;deep learning;deep learning model;experts design features;learned features;objects detection;pedestrian characteristics;pedestrian detection algorithms;redundant windows","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"Beyond maximum likelihood: Boosting the Chow-Liu algorithm for large alphabets","J. Jiao; Y. Han; T. Weissman","EE Department, Stanford University","2016 50th Asilomar Conference on Signals, Systems and Computers","20170306","2016","","","321","325","We show that in high dimensional distributions, i.e., the regime where the alphabet size of each node is comparable to the number of observations, the Chow-Liu algorithm on learning graphical models is highly sub-optimal. We propose a new approach, where the key ingredient is to replace the empirical mutual information in the Chow-Liu algorithm with a minimax rate-optimal estimator proposed recently by Jiao, Venkat, Han, and Weissman. We demonstrate the improved performance of the new approach in two problems: learning tree graphical models and Bayesian network classification.","","DVD:978-1-5386-3952-8; Electronic:978-1-5386-3954-2; POD:978-1-5386-3955-9","10.1109/ACSSC.2016.7869051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869051","Chow-Liu algorithm;approximation theory;high dimensional statistics;mutual information estimation;nonsmooth functional estimation","Complexity theory;Entropy;Graphical models;Machine learning algorithms;Maximum likelihood estimation;Mutual information","Bayes methods;learning (artificial intelligence);maximum likelihood estimation;minimax techniques;pattern classification;trees (mathematics)","Bayesian network classification;Chow-Liu algorithm;alphabet size;learning tree graphical model;maximum likelihood;minimax rate-optimal estimator","","","","","","","6-9 Nov. 2016","","IEEE","IEEE Conference Publications"
"A hybrid deep model with HOG features for Bangla handwritten numeral classification","S. M. A. Sharif; N. Mohammed; N. Mansoor; S. Momen","Department of Computer Science and Engineering, University of Liberal Arts Bangladesh (ULAB), Satmasjid Road, Dhaka, Bangladesh","2016 9th International Conference on Electrical and Computer Engineering (ICECE)","20170216","2016","","","463","466","Considering the practical significances, handwriting recognition is getting an intense interest to the research community. Through, several studies have been conducted for Bengali handwriting recognition, a robust model for Bengali numerals classification is still due. Therefore, a hybrid model is presented in this paper, which aims to classify the Bengali numerals more precisely. The proposed model bridges hand crafted feature extraction based approaches with the automatically learnt features of Convolutional Neural networks (CNN). It is observed that the proposed model outperforms existing models with lesser epochs. The proposed model is trained and tested with the ISI numeral dataset and also cross-validated with the CAMTERDB numeral dataset. For both scenarios, proposed model shows consistency and demonstrate the maximum accuracy of 99.02% and 99.17%, respectively. For the CMATERDB collection, the proposed model achieves the best accuracy rate reported till date.","","Electronic:978-1-5090-2963-1; POD:978-1-5090-2964-8; USB:978-1-5090-2962-4","10.1109/ICECE.2016.7853957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7853957","","Feature extraction;Handwriting recognition;Histograms;Machine learning;Neural networks;Testing;Training","feature extraction;feedforward neural nets;handwriting recognition;handwritten character recognition;learning (artificial intelligence);optical character recognition","Bangla handwritten numeral classification;Bengali handwriting recognition;CAMTERDB numeral dataset;CNN;HOG features;ISI numeral dataset;convolutional neural networks;hand crafted feature extraction;hybrid deep model;robust model","","","","","","","20-22 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Convolutional Neural Network-Based Chinese Text Detection Algorithm via Text Structure Modeling","X. Ren; Y. Zhou; J. He; K. Chen; X. Yang; J. Sun","Department of Electronic Engineering, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Multimedia","20170214","2017","19","3","506","518","Text detection in a natural environment plays an important role in many computer vision applications. While existing text detection methods are focused on English characters, there are strong application demands on text detection in other languages, such as Chinese. In this paper, we present a novel text detection algorithm for Chinese characters based on a specific designed convolutional neural network (CNN). The CNN contains a text structure component detector layer, a spatial pyramid layer, and a multi-input-layer deep belief network (DBN). The CNN is pre-trained via a convolutional sparse auto-encoder, specifically designed for extracting complex features from Chinese characters. In particular, the text structure component detectors enhance the accuracy and uniqueness of feature descriptors by extracting multiple text structure components in various ways. The spatial pyramid layer enhances the scale invariability of the CNN for detecting texts in multiple scales. Finally, the multi-input-layer DBN replaces the fully connected layers in the CNN to ensure features from multiple scales are comparable. A multilingual text detection dataset, in which texts in Chinese, English, and digits are labeled separately, is set up to evaluate the proposed text detection algorithm. The proposed algorithm shows a significant performance improvement over the baseline CNN algorithms. In addition the proposed algorithm is evaluated over a public multilingual benchmark and achieves state-of-the-art result under multiple languages. Furthermore, a simplified version of the proposed algorithm with only general components is evaluated on the ICDAR 2011 and 2013 datasets, showing comparable detection performance to the existing general text detection algorithms.","1520-9210;15209210","","10.1109/TMM.2016.2625259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7733055","Chinese text detection;convolutional neural network (CNN);text structure detector;unsupervised learning","Detection algorithms;Detectors;Feature extraction;Image edge detection;Machine learning;Neural networks;Unsupervised learning","computer vision;natural language processing;neural nets;text analysis","CNN;Chinese;Chinese characters;DBN;English;English characters;chinese text detection algorithm;complex feature extraction;computer vision applications;convolutional neural network;convolutional sparse auto-encoder;general text detection algorithms;multi-input-layer deep belief network;multilingual text detection dataset;multiple text structure components;spatial pyramid layer;text structure component detector layer;text structure modeling","","","","","","20161103","March 2017","","IEEE","IEEE Journals & Magazines"
"Collaboration in Computer Vision Using Scientific Workflows","K. Chug; R. J. Sethi","Univ. of Texas, Austin, TX, USA","2016 International Conference on Collaboration Technologies and Systems (CTS)","20170306","2016","","","564","567","Collaboration, extension, and reproduction of research is of great importance in computer vision. Scientific workflows offer a unique framework for distributed collaboration and sharing of experiments. They provide a structured, end-to-end analysis methodology that easily and automatically allows for standardized replication and testing of models, inter-operability of heterogeneous codebases, and incorporation of novel algorithms. In this paper, we introduce the use of scientific workflows in computer vision to aid collaboration.","","Electronic:978-1-5090-2300-4; POD:978-1-5090-2301-1","10.1109/CTS.2016.0104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871042","collaboration;computer vision;scientific workflows","Algorithm design and analysis;Collaboration;Computer vision;Data analysis;Machine learning algorithms;Semantics;Standards","computer vision;groupware;workflow management software","computer vision;distributed collaboration;heterogeneous codebases;interoperability;reproduction;scientific workflows;standardized replication;structured end-to-end analysis methodology","","","","","","","Oct. 31 2016-Nov. 4 2016","","IEEE","IEEE Conference Publications"
"A novel left ventricular volumes prediction method based on deep learning network in cardiac MRI","G. Luo; G. Sun; K. Wang; S. Dong; H. Zhang","Harbin Institute of Technology, Harbin, China","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","89","92","Accurate estimation of left ventricle (LV) volumes plays an essential role in clinical diagnosis of cardiac diseases using MRI. Conventional methods of estimating ventricular volumes depend on the results of manual or automatic segmentation of MRI. However, manual segmentation of MRI sequences is extremely time-consuming and subjective, and automatic segmentation is still a challenging task. Therefore, this study aims to develop a new LV volumes prediction method without segmentation, motivated by deep learning technology and the large scale cardiac MRI (CMR) datasets from the second Annual Data Science Bowl (ADSB) in 2016. The experiments results shows that the predicted LV volumes have high correlation with the ground truth. These results prove that the proposed method has big potential to be researched and applied in clinical diagnosis and screening of cardiac diseases.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868686","","Cardiac disease;Image segmentation;Machine learning;Magnetic resonance imaging;Predictive models;Training","biomedical MRI;cardiology;diseases;learning (artificial intelligence);medical image processing;patient diagnosis","ADSB;Annual Data Science Bowl;MRI sequences;automatic MRI image segmentation;cardiac MRI dataset;cardiac disease diagnosis;deep learning network;deep learning technology;left ventricle volume estimation;left ventricular volume prediction method","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"SIMISS: A Model-Based Searching Strategy for Inventory Management Systems","Y. T. Demey; M. Wolff","Department of Requirements Engineering and Solution Design (Search and Knowledge Management IM2.8.3.3), European Patent Office, EE Rijswijk, The Netherlands","IEEE Internet of Things Journal","20170216","2017","4","1","172","182","Inventory management is critical in human space flight operations. Currently, we use the inventory management system (IMS) in keeping track of items on the International Space Station (ISS). One challenge is to discover lost or wrongly placed items when IMS fails to discover them due to human factors. In this paper, we will illustrate a model-based searching strategy called semantic inventory management for ISS (SIMISS), with which possible locations of lost items will be calculated based on contextual features in three dimensions: (1) spatial; (2) temporal; and (3) human. It contains ontologies, databases, machine learning algorithms, and ubiquitous client applications. We have implemented and tested SIMISS with the sample data from IMS, operation data files and onboard short term plan experiments have been carried out in a set of simulation scenarios.","2327-4662;23274662","","10.1109/JIOT.2016.2638023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778999","Big data analysis;Internet of Things (IoT);fact-based modeling (FBM);radio frequency identification (RFID)","Analytical models;Context;Internet of Things;Inventory management;Machine learning algorithms;Ontologies;Semantics","aerospace computing;database management systems;inventory management;learning (artificial intelligence);ontologies (artificial intelligence);ubiquitous computing","IMS;International Space Station;SIMISS;contextual features;database mangement;human dimension;human factors;human space flight operations;machine learning algorithms;model-based searching strategy;ontologies;operation data files;semantic inventory management-for-ISS;spatial dimension;temporal dimension;ubiquitous client applications","","","","","","20161209","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Deep reinforcement learning with experience replay based on SARSA","D. Zhao; Haitao Wang; Kun Shao; Y. Zhu","Key Laboratory of Management and Control for Complex Systems, Institute of Automation Chinese Academy of Sciences, Beijing 100190, China","2016 IEEE Symposium Series on Computational Intelligence (SSCI)","20170213","2016","","","1","6","SARSA, as one kind of on-policy reinforcement learning methods, is integrated with deep learning to solve the video games control problems in this paper. We use deep convolutional neural network to estimate the state-action value, and SARSA learning to update it. Besides, experience replay is introduced to make the training process suitable to scalable machine learning problems. In this way, a new deep reinforcement learning method, called deep SARSA is proposed to solve complicated control problems such as imitating human to play video games. From the experiments results, we can conclude that the deep SARSA learning shows better performances in some aspects than deep Q learning.","","Electronic:978-1-5090-4240-1; POD:978-1-5090-4241-8","10.1109/SSCI.2016.7849837","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849837","Q learning;SARSA learning;deep learning;deep reinforcement learning;experience replay","Feature extraction;Games;Learning (artificial intelligence);Machine learning;Neural networks;Training","computer games;learning (artificial intelligence);neural nets","Q learning;deep SARSA learning;deep convolutional neural network;deep reinforcement learning;on-policy reinforcement learning;scalable machine learning problems;video games control problems","","","","","","","6-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Changing video game graphic styles using neural algorithms","B. Yoo; K. J. Kim","Department of Computer Science and Engineering, Sejong University, Seoul, South Korea","2016 IEEE Conference on Computational Intelligence and Games (CIG)","20170223","2016","","","1","2","Recently, procedural content generation (PCG) has attracted positive attentions from gamers and applied for various content types such as maps, items and so on. Deep neural networks have been reported that they have potential to learn styles of artistic images. In this study, we propose to apply convolutional neural networks to change artistic styles of video game graphics. It's expected to change original games into different styles (modern, old-fashioned, scientific, and so on) given the input images. We applied the neural styling algorithm to the game images from Hedgewars, an open-source turn-based strategy game. Our results show that styles of video games can be changed from an input styling image.","","Electronic:978-1-5090-1883-3; POD:978-1-5090-1884-0; USB:978-1-5090-1882-6","10.1109/CIG.2016.7860390","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860390","Convolutional neural network;Deep learning application;Image conversion;Procedural content generation","Convolutional codes;Games;Graphics;Machine learning;Neural networks;Open source software","computer games;computer graphics;convolution;image resolution;neural nets","PCG;artistic images;artistic style change;convolutional neural networks;deep neural networks;image resolution;neural algorithms;procedural content generation;video game graphic styles","","","","","","","20-23 Sept. 2016","","IEEE","IEEE Conference Publications"
"Analysis of Crime Rate Distribution Based on TPML-WMA","X. Wei; J. Yan; Z. Chen; T. Shi","Inf. Eng. Sch., Commun. Univ. of China, Beijing, China","2016 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)","20170228","2016","","","157","160","Crime distribution forecasting has a positive impact on social stability and has drew much attention in academia. Existing research methods are not applicable for specific research problems or specific data sets very well. So we build the Vector Motion Model and propose a new algorithm named as TPML-WMA (Transition Probability Matrix Learning and Weighted Moving Average algorithm) to predict a future robbery distribution and figure out how it transfers. According to the idea of machine learning algorithm, we let the transition probability matrix to learn by itself, and do the weighted moving processing on the matrices. Using data from 2001 to 2011 from a city in China, we set up the model, evaluate the TPML-WMA algorithm on brigandage prediction and discuss the performance of algorithms under different initial conditions. At the same time, we compare the proposed algorithm with the classical linear regression method based on the least square method. The results illustrate that the prediction performance of TPML-WMA is greatly improved compared with the linear regression method.","","Electronic:978-1-5090-5154-0; POD:978-1-5090-5155-7","10.1109/CyberC.2016.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7864224","Crime Rate Distribution;TPML-WMA Algorithm;Vector Motion Model","Algorithm design and analysis;Data models;Linear regression;Machine learning algorithms;Mathematical model;Prediction algorithms;Predictive models","learning (artificial intelligence);least squares approximations;matrix algebra;moving average processes;police data processing;regression analysis","China;TPML-WMA algorithm;brigandage prediction;crime rate distribution;least square method;linear regression method;machine learning algorithm;robbery distribution;transition probability matrix learning and weighted moving average algorithm;vector motion model","","","","","","","13-15 Oct. 2016","","IEEE","IEEE Conference Publications"
"Making telecommunications services accessible to people with severe communication disabilities","R. Y. Y. Chan; J. Ding; L. W. Kong; G. Yan; X. Bai; X. Ma; S. So; X. Wang; J. T. C. Chow","Department of Information Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong","2016 IEEE Global Humanitarian Technology Conference (GHTC)","20170216","2016","","","105","112","Since the advent of telephony in 1880s, a number of important telecommunications technologies have been invented and developed. However, people with severe communication disabilities have been left out from enjoying the electronic transmission of speech and voice due to their limitations in cognitive, social, and/or motor skills. This paper reports a cross-disciplinary endeavour in Hong Kong that aims at paving the very last mile of communication networks. A semantic image-based cloud augmentative and alternative communication system has been developed in an 18-month project. The system enables people with complex communication needs to conduct telephone conversations. The primary user group spans at least 1.3 percent of all population worldwide; including those with dementia, aphasia, developmental disorders, and those in acquired medical conditions, etc. who cannot rely on their natural speech for daily communication.","","Electronic:978-1-5090-2432-2; POD:978-1-5090-2433-9; USB:978-1-5090-2431-5","10.1109/GHTC.2016.7857267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7857267","augmentative and alternative communication (AAC);complex communication needs;semantic images;telecommunications services","Algorithm design and analysis;Conferences;Decision support systems;Heuristic algorithms;Machine learning algorithms;Semantics;System analysis and design","cloud computing;handicapped aids;semantic Web;telephony;visual databases","Hong Kong;alternative communication system;aphasia;cognitive skills;communication networks;daily communication;dementia;developmental disorders;electronic transmission;medical conditions;motor skills;natural speech;semantic image-based cloud augmentative communication system;severe communication disabilities;social skills;speech transmission;telecommunications services;telephone conversations;telephony;voice transmission","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep Belief Networks with Feature Selection for Sentiment Classification","P. Ruangkanokmas; T. Achalakul; K. Akkarajitsakul","Dept. of Comput. Eng., King's Mongkut's Univ. of Technol. Thonburi, Bangkok, Thailand","2016 7th International Conference on Intelligent Systems, Modelling and Simulation (ISMS)","20170316","2016","","","9","14","Due to the complexity of human languages, most of sentiment classification algorithms are suffered from a huge-scale dimension of vocabularies which are mostly noisy and redundant. Deep Belief Networks (DBN) tackle this problem by learning useful information in input corpus with their several hidden layers. Unfortunately, DBN is a time-consuming and computationally expensive process for large-scale applications. In this paper, a semi-supervised learning algorithm, called Deep Belief Networks with Feature Selection (DBNFS) is developed. Using our chi-squared based feature selection, the complexity of the vocabulary input is decreased since some irrelevant features are filtered which makes the learning phase of DBN more efficient. The experimental results of our proposed DBNFS shows that the proposed DBNFS can achieve higher classification accuracy and can speed up training time compared with others well-known semi-supervised learning algorithms.","2166-0670;21660670","Electronic:978-1-5090-0665-6; POD:978-1-5090-0666-3","10.1109/ISMS.2016.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877180","Chi-squared Feature Selection;Deep Belief Networks;Deep Learning;Feature Selection;Restricted Boltzmann Machine;Semi-supervised Learning;Sentiment Classification","Classification algorithms;Feature extraction;Machine learning;Noise measurement;Testing;Training;Vocabulary","belief networks;classification;feature selection;information filtering;learning (artificial intelligence);sentiment analysis","DBNFS;chi-squared based feature selection;deep belief networks;human languages complexity;semi supervised learning algorithms;sentiment classification algorithms;vocabulary input complexity","","","","","","","25-27 Jan. 2016","","IEEE","IEEE Conference Publications"
"Large-scale supervised learning of the grasp robustness of surface patch pairs","D. Seita; F. T. Pokorny; J. Mahler; D. Kragic; M. Franklin; J. Canny; K. Goldberg","The AUTOLAB, Department of Industrial Engineering and Operations Research and Electrical Engineering and Computer Sciences, University of California, Berkeley; Berkeley, CA 94720, USA","2016 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)","20170223","2016","","","216","223","The robustness of a parallel-jaw grasp can be estimated by Monte Carlo sampling of perturbations in pose and friction but this is not computationally efficient. As an alternative, we consider fast methods using large-scale supervised learning, where the input is a description of a local surface patch at each of two contact points. We train and test with disjoint subsets of a corpus of 1.66 million grasps where robustness is estimated by Monte Carlo sampling using Dex-Net 1.0. We use the BIDMach machine learning toolkit to compare the performance of two supervised learning methods: Random Forests and Deep Learning. We find that both of these methods learn to estimate grasp robustness fairly reliably in terms of Mean Absolute Error (MAE) and ROC Area Under Curve (AUC) on a held-out test set. Speedups over Monte Carlo sampling are approximately 7500x for Random Forests and 1500x for Deep Learning.","","Electronic:978-1-5090-4616-4; POD:978-1-5090-4617-1; USB:978-1-5090-4615-7","10.1109/SIMPAR.2016.7862399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862399","","Force;Friction;Machine learning;Probabilistic logic;Robots;Robustness;Uncertainty","Monte Carlo methods;grippers;learning (artificial intelligence);sampling methods","AUC;BIDMach machine learning toolkit;Dex-Net 1.0;MAE;Monte Carlo sampling;ROC area under curve;deep learning;large-scale supervised learning;local surface patch;mean absolute error;parallel-jaw grasp robustness;random forests;surface patch pairs","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Feature extracted sentiment analysis of customer product reviews","N. Devasia; R. Sheik","Department of Computer Science, TKM College of Engineering, Kollam, India","2016 International Conference on Emerging Technological Trends (ICETT)","20170309","2016","","","1","6","Online shopping is more and more common nowadays. The growth in its popularity has led to increase in customer reviews that a product receives. A customer who has to choose the right product among the huge varieties of products, depends heavily on the product reviews to make a purchase decision. With great volume of product reviews, it become difficult for customers to wade through all reviews to make an informed product choice. Nowadays customers look for features that can serve them specifically. But from the thousands of reviews, it is practically impossible for customers to identify the reviews which speak about the specific product feature. As a solution to these problems, in this work we aim to analyze a product at feature level, from the customer product reviews. The proposed system, follows a semantic based approach to extract product features. An algorithm, which employ typed dependencies, is introduced for this purpose. Recursive Deep model is used to identify sentiment orientation of review sentences. A review matrix is constructed to find the importance and polarity of each product feature. The experimental results show that the method proposed is effective and has achieved the desired objective.","","DVD:978-1-5090-3750-6; Electronic:978-1-5090-3751-3; POD:978-1-5090-3752-0","10.1109/ICETT.2016.7873646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873646","Dependency relations;Feature extraction;Product reviews;Recursive deep model;Sentiment orientation","Algorithm design and analysis;Computer science;Feature extraction;Machine learning algorithms;Market research;Semantics;Sentiment analysis","Internet;feature extraction;matrix algebra;retail data processing;sentiment analysis","customer product reviews;feature extracted sentiment analysis;online shopping;product feature analysis;product feature extraction;recursive deep model;review matrix;review sentence sentiment orientation;semantic based approach","","","","","","","21-22 Oct. 2016","","IEEE","IEEE Conference Publications"
"Logistic regression-based device-free localization in changeable environments","Q. Lei; H. Lv; H. Zhang; H. Sun; L. Tang","School of Electronic Information, Wuhan University, 430072 Wuhan, China","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","1062","1066","Device-free localization (DFL) is expected to detect and locate a person by measuring the changes of received signals in wireless sensor networks without the need of any device. Fingerprint-based DFL in changeable environments has attracted wide attenuation in recent years. However, the accuracy of fingerprint-based localization could be improved further in changing environments. In this paper, we adopt the logistic regression classifier to counteract the bad influence to the localization in changeable environments by means of selecting the average channel. The experiment results show that the logistic regression classifier has a lower error rate than the k-nearest neighbors classifier and the linear discriminant analysis classifier. When the change of environments is very obvious, the logistic regression classifier achieves a better result than the random forests classifier in fingerprint-based localization.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7877992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877992","device-free localization;fingerprint-based localization;logistic regression classifier;wireless sensor networks","Algorithm design and analysis;Error analysis;Linear discriminant analysis;Logistics;Machine learning algorithms;Training;Training data","sensor placement;wireless sensor networks","changeable environments;fingerprint-based DFL;fingerprint-based localization;k-nearest neighbors classifier;linear discriminant analysis classifier;logistic regression classifier;logistic regression-based device-free localization;random forests classifier","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"Deep Supervised and Contractive Neural Network for SAR Image Classification","J. Geng; H. Wang; J. Fan; X. Ma","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Geoscience and Remote Sensing","20170224","2017","55","4","2442","2459","The classification of a synthetic aperture radar (SAR) image is a significant yet challenging task, due to the presence of speckle noises and the absence of effective feature representation. Inspired by deep learning technology, a novel deep supervised and contractive neural network (DSCNN) for SAR image classification is proposed to overcome these problems. In order to extract spatial features, a multiscale patch-based feature extraction model that consists of gray level-gradient co-occurrence matrix, Gabor, and histogram of oriented gradient descriptors is developed to obtain primitive features from the SAR image. Then, to get discriminative representation of initial features, the DSCNN network that comprises four layers of supervised and contractive autoencoders is proposed to optimize features for classification. The supervised penalty of the DSCNN can capture the relevant information between features and labels, and the contractive restriction aims to enhance the locally invariant and robustness of the encoding representation. Consequently, the DSCNN is able to produce effective representation of sample features and provide superb predictions of the class labels. Moreover, to restrain the influence of speckle noises, a graph-cut-based spatial regularization is adopted after classification to suppress misclassified pixels and smooth the results. Experiments on three SAR data sets demonstrate that the proposed method is able to yield superior classification performance compared with some related approaches.","0196-2892;01962892","","10.1109/TGRS.2016.2645226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827114","Contractive autoencoder (AE);deep neural network (DNN);supervised classification;synthetic aperture radar (SAR) image","Decoding;Feature extraction;Machine learning;Robustness;Speckle;Synthetic aperture radar;Transforms","feature extraction;geophysical image processing;gradient methods;image classification;learning (artificial intelligence);matrix algebra;neural nets;radar imaging;remote sensing by radar;synthetic aperture radar","DSCNN;Gabor model;SAR image classification;graph-cut-based spatial regularization;gray level-gradient co-occurrence matrix;histogram of oriented gradient descriptors;multiscale patch-based feature extraction model;novel deep supervised and contractive neural network;spatial feature extraction;synthetic aperture radar image","","","","","","20170119","April 2017","","IEEE","IEEE Journals & Magazines"
"A deep learning network for right ventricle segmentation in short-axis MRI","G. Luo; R. An; K. Wang; S. Dong; H. Zhang","Harbin Institute of Technology, Harbin, China","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","485","488","The segmentation of the right ventricle (RV) myocardium on MRI is a prerequisite step for the evaluation of RV structure and function, which is of great importance in the diagnose of most cardiac diseases, such as pulmonary hypertension, congenital heart disease, coronary heart disease, and dysplasia. However, RV segmentation is considered challenging, mainly because of the complex crescent shape of the RV across slices and phases. Hence this study aims to propose a new approach to segment RV endocardium and epicardium based on deep learning. The proposed method contains two subtasks: (1) localizing the region of interest (ROI), the biventricular region which contains more meaningful features and can facilitate the RV segmentation, and (2) segmenting the RV myocardium based on the localization. The two subtasks are integrated into a joint task learning framework, in which each task is solved via two multilayer convolutional neural networks. The experiments results show that the proposed method has big potential to be further researched and applied in clinical diagnosis.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868785","","Cardiac disease;Heart;Image segmentation;Machine learning;Magnetic resonance imaging;Neural networks;Training","biomedical MRI;cardiology;diseases;image segmentation;learning (artificial intelligence);medical image processing;neural nets","RV endocardium;RV epicardium;RV function;RV structure;biventricular region;cardiac diseases;clinical diagnosis;congenital heart disease;convolutional neural networks;coronary heart disease;deep learning network;dysplasia;pulmonary hypertension;region-of-interest;right ventricle segmentation;short-axis MRI","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"SAR ATR by a combination of convolutional neural network and support vector machines","S. A. Wagner","Fraunhofer Institute for High Frequency Physics and Radar Techniques Wachtberg, Germany","IEEE Transactions on Aerospace and Electronic Systems","20170216","2016","52","6","2861","2872","A combination of a convolutional neural network, which belongs to the deep learning research field, and support vector machines is presented as an efficient automatic target recognition system. Additional training methods that incorporate prior knowledge to the classifier and further improve its robustness against imaging errors and target variations are also presented. These methods generate artificial training data by elastic distortion and affine transformations that represent typical examples of image errors, like a changing range scale dependent on the depression angle or an incorrectly estimated aspect angle. With these examples presented to the classifier during the training, the system should become invariant against these variations and thus more robust. For the classification, the spotlight synthetic aperture radar images of the moving and stationary target acquisition and recognition database are used. Results are shown for the ten class database with a forced decision classification as well as with rejection class.","0018-9251;00189251","","10.1109/TAES.2016.160061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7855589","","Biological neural networks;Machine learning;Neurons;Support vector machines;Synthetic aperture radar;Target recognition;Training","convolution;neural nets;object recognition;radar imaging;support vector machines;synthetic aperture radar","SAR ATR;affine transformations;artificial training data;convolutional neural network;elastic distortion;moving target acquisition;spotlight synthetic aperture radar images;stationary target acquisition;support vector machines;target recognition","","","","","","","December 2016","","IEEE","IEEE Journals & Magazines"
"Clickbait detection using deep learning","A. Agrawal","Citrix R&D India Pvt. Ltd., Bangalore, India 560042","2016 2nd International Conference on Next Generation Computing Technologies (NGCT)","20170316","2016","","","268","272","Clickbaits, in social media, are exaggerated headlines whose main motive is to mislead the reader to “click” on them. They create a nuisance in the online experience by creating a lure towards poor content. Online content creators are utilizing more of them to get increased page views and thereby more ad revenue without providing the backing content. This paper proposes a model for detection of clickbait by utilizing convolutional neural networks and presents a compiled clickbait corpus. We create a corpus using multiple social media platforms and utilize deep learning for learning features rather than undergoing the long and complex process of feature engineering. Our model achieves high performance in identification of clickbaits.","","DVD:978-1-5090-3256-3; Electronic:978-1-5090-3257-0; POD:978-1-5090-3258-7","10.1109/NGCT.2016.7877426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877426","Clickbait;convolutional neural networks;deep learning","Computational modeling;Computers;Machine learning;Neural networks;Next generation networking;Twitter","advertising data processing;convolution;learning (artificial intelligence);neural nets;social networking (online)","clickbait detection;convolutional neural networks;deep learning;social media","","","","","","","14-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep learning tracker via SVM ranking vector","B. Dai; Z. Hou; W. Yu; X. Wang; D. Hu","Institute of Information and Navigation, Air Force Engineering University, Xi'an, China","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","963","968","The deep learning based trackers can always achieve high tracking precision and strong adaptability in different scenarios. However, due to the fact that the number of the parameter is large and the fine-tuning is challenging, the time complexity is high. In order to improve the efficiency, we proposed a tracker based on fast deep learning through constructing a new network with less redundancy. Based on the theory of deep learning, we proposed a deep neural network to describe essential features of images. Furthermore, fast deep learning can be achieved by restricting the size of network. With the help of GPU, the time complexity of the network training is released to a large extent. Under the framework of particle filter, the proposed method combined the deep learning extractor with an SVM scoring professor to distinguish the target from the background. The condensed network structure reduced the complexity of the model. Compared with some other deep learning based tracker, the proposed method can achieve higher efficiency. The frame rate keeps at 22 frames per second on average. Experiments on an open tracking benchmark demonstrate that both the robustness and the timeliness of the proposed tracker are promising when the appearance of the target changes containing translation, rotation and scale or the interference containing illumination, occlusion and cluttered background. Unfortunately, it is not robust enough when the target moves fast or the motion blur and some similar objects exist.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7877973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877973","SVM;autoencoder;deep learning;visual tracking","Feature extraction;Machine learning;Robustness;Support vector machines;Target tracking;Visualization","computational complexity;graphics processing units;image coding;image filtering;image motion analysis;learning (artificial intelligence);neural nets;object tracking;particle filtering (numerical methods);support vector machines","GPU;SVM ranking vector;autoencoder;deep learning tracker;deep neural network;image feature;motion blur;particle filter;time complexity","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"Thai text topic modeling system for discovering group interests of Facebook young adult users","R. Jiamthapthaksin","Computer Science Department, Assumption University, Bangkok, Thailand","2016 2nd International Conference on Science in Information Technology (ICSITech)","20170216","2016","","","91","96","Facebook is the largest digital social network in the world, and is the most popular social network in Thailand. This paper proposes Thai text topic modeling system that turns Facebook posts into valuable users' group interests. Latent Dirichlet Allocation (LDA) for topic modeling, if applied directly on Thai text posts, does not capture well the group interests due to unique characteristics of the data like intentional typo. The main contributions of the paper include the integration of Thai slangs from posts for extracting Thai words, insertion and stop words removal, slang stemming, and applying LDA for seed word acquisition and topic modeling enhancement. The experiments performed on Thai Facebook posts of undergraduate student volunteers at Assumption University was used to demonstrate feature size reduction, model enhancement, and discovery of meaningful group interests.","","Electronic:978-1-5090-1721-8; POD:978-1-5090-1722-5; USB:978-1-5090-1720-1","10.1109/ICSITech.2016.7852614","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852614","Knowledge Discovery;Latent Dirichlet Allocation;Mining Thai Text Posts;Social User Interests;Topic Mining","Context;Data mining;Data models;Facebook;Information technology;Machine learning algorithms","data mining;natural language processing;social networking (online);text analysis","Facebook;LDA;Thai text;digital social network;group interest discovering;latent dirichlet allocation;topic mining;topic modeling system;young adult users","","","","","","","26-27 Oct. 2016","","IEEE","IEEE Conference Publications"
"Intruder Detection Using Deep Learning and Association Rule Mining","A. Thilina; S. Attanayake; S. Samarakoon; D. Nawodya; L. Rupasinghe; N. Pathirage; T. Edirisinghe; K. Krishnadeva","Dept. of Inf. Technol., Sri Lanka Inst. of Inf. Technol., Malabe, Sri Lanka","2016 IEEE International Conference on Computer and Information Technology (CIT)","20170313","2016","","","615","620","With the upsurge of internet popularity, nowadays there are millions of online transactions that are being processed per minute thus increasing the possibilities of intruder attacks over the recent times. There have been various intruder detection techniques such as using traditional machine learning based algorithms. These algorithms were widely used to identify and prevent intruder activities in the recent past. Furthermore, multilayer neural networks[5] were also used in this regard to perform the detection. Hence multi-layer neural networks inherit fundamental drawbacks due to its inability to perform training due the problems such as overfitting, etc. In contrast, deep learning algorithms were introduced to overcome these issues effectively. We propose a novel framework to perform intruder detection and analysis using deep learning nets and association rule mining. We utilize a recurrent network to predict intruder activities and FP-Growth to perform the analysis. Our results show the effectiveness of our framework in detail.","","Electronic:978-1-5090-4314-9; POD:978-1-5090-4315-6","10.1109/CIT.2016.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876395","Association rule mining;Deeplearning;FPGrowth;Intruder detection;Pattern Recognition;Recurrent Neural Networks","Algorithm design and analysis;Data mining;Machine learning;Machine learning algorithms;Recurrent neural networks;Training","Internet;data mining;learning (artificial intelligence);multilayer perceptrons;pattern recognition;recurrent neural nets;security of data","FP-growth;Internet;association rule mining;deep learning nets;intruder analysis;intruder attacks;intruder detection;machine learning based algorithms;multilayer neural networks;online transactions;recurrent network","","","","","","","8-10 Dec. 2016","","IEEE","IEEE Conference Publications"
"Crowd Video Classification Using Convolutional Neural Networks","A. Burney; T. Q. Syed","","2016 International Conference on Frontiers of Information Technology (FIT)","20170302","2016","","","247","251","Deep learning tools such as the convolutional neural network (CNN) are extensively used for image analysis and interpretation tasks but they become relatively expensive to use for a corresponding analysis in videos by requiring memory provision for the additional temporal information. Crowd video analysis is one of the subareas in video analysis that has recently gained notoriety. In this paper we have shown that a 2D CNN can be used to classify videos by using 3-channel image map input for each video computed using spatial and temporal information and this reduces space and time complexity over a classical 3D CNN usually used for video analysis. We test the model developed with the state-of-the-art method of [1] using their proposed dataset, and without any additional processing steps, improve upon their reported accuracy.","","Electronic:978-1-5090-5300-1; POD:978-1-5090-5301-8","10.1109/FIT.2016.052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866761","classification;cnn;convolutional neural network;crowd;crowd video analysis;deep learning;video analytics","Image analysis;Machine learning;Neural networks;Stability analysis;Testing;Three-dimensional displays;Two dimensional displays","computational complexity;image classification;learning (artificial intelligence);neural nets;video signal processing","2D CNN;3-channel image map input;convolutional neural network;crowd video analysis;crowd video classification;deep learning tools;image analysis;image interpretation;memory provision;space complexity reduction;spatial information;temporal information;time complexity reduction","","","","","","","19-21 Dec. 2016","","IEEE","IEEE Conference Publications"
"A randomized approach to large-scale subspace clustering","P. A. Traganitis; G. B. Giannakis","Dept. of ECE & Digital Technology Center, Univ. of Minnesota, USA","2016 50th Asilomar Conference on Signals, Systems and Computers","20170306","2016","","","1019","1023","Subspace clustering has become a popular tool for clustering high-dimensional non-linearly separable data. However, state-of-the-art subspace clustering algorithms do not scale well as the number of data increases. The present paper puts forth a novel randomized subspace clustering scheme for high-volume data based on random projections. Performance of the proposed method is assessed via numerical tests, and is compared with state-of-the-art subspace clustering and large-scale subspace clustering methods.","","DVD:978-1-5386-3952-8; Electronic:978-1-5386-3954-2; POD:978-1-5386-3955-9","10.1109/ACSSC.2016.7869522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869522","Subspace clustering;big data;random projections;sketching","Clustering algorithms;Complexity theory;Machine learning algorithms;Optimization;Principal component analysis;Signal processing algorithms;Sparse matrices","data handling;pattern clustering","high-dimensional nonlinearly separable data clustering;high-volume data;large-scale subspace clustering;random projection;randomized approach","","","","","","","6-9 Nov. 2016","","IEEE","IEEE Conference Publications"
"LSTM-based Deep Learning Models for Answer Ranking","Z. Li; J. Huang; Z. Zhou; H. Zhang; S. Chang; Z. Huang","Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2016 IEEE First International Conference on Data Science in Cyberspace (DSC)","20170302","2016","","","90","97","The learning problem of ranking arises in many tasks, including the question answering, information retrieval, and movie recommendation. In these tasks, the ordering of the answers, documents or movies returned is a critical aspect of the system. Recently, deep learning approaches have gained a lot of attention from the research community and industry for their ability to automatically learn optimal feature representation for a given task. We aim to solve the answer ranking problem in practical question answering system with deep learning approaches. In this paper, we define a composite representation for questions and answers by combining convolutional neural network (CNN) with bidirectional long short-term memory (biLSTM) models, and learn a similarity function to relate them in a supervised way from the available training data. Considering the limited training data, we propose a hypernym strategy to get more general text pairs and test the effectiveness of different strategies. Experimental results on a public benchmark dataset from TREC demonstrate that our system outperforms previous work which requires syntactic features and some deep learning models.","","Electronic:978-1-5090-1192-6; POD:978-1-5090-1193-3","10.1109/DSC.2016.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866113","Question Answering;hypernyms;learning to rank;long short-term memory","Computational modeling;Computer architecture;Knowledge discovery;Machine learning;Neural networks;Semantics;Training data","feedforward neural nets;learning (artificial intelligence);question answering (information retrieval);recommender systems;recurrent neural nets;text analysis","CNN;LSTM-based deep learning models;TREC;answer ranking;automatic optimal feature representation learning;biLSTM models;bidirectional long short-term memory models;convolutional neural network;general text pairs;hypernym strategy;information retrieval;long short-term memory-based deep learning models;movie recommendation;public benchmark dataset;question answering;research community","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Deep learning classification of photographic paper based on clustering by domain experts","A. G. Klein; P. Messier; A. L. Frost; D. Palzer; S. L. Wood","Western Washington Univ., Bellingham, WA 98225","2016 50th Asilomar Conference on Signals, Systems and Computers","20170306","2016","","","139","143","Prior work on texture analysis of historic, photographic papers has focused primarily on measures of texture similarity. However, automated grouping or clustering of photographic paper textures in a way that is meaningful to art conservators remains an open problem. In this work a deep learning approach to automated classification is presented, for clusters derived from a human sorting experiment conducted by 19 art conservators and paper experts and subsequently extended through crowd-sourcing. The proposed approach uses a deep convolutional neural network, and results are presented on the performance in automatically classifying images when compared to human experts.","","DVD:978-1-5386-3952-8; Electronic:978-1-5386-3954-2; POD:978-1-5386-3955-9","10.1109/ACSSC.2016.7869011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869011","","Art;Gray-scale;Image resolution;Machine learning;Neural networks;Observers;Training","art;crowdsourcing;image classification;image texture;learning (artificial intelligence);neural nets;pattern clustering;photography","art conservators;automated clustering;automated grouping;automated image classification;crowd-sourcing;deep convolutional neural network;deep learning classification;historic photographic papers;human sorting experiment;paper experts;texture analysis;texture similarity","","","","","","","6-9 Nov. 2016","","IEEE","IEEE Conference Publications"
"Learning From Explanations Using Sentiment and Advice in RL","S. Krening; B. Harrison; K. M. Feigh; C. L. Isbell; M. Riedl; A. Thomaz","Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Cognitive and Developmental Systems","20170309","2017","9","1","44","55","In order for robots to learn from people with no machine learning expertise, robots should learn from natural human instruction. Most machine learning techniques that incorporate explanations require people to use a limited vocabulary and provide state information, even if it is not intuitive. This paper discusses a software agent that learned to play the Mario Bros. game using explanations. Our goals to improve learning from explanations were twofold: (1) to filter explanations into advice and warnings and (2) to learn policies from sentences without state information. We used sentiment analysis to filter explanations into advice of what to do and warnings of what to avoid. We developed object-focused advice to represent what actions the agent should take when dealing with objects. A reinforcement learning agent used object-focused advice to learn policies that maximized its reward. After mitigating false negatives, using sentiment as a filter was approximately 85% accurate. object-focused advice performed better than when no advice was given, the agent learned where to apply the advice, and the agent could recover from adversarial advice. We also found the method of interaction should be designed to ease the cognitive load of the human teacher or the advice may be of poor quality.","2379-8920;23798920","","10.1109/TCDS.2016.2628365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7742965","Advice;reinforcement learning (RL);sentiment","Games;Learning (artificial intelligence);Machine learning;Robots;Sentiment analysis;Vocabulary","intelligent robots;learning (artificial intelligence);sentiment analysis","Mario Bros. game;RL;adversarial advice;false negative mitigation;object-focused advice;reinforcement learning agent;robot learning;sentiment analysis;software agent;warnings","","","","","","20161114","March 2017","","IEEE","IEEE Journals & Magazines"
"Abnormal Event Detection Using Microsoft Kinect in a Smart Home","H. Y. Lin; Y. L. Hsueh; W. N. Lie","Dept. of Comput. Sci. & Inf. Eng., Nat. Chung Cheng Univ., Chiayi, Taiwan","2016 International Computer Symposium (ICS)","20170220","2016","","","285","289","In this paper, we present a continuous deep learning model for fall detection using Microsoft Kinect. The input include pre-processed high-resolution RGB images, depth images collected by a Kinect and optical flow images. We combine several deep learning structures including convolutional neural networks and long short-term memory networks for continuous human fallen detection. Finally, we present experimental results to demonstrate the performance and utility of our approach.","","Electronic:978-1-5090-3438-3; POD:978-1-5090-3439-0","10.1109/ICS.2016.0064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858486","Convolutional neural network;Data mining;Deep learning;Fall detection;Long short-term memory network","Biological neural networks;Feature extraction;Logic gates;Machine learning;Neurons;Optical imaging;Recurrent neural networks","feedforward neural nets;home automation;image colour analysis;image resolution;image sequences;learning (artificial intelligence)","Microsoft Kinect;abnormal event detection;continuous deep learning model;continuous human fallen detection;convolutional neural networks;deep learning structures;optical flow images;preprocessed high-resolution RGB images;short-term memory networks;smart home","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Toward detecting accidents with already available passive traffic information","R. W. Thomas; J. M. Vidal","Department of Computer Science and Engineering, University of South Carolina, Columbia, USA","2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC)","20170302","2017","","","1","4","Traffic accidents occur every day, causing disruptions. The longer disruptions are in place, the more severe they may become as additional vehicles continue to enter the affected roadways. This paper looks at using passive data from a readily available source, smart phones, to detect traffic accidents automatically via machine learning algorithms and thereby allow additional alerts and actions to occur to minimize the disruption. Using simulated data, machine learning algorithms were scored for accuracy and the results were analyzed.","","Electronic:978-1-5090-4228-9; POD:978-1-5090-4229-6","10.1109/CCWC.2017.7868428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868428","Multi-Agent System;smart cities;trace data","Accidents;Automobiles;Data models;Logistics;Machine learning algorithms;Training data;Vehicle crash testing","learning (artificial intelligence);road accidents;smart cities;smart phones;traffic information systems","alerts;automatic traffic accident detection;disruption minimization;machine learning;passive traffic information;roadways;smart phones;vehicles","","","","","","","9-11 Jan. 2017","","IEEE","IEEE Conference Publications"
"Deep Learning Backend for Single and Multisession i-Vector Speaker Recognition","O. Ghahabi; J. Hernando","TALP Research Center, Department of Signal Theory and Communications, Universitat Politecnica de Catalunya&#x2014;BarcelonaTech, Barcelona, Spain","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20170302","2017","25","4","807","817","The lack of labeled background data makes a big performance gap between cosine and Probabilistic Linear Discriminant Analysis (PLDA) scoring baseline techniques for i-vectors in speaker recognition. Although there are some unsupervised clustering techniques to estimate the labels, they cannot accurately predict the true labels and they also assume that there are several samples from the same speaker in the background data that could not be true in reality. In this paper, the authors make use of Deep Learning (DL) to fill this performance gap given unlabeled background data. To this goal, the authors have proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on deep belief networks and deep neural networks to discriminatively model each target speaker. In order to have more insight into the behavior of DL techniques in both single- and multisession speaker enrollment tasks, some experiments have been carried out in this paper in both scenarios. Experiments on National Institute of Standards and Technology 2014 i-vector challenge show that 46% of this performance gap, in terms of minimum of the decision cost function, is filled by the proposed DL-based system. Furthermore, the score combination of the proposed DL-based system and PLDA with estimated labels covers 79% of this gap.","2329-9290;23299290","","10.1109/TASLP.2017.2661705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847321","Deep learning;deep belief network;deep neural network;i-vector;speaker recognition","Adaptation models;Machine learning;NIST;Speaker recognition;Speech;Speech processing;Training","belief networks;feedforward neural nets;learning (artificial intelligence);speaker recognition","DL techniques;DL-based system;PLDA;decision cost function;deep belief networks;deep learning;deep neural networks;hybrid system;i-vector speaker recognition;impostor selection algorithm;multisession speaker enrollment tasks;probabilistic linear discriminant analysis;single-session speaker enrollment tasks;universal model adaptation process","","","","","","20170208","April 2017","","IEEE","IEEE Journals & Magazines"
"14.7 A 288µW programmable deep-learning processor with 270KB on-chip weight storage using non-uniform memory hierarchy for mobile intelligence","S. Bang; J. Wang; Z. Li; C. Gao; Y. Kim; Q. Dong; Y. P. Chen; L. Fick; X. Sun; R. Dreslinski; T. Mudge; H. S. Kim; D. Blaauw; D. Sylvester","University of Michigan, Ann Arbor, USA","2017 IEEE International Solid-State Circuits Conference (ISSCC)","20170306","2017","","","250","251","Deep learning has proven to be a powerful tool for a wide range of applications, such as speech recognition and object detection, among others. Recently there has been increased interest in deep learning for mobile IoT [1] to enable intelligence at the edge and shield the cloud from a deluge of data by only forwarding meaningful events. This hierarchical intelligence thereby enhances radio bandwidth and power efficiency by trading-off computation and communication at edge devices. Since many mobile applications are “always-on” (e.g., voice commands), low power is a critical design constraint. However, prior works have focused on high performance reconfigurable processors [2-3] optimized for large-scale deep neural networks (DNNs) that consume >50mW. Off-chip weight storage in DRAM is also common in the prior works [2-3], which implies significant additional power consumption due to intensive off-chip data movement.","","Electronic:978-1-5090-3758-2; POD:978-1-5090-3759-9","10.1109/ISSCC.2017.7870355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870355","","Machine learning;Memory management;Neurons;Program processors;Random access memory;System-on-chip","DRAM chips;Internet of Things;cloud computing;learning (artificial intelligence);low-power electronics;microprocessor chips;mobile computing;neural nets","DNN;DRAM;Internet of Things;deep learning;deep neural networks;edge devices;hierarchical intelligence;mobile IoT;mobile applications;mobile intelligence;nonuniform memory hierarchy;object detection;on-chip weight storage;power 288 muW;power consumption;power efficiency;programmable deep-learning processor;radio bandwidth;reconfigurable processors;speech recognition","","","","","","","5-9 Feb. 2017","","IEEE","IEEE Conference Publications"
"DeepList: Learning Deep Features With Adaptive Listwise Constraint for Person Reidentification","J. Wang; Z. Wang; C. Gao; N. Sang; R. Huang","National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Circuits and Systems for Video Technology","20170303","2017","27","3","513","524","Person reidentification (re-id) aims to match a specific person across nonoverlapping cameras, which is an important but challenging task in video surveillance. Conventional methods mainly focus either on feature constructing or metric learning. Recently, some deep learning-based methods have been proposed to learn image features and similarity measures jointly. However, current deep models for person re-id are usually trained with either pairwise loss, where the number of negative pairs greatly outnumbering that of positive pairs may lead the training model to be biased toward negative pairs or constant margin hinge loss, without considering the fact that hard negative samples should be paid more attention in the training stage. In this paper, we propose to learn deep representations with an adaptive margin listwise loss. First, ranking lists instead of image pairs are used as training samples, in this way, the problem of data imbalance is relaxed. Second, by introducing an adaptive margin parameter in the listwise loss function, it can assign larger margins to harder negative samples, which can be interpreted as an implementation of the automatic hard negative mining strategy. To gain robustness against changes in poses and part occlusions, our architecture combines four convolutional neural networks, each of which embeds images from different scales or different body parts. The final combined model performs much better than each single model. The experimental results show that our approach achieves very promising results on the challenging CUHK03, CUHK01, and VIPeR data sets.","1051-8215;10518215","","10.1109/TCSVT.2016.2586851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502111","Deep learning;learning to rank;person reidentification (re-id)","Computer architecture;Fasteners;Feature extraction;Machine learning;Measurement;Probes;Training","data mining;image matching;learning (artificial intelligence);neural nets;video surveillance","CUHK01 data sets;CUHK03 data sets;VIPeR data sets;adaptive margin listwise loss function;adaptive margin parameter;automatic hard negative mining;constant margin hinge loss;data imbalance;deep representation;image features;learning-based methods;negative pairs;neural networks;nonoverlapping cameras;pairwise loss;person matching;person reidentification;positive pairs;ranking lists;similarity measures;training model;training samples;training stage;video surveillance","","","","","","20160630","March 2017","","IEEE","IEEE Journals & Magazines"
"Empirical study of PROXTONE and PROXTONE+ for fast learning of large scale sparse models","Z. Shi; R. Liu","Fujitsu R&D Center, Beijing, China","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","1056","1061","PROXTONE is a novel and fast method for the optimization of large scale non-smooth convex problems [1]. In this work, we try to use the PROXTONE method in solving large scale non-smooth non-convex problems, for example training of sparse deep neural networks (sparse DNN) or sparse convolutional neural networks (sparse CNN) for embedded or mobile device. PROXTONE converges much faster than first order methods, while first order methods are easy to derive and control the sparseness of the solutions. Thus in some applications, in order to train sparse models fast, we propose to combine the merits of both methods, that is we use PROXTONE in the first several epochs to reach the neighborhood of an optimal solution, and then use the first order method to explore the possibility of sparsity in the following training. We call such method PROXTONE plus (PROXTONE+). Both PROXTONE and PROXTONE+ are tested in our experiments, and which demonstrate both methods improved convergence speed twice as fast at least on diverse sparse model learning problems, and at the same time reduce the size to 0.5% for DNN models. The source of all the algorithms is available upon request.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7877991","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877991","","Approximation algorithms;Convergence;History;Machine learning;Mobile handsets;Neural networks;Training","Big Data;learning (artificial intelligence);mathematics computing;neural nets;optimisation","Big Data;PROXTONE method;PROXTONE+;deep neural networks;diverse sparse model learning problem;large scale nonsmooth convex problem;large scale sparse models;sparse convolutional neural networks","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"Deep learning-based recognition of underwater target","X. Cao; X. Zhang; Y. Yu; L. Niu","School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, 710072","2016 IEEE International Conference on Digital Signal Processing (DSP)","20170302","2016","","","89","93","Underwater target recognition remains a challenging task due to the complex and changeable environment. There have been a huge number of methods to deal with this problem. However, most of them fail to hierarchically extract deep features. In this paper, a novel deep learning framework for underwater target classification is proposed. First, instead of extracting features relying on expert knowledge, sparse autoencoder (AE) is utilized to learn invariant features from the spectral data of underwater targets. Second, stacked autoencoder (SAE) is used to get high-level features as a deep learning method. At last, the joint of SAE and softmax is proposed to classify the underwater targets. Experiment results with the received signal data from three different targets on the sea indicated that the proposed approach can get the highest classification accuracy compared with support vector machine (SVM) and probabilistic neural network (PNN).","","Electronic:978-1-5090-4165-7; POD:978-1-5090-4166-4","10.1109/ICDSP.2016.7868522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868522","Deep learning;Sparse autoencoder;Stacked autoencoder;Underwater target recognition","Correlation;Cost function;Feature extraction;Machine learning;Target recognition;Training;Visualization","feature extraction;image classification;learning (artificial intelligence);marine engineering;object recognition;sonar target recognition","SAE;deep learning framework;feature extraction;passive sonar;softmax;sparse autoencoder;stacked autoencoder;underwater target classification;underwater target recognition","","","","","","","16-18 Oct. 2016","","IEEE","IEEE Conference Publications"
"Partial opposition-based learning using current best candidate solution","S. Mahdavi; S. Rahnamayan; K. Deb","Department of Electrical, Computer, and Software Engineering, University of Ontario Institute of Technology (UOIT), Oshawa, Canada","2016 IEEE Symposium Series on Computational Intelligence (SSCI)","20170213","2016","","","1","7","Opposition based learning (OBL) has been gaining significant attention in machine learning, specially, in metaheuristic optimization algorithms to take OBL's advantage for enhancing their performance. In OBL, all variables are changed to their opposites while some variables are currently holding proper values which are discarded and converted to worse values by performing opposite. The partial opposition scheme was developed to change randomly some variables to its opposites but they do not pay enough attention to identify and keep variables which have proper values. In this paper, we propose a novel partial opposition scheme, which is generated based on the current best candidate solution. It tries to generate new trial solutions by using the candidate solutions and their opposites such that some variables of a candidate solution are remain unchanged and other variables are changed to their opposites in the trial solution (i.e., gene/variable based optimization). Variables in the trial solution are identified as close or far, according to their Euclidean distance from the corresponding variables/genes in the current best candidate solution. The proposed scheme uses the opposite of variables, which are closer to the current best solution. Only the new trial solutions are included in the next generation which are closer to corresponding opposite solution. As a case study, we employ the proposed partial opposition scheme in the DE algorithm and the partial opposition-based DE is evaluated on CEC-2014 benchmark functions. Simulation results confirm that the partial opposition-based DE obtains a promising performance on the majority of the benchmark functions. The proposed algorithm is compared with the Opposition-based DE (ODE) and random partial opposition-based DE algorithm (DE-RPO); the results show that our new method is better than or at least comparable to other competitors.","","Electronic:978-1-5090-4240-1; POD:978-1-5090-4241-8","10.1109/SSCI.2016.7850255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850255","","Benchmark testing;Computers;Electronic mail;Machine learning algorithms;Optimization;Sociology;Statistics","evolutionary computation;learning (artificial intelligence);optimisation","Euclidean distance;OBL;current best candidate solution;gene based optimization;machine learning;metaheuristic optimization algorithms;partial opposition-based DE algorithm;partial opposition-based learning;variable based optimization","","","","","","","6-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Mid-Level Feature Representation via Sparse Autoencoder for Remotely Sensed Scene Classification","E. Li; P. Du; A. Samat; Y. Meng; M. Che","Department of Geographical Information Science and the Key Laboratory for Satellite Mapping Technology and Applications of State Administration of Surveying, Mapping and Geoinformation of China, Nanjing University, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20170222","2017","10","3","1068","1081","Feature representation is a classic problem in the machine learning community due to the fact that different representations can entangle and hide more or less the different explanatory factors of variation behind the raw data. Especially for scene classification, its performance generally depends on the discriminative power of feature representation. Recently, unsupervised feature learning attracts tremendous attention because of its ability to learn feature representation automatically. However, reliable performance of feature representations by unsupervised learning always requires a large number of features and complex framework of mid-level feature representation. To alleviate such drawbacks, this paper presents a new framework of mid-level feature representation, which does not need learn many convolutional features during the unsupervised feature learning process, and has few parameter settings. In detail, the unsupervised feature learning method, sparse autoencoder, is employed to learn relatively small number of convolutional features from input dataset, and then extended features are extracted from the learned features by a multiple normalized difference features extraction method to compose a derivative feature set. At mid-level feature representation stage, in order to avoid poor performance of standard pooling technology in solving problems brought by rotation and translation of scene images, global feature descriptors (histogram moments, mean, variance, standard deviation) are utilized to build mid-level feature representations of images. For validation and comparison purposes, the proposed approach is evaluated via experiments with two challenging high-resolution remote sensing datasets. The results demonstrate that the approach is effective, and shows strong performance for remotely sensed scene classification.","1939-1404;19391404","","10.1109/JSTARS.2016.2621011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738435","Global feature descriptors;scene classification;sparse autoencoder (SAE);unsupervised feature learning","Computational modeling;Feature extraction;Machine learning;Remote sensing;Semantics;Unsupervised learning;Visualization","feature extraction;image classification;learning (artificial intelligence);remote sensing","feature extraction method;high-resolution remote sensing dataset;machine learning community;mid-level feature representation;remotely sensed scene classification;scene image rotation;scene image translation;sparse autoencoder;standard pooling technology;unsupervised feature learning method","","","","","","20161108","March 2017","","IEEE","IEEE Journals & Magazines"
"Single-output recurrent neural networks for sentence binary classification","A. F. Wicaksono; M. Adriani","Information Retrieval Lab., Faculty of Computer Science, Universitas Indonesia, Depok, Republic of Indonesia","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","293","296","We report several experiments on using Recurrent Neural Networks (RNNs) for sentence binary classification task. In terms of sentence classification, RNNs have an important advantage compared to well-known traditional machine learning models (e.g. SVM and Maximum Entropy), in which it can naturally take into account neighboring information between contiguous words. In addition, to perform binary classification task, we employed Single-Output RNNs (SORNNs) which only consists of a single output layer located in the last time step. The output layer itself is a vector consisting of two units (since we perform binary classification), in which each unit corresponds to a single label. Our results showed that SORNN achieved better performance than other traditional machine learning models, such as SVM, Maximum Entropy, and Naive Bayes, which have been widely used for sentence classification.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872723","","Entropy;Hidden Markov models;Machine learning;Natural language processing;Recurrent neural networks;Support vector machines;Training","pattern classification;recurrent neural nets;vectors","contiguous words;sentence binary classification;single-output RNNs;single-output recurrent neural networks;vector","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Automatic segmentation of left ventricular myocardium by deep convolutional and de-convolutional neural networks","X. L. Yang; L. Gobeawan; S. Y. Yeo; W. T. Tang; Z. Z. Wu; Y. Su","Institute of High Performance Computing, A&#x2217;STAR, Singapore","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","81","84","Deep learning has been integrated into several existing left ventricle (LV) endocardium segmentation methods to yield impressive accuracy improvements. However, challenges remain for segmentation of LV epicardium due to its fuzzier appearance and complications from the right ventricular insertion points. Segmenting the myocardium collectively (i.e., endocardium and epicardium together) confers the potential for better segmentation results. In this work, we develop a computational platform based on deep learning to segment the whole LV myocardium simultaneously from a cardiac magnetic resonance (CMR) image. The deep convolutional network is constructed using Caffe platform, which consists of 6 convolutional layers, 2 pooling layers, and 1 de-convolutional layer. A preliminary result with Dice metric of 0.75±0.04 is reported on York MR dataset. While in its current form, our proposed one-step deep learning method cannot compete with state-of-art myocardium segmentation methods, it delivers promising first pass segmentation results.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868684","","Image segmentation;Machine learning;Magnetic resonance;Magnetic resonance imaging;Measurement;Myocardium;Neural networks","biomedical MRI;cardiology;image segmentation;medical image processing;neural nets","Caffe platform;automatic left ventricular myocardium segmentation;cardiac magnetic resonance image;deconvolutional neural network;deep convolutional neural network;deep learning;left ventricle endocardium segmentation method;right ventricular insertion","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Cancer subtype identification using deep learning approach","A. F. Syafiandini; I. Wasito; S. Yazid; A. Fitriawan; M. Amien","Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia","2016 International Conference on Computer, Control, Informatics and its Applications (IC3INA)","20170228","2016","","","108","112","In this paper, a framework using deep learning approach is proposed to identify two subtypes of human colorectal carcinoma cancer. The identification process uses information from gene expression and clinical data which is obtained from data integration process. One of deep learning architecture, multimodal Deep Boltzmann Machines (DBM) is used for data integration process. The joint representation gene expression and clinical is later used as Restricted Boltzmann Machines (RBM) input for cancer subtype identification. Kaplan Meier survival analysis is employed to evaluate the identification result. The curves on survival plot obtained from Kaplan Meier analysis are tested using three statistic tests to ensure that there is a significant difference between those curves. According to Log Rank, Generalized Wilcoxon and Tarone-Ware, the two groups of patients with different cancer subtypes identified using the proposed framework are significantly different.","","Electronic:978-1-5090-2323-3; POD:978-1-5090-2324-0; USB:978-1-5090-2322-6","10.1109/IC3INA.2016.7863033","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863033","RBM;cancer subtype;deep learning;multimodal DBM","Computer architecture;Data integration;Data mining;Gene expression;Machine learning;Metastasis","Boltzmann machines;cancer;data integration;learning (artificial intelligence);medical computing;statistical analysis","Kaplan Meier survival analysis;Log Rank;RBM;Tarone-Ware;cancer subtype identification;clinical data;data integration process;deep learning approach;gene expression;generalized Wilcoxon;human colorectal carcinoma cancer;restricted Boltzmann machines","","","","","","","3-5 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep learning and deep thinking: New application framework by CICT","R. A. Fiorini","Department of Electronics, Information and Bioengineering, Polit&#x00E9;cnico di Milano","2016 IEEE 15th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","20170223","2016","","","117","128","In a previous paper we showed and discussed how computational information conservation theory (CICT) can help us to develop even competitive advanced quantum cognitive computational systems. To achieve reliable system intelligence outstanding results, current computational system modeling and simulation community has to face and to solve two orders of modeling limitations at least. As a solution, we propose an exponential, prespatial arithmetic scheme (“all-powerful scheme”) by CICT to overcome the Information Double-Bind (IDB) problem and to thrive on both deterministic noise (DN) and random noise (RN) to develop powerful cognitive computational frameworks for deep learning, towards deep thinking applications. An operative example is presented. This paper is a relevant contribution towards an effective and convenient “Science 2.0” universal computational framework to develop deeper learning and deep thinking system and application at your fingertips and beyond.","","CD:978-1-5090-3845-9; Electronic:978-1-5090-3846-6; POD:978-1-5090-3847-3","10.1109/ICCI-CC.2016.7862024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862024","CICT;Deep learning;cognitive informatics;computational intelligence;deep thinking","Brain modeling;Computational modeling;Hidden Markov models;Machine learning;Speech recognition;Training","cognitive systems;learning (artificial intelligence);pattern classification","CICT;advanced quantum cognitive computational systems;computational information conservation theory;deep learning;deep thinking;deterministic noise;information double-bind problem;random noise","","","","","","","22-23 Aug. 2016","","IEEE","IEEE Conference Publications"
"Deep learning for ocean remote sensing: an application of convolutional neural networks for super-resolution on satellite-derived SST data","A. Ducournau; R. Fablet","Institut Mines-Telecom, Telecom-Bretagne; UMR 6285 LabSTICC, Brest, France","2016 9th IAPR Workshop on Pattern Recogniton in Remote Sensing (PRRS)","20170302","2016","","","1","6","In this paper, we propose to address the downscaling of ocean remote sensing data using image super-resolution models based on deep learning, and more particularly Convolutional Neural Networks (CNNs). The goal of this study, for which we focus on satellite-derived Sea Surface Temperature (SST) data, is to evaluate the efficiency and the relevance of deep learning architectures applied to oceanographic remote sensing data. By using a CNN architecture, namely SRCNN (Super Resolution CNN), on a large-scale dataset of SST fields, we show that it allows a considerable gain in terms of PSNR compared to classical downscaling techniques. These results point out the relevance of deep learning models specifically trained for ocean remote sensing data and advocate for other applications to the reconstruction of high-resolution sea surface geophysical fields from multi-sensor satellite observations.","","Electronic:978-1-5090-5041-3; POD:978-1-5090-5042-0","10.1109/PRRS.2016.7867019","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7867019","","Data models;Image reconstruction;Image resolution;Machine learning;Oceans;Remote sensing;Training","data handling;geophysics computing;image resolution;learning (artificial intelligence);neural net architecture;ocean temperature;remote sensing;sensor fusion","CNN architecture;PSNR;SRCNN;convolutional neural networks;deep learning;high-resolution sea surface geophysical field reconstruction;image super-resolution models;multisensor satellite observations;ocean remote sensing data;oceanographic remote sensing data;satellite-derived SST data;satellite-derived sea surface temperature data;super resolution CNN","","","","","","","4-4 Dec. 2016","","IEEE","IEEE Conference Publications"
"Automatic Segmentation and Quantification of White and Brown Adipose Tissues from PET/CT Scans","S. Hussein; A. Green; A. Watane; D. Reiter; X. Chen; G. Z. Papadakis; B. Wood; A. Cypess; M. Osman; U. Bagci","Center for Research in Computer Vision (CRCV), University of Central Florida (UCF), Orlando, FL, USA","IEEE Transactions on Medical Imaging","20170301","2017","36","3","734","744","In this paper, we investigate the automatic detection of white and brown adipose tissues using Positron Emission Tomography/Computed Tomography (PET/CT) scans, and develop methods for the quantification of these tissues at the whole-body and body-region levels. We propose a patient-specific automatic adiposity analysis system with two modules. In the first module, we detect white adipose tissue (WAT) and its two sub-types from CT scans: Visceral Adipose Tissue (VAT) and Subcutaneous Adipose Tissue (SAT). This process relies conventionally on manual or semi-automated segmentation, leading to inefficient solutions. Our novel framework addresses this challenge by proposing an unsupervised learning method to separate VAT from SAT in the abdominal region for the clinical quantification of central obesity. This step is followed by a context driven label fusion algorithm through sparse 3D Conditional Random Fields (CRF) for volumetric adiposity analysis. In the second module, we automatically detect, segment, and quantify brown adipose tissue (BAT) using PET scans because unlike WAT, BAT is metabolically active. After identifying BAT regions using PET, we perform a co-segmentation procedure utilizing asymmetric complementary information from PET and CT. Finally, we present a new probabilistic distance metric for differentiating BAT from non-BAT regions. Both modules are integrated via an automatic body-region detection unit based on one-shot learning. Experimental evaluations conducted on 151 PET/CT scans achieve state-of-the-art performances in both central obesity as well as brown adiposity quantification.","0278-0062;02780062","","10.1109/TMI.2016.2636188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7775001","Abdominal Fat Quantification;Brown Adipose Tissue;Central Obesity Quantification;Co-Segmentation;Segmentation of Brown Fat;Visceral Fat Segmentation","Computed tomography;Fats;Feature extraction;Machine learning;Manuals;Obesity;Positron emission tomography","biological tissues;computerised tomography;image fusion;image segmentation;medical disorders;medical image processing;positron emission tomography;probability;unsupervised learning","CRF;Computed Tomography;PET-CT scans;Positron Emission Tomography;SAT;VAT;WAT;abdominal region;asymmetric complementary information;automatic body-region detection unit;automatic detection;automatic segmentation;body-region levels;brown adipose tissues;brown adiposity quantification;central obesity;clinical quantification;context driven label fusion algorithm;cosegmentation procedure;manual segmentation;nonBAT region;one-shot learning;patient-specific automatic adiposity analysis system;probabilistic distance metric;semiautomated segmentation;sparse 3D Conditional Random Fields;subcutaneous adipose tissue;unsupervised learning method;visceral adipose tissue;volumetric adiposity analysis;white adipose tissues;whole-body levels","","","","","","20161206","March 2017","","IEEE","IEEE Journals & Magazines"
"Change detection by deep neural networks for synthetic aperture radar images","F. Liao; E. Koshelev; M. Milton; Y. Jin; E. Lu","Carnegie Mellon University, Pittsburgh, PA 15213, United States of America","2017 International Conference on Computing, Networking and Communications (ICNC)","20170313","2017","","","947","951","In this Research Experience for Undergraduate (REU) project, we develop and implement deep neural network algorithms for change detection of synthetic aperture radar (SAR) images. Deep neural networks represent a powerful data processing methodology that integrates recent deep learning techniques on neural network computing frameworks to undercover underlying features and structures of observational data. The classic change detection method for SAR images is through the difference image analysis method, i.e., filtering the noise in each before-change and after-change image and then identifying the changes between the two images. Although well researched, the difference image method requires significant pre-processing and has difficulty with applications that require high accuracy and flexibility. The proposed deep neural networks create a change detection map from original SAR images directly without generating difference images, thus providing a novel framework for change detection of complicated SAR images where speckle noise is also present. We conduct numerous experiments on artificial images with added speckle noise and real-world synthetic aperture radar images.","","Electronic:978-1-5090-4588-4; POD:978-1-5090-4589-1","10.1109/ICCNC.2017.7876261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876261","Deep Learning;image change detection;neural network;synthetic aperture radar (SAR)","Change detection algorithms;Classification algorithms;Machine learning;Neural networks;Speckle;Synthetic aperture radar;Training","image denoising;learning (artificial intelligence);neural nets;radar imaging;speckle;synthetic aperture radar","REU project;SAR images;after-change image;before-change image;change detection method;deep learning technique;deep neural networks;difference image analysis method;noise filtering;research experience-for-undergraduate project;speckle noise;synthetic aperture radar images","","","","","","","26-29 Jan. 2017","","IEEE","IEEE Conference Publications"
"Anomaly detection approach using hybrid algorithm of data mining technique","S. M. A. M. Gadal; R. A. Mokhtar","Electronics Eng. Department, College of Engineering, Sudan University of Science & Technology, Khartoum - Sudan","2017 International Conference on Communication, Control, Computing and Electronics Engineering (ICCCCEE)","20170302","2017","","","1","6","The excessive use of the communication networks, rising of Internet of Things leads to increases the vulnerability to the important and secret information. advance attacking techniques and number of attackers are increasing radically. Intrusion is one of the main threats to the internet. Hence security issues had been big problem, so that various techniques and approaches have been presented to address the limitations of intrusion detection system such as low accuracy, high false alarm rate, and time consuming. This paper proposes a hybrid machine learning technique for network intrusion detection based on combination of K-means clustering and Sequential Minimal Optimization (SMO) classification. It introduces hybrid approach that able to reduce the rate of false positive alarm, false negative alarm rate, to improve the detection rate and detect zero-day attackers. The NSL-KDD dataset has been used in the proposed technique.. The classification has been performed by using Sequential Minimal Optimization. After training and testing the proposed hybrid machine learning technique, the results have shown that the proposed technique (K-mean + SMO) has achieved a positive detection rate of (94.48%) and reduce the false alarm rate to (1.2%) and achieved accuracy of (97.3695%).","","Electronic:978-1-5090-1809-3; POD:978-1-5090-1810-9","10.1109/ICCCCEE.2017.7867661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7867661","Intrusion detection;K-mean;NLS KDD;SMO;hybrid algorithm","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Data mining;Internet;Intrusion detection;Machine learning algorithms","Internet;computer network security;data mining;learning (artificial intelligence);pattern classification;pattern clustering","Internet of Things;Internet threats;K-means clustering;NSL-KDD dataset;SMO classification;anomaly detection;attacking techniques;communication networks;data mining;false negative alarm rate;false positive alarm rate;hybrid machine learning;network intrusion detection system;secret information vulnerability;sequential minimal optimization classification;zero-day attacker detection","","","","","","","16-18 Jan. 2017","","IEEE","IEEE Conference Publications"
"Considering eye movement type when applying random forest to detect cognitive distraction","H. Koma; T. Harada; A. Yoshizawa; H. Iwasaki","Tokyo University of Science, Chiba, Japan","2016 IEEE 15th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","20170223","2016","","","377","382","Eye movements are well known to express cognitive distraction. Detecting cognitive distraction can help to prevent work-related accidents; thus, it is very useful to detect cognitive distraction using eye movements. Eye movements can be classified into various types. In this paper, we apply an identification-based machine learning algorithm considering eye movement types. We apply Random Forest as the machine learning algorithm. We show the effectiveness of considering eye movement types when applying Random Forest to detect cognitive distraction.","","CD:978-1-5090-3845-9; Electronic:978-1-5090-3846-6; POD:978-1-5090-3847-3","10.1109/ICCI-CC.2016.7862064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862064","Random Forest;cognitive distraction;eye movement type","Automobiles;Classification algorithms;Decision support systems;Machine learning algorithms;Motion measurement;Robustness;Standards","cognitive systems;gaze tracking;learning (artificial intelligence);pattern classification;random processes","cognitive distraction detection;eye movement type;identification based machine learning;random forest","","","","","","","22-23 Aug. 2016","","IEEE","IEEE Conference Publications"
"Fish recognition from low-resolution underwater images","X. Sun; J. Shi; J. Dong; X. Wang","College of Information Science and Engineering, Ocean University of China, Qingdao, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","20170216","2016","","","471","476","The limited underwater observation scenarios pose great challenges to the problem of object recognition from the low-resolution underwater images. This paper proposes a framework to explicitly learn the discriminative features from relatively low resolution images, by resorting to deep learning approaches and super-resolution method. Firstly, the framework tackles the problem of limited discriminative information of low resolution images by a single-image super resolution method. Then state-of-the-art deep learning approaches are employed to learn recognition models for the special underwater fish recognition task. The proposed framework can be effectively implemented for real-time underwater object recognition on autonomous underwater vehicles. To verify the effectiveness of our method, experiments on a public underwater image dataset of fishes are carried out. The results show that our framework achieves promising results for fish recognition on underwater image datasets.","","Electronic:978-1-5090-3710-0; POD:978-1-5090-3711-7; USB:978-1-5090-3709-4","10.1109/CISP-BMEI.2016.7852757","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852757","Deep learning;image recognition;super-resolution;underwater image","Feature extraction;Fish;Image recognition;Image resolution;Machine learning;Object recognition;Training","geophysical image processing;image recognition;image resolution;learning (artificial intelligence);object recognition","autonomous underwater vehicles;deep learning;discriminative features;low-resolution underwater images;real-time underwater object recognition;single-image super resolution method;underwater fish recognition;underwater image dataset;underwater observation","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"A left ventricular segmentation method on 3D echocardiography using deep learning and snake","S. Dong; G. Luo; G. Sun; K. Wang; H. Zhang","Harbin Institute of Technology, Harbin, China","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","473","476","Segmentation of left ventricular (LV) endocardium from 3D echocardiography is important for clinical diagnosis because it not only can provide some clinical indices (e.g. ventricular volume and ejection fraction) but also can be used for the analysis of anatomic structure of ventricle. In this work, we proposed a new full-automatic method, combining the deep learning and deformable model, for the segmentation of LV endocardium. We trained convolutional neural networks to generate a binary cuboid to locate the region of interest (ROI). And then, using ROI as the input, we trained stacked autoencoder to infer the LV initial shape. At last, we adopted snake model initiated by inferred shape to segment the LV endocardium. In the experiments, we used 3DE data, from CETUS challenge 2014 for training and testing by segmentation accuracy and clinical indices. The results demonstrated the proposed method is accuracy and efficiency respect to expert's measurements.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868782","","Deformable models;Echocardiography;Image segmentation;Machine learning;Shape;Three-dimensional displays;Ultrasonic imaging","echocardiography;image segmentation;learning (artificial intelligence);medical image processing;neural nets","LV endocardium;anatomic structure;autoencoder;binary cuboid;clinical diagnosis;convolutional neural networks;deep learning;deformable model;left ventricular segmentation method;region-of-interest;snake model;three dimensional echocardiography","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Synthesizing benchmarks for predictive modeling","C. Cummins; P. Petoumenos; Z. Wang; H. Leather","University of Edinburgh, UK","2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)","20170228","2017","","","86","99","Predictive modeling using machine learning is an effective method for building compiler heuristics, but there is a shortage of benchmarks. Typical machine learning experiments outside of the compilation field train over thousands or millions of examples. In machine learning for compilers, however, there are typically only a few dozen common benchmarks available. This limits the quality of learned models, as they have very sparse training data for what are often high-dimensional feature spaces. What is needed is a way to generate an unbounded number of training programs that finely cover the feature space. At the same time the generated programs must be similar to the types of programs that human developers actually write, otherwise the learning will target the wrong parts of the feature space. We mine open source repositories for program fragments and apply deep learning techniques to automatically construct models for how humans write programs. We sample these models to generate an unbounded number of runnable training programs. The quality of the programs is such that even human developers struggle to distinguish our generated programs from hand-written code. We use our generator for OpenCL programs, CLgen, to automatically synthesize thousands of programs and show that learning over these improves the performance of a state of the art predictive model by 1.27x. In addition, the fine covering of the feature space automatically exposes weaknesses in the feature design which are invisible with the sparse training examples from existing benchmark suites. Correcting these weaknesses further increases performance by 4.30x.","","Electronic:978-1-5090-4931-8; POD:978-1-5090-4932-5","10.1109/CGO.2017.7863731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863731","Benchmarking;Deep Learning;GPUs;OpenCL;Synthetic program generation","Benchmark testing;Data models;Grammar;Machine learning;Predictive models;Semantics;Training","learning (artificial intelligence);program compilers;public domain software","CLgen;OpenCL programs;deep learning techniques;hand-written code;machine learning;open source repositories mining;predictive modeling;runnable training programs","","","","","","","4-8 Feb. 2017","","IEEE","IEEE Conference Publications"
"Optimization of convolutional neural network using microcanonical annealing algorithm","V. Ayumi; L. M. R. Rere; M. I. Fanany; A. M. Arymurthy","Machine Learning and Computer Vision Laboratory, Faculty of Computer Sciences, Universitas Indonesia, Depok 16424, West Java, Indonesia","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","506","511","Convolutional neural network (CNN) is one of the most prominent architectures and algorithm in Deep Learning. It shows a remarkable improvement in the recognition and classification of objects. This method has also been proven to be very effective in a variety of computer vision and machine learning. As in other deep learning, however, training this approach is interesting yet challenging. Recently, some metaheuristic algorithms have been used to optimize CNN using Genetic Algorithm, Particle Swarm Optimization, Simulated Annealing and Harmony Search. In this paper, another type of metaheuristic algorithms with different strategy has been proposed, i.e. Microcanonical Annealing to optimize Convolutional Neural Network. The performance of the proposed method is tested using the MNIST and CIFAR-10 datasets. Although experiment results of MNIST dataset indicate the increase in computation time (1.02x-1.38x), nevertheless this proposed method can considerably enhance the performance of the original CNN (up to 4.60%). On the CIFAR10 dataset, currently, state of the art is 96.53% using fractional pooling, while this proposed method achieves 99.14%.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872787","CIFAR10;Convolutional Neural Network;MNIST;Metaheuristic;Microcanonical Annealing","Annealing;Biological neural networks;Convolution;Kinetic energy;Machine learning algorithms;Simulated annealing","computer vision;convolution;image classification;learning (artificial intelligence);neural nets;object recognition;simulated annealing","CNN optimization;DL;computer vision;convolutional neural network;deep learning;machine learning;metaheuristic algorithm;microcanonical annealing algorithm;object classification;object recognition","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Recent advances on application of deep learning for recovering object pose","W. Li; Y. Luo; P. Wang; Z. Qin; H. Zhou; H. Qiao","Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing, CO 100190, China","2016 IEEE International Conference on Robotics and Biomimetics (ROBIO)","20170302","2016","","","1273","1280","Recovering object pose is of great importance to many higher level tasks such as robotic manipulation, scene understanding and augmented reality to name a few. Following the recent major breakthroughs in many computer vision tasks made by the deep learning, intensive research to experiment with it also in the task of recovering object pose is conducting. This paper aims to review the state-of-the-art progress on deep learning based pose estimation methods. Firstly, we introduce some popular datasets together with their relevant attributes. Secondly, the deep learning based pose estimation methods are summarized and categorized, and detailed descriptions of representative methods are provided, and their pros and cons are examined. Thirdly, evaluation protocol and comparable performance of reviewed approaches are given. Finally, we highlight the advantages of deep learning based pose estimation methods and provide insights for future.","","Electronic:978-1-5090-4364-4; POD:978-1-5090-4365-1; USB:978-1-5090-4363-7","10.1109/ROBIO.2016.7866501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866501","","Cameras;Clutter;Machine learning;Pose estimation;Shape;Three-dimensional displays;Two dimensional displays","computer vision;learning (artificial intelligence);pose estimation","computer vision;deep learning based pose estimation method;object pose recovery","","","","","","","3-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"EE2: Intelligent machines: Will the technological singularity happen?","S. Pellerano; S. Choi; J. Rabaey","Intel, Hillsboro, OR, United States of America","2017 IEEE International Solid-State Circuits Conference (ISSCC)","20170306","2017","","","521","521","Artificial intelligence (AI) will no doubt have a significant impact on society in the coming years. But how intelligent can a machine be? When artificially-general intelligence is capable of recursive self-improvement, a hypothetical ‘runaway effect’ — an intelligence explosion — might happen, yielding an intelligence surpassing all current human control or understanding. This event is known as the technological singularity; this is the point beyond which events may become unpredictable or even unfathomable to human intelligence. This panel will picture the current state of the art for AI, deep learning and robotics, and try to predict where this technology is heading.","","Electronic:978-1-5090-3758-2; POD:978-1-5090-3759-9","10.1109/ISSCC.2017.7870486","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870486","","Face;Google;Intelligent systems;Knowledge discovery;Machine learning;Robots","","","","","","","","","5-9 Feb. 2017","","IEEE","IEEE Conference Publications"
"Damaged fingerprint classification by Deep Learning with fuzzy feature points","Y. Wang; Z. Wu; J. Zhang","School of Communication Engineering, Hangzhou Dianzi University, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","20170216","2016","","","280","285","As the world enters the information age, the need for identity verification becomes more and more urgent. Therefore, fingerprint identification technology is widely used in the field of personal authentication. With the efforts of researchers, the algorithms of fingerprint recognition have currently made great progress. However, the authentication of low quality fingerprint still needs further improvement. Aiming at imperfect fingerprints, we propose an improved damaged fingerprint recognition algorithm by feature points, based on Convolution Neural Network (CNN) of Deep Learning. Finally, the recognition rate based on Deep Learning is compared with the fingerprint identification algorithm based on Kernel Principal Component Analysis (KPCA) and k-Nearest Neighbor (KNN). Experiments' results show that fingerprint recognition based on Deep Learning has a higher recognition rate.","","Electronic:978-1-5090-3710-0; POD:978-1-5090-3711-7; USB:978-1-5090-3709-4","10.1109/CISP-BMEI.2016.7852722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852722","Convolution Neural Network (CNN);fingerprint identification;fuzzy feature points;recognition rate","Biological neural networks;Convolution;Feature extraction;Fingerprint recognition;Image matching;Machine learning;Training","fingerprint identification;fuzzy set theory;learning (artificial intelligence);neural nets","CNN;convolution neural network;damaged fingerprint classification;deep learning;fingerprint recognition;fuzzy feature points;identity verification;low quality fingerprint authentication;personal authentication","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"Bidirectional LSTMs — CRFs networks for bangla POS tagging","F. Alam; S. A. Chowdhury; S. R. H. Noori","Department of Information Engineering and Computer Science, University of Trento, Italy","2016 19th International Conference on Computer and Information Technology (ICCIT)","20170223","2016","","","377","382","Part-of-speech (POS) information is one of the fundamental components in the natural language processing pipeline, which helps in extracting higher-level information such as named entities, discourse, and syntactic structure of a sentence. For some languages, such as English, Dutch, and Chinese, it is considered as a solved problem due to the higher accuracy (97%) of the predicted system. Significant efforts have been made for such languages in terms of making the data publicly accessible and also organizing evaluation campaigns. Compared to that there are very fewer efforts for Bangla (ethnonym: Bangla; exonym: Bengali). In this paper, we present a knowledge poor approach for POS tagging, which we evaluated using publicly accessible dataset from LDC. The motivation of our approach is that we did not want to rely on any existing resources such as lexicon or named entity recognizer for designing the system as they are not publicly available and difficult to develop. We have not used any handcrafted features, rather we employed distributed representations of word and characters. We designed the system using Long Short Term Memory (LSTM) neural networks followed by Conditional Random Fields (CRFs) for designing the model with an inclusion of pre-trained word embedded model. We obtained promising results with an accuracy of 86.0%.","","Electronic:978-1-5090-4090-2; POD:978-1-5090-4091-9","10.1109/ICCITECHN.2016.7860227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860227","Bangla;Deep Learning;POS tagging","Hidden Markov models;Logic gates;Machine learning algorithms;Natural language processing;Neural networks;Tagging;Training","natural language processing;neural nets;speech processing","Bangla POS tagging;Bengali;Chinese;Dutch;English;LSTM neural networks;POS information;bidirectional LSTM-CRF networks;characters;conditional random fields;lexicon;long short term memory neural networks;named entities;named entity recognizer;natural language processing pipeline;part-of-speech information;pre-trained word embedded model;sentence;syntactic structure","","","","","","","18-20 Dec. 2016","","IEEE","IEEE Conference Publications"
"Automatic Scoring of Multiple Semantic Attributes With Multi-Task Feature Leverage: A Study on Pulmonary Nodules in CT Images","S. Chen; J. Qin; X. Ji; B. Lei; T. Wang; D. Ni; J. Z. Cheng","Department of Biomedical Engineering, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China","IEEE Transactions on Medical Imaging","20170301","2017","36","3","802","814","The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge this gap, we exploit three multi-task learning (MTL) schemes to leverage heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN), as well as hand-crafted Haar-like and HoG features, for the description of 9 semantic features for lung nodules in CT images. We regard that there may exist relations among the semantic features of “spiculation”, “texture”, “margin”, etc., that can be explored with the MTL. The Lung Image Database Consortium (LIDC) data is adopted in this study for the rich annotation resources. The LIDC nodules were quantitatively scored w.r.t. 9 semantic features from 12 radiologists of several institutes in U.S.A. By treating each semantic feature as an individual task, the MTL schemes select and map the heterogeneous computational features toward the radiologists' ratings with cross validation evaluation schemes on the randomly selected 2400 nodules from the LIDC dataset. The experimental results suggest that the predicted semantic scores from the three MTL schemes are closer to the radiologists' ratings than the scores from single-task LASSO and elastic net regression methods. The proposed semantic attribute scoring scheme may provide richer quantitative assessments of nodules for better support of diagnostic decision and management. Meanwhile, the capability of the automatic association of medical image contents with the clinical semantic terms by our method may also assist the development of medical search engine.","0278-0062;02780062","","10.1109/TMI.2016.2629462","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745891","Computer-aided diagnosis (CAD);computed tomography (CT);deep learning;feature learning;lung nodule;multi-task learning","Computational modeling;Computed tomography;Lungs;Machine learning;Medical diagnostic imaging;Semantics","computerised tomography;feature extraction;lung;medical image processing;pneumodynamics;regression analysis","CT images;HoG features;Lung Image Database Consortium data;clinical semantic terms;computer-aided diagnosis performance;convolutional neural network;deep learning models;elastic net regression methods;heterogeneous computational features;lung nodules;medical image;medical search engine;multitask learning schemes;pulmonary nodules;semantic features;single-task LASSO;stacked denoising autoencoder","","","","","","20161116","March 2017","","IEEE","IEEE Journals & Magazines"
"Camera anomaly detection based on morphological analysis and deep learning","L. Dong; Y. Zhang; C. Wen; H. Wu","School of Computer Science, Zhejiang University of Technology, Hangzhou, China","2016 IEEE International Conference on Digital Signal Processing (DSP)","20170302","2016","","","266","270","Recently, camera anomaly detection has attracted increasing interest in order to generate real-time alerts of camera malfunction for video surveillance systems. The existing camera anomaly detection methods still haven't enough ability to detect comprehensive types of anomaly, and lack the self-improvement ability in the case of miscarriage of justice by self-learning. So, this paper proposes a morphological analysis and deep learning based camera anomaly detection method to detect comprehensive types of anomaly. Morphological analysis is used to detect simple camera anomalies to accelerate the processing speed, and deep learning is utilized to detect complicated camera anomalies to improve the accuracy. The experimental results show that the detection accuracy of the proposed method achieves more than 95%.","","Electronic:978-1-5090-4165-7; POD:978-1-5090-4166-4","10.1109/ICDSP.2016.7868559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868559","camera anomaly detection;convolution neural networks;morphological analysis;video surveillance system","Brightness;Cameras;Feature extraction;Image color analysis;Image edge detection;Machine learning;Surveillance","cameras;feature extraction;learning (artificial intelligence);video signal processing;video surveillance","camera anomaly detection;deep learning;morphological analysis;video surveillance system","","","","","","","16-18 Oct. 2016","","IEEE","IEEE Conference Publications"
"Hybrid decision tree and logistic regression classifier for email spam detection","A. Wijaya; A. Bisri","Informatics Engineering Department, Mohammad Husni Thamrin University, Jakarta, Indonesia","2016 8th International Conference on Information Technology and Electrical Engineering (ICITEE)","20170228","2016","","","1","4","Email spam is an increasing problem because it disrupting and time consuming for user, since the easy and cheap of sending email. Email Spam filtering can be done with a binary classification with machine learning as classifier. To date, email spam detection still challenging since the email spam still happens a lot and the detection still need improvement. Decision Tree (DT) is one of famous classifier since DT able to handle nominal and numerical attributes and increasing the efficiency of computing. However, DT has a weakness in over-sensitivity to the training set and the noise data or instance that can degrade the performance. In this study, we propose hybrid combination Logistic Regression (LR) and DT for email spam detection. LR is used for reduce noisy data or instance before data feed to DT induction. Noisy data reducing is done by LR by filtering correct prediction with certain false negative threshold. In this study, Spambase dataset is used to evaluate the proposed method. From the experiment, the result shows that proposed method yield impressive and promising result with the accuracy is 91.67%. It can be concluded that LR able to improve DT performance by reducing noisy data.","","Electronic:978-1-5090-4139-8; POD:978-1-5090-4140-4; USB:978-1-5090-4138-1","10.1109/ICITEED.2016.7863267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863267","decision tree;email spam detection;logistic regression","Decision trees;Detectors;Electronic mail;Filtering;Machine learning algorithms;Noise measurement;Training","data reduction;information filters;pattern classification;regression analysis;security of data;unsolicited e-mail","DT induction;LR;email spam detection;false negative threshold;hybrid decision tree;logistic regression classifier;noisy data reduction","","","","","","","5-6 Oct. 2016","","IEEE","IEEE Conference Publications"
"Ball-cradling using reinforcement algorithms","R. Özakar; B. Özyer","Erzurum Teknik &#x00DC;niversitesi, Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;","2016 National Conference on Electrical, Electronics and Biomedical Engineering (ELECO)","20170213","2016","","","135","141","To successfully learn and execute a new task autonomously is a complex problem for robots. Planning of this learning is based on human behaviors and human learning. For this purpose, a machine learning method, reinforcement learning has been developed. In this work, we modeled a problem called ball-cradling, where we made moving links as fingers, we taught the links using reinforcement algorithms to balance a ball without dropping, which falls from above. Q-learning, SARSA and Adaptive Heuristic Critic (AHC) algorithms were tested using Box2d simulator on this problem. Ball's position, ball's linear velocity, links' angle and links' angular velocity were used as state-space parameters. In the results, system managed to balance the ball without dropping it to the ground in single-link system for all algorithms. In two-link system, a successful learning hasn't been achieved. AHC algorithm showed a better learning performance compared to other algorithms.","","POD:978-605-01-0923-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851968","","Adaptation models;Amplitude shift keying;Dogs;Learning systems;Machine learning algorithms;Planning;Robots","control engineering computing;digital simulation;learning (artificial intelligence);manipulators;state-space methods","AHC;Box2d simulator;Q-learning;SARSA;adaptive heuristic critic algorithms;ball-cradling;human behaviors;human learning;machine learning method;moving links;reinforcement algorithms;single-link system;state-space parameters","","","","","","","1-3 Dec. 2016","","IEEE","IEEE Conference Publications"
"Performance enhancement of cooperative learning algorithms by improved decision making for context based application","D. A. Vidhate; P. Kulkarni","Department of Computer Engineering, College of Engineering, Pune, India","2016 International Conference on Automatic Control and Dynamic Optimization Techniques (ICACDOT)","20170316","2016","","","246","252","Cooperation in learning (CL) can be understood in a multiagent system. In this the agents are capable of learning from both their own experiments and other agents' knowledge and expertise. Implementation of CL is a complicated task in the real world. In distributed systems several agents cooperate to achieve a common goal or accomplish a shared task. In particular, if there are different people or organizations with different goals and information, then a multiagent system (MAS) is needed to handle their interactions. In this paper, various issues related with cooperative machine learning are studied and implemented. A new set of improved cooperative learning algorithms is proposed in the paper. Expertness measuring criteria which were used in earlier work is further enhanced in proposed method. Six methods for measuring the agents' expertness are used i.e. Normal (Nrm), Absolute (Abs), Positive (P), Negative (N), Certainty (Cer) and Entropy (Ent). The novelty of this approach lies in the implementation of Weighted Strategy Sharing with expertness measuring criteria by means of Q-learning, Sarsa learning, Q(λ) and Sarsa(λ) learning algorithms. The paper shows implementation results and performance comparison of all these algorithms.","","Electronic:978-1-5090-2080-5; POD:978-1-5090-2081-2","10.1109/ICACDOT.2016.7877588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877588","Cooperative Learning;Q Learning;Reinforcement learning;Sarsa Learning;Weighted Strategy Sharing","Entropy;Heuristic algorithms;Hospitals;Machine learning algorithms;Multi-agent systems;Organizations;Weight measurement","decision making;learning (artificial intelligence);multi-agent systems","Q(λ) learning algorithms;Q-learning;Sarsa learning;Sarsa(λ) learning algorithms;agent expertness measuring criteria;context based application;cooperative learning algorithms;cooperative machine learning;decision making;distributed systems;multiagent system;weighted strategy sharing","","","","","","","9-10 Sept. 2016","","IEEE","IEEE Conference Publications"
"SAR Automatic Target Recognition Based on Euclidean Distance Restricted Autoencoder","S. Deng; L. Du; C. Li; J. Ding; H. Liu","National Lab of Radar Signal Processing, Xidian University, Xi&#x0027;an710071, China, and Collaborative Innovation Center of Information Sensing and Understanding at Xidian University, Xi&#x0027;an 710071, China&#x00A0;(e-mail: dsfrank18@126.com).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2017","PP","99","1","11","Deep learning algorithms have been introduced into target recognition of synthetic aperture radar (SAR) images for extracting deep features because of its accuracy on various recognition problems with sufficient training samples. However, applying deep structures in recognizing SAR images may suffer lack of training samples. Therefore, a deep learning method is proposed in this study based on a multilayer autoencoder (AE) combined with a supervised constraint. We bind the original AE algorithm with a restriction based on Euclidean distance to use the limited training images well. Moreover, a dropout step is added to our algorithm, which is designed to prevent overfitting caused by supervised learning. Experimental results on the MSTAR dataset demonstrate the effectiveness of the proposed method on real SAR images.","1939-1404;19391404","","10.1109/JSTARS.2017.2670083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879824","Autoencoder (AE);Euclidean distance restriction;deep learning;dropout;synthetic aperture radar (SAR) imagery;target recognition","Euclidean distance;Feature extraction;Image reconstruction;Machine learning;Synthetic aperture radar;Target recognition;Training","","","","","","","","20170316","","","IEEE","IEEE Early Access Articles"
"F3: Beyond the horizon of conventional computing: From deep learning to neuromorphic systems","M. F. Chang; J. Deguchi; V. De; M. Motomura; S. Shiratake; M. Verhelst","National Tsing Hua University, Hsinchu, Taiwan","2017 IEEE International Solid-State Circuits Conference (ISSCC)","20170306","2017","","","506","508","This forum brings together experts in software applications, system architectures, and chip designs to explore cognitive computing approaches over the near-, mid-, and long-term.","","Electronic:978-1-5090-3758-2; POD:978-1-5090-3759-9","10.1109/ISSCC.2017.7870481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870481","","Computer architecture;Field programmable gate arrays;Hardware;Machine learning;Neural networks;Neuromorphics","","","","","","","","","5-9 Feb. 2017","","IEEE","IEEE Conference Publications"
"Learning suite of kernel feature spaces enhances SMR-based EEG-BCI classification","B. Abibullaev","Robotics and Mechatronics Deparment, School of Science And Technology, Nazarbayev University, Qabanbay Batyr Ave 53, Astana 010000, Kazakhstan","2017 5th International Winter Conference on Brain-Computer Interface (BCI)","20170220","2017","","","55","59","Brain-Computer Interface (BCI) research hopes to improve the quality of life for people with severe motor disabilities by providing a capability to control external devices using their thoughts. To control a device through BCI, neural signals of a user must be translated to meaningful control commands using various machine learning components, e.g. feature extraction, dimensionality reduction and classification, that should also be carefully designed for practical use. However, the noise and variability in the neural data pose one of the greatest challenges that in practice previously functioning BCI fails in the subsequent operation requiring re-tuning/optimization. This paper presents an idea of defining multiple feature spaces and optimal decision boundaries therein to account for noise and variability in data and improve a generalization of a learning machine. The spaces are defined in the Reproducing Kernel Hilbert Spaces induced by a Radial Basis Gaussian function. Then the learning is done via L1-regularized Support Vector Machines. The central idea behind our approach is that a classifier predicts an unseen test examples by learning more rich feature spaces with a suite of optimal hyperparameters. Empirical evaluation have shown an improved generalization performance (range 79-90%) on two class motor imagery Electroencephalography (EEG) data, when compared with other conventional machine learning methods.","","Electronic:978-1-5090-5096-3; POD:978-1-5090-5097-0","10.1109/IWW-BCI.2017.7858158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858158","","Electrodes;Electroencephalography;Kernel;Machine learning algorithms;Scalp;Support vector machines;Training","Hilbert spaces;brain-computer interfaces;electroencephalography;learning (artificial intelligence);medical signal processing;radial basis function networks;support vector machines","L1-regularized support vector machines;SMR-based EEG-BCI classification;brain-computer interface;electroencephalography;kernel feature spaces;machine learning components;neural signals;people with severe motor disabilities;radial basis Gaussian function;reproducing kernel Hilbert spaces","","","","","","","9-11 Jan. 2017","","IEEE","IEEE Conference Publications"
"The shopping assistant Robot design based on ROS and deep learning","Hang Su; Yusi Zhang; Jingsong Li; Jie Hu","Key Laboratory of Fiber Optic Sensing Technology and Information Processing, Ministry of Education, Wuhan University of Technology, China","2016 2nd International Conference on Cloud Computing and Internet of Things (CCIOT)","20170302","2016","","","173","176","As the traditional service robots' artificial intelligence bottlenecks, there is a huge gap between service robots and human intelligence in the cognitive and learning discipline. So the service robots could not be widely applied. As deep learning theory is proposed in 2012, it may lead to a generation leap forward in machine learning discipline, so as to improving the traditional robot's cognitive algorithms. This paper studies the principle of three-dimensional Kinect sensor and the deep learning framework of CNN. We proposed a shopping assistant robot designing method which combined Robot Operation System and deep learning method. Firstly, the ROS packages for the service robot are designed. Secondly, Kinect sensors are used for acquiring the information in the robot. Finally, we use simulation to evaluated the design.","","Electronic:978-1-4673-9822-0; POD:978-1-4673-9823-7","10.1109/CCIOT.2016.7868328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868328","Deep Learning;Kinect;Robot;Robot Operation System","Cloud computing;Machine learning;Robot sensing systems;Service robots;Visualization","cognition;image sensors;learning (artificial intelligence);operating systems (computers);robot programming;robot vision;service robots","CNN;Kinect sensors;ROS packages;deep learning;human intelligence;machine learning;robot cognitive algorithms;robot operation system;service robot artificial intelligence;shopping assistant robot design;three-dimensional Kinect sensor","","","","","","","22-23 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep Kernel: Learning Kernel Function from Data Using Deep Neural Network","L. Le; J. Hao; Y. Xie; J. Priestley","Dept. of Stat. & Anal. Sci., Kennesaw State Univ., Kennesaw, GA, USA","2016 IEEE/ACM 3rd International Conference on Big Data Computing Applications and Technologies (BDCAT)","20170316","2016","","","1","7","Kernel function implicitly maps data from its original space to a higher dimensional feature space. Kernel based machine learning algorithms are typically applied to data that is not linearly separable in its original space. Although kernel methods are among the most elegant part of machine learning, it is challenging for users to define or select a proper kernel function with optimized parameter settings for their data. In this paper, we propose a novel method called Deep Kernel that can automatically learn a kernel function from data using deep learning. The deep kernel is currently utilized in classification, and dimension reduction and visualization. For the classification task, we evaluate the deep kernel method by comparing its performance with the optimized Gaussian kernels, both using support vector machines as the decision model, on different types of datasets. The experimental results show that the proposed deep kernel method outperforms the traditional methods with Gaussian kernels on most of the data sets. For the dimension reduction and visualization task, the deep kernel is used along with kernel PCA. The results are also compared and contrasted with using the RBF kernel with multiple parameters. The deep kernel is shown to be more powerful in dimension reduction and visualization than the RBF kernel.","","Electronic:978-1-4503-4617-7; POD:978-1-5090-4468-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877043","Classification;Deep Kernel;Deep Learning;Dimension reduction;Kernel Methods;Support Vector Machines;Visualization","Data models;Data visualization;Kernel;Machine learning;Neural networks;Principal component analysis;Support vector machines","Gaussian processes;data reduction;data visualisation;learning (artificial intelligence);neural nets;pattern classification;principal component analysis;support vector machines","classification task;datasets;decision model;deep kernel;deep learning;deep neural network;dimension reduction;kernel PCA;kernel based machine learning;learning kernel function;optimized Gaussian kernels;principal component analysis;support vector machines;visualization task","","","","","","","6-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Random forest based classification of diseases in grapes from images captured in uncontrolled environments","B. Sandika; S. Avil; S. Sanat; P. Srinivasu","TCS Innovation Labs Mumbai, Tata Consultancy Services, Yantra Park, Thane, India","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","1775","1780","Grapes have proved to be one of the most cost-effective and profitable crops for cultivation in India. This crop however is affected by numerous diseases which cause significant yield losses every year. Early detection of diseases and proper identification of their severity will help to take decisions on proper usage of pesticides in terms of their type and quantity, which eventually will help in maintaining the crop health. In this work, we propose a system for classifying three diseases affecting grapes - Anthracnose, Powdery Mildew and Downy Mildew - and identifying the severity of these diseases using image processing and machine learning algorithms. The key contribution of the proposed system is to consider images of grapes leaves with complex background which are captured under an uncontrolled environment. We compare the performance of four machine learning algorithms, PNN, BPNN, SVM and Random Forest, for separating the background from disease patches and classifying between the different diseases. We also study the performance of different texture features like local texture filters, local binary patterns (LBP), GLCM features, and some statistical features in RGB plane for classification. The proposed system achieves best classification accuracy of 86% using Random Forest and GLCM features.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7878133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7878133","","Agriculture;Classification algorithms;Diseases;Image color analysis;Machine learning algorithms;Pipelines;Sun","backpropagation;crops;forestry;geophysical image processing;matrix algebra;plant diseases;support vector machines","Anthracnose;BPNN algorithm;Downy Mildew;GLCM features;India;Powdery Mildew;RGB plane;SVM algorithm;cost-effective crops;crop health;cultivation;disease patches;diseases;grapes leaves;gray level cooccurrence matrices;image processing;local binary patterns;local texture filters;machine learning;pesticides;profitable crops;random forest based classification;statistical features;texture features;uncontrolled environments","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"DLTSR: A Deep Learning Framework for Recommendation of Long-tail Web Services","B. Bai; Y. Fan; W. Tan; J. Zhang","","IEEE Transactions on Services Computing","","2017","PP","99","1","1","With the growing popularity of web services, more and more developers are composing multiple services into mashups. Developers show an increasing interest in non-popular services (i.e., long-tail ones), however, there are very scarce studies trying to address the long-tail web service recommendation problem. The major challenges for recommending long-tail services accurately include severe sparsity of historical usage data and unsatisfactory quality of description content. In this paper, we propose to build a deep learning framework to address these challenges and perform accurate long-tail recommendations. To tackle the problem of unsatisfactory quality of description content, we use stacked denoising autoencoders (SDAE) to perform feature extraction. Additionally, we impose the usage records in hot services as a regularization of the encoding output of SDAE, to provide feedback to content extraction. To address the sparsity of historical usage data, we learn the patterns of developers’ preference instead of modeling individual services. Our experimental results on a real-world dataset demonstrate that, with such joint autoencoder based feature representation and content-usage learning framework, the proposed algorithm outperforms the state-of-the-art baselines significantly.","1939-1374;19391374","","10.1109/TSC.2017.2681666","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876831","Deep learning;long-tail;mashup creation;service recommendation","Data mining;Ecosystems;Machine learning;Mashups;Neural networks;Noise reduction","","","","","","","","20170313","","","IEEE","IEEE Early Access Articles"
"Comparison of Naive Bayes smoothing methods for Twitter sentiment analysis","R. A. Ramadhani; F. Indriani; D. T. Nugrahadi","Faculty of Mathematics and Natural Science, Universitas Lambung Mangkurat, Banjarbaru, Indonesia","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","287","292","In sentiment analysis, the absence of sample features in the training data will lead to misclassification. Smoothing is used to overcome this problem. Previous studies show that there are differences in performance obtained by the various smoothing techniques against various types of data. In this paper, we compare the performance of Naive Bayes smoothing methods in improving the performance of sentiment analysis of tweets. The results indicated that Laplace smoothing is superior to Dirichlet smoothing and Absolute Discounting with the micro-average value of F1-Score 0.7234 and macro-average F1-Score 0.7182.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872720","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872720","Absolute Discounting;Data Mining;Dirichlet;Laplace;Naive Bayes;Sentiment Analysis;Smoothing","Machine learning algorithms;Sentiment analysis;Smoothing methods;Support vector machines;Training;Training data;Twitter","Bayes methods;sentiment analysis;smoothing methods;social networking (online)","Dirichlet smoothing;Laplace smoothing;Naive Bayes smoothing methods;Twitter sentiment analysis;absolute discounting;training data;tweets","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"DLAU: A Scalable Deep Learning Accelerator Unit on FPGA","C. Wang; L. Gong; Q. Yu; X. Li; Y. Xie; X. Zhou","University of Science and Technology of China, Hefei, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20170216","2017","36","3","513","517","As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. However, the size of the networks becomes increasingly large scale due to the demands of the practical applications, which poses significant challenge to construct a high performance implementations of deep learning neural networks. In order to improve the performance as well as to maintain the low power cost, in this paper we design deep learning accelerator unit (DLAU), which is a scalable accelerator architecture for large-scale deep learning networks using field-programmable gate array (FPGA) as the hardware prototype. The DLAU accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications. Experimental results on the state-of-the-art Xilinx FPGA board demonstrate that the DLAU accelerator is able to achieve up to 36.1× speedup comparing to the Intel Core2 processors, with the power consumption at 234 mW.","0278-0070;02780070","","10.1109/TCAD.2016.2587683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505926","Deep learning;field-programmable gate array (FPGA);hardware accelerator;neural network","Biological neural networks;Computer architecture;Field programmable gate arrays;Hardware;Machine learning;Neurons","field programmable gate arrays;neural nets;power consumption","DLAU accelerator;Intel Core2 processors;Xilinx FPGA board;complex learning problem;deep learning neural networks;field-programmable gate array;large-scale deep learning networks;machine learning;power 234 mW;power consumption;scalable deep learning accelerator unit","","","","","","20160707","March 2017","","IEEE","IEEE Journals & Magazines"
"Model and metric choice of image retrieval system based on deep learning","L. Wang; X. Wang","School of Computer Science, Shaanxi Normal University, Xi'an, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","20170216","2016","","","390","395","In the era of big data, Content-Based Image Retrieval combined with deep learning technology gradually becomes the mainstream. This method can overcome some drawbacks of traditional CBIR, but at the same time there are still some problems to be solved, such as: The extracted feature dimension (generally more than 2000) is higher, which is not beneficial for efficient data storage and fast real-time query on a large scale; And the measurement method for feature matching is difficult to be determined, since the typical method based on distance is designed in the low dimension, but in high dimensional space curse of dimensionality can make those former methods may be no longer suitable. In this paper we discuss a fast efficient CBIR to improve the performace of image retrieval system, through contrasting different model and metric choices. Contrast experiments show that 4 kinds of distances (namely Euclidean Distance, Minkowski Distance, Cosine Distance, Pearson Correlation Distance) is more suitable for processing the similarity measurement on high-dimensional feature, and 5 kinds of models ( namely vgg-m-128, vgg-m-1024, vgg-m-2048, vgg-verydeep-16, vgg-verydeep-19) have higher average query precision for image retrieval task.","","Electronic:978-1-5090-3710-0; POD:978-1-5090-3711-7; USB:978-1-5090-3709-4","10.1109/CISP-BMEI.2016.7852742","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852742","convolutional neural network;deep learning;image retrieval","Biological neural networks;Correlation;Euclidean distance;Feature extraction;Image retrieval;Machine learning","Big Data;content-based retrieval;feature extraction;image matching;image retrieval;learning (artificial intelligence)","Big Data;Euclidean distance;Minkowski distance;Pearson correlation distance;content-based image retrieval;cosine distance;curse of dimensionality;deep learning;feature dimension extraction;feature matching","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"Research on modulation identification of digital signals based on deep learning","J. Li; L. Qi; Y. Lin","College of Information and Communication Engineering, Harbin Engineering University, Heilongjiang, China, 150001","2016 IEEE International Conference on Electronic Information and Communication Technology (ICEICT)","20170316","2016","","","402","405","Modulation identification shows great significance for any receiver that has little knowledge of the modulation scheme of the received signal. In this paper, we compare the performance of a deep autoencoder network and three shallow algorithms including SVM, Naive Bayes and BP neural network in the field of communication signal modulation recognition. Firstly, cyclic spectrum is used to pre-process the simulation communication signals, which are at various SNR (from -10dB to 10dB). Then, a deep autoencoder network is established to approximate the internal properties from great amount of data. A softmax regression model is used as a classifier to identify the five typical communication signals, which are FSK, PSK, ASK, MSK, QAM. The results for the experiment illustrate the excellent classification performance of the networks. At last, we discuss the comparison of these methods and three traditional shallow machine learning models.","","Electronic:978-1-5090-0729-5; POD:978-1-5090-0730-1; USB:978-1-5090-0728-8","10.1109/ICEICT.2016.7879726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879726","Autoencoders;Cyclic spectrum;deep learning;softmax","Amplitude shift keying;Frequency shift keying;Machine learning;Phase shift keying;Quadrature amplitude modulation;Signal to noise ratio","amplitude shift keying;backpropagation;belief networks;frequency shift keying;learning (artificial intelligence);minimum shift keying;neural nets;pattern classification;phase shift keying;quadrature amplitude modulation;radiocommunication;regression analysis;support vector machines;telecommunication computing","ASK;BP neural network;FSK;MSK;Naive Bayes;PSK;QAM;SVM;cyclic spectrum;deep autoencoder network;deep autoencoder network performance;deep learning;digital modulation signal identification;shallow machine learning model;softmax regression model","","","","","","","20-22 Aug. 2016","","IEEE","IEEE Conference Publications"
"Detecting Malicious Server Based on Server-to-Server Realation Graph","Z. Wang; F. Zou; B. Pei; W. He; L. Pan; Z. Mao; L. Li","Sch. of Inf. Security Eng., Shanghai Jiao Tong Univ. Shanghai, Shanghai, China","2016 IEEE First International Conference on Data Science in Cyberspace (DSC)","20170302","2016","","","698","702","The rapid development of Internet attack has posed severe threats to information security. Therefore, it's of great interest to both the Internet security companies and researchers to develop novel methods which are capable of protecting users against new threats. However, the sources of these network attack varies. Existing malware detectors and intrusion detectors mostly treat the web logs separately using supervised learning algorithms. Meanwhile, using features beyond network connection content are starting to be leveraged for Internet server classification. In this paper, based on the Server-to-Server Relation Graph, we present a network Server classification method by analyzing the client distribution of each server. When constructing Server-to-Server Relation graph, k-nearest neighbors are chosen as adjacent nodes for each server node, and being compared with radial basis function network. Files are connected with edges representing the similarity of their client set. In the machine learning part, we used Label propagation algorithm, a semi-supervised learning algorithm which propagates class labels on a graph. We evaluate the effectiveness of our proposed method on a real and large dataset. Experimental results demonstrate that the precision of our method is acceptable and worthwhile.","","Electronic:978-1-5090-1192-6; POD:978-1-5090-1193-3","10.1109/DSC.2016.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866212","Label propagation;Malicious Server Detection;Server-to-Server Relation graph;kNN","Classification algorithms;IP networks;Internet;Machine learning algorithms;Malware;Servers;Telecommunication traffic","Internet;invasive software;learning (artificial intelligence);network servers;pattern classification;radial basis function networks","Internet attack;Internet security;Internet server classification;Label propagation algorithm;Web logs;client set;files;information security;intrusion detectors;k-nearest neighbors;machine learning;malicious server;malware detectors;network attack;network connection content;network server classification;radial basis function network;semisupervised learning algorithms;server node;server-to-server realation graph","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Hyper-heuristic general video game playing","A. Mendes; J. Togelius; A. Nealen","Department of Computer Science, New York University, New York, New York 11021","2016 IEEE Conference on Computational Intelligence and Games (CIG)","20170223","2016","","","1","8","In general video game playing, the challenge is to create agents that play unseen games proficiently. Stochastic tree search algorithms, like Monte Carlo Tree Search, perform relatively well on this task. However, performance is non-transitive: different agents perform best in different games, which means that there is not a single agent that is the best in all the games. Rather, some types of games are dominated by a few agents whereas other different agents dominate other types of games. Thus, it should be possible to construct a hyper-agent that selects from a portfolio, in which constituent sub-agents will play a new game best. Since there is no knowledge about the games, the agent needs to use available features to predict the most suitable algorithm. This work constructs such a hyper-agent using the General Video Game Playing Framework (GVGAI). The proposed method achieves promising results that show the applicability of hyper-heuristics in general video game playing and related tasks.","","Electronic:978-1-5090-1883-3; POD:978-1-5090-1884-0; USB:978-1-5090-1882-6","10.1109/CIG.2016.7860398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860398","","Artificial intelligence;Feature extraction;Games;Heuristic algorithms;Machine learning algorithms;Portfolios;Search problems","computer games;multi-agent systems","GVGAI;general video game playing;hyperagent construction","","","","","","","20-23 Sept. 2016","","IEEE","IEEE Conference Publications"
"Using support vector machine for online purchase predication","X. Liu; J. Li","School of Economics and Management, Beijing Jiaotong University, Beijing, China","2016 International Conference on Logistics, Informatics and Service Sciences (LISS)","20170216","2016","","","1","6","E-commerce has become a vital contributor to China's national economy. A mass of users' behavioral data on E-commerce platforms such as browse, click and purchase have being accumulated during DT era. Using machine learning algorithms to explore patterns behind big data grows into a new focus of research. In this paper, firstly, we use SQL Server to do feature extraction on those behavioral data. Secondly, Libsvm, a software package based on SVM, is used to train the features collected above to build a predicting model. Finally, we employ the model to predict the future buying conditions of online consumers and acquire a desirable outcome. Thus, to a certain extent, our study has a practical significance to discover regular patterns of online shopping as well as improve products recommendation accuracy and conversion rate of e-commerce.","","Electronic:978-1-5090-1102-5; POD:978-1-5090-1103-2","10.1109/LISS.2016.7854334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7854334","Behavior;Featuring Engineering;Online Shopping;Prediction;Support Vector Machine","Big data;Data mining;Data models;Feature extraction;Machine learning algorithms;Predictive models;Support vector machines","Big Data;Internet;SQL;electronic commerce;feature extraction;learning (artificial intelligence);retail data processing;support vector machines","Big Data;China national economy;DT;Libsvm;SQL server;SVM;e-commerce;feature extraction;machine learning;online purchase predication;support vector machine","","","","","","","24-27 July 2016","","IEEE","IEEE Conference Publications"
"Cattle Brand Recognition using Convolutional Neural Network and Support Vector Machines","C. Silva; D. Welfer; F. P. Gioda; C. Dornelles","Univ. Fed. do Pampa, Alegrete, Brazil","IEEE Latin America Transactions","20170214","2017","15","2","310","316","The recognition images of cattle brand in an automatic way is a necessity to governmental organs responsible for this activity. To help this process, this work presents a method that consists in using Convolutional Neural Network for extracting of characteristics from images of cattle brand and Support Vector Machines for classification. This method consists of six stages: (a) select database of images; (b) select pre-trained CNN; (c) pre-process the images and apply CNN; (d) extract images of features; (e) train and sort images (SVM); (f) evaluate the classification results. The accuracy of the method was tested on database of municipal city hall, where it achieved satisfactory results, comparable to other methods from the literature, reporting 93.28% of accuracy and 12.716 seconds of processing time, respectively.","1548-0992;15480992","","10.1109/TLA.2017.7854627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7854627","Cattle Brands;Convolutional Neural Network;Deep Learning;Recognition Images;Support Vector Machines","Computational modeling;Cows;Feature extraction;Image recognition;Machine learning;Neural networks;Support vector machines","farming;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);support vector machines;visual databases","cattle brand image recognition;convolutional neural network;image characteristics extraction;image database;image feature extraction;image preprocessing;image sorting;image training;municipal city hall;pretrained CNN;support vector machines","","","","","","","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Emergency alert prediction for elderly based on supervised learning","Kurnianingsih; L. E. Nugroho; Widyawan; L. Lazuardi; A. S. Prabuwono","Department of Electrical Engineering and Information Technology Universitas Gadjah Mada Yogyakarta, Indonesia","2016 1st International Conference on Biomedical Engineering (IBIOMED)","20170320","2016","","","1","6","At the older age, the likelihood of disability increases and hence the increasing need for long-term care and facilities to assist elderly people who endure gradual loss of body function. Early detection of changes in health condition of elderly can increase safety for elderly people in emergency conditions. Alert prediction can be viewed as an assistive technology that will deliver appropriate escalation in the earliest time so that elderly can receive immediate responses. Supervised learning can be used as a tool to predict alert in emergency condition by training historical data of elderly behaviors and conditions. This paper proposed emergency alert prediction using supervised learning algorithms. Three algorithms of supervised learning, namely deep learning, k-NN, and LVQ were used to simulate the proposed system. The objective of this paper is to investigate the performance of three algorithms in making emergency alert prediction for elderly living independently. We conducted experiments for 30 days to elderly living independently and we obtained 1038 datasets. The simulation results showed deep learning performed the best accuracy 99.57% correct. Whereas k-NN obtained the best accuracy 90.79% correct, and LVQ obtained the best accuracy 80.32%.","","Electronic:978-1-5090-4142-8; POD:978-1-5090-4143-5","10.1109/IBIOMED.2016.7869816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869816","alert prediction;assistive technology for elderly;supervised learning","Data models;Machine learning;Prediction algorithms;Senior citizens;Supervised learning;Temperature measurement;Training","geriatrics;learning (artificial intelligence);medical computing;medical disorders;patient care","LVQ;assistive technology;body function;deep learning;disability;elderly living;emergency alert prediction;emergency conditions;health condition detection;k-NN;long-term care;supervised learning algorithm","","","","","","","5-6 Oct. 2016","","IEEE","IEEE Conference Publications"
"Learning and Transferring Convolutional Neural Network Knowledge to Ocean Front Recognition","E. Lima; X. Sun; J. Dong; H. Wang; Y. Yang; L. Liu","Department of Computer Science and Technology, Ocean University of China, Qingdao, China","IEEE Geoscience and Remote Sensing Letters","20170301","2017","14","3","354","358","In this letter, we investigated how to apply a deep learning method, in particular convolutional neural networks (CNNs), to an ocean front recognition task. Exploring deep CNNs knowledge to ocean front recognition is a challenging task, because the training data is very scarce. This letter overcomes this challenge using a sequence of transfer learning steps via fine-tuning. The core idea is to extract deep knowledge of the CNN model from a large data set and then transfer the knowledge to our ocean front recognition task on limited remote sensing (RS) images. We conducted experiments on two different RS image data sets, with different visual properties, i.e., colorful and gray-level data, which were both downloaded from the National Oceanic and Atmospheric Administration (NOAA). The proposed method was compared with the conventional handcraft descriptor with bag-of-visual-words, original CNN model, and last-layer fine-tuned CNN model. Our method showed a significantly higher accuracy than other methods in both datasets.","1545-598X;1545598X","","10.1109/LGRS.2016.2643000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829262","Convolutional neural networks (CNNs);fine-tuning;ocean front recognition;transfer learning","Computer architecture;Data mining;Feature extraction;Machine learning;Neural networks;Oceans;Training data","geophysical image processing;image recognition;knowledge acquisition;learning (artificial intelligence);neural nets;oceanographic techniques;remote sensing","NOAA;bag-of-visual-words;colorful data;convolutional neural network knowledge;deep learning method;fine-tuning;gray-level data;handcraft descriptor;knowledge learning;knowledge transferring;last-layer fine-tuned CNN model;limited remote sensing images;ocean front recognition","","","","","","20170123","March 2017","","IEEE","IEEE Journals & Magazines"
"Deep learning-based learning to rank with ties for image re-ranking","P. Zhao; O. Wu; L. Guo; W. Hu; J. Yang","College of Electronic Information and Automation, Civil Aviation University of China, Tianjin","2016 IEEE International Conference on Digital Signal Processing (DSP)","20170302","2016","","","452","456","In existing learning to rank problems, the learned ranking function sorts objects according to their predicted scores. Therefore, a full-ordering object list is obtained even if two or more objects have almost identical degrees of relevance (or called objects with ties). For objects containing ties, a more reasonable ranking approach is to learn a ranking function which can judge both the preference and ties relationships among objects. In this paper, we propose a new pairwise ranking algorithm and apply it to image re-ranking. Specifically, we utilize deep learning to re-rank images based on a new loss function. The ties-relationship is considered in both training and testing process. As a result, the learned ranking function can be used to rank objects containing ties. The experimental results demonstrate the effectiveness of the proposed algorithm.","","Electronic:978-1-5090-4165-7; POD:978-1-5090-4166-4","10.1109/ICDSP.2016.7868598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868598","Deep learning;Image re-ranking;Pairwise;Ties","Automation;Feature extraction;Machine learning;Mathematical model;Network architecture;Testing;Training","image processing;learning (artificial intelligence);sorting","deep learning-based learning;full-ordering object list;image reranking;learned ranking function;object sorting;objects with ties;pairwise ranking algorithm;ties ranking","","","","","","","16-18 Oct. 2016","","IEEE","IEEE Conference Publications"
"An Improved KNN Algorithm Based on Minority Class Distribution for Imbalanced Dataset","B. Zang; R. Huang; L. Wang; J. Chen; F. Tian; X. Wei","Coll. of Telecommun. & Inf. Eng., Nanjing Univ. of Posts & Telecommun., Nanjing, China","2016 International Computer Symposium (ICS)","20170220","2016","","","696","700","K-nearest neighbor (KNN) is a popular classification algorithm with good scalability, which has been widely used in many fields. When dealing with imbalanced data, minority examples are given the same weight as majority examples in the existing KNN algorithm. In this paper, we pay more attention to the minority class than the majority class, and we increase the weight of minority class according to the local characteristic of minority class distribution. In addition, we compare the proposed algorithm with the existing Weighted Distance K-nearest neighbor (WDKNN). Experimental results show that our algorithm performs better than WDKNN in imbalanced data sets.","","Electronic:978-1-5090-3438-3; POD:978-1-5090-3439-0","10.1109/ICS.2016.0143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858565","KNN;WDKNN;imbalanced data","Classification algorithms;Euclidean distance;Machine learning algorithms;Scalability;Telecommunications;Training","data handling;pattern classification","WDKNN;imbalanced dataset;improved KNN algorithm;majority class;minority class distribution;weighted distance k-nearest neighbor","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Action recognition with temporal scale-invariant deep learning framework","H. Chen; J. Chen; R. Hu; C. Chen; Z. Wang","State Key Laboratory of Software Engineering, Wuhan University, Wuhan 430072, China; National Engineering Research Center for Multimedia Software, Computer School of Wuhan University, Wuhan 430072, China","China Communications","20170302","2017","14","2","163","172","Recognizing actions according to video features is an important problem in a wide scope of applications. In this paper, we propose a temporal scale-invariant deep learning framework for action recognition, which is robust to the change of action speed. Specifically, a video is firstly split into several sub-action clips and a keyframe is selected from each sub-action clip. The spatial and motion features of the keyframe are extracted separately by two Convolutional Neural Networks (CNN) and combined in the convolutional fusion layer for learning the relationship between the features. Then, Long Short Term Memory (LSTM) networks are applied to the fused features to formulate long-term temporal clues. Finally, the action prediction scores of the LSTM network are combined by linear weighted summation. Extensive experiments are conducted on two popular and challenging benchmarks, namely, the UCF-101 and the HMDB51 Human Actions. On both benchmarks, our framework achieves superior results over the state-of-the-art methods by 93.7% on UCF-101 and 69.5% on HMDB51, respectively.","1673-5447;16735447","","10.1109/CC.2017.7868164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868164","action recognition; CNN; LSTM;","Binary codes;Cameras;Computer vision;Feature extraction;Image motion analysis;Machine learning;Robustness","feature extraction;feature selection;feedforward neural nets;image fusion;image motion analysis;image recognition;learning (artificial intelligence);video signal processing","CNN;HMDB51 Human Actions;LSTM network;UCF-101;action prediction scores;action recognition;convolutional fusion layer;convolutional neural networks;feature fusion;keyframe selection;linear weighted summation;long short term memory networks;motion feature extraction;spatial feature extraction;temporal scale-invariant deep learning framework;video features","","","","","","","February 2017","","IEEE","IEEE Journals & Magazines"
"Motif-driven graph analysis","C. E. Tsourakakis","Harvard University, United States","2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)","20170213","2016","","","891","893","In this talk I will present data-driven algorithms for dense subgraph discovery [11], [16], and community detection [18] respectively. The proposed algorithms leverage graph motifs to attack the large near-clique detection problem, and community detection respectively. In my talk, I will focus on triangles within graphs, but our techniques extend to other motifs as well. The intuition, that has been suggested but not formalized similarly in previous works, is that triangles are a better signature of community than edges. For both problems, we provide theoretical results, we design efficient algorithms, and then show the effectiveness of our methods to multiple applications in machine learning and graph mining.","","Electronic:978-1-5090-4550-1; POD:978-1-5090-4551-8","10.1109/ALLERTON.2016.7852328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852328","","Algorithm design and analysis;Clustering algorithms;Data mining;Image edge detection;Machine learning algorithms;Partitioning algorithms;Social network services","data mining;feature extraction;graph theory;learning (artificial intelligence)","community detection;data-driven algorithms;dense subgraph discovery;graph mining applications;machine learning applications;motif-driven graph analysis;near-clique detection problem;triangles","","","","","","","27-30 Sept. 2016","","IEEE","IEEE Conference Publications"
"A deep domain adaption approach for object recognition using Multiple Model Consistency analysis","B. Pal; B. Ahmed","Department of Computer Science & Engineering, Rajshahi University of Engineering & Technology, Bangladesh","2016 9th International Conference on Electrical and Computer Engineering (ICECE)","20170216","2016","","","562","565","Domain adaption tends to transfer knowledge across domains following dissimilar distribution and where target domain has inadequate labelled samples. When knowledge is transferred from abundantly irrelevant sources negative transfer may occur resulting in poor classification of test samples. Deep learning research illustrates the semantic clustering as well as transferability of deep convolutional features for numerous tasks including domain adaption. Traditional clustering based domain adaption approaches are practical to handle negative transfer scenario. This paper presents a scheme that uses graph based consistency analysis of one supervised and another unsupervised model to effectively transfer knowledge using deep features. This approach uses local neighbourhood analysis to classify hard samples that are identified using consistency analysis of models. This method yields encouraging experimental results on benchmark domain adaption dataset compared to a single deep feature based supervised support vector machine classifier, demonstrating effective use of target domain data.","","Electronic:978-1-5090-2963-1; POD:978-1-5090-2964-8; USB:978-1-5090-2962-4","10.1109/ICECE.2016.7853982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7853982","Clustering;Deep Learning;Domain Adaption;Object Detection;SVM","Adaptation models;Clustering algorithms;Feature extraction;Knowledge transfer;Machine learning;Manifolds;Training","object recognition;support vector machines","deep convolutional features;deep domain adaption approach;graph based consistency analysis;local neighbourhood analysis;multiple model consistency analysis;object recognition;semantic clustering;support vector machine classifier;target domain data","","","","","","","20-22 Dec. 2016","","IEEE","IEEE Conference Publications"
"Improving the Detection of Noise Artifacts in Gravitational-wave Data with a Classifier Graph","X. Zhang; Y. Ji","Key Laboratory of Trustworthy Distributed Computing and Service, Ministry of Education, China. (e-mail: zhangx@bupt.edu.cn)","IEEE Access","","2017","PP","99","1","1","We propose a method for improving the classification performance of a classifier by embedding it in a graph of classifiers, termed the Classifier Graph. Our graph-based method has the advantage of enabling delicate classification from different levels of interpretation and abstraction. For the problem that the thresholds corresponding to different classifiers are correlated and thus have mutual effects on the final performance, we provide a generalization of the Receiver Operator Characteristic curve that properly tunes them jointly to obtain the optimal performance. This method is successfully applied to the detection of noise artifacts (glitches) in the gravitational-wave data. We thus obtain an up to 10 % improvement on the classification performance compared with that of a single classifier. The methods of this paper provide an effective way to improve the classification performance with multiple classifiers.","2169-3536;21693536","","10.1109/ACCESS.2017.2684902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882683","ROC curve;branching program;classification;gravitational waves;support vector machine","Detectors;Interferometers;Machine learning algorithms;Monitoring;Support vector machines;Transient analysis","","","","","","","","20170320","","","IEEE","IEEE Early Access Articles"
"Traffic light candidate elimination based on position","W. Waisakurnia; D. H. Widyantoro","School of Electrical Engineering and Informatics, Institute of Technology Bandung, INDONESIA","2016 10th International Conference on Telecommunication Systems Services and Applications (TSSA)","20170306","2016","","","1","5","There have been some traffic light detection systems developed by researchers and most of them use camera to detect traffic light. Sometimes, those systems still detect many non-traffic light objects as traffic lights. This paper presents methods for eliminating traffic light candidate based on the traffic light candidate's position in video's frame by using machine learning algorithm. The traffic light candidates are represented by bounding boxes. The candidate features include the bounding box position, its dimension as well as its ratio, relative to the video's frame size. It first trains the model of traffic light position using training data and then predicts the traffic light candidate using the same classifier as employed during learning the model. Experiment results show that the system could eliminate traffic light candidate based on position with 0.42 Precision and 0.92 Recall with Random Forest algorithm.","","Electronic:978-1-5090-5170-0; POD:978-1-5090-5171-7","10.1109/TSSA.2016.7871077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871077","detection;position;random forest;traffic light","Cameras;Image color analysis;Machine learning algorithms;Predictive models;Shape;Support vector machines;Training data","cameras;learning (artificial intelligence);pattern classification;traffic;video signal processing","bounding box position;camera;classifier;machine learning algorithm;random forest algorithm;traffic light candidate elimination;traffic light detection system;traffic light position;training data;video frame size","","","","","","","6-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep Neural Networks for traffic flow prediction","Hongsuk Yi; HeeJin Jung; Sanghoon Bae","Supercomputing Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","328","331","Traffic flow prediction is an essential function of traffic information systems. Conventional approaches, using artificial neural networks with narrow network architecture and poor training samples for supervised learning, have been only partially successful. In this paper, a deep-learning neural-network based on TensorFlow™ is suggested for the prediction traffic flow conditions, using real-time traffic data. Until now, no research has applied the TensorFlow™ deep learning neural network model to the estimation of traffic conditions. The suggested supervised model is trained by a deep learning algorithm, which uses real traffic data aggregated every five minutes. Results demonstrate that the model's accuracy rate is around 99%.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881687","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881687","deep learning neural networks;traffic prediction;transportation big data","Analytical models;Big Data;Data models;Machine learning;Optimization;Real-time systems;Transportation","learning (artificial intelligence);neural nets;traffic information systems","TensorFlow;artificial neural networks;deep learning neural network model;supervised learning;traffic condition estimation;traffic flow prediction;traffic information systems","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Toward aircraft recognition with convolutional neural networks","R. Mash; N. Becherer; B. Woolley; J. Pecarina","The Air Force Institute of Technology, Dept. of Elec. & Comp. Eng., WPAFB, OH 45433","2016 IEEE National Aerospace and Electronics Conference (NAECON) and Ohio Innovation Summit (OIS)","20170216","2016","","","225","232","We summarize the history and state of the art in Convolutional Neural Networks (CNNs), which constitute a significant advancement in pattern recognition. As a demonstration of capability, we address the problem of automatic aircraft identification during refueling approach. In this paper we describe the history of CNN development and provide a high level overview of the state of the art and a summary of leading CNN libraries with CUDA support. Finally, we demonstrate an application of CNN technology to autonomous aerial refueling and identify areas of follow-on research.","","Electronic:978-1-5090-3441-3; POD:978-1-5090-3442-0","10.1109/NAECON.2016.7856803","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7856803","Aerial Refueling;Automatic Aircraft Identification;CNN;Deep Learning","Biological neural networks;Kernel;Machine learning;Neurons;Pattern recognition;Training;Visualization","aircraft;neural nets;object recognition;pattern recognition","CNN;CUDA support;aircraft recognition;automatic aircraft identification;autonomous aerial refueling;convolutional neural networks;pattern recognition","","","","","","","25-29 July 2016","","IEEE","IEEE Conference Publications"
"Tutorials","A. Sheikholeslami","","2017 IEEE International Solid-State Circuits Conference (ISSCC)","20170306","2017","","","498","499","There are a total of 10 tutorials this year on 10 different topics. Each tutorial, selected through a competitive process within each subcommittee of the ISSCC, presents the basic concepts and working principles of a single topic. These tutorials are intended for non-experts, graduate students and practicing engineers who wish to explore and understand a new topic.","","Electronic:978-1-5090-3758-2; POD:978-1-5090-3759-9","10.1109/ISSCC.2017.7870478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870478","","Flash memories;Integrated circuit modeling;Machine learning;Phase locked loops;Transceivers;Tutorials","","","","","","","","","5-9 Feb. 2017","","IEEE","IEEE Conference Publications"
"Deep Representation for Finger-vein Image Quality Assessment","H. Qin; M. A. El Yacoubi","SAMOVAR, Telecom SudParis, CNRS, University Paris Saclay, 9 rue Charles Fourier, 91011 Evry Cedex, France. (e-mail: huafeng.qin@telecom-sudparis.eu)","IEEE Transactions on Circuits and Systems for Video Technology","","2017","PP","99","1","1","Finger-vein biometrics has been extensively investigated for personal authentication. One of the open issues in finger-vein verification is the lack of robustness against image quality degradation. Spurious and missing features in poor quality images may degrade the system performance. Despite recent advances in finger-vein quality assessment, current solutions depend on domain knowledge. In this work, we propose a deep Neural Network (DNN) for representation learning to predict image quality using very limited knowledge. Driven by the primary target of biometric quality assessment, i.e. verification error minimization, we assume that low quality images are falsely rejected in a verification system. Based on this assumption, the low and high quality images are labeled automatically. We then train a DNN on the resulting dataset to predict image quality. To further improve DNN’s robustness, the finger vein image is divided into various patches, on which a patch-based DNN is trained. The deepest layers associated with the patches form together a complementary and an over-complete representation. Subsequently, the quality of each patch from a testing image is estimated and the quality scores from the image patches are conjointly input to P-SVM to boost quality assessment performance. To the best of our knowledge, this is the first proposed work of deep learning-based quality assessment, not only for finger vein biometrics, but also for other biometrics in general. The experimental results on two public finger-vein databases show that the proposed scheme accurately identifies high and low quality images and significantly outperforms existing approaches in terms of the impact on equal error rate (EER) decrease.","1051-8215;10518215","","10.1109/TCSVT.2017.2684826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882698","Biometrics;Deep Learning;Deep Neural Network;Finger-vein quality assessment;Representation Learning","Error analysis;Image quality;Iris recognition;Machine learning;Quality assessment;Veins","","","","","","","","20170320","","","IEEE","IEEE Early Access Articles"
"Neighbourhood consistency based deep domain adaption analysis for multi category object detection","B. Pal; B. Ahmed","Department of Computer Science & Engineering, Rajshahi University of Engineering & Technology Rajshahi, Bangladesh","2016 19th International Conference on Computer and Information Technology (ICCIT)","20170223","2016","","","395","398","Pattern classification in domains that follow dissimilar distribution and where target domain has insufficient labelled samples, requires transfer of knowledge across domains through a process called domain adaption. Deep learning research demonstrates the transferability of deep convolutional features that are activations of intermediate layers of convolutional neural networks for domain adaption. Traditional clustering based domain adaption approaches are practical to handle knowledge transfer scenario. This paper presents a scheme that uses local neighborhoods based consistency analysis of one supervised and another unsupervised model to effectively transfer knowledge using deep features. Contrasting conventional models this approach uses only two models to classify patterns except hard ones. Neighbourhood consistency analysis identifies the hard samples, and is classified using a third model. Experimental analysis has been carried out focusing change on category variation of different samples for train and test cases. The proposed approach yields encouraging experimental result on benchmark domain adaption dataset compared to a deep feature based single support vector machine classifier in terms of state of the art metrics demonstrating effective generalization of source domain information.","","Electronic:978-1-5090-4090-2; POD:978-1-5090-4091-9","10.1109/ICCITECHN.2016.7860230","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860230","Clustering;DeCAF;Deep Learning;Domain Adaption;SVM","Adaptation models;Analytical models;Knowledge transfer;Machine learning;Manifolds;Support vector machines;Training","object detection;pattern classification;support vector machines","clustering based domain adaption;deep learning research;insufficient labelled samples;knowledge transfer scenario;multicategory object detection;neighbourhood consistency based deep domain adaption analysis;pattern classification;source domain information;support vector machine classification","","","","","","","18-20 Dec. 2016","","IEEE","IEEE Conference Publications"
"Chinese word segmentation based on conditional random fields with character clustering","L. Du; X. Li; C. Liu; R. Liu; X. Fan; J. Yang; D. Lin; M. Wei","School of Computing, Xi'an University of Posts and Telecommunications, China","2016 International Conference on Asian Language Processing (IALP)","20170313","2016","","","258","261","Chinese word segmentation plays an important role in Chinese text mining. It is the foundation of automatic relation extraction and identification in Chinese information processing. In this paper, we propose a method for Chinese word segmentation based on conditional random fields (CRF) with character clustering. For the character clustering, we firstly use the Skip-Gram model to obtain character embedding from a raw corpus (without word delimiters). We then apply two different clustering algorithms, K-means and Brown clustering algorithm, to get the clusters of character embedding. The effect of different numbers of dimensions of character embedding, the number of clusters, and different clustering algorithms have been studied. We verify our method using the 4th CCF Conference on Natural Language Processing and Chinese Computing (NLPCC2015) Weibo text segmentation task. Our system achieves an F-score of 95.67% and an out of vocabulary (OOV) rate of 94.78%. The result shows that clustering character embedding based on character representation can improve the performance of Chinese word segmentation on short text.","","Electronic:978-1-5090-0922-0; POD:978-1-5090-0923-7; USB:978-1-5090-0921-3","10.1109/IALP.2016.7875981","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875981","Chinese word segmentation;character embedding;clustering algorithm;conditional random field","Algorithm design and analysis;Clustering algorithms;Dictionaries;Machine learning;Semantics;Tagging;Training data","data mining;natural language processing;pattern clustering;random processes;text analysis;vocabulary;word processing","4th CCF Conference on Natural Language Processing and Chinese Computing;Brown clustering;CRF;Chinese information processing;Chinese text mining;Chinese word segmentation;F-score;K-means clustering;NLPCC2015;OOV rate;Skip-Gram model;Weibo text segmentation;automatic relation extraction;automatic relation identification;character clustering;character embedding;character representation;conditional random fields;out of vocabulary rate;raw corpus","","","","","","","21-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"A Dataset and a Technique for Generalized Nuclear Segmentation for Computational Pathology","N. Kumar; R. Verma; S. Sharma; S. Bhargava; A. Vahadane; A. Sethi","Indian Institute of Technology Guwahati, Guwahati 781039, India.(email::neeraj.kumar.iitg)","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Nuclear segmentation in digital microscopic tissue images can enable extraction of high-quality features for nuclear morphometrics and other analysis in computational pathology. Conventional image processing techniques such as Otsu thresholding and watershed segmentation do not work effectively on challenging cases, such as chromatin-sparse and crowded nuclei. In contrast, machine learning-based segmentation can generalize across various nuclear appearances. However, training machine learning algorithms require datasets of images in which a vast number of nuclei have been annotated. Publicly accessible and annotated datasets, along with widely agreed upon metrics to compare techniques, have catalyzed tremendous innovation and progress on other image classification problems, particularly in object recognition. Inspired by their success, we introduce a large publicly accessible dataset of H&E stained tissue images with more than 21,000 painstakingly annotated nuclear boundaries, whose quality was validated by a medical doctor. Because our dataset is taken from multiple hospitals and includes a diversity of nuclear appearances from several patients, disease states, and organs, techniques trained on it are likely to generalize well and work right out-of-the-box on other H&E stained images. We also propose a new metric to evaluate nuclear segmentation results that penalizes object- and pixel-level errors in a unified manner, unlike previous metrics that penalize only one type of error. We also propose a segmentation technique based on deep learning that lays special emphasis on identifying the nuclear boundaries, including those between the touching or overlapping nuclei, and works well on a diverse set of test images.","0278-0062;02780062","","10.1109/TMI.2017.2677499","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872382","Annotation;boundaries;dataset;deep learning,;nuclear segmentation;nuclei","Diseases;Image color analysis;Image segmentation;Machine learning;Measurement;Pathology;Training","","","","","","","","20170306","","","IEEE","IEEE Early Access Articles"
"Spontaneous facial micro-expression detection based on deep learning","X. Li; J. Yu; S. Zhan","School of Computer and information, HeFei University of Technology, Hefei, China","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","1130","1134","Facial micro-expression refers to split-second muscle changes in the face, indicating that a person is either consciously or unconsciously suppressing their true emotions. Although these expressions are constantly occurring on people faces, they were easily ignored by people with the eye blinking. That is to say, most people don't notice them and it is the true representation of people emotions and mental health. Accordingly, both of psychologists and computer scientists (in the fields of computer vision and machine learning in particular) pay attention to it owing to their promising applications in various fields (e.g. Mental clinical diagnosis and therapy, affective computing). However, detecting micro-expression is still difficult task. Here, we proposed a novel approach based on deep multi-task learning method with the HOOF(Histograms of oriented optical flow) feature for micro-expression detection. We investigated a deep multi-task learning method for facial landmark localization and split the facial area into regions of interest(ROIS). Faical micro-expression are generated by the movement of facial muscles, so we combined robust optical flow approach with the HOOF feature for evaluating the direction of movement of facial muscles. Through some experiments on CASME spontaneous micro-expression database, we can demonstrate our proposal method can achieve good performance for detecting micro-expression.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7878004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7878004","deep learning;detection;micro-expression;multi-task;optical flow","Databases;Facial muscles;Feature extraction;Machine learning;Neural networks;Optical network units","computer vision;emotion recognition;face recognition;feature extraction;image sequences;learning (artificial intelligence);object detection","CASME spontaneous microexpression database;HOOF feature;ROIS;computer vision;deep multitask learning method;facial landmark localization;facial microexpression detection;histograms of oriented optical flow feature;machine learning;regions of interest;robust optical flow approach","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"Deep Q-learning using redundant outputs in visual doom","H. Park; K. J. Kim","Department of Computer Science and Engineering, Sejong University, Seoul, South Korea","2016 IEEE Conference on Computational Intelligence and Games (CIG)","20170223","2016","","","1","2","Recently, there is a growing interest in applying deep learning in game AI domain. Among them, deep reinforcement learning is the most famous in game AI communities. In this paper, we propose to use redundant outputs in order to adapt training progress in deep reinforcement learning. We compare our method with general ε-greedy in ViZDoom platform. Since AI player should select an action only based on visual input in the platform, it is suitable for deep reinforcement learning research. Experimental results show that our proposed method archives competitive performance to ε-greedy without parameter tuning.","","Electronic:978-1-5090-1883-3; POD:978-1-5090-1884-0; USB:978-1-5090-1882-6","10.1109/CIG.2016.7860387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860387","deep reinforcement learning;first-person perspective game;reinforcement learning;vizdoom","Convolution;Games;Learning (artificial intelligence);Machine learning;Training;Visualization","computer games;learning (artificial intelligence)","Visual Doom AI game;deep Q-learning;deep reinforcement learning;game AI communities;game AI domain;redundant outputs;training progress","","","","","","","20-23 Sept. 2016","","IEEE","IEEE Conference Publications"
"What makes for good multiple object trackers?","Y. Zhang; Y. Huang; L. Wang","Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","2016 IEEE International Conference on Digital Signal Processing (DSP)","20170302","2016","","","467","471","This paper explores the importance of detection and appearance features for multiple object tracking. Extensive detectors including hand-crafted methods and deep learning methods have been tested. We found in this paper that simply improving detection performance can lead to much better multiple object tracking results. The data association methods used in this paper are Kalman Filter and Hungarian algorithm as proposed in [1]. CNN features and color histogram features are extracted as appearance features to measure similarities between objects. Our experiments show that appearance features can help with data association. We then combine detection and data association together as an overall system. The proposed system can track multiple objects at a speed of 17 fps with high accuracy.","","Electronic:978-1-5090-4165-7; POD:978-1-5090-4166-4","10.1109/ICDSP.2016.7868601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868601","Appearance Features;Deep learning;Multiple Object Tracking","Benchmark testing;Detectors;Feature extraction;Histograms;Image color analysis;Machine learning;Object tracking","Kalman filters;feature extraction;image colour analysis;image filtering;image fusion;learning (artificial intelligence);object tracking","CNN feature extraction;Hungarian algorithm;Kalman filter;appearance features;color histogram feature extraction;data association;deep learning;detection features;hand-crafted methods;multiple object tracking","","","","","","","16-18 Oct. 2016","","IEEE","IEEE Conference Publications"
"Energy efficiency evaluation method based on deep learning model","Meng Fansheng; Li Bin; Yue Zenglei; Cheng Jiangnan; Liu Zhi; Wan Jie","School of Economics and Management, Harbin Engineering University, China","2016 IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","20170302","2016","","","1403","1407","Energy efficiency measurement and its influence factors is important way of energy efficiency evaluation. In this paper, character identification method has been proposed to determine influence factors of energy efficiency and energy efficiency of 24 provinces in china is analyzed and evaluated by deep learning method. By comparison, two classification and prediction models are built with two other common classification and prediction algorithms. Case study with collected data revealed that the classification accuracy of three model is all over 90% and the deep learning model shown the best results. And then energy efficiency of other six provinces are predicted with three model and the deep learning model shown the best results. In the end, a strategy is put forward to improve Chinese energy efficiency.","","CD:978-1-4673-9611-0; Electronic:978-1-4673-9613-4; POD:978-1-5090-0166-8","10.1109/IMCEC.2016.7867444","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7867444","Energy efficiency;classification;cluster;data mining;feature selection","Classification algorithms;Data mining;Economic indicators;Energy consumption;Energy efficiency;Machine learning;Training","energy conservation;learning (artificial intelligence);pattern classification","China;character identification method;classification accuracy;classification algorithms;data mining;deep learning model;energy efficiency evaluation method;energy efficiency factors;energy efficiency measurement;prediction algorithms","","","","","","","3-5 Oct. 2016","","IEEE","IEEE Conference Publications"
"Speech enhancement based on improved deep neural networks with MMSE pretreatment features","W. Han; C. Wu; X. Zhang; M. Sun; G. Min","Lab of Intelligent Information Processing, PLAUST, Nanjing, China","2016 IEEE 13th International Conference on Signal Processing (ICSP)","20170316","2016","","","1140","1145","Speech enhancement plays an important role in robust speech processing. Deep learning has become a new trend towards solving speech enhancement problems. The input feature is a key aspect of deep learning, which effect the enhancement performance. In this paper, we explore a new feature which extract through the minimum mean square error (MMSE) estimator pretreatment. Incorporating the MMSE pretreatment features, we proposed a novel deep neural network (DNN) for speech enhancement task. Evaluation experiments on TIMIT database with 20 noise types at different signal-to-noise ratio (SNR) situations demonstrate the effectiveness of the proposed approach compared with the reference DNN-based enhancement approaches, no matter whether the noise matched the training set or not.","2164-5221;21645221","CD:978-1-5090-1343-2; Electronic:978-1-5090-1345-6; POD:978-1-5090-1346-3; Paper:978-1-5090-1344-9","10.1109/ICSP.2016.7878006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7878006","MMSE estimation;deep neural networks;feature extration;speech enhancement","Feature extraction;Machine learning;Noise measurement;Signal to noise ratio;Speech;Speech enhancement;Training","feature extraction;learning (artificial intelligence);least mean squares methods;neural nets;speech enhancement","MMSE pretreatment features;SNR;TIMIT database;deep learning;improved deep neural networks;minimum mean square error estimator pretreatment features;robust speech processing;signal-to-noise ratio;speech enhancement problems","","","","","","","6-10 Nov. 2016","","IEEE","IEEE Conference Publications"
