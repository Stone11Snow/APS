"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7776792,7797232,7762861,7548359,7837725,7835978,7833310,7836017,7836314,7835885,7779008,7828543,7830701,7832798,7828385,7832461,7829926,7829929,7830677,7829911,7832965,7832464,7832398,7833852,7568999,7827553,7829332,7827589,7828142,7819786,7820963,7821697,7820437,7823844,7821202,7821605,7823615,7820828,7823908,7822491,7822130,7822131,7820413,7821007,7819335,7818876,7820834,7818799,7823618,7822599,7820753,7819792,7823510,7823454,7824728,7823811,7823698,7823911,7822593,7818903,7821710,7822620,7822569,7823841,7820782,7822109,7822625,7822509,7824905,7824810,7820512,7822557,7390084,7814665,7810808,7813057,7814597,7814716,7813061,7814725,7814107,7814435,7816929,7815695,7814106,7816728,7438932,7815339,7814057,7813020,7814074,7814079,7817115,7817036,7811102,7808590,7808050,7807685,7810598,7811237",2017/05/05 22:28:09
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Combining Statistics-Based and CNN-Based Information for Sentence Classification","L. Zhining; G. Xiaozhuo; Z. Quan; X. Taizhong","Inst. of Inf. Eng., Beijing, China","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","1012","1018","Sentence classification, serving as the foundation of the subsequent text-based processing, continues attracting researchers attentions. Recently, with the great success of deep learning, convolutional neural network (CNN), a kind of common architecture of deep learning, has been widely used to this filed and achieved excellent performance. However, most CNN-based studies focus on using complex architectures to extract more effective category information, requiring more time in training models. With the aim to get better performance with less time cost on classification, this paper proposes two simple and effective methods by fully combining information both extracted from statistics and CNN. The first method is S-SFCNN, which combines statistical features and CNN-based probabilistic features of classification to build feature vectors, and then the vectors are used to train the logistic regression classifiers. And the second method is C-SFCNN, which combines CNN-based features and statistics-based probabilistic features of classification to build feature vectors. In the two methods, the Naive Bayes log-count ratios are selected as the text statistical features and the single-layer and single channel CNN is used as our CNN architecture. The testing results executed on 7 tasks show that our methods can achieve better performance than many other complex CNN models with less time cost. In addition, we summarized the main factors influencing the performance of our methods though experiment.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814716","Convolutional Neural Network;Navie Bayes;Sentence Classification","Computer architecture;Data mining;Feature extraction;Logistics;Machine learning;Probabilistic logic;Training","Bayes methods;convolution;feature extraction;learning (artificial intelligence);pattern classification;regression analysis;statistics","C-SFCNN;CNN-based information;CNN-based probabilistic features;Naive Bayes log-count ratios;S-SFCNN method;classification features;convolutional neural network;deep learning;feature vectors;information extraction;logistic regression classifier training;natural language processing;sentence classification;statistical features;statistics-based information;statistics-based probabilistic features;text-based processing","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"How popular CNNs perform in real applications of face recognition","P. Ahmadvand; R. Ebrahimpour; P. Ahmadvand","Faculty of Computer Engineering, Shahid Rajaee Teacher Training University. Shabanlou, Lavizan, Tehran, Iran","2016 24th Telecommunications Forum (TELFOR)","20170119","2016","","","1","4","In this paper we evaluate the performance of CNN in regards to face recognition for real world applications. In recent years, many high performance deep neural networks have been proposed to the face recognition world. These deep networks were trained by images provided by the internet, and they commonly are of good quality when facial expression and posture are not particularly complex. However, this is not the case in real world applications; the provided images vary a lot and do not reflect ideal conditions. We collect and introduce a new dataset in which the images come from two different cameras and scenes. The well-known CNNs are trained on the dataset and then tested on the two collections of the dataset. The results reveal that that though performances of all of the CCNs drop dramatically, VGG-Face can still perform acceptably despite image degradations.","","CD:978-1-5090-4085-8; Electronic:978-1-5090-4086-5; POD:978-1-5090-4087-2","10.1109/TELFOR.2016.7818876","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7818876","CNN;Face Recognition;deep learning;image degradations","Cameras;Computer vision;Face;Face recognition;Machine learning;Robustness;Training","convolution;face recognition;neural nets","CNNs;VGG-Face;face recognition;facial expression;high performance deep neural networks;image degradations","","","","","","","22-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"Learning Sequential and Parallel Runtime Distributions for Randomized Algorithms","A. Arbelaez; C. Truchet; B. O'Sullivan","Insight Centre for Data Analytics, Univ. Coll. Cork, Cork, Ireland","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","655","662","In cloud systems, computation time can be rented by the hour and for a given number of processors. Thus, accurate predictions of the behaviour of both sequential and parallel algorithms has become an important issue, in particular in the case of costly methods such as randomized combinatorial optimization tools. In this work, our objective is to use machine learning to predict performance of sequential and parallel local search algorithms. In addition to classical features of the instances used by other machine learning tools, we consider data on the sequential runtime distributions of a local search method. This allows us to predict with a high accuracy the parallel computation time of a large class of instances, by learning the behaviour of the sequential version of the algorithm on a small number of instances. Experiments with three solvers on SAT and TSP instances indicate that our method works well, with a correlation coefficient of up to 0.85 for SAT instances and up to 0.95 for TSP instances.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814665","","Algorithm design and analysis;Approximation algorithms;Machine learning algorithms;Parallel algorithms;Prediction algorithms;Runtime;Search problems","cloud computing;computability;learning (artificial intelligence);parallel algorithms;randomised algorithms;search problems;travelling salesman problems","SAT instances;TSP instances;cloud systems;correlation coefficient;machine learning;parallel computation time;parallel local search algorithms;randomized algorithms;sequential local search algorithms;sequential runtime distributions","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"Deep Learning and Ensemble Methods for Domain Adaptation","D. Nozza; E. Fersini; E. Messina","Dept. of Inf., Syst. & Commun., Univ. of Milano-Bicocca, Milan, Italy","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","184","189","Real world applications of machine learning in natural language processing can span many different domains and usually require a huge effort for the annotation of domain specific training data. For this reason, domain adaptation techniques have gained a lot of attention in the last years. In order to derive an effective domain adaptation, a good feature representation across domains is crucial as well as the generalisation ability of the predictive model. In this paper we address the problem of domain adaptation for sentiment classification by combining deep learning, for acquiring a cross-domain high-level feature representation, and ensemble methods, for reducing the cross-domain generalization error. The proposed adaptation framework has been evaluated on a benchmark dataset composed of reviews of four different Amazon category of products, significantly outperforming the state of the art methods.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814597","Deep Learning;Domain Adaptation;Ensemble;Sentiment Analysis;Transfer Learning","Adaptation models;Gold;Machine learning;Noise reduction;Standards;Support vector machines;Training","generalisation (artificial intelligence);learning (artificial intelligence);pattern classification;sentiment analysis","cross-domain generalization error;cross-domain high-level feature representation;deep learning;domain adaptation;domain specific training data annotation;feature representation;machine learning;natural language processing;sentiment classification","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"Depth image super-resolution via multi-frame registration and deep learning","C. W. Tseng; H. R. Su; S. H. Lai; J. Liu","National Tsing Hua University, Hsinchu, Taiwan","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20170119","2016","","","1","8","In this paper, we develop an algorithm for depth image super-resolution from RGB-D images, which are acquired under different imaging conditions so that we can combine them to improve the image quality with precise 3D registration. We focus on how to increase the resolution and quality of depth images by combining multiple RGB-D images and using the deep learning technique. In the proposed solution, we combine multiple RGB-D images by 3D alignment from 3D feature point correspondences and apply the guided filter as the input to SRCNN to obtain the up-sampled depth images. We show depth quality improvement of the up-sampled depth maps by using the proposed algorithm over the traditional methods through experimental results on some public-domain RGB-D datasets.","","Electronic:978-9-8814-7682-1; POD:978-1-5090-2401-8","10.1109/APSIPA.2016.7820834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820834","","Color;Feature extraction;Image reconstruction;Image resolution;Machine learning;Three-dimensional displays;Training","image colour analysis;image filtering;image registration;image resolution;learning (artificial intelligence)","3D feature point correspondences;3D registration;RGB-D images;deep learning technique;depth image super-resolution;depth quality improvement;guided filter;image quality;public-domain RGB-D datasets;upsampled depth images","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Semantic Event Detection Using Ensemble Deep Learning","S. Pouyanfar; S. C. Chen","Sch. of Comput. & Inf. Sci., Florida Int. Univ., Miami, FL, USA","2016 IEEE International Symposium on Multimedia (ISM)","20170119","2016","","","203","208","Numerous deep learning architectures have been designed for a variety of tasks in the past few years. However, it is almost impossible for one model to work well for all kinds of scenarios and datasets. Therefore, we present an ensemble deep learning framework in this paper, which not only decreases the information loss and over-fitting problems caused by single models, but also overcomes the imbalanced data issue in multimedia big data. First, a suite of deep learning algorithms are utilized for deep feature selection. Thereafter, an enhanced ensemble algorithm is developed based on the performance of each single Support Vector Machine classifier on each deep feature set. We evaluate our proposed ensemble deep learning framework on a large and highly imbalanced video dataset containing natural disaster events. Experimental results demonstrate the effectiveness of the proposed framework for semantic event detection, and show how it outperforms several state-of-the-art deep learning architectures, as well as handcrafted features integrated with ensemble and non-ensemble algorithms.","","Electronic:978-1-5090-4571-6; POD:978-1-5090-4572-3","10.1109/ISM.2016.0048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823615","Deep learning;Ensemble learning;Imbalanced data;Multimedia big data;Semantic event detection","Event detection;Feature extraction;Machine learning;Multimedia communication;Semantics;Streaming media;Training","disasters;feature selection;image classification;learning (artificial intelligence);multimedia computing;object detection;support vector machines;video signal processing","deep feature selection;deep feature set;ensemble deep learning architecture;handcrafted features;multimedia Big Data;natural disaster events;over-fitting problems;semantic event detection;support vector machine classifier;video dataset","","","","","","","11-13 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Distributed, Asynchronous and Incremental Algorithm for Nonconvex Optimization: An ADMM Approach","M. Hong","Department of Industrial and Manufacturing Systems Engineering (IMSE), Iowa State University, Ames, IA 50011, USA (e-mail: mingyi@iastate.edu)","IEEE Transactions on Control of Network Systems","","2017","PP","99","1","1","The alternating direction method of multipliers (ADMM) has been popular for solving many signal processing problems, convex or nonconvex. In this paper, we study an asynchronous implementation of ADMM for solving a nonconvex nonsmooth optimization problem, whose objective is the sum of a number of component functions. The proposed algorithm allows the problem to be solved in a distributed, asynchronous and incremental manner. First, the component functions can be distributed to different computing nodes, who perform the updates asychronously without coordinating with each other. Two sources of asynchrony are covered by our algorithm: one is caused by the heterogeneity of the computational nodes, and the other arises from unreliable communication links. Second, the algorithm can be viewed as implementing an incremental algorithm where at each step the (possibly delayed) gradients of only a subset of component functions are updated. We show that when certain bounds are imposed on the level of asynchrony, the proposed algorithm converges to the set of stationary solutions (resp. optimal solutions) for the nonconvex (resp. convex) problem, with a global sublinear rate.","2325-5870;23255870","","10.1109/TCNS.2017.2657460","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829332","","Algorithm design and analysis;Control systems;Delays;Machine learning algorithms;Optimization;Signal processing;Signal processing algorithms","","","","","","","","20170123","","","IEEE","IEEE Early Access Articles"
"Learning to Classify Seismic Images with Deep Optimum-Path Forest","L. Afonso; A. Vidal; M. Kuroda; A. X. Falcão; J. P. Papa","Dept. of Comput., Fed. Univ. of Sao Carlos, Sao Carlos, Brazil","2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","20170116","2016","","","401","407","Due to the lack of labeled information, clustering techniques have been paramount in the last years once more. In this paper, inspired by the deep learning phenomenon, we presented a multi-scale approach to obtain more refined cluster representations of the Optimum-Path Forest (OPF) classifier, which has obtained promising results in a number of works in the literature. Here, we propose to fill a gap in OPF-based works by using a deep-driven representation of the feature space. Additionally, we validated the work in the context of high resolution seismic images aiming at petroleum exploration, as well as in general-purpose applications. Quantitative and qualitative analysis are conducted in order to assess the robustness of the proposed approach.","","Electronic:978-1-5090-3568-7; POD:978-1-5090-3569-4","10.1109/SIBGRAPI.2016.062","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813061","Deep Representations;Image Clustering;Optimum-Path Forest;Seismic Images","Context;Image resolution;Labeling;Machine learning;Optimization;Petroleum;Prototypes","geophysical image processing;geophysical techniques;image classification;image resolution;learning (artificial intelligence);seismology","OPF-based works;clustering techniques;deep learning phenomenon;deep optimum-path forest classifier;deep-driven representation;seismic image classification;seismic image resolution","","","","","","","4-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Localization of slab identification numbers using deep learning","S. J. Lee; J. Ban; H. Choi; S. W. Kim","Department of Electrical Engineering, POSTECH, Pohang 790-784, Korea","2016 16th International Conference on Control, Automation and Systems (ICCAS)","20170126","2016","","","1174","1176","In the steel industries, recognizing product information is an important task for the management of the manufacturing processes. For real factory scenes, localization of product identification numbers is conducted prior to recognition to obtain a satisfactory performance. The objective of this paper is localization of slab identification numbers in real factory scenes. Traditionally, most researches in the field of image processing and pattern recognition were focused on feature representation or shallow learning. However, conventional rule-based algorithms heavily depend on carefully engineered feature values and require heuristic parameter tuning. To overcome these limitations, a deep learning based algorithm is proposed for the localization with the minimum of manual interventions. This paper contains construction of training data, labeling process, and an architecture of a deep convolutional neural network. The performance error is remarkably reduced to 2.19% by the proposed algorithm compared to 4.59% in the previous work. By using a data-based method, this algorithm is easily expandable to apply for other applications.","","Electronic:978-89-93215-11-3; POD:978-1-4673-9058-3; USB:978-89-93215-12-0","10.1109/ICCAS.2016.7832461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832461","Industrial application;deep convo-lutional neural network;deep learning;product identification number;steel slab;text localization","Image processing;Machine learning;Neural networks;Pattern recognition;Production facilities;Slabs;Steel industry","image recognition;inspection;learning (artificial intelligence);neural nets;production engineering computing;steel industry","data-based method;deep convolutional neural network;deep learning;feature representation;heuristic parameter;image processing;manufacturing process;pattern recognition;product identification numbers localization;product information recognition;shallow learning;slab identification number;steel industries","","","","","","","16-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Evaluation of stacked autoencoders for pedestrian detection","B. Peralta; L. Parra; L. Caro","Escuela de Ingen&#x00ED;eria Inform&#x00E1;tica, Universidad Cat&#x00F3;lica de Temuco, Temuco, Chile","2016 35th International Conference of the Chilean Computer Science Society (SCCC)","20170130","2016","","","1","7","Pedestrian detection has multiple applications as video surveillance, automatic driver-assistance systems in vehicles or visual control of access. This task is challenging due to presence of factors such as poor lighting, occlusion or uncertainty in the environment. Deep learning has reached many state-of-art results in visual recognition, where one popular and simple variant is stacked autoencoders. Nonetheless, it is not clear what is the effect of each stacked autoencoders parameter in pedestrian detection performance. In this work, we propose to revise the feature representation for pedestrian detection considering the use of deep learning using stacked autoencoders with a sensitivity analysis of relevant parameters. Additionally, this paper presents a methodology for feature extraction using stacked autoencoders. The experiments show that this model is capable of creating a meaningful visual descriptor for pedestrian detection, which improves the detection performance in comparison to baseline techniques without an optimal setting of parameters. In presence of occlusion or poor people images, we found diffuse and distorted visual patterns. A future avenue is the learning of the degree of noise for improving the generalization capabilities of the learned features.","","Electronic:978-1-5090-3339-3; POD:978-1-5090-3340-9","10.1109/SCCC.2016.7836017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836017","Autoencoders;Deep Learning;Pedestrian Detection;Stacked Autoencoders","Feature extraction;Lighting;Machine learning;Uncertainty;Vehicles;Video surveillance;Visualization","feature extraction;image denoising;image recognition;learning (artificial intelligence);pedestrians;road vehicles;video surveillance","automatic driver-assistance systems;baseline techniques;deep learning;distorted visual patterns;feature extraction;pedestrian detection performance;sensitivity analysis;stacked autoencoder parameter;video surveillance;visual control;visual recognition","","","","","","","10-14 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep learning-based pipeline to recognize Alzheimer's disease using fMRI data","S. Sarraf; G. Tofighi","Department of Electrical and Computer Engineering, McMaster University Hamilton, ON, L8S 4L8, Canada, Rotman Research Institue at Baycrest, University of Toronto","2016 Future Technologies Conference (FTC)","20170119","2016","","","816","820","Over the past decade, machine learning techniques and in particular predictive modeling and pattern recognition in biomedical sciences, from drug delivery systems to medical imaging, have become one of the most important methods of assisting researchers in gaining a deeper understanding of issues in their entirety and solving complex medical problems. Deep learning is a powerful machine learning algorithm in classification that extracts low-to high-level features. In this paper, we employ a convolutional neural network to distinguish an Alzheimers brain from a normal, healthy brain. The importance of classifying this type of medical data lies in its potential to develop a predictive model or system in order to recognize the symptoms of Alzheimers disease when compared with normal subjects and to estimate the stages of the disease. Classification of clinical data for medical conditions such as Alzheimers disease has always been challenging, and the most problematic aspect has always been selecting the strongest discriminative features. Using the Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified functional MRI data of Alzheimers subjects from normal controls, where the accuracy of testing data reached 96.85%. This experiment suggests that the shift and scale invariant features extracted by CNN followed by deep learning classification represents the most powerful method of distinguishing clinical data from healthy data in fMRI. This approach also allows for expansion of the methodology to predict more complicated systems.","","Electronic:978-1-5090-4171-8; POD:978-1-5090-4172-5","10.1109/FTC.2016.7821697","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821697","Alzheimer's Disease;Deep learning;fMRI","Alzheimer's disease;Biological neural networks;Biomedical imaging;Feature extraction;Machine learning;Neurons","biomedical MRI;convolution;diseases;feature extraction;learning (artificial intelligence);medical computing;neural nets;pattern classification","Alzheimer disease;Alzheimers brain;CNN;LeNet-5 architecture;biomedical sciences;clinical data classification;convolutional neural network;deep learning-based pipeline;drug delivery systems;functional MRI data classification;machine learning;medical imaging;pattern recognition;predictive modeling;scale invariant features extraction","","","","","","","6-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"RakSOR: Ranking of Ontology Reasoners Based on Predicted Performances","N. Alaya; S. Ben Yahia; M. Lamolle","LIASD, Univ. of Paris 8, Montreuil, France","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","1076","1083","Over the last decade, several ontology reasoners have been proposed to overcome the computational complexity of inference tasks on expressive ontology languages. Nevertheless, it is well-accepted that there is no outstanding reasoner that can outperform in all input ontologies. Thus, an algorithm selection problem have emerged in this field of study. In this paper, we describe first steps to develop a new system to provide user support when looking for guidance over ontology reasoners. Our main goal is to be able to automatically rank a set of candidate reasoners for any given ontology. Robustness standing for the ability of reasoner to correctly achieve a reasoning task within a fixed time limit is our primary ranking criterion. Our ranking method follows a meta-learning approach and applies bucket order rules. An extensive experiments covering over 2500 well selected real-world ontologies and six state-of-the-art of the most performing reasoners was carried out to provide enough data for the study. Our prediction and ranking results are encouraging, witnessing the potential benefits of the proposed approach.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814725","Meta-learning;Ontology;Ranking;Reasoner;Robustness","Cognition;Machine learning algorithms;Numerical models;Ontologies;Prediction algorithms;Predictive models;Robustness","computational complexity;inference mechanisms;ontologies (artificial intelligence)","RakSOR;algorithm selection problem;bucket order rules;computational complexity;inference tasks;meta-learning;ontology languages;ontology reasoners;predicted performances;primary ranking criterion;reasoning task;user support","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"Privacy-Preserving Publication of Deep Neural Networks","Y. Sei; H. Okumura; A. Ohsuga","Univ. of Electro-Commun., Chofu, Japan","2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)","20170126","2016","","","1418","1425","An organization that has a lot of personal data can create a deep neural network (DNN), which predicts sensitive attribute values such as the salary and diseases of people based on other attribute values such as age and hobbies. Moreover, by putting this data on the Cloud and providing the functionality of the DNN to other organizations, they can obtain new knowledge and can subsequently create new services. However, because such DNNs are generated from sensitive attribute values, we cannot share them freely without the explicit consent of the persons whose data are used for the DNNs. On the other hand, in recent years, e-differential privacy has emerged as the de facto privacy metric. Many researchers use e-differential privacy for privacy-preserving data mining such as correlation analysis and association rule analysis. In this paper, we modify e-differential privacy for machine learning, and we propose three approaches for creating privacy-preserved DNNs based on the modified e-differential privacy. Our proposed approaches are experimentally evaluated using a real data set, and we show that our approaches can protect personal attribute values while maintaining the accuracy of the DNNs.","","Electronic:978-1-5090-4297-5; POD:978-1-5090-4298-2","10.1109/HPCC-SmartCity-DSS.2016.0202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828543","Deep neural networks;Model sharing;Privacy","Data privacy;Databases;Histograms;Machine learning algorithms;Measurement;Neural networks;Privacy","data mining;data privacy;learning (artificial intelligence);neural nets;security of data","DNN;attribute value prediction;deep neural network;e-differential privacy;machine learning;privacy-preserving data mining;privacy-preserving publication","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"PredRBR: Accurate Prediction of RNA-Binding Residues in proteins using Gradient Tree Boosting","D. Liu; Y. Tang; C. Fan; Z. Chen; L. Deng","School of Software, Central South University, Changsha 410075, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","47","52","Prediction of Protein-RNA binding sites is one of the most challenging and intriguing problems in the field of computational biology. Here, we proposed an effectively machine learning algorithm termed PredRBR (Prediction of RNA Binding Residues), using Gradient Tree Boosting algorithm and mRMR-IFS feature selection method in combination with sequence features, structure characteristics and two categories of structural neighborhood feature for prediction of RNA binding sites in proteins. We evaluate PredRBR on the independent test dataset (RBP101), and obtain significant improvement on the prediction performance compared with other state-of-the-art approaches. In addition, we test the variable importance of diverse feature types. The results show that structural neighborhood features play a crucial role in the identification of RNA binding sites.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822491","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822491","","Amino acids;Boosting;Feature extraction;Machine learning algorithms;Prediction algorithms;Proteins;RNA","RNA;biological techniques;biology computing;feature selection;learning (artificial intelligence);molecular biophysics;proteins","PredRBR;Prediction of RNA Binding Residues;RBP101;computational biology;gradient tree boosting algorithm;mRMR-IFS feature selection method;machine learning algorithm;protein-RNA binding site prediction;structural neighborhood feature","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Object identification in Vision Systems for expert learning platforms","A. D. T. U. Alawala","Pearson Lanka (Pvt) Ltd. Orion City, Rigel Building, Sri Lanka","2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20170126","2016","","","246","247","This Vision System would be able to identify the objects in the digital imagery by reducing the current limitations by increasing accuracy. Further the extensively trained Vision System could be applied over the Learning Platforms where the outcome could be used to develop rich learning tools where the learners could learn through vision over text.","","CD:978-1-5090-6076-4; Electronic:978-1-5090-6078-8; POD:978-1-5090-6079-5; Paper:978-1-5090-6077-1","10.1109/ICTER.2016.7829926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829926","Artificial Intelligence;Artificial Neural Networks;Expert Learning Platforms;Image Processing;Vision Systems","Algorithm design and analysis;Artificial neural networks;Digital images;Feature extraction;Machine learning;Object recognition","computer vision;learning (artificial intelligence);object recognition","expert learning platforms;learning platforms;learning tools;object identification;vision systems","","","","","","","1-3 Sept. 2016","","IEEE","IEEE Conference Publications"
"N-Light-N: A Highly-Adaptable Java Library for Document Analysis with Convolutional Auto-Encoders and Related Architectures","M. Seuret; R. Ingold; M. Liwicki","Document, Image & Voice Anal. Group, Univ. of Fribourg, Fribourg, Switzerland","2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)","20170116","2016","","","459","464","This paper presents a novel, highly-adaptable Java framework N-light-N, for the work with deep neural networks, especially with CAEs. While the most popular deep learning libraries focus on fast processing and high performance, they only implement the main-stream network architectures and network units. In recent research in the document domain, however, we have shown that modified networks, units, and training processes significantly improve the performance in various tasks. To enable the document research community with such capabilities, in this paper we introduce a novel, publicly available Deep Learning framework which is easy to use, adapt, and extend. Furthermore, we present successful applications for three tasks, including two in the domain of handwritten historical documents, and show how the framework can be used for adaptation, optimization, and deeper analysis.","2167-6445;21676445","Electronic:978-1-5090-0981-7; POD:978-1-5090-0982-4","10.1109/ICFHR.2016.0091","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814107","Convolutional Auto-Encoder;Java framework;layout analysis;text detection","Arrays;Convolution;Layout;Libraries;Machine learning;Open area test sites;Training","Java;document image processing;handwriting recognition;learning (artificial intelligence);neural nets;software libraries;text detection","CAE;N-light-N library;convolutional auto-encoders;deep learning;deep neural networks;document analysis;handwritten historical documents;highly-adaptable Java library;network architectures;network units;performance improvement","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"Development of computional intelligence-based algorithms of preventing voltage collapse in power systems with a complex multi-loop structure","N. Voropai; N. Tomin; V. Kurbatsky; D. Panasetsky; D. Sidorov; A. Zhukov","Dept. of Electric Power Systems, Melentiev Energy Systems Institute, Irkutsk, Russia","2016 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)","20170123","2016","","","1","5","Majority of recent large-scale blackouts have been caused by voltage instability. This paper proposes new algorithms and implementation principles of an intelligent emergency control based on machine learning models and decentralized adaptive models that can effectively prevent voltage instability before they lead to major blackouts and overall collapse of the system. The proposed algorithms have been implemented using MATLAB and R environments. The feasibility of the approach in a proof-of-concept has been demonstrated on the IEEE 118.","","Electronic:978-1-5090-5418-3; POD:978-1-5090-5419-0","10.1109/APPEEC.2016.7827553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827553","blackout;computational intelligence;emergency control;power systems;voltage security","Control systems;Machine learning algorithms;Monitoring;Power system stability;Security;Voltage control","adaptive control;decentralised control;intelligent control;learning (artificial intelligence);power system dynamic stability","IEEE 118 system;MATLAB environments;R environments;complex multiloop structure;computational intelligence-based algorithms;decentralized adaptive models;intelligent emergency control;large-scale blackouts;machine learning models;power systems;voltage collapse prevention;voltage instability","","","","","","","25-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Learning a Coupled Linearized Method in Online Setting","W. Xue; W. Zhang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Neural Networks and Learning Systems","20170118","2017","28","2","438","450","Based on the alternating direction method of multipliers, in this paper, we propose, analyze, and test a coupled linearized method, which aims to minimize an unconstrained problem consisting of a loss term and a regularization term in an online setting. To solve this problem, we first transform it into an equivalent constrained minimization problem with a separable structure. Then, we split the corresponding augmented Lagrangian function and minimize the resulting subproblems distributedly with one variable by fixing another one. This method is easy to execute without calculating matrix inversion by implementing three linearized operations per iteration, and at each iteration, we can obtain a closed-form solution. In particular, our update rule contains the well-known softthresholding operator as a special case. Moreover, upper bound on the regret of the proposed method is analyzed. Under some mild conditions, it can achieve O(1/√T) convergence rate for convex learning problems and O((logT)/T) for strongly convex learning. Numerical experiments and comparisons with several state-of-the-art methods are reported, which demonstrate the efficiency and effectiveness of our approach.","2162-237X;2162237X","","10.1109/TNNLS.2016.2514413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390084","Alternating minimization;convex optimization;linearized operation;online learning;regret bound","Convergence;Convex functions;Lagrangian functions;Learning systems;Machine learning algorithms;Minimization;Optimization","learning (artificial intelligence);linearisation techniques;minimisation","alternating direction method of multipliers;augmented Lagrangian function;constrained minimization problem;coupled linearized method;learning problem;soft-thresholding operator","","","","","","20160122","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Unsupervised feature selection algorithm based on sparse representation","G. Cui; J. Yang; M. Zareapoor","Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Minhang District, Shanghai, China","2016 3rd International Conference on Systems and Informatics (ICSAI)","20170109","2016","","","1028","1033","Feature selection, as a preprocessing step to machine learning, plays a pivotal role in removing irrelevant data, reducing dimensionality and improving performance evaluations. Recent years, sparse representation has become a useful tool for both supervised and unsupervised feature selection. So far, most of these algorithms still have many problems such as large computation load, performance with poor stability. Thus, this paper proposes a new unsupervised feature selection algorithm via sparse representation (UFSSR), with respect to efficiency and effectiveness. Firstly, this paper reconstructs part of data matrix via sparse representation, which makes the proposed algorithm be robust and independent of domain knowledge. Then, to reduce the reconstruction error, a new feature evaluation function is given to rank all features. Theoretical analysis and experiments compared with many popular algorithms on a set of datasets demonstrate the improvements brought by UFSSR.","","Electronic:978-1-5090-5521-0; POD:978-1-5090-5522-7; USB:978-1-5090-5520-3","10.1109/ICSAI.2016.7811102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811102","computation load;feature evaluation function;sparse representation;stability;unsupervised feature selection","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Feature extraction;Machine learning algorithms;Noise measurement;Sparse matrices","feature selection;matrix algebra;unsupervised learning","UFSSR;data matrix;feature evaluation function;machine learning;reconstruction error;sparse representation;supervised feature selection;unsupervised feature selection algorithm","","","","","","","19-21 Nov. 2016","","IEEE","IEEE Conference Publications"
"Fingerprint ROI segmentation based on deep learning","B. Stojanović; O. Marques; A. Nešković; S. Puzović","Institute Vlatacom, Milutina Milankovi&#x0107;a 5, 11070 Belgrade, Serbia","2016 24th Telecommunications Forum (TELFOR)","20170119","2016","","","1","4","This paper presents a novel method for fingerprint ROI (region of interest) segmentation using Deep learning technique - Convolutional Neural Networks. Experimental results, obtained using a publicly available test database of 200 fingerprint images in two variations - with and without Gaussian noise, demonstrate that this method is competitive with Fourier coefficients and NN based method for fingerprint images without noise, while it significantly outperforms it, in all three figures of merit, for fingerprint images with noise.","","CD:978-1-5090-4085-8; Electronic:978-1-5090-4086-5; POD:978-1-5090-4087-2","10.1109/TELFOR.2016.7818799","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7818799","CNN;Deep Learning;NN;ROI segmentation;fingerprint","Databases;Fingerprint recognition;Image matching;Image segmentation;Machine learning;Neural networks;Training","Gaussian noise;fingerprint identification;image segmentation;learning (artificial intelligence);neural nets","Fourier coefficient;Gaussian noise;NN-based method;convolutional neural network;deep learning technique;fingerprint ROI segmentation;fingerprint image test database;fingerprint region of interest segmentation","","","","","","","22-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"No-reference image quality assessment based on local binary patterns","I. Nenakhov; V. Khryashchev; A. Priorov","P.G. Demidov Yaroslavl, State University","2016 IEEE East-West Design & Test Symposium (EWDTS)","20170109","2016","","","1","4","This paper presents the new algorithm for no-reference image quality assessment (NRQ LBP). This algorithm does not need a priori information about possible types of image distortions before assessment. No transformation to another coordinate frame (DCT, wavelet, etc.) is required, distinguishing it from prior no reference quality assessment approaches. NRQ LBP is based on machine learning and uses extremely randomized trees method for mapping quality features with subject quality score (DMOS). Quality features are bins of a histogram of local binary patterns calculated for neighborhood radiuses 1, 2, 3 pixels. Comparative experimental results a given for modern image quality assessment algorithms (PSNR, SSIM, MS-SSIM, LBIQ, GRNN, BRISQUE, NRLBPS). Images from standard LIVE database are used as training and testing datasets. Spearman correlation coefficient, Pearson correlation coefficient and RMSE are used to determine the accuracy of compared algorithms. Performance results shows that proposed algorithm is highly competitive with tested algorithms and moreover it has very low computational complexity, making it well suited for real time applications.","","Electronic:978-1-5090-0693-9; POD:978-1-5090-0694-6","10.1109/EWDTS.2016.7807685","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807685","","Algorithm design and analysis;Correlation coefficient;Distortion;Image quality;Machine learning algorithms;Measurement;Transform coding","computational complexity;distortion;image processing","BRISQUE;GRNN;LBIQ;MS-SSIM;NRLBPS;NRQ LBP;Pearson correlation coefficient;RMSE;Spearman correlation coefficient;computational complexity;image distortions;local binary patterns;no-reference image quality assessment;quality assessment approaches","","","","","","","14-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Device-Free Number Gesture Recognition Approach Based on Deep Learning","Q. Zhou; J. Xing; J. Li; Q. Yang","Coll. of Defense Eng., PLA Univ. of Sci. & Technol., Nanjing, China","2016 12th International Conference on Computational Intelligence and Security (CIS)","20170119","2016","","","57","63","Number gestures play essential parts in our daily communication and have attracted academic interests in developing Human-Computer Interface. In this paper, we resort to the fine-grained Channel State Information (CSI) in the 802.11n standard to recognize number gestures. The intuition is that certain gestures can affect wireless environment in a specific formation and thus generate unique features. Unfortunately, the majority of CSI-based technologies only extracted coarse grained features to recognize macro-movements. Besides, it can be time-consuming to select the most discriminative feature as salient evidence. In this paper, we present a device-free number gesture recognition approach based on deep learning, named DeNum. First, we explore the sensibility of both the amplitude and phase information of de-noised CSI values to action transitions. Then the amplitude difference is utilized to detect the finishing points of actions through multiple sliding windows. To extract discriminative features from both the amplitude and phase information over three antennas, a 4-layer deep learning model is adopted after obtaining number gesture information. Finally, a Support Vector Machine (SVM) algorithm is applied for gesture classification. We conduct extensive experiments on commercial Wi-Fi devices with different experimental parameters. Experimental results demonstrate the presented approach can achieve the average accuracy of 94% in current office scenario.","","Electronic:978-1-5090-4840-3; POD:978-1-5090-4841-0","10.1109/CIS.2016.0022","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820413","Channel State Information;Deep learning;Number gesture recognition;Wi-Fi","Band-pass filters;Feature extraction;Gesture recognition;IEEE 802.11 Standard;Machine learning;Wireless communication;Wireless sensor networks","feature extraction;gesture recognition;image classification;image denoising;learning (artificial intelligence);support vector machines","4-layer deep learning model;CSI-based technologies;DeNum;SVM;Wi-Fi devices;amplitude information;channel state information;coarse grained feature extraction;denoised CSI values;device-free number gesture recognition;discriminative feature extraction;gesture classification;gesture information;human-computer interface;macromovement recognition;multiple sliding windows;number gesture information;phase information;support vector machine","","","","","","","16-19 Dec. 2016","","IEEE","IEEE Conference Publications"
"Combining Techniques to Find the Number of Bins for Discretization","M. A. Á. Carmona; J. A. C. Ochoa; J. F. M. Trinidad","Coordinaci&#x03BF;n de Cienc. Computacionales, Inst. Nac. de Astrofis., Opt. y Electr&#x03BF;n., Tonantzintla, Mexico","2013 32nd International Conference of the Chilean Computer Science Society (SCCC)","20170116","2013","","","54","57","In different problems and for different reasons, it is necessary to work with fully discretized domains. Commonly, continuous attributes are discretized in bins, but determining a suitable number of bins is a difficult task. In this paper, some ways for combining different techniques to estimate the number of bins for discretization are proposed and evaluated for both clustering and supervised classification tasks.","1522-4902;15224902","Electronic:978-1-5090-0426-3; POD:978-1-5090-0427-0","10.1109/SCCC.2013.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814435","Clustering;combining techniques;discretization;mixed data;number of bins","Clustering algorithms;Glass;Indexes;Iris;Linear regression;Machine learning algorithms","pattern classification;pattern clustering","bins number;clustering tasks;discretized domains;supervised classification tasks","","","","","","","11-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Sentiment Classification with Convolutional Neural Networks: An Experimental Study on a Large-Scale Chinese Conversation Corpus","L. Zhang; C. Chen","","2016 12th International Conference on Computational Intelligence and Security (CIS)","20170119","2016","","","165","169","Previous research on sentiment classification by machine learning algorithms has shown that they usually work well with large-scale dataset. However, most open datasets for Chinese sentiment classification are quite small. In this paper we build a large-scale annotated Chinese sentiment dataset by filtering a vast amount of human-computer conversations. We conduct thorough experiments by using Convolutional Neural Networks (CNNs) and other classical machine learning methods. The experimental evaluation is made on a human-annotated dataset and COAE2014 task. The extensive experiments demonstrate that Chinese sentiment classification task can benefit from our dataset and CNNs model can achieve better performance than classical machine learning approaches.","","Electronic:978-1-5090-4840-3; POD:978-1-5090-4841-0","10.1109/CIS.2016.0046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820437","Chinese sentiment classification;Convolutional Neural Networks;deep learning","Computational modeling;Feature extraction;Machine learning algorithms;Neural networks;Robots;Sentiment analysis;Training","feedforward neural nets;human computer interaction;learning (artificial intelligence);natural language processing;sentiment analysis","CNN model;COAE2014 task;Chinese sentiment classification;convolutional neural networks;human-annotated dataset;human-computer conversations;large-scale Chinese conversation corpus;large-scale annotated Chinese sentiment dataset;large-scale dataset;machine learning;open dataset","","","","","","","16-19 Dec. 2016","","IEEE","IEEE Conference Publications"
"Future 50 years of mobile radio propagation research","K. Kitao","5G Laboratory, NTT DOCOMO, INC., 3-6 Hikarino-oka, Yokosuka-shi, Kanagawa 239-8536, Japan","2016 International Symposium on Antennas and Propagation (ISAP)","20170119","2016","","","560","561","This paper overviews the latest developments in mobile radio propagation research and presents our views looking to the future. Radio propagation research has high affinity to machine learning such as deep learning since it can deal with copious amounts of measurement data. Deep learning is useful for image recognition and can be applied to modeling of building materials. This modeling achieved through the analysis of building images is needed for radio propagation simulations. Therefore, we believe that the application of deep learning to mobile radio propagation research will emerge as a main topic in the future.","","Electronic:978-4-88552-313-7; POD:978-1-4673-7960-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821202","Deep learning;Mobile radio propagation;Radio propagation model;Radio propagation simulation","Analytical models;Buildings;Data models;Land mobile radio;Machine learning;Radio propagation","learning (artificial intelligence);mobile communication;radiowave propagation","building material modeling;deep learning;image recognition;machine learning;mobile radio propagation","","","","","","","24-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Multi-stream Deep Learning Framework for Automated Presentation Assessment","J. Li; Y. Wong; M. S. Kankanhalli","Grad. Sch. for Integrative Sci. & Eng., Nat. Univ. of Singapore, Singapore, Singapore","2016 IEEE International Symposium on Multimedia (ISM)","20170119","2016","","","222","225","Presentation is one of the most effective methods to disseminate information. Traditional methods to evaluate the quality of a presentation generally involves a human instructor, which is infeasible in many scenarios. Recent studies have focused on the automated assessment of presentations. A variety of systems have been developed that focus on analyzing various aspects of presentations. However, those systems are mainly limited by their performance, as they mostly adopt hand-crafted features and ad-hoc algorithms. In this work, we propose a multi-stream deep learning framework customized for presentation assessment. The framework uses Bidirectional Long Short-Term Memory with attention mechanism for temporal modeling, and fuses information from multiple modalities for the final decision. We also design a novel assessment rubric based on input from a domain expert. Experimental results on the NUS Multi-Sensor Presentation (NUSMAP) dataset show that the proposed framework is computationally efficient and achieves significant improvement in classification accuracy.","","Electronic:978-1-5090-4571-6; POD:978-1-5090-4572-3","10.1109/ISM.2016.0051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823618","Deep Learning;Presentation Assessment","Feature extraction;Machine learning;Mel frequency cepstral coefficient;Robustness;Sensors;Skeleton;Speech recognition","information dissemination;learning (artificial intelligence);pattern classification;sensor fusion","NUS multisensor presentation dataset;NUSMAP dataset;assessment rubric;attention mechanism;automated presentation assessment;bidirectional long short-term memory;classification accuracy;domain expert;information dissemination;information fusion;multistream deep learning;temporal modeling","","","","","","","11-13 Dec. 2016","","IEEE","IEEE Conference Publications"
"A predictive model of gene expression using a deep learning framework","Rui Xie; A. Quitadamo; J. Cheng; Xinghua Shi","Department of Computer Science, University of Missouri at Columbia, 65201, USA","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","676","681","With an unprecedented amount of data available, it is important to explore new methods for developing predictive models to mine this data for scientific discoveries. In this study, we propose a deep learning regression model based on MultiLayer Perceptron and Stacked Denoising Auto-encoder (MLP-SAE) to predict gene expression from genotypes of genetic variation. Specifically, we use a stacked denoising auto-encoder to train our regression model in order to extract useful features, and utilize the multilayer perceptron for backpropagation. We further improve our model by adding a dropout technique to prevent overfitting. Our results on a real genomic dataset show that our MLP-SAE model with dropout outperform Lasso, Random Forests, and MLP-SAE without dropout. Our study provides a new application of deep learning in mining genomics data, and demonstrates that deep learning has great potentials in building predictive models to help understand biological systems.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822599","","Data models;Gene expression;Machine learning;Mathematical model;Predictive models;Training","backpropagation;biology computing;data mining;feature extraction;genetics;genomics;multilayer perceptrons;regression analysis","MLP-SAE model;backpropagation;biological systems;deep learning regression model;dropout technique;feature extraction;gene expression;genetic variation genotypes;genomic dataset;genomics data mining;multilayer perceptron;stacked denoising autoencoder","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"DNN-based voice activity detection with local feature shift technique","T. G. Kang; K. H. Lee; W. H. Kang; S. H. Bae; N. S. Kim","Department of Electrical and Computer Engineering and INMC, Seoul National University, Seoul, Korea","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20170119","2016","","","1","4","Recently, the deep neural networks (DNNs) are successfully adopted into the voice activity detection (VAD) area. However, the performance of the DNN-based VAD is still unsatisfactory in noise environments where the feature subspace of the training database and the test environments are not matched with each other. In this paper, we propose a local feature shift technique which normalizes the feature subspaces over various noise environments. The proposed technique considers the local minimum vectors of the log-Mel filterbank features as noise power estimates and produces feature shift vectors from them. The experimental results in stationary and non-stationary noise environments show that the DNN with the proposed technique outperforms the conventional DNN-based VAD algorithms.","","Electronic:978-9-8814-7682-1; POD:978-1-5090-2401-8","10.1109/APSIPA.2016.7820753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820753","","Databases;Feature extraction;Machine learning algorithms;Noise measurement;Signal processing algorithms;Speech;Training","channel bank filters;neural nets;voice activity detection","DNN-based voice activity detection;deep neural network-based VAD;feature subspace normalization;local feature shift technique;log-Mel filterbank;noise environment;nonstationary noise environment;stationary noise environment;test environment;training database feature subspace","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks","C. Zhang; Zhenman Fang; Peipei Zhou; Peichen Pan; Jason Cong","Center for Energy-Efficient Computing and Applications, Peking University, Beijing, China","2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","20170123","2016","","","1","8","With the recent advancement of multilayer convolutional neural networks (CNN), deep learning has achieved amazing success in many areas, especially in visual content understanding and classification. To improve the performance and energy-efficiency of the computation-demanding CNN, the FPGA-based acceleration emerges as one of the most attractive alternatives. In this paper we design and implement Caffeine, a hardware/software co-designed library to efficiently accelerate the entire CNN on FPGAs. First, we propose a uniformed convolutional matrix-multiplication representation for both computation-intensive convolutional layers and communication-intensive fully connected (FCN) layers. Second, we design Caffeine with the goal to maximize the underlying FPGA computing and bandwidth resource utilization, with a key focus on the bandwidth optimization by the memory access reorganization not studied in prior work. Moreover, we implement Caffeine in the portable high-level synthesis and provide various hardware/software definable parameters for user configurations. Finally, we also integrate Caffeine into the industry-standard software deep learning framework Caffe. We evaluate Caffeine and its integration with Caffe by implementing VGG16 and AlexNet network on multiple FPGA platforms. Caffeine achieves a peak performance of 365 GOPS on Xilinx KU060 FPGA and 636 GOPS on Virtex7 690t FPGA. This is the best published result to our best knowledge. We achieve more than 100× speedup on FCN layers over previous FPGA accelerators. An end-to-end evaluation with Caffe integration shows up to 7.3× and 43.5× performance and energy gains over Caffe on a 12-core Xeon server, and 1.5× better energy-efficiency over the GPU implementation on a medium-sized FPGA (KU060). Performance projections to a system with a high-end FPGA (Virtex7 690t) shows even higher gains.","","Electronic:978-1-4503-4466-1; POD:978-1-5090-3421-5","10.1145/2966986.2967011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827589","","Acceleration;Bandwidth;Convolution;Field programmable gate arrays;Graphics processing units;Kernel;Machine learning","circuit optimisation;energy conservation;feedforward neural nets;field programmable gate arrays;image classification;learning (artificial intelligence);matrix multiplication;performance evaluation;power aware computing;resource allocation","12-core Xeon server;AlexNet network;CNN;Caffe integration evaluation;Caffeine design;FCN layers;FPGA accelerators;FPGA-based acceleration;VGG16 network;Virtex7 690t FPGA;Xilinx KU060 FPGA;bandwidth optimization;bandwidth resource utilization;communication-intensive fully connected layers;computation-intensive convolutional layers;deep convolutional neural networks;energy gains;energy-efficiency;hardware-software co-designed library;industry-standard software deep learning framework;memory access reorganization;multilayer convolutional neural networks;performance improvement;portable high-level synthesis;uniformed convolutional matrix-multiplication representation;visual content classification;visual content understanding","","","","","","","7-10 Nov. 2016","","IEEE","IEEE Conference Publications"
"Human activity recognition with inertial sensors using a deep learning approach","T. Zebin; P. J. Scully; K. B. Ozanyan","School of EEE, University of Manchester, UK","2016 IEEE SENSORS","20170109","2016","","","1","3","Our focus in this research is on the use of deep learning approaches for human activity recognition (HAR) scenario, in which inputs are multichannel time series signals acquired from a set of body-worn inertial sensors and outputs are predefined human activities. Here, we present a feature learning method that deploys convolutional neural networks (CNN) to automate feature learning from the raw inputs in a systematic way. The influence of various important hyper-parameters such as number of convolutional layers and kernel size on the performance of CNN was monitored. Experimental results indicate that CNNs achieved significant speed-up in computing and deciding the final class and marginal improvement in overall classification accuracy compared to the baseline models such as Support Vector Machines and Multi-layer perceptron networks.","","Electronic:978-1-4799-8287-5; POD:978-1-4799-8288-2","10.1109/ICSENS.2016.7808590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7808590","Convolution;Convolutional Neural Networks (CNN);Feature Extraction;Human activity recognition (HAR);Signal Processing","Activity recognition;Convolution;Feature extraction;Machine learning;Neural networks;Support vector machines","feature extraction;neural nets;signal processing","convolutional layers;convolutional neural networks;deep learning approach;feature learning method;human activity recognition;inertial sensors;kernel size","","","","","","","Oct. 30 2016-Nov. 3 2016","","IEEE","IEEE Conference Publications"
"Animation Rendering on Multimedia Fog Computing Platforms","H. J. Hong; J. C. Chuang; C. H. Hsu","Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsin-Chu, Taiwan","2016 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)","20170126","2016","","","336","343","Modern distributed multimedia applications are resource-hungry, and they often leverage on-demand cloud services to reduce their expenses. Existing cloud services deploy many servers in a few data centers, which consume a lot of electricity to power up and cold down, and thus are expensive and environmentally unfriendly. In this paper, we present a multimedia fog computing platform that utilizes resources from public crowds, edge networks, and data centers to serve distributed multimedia applications at lower costs. We use animation rendering as a case study, and identify several challenges for optimizing it on our multimedia fog computing platform. Among these challenges, we focus on the problem of predicting the completion time of each rendering job. We propose an efficient algorithm based on state-of-the-art machine learning algorithms. We also fine-tune the algorithm using multi-fold cross-validation for higher prediction accuracy. With real datasets, we conduct trace-driven simulations to quantify the performance of our prediction algorithm and that of the whole platform. The simulation results show that our proposed algorithm outperforms a state-of the-art statistical model in several aspects: completed job ratio by 20%, makespan by 2 times, and normalized deviation by 30 times, on average. Moreover, the overall performance of the platform with our proposed algorithm is fairly close to that with an Oracle of the actual job completion time: a small factor of 1.48 in terms of makespan is observed.","","Electronic:978-1-5090-1445-3; POD:978-1-5090-1446-0","10.1109/CloudCom.2016.0060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830701","Edge computing;animation rendering;fog computing;prediction;volunteer computing","Animation;Edge computing;Machine learning algorithms;Multimedia communication;Multimedia computing;Prediction algorithms;Rendering (computer graphics)","cloud computing;computer animation;computer centres;learning (artificial intelligence);multimedia computing;rendering (computer graphics);statistical analysis","Oracle;animation rendering;data centers;distributed multimedia applications;edge networks;job completion time;machine learning;multifold cross-validation;multimedia fog computing platforms;on-demand cloud services;public crowds;statistical model","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep Learning Based Affective Model for Speech Emotion Recognition","X. Zhou; J. Guo; R. Bie","Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China","2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)","20170116","2016","","","841","846","Considering the application value of emotion, increasing attention has been attracted on emotion recognition over the last decades. We devote ourselves to feasible speech emotion recognition research. We build two affective model based on deep learning methods (stacked autoencoder network, deep belief network) for automatic salient emotion feature extraction, emotion states classification. The experiments are based on a well-known German Berlin Emotional Speech Database, the recognition accuracy reaches 65% in the best case. In addition, we validate the influence of different speakers, different emotion categories on recognition accuracy.","","Electronic:978-1-5090-2771-2; POD:978-1-5090-2772-9","10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816929","Affective Model;Deep Learning;Speech Emotion Recognition","Emotion recognition;Encoding;Feature extraction;Machine learning;Speech;Speech recognition;Training","affective computing;belief networks;emotion recognition;feature extraction;learning (artificial intelligence);speech recognition","German Berlin Emotional Speech Database;automatic salient emotion feature extraction;deep belief network;deep learning based affective model;emotion categories;emotion states classification;recognition accuracy;speech emotion recognition;stacked autoencoder network","","","","","","","18-21 July 2016","","IEEE","IEEE Conference Publications"
"A deep learning-based multi-sensor data fusion method for degradation monitoring of ball screws","L. Zhang; H. Gao","Department of Mechanical Engineering, Southwest Jiaotong University, Chengdu 610031, China","2016 Prognostics and System Health Management Conference (PHM-Chengdu)","20170119","2016","","","1","6","As ball screw has complex structure and long range of distribution, single signal collected by one sensor is difficult to express its condition fully and accurately. Multi-sensor data fusion usually has a better effect compared with single signal. Multi-sensor data fusion based on neural network(BP) is a commonly used multi-sensor data fusion method, but its application is limited by local optimum problem. Aiming at this problem, a multi-sensor data fusion method based on deep learning for ball screw is proposed in this paper. Deep learning, which consists of unsupervised learning and supervised learning, is the development and evolution of traditional neural network. It can effectively alleviate the optimization difficulty. Parallel superposition on frequency spectra of signals is directly done in the proposed deep learning-based multi-sensor data fusion method, and deep belief networks(DBN) are established by using fused data to adaptively mine available fault characteristics and automatically identify the degradation condition of ball screw. Test is designed to collect vibration signals of ball screw in 7 different degradation conditions by using 5 acceleration sensors installed on different places. The proposed fusion method is applied in identifying the degradation degree of ball screw in the test to demonstrate its efficacy. Finally, the multi-sensor data fusion based on neural network is also applied in degradation degree monitoring. The monitoring accuracy of deep learning-based multi-sensor data fusion is higher compared with that of neural network-based multi-sensor data fusion, which means the proposed method has more superiority.","","Electronic:978-1-5090-2778-1; POD:978-1-5090-2779-8; USB:978-1-5090-2777-4","10.1109/PHM.2016.7819792","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819792","ball screw;deep learning;degradation monitoring;multi-sensor data fusion","Data integration;Degradation;Machine learning;Mechanical products;Monitoring;Sensors;Training","ball screws;belief networks;condition monitoring;learning (artificial intelligence);mechanical engineering computing;neural nets;sensor fusion","BP;DBN;acceleration sensors;ball screws;deep belief networks;deep learning-based multisensor data fusion method;degradation conditions;degradation degree monitoring;local optimum problem;neural network;parallel superposition","","","","","","","19-21 Oct. 2016","","IEEE","IEEE Conference Publications"
"Estimation method of initial labels for propagation-based saliency detection","Y. Umeki; T. Yoshida; M. Iwahashi","Dept. Electrical Electronics Information Engineering, Nagaoka Univ. of Tech., Nagaoka, Niigata, 940-2137 Japan","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20170119","2016","","","1","4","We propose an estimation method of initial labels based on scale-invariant feature transform (SIFT), high dimensional color transform (HDCT), and machine learning for propagation-based saliency detection. The label propagation strategy is efficient for saliency detection, but its accuracy depends on the distribution of initial labels. In this paper, the proposed method respectively estimates initial labels of fore/background based on the machine learning with HDCT and the density of SIFT feature points. Consequently, initial labels are certainly distributed all over the region and inaccurate saliencies are attenuated in resultant saliency maps. Through simulations, we show that the proposed method outperforms the state-of-the-art methods objectively and perceptually.","","Electronic:978-9-8814-7682-1; POD:978-1-5090-2401-8","10.1109/APSIPA.2016.7820828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820828","","Estimation;Feature extraction;Histograms;Image color analysis;Machine learning algorithms;Object detection;Transforms","discrete cosine transforms;image colour analysis;learning (artificial intelligence);object detection","HDCT;SIFT feature points;high dimensional color transform;initial labels estimation method;initial labels. distribution;label propagation strategy;machine learning;propagation-based saliency detection;scale-invariant feature transform","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Hyperspectral image analysis using deep learning — A review","H. Petersson; D. Gustafsson; D. Bergstrom","Swedish Defence Research Agency (FOI), Division of C4ISR","2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","20170119","2016","","","1","6","Deep learning is a rather new approach to machine learning that has achieved remarkable results in a large number of different image processing applications. Lately, application of deep learning to detect and classify spectral and spatio-spectral signatures in hyperspectral images has emerged. The high dimensionality of hyperspectral images and the limited amount of labelled training data makes deep learning an appealing approach for analysing hyperspectral data. Auto-Encoder can be used to learn a hierarchical feature representation using solely unlabelled data, the learnt representation can be combined with a logistic regression classifier to achieve results in-line with existing state-of-the-art methods. In this paper, we compare results between a set of available publications and find that deep learning perform in line with state-of-the-art on many data sets but little evidence exists that deep learning outperform the reference methods.","","Electronic:978-1-4673-8910-5; POD:978-1-4673-8911-2","10.1109/IPTA.2016.7820963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820963","Auto-Encoder (AE);Convolutional Neural Network (CNN);Deep Learning;Hyperspectral Imaging (HSI);Stacked Auto-Encoder (SAE);feature representation","Feature extraction;Hyperspectral imaging;Kernel;Machine learning;Neural networks","feature extraction;hyperspectral imaging;image classification;image representation;learning (artificial intelligence);regression analysis","auto-encoder;deep learning;hierarchical feature representation;hyperspectral data analysis;hyperspectral image analysis;image processing applications;logistic regression classifier;machine learning","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Human interaction recognition through deep learning network","S. J. Berlin; M. John","Department of Electronics Engineering, Madras Institute of Technology, Anna University, Chennai, India","2016 IEEE International Carnahan Conference on Security Technology (ICCST)","20170116","2016","","","1","4","This paper provides an efficient framework for recognizing human interactions based on deep learning based architecture. The Harris corner points and the histogram form the feature vector of the spatiotemporal volume. The feature vector extraction is restricted to the region of interaction. A stacked autoencoder configuration is embedded in the deep learning framework used for classification. The method is evaluated on the benchmark UT interaction dataset and average recognition rates as high as 95% and 88% are obtained on setl and set2 respectively.","","Electronic:978-1-5090-1072-1; POD:978-1-5090-1073-8","10.1109/CCST.2016.7815695","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7815695","Video surveillance;autoencoder;deep learning network;human interaction recognition;video analytics","Classification algorithms;Feature extraction;Histograms;Machine learning;Spatiotemporal phenomena;Trajectory;Video sequences","feature extraction;learning (artificial intelligence);video surveillance","Harris corner points;UT interaction dataset;deep learning based architecture;deep learning network;feature vector;feature vector extraction;human interaction recognition;spatiotemporal volume;stacked autoencoder configuration","","","","","","","24-27 Oct. 2016","","IEEE","IEEE Conference Publications"
"KPTI: Katib's Pashto Text Imagebase and Deep Learning Benchmark","R. Ahmad; M. Z. Afzal; S. F. Rashid; M. Liwicki; T. Breuel; A. Dengel","DFKI, Tech. Univ. Kaiserslautern, Kaiserslautern, Germany","2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)","20170116","2016","","","453","458","This paper presents the first Pashto text image database for scientific research and thereby the first dataset with complete handwritten and printed text line images which ultimately covers all alphabets of Arabic and Persian languages. Language like Pashto, written in a complex way by calligraphers, still requires a mature Optical Character Recognition (OCR), system. Although 50 million people use this language both for oral and written communication, there is no significant effort which is devoted to the recognition of Pashto Script. A real dataset of 17,015 images having Pashto text lines is introduced. The images are acquired via scanning from hand scribed Pashto books. Further, in this work, we evaluated the performance of deep learning based models like Bidirectional and Multi-Dimensional Long Short Term Memory (BLSTM and MDLSTM) networks for Pashto texts and provide a baseline character error rate of 9.22%.","2167-6445;21676445","Electronic:978-1-5090-0981-7; POD:978-1-5090-0982-4","10.1109/ICFHR.2016.0090","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814106","Cursive script;KPTI;LSTM;OCR;Pashto","Benchmark testing;Character recognition;Handwriting recognition;Layout;Machine learning;Optical character recognition software;Text recognition","database management systems;image texture;learning (artificial intelligence);natural language processing;optical character recognition","Arabic languages;BLSTM;KPTI;Katib Pashto text image database;MDLSTM;OCR;Pashto Script recognition;Persian languages;baseline character error rate;bidirectional long short term memory networks;deep learning benchmark;hand scribed Pashto books;multidimensional long short term memory networks;optical character recognition;printed text line images","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Review of Soft Computing Based on Deep Learning","J. Zhang; C. Tao; P. Wang","Sch. of Autom., Wuhan Univ. of Technol. Wuhan, Wuhan, China","2016 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII)","20170119","2016","","","136","144","A review of deep learning based soft computing techniques in several applications is presented. On one hand, soft computing, defined as a group of methodologies, is an important element for constructing a new generation of computational intelligent system and has gained great success in solving practical computing problems. On the other hand, deep learning has become one of the most promising techniques in artificial intelligence in the past decade. Since soft computing is an evolving collection of methodologies, by presenting the latest research results of soft computing based on deep learning, this review not only reveals a promising direction for soft computing by incorporating deep learning, but also gives some suggestions for improving the performance of deep learning with soft computing techniques.","","Electronic:978-1-5090-3575-5; POD:978-1-5090-3576-2; USB:978-1-5090-3574-8","10.1109/ICIICII.2016.0043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823510","convolutional neural network;deep belief network;fuzzy logic;genetic algorithm;soft computing","Biological neural networks;Feature extraction;Fuzzy logic;Genetic algorithms;Machine learning;Optimization","fuzzy logic;learning (artificial intelligence);neural nets","computational intelligent system;deep learning;performance improvement;soft computing","","","","","","","3-4 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Novel Deep Model for Biopsy Image Grading","G. Zhang; Z. H. Liang; H. D. Lai; Y. Y. Lin; D. Lin; Z. P. Li","Sch. of Autom., Guangdong Univ. of Technol., Guangzhou, China","2016 International Conference on Information System and Artificial Intelligence (ISAI)","20170116","2016","","","323","326","We propose in this paper a deep learning model based on convolutional neural network (CNN) for biopsy image grading. The model outputs a vector of scores indicating presence or severity of the target histopathological characteristics. Within the model, we first design a 7-layer CNN for feature representation and high level concept extraction. Each biopsy image is expressed as a feature vector through our CNN processor. We then place a sigmoid function into the output layer so as to generate a score for each target characteristic. The proposed model is evaluated on a benchmark dataset and a real biopsy image dataset to show its effectiveness.","","Electronic:978-1-5090-1585-6; POD:978-1-5090-1586-3","10.1109/ISAI.2016.0075","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816728","biopsy image grading;convolutional neural network;deep learning;histopathological image analysis;sigmoid function","Biological system modeling;Biopsy;Computational modeling;Feature extraction;Machine learning;Solid modeling;Training","feature extraction;learning (artificial intelligence);medical image processing;neural nets","CNN;biopsy image grading;convolutional neural network;deep learning model;feature representation;high level concept extraction;histopathological characteristics;sigmoid function","","","","","","","24-26 June 2016","","IEEE","IEEE Conference Publications"
"Improving the reliability of 3D people tracking system by means of deep-learning","M. Boschini; M. Poggi; S. Mattoccia","University of Bologna, Department of Computer Science and Engineering (DISI), Viale del Risorgimento 2, Bologna, Italy","2016 International Conference on 3D Imaging (IC3D)","20170119","2016","","","1","8","People tracking is a crucial task in most computer vision applications aimed at analyzing specific behaviors in the sensed area. Practical applications include vision analytics, people counting, etc. In order to properly follow the actions of a single subject, a people tracking framework needs to robustly recognize it from the rest of the surrounding environment, thus allowing proper management of changing positions, occlusions and so on. The recent widespread diffusion of deep learning techniques on almost any kind of computer vision application provides a powerful methodology to address recognition. On the other hand, a large amount of data is required to train state-of-the-art Convolutional Neural Networks (CNN) and this problem is solved, when possible, by means of transfer learning. In this paper, we propose a novel dataset made of nearly 26 thousand samples acquired with a custom stereo camera providing depth according to a fast and accurate stereo algorithm. The dataset includes sequences acquired in different environments with more than 20 different people moving across the sensed area. Once labeled the 26 K images and depth maps of the dataset, we train a head detection module based on state-of-the-art deep network on a portion of the dataset and validate it a different sequence. Finally, we include the head detection module within an existing 3D tracking framework showing that the proposed approach notably improves people detection and tracking accuracy.","","Electronic:978-1-5090-5743-6; POD:978-1-5090-5744-3; USB:978-1-5090-5742-9","10.1109/IC3D.2016.7823454","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823454","3D;deep learning;people detection;stereo vision;tracking","Cameras;Head;Image color analysis;Machine learning;Three-dimensional displays;Two dimensional displays;Visualization","cameras;computer vision;learning (artificial intelligence);neural nets;object detection;object tracking;stereo image processing","3D people tracking system reliability;computer vision;convolutional neural networks;deep-learning;head detection module;people detection;stereo algorithm;stereo camera","","","","","","","13-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"Clothing-invariant gait recognition using convolutional neural network","T. Yeoh; H. E. Aguirre; K. Tanaka","Faculty of Engineering, Shinshu University, 4-17-1 Wakasato, Nagano 380-8553, Japan","2016 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)","20170119","2016","","","1","5","Gait recognition is recognizing human through the style in which they walk. However, the recognition task can become complicated due to the existence of covariate factors (e.g. clothing, camera viewpoint, carrying condition, elapsed time, walking surface, etc). Amongst all the covariate factors, clothing is the most challenging one. This is because it may obscure a significant amount of discriminative human gait features and makes it much more challenging for human recognition task. In recent, there has been significant research on this problem. However, conventional state-of-the-art methods have mostly use hand-crafted features for representing the human gait. In this work, we explore and study the use of convolutional neural networks (CNN) to automatically learn gait features or representations directly from low-level input raw data (i.e. Gait Energy Image (GEI)). Evaluations on the challenging clothing-invariant gait recognition of OU-ISIR Treadmill dataset B, the experiment results shows that our method can achieve far better performance as compared to hand-crafted feature in conventional state-of-the-art methods with minimal preprocessing knowledge of the problem are required.","","Electronic:978-1-5090-0629-8; POD:978-1-5090-0630-4; USB:978-1-5090-0628-1","10.1109/ISPACS.2016.7824728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7824728","Clothing-invariant;Convolutional Neural Network (CNN);Deep learning;Gait energy image (GEI);Gait recognition","Clothing;Feature extraction;Gait recognition;Legged locomotion;Machine learning;Probes;Training","convolution;gait analysis;image representation;neural nets;object recognition","CNN;OU-ISIR Treadmill dataset B;clothing-invariant gait recognition;convolutional neural network;covariate factors;discriminative human gait features;hand-crafted features;human gait representation;human recognition","","","","","","","24-27 Oct. 2016","","IEEE","IEEE Conference Publications"
"Benchmarking Sentiment Analysis Approaches on the Cloud","R. O. Sinnott; S. Cui","Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia","2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)","20170119","2016","","","695","704","Social media resources such as Twitter provide global services for citizens to express opinions on people, products, events or even themselves. Often this data captures the mood (sentiment) of the tweeter. Accurate and timely extraction of sentiment from such big data can be used for many population-wide business and research scenarios. Whilst a range of sentiment analysis approaches has been taken, little systematic comparison of these approaches has been undertaken. The motivation of this paper is to investigate various sentiment analysis approaches and evaluate their accuracy and performance for Twitter-based sentiment analysis on major Cloud facilities across Australia. We consider especially the impact of training data on performance and accuracy of sentiment analysis. To support this, we present a Cloud-based architecture and its realization through an elastic, distributed, data processing system used for harvesting, analyzing and storing large-scale Twitter data sets.","1521-9097;15219097","Electronic:978-1-5090-4457-3; POD:978-1-5090-5382-7","10.1109/ICPADS.2016.0096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823811","Cloud Computing;Performance;Sentiment Analysis;Twitter","Algorithm design and analysis;Cloud computing;Machine learning algorithms;Sentiment analysis;Training;Training data;Twitter","benchmark testing;cloud computing;data analysis;distributed processing;sentiment analysis;social networking (online)","Australia;benchmarking sentiment analysis approaches;cloud computing;cloud facilities;cloud-based architecture;data processing system;distributed system;elastic system;global services;large-scale Twitter data sets;social media resources","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Fusion Based Deep CNN for Improved Large-Scale Image Action Recognition","Y. Lavinia; H. H. Vo; A. Verma","Dept. of Comput. Sci., California State Univ., Fullerton, CA, USA","2016 IEEE International Symposium on Multimedia (ISM)","20170119","2016","","","609","614","Still image-based action recognition is a process of labeling actions captured in still images. We propose a fusion method that concatenates two and three deep convolutional neural networks (CNN). After examining the classification accuracy of each deep CNN candidates, we inserted a 100 dimensional fully-connected layer and extracted features from the new 100 dimensional and the last fully-connected layers to create a pool of candidate layers. We form our fusion models by concatenating two or three layers from this pool-one from each model-and trained and tested them on the large-scale Stanford 40 Actions still image dataset. We forwarded the concatenated features to Random Forest and SVM for classification. Our experiments show that our fusion of two deep CNN models achieved better accuracy than the individual models, with the best performing fusion duo of 80.351% accuracy. The fusion of three models increases the accuracy even further, performing better than both the individual and the fusion of two models, with 81.146% accuracy. Moreover, we also investigate the classification difficulty level of the Stanford 40 Actions category.","","Electronic:978-1-5090-4571-6; POD:978-1-5090-4572-3","10.1109/ISM.2016.0131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823698","GoogLeNet;ResNet;VGGNet;action recognition;deep convolutional neural networks;deep learning fusion model","Computational modeling;Feature extraction;Image recognition;Machine learning;Neural networks;Support vector machines;Visualization","feature extraction;image classification;image fusion;image recognition;neural nets;support vector machines","SVM;deep convolutional neural networks;feature extraction;fusion based deep CNN;fusion models;large-scale image action recognition;random forest;still image-based action recognition","","","","","","","11-13 Dec. 2016","","IEEE","IEEE Conference Publications"
"Bayesian optimization for maximum power point tracking in photovoltaic power plants","H. Abdelrahman; F. Berkenkamp; J. Poland; A. Krause","Learning & Adaptive Systems Group (LAS), Department of Computer Science, ETH Zurich, Switzerland","2016 European Control Conference (ECC)","20170109","2016","","","2078","2083","The amount of power that a photovoltaic (PV) power plant generates depends on the DC voltage that is applied to the PV panels. The relationship between this control input and the generated power is non-convex and has multiple local maxima. Moreover, since the generated power depends on time-varying environmental conditions, such as solar irradiation, the location of the global maximum changes over time. Maximizing the amount of energy that is generated over time is known as the maximum power point tracking (MPPT) problem. Traditional approaches to solve the MPPT problem rely on heuristics and data-based gradient estimates. These methods typically converge to local optima and thus waste energy. Our approach formalizes the MPPT problem as a Bayesian optimization problem. This formalization admits algorithms that can find the maximum power point after only a few evaluations at different input voltages. Specifically, we model the power-voltage curve as a Gaussian process (GP) and use the predictive uncertainty information in this model to choose control inputs that are informative about the location of the maximum. We extend the basic approach by including operational constraints and making it computationally tractable so that the method can be used on real systems. We evaluate our method together with two standard baselines in experiments, which show that our approach outperforms both.","","Electronic:978-1-5090-2591-6; POD:978-1-5090-2592-3; USB:978-1-5090-2590-9","10.1109/ECC.2016.7810598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7810598","","Bayes methods;Machine learning algorithms;Maximum power point trackers;Optimization;Uncertainty;Voltage measurement","Bayes methods;Gaussian processes;maximum power point trackers;optimisation;photovoltaic power systems","Bayesian optimization problem;GP;Gaussian process;MPPT problem;PV panels;data-based gradient estimates;maximum power point tracking;photovoltaic power plants;predictive uncertainty information","","","","","","","June 29 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"CSI-Based Fingerprinting for Indoor Localization: A Deep Learning Approach","X. Wang; L. Gao; S. Mao; S. Pandey","Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA","IEEE Transactions on Vehicular Technology","20170116","2017","66","1","763","776","With the fast-growing demand of location-based services in indoor environments, indoor positioning based on fingerprinting has attracted significant interest due to its high accuracy. In this paper, we present a novel deep-learning-based indoor fingerprinting system using channel state information (CSI), which is termed DeepFi. Based on three hypotheses on CSI, the DeepFi system architecture includes an offline training phase and an online localization phase. In the offline training phase, deep learning is utilized to train all the weights of a deep network as fingerprints. Moreover, a greedy learning algorithm is used to train the weights layer by layer to reduce complexity. In the online localization phase, we use a probabilistic method based on the radial basis function to obtain the estimated location. Experimental results are presented to confirm that DeepFi can effectively reduce location error, compared with three existing methods in two representative indoor environments.","0018-9545;00189545","","10.1109/TVT.2016.2545523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438932","Channel state information (CSI);WiFi;deep learning;fingerprinting;indoor localization","Antennas;Complexity theory;Fading channels;IEEE 802.11 Standard;Indoor environments;Machine learning;Training","greedy algorithms;indoor communication;telecommunication channels;telecommunication security","CSI-based fingerprinting;DeepFi;channel state information;deep learning approach;deep network;indoor environments;indoor localization;indoor positioning;localization phase;location-based services;probabilistic method;representative indoor environments","","5","","","","20160322","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"A deep learning approach to detection of splicing and copy-move forgeries in images","Y. Rao; J. Ni","Guangdong Key Laboratory of Information Security Technology, Sun Yat-Sen University, GuangZhou, GuangDong, P.R. China","2016 IEEE International Workshop on Information Forensics and Security (WIFS)","20170119","2016","","","1","6","In this paper, we present a new image forgery detection method based on deep learning technique, which utilizes a convolutional neural network (CNN) to automatically learn hierarchical representations from the input RGB color images. The proposed CNN is specifically designed for image splicing and copy-move detection applications. Rather than a random strategy, the weights at the first layer of our network are initialized with the basic high-pass filter set used in calculation of residual maps in spatial rich model (SRM), which serves as a regularizer to efficiently suppress the effect of image contents and capture the subtle artifacts introduced by the tampering operations. The pre-trained CNN is used as patch descriptor to extract dense features from the test images, and a feature fusion technique is then explored to obtain the final discriminative features for SVM classification. The experimental results on several public datasets show that the proposed CNN based model outperforms some state-of-the-art methods.","","Electronic:978-1-5090-1138-4; POD:978-1-5090-1139-1","10.1109/WIFS.2016.7823911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823911","","Convolution;Feature extraction;Forgery;Kernel;Machine learning;Splicing;Support vector machines","image representation;learning (artificial intelligence);neural nets;object detection;support vector machines","RGB color images;SRM;SVM classification;convolutional neural network;copy-move forgery detection;deep learning approach;feature fusion technique;hierarchical representation;image contents;image forgery detection method;red-green-blue color image;residual maps;spatial rich model;splicing detection;support vector machines;tampering operation","","","","","","","4-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"DeepEnhancer: Predicting enhancers by convolutional neural networks","Xu Min; Ning Chen; Ting Chen; Rui Jiang","MOE Key Laboratory of Bioinformatics, Bioinformatics Division and Center for Synthetic & Systems Biology, TNLIST, Department of Automation, Tsinghua University, Beijing 100084, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","637","644","Enhancers are crucial to the understanding of mechanisms underlying gene transcriptional regulation. Although having been successfully applied in such projects as ENCODE and Roadmap to generate landscape of enhancers in human cell lines, high-throughput biological experimental techniques are still costly and time consuming for even larger scale identification of enhancers across a variety of tissues under different disease status, making computational identification of enhancers indispensable. In this paper, we propose a computational framework, named DeepEnhancer, to classify enhancers from background genomic sequences. We construct convolutional neural networks of various architectures and compare the classification performance with traditional sequence-based classifiers. We first train the deep learning model on the FANTOM5 permissive enhancer dataset, and then fine-tune the model on ENCODE cell type-specific enhancer datasets by adopting the transfer learning strategy. Experimental results demonstrate that DeepEnhancer has superior efficiency and effectiveness in classification tasks, and the use of max-pooling and batch normalization is beneficial to higher accuracy. To make our approach more understandable, we propose a strategy to visualize the convolutional kernels as sequence logos and compare them against the JASPAR database using TOMTOM. In summary, DeepEnhancer allows researchers to train highly accurate deep models and will be broadly applicable in computational biology.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822593","","Bioinformatics;Computer architecture;DNA;Feature extraction;Genomics;Kernel;Machine learning","biological tissues;biology computing;diseases;genetics;genomics;learning (artificial intelligence);neural nets","DeepEnhancer;ENCODE cell type-specific enhancer datasets;FANTOM5 permissive enhancer dataset;JASPAR database;Roadmap;TOMTOM;background genomic sequences;batch normalization;classification performance;classification tasks;computational biology;computational framework;computational identification;convolutional kernels;convolutional neural networks;deep learning model;disease status;gene transcriptional regulation;high-throughput biological experimental techniques;human cell lines;max-pooling;sequence logos;tissues;traditional sequence-based classifiers;transfer learning strategy","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Analysis of churn prediction: A case study on telecommunication services in Macedonia","A. J. Petkovski; B. L. R. Stojkoska; K. V. Trivodaliev; S. A. Kalajdziski","Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Rugjer Boshkovikj 16, 1000 Skopje, Macedonia","2016 24th Telecommunications Forum (TELFOR)","20170119","2016","","","1","4","Customer churn is one of the main problems in the telecommunications industry. Several studies have shown that attracting new customers is much more expensive than retaining existing ones. Therefore, companies are focusing on developing accurate and reliable predictive models to identify potential customers that will churn in the near future. The aim of this paper is investigating the main reasons for churn in telecommunication sector in Macedonia. The proposed methodology for analysis of churn prediction covers several phases: understanding the business; selection, analysis and data processing; implementing various algorithms for classification; evaluation of the classifiers and choosing the best one for prediction. The obtained results for the data from a telecommunication company in Macedonia, should be of great value for management and marketing departments of other telecommunication companies in the country and wider.","","CD:978-1-5090-4085-8; Electronic:978-1-5090-4086-5; POD:978-1-5090-4087-2","10.1109/TELFOR.2016.7818903","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7818903","KNN;churn prediction;data mining;decision trees;logistic regression;naîve Bayes","Classification algorithms;Companies;Contracts;Logistics;Machine learning algorithms;Prediction algorithms;Telecommunications","pattern classification;telecommunication industry;telecommunication services","Macedonia;Telecommunication Services;churn prediction analysis;customer churn;data processing;predictive model;telecommunication industry","","","","","","","22-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"POSTER: Anomaly-based misbehaviour detection in connected car backends","O. Berlin; A. Held; M. Matousek; F. Kargl","Daimler AG","2016 IEEE Vehicular Networking Conference (VNC)","20170130","2016","","","1","2","As a novel way to protect connected cars, we are developing a Security Information and Event Management System (SIEM) called Security Management of Services in Connected Cars (SeMaCoCa) located in the backend of the connected car. For that we defined a connected car architecture and possible use cases which serve as a basis for the research. Using data from the connected cars and additional information, attacks on individual vehicles or fleets should be recognized. A combination of rule-based-, machine-learning-, deep learning-, real-time-based-, security-algorithms and algorithms for big data are used. Furthermore, we aim for a privacy-friendly solution that does not require the backend operator to have access to cleartext data. The new security system should be able to recognise misbehaviour under the conditions of a permanently growing number and variety of connected cars, upcoming services on the market and related constantly to changing user behavior. The challenge for the security system is, that under these conditions no stable system state exists, that the system can rely on. In this paper, we introduce the architecture of SeMaCoCa, user stories and the idea behind the approach of the system.","","Electronic:978-1-5090-5197-7; POD:978-1-5090-5198-4","10.1109/VNC.2016.7835978","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835978","","Automobiles;Intrusion detection;Machine learning;Machine learning algorithms;Support vector machines","Big Data;automobiles;data privacy;knowledge based systems;learning (artificial intelligence);security of data","Big Data;SIEM;SeMaCoCa;anomaly-based misbehaviour detection;connected car backends;deep learning;machine-learning;privacy-friendly solution;real-time-based security algorithms;rule-based security algorithms;security information and event management system;security management of services in connected cars","","","","","","","8-10 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multimodal architecture for emotion in robots using deep learning","M. Ghayoumi; A. K. Bansal","Artificial Intelligent Lab, Computer Science Department, Kent State University, Kent, Ohio, USA","2016 Future Technologies Conference (FTC)","20170119","2016","","","901","907","These days, some robots have emotional state (expression and recognition) to make Human-Robot Interaction (HRI) and Robot-Robot Interaction (RRI) better. In this article we analyze what it means for a robot to have emotion and distinguishing emotional state for communication from an emotional state as a mechanism for the organization of its behavior with humans and robots by convolutional neural network (CNN). We discuss these relations and explain why it can be more effective by CNN for having better emotion in the robots. Here, we present a multimodal system for Emotions in Robots by CNN.","","Electronic:978-1-5090-4171-8; POD:978-1-5090-4172-5","10.1109/FTC.2016.7821710","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821710","convolutional neural network;deep learning;emotion expression;emotion recognition;multimodal systems;robot","Biological neural networks;Computer architecture;Computer science;Emotion recognition;Machine learning;Robots;Visualization","convolution;emotion recognition;human-robot interaction;learning (artificial intelligence);neurocontrollers","CNN;HRI;RRI;behavior organization;convolutional neural network;deep learning;emotion expression;emotion recognition;human-robot interaction;multimodal architecture;multimodal system;robot emotional state;robot-robot interaction","","","","","","","6-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"Principle component analysis based intrusion detection system using support vector machine","P. Nskh; M. N. Varma; R. R. Naik","Department of ECE, Manipal Institute of Technology, Manipal, India","2016 IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","20170109","2016","","","1344","1350","Whenever an intrusion happens, privacy and security of the system are compromised. In order to detect different types of attacks that happen in a network, Intrusion Detection System (IDS) plays a crucial role in Network security. IDS is designed in order to classify the activities of the system into abnormal and normal. Machine learning based Intrusion Detection is gaining attention in recent years and is able to give better results with greater accuracy and high detection rate on novel attacks. In this paper, performance of different kernels of Support Vector Machine (SVM) are evaluated against Knowledge Discovery in Databases Cup'99(KDD) data set and detection accuracy, detection time are compared. The detection time is reduced by adopting Principal Component Analysis (PCA) which curtails higher dimensional dataset to lower dimensional dataset. The experiments which are conducted in this research shows that Gaussian Radial Basis Function kernel of SVM has higher detection accuracy.","","Electronic:978-1-5090-0774-5; POD:978-1-5090-0775-2","10.1109/RTEICT.2016.7808050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7808050","Detection Accuracy;Detection Time;Intrusion Detection System (IDS);KDDCup'99 dataset;Kernel function;Principal Component Analysis(PCA);Support Vector Machine (SVM)","Algorithm design and analysis;Conferences;Covariance matrices;Intrusion detection;Machine learning algorithms;Principal component analysis;Support vector machines","principal component analysis;security of data;support vector machines","Gaussian radial basis function kernel;IDS;KDDCup'99 dataset;Knowledge Discovery in Databases Cup'99;PCA;intrusion detection system;network security;principle component analysis;support vector machine","","","","","","","20-21 May 2016","","IEEE","IEEE Conference Publications"
"Site-ability: A website usability measurement tool","N. L. Liyanage; K. Vidanage","University of Westminster 309 Regent St, London W1B 2UW, United Kingdom","2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20170126","2016","","","257","265","Usability plays a major role towards user acceptance of website and it is increasingly becoming an important topic for organizations that develop and implement websites to market their products and services. Thus evaluating usability is critical for organizations in order to develop user friendly websites. One major challenge in usability evaluation is that most of the evaluation methods are subjective which depends on the evaluator's personal interpretations and judgment of the website. This is due to the lack of availability of automated tools in the respective field. Further, most of the usability evaluation methods are involved with manual approaches that consume time and money which is not affordable for organizations. Site-ability is an automation tool for website usability evaluation which is capable of mimicking human usability experts and it is based on usability guidelines provided by U.S. Department of Health and Human Services' (HHS) Research-Based Web Design and Usability Guidelines.","","CD:978-1-5090-6076-4; Electronic:978-1-5090-6078-8; POD:978-1-5090-6079-5; Paper:978-1-5090-6077-1","10.1109/ICTER.2016.7829929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829929","Automation;Expert System;Website Usability","Automation;Classification algorithms;Data models;Guidelines;Machine learning algorithms;Training data;Usability","Web sites;human factors;social aspects of automation","HHS Research-Based Web Design and Usability Guidelines;US Department of Health and Human Services;Web site usability measurement tool;automation tool;human usability experts;personal interpretations;personal judgment;site-ability;user acceptance;user friendly websites","","","","","","","1-3 Sept. 2016","","IEEE","IEEE Conference Publications"
"Improve the Quality of ARC Systems Based on the Metamorphic Testing","J. Zhang; X. Jing; W. Zhang; H. Wang; Y. Dong","Sch. of Software, Beijing Inst. of Technol., Beijing, China","2016 International Symposium on System and Software Reliability (ISSSR)","20170116","2016","","","137","141","In order to improve the quality of Activity Recognition Chain (ARC) systems, an effective testing approach is required to evaluate the functionalities of their major components, especially for two kernel components, the segmentation and recognition components. Both of them largely utilize the machine learning algorithms to achieve the detection and recognition of activity correctly. The probabilistic nature of the machine learning algorithms present severe challenge to the testing for the ARC systems. The article adopts a MT (metamorphic testing) methodology to address this topic. We analyze the MR (metamorphic relation) between the results of segmentation and recognition components. Based on this kind of MR, we propose a two-stage MT based approach for the testing of ARC systems, which exploits the association fact between segmentation and recognition, and then performs the MT testing on them respectively in sequence. This approach is able to deal with the specific issues in ARC systems testing, and provides a general method for systems testing with probabilistic nature.","","Electronic:978-1-5090-5563-0; POD:978-1-5090-5564-7","10.1109/ISSSR.2016.029","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7810808","activity recognition chain;metamorphic relation;metamorphic testing;software quality","Accelerometers;Computer bugs;Feature extraction;Machine learning algorithms;Probabilistic logic;Software;Testing","learning (artificial intelligence);program testing;software quality","ARC systems;activity recognition chain systems;machine learning algorithms;metamorphic relation;metamorphic testing;recognition components;segmentation components;two kernel components","","","","","","","29-30 Oct. 2016","","IEEE","IEEE Conference Publications"
"Re-Designing CNTK Deep Learning Framework on Modern GPU Enabled Clusters","D. S. Banerjee; K. Hamidouche; D. K. Panda","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2016 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)","20170126","2016","","","144","151","Deep learning frameworks have recently gained widespread popularity due to their highly accurate prediction capabilities and availability of low cost processors that can perform training over a large dataset quickly. Given the high core count in modern generation high performance computing systems, training deep networks over large data has now become practical. In this work, while targeting the Computational Network Toolkit (CNTK) framework, we propose new mechanisms and designs to boost the performance of the communications between GPU nodes. We perform thorough analysis of the different phases of the toolkit such as I/O, communications, and computation of CNTK to identify the different bottlenecks that can be potentially alleviated using the high performance capabilities provided by many CUDA aware MPI runtimes. Using a CUDA aware MPI library, we propose CUDA Aware CNTK (CA-CNTK) which does low overhead communications. Different datasets ranging from small to large sizes prove the advantage of our re-design, and how it can show similar results on deep learning frameworks having a similar execution pattern. Our designs show an average improvement of 23%, 21% and 15% per epoch for the popular CIFAR10, MNIST and ImageNet datasets, respectively.","","Electronic:978-1-5090-1445-3; POD:978-1-5090-1446-0","10.1109/CloudCom.2016.0036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830677","","Computer architecture;Graphics processing units;Kernel;Machine learning;Performance evaluation;Runtime;Training","application program interfaces;graphics processing units;learning (artificial intelligence);message passing;parallel architectures","CA-CNTK;CIFAR10 dataset;CNTK deep-learning framework redesign;CUDA aware MPI library;CUDA aware MPI runtimes;CUDA-aware CNTK;Computational Network Toolkit framework;GPU enabled clusters;ImageNet dataset;MNIST dataset;deep networks training;execution pattern;high-performance computing systems","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Robust Stereo Data Cost With a Learning Strategy","V. D. Nguyen; H. V. Nguyen; J. W. Jeon","School of Information and Communication Engineering, Sungkyunkwan University, Suwon, South Korea","IEEE Transactions on Intelligent Transportation Systems","20170131","2017","18","2","248","258","The performance of stereo matching algorithms strongly depends on the quality of the stereo data/matching cost. Most state-of-the-art data costs require expert knowledge for the design of a transformation function, such as census for handling gray-level changes monotonically, adaptive normalized cross correlation for handling Lambertian cases, guided filtering for preserving edge information, and local density encoding for handling illumination differences. However, it is difficult to design a complex transformation function to handle unknown factors that often occur in driving conditions such as snow, rain, and sun. Therefore, this paper has investigated the deep learning strategy to develop a novel stereo matching cost model without using much expert knowledge. Experimental results show that the proposed deep learning model obtains better results than the state-of-the-art stereo matching cost as judged by the standard KITTI benchmark, Middlebury, and HCI datasets.","1524-9050;15249050","","10.1109/TITS.2016.2563661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548359","Stereo matching cost;deep learning;unlabeled data;unsupervised training","Algorithm design and analysis;Feature extraction;Image color analysis;Machine learning;Robustness;Snow;Training","edge detection;image matching;learning (artificial intelligence);statistical analysis;stereo image processing","HCI datasets;KITTI benchmark;Lambertian case handling;Middlebury;adaptive normalized cross correlation;deep learning;driving conditions;gray-level change handling;guided filtering;illumination difference handling;local density encoding;preserving edge information;robust stereo data cost;stereo matching algorithms;stereo matching cost;transformation function design","","","","","","20160824","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Multisource Transfer Learning With Convolutional Neural Networks for Lung Pattern Analysis","S. Christodoulidis; M. Anthimopoulos; L. Ebner; A. Christe; S. Mougiakakou","ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, Switzerland","IEEE Journal of Biomedical and Health Informatics","20170201","2017","21","1","76","84","Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns, and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.","2168-2194;21682194","","10.1109/JBHI.2016.2636929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776792","Convolutional neural networks (CNNs);interstitial lung diseases (ILDs);knowledge distillation;model compression;model ensemble;texture classification;transfer learning","Biomedical imaging;Computed tomography;Databases;Knowledge engineering;Lungs;Machine learning;Training","biological tissues;computerised tomography;diseases;image classification;image texture;learning (artificial intelligence);lung;medical image processing;neural nets","CT images;computed tomography;computer-aided diagnosis;convolutional neural networks;fused knowledge compression;interstitial lung disease diagnosis;lung pattern analysis;lung tissue data;medical image analysis;multisource transfer learning;texture classification;texture databases","","","","","","20161207","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Accelerating Deep Learning with Shrinkage and Recall","S. Zheng; A. Vishnu; C. Ding","Pacific Northwest Nat. Lab., Richland, WA, USA","2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)","20170119","2016","","","963","970","Deep Learning is a very powerful machine learning model. Deep Learning trains a large number of parameters for multiple layers and is very slow when data is in large scale and the architecture size is large. Inspired from the shrinking technique used in accelerating computation of Support Vector Machines (SVM) algorithm and screening technique used in LASSO, we propose a shrinking Deep Learning with recall (sDLr) approach to speed up deep learning computation. We experiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network (DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data sets. Results show that the speedup using shrinking Deep Learning with recall (sDLr) can reach more than 2.0 while still giving competitive classification performance.","1521-9097;15219097","Electronic:978-1-5090-4457-3; POD:978-1-5090-5382-7","10.1109/ICPADS.2016.0129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823844","Convolution Neural Network (CNN);Deep Belief Network (DBN);Deep Learning; Deep Neural Network (DNN)","Acceleration;Biological neural networks;Computational modeling;Machine learning;Support vector machines;Training;Training data","belief networks;learning (artificial intelligence);neural nets","CNN;DBN;DNN;classification performance;convolution neural network;deep belief network;deep neural network;sDLr;shrinking deep learning with recall","","1","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Biomedical event extraction based on distributed representation and deep learning","Anran Wang; Jian Wang; Hongfei Lin; Jianhai Zhang; Zhihao Yang; Kan Xu","School of Computer Science and Technology, Dalian University of Technology, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","775","775","The two main problems of biomedical event extraction are trigger identification and argument detection which can both be considered as classification problems. In this paper, we propose a distributed representation method, which combines context, consisted by dependency-based word embedding, and task-based features represented in a distributed way on deep learning models to realize biomedical event extraction. The experimental results on Multi-Level Event Extraction (MLEE) corpus show higher F-scores compared to the state-of-the-art SVM method. This demonstrates that our proposed method is effective for biomedical event extraction.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822620","Biomedical event extraction;Convolutional neural network;Deep learning;Distributed representation","Bioinformatics;Biological system modeling;Feature extraction;Machine learning;Neural networks;Semantics;Support vector machines","learning (artificial intelligence);medical computing;support vector machines","SVM method;biomedical event extraction;deep learning;dependency-based word embedding;distributed representation method;multilevel event extraction;support vector machines;task-based feature","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Unsupervised deep hashing for large-scale visual search","Z. Xia; X. Feng; J. Peng; A. Hadid","School of Electronics and Information, Northwestern Polytechnical University","2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","20170119","2016","","","1","5","Learning based hashing plays a pivotal role in large-scale visual search. However, most existing hashing algorithms tend to learn shallow models that do not seek representative binary codes. In this paper, we propose a novel hashing approach based on unsupervised deep learning to hierarchically transform features into hash codes. Within the heterogeneous deep hashing framework, the autoencoder layers with specific constraints are considered to model the nonlinear mapping between features and binary codes. Then, a Restricted Boltzmann Machine (RBM) layer with constraints is utilized to reduce the dimension in the hamming space. The experiments on the problem of visual search demonstrate the competitiveness of our proposed approach compared to the state of the art.","","Electronic:978-1-4673-8910-5; POD:978-1-4673-8911-2","10.1109/IPTA.2016.7821007","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821007","Autoencoder;Deep learning;Learning based hashing;RBM;Unsupervised learning","Binary codes;Image reconstruction;Linear programming;Machine learning;Optimization;Training;Visualization","Boltzmann machines;feature extraction;file organisation;image retrieval;unsupervised learning","RBM;autoencoder layer;feature transformation;hash code;learning based hashing;nonlinear mapping modelling;restricted Boltzmann machine;unsupervised deep learning;visual image search","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"An Investigation of Deep Learning Frameworks for Speaker Verification Anti-spoofing","C. Zhang; C. Yu; J. H. L. Hansen","","IEEE Journal of Selected Topics in Signal Processing","","2017","PP","99","1","1","In this study, we explore the use of deep learning approaches for spoofing detection in speaker verification. Most spoofing detection systems that have achieved recent success employ hand-craft features with specific spoofing prior knowledge, which may limit the feasibility to unseen spoofing attacks.We aim to investigate the genuine-spoofing discriminative ability from the back-end stage, utilizing recent advancements in deep learning research. In this work, alternative network architectures are exploited to target spoofed speech. Based on this analysis, a novel spoofing detection system which simultaneously employs Convolutional Neural networks (CNNs) and Recurrent Neural Networks (RNNs) is proposed. In this framework, CNN is treated as a convolutional feature extractor applied on the speech input. On top of the CNN processed output, recurrent networks are employed to capture long-term dependencies across the time domain. Novel features including Teager Energy Operator Critical Band Autocorrelation Envelope (TEO-CB-Auto-Env), Perceptual Minimum Variance Distortionless Response (PMVDR) and a more general spectrogram are also investigated as inputs to our proposed deep learning frameworks. Experiments using the ASVspoof 2015 Corpus show that the integrated CNN-RNN framework achieves state-of-the-art single system performance. The addition of score-level fusion further improves system robustness. A detailed analysis shows that our proposed approach can potentially compensate for the issue due to short duration test utterances which is also an issue in the evaluation corpus.","1932-4553;19324553","","10.1109/JSTSP.2016.2647199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7815339","PMVDR;Spoofing detection;TEO-CB-Auto-Env;convolutional neural networks;recurrent neural networks;spectrogram","Context;Feature extraction;Machine learning;Recurrent neural networks;Robustness;Spectrogram;Speech","","","","","","","","20170116","","","IEEE","IEEE Early Access Articles"
"SAFS: A deep feature selection approach for precision medicine","M. Z. Nezhad; Dongxiao Zhu; Xiangrui Li; Kai Yang; P. Levy","Department of Industrial and Systems Engineering, Wayne State University, United States of America","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","501","506","In this paper, we propose a new deep feature selection method based on deep architecture. Our method uses stacked auto-encoders for feature representation in higher-level abstraction. We developed and applied a novel feature learning approach to a specific precision medicine problem, which focuses on assessing and prioritizing risk factors for hypertension (HTN) in a vulnerable demographic subgroup (African-American). Our approach is to use deep learning to identify significant risk factors affecting left ventricular mass indexed to body surface area (LVMI) as an indicator of heart damage risk. The results show that our feature learning and representation approach leads to better results in comparison with others.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822569","Deep Learning;Feature Learning and Representation;Hypertension (HTN);Left Ventricular Mass (LVM);Precision Medicine;Stacked Auto-Encoders","Bioinformatics;Cancer;Decoding;Encoding;Machine learning;Neural networks;Training","cardiology;feature selection;learning (artificial intelligence);medical computing","African-American group;body surface area;deep architecture;deep feature selection approach;demographic subgroup;feature learning approach;heart damage risk;higher-level abstraction;hypertension;left ventricular mass index;precision medicine;stacked autoencoders","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Using Supercomputer to Speed up Neural Network Training","Y. Yu; J. Jiang; X. Chi","Dept. of High Performance Comput. Technol. & Applic. Dev., Univ. of Chinese Acad. of Sci., Beijing, China","2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)","20170119","2016","","","942","947","Recent works in deep learning have shown that large models can dramatically improve performance. In this paper, we accelerated the deep network training using many GPUs. We have developed a framework based on Caffe called Caffe-HPC that can utilize computing clusters with multiple GPUs to train large models. Caffe[6] provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. And Caffe-HPC retains all the features of the original Caffe, the model trained on original Caffe can be continue to trained on Caffe-HPC. It provides a convenient solution for people who are using Caffe and want to speed up the training. Using an Asynchronous Stochastic Gradient Descent optimizer, We made a good acceleration on training a CNN model on ILSVRC[5] 2012 dataset. And we have compared the convergence of different SGD algorithms. We believe our work will makes it possible to train larger networks on larger training sets in a reasonable amount of time.","1521-9097;15219097","Electronic:978-1-5090-4457-3; POD:978-1-5090-5382-7","10.1109/ICPADS.2016.0126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823841","asynchronous stochastic gradient descent;deep learning;neural network;parallel computation;parameter server;supercomputing","Acceleration;Computational modeling;Graphics processing units;Machine learning;Neural networks;Servers;Training","gradient methods;graphics processing units;mainframes;neural nets;parallel machines;stochastic processes","Caffe-HPC;GPU;asynchronous stochastic gradient descent optimizer;computing clusters;deep learning;multimedia scientists;speed up neural network training;supercomputer","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Cascading Training for Relaxation CNN on Handwritten Character Recognition","L. Chen; S. Wang; W. Fan; J. Sun; S. Naoi","Fujitsu R&D Center, Beijing, China","2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)","20170116","2016","","","162","167","With the development of deep learning, many difficult recognition problems can be solved by deep learning models. For handwritten character recognition, the CNN is used the most. In order to improve the performance of CNN, many new models have been proposed and in which the relaxation CNN [35] is widely used. The relaxation CNN has more complicated structure than CNN while the recognition time is the same with which. However, the training of relaxation CNN needs much more time than CNN. In this paper, we propose the cascading training for relaxation CNN. Our method can train a relaxation CNN of better performance while using almost the same training time with normal CNN. The experimental results proved that the relaxation CNN trained by cascading training is able to achieve the state-of-the-art performance on handwritten Chinese character recognition.","2167-6445;21676445","Electronic:978-1-5090-0981-7; POD:978-1-5090-0982-4","10.1109/ICFHR.2016.0041","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814057","CNN;cascading training;character recognition","Character recognition;Distortion;Kernel;Machine learning;Neurons;Stochastic processes;Training","feedforward neural nets;handwritten character recognition;learning (artificial intelligence);natural language processing","deep learning models;handwritten Chinese character recognition;recognition time;relaxation CNN;relaxation CNN training;training time","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"Research advances in fault diagnosis and prognostic based on deep learning","G. Zhao; G. Zhang; Q. Ge; X. Liu","Department of Automatic Test and Control, Harbin Institute of Technology, Harbin, China","2016 Prognostics and System Health Management Conference (PHM-Chengdu)","20170119","2016","","","1","6","Aiming to condition based maintenance for complex equipment, numerous intelligent fault diagnosis and prognostic methods based on machine learning have been researched. Compared with the traditional shallow models, which have problems of lacking expression capacity and existing the curse of dimensionality, using deep learning theory can effectively mine characteristics and accurately recognize the health condition. In consequence, fault diagnosis and prognostic based on deep learning have turned into an innovative and promising research field. This paper gives a review of fault diagnosis and prognostic based on deep learning. First of all, a brief introduction to deep learning architecture and the framework of fault diagnosis based on deep learning is described. Second, tracking describes the latest progress of fault diagnosis and prognostic based on deep learning in chronological order. In this section, the deep learning methods used in fault diagnosis and prognostic are discussed, including Deep Neural Network (DNN), Deep Belief Network (DBN) and Convolutional Neural Network (CNN). Then the engineering application fields are summarized, such as mechanical equipment diagnosis, electrical equipment diagnosis, etc. Finally, this paper indicates the potential future research issues in this field.","","Electronic:978-1-5090-2778-1; POD:978-1-5090-2779-8; USB:978-1-5090-2777-4","10.1109/PHM.2016.7819786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819786","deep belief network;deep learning;fault diagnosis;fault prognostic","Circuit faults;Classification algorithms;Fault diagnosis;Feature extraction;Machine learning;Neural networks;Training","belief networks;condition monitoring;fault diagnosis;learning (artificial intelligence);maintenance engineering;mechanical engineering computing;neural nets;production equipment","CNN;DBN;DNN;complex equipment;condition based maintenance;convolutional neural network;deep belief network;deep learning architecture;deep neural network;fault prognostic;health condition;intelligent fault diagnosis;machine learning","","","","","","","19-21 Oct. 2016","","IEEE","IEEE Conference Publications"
"Missing data imputation using Evolutionary k- Nearest neighbor algorithm for gene expression data","H. de Silva; A. S. Perera","Department of Computer Science and Engineering, University of Moratuwa, Sri Lanka","2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20170126","2016","","","141","146","Gene expression data are recognized as a common data source which contains missing expression values. In this paper, we present a genetic algorithm optimized k- Nearest neighbor algorithm (Evolutionary kNNImputation) for missing data imputation. Despite the common imputation methods this paper addresses the effectiveness of using supervised learning algorithms for missing data imputation. We have compared the k- Nearest Neighbor Imputation algorithm with the proposed Evolutionary k- Nearest Neighbor Imputation algorithm. The two algorithms were tested using gene expression datasets. Certain percentages of values are randomly deleted in the datasets and recovered the missing values using the two algorithms. Results show that Evolutionary kNNImputation outperforms kNNImputation.","","CD:978-1-5090-6076-4; Electronic:978-1-5090-6078-8; POD:978-1-5090-6079-5; Paper:978-1-5090-6077-1","10.1109/ICTER.2016.7829911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829911","EvlkNNImputation;Genetic algorithm optimization;Missing data imputation;kNNImputation","Algorithm design and analysis;Gene expression;Genetic algorithms;Machine learning algorithms;Optimization;Prediction algorithms;Training","biology computing;data handling;genetic algorithms;genetics;learning (artificial intelligence)","evolutionary k-nearest neighbor algorithm;evolutionary kNN imputation;gene expression data;genetic algorithm;missing data imputation;supervised learning","","","","","","","1-3 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Data Augmentation Methodology to Improve Age Estimation Using Convolutional Neural Networks","Í. d. P. Oliveira; J. L. P. Medeiros; V. F. d. Sousa","Fed. Univ. of Campina Grande, Campina Grande, Brazil","2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","20170116","2016","","","88","95","Recent advances in deep learning methodologies are enabling the construction of more accurate classifiers. However, existing labeled face datasets are limited in size, which prevents CNN models from reaching their full generalization capabilities. A variety of techniques to generate new training samples based on data augmentation have been proposed, but the great majority is limited to very simple transformations. The approach proposed in this paper takes into account intrinsic information about human faces in order to generate an augmented dataset that is used to train a CNN, by creating photo-realistic smooth face variations based on Active Appearance Models optimized for human faces. An experimental evaluation taking CNN models trained with original and augmented versions of the MORPH face dataset allowed an increase of 10% in the F-Score and yielded Receiver Operating Characteristic curves that outperformed state-of-the-art work in the literature.","","Electronic:978-1-5090-3568-7; POD:978-1-5090-3569-4","10.1109/SIBGRAPI.2016.021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813020","Age Estimation;Data Augmentation;Deep Learning;Face Detection;Fiducial Points","Active appearance model;Estimation;Face;Machine learning;Neural networks;Shape;Training","convolution;data handling;estimation theory;face recognition;image classification;learning (artificial intelligence);neural nets","MORPH face dataset;active appearance models;age estimation;classifiers;convolutional neural networks;data augmentation methodology;deep learning;photo-realistic smooth face variations","","","","","","","4-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"A New Deep Learning-based Food Recognition System for Dietary Assessment on An Edge Computing Service Infrastructure","C. Liu; Y. Cao; Y. Luo; G. Chen; V. Vokkarane; Y. Ma; S. Chen; P. Hou","","IEEE Transactions on Services Computing","","2017","PP","99","1","1","Literature has indicated that accurate dietary assessment is very important for assessing the effectiveness of weight loss interventions. However, most of the existing dietary assessment methods rely on memory. With the help of pervasive mobile devices and rich cloud services, it is now possible to develop new computer-aided food recognition system for accurate dietary assessment. However, enabling this future Internet of Things-based dietary assessment imposes several fundamental challenges on algorithm development and system design. In this paper, we set to address these issues from the following two aspects: (1) to develop novel deep learning-based visual food recognition algorithms to achieve the best-in-class recognition accuracy; (2) to design a food recognition system employing edge computing-based service computing paradigm to overcome some inherent problems of traditional mobile cloud computing paradigm, such as unacceptable system latency and low battery life of mobile devices. We have conducted extensive experiments with real-world data. Our results have shown that the proposed system achieved three objectives: (1) outperforming existing work in terms of food recognition accuracy; (2) reducing response time that is equivalent to the minimum of the existing approaches; and (3) lowering energy consumption which is close to the minimum of the state-of-the-art.","1939-1374;19391374","","10.1109/TSC.2017.2662008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7837725","Deep Learning;Edge Computing;Food Recognition;Mobile Applications;Object Recognition","Algorithm design and analysis;Edge computing;Image recognition;Machine learning;Mobile communication;Mobile handsets;Time factors","","","","","","","","20170131","","","IEEE","IEEE Early Access Articles"
"Active Deep Learning for Classification of Hyperspectral Images","P. Liu; H. Zhang; K. B. Eom","Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20170124","2017","10","2","712","724","Active deep learning classification of hyperspectral images is considered in this paper. Deep learning has achieved success in many applications, but good-quality labeled samples are needed to construct a deep learning network. It is expensive getting good labeled samples in hyperspectral images for remote sensing applications. An active learning algorithm based on a weighted incremental dictionary learning is proposed for such applications. The proposed algorithm selects training samples that maximize two selection criteria, namely representative and uncertainty. This algorithm trains a deep network efficiently by actively selecting training samples at each iteration. The proposed algorithm is applied for the classification of hyperspectral images, and compared with other classification algorithms employing active learning. It is shown that the proposed algorithm is efficient and effective in classifying hyperspectral images.","1939-1404;19391404","","10.1109/JSTARS.2016.2598859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568999","Active learning;deep learning;remote sensing classification;sparse representation","Hyperspectral imaging;Machine learning;Training;Tuning;Uncertainty","hyperspectral imaging;image classification;learning (artificial intelligence)","active deep learning;classification algorithms;deep learning network;hyperspectral image classification;remote sensing applications;representative criteria;selection criteria;uncertainty criteria;weighted incremental dictionary learning","","","","","","20160915","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"A Robust Dissimilarity-Based Neural Network for Temporal Pattern Recognition","B. K. Iwana; V. Frinken; S. Uchida","Dept. of Adv. Inf. Technol., Kyushu Univ., Fukuoka, Japan","2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)","20170116","2016","","","265","270","Temporal pattern recognition is challenging because temporal patterns require extra considerations over other data types, such as order, structure, and temporal distortions. Recently, there has been a trend in using large data and deep learning, however, many of the tools cannot be directly used with temporal patterns. Convolutional Neural Networks (CNN) for instance are traditionally used for visual and image pattern recognition. This paper proposes a method using a neural network to classify isolated temporal patterns directly. The proposed method uses dynamic time warping (DTW) as a kernel-like function to learn dissimilarity-based feature maps as the basis of the network. We show that using the proposed DTW-NN, efficient classification of on-line handwritten digits is possible with accuracies comparable to state-of-the-art methods.","2167-6445;21676445","Electronic:978-1-5090-0981-7; POD:978-1-5090-0982-4","10.1109/ICFHR.2016.0058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814074","Deep Learning;Dynamic Time Warping;Neural Networks;Temporal Pattern Recognition;Time Series","Biological neural networks;Feature extraction;Handwriting recognition;Machine learning;Prototypes","image recognition;learning (artificial intelligence);neural nets;pattern classification","CNN;DTW-NN;convolutional neural networks;deep learning;dissimilarity-based feature maps;dynamic time warping;image pattern recognition;isolated temporal pattern classification;online handwritten digits;robust dissimilarity-based neural network;temporal distortions;temporal pattern recgnition","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep thinking and quick learning for viable AI","S. B. Ho","Department of Social and Cognitive Computing, Institute of High Performance Computing, A&#x2217;STAR, Singapore","2016 Future Technologies Conference (FTC)","20170119","2016","","","156","164","Despite the vast progress made in artificial intelligence (AI) over the years and the recent renewed interest in it because of some major breakthroughs in methodologies seemingly signifying its general viability, there are still important gaps that have to be filled to enable the construction of truly general and adaptive intelligent machines. This paper points out that a useful general learning machine must not only be “general” in the sense of being able to learn to solve many different kinds of problem, it must also be able to learn to solve them rapidly, and continue to learn rapidly in an ever-changing, non-stationary environment. The paper reviews the current limitations in certain popular learning methods, such as reinforcement learning, and proposes new methodologies that address the gaps. A new paradigm of deep thinking and quick learning is proposed for a future direction of research to produce truly general and adaptive intelligent machines.","","Electronic:978-1-5090-4171-8; POD:978-1-5090-4172-5","10.1109/FTC.2016.7821605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821605","AI methodologies;causal learning;rapid learning;reinforcement learning;thinking and reasoning","Aircraft;Games;Learning (artificial intelligence);Learning systems;Machine learning;Training","learning (artificial intelligence);problem solving","adaptive intelligent machine;artificial intelligence;deep thinking;general learning machine;problem solving;quick learning;reinforcement learning","","","","","","","6-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"Computer-assisted pronunciation training: From pronunciation scoring towards spoken language learning","N. F. Chen; H. Li","Institute for Infocomm Research, A&#x2217;STAR, Singapore","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20170119","2016","","","1","7","This paper reviews the research approaches used in computer-assisted pronunciation training (CAPT), addresses the existing challenges, and discusses emerging trends and opportunities. To complement existing work, our analysis places more emphasis on pronunciation teaching and learning (as opposed to pronunciation assessment), prosodic error detection (as opposed to phonetic error detection), and research work from the past five years given the recent rapid development in spoken language technology.","","Electronic:978-9-8814-7682-1; POD:978-1-5090-2401-8","10.1109/APSIPA.2016.7820782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820782","computer assisted language learning (CALL);pronunciation tutoring;second language learning;speech and language technologies in education","Acoustics;Feature extraction;Machine learning;Speech;Stress;Training","computer based training;linguistics;speech recognition;teaching","CAPT;computer-assisted pronunciation training;phonetic error detection;pronunciation assessment;pronunciation scoring;pronunciation teaching;prosodic error detection;spoken language learning;spoken language technology","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multicolumn RBF Network","A. O. Hoori; Y. Motai","Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA 23284 USA, and also with the Department of Computer Engineering, University of Baghdad, Baghdad, Iraq.","IEEE Transactions on Neural Networks and Learning Systems","","2017","PP","99","1","13","This paper proposes the multicolumn RBF network (MCRN) as a method to improve the accuracy and speed of a traditional radial basis function network (RBFN). The RBFN, as a fully connected artificial neural network (ANN), suffers from costly kernel inner-product calculations due to the use of many instances as the centers of hidden units. This issue is not critical for small datasets, as adding more hidden units will not burden the computation time. However, for larger datasets, the RBFN requires many hidden units with several kernel computations to generalize the problem. The MCRN mechanism is constructed based on dividing a dataset into smaller subsets using the k-d tree algorithm. N resultant subsets are considered as separate training datasets to train $N$ individual RBFNs. Those small RBFNs are stacked in parallel and bulged into the MCRN structure during testing. The MCRN is considered as a well-developed and easy-to-use parallel structure, because each individual ANN has been trained on its own subsets and is completely separate from the other ANNs. This parallelized structure reduces the testing time compared with that of a single but larger RBFN, which cannot be easily parallelized due to its fully connected structure. Small informative subsets provide the MCRN with a regional experience to specify the problem instead of generalizing it. The MCRN has been tested on many benchmark datasets and has shown better accuracy and great improvements in training and testing times compared with a single RBFN. The MCRN also shows good results compared with those of some machine learning techniques, such as the support vector machine and k-nearest neighbors.","2162-237X;2162237X","","10.1109/TNNLS.2017.2650865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828142","Deep neural network;k-d tree;k-nearest neighbors (KNNs);kernel;radial basis function networks (RBFNs).","Convergence;Kernel;Machine learning;Radial basis function networks;Testing;Training","","","","","","","","20170120","","","IEEE","IEEE Early Access Articles"
"Integrating Mobile and Cloud for PPG Signal Selection to Monitor Heart Rate during Intensive Physical Exercise","V. Jindal","Univ. of Texas at Dallas, Richardson, TX, USA","2016 IEEE/ACM International Conference on Mobile Software Engineering and Systems (MOBILESoft)","20170126","2016","","","36","37","Heart rate monitoring has become increasingly popular in the industry through mobile phones and wearable devices. However current determination of heart rate through mobile applications suffer from high corruption of signals during intensive physical exercise. In this paper, we present a novel technique for accurately determining heart rate during intensive motion by classifying PPG signals obtained from smartphones or wearable devices combined with motion data obtained from accelerometer sensors. Our approach utilizes the Internet of Things (IoT) cloud connectivity of smartphones for PPG signals selection using deep learning. The technique is validated using the TROIKA dataset and is accurately able to predict heart rate with a 10-fold cross validation error margin of 4.88%.","","Electronic:978-1-4503-4178-3; POD:978-1-5090-2233-5","10.1109/MobileSoft.2016.027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832965","Internet of Things (IoT);PPG signals;deep belief network;deep learning;heart rate monitoring","Accelerometers;Biomedical monitoring;Heart rate;Machine learning;Mobile communication;Mobile handsets;Monitoring","Internet of Things;cardiology;cloud computing;learning (artificial intelligence);medical signal processing;mobile computing;patient monitoring;photoplethysmography;signal classification;smart phones","Internet of Things;IoT cloud connectivity;PPG signal classification;PPG signal selection;deep learning;heart rate monitoring;intensive physical exercise;mobile phone;photoplethysmography;smart phone","","","","","","","16-17 May 2016","","IEEE","IEEE Conference Publications"
"Deep learning based modeling for the lateral movement of a strip in hot finishing mill","W. Kwon; J. Baek; S. Han; S. Won","Graduate Institute of Ferrous Technology, POSTECH, Gyeongbuk, Korea, 37673","2016 16th International Conference on Control, Automation and Systems (ICCAS)","20170126","2016","","","1189","1191","In this paper, the problem of system identification for the lateral motion of a strip in hot finishing mill is investigated. The movement is affected by various asymmetric factors with respect to rolling force. Not only that, the tension between rolling mills determines the direction of strip's moving. Consequently, the movement of a strip is complex dynamics with rolling condition, tension and other phenomena. To identify a neural network type system model in the existence of both uncertain parameters and nonlinear signals, deep learning based modelling is employed.","","Electronic:978-89-93215-11-3; POD:978-1-4673-9058-3; USB:978-89-93215-12-0","10.1109/ICCAS.2016.7832464","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832464","Deep learning;Hot strip finishing mill;Steering control;System identification","Algorithm design and analysis;Machine learning;Mathematical model;Neurons;Recurrent neural networks;Strips","finishing;hot rolling;learning (artificial intelligence);motion control;neurocontrollers;rolling mills;strips;tensile strength","deep learning based modeling;hot finishing mill;neural network;nonlinear signals;rolling condition;rolling force;strip lateral motion;strip lateral movement;system identification;tension;uncertain parameters","","","","","","","16-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Deep Learning Based Approach for Bearing Fault Diagnosis","M. He; D. He","","IEEE Transactions on Industry Applications","","2017","PP","99","1","1","Bearing is one of the most critical components in most electrical and power drives. Effective bearing fault diagnosis is important for keeping the electrical and power drives safe and operate normally. In the age of Internet of Things and Industrial 4.0, massive real-time data are collected from bearing health monitoring systems. Mechanical big data has the characteristics of large volume, diversity and high-velocity. There are two major problems in using the existing methods for bearing fault diagnosis with big data: (1) the features are manually extracted relying on much prior knowledge about signal processing techniques and diagnostic expertise; (2) the used models have shallow architectures, limiting their capability in fault diagnosis. Effectively mining features from big data and accurately identifying the bearing health conditions with new advanced methods become new issues. This paper presents a deep learning based approach for bearing fault diagnosis. The presented approach pre-processes sensor signals using short time Fourier transform (STFT). Based on a simple spectrum matrix obtained by STFT, an optimized deep learning structure, large memory storage retrieval (LAMSTAR) neural network is built to diagnose the bearing faults. Acoustic emission signals acquired from a bearing test rig are used to validate the presented method. The validation results show the accurate classification performance on various bearing faults under different working conditions. The performance of the presented method is also compared with other effective bearing fault diagnosis methods reported in the literature. The comparison results have shown that the presented method gives much better diagnostic performance even at relatively low rotating speeds.","0093-9994;00939994","","10.1109/TIA.2017.2661250","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836314","Bearing fault diagnosis;acoustic emission (AE) sensor;deep learning, large memory storage retrieval (LAMSTAR) neural network","Big data;Fault diagnosis;Feature extraction;Machine learning;Machinery;Neurons;Signal processing","","","","","","","","20170130","","","IEEE","IEEE Early Access Articles"
"SpottingNet: Learning the Similarity of Word Images with Convolutional Neural Network for Word Spotting in Handwritten Historical Documents","Z. Zhong; W. Pan; L. Jin; H. Mouchère; C. Viard-Gaudin","Sch. of Electron. & Inf. Eng., South China Univ. of Technol., Guangzhou, China","2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)","20170116","2016","","","295","300","Word spotting is a content-based retrieval process that obtains a ranked list of word image candidates similar to the query word in digital document images. In this paper, we present a convolutional neural network (CNN) based end-to-end approach for Query-by-Example (QBE) word spotting in handwritten historical documents. The presented models enable conjointly learning the representative word image descriptors and evaluating the similarity measure between word descriptors directly from the word image, which are the two crucial factors in this task. We propose a similarity score fusion method integrated with hybrid deep-learning classifica-tion and regression models to enhance word spotting perfor-mance. In addition, we present a sample generation method using location jitter to balance similar and dissimilar image pairs and enlarge the dataset. Experiments are conducted on the George Washington (GW) dataset without involving any recognition methods or prior word category information. Our experiments show that the proposed model yields a new state-of-the-art mean average precision (mAP) of 80.03%, significantly outperforming previous results.","2167-6445;21676445","Electronic:978-1-5090-0981-7; POD:978-1-5090-0982-4","10.1109/ICFHR.2016.0063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814079","convolutional neural network;similarity learning;similarity score fusion;word spotting","Jitter;Machine learning;Neural networks;Optimization;Standards;Testing;Training","content-based retrieval;document image processing;feedforward neural nets;handwritten character recognition;history;image retrieval;learning (artificial intelligence);regression analysis;word processing","GW dataset;George Washington dataset;SpottingNet;content-based retrieval;convolutional neural network;convolutional neural network based end-to-end approach;digital document images;handwritten historical documents;hybrid deep-learning classification model;hybrid deep-learning regression model;location jitter;mAP;mean average precision;query word;query-by-example word spotting;similarity score fusion method;word image candidates;word image descriptors;word image similarity","","","","","","","23-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices","D. Ravì; C. Wong; B. Lo; G. Z. Yang","Hamlyn Centre, Imperial College London, London, U.K.","IEEE Journal of Biomedical and Health Informatics","20170201","2017","21","1","56","64","The increasing popularity of wearable devices in recent years means that a diverse range of physiological and functional data can now be captured continuously for applications in sports, wellbeing, and healthcare. This wealth of information requires efficient methods of classification and analysis where deep learning is a promising technique for large-scale data analytics. While deep learning has been successful in implementations that utilize high-performance computing platforms, its use on low-power wearable devices is limited by resource constraints. In this paper, we propose a deep learning methodology, which combines features learned from inertial sensor data together with complementary information from a set of shallow features to enable accurate and real-time activity classification. The design of this combined method aims to overcome some of the limitations present in a typical deep learning framework where on-node computation is required. To optimize the proposed method for real-time on-node computation, spectral domain preprocessing is used before the data are passed onto the deep learning framework. The classification accuracy of our proposed deep learning approach is evaluated against state-of-the-art methods using both laboratory and real world activity datasets. Our results show the validity of the approach on different human activity datasets, outperforming other methods, including the two methods used within our combined pipeline. We also demonstrate that the computation times for the proposed method are consistent with the constraints of real-time on-node processing on smartphones and a wearable sensor platform.","2168-2194;21682194","","10.1109/JBHI.2016.2633287","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797232","ActiveMiles;Human Activity Recognition (HAR);Internet-of-Things (IoT);deep learning;low-power devices;wearable","Feature extraction;Machine learning;Performance evaluation;Pipelines;Real-time systems;Spectrogram;Time-frequency analysis","Internet of Things;data analysis;health care;learning (artificial intelligence);wearable computers","HAR;Human Activity Recognition;Internet-of-Things;deep learning approach;inertial sensor;on-node sensor data analytics;smartphones;spectral domain preprocessing;wearable devices","","","","","","20161223","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"New history-based delay predictors for service systems","M. Thiongane; W. Chan; P. L'Ecuyer","Department of Computer Science and Operations Research, Universit&#x00E9; de Montr&#x00E9;al, 2920, chemin de la Tour, Qu&#x00E9;bec, H3C 3J7, CANADA","2016 Winter Simulation Conference (WSC)","20170119","2016","","","425","436","We are interested in predicting the wait time of customers upon their arrival in some service system such as a call center or emergency service. We propose two new predictors that are very simple to implement and can be used in multiskill settings. They are based on the wait times of previous customers of the same class. The first one estimates the delay of a new customer by extrapolating the wait history (so far) of customers currently in queue, plus the last one that started service, and taking a weighted average. The second one takes a weighted average of the delays of the past customers of the same class that have found the same queue length when they arrived. In our simulation experiments, these new predictors are very competitive with the optimal ones for a simple queue, and for multiskill centers they perform better than other predictors of comparable simplicity.","","CD:978-1-5090-4484-9; Electronic:978-1-5090-4486-3; POD:978-1-5090-4487-0; USB:978-1-5090-4485-6","10.1109/WSC.2016.7822109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822109","","Computational modeling;DH-HEMTs;Delay estimation;Machine learning algorithms;Predictive models;Servers","queueing theory","customer wait time;history-based delay predictors;multiskill centers;multiskill settings;new-customer delay;queue length;wait history","","","","","","","11-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"ML-CNN: A novel deep learning based disease named entity recognition architecture","Zhehuan Zhao; Zhihao Yang; Ling Luo; Yin Zhang; Lei Wang; Hongfei Lin; Jian Wang","College of Computer Science and Technology, Dalian University of Technology, China, 116023","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","794","794","In this paper, we present a deep learning based disease named entity recognition architecture. First, the word-level embedding, character-level embedding and lexicon feature embedding are concatenated as input. Then multiple convolutional layers are stacked over the input to extract useful features automatically. Finally, multiple label strategy, which is firstly introduced, is applied to the output layer to capture the correlation information between neighboring labels. Experimental results on both NCBI and CDR corpora show that ML-CNN can achieve the state-of-the-art performance.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822625","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822625","convolutional neural network;deep learning;disease;multiple label strategy;named entity recognition","Computational linguistics;Computer architecture;Context;Correlation;Diseases;Feature extraction;Machine learning","diseases;feature extraction;learning (artificial intelligence);medical computing;neural nets","CDR corpora;ML-CNN;NCBI corpora;character-level embedding;deep learning method;disease named entity recognition architecture;feature extraction;lexicon feature embedding;multiple label convolutional neural network;word-level embedding","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"The graphics of the solutions by learning a RBM: Discussion on a special case","Q. Zhang; Z. Yang; C. Huang; Z. Yang; L. Yang","College of Mathematics and Statistics, Shenzhen University, China","2016 IEEE 14th International Conference on Industrial Informatics (INDIN)","20170119","2016","","","1130","1133","The study of Restricted Boltzmann Machine(RBM) attracts considerable attentions in recent years. RBM training algorithm is an unsupervised learning method with many applications, moreover, it is the basic module in deep learning. Maximizing the log-likelihood by gradient ascent method, RBM training algorithm can approximate the probability distribution underlying the observing data. For a simple RBM system, we give the closed-form representation for the solutions of the training algorithm, which forms a manifold. Based on the result, it is understood that the solution of the maximization of the log-likelihood function calculated by the gradient ascent method give only one point on the manifold. To illustrate the phenomenon more clearly, a family of new parameters are introduced to express the solution manifold.","","Electronic:978-1-5090-2870-2; POD:978-1-5090-2871-9","10.1109/INDIN.2016.7819335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819335","","Clustering algorithms;Electronic mail;Machine learning;Manifolds;Neurons;Probability distribution;Training","Boltzmann machines;gradient methods;learning (artificial intelligence);log normal distribution","RBM learning;RBM training algorithm;closed-form representation;gradient ascent method;log-likelihood maximization;probability distribution approximation;restricted Boltzmann machine;unsupervised learning","","","","","","","19-21 July 2016","","IEEE","IEEE Conference Publications"
"Deep Learning and Insomnia: Assisting Clinicians with their Diagnosis","M. SHAHIN; B. Ahmed; S. Tmar-Ben Hamida; F. Mulaffer; M. Glos; T. Penzel","Electrical and Computer Engineering Program, Texas A&M University at Qatar, Doha, Qatar.(email:mostafa.shahin@qatar.tamu.edu)","IEEE Journal of Biomedical and Health Informatics","","2017","PP","99","1","1","Effective sleep analysis is hampered by the lack of automated tools catering for disordered sleep patterns and cumbersome monitoring hardware. In this paper, we apply deep learning on a set of 57 EEG features extracted from a maximum of two EEG channels to accurately differentiate between patients with insomnia or controls with no sleep complaints. We investigated two different approaches to achieve this. The first approach used EEG data from the whole sleep recording irrespective of the sleep stage (stage-independent classification), while the second used only EEG data from insomnia-impacted specific sleep stages (stage-dependent classification). We trained and tested our system using both healthy and disordered sleep collected from 41 controls and 42 primary insomnia patients. When compared with manual assessments, a NREM+REM based classifier had an overall discrimination accuracy of 92% and 86% between two groups using both two and one EEG channels respectively. These results demonstrate that deep learning can be used to assist in the diagnosis of sleep disorders such as insomnia.","2168-2194;21682194","","10.1109/JBHI.2017.2650199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811237","EEG;automatic sleep stage scoring;deep learning;insomnia;sleep analysis","Electroencephalography;Electromyography;Electrooculography;Feature extraction;Machine learning;Monitoring;Sleep","","","","","","","","20170109","","","IEEE","IEEE Early Access Articles"
"A Basic Study on Spoiler Detection from Review Comments Using Story Documents","K. Maeda; Y. Hijikata; S. Nakamura","Grad. Sch. of Eng. Sci., Osaka Univ., Toyonaka, Japan","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","572","577","In many shopping sites such as Amazon.com it is possible to view and write reviews of items (products and content). Reviews of items including stories, such as novels, movies, and comics, include reviewers' opinions. Often, these reviews also include descriptions of the story. In some cases, these descriptions may spoil later reader's or viewer's enjoyment and excitement. Hereinafter, we call these descriptions spoilers. Spoilers may be related to the position in the story line. In this study we use story documents. Story documents are documents that record all of the details of the given story. Using the story documents, we investigate the location to which the content of the spoilers correspond in the story documents. Based on the result of the investigation, we consider how to detect spoilers in reviewers' comments.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817115","opinion mining;spoiler detection;story document","Electronic mail;Internet;Machine learning algorithms;Motion pictures;Reliability;Social network services;Text mining","Internet;document handling;retail data processing","Amazon.com;item reviews;review comments;shopping sites;spoiler detection;story documents","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"A kernel-independent FMM in general dimensions","W. B. March; B. Xiao; S. Tharakan; C. D. Yu; G. Biros","Inst. for Comput. Eng. & Sci., Univ. of Texas, Austin, TX, USA","SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","20170126","2015","","","1","12","We introduce a general-dimensional, kernel-independent, algebraic fast multipole method and apply it to kernel regression. The motivation for this work is the approximation of kernel matrices, which appear in mathematical physics, approximation theory, non-parametric statistics, and machine learning. Existing fast multipole methods are asymptotically optimal, but the underlying constants scale quite badly with the ambient space dimension. We introduce a method that mitigates this shortcoming; it only requires kernel evaluations and scales well with the problem size, the number of processors, and the ambient dimension---as long as the intrinsic dimension of the dataset is small. We test the performance of our method on several synthetic datasets. As a highlight, our largest run was on an image dataset with 10 million points in 246 dimensions.","","Electronic:978-1-4503-3723-6; POD:978-1-5090-0273-3","10.1145/2807591.2807647","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832798","","Acceleration;Approximation algorithms;Complexity theory;Kernel;Machine learning algorithms;Skeleton;Transforms","data mining;learning (artificial intelligence);matrix algebra;parallel algorithms;regression analysis","algebraic fast multipole method;approximation theory;data mining;general-dimensional method;kernel evaluations;kernel matrices approximation;kernel regression;kernel-independent FMM;machine learning;mathematical physics;nonparametric statistics;parallel algorithm;synthetic datasets","","1","","","","","15-20 Nov. 2015","","IEEE","IEEE Conference Publications"
"Towards recognition of protein function based on its structure using deep convolutional networks","A. Tavanaei; A. S. Maida; A. Kaniymattam; R. Loganantharaj","The Center for Advanced Computer Studies, Bio-inspired AI Lab, University of Louisiana at Lafayette, 70504, USA","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","145","149","This paper proposes a novel method for protein function recognition using deep learning. Recently, deep convolutional neural networks (DCNNs) demonstrated high performances in many areas of pattern recognition. Protein function is often associated with its tertiary structure denoting the active domain of a protein. This investigation develops a novel DCNN for protein functionality recognition based on its tertiary structure. Two rounds of experiments are performed. The initial experiment on tertiary protein structure alignment shows promising performances (94% accuracy rate) such that it shows the model robustness against rotations, local translations, and scales of the 3D structure. With these results, the main experiments contain five different datasets obtained by similarity measures between pairs of gene ontology terms. The experimental results for protein function recognition on selected datasets show 87.6% and 80.7% maximum and average accuracy rates respectively. The initial success of the DCNN in tertiary protein structure recognition supports further investigations with respect to tertiary protein retrieval and pattern mining on large scale problems.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822509","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822509","","Feature extraction;Machine learning;Protein engineering;Proteins;Solid modeling;Three-dimensional displays;Visualization","bioinformatics;biological techniques;genetics;learning (artificial intelligence);macromolecules;molecular biophysics;molecular configurations;neural nets;ontologies (artificial intelligence);pattern recognition;proteins","deep convolutional neural networks;deep learning;gene ontology terms;pattern mining;pattern recognition;protein function recognition;tertiary protein retrieval;tertiary protein structure alignment","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Heuristic generation of dynamic quiz game using linked data and gamfication","A. Parekh; N. Shah; L. Varshney; N. Shah; M. Dsilva","Department of Information Technology, Dwarkadas J. Sanghvi College of Engineering, Mumbai, India","2016 International Conference on Inventive Computation Technologies (ICICT)","20170119","2016","2","","1","6","In this paper, we propose a method to dynamically generate a quiz game which automatically renders a quiz based on a given topic on the fly leveraging the DBpedia database which is the most popular source of Linked Data. Linked Data is a paradigm to create a more machine-readable, structured web which shall form the underlying structure for the semantic web. In our attempt to develop the quiz, we propose solutions to two very critical problems having high magnitude applications, ranking a given set of properties for a given resource using machine learned ranking algorithms and recommending similar resources given a particular resource. The quiz also employs the gamification philosophy by offering a solution to clean the publically maintained data repositories of DBpedia and Wikipedia.","","DVD:978-1-5090-1283-1; Electronic:978-1-5090-1285-5; POD:978-1-5090-1286-2","10.1109/INVENTIVE.2016.7824905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7824905","DBpedia;Gamification;Linked Data;Machine Learned Ranking;Quiz Game;Recommendation System;Semantic Web","Databases;Electronic publishing;Encyclopedias;Games;Internet;Machine learning algorithms","Linked Data;Web sites;computer games;learning (artificial intelligence);semantic Web","DBpedia database;Linked Data;Wikipedia;dynamic quiz game;gamification philosophy;heuristic generation;machine learned ranking algorithms;machine-readable structured Web;publically maintained data repositories;semantic Web","","","","","","","26-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Class-specific pre-trained sparse autoencoders for learning effective features for document classification","M. I. Abdulhussain; J. Q. Gan","School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, UK","2016 8th Computer Science and Electronic Engineering (CEEC)","20170130","2016","","","36","41","Sparse autoencoder is a commonly used deep learning approach for automatically learning features from unlabelled data (unsupervised feature learning). This paper proposes class-specific (supervised) pre-trained approach based on sparse autoencoder to gain low-dimensional interesting structure of features with high performance in document classification. Experimental results have demonstrated the advantages and usefulness of the proposed method in document classification in high-dimensional feature space, in terms of the limited number of features required to achieve good classification accuracy.","","Electronic:978-1-5090-2050-8; POD:978-1-5090-1275-6","10.1109/CEEC.2016.7835885","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835885","Sparse autoencoder;deep learning;document categorization;feature learning","Big data;Computer science;Electronic mail;Feature extraction;Machine learning;Support vector machines;Training","document handling;pattern classification;unsupervised learning","class-specific pretrained approach;deep learning;document classification;sparse autoencoder;unsupervised feature learning","","","","","","","28-30 Sept. 2016","","IEEE","IEEE Conference Publications"
"Extraction of GGO candidate regions from the LIDC database using deep learning","K. Hirayama; J. K. Tan; H. Kim","Kyushu Institute of Technology, 1-1, Sensui, Tobata, Kitakyushu 804-8550, Japan","2016 16th International Conference on Control, Automation and Systems (ICCAS)","20170126","2016","","","724","727","In recent years, development of the computer-aided diagnosis (CAD) systems for the purpose of reducing the false positive on visual screening and improving accuracy of lesion detection has been advanced. Lung cancer is the leading cause of cancer death in the world. Among them, GGO (Ground Glass Opacity) that exhibited early in the before cancer lesion and carcinoma in situ shows a pale concentration, have been concerned about the possibility of undetected on the screening. In this paper, we propose an automatic extraction method of GGO candidate regions from the chest CT image. Our proposed image processing algorithms is consist of four main steps; (1) segmentation of volume of interest from the chest CT image and removing the blood vessel regions, bronchus regions based on 3D line filter, (2) first detection of GGO regions based on density and gradient which is selected the initial GGO candidate regions, (3) identification of the final GGO candidate regions based on DCNN (Deep Convolutional Neural Network) algorithms. Finally, we calculates the statistical features for reducing the false-positive (FP) shadow by the rule-based method, performs identification of the final GGO candidate regions by SVM (Support Vector Machine). Our proposed method performed on to the 31 cases of the LIDC (Lung Image Database Consortium) database, and final identification performance of TP: 93.02[%], FP: 128.52[/case] are obtained respectively.","","Electronic:978-89-93215-11-3; POD:978-1-4673-9058-3; USB:978-89-93215-12-0","10.1109/ICCAS.2016.7832398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832398","Computer Aided Diagnosis;Deep Convolutional Neural Network;Ground Glass Opacity;Lung Image Database Consortium;Support Vector Machine","Biomedical imaging;Blood vessels;Cancer;Lungs;Machine learning;Support vector machines;Three-dimensional displays","blood vessels;cancer;computerised tomography;feature extraction;feedforward neural nets;image filtering;image segmentation;learning (artificial intelligence);lung;medical image processing;opacity;statistical analysis;support vector machines;visual databases","3D line filter;DCNN algorithms;FP shadow reduction;GGO region detection;GGO region extraction;LIDC database;Lung Image Database Consortium database;SVM;automatic extraction method;blood vessel region removal;bronchus regions;cancer lesion;carcinoma;chest CT image;computer-aided diagnosis systems;deep learning;deep-convolutional neural network algorithms;false-positive shadow reduction;ground glass opacity;image processing algorithm;lung cancer;pale concentration;rule-based method;statistical features;support vector machine;volume-of-interest segmentation","","","","","","","16-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Restricted Boltzmann Machines and Deep Belief Networks on Sunway Cluster","K. Song; Y. Liu; R. Wang; M. Zhao; Z. Hao; D. Qian","Sino-German Joint Software Inst., Beihang Univ. Beijing, Beijing, China","2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)","20170126","2016","","","245","252","Deep learning models have showed great potential in classification and recognition over the last decade. Deep Belief Networks (DBNs) have been applied in visual, voice fields due to their great feature presentation capability. However, there are a vast number of time consuming calculations in the training of DBNs. Many researches have accelerated the training of DBNs with good speedups on CPU, GPU, FPGA, etc. At the same time, the latest published Sunway(SW) many-core processor has high computing performance and dedicated heterogeneous architecture. This paper provides a DBNs training system on SW cluster and verifies SW cluster's applicability of training DBNs. We firstly optimize the Restricted Boltzmann Machines and Deep Belief Networks on Sunway processor, then build a parallelism model with linear topology to train DBNs on multiple processors. The system is implemented on the TaihuLight supercomputer and evaluated by training a DBN with 2.8 million parameters with MNIST dataset. Experimental results show that our system achieves considerable speedups on Sunway processors as compared with CPUs.","","Electronic:978-1-5090-4297-5; POD:978-1-5090-4298-2","10.1109/HPCC-SmartCity-DSS.2016.0044","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828385","Deep Belief Networks;Restricted Boltzmann Machines;Sunway processor;TaihuLight supercomputer;data parallelism model","Computer architecture;Conferences;Feature extraction;Machine learning;Neural networks;Supercomputers;Training","Boltzmann machines;belief networks;multiprocessing systems;parallel processing","DBN training system;SW cluster;Sunway cluster;Sunway many-core processor;TaihuLight supercomputer;deep belief networks;deep learning;heterogeneous architecture;high computing performance;linear topology;multiple processors;parallelism model;restricted Boltzmann machines","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"$mathtt {Deepr}$: A Convolutional Net for Medical Records","P. Nguyen; T. Tran; N. Wickramasinghe; S. Venkatesh","Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, Geelong, Vic, Australia","IEEE Journal of Biomedical and Health Informatics","20170201","2017","21","1","22","30","Feature engineering remains a major bottleneck when creating predictive systems from electronic medical records. At present, an important missing element is detecting predictive regular clinical motifs from irregular episodic records. We present Deepr (short for Deep record), a new end-to-end deep learning system that learns to extract features from medical records and predicts future risk automatically. Deepr transforms a record into a sequence of discrete elements separated by coded time gaps and hospital transfers. On top of the sequence is a convolutional neural net that detects and combines predictive local clinical motifs to stratify the risk. Deepr permits transparent inspection and visualization of its inner working. We validate Deepr on hospital data to predict unplanned readmission after discharge. Deepr achieves superior accuracy compared to traditional techniques, detects meaningful clinical motifs, and uncovers the underlying structure of the disease and intervention space.","2168-2194;21682194","","10.1109/JBHI.2016.2633963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7762861","Convolutional neural networks;deep learning;medical records","Diseases;Electronic medical records;Feature extraction;Hospitals;Machine learning;Medical diagnostic imaging","diseases;electronic health records;feature extraction;hospitals;learning (artificial intelligence);neural nets","Deepr;coded time gaps;convolutional neural networks;disease;electronic medical records;end-to-end deep learning system;feature extraction;hospital data;hospital transfers","","","","","","20161201","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Toward a spintronic deep learning spiking neural processor","A. Sengupta; B. Han; K. Roy","School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN 47907, USA","2016 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20170126","2016","","","544","547","Deep Spiking neural architectures are becoming increasingly popular tools in complex pattern recognition tasks. However, implementation of such algorithms in conventional CMOS hardware entails huge area and power consumption due to the significant mismatch between the computational units and the corresponding CMOS devices. In this paper, we explore the design of an All-Spin Deep Spiking Neural Network where we demonstrate the mapping of synaptic and neuronal functionalities to domain wall dynamics in ferromagnets. We evaluate the potential advantages offered by such spintronic devices by performing micromagnetic simulations calibrated to experimental results. In order to investigate the benefits of such a spintronic design for large-scale neuromorphic systems, we perform device-circuit-algorithm co-design for a standard digit recognition problem on the MNIST dataset. Results indicate 250 × improvements in energy consumption and 56× improvement in EDP of the spintronic deep network over a baseline CMOS implementation in commercial 45nm technology.","","Electronic:978-1-5090-2959-4; POD:978-1-5090-2960-0","10.1109/BioCAS.2016.7833852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833852","Deep Learning Architectures;Domain-Wall;Spiking Neural Network;Spintronics","Biological neural networks;Computer architecture;Machine learning;Magnetic multilayers;Magnetic tunneling;Neurons;Spintronics","CMOS integrated circuits;biology computing;learning (artificial intelligence);neural nets","CMOS devices;MNIST dataset;all-spin deep spiking neural network;conventional CMOS hardware;device-circuit-algorithm codesign;domain wall dynamics;energy consumption;ferromagnets;large-scale neuromorphic systems;micromagnetic simulations;neuronal functionalities;pattern recognition tasks;power consumption;spintronic deep learning spiking neural processor;standard digit recognition problem;synaptic functionalities","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Fine-Grained Parallelism in Probabilistic Parsing with Habanero Java","M. Francis-Landau; B. Xue; J. Eisner; V. Sarkar","Johns Hopkins Univ., Baltimore, MD, USA","2016 6th Workshop on Irregular Applications: Architecture and Algorithms (IA3)","20170130","2016","","","78","81","Structured prediction algorithms-used when applying machine learning to tasks like natural language parsing and image understanding-present some opportunities for fine-grained parallelism, but also have problem-specific serial dependencies. Most implementations exploit only simple opportunities such as parallel BLAS, or embarrassing parallelism over input examples. In this work we explore an orthogonal direction: using the fact that these algorithms can be described as specialized forward-chaining theorem provers [1], [2], and implementing fine-grained parallelization of the forward-chaining mechanism. We study context-free parsing as a simple canonical example, but the approach is more general.","","Electronic:978-1-5090-3867-1; POD:978-1-5090-3868-8","10.1109/IA3.2016.020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833310","","Grammar;Heuristic algorithms;Interference;Machine learning algorithms;Parallel processing;Prediction algorithms;Probabilistic logic","Java;context-free grammars;learning (artificial intelligence);parallel processing;probability;theorem proving","Habanero Java;context-free parsing;fine-grained parallelism;forward-chaining mechanism;machine learning;probabilistic parsing;structured prediction algorithms;theorem provers","","","","","","","13-13 Nov. 2016","","IEEE","IEEE Conference Publications"
"A novel text mining algorithm based on deep neural network","X. Sheng; X. Wu; Y. Luo","School of Economics and Management, Tongji University, Siping Road, Shanghai, P.R. China","2016 International Conference on Inventive Computation Technologies (ICICT)","20170119","2016","2","","1","6","In this paper, we propose the novel text mining algorithm based on the deep neural network. In knowledge representation, capable of embodying the of the information content characteristic and external characteristic not only has the semantic meaning and it is interlinked, the content and the external characteristics constitute the text knowledge mining association reveals and knowledge base. This article through to the contents of a text knowledge characteristics and appearance characteristics of general different combination of co-occurrence analysis, explore the co-occurrence analysis method based on spatial distribution, time distribution and the application of the internal and the external association mapping text knowledge mining. In terms of the types of mining, not only limited to the simple knowledge classification, clustering, we found that can explore richer knowledge mining method, such as semantic rules found, trend analysis, topic tracking, etc. Under this prior basic knowledge, we propose the novel algorithm with the DNN. The experiment result proves the feasibility.","","DVD:978-1-5090-1283-1; Electronic:978-1-5090-1285-5; POD:978-1-5090-1286-2","10.1109/INVENTIVE.2016.7824810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7824810","data mining;deep learning;neural network;optimization;structure modelling;text analysis","Data models;Feature extraction;Machine learning;Neural networks;Semantics;Text mining","data mining;knowledge representation;neural nets;pattern classification;text analysis","appearance characteristics;association mapping text knowledge mining;co-occurrence analysis;deep neural network;knowledge classification;knowledge representation;semantic meaning;semantic rules;spatial distribution;text knowledge characteristics;text knowledge mining association;time distribution;topic tracking;trend analysis","","","","","","","26-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Camera model identification with the use of deep convolutional neural networks","A. Tuama; F. Comby; M. Chaumont","LIRMM(UMR5506) /CNRS, Montpellier University, France","2016 IEEE International Workshop on Information Forensics and Security (WIFS)","20170119","2016","","","1","6","In this paper, we propose a camera model identification method based on deep convolutional neural networks (CNNs). Unlike traditional methods, CNNs can automatically and simultaneously extract features and learn to classify during the learning process. A layer of preprocessing is added to the CNN model, and consists of a high pass filter which is applied to the input image. Before feeding the CNN, we examined the CNN model with two types of residuals. The convolution and classification are then processed inside the network. The CNN outputs an identification score for each camera model. Experimental comparison with a classical two steps machine learning approach shows that the proposed method can achieve significant detection performance. The well known object recognition CNN models, AlexNet and GoogleNet, are also examined.","","Electronic:978-1-5090-1138-4; POD:978-1-5090-1139-1","10.1109/WIFS.2016.7823908","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823908","Camera Identification;Convolutional Neural Network;Deep Learning;Fully Connected Network","Biological neural networks;Cameras;Convolution;Feature extraction;Image color analysis;Machine learning;Neurons","cameras;convolution;feature extraction;high-pass filters;learning (artificial intelligence);neural nets;object recognition","AlexNet;GoogleNet;camera model identification;deep convolutional neural networks;feature extraction;high pass filter;image;learning process classification;machine learning;network convolution;object recognition CNN models;preprocessing layer","","","","","","","4-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep Dictionary Learning","S. Tariyal; A. Majumdar; R. Singh; M. Vatsa","IIIT Delhi, New Delhi, India","IEEE Access","20170127","2016","4","","10096","10109","Two popular representation learning paradigms are dictionary learning and deep learning. While dictionary learning focuses on learning “basis” and “features” by matrix factorization, deep learning focuses on extracting features via learning “weights” or “filter” in a greedy layer by layer fashion. This paper focuses on combining the concepts of these two paradigms by proposing deep dictionary learning and show how deeper architectures can be built using the layers of dictionary learning. The proposed technique is compared with other deep learning approaches, such as stacked autoencoder, deep belief network, and convolutional neural network. Experiments on benchmark data sets show that the proposed technique achieves higher classification and clustering accuracies. On a real-world problem of electrical appliance classification, we show that deep dictionary learning excels where others do not yield at-par performance. We postulate that the proposed formulation can pave the path for a new class of deep learning tools.","2169-3536;21693536","","10.1109/ACCESS.2016.2611583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779008","Deep learning;dictionary learning;feature representation","Dictionaries;Feature extraction;Machine learning;Matrix decomposition;Neural networks;Sparse matrices","feature extraction;learning (artificial intelligence);pattern classification;pattern clustering","benchmark data sets;classification accuracies;clustering accuracies;deep dictionary learning;electrical appliance classification;feature extraction;greedy layer by layer approach;matrix factorization","","","","","","20161209","2016","","IEEE","IEEE Journals & Magazines"
"Context-Based Plot Detection from Online Review Comments for Preventing Spoilers","Y. Hijikata; H. Iwai; S. Nishida","Grad. Sch. of Eng. Sci., Osaka Univ., Toyonaka, Japan","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","57","65","The plot (content or storyline of a story) may disappoint users who read review comments associated with items containing a story such as comics, novels, and movies. This paper proposes a new method for identifying sentences that include descriptions of the plot of the story. Conventional methods only use information based on the words contained in a target sentence, however, our new method uses contextual information in addition to word information. We identify contextual information by using the sentence location and the plot probability of surrounding sentences. An experiment showed that this method improved the accuracy with which plot-related information can be identified.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0019","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817036","context;opinion mining;plot detection;spoiler","Context;Databases;Machine learning algorithms;Motion pictures;TV;Web pages;Writing","Internet;data mining;probability;word processing","context-based plot detection;contextual information;online review comments;plot probability;plot-related information;sentence location;word information","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"AlphaGo and Monte Carlo tree search: The simulation optimization perspective","M. C. Fu","Robert H. Smith School of Business, Institute for Systems Research, University of Maryland, College Park, 20742, USA","2016 Winter Simulation Conference (WSC)","20170119","2016","","","659","670","In March of 2016, Google DeepMind's AlphaGo, a computer Go-playing program, defeated the reigning human world champion Go player, 4-1, a feat far more impressive than previous victories by computer programs in chess (IBM's Deep Blue) and Jeopardy (IBM's Watson). The main engine behind the program combines machine learning approaches with a technique called Monte Carlo tree search. Current versions of Monte Carlo tree search used in Go-playing algorithms are based on a version developed for games that traces its roots back to the adaptive multi-stage sampling simulation optimization algorithm for estimating value functions in finite-horizon Markov decision processes (MDPs) introduced by Chang et al. (2005), which was the first use of Upper Confidence Bounds (UCBs) for Monte Carlo simulation-based solution of MDPs. We review the main ideas in UCB-based Monte Carlo tree search by connecting it to simulation optimization through the use of two simple examples: decision trees and tic-tac-toe.","","CD:978-1-5090-4484-9; Electronic:978-1-5090-4486-3; POD:978-1-5090-4487-0; USB:978-1-5090-4485-6","10.1109/WSC.2016.7822130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822130","","Computers;Decision trees;Games;Google;Machine learning algorithms;Monte Carlo methods;Optimization","Markov processes;Monte Carlo methods;computer games;learning (artificial intelligence);tree searching","AlphaGo;Go-playing algorithms;MDP;Monte Carlo tree search;UCB;computer Go-playing program;finite-horizon Markov decision process;machine learning approach;simulation optimization perspective;upper confidence bounds","","","","","","","11-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Meta-Learning Approach for Recommendation of Image Segmentation Algorithms","G. F. C. Campos; S. Barbon; R. G. Mantovani","Dept. of Comput. Sci., Londrina State Univ., Londrina, Brazil","2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","20170116","2016","","","370","377","There are many algorithms for image segmentation, but there is no optimal algorithm for all kind of image applications. To recommend an adequate algorithm for segmentation is a challenging task that requires knowledge about the problem and algorithms. Meta-learning has recently emerged from machine learning research field to solve the algorithm selection problem. This paper applies meta-learning to recommend segmentation algorithms based on meta-knowledge. We performed experiments in four different meta-databases representing various real world problems, recommending when three different segmentation techniques are adequate or not. A set of 44 features based on color, frequency domain, histogram, texture, contrast and image quality were extracted from images, obtaining enough discriminative power for the recommending task in different segmentation scenarios. Results show that Random Forest meta-models were able to recommend segmentation algorithms with high predictive performance.","","Electronic:978-1-5090-3568-7; POD:978-1-5090-3569-4","10.1109/SIBGRAPI.2016.058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813057","image processing;meta-learning;segmentation algorithm recommendation","Histograms;Image color analysis;Image segmentation;Machine learning algorithms;Prediction algorithms;Standards;Wounds","image colour analysis;image segmentation;image texture;learning (artificial intelligence);quality control","algorithm selection problem;frequency domain;histogram;image color;image contrast;image quality;image segmentation;image texture;machine learning;metadatabases;metalearning approach","","","","","","","4-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Clustering by Creating a Graph","Y. Wang; H. Zhang; K. Huang; C. Yu; H. Cui","Ningbo Inst. of Technol., Zhejiang Univ., Ningbo, China","2016 12th International Conference on Computational Intelligence and Security (CIS)","20170119","2016","","","499","502","In this paper, we presented a novel graph-based clustering algorithm (GC). GC contains two main steps: the first step is to create a graph and find out the key nodes as centers, the second step is to divide every data point to each center. The centers are selected from a graph view. Experimental results on 8 datasets demonstrated that GC could do better than k-means, k-medoids, Hierarchical Clustering and Gaussian Mixture Models. Moreover, the most important parameter of clustering algorithms is the number of clusters K and the comparing algorithms need K set to true number of clusters. But for GC, the only requirement is that K is not less than the true number of clusters.","","Electronic:978-1-5090-4840-3; POD:978-1-5090-4841-0","10.1109/CIS.2016.0121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820512","Adjacency Matrix;Clustering;Graph Theory","Algorithm design and analysis;Clustering algorithms;Data mining;Fires;Machine learning algorithms;Partitioning algorithms;Spirals","graph theory;pattern clustering","GC algorithm;adjacency matrix;graph theory;graph-based clustering algorithm","","","","","","","16-19 Dec. 2016","","IEEE","IEEE Conference Publications"
"V-shaped sampling based on Kendall-Distance to enhance optimization with ranks","H. Li; G. Pedrielli; Min Chen; L. H. Lee; E. P. Chew; C. H. Chen","Department of Computing Science, Institute of High Performance Computing, A*STAR Singapore, 1 Fusionopolis Way, #16-16 Connexis, 138632 SINGAPORE","2016 Winter Simulation Conference (WSC)","20170119","2016","","","671","681","In the area of discrete optimization via simulation (DOvS), optimization over rank values has been of concern in computer science and, more recently, in multi-fidelity simulation optimization. Specifically, Chen et al. (2015) proposes the concept of Ordinal Transformation to translate multi-dimensional discrete optimization problems into single-dimensional problems which are simpler, and the transformed solution space is referred as ordinal space. In this paper, we build on the idea of ordinal transformation and its properties in order to derive an efficient sampling algorithm for identifying the solution with the best rank in the setting of multi-fidelity optimization. We refer to this algorithm as V-shaped and we use the concept of Kendall distance adopted in the machine learning theory, in order to characterize solutions in the OT space. The algorithm is presented for the first time and preliminary performance results are provided comparing the algorithm with the sampling proposed in Chen et al. (2015).","","CD:978-1-5090-4484-9; Electronic:978-1-5090-4486-3; POD:978-1-5090-4487-0; USB:978-1-5090-4485-6","10.1109/WSC.2016.7822131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822131","","Algorithm design and analysis;Computational modeling;Machine learning algorithms;Optimization;Sun;Workstations","optimisation;sampling methods","DOvS;Kendall-distance;OT space;V-shaped sampling;discrete optimization via simulation;machine learning theory;multidimensional discrete optimization problems;multifidelity simulation optimization;ordinal space;ordinal transformation;single-dimensional problems","","","","","","","11-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"Coarse-to-Fine Stacked Fully Convolutional Nets for lymph node segmentation in ultrasound images","Y. Zhang; M. T. C. Ying; L. Yang; A. T. Ahuja; D. Z. Chen","Department of Computer Science and Engineering, University of Notre Dame, IN 46556, USA","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","443","448","Ultrasound as a well-established imaging modality is widely used in imaging lymph nodes for clinical diagnosis and disease analysis. Quantitative analysis of lymph node features, morphology, and relations can provide valuable information for diagnosis and immune system studies. For such analysis, it is necessary to first accurately segment the lymph node areas in ultrasound images. In this paper, we develop a new deep learning method, called Coarse-to-Fine Stacked Fully Convolutional Nets (CFS-FCN), for automatically segmenting lymph nodes in ultrasound images. Our method consists of multiple stages of FCN modules. We train the CFS-FCN model to learn the segmentation knowledge from a coarse-to-fine, simple-to-complex manner. A data set of 80 ultrasound images containing both normal and diseased lymph nodes is used in our experiments, which show that our method considerably outperforms the state-of-the-art deep learning methods for lymph node segmentation.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822557","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822557","","Biological system modeling;Biomedical imaging;Image segmentation;Lymph nodes;Machine learning;Training;Ultrasonic imaging","biomedical ultrasonics;diseases;image segmentation;learning (artificial intelligence);medical image processing","CFS-FCN;FCN module;clinical diagnosis;coarse-to-fine stacked fully convolutional net;deep learning method;disease analysis;lymph node imaging;lymph node segmentation;ultrasound images;ultrasound imaging modality","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
