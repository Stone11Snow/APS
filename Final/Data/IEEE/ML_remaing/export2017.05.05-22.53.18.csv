"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5647601,5646812,5648017,5642314,5643699,5432213,5444873,5639901,5518429,5638384,5636476,5451105,5636708,5499456,5635562,5636695,5635946,5630198,5626227,5627757,5632366,5629219,5628629,5632559,5626259,5634699,5630081,5628875,5633162,5634387,5633679,5626990,5626963,5628605,5634337,5624929,5545414,5625582,5625605,5622946,5623139,5401168,5593883,5614639,5614727,5416712,5612909,5342422,5608830,5609736,5607748,5609385,5610650,5600460,5596506,5596639,5596824,5596480,5596869,5596825,5604101,5602589,5596617,5602796,5596717,5596519,5524019,5596769,5596750,5596641,5603054,5600648,5596787,5599818,5599675,5599790,5473140,5597464,5597245,5597631,5597065,5595848,5596032,5597457,5597285,5597868,5597455,5597632,5597367,5597394,5597757,5597278,5597392,5595913,5597266,5595819,5597652,5595920,5597152,5595922",2017/05/05 22:53:18
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Generator of learning data for the TSPs based on the visiting order of the cities on convex hull","A. Kawashima; Y. Sugai","Graduate School of Engineering, Chiba University, Japan","2010 IEEE International Symposium on Intelligent Control","20101028","2010","","","2302","2307","The optimal tours of the traveling salesman problems( TSPs) in two dimensional Euclidean space have the characteristics in the visiting order of the cities on the convex hull. Based on this characteristics, the TSPs can be replaced into some shortest Hamiltonian path problems(SHPPs) of which solutions assemble a tour. This reduction is enabled by the calculation of convex hull and the classification of the cities not on the convex hull into the subsets of cities which construct SHPPs. This procedure means that the TSPs are equivalent to the classification problems, which leads to be able to apply existing methods of machine learning to the TSPs. We show that the teaching data for machine learning are available as the optimal classifications in the instances of which the optimal tour has been found.","2158-9860;21589860","Electronic:978-1-4244-5361-0; POD:978-1-4244-5360-3","10.1109/ISIC.2010.5612909","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5612909","","Cities and towns;Complexity theory;Education;Lead;Learning systems;Machine learning;Software algorithms","learning (artificial intelligence);pattern classification;travelling salesman problems","TSP;cities visiting order;classification problems;convex hull;learning data generator;machine learning;optimal tour;shortest Hamiltonian path problems;traveling salesman problems;two dimensional Euclidean space","","0","","11","","","8-10 Sept. 2010","","IEEE","IEEE Conference Publications"
"Constructing Corpus for Query-Oriented XML Text Summarization","S. Wu; D. Liu; X. Jiao","Jiangxi Key Lab. of Data & Knowledge Eng., Jiangxi Univ. of Finance &Econ., Nanchang, China","2010 International Conference on Management of e-Commerce and e-Government","20101111","2010","","","45","49","XML Retrieval is becoming the focus study of the field of Information Retrieval and Database. Summarization of the results which come from the XML search engines will alleviate the read burden of user's. However, as the basis of this study, the construction of the query-oriented XML text summarization corpus has not yet received enough attention. In this paper, we introduce our works on constructing this kind of corpus, including the selection of topics and XML elements/documents, construction process and the feature of the constructed corpus. Up to now, the corpus has 25 English query topics, including 422 elements for summarization, and 32 Chinese topics which including 402 elements. For each topic, 4 pieces of extracted summaries and 4 pieces of generated summaries are made manually by 4 experts.","","Electronic:978-0-7695-4245-4; POD:978-1-4244-8507-9","10.1109/ICMeCG.2010.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5628629","Automatic Summarization;Corpus;Query-oriented;XML","Databases;Education;Feature extraction;Machine learning;Pragmatics;Security;XML","XML;query processing;search engines;text analysis","Chinese topics;English query topics;XML documents;XML elements;XML retrieval;XML search engine;corpus construction;information retrieval;query-oriented XML text summarization;result summarization","","0","","10","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Consistent Estimator of Median and Mean Graph","B. Jain; K. Obermayer","Berlin Univ. of Technol., Berlin, Germany","2010 20th International Conference on Pattern Recognition","20101007","2010","","","1032","1035","The median and mean graph are basic building blocks for statistical graph analysis and unsupervised pattern recognition methods such as central clustering and graph quantization. This contribution provides sufficient conditions for consistent estimators of true but unknown central points of a distribution on graphs.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595848","","Calculus;Machine learning;Measurement;Optimization;Pattern recognition;Quantization;Stochastic processes","graph theory;pattern clustering;statistical analysis","central clustering;consistent median estimators;graph quantization;mean graph;statistical graph analysis;unsupervised pattern recognition methods","","1","","23","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Unsupervised Learning from Linked Documents","Z. Guo; S. Zhu; Y. Chi; Z. Zhang; Y. Gong","Comput. Sci. Dept., SUNY at Binghamton, Binghamton, NY, USA","2010 20th International Conference on Pattern Recognition","20101007","2010","","","730","733","Documents in many corpora, such as digital libraries and webpages, contain both content and link information. In a traditional topic model which plays an important role in the unsupervised learning, the link information is either totally ignored or treated as a feature similar to content. We believe that neither approach is capable of accurately capturing the relations represented by links. To address the limitation of traditional topic models, in this paper we propose a citation-topic (CT) model that explicitly considers the document relations represented by links. In the CT model, instead of being treated as yet another feature, links are used to form the structure of the generative model. As a result, in the CT model a given document is modeled as a mixture of a set of topic distributions, each of which is borrowed (cited) from a document that is related to the given document. We apply the CT model to several document collections and the experimental comparisons against state-of-the-art approaches demonstrate very promising performances.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596032","Unsupervised learning;document clustering;latent topic model","Accuracy;IP networks;Indexing;Machine learning;Measurement;Probabilistic logic;Unsupervised learning","Internet;digital libraries;document handling;unsupervised learning","Web pages;citation-topic model;digital libraries;linked documents;unsupervised learning","","0","","13","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Learning in Glaucoma Genetic Risk Assessment","Z. Zhang; J. Liu; C. K. Kwoh; X. Sim; W. T. Tay; Y. Tan; F. Yin; T. Y. Wong","Institute for Infocomm Research, A*STAR, Singapore","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","20101111","2010","","","6182","6185","Genome Wide Association (GWA) studies are powerful tools to identify genes involved in common human diseases, and are becoming increasingly important in genetic epidemiology research. However, the statistical approaches behind GWA studies lack capability in taking into account the possible interactions among genetic markers; and true disease variants may be lost in statistical noise due to high threshold. A typical GWA study reports a few highly suspected signals, e.g. Single-nucleotide polymorphisms (SNPs), which usually account for a tiny portion of overall genetic risks for the disease of interest. This study proposes a computational learning approach in addition to parametric statistical methods along with a filtering mechanism, to build glaucoma genetic risk assessment model. Our data set was obtained from Singapore Malay Eye Study (SiMES), genotyped on Illumina 610quad arrays. We constructed case-control data set with 233 glaucoma and 458 healthy samples. A standard case-control association test was conducted on post-QC dataset with more than 500k SNPs. Genetic profile is constructed using genotype information from a list of 412 SNPs filtered by a relaxed p-value threshold of 1×10<sup>-3</sup>, and forms the feature space for learning. Among the five learning algorithms we performed, Support Vector Machines with radial kernel (SVM-radial) achieved the best result, with area under curve (ROC) of 99.4% and accuracy of 95.9%. The result illustrates that, learning approach in post GWAS data analysis is able to accurately assess genetic risk for glaucoma. The approach is more robust and comprehensive than individual SNPs matching method. We will further validate our results in several other data sets obtained in consequential population studies conducted in Singapore.","1094-687X;1094687X","Electronic:978-1-4244-4124-2; POD:978-1-4244-4123-5","10.1109/IEMBS.2010.5627757","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5627757","","Accuracy;Bioinformatics;Diseases;Genomics;Machine learning;Risk management","genetics;genomics;learning (artificial intelligence);medical computing;statistical analysis;support vector machines;vision defects","Illumina 610quad arrays;SiMES;Singapore Malay Eye Study;computational learning approach;consequential population studies;filtering mechanism;genes;genetic epidemiology research;genetic markers;genetic profile;genome wide association studies;genotyping;glaucoma genetic risk assessment;human diseases;parametric statistical methods;radial kernel;single-nucleotide polymorphisms;statistical noise;support vector machines","Adult;Aged;Aged, 80 and over;Algorithms;Databases, Genetic;Genetic Predisposition to Disease;Genome-Wide Association Study;Glaucoma;Humans;Learning;Middle Aged;Polymorphism, Single Nucleotide;ROC Curve;Reproducibility of Results;Risk Assessment","1","","16","","","Aug. 31 2010-Sept. 4 2010","","IEEE","IEEE Conference Publications"
"Feature Ranking Based on Decision Border","C. Diamantini; A. Gemelli; D. Potena","Univ. Politec. delle Marche, Ancona, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","609","612","In this paper a Feature Ranking algorithm for classification is proposed, which is based on the notion of Bayes decision border. The method elaborates upon the results of the Decision Border Feature Extraction approach, exploiting properties of eigenvalues and eigenvectors of the orthogonal transformation to calculate the discriminative importance weights of the original features. Non parametric classification is also considered by resorting to Labeled Vector Quantizers neural networks trained by the BVQ algorithm. The choice of this architecture leads to a cheap implementation of the ranking algorithm we call BVQ-FR. The effectiveness of BVQ-FR is tested on real datasets. The novelty of the method is to use a feature extraction technique to assess the weight of the original features, as opposed to heuristics methods commonly used.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597457","","Accuracy;Approximation algorithms;Artificial neural networks;Eigenvalues and eigenfunctions;Feature extraction;Iron;Machine learning","Bayes methods;eigenvalues and eigenfunctions;feature extraction;learning (artificial intelligence);neural nets","Bayes decision border;decision border feature extraction;eigenvalues;eigenvectors;feature ranking algorithm;labeled vector quantizer;neural network training;nonparametric classification;orthogonal transformation","","0","","8","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Effective feature selection with Particle Swarm Optimization based one-dimension searching","Jun Wang; Yan Zhao; Ping Liu","Department of Electronics Engineering, Shantou University, No.243 Daxue Road, Guangdong, 515063, China","2010 3rd International Symposium on Systems and Control in Aeronautics and Astronautics","20101111","2010","","","702","705","Forming an efficient feature space for classification problems is a grand challenge in pattern recognition. Many optimization algorithms are adopted to do feature selection, but these algorithms do searching in multi-dimensions space and always cannot get the optimal feature subset. In this paper, a feature selection method with Particle Swarm Optimization based one-dimension searching is proposed to improve the classification performance. Experimental results show that the proposed method can do feature selection more effectively than the compared method and get much higher classification accuracy.","","Electronic:978-1-4244-6045-8; POD:978-1-4244-6043-4","10.1109/ISSCAA.2010.5632559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5632559","","Classification algorithms;Complexity theory;Gallium;Kernel;Machine learning algorithms;Particle swarm optimization;Support vector machines","particle swarm optimisation;pattern classification","classification problems;feature selection;one-dimension searching method;particle swarm optimization;pattern recognition","","1","","10","","","8-10 June 2010","","IEEE","IEEE Conference Publications"
"Multiobjective Neural Network Ensembles Based on Regularized Negative Correlation Learning","H. Chen; X. Yao","University of Birmingham, Birmingham","IEEE Transactions on Knowledge and Data Engineering","20101028","2010","22","12","1738","1751","Negative Correlation Learning (NCL) [CHECK END OF SENTENCE], [CHECK END OF SENTENCE] is a neural network ensemble learning algorithm which introduces a correlation penalty term to the cost function of each individual network so that each neural network minimizes its mean-square-error (MSE) together with the correlation. This paper describes NCL in detail and observes that the NCL corresponds to training the entire ensemble as a single learning machine that only minimizes the MSE without regularization. This insight explains that NCL is prone to overfitting the noise in the training set. The paper analyzes this problem and proposes the multiobjective regularized negative correlation learning (MRNCL) algorithm which incorporates an additional regularization term for the ensemble and uses the evolutionary multiobjective algorithm to design ensembles. In MRNCL, we define the crossover and mutation operators and adopt nondominated sorting algorithm with fitness sharing and rank-based fitness assignment. The experiments on synthetic data as well as real-world data sets demonstrate that MRNCL achieves better performance than NCL, especially when the noise level is nontrivial in the data set. In the experimental discussion, we give three reasons why our algorithm outperforms others.","1041-4347;10414347","","10.1109/TKDE.2010.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416712","Multiobjective algorithm;multiobjective learning;negative correlation learning;neural network ensembles;neural networks;regularization.","Algorithm design and analysis;Application software;Computational intelligence;Cost function;Genetic mutations;Machine learning;Machine learning algorithms;Neural networks;Noise level;Sorting","evolutionary computation;learning (artificial intelligence);mathematical operators;mean square error methods;neural nets;sorting","correlation penalty term;cost function;crossover operator;evolutionary multiobjective algorithm;fitness sharing;mean-square-error;multiobjective neural network ensembles;multiobjective regularized negative correlation learning algorithm;mutation operator;neural network ensemble learning algorithm;nondominated sorting algorithm;rank-based fitness assignment","","37","","42","","20100218","Dec. 2010","","IEEE","IEEE Journals & Magazines"
"View-Independent Action Recognition from Temporal Self-Similarities","I. N. Junejo; E. Dexter; I. Laptev; P. Perez","University of Sharjah, Sharjah, UAE","IEEE Transactions on Pattern Analysis and Machine Intelligence","20101118","2011","33","1","172","185","This paper addresses recognition of human actions under view changes. We explore self-similarities of action sequences over time and observe the striking stability of such measures across views. Building upon this key observation, we develop an action descriptor that captures the structure of temporal similarities and dissimilarities within an action sequence. Despite this temporal self-similarity descriptor not being strictly view-invariant, we provide intuition and experimental validation demonstrating its high stability under view changes. Self-similarity descriptors are also shown to be stable under performance variations within a class of actions when individual speed fluctuations are ignored. If required, such fluctuations between two different instances of the same action class can be explicitly recovered with dynamic time warping, as will be demonstrated, to achieve cross-view action synchronization. More central to the current work, temporal ordering of local self-similarity descriptors can simply be ignored within a bag-of-features type of approach. Sufficient action discrimination is still retained in this way to build a view-independent action recognition system. Interestingly, self-similarities computed from different image features possess similar properties and can be used in a complementary fashion. Our method is simple and requires neither structure recovery nor multiview correspondence estimation. Instead, it relies on weak geometric properties and combines them with machine learning for efficient cross-view action recognition. The method is validated on three public data sets. It has similar or superior performance compared to related methods and it performs well even in extreme conditions, such as when recognizing actions from top views while using side views only for training.","0162-8828;01628828","","10.1109/TPAMI.2010.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432213","Human action recognition;human action synchronization;local temporal descriptors.;temporal self-similarities;view invariance","Buildings;Cameras;Fluctuations;Hidden Markov models;Humans;Machine learning;Shape;Stability;Support vector machines;Time measurement","computational geometry;feature extraction;image sequences;learning (artificial intelligence)","action descriptor;action discrimination;action sequence;bag of features type approach;cross view action synchronization;dynamic time warping;image feature;machine learning;multiview correspondence estimation;public data set;striking stability;temporal ordering;temporal self similarity;view independent action recognition;weak geometric property","Algorithms;Artificial Intelligence;Computer Simulation;Humans;Movement;Pattern Recognition, Automated","150","","53","","20100318","Jan. 2011","","IEEE","IEEE Journals & Magazines"
"Feature Selection Using Multiobjective Optimization for Named Entity Recognition","A. Ekbal; S. Saha; C. S. Garbe","Dept. of Comput. Linguistics, Heidelberg Univ., Heidelberg, Germany","2010 20th International Conference on Pattern Recognition","20101007","2010","","","1937","1940","Appropriate feature selection is a very crucial issue in any machine learning framework, specially in Maximum Entropy (ME). In this paper, the selection of appropriate features for constructing a ME based Named Entity Recognition (NER) system is posed as a multiobjective optimization (MOO) problem. Two classification quality measures, namely recall and precision are simultaneously optimized using the search capability of a popular evolutionary MOO technique, NSGA-II. The proposed technique is evaluated to determine suitable feature combinations for NER in two languages, namely Bengali and English that have significantly different characteristics. Evaluation results yield the recall, precision and F-measure values of 70.76%, 81.88% and 75.91%, respectively for Bengali, and 78.38%, 81.27% and 79.80%, respectively for English. Comparison with an existing ME based NER system shows that our proposed feature selection technique is more efficient than the heuristic based feature selection.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597245","Feature Selection;Maximum Entropy;Multiobjective Optimization;Named Entity Recognition","Biological cells;Context;Entropy;Machine learning;Optimization;Training;Training data","feature extraction;image recognition;learning (artificial intelligence);optimisation","NSGA-II;classification quality measures;evolutionary MOO technique;feature selection technique;heuristic based feature selection;maximum entropy;multiobjective optimization;named entity recognition","","5","","6","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"The Balanced Accuracy and Its Posterior Distribution","K. H. Brodersen; C. S. Ong; K. E. Stephan; J. M. Buhmann","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3121","3124","Evaluating the performance of a classification algorithm critically requires a measure of the degree to which unseen examples have been identified with their correct class labels. In practice, generalizability is frequently estimated by averaging the accuracies obtained on individual cross-validation folds. This procedure, however, is problematic in two ways. First, it does not allow for the derivation of meaningful confidence intervals. Second, it leads to an optimistic estimate when a biased classifier is tested on an imbalanced dataset. We show that both problems can be overcome by replacing the conventional point estimate of accuracy by an estimate of the posterior distribution of the balanced accuracy.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.764","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597285","bias;class imbalance;classification performance;generalizability","Accuracy;Approximation algorithms;Inference algorithms;Machine learning;Prediction algorithms;Probabilistic logic;Training","generalisation (artificial intelligence);pattern classification;performance evaluation;statistical distributions","balanced accuracy;classification algorithm;generalizability;performance evaluation;posterior distribution","","58","","7","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic decision using dirty databases: Application to prostate cancer diagnosis","O. R. Marin; D. Ruiz; A. Soriano; F. J. Delgado","Bioinspired Engineering and Health Computing Research Group, University of Alicante, P.O. 99 E-03080 Spain","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","20101111","2010","","","1162","1165","Currently, the best way to reduce the mortality of cancer is to detect and treat it in its early stages. Automatic decision support systems, such as automatic diagnosis systems, are very helpful in this task but their performance is constrained by the integrity of the clinical input data. This could be a problem since clinical databases, in which these systems are based on, are commonly built up containing dirty data (empty fields, non-standard or normalized values, etc). This article presents a study of the performance of a clinical decision support system, based on an artificial neural networks, using sets of clean and dirty prostate cancer data. The study shows that is possible to obtain an implementation that allow us to avoid the problems associated to the database's lack of integrity and reach a similar performance using either clean or dirty data.","1094-687X;1094687X","Electronic:978-1-4244-4124-2; POD:978-1-4244-4123-5","10.1109/IEMBS.2010.5626259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5626259","","Artificial neural networks;Classification algorithms;Databases;Machine learning;Prostate cancer;Training","biological organs;cancer;decision support systems;diagnostic expert systems;medical diagnostic computing;neural nets","artificial neural networks;automatic decision support systems;automatic diagnosis systems;clinical decision support system;dirty databases;prostate cancer","Data Mining;Databases, Factual;Decision Support Systems, Clinical;Diagnosis, Computer-Assisted;Humans;Male;Medical Records Systems, Computerized;Prostatic Neoplasms;Reproducibility of Results;Sensitivity and Specificity","0","","19","","","Aug. 31 2010-Sept. 4 2010","","IEEE","IEEE Conference Publications"
"Brain connectivity analysis by reduction to pair classification","E. Olivetti; S. Veeramachaneni; S. Greiner; P. Avesani","NeuroInformatics Laboratory (NILab), Fondazione Bruno Kessler, Trento, Italy","2010 2nd International Workshop on Cognitive Information Processing","20101014","2010","","","275","280","Brain connectivity studies aim at describing the connections within the brain. Diffusion and functional MRI techniques provide different kinds of information to understand brain connectivity non-invasively. Fiber tract segmentation is the task of identifying pathways of neuronal axons connecting different brain areas from MRI data. In this work we propose a method to investigate the role of both diffusion and functional MRI data for supervised tract segmentation based on learning the pairwise relationships between streamlines. Experiments on real data demonstrate the promise of the approach.","2327-1671;23271671","Electronic:978-1-4244-6459-3; POD:978-1-4244-6457-9","10.1109/CIP.2010.5604101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604101","","Brain;Error analysis;Kernel;Machine learning;Magnetic resonance imaging;Nerve fibers;Streaming media","biodiffusion;biomedical MRI;brain;image classification;image segmentation;medical image processing;neurophysiology","brain connectivity analysis;diffusion;fiber tract segmentation;functional MRI;neuronal axons;pair classification","","1","","22","","","14-16 June 2010","","IEEE","IEEE Conference Publications"
"Combining Single Class Features for Improving Performance of a Two Stage Classifier","L. P. Cordella; C. D. Stefano; F. Fontanella; C. Marrocco; A. S. d. Freca","DIS, Univ. di Napoli, Naples, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4352","4355","We propose a feature selection--based approach for improving classification performance of a two stage classification system in contexts where a high number of features is involved. A problem with a set of N classes is subdivided into a set of N two class problems. In each problem, a GA-based feature selection algorithm is used for finding the best subset of features. These subsets are then used for training N classifiers. In the classification phase, unknown samples are given in input to each of the trained classifiers by using the corresponding subspace. In case of conflicting responses, the sample is sent to a suitably trained supplementary classifier. The proposed approach has been tested on a real world dataset containing hyper--spectral image data. The results favourably compare with those obtained by other methods on the same data.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597868","","Covariance matrix;Gallium;Machine learning;Noise measurement;Pattern recognition;Support vector machines;Training","feature extraction;geophysical image processing;image classification;set theory","GA based feature selection;hyperspectral image;set theory;two stage classifier","","1","5","14","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Low-rank kernel learning for semi-supervised clustering","M. S. Baghshah; S. B. Shouraki","Computer Engineering Department, Sharif University of Technology, Tehran, Iran","Cognitive Informatics (ICCI), 2010 9th IEEE International Conference on","20101011","2010","","","567","572","In the last decade, there has been a growing interest in distance function learning for semi-supervised clustering settings. In addition to the earlier methods that learn Mahalanobis metrics (or equivalently, linear transformations), some nonlinear metric learning methods have also been recently introduced. However, these methods either allow limited choice of distance metrics yielding limited flexibility or learn nonparametric kernel matrices and scale very poorly (prohibiting applicability to medium and large data sets). In this paper, we propose a novel method that learns low-rank kernel matrices from pairwise constraints and unlabeled data. We formulate the proposed method as a trace ratio optimization problem and learn appropriate distance metrics through finding optimal low-rank kernel matrices. The proposed optimization problem can be solved much more efficiently than SDP problems introduced to learn nonparametric kernel matrices. Experimental results demonstrate the effectiveness of our method on synthetic and real-world data sets.","","Electronic:978-1-4244-8042-5; POD:978-1-4244-8041-8","10.1109/COGINF.2010.5599675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599675","Low-rank kernel matrix;kernel learning;pairwise constraints;unlabeled data","Artificial neural networks;Clustering algorithms;Kernel;Learning systems;Machine learning;Measurement;Optimization","distance learning;learning (artificial intelligence);optimisation;pattern clustering","Mahalanobis metrics;distance function learning;distance metrics;kernel learning;nonlinear metric learning method;nonparametric kernel matrix;semidefinite programming problem;semisupervised clustering;trace ratio optimization problem","","0","","22","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Low Resources Prepositional Phrase Attachment","P. Nalmpantis; R. Kalamatianos; K. Kordas; K. Kermanidis","Dept. of Inf., Ionian Univ., Corfu, Greece","2010 14th Panhellenic Conference on Informatics","20101021","2010","","","78","82","Prepositional phrase attachment is a major disambiguation problem when it's about parsing natural language, for many languages. In this paper a low resources policy is proposed using supervised machine learning algorithms in order to resolve the disambiguation problem of Prepositional phrase attachment in Modern Greek. It is a first attempt to resolve Prepositional phrase attachment in Modern Greek, without using sophisticated syntactic annotation and semantic resources. Also there are no restrictions regarding the prepositions addressed, as is common in previous approaches.","","Electronic:978-0-7695-4172-3; POD:978-1-4244-7838-5","10.1109/PCI.2010.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5600460","Decision Trees;Modern Greek;PP attachment;Supervised learning","Classification algorithms;Classification tree analysis;Feature extraction;Machine learning;Machine learning algorithms;Support vector machine classification;Syntactics","learning (artificial intelligence);natural language processing","disambiguation problem;low resources prepositional phrase attachment;natural language;supervised machine learning","","0","","14","","","10-12 Sept. 2010","","IEEE","IEEE Conference Publications"
"Automatic tuning of judgement parameter in continuous state exploitation-oriented learning","K. Miyazaki","Dept. of Assessment and Research for Degree Awarding, National Institution for Academic Degrees and University Evaluation, Kodaira, Tokyo, Japan","Proceedings of SICE Annual Conference 2010","20101014","2010","","","3246","3249","The rational policy making algorithm (PPM) and the penalty avoiding rational policy making algorithm (PARP) under continuous state spaces has important parameter that decides the same of basic functions. It is necessary to set an appropriate value through a preliminary experiment. In this paper, we propose an automatic tuning mechanism of the judgement parameter. We show the effectiveness of our proposal using a pole-cart problem.","","DVD:978-4-907764-35-7; Electronic:978-4-907764-36-4; POD:978-1-4244-7642-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602589","Continuous State Spaces;Exploitation-oriented Learning XoL;PARP;RPM;Reinforcement Learning","Algorithm design and analysis;Learning;Machine learning;Markov processes;Proposals;Tuning","decision making;learning (artificial intelligence)","automatic tuning mechanism;continuous state exploitation oriented learning;judgement parameter;penalty avoiding rational policy making algorithm;pole-cart problem","","0","","5","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"Online Learning and Acoustic Feature Adaptation in Large-Margin Hidden Markov Models","C. C. Cheng; F. Sha; L. K. Saul","Department of Computer Science and Engineering, University of California, San Diego","IEEE Journal of Selected Topics in Signal Processing","20101115","2010","4","6","926","942","We explore the use of sequential, mistake-driven updates for online learning and acoustic feature adaptation in large-margin hidden Markov models (HMMs). The updates are applied to the parameters of acoustic models after the decoding of individual training utterances. For large-margin training, the updates attempt to separate the log-likelihoods of correct and incorrect transcriptions by an amount proportional to their Hamming distance. For acoustic feature adaptation, the updates attempt to improve recognition by linearly transforming the features computed by the front end. We evaluate acoustic models trained in this way on the TIMIT speech database. We find that online updates for large-margin training not only converge faster than analogous batch optimizations, but also yield lower phone error rates than approaches that do not attempt to enforce a large margin. Finally, experimenting with different schemes for initialization and parameter-tying, we find that acoustic feature adaptation leads to further improvements beyond the already significant gains achieved by large-margin training.","1932-4553;19324553","","10.1109/JSTSP.2010.2048607","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451105","Acoustic feature adaptation;automatic speech recognition (ASR);discriminative training;hidden Markov models (HMMs);large-margin classification;online learning","Automatic speech recognition;Computer science;Error analysis;Hidden Markov models;Machine learning algorithms;Management training;Maximum likelihood estimation;Parameter estimation;Permission;Training data","hidden Markov models;maximum likelihood estimation;speech recognition","Hamming distance;TIMIT speech database;acoustic feature adaptation;discriminative training;large-margin hidden Markov models;online learning","","2","","56","","20100419","Dec. 2010","","IEEE","IEEE Journals & Magazines"
"Coclustering Multiple Heterogeneous Domains: Linear Combinations and Agreements","G. Greco; A. Guzzo; L. Pontieri","University of Calabria, Rende","IEEE Transactions on Knowledge and Data Engineering","20101028","2010","22","12","1649","1663","The high-order coclustering problem, i.e., the problem of simultaneously clustering heterogeneous types of domain, has become an active research area in the last few years, due to the notable impact it has on several application scenarios. This problem is generally faced by optimizing a weighted combination of functions measuring the quality of coclustering over each pair of domains, where weights are chosen based on the supposed reliability/relevance of their correlation. However, little knowledge is likely to be available, in practice, in order to set these weights in a definite and precise manner. And, more importantly, it might even be conceptually unclear whether to prefer a weighing scheme over others, in those cases where functions encode contrasting goals so that improving the quality for a pair of domains leads to a deterioration for other pairs. The aim of this paper is precisely to shed light on the impact of weighting schemes on techniques based on linear combinations of pairwise objective functions, and to define an approach that overcomes the above problems by looking for an agreement-intuitively, a kind of compromise-among the various domains, thereby getting rid of the need to define an appropriate weighting scheme. Two algorithms performing coclustering on ""star-structured” domains, based on linear combinations and agreements, respectively, have been designed within an information-theoretic framework. Results from a thorough experimentation, on both synthetic and real data, are discussed, in order to assess the effectiveness of the approaches and to get more insight into their actual behavior.","1041-4347;10414347","","10.1109/TKDE.2009.207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342422","Data mining;coclustering;contingency table analysis.","Algorithm design and analysis;Bipartite graph;Encoding;Information theory;Machine learning;Mutual information;Pairwise error probability;Particle measurements;Probability distribution","pattern clustering","compromise agreement;high-order coclustering problem;linear combinations;multiple heterogeneous domain coclustering;pairwise objective functions;weighting schemes","","5","","32","","20091201","Dec. 2010","","IEEE","IEEE Journals & Magazines"
"An Automated Solution to the Multiuser Carved Data Ascription Problem","S. L. Garfinkel; A. Parker-Wood; D. Huynh; J. Migletz","Department of Computer Science, Naval Postgraduate School, Pacific Grove, CA, USA","IEEE Transactions on Information Forensics and Security","20101115","2010","5","4","868","882","This paper presents a novel solution to the problem of determining the ownership of carved information found on disk drives and other storage media that have been used by more than one person. When a computer is subject to forensic examination, information may be found that cannot be readily ascribed to a specific user. Such information is typically not located in a specific file or directory, but is found through file carving, which recovers data from unallocated disk sectors. Because the data is carved, it does not have associated file system metadata, and its owner cannot be readily ascertained. The technique presented in this paper starts by automatically recovering both file system metadata as well as extended metadata embedded in files (for instance, embedded timestamps) directly from a disk image. This metadata is then used to find exemplars and to create a machine learning classifier that can be used to ascertain the likely owner of the carved data. The resulting classifier is well suited for use in a legal setting since the accuracy can be easily verified using cross-validation. Our technique also results in a classifier that is easily validated by manual inspection. We report results of the technique applied to both specific hard drive data created in our laboratory and multiuser drives that we acquired on the secondary market. We also present a tool set that automatically creates the classifier and performs validation.","1556-6013;15566013","","10.1109/TIFS.2010.2060484","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5518429","Data mining;forensics;information security","Disk drives;Educational institutions;File systems;Forensics;Inspection;Law;Legal factors;Machine learning;Manuals;Permission","computer forensics;data handling;file organisation;learning (artificial intelligence);meta data;pattern classification;storage management","associated file system metadata;disk drives;disk image;file carving;forensic examination;machine learning classifier;multiuser carved data ascription problem;storage media;unallocated disk sectors","","6","","20","","20100723","Dec. 2010","","IEEE","IEEE Journals & Magazines"
"Transferred correlation learning: An incremental scheme for neural network ensembles","L. Jiang; J. Zhang; G. Allen","Department of Computer Science, Louisiana State University, Baton Rouge, 70803, USA","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","Transfer learning is a new learning paradigm, in which, besides the training data for the targeted learning task, data that are related to the task (often under a different distribution) are also employed to help train a better learner. For example, out-dated data can be used as such related data. In this paper, we propose a new transfer learning framework for training neural network (NN) ensembles. The framework has two key features: 1) it uses the well-known negative correlation learning to train an ensemble of diverse neural networks from the related data, fully discovering the knowledge in the data; and 2) a penalized incremental learning scheme is used to adapt the neural networks obtained from negative correlation learning to the training data for the targeted learning task. The adaptation is guided by reference neural networks that measure the relatedness between the training and the related data. Experiments on benchmark data sets show that our framework can achieve classification accuracy competitive to existing ensemble transfer learning methods such as TrAdaBoost and TrBagg. We discuss some characteristics of our framework observed in the experiment and the scenarios under which the framework may have superior performance.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596617","","Accuracy;Artificial neural networks;Correlation;Degradation;Machine learning;Training;Training data","data mining;learning (artificial intelligence);neural nets;pattern classification","TrAdaBoost;TrBagg;incremental learning scheme;knowledge discovery;training neural network ensembles;transferred correlation learning;well-known negative correlation learning","","4","","23","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"An Improved Structural EM to Learn Dynamic Bayesian Nets","C. P. de Campos; Z. Zeng; Q. Ji","","2010 20th International Conference on Pattern Recognition","20101007","2010","","","601","604","This paper addresses the problem of learning structure of Bayesian and Dynamic Bayesian networks from incomplete data based on the Bayesian Information Criterion. We describe a procedure to map the problem of the dynamic case into a corresponding augmented Bayesian network through the use of structural constraints. Because the algorithm is exact and anytime, it is well suitable for a structural Expectation-Maximization (EM) method where the only source of approximation is due to the EM itself. We show empirically that the use a global maximizer inside the structural EM is computationally feasible and leads to more accurate models.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597455","","Approximation algorithms;Approximation methods;Bayesian methods;Equations;Machine learning;Uncertainty","Bayes methods;expectation-maximisation algorithm","Bayesian information criterion;augmented Bayesian network;dynamic Bayesian network;global maximizer;learning structure;structural constraints;structural expectation-maximization;structural method","","0","","7","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"TCFOM: A Robust Traffic Classification Framework Based on OC-SVM Combined with MC-SVM","G. Lu; H. Zhang; X. Sha; C. Chen; L. Peng","Dept. of Comput. Sci., Harbin Inst. of Technol., Harbin, China","2010 International Conference on Communications and Intelligence Information Security","20101111","2010","","","180","186","New application traffic occurring on Internet frequently challenges the traditional traffic classifiers based on machine learning. These classifiers always identify it inaccurately and assign it into one of their known classes forcibly, even though the extra class is labeled as 'other' when training. In this case, the precision of identifying known classes is reduced. In this paper, a robust traffic classification framework based on OC-SVM combined with MC-SVM (TCFOM) is presented. We capture several kinds of application traffic, and carry out an experiment under supervised environment. Using the OC-SVM, the unknown traffic is classified into extra class labeled as 'other'. The precision of identifying known traffic is improved. Using the unknown traffic identified, the new classifying model is set up. TCFOM can classify the unknown traffic and extend well. We compare TCFOM with three classifiers respectively based on SVM, RBF network, Naive Bayes. Experimental results show that the robustness of TCFOM is best.","","Electronic:978-0-7695-4260-7; POD:978-1-4244-8649-6","10.1109/ICCIIS.2010.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5629219","MC-SVM;OC-SVM;TCFOM;robust;traffic classification","Classification algorithms;Machine learning algorithms;Noise;Support vector machines;Testing;Training;World Wide Web","Internet;pattern classification;radial basis function networks;support vector machines;telecommunication traffic","Internet;MC-SVM;OC-SVM;RBF network;TCFOM;multiple classes support vector machine;network traffic classification framework;one-class support vector machine;traffic classifiers","","1","","18","","","13-14 Oct. 2010","","IEEE","IEEE Conference Publications"
"Random Prototype-based Oracle for Selection-fusion Ensembles","G. Armano; N. Hatami","DIEE-Dept. of Electr. & Electron. Eng., Univ. of Cagliari, Cagliari, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","77","80","Classifier ensembles based on selection-fusion strategy have recently aroused enormous interest. The main idea underlying this strategy is to use miniensembles instead of monolithic base classifiers in an ensemble in order to improve the overall performance. This paper proposes a classifier selection method to be used in selection-fusion strategies. The method involves first splitting the original classification problem according to some prototypes randomly selected from training data, and then building a classifier on each subset. The trained classifiers, together with an oracle used to switch between them, form a miniensemble of classifier selection. With respect to the other methods used in the selection-fusion framework, the proposed method has proven to be more efficient in the decomposition process with no limitation in the number of resulting partitions. Experimental results on some datasets from the UCI repository show the validity of the proposed method.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597632","Classification;Combining classifiers;Ensemble learning","Accuracy;Classification algorithms;Iris;Machine learning;Prototypes;Support vector machines;Training","pattern classification","UCI repository;classifier ensembles;monolithic base classifiers;random prototype based oracle;selection fusion ensembles;selection fusion strategy","","0","","9","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Semi-Supervised Learning via Regularized Boosting Working on Multiple Semi-Supervised Assumptions","K. Chen; S. Wang","The University of Manchester, Manchester","IEEE Transactions on Pattern Analysis and Machine Intelligence","20101118","2011","33","1","129","143","Semi-supervised learning concerns the problem of learning in the presence of labeled and unlabeled data. Several boosting algorithms have been extended to semi-supervised learning with various strategies. To our knowledge, however, none of them takes all three semi-supervised assumptions, i.e., smoothness, cluster, and manifold assumptions, together into account during boosting learning. In this paper, we propose a novel cost functional consisting of the margin cost on labeled data and the regularization penalty on unlabeled data based on three fundamental semi-supervised assumptions. Thus, minimizing our proposed cost functional with a greedy yet stagewise functional optimization procedure leads to a generic boosting framework for semi-supervised learning. Extensive experiments demonstrate that our algorithm yields favorite results for benchmark and real-world classification tasks in comparison to state-of-the-art semi-supervised learning algorithms, including newly developed boosting algorithms. Finally, we discuss relevant issues and relate our algorithm to the previous work.","0162-8828;01628828","","10.1109/TPAMI.2010.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444873","Semi-supervised learning;boosting framework;cluster assumption;manifold assumption;regularization.;smoothness assumption","Boosting;Clustering algorithms;Cost function;Data mining;Machine learning;Machine learning algorithms;Manifolds;Semisupervised learning;Supervised learning;Unsupervised learning","costing;learning (artificial intelligence);optimisation;pattern classification","boosting algorithm;boosting learning;cluster assumption;cost functional;generic boosting framework;labeled data;manifold assumption;margin cost;multiple semisupervised assumption;real world classification task;regularization penalty;regularized boosting;semisupervised learning;smoothness assumption;stagewise functional optimization;unlabeled data","Algorithms;Artificial Intelligence;Cluster Analysis;Learning;Pattern Recognition, Automated","45","1","43","","20100408","Jan. 2011","","IEEE","IEEE Journals & Magazines"
"Pseudo fuzzy clustering derived from Fisher criterions","S. Xuan; Y. Liu","College of Computer, Sichuan University, Chengdu, China, 610065","2010 3rd International Congress on Image and Signal Processing","20101129","2010","4","","1914","1918","This paper describes a new revised clustering algorithm in which each cluster center derived from the revised mean of a subclass in previous recursion. This modification factors make up with the mean of the cluster center in previous recursion multiplied with a coefficient polynomial. This computing center formula is derived from Fisher criteria. Experimental results show that the proposed clustering algorithm outperforms several other state of the art methods. It enjoys all advantage of K-means algorithm, and possesses faster running speed than kernel-based methods.","","Electronic:978-1-4244-6516-3; POD:978-1-4244-6513-2","10.1109/CISP.2010.5647601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5647601","Clustering;FCM;Fisher criteria;revised K-means","Accuracy;Algorithm design and analysis;Classification algorithms;Clustering algorithms;Machine learning algorithms;Pattern recognition;Tuning","fuzzy set theory;pattern clustering;polynomials","Fisher criteria;K-means algorithm;coefficient polynomial;pseudo fuzzy clustering","","0","","24","","","16-18 Oct. 2010","","IEEE","IEEE Conference Publications"
"Weighting imputation methods and their evaluation under shell-neighbor machine","S. Zhang; M. Zhu","Department of Computer Science, Zhejiang Normal University, China","Cognitive Informatics (ICCI), 2010 9th IEEE International Conference on","20101011","2010","","","874","879","The paper studies three typical weighting strategies for Shell-Neighbor Imputation (SNI) algorithm, while there are many weighting modes that can be used in the SNI. To best capture the imputation efficiency, a new metrics, called goodess, is proposed for evaluating imputation algorithms. We conduct some experiments for examining the proposed approached, and demonstrate that (1) distance-frequency-weighting strategy is the best one for the shell-neighbor imputation; (2) the goodness is much better than the RMSE if there is a few individual values of serious deviation, otherwise, the goodness is the same as the RMSE at measuring the imputation efficiency.","","Electronic:978-1-4244-8042-5; POD:978-1-4244-8041-8","10.1109/COGINF.2010.5599790","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599790","Missing data imputation;Shell-Neighbor imputation;k nearest neighbor imputation","Accuracy;Algorithm design and analysis;Data mining;Estimation;Machine learning algorithms;Nearest neighbor searches;Prediction algorithms","learning (artificial intelligence);pattern classification","RMSE;SNI algorithm;distance-frequency-weighting strategy;goodess;imputation algorithm evaluation;k-nearest neighbor imputation;shell-neighbor machine algorithm;weighting imputation methods","","0","","22","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Semisupervised Kernel Matrix Learning by Kernel Propagation","E. Hu; S. Chen; D. Zhang; X. Yin","Department of Mathematics, Yunnan Normal University, Kunming, China","IEEE Transactions on Neural Networks","20101101","2010","21","11","1831","1841","The goal of semisupervised kernel matrix learning (SS-KML) is to learn a kernel matrix on all the given samples on which just a little supervised information, such as class label or pairwise constraint, is provided. Despite extensive research, the performance of SS-KML still leaves some space for improvement in terms of effectiveness and efficiency. For example, a recent pairwise constraints propagation (PCP) algorithm has formulated SS-KML into a semidefinite programming (SDP) problem, but its computation is very expensive, which undoubtedly restricts PCPs scalability in practice. In this paper, a novel algorithm, called kernel propagation (KP), is proposed to improve the comprehensive performance in SS-KML. The main idea of KP is first to learn a small-sized sub-kernel matrix (named seed-kernel matrix) and then propagate it into a larger-sized full-kernel matrix. Specifically, the implementation of KP consists of three stages: 1) separate the supervised sample (sub)set from the full sample set ; 2) learn a seed-kernel matrix on through solving a small-scale SDP problem; and 3) propagate the learnt seed-kernel matrix into a full-kernel matrix on . Furthermore, following the idea in KP, we naturally develop two conveniently realizable out-of-sample extensions for KML: one is batch-style extension, and the other is online-style extension. The experiments demonstrate that KP is encouraging in both effectiveness and efficiency compared with three state-of-the-art algorithms and its related out-of-sample extensions are promising too.","1045-9227;10459227","","10.1109/TNN.2010.2076301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593883","Kernel propagation;out-of-sample extension;pairwise constraint;seed-kernel matrix learning;semidefinite programming","Accuracy;Kernel;Laplace equations;Machine learning;Programming;Propagation;Supervised learning","learning (artificial intelligence);matrix algebra","batch-style extension;kernel propagation;larger-sized full-kernel matrix;online-style extension;pairwise constraint propagation algorithm;seed-kernel matrix;semidefinite programming;semisupervised kernel matrix learning;small-sized sub-kernel matrix","Algorithms;Artificial Intelligence;Mathematical Computing;Neural Networks (Computer);Normal Distribution;Programming Languages;Software Design","17","","28","","20101004","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"A comparative study of urban traffic signal control with reinforcement learning and Adaptive Dynamic Programming","Y. Dai; D. Zhao; J. Yi","Laboratory of Complex Systems and Intelligence Science, Institute of Automation, Chinese Academy of Sciences. No.95 Zhongguancun East Road, Haidian District, Beijing 100190, China","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","7","This paper proposes a new algorithm that employs Adaptive Dynamic Programming(ADP) to solve the distributed control problem of urban traffic with an infinite horizon. Urban traffic congestions lead to a lot of time consumption and exhaust emissions. So alleviating congested situation will have a good impact on both economy and environment. The signal control at urban intersections is an effective and most important way to reduce the traffic jams and collisions. A lot of control theories including traditional mathematical ways and modern artificial intelligent ways have been exploited. ADP is an effective and amiable intelligent control method. We proposed an algorithm to adjust the signal time plan at urban traffic intersections based on ADP theory. Simulations are taken under a microscopic traffic simulation software, TSIS(Traffic Software Integrated System). Several criteria named MOEs(Measures of Effectiveness) are collected to compare with the widely used pre-timed control, actuated control, also with a machine learning method Q-learning control. Results show that ADP control method have a better adaptability to the various traffic simulating real traffic flows.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596480","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596480","","Dynamic programming;Green products;Heuristic algorithms;Machine learning algorithms;Software;Software algorithms;Vehicles","dynamic programming;learning (artificial intelligence);traffic control;traffic engineering computing","Q-learning control;adaptive dynamic programming;artificial intelligent;machine learning method;microscopic traffic simulation software;reinforcement learning;traffic software integrated system;urban traffic congestion;urban traffic signal control","","8","","18","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Paper Bagging ensemble based on fuzzy c-means","J. Zhang; H. Zhang","Department of Information Science and Engineering, Shandong Normal University, Jinan, China","2010 3rd International Congress on Image and Signal Processing","20101129","2010","4","","1828","1831","Based on fuzzy clustering, a new ensemble method of Bagging F-Bagging is proposed in this paper. Firstly the training data are clustered using fuzzy clustering, and then according to the matrix, dividing the training samples into subset intersect, at last each subset of the data are trained, and proper weighted method is used to base learners. As each subset contains different categories and different training data, thus the members of the classifier are diverse. The number of subsets determines the number of the base learners. Experimental results show that this approach can achieve good results.","","Electronic:978-1-4244-6516-3; POD:978-1-4244-6513-2","10.1109/CISP.2010.5646812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5646812","Ensemble classifier;diversity;fuzzy clustering;membership matrix","Bagging;Classification algorithms;Clustering algorithms;Machine learning;Signal processing algorithms;Training;Training data","fuzzy set theory;learning (artificial intelligence);matrix algebra;pattern classification;pattern clustering","F-Bagging;base learner;classifier member;data sample;fuzzy c-means clustering;matrix method;paper bagging ensemble;subset method","","0","","14","","","16-18 Oct. 2010","","IEEE","IEEE Conference Publications"
"Threshold learning in the improved penalty avoiding rational policy making algorithm","K. Miyazaki; R. Kobayashi; H. Kobayashi","Dept. of Assessment and Research, for Degree Awarding, National Institution for Academic, Degrees and University Evaluation, Kodaira, Tokyo, Japan","Proceedings of SICE Annual Conference 2010","20101014","2010","","","3240","3245","The penalty avoiding rational policy making algorithm (PARP) previously improved to save memory and cope with uncertainty, i.e., Improved PARP (IPARP). The efficiency of IPARP is influenced by threshold of a penalty rule or a penalty basis function γ significantly. In this paper, we propose a technique for learning γ. We show the effectiveness of our proposal using a soccer game task called “Keepaway”.","","DVD:978-4-907764-35-7; Electronic:978-4-907764-36-4; POD:978-1-4244-7642-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602796","Exploitation-oriented Learning XoL;Improved PARP;Keepaway Task;Reinforcement Learning;Threshold Learning","Function approximation;Games;Machine learning;Memory management;Proposals;Tiles;Uncertainty","game theory;learning (artificial intelligence)","PARP;keepaway;penalty avoiding rational policy making algorithm;soccer game;threshold learning","","0","","10","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"Online Support Vector Regression With Varying Parameters for Time-Dependent Data","O. A. Omitaomu; M. K. Jeong; A. B. Badiru","Computational Sciences and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, USA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20101109","2011","41","1","191","197","Support vector regression (SVR) is a machine learning technique that continues to receive interest in several domains, including manufacturing, engineering, and medicine. In order to extend its application to problems in which data sets arrive constantly and in which batch processing of the data sets is infeasible or expensive, an accurate online SVR (AOSVR) technique was proposed. The AOSVR technique efficiently updates a trained SVR function whenever a sample is added to or removed from the training set without retraining the entire training data. However, the AOSVR technique assumes that the new samples and the training samples are of the same characteristics; hence, the same value of SVR parameters is used for training and prediction. This assumption is not applicable to data samples that are inherently noisy and nonstationary, such as sensor data. As a result, we propose AOSVR with varying parameters that uses varying SVR parameters rather than fixed SVR parameters and hence accounts for the variability that may exist in the samples. To accomplish this objective, we also propose a generalized weight function to automatically update the weights of SVR parameters in online monitoring applications. The proposed function allows for lower and upper bounds for SVR parameters. We tested our proposed approach and compared results with the conventional AOSVR approach using two benchmark time-series data and sensor data from a nuclear power plant. The results show that using varying SVR parameters is more applicable to time-dependent data.","1083-4427;10834427","","10.1109/TSMCA.2010.2055156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5545414","Condition monitoring;inferential sensing;online prediction;support vector machine;system diagnosis","Accuracy;Automobile manufacture;Condition monitoring;Data engineering;Machine learning;Manufacturing;Medical diagnostic imaging;Monitoring;Power generation;Sensor systems;Sensors;Systems engineering and theory;Training;Training data;Upper bound","computerised monitoring;learning (artificial intelligence);regression analysis;support vector machines","generalized weight function;machine learning technique;online monitoring application;online support vector regression;time-dependent data;trained SVR function","","15","","16","","20100809","Jan. 2011","","IEEE","IEEE Journals & Magazines"
"A Novel Hybrid Algorithm Based on Baldwinian Learning and PSO","W. Wang; L. Chen; J. Jie; H. Wang; X. Xu","Coll. of Comput. Sci. & Technol., Zhejiang Univ. of Technol., Hangzhou, China","2010 International Conference on Computational Aspects of Social Networks","20101115","2010","","","299","302","In the paper, a novel hybrid algorithm based on Baldwinian learning and PSO (BLPSO) is proposed to increase the diversity of the particles and to prevent premature convergence of PSO. Firstly, BLPSO adopts the Baldwinian operator to simulate the learning mechanism among the particles and employs the information of the swarm to alter the search space adaptively. Secondly, a mutation operation is introduced to make the particles leap the local optimum and enhance the chance to find out the global optimum. Finally, the proposed BLPSO is used to solve some complex optimization problems, the experiment results illustrate the efficiency of the proposed method.","","Electronic:978-0-7695-4202-7; POD:978-1-4244-8785-1","10.1109/CASoN.2010.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5636708","Baldwinian learning;Hybrid algorithm;Particle swarm optimization","Acceleration;Algorithm design and analysis;Artificial neural networks;Convergence;Machine learning algorithms;Optimization;Particle swarm optimization","learning (artificial intelligence);particle swarm optimisation","Baldwinian learning;Baldwinian operator;PSO;complex optimization problem;hybrid algorithm;learning mechanism;mutation operation;search space","","0","","11","","","26-28 Sept. 2010","","IEEE","IEEE Conference Publications"
"Constraint-based semi-supervised dimensionality reduction with conflict detection","B. Chen; Q. Bai","School of Mathematics and Computer Science, Fuzhou University, China","2010 3rd International Conference on Biomedical Engineering and Informatics","20101118","2010","7","","3036","3040","Most existing typical semi-supervised learning algorithms focused on the results of learning while facing the conflict on constraints. And most solutions use unsupervised distance-based methods to adjust the conflicting constraints on the information by recalculating the samples' distance. This paper presents a constraint-based semi-supervised dimensionality reduction algorithm with conflict detection, called CDSSDR, which uses the information of priori constraints to adjust the contradictions in the constraints. It avoids the use of unsupervised methods to adjust the prior knowledge.","1948-2914;19482914","Electronic:978-1-4244-6498-2; POD:978-1-4244-6495-1","10.1109/BMEI.2010.5639901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5639901","SSDR;adjustment of constraints;clustering analysis;conflict detection;semi-supervised learning","Accuracy;Algorithm design and analysis;Clustering algorithms;Data mining;Machine learning;Software;Symmetric matrices","learning (artificial intelligence)","conflict detection;constraint-based semisupervised dimensionality reduction;semisupervised learning algorithms;unsupervised distance-based methods","","0","","15","","","16-18 Oct. 2010","","IEEE","IEEE Conference Publications"
"Anomaly, novelty, one-class classification: A short introduction","A. M. Bartkowiak","Institute of Computer Science, University of Wroclaw, Joliot-Curie 15, 50-383, Poland","2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM)","20101122","2010","","","1","6","In data analysis and decision making we need frequently to judge whether the observed data items are normal or abnormal. This happens in banking, credit card use, diagnosing a patients health state, fault detection in an engine or device like an off-shore oil platform or gearbox in an airplane motor. Sometimes the normal cases are boring and only the abnormal cases are of interest (anomaly hunting). In practice, it happens quite frequently that the normal state has a good representation, however the abnormal cases are rare and the abnormal class is ill-defined - then we have to judge on the abnormality using information from the normal class only. The problem is named `one-class classification' (OCC). The paper gives a survey of methods for performing the OCC. There is also an example: how to detect a masquerader (non-legitimate user) in a computer system - when observing a sequence of commands several thousands long.","","Electronic:978-1-4244-7818-7; POD:978-1-4244-7817-0","10.1109/CISIM.2010.5643699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643699","Schonlau's masquerade data;anomaly detection;intrusion detection;object classification and recognition;one-class classification","Artificial neural networks;Computers;Data models;Hidden Markov models;Machine learning;Monitoring;Signal processing","data analysis;decision making;pattern classification","data analysis;decision making;one-class classification","","5","","34","","","8-10 Oct. 2010","","IEEE","IEEE Conference Publications"
"Intellectual information circle based on bayes algorithm","Guodong Li; Liangjun Wen","School of Control and Computer Engineering, North China Electric Power University, Beijing, China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","20101104","2010","9","","V9-665","V9-667","In this paper,the concept of intellectual information circle is presented,because of the poor accuracy rate about searching informarion in this circle,an approach of classification about information based on bayes algorithm is discussed. The result of the experiment shows that comparing with the old system, the apply of bayes algorithm for the intellectual information circle improves the accuracy of information searching and obtains a better user experience.","2161-9069;21619069","Electronic:978-1-4244-7237-6; POD:978-1-4244-7235-2","10.1109/ICCASM.2010.5622946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5622946","Navie Bayes;data mining;intellectual information circle","Accuracy;Bayesian methods;Classification algorithms;Data mining;Databases;Machine learning;Modeling","Bayes methods;data mining;information retrieval;pattern classification","Bayes algorithm;information searching;intellectual information circle;user experience","","0","","8","","","22-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Data-Driven Approaches to Community-Contributed Video Applications","X. Wu; C. W. Ngo; W. L. Zhao","Southwest Jiaotong University","IEEE MultiMedia","20101115","2010","17","4","58","69","In this article, we explore near-duplicate Web video detection, video annotation, and video classification using a data-driven framework, by exploiting different aspects derived from contextual and social resources.","1070-986X;1070986X","","10.1109/MMUL.2010.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5499456","Web video;annotation;categorization;data-driven;near-duplicate detection;social Web","Application software;Computer science;Data engineering;Large-scale systems;Machine learning;Management training;Support vector machine classification;Support vector machines;Video sharing;YouTube","Web sites;data mining;social networking (online);video retrieval","community contributed video;data driven framework;near duplicate Web video detection;social resource;video annotation;video classification","","3","","10","","20100701","Oct.-Dec. 2010","","IEEE","IEEE Journals & Magazines"
"A Gaussian Process Regression Framework for Spatial Error Concealment with Adaptive Kernels","H. Asheri; H. R. Rabiee; N. Pourdamghani; M. H. Rohban","","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4541","4544","We have developed a Gaussian Process Regression method with adaptive kernels for concealment of the missing macro-blocks of block-based video compression schemes in a packet video system. Despite promising results, the proposed algorithm introduces a solid framework for further improvements. In this paper, the problem of estimating lost macro-blocks will be solved by estimating the proper covariance function of the Gaussian process defined over a region around the missing macro-blocks (i.e. its kernel function). In order to preserve block edges, the kernel is constructed adaptively by using the local edge related information. Moreover, we can achieve more improvement by local estimation of the kernel parameters. While restoring the prominent edges of the missing macro-blocks, the proposed method produces perceptually smooth concealed frames. Objective and subjective evaluations verify the effectiveness of the proposed method.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597367","Adaptive kernels;Gaussian Process Regression;Spatial Error Concealment","Bismuth;Estimation;Gaussian processes;Interpolation;Kernel;Machine learning;Pixel","Gaussian processes;covariance analysis;data compression;regression analysis;video coding","Gaussian process regression method;adaptive kernels;block-based video compression;covariance function;local edge related information;missing macro-blocks concealment;packet video system;spatial error concealment","","4","","18","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Policy Generation Framework for Large-Scale Storage Infrastructures","R. Routray; R. Zhang; D. Eyers; D. Willcocks; P. Pietzuch; P. Sarkar","","2010 IEEE International Symposium on Policies for Distributed Systems and Networks","20101111","2010","","","65","72","Cloud computing is gaining acceptance among mainstream technology users. Storage cloud providers often employ Storage Area Networks (SANs) to provide elasticity, rapid adaptability to changing demands, and policy based automation. As storage capacity grows, the storage environment becomes heterogeneous, increasingly complex, harder to manage, and more expensive to operate. This paper presents PGML (Policy Generation for largescale storage infrastructure configuration using Machine Learning), an automated, supervised machine learning framework for generation of best practices for SAN configuration that can potentially reduce configuration errors by up to 70% in a data center. A best practice or policy is nothing but a technique, guideline or methodology that, through experience and research, has proven to lead reliably to a better storage configuration. Given a standards-based representation of SAN management information, PGML builds on the machine learning constructs of inductive logic programming (ILP) to create a transparent mapping of hierarchical, object-oriented management information into multi-dimensional predicate descriptions. Our initial evaluation of PGML shows that given an input of SAN problem reports, it is able to generate best practices by analyzing these reports. Our simulation results based on extrapolated real-world problem scenarios demonstrate that ILP is an appropriate choice as a machine learning technique for this problem.","","Electronic:978-0-7695-4238-6; POD:978-1-4244-8206-1","10.1109/POLICY.2010.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630198","","Best practices;Computer integrated manufacturing;Databases;Fabrics;Machine learning;Servers;Storage area networks","inductive logic programming;learning (artificial intelligence);object-oriented programming;storage area networks;storage management","cloud computing;inductive logic programming;large-scale storage infrastructures;machine learning;object-oriented management;policy generation framework;standards-based representation;storage area networks;storage cloud providers","","3","","39","","","21-23 July 2010","","IEEE","IEEE Conference Publications"
"Correntropy-based density-preserving data sampling as an alternative to standard cross-validation","M. Budka; B. Gabrys","Computational Intelligence Research Group, Bournemouth University, School of Design, Engineering and Computing, Poole House, Talbot Campus, Fern Barrow, BH12 5BB, United Kingdom","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","Estimation of the generalization ability of a predictive model is an important issue, as it indicates expected performance on previously unseen data and is also used for model selection. Currently used generalization error estimation procedures like cross-validation (CV) or bootstrap are stochastic and thus require multiple repetitions in order to produce reliable results, which can be computationally expensive if not prohibitive. The correntropy-based Density Preserving Sampling procedure (DPS) proposed in this paper eliminates the need for repeating the error estimation procedure by dividing the available data into subsets, which are guaranteed to be representative of the input dataset. This allows to produce low variance error estimates with accuracy comparable to 10 times repeated cross-validation at a fraction of computations required by CV, which has been investigated using a set of publicly available benchmark datasets and standard classifiers.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596717","","Entropy;Error analysis;Estimation;Kernel;Machine learning;Mathematical model;Training","data analysis;entropy;generalisation (artificial intelligence);learning (artificial intelligence);sampling methods","correntropy-based density-preserving data sampling;cross-validation;generalization ability;generalization error estimation;low variance error estimate;model selection;predictive model","","1","","21","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Semisupervised Feature Selection for Unbalanced Sample Sets of VHR Images","X. Chen; T. Fang; H. Huo; D. Li","Institute of Image Processing and Pattern Recognition, Automation Department, Shanghai Jiao Tong University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","20101011","2010","7","4","781","785","A semisupervised feature selection method, named asymmetrically local discriminant selection (ALDS), is proposed to evaluate the class separability of unbalanced sample sets from very high resolution (VHR) imagery in an object-oriented classification. In order to cope with class imbalance, ALDS incorporates asymmetric misclassification costs of classes into weight matrices. Furthermore, this method locally exploits multiple kinds of relationships between sample pairs to more accurately assess the ability of features in preserving the geometrical and discriminant structures. The experimental results on VHR satellite and airborne imagery attest to the effectiveness and practicability of ALDS.","1545-598X;1545598X","","10.1109/LGRS.2010.2048197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473140","Asymmetrically local discriminant selection (ALDS);class imbalance;graph-based filter model;objectoriented classification;semisupervised feature selection","Costs;Face recognition;Filters;Image processing;Image resolution;Machine learning;Object oriented modeling;Remote sensing;Research and development;Satellites","image classification;remote sensing","VHR images;VHR satellite;airborne imagery;asymmetric misclassification costs;asymmetrically local discriminant selection;class imbalance;class separability;discriminant structures;geometrical structures;object-oriented classification;semisupervised feature selection;unbalanced sample sets;very high resolution imagery;weight matrices","","9","","14","","20100527","Oct. 2010","","IEEE","IEEE Journals & Magazines"
"Semi-Supervised Classification via Local Spline Regression","S. Xiang; F. Nie; C. Zhang","Chinese Academy of Sciences, Beijing","IEEE Transactions on Pattern Analysis and Machine Intelligence","20101101","2010","32","11","2039","2053","This paper presents local spline regression for semi-supervised classification. The core idea in our approach is to introduce splines developed in Sobolev space to map the data points directly to be class labels. The spline is composed of polynomials and Green's functions. It is smooth, nonlinear, and able to interpolate the scattered data points with high accuracy. Specifically, in each neighborhood, an optimal spline is estimated via regularized least squares regression. With this spline, each of the neighboring data points is mapped to be a class label. Then, the regularized loss is evaluated and further formulated in terms of class label vector. Finally, all of the losses evaluated in local neighborhoods are accumulated together to measure the global consistency on the labeled and unlabeled data. To achieve the goal of semi-supervised classification, an objective function is constructed by combining together the global loss of the local spline regressions and the squared errors of the class labels of the labeled data. In this way, a transductive classification algorithm is developed in which a globally optimal classification can be finally obtained. In the semi-supervised learning setting, the proposed algorithm is analyzed and addressed into the Laplacian regularization framework. Comparative classification experiments on many public data sets and applications to interactive image segmentation and image matting illustrate the validity of our method.","0162-8828;01628828","","10.1109/TPAMI.2010.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401168","Semi-supervised classification;interactive image segmentation.;local spline regression","Image segmentation;Iterative algorithms;Labeling;Laplace equations;Machine learning;Machine learning algorithms;Polynomials;Semisupervised learning;Spline;Web pages","image segmentation;learning (artificial intelligence);least squares approximations;regression analysis;splines (mathematics)","Greens functions;Laplacian regularization;Sobolev space;image matting;image segmentation;least squares regression;local spline regression;scattered data points;semi supervised classification;transductive classification algorithm","Algorithms;Animals;Artificial Intelligence;Cluster Analysis;Databases, Factual;Humans;Image Processing, Computer-Assisted;Least-Squares Analysis;Pattern Recognition, Automated","53","","60","","20100129","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"Margin Preserved Approximate Convex Hulls for Classification","T. Takahashi; M. Kudo","Grad. Sch., Hokkaido Univ., Sapporo, Japan","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4052","4055","The usage of convex hulls for classification is discussed with a practical algorithm, in which a sample is classified according to the distances to convex hulls. Sometimes convex hulls of classes are too close to keep a large margin. In this paper, we discuss a way to keep a margin larger than a specified value. To do this, we introduce a concept of ""expanded convex hull"" and confirm its effectiveness.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597394","Convex hull;Margin;Pattern recognition","Approximation algorithms;Glass;Kernel;Machine learning;Pattern recognition;Support vector machines;Training","pattern classification","expanded convex hull;margin preserved approximate convex hulls;sample classification","","1","","10","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"AUC-based Combination of Dichotomizers: Is Whole Maximization also Effective for Partial Maximization?","M. T. Ricamato; F. Tortorella","Univ. degli Studi di Cassino, Cassino, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","73","76","The combination of classifiers is an established technique to improve the classification performance. When dealing with two-class classification problems, a frequently used performance measure is the Area under the ROC curve (AUC) since it is more effective than accuracy. However, in many applications, like medical or biometric ones, tests with false positive rate over a given value are of no practical use and thus irrelevant for evaluating the performance of the system. In these cases, the performance should be measured by looking only at the interesting part of the ROC curve. Consequently, the optimization goal is to maximize only a part of the AUC instead of the whole area. In this paper we propose a method tailored for these situations which builds a linear combination of two dichotomizers maximizing the partial AUC (pAUC). Another aim of the paper is to understand if methods that maximize the AUC can maximize also the pAUC. An empirical comparison drawn between algorithms maximizing the AUC and the proposed method shows that this latter is more effective for the pAUC maximization than methods designed to globally optimize the AUC.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597631","Area under the ROC Curve;Combination of Classifiers","Accuracy;Algorithm design and analysis;Indexes;Machine learning;Machine learning algorithms;Manganese;Optimized production technology","optimisation;pattern classification","classification performance;dichotomizers;optimization goal;partial area under the ROC curve;partial maximization","","0","","13","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Nonlinear regularization path for the modified Huber loss Support Vector Machines","M. Karasuyama; I. Takeuchi","Department of Engineering, Nagoya Institute of Technology, 466-8555, Japan","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","Regularization path algorithms have been proposed to deal with model selection problem in several machine learning approaches. These algorithms allow to compute the entire path of solutions for every value of regularization parameter using the fact that their solution paths have piecewise linear form. In this paper, we propose nonlinear regularization path for the Support Vector Machine (SVM) with a modified Huber loss. We first show that the solution path of the modified Huber loss SVM is represented as piecewise nonlinear function. Since the solutions between two breakpoints are characterized by a rational function, the breakpoint itself can be identified solving the rational equations. Then we develop an efficient iterative algorithm to solve these rational equations with quadratic convergence rate. Note that our algorithm is NOT a predictor-corrector type method that can only follow nonlinear regularization path with rough approximation. We show the algorithm performance on some artificial and real data sets.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596869","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596869","","Approximation methods;Convergence;Equations;Fasteners;Machine learning;Piecewise linear approximation;Support vector machines","iterative methods;learning (artificial intelligence);support vector machines","Huber loss support vector machines;iterative algorithm;machine learning approach;model selection problem;nonlinear regularization path;piecewise nonlinear function;predictor-corrector type method;rational equations;rational function","","1","","28","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"The importance of a piece difference feature to Blondie24","B. Al-Khateeb; G. Kendall","The School of Computer Science, University of Nottingham, UK","2010 UK Workshop on Computational Intelligence (UKCI)","20101109","2010","","","1","6","In recent years, significant research attention has been paid to evolving self-learning checkers players. Fogel's Blondie24 has been very successful in this field and has inspired other researchers to further develop this area. In this paper we address the question of whether piece difference is an important factor in the Blondie24 architecture. Although this issue has been addressed before, this work provides a different experimental setup to previous work, but arrives at the same conclusion. Our experiments show that piece difference has a significant effect on learning abilities.","2162-7657;21627657","Electronic:978-1-4244-8775-2; POD:978-1-4244-8774-5; USB:978-1-4244-8773-8","10.1109/UKCI.2010.5625582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5625582","","Artificial neural networks;Computers;Games;Humans;Learning;Machine learning","computer games;unsupervised learning","Blondie24;Blondie24 architecture;piece difference feature;self learning checkers players","","2","","24","","","8-10 Sept. 2010","","IEEE","IEEE Conference Publications"
"Enhanced Two-Phase method in fast learning algorithms","C. C. Cheung; S. C. Ng; A. K. Lui; S. S. Xu","Department of Electronic and Information Engineering, Hong Kong Polytechnic University, China","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","7","Backpropagation (BP) learning algorithm is the most widely supervised learning technique which is extensively applied in the training of multi-layer feed-forward neural networks. Many modifications of BP have been proposed to speed up the learning of the original BP. However, the performance of these modifications is still not promising due to the existence of the local minimum problem and the error overshooting problem. This paper proposes an Enhanced Two-Phase method to solve these two problems to improve the performance of existing fast learning algorithms. The proposed method effectively locates the existence of the above problems and assigns appropriate fast learning algorithms to solve them. Throughout our investigation, the proposed method significantly improves the performance of different fast learning algorithms in terms of the convergence rate and the global convergence capability in different problems. The convergence rate can be increased up to 100 times compared with the existing fast learning algorithms.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596519","","Machine learning","backpropagation;convergence;multilayer perceptrons;problem solving;recurrent neural nets","backpropagation learning algorithm;convergence rate;enhanced two-phase method;error overshooting problem;fast learning algorithms;local minimum problem;multilayer feedforward neural network training;supervised learning technique","","10","","21","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Incremental Training of Multiclass Support Vector Machines","S. Nikitidis; N. Nikolaidis; I. Pitas","Centre for Res. & Technol., Inf. & Telematics Inst., Hellas, Greece","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4267","4270","We present a new method for the incremental training of multiclass Support Vector Machines that provides computational efficiency for training problems in the case where the training data collection is sequentially enriched and dynamic adaptation of the classifier is required. An auxiliary function that incorporates some desired characteristics in order to provide an upper bound of the objective function which summarizes the multiclass classification task has been designed and the global minimizer for the enriched dataset is found using a warm start algorithm, since faster convergence is expected when starting from the previous global minimum. Experimental evidence on two data collections verified that our method is faster than retraining the classifier from scratch, while the achieved classification accuracy is maintained at the same level.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597757","Incremental Training;Multiplicative Updates;Support Vector Machines","Accuracy;Kernel;Machine learning;Optimization;Support vector machines;Training;Training data","learning (artificial intelligence);pattern classification;support vector machines","auxiliary function;global minimizer;incremental training;multiclass classification;multiclass support vector machines;objective function;training data collection","","0","","10","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Application research into Situational Teaching Approach in for vocational college students","Chen Xu","Department of Building Facility, Sichuan Institute of Architectural Technology, Deyang, 618000, China","2010 International Conference on Educational and Information Technology","20101025","2010","1","","V1-209","V1-212","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>The situational teaching approach is a teaching method with relatively strong practical significance and feasibility derived from the case study analysis. The pedagogy of situational teaching approach is significantly conductive to integrate theory with practice. Implementation of the Situational Teaching Approach should insist on theoretical teaching and exercise simulation, the domination of teachers' guidance, and the unity of form and content. The implementation of the Situational Teaching Approach should pay attention to the combination with other teaching approaches.","","Electronic:978-1-4244-8035-7; POD:978-1-4244-8033-3","10.1109/ICEIT.2010.5607748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607748","Architectural Equipment;Capacity Cultivation;Situational Teaching","Communities;Education;Machine learning;Materials;Size measurement","civil engineering;construction equipment;educational courses;educational institutions;engineering education;further education;teaching;vocational training","situational teaching approach;vocational college student","","0","","4","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"On the effectiveness of discretization on gene selection of microarray data","V. Bolón-Canedo; N. Sánchez-Maroño; A. Alonso-Betanzos","Department of Computer Science, University of A Coru&#x00F1;a, Spain","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","DNA microarray data is a challenging issue for machine learning researchers due to the high number of gene expression contained and the small samples sizes. To deal with this problem, feature selection methods, such as filters and wrappers, are typically applied to reduce the dimensionality. In this work, we apply a filter method before the classification and include a discretization step. The results obtained over ten different microarray data sets confirm the adequacy of the proposed method, that achieves better performances than the classifier alone. Besides, the combination method is also compared with the approaches of other authors (using wrappers and filters), outperforming the prediction accuracy and maintaining or even decreasing the number of genes required.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596825","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596825","","Accuracy;Cancer;Entropy;Machine learning;Niobium;Prediction algorithms;Training","DNA;biology computing;information filtering;lab-on-a-chip;learning (artificial intelligence);pattern classification","DNA microarray data set;feature selection methods;filter method;gene expression;gene selection discretization;machine learning","","2","","35","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Fine-grained incremental learning and multi-feature tossing graphs to improve bug triaging","P. Bhattacharya; I. Neamtiu","Department of Computer Science and Engineering, University of California, Riverside, 92521, USA","2010 IEEE International Conference on Software Maintenance","20101025","2010","","","1","10","Software bugs are inevitable and bug fixing is a difficult, expensive, and lengthy process. One of the primary reasons why bug fixing takes so long is the difficulty of accurately assigning a bug to the most competent developer for that bug kind or bug class. Assigning a bug to a potential developer, also known as bug triaging, is a labor-intensive, time-consuming and fault-prone process if done manually. Moreover, bugs frequently get reassigned to multiple developers before they are resolved, a process known as bug tossing. Researchers have proposed automated techniques to facilitate bug triaging and reduce bug tossing using machine learning-based prediction and tossing graphs. While these techniques achieve good prediction accuracy for triaging and reduce tossing paths, they are vulnerable to several issues: outdated training sets, inactive developers, and imprecise, single-attribute tossing graphs. In this paper we improve triaging accuracy and reduce tossing path lengths by employing several techniques such as refined classification using additional attributes and intra-fold updates during training, a precise ranking function for recommending potential tossees in tossing graphs, and multi-feature tossing graphs. We validate our approach on two large software projects, Mozilla and Eclipse, covering 856,259 bug reports and 21 cumulative years of development. We demonstrate that our techniques can achieve up to 83.62% prediction accuracy in bug triaging. Moreover, we reduce tossing path lengths to 1.5-2 tosses for most bugs, which represents a reduction of up to 86.31% compared to original tossing paths. Our improvements have the potential to significantly reduce the bug fixing effort, especially in the context of sizable projects with large numbers of testers and developers.","1063-6773;10636773","Electronic:978-1-4244-8629-8; POD:978-1-4244-8630-4; USB:978-1-4244-8628-1","10.1109/ICSM.2010.5609736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609736","","Accuracy;Computer bugs;History;Machine learning;Software;Training;Training data","learning (artificial intelligence);program debugging;software engineering","bug tossing reduction;bug triaging improvement;fine grained incremental learning;machine learning based prediction;multifeature tossing graphs;single attribute tossing graph;software bug fixing;triaging accuracy improvement","","24","","20","","","12-18 Sept. 2010","","IEEE","IEEE Conference Publications"
"Using Projection Gradient Method to Train Linear Support Vector Machines","L. Niu; Y. Shi","CAS Res. Center on Fictitious Econ. & Data Sci., Grad. Univ. of Chinese Acad. of Sci., Beijing, China","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","3","","207","210","Linear Support Vector Machines(SVMs) have broad application in supervised classification problem with high dimensional feature space, such as text classification, word sense disambiguation, email spam detection and etc.. Considering the large volume of available training data, efficient training algorithm for linear SVMs draws many attention from the research community in recent years. Cutting-plane based method is one of the state-of-the-art training algorithms for linear SVMs. Within this cutting-plane framework, the quadratic programming(QP) subproblem, which consists of boundary constraints and a single inequality constraint, need to be solved at each iteration. This step is one of the most time consuming tasks in the whole method. In the current software, the QP subproblems are usually solved by the interior point method. In order to improve the efficiency of the cutting-plane based training algorithm, we transform the inequality constraint to an equation by introducing the slack variable and propose using projection gradient algorithm to solve the transformed QP subproblem. Compared with the existing method, the new algorithm has the following advantages. Firstly, because the special structure information in the subproblem is used carefully, the efficiency of solving the subproblem can be improved significantly. Secondly, through projecting the variables to the bound constraints explicitly, the variables that are not related to support vectors can be identified directly. Therefore, the rounding techniques, which is a necessary step in the widely used interior point method based solvers, is not required anymore. Experimental results on several public data sets also show the effectiveness and efficiency of our new algorithm.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.232","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614639","Cutting Plane;Large Margin;Linear Support Vector Machines;Projection Gradient","Biological system modeling;Electronic mail;Machine learning;Support vector machines;Training;USA Councils;Vectors","gradient methods;pattern classification;quadratic programming;support vector machines","boundary constraint;cutting-plane based method;email spam detection;high dimensional feature space;interior point method;linear support vector machine training;projection gradient method;quadratic programming;single inequality constraint;slack variable;supervised classification problem;text classification;training algorithm;word sense disambiguation","","1","","14","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Cluster-based majority under-sampling approaches for class imbalance learning","Y. P. Zhang; L. N. Zhang; Y. C. Wang","School of Computer Science and, Technology, Anhui University, Hefei, China","2010 2nd IEEE International Conference on Information and Financial Engineering","20101025","2010","","","400","404","The class imbalance problem usually occurs in real applications. The class imbalance is that the amount of one class may be much less than that of another in training set. Under-sampling is a very popular approach to deal with this problem. Under-sampling approach is very efficient, it only using a subset of the majority class. The drawback of under-sampling is that it throws away many potentially useful majority class examples. To overcome this drawback, we adopt an unsupervised learning technique for supervised learning. We proposes cluster-based majority under-sampling approaches for selecting a representative subset from the majority class. Compared to under-sampling, cluster-based under-sampling can effectively avoid the important information loss of majority class. We adopt two methods to select representative subset from k clusters with certain proportions, and then use the representative subset and the all minority class samples as training data to improve accuracy over minority and majority classes. In the paper, we compared the behaviors of our approaches with the traditional random under-sampling approach on ten UCI repository datasets using the following classifiers: k-nearest neighbor and Naïve Bayes classifier. Recall, Precision, F-measure, G-mean and BACC (balance accuracy) are used for evaluating performance of classifiers. Experimental results show that our cluster-based majority under-sampling approaches outperform the random under-sampling approach. Our approaches attain better overall performance on k-nearest neighbor classifier compared to Naïve Bayes classifier.","","Electronic:978-1-4244-6928-4; POD:978-1-4244-6927-7","10.1109/ICIFE.2010.5609385","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609385","class imbalance learning;classification;clustering;under-sampling","Accuracy;Classification algorithms;Conferences;Data mining;Learning;Machine learning;Training","Bayes methods;pattern classification;pattern clustering;sampling methods;unsupervised learning","F-measure;G-mean;Naive Bayes classifier;class imbalance learning;cluster based under sampling approach;k-nearest neighbor;supervised learning;unsupervised learning technique","","4","","22","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"The Application of Data Mining Technology in Distance Learning Evaluation","A. Yubing; Z. Jianping","Sch. of Educ., Zhejiang Normal Univ., Jinhua, China","2010 International Forum on Information Technology and Applications","20101111","2010","3","","145","148","In the distance learning environment, students mainly study in their own pace and in their spare time. This has been a challenge for online institutions to supervise students'online learning and evaluate learning outcomes. So far there is little research have been conducted on the quality of distant learning. One effective way to improve learning outcomes is through scientific and efficient assessment to identifying problems, so that suitable strategies could be development. This paper uses a typical distance education system as the operating environment and introduces the data mining technology into the process of evaluation on distance learning. Text Mining and Usage Mining technology are uesed to to carry out excavation, analysis and contrast evaluation Rubric on students' learning processes and learning performances to achieve the aims of improving the efficiency of learning evaluation.","","Electronic:978-1-4244-7622-0; POD:978-1-4244-7621-3","10.1109/IFITA.2010.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634699","application;data mining;distance learning;evaluation","Computer aided instruction;Knowledge engineering;Machine learning;Servers;Text mining","data mining;distance learning;educational institutions","data mining technology;distance education system;distance learning evaluation;online institution;student online learning;text mining;usage mining technology","","1","","8","","","16-18 July 2010","","IEEE","IEEE Conference Publications"
"Clustering based deletion policy for case-base maintenance","R. Ali; M. Ather; R. Ijaz; H. Razzaq; F. Saleem; M. J. Khan","Department of Computer Sciences, Kinnaird College for Women, Lahore, Pakistan","2010 6th International Conference on Emerging Technologies (ICET)","20101115","2010","","","45","48","Case-base maintenance (CBM) is becoming more important with the increased use of case-based reasoning (CBR) systems especially in machine learning. Large scale CBR systems are becoming more ubiquitous, with huge sizes of case libraries consisting of thousands to millions of cases. Large case-bases raise the concern about the utility problem for case retrieval and emphasize on the need of controlling case-base growth through certain policies. Various case-base deletion and addition strategies have been suggested which claim to preserve case-base competence. In this paper, we present a clustering based deletion strategy for case-base maintenance which exploits k-means clustering algorithm. The results presented in this paper reveal that the proposed policy performs better than the existing benchmark deletion policy and ensures better competence.","","Electronic:978-1-4244-8058-6; POD:978-1-4244-8057-9","10.1109/ICET.2010.5638384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5638384","Case-base maintenance;competence;footprint deletion;k-means clustering","Benchmark testing;Clustering algorithms;Cognition;Libraries;Machine learning;Maintenance engineering","case-based reasoning;information retrieval;large-scale systems;pattern clustering;ubiquitous computing","case retrieval;case-base deletion;case-base maintenance;case-based reasoning;clustering based deletion policy;k-means clustering algorithm;large scale CBR system;ubiquitous system","","0","","12","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"An Incremental Learning Algorithm for Non-stationary Environments and Class Imbalance","G. Ditzler; R. Polikar; N. Chawla","Dept. of Electr. & Comput. Eng., Rowan Univ., Glassboro, NJ, USA","2010 20th International Conference on Pattern Recognition","20101007","2010","","","2997","3000","Learning in a non-stationary environment and in the presence of class imbalance has been receiving more recognition from the computational intelligence community, but little work has been done to create an algorithm or a framework that can handle both issues simultaneously. We have recently introduced a new member to the Learn<sup>++</sup> family of algorithms, Learn<sup>++</sup>.NSE, which is designed to track non-stationary environments. However, this algorithm does not work well when there is class imbalance as it has not been designed to handle this problem. On the other hand, SMOTE - a popular algorithm that can handle class imbalance - is not designed to learn in nonstationary environments because it is a method of over sampling the data. In this work we describe and present preliminary results for integrating SMOTE and Learn<sup>++</sup>.NSE to create an algorithm that is robust to learning in a non-stationary environment and under class imbalance.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.734","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597278","Learn++;concept drift;ensemble systems;imbalanced data;nonstationary learning","Algorithm design and analysis;Artificial neural networks;Classification algorithms;Computer science;Conferences;Data mining;Machine learning","learning (artificial intelligence);pattern classification","Learn<sup>++</sup> family;Learn<sup>++</sup>.NSE;SMOTE algorithm;class imbalance;computational intelligence;incremental learning algorithm;nonstationary environment","","9","1","11","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Bound on the Performance of LDA in Randomly Projected Data Spaces","R. J. Durrant; A. Kaban","Sch. of Comput. Sci., Univ. of Birmingham, Birmingham, UK","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4044","4047","We consider the problem of classification in nonadaptive dimensionality reduction. Specifically, we bound the increase in classification error of Fisher's Linear Discriminant classifier resulting from randomly projecting the high dimensional data into a lower dimensional space and both learning the classifier and performing the classification in the projected space. Our bound is reasonably tight, and unlike existing bounds on learning from randomly projected data, it becomes tighter as the quantity of training data increases without requiring any sparsity structure from the data.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.983","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597392","Classification;Compressed Learning;Dimensionality Reduction;Linear Discriminant Analysis;Random Projection","Covariance matrix;Eigenvalues and eigenfunctions;Estimation error;Machine learning;Training;Training data;Writing","learning (artificial intelligence);pattern classification;statistical analysis","Fisher linear discriminant analysis;classification problem;nonadaptive dimensionality reduction;randomly projected data spaces;sparsity structure","","1","","10","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Fuzzy-Based Broken Schema Mapping Detecting Approach","J. Miao; D. Zhang; A. Li; G. Chen","Inst. of Command Autom., PLA Univ. of Sci. & Technol., Nanjing, China","2010 International Conference on Electrical and Control Engineering","20101111","2010","","","4871","4874","In the dynamic distributed environment, the data sources trend to suffer changes that invalidate the mappings. We put forward a Fuzzy-based Broken Schema Mapping Detecting Approach (BSMD) to process the run time broken mapping detecting problem. The core of BSMD is a set of computationally inexpensive modules called sensors, which capture salient characteristics of data sources. There are two novel improvements: Disjunction-Weighted Average Operators are leveraged to calculate the score, which implies whether the mapping is broken; Change Weight Operators is introduced combine artificial data with real data in the training phase. The experiments over the real-world sources demonstrate the effectiveness of our fuzzy-based approach over existing solutions, as well as the utility of our improvements.","","Electronic:978-1-4244-6881-2; POD:978-1-4244-6880-5","10.1109/iCECE.2010.1178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630081","broken mapping detecting;data integration;fuzzy aggregation operators","Computers;Machine learning;Maintenance engineering;Peer to peer computing;Presses;Programmable logic arrays;Sensors","data handling;distributed processing;fuzzy set theory","broken schema mapping detecting approach;change weight operators;disjunction-weighted average operators;dynamic distributed environment;fuzzy-based detecting approach","","0","","14","","","25-27 June 2010","","IEEE","IEEE Conference Publications"
"High Level Semantic Retrieval of Thangka Image Based on C-K Relation Net","W. Wang; J. Qian; L. Yin","Sch. of Math. & Comput. Sci., Northwest Univ. for Nat., Lanzhou, China","2010 Fifth International Multi-conference on Computing in the Global Information Technology","20101111","2010","","","77","81","Image retrieval is one of the hottest fields of computer vision and pattern recognition. In recent years, many researchers addressed the challenging problem of interpreting the semantics of images. This paper presented a novel approach based on relation net (concept and semantic keyword relation net) for high level semantic retrieval of Thangka image. Here, we use Delphi method and fuzzy statistic to construct the relation net, which can descript the membership degree between semantic keywords and concepts better. Finally, this paper proposed CSM (concept similar measurement) algorithm to compute the similarity during the concepts on the basis of relation net. The experiments show that the proposed approach can retrieval Thangka image by the similar concepts well and effectively.","","Electronic:978-0-7695-4181-5; POD:978-1-4244-8068-5","10.1109/ICCGI.2010.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5628875","C-K relation net;Thangka image;concept;keyword;semantic retrieval","Correlation;Image retrieval;Machine learning;Manuals;Multimedia communication;Semantics;Visualization","fuzzy set theory;image retrieval;programming language semantics;statistical analysis","C-K relation net;CSM algorithm;Delphi method;Thangka image;computer vision;concept similar measurement;fuzzy statistic;high level semantic retrieval;image retrieval;image semantics;membership degree;pattern recognition;semantic keyword","","0","","23","","","20-25 Sept. 2010","","IEEE","IEEE Conference Publications"
"Improving Mouse Dynamics Biometric Performance Using Variance Reduction via Extractors With Separate Features","Y. Nakkabi; I. Traore; A. A. E. Ahmed","Department of Electrical and Computer Engineering, University of Victoria, Victoria, Canada","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20101014","2010","40","6","1345","1353","The European standard for access control imposes stringent performance requirements on commercial biometric technologies that few existing recognition systems are able to meet. In this correspondence paper, we present the first mouse dynamics biometric recognition system that fulfills this standard. The proposed system achieves notable performance improvement by developing separate models for separate feature groups involved. The improvements are achieved through the use of a fuzzy classification based on the Learning Algorithm for Multivariate Data Analysis and using a score-level fusion scheme to merge corresponding biometric scores. Evaluation of the proposed framework using mouse data from 48 users achieves a false acceptance rate of 0% and a false rejection rate of 0.36%.","1083-4427;10834427","","10.1109/TSMCA.2010.2052602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5524019","Biometric fusion;biometric systems;fuzzy clustering;human computer interaction;mouse dynamics;variance reduction (VR)","Access control;Analytical models;Artificial neural networks;Biological system modeling;Biometrics;Computational modeling;Data analysis;Feature extraction;Fuzzy logic;Humans;Machine learning;Mice;Statistics;Uncertainty","authorisation;biometrics (access control);data analysis;feature extraction;fuzzy set theory;learning (artificial intelligence);pattern classification;sensor fusion","European standard;access control;commercial biometric technology recognition system;false rejection rate;fuzzy classification;learning algorithm;mouse dynamics biometric performance;multivariate data analysis;score level fusion;separate feature;variance reduction","","22","2","21","","20100726","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"A new learning method inspired by cooperative transportation in ants: modelling and simulation","F. Li; P. Cheng","College of Economics and Management, YanShan University, Qinhuangdao, China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","20101104","2010","11","","V11-586","V11-590","Inspired by cooperative transport behaviors of ants, on the basis of Q-learning, a new learning method, Neighbors' Discounted Information (NDI) learning method, is present in the paper. This is a swarm-based learning method, in which principles of swarm intelligence are strictly complied with. In NDI learning, the i-interval neighbor's information, namely its discounted reward, is referenced when an individual selects the next state, so that it can make the best decision in a computable local neighborhood. In application, different policies of NDI learning are recommended by controlling the parameters according to time-relativity of concrete tasks. By applying this learning method, the cooperative transport of ants is simulated. Experiment results show that the transport process in simulation is very similar to the phenomenon in natural world, which proves the designed learning mechanism's rationality.","2161-9069;21619069","Electronic:978-1-4244-7237-6; POD:978-1-4244-7235-2","10.1109/ICCASM.2010.5623139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623139","Neighbors' Discounted Information learning (NDI learning);Q-learning;discounted reward;i-interval neighbor;swarm intelligence","Learning;Learning systems;Machine learning;Modeling;Particle swarm optimization;Robots;Transportation","learning (artificial intelligence);multi-agent systems","ant cooperative transportation;discounted reward information;neighbors discounted information learning method;q-learning;swarm intelligence;swarm-based learning method","","0","","12","","","22-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"A Hybrid and Ensemble Intelligent Pattern Classification Algorithm","Y. Zhang; C. Zhang; P. Ma; X. Su","Sch. of Comput. Sci. & Technol., Harbin Inst. of Technol., Harbin, China","2010 First International Conference on Pervasive Computing, Signal Processing and Applications","20101115","2010","","","833","836","We introduce a novel hybrid and ensemble intelligent classifier which is an extension of ensemble classifier. Particular emphasis is put on the task of establishing the hybrid and ensemble structure of classifier depending on the principle of multi-agent structure. The hybrid and ensemble classifier include several classifiers with different types which is regarded as a set of agents. Meanwhile, every agent is composed of a set of same type's intelligent classifiers by choosing different initialization parameters or different training set of samples. The concrete classification process contain four steps. For the unknown samples, first we obtain a set of classification results form every agent generating by all the classifiers from the agent. Second, we provide an optimization model of obtaining the associated weights of all agents. Meanwhile, the set of classification data of every agent is divided into three clustering through k-means method, further obtain three values by choosing the medians of three clustering respectively. Third, the triangular fuzzy numbers generating by all the agents are aggregated a group consensus using the known weights. Finally the consensus is compared with the pre-defined threshold. For illustration and verification purpose, a practical example is provided to analyze the developed pattern classification approach.","","Electronic:978-0-7695-4180-8; POD:978-1-4244-8043-2","10.1109/PCSPA.2010.207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635562","ensemble learnling;hybrid learning;intelligent agents;pattern classification","Artificial neural networks;Classification algorithms;Clustering algorithms;Educational institutions;Machine learning algorithms;Pattern classification;Training","fuzzy set theory;multi-agent systems;number theory;pattern classification","intelligent pattern classification algorithm;k-means clustering method;multiagent structure;optimization model;triangular fuzzy numbers generation","","0","","8","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"A Modified Artificial Neural Network Learning Algorithm for Imbalanced Data Set Problem","A. Adam; I. Shapiai; Z. Ibrahim; M. Khalid; L. C. Chew; L. W. Jau; J. Watada","Univ. Teknol. Malaysia, Malaysia","2010 2nd International Conference on Computational Intelligence, Communication Systems and Networks","20101101","2010","","","44","48","A modified learning algorithm of Artificial Neural Networks (ANN) is introduced in this paper to solve imbalanced data set problems. In solving imbalanced data set, it is critical to predict the minority class due to their imbalanced nature. In order to improve the standard ANN classifier prediction performance, this paper focuses on optimizing the decision boundary of the step function at the output layer of ANN using particle swarm optimization (PSO). A feedforward ANN is chosen in this study. Firstly, a conventional back propagation algorithm is employed to train the ANN. PSO is then applied to train the real predicted output of training data from this trained network. As the result, the optimum value of decision boundary is found and applied to the classifier. Prediction performance is assessed by G-mean, which is a measure to indicate the efficiency of classifiers for imbalanced data sets. Based on experimental results, the proposed model is able to solve imbalanced data sets problem with better performance compared to the standard ANN.","","Electronic:978-0-7695-4158-7; POD:978-1-4244-7837-8","10.1109/CICSyN.2010.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614727","artificial neural network;imbalanced data set problems;particle swarm optimization","Artificial neural networks;Classification algorithms;Feedforward neural networks;Machine learning;Prediction algorithms;Testing;Training","backpropagation;feedforward neural nets;particle swarm optimisation;pattern classification;statistical analysis","ANN classifier prediction performance;artificial neural network learning algorithm;backpropagation algorithm;decision boundary;feedforward ANN;g-mean;imbalanced data set problem;particle swarm optimization;step function","","2","","26","","","28-30 July 2010","","IEEE","IEEE Conference Publications"
"Instance-based ensemble learning algorithm with stacking framework","H. Homayouni; S. Hashemi; A. Hamzeh","Department of Computer Science and Engineering, University of Shiraz, Iran","2010 2nd International Conference on Software Technology and Engineering","20101025","2010","2","","V2-164","V2-169","Nowadays the most active research in supervised learning includes an integration of several base classifiers into the combined classification system. Such systems are known under the names multiple classifiers, ensembles methods. This topic attracts an interest of machine learning researchers as multiple classifiers are often much more accurate than the component classifiers that make them up. In this paper, we proposed a Lazy Stacking approach to classification (LS), a stacking framework with lazy local learning for building a classifier ensemble learner. Stacking is an ensemble that uses different “type” of base classifiers for labeling new instance. So by using stacking along with lazy learners, we can provide the desire accuracy. To investigate LS's performance, we test LS against four rival algorithms on a large suite of 10 real-world benchmark numeric datasets. Empirical results confirm that LS can statistically significantly outperform alternative methods in terms of classification accuracy.","","Electronic:978-1-4244-8666-3; POD:978-1-4244-8667-0","10.1109/ICSTE.2010.5608830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5608830","classification;classifier ensemble;diversity;lazy learning;stacking","Accuracy;Bagging;Classification algorithms;Machine learning;Prediction algorithms;Stacking;Training","learning (artificial intelligence);pattern classification","base classifier;classification system;component classifier;instance labeling;instance-based ensemble learning algorithm;lazy local learning;lazy stacking approach;machine learning;multiple classifiers;stacking framework;supervised learning","","1","","16","","","3-5 Oct. 2010","","IEEE","IEEE Conference Publications"
"A Hybrid Harmony Search Algorithm for Numerical Optimization","P. J. Zhao","Dept. of Math. & Comput. Sci., Shangluo Univ., Shangluo, China","2010 International Conference on Computational Aspects of Social Networks","20101115","2010","","","255","258","In the paper a novel harmony search (HS) algorithm based on opposition and differential evolution (ODHS) algorithm is proposed in order to solve high dimensional optimization problems. It provides a new architecture of hybrid algorithms, which organically merges the differential evolution (DE) into HS algorithm and the ODHS algorithm initializes the HM (harmony memory) using opposition based learning and uses “opposites” selection replacing random selection. During the course of evolvement, harmony search and differential evolution is alternately used to improve the search performance, which makes the ODHS algorithm have more powerful exploitation capabilities. Simulation and comparisons based on four benchmark functions demonstrate the effectiveness, efficiency and robustness of the proposed ODHS.","","Electronic:978-0-7695-4202-7; POD:978-1-4244-8785-1","10.1109/CASoN.2010.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5636695","component;differential evolution;harmony search;opposition based learning","Algorithm design and analysis;Benchmark testing;Evolutionary computation;Machine learning;Optimization;Search problems","evolutionary computation;learning (artificial intelligence);search problems","differential evolution algorithm;hybrid harmony search algorithm;numerical optimization;opposition based learning","","1","","13","","","26-28 Sept. 2010","","IEEE","IEEE Conference Publications"
"On-Line Random Naive Bayes for Tracking","M. Godec; C. Leistner; A. Saffari; H. Bischof","Inst. for Comput. Vision & Graphics, Graz Univ. of Technol., Graz, Austria","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3545","3548","Randomized learning methods (i.e., Forests or Ferns) have shown excellent capabilities for various computer vision applications. However, it was shown that the tree structure in Forests can be replaced by even simpler structures, e.g., Random Naive Bayes classifiers, yielding similar performance. The goal of this paper is to benefit from these findings to develop an efficient on-line learner. Based on the principals of on-line Random Forests, we adapt the Random Naive Bayes classifier to the on-line domain. For that purpose, we propose to use on-line histograms as weak learners, which yield much better performance than simple decision stumps. Experimentally we show, that the approach is applicable to incremental learning on machine learning datasets. Additionally, we propose to use an IIR filtering-like forgetting function for the weak learners to enable adaptivity and evaluate our classifier on the task of tracking by detection.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597464","Naive Bayes;Object Tracking;Online Learning","Bagging;Histograms;Learning systems;Machine learning;Memory management;Training;Visualization","Bayes methods;IIR filters;computer vision;learning (artificial intelligence);object detection;random processes","IIR filtering-like forgetting function;computer vision;decision stumps;incremental learning;machine learning datasets;on-line histograms;on-line random Naive Bayes method;on-line random forests;random Naive Bayes classifiers;randomized learning methods;tracking by detection trask;tree structure","","7","1","17","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Random Subspace Method in Text Categorization","M. J. Gangeh; M. S. Kamel; R. P. W. Duin","Dept. of Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada","2010 20th International Conference on Pattern Recognition","20101007","2010","","","2049","2052","In text categorization (TC), which is a supervised technique, a feature vector of terms or phrases is usually used to represent the documents. Due to the huge number of terms in even a moderate-size text corpus, high dimensional feature space is an intrinsic problem in TC. Random subspace method (RSM), a technique that divides the feature space to smaller ones each submitted to a (base) classifier (BC) in an ensemble, can be an effective approach to reduce the dimensionality of the feature space. Inspired by a similar research on functional magnetic resonance imaging (fMRI) of brain, here we address the estimation of ensemble parameters, i.e., the ensemble size (L) and the dimensionality of feature subsets (M) by defining three criteria: usability, coverage, and diversity of the ensemble. We will show that relatively medium M and small L yield an ensemble that improves the performance of a single support vector machine, which is considered as the state-of-the-art in TC.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.505","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595913","ensemble of classifiers;random subspace method;support vector machine;text categorization","Accuracy;Brain;Kernel;Machine learning;Presses;Support vector machines;Text categorization","estimation theory;pattern classification;random processes;support vector machines;text analysis","base classifier;document representation;feature subsets dimensionality;feature vector;functional magnetic resonance imaging;high dimensional feature space;moderate size text corpus;random subspace method;support vector machine;text categorization","","2","1","9","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Feature Selection for Fault Diagnosis Using Fuzzy-ARTMAP Classification and Conflict Intersection","M. Benkaci; A. Doncescu; B. Jammes","Lab. d'Archit. et d'Analyse des Sytemes, Toulouse, France","2010 International Conference on Broadband, Wireless Computing, Communication and Applications","20101111","2010","","","495","500","In automotive industry the safety of cars behavior is monitoring using computers. The information acquired on the bus communication is often redundant and not relevant. Therefore in the case of faults detection and isolation based on machine learning model, we need to reduce the number of variables according with their relevance and allowing taking decision in real time. In this paper, we propose a new approach for feature selection using fuzzy-ARTMAP classification and conflict characterization in fault diagnosis process. This approach is realized in two stages. In the first one, we classify the unfaulty functioning data of system using the fuzzy-ARTMAP classification. In the second stage, a conflict is accounted between features of test data based on the hyper-cubes resulted in the first stage. Two features are in conflict if her intersection does not belong to the model elaborated by fuzzy-ARTMAP classification. This approach is applied with success in automotive application in which the relevant features are detected and isolated.","","Electronic:978-0-7695-4236-2; POD:978-1-4244-8448-5","10.1109/BWCCA.2010.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5632366","Conflict;Feature selection;fault diagnosis;fuzzy-ARTMAP classification;relevance","Artificial neural networks;Classification algorithms;Databases;Fault detection;Feature extraction;Machine learning;Pattern recognition","automobile industry;computerised monitoring;fault location;feature extraction;learning (artificial intelligence);pattern classification;production engineering computing","automotive industry;bus communication;car safety;computer monitoring;conflict intersection;fault diagnosis;faults detection;faults isolation;feature selection;fuzzy-ARTMAP classification;hyper-cubes;machine learning model","","0","","26","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"Decomposition Methods and Learning Approaches for Imbalanced Dataset: An Experimental Integration","P. Soda; G. Iannello","Integrated Res. Centre, Univ. Campus Bio-Medico of Rome, Rome, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3117","3120","Decomposition methods are multiclass classification schemes where the polychotomy is reduced into several dichotomies. Each dichotomy is addressed by a classifier trained on a training set derived from the original one on the basis of the decomposition rule adopted. These new training sets may present a disproportion between the classes, harming the global recognition accuracy. Indeed, traditional learning algorithms are biased towards the majority class, resulting in poor predictive accuracy over the minority one. This paper investigates if the application of learning methods specifically tailored for imbalanced training set introduces any performance improvement when used by dichotomizers of decomposition methods. The results on five public datasets show that the application of these learning methods improves the global performance of decomposition schemes.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.763","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597266","Classification;Decomposition methods;Imbalance dataset;Pattern recognition systems and applications","Accuracy;Data mining;Learning systems;Machine learning;Protocols;Training","learning (artificial intelligence);pattern classification","decomposition methods;dichotomies;experimental integration;imbalanced dataset;learning algorithms;multiclass classification schemes;polychotomy","","1","","14","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Weighting of the k-Nearest-Neighbors","K. Chernoff; M. Nielsen","Dept. of Comput. Sci., Univ. of Copenhagen, Copenhagen, Denmark","2010 20th International Conference on Pattern Recognition","20101007","2010","","","666","669","This paper presents two distribution independent weighting schemes for k-Nearest-Neighbors (kNN). Applying the first scheme in a Leave-One-Out (LOO) setting corresponds to performing complete b-fold cross validation (b-CCV), while applying the second scheme corresponds to performing bootstrapping in the limit of infinite iterations. We demonstrate that the soft kNN errors obtained through b-CCV can be obtained by applying the weighted kNN in a LOO setting, and that the proposed weighting schemes can decrease the variance and improve the generalization of kNN in a CV setting.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595819","","Artificial neural networks;Error analysis;Extraterrestrial measurements;Feature extraction;Machine learning;Nearest neighbor searches;Training","iterative methods;pattern classification;statistical analysis","b-CCV;b-fold cross validation;bootstrapping;distribution independent weighting schemes;infinite iterations;k-nearest neighbors weighting;leave-one-out setting;soft kNN errors","","2","2","13","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Support Vectors Selection for Supervised Learning Using an Ensemble Approach","L. Guo; S. Boukir; N. Chehata","GHYMAC Lab., Inst. EGID, Pessac, France","2010 20th International Conference on Pattern Recognition","20101007","2010","","","37","40","Support Vector Machines (SVMs) are popular for pattern classification. However, training a SVM requires large memory and high processing time, especially for large datasets, which limits their applications. To speed up their training, we present a new efficient support vector selection method based on ensemble margin, a key concept in ensemble classifiers. This algorithm exploits a new version of the margin of an ensemble-based classification and selects the smallest margin instances as support vectors. Our experimental results show that our method reduces training set size significantly without degrading the performance of the resulting SVMs classifiers.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597652","SVM;ensemble learning;margin","Accuracy;Bagging;Kernel;Machine learning;Support vector machines;Training;Training data","learning (artificial intelligence);pattern classification;support vector machines","SVM classifier;ensemble margin;ensemble-based classification;pattern classification;supervised learning;support vector machine;support vector selection method","","6","","8","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Subclass Error Correcting Output Codes Using Fisher's Linear Discriminant Ratio","N. Arvanitopoulos; D. Bouzas; A. Tefas","Dept. of Inf., Aristotle Univ. of Thessaloniki, Thessaloniki, Greece","2010 20th International Conference on Pattern Recognition","20101007","2010","","","2953","2956","Error-Correcting Output Codes (ECOC) with sub-classes reveal a common way to solve multi-class classification problems. According to this approach, a multi-class problem is decomposed into several binary ones based on the maximization of the mutual information (MI) between the classes and their respective labels. The MI is modelled through the fast quadratic mutual information (FQMI) procedure. However, FQMI is not applicable on large datasets due to its high algorithmic complexity. In this paper we propose Fisher's Linear Discriminant Ratio (FLDR) as an alternative decomposition criterion which is of much less computational complexity and achieves in most experiments conducted better classification performance. Furthermore, we compare FLDR against FQMI for facial expression recognition over the Cohn-Kanade database.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595920","Facial Expression Recognition;Fisher's Linear Discriminant;Subclass Error Correcting Output Codes","Art;Databases;Encoding;Equations;Machine learning;Support vector machines;Training","computational complexity;error correction codes;face recognition;pattern classification","Cohn Kanade database;Fisher linear discriminant ratio;computational complexity;facial expression recognition;fast quadratic mutual information;multiclass classification problems;mutual information maximization;subclass error correcting output codes","","1","","10","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"An Optimum Class-Rejective Decision Rule and Its Evaluation","H. L. Capitaine; C. Frelicot","Math., Image & Applic. Lab., Univ. of La Rochelle, La Rochelle, France","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3312","3315","Decision-making systems intend to copy human reasoning which often consists in eliminating highly non probable situations (e.g. diseases, suspects) rather than selecting the most reliable ones. In this paper, we present the concept of class-rejective rules for pattern recognition. Contrary to usual reject option schemes where classes are selected when they may correspond to the true class of the input pattern, it allows to discard classes that can not be the true one. Optimality of the rule is proven and an upper-bound for the error probability is given. We also propose a criterion to evaluate such class-rejective rules. Classification results on artificial and real datasets are provided.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597152","bayesian classification;decision rules;loss structure;reject option;risk minimization","Chromium;DH-HEMTs;Error analysis;Error probability;Machine learning;Optical character recognition software;Pattern recognition","decision making;inference mechanisms;pattern recognition;probability","class-rejective decision rule;class-rejective rules;decision-making systems;error probability;human reasoning;pattern recognition;real datasets;reject option schemes","","2","","13","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Design and analysis of the WCCI 2010 active learning challenge","I. Guyon; G. Cawley; G. Dror; V. Lemaire","Clopinet, 955 Creston Road, Berkeley, CA 94708, USA","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","We organized a data mining challenge on “active learning” for IJCNN/WCCI 2010, addressing machine learning problems where labeling data is expensive, but large amounts of unlabeled data are available at low cost. Examples include handwriting and speech recognition, document classification, vision tasks, drug design using recombinant molecules and protein engineering. Such problems might be tackled from different angles: learning from unlabeled data or active learning. In the former case, the algorithms must satisfy themselves with the limited amount of labeled data and capitalize on the unlabeled data with semi-supervised learning methods. Several challenges have addressed this problem in the past. In the latter case, the algorithms may place a limited number of queries to get new sample labels. The goal in that case is to optimize the queries and the problem is referred to as active learning. While the problem of active learning is of great importance, organizing a challenge in that area is non trivial. This is the problem we have addressed, and we describe our approach in this paper. The “active learning” challenge is part of the WCCI 2010 competition program (http://www.wcci2010. org/competition-program). The website of the challenge remains open for submission of new methods beyond the termination of the challenge as a resource for students and researchers (http://clopinet.com/al).","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596506","","Data models;Environmental factors;Machine learning;Organisms;Predictive models;Protocols;Training","data mining;document handling;handwriting recognition;learning (artificial intelligence)","WCCI 2010 active learning challenge;data mining challenge;document classification;drug design;handwriting recognition;machine learning;semi-supervised learning methods;speech recognition;vision tasks","","1","","23","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"On NSF “open questions,” some external properties of the brain as a learning system and an architecture for autonomous learning","A. Roy","Dept. of Information Systems, Arizona State University, Tempe, 85048, USA","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","The 2007 NSF workshop report titled “Future Challenges for the Science and Engineering of Learning” (http://www.cnl.salk.edu/Media/NSFWorkshopReport.v4.pdf) raises lots of questions about how the brain works and learns and they have important implications for the development of autonomous adaptive systems. The report also defines some general characteristics of biological learners that, in essence, impose constraints on any kind of learning systems that we call brain-like. This paper examines these general characteristics of biological learners, as defined in the NSF report, and relates them to a set of properties of brain-like learning defined as early as 1994. The paper also shows how a control theoretic architecture for autonomous learning systems mitigates or resolves many of the “open questions” posed by the NSF report. It also provides some recent evidence from neuroscience on the nature of learning in biological systems that support the notion that the brain has a control theoretic architecture.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596769","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596769","","Conferences;Learning systems;Machine learning;Neuroscience;Sleep;Training","brain models;learning (artificial intelligence);learning systems;self-adjusting systems","NSF workshop;autonomous adaptive system;autonomous learning;biological learner;brain like learning;brain work;control theoretic architecture;learning system;national science foundation;neuroscience","","1","","31","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Common spatial pattern patches - An optimized filter ensemble for adaptive brain-computer interfaces","C. Sannelli; C. Vidaurre; K. R. Müller; B. Blankertz","Berlin Institute of Technology, Machine Learning Laboratory, Germany","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","20101111","2010","","","4351","4354","Laplacian filters are commonly used in Brain Computer Interfacing (BCI). When only data from few channels are available, or when, like at the beginning of an experiment, no previous data from the same user is available complex features cannot be used. In this case band power features calculated from Laplacian filtered channels represents an easy, robust and general feature to control a BCI, since its calculation does not involve any class information. For the same reason, the performance obtained with Laplacian features is poor in comparison to subject-specific optimized spatial filters, such as Common Spatial Patterns (CSP) analysis, which, on the other hand, can be used just in a later phase of the experiment, since they require a considerable amount of training data in order to enroll a stable and good performance. This drawback is particularly evident in case of poor performing BCI users, whose data is highly non-stationary and contains little class relevant information. Therefore, Laplacian filtering is preferred to CSP, e.g., in the initial period of co-adaptive calibration, a novel BCI paradigm designed to alleviate the problem of BCI illiteracy. In fact, in the co-adaptive calibration design the experiment starts with a subject-independent classifier and simple features are needed in order to obtain a fast adaptation of the classifier to the newly acquired user's data. Here, the use of an ensemble of local CSP patches (CSPP) is proposed, which can be considered as a compromise between Laplacians and CSP: CSPP needs less data and channels than CSP, while being superior to Laplacian filtering. This property is shown to be particularly useful for the co-adaptive calibration design and is demonstrated on off-line data from a previous co-adaptive BCI study.","1094-687X;1094687X","Electronic:978-1-4244-4124-2; POD:978-1-4244-4123-5","10.1109/IEMBS.2010.5626227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5626227","","Algorithm design and analysis;Brain computer interfaces;Calibration;Eigenvalues and eigenfunctions;Electroencephalography;Laplace equations;Machine learning","brain-computer interfaces;calibration;electroencephalography;medical signal processing;signal classification","Laplacian filters;adaptive brain-computer interface;co-adaptive calibration;common spatial pattern patches;fast adaptation;optimized filter ensemble","Brain;Computers;Humans;Man-Machine Systems","4","","12","","","Aug. 31 2010-Sept. 4 2010","","IEEE","IEEE Conference Publications"
"Nonlinear Mappings for Generative Kernels on Latent Variable Models","A. Carli; M. Bicego; S. Baldo; V. Murino","Dipt. di Inf., Univ. di Verona, Verona, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","2134","2137","Generative kernels have emerged in the last years as an effective method for mixing discriminative and generative approaches. In particular, in this paper, we focus on kernels defined on generative models with latent variables (e.g. the states in a Hidden Markov Model). The basic idea underlying these kernels is to compare objects, via a inner product, in a feature space where the dimensions are related to the latent variables of the model. Here we propose to enhance these kernels via a nonlinear normalization of the space, namely a nonlinear mapping of space dimensions able to exploit their discriminative characteristics. In this paper we investigate three possible nonlinear mappings, for two HMM-based generative kernels, testing them in different sequence classification problems, with really promising results.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595922","generative kernels;nonlinear mappings","Conferences;Hidden Markov models;Kernel;Logistics;Machine learning;Shape;Training","hidden Markov models;pattern recognition","HMM-based generative kernel;feature space;hidden Markov model;latent variable model;nonlinear mapping;nonlinear normalization;space dimension","","2","","14","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"A strategy for dealing with missing values by using selective activation neurons in a multi-topology framework","N. Lopes; B. Ribeiro","School of Technology and Management, Polytechnic Institute of Guarda (IPG/UDI) and CISUC, Portugal","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","5","Neural Networks (NN) have proven to be able to successfully solve problems in many areas. However, for large scale real problems, data is often incomplete. This is a serious problem, because NN cannot handle directly missing values. The usual approach to solve this problem consists of removing attributes and/or samples containing unknown values. This strategy is very attractive since it is simple to implement and reduces the dimensionality of data, therefore potentially reducing the complexity of the problem. However removing features or instances containing vital information, which can not be compensated by the remaining data, may result in the unattainability of accurate NN models. Another strategy consists of estimating missing values. However, wrong estimations of crucial data can lead to unpredicted results. Moreover these techniques do not account for real situations (e.g. where sensors may fail) and the output of such NN models may cause instabilities in the whole process. In this paper we propose a technique for handling missing values that accounts for the creation of different transparent NN models with respect to the missing features instead of relying on tedious data pre-processing techniques. The resulting models are bounded to share information among them. Contrary to the imputation of data (estimate) our models take into account the uncertainty caused by unknown values. Moreover the presented technique is prepared to deal with faulty sensors. The preliminary results obtained in several datasets show the efficacy of the proposed approach.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596750","","Accuracy;Artificial neural networks;Machine learning;Mathematical model;Neurons;Sensors;Training","computational complexity;data handling;neural nets;uncertainty handling","data imputation;data preprocessing techniques;faulty sensor;large scale real problems;missing value estimation;multitopology framework;neural network;selective activation neuron","","1","","22","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Enhancing Web Page Classification via Local Co-training","Y. Du; X. Guan; Z. Cai","MOE Key Lab. for Intell. Networks & Network Security, Xi 'an Jiaotong Univ., Xi'an, China","2010 20th International Conference on Pattern Recognition","20101007","2010","","","2905","2908","In this paper we propose a new multi-view semi-supervised learning algorithm called Local Co-Training(LCT). The proposed algorithm employs a set of local models with vector outputs to model the relations among examples in a local region on each view, and iteratively refines the dominant local models (i.e. the local models related to the unlabeled examples chosen for enriching the training set) using unlabeled examples by the co-training process. Compared with previous co-training style algorithms, local co-training has two advantages: firstly, it has higher classification precision by introducing local learning; secondly, only the dominant local models need to be updated, which significantly decreases the computational load. Experiments on WebKB and Cora datasets demonstrate that LCT algorithm can effectively exploit unlabeled data to improve the performance of web page classification.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597065","","Computational modeling;Error analysis;Machine learning;Support vector machines;Training;Web pages","Internet;learning (artificial intelligence);pattern classification","Cora datasets;Web page classification;WebKB datasets;local co-training;machine learning;multiview semi-supervised learning algorithm","","0","","12","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Improving recall values in breast cancer diagnosis with Incremental Background Knowledge","C. Silva; B. Ribeiro; N. Lopes","School of Technology and Management, Polytechnic Institute of Leiria, and CISUC, University of Coimbra, Portugal","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","6","Cancer diagnosis is generally the process of using some form of physical or genetic tests or exams, usually referred as patient data, to detect the disease. One of the main problems with cancer diagnosis systems is the lack of labeled data, as well as the difficulties of labeling pre-existing unlabeled data. Thus, there is a growing interest in exploring the use of unlabeled data as a way to improve classification performance in cancer diagnosis. The possible availability of this kind of data for some applications makes it an appealing source of information. In this work we explore an Incremental Background Knowledge (IBK) technique to introduce unlabeled data into the training set by expanding it using initial classifiers to better aid decisions, namely by improving recall values. The defined incremental SVM margin-based method was tested in the Wisconsin-Madison breast cancer diagnosis problem to examine the effectiveness of such techniques in supporting diagnosis.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596641","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596641","","Breast cancer;Learning systems;Machine learning;Support vector machines;Training;Vectors","cancer;knowledge engineering;medical computing;patient diagnosis;pattern classification;support vector machines","breast cancer diagnosis;classification performance;incremental SVM margin based method;incremental background knowledge;initial classifiers;patient data;recall values","","0","","22","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Construction of players' action for robocup soccer using graph structured program evolution","Y. Horima; S. Shirakawa; N. Yata; T. Nagao","Graduate School of Environment, and Information Sciences, Yokohama National University, Yokohama, Japan","Proceedings of SICE Annual Conference 2010","20101014","2010","","","690","695","In recent years, many researchers addressed multiagent system. Multi-agent system is the system consisted of multiple robots that have only limited capability. Robocup simulated soccer is proposed as a test bed of multi-agent system. It has a subtask called keepaway soccer. Automatic construction of the strategy of multi-agent system is required because it is difficult. Therefore, we purpose construction of the strategy for multiagent system by graph structured program evolution (GRAPE) in keepaway soccer. GRAPE is the method of construction of graph-structured programs automatically.","","DVD:978-4-907764-35-7; Electronic:978-4-907764-36-4; POD:978-1-4244-7642-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603054","Keepaway soccer;Multi-agent system;Robocup soccer","Economic indicators;Genetics;Heuristic algorithms;Machine learning;Multiagent systems;Pipelines;Robots","graph theory;mobile robots;multi-agent systems;multi-robot systems","Robocup soccer;graph structured program evolution;keepaway soccer;multiagent system;player action construction","","0","","18","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"Equity markets and computational intelligence","R. Abbott","Computer Science at California State University, Los Angeles, 90032 USA","2010 UK Workshop on Computational Intelligence (UKCI)","20101109","2010","","","1","6","I propose a new characterization of the types of problems for which computational intelligence (CI) tends to be used, namely the identification of approximate abstractions. I then suggest that equity markets provide a challenging example for CI. Because markets are inherently adaptive, they pose a more difficult problem than traditional CI domains. I discuss my experience teaching a CI class that took the development of stock trading systems as a theme. A simple genetic algorithm to generate a trading strategy was developed as a class example. Although the astonishingly good results it achieved were due at least in part to data snooping, a simple unevolved version of the same strategy was almost as profitable. Yet it too had subtle data snooping problems-showing how difficult it is to avoid data snooping entirely, especially in adaptive domains.","2162-7657;21627657","Electronic:978-1-4244-8775-2; POD:978-1-4244-8774-5; USB:978-1-4244-8773-8","10.1109/UKCI.2010.5625605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5625605","","Biological system modeling;Computer science;Economics;Gallium;History;Machine learning","computer science education;data mining;genetic algorithms;stock markets","computational intelligence;data snooping;equity market;genetic algorithm;stock trading system;trading strategy","","1","","12","","","8-10 Sept. 2010","","IEEE","IEEE Conference Publications"
"An Approach to Building Extraction in Natural Image","L. Li; T. Jin","Dept. of Comput. Sci. & Applic., Zhengzhou Inst. of Aeronaut. Ind. Manage., Zhengzhou, China","2010 6th International Conference on Wireless Communications Networking and Mobile Computing (WiCOM)","20101014","2010","","","1","3","A new approach to building extraction is proposed. Firstly, RPCL algorithm is used to improve segmentation granularity of super-pixel algorithm; Secondly, the spatial envelope pattern is used to classify image patches using support vector machine classifier, and distinguish building from non-building category in the image; Finally, building hypothesis in the image is verified based on parallel feature of the building in the image. The experiments on standard dataset show that the proposed algorithm outperforms other building extraction algorithms, and also meet the real-time requirements in general application.","2161-9646;21619646","Electronic:978-1-4244-3707-8; POD:978-1-4244-3708-5","10.1109/WICOM.2010.5600648","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5600648","","Buildings;Classification algorithms;Feature extraction;Image segmentation;Inference algorithms;Machine learning algorithms;Semantics","feature extraction;image classification;image segmentation;support vector machines","RPCL algorithm;building extraction;building hypothesis;image patches classification;natural image;segmentation granularity;spatial envelope pattern;super-pixel algorithm;support vector machine classifier","","0","","9","","","23-25 Sept. 2010","","IEEE","IEEE Conference Publications"
"Time-series temporal classification using Feature Ensemble learning","R. Liu; Y. L. Murphey","University of Michigan - Dearborn, 48128, USA","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","5","Time series data classification is important in many applications. Learning temporal knowledge in time series data is challenging. In this paper we propose a novel machine learning algorithm, Feature Ensemble (FE), to learn effective subsequences of signal features distributed over time series data streams. Both the FE learning and the FE classification have been applied to an application problem. Our empirical results strongly suggest that FE learning is an effective technique for time series data classification.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596639","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596639","","Artificial neural networks;Data mining;Feature extraction;Iron;Machine learning;Machine learning algorithms;Time series analysis","learning (artificial intelligence);pattern classification;time series","feature ensemble learning;machine learning algorithm;temporal knowledge learning;time series data classification;time-series temporal classification","","0","","11","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"An Efficient Vietnamese Text Summarization Approach Based on Graph Model","T. A. Nguyen Hoang; H. K. Nguyen; Q. V. Tran","Fac. of Inf. Technol., Univ. of Sci., Ho Chi Minh City, Vietnam","2010 IEEE RIVF International Conference on Computing & Communication Technologies, Research, Innovation, and Vision for the Future (RIVF)","20101111","2010","","","1","6","This paper proposes an automatic method to generate an extractive summary of multiple Vietnamese documents which are related to a common topic by modeling text documents as weighted undirected graphs. It initially builds undirected graphs with vertices representing the sentences of documents and edges indicate the similarity between sentences. Then, by adopting PageRank algorithm, we can generate salient scores for sentences. Sentences are ranked according to their salient scores and selected based on Maximal marginal relevance to form the summaries. These summaries are combined and applied the same process one more time to form the final extractive summary of the document set. A series of experiments are performed on Vietnamese news articles. The results demonstrate the effectiveness of the proposed technique over reference systems.","","Electronic:978-1-4244-8075-3; POD:978-1-4244-8074-6","10.1109/RIVF.2010.5633162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5633162","","Computational modeling;Data mining;Lead;Machine learning;Meteorology;Pragmatics;Redundancy","graph theory;text analysis","PageRank algorithm;Vietnamese documents;Vietnamese text summarization approach;graph model;maximal marginal relevance;weighted undirected graphs","","1","","25","","","1-4 Nov. 2010","","IEEE","IEEE Conference Publications"
"Type 2 Generalized Intuitionistic Fuzzy Choquet Integral Operator for Multi-criteria Decision Making","H. C. Liu","Dept. of Bioinf., Asia Univ., Taichung, Taiwan","International Symposium on Parallel and Distributed Processing with Applications","20101111","2010","","","605","611","Type 2 Liu's addition and scalar multiplication operators on Mondal and Samanta's generalized intuitionistic fuzzy numbers were proposed by author's previous work, In this paper, a generalized linear aggregation operator of type 2 Liu's addition and scalar multiplication operators, called type 2 generalized intuitionistic fuzzy Choquet integral operator, is proposed, moreover, it is proved that Liu's operation-invariant partial order is appropriate for choquet integral operator on not only Atanassov's intuitionistic fuzzy numbers and Liu's generalized intuitionistic fuzzy numbers but also Mondal and Samanta's generalized intuitionistic fuzzy numbers, which can be used to handle generalized intuitionistic fuzzy multi-criteria decision making problems.","2158-9178;21589178","Electronic:978-0-7695-4190-7; POD:978-1-4244-8095-1","10.1109/ISPA.2010.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634387","Intuitionistic fuzzy numbers;generalized intuitionistic fuzzy numbers;linear aggregation operator;operation-invariant;partial order","Asia;Bioinformatics;Decision making;Lead;Logic programming;Machine learning;Pattern recognition","decision making;fuzzy set theory","Liu operation invariant partial order;intuitionistic fuzzy numbers;linear aggregation operator;multicriteria decision making;scalar multiplication operators;type 2 generalized intuitionistic fuzzy Choquet integral operator","","3","","20","","","6-9 Sept. 2010","","IEEE","IEEE Conference Publications"
"An improved KNN algorithm for text classification","Jingzhong Wang; Xia Li","College of Information Engineering, North China University of Technology, Beijing, China","2010 International Conference on Information, Networking and Automation (ICINA)","20101115","2010","2","","V2-436","V2-439","This paper analyzes the advantages and disadvantages of KNN alogrithm and introduces an improved KNN alogrithm (WPSOKN) for text classification. It is based on particle swarm optimization which has the ability of random and directed global search within training document set. During the procedure for searching k nearest neighbors of the test sample, those document vectors that are impossible to be the k closest vectors are kicked out quickly. Besides it reduces the impact of individual particles from the overall. Moreover, the interference factor is introduced to avoid premature to find the k nearest neighbors of test samples quickly. We conducted an extensive experimental study using real datasets, and the results show that the WPSOKNN algorithm is more efficient than other KNN algorithm.","2162-5476;21625476","Electronic:978-1-4244-8106-4; POD:978-1-4244-8104-0","10.1109/ICINA.2010.5636476","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5636476","KNN;Particle Swarm Optimization;Text Classification;WPSOKNN","Algorithm design and analysis;Artificial neural networks;Classification algorithms;Computers;Machine learning;Machine learning algorithms;Optimization","particle swarm optimisation;pattern classification;search problems;text analysis","directed global search;improved k nearest neighbor algorithm;particle swarm optimization;text classification","","0","","10","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"A generic approach for learning performance assessment functions","T. Palau; S. Sigl; A. Kuhn; H. A. Mayer","Andata Entwicklungstechnologie GmbH & Co KG, Hallburgstr 5, 5400 Hallein, Salzburg, Austria","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","6","This paper presents a generic machine learning based approach to devise performance assessment functions for any kind of optimization problem. The need of a performance assessment process taking into account robustness of the solutions is stressed and a general methodology for devising a function to estimate such a performance on any given engineering problem is formalized. This methodology is used as basis to train machine learning models capable of assessing performance of real world time series classification algorithms through the use of ratings from expert engineers as training data. Although the methodology presented is used on a time series classification problem, it possesses generic validity and can be easily applied to devise arbitrary scalar performance functions for complex multi-objective problems as well. The trained machine learning models can be understood as performance assessment functions that, having learned the engineer's “gut instinct”, are able to assess robustness performance in a much more objective way than a human expert could do. They represent key components for enabling automatic, computationally intensive processes such as multi-objective optimization or feature selection.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596824","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596824","","Computer crashes;Fires;Humans;Machine learning;Robustness;Sensors;Time series analysis","learning (artificial intelligence);optimisation;time series","engineering problem;feature selection;machine learning model;multiobjective optimization problem;performance assessment function;time series classification algorithms;training data","","0","","6","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Cascaded Simple Filters for Accurate and Lightweight Email-Spam Detection","M. Takesue","Dept. Appl. Inf., Hosei Univ., Tokyo, Japan","2010 Fourth International Conference on Emerging Security Information, Systems and Technologies","20101111","2010","","","160","165","Accurate spam filters, such as the Bayesian filter, need a large cost for off-line training (or learning) based on the analysis of a large corpus of email. This paper presents cascaded simple, i.e., rule-based, filters for accurate and lightweight detection of email spam. We cascade three filters that classify email based on respectively the fingerprints of message bodies, the white and black lists of email addresses in the From header, and the words specific to spam and legitimate email in the Subject header. Our filter need no training, but collect by themselves the information above when they are working, and especially when the user notifies them of their false negative decision (classifying spam as legitimate). We show by experiment with about 20,000 real world emails that the cascaded simple filters achieve the false negative rate of about 0.025 with no false positive (deciding legal email as spam) and the high performance of about 90 emails per seconds.","2162-2108;21622108","Electronic:978-1-4244-7518-6; POD:978-1-4244-7517-9","10.1109/SECURWARE.2010.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5633679","Spam filter;cascaded filters;ensemble filter;fingerprint;rule-based;white/black lists","Accuracy;Bayesian methods;Machine learning;Pattern matching;Training;Unsolicited electronic mail","Bayes methods;e-mail filters;learning (artificial intelligence);security of data;unsolicited e-mail","Bayesian filter;cascaded simple filter;email addresses;false negative decision;lightweight email spam detection;message body fingerprint;off line training;rule based filter;subject header","","0","","17","","","18-25 July 2010","","IEEE","IEEE Conference Publications"
"Clustering processing ant colony algorithm","XianMin Wei","School of Computer and Communication Engineering, Weifang University, Shandong, China","2010 Second Pacific-Asia Conference on Circuits, Communications and System","20101111","2010","2","","75","77","Contrary to TSP with clustering features, clustering processing ant colony algorithm (CPACA) is studied in this paper. CPACA first clusters cities in TSP, the TSP problem is decomposed into many small-scale sub-problems (the number of sub-problems equals to the clustering number of cities), then each sub-problem is solved using the ant colony algorithm in parallel, and solutions for all sub-problems are to be merged into the solution to solve the problem according to certain rules. As the problem is decomposed using the clustering characteristics of the problem itself, to solve each sub-problem in parallel, then to speed up the solving speed greatly.","","Electronic:978-1-4244-7970-2; POD:978-1-4244-7969-6","10.1109/PACCS.2010.5626990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5626990","clustering processing ant colony algorithm;solution in parallel;traveling salesman problem","Machine learning","optimisation;pattern clustering;travelling salesman problems","CPACA;TSP;clustering characteristics;clustering processing ant colony algorithm;small-scale sub-problems","","0","","5","","","1-2 Aug. 2010","","IEEE","IEEE Conference Publications"
"Evaluation of HTTP video classification method using flow group information","K. Takeshita; T. Kurosawa; M. Tsujino; M. Iwashita; M. Ichino; N. Komatsu","Service Integration Laboratories, NTT corporation, 3-9-11 Midori-cho Musashino-shi, Tokyo, 180-8585, Japan","2010 14th International Telecommunications Network Strategy and Planning Symposium (NETWORKS)","20101109","2010","","","1","6","Recently, the traffic volume of HTTP video applications, such as YouTube, is rapidly growing on the Internet. To support the quality of service requirements of HTTP video applications, network carriers need to design bandwidth by taking into account the traffic volume of HTTP video applications. However, since most HTTP video applications are provided in a web browser, it is difficult to classify HTTP video applications with other web applications by the port number. We propose an HTTP video application classification method by using a machine learning method with traffic-flow features such as packet size. We propose a new feature that is useful in classifying HTTP video applications. We can improve the accuracy of traffic classification of HTTP video applications by 12%. Furthermore, we compare the accuracy and calculation time among three machine learning methods.","","Electronic:978-1-4244-6705-1; POD:978-1-4244-6704-4","10.1109/NETWKS.2010.5624929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5624929","","Accuracy;Classification algorithms;Decision trees;IP networks;Learning systems;Machine learning;Streaming media","Internet;image classification;learning (artificial intelligence);quality of service;social networking (online);telecommunication traffic;video communication","HTTP video classification method;Internet;Web browser;YouTube;flow group information;machine learning method;quality of service requirements;traffic classification;traffic volume;traffic-flow features","","6","","23","","","27-30 Sept. 2010","","IEEE","IEEE Conference Publications"
"A novel emotion recognition approach based on ensemble learning and rough set theory","Y. Yang; G. Wang; Z. Zhang; K. Tian","Institute of Computer Science & Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, P.R. China","Cognitive Informatics (ICCI), 2010 9th IEEE International Conference on","20101011","2010","","","46","52","Emotion recognition is very important for applications of human-computer intelligent interaction. It is always performed on facial or audio information with such method as ANN, fuzzy set, SVM, HMM, etc. Ensemble learning is a hot topic in machine learning and ensemble method is proved an effective pattern recognition method. In this paper, a novel ensemble learning method which is based on selective ensemble feature selection and rough set theory is proposed, and it meets the tradeoff between the accuracy and diversity of base classifiers. Moreover, the proposed method is taken as an emotion recognition method and proved to be effective according to the simulation experiments.","","Electronic:978-1-4244-8042-5; POD:978-1-4244-8041-8","10.1109/COGINF.2010.5599818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599818","emotion recognition;ensemble learning;feature selection;rough set;selective ensemble","Artificial neural networks;Classification algorithms;Emotion recognition;Information systems;Machine learning;Set theory;Training","emotion recognition;human computer interaction;learning (artificial intelligence);rough set theory","ANN;HMM;effective pattern recognition method;emotion recognition approach;ensemble learning method;fuzzy set theory;human-computer intelligent interaction;machine learning;rough set theory;selective ensemble feature selection","","0","","32","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Chinese Text Classification Based on Extended Naïve Bayes Model with Weighed Positive Features","Y. Qiu; G. Yang; Z. Tan","Software Coll., Northeastern Univ., Shenyang, China","2010 First International Conference on Pervasive Computing, Signal Processing and Applications","20101115","2010","","","243","246","As a simple but efficient classification method, Naive Bayes algorithm has shown its desirable characters in many fields. However, the effect still needs to be improved for applying in practice. In this paper, we construct an extended model with assigning weights to some important features. A method called CF is used to measure the relevance between a feature and a category to make up the deficiency of CHI-Square statistic method. We select best features based on a new proposed method called CHCFW to reinforce the distribution of key features in a document and remove the disturbed features. Compared with the original Naïve Bayes model and other algorithm to assign weight to features, the experiment results show that CHCFW method performs better and more appropriate to larger amounts of training documents.","","Electronic:978-0-7695-4180-8; POD:978-1-4244-8043-2","10.1109/PCSPA.2010.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635946","CHCFW method;Extended Bayes Model;assign weight;dependency type;feature selection","Classification algorithms;Computational modeling;Machine learning;Signal processing algorithms;Text categorization;Training;Vocabulary","Bayes methods;natural language processing;pattern classification;text analysis","CHI-Square statistic method;Chinese text classification;extended Naïve Bayes model;weighed positive features","","0","","11","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"A study of integrating artificial immune system and artificial neural network in real estate evaluation","P. C. Chen; K. J. Zhu; Y. T. Chang","Schoof of Economics and Management, China University of Geosciences, Wuhan 430074, China","2010 Second Pacific-Asia Conference on Circuits, Communications and System","20101111","2010","1","","374","378","This study integrates artificial immune system and artificial neural network into a real estate evaluation model. Artificial immune system has the abilities of self-organizing, memory, recognition, adaptive, and ability of learning. It can be applied to nonlinear system identification and provided various feasible system models with robust and adaptive characteristics. Artificial neural network doesn't need any complicated mathematics application and its self-learning, self-adaptive capacity, parallel processing capability and strong fault tolerance can obtain more accurate non-linear outputs from various impact factors. The result of this study indicates that the integration of artificial immune system and artificial neural network can achieve promptly accurate and satisfactory results in the real estate evaluation.","","Electronic:978-1-4244-7970-2; POD:978-1-4244-7969-6","10.1109/PACCS.2010.5626963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5626963","artificial immune system;artificial neural network;real estate evaluation","Book reviews;Machine learning","artificial immune systems;neural nets;real estate data processing","artificial immune system;artificial neural network;nonlinear system identification;real estate evaluation model","","0","","17","","","1-2 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Multi-agent System for Complex Vehicle Fault Diagnostics and Health Monitoring","Y. L. Murphey; Z. Chen","Dept. of Electr. & Comput. Eng., Univ. of Michigan-Dearborn, Dearborn, MI, USA","2010 15th IEEE International Conference on Engineering of Complex Computer Systems","20101111","2010","","","257","258","This paper presents a multi-agent system(MAS_VFD&HM) developed for complex vehicle fault diagnosis and health monitoring. The MAS_VFD&HM consists of signal diagnostic agents, special case agents, and a vehicle diagnostic/monitoring agent. A signal agent is responsible for the fault diagnosis or monitoring of one particular signal using either a single signal or multiple signals depending on the complexity of signal faults. Special case agents are those trained to detect specific component faults. All these agents are autonomous and report their results to the Vehicle System Agent. A computational framework is presented for agent learning and agent operation. The proposed MAS_VFD&HM is scalable, versatile, and has the capability of dealing complex problems such as multiple faults in a vehicle system. Although our focus was on the automotive diagnostics, the proposed MAS_VFD&HM is applicable to complex engineering diagnostic problems beyond vehicles.","","Electronic:978-1-4244-6639-9; POD:978-1-4244-6638-2","10.1109/ICECCS.2010.4","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5628605","component;multi-agent systems;signal analysis;vehicle fault diagnostics","Automotive engineering;Fault diagnosis;Feature extraction;Machine learning;Monitoring;Multiagent systems;Vehicles","automotive engineering;condition monitoring;fault diagnosis;multi-agent systems;signal processing","MAS_VFD&HM;agent learning;agent operation;automotive diagnostics;complex engineering diagnostic problem;complex vehicle fault diagnosis;fault detection;health monitoring;multiagent system;signal diagnostic agent;signal fault;special case agent;vehicle diagnostic agent;vehicle monitoring agent;vehicle system agent","","0","","3","","","22-26 March 2010","","IEEE","IEEE Conference Publications"
"Computational approaches for emotion detection in text","H. Binali; C. Wu; V. Potdar","Digital Ecosystems Business Intelligence Institute, Curtin University of Technology, Perth, Australia","4th IEEE International Conference on Digital Ecosystems and Technologies","20101025","2010","","","172","177","Emotions are part and parcel of human life and among other things, highly influence decision making. Computers have been used for decision making for quite some time now but have traditionally relied on factual information. Recently, interest has been growing among researchers to find ways of detecting subjective information used in blogs and other online social media. This paper presents emotion theories that provide a basis for emotion models. It shows how these models have been used by discussing computational approaches to emotion detection. We propose a hybrid based architecture for emotion detection. The SVM algorithm is used for validating the proposed architecture and achieves a prediction accuracy of 96.43% on web blog data.","2150-4938;21504938","Electronic:978-1-4244-5553-9; POD:978-1-4244-5551-5","10.1109/DEST.2010.5610650","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5610650","Emotion detection;Emotion models;Sentiment analysis;Text classification","Biological system modeling;Classification algorithms;Logic gates;Machine learning;Semantics;Syntactics;Training","Web sites;decision making;support vector machines;text analysis","SVM algorithm;blogs;computational approaches;decision making;emotion detection;emotion models;emotion theories;factual information;hybrid based architecture;online social media;subjective information;text","","11","","21","","","13-16 April 2010","","IEEE","IEEE Conference Publications"
"Random subspace method based on Canonical Correlation Analysis","Y. Zhu","College of Information and Science Technology Nanjing University of Aeronautics Astronautics Nanjing, China","2010 3rd International Congress on Image and Signal Processing","20101129","2010","1","","185","188","Random subspace method (RSM) is a successful ensemble construction technique for classification and its success mainly lies in that it could generate quite diverse component classifiers. However, the recognition accuracy of the component classifier is often insufficient due to its random selection of inputs. In this paper, to improve the accuracy of the component classifier and further gain high performance ensemble classifier, I introduce the idea of information fusion into RSM and propose a new method called RS CCA. RS CCA fuses randomly selected features and global features using Canonical Correlation Analysis (CCA) method, so it can obtain the feature sets containing global information. The experiments on 13 UCI datasets show RS CCA is very effective to improve the performance of RSM. In addition, an analysis about average diversity and average accuracy is given to explain why RS CCA can yield better performance than RSM.","","Electronic:978-1-4244-6516-3; POD:978-1-4244-6513-2","10.1109/CISP.2010.5648017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5648017","","Accuracy;Algorithm design and analysis;Databases;Diversity reception;Feature extraction;Machine learning;Sonar","correlation methods;pattern classification;random processes","CCA method;RS CCA;RSM;UCI datasets;average accuracy;average diversity;canonical correlation analysis;component classifiers;ensemble construction technique;feature sets;global information;high performance ensemble classifier;information fusion;random subspace method;recognition accuracy","","1","","17","","","16-18 Oct. 2010","","IEEE","IEEE Conference Publications"
"Efficient Parallel Top-k Computation Algorithm Using Symmetry Breaking","C. Wu; G. z. Sun; G. l. Chen","Anhui Key Lab. of High Performance Comput., Univ. of Sci. & Technol. of China, Hefei, China","International Symposium on Parallel and Distributed Processing with Applications","20101111","2010","","","231","235","A key problem of relational database is to aggregate different values of the same object and find the first k objects with highest overall values. Many sequential algorithms have been proposed to solve this problem. In this paper, we propose a new parallel algorithm using symmetry breaking strategy. New algorithm is proved to be instance optimal. Experiment results on both synthetic and real data also show that new algorithm costs fewer accesses, compared to previous algorithms.","2158-9178;21589178","Electronic:978-0-7695-4190-7; POD:978-1-4244-8095-1","10.1109/ISPA.2010.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634337","","Algorithm design and analysis;Arrays;Computers;Databases;Machine learning;Software;Sun","parallel algorithms;relational databases;spontaneous symmetry breaking","parallel top-k computation algorithm;relational database;symmetry breaking strategy","","0","","12","","","6-9 Sept. 2010","","IEEE","IEEE Conference Publications"
"Efficient resampling methods for training support vector machines with imbalanced datasets","R. Batuwita; V. Palade","Oxford University Computing Laboratory, Wolfson Building, Parks Road, OX1 3QD, UK","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","Random undersampling and oversampling are simple but well-known resampling methods applied to solve the problem of class imbalance. In this paper we show that the random oversampling method can produce better classification results than the random undersampling method, since the oversampling can increase the minority class recognition rate by sacrificing less amount of majority class recognition rate than the undersampling method. However, the random oversampling method would increase the computational cost associated with the SVM training largely due to the addition of new training examples. In this paper we present an investigation carried out to develop efficient resampling methods that can produce comparable classification results to the random oversampling results, but with the use of less amount of data. The main idea of the proposed methods is to first select the most informative data examples located closer to the class boundary region by using the separating hyperplane found by training an SVM model on the original imbalanced dataset, and then use only those examples in resampling. We demonstrate that it would be possible to obtain comparable classification results to the random oversampling results through two sets of efficient resampling methods which use 50% less amount of data and 75% less amount of data, respectively, compared to the sizes of the datasets generated by the random oversampling method.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596787","","Computational efficiency;Computational modeling;Digital signal processing;Machine learning;Support vector machines;Testing;Training","data handling;sampling methods;support vector machines","SVM model;class imbalance problem;imbalanced datasets;random oversampling method;random undersampling method;resampling methods;support vector machines","","9","","17","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Multi-Agent Intelligent Simulator to estimate U.S. wholesale price of electricity","T. Sueyoshi; M. Goto","Management Department, New Mexico Institute of Mining & Technology, Socorro, USA","2010 IEEE International Conference on Systems, Man and Cybernetics","20101122","2010","","","3278","3283","This study examines the price estimation capability of MAIS (Multi-Agent Intelligent Simulator) when two types of agents with different learning capabilities coexist in a power trading market. This study identifies that the proposed MAIS, considering the coexistence of different types of agents, can improve its estimation accuracy of wholesale electricity price. This study also reexamines the estimation capability of the MAIS on a data set generated by the mean reverting method. Using a real data set regarding PJM and its simulated data sets, we confirm that the proposed MAIS performs as well as the other well-known computer science approaches (SVM: Support Vector Machines, NN: Neural Networks, and GA: Genetic Algorithm) in terms of price estimation.","1062-922X;1062922X","Electronic:978-1-4244-6588-0; POD:978-1-4244-6586-6","10.1109/ICSMC.2010.5642314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5642314","Agent-based Approach;Mean Reverting Model;Numerical Analysis;Power Trading","Artificial neural networks;Complexity theory;Electricity;Estimation;Gallium;Machine learning;Support vector machines","genetic algorithms;multi-agent systems;neural nets;power engineering computing;power markets;pricing;support vector machines","US wholesale electricity price estimation;genetic algorithm;learning capabilities;mean reverting method;multiagent intelligent simulator;neural networks;power trading market;support vector machines","","0","","22","","","10-13 Oct. 2010","","IEEE","IEEE Conference Publications"
