"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7729176,7723716,7724731,7723739,7723730,7606789,7606913,7258342,7576681,7603340,7603153,7603391,7603410,7603401,7603365,7603262,7600211,7600183,7600385,7591015,7591386,7591263,7591222,7591525,7590766,7592193,7590963,7590785,7590649,7591186,7590781,7590823,7590799,7588947,7588835,7589715,7559716,7586437,7586606,7587490,7587466,7581275,7586429,7584933,7582712,7584931,7582745,7584940,7582749,7581411,7496826,7574389,7582441,7581018,7405235,7576885,7578241,7578384,7578530,7578673,7559702,7560597,7579229,7574841,7574866,7574756,7574872,7576472,7573137,7571863,7573526,7571941,7570937,7569734,7542548,7348689,7566051,7566318,7568891,7513378,7565166,7567344,7547961,7564067,7465842,7465766,7561733,7562974,7561206,7562248,7561432,7562283,7560007,7559588,7560389,7559560,7558609,7559072,7558064,7556003",2017/05/05 22:32:05
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An asynchronous multi-view learning approach for activity recognition using wearables","Y. Ma; H. Ghasemzadeh","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA 99164 USA","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","3105","3108","In this paper, we introduce an Asynchronous Multiview Learning (AML) approach to allow accurate transfer of activity classification models across asynchronous sensor views. Our study is motivated by the highly dynamic nature of health monitoring using wearable sensors. Such dynamics include changes in sensing platform (e.g., sensor upgrade) and platform settings (e.g., sampling frequency, on-body sensor location), which result in failure of the machine learning algorithms if they remain untrained in the new setting. Our approach allows machine learning algorithms to automatically reconfigure without any need for labeled training data in the new setting. Our evaluation using real data collected with wearable motion sensors demonstrates that the average classification accuracy using our automatically labeled training data is 85.2%. This accuracy is only 3.4% to 4.5% less than the experimental upper bound, where ground truth labeled training data are used to develop a new activity recognition classifier.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591386","","Heuristic algorithms;Labeling;Machine learning algorithms;Training;Training data;Upper bound","learning (artificial intelligence);medical signal processing;patient monitoring;pattern classification;wireless sensor networks","activity classification model;activity recognition classifier;asynchronous multiview learning approach;asynchronous sensor view;health monitoring;machine learning algorithm;on-body sensor location;wearable motion sensor","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Predicting semantically linkable knowledge in developer online forums via convolutional neural network","B. Xu; D. Ye; Z. Xing; X. Xia; G. Chen; S. Li","College of Computer Science and Technology, Zhejiang University, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","20161006","2016","","","51","62","Consider a question and its answers in Stack Overflow as a knowledge unit. Knowledge units often contain semantically relevant knowledge, and thus linkable for different purposes, such as duplicate questions, directly linkable for problem solving, indirectly linkable for related information. Recognising different classes of linkable knowledge would support more targeted information needs when users search or explore the knowledge base. Existing methods focus on binary relatedness (i.e., related or not), and are not robust to recognize different classes of semantic relatedness when linkable knowledge units share few words in common (i.e., have lexical gap). In this paper, we formulate the problem of predicting semantically linkable knowledge units as a multiclass classification problem, and solve the problem using deep learning techniques. To overcome the lexical gap issue, we adopt neural language model (word embeddings) and convolutional neural network (CNN) to capture word- and document-level semantics of knowledge units. Instead of using human-engineered classifier features which are hard to design for informal user-generated content, we exploit large amounts of different types of user-created knowledge-unit links to train the CNN to learn the most informative wordlevel and document-level features for the multiclass classification task. Our evaluation shows that our deep-learning based approach significantly and consistently outperforms traditional methods using traditional word representations and human-engineered classifier features.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582745","Deep learning;Link prediction;Mining software repositories;Multiclass classification;Semantic relatedness","Complex networks;Knowledge engineering;Machine learning;Semantics;Social network services;Software;Uniform resource locators","data mining;learning (artificial intelligence);neural nets;pattern classification;social networking (online)","CNN;Stack Overflow;binary relatedness;convolutional neural network;deep learning techniques;developer online forums;document-level semantics;human-engineered classifier features;informal user-generated content;information needs;knowledge unit;multiclass classification problem;neural language model;semantically linkable knowledge prediction;word embeddings;word representation;word-level semantics","","","","","","","3-7 Sept. 2016","","IEEE","IEEE Conference Publications"
"Improving the face recognition system by hybrid image preprocessing","C. Cui; X. Wang; H. Shen","School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, Guangdong Province, China","2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","20160926","2016","","","442","447","In this paper we present a framework for improving face recognition system that have several stages. Some improvements of every stage are very important to the recognition results. Driven by this intuition, we proposed a novel scheme that gives the system a better performance. The scheme including dataset augment for learning, especially for big data requirement of deep learning. Enhancing the image contrast ratio and rotate the image for several angles that can improve the detection accuracy. Then, cropping the face in appropriate area for feature extraction and getting the optimal feature vector for face recognition at last.","","Electronic:978-1-5090-2733-0; POD:978-1-5090-2734-7; USB:978-1-5090-2732-3","10.1109/CYBER.2016.7574866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574866","deep learning;face recognition;framwork;preprocessing","Face;Face detection;Face recognition;Feature extraction;Machine learning;Skin;Transforms","face recognition;feature extraction;image enhancement;learning (artificial intelligence)","Big Data;deep learning;face recognition system;feature extraction;feature vector;hybrid image preprocessing;image contrast ratio enhancement","","","","","","","19-22 June 2016","","IEEE","IEEE Conference Publications"
"Learnability of the Moving Surface Profiles of a Soft Robotic Sorting Table","M. Stommel; W. Xu","Department of Electrical and Electronic Engineering, Auckland University of Technology, Auckland, New Zealand","IEEE Transactions on Automation Science and Engineering","20161005","2016","13","4","1581","1587","This paper analyzes the application of machine learning techniques to the control of a soft, peristaltic, xy-sorting table. In particular, we address peristaltic tables made of a soft upper silicone layer and actuated by an array of integrated air-filled chambers. The chambers are pneumatically inflated in order to deform the table and move objects on the table. To control the robot precisely, it is necessary to model both the inverse mapping between the control signals of the actuators and the resulting surface deformation. There is currently no parametric model available. In this paper, we, therefore, study if nonparametric approaches are applicable. In these approaches, the mapping would be learned from a database of input signals and observed behaviors. From our analysis, we conclude that the most promising research direction consists in the nonparametric modeling of a limited set of peristaltic actuation patterns. However, the nonlinear hardware design that impedes a parametric model also affects the nonparametric optimization process. Our simulation suggests that the optimization is nonconvex, approximately monotonous, and feasible in terms of the number of observations of the physical robot.","1545-5955;15455955","","10.1109/TASE.2016.2570208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496826","Control;peristalsis;radial basis functions;soft robotics","Machine learning;Optimization;Radial basis function networks;Robot control;Simulation;Soft robotics;Sorting","control engineering computing;learning (artificial intelligence);optimisation;robots","air-filled chamber;inverse mapping;machine learning;moving surface profile;nonlinear hardware design;nonparametric optimization;peristaltic actuation pattern;peristaltic table;soft robotic sorting table;soft upper silicone layer;surface deformation","","","","","","20160621","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Featue selection effects on kidney desease analysis","Z. Sedighi; H. Ebrahimpour-Komleh; S. J. Mousavirad","Department of Computer Engineering, Faculty of Computer and Electrical Engineering, University of Kashan, Kashan, I.R. Iran","2015 International Congress on Technology, Communication and Knowledge (ICTCK)","20161006","2015","","","455","459","Chronic kidney disease is a universal common obstacle which its outcomes can be prevented or delayed by early detection and cure. Classification of kidney disease is vital for global improvement and accomplishment of practical guidance. Therefore, data mining and machine learning techniques can be used to discover knowledge and identify patterns for classification. Since there exist features that make noise or have low information, feature selection issue identifies useful subset of features from raw data. The fact that dimensionality reduction improves computation performance creates fast and low-cost classifiers and produces quick classified models, makes it popular in data mining and machine learning techniques. In this article, we use a set of filter and wrapper methods followed by machine learning techniques to classify chronic kidney disease. We show that feature selection techniques enable us to perform precise classification in minimum time using fewer dimensions.","","","10.1109/ICTCK.2015.7582712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582712","chronic kidney disease;classification;data minig;feature subset selection;knowledge discovery","Classification algorithms;Computers;Diseases;Genetic algorithms;Kernel;Kidney;Machine learning algorithms","data mining;diseases;feature selection;filters;kidney;learning (artificial intelligence);medical computing;pattern classification","chronic kidney disease analysis;computation performance;data mining;feature selection effects;feature subset;filter set;kidney disease classification;knowledge discovery;low-cost classifiers;machine learning techniques;pattern classification;pattern identification;practical guidance;raw data;wrapper methods","","","","","","","11-12 Nov. 2015","","IEEE","IEEE Conference Publications"
"Exploiting Fuzzy Clustering and Case-Based Reasoning for Autonomic Managers","C. Khan; M. J. Khan","Dept. of Comput. Sci., Namal Coll., Mianwali, Pakistan","2016 IEEE International Conference on Autonomic Computing (ICAC)","20160922","2016","","","225","226","Designing efficient self-management algorithms for autonomic managers has been an ongoing and evolving research area. In literature, many machine learning paradigms have been proposed and exploited to make effective decisions in autonomic managers. This position paper proposes to optimize the decision making algorithm closer to the nature inspired decision making process. Core of the proposed framework is case-based reasoning which is an incremental learning mechanism for solving new system problems using the past experience. Fuzzy clustering has been proposed to maintain the knowledge-base of past problems in autonomic managers. New monitored problem in autonomic manager seeks fuzzy memberships amongst different clusters in the knowledge-base and problem solver in autonomic manager exploits existing solutions in different clusters with respect to their fuzzy membership value. It has been tested on a simulated case-study of Autonomic Forest Fire Application and up to 88% accurate predictions have been observed.","","Electronic:978-1-5090-1654-9; POD:978-1-5090-1655-6","10.1109/ICAC.2016.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573137","","Autonomic systems;Clustering algorithms;Cognition;Computational modeling;Knowledge based systems;Machine learning algorithms;Monitoring","case-based reasoning;decision making;emergency management;environmental science computing;fuzzy set theory;knowledge based systems;learning (artificial intelligence);optimisation;pattern clustering;problem solving;wildfires","CBR;autonomic forest fire;autonomic manager;case-based reasoning;decision making algorithm optimization;fuzzy clustering;knowledge-base system;machine learning;problem solver;self-management algorithm","","","","","","","17-22 July 2016","","IEEE","IEEE Conference Publications"
"Internet traffic data categorization using particle of swarm optimization algorithm","N. Shrivastava; A. Dubey","Computer Science and Engineering, Oriental College of Technology, Bhopal, India","2016 Symposium on Colossal Data Analysis and Networking (CDAN)","20160919","2016","","","1","8","The clustering technique plays an important role in data mining process. For the mining of internet traffic data faced a lot of problem of noise and internet traffic number of iteration. The process of pattern generation used two type of technique such as supervised learning and unsupervised learning. In unsupervised learning clustering process are used. The varieties of clustering technique are used such as k-means, FCM and constraints clustering technique. The constraints clustering technique gives the two solution approach one is seed selection and another is mapping of seed in terms of constraint of center. In this paper modified the seed selection process using genetic algorithm technique. The genetic algorithm process select variable value one is seed value and another is constraint of center value. In constraints cluster technique used some value of center and generates new center value of new cluster for the better generation of cluster. For more improvement of constraints clustering technique used two level constraints clustering technique for better improvement of cluster technique. In this dissertation modified the constraints clustering technique for improvement. In the process of improvement used genetic algorithm technique. Genetic algorithm technique gives the better selection of seed for internet traffic database. For the performance evaluation of proposed algorithm used three real time dataset from UCI machine learning center. The proposed algorithm implemented in MATLAB software and measures some standard parameter for the validation of proposed methodology.","","","10.1109/CDAN.2016.7570937","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7570937","Classification;Clustering;FCM;GA;UCI","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Data mining;Internet;Machine learning algorithms;Prediction algorithms","Internet;data mining;genetic algorithms;particle swarm optimisation;pattern clustering;performance evaluation;telecommunication traffic;unsupervised learning","Internet traffic data categorization;MATLAB software;UCI machine learning center;constraints clustering;data clustering;data mining;genetic algorithm;particle swarm optimisation;pattern generation;performance evaluation;seed selection;unsupervised learning clustering;variable value selection","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Integrated brain implant using Nano memory","L. Yuvaraj; S. R. Sankar; D. Selvaraj","Department of ECE, Panimalar Engineering College, India","2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","20160915","2016","","","1159","1163","The main aim of this paper is to make the human to use their intelligence and the memory which the computer works with. This bio medical document is the live aspects that make the human to target everything with this tiny memory device, connected to the human brain. Internet is ruling the world for many years, like that this brain memory integrated technology will have the same effect among every people. The vast world is really our memory, we circle every minute of our thinking around it. This device makes it possible to recollect the memories simply as the same way you felt during that moment. This device makes a revolution in the thinking of a human. It is a mini-device, compatible to the size as similar to the phase maker and it has some extra features as follows: (1) placed inside of human body, (2) connected to our Neurons and works with the help of battery, and (3) consist of Nano memory (CNT) having vast storage. So now we can see the intelligence of this great device. This memory is processed through voice and optical support signal that travel through nervous system of neurons. Every nerve in our body produces electrical pulse that carries information and these information are processed as fast as the device can. Hence this device is called intellectual chip. Using this device, humans will be free of memorizing things because this device stores everything they have been encountered in the Nano memory.","","","10.1109/WiSPNET.2016.7566318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566318","CNT;Nano memory;electrical pulse","Axons;Clustering algorithms;Electric potential;Electrodes;Machine learning algorithms;Nanoscale devices","Internet;bioelectric phenomena;biomedical electronics;brain;medical signal processing;nanomedicine;neurophysiology;prosthetics;speech;speech processing","Internet;battery;biomedical document;brain memory integrated technology;electrical pulse;feature extraction;human brain;integrated brain implant;intellectual chip;memory processing;minidevice;nanomemory;nervous system;neurons;optical support signal;tiny memory device;voice","","","","","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Saliency meets spatial quantization: A practical framework for large scale product search","Shuhan Qi; K. Zawlin; Hanwang Zhang; Xuan Wang; Ke Gao; Lin Yao; Tat-seng Chua","Harbin Institute of Technology ShenZhen Graduate School, China","2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","20160926","2016","","","1","6","Product image search aims to retrieve similar product images based on a query image. While deep learning based features work well in retrieving images of the same category (e.g. “searching for T-shirts from all the clothing images”), they perform poorly when retrieving variants of images within the same category (e.g. “searching for uniform of Chelsea football club from all T-shirts image”), since it requires fine grained matching on image details. In this paper, we present a spatial quantization approach that utilizes spatial pyramid pooling (SPP) and vector of locally aggregated descriptors (VLAD) to extract more discriminative features for style-aware product search. By using the proposed spatial quantization, spatial information is encoded into the image feature to improve the fine grained product image search. Finally, the experiments on a large scale real world dataset provided by Alibaba large-scale image search challenge (ALISC) demonstrate the effectiveness of our method.","","","10.1109/ICMEW.2016.7574756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574756","image retrieval;salient region detection;vector quantization","Feature extraction;Image representation;Image retrieval;Machine learning;Quantization (signal);Robustness;Transforms","feature extraction;image coding;image retrieval;quantisation (signal)","ALISC;Alibaba large-scale image search challenge;SPP;deep learning based features;discriminative feature extraction;grained image matching;grained product image searching;image querying;large scale product search;saliency;similar product image retrieval;spatial information encoding;spatial pyramid pooling;spatial quantization approach;style-aware product searching;vector of locally aggregated descriptors","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Human action recognition with DeepAction Kernel Gaussian Process","Y. Wang; L. Li; Y. Qiao","Guangdong Key Lab of Comp. Vis. & Vi. Real., Shenzhen Institutes of Advanced Technology, CAS, China","2016 International Conference on Advanced Robotics and Mechatronics (ICARM)","20161027","2016","","","165","170","Human action recognition is a challenging vision task due to the complex action patterns in the real-world videos. In this work, we propose a DeepAction Kernel Gaussian Process, which takes advantage of Gaussian process (GP) and deep learning, to capture the distinctive action characteristics. Specifically, we design a unified, deep and non-adjacent kernel structure within Gaussian process to classify different actions. First, we design an adaptive GMM kernel (adGMMK) to encode the low-level features of different actions in a specific manner. Second, inspired by the theoretical connections between neural network and GP, we transform our shallow kernels into deep kernels to learn actions with their high-level representations. Finally, we propose a novel non-adjacent kernel framework to leverage the benefits from both shallow and deep kernels for action classification. Our experimental results on two benchmark data sets (HMDB51 and UCF101) show the superior performance of our approach, in comparison with several relevant works.","","","10.1109/ICARM.2016.7606913","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7606913","","Feature extraction;Gaussian processes;Kernel;Machine learning;Neural networks;Transforms;Videos","Gaussian processes;computer vision;image classification;image representation;learning (artificial intelligence);video signal processing","DeepAction kernel Gaussian process;HMDB51 data sets;UCF101 data sets;action classification;adGMMK;adaptive GMM kernel;computer vision task;deep kernels;deep learning;high-level representations;human action recognition;nonadjacent kernel structure;real-world videos;shallow kernels","","","","","","","18-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"KinLinks: Software Toolkit for kinship analysis and pedigree generation from HTS datasets","A. Shcherbina; D. O. Ricke; E. Schwoebel; T. Boettcher; C. Zook; J. Bobrow; M. Petrovick; E. Wack","Bioengineering Systems and Technologies, Massachusetts Institute of Technology, Lexington, MA USA","2016 IEEE Symposium on Technologies for Homeland Security (HST)","20160915","2016","","","1","6","The ability to predict familial relationships from source DNA in multiple samples has a number of forensic and medical applications. Kinship testing of suspect DNA profiles against relatives in a law enforcement database can provide valuable investigative leads, determination of familial relationships can inform immigration decisions, and remains identification can provide closure to families of missing individuals. The proliferation of High-Throughput Sequencing technologies allows for enhanced capabilities to accurately predict familial relationships to the third degree and beyond. KinLinks, developed by MIT Lincoln Laboratory, is a software tool that predicts pairwise relationships and reconstructs kinship pedigrees for multiple input samples using single-nucleotide polymorphism (SNP) profiles. The software has been trained and evaluated on a set of 175 subjects (30,450 pairwise relationships), consisting of three multi-generational families and 52 geographically diverse subjects. Though a panel of 5396 SNPs was selected for kinship prediction, KinLinks is highly modular, allowing for the substitution of expanded SNP panels and additional training models as sequencing capabilities continue to progress. KinLinks builds on the SNP-calling capabilities of Sherlocks Toolkit, and is fully integrated with the Sherlocks Toolkit pipeline.","","","10.1109/THS.2016.7568891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568891","","DNA;Law enforcement;Machine learning algorithms;Sequential analysis;Software;Testing;Training","DNA;bioinformatics;data analysis","DNA;HTS dataset;KinLinks;MIT Lincoln Laboratory;SNP profile;Sherlocks Toolkit pipeline;familial relationship prediction;forensic application;high-throughput sequencing technology;kinship analysis;kinship pedigree reconstruction;kinship testing;law enforcement database;medical application;pairwise relationship prediction;pedigree generation;sequencing capability;single-nucleotide polymorphism profile;software toolkit","","","","","","","10-11 May 2016","","IEEE","IEEE Conference Publications"
"Detection of mitotic nuclei in breast histopathology images using localized ACM and Random Kitchen Sink based classifier","K. S. Beevi; M. S. Nair; G. R. Bindu","Electrical Engineering Department, College of Engineering Trivandrum, Thiruvananthapuram-695016, Kerala, India","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2435","2439","The exact measure of mitotic nuclei is a crucial parameter in breast cancer grading and prognosis. This can be achieved by improving the mitotic detection accuracy by careful design of segmentation and classification techniques. In this paper, segmentation of nuclei from breast histopathology images are carried out by Localized Active Contour Model (LACM) utilizing bio-inspired optimization techniques in the detection stage, in order to handle diffused intensities present along object boundaries. Further, the application of a new optimal machine learning algorithm capable of classifying strong non-linear data such as Random Kitchen Sink (RKS), shows improved classification performance. The proposed method has been tested on Mitosis detection in breast cancer histological images (MITOS) dataset provided for MITOS-ATYPIA CONTEST 2014. The proposed framework achieved 95% recall, 98% precision and 96% F-score.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591222","","Correlation;Entropy;Feature extraction;Image color analysis;Image segmentation;Machine learning algorithms;Shape","biomedical optical imaging;cancer;image classification;image segmentation;learning (artificial intelligence);medical image processing","bioinspired optimization techniques;breast cancer grading;breast cancer histological images;breast cancer prognosis;breast histopathology images;classification techniques;localized active contour model;mitosis detection;mitotic detection;mitotic nuclei;nonlinear data;optimal machine learning algorithm;random kitchen sink-based classifier;segmentation techniques","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Distributed Reservoir Computing with Sparse Readouts [Research Frontier]","S. Scardapane; M. Panella; D. Comminiello; A. Hussain; A. Uncini","DIET, Sapienza University of Rome, Rome, Italy","IEEE Computational Intelligence Magazine","20161010","2016","11","4","59","70","In a network of agents, a widespread problem is the need to estimate a common underlying function starting from locally distributed measurements. Real-world scenarios may not allow the presence of centralized fusion centers, requiring the development of distributed, message-passing implementations of the standard machine learning training algorithms. In this paper, we are concerned with the distributed training of a particular class of recurrent neural networks, namely echo state networks (ESNs). In the centralized case, ESNs have received considerable attention, due to the fact that they can be trained with standard linear regression routines. Based on this observation, in our previous work we have introduced a decentralized algorithm, framed in the distributed optimization field, in order to train an ESN. In this paper, we focus on an additional sparsity property of the output layer of ESNs, allowing for very efficient implementations of the resulting networks. In order to evaluate the proposed algorithm, we test it on two well-known prediction benchmarks, namely the Mackey-Glass chaotic time series and the 10th order nonlinear auto regressive moving average (NARMA) system.","1556-603X;1556603X","","10.1109/MCI.2016.2601759","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7587490","","Algorithm design and analysis;Linear regression;Machine learning algorithms;Optimization;Recurrent neural networks;Regression analysis;Training data","distributed processing;learning (artificial intelligence);optimisation;recurrent neural nets;regression analysis","10th order nonlinear auto regressive moving average system;ESNs;Mackey-Glass chaotic time series;NARMA system;decentralized algorithm;distributed message-passing;distributed reservoir computing;echo state networks;linear regression;locally distributed measurements;machine learning training algorithms;optimization field;recurrent neural networks;sparse readouts","","","","","","","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Melanoma detection by analysis of clinical images using convolutional neural network","E. Nasr-Esfahani; S. Samavi; N. Karimi; S. M. R. Soroushmehr; M. H. Jafari; K. Ward; K. Najarian","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan 84156-83111, Iran","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","1373","1376","Melanoma, most threatening type of skin cancer, is on the rise. In this paper an implementation of a deep-learning system on a computer server, equipped with graphic processing unit (GPU), is proposed for detection of melanoma lesions. Clinical (non-dermoscopic) images are used in the proposed system, which could assist a dermatologist in early diagnosis of this type of skin cancer. In the proposed system, input clinical images, which could contain illumination and noise effects, are preprocessed in order to reduce such artifacts. Afterward, the enhanced images are fed to a pre-trained convolutional neural network (CNN) which is a member of deep learning models. The CNN classifier, which is trained by large number of training samples, distinguishes between melanoma and benign cases. Experimental results show that the proposed method is superior in terms of diagnostic accuracy in comparison with the state-of-the-art methods.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590963","","Computers;Feature extraction;Lesions;Lighting;Machine learning;Malignant tumors;Training","biomedical optical imaging;cancer;graphics processing units;image classification;image denoising;learning (artificial intelligence);medical image processing;neural nets;skin","CNN classifier;artifact reduction;clinical image analysis;convolutional neural network;deep-learning system;diagnostic accuracy;early skin cancer diagnosis;graphic processing unit;illumination effect;input clinical image;melanoma detection;noise effect;nondermoscopic image","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Automatic Content Generation in Tetris Game Based on Emotion Modeling","H. Xu; Z. Wu; T. Lin; N. Tang; L. Hua","Coll. of Comput. Sci., Sichuan Univ., Chengdu, China","2016 Nicograph International (NicoInt)","20160912","2016","","","139","139","Experiencing the personalization via the player's modeling as well as appropriate adjustment of the content according to specific needs and preferences was important steps towards effective content generation. For the experiments presented here, a version of the classic Tetris game is enhanced with 4 controllable parameters. We extracted 57 features derived from gameplay interaction, which are probably associated with emotions such as fun, challenge and frustration. The pairwise preference data of the player was collected by using forced choice questionnaires, and the models were trained by using 5 machine learning algorithms after the selection of the features.","","","10.1109/NicoInt.2016.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7564067","Tetris;content generation;emotion modeling;feature selection","Biological system modeling;Computational modeling;Computer science;Data models;Feature extraction;Games;Machine learning algorithms","computer games;feature selection;human factors;learning (artificial intelligence)","Tetris game;automatic content generation;emotion modeling;feature selection;forced choice questionnaires;game personalization;gameplay interaction;machine learning algorithms;pairwise preference data;user needs;user preferences","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"A Proposed Model for Malicious Spam Detection in Email Systems of Educational Institutes","A. Zaid; J. Alqatawna; A. Huneiti","King Abdullah II Sch. for Inf. Technol., Univ. of Jordan, Amman, Jordan","2016 Cybersecurity and Cyberforensics Conference (CCC)","20161020","2016","","","60","64","The cheapest form of communication in the world today is email, and its simplicity makes it vulnerable to many threats. One of the most important threats to email is spam, unsolicited email, normally with an advertising content sent out as a mass mailing. Malicious spam is spam with malicious content in forms of harmful attachments or links to phishing websites. In the case of educational institutes, malicious spam threatens the privacy and security of large amount of sensitive data relating to staff and students. Hence, a system that can automatically learn how to classify malicious spam in educational institutes is highly desirable. In this paper, we aim to improve detection of malicious spam through feature selection, with focus on the educational field. We propose a model that employs a novel dataset for the process of feature selection, a step for improving classification in later stage. This dataset is unprecedented as no research in the literature was intended to serve malicious spam detection in a specific domain or field such as the educational field. Feature selection is expected to improve training time and accuracy of malicious spam detection.","","","10.1109/CCC.2016.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600211","context-aware spam detection;educational institute;email;feature selection;malicious spam detection","Bibliographies;Classification algorithms;Electronic mail;Feature extraction;Filtering;Machine learning algorithms;Support vector machines","advertising;data privacy;educational institutions;feature selection;learning (artificial intelligence);pattern classification;security of data;unsolicited e-mail","advertising content;automatic learning;educational field focus;educational institutes;email systems;feature selection;harmful attachments;harmful links;malicious content;malicious spam classification;malicious spam detection model;mass mailing;phishing websites;sensitive data privacy;sensitive data security;staff data;student data;threat vulnerability;training time improvement;unsolicited email","","","","","","","2-4 Aug. 2016","","IEEE","IEEE Conference Publications"
"Collaborative Filtering and Deep Learning Based Hybrid Recommendation for Cold Start Problem","J. Wei; J. He; K. Chen; Y. Zhou; Z. Tang","","2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)","20161013","2016","","","874","877","Recommender systems (RS) are used by many social networking applications and online e-commercial services. Collaborative filtering (CF) is one of the most popular approaches used for RS. However traditional CF approach suffers from sparsity and cold start problems. In this paper, we propose a hybrid recommendation model to address the cold start problem, which explores the item content features learned from a deep learning neural network and applies them to the timeSVD++ CF model. Extensive experiments are run on a large Netflix rating dataset for movies. Experiment results show that the proposed hybrid recommendation model provides a good prediction for cold start items, and performs better than four existing recommendation models for rating of non-cold start items.","","","10.1109/DASC-PICom-DataCom-CyberSciTec.2016.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7588947","","Collaboration;Computational modeling;Data models;Machine learning;Motion pictures;Predictive models;Training","","","","","","","","","8-12 Aug. 2016","","IEEE","IEEE Conference Publications"
"Behavior prediction using an improved Hidden Markov Model to support people with disabilities in smart homes","E. Wu; P. Zhang; T. Lu; H. Gu; N. Gu","School of Computer Science, Fudan University, Shanghai, China","2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20160915","2016","","","560","565","Smart environment has been evolved as a hot research topic with the development of machine learning algorithms and wireless communication technologies. Existing smart home solutions usually need inhabitants to operate device controllers directly. However, for people with disabilities, it is inconvenient and difficult to perform such manual operations. Therefore, it is important to develop automatic and intelligent services to reduce operation inconvenience and improve comfort level. In this paper, an Improved Hidden Markov Model (IHMM) is presented to support personalized behavior prediction for people with disabilities. The model can learn behavior patterns of users and provide services to inhabitants automatically. Moreover, by breaking the time invariant hypothesis in Hidden Markov Model, we incorporate time information as positions of states, and develop a temporal state transition matrix to replace the fixed state transition matrix to demonstrate the probabilities of state transitions. As a result, different values of daily temperature sections are characterized and identified as hidden variables, which guide user activities. Evaluation of proposed work has shown that IHMM improves the prediction accuracy by at least 10% compared to the traditional HMM.","","","10.1109/CSCWD.2016.7566051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566051","Improved Hidden Markov Model;behavior prediction;people with disabilities;smart home","Decision support systems;Hidden Markov models;Machine learning algorithms;Performance evaluation;Smart homes;Training;Wireless communication","handicapped aids;hidden Markov models;home computing;matrix algebra","IHMM;improved hidden Markov model;machine learning algorithms;people with disabilities;personalized behavior prediction;smart environment;smart homes;temporal state transition matrix;time invariant hypothesis;wireless communication technologies","","","","","","","4-6 May 2016","","IEEE","IEEE Conference Publications"
"A New Kind of Nonparametric Test for Statistical Comparison of Multiple Classifiers Over Multiple Datasets","Z. Yu; Z. Wang; J. You; J. Zhang; J. Liu; H. S. Wong; G. Han","School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China, and also with Hong Kong Baptist University, Hong Kong.","IEEE Transactions on Cybernetics","","2016","PP","99","1","14","Nonparametric statistical analysis, such as the Friedman test (FT), is gaining more and more attention due to its useful applications in a lot of experimental studies. However, traditional FT for the comparison of multiple learning algorithms on different datasets adopts the naive ranking approach. The ranking is based on the average accuracy values obtained by the set of learning algorithms on the datasets, which neither considers the differences of the results obtained by the learning algorithms on each dataset nor takes into account the performance of the learning algorithms in each run. In this paper, we will first propose three kinds of ranking approaches, which are the weighted ranking approach, the global ranking approach (GRA), and the weighted GRA. Then, a theoretical analysis is performed to explore the properties of the proposed ranking approaches. Next, a set of the modified FTs based on the proposed ranking approaches are designed for the comparison of the learning algorithms. Finally, the modified FTs are evaluated through six classifier ensemble approaches on 34 real-world datasets. The experiments show the effectiveness of the modified FTs.","2168-2267;21682267","","10.1109/TCYB.2016.2611020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581018","Classification;Friedman test (FT);classifier ensemble;nonparametric test;statistical test","Algorithm design and analysis;Computer science;Cybernetics;Machine learning algorithms;Sociology;Statistical analysis","","","","","","","","20161003","","","IEEE","IEEE Early Access Articles"
"Intrusion detection algorithm based on density, cluster centers, and nearest neighbors","Xiujuan Wang; Chenxi Zhang; Kangfeng Zheng","Computer Sciences, Beijing University of Technology, China","China Communications","20160902","2016","13","7","24","31","Intrusion detection aims to detect intrusion behavior and serves as a complement to firewalls. It can detect attack types of malicious network communications and computer usage that cannot be detected by idiomatic firewalls. Many intrusion detection methods are processed through machine learning. Previous literature has shown that the performance of an intrusion detection method based on hybrid learning or integration approach is superior to that of single learning technology. However, almost no studies focus on how additional representative and concise features can be extracted to process effective intrusion detection among massive and complicated data. In this paper, a new hybrid learning method is proposed on the basis of features such as density, cluster centers, and nearest neighbors (DCNN). In this algorithm, data is represented by the local density of each sample point and the sum of distances from each sample point to cluster centers and to its nearest neighbor. k-NN classifier is adopted to classify the new feature vectors. Our experiment shows that DCNN, which combines K-means, clustering-based density, and k-NN classifier, is effective in intrusion detection.","1673-5447;16735447","","10.1109/CC.2016.7559072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559072","DCNN;cluster center;density;intrusion detection;nearest neighbor","Classification algorithms;Clustering algorithms;Data mining;Feature extraction;Intrusion detection;Machine learning algorithms","learning (artificial intelligence);pattern classification;pattern clustering;security of data","DCNN;clustering-based density;data density;density-cluster centers-and-nearest neighbors;feature vectors;hybrid learning method;intrusion detection method;k-NN classifier;k-means;k-nearest neighbors","","","","","","","July 2016","","IEEE","IEEE Journals & Magazines"
"Deep Transfer Metric Learning","J. Hu; J. Lu; Y. P. Tan; J. Zhou","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Image Processing","20161005","2016","25","12","5576","5588","Conventional metric learning methods usually assume that the training and test samples are captured in similar scenarios so that their distributions are assumed to be the same. This assumption does not hold in many real visual recognition applications, especially when samples are captured across different data sets. In this paper, we propose a new deep transfer metric learning (DTML) method to learn a set of hierarchical nonlinear transformations for cross-domain visual recognition by transferring discriminative knowledge from the labeled source domain to the unlabeled target domain. Specifically, our DTML learns a deep metric network by maximizing the inter-class variations and minimizing the intra-class variations, and minimizing the distribution divergence between the source domain and the target domain at the top layer of the network. To better exploit the discriminative information from the source domain, we further develop a deeply supervised transfer metric learning (DSTML) method by including an additional objective on DTML, where the output of both the hidden layers and the top layer are optimized jointly. To preserve the local manifold of input data points in the metric space, we present two new methods, DTML with autoencoder regularization and DSTML with autoencoder regularization. Experimental results on face verification, person re-identification, and handwritten digit recognition validate the effectiveness of the proposed methods.","1057-7149;10577149","","10.1109/TIP.2016.2612827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574389","Deep metric learning;deep transfer metric learning;face verification;person reidentification;transfer learning","Learning systems;Machine learning;Manifolds;Measurement;Neural networks;Training;Visualization","biometrics (access control);face recognition;handwritten character recognition;learning (artificial intelligence)","DSTML-with-autoencoder regularization method;DTML-with-autoencoder regularization method;cross-domain visual recognition;deep metric network;deep transfer metric learning method;deeply supervised transfer metric learning method;discriminative knowledge transfer;distribution divergence minimization;face verification;handwritten digit recognition;hierarchical nonlinear transformations;interclass variation maximization;intraclass variation minimization;labeled source domain;person reidentification;unlabeled target domain","","","","","","20160922","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"An Asynchronous Distributed ADMM Algorithm and Efficient Communication Model","L. Fang; Y. Lei","","2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)","20161013","2016","","","136","140","In this paper, we present a hierarchical butterfly communication model, which is applied to an asynchronous distributed ADMM algorithm. The goal is to minimize the communication overhead of the distributed ADMM algorithm in the fully connected network. We give a theoretical analysis of the convergence of the algorithm with hierarchical butterfly communication model. Experiments show that hierarchical butterfly communication model does not have a great impact on the convergence of the algorithm with the increase of computing nodes and thus effectively improve the performance and scalability of the algorithm.","","","10.1109/DASC-PICom-DataCom-CyberSciTec.2016.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7588835","ADMM;asynchronous;butterfly;hierarchical communication model","Algorithm design and analysis;Analytical models;Computational modeling;Computers;Convergence;Data models;Machine learning algorithms","","","","","","","","","8-12 Aug. 2016","","IEEE","IEEE Conference Publications"
"Super-Sparse Learning in Similarity Spaces","A. Demontis; M. Melis; B. Biggio; G. Fumera; F. Roli","Dept. of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy","IEEE Computational Intelligence Magazine","20161010","2016","11","4","36","45","In a growing number of applications, including computer vision, biometrics, text categorization and information retrieval, samples are often represented more naturally in terms of similarities between each other, rather than in an explicit feature vector space [1], [2]. Traditional machine-learning algorithms can still be used to learn over similarity-based representations; e.g., linear classification algorithms like Support Vector Machines (SVMs) [3], [4] can be trained in the space implicitly induced by the similarity measure (i.e., the kernel function) to learn nonlinear functions in input space. However, the main drawback of similarity-based techniques is their high computational complexity at test time, since computing their classification function often requires matching the input sample against a large set of reference prototypes, and evaluating such similarity measures is usually computationally demanding. Even SVMs, that induce sparsity in the number of required prototypes (the so-called support vectors, SVs) may not provide solutions that are sparse enough, as the number of prototypes (i.e., SVs) grows linearly with respect to the number of training samples [5], [6]. To reduce the number of reference prototypes, several state-of-the-art approaches select them from the training data, and then separately train the classification function using the reduced set of prototypes. However, decoupling these two steps may not effectively reduce the number of prototypes, without significantly affecting classification accuracy [2], [7], [8].","1556-603X;1556603X","","10.1109/MCI.2016.2601702","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7587466","","Adaptation models;Biometrics;Classification;Computational complexity;Computer vision;Eigenvalues and eigenfunctions;Machine learning;Sparse matrices;Support vector machines;Text mining;Training data","computational complexity;learning (artificial intelligence);pattern classification;support vector machines","SVM;classification accuracy;classification function;computational complexity;explicit feature vector space;input space;machine-learning algorithms;nonlinear function learning;similarity measure;similarity spaces;similarity-based representation learning;supersparse learning;training data","","","","","","","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Energy Consumption Prediction with Big Data: Balancing Prediction Accuracy and Computational Resources","K. Grolinger; M. A. M. Capretz; L. Seewald","Dept. of Electr. & Comput. Eng., Western Univ., London, ON, Canada","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","157","164","In recent years, advances in sensor technologies and expansion of smart meters have resulted in massive growth of energy data sets. These Big Data have created new opportunities for energy prediction, but at the same time, they impose new challenges for traditional technologies. On the other hand, new approaches for handling and processing these Big Data have emerged, such as MapReduce, Spark, Storm, and Oxdata H2O. This paper explores how findings from machine learning with Big Data can benefit energy consumption prediction. An approach based on local learning with support vector regression (SVR) is presented. Although local learning itself is not a novel concept, it has great potential in the Big Data domain because it reduces computational complexity. The local SVR approach presented here is compared to traditional SVR and to deep neural networks with an H2O machine learning platform for Big Data. Local SVR outperformed both SVR and H2O deep learning in terms of prediction accuracy and computation time. Especially significant was the reduction in training time, local SVR training was an order of magnitude faster than SVR or H2O deep learning.","","","10.1109/BigDataCongress.2016.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584933","Big Data;Oxdata H2O;consumption prediction;deep learning;deep neural networks;local SVR;local learning","Big data;Machine learning;Machine learning algorithms;Predictive models;Support vector machines;Training;Water","Big Data;energy consumption;learning (artificial intelligence);load forecasting;power engineering computing;regression analysis;support vector machines","Big Data handling;Big Data processing;MapReduce;Oxdata H2O;SVR;Spark;Storm;balancing prediction accuracy;computational complexity;computational resources;energy consumption prediction;energy data sets;local learning;machine learning;sensor technologies;smart meters;support vector regression","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Learning Cascaded Deep Auto-Encoder Networks for Face Alignment","R. Weng; J. Lu; Y. P. Tan; J. Zhou","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Multimedia","20160915","2016","18","10","2066","2078","In this paper, we propose a new cascaded deep auto-encoder networks (CDAN) approach for face alignment. Our framework consists of a global exemplar-based deep auto-encoder network (GEDAN) and a series of localized deep auto-encoder networks (LDAN) in a cascaded fashion. The global network takes a low-resolution holistic facial image as input and generates a preliminary facial landmark configuration. The following localized networks sample pose-indexed local features around current landmark positions, and refine the landmark positions with increasingly higher image resolutions. Our network architectures are designed to achieve greater robustness against pose variations as well as higher landmark estimation accuracy. Experimental results on three datasets show that the proposed approach achieves superior alignment accuracy with real-time speed.","1520-9210;15209210","","10.1109/TMM.2016.2591508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7513378","Auto-encoder;deep learning;face alignment","Face;Face recognition;Feature extraction;Image resolution;Machine learning;Real-time systems;Shape","face recognition;feature extraction;image resolution;learning (artificial intelligence);pose estimation","CDAN;GEDAN;LDAN;cascaded deep auto-encoder networks;deep learning;face alignment;facial landmark configuration;global exemplar-based deep auto-encoder network;global network;image resolutions;landmark estimation accuracy;landmark positions;localized deep auto-encoder networks;low-resolution holistic facial image;network architectures;pose variations;pose-indexed local features","","","","","","20160714","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Object tracking in robotic micromanipulation by supervised ensemble learning classifier","Z. Cenev; J. Venäläinen; V. Sariola; Q. Zhou","Department of Electrical Engineering and Automation, School of Electrical Engineering, Aalto University, Espoo, Finland","2016 International Conference on Manipulation, Automation and Robotics at Small Scales (MARSS)","20160908","2016","","","1","5","Autonomous micromanipulation has a great potential to impact every research field concerning objects at a small scale. In this paper, we report our work on detection and tracking of a transparent SU-8 microchip in 3D Cartesian space during micromanipulation. Conditions such as occlusion, variant object orientation and poor edge prominence hinder the implementation of conventional vision algorithms. To enable tracking in such difficult conditions, an object detection classifier that utilizes an ensemble machine learning algorithm has been implemented. The classifier has been trained with 165 and 85 unique positive and negative samples, respectively. Object detection was achieved at a distance of three times the nominal depth of field with maximum tracking error of only 12 % of the object size.","","Electronic:978-1-5090-1510-8; POD:978-1-5090-1511-5","10.1109/MARSS.2016.7561733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561733","Ensemble;classification;detection;learning;machine;micro-object;micromanipulation;robotic","Cameras;Classification algorithms;Detectors;Grippers;Machine learning algorithms;Microscopy;Robots","computer vision;image classification;learning (artificial intelligence);manipulators;object detection;object tracking","3D Cartesian space;Supervised Ensemble Learning Classifier;autonomous micromanipulation;conventional vision algorithms;machine learning algorithm;object detection;object detection classifier;object orientation;object tracking;robotic micromanipulation;transparent SU-8 microchip","","","","","","","18-22 July 2016","","IEEE","IEEE Conference Publications"
"Mining advisor-advisee relationships in scholarly big data: A deep learning approach","W. Wang; J. Liu; S. Yu; C. Zhang; Z. Xu; F. Xia","School of Software, Dalian University of Technology, Dalian 116620, China","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","209","210","Mining advisor-advisee relationships can benefit many interesting applications such as advisor recommendation and protege performance analysis. Based on the hypothesis that, advisor-advisee relationships among researchers are hidden in scholarly big data, we propose in this work a deep learning based advisor-advisee relationship identification method which considers the personal properties and network characteristics with a stacked autoencoder model. To the best of our knowledge, this is the first time that a deep learning model is utilized to represent coauthor network features for relationships identification. Moreover, experiments demonstrate that the proposed method has better performance compared with other state-of-the-art methods.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559588","Deep learning;Relationship mining;Stacked autoencoders","Data mining;Data models;Learning systems;Logistics;Machine learning;Support vector machines;Training","Big Data;data mining;learning (artificial intelligence)","advisor recommendation;deep learning based advisor-advisee relationship identification method;protege performance analysis;relationships identification;scholarly Big Data","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"A 1.40mm<sup>2</sup> 141mW 898GOPS sparse neuromorphic processor in 40nm CMOS","P. Knag; Chester Liu; Zhengya Zhang","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, United States of America","2016 IEEE Symposium on VLSI Circuits (VLSI-Circuits)","20160922","2016","","","1","2","Sparsity is a brain-inspired property that enables a significant reduction in workload and power dissipation of deep learning. This work presents a 1.40mm<sup>2</sup> 40nm CMOS sparse neuromorphic processor that implements a two-layer convolutional restricted Boltzmann machine (CRBM) for inference and a support vector machine (SVM) classifier. The processor incorporates sparse convolvers to realize sparsity-proportional workload reduction. The architecture is parallelized along a non-sparse dimension to minimize stalling. At 0.9V and 240MHz, the processor achieves an effective 898.2GOPS performance, dissipating 140.9mW. Using sparsity, we reduce the workload, datapath power consumption and area by 3.4×, 3.3× and 1.74×, respectively. The design uses latch-based memory to reduce area and dynamic clock gating to save power.","","","10.1109/VLSIC.2016.7573526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573526","","Bandwidth;Convolvers;Kernel;Machine learning;Micromechanical devices;Neuromorphics;Support vector machines","Boltzmann machines;CMOS digital integrated circuits;neural chips;parallel architectures;pattern classification;storage management chips;support vector machines","CMOS sparse neuromorphic processor;CRBM;SVM classifier;datapath power consumption;deep learning;dynamic clock gating;inference;latch-based memory;parallelized architecture;power 140.9 mW;processor;sparse convolvers;sparsity-proportional workload reduction;support vector machine;two-layer convolutional restricted Boltzmann machine","","","","","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"The effects of deep network topology on mortality prediction","H. Du; M. M. Ghassemi; M. Feng","School of Electrical and Electronic Engineering, Nanyang Technology University, Singapore","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2602","2605","Deep learning has achieved remarkable results in the areas of computer vision, speech recognition, natural language processing and most recently, even playing Go. The application of deep-learning to problems in healthcare, however, has gained attention only in recent years, and it's ultimate place at the bedside remains a topic of skeptical discussion. While there is a growing academic interest in the application of Machine Learning (ML) techniques to clinical problems, many in the clinical community see little incentive to upgrade from simpler methods, such as logistic regression, to deep learning. Logistic regression, after all, provides odds ratios, p-values and confidence intervals that allow for ease of interpretation, while deep nets are often seen as `black-boxes' which are difficult to understand and, as of yet, have not demonstrated performance levels far exceeding their simpler counterparts. If deep learning is to ever take a place at the bedside, it will require studies which (1) showcase the performance of deep-learning methods relative to other approaches and (2) interpret the relationships between network structure, model performance, features and outcomes. We have chosen these two requirements as the goal of this study. In our investigation, we utilized a publicly available EMR dataset of over 32,000 intensive care unit patients and trained a Deep Belief Network (DBN) to predict patient mortality at discharge. Utilizing an evolutionary algorithm, we demonstrate automated topology selection for DBNs. We demonstrate that with the correct topology selection, DBNs can achieve better prediction performance compared to several bench-marking methods.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591263","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591263","","Bioinformatics;Genomics;Machine learning;Network topology;Neural networks;Topology;Training","belief networks;electronic health records;evolutionary computation;health care;learning (artificial intelligence);medical computing","EMR dataset;deep belief network;deep network topology;deep-learning methods;electronic medical record;evolutionary algorithm;healthcare;intensive care unit patients;network structure;patient mortality prediction","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Learning Framework for Robust Obstacle Detection, Recognition, and Tracking","V. D. Nguyen; H. Van Nguyen; D. T. Tran; S. J. Lee; J. W. Jeon","School of Information and Communication Engineering, Sungkyunkwan University 16419, South Korea (email: vinhnd@ skku.edu; haunguyen@skku.edu; dinhtt@skku.edu; vision.fpga@gmail.com; jwjeon@yurim.skku.ac.kr).","IEEE Transactions on Intelligent Transportation Systems","","2016","PP","99","1","14","This paper introduces a general framework for detection, recognition, and tracking preceding vehicles and pedestrians based on a deep learning approach. The proposed framework combines a novel deep learning approach with the use of multiple sources of local patterns and depth information to yield robust on-road vehicle and pedestrian detection, recognition, and tracking. The proposed system is first based on robust obstacle detection to identify obstacles appearing along the road that are likely to be vehicles and pedestrians, implemented as an efficient adaptive U-V disparity algorithm. Second, the results from the obstacle detection stage are input into a novel vehicle and pedestrian recognition system based on a deep learning model that processes multiple sources of depth information and local patterns. Finally, the results from the recognition stage are used to track detected vehicles or pedestrians in the next frame by means of a proposed tracking and validation model. The proposed framework has been thoroughly evaluated by inputting several vehicle and pedestrian data sets that were collected under various driving conditions. Experimental results show that this framework provides robust vehicle and pedestrian detection, recognition, and tracking with high accuracy, and also satisfies the real-time requirements of driver assistance systems.","1524-9050;15249050","","10.1109/TITS.2016.2614818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600385","Deep learning;unsupervised learning.;vehicle and pedestrian detection","Cameras;Machine learning;Neural networks;Roads;Robustness;Training;Vehicles","","","","","","","","20161019","","","IEEE","IEEE Early Access Articles"
"SOLAR: Services-Oriented Learning Architectures","C. Wang; X. Li; Q. Yu; A. Wang; P. Hung; X. Zhou","Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China","2016 IEEE International Conference on Web Services (ICWS)","20160901","2016","","","662","665","Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data sizes have posed significant challenge to construct a flexible and high efficient implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA based approaches. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.","","Electronic:978-1-5090-2675-3; POD:978-1-5090-2676-0","10.1109/ICWS.2016.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7558064","Accelerator;Deep Learning;Neural Network;Services-oriented Architecture","Computer architecture;Field programmable gate arrays;Graphics processing units;Hardware;Machine learning;Service-oriented architecture","field programmable gate arrays;graphics processing units;learning (artificial intelligence);multiprocessing systems;neural nets;service-oriented architecture","FPGA based approaches;GPU;Intel i5 processors;SOLAR;deep learning neural networks;machine learning;services-oriented deep learning architecture;ubiquitous framework;uniform programming model","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"The evaluation of detectors and descriptors on determination of semen cell","H. O. Ilhan; A. Elbir","Department of Computer Engineering, Yildiz Technical University, Istanbul, Turkey","2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","20160922","2016","","","1","4","Detectors and descriptors refer to the key points of the images where informative features can be detected or extracted to use in machine learning for classification or clustering problems. Four algorithms as two descriptor (SURF, MRES) and two detectors (Harris, Shi Tomasi) are utilized for semen cell detection problem in this paper. Results emphasize the best algorithm for future studies to use in tracking or morphological analysis of semen. The evaluation of algorithms is carried out on manually labeled images over a pre-defined verification area. Not only accuracy is measured owing to data imbalance problem, but also f-measure scores are registered to indicate the methods success rates. As a summary of paper, SURF surpasses over other methods with 87.67% accuracy rate and 0.92 F-measure score owing to the scale invariant method.","","","10.1109/INISTA.2016.7571863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571863","Descriptor;Detector;Harris Corner Detector;MERS Descriptor;SURF Descriptor;Semen Analysis;Shi Tomasi Corner Detector","Algorithm design and analysis;Classification algorithms;Computers;Detectors;Feature extraction;Machine learning algorithms;Microscopy","computer aided analysis;feature extraction;image classification;learning (artificial intelligence);pattern clustering","Harris corner detector;MRES descriptor;SURF descriptor;Shi Tomasi corner detector;classification problems;clustering problems;descriptors evaluation;detectors evaluation;f-measure scores;image key points;informative feature detection;informative feature extraction;machine learning;manually labeled images;predefined verification area;semen cell detection problem","","","","","","","2-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"Fathom: reference workloads for modern deep learning methods","R. Adolf; S. Rama; B. Reagen; G. y. Wei; D. Brooks","Harvard University","2016 IEEE International Symposium on Workload Characterization (IISWC)","20161010","2016","","","1","10","Deep learning has been popularized by its recent successes on challenging artificial intelligence problems. One of the reasons for its dominance is also an ongoing challenge: the need for immense amounts of computational power. Hardware architects have responded by proposing a wide array of promising ideas, but to date, the majority of the work has focused on specific algorithms in somewhat narrow application domains. While their specificity does not diminish these approaches, there is a clear need for more flexible solutions. We believe the first step is to examine the characteristics of cutting edge models from across the deep learning community. Consequently, we have assembled Fathom: a collection of eight archetypal deep learning workloads for study. Each of these models comes from a seminal work in the deep learning community, ranging from the familiar deep convolutional neural network of Krizhevsky et al., to the more exotic memory networks from Facebook's AI research group. Fathom has been released online, and this paper focuses on understanding the fundamental performance characteristics of each model. We use a set of application-level modeling tools built around the TensorFlow deep learning framework in order to analyze the behavior of the Fathom workloads. We present a breakdown of where time is spent, the similarities between the performance profiles of our models, an analysis of behavior in inference and training, and the effects of parallelism on scaling.","","","10.1109/IISWC.2016.7581275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581275","","Analytical models;Computational modeling;Computer architecture;Hardware;Libraries;Machine learning;Training","inference mechanisms;learning (artificial intelligence);neural nets;parallel programming","Facebook AI research group;Fathom workload behavior analysis;TensorFlow deep learning framework;application domain;application-level modeling tool;archetypal deep learning workload;artificial intelligence;computational power;deep convolutional neural network;exotic memory network;inference;modern deep learning methods;parallel scalability;training","","","","","","","25-27 Sept. 2016","","IEEE","IEEE Conference Publications"
"Enhancing text classification with the Universum","C. L. Liu; C. H. Lee","Department of Industrial Engineering and Management, National Chiao Tung University, 1001 University Road, Hsinchu 300, Taiwan, ROC","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1147","1153","The Universum is a data set that shares the same domain as the target problem, but does not comprise any category of interest. Recently, the concept of inference through contradictions has shown that the Universum provides a means for machine learning algorithms to encode prior knowledge into the model to improve performance. This work investigates whether text classification algorithms can benefit from the Universum when one has only a few labeled examples at hand. Additionally, this work proposes a confidence scheme to incorporate Universum into the learning process, and further devises a learning with Universum algorithm called Universum logistic regression (U-LR). The confidence scheme provides another means for machine learning algorithms to incorporate Universum into learning process. We conduct experiments on three data sets with several combinations. The experimental results indicate that the proposed method outperforms the other learning with Universum methods.","","","10.1109/FSKD.2016.7603340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603340","","Algorithm design and analysis;Classification algorithms;Cost function;Logistics;Machine learning algorithms;Mathematical model;Semisupervised learning","learning (artificial intelligence);pattern classification;regression analysis;text analysis","U-LR;Universum logistic regression;data set;machine learning algorithms;text classification","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"DeepSky: Identifying Absorption Bumps via Deep Learning","X. Yuan; M. Li; S. Gaddam; X. Li; Y. Zhao; J. Ma; J. Ge","Scalable Software Syst. Lab., Univ. of Florida, Gainesville, FL, USA","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","214","221","The pervasive interstellar grains provide significant insights to help us understand the formation and evolution of stars, planetary systems, and galaxies, and could potentially lead us to the secret of the origin of life. One of the most effective ways to analyze the dusts is via their interaction and interference on some background light. The observable extinction curves and spectral features carry the information about the size and composition of the dusts. Among the features, the broad 2175 Å absorption bump is one of the most significant spectroscopic interstellar extinction features. Traditionally, astronomers apply conventional statistical and signal processing techniques to detect the existence of absorption bumps. These approaches require labor-intensive preprocessing and the co-existence of some other reference features to alleviate the influence from the noises. Conventional approaches not only involve substantial labor cost in complicated workflows, but also demand well-trained expertise to make subtle and error-prone conditional decisions. In this paper, we propose to leverage deep learning to automate the detection workflow without minute feature engineering. We design and analyze deep convolutional neural networks for detecting absorption bumps. We further propose the framework of deep learning mechanisms and models (collectively called DeepSky) for scientific discovery in astronomy. The prototype of DeepSky demonstrates efficient and effective results using limited labeled data. With well-designed data augmentation, our trained model achieved about 99% accuracy in prediction using the real-world data.","","","10.1109/BigDataCongress.2016.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584940","astronomy;bump;deep convolutional neural network;deep learning","Absorption;Astronomy;Data models;Machine learning;Mathematical model;Neural networks;Training","astronomy;astronomy computing;learning (artificial intelligence)","DeepSky;absorption bumps;astronomers;astronomy;complicated workflows;data augmentation;deep convolutional neural networks;deep learning mechanisms;dusts;error-prone conditional decisions;galaxies;labor-intensive preprocessing;minute feature engineering;pervasive interstellar grains;planetary systems;scientific discovery;signal processing techniques;spectroscopic interstellar extinction features;stars;substantial labor cost","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Partial Label Learning via Gaussian Processes","Y. Zhou; J. He; H. Gu","Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China.","IEEE Transactions on Cybernetics","","2016","PP","99","1","8","Partial label learning (PL) is a new weakly supervised machine learning framework that addresses the problems where each training sample is associated with a candidate set of its actual label. Since precisely-labeled data are usually expensive and hard to obtain in practice, PL can be widely used in many real-world tasks. However, as the ambiguity in training data inevitably makes such learning framework difficult to address, only a few algorithms are available so far. In this paper, a new probabilistic kernel algorithm is proposed by employing the Gaussian process model. The main idea is to assume an unobservable latent function with the Gaussian process prior on feature space for each class label. Then a new likelihood function is defined to disambiguate the ambiguous labeling information conveyed by the training data. By introducing the aggregate function to approximate the max(·) function involved in likelihood function, not only is a likelihood function equivalent to the max-loss function defined, which has been proved to be tighter than other loss functions, but also a differentiable convex objective function is presented. The experimental results on six UCI data sets and three real-world PL problems show that the proposed algorithm can get higher accuracy than the state-of-the-art PL algorithms.","2168-2267;21682267","","10.1109/TCYB.2016.2611534","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582441","Gaussian process model;imprecisely-labeled data;kernel method;partial label learning (PL)","Gaussian processes;Kernel;Labeling;Machine learning algorithms;Prediction algorithms;Training;Training data","","","","","","","","20161004","","","IEEE","IEEE Early Access Articles"
"Deep Learning Driven Visual Path Prediction From a Single Image","S. Huang; X. Li; Z. Zhang; Z. He; F. Wu; W. Liu; J. Tang; Y. Zhuang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Image Processing","20161026","2016","25","12","5892","5904","Capabilities of inference and prediction are the significant components of visual systems. Visual path prediction is an important and challenging task among them, with the goal to infer the future path of a visual object in a static scene. This task is complicated as it needs high-level semantic understandings of both the scenes and underlying motion patterns in video sequences. In practice, cluttered situations have also raised higher demands on the effectiveness and robustness of models. Motivated by these observations, we propose a deep learning framework, which simultaneously performs deep feature learning for visual representation in conjunction with spatiotemporal context modeling. After that, a unified path-planning scheme is proposed to make accurate path prediction based on the analytic results returned by the deep context models. The highly effective visual representation and deep context models ensure that our framework makes a deep semantic understanding of the scenes and motion patterns, consequently improving the performance on visual path prediction task. In experiments, we extensively evaluate the model's performance by constructing two large benchmark datasets from the adaptation of video tracking datasets. The qualitative and quantitative experimental results show that our approach outperforms the state-of-the-art approaches and owns a better generalization capability.","1057-7149;10577149","","10.1109/TIP.2016.2613686","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576681","Visual path prediction;convolutional neural networks;deep learning;visual context model","Adaptation models;Context;Context modeling;Machine learning;Predictive models;Semantics;Visualization","feature extraction;image motion analysis;image representation;image sequences;learning (artificial intelligence);video signal processing","deep feature learning;deep learning framework;high-level semantic;motion pattern;spatiotemporal context modeling;unified path-planning scheme;video sequence;video tracking dataset;visual path prediction;visual representation","","","","","","20160926","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"Research of 3D face recognition algorithm based on deep learning stacked denoising autoencoder theory","J. Zhang; Z. Hou; Z. Wu; Y. Chen; W. Li","College of Information, Mathematics and Physics, Changzhou University, Changzhou, China","2016 8th IEEE International Conference on Communication Software and Networks (ICCSN)","20161010","2016","","","663","667","This electronic Due to the fact that the 3D face depth data have more information, the 3D face recognition is attracting more and more attention in the machine learning area. Firstly, this paper selects 30 feature points from the 113 feature points of Candide-3 face model to characterize face, which improves the efficiency of recognition algorithm obviously without affecting the recognition accuracy. With the significant advantage of the characterization of essential features by learning a deep nonlinear network, this paper presents a stacked denoising autoencoder algorithm model based on deep learning which improves neural networks model. This algorithm conducts the unsupervised preliminary training of face depth data and the supervised training to fine-tuning the network which is better than neural network's random initialization. The experiment indicates that compared with real face data, the reconstruction face model has a small matching error by using SDAE algorithm and it achieves an excellent face recognition effect.","","","10.1109/ICCSN.2016.7586606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586606","3D face depth data;deep learning;neural networks;stacked denoising autoencoder;unsupervised preliminary training","Analytical models;Data models;Face;Face recognition;Machine learning;Three-dimensional displays;Training","face recognition;learning (artificial intelligence)","3D face recognition algorithm;Candide-3 face model;deep learning;machine learning;stacked denoising autoencoder algorithm model;supervised training","","","","","","","4-6 June 2016","","IEEE","IEEE Conference Publications"
"Finding a Sparse Vector in a Subspace: Linear Sparsity Using Alternating Directions","Q. Qu; J. Sun; J. Wright","Electrical Engineering Department, Columbia University, New York, NY, USA","IEEE Transactions on Information Theory","20160913","2016","62","10","5855","5880","Is it possible to find the sparsest vector (direction) in a generic subspace S ⊆ ℝ<sup>p</sup> with dim(S) = n <; p? This problem can be considered a homogeneous variant of the sparse recovery problem and finds connections to sparse dictionary learning, sparse PCA, and many other problems in signal processing and machine learning. In this paper, we focus on a planted sparse model for the subspace: the target sparse vector is embedded in an otherwise random subspace. Simple convex heuristics for this planted recovery problem provably break down when the fraction of nonzero entries in the target sparse vector substantially exceeds O(1/√n). In contrast, we exhibit a relatively simple nonconvex approach based on alternating directions, which provably succeeds even when the fraction of nonzero entries is Ω(1). To the best of our knowledge, this is the first practical algorithm to achieve linear scaling under the planted sparse model. Empirically, our proposed algorithm also succeeds in more challenging data models, e.g., sparse dictionary learning.","0018-9448;00189448","","10.1109/TIT.2016.2601599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547961","Sparse vector;alternating direction method;dictionary learning;homogeneous recovery;nonconvex optimization;sparse recovery;subspace modeling","Data models;Dictionaries;Machine learning algorithms;Null space;Optimization;Principal component analysis;Sparse matrices","concave programming;principal component analysis;signal processing","alternating direction;convex heuristics;linear sparsity;machine learning;nonconvex approach;planted sparse model;random subspace;signal processing;sparse PCA;sparse dictionary learning;sparse recovery problem;sparse vector;target sparse vector","","1","","","","20160819","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Exact clothing retrieval approach based on deep neural network","L. Xiao; X. Yichao","Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China","2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference","20160905","2016","","","396","400","In recent years, the trend of shopping for clothing on an onscreen character has been raising. Unfortunately, clothes that appear on screen could be difficult to track down, much less to purchase directly. It is a challenging task to find out exactly what the clothing in a TV show is from massive amounts of clothing items in online clothing retails due to the clearly noticeable visual discrepancies of the same clothing in video and in online shop photos. In order to tackle the problem, we adopt the deep neural network to learn recognizable clothing-specific feature for finding the exact clothing item in the video scenario among a large collection of online shop images. The experiments shows the clothing-specific feature is more effective in retrieval task and color filtering improve the retrieval performance.","","CD-ROM:978-1-4673-9193-1; Electronic:978-1-4673-9194-8; POD:978-1-4673-9195-5","10.1109/ITNEC.2016.7560389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560389","clothing image retrieval;deep neural network;online shop images;video scenario","Clothing;Feature extraction;Image color analysis;Lighting;Machine learning;Neural networks;Training","Internet;clothing;image retrieval;neural nets;object recognition;retail data processing","clothing retrieval approach;color filtering;deep neural network;online clothing;online shop images;online shop photos;onscreen character;shopping","","","","","","","20-22 May 2016","","IEEE","IEEE Conference Publications"
"Analysing and Predicting the Runtime of Social Graphs","R. Maher; D. Malone","Hamilton Inst., Maynooth Univ., Maynooth, Ireland","2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)","20161031","2016","","","370","376","The explosion of Social Network Analysis (SNA) in many different areas and the growing need for powerful data analysis has emphasized the importance of in-memory big data processing in computer systems. Particularly, large-scale graphs are gaining much more attention due to their wide range of application. This rise, accompanied by a massive number of vertices and edges, led computations to become increasingly expensive and time consuming. That is why there is a move towards distributed systems or Big Data cluster(s) to provide the required computational power and memory to handle such demand of huge graphs. Thus, figuring out whether a new social graph dataset can be processed successfully on a personal machine or there is a need for a distributed system or big-memory machine is still a remaining open question. In this paper, we try to address this question by providing a comparative analysis for the performance of two of the most well known SNA tools for performing commonly used graph algorithms such as counting Triads, calculating Degree Distribution and finding Clusters which can give an indication of the possibility of carrying out the work on a personal machine. Based on these measurements, we train different supervised machine learning models for predicting the execution time of these algorithms. We compare the accuracy of the different machine learning models and provided the details of the most accurate model that can be exploited by end users to better estimate the execution time expected for processing new social graphs on a personal machine.","","","10.1109/BDCloud-SocialCom-SustainCom.2016.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723716","Graph Algorithms;Graph Analytics;Performance;Predictive Modeling;Social Graphs;Social Network Analysis","Algorithm design and analysis;Clustering algorithms;Database languages;Facebook;Machine learning algorithms;Prediction algorithms","Big Data;data analysis;learning (artificial intelligence);social networking (online)","SNA;data analysis;graph edges;graph vertices;in-memory big data processing;large-scale graph;social graph dataset;social network analysis;supervised machine learning models","","","","","","","8-10 Oct. 2016","","IEEE","IEEE Conference Publications"
"Expert-prescribed weighting for support vector machine classification","N. Bajaj; N. J. Murrell; J. G. Whitney; J. P. Allebach; G. T. C. Chiu","School of Mechanical Engineering, Purdue University, West Lafayette, IN 47907, USA","2016 IEEE International Conference on Advanced Intelligent Mechatronics (AIM)","20160929","2016","","","913","918","Support Vector Machines (SVM) are a family of algorithms that are used in classification and regression tasks. Often, multiple SVMs are combined in a coding scheme to provide multi-class classification capabilities. Generally, multi-class classification systems are evaluated on their accuracy of producing a correct coding by using test data and successful predictions are counted as a percentage of the whole, assuming that the test data set is a “good” representation of what the classification algorithm will see in its applied use. However, in practical applications, there may be situations where certain mistakes/confusions in classification are inconsequential to system operation. In this work, a method for integration of expert-defined allowable confusions into SVM systems is introduced, with an example implementation in a least squares support vector machine (LS-SVM) tested on industrial data, and shown to improve overall performance of a multi-class classification system when an appropriate performance measurement method is formulated.","","","10.1109/AIM.2016.7576885","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576885","","Algorithm design and analysis;Encoding;Machine learning algorithms;Prediction algorithms;Support vector machines;Training;Training data","least squares approximations;pattern classification;regression analysis;support vector machines","LS-SVM;coding scheme;expert-defined allowable confusion integration;expert-prescribed weighting;least squares support vector machine;multiclass classification systems;regression tasks;support vector machine classification","","","","","","","12-15 July 2016","","IEEE","IEEE Conference Publications"
"Quality assessment of Wikipedia articles without feature engineering","Q. V. Dang; C. L. Ignat","Universit&#x00E9; de Lorraine, LORIA, F-54506, Inria, F-54600, CNRS, LORIA, F-54506","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","27","30","As Wikipedia became the largest human knowledge repository, quality measurement of its articles received a lot of attention during the last decade. Most research efforts focused on classification of Wikipedia articles quality by using a different feature set. However, so far, no “golden feature set” was proposed. In this paper, we present a novel approach for classifying Wikipedia articles by analysing their content rather than by considering a feature set. Our approach uses recent techniques in natural language processing and deep learning, and achieved a comparable result with the state-of-the-art.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559560","Wikipedia;deep learning;document representation;feature engineering;quality assessment","Electronic publishing;Encyclopedias;Internet;Machine learning;Neural networks;Training","Internet;classification;encyclopaedias;learning (artificial intelligence);natural language processing","Wikipedia article classification;content analysis;deep learning;feature set;human knowledge repository;natural language processing;quality assessment;quality measurement","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"A Parallel DBSCAN Algorithm Based on Spark","G. Luo; X. Luo; T. F. Gooch; L. Tian; K. Qin","Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)","20161031","2016","","","548","553","With the explosive growth of data, we have entered the era of big data. In order to sift through masses of information, many data mining algorithms using parallelization are being implemented. Cluster analysis occupies a pivotal position in data mining, and the DBSCAN algorithm is one of the most widely used algorithms for clustering. However, when the existing parallel DBSCAN algorithms create data partitions, the original database is usually divided into several disjoint partitions, with the increase in data dimension, the splitting and consolidation of high-dimensional space will consume a lot of time. To solve the problem, this paper proposes a parallel DBSCAN algorithm (S_DBSCAN) based on Spark, which can quickly realize the partition of the original data and the combination of the clustering results. It is divided into the following steps: 1) partitioning the raw data based on a random sample, 2) computing local DBSCAN algorithms in parallel, 3) merging the data partitions based on the centroid. Compared with the traditional DBSCAN algorithm, the experimental result shows the proposed S_DBSCAN algorithm provides better operating efficiency and scalability.","","","10.1109/BDCloud-SocialCom-SustainCom.2016.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723739","DBSCAN Algorithm;Data Mining;Data Partition;Parallel Algorithms;Spark","Algorithm design and analysis;Clustering algorithms;Data mining;Machine learning algorithms;Merging;Partitioning algorithms;Sparks","Big Data;data mining;parallel algorithms;pattern clustering;public domain software","Big Data;S_DBSCAN;Spark;cluster analysis;data dimension;data mining algorithms;data partitions;density-based spatial clustering of applications with noise;disjoint partitions;high-dimensional space consolidation;high-dimensional space splitting;parallel DBSCAN algorithm","","","","","","","8-10 Oct. 2016","","IEEE","IEEE Conference Publications"
"Automatic Lumbar Vertebrae Detection Based on Feature Fusion Deep Learning for Partial Occluded C-arm X-ray Images","Y. Li; W. Liang; Y. Zhang; H. An; J. Tan","Key Laboratory of Networked Control Systems, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","647","650","Automatic and accurate lumbar vertebrae detection is an essential step of image-guided minimally invasive spine surgery (IG-MISS). However, traditional methods still require human intervention due to the similarity of vertebrae, abnormal pathological conditions and uncertain imaging angle. In this paper, we present a novel convolutional neural network (CNN) model to automatically detect lumbar vertebrae for C-arm X-ray images. Training data is augmented by DRR and automatic segmentation of ROI is able to reduce the computational complexity. Furthermore, a feature fusion deep learning (FFDL) model is introduced to combine two types of features of lumbar vertebrae X-ray images, which uses sobel kernel and Gabor kernel to obtain the contour and texture of lumbar vertebrae, respectively. Comprehensive qualitative and quantitative experiments demonstrate that our proposed model performs more accurate in abnormal cases with pathologies and surgical implants in multi-angle views.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590785","","Computational modeling;Feature extraction;Kernel;Machine learning;Pathology;Surgery;X-ray imaging","computational complexity;computerised tomography;image fusion;image segmentation;image texture;learning (artificial intelligence);medical image processing;neural nets;prosthetics;surgery","CNN;DRR;FFDL;Gabor kernel;IG-MISS;ROI;abnormal pathological condition;automatic lumbar vertebrae detection;automatic segmentation;computational complexity;convolutional neural network model;feature fusion deep learning model;image-guided minimally invasive spine surgery;imaging angle;lumbar vertebrae X-ray images;lumbar vertebrae contour;lumbar vertebrae texture;partial occluded C-arm X-ray images;sobel kernel;surgical implants;training data","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Deep Metric Learning for Visual Tracking","J. Hu; J. Lu; Y. P. Tan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Circuits and Systems for Video Technology","20161027","2016","26","11","2056","2068","In this paper, we propose a deep metric learning (DML) approach for robust visual tracking under the particle filter framework. Unlike most existing appearance-based visual trackers, which use hand-crafted similarity metrics, our DML tracker learns a nonlinear distance metric to classify the target object and background regions using a feed-forward neural network architecture. Since there are usually large variations in visual objects caused by varying deformations, illuminations, occlusions, motions, rotations, scales, and cluttered backgrounds, conventional linear similarity metrics cannot work well in such scenarios. To address this, our proposed DML tracker first learns a set of hierarchical nonlinear transformations in the feed-forward neural network to project both the template and particles into the same feature space where the intra-class variations of positive training pairs are minimized and the interclass variations of negative training pairs are maximized simultaneously. Then, the candidate that is most similar to the template in the learned deep network is identified as the true target. Experiments on the benchmark data set including 51 challenging videos show that our DML tracker achieves a very competitive performance with the state-of-the-art trackers.","1051-8215;10518215","","10.1109/TCSVT.2015.2477936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7258342","Deep learning;metric learning;visual tracking","Learning systems;Machine learning;Neural networks;Target tracking;Training;Visualization","feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);neural net architecture;object tracking;particle filtering (numerical methods)","DML tracker;appearance-based visual trackers;background regions classification;deep metric learning;deep network learning;feature space;feed-forward neural network architecture;hierarchical nonlinear transformations;interclass variations;intra-class variations;nonlinear distance metric;object classification;particle filter;visual objects;visual tracking","","5","","","","20150911","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Edge preservation ratio for image sharpness assessment","L. Chen; F. Jiang; H. Zhang; S. Wu; S. Yu; Y. Xie","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China","2016 12th World Congress on Intelligent Control and Automation (WCICA)","20160929","2016","","","1377","1381","Image sharpness is one of the most determining factors for image readability and scene understanding. How to accurately quantify it is a hot topic. This paper systematically validates a previously proposed index for full-reference image sharpness assessment (edge preservation ratio, EPR). Based on Gaussian blurring images in LIVE, CSIQ, TID2008 and TID2013 databases, we firstly evaluated EPR accuracy on five edge detectors on LIVE and selected an optimal one for further analysis. Then nine state-of-the-art image quality assessment metrics are compared, including full-reference, no-reference and dedicated image sharpness assessment categories. Experimental results demonstrate (1) Canny is an optimal edge detector for EPR implementation; (2) EPR is a top-ranking image sharpness assessment metric that outperforms PSNR and SSIM and rivals FSIM; and (3) EPR accords more closely with human subjective judgment than involved image sharpness assessment metrics. This study also indicates that image sharpness assessment is still full of challenges and utilizing deep learning architectures to learning the direct mapping from images to quality will be a trend in the near future.","","","10.1109/WCICA.2016.7578241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578241","","Databases;Detectors;Feature extraction;Image edge detection;Image quality;Machine learning;Measurement","edge detection;image restoration","Canny;EPR;FSIM;Gaussian blurring images;LIVE;PSNR;SSIM;edge detectors;edge preservation ratio;full-reference image sharpness assessment metrics;human subjective judgment;image quality assessment metrics;image readability;optimal edge detector;scene understanding","","","","","","","12-15 June 2016","","IEEE","IEEE Conference Publications"
"A deep learning approach to fetal-ECG signal reconstruction","P. R. Muduli; R. R. Gunukula; A. Mukherjee","Department of Electrical Engineering, Indian Institute of Technology Kharagpur, WB, 721302, India","2016 Twenty Second National Conference on Communication (NCC)","20160908","2016","","","1","6","Fetal electrocardiogram (FECG) monitoring has become essential due to the current increase in the relative number of cardiac patients worldwide. This paper proposes to use a deep learning approach to compress/recover FECG signals, improving the computation speed in a telemonitoring system. The problem is analogous to the reconstruction of a non-sparse signal in compressive sensing (CS) framework. The architecture incorporates a non-linear mapping using a stacked denoising autoencoder (SDAE). The compression of the raw non-sparse FECG data takes place at the transmitter side using a deep neural network. After pre-training, the whole deep SDAE can be further fine tuned by the mini-batch gradient descent-based back-propagation algorithm. Although the training for SDAE is usually time-consuming, it does not affect the performance due to the one-time off-line training process. The real-time FECG reconstruction is faster due to a few matrix-vector multiplications at the receiver end. The simulations performed by employing standard non-invasive FECG databases shows promising results in terms of the reconstruction quality.","","Electronic:978-1-5090-2361-5; POD:978-1-5090-2362-2","10.1109/NCC.2016.7561206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561206","","Computer architecture;Databases;Machine learning;Noise reduction;Sensors;Training;Transforms","compressed sensing;electrocardiography;encoding;learning (artificial intelligence);medical signal processing;signal denoising;signal reconstruction;signal restoration","CS framework;FECG monitoring;FECG signal compression;FECG signal recovery;SDAE;cardiac patients;compressive sensing framework;deep learning approach;deep neural network;fetal-ECG signal reconstruction;matrix-vector multiplication;mini-batch gradient descent-based back-propagation algorithm;nonlinear mapping;nonsparse FECG data;nonsparse signal reconstruction;one-time off-line training process;real-time FECG reconstruction;reconstruction quality;stacked denoising autoencoder;standard noninvasive FECG databases;telemonitoring system","","","","","","","4-6 March 2016","","IEEE","IEEE Conference Publications"
"Improving quality and intelligibility of speech using single microphone for the broadband fMRI noise at low SNR","C. Vahanesa; C. K. A. Reddy; I. M. S. Panahi","Department of Electrical Engineering, The University of Texas at Dallas, Richardson, Texas 75080, USA","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","3674","3678","Functional Magnetic Resonance Imaging (fMRI) is used in many diagnostic procedures for neurological related disorders. Strong broadband acoustic noise generated during fMRI scan interferes with the speech communication between the physician and the patient. In this paper, we propose a single microphone Speech Enhancement (SE) technique which is based on the supervised machine learning technique and a statistical model based SE technique. The proposed algorithm is robust and computationally efficient and has capability to run in real-time. Objective and Subjective evaluations show that the proposed SE method outperforms the existing state-of-the-art algorithms in terms of quality and intelligibility of the recovered speech at low Signal to Noise Ratios (SNRs).","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591525","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591525","","Acoustic noise;Algorithm design and analysis;Machine learning algorithms;Noise measurement;Speech;Speech enhancement;Training","acoustic noise;biomedical MRI;image denoising;learning (artificial intelligence);medical disorders;medical image processing;microphones;neurophysiology;speech enhancement;speech intelligibility;statistical analysis","SNR;broadband fMRI noise;diagnostic procedures;fMRI scan;functional magnetic resonance imaging;neurological related disorders;patient;physician;signal to noise ratio;single microphone speech enhancement technique;speech communication;speech intelligibility;speech quality;statistical model based SE technique;strong broadband acoustic noise;supervised machine learning technique","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Automatic tissue characterization of air trapping in chest radiographs using deep neural networks","A. Mansoor; G. Perez; G. Nino; M. G. Linguraru","Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Health System, Washington DC","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","97","100","Significant progress has been made in recent years for computer-aided diagnosis of abnormal pulmonary textures from computed tomography (CT) images. Similar initiatives in chest radiographs (CXR), the common modality for pulmonary diagnosis, are much less developed. CXR are fast, cost effective and low-radiation solution to diagnosis over CT. However, the subtlety of textures in CXR makes them hard to discern even by trained eye. We explore the performance of deep learning abnormal tissue characterization from CXR. Prior studies have used CT imaging to characterize air trapping in subjects with pulmonary disease; however, the use of CT in children is not recommended mainly due to concerns pertaining to radiation dosage. In this work, we present a stacked autoencoder (SAE) deep learning architecture for automated tissue characterization of air-trapping from CXR. To our best knowledge this is the first study applying deep learning framework for the specific problem on 51 CXRs, an F-score of ≈ 76.5% and a strong correlation with the expert visual scoring (R=0.93, p =<; 0.01) demonstrate the potential of the proposed method to characterization of air trapping.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590649","","Charge carrier processes;Computed tomography;Lungs;Machine learning;Shape;Training;Visualization","biological tissues;computerised tomography;diseases;learning (artificial intelligence);medical image processing;neural nets;pneumodynamics","CXR textures;abnormal pulmonary textures;air trapping;automatic tissue characterization;chest radiographs;computed tomography images;computer-aided diagnosis;deep neural networks;pulmonary diagnosis;pulmonary disease;radiation dosage;stacked autoencoder deep learning architecture","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"An improved fall detection approach for elderly people based on feature weight and Bayesian classification","H. Wang; M. Li; J. Li; J. Cao; Z. Wang","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai 200072, China","2016 IEEE International Conference on Mechatronics and Automation","20160905","2016","","","471","476","Aging population and empty-nesters are two big challenges in modern healthcare. Fall incidents can cause various physical injuries and serious consequence without receiving timely assistance. Therefore, fall detection and movement classification have very high research value and application significance. This paper aims to study the optimum feature subset of falls and put forward an improved approach to detect falls. A set of twelve motion features of eleven kinds of activities are extracted from different parts of body. Then, an improved classifier is proposed based on feature weight and Bayesian framework for fall detection. The optimal features will be selected to reduce the number of features required for the classification problem. Finally, the activity types of unknown samples are predicted using the optimal features and the classifier gained above, and the accuracy of classification will be analyzed. It has been verified through experiments that the improved fall detection approach can get higher accuracy (sensitivity 95.75% and specificity 1.24%) and better robustness (AUC 0.993).","","CD-ROM:978-1-5090-2394-3; Electronic:978-1-5090-2396-7; POD:978-1-5090-2397-4","10.1109/ICMA.2016.7558609","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7558609","Fall detection;Feature weight;Improved Bayes","Accelerometers;Bayes methods;Classification algorithms;Feature extraction;Machine learning algorithms;Robustness;Senior citizens","Bayes methods;feature extraction;geriatrics;patient care;signal classification;signal detection","Bayesian classification;elderly people;fall detection;movement classification","","","","","","","7-10 Aug. 2016","","IEEE","IEEE Conference Publications"
"Optimal label vector for convolutional neural network","L. Feng; M. Sun; S. Liu; J. Wu","School of Computer Science and Technology, Dalian University of Technology, Dalian, Liaoning, China","2016 12th World Congress on Intelligent Control and Automation (WCICA)","20160929","2016","","","1842","1845","Convolutional Neural Network(CNN) is a kind of deep learning and it has become a current hot topic in the field of image recognition. In the CNN, Output layer consists of Euclidean Radial Basis Function, unit matrix column as CNN's label vector. The category of the input image can be interpreted as the nearest label vector. This paper addresses a question: what is CNN's optimal label vector? We show that label vector influence CNN's accuracy. Most surprisingly, we show that the new label vector achieves the lowest known error rate on the Convolutional net LeNet-5, unprocessed MNIST dataset (0.45%).","","","10.1109/WCICA.2016.7578384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578384","","Biological neural networks;Circuits and systems;Electronic mail;Image recognition;Linear programming;Machine learning","convolution;image recognition;learning (artificial intelligence);matrix algebra;radial basis function networks;vectors","CNN optimal label vector;Euclidean radial basis function;convolutional net LeNet-5;convolutional neural network;deep learning;image recognition;input image category;unit matrix column;unprocessed MNIST dataset","","","","","","","12-15 June 2016","","IEEE","IEEE Conference Publications"
"AG-MIC: Azure-Based Generalized Flow for Medical Image Classification","S. Roychowdhury; M. Bihis","Department of Electrical Engineering, University of Washington, Bothell-, WA, USA","IEEE Access","20160928","2016","4","","5243","5257","Medical image-based research requires heavy computational workload associated with image analysis and collaborative device independent platforms to incorporate expert opinions from multiple institutions. Cloud-based resources such as Microsoft Azure Machine Learning Studio (MAMLS) provide such a platform that is conducive to the medical-image-based data analysis. This paper fosters the advantages of the cloud-based computing frameworks (such as MAMLS) and presents a practical work-flow well-suited for the standard machine learning tasks seen in medical image research viz., binary classification, multi-class learning, regression and so on. The proposed automated generalized workflow allows medical researchers/practitioners to focus on data inferencing rather than dealing with the intricate details of predictive modeling, such as feature and model selection. The scalable architecture of the proposed flow utilizes the MAMLS framework to processes data sets that require partial core storage space in the virtual machine to one complete core storage space in a common flow. Also, the proposed flow invokes multiple feature ranking and predictive models in parallel for automated selection and parameterization of the optimal data model. The performance of the proposed flow is bench-marked on 14 public data sets and four local medical image data sets (~0.12 MB-1.22 GB) using a single common flow, while ensuring better (~8% improvement) or atleast similar generalization capability with respect to existing works.","2169-3536;21693536","","10.1109/ACCESS.2016.2605641","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559702","Microsoft Azure;cloud-computing;feature selection;hyper-parameter search;machine leaning;medical image","Biomedical imaging;Cloud computing;Computer architecture;Data analysis;Data models;Machine learning algorithms;Predictive models","cloud computing;computerised tomography;feature selection;image classification;learning (artificial intelligence);medical image processing","AG-MIC;MAMLS;Microsoft azure machine learning studio;azure-based generalized flow;bench-marked flow;binary classification;cloud-based computing frameworks;cloud-based resources;computational workload;feature ranking;feature selection;image analysis;local medical image data sets;medical image classification;medical-image-based data analysis;model selection;multiclass learning;multiclass regression;virtual machine","","","","","","20160902","2016","","IEEE","IEEE Journals & Magazines"
"A novel incremental learning scheme for reinforcement learning in dynamic environments","Z. Wang; C. Chen; H. X. Li; D. Dong; T. J. Tarn","Department of Control and Systems Engineering, School of Management and Engineering, Nanjing University, Nanjing 210093, China","2016 12th World Congress on Intelligent Control and Automation (WCICA)","20160929","2016","","","2426","2431","In this paper, we develop a novel incremental learning scheme for reinforcement learning (RL) in dynamic environments, where the reward functions may change over time instead of being static. The proposed incremental learning scheme aims at automatically adjusting the optimal policy in order to adapt to the ever-changing environment. We evaluate the proposed scheme on a classical maze navigation problem and an intelligent warehouse system in simulated dynamic environments. Simulation results show that the proposed scheme can greatly improve the adaptability and applicability of RL in dynamic environments compared to several other direct methods.","","","10.1109/WCICA.2016.7578530","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578530","","Dynamic programming;Electronic mail;Heuristic algorithms;Intelligent control;Learning (artificial intelligence);Machine learning algorithms;Systems engineering and theory","learning (artificial intelligence)","classical maze navigation problem;incremental learning scheme;intelligent warehouse system;optimal policy;reinforcement learning;reward functions;simulated dynamic environments","","","","","","","12-15 June 2016","","IEEE","IEEE Conference Publications"
"Improvement of Chinese sign language translation system based on collaboration of arm and finger sensing nodes","C. Wu; C. Pan; Y. Jin; S. Sun; G. Shi","Shaoxing University Yuanpei College, China","2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","20160926","2016","","","474","478","With the rapid development of science and technology, the accelerated pace of life, people need to rely on language and hearing to exchange information, share information, learn and progress together. Currently there are about 70 million deaf and dumb people in the world, and in China there are about 20 million patients with different levels of hearing impairment. It is imminent to develop a set of devices that can connect the deaf and the normal people. With the development of human-computer interaction technology and pattern recognition technology, more and more researchers have entered into the field of sign language recognition and sign language translation. In this paper, we design a multi node sign language translation based on the pattern recognition technology. After data preprocessing, feature extraction, C4.5 decision tree algorithm recognition, 50 sign language actions with arms and body can get the recognition rate about 98%.","","Electronic:978-1-5090-2733-0; POD:978-1-5090-2734-7; USB:978-1-5090-2732-3","10.1109/CYBER.2016.7574872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574872","C4.5 decision tree;Feature Extraction;Sign language","Assistive technology;Classification algorithms;Decision trees;Gesture recognition;Machine learning algorithms;Micromechanical devices;Prediction algorithms","decision trees;feature extraction;groupware;handicapped aids;human computer interaction;sign language recognition","C4.5 decision tree algorithm recognition;Chinese sign language translation system;arm sensing nodes;collaboration;feature extraction;finger sensing nodes;hearing impairment;human computer interaction technology;pattern recognition technology;science and technology;sign language recognition","","","","","","","19-22 June 2016","","IEEE","IEEE Conference Publications"
"Clothes classification based on deep belief network","Xue Lin; Lizhi Peng; Guangshun Wei; Xiaofang Wang; Xiuyang Zhao","School of Information Science and Engineering, University of Jinan, China 250022","2016 3rd International Conference on Informative and Cybernetics for Computational Social Systems (ICCSS)","20161010","2016","","","87","92","In this paper, faced with the diversity and difference of clothes, we propose a novel method combined deep belief network and softmax classifier to achieve the classification of clothes. First of all, we preprocess the angle and scaling of various styles of clothes images that are collected through web crawler, then we do something to convert the image into the corresponding input format. In addition, the DBN is trained layer-by-layer with the input of all image pixels and the top level of the network is a classification hyperplane. At last, we apply the DBN that has been trained completely to classify the strange clothes. Compared with traditional classifier softmax and deep structure deepid1, our algorithm has higher classification accuracy rate.","","","10.1109/ICCSS.2016.7586429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586429","","Classification algorithms;Feature extraction;Information science;Internet;Machine learning;Neural networks;Training","Internet;belief networks;clothing;image classification","Web crawler;clothes classification;clothes imaging;deep belief network;image pixels;softmax classifier","","","","","","","26-29 Aug. 2016","","IEEE","IEEE Conference Publications"
"Context-aware fall detection using inertial sensors and time-of-flight transceivers","M. C. Shastry; M. Asgari; E. A. Wan; J. Leitschuh; N. Preiser; J. Folsom; J. Condon; M. Cameron; P. G. Jacobs","Dept. of Biomedical Engineering, Oregon Health & Science University, Portland, OR, 97239","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","570","573","Automatic detection of falls is important for enabling people who are older to safely live independently longer within their homes. Current automated fall detection systems are typically designed using inertial sensors positioned on the body that generate an alert if there is an abrupt change in motion. These inertial sensors provide no information about the context of the person being monitored and are prone to false positives that can limit their ongoing usage. We describe a fall-detection system consisting of a wearable inertial measurement unit (IMU) and an RF time-of-flight (ToF) transceiver that ranges with other ToF beacons positioned throughout a home. The ToF ranging enables the system to track the position of the person as they move around a home. We describe and show results from three machine learning algorithms that integrate context-related position information with IMU based fall detection to enable a deeper understanding of where falls are occurring and also to improve the specificity of fall detection. The beacons used to localize the falls were able to accurately track to within 0.39 meters of specific waypoints in a simulated home environment. Each of the three algorithms was evaluated with and without the context-based false alarm detection on simulated falls done by 3 volunteer subjects in a simulated home. False positive rates were reduced by 50% when including context.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590766","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590766","","Acceleration;Accelerometers;Classification algorithms;Histograms;Machine learning algorithms;Standards;Support vector machines","assisted living;geriatrics;inertial systems;learning (artificial intelligence);ubiquitous computing","automatic falls detection;context aware fall detection;context related position information;false positive rate;inertial sensors;machine learning algorithms;time-of-flight transceivers;wearable inertial measurement unit","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Thorax disease diagnosis using deep convolutional neural network","J. Chen; X. Qi; O. Tervonen; O. Silvén; G. Zhao; M. Pietikäinen","University of Oulu, Finland","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2287","2290","Computer aided diagnosis (CAD) is an important issue, which can significantly improve the efficiency of doctors. In this paper, we propose a deep convolutional neural network (CNN) based method for thorax disease diagnosis. We firstly align the images by matching the interest points between the images, and then enlarge the dataset by using Gaussian scale space theory. After that we use the enlarged dataset to train a deep CNN model and apply the obtained model for the diagnosis of new test data. Our experimental results show our method achieves very promising results.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591186","","Diseases;Filtering theory;Machine learning;Radiography;Solid modeling;Thorax;Training","Gaussian processes;diagnostic radiography;diseases;image matching;medical image processing;neural nets;radiology","CAD;Gaussian scale space theory;computer aided diagnosis;deep CNN model;deep convolutional neural network;image alignment;image matching;radiograph;radiology;thorax disease diagnosis","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Robust malware detection with Dual-Lane AdaBoost","X. Y. Zhang; Z. Hou; X. Zhu; G. Wu; S. Wang","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China","2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","20160908","2016","","","1051","1052","As an effective algorithm that integrates weak learners into a strong one, AdaBoost has found its application in various fields. Traditional AdaBoost works under the supervised learning scenario. Typically, with a limited number of labeled instances available, the learning performance is jeopardized. In this paper, we propose a novel Dual-Lane AdaBoost algorithm, which introduces semi-supervised learning into AdaBoost. On one hand, weak learners pass the weights on the labeled instances to the subsequent ones. On the other hand, the unlabeled instances with high confidence are recommended from one weak learner to another. From the perspective of information flow, we establish a dual-lane path between the weak learners. In this way, both the labeled and the unlabeled instances are fully explored and exploited. Consequently, the integrated strong learner can be remarkably improved. Experimental results on the malware dataset demonstrate the effectiveness of the proposed algorithm.","","Electronic:978-1-4673-9955-5; POD:978-1-4673-9956-2","10.1109/INFCOMW.2016.7562248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562248","AdaBoost;collaborative recommendation;dual-lane path;information propagation;semi-supervised learning","Collaboration;Machine learning algorithms;Malware;Robustness;Semisupervised learning;Supervised learning;Training","invasive software;learning (artificial intelligence)","dual-lane AdaBoost;information flow;labeled instances;learning performance;malware dataset;malware detection;semisupervised learning;strong learner;supervised learning scenario;unlabeled instances;weak learners","","","","","","","10-14 April 2016","","IEEE","IEEE Conference Publications"
"Evolving deep neural networks: A new prospect","S. S. Tirumala; S. Ali; C. P. Ramesh","Auckland University of Technology, Auckland, New Zealand","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","69","74","The success of Deep Neural Networks (DNNs) for various applications like language processing (NLP), image processing, character recognition inspired to use machine learning (ML) and Evolutionary Computation (EC) techniques for improving learning process. Using evolutionary algorithms to improve the efficiency of deep learning attained some success. However, these techniques are unable to reduce the learning time which is the key concern for deep learning. The main problem with DNN is that, it uses a random topology to start with (similar to artificial neural networks). If the topology is not suitable, training procedure will restart with a new topology and this process continues till expected results are obtained. In this paper, we propose, for the first time, a new prospect for evolving optimized deep neural networks which can provide a warm start to the training process compared to heuristic random initial architecture. We discuss the theoretical approach towards possibility of optimizing the learning process inspired from the existing un-conventional approaches. The training process of DNN with EC approach is faster than regular approach by a considerable difference of over 6 hours for MNIST data set. Further, we observed a considerable improvement in the classification accuracies. Our approaches resulted in an improved classification accuracy of 2% and 4.4%for MNIST data set and 1.2% and 1.4% for IRIS data set compared to heuristic random weights approach. Our initial experimental results prove that evolutionary approaches provides a warm start to the deep learning, thus, reducing the training time.","","","10.1109/FSKD.2016.7603153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603153","Co-evolution;Deep Neural Networks;Evolving Neural Networks;Multi-population evolution","Computer architecture;Encoding;Machine learning;Network topology;Neural networks;Topology;Training","evolutionary computation;neural nets;pattern classification;topology","EC;ML;MNIST data set;NLP;character recognition;classification accuracy;deep neural networks;evolutionary algorithms;evolutionary computation;image processing;machine learning;natural language processing;time training reduction","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Multimodal image stitching algorithm for weed control applications in organic farming","T. Holtorf; F. J. Knoll; S. Hussmann","Faculty of Engineering, West Coast University of Applied Sciences, Heide, Germany","2016 SAI Computing Conference (SAI)","20160901","2016","","","336","342","In computer vision applications based on machine learning algorithms, a ground truth of datasets is necessary for efficient training of classification or data mining algorithms. Due to the increasing computer power, machine vision systems are developed for robotic, medical and industrial applications. This paper puts the main emphasis on the SURF algorithm for agricultural image applications in organic farming. The algorithm is used for a multimodal image stitching algorithm for biological weed control in the agricultural sector. Based on the algorithm a ground truth agricultural crop map is produced to allow a proper detection of weed. The calculation effort of the algorithm is examined and the experimental results are presented.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7556003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556003","Plant segmentation;SURF algorithm (speedup robust features);biological weed control;image database;image stitching;optical measurement;robotic;weed detection","Algorithm design and analysis;Cameras;Classification algorithms;Image color analysis;Machine learning algorithms;Robots;Standards","computer vision;crops;data mining;farming;image classification;learning (artificial intelligence)","SURF algorithm;agricultural image applications;agricultural sector;biological weed control;classification training;computer vision;data mining;ground truth agricultural crop map;machine learning algorithms;machine vision systems;multimodal image stitching algorithm;organic farming;weed control applications;weed detection","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Spectral–Spatial Classification of Hyperspectral Image Based on Deep Auto-Encoder","X. Ma; H. Wang; J. Geng","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20161003","2016","9","9","4073","4085","Deep learning, which represents data by a hierarchical network, has proven to be efficient in computer vision. To investigate the effect of deep features in hyperspectral image (HSI) classification, this paper focuses on how to extract and utilize deep features in HSI classification framework. First, in order to extract spectral-spatial information, an improved deep network, spatial updated deep auto-encoder (SDAE), is proposed. SDAE, which is an improved deep auto-encoder (DAE), considers sample similarity by adding a regularization term in the energy function, and updates features by integrating contextual information. Second, in order to deal with the small training set using deep features, a collaborative representation-based classification is applied. Moreover, in order to suppress salt-and-pepper noise and smooth the result, we compute the residual of collaborative representation of all samples as a residual matrix, which can be effectively used in a graph-cut-based spatial regularization. The proposed method inherits the advantages of deep learning and has solutions to add spatial information of HSI in the learning network. Using collaborative representation-based classification with deep features makes the proposed classifier extremely robust under a small training set. Extensive experiments demonstrate that the proposed method provides encouraging results compared with some related techniques.","1939-1404;19391404","","10.1109/JSTARS.2016.2517204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405235","Deep auto-encoders (DAE);feature learning;hyperspectral image (HSI);supervised classification","Collaboration;Data mining;Feature extraction;Hyperspectral imaging;Kernel;Machine learning;Training","hyperspectral imaging;image classification;remote sensing","computer vision;deep learning;deep network;hyperspectral image spectral-spatial classification;representation-based classification;residual matrix;spatial updated deep autoencoder","","3","","","","20160211","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Semantic computation in geography question answering","S. Zhao; Y. Zheng; C. Zhu; T. Zhao; S. Li","School of Computer Science and Technology, Harbin Institute of Technology, HIT, Harbin, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1572","1576","In this paper, we develop a question answering system for solving single-option geography questions. The system is built in two directions. One computes semantic similarity between two questions. The other converts the task into question sentence binary-classification by generating the distributed representation of sentence semantic. When computing semantic similarity, we first implement a basic framework based on bag-of-words (BOW), and then extend the framework to Edit Distance variant and BM25 variant. On the other hand, we use convolutional neural network and stacked denoising auto-encoder to generate the distributed representation of sentence semantic respectively. Given the semantic representation of sentence, a logistic regression classifier is employed to classify the sentence. The dataset we use is a large scale Chinese college entrance examination question set of geography, which is clawed from the internet. Experiment results show that the performance of CNN can answer the single-option geography questions with high accuracy, which can achieve 0.7310.","","","10.1109/FSKD.2016.7603410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603410","BM25;CNN;SDA;single-option question","Computational modeling;Feature extraction;Geography;Knowledge discovery;Machine learning;Rocks;Semantics","Internet;geophysics computing;neural nets;pattern classification;question answering (information retrieval);regression analysis","BM25 variant;CNN;Chinese college entrance examination question set;Internet;convolutional neural network;edit distance variant;geography question answering;logistic regression classifier;question sentence binary-classification;semantic computation;semantic sentence representation;single-option geography questions;stacked denoising auto-encoder","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Automatically recommending code reviewers based on their expertise: An empirical comparison","C. Hannebauer; M. Patalas; S. Stünkelt; V. Gruhn","paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","20161006","2016","","","99","110","Code reviews are an essential part of quality assurance in Free, Libre, and Open Source Software (FLOSS) projects. However, finding a suitable reviewer can be difficult, and delayed or forgotten reviews are the consequence. Automating reviewer selection with suitable algorithms can mitigate this problem. We compare empirically six algorithms based on modification expertise and two algorithms based on review expertise on four major FLOSS projects. Our results indicate that the algorithms based on review expertise yield better recommendations than those based on modification expertise. The algorithm Weighted Review Count (WRC) recommends at least one out of five reviewers correctly in 69 % to 75 % of all cases, which is one of the best results achieved in the comparison.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582749","Code reviewer recommendation;code reviews;expertise metrics;issue tracker;open source;patches;recommendation system","Algorithm design and analysis;History;Machine learning algorithms;Measurement;Prediction algorithms;Software;Software algorithms","project management;public domain software;software quality","FLOSS projects;WRC;code reviewer automatic recommendation;free, libre, and open source software projects;modification expertise;quality assurance;review expertise;reviewer selection automation;weighted review count","","","","","","","3-7 Sept. 2016","","IEEE","IEEE Conference Publications"
"Convolutional neural networks applied to handwritten mathematical symbols classification","I. Ramadhan; B. Purnama; S. A. Faraby","School of Computing, Telkom University, Bandung, Indonesia","2016 4th International Conference on Information and Communication Technology (ICoICT)","20160922","2016","","","1","4","Convolutional Neural Networks have achieved great performance in computer vision and pattern recognition applications. In this work, we propose the use of Convolutional Neural Networks in order to improve the handwritten mathematical symbol classification rate. We trained a Convolutional Neural Networks to classifying mathematical symbols into a proper class using Competition on Recognition of Online Handwritten Mathematical Expressions (CROHME) 2014 dataset. The results show that Convolutional Neural Networks outperforms the previous works in terms of accuracy.","","","10.1109/ICoICT.2016.7571941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571941","convolutional neural networks;handwritten mathematical symbols recognition;pattern recognition","Biological neural networks;Computer architecture;Convolution;Handwriting recognition;Machine learning","computer vision;convolution;handwritten character recognition;image classification;mathematics computing;neural nets;symbol manipulation","computer vision;convolutional neural network;handwritten mathematical symbol classification;pattern recognition","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Fault diagnosis for centrifugal pumps using deep learning and softmax regression","W. Zhao; Z. Wang; C. Lu; J. Ma; L. Li","School of Reliability and Systems Engineering, Beihang University, China","2016 12th World Congress on Intelligent Control and Automation (WCICA)","20160929","2016","","","165","169","Fault diagnosis of centrifugal pumps is critical to lower its operating and maintenance costs. Due to the non-stationary and non-linear characteristics of vibration signals of centrifugal pumps, a large number of approaches for feature extraction and fault classification have been developed. However, these traditional methods spend too much time extracting features, reducing feature dimension and fusing different features. To resolve the issue, this paper presents an effective unsupervised self-learning method to achieve the fault diagnosis of centrifugal pumps, which uses deep learning method to adaptively extract fault features from non-stationary vibration signals and softmax regression model is used to identify possible failure modes automatically. In particular, the stacked denoising autoencoder (SDA) of deep learning models is selected to learn effective feature representations and we improved fault pattern classification robustness by corrupting the input data. The effectiveness and feasibility of the proposed method are validated by experiments in this paper.","","","10.1109/WCICA.2016.7578673","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578673","","Fault diagnosis;Feature extraction;Machine learning;Noise reduction;Pumps;Reliability engineering","costing;encoding;fault diagnosis;feature extraction;pattern classification;pumps;regression analysis;signal denoising;unsupervised learning;vibrational signal processing","SDA;centrifugal pumps;deep learning;fault classification;fault diagnosis;fault pattern classification;feature dimension reduction;feature extraction;maintenance cost;nonlinear characteristic;nonstationary characteristic;operation cost;softmax regression;stacked denoising autoencoder;unsupervised self-learning;vibration signals","","","","","","","12-15 June 2016","","IEEE","IEEE Conference Publications"
"Compressed auto-encoder building block for deep learning network","Qiying Feng; C. L. P. Chen; Long Chen","Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, China","2016 3rd International Conference on Informative and Cybernetics for Computational Social Systems (ICCSS)","20161010","2016","","","131","136","Deep learning algorithm has been widely used in many area which is one of the most important representation learning algorithms in machine learning tasks. Deep learning network is stacked by the building blocks such as the restricted Boltzmann machine(RBM) and the auto-encoder, convolutional building block. After stacking the building blocks layers and layers, the improvement of the deep learning network would be notable. In this paper, we proposed a new deep learning building block that inspired by the auto-encoder, which is the compressed auto-encoder with fewer layers and parameters compared with the auto-encoder, and we put forward a bidirectional gradient decent method to update the parameters of this building block. As the experimental results show that improves the performance of the auto-encoder in accuracy of the reconstruction data. It keeps declining the error while the results of rbm or the auto-encoder becomes saturation, and some analysis are given in this paper.","","","10.1109/ICCSS.2016.7586437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586437","RBM;back propagation;bidirectional gradient decent;compressed auto-encoder","Biological neural networks;Data models;Linear programming;Machine learning;Mathematical model;Training;Training data","Boltzmann machines;convolution;data compression;gradient methods;learning (artificial intelligence)","RBM;bidirectional gradient descent method;compressed autoencoder building block;convolutional building block;deep learning network;machine learning;representation learning algorithms;restricted Boltzmann machine","","","","","","","26-29 Aug. 2016","","IEEE","IEEE Conference Publications"
"Saliency detection based on Markov chain and Adaboost","Y. Zhao; G. Tan; L. Zhang","College of Computer Science and Electronic Engineering, Hunan University, Changsha, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1516","1522","In this paper, an effective saliency detection method is proposed to minimize the error caused by boundary prior. When the salient objects appear in picture edge, the results generated by the traditional methods are usually not ideal. We proposed a two-step algorithm to optimize the saliency detection. Firstly, an initial saliency map is generated by absorbing Markov chain model. In this model, super-pixels in edge of the picture are treated as virtual boundary absorbing nodes. The remaining super-pixels are treated as transient nodes. Transient nodes' absorbed time are calculated as their saliency value. Then the initial saliency map is utilized as training samples to train an Adaboost classifier. The initial saliency map is refined with the trained Adaboost model to get a optimized saliency map. By combining the two maps we get the final saliency map. Experiments show that our algorithm is superior to other traditional saliency detection method when salient objects are close to image boundaries.","","","10.1109/FSKD.2016.7603401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603401","Absorbing Markov Chain;Adaboost;Saliency Detection","Classification algorithms;Image color analysis;Image edge detection;Machine learning algorithms;Markov processes;Support vector machines;Transient analysis","Markov processes;edge detection;image classification;image resolution;learning (artificial intelligence)","Adaboost classifier;Markov chain model;initial saliency map;picture edge;saliency detection method;saliency map optmization;saliency value;super-pixels;training samples;two-step algorithm;virtual boundary absorbing nodes","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"A Deep Learning Framework of Quantized Compressed Sensing for Wireless Neural Recording","B. Sun; H. Feng; K. Chen; X. Zhu","School of Electrical Engineering and Automation, Tianjin University, Tianjin, China","IEEE Access","20160928","2016","4","","5169","5178","In low-power wireless neural recording tasks, signals must be compressed before transmission to extend battery life. Recently, compressed sensing (CS) theory has successfully demonstrated its potential in neural recording applications. In this paper, a deep learning framework of quantized CS, termed BW-NQ-DNN, is proposed, which consists of a binary measurement matrix, a non-uniform quantizer, and a non-iterative recovery solver. By training the BW-NQ-DNN, the three parts are jointly optimized. Experimental results on synthetic and real datasets reveal that BW-NQ-DNN not only drastically reduce the transmission bits but also outperforms the state-of-the-art CS-based methods. On the challenging high compression ratio task, the proposed approach still achieves high recovery performance and spike classification accuracy. This framework is of great values to wireless neural recoding devices, and many variants can be straightforwardly derived for low-power wireless telemonitoring applications.","2169-3536;21693536","","10.1109/ACCESS.2016.2604397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560597","Wireless neural recording;deep learning;non-uniform quantization;quantized compressive sensing","Battery charge measurement;Compressed sensing;Deep learning;Low power electronics;Machine learning;Wireless communication;Wireless sensor networks","bioelectric phenomena;compressed sensing;learning (artificial intelligence);medical signal processing;neurophysiology","BW-NQ-DNN;binary measurement matrix;deep learning;high recovery performance;low-power wireless telemonitoring;no-uniform quantizer;noniterative recovery solver;quantized compressed sensing;signal compression;spike classification accuracy;wireless neural recoding devices;wireless neural recording","","","","","","20160905","2016","","IEEE","IEEE Journals & Magazines"
"Combining deep learning with rough set analysis: A model of cyberspace situational awareness","X. Li; X. Li; Z. Zhao","College of Information Science and Engineering, Shandong University of Science and Technology, Qingdao, Shandong Province, China","2016 6th International Conference on Electronics Information and Emergency Communication (ICEIEC)","20161013","2016","","","182","185","A cyberspace situational awareness (CSA) model, DLRSA model, is proposed in this paper, with feature extraction based on deep learning (DL) and situation assessment based on rough set analysis (SARSA). We focus on network flow instead of server logs of IDS to extract features, transforming source data into information and establishing knowledge base. On account of Gaussian-Bernoulli deep belief network (GBDBN), accurate feature information is provided for assessment. While DLRSA model assesses situation in reference to pattern recognition, assessment strategy could be given by rough set analysis and pattern information abstracted deeply. Experiments indicate that DLRSA model has low extraction error and succinct assessment rule.","","","10.1109/ICEIEC.2016.7589715","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589715","Gaussian-Bernoulli Deep Belief Network;cyberspace situational awareness;deep learning;feature extraction;rough set analysis;situation assessment","Analytical models;Artificial neural networks;Cyberspace;Feature extraction;Machine learning;Pattern recognition;Rough sets","belief networks;feature extraction;learning (artificial intelligence);rough set theory;ubiquitous computing","CSA model;DLRSA model;GBDBN;Gaussian-Bernoulli deep belief network;SARSA;cyberspace situational awareness;deep learning;feature extraction;knowledge base establishment;network flow;pattern recognition;server logs;situation assessment based on rough set analysis;source data transformation","","","","","","","17-19 June 2016","","IEEE","IEEE Conference Publications"
"An incremental algorithm for rapidly computing tolerance class of incomplete information system","M. Ding; T. Zhang; F. Ma; D. Yue","College of Automation, Nanjing University of Posts and Telecommunications, Nanjing, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1296","1300","The tolerance class is a basic concept in rough set for incomplete information systems. The effective computation of tolerance class is vital for improving the performance of knowledge reduction and other related tasks. For the purpose of speeding up the tolerance class calculation, an improved static algorithm is developed firstly, followed by a novel incremental algorithm, which can update rapidly the tolerance class when a new object is coming. The validity of this algorithm is demonstrated by simulation and experimental results.","","","10.1109/FSKD.2016.7603365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603365","incomplete system;incremental algorithm;tolerance class;tolerance relation","Analytical models;Computational modeling;Data mining;Heuristic algorithms;Information systems;Machine learning algorithms;Rough sets","information systems;rough set theory","incomplete information system;incremental algorithm;knowledge reduction;rough set;static algorithm development;tolerance class calculation;tolerance class rapid computing;tolerance class updating","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"On Learning of Choice Models with Interactive Attributes","M. Aggarwal","Indian Institute of Management, Ahmedabad, Gujarat, India","IEEE Transactions on Knowledge and Data Engineering","20160909","2016","28","10","2697","2708","Introducing recent advances in the machine learning techniques to state-of-the-art discrete choice models, we develop an approach to infer the unique and complex decision making process of a decision-maker (DM), which is characterized by the DM's priorities and attitudinal character, along with the attributes interaction, to name a few. On the basis of exemplary preference information in the form of pairwise comparisons of alternatives, our method seeks to induce a DM's preference model in terms of the parameters of recent discrete choice models. To this end, we reduce our learning function to a constrained non-linear optimization problem. Our learning approach is a simple one that takes into consideration the interaction among the attributes along with the priorities and the unique attitudinal character of a DM. The experimental results on standard benchmark datasets suggest that our approach is not only intuitively appealing and easily interpretable but also competitive to state-of-the-art methods.","1041-4347;10414347","","10.1109/TKDE.2016.2563434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7465842","Preference learning;attitudinal character;attributes interaction;choice modelling;multi-attribute decision making","Biological system modeling;Computational modeling;Data models;Decision making;Machine learning algorithms;Optimization;Predictive models","behavioural sciences computing;decision making;learning (artificial intelligence);nonlinear programming","DM attitudinal character;DM preference model;DM priorities;attitudinal character;attribute interaction;choice model learning;constrained nonlinear optimization problem;decision making process inference;decision-maker;discrete choice model parameters;discrete choice models;exemplary preference information;interactive attributes;learning function reduction;machine learning techniques;standard benchmark datasets","","","","","","20160505","Oct. 1 2016","","IEEE","IEEE Journals & Magazines"
"Multilayer Unmixing for Hyperspectral Imagery With Fast Kernel Archetypal Analysis","G. Zhao; C. Zhao; X. Jia","College of Information and Telecommunications, Harbin Engineering University, Harbin, China","IEEE Geoscience and Remote Sensing Letters","20160916","2016","13","10","1532","1536","The multilayer network in deep learning provides a promising means for rich data representation. Inspired by this approach, we investigate multilayer unmixing for spectral decomposition with fast kernel archetypal analysis (KAA). KAA is used for endmember extraction and abundance estimation simultaneously. To refine the initial unmixing results, a multilayer process is utilized to provide final unmixing results at the end of the network. Moreover, a fast implementation of KAA is proposed via using the Nyström method to relieve KAA's memory issue and decrease the processing time. The proposed method is tested on both synthetic and real hyperspectral image data sets. The results demonstrate that the multilayer unmixing algorithm outperforms the conventional unmixing techniques.","1545-598X;1545598X","","10.1109/LGRS.2016.2595102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542548","Hyperspectral imagery;Nyström method;kernel archetypal analysis (KAA);multilayer network;spectral unmixing","Estimation;Hyperspectral imaging;Kernel;Machine learning;Neurons;Nonhomogeneous media","geophysical image processing;hyperspectral imaging;remote sensing","Nystrom method;fast kernel archetypal analysis;hyperspectral imagery;multilayer unmixing algorithm;spectral decomposition","","","","","","20160812","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Network planning tool based on network classification and load prediction","S. E. Hammami; H. Afifi; M. Marot; V. Gauthier","RST Department, Institute Mines-Telecom, T&#x00E9;l&#x00E9;com SudParis Saclay, France","2016 IEEE Wireless Communications and Networking Conference","20160915","2016","","","1","6","Real Call Detail Records (CDR) are analyzed and classified based on Support Vector Machine (SVM) algorithm. The daily classification results in three traffic classes. We use two different algorithms, K-means and SVM to check the classification efficiency. A second support vector regression (SVR) based algorithm is built to make an online prediction of traffic load using the history of CDRs. Then, these algorithms will be integrated to a network planning tool which will help cellular operators on planning optimally their access network.","","Electronic:978-1-4673-9814-5; POD:978-1-4673-9815-2","10.1109/WCNC.2016.7565166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565166","CDR;Classification;K-means;Network planning tool;Prediction;SVM;SVR;traffic Load","Algorithm design and analysis;Base stations;Classification algorithms;Machine learning algorithms;Prediction algorithms;Support vector machines;Training","cellular radio;regression analysis;support vector machines;telecommunication computing;telecommunication network planning;telecommunication traffic","CDR analysis;K-means algorithm;SVM algorithm;SVR-based algorithm;access network;call detail record analysis;cellular operator;load prediction;network classification;network planning tool;support vector machine algorithm;support vector regression-based algorithm;traffic classification;traffic load online prediction","","","","","","","3-6 April 2016","","IEEE","IEEE Conference Publications"
"Block2Vec: A Deep Learning Strategy on Mining Block Correlations in Storage Systems","D. Dai; F. S. Bao; J. Zhou; Y. Chen","Dept. of Comput. Sci., Texas Tech Univ., Lubbock, TX, USA","2016 45th International Conference on Parallel Processing Workshops (ICPPW)","20160926","2016","","","230","239","Block correlations represent the semantic patterns in storage systems. These correlations can be exploited for data caching, pre-fetching, layout optimization, I/O scheduling, etc. In this paper, we introduce Block2Vec, a deep learning based strategy to mine the block correlations in storage systems. The core idea of Block2Vec is twofold. First, it proposes a new way to abstract blocks, which are considered as multi-dimensional vectors instead of traditional block Ids. In this way, we are able to capture similarity between blocks through the distances of their vectors. Second, based on vector representation of blocks, it further trains a deep neural network to learn the best vector assignment for each block. We leverage the recently advanced word embedding technique in natural language processing to efficiently train the neural network. To demonstrate the effectiveness of Block2Vec, we design a demonstrative block prediction algorithm based on mined correlations. Empirical comparison based on the simulation of real system traces shows that Block2Vec is capable of mining block-level correlations efficiently and accurately. This research and trial show that the deep learning strategy is a promising direction in optimizing storage system performance.","","","10.1109/ICPPW.2016.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576472","IO;block correlation;deep learning;embedding","Computational modeling;Correlation;Machine learning;Natural language processing;Neural networks;Probability;Training","data mining;learning (artificial intelligence);natural language processing;neural nets;storage management;vectors","Block2Vec;block correlation mining;block prediction algorithm;deep learning strategy;deep neural network;multidimensional vectors;natural language processing;real system traces;semantic patterns;storage systems;word embedding technique","","","","","","","16-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Autonomous website categorization with pre-defined dictionary","A. Chanakitkarnchok; K. N. Nakorn; K. Rojviboolchai","Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand","2016 13th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","20160908","2016","","","1","6","In this technology emerging era, the number of websites is increasing dramatically. The content and category of information are overflowing the Internet World. Finding the right information from almost a billion of websites is considerably hard, but finding the accurate and quality one is even harder. Hence, the need of website categorization's demand is increasing tremendously. Unfortunately, the website categorization techniques in previous works are still immature and not good enough to satisfy the need. Additionally, a training dataset is a limitation of supervised learning algorithm and unsupervised learning algorithm also have a complex algorithm. Regularly, they can categorize into only 1 category but the content usually contains various types. Therefore, in this paper, we propose the simple yet powerful algorithm for website categorization which can give a multi-category results with confidence level, distributed systems supported, and does not even need to be trained because the algorithm uses word frequency in the content of each website to match with the categories in a pre-defined dictionary. The result shows that the accuracy of our proposed algorithm is over 95% when tested with Reuters dataset. The comparison of our algorithm and another Text Analysis API shows that our algorithm has more accuracy with less computation time. The accuracy can also be increased by improving the pre-defined dictionary and filtering noise words.","","Electronic:978-1-4673-9749-0; POD:978-1-4673-9750-6","10.1109/ECTICon.2016.7561432","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561432","URL categorize;Web categorize;text analysis;text categorize;text classification","Algorithm design and analysis;Classification algorithms;Dictionaries;HTML;Machine learning algorithms;Text categorization;Uniform resource locators","Internet;Web sites;dictionaries;text analysis;unsupervised learning;word processing","Internet world;Reuters dataset;autonomous website categorization;category match;distributed systems support;information finding;noise word filtering;predefined dictionary;text analysis API;training dataset;unsupervised learning algorithm;word frequency","","","","","","","June 28 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Semi-advised learning model for skin cancer diagnosis based on histopathalogical images","A. Masood; A. Al-Jumaily","University of Technology Sydney, P.O. Box 123 Broadway, NSW 2007 Australia","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","631","634","Computer aided classification of skin cancer images is an active area of research and different classification methods has been proposed so far. However, the supervised classification models based on insufficient labeled training data can badly influence the diagnosis process. To deal with the problem of limited labeled data availability this paper presents a semi advised learning model for automated recognition of skin cancer using histopathalogical images. Deep belief architecture is constructed using unlabeled data by making efficient use of limited labeled data for fine tuning done the classification model. In parallel an advised SVM algorithm is used to enhance classification results by counteracting the effect of misclassified data using advised weights. To increase generalization capability of the model, advised SVM and Deep belief network are trained in parallel. Then the results are aggregated using least square estimation weighting. The proposed model is tested on a collection of 300 histopathalogical images taken from biopsy samples. The classification performance is compared with some popular methods and the proposed model outperformed most of the popular techniques including KNN, ANN, SVM and semi supervised algorithms like Expectation maximization algorithm and transductive SVM based classification model.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590781","","Computer architecture;Data models;Machine learning;Skin cancer;Support vector machines;Training;Training data","belief networks;cancer;image classification;learning (artificial intelligence);least squares approximations;medical image processing;skin;support vector machines","advised SVM algorithm;automated recognition;biopsy samples;computer aided classification;deep belief architecture;deep belief network;histopathalogical images;least square estimation weighting;semiadvised learning model;skin cancer diagnosis;skin cancer images","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Online Learning from Trapezoidal Data Streams","Q. Zhang; P. Zhang; G. Long; W. Ding; C. Zhang; X. Wu","Centre for Quantum Computation and Intelligent Systems, Faculty of Engineering and Information Technology, University of Technology Sydney, NSW,, Australia","IEEE Transactions on Knowledge and Data Engineering","20160909","2016","28","10","2709","2723","In this paper, we study a new problem of continuous learning from doubly-streaming data where both data volume and feature space increase over time. We refer to the doubly-streaming data as trapezoidal data streams and the corresponding learning problem as online learning from trapezoidal data streams. The problem is challenging because both data volume and data dimension increase over time, and existing online learning <xref ref-type=""bibr"" rid=""ref1""> [1]</xref> , <xref ref-type=""bibr"" rid=""ref2"">[2]</xref> , online feature selection <xref ref-type=""bibr"" rid=""ref3"">[3]</xref> , and streaming feature selection algorithms <xref ref-type=""bibr"" rid=""ref4"">[4]</xref> , <xref ref-type=""bibr"" rid=""ref5"">[5]</xref> are inapplicable. We propose a new Online Learning with Streaming Features algorithm (OL<inline-formula> <tex-math notation=""LaTeX"">$_{SF}$</tex-math><alternatives> <inline-graphic xlink:type=""simple"" xlink:href=""zhang-ieq1-2563424.gif""/></alternatives></inline-formula> for short) and its two variants, which combine online learning <xref ref-type=""bibr"" rid=""ref1"">[1]</xref> , <xref ref-type=""bibr"" rid=""ref2"">[2]</xref> and streaming feature selection <xref ref-type=""bibr"" rid=""ref4"">[4]</xref> , <xref ref-type=""bibr"" rid=""ref5"">[5]</xref> to enable learning from trapezoidal data streams with infinite training instances and features. When a new training instance carrying new features arrives, a classifier updates the existing features by following the passive-aggressive update rule <xref ref-type=""bibr"" rid=""ref2"">[2]</xref> and updates the new features by following the structural risk minimization principle. Feature sparsity is then introduced by using the projected truncation technique. We derive performance bounds of the OL<inline-formula> <tex-math notation=""LaTeX"">$_{SF}$</tex-math><alternatives> <inline-graphic xlink:type=""simple"" xlink:href=""zhang-ieq2-2563424.gif""/></alternatives></inline-formula> algorithm and its variants. We also conduct experimen- s on real-world data sets to show the performance of the proposed algorithms.","1041-4347;10414347","","10.1109/TKDE.2016.2563424","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7465766","Online learning;sparsity;streaming features;trapezoidal data streams","Algorithm design and analysis;Approximation algorithms;Data mining;Decision support systems;Heuristic algorithms;Machine learning algorithms;Training","","","","","","","","20160505","Oct. 1 2016","","IEEE","IEEE Journals & Magazines"
"Information-theoretic analysis of stability and bias of learning algorithms","M. Raginsky; A. Rakhlin; Matthew Tsao; Y. Wu; Aolin Xu","University of Illinois at Urbana-Champaign, 61801, USA","2016 IEEE Information Theory Workshop (ITW)","20161027","2016","","","26","30","Machine learning algorithms can be viewed as stochastic transformations that map training data to hypotheses. Following Bousquet and Elisseeff, we say that such an algorithm is stable if its output does not depend too much on any individual training example. Since stability is closely connected to generalization capabilities of learning algorithms, it is of theoretical and practical interest to obtain sharp quantitative estimates on the generalization bias of machine learning algorithms in terms of their stability properties. We propose several information-theoretic measures of algorithmic stability and use them to upper-bound the generalization bias of learning algorithms. Our framework is complementary to the information-theoretic methodology developed recently by Russo and Zou.","","","10.1109/ITW.2016.7606789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7606789","","Algorithm design and analysis;Machine learning algorithms;Mutual information;Stability criteria;Training;Training data","information theory;learning (artificial intelligence)","algorithmic stability;information-theoretic analysis;machine learning algorithms","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Accelerating forwarding computation of artificial neural network using CUDA","J. H. Park; W. W. Ro","School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea","2016 International Conference on Electronics, Information, and Communications (ICEIC)","20160908","2016","","","1","4","Recently, graphics processing units (GPUs) are widely used for accelerating general purpose workloads using programming models such as open computing language (OpenCL) or compute unified device architecture (CUDA). In this paper, we accelerated the Artificial Neural Network (ANN) algorithm, one of the popular algorithm in machine learning and cognitive science, since the ANN algorithm needs to be faster for solving more complex problem or operating in real-time. The ANN algorithm has great potential for GPU acceleration since it is constructed with large data-parallel computations. We implemented forwarding computation of ANN in CUDA and optimized it using scratchpad memory of GPUs and leveraging the thread block size. As a results, our method shows 2.32 times faster performance compared to conventional CPU.","","Electronic:978-1-4673-8016-4; POD:978-1-4673-8017-1","10.1109/ELINFOCOM.2016.7562974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562974","ANN;CUDA;GPGPU","Acceleration;Artificial neural networks;Computer architecture;Graphics processing units;Instruction sets;Machine learning algorithms;Performance evaluation","graphics processing units;neural nets;parallel architectures","ANN algorithm;CUDA;GPU acceleration;artificial neural network;compute unified device architecture;forwarding computation acceleration;graphics processing units;scratchpad memory","","","","","","","27-30 Jan. 2016","","IEEE","IEEE Conference Publications"
"Effect of data representations on deep learning in fall detection","B. Jokanovic; M. G. Amin; F. Ahmad","Center for Advanced Communications, Villanova University, Villanova, PA 19085, USA","2016 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM)","20160919","2016","","","1","5","Fall-related injuries can have a significant impact on the quality of life of the elderly population. Because of the upward trend in the elderly for continued independent living, there is a growing need for reliable fall detectors that can enable prompt assistance in case of falls. Doppler radar technology offers a number of desirable attributes for realization of fall detection and health monitoring systems that can facilitate self-dependent living. Human motions generate changes in Doppler frequencies that can be accurately captured using time-frequency representations. A variety of time-frequency distributions have been proposed in the literature. In this paper, we investigate the impact of different time-frequency representations on the performance of a deep neural network based fall detector. Using real data, we demonstrate that the choice of data representation in the time-frequency domain is important for enhancing the accuracy of the fall detector.","","","10.1109/SAM.2016.7569734","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569734","","Detectors;Doppler effect;Feature extraction;Machine learning;Radar;Senior citizens;Spectrogram","Doppler radar;biomechanics;data structures;geriatrics;injuries;learning (artificial intelligence);medical signal processing;neural nets;patient monitoring;time-frequency analysis","Doppler frequencies;Doppler radar technology;continued independent living;data representations;deep learning;deep neural network;elderly population;fall detection;fall-related injuries;health monitoring systems;time-frequency distributions;time-frequency representations","","","","","","","10-13 July 2016","","IEEE","IEEE Conference Publications"
"Infra: SLO Aware Elastic Auto-scaling in the Cloud for Cost Reduction","S. Sidhanta; S. Mukhopadhyay","Louisiana State Univ., Baton Rouge, LA, USA","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","141","148","Enterprises often host applications and services on clusters of virtual machine instances provided by cloud service providers, like Amazon, Rackspace, Microsoft, etc. Users pay a cloud usage cost on the basis of the hourly usage [1] of virtual machine instances composing the cluster. A cluster composition refers to the number of virtual machine instances of each type (from a predefined list of types) comprising a cluster. We present Infra, a cloud provisioning framework that can predict an (ϵ, δ)-minimum cluster composition required to run a given application workload on a cloud under an SLO (i.e., Service Level Objective) deadline. This paper does not present a new approximation algorithm, instead we provide a tool that applies existing machine learning techniques to predict an (ϵ, δ)-minimum cluster composition. An (ϵ, δ)-minimum cluster composition specifies a cluster composition whose cost approximates that of the minimum cluster composition (i.e., the cluster composition that incurs the minimum cloud usage cost that must be incurred in executing a given application under an SLO deadline); the approximation bounds the error to a predefined threshold ϵ with a degree of confidence 100 * (1 - δ)%. The degree of confidence 100 * (1 - δ)% specifies that the probability of failure in achieving the error threshold ϵ for the above approximation is at most δ. For ϵ = 0.1 and δ = 0.02, we experimentally demonstrate that an (ϵ, δ)-minimum cluster composition predicted by Infra successfully approximates the minimum cluster composition, i.e., the accuracy of prediction of minimum cluster composition ranges from 93.1% to 97.99% (the error is bound by the error threshold of 0.1) with - 98% degree of confidence, since 100* (1 - δ) = 98%. Auto scaling refers to the process of automatically adding cloud instances to a cluster to adapt to an increase in application workload (increased request rate), and deleting instances from a cluster when there is a decrease in workload (reduced request rate). However, state-of-the-art auto scaling techniques have the following disadvantages: A) they require explicit policy definition for changing the cluster configuration and therefore lack the ability to automatically adapt a cluster with respect to changing workload, B) they do not compute the appropriate size of resources required, and therefore do not result in an “optimal” cluster composition. Infra provides an auto scaler that automatically adapts a cloud infrastructure to changing application workload, scaling the cluster up/down based on predictions from the Infra provisioning tool.","","","10.1109/BigDataCongress.2016.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584931","cost optimal cluster composition;elastic auto scaling;provisioning","Algorithm design and analysis;Cloud computing;Clustering algorithms;Machine learning algorithms;Mathematical model;Training;Virtual machining","cloud computing;cost reduction;learning (artificial intelligence);pattern clustering;virtual machines","(ϵ, δ)-minimum cluster composition prediction;Infra provisioning tool;SLO aware elastic autoscaling;cloud infrastructure;cloud provisioning framework;cloud service providers;cloud usage cost;cost reduction;error threshold;machine learning techniques;probability of failure;service level objective;virtual machine instances","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"An efficient technique for author name disambiguation","R. Hazra; A. Saha; S. B. Deb; D. Mitra","Department of Information Technology, National Institute of Technology, Durgapur, India","2016 IEEE International Conference on Current Trends in Advanced Computing (ICCTAC)","20160915","2016","","","1","6","Scholarly digital libraries have become an important source of bibliographic records for scientific communities. Author name search is one of the most common query exercised in digital libraries. The name ambiguity problem in the context of author search in digital libraries, arising from multiple authors sharing the same name, poses many challenges. A number of name disambiguation methods have been proposed in the literature so far. A variety of bibliographic attributes have been considered in these methods. However, hardly any effort has been made to assess the potential contribution of these attributes. We, for the first time, evaluate the potential strength and/or weaknesses of these attributes by a rigorous course of experiments on a large data set. We also explore the potential utility of some attributes from different perspective. A close look reveals that most of the earlier work require one or more attributes which are difficult to obtain in practical applications. Based on this empirical study, we identify three very common and easy to access attributes and propose a two-step hierarchical clustering technique to solve name ambiguity using these attributes only. Experimental results on data set extracted from a popular digital library show that the proposed method achieves significantly high level of accuracy (> 90%) for most of the instances.","","","10.1109/ICCTAC.2016.7567344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7567344","","Databases;Electronic mail;Hidden Markov models;Libraries;Machine learning algorithms;Search problems;Training data","bibliographic systems;digital libraries;pattern clustering;query processing;scientific information systems;text analysis","author name disambiguation;bibliographic attributes;bibliographic records;name disambiguation methods;scholarly digital libraries;scientific communities;two-step hierarchical clustering technique","","","","","","","10-11 March 2016","","IEEE","IEEE Conference Publications"
"Implementing Cost-Effective Data Collection and Extraction Processes with CollaMine","K. Z. M. Lu; B. Heng","Sch. of Inf. Technol., Nanyang Polytech., Singapore, Singapore","2016 International Conference on Cloud Computing Research and Innovations (ICCCRI)","20161020","2016","","","92","99","We present the CollaMine framework which aims to reduce the cost of data collection and data extraction. The framework consists of two keysolutions, namely, a collaborative system for web crawlers, and an automated regular expression diagnosis system for web content extractors. The empirical results show that the systems help to reduce the costs of data collection and extraction.","","","10.1109/ICCCRI.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600183","automation;data extraction;data scraping;regular expression;web crawler","Business;Crawlers;Data mining;HTML;Layout;Machine learning algorithms;Uniform resource locators","Internet;cost reduction;groupware;information retrieval","CollaMine framework;Web content extractors;Web crawlers;automated regular expression diagnosis system;collaborative system;cost reduction;cost-effective data collection;cost-effective data extraction process","","","","","","","4-5 May 2016","","IEEE","IEEE Conference Publications"
"An adaptive deep learning approach for PPG-based identification","V. Jindal; J. Birjandtalab; M. B. Pouyan; M. Nourani","Quality of Life Technology Laboratory, The University of Texas at Dallas, Richardson, TX 75080","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","6401","6404","Wearable biosensors have become increasingly popular in healthcare due to their capabilities for low cost and long term biosignal monitoring. This paper presents a novel two-stage technique to offer biometric identification using these biosensors through Deep Belief Networks and Restricted Boltzman Machines. Our identification approach improves robustness in current monitoring procedures within clinical, e-health and fitness environments using Photoplethysmography (PPG) signals through deep learning classification models. The approach is tested on TROIKA dataset using 10-fold cross validation and achieved an accuracy of 96.1%.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7592193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592193","","Biological system modeling;Biomedical monitoring;Brain modeling;Feature extraction;Machine learning;Neural networks;Training","Boltzmann machines;belief networks;biometrics (access control);biosensors;body sensor networks;health care;learning (artificial intelligence);medical signal processing;patient monitoring;photoplethysmography","10-fold cross validation;Deep Belief Networks;PPG-based identification;Restricted Boltzman Machines;TROIKA dataset;adaptive deep learning approach;biometric identification;biosignal monitoring;clinical environments;deep learning classification models;e-health environments;fitness environments;healthcare;photoplethysmography signals;two-stage technique;wearable biosensors","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Deep Models for Engagement Assessment With Scarce Label Information","F. Li; G. Zhang; W. Wang; R. Xu; T. Schnell; J. Wen; F. McKenzie; J. Li","Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA 23529 USA (e-mail: flixx003@odu.edu).","IEEE Transactions on Human-Machine Systems","","2016","PP","99","1","8","Task engagement is defined as loadings on energetic arousal (affect), task motivation, and concentration (cognition) . It is usually challenging and expensive to label cognitive state data, and traditional computational models trained with limited label information for engagement assessment do not perform well because of overfitting. In this paper, we proposed two deep models (i.e., a deep classifier and a deep autoencoder) for engagement assessment with scarce label information. We recruited 15 pilots to conduct a 4-h flight simulation from Seattle to Chicago and recorded their electroencephalograph (EEG) signals during the simulation. Experts carefully examined the EEG signals and labeled 20 min of the EEG data for each pilot. The EEG signals were preprocessed and power spectral features were extracted. The deep models were pretrained by the unlabeled data and were fine-tuned by a different proportion of the labeled data (top 1%, 3%, 5%, 10%, 15%, and 20%) to learn new representations for engagement assessment. The models were then tested on the remaining labeled data. We compared performances of the new data representations with the original EEG features for engagement assessment. Experimental results show that the representations learned by the deep models yielded better accuracies for the six scenarios (77.09%, 80.45%, 83.32%, 85.74%, 85.78%, and 86.52%), based on different proportions of the labeled data for training, as compared with the corresponding accuracies (62.73%, 67.19%, 73.38%, 79.18%, 81.47%, and 84.92%) achieved by the original EEG features. Deep models are effective for engagement assessment especially when les- label information was used for training.","2168-2291;21682291","","10.1109/THMS.2016.2608933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7579229","Deep learning;electroencephalography (EEG);engagement assessment;scarce label information","Brain models;Data models;Electroencephalography;Feature extraction;Machine learning;Training","","","","","","","","20160928","","","IEEE","IEEE Early Access Articles"
"Evaluating the Energy Efficiency of Deep Convolutional Neural Networks on CPUs and GPUs","D. Li; X. Chen; M. Becchi; Z. Zong","Dept. of Electr. & Comput. Eng., Univ. of Missouri, Columbia, MO, USA","2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)","20161031","2016","","","477","484","In recent years convolutional neural networks (CNNs) have been successfully applied to various applications that are appropriate for deep learning, from image and video processing to speech recognition. The advancements in both hardware (e.g. more powerful GPUs) and software (e.g. deep learning models, open-source frameworks and supporting libraries) have significantly improved the accuracy and training time of CNNs. However, the high speed and accuracy are at the cost of energy consumption, which has been largely ignored in previous CNN design. With the size of data sets grows exponentially, the energy demand for training such data sets increases rapidly. It is highly desirable to design deep learning frameworks and algorithms that are both accurate and energy efficient. In this paper, we conduct a comprehensive study on the power behavior and energy efficiency of numerous well-known CNNs and training frameworks on CPUs and GPUs, and we provide a detailed workload characterization to facilitate the design of energy efficient deep learning solutions.","","","10.1109/BDCloud-SocialCom-SustainCom.2016.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723730","GPUs;deep learning;energy-efficiency;neural networks","Biological neural networks;Energy consumption;Energy efficiency;Graphics processing units;Hardware;Machine learning;Training","energy conservation;graphics processing units;learning (artificial intelligence);neural nets","CPU;GPU;central processing unit;deep convolutional neural networks;deep learning framework;energy efficiency;graphics processing unit","","1","","","","","8-10 Oct. 2016","","IEEE","IEEE Conference Publications"
"Feature-Level Change Detection Using Deep Representation and Feature Change Analysis for Multispectral Imagery","H. Zhang; M. Gong; P. Zhang; L. Su; J. Shi","Department of Integrated Circuit Design and Integrated System, School of Microelectronics, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xidian University, Xi&#x0027;an, Xi&#x0027;an, ChinaChina","IEEE Geoscience and Remote Sensing Letters","20161012","2016","13","11","1666","1670","Due to the noise interference and redundancy in multispectral images, it is promising to transform the available spectral channels into a suitable feature space for relieving noise and reducing the redundancy. The booming of deep learning provides a flexible tool to learn abstract and invariant features directly from the data in their raw forms. In this letter, we propose an unsupervised change detection technique for multispectral images, in which we combine deep belief networks (DBNs) and feature change analysis to highlight changes. First, a DBN is established to capture the key information for discrimination and suppress the irrelevant variations. Second, we map bitemporal change feature into a 2-D polar domain to characterize the change information. Finally, an unsupervised clustering algorithm is adopted to distinguish the changed and unchanged pixels, and then, the changed types can be identified by classifying the changed pixels into several classes according to the directions of feature changes. The experimental results demonstrate the effectiveness and robustness of the proposed method.","1545-598X;1545598X","","10.1109/LGRS.2016.2601930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559716","Change detection;change vector analysis (CVA);cosine angle distance (CAD);deep belief networks (DBNs);multispectral images","Feature extraction;Interference;Lighting;Machine learning;Principal component analysis;Redundancy;Transforms","belief networks;feature extraction;geophysical image processing;image representation;learning (artificial intelligence);pattern clustering;vectors","CVA;DBN;bitemporal change feature mapping;change vector analysis;deep belief network;deep learning;deep representation;feature change analysis;feature-level change detection;multispectral imagery;unsupervised change detection;unsupervised clustering algorithm","","","","","","20160902","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Multi-modal Deep Embedding via Hierarchical Grounded Composition Semantics","Y. Zhuang; J. Song; F. Wu; X. Li; Z. Zhang; Y. Rui","Yueting Zhuang (email: yzhuang@cs.zju.edu.cn)","IEEE Transactions on Circuits and Systems for Video Technology","","2016","PP","99","1","1","For a number of important problems, isolated semantic representations of individual syntactic words or visual objects do not suffice, but instead a compositional semantic representation is required, for examples, a literal phrase or a set of spatially-concurrent objects. In this paper, we aim to harness the existing image-sentence databases to exploit the compositional nature of image-sentence data for multi-modal deep embedding. Specifically, we propose an approach called hierarchical-alike (bottom-up two layers) multi-modal grounded compositional semantics learning (hiMoCS). The proposed hiMoCS systemically captures the compositional semantic connotation of multimodal data in the setting of hierarchical-alike deep learning by modelling the inherent correlations between two modalities of collaboratively grounded semantics, such as the textual entity (with its describing attribute) and visual object, the phrase (e.g., subject-verb-object triplet) and spatially-concurrent objects. We argue that hiMoCS is more appropriate to reflect the multi-modal compositional semantics of the image and its narrative textual sentence which are strongly-coupled. We evaluate hiMoCS on the several benchmark datasets and show that the utilization of the hierarchical-alike multi-modal grounded compositional semantics (textual entities and visual objects, textual phrase and spatiallyconcurrent objects) achieves a much better performance than only using the flat grounded compositional semantics.","1051-8215;10518215","","10.1109/TCSVT.2016.2606648","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562283","Compositional Semantics;Multi-modal Analysis;Multi-modal Embedding","Bicycles;Buildings;Correlation;Feature extraction;Machine learning;Semantics;Visualization","","","","","","","","20160907","","","IEEE","IEEE Early Access Articles"
"Application of semi-supervised deep learning to lung sound analysis","D. Chamberlain; R. Kodgule; D. Ganelin; V. Miglani; R. R. Fletcher","Massachusetts Institute of Technology, Cambridge, MA 02139 USA","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","804","807","The analysis of lung sounds, collected through auscultation, is a fundamental component of pulmonary disease diagnostics for primary care and general patient monitoring for telemedicine. Despite advances in computation and algorithms, the goal of automated lung sound identification and classification has remained elusive. Over the past 40 years, published work in this field has demonstrated only limited success in identifying lung sounds, with most published studies using only a small numbers of patients (typically N<;20) and usually limited to a single type of lung sound. Larger research studies have also been impeded by the challenge of labeling large volumes of data, which is extremely labor-intensive. In this paper, we present the development of a semi-supervised deep learning algorithm for automatically classify lung sounds from a relatively large number of patients (N=284). Focusing on the two most common lung sounds, wheeze and crackle, we present results from 11,627 sound files recorded from 11 different auscultation locations on these 284 patients with pulmonary disease. 890 of these sound files were labeled to evaluate the model, which is significantly larger than previously published studies. Data was collected with a custom mobile phone application and a low-cost (US$30) electronic stethoscope. On this data set, our algorithm achieves ROC curves with AUCs of 0.86 for wheeze and 0.74 for crackle. Most importantly, this study demonstrates how semi-supervised deep learning can be used with larger data sets without requiring extensive labeling of data.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590823","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590823","","Classification algorithms;Feature extraction;Labeling;Lungs;Machine learning;Neurons;Noise reduction","bioacoustics;biomedical electronics;diseases;learning (artificial intelligence);lung;medical signal processing;patient monitoring;signal classification;smart phones","auscultation location;automated lung sound classification;automated lung sound identification;custom mobile phone application;low-cost electronic stethoscope;lung sound analysis;patient monitoring;primary care;pulmonary disease diagnostics;semisupervised deep learning;sound file;telemedicine","","1","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Day-to-day variability in hybrid, passive brain-computer interfaces: Comparing two studies assessing cognitive workload","S. L. Klosterman; J. R. Estepp; J. W. Monnin; J. C. Christensen","Ball Aerospace & Technologies Corp., Fairborn, OH 45324-6269 USA","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","1584","1590","As hybrid, passive brain-computer interface systems become more advanced, it is important to grow our understanding of how to produce generalizable pattern classifiers of physiological data. One of the most difficult problems in applying machine learning algorithms to these data types is nonstationarity, which can evolve over the course of hours and days, and is more susceptible to changes resulting from complex cognitive function in comparison to simple, stimulus-based processes. This nonstationarity, referenced as day-to-day variability, results in the inability of many learning algorithms to generalize to new data. In previous work, we have shown that increasing the number of unique testing sessions used to form a learning set can improve the accuracy of classifying mental workload in a binary state paradigm. While this result was very promising, we did not address whether the additional discriminability was the result of a larger learning set or the uniqueness contributed by the testing sessions being spread over multiple days. Further, the simulation task used in this prior analysis was low-fidelity with respect to the task it attempted to model; whether these methods extend to more realistic task simulation environments has not been comparatively investigated. In this work, we compare these previous results to a second study, with a similar multi-day paradigm, that required participants to perform a more realistic simulation task. Comparative analysis of these two studies reveals that the improved generalization of the multi-day learning set is attributable, in large part, to the uniqueness of the multi-day paradigm. Further, this multi-day effect was also observed in the higher fidelity simulation study. These results help to validate the use of the multi-day learning set approach for improving overall system classification accuracy. Future studies should consider the use of multi-day designs for improving generalizability over other interesting - imensions.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591015","","Brain modeling;Brain-computer interfaces;Electrodes;Electroencephalography;Machine learning algorithms;Real-time systems;Support vector machines","brain-computer interfaces;cognition;electrocardiography;electroencephalography;learning (artificial intelligence);medical signal processing","brain-computer interface system;cognitive workload assessment;day-to-day variability;machine learning algorithm;mental workload classification;multiday paradigm;pattern classifier;system classification accuracy;task simulation environment","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Why Deep Learning Works: A Manifold Disentanglement Perspective","P. P. Brahma; D. Wu; Y. She","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","IEEE Transactions on Neural Networks and Learning Systems","20160915","2016","27","10","1997","2008","Deep hierarchical representations of the data have been found out to provide better informative features for several machine learning applications. In addition, multilayer neural networks surprisingly tend to achieve better performance when they are subject to an unsupervised pretraining. The booming of deep learning motivates researchers to identify the factors that contribute to its success. One possible reason identified is the flattening of manifold-shaped data in higher layers of neural networks. However, it is not clear how to measure the flattening of such manifold-shaped data and what amount of flattening a deep neural network can achieve. For the first time, this paper provides quantitative evidence to validate the flattening hypothesis. To achieve this, we propose a few quantities for measuring manifold entanglement under certain assumptions and conduct experiments with both synthetic and real-world data. Our experimental results validate the proposition and lead to new insights on deep learning.","2162-237X;2162237X","","10.1109/TNNLS.2015.2496947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7348689","Deep learning;disentanglement;manifold learning;unsupervised feature transformation","Data models;Kernel;Machine learning;Manifolds;Neural networks;Nonhomogeneous media;Principal component analysis","learning (artificial intelligence);neural nets","deep hierarchical representations;deep learning works;disentanglement perspective;machine learning applications;manifold shaped data flattening;multilayer neural networks;unsupervised pretraining","","","","","","20151207","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Errata","","","IEEE Signal Processing Magazine","20160905","2016","33","5","172","172","Presents corrections to the paper, ""Bayesian machine learning: EEG/MEG signal processing measurements,"" (Wu, W., et al),IEEE Signal Processing Mag., vol. 33, no. 1, pp. 14-36, Jan. 2016.","1053-5888;10535888","","10.1109/MSP.2016.2585746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560007","","Bayes methods;Machine learning","","","","","","","","","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Research on speech emotion recognition based on deep auto-encoder","W. Fei; X. Ye; Zhaoyu Sun; Yujia Huang; Xing Zhang; Shengxing Shang","College of Information Science and Engineering, Northeastern University, Shenyang 110819, China","2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","20160926","2016","","","308","312","Good features are critical for the research of speech emotion recognition. This paper based on the theory of deep learning, and phonetic features were extracted by using the method of deep auto-encoder (DAE). In this paper, a deep auto-encoder containing five hidden layers was designed. To get the input data, we divided the audio into short frames, each frame of speech emotion signal was then decomposed with wavelet, and was calculated the Fourier transform. Higher features were learned with deep automatic encoder, and some traditional features such as MFCC, LPCC were also extracted. With high-level features and traditional features, support vector machine was used for classification and recognition. Compared with the traditional features, the results show that the highest recognition accuracy rate can be reached 86.41%.","","Electronic:978-1-5090-2733-0; POD:978-1-5090-2734-7; USB:978-1-5090-2732-3","10.1109/CYBER.2016.7574841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574841","DAE speech emotion recognition feature extraction","Computers;Emotion recognition;Feature extraction;Machine learning;Speech;Speech recognition;Training","Fourier transforms;cepstral analysis;emotion recognition;feature extraction;learning (artificial intelligence);signal classification;speech coding;speech recognition;support vector machines;wavelet transforms","DAE;Fourier transform;LPCC feature extraction;MFCC feature extraction;Mel-frequency cepstral coefficient;classification task;deep-automatic encoder;deep-learning theory;feature learning;frame decomposition;hidden layers;high-level features;input data;linear predictive cepstral coefficient;phonetic feature extraction;recognition accuracy rate;short-audio frames;speech emotion signal recognition;support vector machine;wavelet transform","","","","","","","19-22 June 2016","","IEEE","IEEE Conference Publications"
"Kernel approach for similarity measure in latent fingerprint recognition","S. Kumar; R. L. Velusamy","Department of Computer Science and Engineering, National Institute of Technology, Tiruchirappalli-620015, Tiruchirappalli, India","2016 International Conference on Emerging Trends in Electrical Electronics & Sustainable Energy Systems (ICETEESES)","20161006","2016","","","368","373","The Recognition of Fingerprint is one of the fundamental problems in the field of pattern recognition. Unfortunately, accuracy of Latent fingerprint matching is still difficult implication and challenging until today. To find the similarity between two images is a trivial task. This process becomes more challenging and risky, when among two input images one is poor quality, such as a latent fingerprint. Latent fingerprints are distorted, partial and having background noise. The main motto of this research is to design an intelligent procedure equivalent to human perception in matching the latent to exemplar fingerprint scenario. In this paper, a new Kernel-based structural similarity measure algorithm is designed for match score computation. The proposed approach is more robust to invariance such as scale change and rotation in the input image. The result describe, that the similarity score value is improved by 1.6% on an average as compared to existing similarity calculation approach.","","","10.1109/ICETEESES.2016.7581411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581411","Kernel Method;Latent Fingerprint;Log-polar Transform;Similarity Measure","Algorithm design and analysis;Distortion;Feature extraction;Fingerprint recognition;Kernel;Machine learning algorithms","fingerprint identification;image matching","Kernel approach;Kernel-based structural similarity measure algorithm;fingerprint recognition;human identification;intelligent procedure equivalent;latent fingerprint matching;pattern recognition","","","","","","","11-12 March 2016","","IEEE","IEEE Conference Publications"
"Development of anti-spam technique using modified K-Means & Naive Bayes algorithm","D. K. Tayal; A. Jain; K. Meena","IGDTUW, Delhi, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","2593","2597","In recent years, the issues of expanding spam mail on the web has turned into a major issue and has also become difficult to detect. Junk mails or unsolicited bulk emails are known as spam mails. They may contain malicious content and they are sent to numerous recipients through email. Spam emails also contain the malwares in executable file attachments. At commercial level, many companies hire the spammers to publicize their information regarding the offers, as it is the fastest and cheapest way of advertising. Spammers are the group of the people who apply different techniques to bypass the spam filtering methods. The general classifications of spam filtering techniques are Rule-based classification or Non Machine Learning (NML) which uses set of rules to classify whether the incoming message is spam or not. Content based classification that use machine learning techniques have given quite a promising result. Machine Learning (ML) is concerned with development of algorithms that allow computer to take intelligent decision on the basis of dataset. Some of the commonly used statistical filters are Naïve Bayes, K-Means, Support Vector Machine and TF-IDF. This paper proposes a new approach to detect spam mails using linear approach of Modified K-Means & Naive Bayes classification algorithm and the Modified K-Means algorithm was proposed by Malay K. Pakhira in year 2009 to avoid empty clusters [19] which is used in our approach. This proposed approach offers the advantage w.r.t modified K-means algorithm such as improved classification accuracy, decreasing the number of iteration steps.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724731","Modified K-Means;Naïve Bayes;Preprocessing;Tokenization","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Electronic mail;Machine learning algorithms;Postal services;Support vector machines","Bayes methods;Internet;invasive software;learning (artificial intelligence);pattern classification;support vector machines;unsolicited e-mail","NML;Naive Bayes classification algorithm;TF-IDF;World Wide Web;antispam technique;content based classification;executable file attachments;junk mails;machine learning techniques;malwares;modified K-means algorithm;nonmachine learning;rule-based classification;spam e-mail;spam filtering techniques;statistical filters;support vector machine;unsolicited bulk e-mails","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Cloud detection of remote sensing images by deep learning","M. Shi; F. Xie; Y. Zi; J. Yin","Image Processing Center, School of Astronautics, Beihang University, Beijing 100191, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","701","704","Cloud detection plays a major role for remote sensing image processing. Most of the existed cloud detection methods use the low-level feature of the cloud, which often cause error result especially for thin cloud and complex scene. In this paper, a novel cloud detection method based on deep learning framework is proposed. The designed deep Convolutional Neural Networks (CNNs) consists of four convolutional layers and two fully-connected layers, which can mine the deep features of cloud. The image is firstly clustered into superpixels as sub-region through simple linear iterative cluster (SLIC) method. Through the designed network model, the probability of each superpixel that belongs to cloud region is predicted, so that the cloud probability map of the image is generated. Lastly, the cloud region is obtained according to the gradient of the cloud map. Through the proposed method, both thin cloud and thick cloud can be detected well, and the result is insensitive to complex scene. Experimental results indicate that the proposed method is more robust and effective than compared methods.","","","10.1109/IGARSS.2016.7729176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729176","Cloud Detection;Convolutional Neural Networks;Deep Learning;Superpixel","Clouds;Erbium;Feature extraction;Machine learning;Refining;Remote sensing;Training","clouds;geophysical image processing;iterative methods;learning (artificial intelligence);neural nets;remote sensing","SLIC method;cloud detection method;cloud probability map;cloud region;convolutional neural network;deep learning;remote sensing image processing;simple linear iterative cluster method","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Iterative sparse matrix-vector multiplication on in-memory cluster computing accelerated by GPUs for big data","J. Peng; Z. Xiao; C. Chen; W. Yang","College of Information Science and Engineering, Hunan University, Changsha, Hunan 410082, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1454","1460","Iterative SpMV (ISpMV) is a key operation in many graph-based data mining algorithms and machine learning algorithms. Along with the development of big data, the matrices can be so large, perhaps billion-scale, that the SpMV can not be implemented in a single computer. Therefore, it is a challenging issue to implement and optimize SpMV for large-scale data sets. In this paper, we used an in-memory heterogeneous CPU-GPU cluster computing platforms (IMHCPs) to efficiently solve billion-scale SpMV problem. A dedicated and efficient hierarchy partitioning strategy for sparse matrices and the vector is proposed. The partitioning strategy contains partitioning sparse matrices among workers in the cluster and among GPUs in one worker. More, the performance of the IMHCPs-based SpMV is evaluated from the aspects of computation efficiency and scalability.","","","10.1109/FSKD.2016.7603391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603391","BigData;Flink;GPU;In-memory Computing;Iterative SpMV","Acceleration;Clustering algorithms;Computers;Data mining;Graphics processing units;Machine learning algorithms;Sparse matrices","Big Data;data analysis;graphics processing units;iterative methods;matrix multiplication;microprocessor chips;pattern clustering;sparse matrices;vectors","IMHCP;ISpMV;big data;computation efficiency;computation scalability;graph-based data mining algorithms;hierarchy partitioning strategy;in-memory heterogeneous CPU-GPU cluster computing platforms;iterative sparse matrix-vector multiplication;large-scale data sets;machine learning algorithms","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Response conflict processes' classification in 7 and 9 year old children using EEG brain connectivity measures","T. Almabruk; K. Iyer; S. Girdler; M. M. Khan; T. Tan","Department of Computing, Curtin University, Perth, WA 6102 Australia","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","704","707","Investigating cognitive development of children poses interesting challenges pertaining to emergence of children's' ability to think and understand. Psychological tasks that involve conflict, like the Flanker task, are widely used to understand development of response conflict processes. In this study, EEG signals were used to examine the coherence and imaginary part of coherency within the delta, theta, alpha and beta bands across different conditions of the Flanker task. Longitudinal data were collected from a group of typically developing children at ages of seven and nine. We found that the imaginary part of coherency was more helpful in distinguishing between stimuli - alpha and beta bands resulted in 90.90% classification rate in seven year old children. The beta and theta bands were found to be more effective for stimuli classification in nine year old children - more than 84.09% classification accuracy was achieved.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590799","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590799","","Aging;Australia;Coherence;Electroencephalography;Fish;Frequency measurement;Machine learning algorithms","cognition;electroencephalography;medical signal processing;paediatrics;signal classification","EEG brain connectivity measures;EEG signals;Flanker task;age 7 yr;age 9 yr;alpha bands;beta bands;classification rate;cognitive development;delta bands;psychological tasks;response conflict process classification;stimuli classification;theta bands","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"A theoretical line losses calculation method of distribution system based on boosting algorithm","Y. Wang; C. Wang; J. Wang; L. Zuo; Y. Shi","Global Energy Interconnection Research Institute, Beijing, 102209, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","714","718","Existing intelligent theoretical line losses calculation methods that prevalent on worse line calculation error, are all based on single learning algorithm. In order to overcome this defect, a novel intelligent calculation method based on boosting algorithm is proposed. In this calculation method, the theoretical line losses calculation is abstracted into function fitting problem, in addition, the sample set - which is structured by the lines' information of known theoretical line losses - is input to many single learning algorithms of boosting algorithm for training many sub-calculation model and constituting them as a sequence, which sequence is the final theoretical line losses calculation model. In the sub-calculation model training process, this intelligent method effectively reduces the calculation error by the boosting algorithm's internal mechanism that the large calculation error lines are constantly reinforcement training. Finally the experiment shows that this intelligent calculation method based on boosting algorithm has lower calculation error than traditions.","","","10.1109/FSKD.2016.7603262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603262","Boosting Algorithm;Calculation Error;Data Quality;Distribution System;Function Fitting;Theoretical Line Losses","Algorithm design and analysis;Boosting;Data models;Fitting;Heuristic algorithms;Machine learning algorithms;Training","learning (artificial intelligence);power distribution lines;power engineering computing","boosting algorithm;distribution system;function fitting problem;intelligent theoretical line loss calculation method;single learning algorithm;subcalculation model training process;worse line calculation error reduction","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
