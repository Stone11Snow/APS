"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5597769,5595842,5597407,5591523,5587774,5593127,5591456,5593370,5590775,5591994,5587857,5591520,5593090,5593438,5590600,5593551,5593355,5591018,5585986,5586066,5586521,5586241,5586432,5586501,5586506,5585965,5586120,5584822,5584220,5584417,5584772,5584470,5584520,5583331,5584328,5583269,5583242,5584447,5583692,5583909,5584718,5584336,5584499,5584092,5581312,5573208,5578841,5574058,5572372,5572936,5577884,5578282,5573833,5572466,5578464,5575656,5571698,5577866,5571212,5576156,5573217,5575696,5345824,5473115,5569116,5569794,5569351,5569867,5569437,5569542,5569831,5569338,5569293,5569330,5569265,5569659,5566126,5569740,5569712,5569827,5564220,5569357,5566082,5569339,5569324,5569830,5569791,5569327,5565953,5566057,5563594,5562761,5565772,5562793,5562762,5562782,5560151,5559828,5560167,5561323",2017/05/05 22:54:16
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Q-convergence Theory of Nets of Fuzzy Sets in Fuzzy Topological Spaces","H. Teng; B. Chen","Sch. of Sci., Univ. of Jinan, Jinan, China","2010 International Conference of Information Science and Management Engineering","20100916","2010","2","","265","268","The convergence theory is a basic theory of fuzzy topology and fuzzy analysis. In this paper we introduce the notions of fuzzy Q-upper limit, fuzzy Q-lower limit and the fuzzy Q-convergent nets of fuzzy sets. We also study the properties of fuzzy Q-upper limit, fuzzy Q-lower limit and the fuzzy Q-convergent nets of fuzzy sets.","","Electronic:978-1-4244-7670-1; POD:978-1-4244-7669-5","10.1109/ISME.2010.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5573833","fuzzy Q-convergent nets of fuzzy sets;fuzzy Q-lower limit;fuzzy Q-upper limit","Convergence;Cybernetics;Extraterrestrial measurements;Fuzzy sets;Lattices;Machine learning;Topology","convergence;fuzzy set theory;topology","fuzzy Q-convergent nets;fuzzy Q-lower limit;fuzzy Q-upper limit;fuzzy analysis;fuzzy set;fuzzy topological spaces","","0","","16","","","7-8 Aug. 2010","","IEEE","IEEE Conference Publications"
"Newton's Method for L<inf>∞</inf> Support Vector Machine Via Smoothing technique","R. Wang; H. Xu; H. Shi","Department of Mathematics and Physics, Beijing Institute of Petrochemical Technology, China 102617","2010 Sixth International Conference on Natural Computation","20100923","2010","1","","436","440","The standard 2-norm support vector machine (SVM for short) is known for its good performance in classification and regression problems. In this paper, the L<sub>∞</sub> norm support vector machine is considered and a novel smoothing function method is proposed in an attempt to overcome some drawbacks of the former methods which are complex, subtle, and sometimes difficult to implement. Based on Karush-Kuhn-Tucker complementarity condition in optimization theory, unconstrained non-differentiable optimization model is built, and an approximate algorithm is presented. we take advantage of approximate smooth function and a Newton-Armijo algorithm is given to solve the corresponding optimization using difference convex algorithm. The paper trains the data sets with standard unconstraint optimization method. This algorithm is fast and insensitive to the initial point. Theory analysis and numerical results illustrate that the smoothing function method for the L<sub>∞</sub> norm SVM is feasible and effective.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583331","","Approximation algorithms;Approximation methods;Machine learning;Optimization;Smoothing methods;Support vector machines;Vectors","Newton method;nonlinear programming;regression analysis;smoothing methods;support vector machines","2-norm support vector machine;Karush Kuhn Tucker complementarity condition;L<sub>∞</sub> support vector machine;Newton Armijo algorithm;Newton method;difference convex algorithm;regression problems;smoothing technique;unconstrained nondifferentiable optimization model","","0","","25","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Semi-supervised incremental learning","A. Bouchachia; M. Prossegger; H. Duman","Dept. of Informatics, University of Klagenfurt, Austria","International Conference on Fuzzy Systems","20100923","2010","","","1","6","The paper introduces a hybrid evolving architecture for dealing with incremental learning. It consists of two components: resource allocating neural network (RAN) and growing Gaussian mixture model (GGMM). The architecture is motivated by incrementality on one hand and on the other hand by the possibility to handle unlabeled data along with the labeled one, given that the architecture is dedicated to classification problems. The empirical evaluation shows the efficiency of the proposed hybrid learning architecture.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584328","","Accuracy;Computational modeling;Computer architecture;Covariance matrix;Data models;Machine learning;Radio access networks","Gaussian processes;data handling;learning (artificial intelligence);neural nets;pattern classification;resource allocation","growing Gaussian mixture model;hybrid learning architecture;resource allocating neural network;semisupervised incremental learning;unlabeled data handling","","2","","21","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Characterizing player's experience from physiological signals using fuzzy decision trees","F. Levillain; J. O. Orero; M. Rifqi; B. Bouchon-Meunier","Laboratoire Cognitions Humaine et Artificielle (CHART), Universit&#x00E9; Paris 8, France","Proceedings of the 2010 IEEE Conference on Computational Intelligence and Games","20100930","2010","","","75","82","In the recent years video games have enjoyed a dramatic increase in popularity, the growing market being echoed by a genuine interest in the academic field. With this flourishing technological and theoretical efforts, there is need to develop new evaluative methodologies for acknowledging the various aspects of the player's subjective experience, and especially the emotional aspect. In this study, we addressed the possibility of developing a model for assessing the player's enjoyment (amusement) with respect to challenge in an action game. Our aim was to explore the viability of a generic model for assessing emotional experience during gameplay from physiological signals. In particular, we propose an approach to characterize the player's subjective experience in different psychological levels of enjoyment from physiological signals using fuzzy decision trees.","2325-4270;23254270","Electronic:978-1-4244-6297-1; POD:978-1-4244-6295-7; USB:978-1-4244-6296-4","10.1109/ITW.2010.5593370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593370","","Biomedical monitoring;Computational intelligence;Decision trees;Feature extraction;Games;Heart rate;Machine learning","behavioural sciences computing;computer games;decision trees;fuzzy set theory;physiology","fuzzy decision tree;generic model;physiological signal;player enjoyment;player experience;video game","","4","","42","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"Learning Influence Propagation of Personal Blogs with Content and Network Analyses","I. C. Moon; D. Kim; Y. Jo; A. H. Oh","Dept. of Electr. Eng., KAIST, Daejeon, South Korea","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","669","674","Weblogs (blogs) serve as a gateway to a large blog reader population, so blog authors can potentially influence a large reader population by expressing their thoughts and expertise in their blog posts. An important and complex problem, then, is figuring out why and how influence propagates through the blogosphere. While a number of previous research has looked at the network characteristics of blogs to analyze influence propagation through the blogspace, we hypothesize that a blog's influence depends on its contents as well as its network positions. Thus, in this paper, we explore two different influence propagation metrics showing different influence characteristics: Digg score and comment counts. Then, we present the results of our experiments to predict the level of influence propagation of a blog by applying machine learning algorithms to its contents and network positions. We observed over 70,000 blog posts, pruned from over 20,000,000 posts, and we found that the prediction accuracy using the content and the network features simultaneously shows the best F-score in various measures. We expect that this research result will contribute to understanding the problem of influence propagation through the blogosphere, and to developing applications for recommending influential blogs to social web users.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591523","","Blogs;Information services;Internet;Machine learning;Measurement;Predictive models;Web sites","Web sites;learning (artificial intelligence);social aspects of automation","blogosphere;influence propagation;large reader population;machine learning algorithms;personal blogs","","0","","14","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research of P2P traffic identification based on naive Bayes and decision tables combination algorithm","H. Xu; S. Wang; R. Wang; D. Zhao","Institute of Information Network Technology, Nanjing 210003, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","6","","2875","2879","A novel P2P traffic identification method based on the combination of naive Bayes and decision tables is proposed, which uses Fast Correlation-Based Filter (FCBF) algorithm to extract P2P flow characteristics, and utilises six DTNB (combination of naive Bayes and decision tables) combined with dynamic weighted integration method to set up a P2P flow detection model. Through experimental comparison between this proposed model and traditional methods, such as single DTNB, decision tree and naive Bayes, we find that the proposed method has a better P2P traffic identification accuracy and stability.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569265","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569265","P2P;decision tree;naive Bayes;traffic identification","Accuracy;Classification algorithms;IP networks;Internet;Machine learning;Niobium;Software","Bayes methods;decision tables;filtering theory;peer-to-peer computing;telecommunication traffic;trees (mathematics)","FCBF algorithm;P2P flow detection model;P2P traffic identification;decision tables combination algorithm;decision tree;fast correlation-based filter;naive Bayes","","4","","29","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"An improved ordinal regression approach with Sum-of-Margin principle","B. Y. Sun; X. M. Zhang; W. B. Li","The Institute of Intelligent Machines, Chinese Academy of Sciences, Hefei, Anhui Province, China, 230031","2010 Sixth International Conference on Natural Computation","20100923","2010","2","","853","857","In this paper, we propose a new support vector approach for ordinal regression, which maximizes the sum of the margins of parallel discriminant hyperplanes. For ordinal regression, there are two strategies to take on the large margin principle: the fixed margin principle and the sum-of-margin principle. While the fixed margin strategy requires that the margins between two neighboring classes are equal and fails to define the thresholds of different ranks uniquely and directly, the Sum-of-Margin strategy is to maximize the sum of margins and the threshold defining each rank is unique and can be obtained directly. However, the performance of the traditional support vector ordinal regression method based on the Sum-of-Margin Principle is unsatisfactory because of unreasonable definition of empirical errors of training data. To solve this problem, we use different constraints and a new support vector ordinal regression algorithm is developed. The experiment results verify the effectiveness and efficiency of the proposed approach.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583269","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583269","Fixed Margin;Ordinal Regression;Sum-of-Margin;Support Vector","Benchmark testing;Error analysis;Machine learning algorithms;Optimization;Presses;Support vector machines;Training","mathematics computing;regression analysis;support vector machines","fixed margin principle strategy;parallel discriminant hyperplane margin;sum-of-margin principle strategy;support vector approach;support vector ordinal regression method","","1","","10","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Fuzzy-rough k-nearest neighbor algorithm for imbalanced data sets learning","H. Han; B. Mao","School of Information Science and Technology, Beijing Forestry University, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","3","","1286","1290","Learning from imbalanced data sets presents a new challenge to machine learning community, as traditional methods are biased to majority classes and produce poor detection rate of minority classes. This paper presents a new approach, namely fuzzy-rough k-nearest neighbor algorithm for imbalanced data sets learning to improve the classification performance of minority class. The approach defines fuzzy membership function that is in favor of minority class and constructs fuzzy equivalent relation between the unlabeled instance and its k nearest neighbors. The approach takes the fuzziness and roughness of the nearest neighbors of an instance into consideration, and can reduce the disturbance of majority class to minority class. Experiments show that our new approach improves not only the classification performance of minority class more effectively, but also the classification performance of the whole data set comparing with other methods.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569116","fuzzy set theory;fuzzy-rough set theory;imbalanced data set;rough set theory","Approximation methods;Classification algorithms;Fuzzy set theory;Machine learning;Nearest neighbor searches;Rough sets","fuzzy set theory;learning (artificial intelligence);pattern classification;rough set theory","fuzzy equivalent relation;fuzzy membership function;fuzzy rough k-nearest neighbor algorithm;imbalanced data sets learning;machine learning","","1","","14","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Novel Method for Training Large Scale E-Business SVM Models in a Grid Computing Environment","Q. Hua; X. Yan-zi","Sch. of Comput. & Electron. Inf., Guangxi Univ., Nanning, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","3540","3543","The Support Vector Machines (SVM) become popular E-Business data mining tools recently, and the datasets of E-Business are usually large-scale. If Support Vector Machines are trained on large-scale datasets, the training time will be very long and the classifier's accuracy will become lower too. As training a large-scale SVM is equated to solve a large-scale quadratic programming (QP) problem, so Path Following Interior Point Method (IPM) that can efficiently solve large scale QP problem in polynomial time is proposed to construct a new SVM learning algorithm on large-scale datasets. To improve the SVM learning efficiency, the dimensions of IPM direction equations are degraded first, then LDLT parallel decomposition method is used to solve the direction sub-equations efficiently, and the parallel algorithm is implemented in the ProActive grid-computing environment. The experiment results show that the new parallel SVM training algorithm is efficient and the SVM classifying accuracy is higher than libsvm.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591456","Grid Computing;Large scale SVM;Matrix LDLT Parallel Decomposition;Path Following Method;ProActiv","Artificial neural networks;Classification algorithms;Grid computing;Machine learning;Optimization;Support vector machines;Training","business data processing;computational complexity;data mining;grid computing;learning (artificial intelligence);parallel algorithms;quadratic programming;support vector machines","IPM direction equations;LDL<sup>T</sup> parallel decomposition;ProActive grid computing environment;SVM learning efficiency;e-business data mining tool;large scale QP problem;large scale quadratic programming;parallel algorithm;path following interior point method;polynomial time;support vector machine;training large scale e-business SVM model","","1","","15","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Learning Math and Statistics on the Cloud, Towards an EC2-Based Google Docs-like Portal for Teaching / Learning Collaboratively with R and Scilab","K. Chine","Cloud Era Ltd., Cambridge, UK","2010 10th IEEE International Conference on Advanced Learning Technologies","20100916","2010","","","752","753","The Elastic-R portal allows educators and students to easily allocate, use and manage cloud resources and to work on the cloud, from standard web browsers, with the most commonly used statistical and mathematical environments such as R and Scilab. Elastic-R enables collaboration and resources sharing as well as interactive local or remote teaching sessions. Elastic-R is also a platform and provides frameworks and tools that make it easy for educators to create their own cloud-based e-Learning tools.","2161-3761;21613761","Electronic:978-1-4244-7145-4; POD:978-1-4244-7144-7","10.1109/ICALT.2010.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572466","Cloud computing;R;Scilab;Virtual Learning Envronments;Virtual Research Environments;remote teaching","Clouds;Collaboration;Electronic learning;Machine learning;Portals;Virtual machining","Internet;computer aided instruction;online front-ends;portals;statistics","Scilab;cloud based e-learning tool;cloud resource;elastic-R portal;interactive local teaching session;interactive remote teaching session;math learning;resources sharing;statistics learning;web browser","","3","","6","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"Semi-pre-convergence theory of nets of fuzzy sets in fuzzy topological spaces","B. Chen; J. Li","School of Science, University of Jinan, 250022, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","1","","314","318","The convergence theory is a basic theory of fuzzy topology and fuzzy analysis. In this paper we introduce the notions of fuzzy SP-upper limit, fuzzy SP-lower limit and the fuzzy SP-convergent nets of fuzzy sets. We also study the properties of fuzzy SP-upper limit, fuzzy SP-lower limit and the fuzzy SP-convergent nets of fuzzy sets.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569659","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569659","","Convergence;Cybernetics;Fuzzy sets;Lattices;Machine learning;Topology","convergence;fuzzy set theory;topology","convergence theory;fuzzy SP lower limit;fuzzy SP upper limit;fuzzy sets;fuzzy topological spaces;semi preconvergence theory","","0","","16","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Textual Entailment Search Task: An Initial Approach Based on Coreference Resolution","J. J. Castillo","FaMAF, Nat. Univ. of Cordoba, Cordoba, Argentina","2010 International Conference on Intelligent Computing and Cognitive Informatics","20100907","2010","","","388","391","In this work we present our initial approach to the Recognizing Textual Entailment Search Pilot Task proposed by NIST. We proposed a new algorithm to address Text Entailment task to a document level making use of coreference resolution and then reducing this problem to a traditional main task problem. We also applied machine learning algorithms and a combination of datasets for the textual entailment task. The features chosen quantity lexical, syntactic and semantic level matching between text and hypothesis sentences. Despite our system being very preliminary, it is placed third among other existing systems.","","Electronic:978-1-4244-6641-2; POD:978-1-4244-6640-5","10.1109/ICICCI.2010.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5565953","","Humans;Machine learning;Machine learning algorithms;Semantics;Support vector machines;Training;USA Councils","learning (artificial intelligence);text analysis","NIST;coreference resolution;document level;hypothesis sentences;machine learning algorithms;textual entailment search task","","0","","12","","","22-23 June 2010","","IEEE","IEEE Conference Publications"
"Discussion on Informationized Teaching Mode of Design of Mechanisms and Machines Courses","H. X. Yang; F. M. Chen","Dept. of Mech. &Electr. Eng., Wuhan Textile Univ., Wuhan, China","2010 International Conference on Management and Service Science","20100916","2010","","","1","4","This essay introduces the basic connotation of the integration of information technology and courses and summarizes the common ways and strategies of the integration on the basis of analysis of the characteristics of Design of Mechanisms and Machines courses. It also elaborates on the specific implement of technology in representative teaching content and procedures of Design of Mechanisms and Machines courses including introductory class, courses experiment and knowledge unit teaching and works out an efficient informationized teaching mode of Design of Mechanisms and Machines courses.","","Electronic:978-1-4244-5326-9; POD:978-1-4244-5325-2","10.1109/ICMSS.2010.5578464","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578464","","History;Information technology;Internet;Machine learning;Machinery;Training","computer aided instruction;design;machining;mechanical engineering computing","informationized teaching mode;machines courses;mechanisms design;representative teaching content","","0","","6","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Dominating ranking algorithm for information retrieval","H. Liu; Z. Li; J. Xin; C. Chen","Key Laboratory of Medical Image Computing (Northeastern University), Ministry of Education Authors Name/s per 2nd, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2456","2460","There are lots of ranking algorithms used in Web information retrieval. However, current algorithms have some problems: these algorithms are based on different calculation formulas to calculate the documents and query similarity or train a lot of training data to get corresponding calculation formula which calculate documents and query similarity. We know that this process is a very complex, and sometimes the accuracy is not good. So we propose a new algorithm - dominating ranking algorithm for information retrieval, which rank documents according to the number of dominated documents and the dominated documents' dominating capacity. Experimental results show that the algorithm proposed in this paper could achieve the best performance on the TREC Web Track data set.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569293","dominance capacity;dominance weight;ranking","Algorithm design and analysis;Classification algorithms;Indexes;Machine learning;Machine learning algorithms;Web pages","Internet;information retrieval","TREC Web Track data set;document ranking;dominating ranking algorithm;information retrieval;query similarity","","0","","18","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Improve the Performance of Random Forests by Introducing Weight Update Technique","B. Sun; J. Luo; S. Shu; E. Xue","Coll. of Sci., Donghua Univ., Shanghai, China","2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics","20100930","2010","1","","34","37","We investigate approaches to improve the performance of random forests by introducing weight update and bootstrap techniques and propose a new algorithm that combine these techniques smoothly. Experiments show that the proposed approach performs better than the original RF and works well with different weight update techniques used by three most popular version of AdaBoost. At the same time there is no more parameters to adjust compared with RF.","","Electronic:978-0-7695-4151-8; POD:978-1-4244-7869-9","10.1109/IHMSC.2010.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590775","AdaBoost;CART;bagging;bootstrap;random forests","Bagging;Classification algorithms;Classification tree analysis;Correlation;Machine learning;Radio frequency;Training","computer bootstrapping;learning (artificial intelligence)","AdaBoost;bootstrap techniques;random forests;weight update technique","","0","","9","","","26-28 Aug. 2010","","IEEE","IEEE Conference Publications"
"Mining Acute Inflammations of urinary system using GAJA2: A new data mining algorithm","S. Kooptiwoot","Computer Science Program, Faculty of Science and Technology, Suan Sunandha Rajabhat University, 1 Uthong Nok, Dusit, Bangkok 10300, THAILAND","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","3","","278","281","Medical data mining is so challenging. In this paper, we propose a new data mining algorithm called GAJA2, which is a derivation of GAJA [1]. We apply GAJA2 to mine Acute Inflammations data set, a medical data set got from UCI machine learning repository 2009[2]. This data set is about symptoms and diagnosis of two diseases of urinary system which are inflammation of urinary bladder and Nephritis of renal pelvis origin. The results show that knowledge mined by using GAJA2 is very interesting. We compare the results from GAJA2 with GAJA and Rough Set Theory. We found that the results from GAJA2 can be used by the experts in the fields and are very much easier to understand than from GAJA and Rough Set Theory.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563594","Acute Inflammations of Urinary System;GAJA2;Medical Data Mining;Nephritis of renal pelvis origin;inflammation of urinary bladder","Artificial neural networks;Classification algorithms;Machine learning;Presses","data mining;medical computing;rough set theory","Nephritis;UCI machine learning repository;acute inflammation;medical data mining algorithm;medical data set;renal pelvis origin;rough set theory;urinary bladder;urinary system","","1","","18","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A Multiclass SVM Method via Probabilistic Error-Correcting Output Codes","Z. Wang; W. Xu; J. Hu; J. Guo","Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","4","Error-correcting output code (ECOC) is an effective approach to solve the problem of multiclass SVM. In this paper, a probabilistic approach that is based on ECOC is proposed. In the training stage, a coding scheme is predefined, and a special model is trained by samples. In the classification stage, besides the labels from SVM as usual, posterior probabilities of labels are also calculated. They are used to compute probability estimates of categories. Rank the normalized scores of probabilities and choose the maximum as the object category. Evaluations on different text categorization collections show our approach can significantly improve the performance.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566126","","Encoding;Machine learning;Probabilistic logic;Reliability;Support vector machines;Text categorization;Training","error correction codes;probability;support vector machines;text analysis","multiclass SVM method;posterior probability;probabilistic error-correcting output codes;support vector machine","","2","","12","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Dynamic Bayesian approach to forecasting","A. Tang","School of Computer Technology, Sunway University College, Petaling Jaya, Malaysia","2010 Sixth International Conference on Natural Computation","20100923","2010","8","","3933","3937","Bayesian belief propagation is flexible and highly adaptable in machine learning and artificial intelligence methodologies. Coupled with a time element, the Dynamic Bayesian approach has shown promise in forecasting applications. A methodology consisting of beliefs propagated through the TAN-Pearl network and computed for every time slice is proposed to this end. Benchmark comparisons indicate encouraging results.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5584772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584772","dynamic bayesian;forecasting;time-slice;tree augmented","Additives;Artificial neural networks;Bayesian methods;Forecasting;Machine learning;Training","belief networks;learning (artificial intelligence);trees (mathematics)","Bayesian belief propagation;TAN-Pearl network;artificial intelligence methodologies;machine learning;time slice","","1","","22","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"An adaptive k-nearest neighbor algorithm","S. Sun; R. Huang","Department of Computer Science and Technology, East China Normal University, 500 Dongchuan Road, Shanghai 200241, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","1","","91","94","An adaptive k-nearest neighbor algorithm (AdaNN) is brought forward in this paper to overcome the limitation of the traditional k-nearest neighbor algorithm (kNN) which usually identifies the same number of nearest neighbors for each test example. It is known that the value of k has crucial influence on the performance of the kNN algorithm, and our improved kNN algorithm focuses on finding out the suitable k for each test example. The proposed algorithm finds out the optimal k, the number of the fewest nearest neighbors that every training example can use to get its correct class label. For classifying each test example using the kNN algorithm, we set k to be the same as the optimal k of its nearest neighbor in the training set. The performance of the proposed algorithm is tested on several data sets. Experimental results indicate that our algorithm performs better than the traditional kNN algorithm.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569740","adaptive k-nearest neighbor algorithm (AdaNN);k-nearest neighbor algorithm (kNN);nearest neighbors;pattern classification","Accuracy;Classification algorithms;Error analysis;Iris;Machine learning algorithms;Nearest neighbor searches;Training","learning (artificial intelligence);pattern classification;set theory","AdaNN;adaptive k-nearest neighbor algorithm;kNN algorithm;training set","","8","","16","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Direct Optimization of Evaluation Measures in Learning to Rank Using Particle Swarm","O. Alejo; J. M. Fernandez-Luna; J. F. Huete; R. Perez-Vazquez","Informatic Fac., Univ. of Cienfuegos Cienfuegos, Cienfuegos, Cuba","2010 Workshops on Database and Expert Systems Applications","20100930","2010","","","42","46","One of the central issues in Learning to Rank (L2R) for Information Retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures used in IR such as Precision at n, Mean Average Precision and Normalized Discounted Cumulative Gain. In this work we propose a new learning-to-rank method, referred as RankPSO. This algorithm is based on Particle Swarm Optimization. It builds a ranking model able to directly optimize evaluation measures used in Information Retrieval. To evaluate performance of RankPSO, we have compared it with other methods referenced in literature. We have carried out an experimental study using Letor OHSUMED dataset. The obtained results were analyzed statistically, demonstrating that RankPSO has significant improvement in precision compared to RankSVM, RankBoost and Regression methods; nevertheless, it does not have significant differences with AdaRank-MAP, AdaRank-NDCG, ListNet and FRank. The results show the advantages to use Particle Swarm Optimization as bio-inspired algorithm for learning to rank.","1529-4188;15294188","Electronic:978-0-7695-4174-7; POD:978-1-4244-8049-4","10.1109/DEXA.2010.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591994","Information Retrieval;Learning to Rank;Particle Swarm Optimization","Atmospheric measurements;Loss measurement;Machine learning;Optimization;Particle measurements;Particle swarm optimization;Position measurement","information retrieval;learning (artificial intelligence);particle swarm optimisation;regression analysis;support vector machines","Letor OHSUMED dataset;RankBoost;RankPSO;RankSVM;bio-inspired algorithm;evaluation measures;information retrieval;learning-to-rank method;mean average precision;normalized discounted cumulative gain;particle swarm optimization;regression methods","","1","","17","","","Aug. 30 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Chinese text categorization study based on CBM learning","Y. Zhan; H. Chen","Key Lab. of Machine Learning and Computational Intelligence, College of Mathematics and Computer Science, Hebei University, Baoding, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1511","1514","Text Categorization (TC) is an important component in many information organization and information management tasks. In many TC applications, the case-base grows at a fast rate and this causes inefficiency in the case retrieval process. Using Case-Base Maintenance learning via the GC (Generalization Capability) algorithm, which can reduce the case number into KNN algorithm, can improve efficiency when indexing near neighbor in K-Nearest Neighbor algorithm. The numerical experiments prove the validity of this learning algorithm. Since K-NN algorithm is used extensively to a variety of areas, we can improve classification performance further in TC.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569330","CBM;K-NN;Text Categorization","Accuracy;Algorithm design and analysis;Classification algorithms;Databases;Machine learning;Text categorization;Training data","case-based reasoning;information retrieval;learning (artificial intelligence);pattern clustering;statistical analysis;text analysis","CBM learning;Chinese text categorization;K-NN algorithm;case base maintenance learning;generalization capability algorithm;information management;information retrieval process;k-nearest neighbor","","0","","9","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Taxonomy and Comparative Evaluation of Algorithms for Parallel Anomaly Detection","S. Shanbhag; Y. Gu; T. Wolf","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Amherst, MA, USA","2010 Proceedings of 19th International Conference on Computer Communications and Networks","20100902","2010","","","1","8","Anomaly detection in network traffic is an important technique for identifying operation and security problems in networks. Numerous anomaly detection algorithms have been proposed and deployed in practice. The recent availability of high-performance embedded processors in network systems has made it possible to implement these algorithms to monitor traffic in real-time. Since it is unlikely that any single anomaly detection technique will ever be sufficient, we propose the use of multiple existing anomaly detection algorithms in parallel. In this paper, we develop a method of combining different classes of anomaly detection algorithms and address the question of which combination of existing anomaly detection algorithms achieves the best detection accuracy. We also present a taxonomy of anomaly detection algorithms and evaluate six specific algorithms on a common evaluation platform. Based on this evaluation, we identify the combination of anomaly detection algorithms that achieve the highest detection accuracy and derive a few rules that can be used when deciding on combining and aggregating multiple algorithms.","1095-2055;10952055","Electronic:978-1-4244-7116-4; POD:978-1-4244-7114-0","10.1109/ICCCN.2010.5560167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560167","","Accuracy;Algorithm design and analysis;Classification algorithms;Clustering algorithms;Detection algorithms;Machine learning algorithms;Measurement","microprocessor chips;signal detection;telecommunication networks;telecommunication security;telecommunication traffic","detection accuracy;high-performance embedded processors;multiple algorithms;network traffic;parallel anomaly detection;real-time traffic monitoring;security problems;taxonomy","","1","","24","","","2-5 Aug. 2010","","IEEE","IEEE Conference Publications"
"High Performance Flow Feature Extraction with Multi-core Processors","S. Li; Y. Luo","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Lowell, MA, USA","2010 IEEE Fifth International Conference on Networking, Architecture, and Storage","20100916","2010","","","193","201","Next generation networks anticipate an increasing amount of network traffic from a wide range of emerging network applications. The features of packet flows (such as the minimal packet inter-arrival time and the number of packets with non-zero options in TCP headers) are used frequently in determining the traffic type and applying security policies. However, the extraction of flow features is difficult due to the increasing line rates, a broad range of network protocols, and a variety of complex flow features. In this paper, we leverage the multi-core processors to speed up the feature extraction process. We design an open source parallel software tool, aiming for processing network packet flows in real-time. We implement the software in four different designs including serial, parallel, pipelined and hybrid architectures. We evaluate the performance of the parallel software tool through measurement experiments. Our experimental results show that each method increases the packet processing throughput by 5-7% in comparison with the previous method. And finally the implementation based on the hybrid architecture improves the packet processing performance by 19.3% than the implementation based on the serial architecture.","","Electronic:978-0-7695-4134-1; POD:978-1-4244-8133-0","10.1109/NAS.2010.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575656","Flow feature extraction;multi-core processors;parallelism","Feature extraction;Instruction sets;Machine learning algorithms;Multicore processing;Payloads;Throughput","computer network security;feature extraction;multiprocessing systems;parallel architectures;parallel processing;parallel programming;performance evaluation;software tools;telecommunication traffic","high performance flow feature extraction;hybrid architecture;multicore processors;network applications;network protocols;network traffic;open source parallel software tool;packet flows;packet processing;performance evaluation;security policies;serial architecture","","6","","27","","","15-17 July 2010","","IEEE","IEEE Conference Publications"
"K-means clustering with manifold","L. Wei; W. Zeng; H. Wang","Department of Computer Science, Shanghai Maritime University, China 200135","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2095","2099","K-means clustering is a popular conventional clustering algorithm. As it does not use the structure information of data sets, sometime the clustering result will be dissatisfied. Manifold learning algorithms can reveal the low-dimensional geometry structure of the data sets. In this paper, we combine K-means clustering algorithm with manifold learning algorithms into a coherent framework. We show the proposed algorithms KCM(K-means clustering with manifold) approaches can obtain good clustering results on UCI data sets. We also illustrate that the KCM clustering algorithms can be naturally extended to semi-supervised clustering. Experimental results also show the effectiveness of the semi-supervised clustering approaches.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569712","","Accuracy;Algorithm design and analysis;Clustering algorithms;Data mining;Laplace equations;Machine learning;Manifolds","learning (artificial intelligence);pattern clustering","K-means clustering;low-dimensional geometry structure;manifold learning algorithms;semi-supervised clustering","","3","","23","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Improved Fuzzy based Kernel PCA","X. Shen; X. Luo; P. Du","School of Electrical Engineering, Zhejiang University, Hangzhou 310027, China","Proceedings of the 29th Chinese Control Conference","20100920","2010","","","2941","2944","In the non-linear principal component analysis processing, the kernel-based nonlinear dimensionality reduction technique KPCA is great sensitive to large deviation samples, while RKF-PCA is non-convergence due to improper parameter selection. A Improved Fuzzy Kernel Principal Component Analysis (IFKPCA) algorithm, which managed through weighting the sample points by a membership function included fuzzy parameters C, is introduced based on fuzzy theory. Various distribution functions, including large deviation samples or not, are tested using conventional KPCA, RKF-PCA and IFKPCA separately. The results show that, IFKPCA weakened the impact of the large deviation samples, and avoided the non-convergence problem, cased by improper parameter selection. Besides, IFKPCA is robust, and the selection of the weight coefficient parameters of IFKPCA is also convenient. So IFKPCA is a good solution to the samples sensitive problem of KPCA.","1934-1768;19341768","Electronic:978-7-8946-3104-6; POD:978-1-4244-6263-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5574058","IFKPCA;Kernel;Nonlinear Dimensionality;Sensitivity","Conferences;Educational institutions;Kernel;Machine learning algorithms;Principal component analysis;Robustness;Signal processing algorithms","fuzzy set theory;principal component analysis","IFKPCA analysis;KPCA analysis;RKF-PCA analysis;fuzzy parameters;fuzzy theory;improved fuzzy kernel principal component analysis;membership function;nonlinear dimensionality reduction technique;nonlinear principal component analysis","","0","","7","","","29-31 July 2010","","IEEE","IEEE Conference Publications"
"A feature selection method for document clustering based on part-of-speech and word co-occurrence","Z. Liu; W. Yu; Y. Deng; Y. Wang; Z. Bian","International School of Software, Wuhan University, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2331","2334","Feature selection is a process which chooses a subset from the original feature set according to some rules. The selected feature retains original physical meaning and provides a better understanding for the data and learning process. However, few modern feature selection approaches take the advantage of features' context information. Based on this analysis, we propose a novel feature selection method based on part-of-speech and word co-occurrence. According the components of Chinese document text, we utilize the words' part-of-speech attributes to filter lots of meaningless terms. Then we define and use co-occurrence words by their part-of-speech to select features. In the evaluating process, we use the text corpus from Sogou Lab to do some experiments and use Entropy and Precision as criteria to give an objective evaluation of document clustering performance. The results show that our method can select better features and get a more pleasant clustering performance.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569827","document clustering;feature selection;part-ofspeech;word co-occurrence","Context;Educational institutions;Entropy;Feature extraction;Machine learning;Software;Speech","feature extraction;pattern clustering;speech synthesis;text analysis;unsupervised learning;word processing","Chinese document;Sogou lab;context information;document clustering;feature selection method;learning process;part of speech;text corpus;word co-occurrence","","3","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Negation disambiguation using the maximum entropy model","C. Zhang; X. Fei; J. Zhu","Natural Language Lab, Northeastern University, Shenyang, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","5","Handling negation issue is of great significance for sentiment analysis. Most previous studies adopted a simple heuristic rule for sentiment negation disambiguation within a fixed context window. In this paper we present a supervised method to disambiguate which sentiment word is attached to the negator such as “(not)” in an opinionated sentence. Experimental results show that our method can achieve better performance than traditional methods.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587857","Negator;relation pair;sentiment negation disambiguation","Classification algorithms;Entropy;Gold;Machine learning;Manuals;Natural languages;Pragmatics","learning (artificial intelligence);maximum entropy methods;natural language processing","fixed context window;maximum entropy model;sentiment analysis;sentiment negation disambiguation;supervised learning method","","0","","11","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automated discovery of vital knowledge from Pareto-optimal solutions: First results from engineering design","S. Bandaru; K. Deb","Research scholar, Department of Mechanical Engineering, Indian Institute of Technology, Kanpur","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","Real world multi-objective optimization problems are often solved with the only intention of selecting a single trade-off solution by taking up a decision-making task. The computational effort and time spent on obtaining the entire Pareto front is thus not justifiable. The Pareto solutions as a whole contain within them a lot more information than that is used. Extracting this knowledge would not only give designers a better understanding of the system, but also bring worth to the resources spent. The obtained knowledge acts as governing principles which can help solve other similar systems easily. We propose a genetic algorithm based unsupervised approach for learning these principles from the Pareto-optimal dataset of the base problem. The methodology is capable of discovering analytical relationships of a certain type between different problem entities.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586501","","Clustering algorithms;Data mining;Equations;Machine learning;Optimization;Stress;Unsupervised learning","Pareto optimisation;data mining;genetic algorithms;unsupervised learning","Pareto front;Pareto-optimal solutions;genetic algorithm;knowledge discovery;multiobjective optimization problems;unsupervised learning approach","","7","","25","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"The Q(λ) algorithm based on heuristic reward function","J. Zhang; Y. Shi; X. Xie","School of Information & Engineering, Huzhou Teachers College, 313000, Zhejiang, China","2010 International Conference on Intelligent Control and Information Processing","20100909","2010","","","139","142","For reinforcement learning often show slow convergence speed problem in continuous and complex tasks, this paper proposes a Q(λ) algorithm based on heuristic reward function-Q(λ)-HRF algorithm. This algorithm can extract features from the environment and get the heuristic information, which can be applied to the study by Agent in the form of reward function, which can accelerate the convergence speed significantly. We also proved the convergence of the algorithm by mathematical way, and applied the algorithm to the Maze platform, the experimental results show that: the Q(λ)-HRF algorithm has better convergence speed than Q(λ) algorithm.","","Electronic:978-1-4244-7050-1; POD:978-1-4244-7047-1","10.1109/ICICIP.2010.5564220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564220","","Algorithm design and analysis;Convergence;Feature extraction;Heuristic algorithms;Learning;Machine learning algorithms;Markov processes","learning (artificial intelligence)","HRF algorithm;Maze platform;Q(λ) algorithm;complex task;continuous task;convergence speed problem;feature extraction;heuristic reward function;reinforcement learning","","0","","9","","","13-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"A hybrid constrained semi-supervised clustering algorithm","X. Li; L. Wang; Y. Song; X. Zhao","Department of Computer Science & Technology, Yantai University, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1597","1601","A hybrid constrained semi-supervised clustering algorithm(HCC) is proposed, both labeled data and pairwise constraints are concerned in clustering a given dataset to get a better clustering result. This paper gives theoretical derivation and experiments on UCI data sets, and the experiments show that the quality of clustering using two kinds of constraint information is better than only one kind of labeled data information. Additionally, HCC is more stable than other algorithms such as CCL and SAP.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569357","Semi-supervised clustering;hybrid constrained;labeled data;pairwise constraints","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Cost function;Heart;Iris;Machine learning","constraint handling;pattern clustering","CCL;SAP;UCI data sets;hybrid constrained semi supervised clustering algorithm;pairwise constraints","","1","","8","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Robustness of neural ensembles against targeted and random Adversarial Learning","S. L. Wang; K. Shafi; C. Lokan; H. A. Abbass","School of SEIT, UNSW@ADFA, University of New South Wales, Australia","International Conference on Fuzzy Systems","20100923","2010","","","1","8","Machine learning has become a prominent tool in various domains owing to its adaptability. However, this adaptability can be taken advantage of by an adversary to cause dysfunction of machine learning; a process known as Adversarial Learning. This paper investigates Adversarial Learning in the context of artificial neural networks. The aim is to test the hypothesis that an ensemble of neural networks trained on the same data manipulated by an adversary would be more robust than a single network. We investigate two attack types: targeted and random. We use Mahalanobis distance and covariance matrices to selected targeted attacks. The experiments use both artificial and UCI datasets. The results demonstrate that an ensemble of neural networks trained on attacked data are more robust against the attack than a single network. While many papers have demonstrated that an ensemble of neural networks is more robust against noise than a single network, the significance of the current work lies in the fact that targeted attacks are not white noise.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584822","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584822","","Artificial neural networks;Availability;Electronic mail;Learning systems;Machine learning;Training;Training data","covariance matrices;learning (artificial intelligence);neural nets","Mahalanobis distance;UCI datasets;artificial neural networks;covariance matrices;dysfunction;machine learning;random adversarial learning;targeted adversarial learning","","1","","12","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"A fast training method for OC-SVM based on the random sampling lemma","H. Wang; G. Zhao; H. Gu","College of Electrical Engineering, Zhejiang University, Hangzhou, China","2010 Sixth International Conference on Natural Computation","20100923","2010","2","","824","827","Recently, One-class Support Vector Machine (OC-SVM) has been introduced to detect novel data or outliers. The key problem of training an OC-SVM is how to solve the constrained quadratic programming problem. The optimization process suffers from the problem of memory and time consuming. We present a new method to efficiently train the OC-SVM. Based on the random sampling lemma, the training dataset was firstly decomposed into subsets and each OC-SVM of subset was trained by Sequential Minimal Optimization (SMO). The combining lemmas of support vectors and outliers of OC-SVM were deduced. A new decision boundary was merged by decomposing and combining lemmas (DC). Experimental results demonstrate that the proposed method not only can handle larger scale data sets than standard SMO, but also outperforms SMO in time consumption.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583242","combining lemmas;one-class support vector machine;quadratic programming;random sampling lemma;sequential minimal optimization","Classification algorithms;Kernel;Machine learning;Quadratic programming;Support vector machines;Training","quadratic programming;random processes;sampling methods;support vector machines","constrained quadratic programming problem;decision boundary;decomposing and combining lemmas;novel data detection;one-class support vector machine training;optimization process;outlier detection;random sampling lemma;sequential minimal optimization","","2","","14","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Cohen's kappa coefficient as a performance measure for feature selection","S. M. Vieira; U. Kaymak; J. M. C. Sousa","Technical University of Lisbon, Instituto Superior T&#x00E9;cnico, Dept. of Mechanical Engineering, CIS/IDMEC - LAETA, Av. Rovisco Pais","International Conference on Fuzzy Systems","20100923","2010","","","1","8","Measuring the performance of a given classifier is not a straightforward or easy task. Depending on the application, the overall classification rate may not be sufficient if one, or more, of the classes fail in prediction. This problem is also reflected in the feature selection process, especially when a wrapper method is used. Cohen's kappa coefficient is a statistical measure of inter-rater agreement for qualitative items. It is generally thought to be a more robust measure than simple percent agreement calculation, since it takes into account the agreement occurring by chance. Considering that kappa is a more conservative measure, then its use in wrapper feature selection is suitable to test the performance of the models. This paper proposes the use of the kappa measure as an evaluation measure in a feature selection wrapper approach. In the proposed approach, fuzzy models are used to test the feature subsets and fuzzy criteria are used to formulate the feature selection problem. Results show that using the kappa measure leads to more accurate classifiers, and therefore it leads to feature subset solutions with more relevant features.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584447","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584447","","Accuracy;Biological system modeling;Computational modeling;Fuzzy sets;Machine learning;Minimization;Optimization","feature extraction;fuzzy logic;fuzzy set theory;image classification;statistical analysis","Cohen kappa coefficient;feature subsets;fuzzy models;inter-rater agreement statistical measurement;qualitative items;wrapper feature classification;wrapper feature selection process;wrapper method","","8","","25","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Opinion Summarization in Bengali: A Theme Network Model","A. Das; S. Bandyopadhyay","Dept. of Comput. Sci. & Eng., Jadavpur Univ., Kolkata, India","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","675","682","Theme network is a semantic network of document specific themes. So far Natural Language Processing (NLP) research patronized much of topic based summarizer system, unable to capture thematic semantic affinity of any text i.e. a news article containing the concepts, ""gun,"" ""convenience store,"" ""demand money"" and ""make getaway"" might suggest the topics ""robbery"" and ""crime"". In this paper the development of an opinion summarization system that works on Bengali News corpus has been described. The system identifies the sentiment information in each document, aggregates them and represents the summary information in text. The present system follows a topic-sentiment model for sentiment identification and aggregation. Topic-sentiment model is designed as discourse level theme identification and the topic-sentiment aggregation is achieved by theme clustering (k-means) and Document level Theme Relational Graph representation. The Document Level Theme Relational Graph is finally used for candidate summary sentence selection by standard page rank algorithms used in Information Retrieval (IR). As Bengali is a resource constraint language, the building of annotated gold standard corpus and acquisition of linguistics tools for lexico-syntactic, syntactic and discourse level features extraction are described in this paper. The reported accuracy of the Theme detection technique is 83.60% (precision), 76.44% (recall) and 79.85% (F-measure). The summarization system has been evaluated with Precision of 72.15%, Recall of 67.32% and F-measure of 69.65%.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591520","","Clustering algorithms;Feature extraction;Frequency measurement;Gold;Machine learning;Organizations;Syntactics","information retrieval;natural language processing;semantic networks;text analysis","Bengali news corpus;NLP;discourse level feature extraction;discourse level theme identification;document level theme relational graph representation;information retrieval;lexico-syntactic level feature extraction;natural language processing;opinion summarization system;page rank algorithms;resource constraint language;semantic network;syntactic level feature extraction;thematic semantic affinity;theme clustering;theme detection technique;theme network model;topic based summarizer system;topic sentiment identification;topic-sentiment aggregation","","1","1","18","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Coordinate System Archive for coevolution","W. Jaśkowski; K. Krawiec","Institute of Computing Science, Poznan University of Technology, Piotrowo 2, 60965 Pozna&#x0144;, Poland","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","10","Problems in which some entities interact with each other are common in computational intelligence. This scenario, typical for co-evolving artificial-life agents, learning strategies for games, and machine learning from examples, can be formalized as test-based problem. In test-based problems, candidate solutions are evaluated on a number of test cases (agents, opponents, examples). It has been recently shown that at least some of such problems posses underlying problem structure, which can be formalized in a notion of coordinate system, which spatially arranges candidate solutions and tests in a multidimensional space. Such a coordinate system can be extracted to reveal underlying objectives of the problem, which can be then further exploited to help coevolutionary algorithm make progress. In this study, we propose a novel coevolutionary archive method, called Coordinate System Archive (COSA) that is based on these concepts. In the experimental part, we compare COSA to two state-of-the-art archive methods, IPCA and LAPCA. Using two different objective performance measures, we find out that COSA is superior to these methods on a class of artificial problems (COMPARE-ON-ONE).","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586066","","Approximation algorithms;Approximation methods;Context;Games;Machine learning;Machine learning algorithms;Partitioning algorithms","artificial life;evolutionary computation;learning (artificial intelligence)","IPCA;LAPCA;coevolutionary algorithm;coevolving artificial life agents;computational intelligence;coordinate system archive;machine learning;test based problem","","2","","25","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"The Optimization of Large Scale Multiple Kernel SVM Based on K-Means Clustering in Kernel Space","H. Qin; M. Zhang; X. Qin; Y. d. Su","Comput. Sci. Dept., Guangxi Univ., Nanning, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","5","The generalization ability of multiple kernel support vector machines is better than the single kernel ones. If the training datasets are large scale, solving the optimal multiple kernels' combination coefficients with semidefinite programming method is difficult, and the time-consuming is large. We use K-means Clustering algorithm in kernel space to reduce the scale of SVM's training datasets, then the scale of the corresponding semidefinite programming is reduced. Our experimental results show that: the new method received more than several times faster than the old one in solving the semidefinite programming problem of SVM, and does not reduce the classification accuracy of multi-kernel SVM model.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566082","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566082","","Computers;Educational institutions;Kernel;Machine learning;Programming;Support vector machines","learning (artificial intelligence);linear programming;pattern clustering;statistical analysis;support vector machines","K-means clustering;kernel space;large scale multiple kernel SVM;optimization;semidefinite programming method;training dataset","","1","","12","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"An Increased Performance of Clustering High Dimensional Data Using Principal Component Analysis","N. Tajunisha; V. Saravanan","Dept. of Comput. Sci., Sri Ramakrishna Coll. of Arts &amp; Sci. for Women, Coimbatore, India","2010 First International Conference on Integrated Intelligent Computing","20100916","2010","","","17","21","In many application domains such as information retrieval, computational biology, and image processing the data dimension is usually very high. Developing effective clustering methods for high dimensional dataset is a challenging problem due to the curse of dimensionality. The k-means clustering algorithm is used for many practical applications. But it is computationally expensive and the quality of the resulting clusters heavily depends on the selection of initial centroid and dimension of the data. The accuracy of the resultant value perhaps not up to the level of expectation when the dimensions of the dataset is high because we cannot say that the dataset chosen are free from noisy and flawless. So it is required to reduce the dimensionality of the given dataset in order to improve the efficiency and accuracy. This paper proposed a new approach to improve the accuracy of the cluster results by using PCA to determine the initial centroid and also to reduce the dimension of the data.","","Electronic:978-0-7695-4152-5; POD:978-1-4244-7963-4","10.1109/ICIIC.2010.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571698","dimension reduction;k-means;principal component analysis","Accuracy;Algorithm design and analysis;Clustering algorithms;Iris;Machine learning algorithms;Partitioning algorithms;Principal component analysis","data analysis;pattern clustering;principal component analysis","computational biology;curse of dimensionality;data dimension;high dimensional data;image processing;information retrieval;k-means clustering;principal component analysis","","0","","12","","","5-7 Aug. 2010","","IEEE","IEEE Conference Publications"
"Subspace selection using semi-supervised harmonic mean of Kullback-Leibler divergences","S. B. Chen; H. X. Wang; B. Luo","Key Lab of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui University, Hefei, 230039, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1578","1581","In many areas of pattern recognition and machine learning, subspace selection is an essential step. Fisher's linear discriminant analysis (LDA) is one of the most well-known linear subspace selection methods. However, LDA suffers from the class separation problem. The projection to a subspace tends to merge close class pairs. A recent result, named maximizing the geometric mean of Kullback-Leibler (KL) divergences of class pairs (MGMD), can significantly reduce the class separation problem. Furthermore, maximizing the harmonic mean of Kullback-Leibler (KL) divergences of class pairs (MHMD) emphasizes smaller divergences more than MGMD, and deals with the class separation problem more effectively. However, in many applications, labeled data are very limited while unlabeled data can be easily obtained. The estimation of divergences of class pairs is unstable using inadequate labeled data. To take advantage of unlabeled data for subspace selection, semi-supervised MHMD (SSMHMD) is proposed using graph Laplacian as normalization. Quasi-Newton method is adopted to solve the optimization problem. Experiments on synthetic data and real image data show the validity of SSMHMD.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569351","KL divergence;geometric mean;harmonic mean;semi-supervised learning;subspace selection","Covariance matrix;Harmonic analysis;Laplace equations;Machine learning;Manifolds;Symmetric matrices;Training","Laplace equations;Newton method;data handling;graph theory;optimisation;pattern recognition","Kullback-Leibler divergence;class separation problem;geometric mean;graph Laplacian;linear discriminant analysis;machine learning;pattern recognition;quasi-Newton method;semisupervised harmonic mean;subspace selection","","0","","14","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"The hybrid genetic algorithm based on the niche's technology","F. G. Jiang","School of Civil Engineering, Heilongjiang Institute of Science & Technology, Harbin 150027, China","Proceedings of the 29th Chinese Control Conference","20100920","2010","","","5276","5279","Genetic arithmetic operators in genetic algorithm be improved, and a hybrid genetic algorithm of a gradient algorithm combining with the genetic algorithm be given against to the defects such as the prematurity, slow on the convergence rate, weak in the ability of local search, all those appeared on the progress of the genetic algorithm' iteration. The niche's technology be inducted due to the local optimal solution can easily appear on optimization of the multiply peak value. The analysis result indicates that not only the strong on the local search capacity of gradient algorithm be exhibited but also the strong on the general search capacity of genetic algorithm be combined based on the niche hybrid genetic algorithm, which make the capacity of convergence improve greatly. At the same time, the local optimal solution aroused in the optimization be avoided due to the niche technology be utilized, the hybrid genetic algorithm is an effective structural optimization method be proved in the computational example.","1934-1768;19341768","Electronic:978-7-8946-3104-6; POD:978-1-4244-6263-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572372","Genetic Algorithm;Gradient Algorithm;Hybrid Genetic Algorithm;Structural Optimization","Algorithm design and analysis;Classification algorithms;Convergence;Electronic mail;Genetics;Machine learning algorithms;Optimization","convergence;genetic algorithms;gradient methods;search problems","convergence rate;genetic algorithm iteration;gradient algorithm;local search;niche hybrid genetic algorithm;structural optimization method","","0","","11","","","29-31 July 2010","","IEEE","IEEE Conference Publications"
"Hierarchical fuzzy system modeling by Genetic and Bacterial Programming approaches","K. Balázs; J. Botzheim; L. T. Kóczy","Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary","International Conference on Fuzzy Systems","20100923","2010","","","1","6","In this paper a method is proposed for constructing hierarchical fuzzy rule bases in order to model black box systems defined by input-output pairs, i.e. to solve supervised machine learning problems. The resultant hierarchical rule base is the knowledge base, which is constructed by using structure constructing evolutionary techniques, namely, Genetic and Bacterial Programming Algorithms. Applying hierarchical fuzzy rule bases is a way of reducing the complexity of the knowledge base, whereas evolutionary methods ensure a relatively efficient learning process. This is the reason of the investigation of this combination.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584220","","Complexity theory;Genetics;Knowledge based systems;Machine learning;Microorganisms;Optimization;Programming","fuzzy systems;genetic algorithms;hierarchical systems;knowledge based systems;learning (artificial intelligence);logic programming","bacterial programming algorithm;black box system;evolutionary method;genetic programming algorithm;hierarchical fuzzy rule bases;hierarchical fuzzy system;knowledge base complexity reduction;machine learning","","5","","18","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Link State Protocol Data Mining for Shared Risk Link Group Detection","G. Das; D. Papadimitriou; W. Tavernier; D. Colle; T. Dhaene; M. Pickavet; P. Demeester","Dept. of Inf. Technol. (INTEC), Ghent Univ., Ghent, Belgium","2010 Proceedings of 19th International Conference on Computer Communications and Networks","20100902","2010","","","1","8","In this paper, we use machine learning technique at the routers to study the link state protocol data to predict the existence of shared risk link groups (SRLG) in the network. In particular, we use the correlation between different link state updates (LSUs) issued by different network nodes (routers) upon failure. The concerned network router then runs a novel Bayesian network based statistical learning process to learn about the possible existence of SRLGs. The decision of this online learning is transferred to the routing information base (RIB) so that it can accordingly modify the routing table for the entire SRLG upon failure detection of one of the candidate node of that particular SRLG and hence reduce the protection switching time.","1095-2055;10952055","Electronic:978-1-4244-7116-4; POD:978-1-4244-7114-0","10.1109/ICCCN.2010.5560151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560151","","Equations;Machine learning;Machine learning algorithms;Mathematical model;Routing;Routing protocols","cognitive radio;data mining;routing protocols;telecommunication computing","cognitive network;link state protocol data mining;machine learning technique;network nodes;routers;routing information base;shared risk link group detection","","4","","13","","","2-5 Aug. 2010","","IEEE","IEEE Conference Publications"
"Formulating description logic learning as an Inductive Logic Programming task","S. Konstantopoulos; A. Charalambidis","Institute of Informatics and Telecommunications, NCSR &#x2018;Demokritos&#x2019;, Aghia Paraskevi 153 10, Athens, Greece","International Conference on Fuzzy Systems","20100923","2010","","","1","7","We describe an Inductive Logic Programming (ILP) approach to learning descriptions in Description Logics (DL) under uncertainty. The approach is based on implementing many-valued DL proofs as propositionalizations of the elementary DL constructs and then providing this implementation as background predicates for ILP. The proposed methodology is tested on a many-valued variation of eastbound-trains and Iris, two well known and studied Machine Learning datasets.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584417","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584417","","Cost accounting;Logic programming;Machine learning;OWL;Semantics;Uncertainty","inductive logic programming;learning (artificial intelligence);multivalued logic","description logic learning;eastbound-trains;inductive logic programming task;machine learning datasets;many-valued DL proofs","","4","","19","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Meta-learning for data summarization based on instance selection method","K. Smith-Miles; R. Islam","School of Mathematical Sciences, Faculty of, Science, Monash University, Building 28, Wellington Road, Clayton, Australia","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","The purpose of instance selection is to identify which instances (examples, patterns) in a large dataset should be selected as representatives of the entire dataset, without significant loss of information. When a machine learning method is applied to the reduced dataset, the accuracy of the model should not be significantly worse than if the same method were applied to the entire dataset. The reducibility of any dataset, and hence the success of instance selection methods, surely depends on the characteristics of the dataset, as well as the machine learning method. This paper adopts a meta-learning approach, via an empirical study of 112 classification datasets from the UCI Repository, to explore the relationship between data characteristics, machine learning methods, and the success of instance selection method.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5585986","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5585986","","Accuracy;Algorithm design and analysis;Classification algorithms;Machine learning algorithms;Prediction algorithms;Prototypes;Training data","data reduction;learning (artificial intelligence)","UCI repository;data summarization;dataset reducibility;instance selection method;machine learning;meta learning","","4","","36","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Multi-document Chinese name disambiguation based on Latent Semantic Analysis","C. Wu; L. Gong; J. Zeng","School of Computer Science, Fudan University, Shanghai, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2367","2371","Name disambiguation has received considerable attention as an important subtask of NLP (Natural Language Processing). Given many potential references of person entities, the goal is to find out for each reference involved in the context the most possible person entity it refers to. However, many researches in this field either focus on name disambiguation within a single text or employ machine learning models on multi-document without any consideration of semantics. In this paper we propose a new algorithm based on LSA (Latent Semantic Analysis) for the multi-document disambiguation task for Chinese name. The method employs SVD (Singular Value Decomposition) to reduce the original high dimensional text space to comparatively lower dimensional semantic space and then cluster possible reference words on the semantic space to get the result. Experiments on a real world dataset which is collected from a BBS site show that the proposed method can generate reasonable result.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569867","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569867","LSA;SVD;name disambiguation","Algorithm design and analysis;Clustering algorithms;Computational linguistics;Context;Machine learning algorithms;Semantics;Tagging","learning (artificial intelligence);natural language processing;text analysis","BBS site;high dimensional text space;latent semantic analysis;machine learning model;multidocument Chinese name disambiguation;natural language processing;singular value decomposition","","0","","11","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Classification of Closed Frequent Patterns Improved by Feature Space Transformation","C. H. Jin; G. Pok; H. S. Kim; E. J. Cha; K. H. Ryu","Database/Bioinf. Lab., Chungbuk Nat. Univ., Cheongju, South Korea","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1306","1311","In some real-world applications, the predefined features are not discriminative enough to represent well the distinctiveness of different classes. Therefore, building a more well-defined feature space becomes an urgent task. The main goal of feature space transformation is to map a set of features defined in a space into a new more powerful feature space so that the classification based on the transformed data can achieve performance gain compared to the performance in the original space. In this paper, we introduce a feature transformation method in which the feature transformation is conducted using the closed frequent patterns. Experiments on real-world datasets show that the transformed features obtained from combining the closed frequent patterns and the original features are superior in terms of classification accuracy than the approach based solely on closed frequent patterns.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577866","Classification Accuracy;Closed Frequent Pattern;Feature Space Transformation","Accuracy;Association rules;Classification algorithms;Itemsets;Machine learning","pattern classification","closed frequent patterns classification;feature space transformation;real world datasets","","0","","32","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Extracting rubber plant in Quickbird imagery based on Support Vector Machines","ShaoJun Liu; JingHong Zhang; Zhengwei He","Chengdou University of Technology, Hainan Institute of Meteorological Science, China","2010 2nd International Conference on Industrial and Information Systems","20100907","2010","2","","533","536","In recent years high-resolution space borne images have disclosed a large number of new opportunities for medium and large-scale rubber plant mapping. Some traditional algorithms used for hyper spectral remote sensing image classification have some problems such as low computing rate, low accuracy. According to SVM theory, the Rubber plant classification model based on SVM was constructed, by experimenting with Quickbird imagery, the classification accuracy of SVM using four different kernel functions were analyzed, the results indicate that the four types of kernels for training and classification of SVM can be used for rubber plant classification.","","Electronic:978-1-4244-7862-0; POD:978-1-4244-7860-6","10.1109/INDUSIS.2010.5565772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5565772","Classification;Rubber plant;Support Vector Machines","Classification algorithms;Data mining;Kernel;Machine learning;Spatial resolution;Support vector machines;Training","cartography;image classification;image resolution;remote sensing;support vector machines","Quickbird imagery;high resolution space borne images;hyper spectral remote sensing image classification;large-scale rubber plant mapping;rubber plant classification;rubber plant classification model;support vector machine classification","","0","","4","","","10-11 July 2010","","IEEE","IEEE Conference Publications"
"Enhanced Maximum AUC Linear Classifier","X. Fan; K. Tang","Nature Inspired Computation and Application Laboratory, School of Computer Science and Technology, University of Science and Technology of China, Hefei, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1540","1544","In the field of imbalance learning and cost sensitive learning, minimization of the classification error rate is not an appropriate approach due to class skew and cost distributions. Thus the area under the ROC Curve (AUC) has been widely utilized to assess the performance of the classifiers in such cases. The Maximum AUC Linear Classifier (MALC), aiming at maximizing AUC directly, is a nonparametric linear classifier. MALC is based on the analysis of Wilcoxon-Mann-Whitney statistic of each single feature and on greedy pairwise combinations of the features. This paper finds that the MALC searches the solution in a much constrained resolution space. Furthermore, the heuristic method for guiding the structure of the classifier is worthy of notice. In this paper the Enhanced MALC (EMALC) is proposed. In the EMALC, two modifications are presented. Modification 1 aims at extensive searching in the solution space. Modification 2 modifies the way that MALC guides to induce the structure of the classifier. Experimental studies are carried out on a broad range of real world dataset. And the proposed methods have shown significant effect.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569339","AUC;ROC curve;class skew;linear classifier","Accuracy;Algorithm design and analysis;Classification algorithms;Correlation;Learning;Machine learning;Training","learning (artificial intelligence);pattern classification;statistical distributions","Wilcoxon-Mann-Whitney statistic;class cost distribution;class skew distribution;cost sensitive learning;heuristic method;imbalance learning;maximum AUC linear classifier;nonparametric linear classifier","","8","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"The Analysis of Research Frontier and Hot Topics about Knowledge Discovery (KD) Based on Mapping Knowledge Domain","L. Chen","Sch. of Manage., Hebei Univ., Baoding, China","2010 WASE International Conference on Information Engineering","20100916","2010","2","","28","32","This article choosing all the 3987 documents' citation as data sample of Knowledge Discovery(KD), which was published in Web of Science(SCI-EXPANDED, SSCI, A&HCI) from 1986 to2009, confirming the hot research topics and the research fronts by using word frequency analysis and detect key words that their term frequency changed notably, and drawing the knowledge mapping of them by using Citespace: a information visualization software. Hoping it can benefit to the research of Knowledge Discovery(KD).","","Electronic:978-1-4244-7507-0; POD:978-1-4244-7506-3","10.1109/ICIE.2010.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571212","CiteSpace;co-citation analysis;information visualization;knowledge discovery;mapping knowledge domain","Association rules;Classification algorithms;Databases;Decision trees;Knowledge engineering;Machine learning algorithms","Internet;citation analysis;data mining","Citespace;Web of Science;co-citation analysis;information visualization software;knowledge discovery;mapping knowledge domain;word frequency analysis","","0","","33","","","14-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research on Ranking Support Vector machine and prospects","S. F. Ding; X. L. Liu; L. W. Zhang","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou 221008, China","Proceedings of the 29th Chinese Control Conference","20100920","2010","","","2829","2831","Learning to rank is designed to determine a ranking for the target objects according to some rule. Specifically, the problem about learning to rank is to learn a ranking function from a training set whose data has been ranked. It is most applied to the social sciences and information retrieval. Learning to rank is a hot issue in the field of information retrieval and machine learning at present. This paper analyses the process of Ranking Support Vector machine (RSVM) from a theoretical point of view from the classification and regression respectively, and sets up the two basic mathematical models about RSVM. The general introduction about RSVM in the application, training speed and generalization ability is also given. In the end, we come to a conclusion.","1934-1768;19341768","Electronic:978-7-8946-3104-6; POD:978-1-4244-6263-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5573208","Learning to Rank;Ordinal Regression;Ranking SVM (RSVM);Support Ector Machine (SVM)","Data models;Equations;Information retrieval;Machine learning;Mathematical model;Support vector machines;Training","generalisation (artificial intelligence);information retrieval;learning (artificial intelligence);pattern classification;regression analysis;support vector machines","classification;generalization ability;information retrieval;machine learning;mathematical model;ranking function learning;ranking support vector machine;regression;social sciences;training speed","","0","","18","","","29-31 July 2010","","IEEE","IEEE Conference Publications"
"Learning performance of Fisher Linear Discriminant based on Markov sampling","B. Zou; Zhiming Peng; Huihua Fan; Jie Xu","Faculty of Mathematics, Hubei University, Wuhan 430062, China","2010 Sixth International Conference on Natural Computation","20100923","2010","3","","1114","1118","Fisher Linear Discriminant (FLD) is a well-known method for dimensionality reduction and classification that projects high-dimensional data onto a low-dimensional space where the data achieves maximum class separability. To improve the learning performance of FLD algorithm, in this paper we introduce Markov sampling algorithm to generate uniformly ergodic Markov chain samples from a given i.i.d. data of finite size by following the enlightening idea from MCMC methods. Through simulation studies and numerical studies on benchmark repository using FLD algorithm, we found that FLD algorithm based on uniformly ergodic Markov samples generated by the markov sampling algorithm introduced in this paper can provide smaller mean square error compared to the i.i.d. sampling from the same data.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583692","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583692","","Benchmark testing;Data models;Machine learning;Markov processes;Mean square error methods;Numerical models;Training","Markov processes;Monte Carlo methods;learning (artificial intelligence);sampling methods","FLD algorithm;MCMC methods;Markov chain Monte Carlo method;dimensionality reduction;ergodic Markov chain samples;fisher linear discriminant learning performance;maximum class separability","","1","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Learning Curve: Principle, Application and Limitation","G. Huang; W. Man","Sch. of Manage., China Univ. of Min. & Technol., Xuzhou, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","1840","1843","The article introduces the background that learning curve was established and sets up its model. The basic principles and methods of estimating and improving learning rate are put forward. The author elaborates the concrete application of learning curve in enterprise management, and analyzes its applied conditions and limitations to provide suggestions for enterprises making reasonable application.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.465","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593090","actual application;learning curve;learning rate;limitations","Companies;Corporate acquisitions;Machine learning;Manufacturing;Productivity","manufacturing systems;organisational aspects","concrete application;enterprise management;learning curve;learning rate","","0","","5","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Semi-supervised Fuzzy c-Means Clustering Using Clusterwise Tolerance Based Pairwise Constraints","Y. Hamasuna; Y. Endo; S. Miyamoto","Dept. of Risk Eng., Univ. of Tsukuba, Tsukuba, Japan","2010 IEEE International Conference on Granular Computing","20100916","2010","","","188","193","Recently, semi-supervised clustering has been remarked and discussed in many research fields. In semi-supervised clustering, prior knowledge or information are often formulated as pairwise constraints, that is, must-link and cannot-link. Such pairwise constraints are frequently used in order to improve clustering properties. In this paper, we will propose a new semi-supervised fuzzy c-means clustering by using clusterwise tolerance and pairwise constraints. First, the concept of clusterwise tolerance and pairwise constraints are introduced. Second, the optimization problem of fuzzy c-means clustering using clusterwise tolerance based pairwise constraint is formulated. Especially, must-link constraint is considered and introduced as pairwise constraints. Third, a new clustering algorithm is constructed based on the above discussions. Finally, the effectiveness of proposed algorithm is verified through numerical examples.","","Electronic:978-0-7695-4161-7; POD:978-1-4244-7964-1","10.1109/GrC.2010.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5576156","clusterwise tolerance;fuzzy c-means clustering;pairwise constraints;semi-supervised clustering","Clustering algorithms;Clustering methods;Entropy;Equations;Kernel;Machine learning;Mathematical model","constraint handling;optimisation;pattern clustering","cannot link;clusterwise tolerance based pairwise constraints;must link;optimization problem;semi supervised fuzzy c-means clustering","","1","","18","","","14-16 Aug. 2010","","IEEE","IEEE Conference Publications"
"Adversarial Evolution: Phase transition in non-uniform hard satisfiability problems","M. M. Hossain; H. A. Abbass; C. Lokan; S. Alam","School of SEIT, UNSW@ADFA, University of New South Wales, Australia","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","What makes a combinatorial optimization problem hard? The concept of phase transition was introduced in combinatorial decision problems to explain that not all NP-Complete problems are hard, and that there exists a phase transition from solvable to unsolvable problems, within which hard problems exist. Phase transition has been studied using randomly generated problems in which variables have uniform distributions across the different constraints. Real-world problems demonstrate different distributions, however. This paper reveals the relationship between the difficulty of a 3-SAT problem and graph properties. It establishes for the first time a link between the theory of phase-transition in 3-SAT and phase transitions in complex systems and networks. This paper also addresses the question of whether the phase transition phenomenon exists for non-uniform randomly generated problems. A positive answer to this question means in principle that (1) we can generate test problems for combinatorial optimization that are not uniform; (2) we can generate test problems that resemble hard versions of real-world problems; (3) we can identify the features that we need to look for in a problem to test whether or not it is hard. We use a method that we call Adversarial Evolution (AE). In AE, an evolutionary computation method is used to generate hard problem instances by evolving solutions towards the failure of an algorithm and the phase transition region.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586506","","Accuracy;Artificial neural networks;Biological cells;Complexity theory;Level measurement;Machine learning algorithms;Optimization","computability;computational complexity;evolutionary computation;graph theory","3-SAT problem;NP-complete;adversarial evolution;combinatorial decision problem;combinatorial optimization;complex network;complex system;evolutionary computation;graph property;nonuniform hard satisfiability problem;nonuniform randomly generated problem;phase transition;real-world problem","","1","","29","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Scaling the iHMM: Parallelization versus Hadoop","S. Bratières; J. van Gael; A. Vlachos; Z. Ghahramani","Dept. of Eng., Univ. of Cambridge, Cambridge, UK","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1235","1240","This paper compares parallel and distributed implementations of an iterative, Gibbs sampling, machine learning algorithm. Distributed implementations run under Hadoop on facility computing clouds. The probabilistic model under study is the infinite HMM, in which parameters are learnt using an instance blocked Gibbs sampling, with a step consisting of a dynamic program. We apply this model to learn part-of-speech tags from newswire text in an unsupervised fashion. However our focus here is on runtime performance, as opposed to NLP-relevant scores, embodied by iteration duration, ease of development, deployment and debugging.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577884","","Computational modeling;Data models;Hidden Markov models;Machine learning;Markov processes;Probabilistic logic;Tagging","computer facilities;hidden Markov models;iterative methods;parallel programming;probability;unsupervised learning","Gibbs sampling algorithm;Hadoop;NLP-relevant scores;distributed implementation;dynamic program;facility computing clouds;infinite HMM;iterative algorithm;machine learning algorithm;parallel implementation;probabilistic model;unsupervised learning","","0","","11","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Automatic filtering algorithm for imbalanced classification","W. Gong; Y. Zhou; H. Luo; J. Fan; A. Zhou","Massive Computing Institute, East China Normal University, Shanghai, 200062, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1853","1857","The imbalanced data set has been reported to hinder the classification performance of many machine learning algorithms on both accuracy and speed. But extremely imbalanced data sets (3~5% positive samples) are common for many applications, such as multimedia semantic classification. In this paper, we propose a novel algorithm to automatically remove samples that have no or negative effects on classifier training for imbalanced training data sets. By using our algorithm, most easy-to-classify dominant-class samples in imbalanced training set will be eliminated automatically. As a result, the ratio of minority class samples is increased significantly, making it more suitable for classification algorithms. Experiments show that our algorithm can keep the classification accuracy of SVM, and decrease the training time dramatically.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569437","","Accuracy;Algorithm design and analysis;Feature extraction;Machine learning algorithms;Support vector machines;Training;Training data","information filtering;learning (artificial intelligence);pattern classification;support vector machines","SVM;automatic filtering algorithm;classifier training;imbalanced data classification;machine learning algorithms;training data sets","","2","","12","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"A new approach of Random Forest for multiclass classification problem","B. Sun; J. Luo; S. Shu; N. Yu","College of Science, Donghua University, Shanghai, China","2010 5th International Conference on Computer Science & Education","20100930","2010","","","6","8","Investigate the potential of Random Forests in a multiclass setting and propose a new algorithm based on error-correct-coding (ECC) and loop-symmetrical division. It performs significantly better than the original RF and slightly better than the other two approach that usually used to handle multiclass problem. But our algorithm has lower computation cost which is very important especially in large classification problems. Experiments show its efficiency.","","Electronic:978-1-4244-6005-2; POD:978-1-4244-6002-1","10.1109/ICCSE.2010.5593438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593438","ECC;multiclass;random forests","Classification algorithms;Classification tree analysis;Encoding;Machine learning;Radio frequency;Support vector machine classification;Training","decision trees;error correction codes;learning (artificial intelligence);pattern classification","error-correct-coding;loop-symmetrical division;multiclass classification problem;random forest","","0","","13","","","24-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Mapping the performance of heuristics for Constraint Satisfaction","J. C. Ortiz-Bayliss; E. Özcan; A. J. Parkes; H. Terashima-Marin","Center For Intelligent Computing and Robotics, Tecnol&#x00F3;gico de Monterrey, Campus Monterrey, Monterrey, Mexico","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","Hyper-heuristics are high level search methodologies that operate over a set of heuristics which operate directly on the problem domain. In one of the hyper-heuristic frameworks, the goal is automating the process of selecting a human-designed low level heuristic at each step to construct a solution for a given problem. Constraint Satisfaction Problems (CSP) are well know NP complete problems. In this study, behaviours of two variable ordering heuristics Max-Conflicts (MXC) and Saturation Degree (SD) with respect to various combinations of constraint density and tightness values are investigated in depth over a set of random CSP instances. The empirical results show that the performance of these two heuristics are somewhat complementary and they vary for changing constraint density and tightness value pairs. The outcome is used to design three hyper-heuristics using MXC and SD as low level heuristics to construct a solution for unseen CSP instances. It has been observed that these hyper-heuristics improve the performance of individual low level heuristics even further in terms of mean consistency checks for some CSP instances.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5585965","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5585965","","Computer science;Construction industry;Educational institutions;Electronic mail;Machine learning algorithms;Robots;Search problems","computational complexity;constraint theory;optimisation;search problems","NP complete problem;constraint satisfaction problems;hyper-heuristic framework;ordering heuristics max-conflicts;performance mapping;saturation degree;search methodology","","8","","44","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"A multiple population XCS: Evolving condition-action rules based on feature space partitions","M. Abedini; M. Kirley","Department of Computer Sciences and Software Engineering, The University of Melbourne, Australia","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","XCS is an accuracy-based machine learning technique, which combines reinforcement learning and evolutionary algorithms to evolve a set of classifiers (or rules) for pattern classification tasks. In this paper, we investigate the effects of alternative feature space partitioning techniques in a multiple population island-based parallel XCS. Here, each of the isolated populations evolve rules based on a subset of the features. The behavior of the multiple population model is carefully analyzed and compared with the original XCS using the Boolean logic multiplexer problem as a test case. Simulation results show that our multiple population XCS produced better performance and better generalization than the single population XCS model, especially when the problem increased in size. A caveat, however, is that the effectiveness of the model was dependent upon the feature space partitioning strategy used.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586521","","Accuracy;Brain modeling;Computational modeling;Data models;Machine learning;Multiplexing;Protocols","Boolean functions;evolutionary computation;learning (artificial intelligence);pattern classification","Boolean logic multiplexer problem;accuracy-based machine learning technique;alternative feature space partitioning technique;evolutionary algorithm;feature space partitioning strategy;pattern classification;population island-based parallel XCS;reinforcement learning","","3","","27","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Approaches to identification of nonlinear systems","L. Ljung","Division of Automatic Control, Link&#x00F6;ing University, SE-58183, Sweden","Proceedings of the 29th Chinese Control Conference","20100920","2010","","","1","5","System Identification for linear systems and models is a well established and mature topic. Identifying nonlinear models is a much more rich and demanding problem area. In this presentation some major approaches and concepts for that are outlined.","1934-1768;19341768","Electronic:978-7-8946-3104-6; POD:978-1-4244-6263-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572936","Black Box;Estimation;Gray Box;Manifold Learning;Nonlinear Models;Nonparametric Methods;System Identification","Atmospheric modeling;Kernel;Machine learning;Manifolds;Mathematical model;Polynomials;Wavelength division multiplexing","identification;nonlinear systems","mature topic;nonlinear systems;system Identification","","1","","25","","","29-31 July 2010","","IEEE","IEEE Conference Publications"
"The Structure of the Computer Science Knowledge Network","M. C. Pham; R. Klamma","Inf. Syst. & Database Technol., RWTH Aachen Univ., Aachen, Germany","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","17","24","How is our knowledge organized? What research fields in computer science do exist? How are they interconnected? Previous work on knowledge mapping focused on building the map of all of sciences or a particular domain based on ISI published JCR (Journal Citation Report) dataset. Although this dataset covers most of important journals, it lacks of computer science conference and workshop proceedings. That results in an imprecise and incomplete analysis on the map of computer science knowledge. This paper presents an analysis on the computer science knowledge network with the aims to understand its structure and to answer the above questions. Based on the combination of two important digital libraries for computer science (DBLP and CiteSeerX), the knowledge networks are created at venue (journals, conferences and workshops) level and social network analysis is applied to determine clusters of similar venues, interdisciplinary venues and high prestige venues.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5562793","citation analysis;digital library;knowledge network;social network","Computer science;Conferences;Indexes;Knowledge engineering;Libraries;Machine learning","computer science;digital libraries","JCR;computer science conference;computer science knowledge network;digital libraries;journal citation report;knowledge mapping","","6","","22","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Benchmarking evolutionary multiobjective optimization algorithms","O. Mersmann; H. Trautmann; B. Naujoks; C. Weihs","Statistics Department of TU Dortmund University, Germany","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","Choosing and tuning an optimization procedure for a given class of nonlinear optimization problems is not an easy task. One way to proceed is to consider this as a tournament, where each procedure will compete in different `disciplines'. Here, disciplines could either be different functions, which we want to optimize, or specific performance measures of the optimization procedure. We would then be interested in the algorithm that performs best in a majority of cases or whose average performance is maximal. We will focus on evolutionary multiobjective optimization algorithms (EMOA), and will present a novel approach to the design and analysis of evolutionary multiobjective benchmark experiments based on similar work from the context of machine learning. We focus on deriving a consensus among several benchmarks over different test problems and illustrate the methodology by reanalyzing the results of the CEC 2007 EMOA competition.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586241","","Algorithm design and analysis;Benchmark testing;Context;Handheld computers;Machine learning algorithms;Optimization;Systematics","evolutionary computation;learning (artificial intelligence);optimisation","CEC 2007 EMOA competition;evolutionary multiobjective optimization algorithm;machine learning;nonlinear optimization problem","","1","","19","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Modelling Affect in Learning Environments - Motivation and Methods","S. Afzal; P. Robinson","Comput. Lab., Univ. of Cambridge, Cambridge, UK","2010 10th IEEE International Conference on Advanced Learning Technologies","20100916","2010","","","438","442","Emotions have a functional relevance to learning and achievement. Not surprisingly then, affective diagnoses are an important aspect of expert human mentoring. Computer-based learning environments aim to model such social dynamics to make learning with computers more immersive, engaging and hence, more effective. This paper draws on the recent surge of interest in studying emotions in learning, highlights available techniques for measuring emotions and surveys recent efforts to automatically measure emotional experience in learning environments. Finally, a context-sensitive dataset is used to develop an automatic system for modeling six pertinent emotions. This paper attempts to bring together the motivation, methodological issues, and modeling approaches for affect inference in learning environments in order to contribute to an understanding of the problem and the current state-of-art.","2161-3761;21613761","Electronic:978-1-4244-7145-4; POD:978-1-4244-7144-7","10.1109/ICALT.2010.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5573217","Affective Computing;Computer-based Learning;Emotion","Computational modeling;Computers;Context;Face;Hidden Markov models;Machine learning","behavioural sciences;computer aided instruction;social aspects of automation","affective diagnoses;computer based learning environment;context sensitive dataset;emotional experience measurement;expert human mentoring;functional relevance;learning environment;pertinent emotions modeling;social dynamics","","5","","44","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"A Re-ranking Algorithm Based on Focused Named Entities","D. Jie","Inf. Eng. Dept., Shandong Youth Univ. of Political Sci., Jinan, China","2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics","20100930","2010","1","","187","191","This paper proposed a new method for learning to re-rank the retrieved documents based on the evaluation of the semantic relevance between named-entities in these documents and the query words, especially relevance between the query and the most topical named entities in these documents. The relevance weights used to rank documents were evaluated by analyzing the co-occurrence characters of focused named entities with respect to query. In this method, firstly, given the set of retrieved documents containing a query, the focused named entities in these documents are recognized; secondly, the relevance level of the query with respect to the focused entities in each retrieved document is estimated; thirdly, these retrieved documents are re-ranked with these relevance levels. Moreover, Experimental results on SEWM2006 test set indicate that our method can work well.","","Electronic:978-0-7695-4151-8; POD:978-1-4244-7869-9","10.1109/IHMSC.2010.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590600","Focused named entities;Ranking algorithm;Relevance levels","Classification algorithms;Feature extraction;Filtration;Frequency measurement;Machine learning;Semantic Web;Semantics","information retrieval","SEWM2006 test set;cooccurrence characters;document retrieval;focused named entities;information retrieval applications;query words;rank documents;relevance weights;reranking algorithm;semantic relevance","","0","","16","","","26-28 Aug. 2010","","IEEE","IEEE Conference Publications"
"A two-stage feature selection method for text categorization","J. Meng; H. Lin","Department of Computer Science and Engineering, Dalian University of Technology, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1492","1496","Feature selection for text classification is a well-studied problem and the goals are improving classification effectiveness, computational efficiency, or both. In this paper, we propose a two-stage feature selection algorithm based on a kind of feature selection method and latent semantic indexing. Traditional word-matching based text categorization system uses vector space model to represent the document. However, it needs a high dimensional space to represent the document, and does not take into account the semantic relationship between terms, which can also lead to poor classification accuracy. Latent semantic indexing can overcome the problems caused by using statistically derived conceptual indices instead of individual words. It constructs a conceptual vector space in which each term or document is represented as a vector in the space. It not only greatly reduces the dimensionality but also discovers the important associative relationship between terms. Because of the too much calculation time of constructing a new semantic space, in this algorithm, firstly we apply a kind of feature selection method to reduce the term dimensions. Secondly, we construct a new reduced semantic space between terms based on latent semantic indexing method. Through some applications involving spam database categorization, we find that our two-stage feature selection method performs better.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569324","feature selection;latent semantic indexing;support vector space;text categorization","Accuracy;Indexing;Large scale integration;Machine learning;Semantics;Support vector machines;Text categorization","document handling;feature extraction;indexing;pattern classification;support vector machines;text analysis","latent semantic indexing;reduced semantic space;spam database categorization;text categorization;two stage feature selection method;vector space model;word matching based text categorization system","","4","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Gradient-Descent-Based Approach for Transparent Linguistic Interface Generation in Fuzzy Models","L. Chen; C. L. P. Chen; W. Pedrycz","Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20100913","2010","40","5","1219","1230","Linguistic interface is a group of linguistic terms or fuzzy descriptions that describe variables in a system utilizing corresponding membership functions. Its transparency completely or partly decides the interpretability of fuzzy models. This paper proposes a GRadiEnt-descEnt-based Transparent lInguistic iNterface Generation (GREETING) approach to overcome the disadvantage of traditional linguistic interface generation methods where the consideration of the interpretability aspects of linguistic interface is limited. In GREETING, the widely used interpretability criteria of linguistic interface are considered and optimized. The numeric experiments on the data sets from University of California, Irvine (UCI) machine learning databases demonstrate the feasibility and superiority of the proposed GREETING method. The GREETING method is also applied to fuzzy decision tree generation. It is shown that GREETING generates better transparent fuzzy decision trees in terms of better classification rates and comparable tree sizes.","1083-4419;10834419","","10.1109/TSMCB.2009.2036443","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345824","Fuzzy clustering;fuzzy decision tree;fuzzy systems;linguistic interface;membership functions;transparency and interpretability","Association rules;Classification tree analysis;Computer interfaces;Databases;Decision trees;Fuzzy neural networks;Fuzzy sets;Fuzzy systems;Machine learning;Multiplexing","computational linguistics;decision trees;fuzzy set theory;gradient methods;optimisation;pattern classification","fuzzy decision trees;fuzzy description;gradient-descent-based approach;interpretability aspect;linguistic interface;membership functions","Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Fuzzy Logic;Linguistics;Models, Theoretical;Pattern Recognition, Automated","13","","58","","20091204","Oct. 2010","","IEEE","IEEE Journals & Magazines"
"Manifold feature extraction for video based on locally linear embedding","M. Fu; Q. Xu; M. Kong; B. Luo","Key Lab of Intelligent Computing & Signal Processing of Ministry of Education, Anhui University, Hefei, 230039. P. R. China","2010 5th International Conference on Computer Science & Education","20100930","2010","","","557","560","Locally linear embedding (LLE) is an elegant nonlinear method for feature extraction and manifold learning, which attempt to project the original data into a lower dimensional feature space by preserving the local neighborhood structure. However, LLE algorithm fails when it is directly applied to video with multi-shot. In this paper, video manifold feature is defined firstly, and then using LLE we extract video manifold feature through adding virtual frames on an enriched set. The proposed manifold feature extraction method is applied to shot transition and video trajectories. The video manifold feature description gives a new tool for video analysis.","","Electronic:978-1-4244-6005-2; POD:978-1-4244-6002-1","10.1109/ICCSE.2010.5593551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593551","Feature extraction;Linear locally embedding;Video","Artificial neural networks;Feature extraction;Machine learning;Manifolds;Trajectory;Vectors;Video sequences","feature extraction;video signal processing","local neighborhood structure;locally linear embedding;manifold learning;nonlinear method;video analysis;video manifold feature extraction","","0","","17","","","24-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Opinion Detection in Blogs: What Is Still Missing?","M. M. S. Missen; M. Boughanem; G. Cabanac","IRIT, Univ. de Toulouse, Toulouse, France","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","270","275","In recent years, a lot of work has been done in the field of Opinion Detection in blogs but most of the research is based on machine learning or lexical based approaches. The objective of this paper is to focus on Social Network based evidences that can be exploited for the task of Opinion Detection. We propose a framework that makes use of the major elements of the blogosphere for extracting opinions from blogs. Besides this, we highlight the tasks of opinion prediction and multidimensional ranking. In addition, we also discuss the challenges that researchers might face while realizing the proposed framework. At the end, we demonstrate the importance of social networking evidences by performing experimentation.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5562761","Blogosphere;Blogs;Information Retrieval;Opinion Detection;Opinion Prediction;Polarity Detection;Social Networking;Subjectivity","Blogs;Context;Estimation;Face;Machine learning;Social network services;Time frequency analysis","learning (artificial intelligence);social networking (online)","blogosphere;lexical based approaches;machine learning;opinion detection;social network","","2","","26","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Batch versus interactive learning by demonstration","P. Zang; R. Tian; A. L. Thomaz; C. L. Isbell","College of Computing, Georgia Institute of Technology, Atlanta, Georgia 30332-0259","2010 IEEE 9th International Conference on Development and Learning","20100920","2010","","","219","224","Agents that operate in human environments will need to be able to learn new skills from everyday people. Learning from demonstration (LfD) is a popular paradigm for this. Drawing from our interest in Socially Guided Machine Learning, we explore the impact of interactivity on learning from demonstration. We present findings from a study with human subjects showing people who are able to interact with the learning agent provide better demonstrations (in part) by adapting based on learner performance which results in improved learning performance. We also find that interactivity increases a sense of engagement and may encourage players to participate longer. Our exploration of interactivity sheds light on how best to obtain demonstrations for LfD applications.","","DVD:978-1-4244-6901-7; Electronic:978-1-4244-6902-4; POD:978-1-4244-6900-0","10.1109/DEVLRN.2010.5578841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578841","","Conferences;Education;Games;Humans;Interviews;Machine learning;Trajectory","learning by example","batch learning;interactive learning;interactivity;learning agent;socially guided machine learning","","1","","23","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"FS_KPARD: An effective SVM feature selection method","T. Wang","School of Mathematics and Computer Science, Gannan Normal University, Ganzhou 341000, China","2010 Sixth International Conference on Natural Computation","20100923","2010","2","","892","895","This paper presents an effective feature selection method for support vector machine (SVM). Unlike the traditional combinatorial searching method, feature selection is translated into the model selection of SVM which has been well studied. In more detail, the basic idea of this method is to tune the parameters of the Gaussian ARD (Automatic Relevance Determination) kernel via optimization of kernel polarization, and then to rank all features in decreasing order of importance so that more relevant features can be identified. The proposed method is tested on two UCI data sets to demonstrate its effectiveness.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583909","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583909","auto relevance determination;feature selection;model selection;support vector machine","Accuracy;Correlation;Kernel;Machine learning;Optimization;Support vector machines;Training","Gaussian processes;feature extraction;learning (artificial intelligence);pattern classification;support vector machines","FS_KPARD;Gaussian ARD;SVM feature selection method;automatic relevance determination;combinatorial searching method;kernel polarization;support vector machine","","0","","11","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic generation and exploitation of related problems in genetic programming","K. Krawiec; B. Wieloch","Institute of Computing Science, Poznan University of Technology, Piotrowo 2, 60965 Pozna&#x0144;, Poland","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","We propose an evolutionary framework that uses the set of instructions provided with a genetic programming (GP) problem to automatically build a repertoire of related problems and subsequently uses them to improve the performance of search. The novel idea is to use the synthesized related problems to simultaneously exert multiple selection pressures on the evolving population(s). For that framework, we design two methods. In the first method, individuals optimizing for particular problems dwell in separate populations and spawn clones which migrate to other populations, similarly to the island model. The second method operates on a single population and ranks the fitness values that individuals receive from particular problems to make them comparable. When applied to six symbolic regression problems of different difficulty, both methods perform better than the standard GP, though sometimes fail to prove superior to certain control setup.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586120","","Cloning;Computational modeling;Genetic programming;Inverters;Machine learning;Polynomials;Transforms","genetic algorithms;mathematical programming;regression analysis;search problems","automatic exploitation;automatic generation;evolutionary framework;fitness values;genetic programming;six symbolic regression problems","","6","","17","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Event-event relation identification: A CRF based approach","A. K. Kolya; A. Ekbal; S. Bandyopadhyay","Dept. of Computer Science and Engineering, Jadavpur University, Kolkata, India-700032","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","8","Temporal information extraction is a popular and interesting research field in the area of Natural Language Processing (NLP). The main tasks involve the identification of event-time, event-document creation time and event-event relations in a text. In this paper, we take up Task C that involves identification of relations between the events in adjacent sentences under the TimeML framework. We use a supervised machine learning technique, namely Conditional Random Field (CRF). Initially, a baseline system is developed by considering the most frequent temporal relation in the task's training data. For CRF, we consider only those features that are already available in the TempEval-2007 training set. Evaluation results on the Task C test set yield precision, recall and F-score values of 55.1%, 55.1% and 55.1%, respectively under the strict evaluation scheme and 56.9%, 56.9 and 56.9%, respectively under the relaxed evaluation scheme. Results also show that the proposed system performs better than the baseline system.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587774","Conditional Random Field;TempEval 2007 Task C;Temporal Relation Identification;TimeML","Accuracy;Classification algorithms;Feature extraction;Machine learning;Speech;Training;Training data","information retrieval;learning (artificial intelligence);natural language processing","TimeML framework;conditional random field;event-event relation identification;machine learning technique;natural language processing;temporal information extraction","","2","","10","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Analysing the effectiveness of COMA++ on the mapping between Traditional Malay Textile (TMT) knowledge model and CIDOC CRM","S. A. M. Nasir; N. L. M. Noor","Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA, 40000, Shah Alam, Malaysia","2010 International Symposium on Information Technology","20100902","2010","1","","1","6","The existence of state-of-the art mapping tools facilitate in finding correspondences between ontology entities. COMA++ among others is a tool that accommodates both schemas and ontologies matching with additional enhancements and provides a platform to evaluate different match algorithms. COMA++ is asserted to be a useful support tool due to its availability online, capability to integrate large variety of similarity algorithms and feasibility for complex metadata management problems. Thus, COMA++ is chosen in this study based on the input type, output type, interaction and availability. The findings show that COMA++ is an effective tool in finding similarity between schemas in terms of element and structural aspects with its single hybrid matchers and combination matchers. However, there are several limitations identified during the experiments that drive this study for further enhancement to be carried out in the future to test its true potential.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561323","composite match;hybrid matcher;ontology mapping;similarity values","Availability;Cultural differences;Machine learning;Ontologies;Pediatrics;Semantic Web;Textiles","ontologies (artificial intelligence);software tools","CIDOC CRM;COMA++;complex metadata management problems;ontologies matching;single hybrid matchers;traditional malay textile knowledge model","","0","","30","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Prediction of hepatitis prognosis using Support Vector Machines and Wrapper Method","A. H. Roslina; A. Noraziah","Faculty of Computer Systems & Software Engineering, University Malaysia Pahang, Lebuhraya Tun Abdul Razak,26300, Kuantan, Malaysia","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2209","2211","Hepatitis patients are those who need continuous special medical treatment to reduce mortality rate. Using clinical test findings data and machine learning technology such as Support Vector Machines (SVM), the classification and prediction of their life prognosis can be done. However, we cannot pledge that all the features values in the data are correlated to each other. Therefore, we incorporate Wrapper Methods to remove noise features before classification. This study shows the increase in prediction between data by combining feature selection method prior to classification process.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569542","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569542","SVM;Wrapper Method;component;feature selection","Accuracy;Classification algorithms;Data mining;Feature extraction;Learning;Machine learning;Support vector machines","diseases;learning (artificial intelligence);patient treatment;pattern classification;support vector machines","continuous special medical treatment;feature selection method;hepatitis prognosis prediction;image classification;machine learning;mortality rate reduction;noise features removal;support vector machine;wrapper method","","2","","11","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Extending propositional satisfiability to determine minimal fuzzy-rough reducts","R. Jensen; A. Tuson; Q. Shen","Department of Computer Science, Aberystwyth University, UK","International Conference on Fuzzy Systems","20100923","2010","","","1","8","This paper describes a novel, principled approach to real-valued dataset reduction based on fuzzy and rough set theory. The approach is based on the formulation of fuzzy-rough discernibility matrices, that can be transformed into a satisfiability problem; an extension of rough set approaches that only apply to discrete datasets. The fuzzy-rough hybrid reduction method is then realised algorithmically by a modified version of a traditional satisifability approach. This produces an efficient and provably optimal approach to data reduction that works well on a number of machine learning benchmarks in terms of both time and classification accuracy.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584470","","Approximation methods;Equations;Facsimile;Information systems;Machine learning algorithms;Rough sets;Symmetric matrices","computability;data reduction;fuzzy set theory;learning (artificial intelligence);matrix algebra;pattern classification;rough set theory","data reduction;discrete datasets;fuzzy set theory;fuzzy-rough discernibility matrix;fuzzy-rough hybrid reduction method;machine learning benchmark;minimal fuzzy-rough reduct;propositional satisfiability;real-valued dataset reduction;rough set theory;satisfiability problem","","1","","16","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"A genetic learning of fuzzy relational rules","Y. Caises; E. Leyva; A. González; R. Pérez","Facultad de Inform&#x00E1;tica of the Universidad de Holgu&#x00ED;n, Holgu&#x00ED;n, Cuba","International Conference on Fuzzy Systems","20100923","2010","","","1","8","Two basic requirements of fuzzy modeling are the accuracy and simplicity of the knowledge obtained. In this study, we propose a genetic learning algorithm of fuzzy relational rules, that is, fuzzy rules that include fuzzy relations. Fuzzy relational rules allow us to obtain fuzzy models with a good interpretability-accuracy trade-off. Since, the inclusion of relations increases the accuracy keeping the interpretability but increasing the number of features to be considered in the learning process. We also present a model to reduce the additional complexity that occurs when using this new type of rules. Finally, we also present an experimental study that demonstrated the advantage of the use of relational fuzzy rules.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584718","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584718","","Catalogs;Chromium;Encoding;Genetics;Inference algorithms;Machine learning algorithms;Pragmatics","fuzzy logic;fuzzy set theory;genetic algorithms;learning (artificial intelligence)","fuzzy relations;fuzzy rules;genetic learning;learning process","","0","","18","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Exploiting System Knowledge to Improve ECOC Reject Rules","P. Simeone; C. Marrocco; F. Tortorella","DAEIMI, Univ. degli Studi di Cassino, Cassino, Italy","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4340","4343","Error Correcting Output Coding is a common technique for multiple class classification tasks which decomposes the original problem in several two-class problems solved through dichotomizers. Such classification system can be improved with a reject option which can be defined according to the level of information available from the dichotomizers. This paper analyzes how this knowledge is useful when applying such reject rules. The nature of the outputs, the kind of the employed classifiers and the knowledge of their loss function are influential details for the improvement of the general performance of the system. Experimental results on popular benchmark data sets are reported to show the behavior of the different schemes.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1055","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597769","Error Correcting Output Coding;Reject option","Decoding;Encoding;Error analysis;Hamming distance;High definition video;Machine learning;Reliability","error correction codes;pattern classification","ECOC reject rules;classification system;dichotomizers;error correcting output coding;multiple class classification tasks;system knowledge","","1","","12","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Interval type-2 fuzzy classifier design using Genetic Algorithms","A. H. M. Pimenta; H. A. Camargo","Artificial Intelligence Group, Computer Science Department, Federal University of S&#x00E3;o Carlos (UFSCar), S&#x00E3;o Carlos, SP 13565-905 Brazil","International Conference on Fuzzy Systems","20100923","2010","","","1","7","This paper aims at investigating the advantages of using an interval type-2 fuzzy system for classification problems. An evolutionary architecture was proposed to generate the rule base and to optimize the membership functions of a type-2 Fuzzy Classification System The proposed architecture is composed of three stages. In the first stage of the architecture, a Genetic Algorithm generates the rule base of the Fuzzy Classification System using predefined and fixed membership functions. In the second stage, another Genetic Algorithm optimizes the interval type-2 membership functions that were used in the first stage. Finally, a third Genetic Algorithm is used for the optimization of the number of rules in the best Fuzzy Classification System generated in the two previous stages. Some experiments have been run using different datasets from the UCI Machine Learning Repository in order to validate the proposed approach and to compare the results with the ones obtained with the Wang&Mendel method and a type-1 fuzzy classification system also generated by the evolutionary architecture proposed here. The results demonstrated that the type-2 fuzzy classification system performed better than the other classifiers used in the study.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584520","","Classification algorithms;Fuzzy systems;Machine learning;Optimization","fuzzy set theory;fuzzy systems;genetic algorithms;knowledge based systems;learning (artificial intelligence);pattern classification","UCI machine learning repository;Wang & Mendel method;evolutionary architecture;fuzzy classification system;genetic algorithm;interval type-2 fuzzy classifier design;membership function;rule base function;type-1 fuzzy classification system","","3","","38","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"A new feature weighting method based on probability distribution in imbalanced text classification","L. Chu; H. Gao; W. Chang","Faculty of Science, Xi'an Jiaotong University, 710049, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2335","2339","Many real-world text classification tasks involve imbalanced training examples. Categories with fewer examples are under-represented and their classifiers often perform far below satisfactory. We propose a new approach using a probability distribution to assign the feature weight and apply it to Naive Bayes classifier. The method is evaluated in our experiments on FuDan Chinese Corpus. The experimental result shows significant improvement for imbalanced datasets while the performance for balanced datasets is not jeopardized. Our approach has suggested a simple and effective solution to boost the performance of text classification over skewed datasets.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569830","Feature weighting;Imbalanced text classification;Naive Bayes;Skew","Accuracy;Machine learning;Niobium;Probability distribution;Tagging;Text categorization;Training","Bayes methods;pattern classification;statistical distributions;text analysis","FuDan Chinese Corpus;Naive Bayes classifier;feature weight;imbalanced text classification;probability distribution","","3","","12","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Achieving memetic adaptability by means of fuzzy decision trees","G. Acampora; J. M. Cadenas; V. Loia; E. Muñoz","Department of Mathematical and Computer Science, University of Salerno, 84084, Fisciano, Salerno, Italy","International Conference on Fuzzy Systems","20100923","2010","","","1","8","Evolutionary Algorithms are a collection of optimization techniques that take their inspiration from natural selection and survival of the fittest in the biological world and they have been exploited to try to resolve some of the more complex NP-complete problems. Nevertheless, in spite of their capability of exploring and exploiting promising regions of the search space, they present some drawbacks and, in detail, they can take a relatively long time to locate the exact optimum in a region of convergence and may sometimes not find the solutions with sufficient precision. Memetic Algorithms are innovative meta-heuristic search methods that try to alleviate evolutionary approaches' weaknesses by efficiently converging to high quality solutions. However, as shown in literature, memetic approaches are affected by several design issues related to the different choices that can be made to implement them. This paper introduces a multi-agent based memetic algorithm which executes in a parallel way different cooperating optimization strategies in order to solve a given problem's instance in an efficient way. The algorithm adaptation is performed by jointly exploiting a knowledge extraction process, based on fuzzy decision trees, together with a decision making framework based on fuzzy methodologies. The effectiveness of our approach is tested in several experiments in which our results are compared with those obtained by some non-adaptive memetic algorithms.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584336","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584336","","Adaptation model;Data mining;Databases;Decision trees;Machine learning;Memetics;Optimization","decision trees;fuzzy set theory;genetic algorithms;multi-agent systems;parallel algorithms","NP-complete problems;decision making framework;evolutionary algorithms;fuzzy decision trees;knowledge extraction process;memetic adaptability;multi-agent based memetic algorithm;parallel algorithm adaptation","","0","","17","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Entity answer extraction of web table","Y. Xu; Z. Yu; C. Mao; Y. Wang; J. Guo","The School of Information Engineering and Automation, Kunming University of Science and Technology, China, 650051","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2465","2468","This paper presents an entity answer extraction method based on list web table. Firstly, extract table from page using the features of web page table and label, segment the table that includes the potential entity answers by calculating the relevance of web table's title and query context, merge the table elements of each column according to table properties, and merge the web table's title with the merged elements of column again. Secondly, using merged passage as context of entity recognition, and recognize the entity for each element of the table, thus get the probability of the column elements belongs to the same type of entity answer, and locate the passages of entity answers and the entity answers. Finally, we conduct the experiment in the task of Entity Track of TREC2009. It turns out that the proposed method shows a very good result, the accuracy of entity answer extraction for web table has achieved 99.08%.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569791","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569791","list answers;table NER;table entity answer extraction;table passage segment;web table","Accuracy;Context;Data mining;Feature extraction;Machine learning;Text recognition;Web pages","Web sites;information retrieval","Web page table;Web table title;entity answer extraction;entity recognition;query context","","0","","9","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Predicting player behavior in Tomb Raider: Underworld","T. Mahlmann; A. Drachen; J. Togelius; A. Canossa; G. N. Yannakakis","Center for Computer Games Research, IT University of Copenhagen, Rued Langgaards Vej 7, DK-2300 Copenhagen S, Denmark","Proceedings of the 2010 IEEE Conference on Computational Intelligence and Games","20100930","2010","","","178","185","This paper presents the results of an explorative study on predicting aspects of playing behavior for the major commercial title Tomb Raider: Underworld (TRU). Various supervised learning algorithms are trained on a large-scale set of in-game player behavior data, to predict when a player will stop playing the TRU game and, if the player completes the game, how long will it take to do so. Results reveal that linear regression models and other non-linear classification techniques perform well on the tasks and that decision tree learning induces small yet well-performing and informative trees. Moderate performance is achieved from the prediction models, which indicates the complexity of predicting player behavior based on a constrained set of gameplay metrics and the noise existent in the dataset examined, a generic problem in large-scale data collection from millions of remote clients.","2325-4270;23254270","Electronic:978-1-4244-6297-1; POD:978-1-4244-6295-7; USB:978-1-4244-6296-4","10.1109/ITW.2010.5593355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593355","Player modeling;Tomb Raider: Underworld;classification;supervised learning","Classification algorithms;Data mining;Feature extraction;Games;Machine learning algorithms;Measurement;Prediction algorithms","computer games;learning (artificial intelligence);pattern classification;solid modelling","TRU game;Tomb Raider:Underworld;constrained set;decision tree learning;gameplay metrics;generic problem;informative tree;large scale data collection;linear regression model;nonlinear classification technique;player behavior prediction;remote client;supervised learning algorithm","","15","1","23","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Novel Multi-view Agglomerative Clustering Algorithm Based on Ensemble of Partitions on Different Views","H. Mirzaei","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada","2010 20th International Conference on Pattern Recognition","20101007","2010","","","1007","1010","In this paper, we propose a new algorithm for extending the hierarchical clustering methods and introduce a Multi-View Agglomerative Clustering approach to handle multi-view represented objects. Experiments on real world datasets indicate that our algorithm considering the relationship among multiple views can provide a solution with improved quality in multi-view setting. We find empirically that the multi-view version of our Agglomerative Clustering, independent of linkage method and given any number of views, greatly improves on its single-view counterparts.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595842","Agglomerative Clustering;Entropy;Multi-view;Single-View","Clustering algorithms;Clustering methods;Conferences;Couplings;Entropy;Machine learning;Partitioning algorithms","pattern clustering","hierarchical clustering methods;multiview agglomerative clustering algorithm;multiview represented objects;partitions ensemble","","2","","14","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Information Theoretic fuzzy modeling for regression","D. Álvarez-Estévez; J. C. Príncipe; V. Moret-Bonillo","Laboratory for the Research and Development of Artificial Intelligence (LIDIA), University of A Coru&#x00F1;a, Spain","International Conference on Fuzzy Systems","20100923","2010","","","1","5","This paper presents a novel, Information Theoretic Learning (ITL) method to model a fuzzy system for regression tasks that minimizes the Renyi's entropy of the error signal. An architecture based on a generalization of the well-known Adaptive-Network-Based Fuzzy Inference System (ANFIS) was used to perform such a modeling. The resulting method was tested on the prediction of future values for the Mackey-Glass chaotic time series. The results show that, when using the ITL cost function, the method returns better models in comparison with a Mean Squared Error (MSE)-guided cost function.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584499","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584499","","Clustering algorithms;Cost function;Entropy;Fuzzy systems;Input variables;Machine learning","fuzzy systems;generalisation (artificial intelligence);inference mechanisms;mean square error methods;regression analysis","Mackey-Glass chaotic time series;Renyi entropy;adaptive-network-based fuzzy inference system;error signal;fuzzy system;generalization;information theoretic fuzzy modeling;information theoretic learning method;mean squared error;regression tasks","","1","","27","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Re-weighting relevance feedback image retrieval algorithm based on particle swarm optimization","X. Xu; Xiangdong Liu; Zhezhou Yu; Chunguang Zhou; Libiao Zhang","College of Computer Science and Technology, Jilin University, Changchun, China","2010 Sixth International Conference on Natural Computation","20100923","2010","7","","3609","3613","Aiming at the inflexible re-weighting problem of relevance feedback (RF) in image retrieval, a re-weighting relevance feedback method utilizing particle swarm optimization (PSORW-RF) is proposed. Firstly, initialize feature weightings randomly, then use the variances of the positive and negative feedback samples' features as study principle, utilize particle swarm optimization (PSO) algorithm to optimize weightings according to user's retrieval requirement, and obtain retrieval results at last. Experiments show that the proposed algorithm is validity.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5584092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584092","image retrieval;particle swarm optimization;re-weighting;relevance feedback","Distance measurement;Image color analysis;Image retrieval;Machine learning algorithms;Optimization;Particle swarm optimization;Radio frequency","image retrieval;particle swarm optimisation","image retrieval;negative feedback;particle swarm optimization;positive feedback;reweighting relevance feedback method;user retrieval requirement","","2","","13","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Spatio–Temporal Multimodal Developmental Learning","Y. Zhang; J. Weng","General Motors Global R&D, Warren","IEEE Transactions on Autonomous Mental Development","20100909","2010","2","3","149","166","It is elusive how the skull-enclosed brain enables spatio-temporal multimodal developmental learning. By multimodal, we mean that the system has at least two sensory modalities, e.g., visual and auditory in our experiments. By spatio-temporal, we mean that the behavior from the system depends not only on the spatial pattern in the current sensory inputs, but also those of the recent past. Traditional machine learning requires humans to train every module using hand-transcribed data, using handcrafted symbols among modules, and hand-link modules internally. Such a system is limited by a static set of symbols and static module performance. A key characteristic of developmental learning is that the “brain” is “skull-closed” after birth - not directly manipulatable by the system designer - so that the system can continue to learn incrementally without the need for reprogramming. In this paper, we propose an architecture for multimodal developmental learning - parallel modality pathways all situate between a sensory end and the motor end. Motor signals are not only used as output behaviors, but also as part of input to all the related pathways. For example, the proposed developmental learning does not use silence as cut points for speech processing or motion static points as key frames for visual processing.","1943-0604;19430604","","10.1109/TAMD.2010.2051437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473115","Developmental architecture;multimodal development;speech recognition;visual recognition","Contracts;Humans;Indium tin oxide;Joining processes;Machine learning;Permission;Spatiotemporal phenomena;Speech processing;Speech recognition;Uncertainty","biomechanics;brain;hearing;learning (artificial intelligence);medical computing;neurophysiology;spatiotemporal phenomena;visual perception","auditory modality;cut points;machine learning;motion static points;parallel modality pathways;sensory inputs;sensory modalities;silence;skull-enclosed brain;spatial pattern;spatio-temporal multimodal developmental learning;speech processing;visual modality;visual processing","","5","","44","","20100527","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"An empirical evaluation of linear and nonlinear kernels for text classification using Support Vector Machines","Y. Gao; S. Sun","Department of Computer Science and Technology, East China Normal University, 500 Dongchuan Road, Shanghai 200241, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1502","1505","This paper compares the performance of linear and nonlinear kernels of Support Vector Machines (SVM) used for text classification. The study is motivated by the previous viewpoint that linear SVM performs better than nonlinear one, and that, although there are many investigations have proved that SVM performs well in text classification, there is no serious investigation on the comparison between linear SVM and nonlinear SVM. In our study, we carry out two experiments with different datasets and use grid-search on the selection of kernel parameters. Empirical results show that, in fact, nonlinear SVM performs better than linear SVM as long as with appropriate kernel parameters. This conclusion will provide useful guidance for people applying SVM to text classification and other corresponding fields.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569327","Support Vector Machines;linear kernel;nonlinear kernel;text classification","Accuracy;Computer science;Kernel;Machine learning;Support vector machines;Text categorization;Web pages","pattern classification;support vector machines;text analysis","SVM;empirical evaluation;linear kernels;nonlinear kernels;support vector machines;text classification","","1","","18","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Internet Traffic Classification Using Score Level Fusion of Multiple Classifier","M. Ichino; H. Maeda; T. Yamashita; K. Hoshi; N. Komatsu; K. Takeshita; M. Tsujino; M. Iwashita; H. Yoshino","Media Network Center, Waseda Univ., Tokyo, Japan","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","20100930","2010","","","105","110","Internet traffic is continuously growing fast due to the rapid spread of the internet and the speed-up of the internet connection. Also, the applications provided on the internet have become more diversified. To support the QoS requirements for these internet applications, it would be better to measure the traffic volume according to the applications. Therefore, we are engaged in the application classification method, which is an offline technique for identifying the applications in units of flow. In some application classification methods, the applications of the target flows are analyzed according to their statistics on traffic metric, or features. We focus on these feature based classification methods, since the methods have the advantage that the port number and the packet payload need not be checked for classification. In the field of the machine learning, the classification methods that consist of multiple classifiers have been discussed. This is why the classification methods are improved in performance. However, the conventional feature based classification methods consists of single classifier. Also, the design of multiple classifiers has hardly been discussed. The design includes the way of combining some classifiers. Here, we introduce the fusion of multiple classifiers and propose applying the score level fusion using feature vectors to concatenate each classifier score to classify the flow into applications.","","Electronic:978-0-7695-4147-1; POD:978-1-4244-8198-9","10.1109/ICIS.2010.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593127","application classification;internet traffic;multiple classifier;score level fusion","Accuracy;Internet;Machine learning;Payloads;Postal services;Support vector machine classification;Training","Internet;learning (artificial intelligence);quality of service;telecommunication traffic","Internet traffic classification;QoS requirements;internet applications;internet connection;machine learning;multiple classifier;score level fusion","","4","","19","","","18-20 Aug. 2010","","IEEE","IEEE Conference Publications"
"Analyzing the Blogosphere for Predicting the Success of Music and Movie Products","F. Abel; E. Diaz-Aviles; N. Henze; D. Krause; P. Siehndel","L3S Res. Center, Leibniz Univ. Hannover, Hannover, Germany","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","276","280","Over the last decade blogs became an important part of the Web, where people can announce anything that is on their mind. Due to their high popularity blogs have great potential to mine public opinions regarding products. Such knowledge is very valuable as it could be used to adjust marketing campaigns or advertisement of products accordingly. In this paper we investigate how the blogosphere can be used to predict the success of products in the domain of music and movies. We analyze and characterize the blogging behavior in both domains particularly around product releases, propose different methods for extracting characteristic features from the blogosphere, and show that our predictions correspond to the real world measures Sales Rank and box office revenue respectively.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5562762","","Blogs;Correlation;Feature extraction;Machine learning algorithms;Marketing and sales;Motion pictures;Prediction algorithms","Web sites;consumer behaviour;data mining;marketing data processing","blogosphere analysis;box office revenue;market campaigning;movie product;music product;product advertisement;public opinion mining;sales ranking;success prediction","","1","","12","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Parameter learning for multi-factors of entity answer extracting","H. Zong; Z. Yu; C. Mao; J. Zou; J. Guo","The School of Information Engineering and Automation, Kunming University of Science and Technology, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2478","2482","Entity extraction involves multi-factors, and the different factor has an impact on the answer in varying degrees, this paper presents a machine learning approach to parameter learning for entity answer. Firstly, in view of characteristics of the Question Answering System (QA), we define three elements of the text score, passage score and entity score which influenced the answer extraction, also give the relevant computational method about them. Then collect 400 entity answers of product, person, and organization according to TREC2009 entity task requirements. With the help of search engines, retrieve related pages and calculate the score of the various factors related to the answer respectively. Thereafter compute the score of entity answers according to a linear combination of the various factors. Define an initial score to extract the entity answer and get a sorted list of answers. Finally, mark these entities answer to obtain the correct marked answers corpus, then build parameter learning model by the EM algorithm iterate gradually to find the optimal answer weight of different factors that influenced the answer extraction. We carried on the experiment in the TREC2009 entity task; it shows very good results for this method. The accuracy of entity answer has achieved 88.93%.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569794","EM algorithm;entity answer extraction;entity relevance;parameter estimation;passage relevance;text relevance","Accuracy;Algorithm design and analysis;Context;Data mining;Machine learning;Parameter estimation;Training","information retrieval;learning (artificial intelligence)","TREC2009 entity task requirements;answer extraction;entity answer extraction;entity score;machine learning;parameter learning;passage score;question answering system;relevant computational method;search engines;text score","","1","","8","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research of Classification Algorithm Based on Local Coordination","L. Jia; L. Li; L. Huang","Dept. of Comput. Sci., Hunan City Univ., Yiyang, China","2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics","20100930","2010","2","","303","306","Most of graph-based methods for semi-supervised learning are transductive, giving predictions for only the unlabeled data in the training set, and not for an arbitrary test point. SLC (Semi-supervised Local Linear Coordinate), which is based on LLC (Local Linear Coordinate) is present here as an inductive method. The mixture of factor analyzers is used to model the raw data set, and the label smoothness over the graph is enforced by local approximation. At last, smooth nonlinear projection is achieved by local affine transformation. Experiment shows the superiority of our proposed method in comparison to others.","","Electronic:978-0-7695-4151-8; POD:978-1-4244-7869-9","10.1109/IHMSC.2010.175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591018","local linear coordinate;manifold learning;mixture of factor analyzers;semi-supervised classification","Approximation methods;Classification algorithms;Data models;Information processing;Machine learning;Manifolds;Training","approximation theory;graph theory;learning (artificial intelligence);pattern classification;transforms","classification algorithm;graph-based methods;local affine transformation;local approximation;semi-supervised learning;semi-supervised local linear coordinate;smooth nonlinear projection","","0","","17","","","26-28 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Novel Framework for Ranking Model Adaptation","P. Cai; A. Zhou","Inst. of Massive Comput., East China Normal Univ., Shanghai, China","2010 Seventh Web Information Systems and Applications Conference","20100923","2010","","","149","154","Domain adaptation is an important problem in learning to rank due to the lack of training data in a new search task. Recently, an approach based on instance weighting and pairwise ranking algorithms has been proposed to address the problem by learning a ranking model for a target domain only using training data from a source domain. In this paper, we propose a novel framework which extends the previous work using a listwise ranking algorithm for ranking adaptation. Our framework firstly estimates the importance weight of a query in the source domain. Then, the importance weight is incorporated into the state-of-the-art listwise ranking algorithm, known as AdaRank. The framework is evaluated on the Letor3.0 benchmark dataset. The results of experiment demonstrate that it can significantly outperform the baseline model which is directly trained on the source domain, and most of the time not significantly worse than the optimal model which is trained on the target domain.","","Electronic:978-0-7695-4193-8; POD:978-1-4244-8440-9","10.1109/WISA.2010.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581312","listwise;query weight ranking model adaptation learning to rank","Adaptation model;Data models;Estimation;Feature extraction;Machine learning;Training;Training data","learning (artificial intelligence);query formulation","AdaRank;Letor3.0 benchmark dataset;instance weighting;listwise ranking algorithm;pairwise ranking algorithm;query;rank learning;ranking model adaptation;search task","","0","","29","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Using evolutionary computation to improve SVM classification","U. Kamath; A. Shehu; K. De Jong","Norkom Technologies in Reston, Virginia, USA 20191","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","Support vector machines (SVMs) are now one of the most popular machine learning techniques for solving difficult classification problems. Their effectiveness depends on two critical design decisions: 1) mapping a decision problem into an n-dimensional feature space, and 2) choosing a kernel function that maps the n-dimensional feature space into a higher dimensional and more effective classification space. The choice of kernel functions is generally limited to a small set of well-studied candidates. However, the choice of a feature set is much more open-ended without much design guidance. In fact, many SVMs are designed with standard generic feature space mappings embedded a priori. In this paper we describe a procedure for using an evolutionary algorithm to design more compact non-standard feature mappings that, for a fixed kernel function, significantly improves the classification accuracy of the constructed SVM.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586432","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586432","","Accuracy;Bioinformatics;DNA;Evolutionary computation;Kernel;Machine learning;Support vector machines","decision theory;evolutionary computation;pattern classification;support vector machines","decision problem mapping;evolutionary computation;generic feature space mapping;kernel function;machine learning technique;support vector machine classification","","6","","34","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Transfer Learning Based on SVD for Spam Filtering","J. n. Meng; H. f. Lin; Y. h. Yu","Coll. of Sci., Dalian Nat. Univ., Dalian, China","2010 International Conference on Intelligent Computing and Cognitive Informatics","20100907","2010","","","491","494","At present most email spam filtering methods assume that the training data from a source domain and the test data from a target domain follow the same distribution. However, in many cases this assumption may not be hold. In this paper we propose a transfer learning method based on singular value decomposition (SVD) for solving spam filtering problem. We compute the similarity between target particular features and common features with singular value decomposition method in order to learn a common feature representation. Then we rebuild a vector space model (VSM) of the training and the test data. The final label predictions are decided by a traditional machine learning method. The empirical results on three data sets show that our method is effective.","","Electronic:978-1-4244-6641-2; POD:978-1-4244-6640-5","10.1109/ICICCI.2010.115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566057","Singular value decomposition (SVD);Spam filtering;Transfer learning;Vector space model (VSM)","Accuracy;Filtering;Machine learning;Training;Training data;Unsolicited electronic mail","e-mail filters;learning (artificial intelligence);security of data;singular value decomposition;unsolicited e-mail","SVD;email spam filtering method;machine learning method;singular value decomposition;transfer learning method;vector space model","","1","","13","","","22-23 June 2010","","IEEE","IEEE Conference Publications"
"EBDA: An Effective Bottom-up Discretization Algorithm for Continuous Attributes","Y. Sang; K. Li; Y. Shen","Dept. of Comput. Sci. & Eng., Dalian Univ. of Technol., Dalian, China","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","2455","2462","Discretization algorithms have played an important role in many areas such as artificial intelligence, data mining and machine learning. In this paper, we propose an effective bottom-up discretization algorithm, namely EBDA. Firstly, we present a novel merging criterion which not only considers the effect of variance on degrees of freedom in the two merged intervals but also the effect of variance on interval difference and data distribution. In addition, we present a new stopping criterion with the aim to control the degree of misclassification and to merge intervals as many as possible. Detailed analysis shows that this algorithm can bring higher accuracy to the discretization process. Empirical experiments on 16 real data sets show that our proposed algorithm generates a better discretization scheme which significantly improves the accuracy of classification than existing algorithms by running C4.5.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578282","Chi2 algorithm;Classification;Discretization;Merging criterion;Stopping criterion","Accuracy;Algorithm design and analysis;Educational institutions;Machine learning algorithms;Merging;Upper bound","data mining;learning (artificial intelligence);merging","Chi2 algorithm;artificial intelligence;continuous attributes;data mining;effective bottom-up discretization algorithm;machine learning;merging criterion","","2","","18","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"A new incremental learning algorithm based on hyper-sphere SVM","Y. Qin; Qiangkui Leng; Xiangna Meng; Qian Luo","College of Information Science and Technology, Bohai University, Jinzhou, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2340","2343","A sample and class incremental learning algorithm based on hyper-sphere support vector machine is proposed. For every class, hyper-sphere support vector machine is used to get the smallest hyper-sphere that contains most samples of the class, which can divide the class samples from others. In the process of incremental learning, the hyper-sphere of every new class are trained, and the history hyper-spherees that have something to do with the new incremental samples are retrained. For the sample to be classified, the distances from it to the centre of every hyper-spheres are used to confirm the class that the sample belongs to. The experimental results show that the algorithm has a higher performance on training speed, classification speed, and classification precision.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569831","hyper-sphere;incremental learning;support vector machine","Classification algorithms;Kernel;Machine learning;Support vector machine classification;Testing;Training","learning (artificial intelligence);support vector machines","hyper-sphere SVM;hyper-sphere support vector machine;incremental learning","","1","","14","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Profiling Phishing Emails Based on Hyperlink Information","J. Yearwood; M. Mammadov; A. Banerjee","Grad. Sch. of ITMS, Univ. of Ballarat, Ballarat, VIC, Australia","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","120","127","In this paper, a novel method for profiling phishing activity from an analysis of phishing emails is proposed. Profiling is useful in determining the activity of an individual or a particular group of phishers. Work in the area of phishing is usually aimed at detection of phishing emails. In this paper, we concentrate on profiling as distinct from detection of phishing emails. We formulate the profiling problem as a multi-label classification problem using the hyperlinks in the phishing emails as features and structural properties of emails along with who is (i.e. DNS) information on hyperlinks as profile classes. Further, we generate profiles based on classifier predictions. Thus, classes become elements of profiles. We employ a boosting algorithm (AdaBoost) as well as SVM to generate multi-label class predictions on three different datasets created from hyperlink information in phishing emails. These predictions are further utilized to generate complete profiles of these emails. Results show that profiling can be done with quite high accuracy using hyperlink information.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5562782","","Browsers;Electronic mail;Feature extraction;HTML;Machine learning algorithms;Prediction algorithms;Servers","computer crime;learning (artificial intelligence);pattern classification;support vector machines;unsolicited e-mail","AdaBoost;boosting algorithm;classifier predictions;hyperlink information;multilabel classification problem;phishing emails profiling;support vector machine","","7","","26","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Boosted Multiple Kernel Learning for Scene Category Recognition","I. H. Jhuo; D. T. Lee","Dept. of CSIE, Nat. Taiwan Univ., Taipei, Taiwan","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3504","3507","Scene images typically include diverse and distinctive properties. It is reasonable to consider different features in establishing a scene category recognition system with a promising performance. We propose an adaptive model to represent various features in a unified domain, i.e., a set of kernels, and transform the discriminant information contained in each kernel into a set of weak learners, called dyadic hyper cuts. Based on this model, we present a novel approach to carrying out incremental multiple kernel learning for feature fusion by applying AdaBoost to the union of the sets of weak learners. We further evaluate the performance of this approach by a benchmark dataset for scene category recognition. Experimental results show a significantly improved performance in both accuracy and efficiency.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597407","Multiple kernel learning","Accuracy;Image recognition;Kernel;Machine learning;Shape;Training data;Visualization","image recognition;learning (artificial intelligence)","AdaBoost;boosted multiple kernel learning;dyadic hyper cuts;feature fusion;incremental multiple kernel learning;scene category recognition;scene images","","3","","23","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Bayesian Network Structure Learning Method Based on Ant Colony Algorithm","F. Wang; W. Zhu","Corps of Eng., Eng. Inst., PLA Univ. of Sci. & Technol., Nanjing, China","2010 International Conference on Management and Service Science","20100916","2010","","","1","4","To find the implied dependency relationships and knowledge representation from sample data, a Bayesian Network structure learning method was proposed on the basis of ant colony algorithm, which provided support for the modeling of complex decision-making tasks. Algorithm design was presented after the formal description of Bayesian network structure learning problems. Accordingly, a Bayesian network structure learning rules were built, including node state transferring rule, node sequence scoring rule, pheromone inspired strength calculating rule, pheromone updating rule, process controlling rule, network structure establishing rule, etc. Finally, the important value of algorithm applied in complex decision-making fields was effectively verified with the example of construction about damage assessing system for a certain military engineering.","","Electronic:978-1-4244-5326-9; POD:978-1-4244-5325-2","10.1109/ICMSS.2010.5575696","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575696","","Algorithm design and analysis;Bayesian methods;Data models;Decision making;Knowledge engineering;Machine learning algorithms;Process control","belief networks;decision making;formal specification;learning (artificial intelligence)","Bayesian network structure learning;ant colony algorithm;decision-making;formal description;knowledge representation;node sequence scoring rule;node state transferring rule;pheromone;process controlling rule;strength calculating rule","","0","","9","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Feature selection based on modified minimize entropy principle","J. S. Chen; H. L. Chou; D. W. S. Tai","Department of Computer Science and Information, Management, HUNGKUANG University, No.34, Chung-Chie Road, Shalu, Taichung 433, Taiwan","2010 International Conference on Electronics and Information Engineering","20100902","2010","1","","V1-10","V1-13","Feature selections have seen growing importance placed on statistics, pattern recognition, machine learning and data mining. Researchers have demonstrated the interest in the methods for improving the performance of their forecasting results. Therefore, this study proposes a feature selection approach, which based on minimize entropy principle approach. Experimental results have shown that the proposed model provided more average accuracy rate and stability then other methods.","","Electronic:978-1-4244-7681-7; POD:978-1-4244-7679-4","10.1109/ICEIE.2010.5559828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559828","Feature Selection;Minimize Entropy Principle","Accuracy;Classification algorithms;Computer science;Data mining;Entropy;Machine learning;Windows","data mining;entropy;learning (artificial intelligence);pattern recognition","data mining;feature selection;machine learning;modified minimize entropy principle;pattern recognition","","0","","12","","","1-3 Aug. 2010","","IEEE","IEEE Conference Publications"
"Documents classification by using ontology reasoning and similarity measure","J. Fang; L. Guo; Y. Niu","School of Automation, Northwestern Polytechnical University, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1535","1539","Ontology-based documents classification method is introduced to solve the problem of classifier training and not considering semantic relations between words in traditional Machine Learning algorithms. However, previous work on ontology-based documents classification have some drawbacks on precision and run-time performance. In order to solve these problems, this paper proposes a novel ontology-based documents classification method by using ontology reasoning and similarity measure. Firstly, weighted terms set are extracted from documents, and categories are represented by ontologies; then the lowest concepts for each ontology is computed by using ontology reasoning techniques; next similarity score between documents and ontology is computed by using Google Distance measure; finally, web documents are assigned to categories according to the similarity score. Experimental results show our method is effective when comparing with the current ontology-based classification method, especially in the delicate classification evaluation, and the run-time performance is also better.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569338","","Accuracy;Cognition;Current measurement;Google;Machine learning algorithms;Ontologies;Semantics","document handling;ontologies (artificial intelligence)","documents classification;google distance measure;machine learning algorithms;ontology reasoning;semantic relations;similarity measure;web documents","","0","1","12","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
