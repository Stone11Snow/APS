"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7905453,7900236,7899840,7900105,7906954,7900302,7905839,7905837,7900165,7900000,7899755,7907527,7900220,7905544,7899664,7907464,7900103,7900139,7900298,7905686,7904322,7888438,7906545,7900185,7899844,7899646,7906399,7900187,7899702,7907444,7900012,7887720,7904596,7904689,7897535,7414528,7892928,7897215,7897204,7897263,7897206,7862816,7874158,7723870,7870632,7864423,7895175,7891835,7893333,7893777,7889642,7892681,7893702,7398188,7891896,7890309,7886888,7888298,7889775,7889830,7889681,7889290,7888731,7890387,7890146,7890487,7890445,7890178,7889171,7888183,7889505,7890382,7849143,7828108,7888458,7547326,7885852,7887751,7886726,7886102,7886302,7883675,7883636,7883252,7883684,7884415,7752793,7882969,7885066,7883886,7881503,7881722,7881743,7881532,7881684,7881442,7881329,7880852,7881336,7881453",2017/05/05 22:25:15
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Spatial and rotation invariant 3D gesture recognition based on sparse representation","F. Argelaguet; M. Ducoffe; A. Lécuyer; R. Gribonval","Inria, IRISA, France","2017 IEEE Symposium on 3D User Interfaces (3DUI)","20170406","2017","","","158","167","Advances in motion tracking technology, especially for commodity hardware, still require robust 3D gesture recognition in order to fully exploit the benefits of natural user interfaces. In this paper, we introduce a novel 3D gesture recognition algorithm based on the sparse representation of 3D human motion. The sparse representation of human motion provides a set of features that can be used to efficiently classify gestures in real-time. Compared to existing gesture recognition systems, sparse representation, the proposed approach enables full spatial and rotation invariance and provides high tolerance to noise. Moreover, the proposed classification scheme takes into account the inter-user variability which increases gesture classification accuracy in user-independent scenarios. We validated our approach with existing motion databases for gestural interaction and performed a user evaluation with naive subjects to show its robustness to arbitrarily defined gestures. The results showed that our classification scheme has high classification accuracy for user-independent scenarios even with users who have different handedness. We believe that sparse representation of human motion will pave the way for a new generation of 3D gesture recognition systems in order to fully open the potential of natural user interfaces.","","Electronic:978-1-5090-6716-9; POD:978-1-5090-6717-6","10.1109/3DUI.2017.7893333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893333","I.5.2 [Pattern Recognition]: Design Methodology—Classifier design and evaluation;I.6.3 [Computing Methodologies]: Methodologies and Techniques—Interaction Techniques","Dictionaries;Gesture recognition;Machine learning algorithms;Matching pursuit algorithms;Robustness;Three-dimensional displays;User interfaces","gesture recognition;image classification;image motion analysis;image representation","3D gesture recognition algorithm;3D human motion representation;arbitrarily defined gestures;gesture classification;motion tracking technology;natural user interfaces;sparse representation;user evaluation","","","","","","","18-19 March 2017","","IEEE","IEEE Conference Publications"
"Heterogeneous Sensor Data Fusion By Deep Multimodal Encoding","Z. Liu; W. Zhang; S. Lin; T. Q. S. Quek","Information Systems Technology and Design Pillar, Singapore University, Singapore","IEEE Journal of Selected Topics in Signal Processing","20170412","2017","11","3","479","491","Heterogeneous sensor data fusion is a challenging field that has gathered significant interest in recent years. Two of these challenges are learning from data with missing values, and finding shared representations for multimodal data to improve inference and prediction. In this paper, we propose amultimodal data fusion framework, the deep multimodal encoder (DME), based on deep learning techniques for sensor data compression, missing data imputation, and new modality prediction under multimodal scenarios. While traditional methods capture only the intramodal correlations, DME is able to mine both the intramodal correlations in the initial layers and the enhanced intermodal correlations in the deeper layers. In this way, the statistical structure of sensor data may be better exploited for data compression. By incorporating our new objective function, DME shows remarkable ability for missing data imputation tasks in sensor data. The shared multimodal representation learned by DME may be used directly for predicting new modalities. In experiments with a real-world dataset collected from a 40-node agriculture sensor network which contains three modalities, DME can achieve a root mean square error (RMSE) of missing data imputation which is only 20% of the traditional methods like K-nearest neighbors and sparse principal component analysis and the performance is robust to different missing rates. It can also reconstruct temperature modality from humidity and illuminance with an RMSE of 7 °C, directly from a highly compressed (2.1%) shared representation that was learned from incomplete (80% missing) data.","1932-4553;19324553","","10.1109/JSTSP.2017.2679538","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874158","Deep learning;heterogeneous sensor data;missing data imputation;multimodal data fusion","Correlation;Cost function;Data compression;Data integration;Encoding;Machine learning;Training","learning (artificial intelligence);mean square error methods;sensor fusion;statistical analysis","DME;K-nearest neighbors;RMSE;agriculture sensor network;deep learning techniques;deep multimodal encoding;heterogeneous sensor data fusion;missing data imputation;modality prediction;root mean square error;sensor data compression;sparse principal component analysis","","","","","","20170308","April 2017","","IEEE","IEEE Journals & Magazines"
"Confidence-Based Data Association and Discriminative Deep Appearance Learning for Robust Online Multi-Object Tracking","S. H. Bae; K. J. Yoon","SW&#x00B7;Content Research Laboratory, Electronics and Telecommunications Research Institute, 218 Gajeong-ro, Yuseong-Gu, Daejeon, 34129, South Korea.(email:shbae@etri.re.kr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2017","PP","99","1","1","Online multi-object tracking aims at estimating the tracks of multiple objects instantly with each incoming frame and the information provided up to the moment. It still remains a difficult problem in complex scenes, because of the large ambiguity in associating multiple objects in consecutive frames and the low discriminability between objects appearances. In this paper, we propose a robust online multi-object tracking method that can handle these difficulties effectively. We first define the tracklet confidence using the detectability and continuity of a tracklet, and decompose a multi-object tracking problem into small subproblems based on the tracklet confidence. We then solve the online multi-object tracking problem by associating tracklets and detections in different ways according to their confidence values. Based on this strategy, tracklets sequentially grow with online-provided detections, and fragmented tracklets are linked up with others without any iterative and expensive association steps. For more reliable association between tracklets and detections, we also propose a deep appearance learning method to learn a discriminative appearance model from large training datasets, since the conventional appearance learning methods do not provide rich representation that can distinguish multiple objects with large appearance variations. In addition, we combine online transfer learning for improving appearance discriminability by adapting the pre-trained deep model during online tracking. Experiments with challenging public datasets show distinct performance improvement over other state-of-the-arts batch and online tracking methods, and prove the effect and usefulness of the proposed methods for online multi-object tracking.","0162-8828;01628828","","10.1109/TPAMI.2017.2691769","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893777","Multi-object tracking;confidence-based data association;deep appearance learning;online transfer learning;surveillance system;tracking-by-detection;tracklet confidence","Adaptation models;Learning systems;Machine learning;Robustness;Target tracking;Trajectory","","","","","","","","20170406","","","IEEE","IEEE Early Access Articles"
"Intensified analysis and comparison of 5 flacicirus with the use of decision tree and support vector machine (SVM)","E. Yang; B. Gu; T. Yoon","Natural Science, Hankuk Academy of Foreign Studies, Young-in, South Korea","2017 19th International Conference on Advanced Communication Technology (ICACT)","20170330","2017","","","526","529","Flavivirus is spreaded with the help of intermediary, especially mosquitoes. In preceding research, we found out that Leucine has high frequency. Wanting to know specific relationship between 5 flaviviruses; Yellow fever, West Nile virus, Dengue virus, Tick borne encephalitis, decision tree and support vector machine algorithm were used. Analyzing results of the algorithms, difference or similarity about the viruses and a group as flavivirus were found.","","CD:978-89-968650-8-7; Electronic:978-89-968650-9-4; POD:978-1-5090-4892-2","10.23919/ICACT.2017.7890146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890146","Decision tree algorithm;Dengue virus;Flavivirus;Support Vector Machine(SVM);Tick borne encephalitis;West Nile virus;Yellow fever;Zika virus","Algorithm design and analysis;Classification algorithms;Decision trees;Libraries;Machine learning algorithms;Support vector machines;Viruses (medical)","biology computing;decision trees;microorganisms;support vector machines","Dengue virus;SVM;Tick borne encephalitis;West Nile virus;Yellow fever;decision tree;flacicirus;flavivirus;support vector machine","","","","","","","19-22 Feb. 2017","","IEEE","IEEE Conference Publications"
"Rehabilitation posture correction using deep neural network","Seung-Ho Han; Han-Gyu Kim; Ho-Jin Choi","School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","400","402","The rehabilitation treatment is important because it helps a patient restore physical sensory and mental capabilities. The patient whose symptoms are moderately relieved, or outpatient, usually rehabilitate the individual alone. Improper exercise or posture can slow the recovery of the patient or even worsen the patient's health status when doing rehabilitation exercise alone. The best way is to receive home visiting treatment from professional therapist until cured. However, such way is a burden on the patient in terms of cost. This paper proposes the novel model that corrects the improper postures of the patient when having rehabilitating exercise alone. We use Microsoft Kinect to recognize the posture of the patient by extracting the human skeleton. We will adopt deep neural network to analyze the extracted human skeleton, in order to determine whether the posture is correct or not. The data for training our model will be correct postures and incorrect postures and detailed data collection plan is provided in this paper. The implementation and experiment will be performed in the future work.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881743","deep neural network;posture recognition;rehabilitation","Algorithm design and analysis;Machine learning;Neural networks;Robot sensing systems;Skeleton;Solid modeling","learning (artificial intelligence);medical computing;neural nets;patient rehabilitation;patient treatment;pose estimation","Microsoft Kinect;correct postures;data collection plan;deep neural network;home visiting treatment;human skeleton extraction;incorrect postures;mental capabilities;physical sensory;posture recognition;rehabilitation exercise;rehabilitation posture correction;rehabilitation treatment","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Deep Representation based feature extraction and recovering for Finger-vein verification","H. Qin; M. A. El-Yacoubi","SAMOVAR, Telecom SudParis, CNRS, University Paris Saclay, 9 rue Charles Fourier, 91011 Evry Cedex, France.(email:qin","IEEE Transactions on Information Forensics and Security","","2017","PP","99","1","1","Finger-vein biometrics has been extensively investigated for personal verification. Despite recent advances in fingervein verification, current solutions completely depend on domain knowledge and still lack the robustness to extract finger-vein features from raw images. This paper proposes a deep learning model to extract and recover vein features using limited a priori knowledge. Firstly, based on a combination of known state of the art handcrafted finger-vein image segmentation techniques, we automatically identify two regions: a clear region with high separability between finger-vein patterns and background, and an ambiguous region with low separability between them. The first is associated with pixels on which all the segmentation techniques above assign the same segmentation label (either foreground or background), while the second corresponds to all the remaining pixels. This scheme is used to automatically discard the ambiguous region and to label the pixels of the clear region as foreground or background. A training dataset is constructed based on the patches centered on the labeled pixels. Secondly, a Convolutional Neural Network (CNN) is trained on the resulting dataset to predict the probability of each pixel of being foreground (i.e. vein pixel) given a patch centered on it. The CNN learns what a fingervein pattern is by learning the difference between vein patterns and background ones. The pixels in any region of a test image can then be classified effectively. Thirdly, we propose another new and original contribution by developing and investigating a Fully Convolutional Network (FCN) to recover missing fingervein patterns in the segmented image. The experimental results on two public finger-vein databases show a significant improvement in terms of finger-vein verification accuracy.","1556-6013;15566013","","10.1109/TIFS.2017.2689724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890487","Convolutional Autoencoder;Convolutional Neural Network;Deep Learning;Finger-vein verification;Hand biometrics;Representation learning","Feature extraction;Image segmentation;Iris recognition;Machine learning;Neural networks;Veins","","","","","","","","20170330","","","IEEE","IEEE Early Access Articles"
"Ultrasound Standard Plane Detection Using a Composite Neural Network Framework","H. Chen; L. Wu; Q. Dou; J. Qin; S. Li; J. Z. Cheng; D. Ni; P. A. Heng","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong.","IEEE Transactions on Cybernetics","","2017","PP","99","1","11","Ultrasound (US) imaging is a widely used screening tool for obstetric examination and diagnosis. Accurate acquisition of fetal standard planes with key anatomical structures is very crucial for substantial biometric measurement and diagnosis. However, the standard plane acquisition is a labor-intensive task and requires operator equipped with a thorough knowledge of fetal anatomy. Therefore, automatic approaches are highly demanded in clinical practice to alleviate the workload and boost the examination efficiency. The automatic detection of standard planes from US videos remains a challenging problem due to the high intraclass and low interclass variations of standard planes, and the relatively low image quality. Unlike previous studies which were specifically designed for individual anatomical standard planes, respectively, we present a general framework for the automatic identification of different standard planes from US videos. Distinct from conventional way that devises hand-crafted visual features for detection, our framework explores in- and between-plane feature learning with a novel composite framework of the convolutional and recurrent neural networks. To further address the issue of limited training data, a multitask learning framework is implemented to exploit common knowledge across detection tasks of distinctive standard planes for the augmentation of feature learning. Extensive experiments have been conducted on hundreds of US fetus videos to corroborate the better efficacy of the proposed framework on the difficult standard plane detection problem.","2168-2267;21682267","","10.1109/TCYB.2017.2685080","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890445","Convolutional neural network (CNN);deep learning;knowledge transfer;recurrent neural network (RNN);standard plane;ultrasound (US)","Biomedical imaging;Feature extraction;Fetus;Machine learning;Standards;Training data;Videos","","","","","","","","20170330","","","IEEE","IEEE Early Access Articles"
"Capturing High Discriminative Fault Features for Electronics-rich Analog System via Deep Learning","Z. Liu; Z. Jia; C. M. Vong; S. Bu; J. Han; X. Tang","","IEEE Transactions on Industrial Informatics","","2017","PP","99","1","1","Fault detection and isolation (FDI) is very difficult for electronics-rich analog systems due to its sophisticated mechanism and variable operational conditions. Traditionally, FDI in such systems is done through the monitoring of deviation of output signals in voltage or current at system level, which commonly arises from the degradation of one or more critical components. Therefore, FDI can be transformed to a multi-class classification task given the extracted features of the output signals in voltage or current of the circuit. Traditional feature extraction on the circuit output are mostly based on time-domain, frequencydomain, or time-frequency signal processing, which collapse high dimensional raw signals into a lower dimensional feature set. Such low dimensional feature set usually suffers from information loss so as to affect the accuracy of the later fault diagnosis. In order to retain as much information as possible, deep learning is proposed which employs a hierarchical structure to capture different levels of semantic representations of the signals. In this paper, a novel fault diagnostic application of Gaussian-Bernoulli deep belief network (GB-DBN) for electronics-rich analog systems is developed which can more effectively capture the high order semantic features within the raw output signals. The novel fault diagnosis is validated experimentally on two typical analog filter circuits. Experimental results show the fault diagnosis based on GB-DBN is with superior diagnostic performance than the traditional feature extraction methods.","1551-3203;15513203","","10.1109/TII.2017.2690940","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7891896","Analog circuits;Deep Belief Network;Deep Learning;Diagnosis;Failure;Fault;Restricted Boltzmann Machines","Analog circuits;Circuit faults;Fault diagnosis;Feature extraction;Machine learning;Time-frequency analysis","","","","","","","","20170404","","","IEEE","IEEE Early Access Articles"
"String vector based AHC for text clustering","T. Jo","Department of Computer and Information Communication Engineering, Hongik University, Sejong, South Korea","2017 19th International Conference on Advanced Communication Technology (ICACT)","20170330","2017","","","673","678","In this research, we propose the string vector based version of AHC algorithm as the approach to the text clustering. Using the traditional version leads to the three main problems: huge dimensionality, sparse distribution, poor transparency, since texts need to be encoded into numerical vectors. In order to solve the problems, in this research, we encode texts into string vectors, define the similarity measure between them, and modify the AHC algorithm into the version where a string vector is given as its input. As the benefits from this research, we expect the better performance, the more compact representation, and the better transparency. Hence, this research is intended to improve the text clustering performance, by solving the problems.","","CD:978-89-968650-8-7; Electronic:978-89-968650-9-4; POD:978-1-5090-4892-2","10.23919/ICACT.2017.7890178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890178","Semantic Similarity Similarity;String Vector;String Vector based AHC;Text Clustering","Clustering algorithms;Encoding;Kernel;Machine learning algorithms;Semantics;Support vector machines;Text categorization","pattern clustering;text analysis;vectors","numerical vectors;similarity measure;string vector based AHC;text clustering","","","","","","","19-22 Feb. 2017","","IEEE","IEEE Conference Publications"
"A novel artificial fish swarm algorithm for pattern recognition with convex optimization","L. Shi; R. Guo; Y. Ma","Peking University, Beijing, China","2016 International Conference on Communication and Electronics Systems (ICCES)","20170330","2016","","","1","4","Image pattern recognition is an important area in digital image processing. An efficient pattern recognition algorithm should be able to provide correct recognition at a reduced computational time. Off late amongst the machine learning pattern recognition algorithms, Artificial fish swarm algorithm is one of the swarm intelligence optimization algorithms that works based on population and stochastic search. In order to achieve acceptable result, there are many parameters needs to be adjusted in AFSA. Among these parameters, visual and step are very significant in view of the fact that artificial fish basically move based on these parameters. In standard AFSA, these two parameters remain constant until the algorithm termination. Large values of these parameters increase the capability of algorithm in global search, while small values improve the local search ability of the algorithm. In this paper, we empirically study the performance of the AFSA and different approaches to balance between local and global exploration have been tested based on the adaptive modification of visual and step during algorithm execution. The proposed approaches have been evaluated based on the four well-known benchmark functions. Experimental results show considerable positive impact on the performance of AFSA. A Convex optimization has been integrated into the proposed work to have an ideal segmentation of the input image which is a MR brain image.","","DVD:978-1-5090-1064-6; Electronic:978-1-5090-1066-0; POD:978-1-5090-1067-7; Paper:978-1-5090-1065-3","10.1109/CESYS.2016.7889830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889830","Image segmentation;convex optimization;fish school algorithms;recognition rates","Algorithm design and analysis;Feature extraction;Fish;Image segmentation;Machine learning algorithms;Neural networks;Pattern recognition","computer vision;convex programming;image recognition;learning (artificial intelligence)","AFSA performance;MR brain image;artificial fish swarm algorithm;convex optimization;image pattern recognition;machine learning pattern recognition algorithms;swarm intelligence optimization algorithms","","","","","","","21-22 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Data-Driven Soft Sensor Modeling Method Based on Deep Learning and its Application","W. Yan; D. Tang; Y. Lin","Department of Automation, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Industrial Electronics","20170412","2017","64","5","4237","4245","Soft sensors have been widely used in industrial processes. The core issue of data-driven soft sensors is building soft sensor models with excellent performance and robustness. This paper introduces deep learning to soft sensor modeling and proposes a novel soft sensor modeling method based on a deep learning network that integrates denoising autoencoders with a neural network (DAE-NN). An improved gradient descent is employed to update the model parameters. The proposed modeling method is able to capture the essential information of input data through deep architecture, building soft sensors with excellent performance. The DAE-NN-based soft sensor is applied in practical applications to estimate the oxygen content in flue gasses in 1000-MW ultrasuperficial units. Comparing conventional soft sensor modeling methods, i.e., shallow learning methods, DAE-NN-based soft sensor significantly improves the performance and generalization of data-driven soft sensors. Deep learning provides a very effective and promising method for soft sensor modeling.","0278-0046;02780046","","10.1109/TIE.2016.2622668","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723870","Deep learning;denoising autoencoder (DAE);soft sensor;unlabeled data","Biological system modeling;Computational modeling;Data models;Machine learning;Noise reduction;Robustness;Training","gradient methods;industrial engineering;learning (artificial intelligence);neural nets","DAE-NN;data-driven soft sensor modeling;deep learning network;denoising autoencoders;gradient descent method;industrial process;neural network;robustness","","","","","","20161027","May 2017","","IEEE","IEEE Journals & Magazines"
"A deep learning model for predicting transcription factor binding location at single nucleotide resolution","S. Salekin; J. M. Zhang; Y. Huang","Electrical and Computer Engineering Department, University of Texas at San Antonio, 1 UTSA Circle, San Antonio, TX 78249, USA","2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","20170413","2017","","","57","60","Transcriptional regulation by transcription factors (TFs) plays a pivotal role in controlling the gene expression. However, understanding the mechanism through which the transcription factors regulate the gene expression is a challenging task. This is primarily hindered by the low specificity in identifying transcription factor binding sites (TFBS). The emergence of the ChIP-exonuclease (ChIP-exo) method enables the detection of TFBS at single nucleotide sensitivity, providing us an opportunity to study the detailed mechanisms of TF regulation. Nevertheless, there is still a lack of computational tools that can also provide single base pair (bp) resolution prediction of TFBS. In this paper, we propose DeepSNR, a Deep Learning algorithm for Single Nucleotide Resolution prediction of transcription factor binding site. Our proposed method is inspired by the similarity between predicting the specific binding location from input nucleotide sequence and image segmentation. Particularly, we adopted the deconvolution network (deconvNet); a deep learning model designed for image segmentation, and developed a TFBS specific deconvNet architecture constructed on top of ‘DeepBind’. We trained a deconvNet for predicting CTCF binding sites using the data from ChIP-exo experiments. The proposed algorithm achieved median precision and recall of 87% and 77% respectively, significantly outperforming motif search based algorithms such as MatInspector.","","Electronic:978-1-5090-4179-4; POD:978-1-5090-4180-0","10.1109/BHI.2017.7897204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897204","","Algorithm design and analysis;Bioinformatics;DNA;Deconvolution;Genomics;Machine learning;Training","","","","","","","","","16-19 Feb. 2017","","IEEE","IEEE Conference Publications"
"A deep convolutional neural network and a random forest classifier for solar photovoltaic array detection in aerial imagery","J. M. Malof; L. M. Collins; K. Bradbury; R. G. Newell","Electrical and Computer Engineering, Duke University, Durham, NC, USA","2016 IEEE International Conference on Renewable Energy Research and Applications (ICRERA)","20170323","2016","","","650","654","Power generation from distributed solar photovoltaic PV arrays has grown rapidly in recent years. As a result, there is interest in collecting information about the quantity, power capacity, and energy generated by such arrays; and to do so over small geo-spatial regions (e.g., counties, cities, or even smaller regions). Unfortunately, existing sources of such information are dispersed, limited in geospatial resolution, and otherwise incomplete or publically unavailable. As result, we recently proposed a new approach for collecting such distributed PV information that relies on computer algorithms to automatically detect PV arrays in high resolution aerial imagery [1], Here we build on this work by investigating two machine learning algorithms for PV array detection: a Random Forest classifier (RF) [2] and a deep convolutional neural network (CNN) [3]. We use the RF algorithm as a benchmark, or baseline, for comparison with a CNN model. The two models are developed and tested using a large collection of publicly available [4] aerial imagery, covering 135 km<sup>2</sup>, and including over 2,700 manually annotated distributed PV array locations. The results indicate that the CNN substantially improves over the RF. The CNN is capable of excellent performance, detecting nearly 80% of true panels with a precision measure of 72%.","","Electronic:978-1-5090-3388-1; POD:978-1-5090-3389-8","10.1109/ICRERA.2016.7884415","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884415","convolutional neural networks;deep learning;detection;energy;photovoltaic;solar","Biological neural networks;Decision support systems;Machine learning;Photovoltaic systems;Power systems","neural nets;pattern classification;power engineering computing;solar cell arrays","CNN model;RF algorithm;deep convolutional neural network;distributed PV information collection;high-resolution aerial imagery;random forest classifier;solar photovoltaic array detection","","","","","","","20-23 Nov. 2016","","IEEE","IEEE Conference Publications"
"Grammatical Inference System for Finite State Automata - GIFSA","C. Kara-Mohamed; A. Hamdi-Cherif; H. Al'Alwi; K. Al-Khalifa; N. Al-Harbi","Comput. Coll., Qassim Univ., Buraydah, Saudi Arabia","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1274","1279","As a first step toward the development of a general grammatical inference (GI) software environment, GIFSA represents an integrated system for inferring finite state automata (FSA). Using the unified modeling language (UML), GIFSA offers a continuously upgradable software system initially implementing two AI-based algorithms, namely the tabu search method and the minimum description length (MDL) principle. For portability reasons, Java™ programming language is used for development, enhanced by a friendly graphical user interface (GUI).","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881532","Finite State Automata (FSA);Grammatical Inference (GI);UML Design","Algorithm design and analysis;Automata;Inference algorithms;MATLAB;Machine learning algorithms;Software algorithms","Unified Modeling Language;description logic;finite automata;inference mechanisms;search problems","AI-based algorithms;GIFSA;GUI;Java programming language;MDL principle;UML;finite state automata;grammatical inference software environment;grammatical inference system;graphical user interface;minimum description length principle;tabu search method;unified modeling language","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Instance-specific algorithm selection via multi-output learning","K. Chen; Y. Dou; Q. Lv; Z. Liang","National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha 410037, China","Tsinghua Science and Technology","20170406","2017","22","2","210","217","Instance-specific algorithm selection technologies have been successfully used in many research fields, such as constraint satisfaction and planning. Researchers have been increasingly trying to model the potential relations between different candidate algorithms for the algorithm selection. In this study, we propose an instancespecific algorithm selection method based on multi-output learning, which can manage these relations more directly. Three kinds of multi-output learning methods are used to predict the performances of the candidate algorithms: (1) multi-output regressor stacking; (2) multi-output extremely randomized trees; and (3) hybrid single-output and multioutput trees. The experimental results obtained using 11 SAT datasets and 5 MaxSAT datasets indicate that our proposed methods can obtain a better performance over the state-of-the-art algorithm selection methods.","","","10.23919/TST.2017.7889642","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889642","algorithm selection; multi-output learning; extremely randomized trees; performance prediction;constraint satisfaction","Clustering algorithms;Feature extraction;Machine learning algorithms;Prediction algorithms;Regression tree analysis;Stacking;Vegetation","","","","","","","","","April 2017","","TUP","TUP Journals & Magazines"
"DP-miRNA: An improved prediction of precursor microRNA using deep learning model","J. Thomas; S. Thomas; L. Sael","Department of Computer Science, Stony Brook University, NY 11794, USA","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","96","99","MicroRNA (miRNA) are small non-coding RNAs regulating gene expression at the post-transcriptional level. Detecting miRNA in a genome is challenging experimentally and results vary depending on their cellular environment. These limitations inspire the development of knowledge-based prediction method. This paper proposes a deep learning based classification model for predicting precursor miRNA sequence that contains the miRNA sequence. The feature set consists of sequence features, folding measures, stem-loop features and statistical features. We evaluate the performance of the proposed method on human dataset. The deep neural network based classification outperformed support vector machine, neural network, naive Bayes classifiers, k-nearest neighbors, random forests as well as hybrid systems combining SVM and genetic algorithm.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881722","","Computer science;Machine learning;Neural networks;Predictive models;Proteins;Support vector machines;Training","Bayes methods;RNA;biology computing;cellular biophysics;genetic algorithms;knowledge based systems;learning (artificial intelligence);neural nets;random processes;statistical analysis;support vector machines","DP-miRNA;Naive Bayes classifiers;SVM;cellular environment;deep learning based classification model;deep learning model;deep neural network based classification;folding measures;gene expression;genetic algorithm;genome miRNA detection;human dataset;hybrid systems;k-nearest neighbors;knowledge-based prediction method;noncoding RNA;post-transcriptional level;precursor microRNA prediction;random forests;sequence features;statistical features;stem-loop features;support vector machine","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Hardware implementation of Hierarchical Temporal Memory algorithm","W. Li; P. Franzon","Department of Electrical Engineering, North Carolina State University, Raleigh, USA","2016 29th IEEE International System-on-Chip Conference (SOCC)","20170424","2016","","","133","138","In this paper, a hardware ASIC implementation of the Numenta Hierarchical Temporal Memory (HTM) algorithm is presented. Each column in the neural network is implemented as a processing element (PE). Neuron cells in columns are built as identical cell modules. Dedicated register files for each module cell are employed to replace the conventional centralized memory organization. A complete neural network is built as a matrix of PEs connected in the mesh network. Both first order and high order network are successfully performed on a 20×20 PE matrix using images from MNIST dataset as input patterns. The power and area of a single PE including 2 cell modules are 1.29 mW and 17511 µm<sup>2</sup> respectively. The average processing time in the proposed implementation is 4.52 µs in learning mode and 4.39 µs in inference mode. Compared to the performance of a software implementation on the 4 threads CPU, the ASIC version provides a 329.6× speedup in learning mode.","","Electronic:978-1-5090-1367-8; POD:978-1-5090-1368-5; USB:978-1-5090-1366-1","10.1109/SOCC.2016.7905453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905453","ASIC Design;Distributed Memory;HTM Network;MNIST Dataset","Biological neural networks;Hardware;Machine learning algorithms;Memory management;Mesh networks;Neurons;Pattern recognition","","","","","","","","","6-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Person re-identification via person DPM based partition","Shaomei Li; Chao Gao; Hongtao Yu; Jianpeng Zhang","National Digital Switching System Engineering and Technological Research and Development Center, Zhengzhou, China","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3856","3861","In surveillance videos, the pictures of a same person often present significant variation which makes person re-identification difficult. Though the globe appearances may present great difference, some local patches still have great similarities, and human eyes can be used to distinguish the identity of each person via these local patches. Inspired from it, patch matching is introduced in person re-identification and has been shown to be an efficient method to solve these problems caused by different viewpoints, poses, camera settings, illumination and occlusion. But until now there is no guide for how to decide the size of patch, and most researches got these patches either by dense sampling or coarse partition. In both case, the person structure information is missing. To improve re-identification accuracy, we propose a method via person DPM (Deformable Parts Model) partition. First, both compared appearances are partitioned into several body parts by pre-trained person DPM and these parts are grouped according to their positions in the body; Second, part matching is conducted between two appearances' parts in each group based on deep learning features; Finally, fusing the similarities of each group are to decide whether these two appearances are from the same person or not. Experiments on VIPeR dataset illustrate that without supervised training, the proposed method can obtain good re-identification performances compared with state-of-the-art methods.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900236","Deep learning feature;Deformable Part Model;Part matching;Person re-identification","Feature extraction;Head;Image color analysis;Machine learning;Measurement;Surveillance;Videos","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Design of Continuous Learning System Based on Knowledge Augmentation","H. Kang; S. H. Kwon; E. J. Kim; H. Kim; H. S. Lee; K. Kim; N. s. Kim","KSB Convergence Res. Dept., Electron. & Telecommun. Res. Inst., Daejeon, South Korea","2017 International Conference on Platform Technology and Service (PlatCon)","20170323","2017","","","1","4","To create an algorithm with Machine Learning, users should understand all the knowledge such as learning rate, activation, dimension reduction, hyper parameter, neural network, etc. Therefore, in order to construct a machine learning procedure, expert knowledge is required. So, it is difficult for general users to use it. Also, experts are also hard to regenerate well-defined model if it is described only in the paper. In this paper, we propose a knowledge based Continuous Learning System (CLS) which persistently collect and infer new knowledge from information for the existing learning setup and results instantiated based on a hierarchically designed ontology model.","","Electronic:978-1-5090-5140-3; POD:978-1-5090-5141-0","10.1109/PlatCon.2017.7883675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883675","","Concrete;Engines;Libraries;Load modeling;Machine learning algorithms;Ontologies","knowledge acquisition;learning (artificial intelligence);ontologies (artificial intelligence)","continuous learning system design;expert knowledge;hierarchically designed ontology model;knowledge augmentation;machine learning","","","","","","","13-15 Feb. 2017","","IEEE","IEEE Conference Publications"
"Learning face recognition from limited training data using deep neural networks","X. Peng; N. Ratha; S. Pankanti","Department of Computer Science, Rutgers University, Piscataway, New Jersey 08854, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1442","1447","Often deep learning methods are associated with huge amounts of training data. The deeper the network gets, the larger is the need for training data. A large amount of labeled data helps the network learn about the variations it needs to handle in the prediction stage. It is not easy for everyone to get access to huge amounts of labeled data leaving a few to have the luxury to design very deep networks. In this paper, we propose to flatten the disparity by using the modeling methods to minimize the need for huge amounts of data for training a deep network. Using face recognition as an example, we demonstrate how limited labeled data can be leveraged to obtain near state of the art performance with generalization capability across multiple databases. In addition, we show that the normalization in the overall network can improve the speed and resource requirement for the prediction/inferencing stage.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899840","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899840","","Face;Face recognition;Feature extraction;Image recognition;Machine learning;Training;Training data","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Retrieving relative soft biometrics for semantic identification","D. Martinho-Corbishley; M. S. Nixon; J. N. Carter","School of Electronics and Computer Science, University of Southampton, United Kingdom","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3067","3072","Automatically describing pedestrians in surveillance footage is crucial to facilitate human accessible solutions for suspect identification. We aim to identify pedestrians based solely on human description, by automatically retrieving semantic attributes from surveillance images, alleviating exhaustive label annotation. This work unites a deep learning solution with relative soft biometric labels, to accurately retrieve more discriminative image attributes. We propose a Semantic Retrieval Convolutional Neural Network to investigate automatic retrieval of three soft biometric modalities, across a number of ‘closed-world’ and ‘open-world’ re-identification scenarios. Findings suggest that relative-continuous labels are more accurately predicted than absolute-binary and relative-binary labels, improving semantic identification in every scenario. Furthermore, we demonstrate a top rank-1 improvement of 23.2% and 26.3% over a traditional, baseline retrieval approach, in one-shot and multi-shot re-identification scenarios respectively.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900105","","Biometrics (access control);Cameras;Machine learning;Neural networks;Semantics;Surveillance;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep Learning for target recognition from SAR images","A. El Housseini; A. Toumi; A. Khenchaf","Lab-STICC UMR CNRS 6285, ENSTA Bretagne, Brest, France","2017 Seminar on Detection Systems Architectures and Technologies (DAT)","20170330","2017","","","1","5","This paper deals with the problematic of automatic target recognition (ATR) using Synthetic Aperture Radar (SAR) images. In this work, the Deep Learning (DL) architecture is proposed and applied in order to recognize military vehicles from SAR images. We propose mainly in this work the deep learning algorithms based on convolutional neural network architecture. In the second step and in order to optimize the convolution of DL steps, we propose to use a convolutional auto-encoder which may be better suited to image processing. Its use provides several areas of the best results in the presence of noise on shifted and truncated images. To validate our approach, some experimentation results are given and compared. The obtained results show that the proposed approach of DL achieves a height recognition accuracy of 93%.","","Electronic:978-1-5090-4508-2; POD:978-1-5090-4509-9","10.1109/DAT.2017.7889171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889171","Deep learning;Pattern recognition;SAR images;Target recognition","Computer architecture;Convolution;Feature extraction;Machine learning;Neural networks;Synthetic aperture radar;Target recognition","","","","","","","","","20-22 Feb. 2017","","IEEE","IEEE Conference Publications"
"Sampling and partitioning for differential privacy","H. Ebadi; T. Antignac; D. Sands","Chalmers University of Technology, G&#x00F6;teborg, Sweden","2016 14th Annual Conference on Privacy, Security and Trust (PST)","20170424","2016","","","664","673","Differential privacy enjoys increasing popularity thanks to both a precise semantics for privacy and effective enforcement mechanisms. Many tools have been proposed to spread its use and ease the task of the concerned data scientist. The most promising among them completely discharge the user of the privacy concerns by transparently taking care of the privacy budget. However, their implementation proves to be delicate, and introduce flaws by falsifying some of the theoretical assumptions made to guarantee differential privacy. Moreover, such tools rely on assumptions leading to over-approximations which artificially reduce utility. In this paper we focus on a key mechanism that tools do not support well: sampling. We demonstrate an attack on PINQ (McSherry, SIGMOD 2009), one of these tools, relying on the difference between its internal mechanics and the formal theory for the sampling operation, and study a range of sampling methods and show how they can be correctly implemented in a system for differential privacy.","","Electronic:978-1-5090-4379-8; POD:978-1-5090-4380-4","10.1109/PST.2016.7906954","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7906954","","Data privacy;Machine learning algorithms;Privacy;Sampling methods;Sensitivity;Sociology","","","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"Audio recording device identification based on deep learning","S. Qi; Z. Huang; Y. Li; S. Shi","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, P.R. China","2016 IEEE International Conference on Signal and Image Processing (ICSIP)","20170330","2016","","","426","431","In this paper we present a research on identification of audio recording devices from background noise, thus providing a method for forensics. The audio signal is the sum of speech signal and noise signal. Usually, people pay more attention to speech signal, because it carries the information to deliver. So a great amount of researches have been dedicated to getting higher Signal-Noise-Ratio (SNR). There are many speech enhancement algorithms to improve the quality of the speech, which can be seen as reducing the noise. However, noises can be regarded as the intrinsic fingerprint traces of an audio recording device. These digital traces can be characterized and identified by new machine learning techniques. Therefore, in our research, we use the noise as the intrinsic features. As for the identification, multiple classifiers of deep learning methods are used and compared. The identification result shows that the method of getting feature vector from the noise of each device and identifying them with deep learning techniques is viable, and well-preformed.","","CD:978-1-5090-2375-2; Electronic:978-1-5090-2377-6; POD:978-1-5090-2378-3","10.1109/SIPROCESS.2016.7888298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888298","audio forensic;deep learning;device detection","Audio recording;Classification algorithms;Feature extraction;Machine learning;Noise measurement;Object recognition;Speech","audio recording;learning (artificial intelligence);pattern classification;speech enhancement","audio recording device identification;background noise;deep learning;machine learning technique;noise signal;signal-noise ratio;speech enhancement algorithm;speech signal","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Selection of robust features for the Cover Source Mismatch problem in 3D steganalysis","Z. Li; A. G. Bors","Department of Computer Science, University of York, UK YO10 5GH","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","4256","4261","This paper introduces a novel method for extracting sets of feature from 3D objects characterising a robust steganalyzer. Specifically, the proposed steganalyzer should mitigate the Cover Source Mismatch (CSM) paradigm. A steganalyzer is considered as a classifier aiming to identify separately cover and stego objects. A steganalyzer behaves as a classifier by considering a set of features extracted from cover stego pairs of 3D objects as inputs during the training stage. However, during the testing stage, the steganalyzer would have to identify whether specific information was hidden in a set of 3D objects which can be different from those used during the training. Addressing the CSM paradigm corresponds to testing the generalization ability of the steganalyzer when introducing distortions in the cover objects before hiding information through steganography. Our method aims to select those 3D features that model best the changes introduced in objects by steganography or information hiding and moreover they are able to generalize for different objects, not present in the training set. The proposed robust steganalysis approach is tested when considering changes in 3D objects such as those produced by mesh simplification and additive noise. The results obtained from this study show that the steganalyzers trained with the selected set of robust features achieve better detection accuracy of the changes embedded in the objects, when compared to other sets of features.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900302","3D Steganalysis;Cover Source Mismatch;Feature Selection","Correlation;Feature extraction;Machine learning algorithms;Robustness;Testing;Three-dimensional displays;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Mosquito larva classification method based on convolutional neural networks","A. Sanchez-Ortiz; A. Fierro-Radilla; A. Arista-Jalife; M. Cedillo-Hernandez; M. Nakano-Miyatake; D. Robles-Camarillo; V. Cuatepotzo-Jiménez","ESIME Culhuacan, Instituto Polit&#x00E9;cnico Nacional, Mexico City, Mexico","2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)","20170406","2017","","","1","6","In Mexico a great number of diseases spread by the mosquitos Aedes has been reported. There are some regions on the country that this number is alarming. The spread of this disease becomes a public health problem and the government is worried about this situation and applied some methods for reducing the infection rate. One of principal methods relies on the localization of the mosquito's larvae and then fumigates them. The localization of Aedes larvae is accomplished through state programs which take a considerable time, making them not efficient enough. In this paper we propose a novel method based on convolutional neural networks, where a dataset of larva is used in training in order that the machine learns two types of mosquitos, genus Aedes and “others” genera. The digital images of larva are processed using a set of machine learning algorithms and as a result, the classification task is done. The proposed method would make the larva identification process more efficient, automatic and faster than the conventional methods, and thus the infection rates would be decrease. The results show a good performance on Aedes larva identification, proving that the system can be applied in the real world.","","Electronic:978-1-5090-3621-9; POD:978-1-5090-3622-6","10.1109/CONIELECOMP.2017.7891835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7891835","Aedes;classification;convolutional neural networks;larva;mosquito","Diseases;Image classification;Image segmentation;Machine learning;Microscopy;Neural networks;Training","biology computing;diseases;feedforward neural nets;image classification;learning (artificial intelligence)","Aedes larvae;Mexico;convolutional neural networks;digital image processing;diseases;larva identification process;machine learning;mosquito larva classification method;mosquito larvae localization;training","","","","","","","22-24 Feb. 2017","","IEEE","IEEE Conference Publications"
"City-Wide Traffic Flow Estimation From a Limited Number of Low-Quality Cameras","T. Idé; T. Katsuki; T. Morimura; R. Morris","IBM Thomas J. Watson Research Center, IBM Research, Yorktown Heights, NY, USA","IEEE Transactions on Intelligent Transportation Systems","20170327","2017","18","4","950","959","We present a new approach to lightweight intelligent transportation systems. Our approach does not rely on traditional expensive infrastructures, but rather on advanced machine learning algorithms. It takes images from traffic cameras at a limited number of locations and estimates the traffic over the entire road network. Our approach features two main algorithms. The first is a probabilistic vehicle counting algorithm from low-quality images that falls into the category of unsupervised learning. The other is a network inference algorithm based on an inverse Markov chain formulation that infers the traffic at arbitrary links from a limited number of observations. We evaluated our approach on two different traffic data sets, one acquired in Nairobi, Kenya, and the other in Kyoto, Japan.","1524-9050;15249050","","10.1109/TITS.2016.2597160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547326","Gaussian mixtures;image analysis;inverse Markov problem;object counting;variational Bayes","Estimation;Inference algorithms;Machine learning algorithms;Monitoring;Vehicles;Webcams","Markov processes;cameras;image processing;intelligent transportation systems;unsupervised learning","Japan;Kenya;Kyoto;Nairobi;advanced machine learning algorithms;city-wide traffic flow estimation;inverse Markov chain formula;lightweight intelligent transportation systems;low-quality cameras;low-quality images;probabilistic vehicle counting algorithm;traffic cameras;traffic data sets;unsupervised learning","","","","","","20160818","April 2017","","IEEE","IEEE Journals & Magazines"
"Deep learning based image super-resolution with coupled backpropagation","T. Guo; H. S. Mousavi; V. Monga","Department of Electrical Engineering, The Pennsylvania State University","2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","20170424","2016","","","237","241","Recently deep learning methods have been applied to image super-resolution (SR). Typically, these approaches involve training a single convolutional neural network that is trained to perform resolution enhancement. We propose a new low-complexity but effective algorithm called Superresolution with Coupled Backpropagation (SR-CBP) which builds two Coupled Auto-encoder Networks (CAN), resp. the high-resolution (HR) and low-resolution (LR) networks, that capture the features of both high and low resolution images. The two networks in CAN have the ability to self-reconstruct its own input. Specifically, SR-CBP allows joint training of the LR and HR networks to have middle layer representations that agree for a pair of images (high-resolution image and its corresponding low-resolution version). For an LR input image, its middle layer representation obtained via the trained LR network can be fed into the HR network to generate the SR result. Preliminary experiments show that SR-CBP can produce better results than state of the art single image superresolution methods based on sparse representations. The memory and storage requirements of CAN are lesser than existing deep learning based SR methods.","","Electronic:978-1-5090-4545-7; POD:978-1-5090-4546-4; USB:978-1-5090-4544-0","10.1109/GlobalSIP.2016.7905839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905839","Deep learning;image super-resolution","Backpropagation;Cost function;Dictionaries;Encoding;Image resolution;Machine learning;Training","","","","","","","","","7-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Towards the design of an end-to-end automated system for image and video-based recognition","R. Chellappa; J. C. Chen; R. Ranjan; S. Sankaranarayanan; A. Kumar; V. M. Patel; C. D. Castillo","Department of ECE and the Center for Automation Research, UMIACS, University of Maryland, College Park, MD USA","2016 Information Theory and Applications Workshop (ITA)","20170330","2016","","","1","7","Over many decades, researchers working in object recognition have longed for an end-to-end automated system that will simply accept 2D or 3D image or videos as inputs and output the labels of objects in the input data. Computer vision methods that use representations derived based on geometric, radiometric and neural considerations and statistical and structural matchers and artificial neural network-based methods where a multi-layer network learns the mapping from inputs to class labels have provided competing approaches for image recognition problems. Over the last four years, methods based on Deep Convolutional Neural Networks (DCNNs) have shown impressive performance improvements on object detection/recognition challenge problems. This has been made possible due to the availability of large annotated data, a better understanding of the non-linear mapping between image and class labels as well as the affordability of GPUs. In this paper, we present a brief history of developments in computer vision and artificial neural networks over the last forty years for the problem of image-based recognition. We then present the design details of a deep learning system for end-to-end unconstrained face verification/recognition. Some open issues regarding DCNNs for object recognition problems are then discussed. We caution the readers that the views expressed in this paper are from the authors and authors only!","","Electronic:978-1-5090-2529-9; POD:978-1-5090-2530-5","10.1109/ITA.2016.7888183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888183","","Computer vision;Face;Feature extraction;Image recognition;Machine learning;Object recognition;Videos","computer vision;convolution;face recognition;image representation;learning (artificial intelligence);neural nets;object detection;object recognition;video signal processing","DCNNs;artificial neural network;computer vision;deep convolutional neural networks;deep learning system;end-to-end automated system;end-to-end unconstrained face recognition;geometric considerations;image representations;image-based recognition;multilayer network;neural considerations;object detection;object recognition;radiometric considerations;statistical matchers;structural matchers;video-based recognition","","","","","","","Jan. 31 2016-Feb. 5 2016","","IEEE","IEEE Conference Publications"
"Comparison of Random Forest and SVM for electrical short-term load forecast with different data sources","Juan Huo; Tingting Shi; Jing Chang","School of Electrical Engineering, Zhengzhou University, Henan Province, China","2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20170323","2016","","","1077","1080","There is always argument about which machine learning algorithm is the best one for electrical load forecast. Here in this paper, we compare two open-source machine learning algorithm SVM(Support Vector Machine) and RFR(Random Forest Regression). We evaluate their difference by implementing them into different data sets. We clarify that both SVM and RFR are excellent choices for electrical load forecast, however, their good performance is parameter and data dependent. Parameter setting is more important for SVM than RFR.","","Electronic:978-1-4673-9904-3; POD:978-1-4673-9905-0","10.1109/ICSESS.2016.7883252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883252","Random Forest Regression;SVM;load forecast","Load forecasting;Machine learning algorithms;Support vector machines;Time series analysis;Urban areas","learning (artificial intelligence);load forecasting;power engineering computing;random processes;regression analysis;support vector machines","RFR;SVM;electrical short-term load forecasting;open-source machine learning algorithm;random forest regression;support vector machine","","","","","","","26-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Onsager-corrected deep learning for sparse linear inverse problems","M. Borgerding; P. Schniter","Dept. of ECE, The Ohio State University, Columbus, OH 43202","2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","20170424","2016","","","227","231","Deep learning has gained great popularity due to its widespread success on many inference problems. We consider the application of deep learning to the sparse linear inverse problem encountered in compressive sensing, where one seeks to recover a sparse signal from a small number of noisy linear measurements. In this paper, we propose a novel neural-network architecture that decouples prediction errors across layers in the same way that the approximate message passing (AMP) algorithm decouples them across iterations: through Onsager correction. Numerical experiments suggest that our “learned AMP” network significantly improves upon Gregor and Le-Cun's “learned ISTA” network in both accuracy and complexity.<sup>1</sup>","","Electronic:978-1-5090-4545-7; POD:978-1-5090-4546-4; USB:978-1-5090-4544-0","10.1109/GlobalSIP.2016.7905837","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905837","Deep learning;approximate message passing;compressive sensing;sparse coding","Approximation algorithms;Inverse problems;Machine learning;Message passing;Neural networks;Noise reduction;Training data","","","","","","","","","7-9 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep learning features for handwritten keyword spotting","B. Wicht; A. Fischer; J. Hennebert","University of Fribourg, Switzerland","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3434","3439","Deep learning had a significant impact on diverse pattern recognition tasks in the recent past. In this paper, we investigate its potential for keyword spotting in handwritten documents by designing a novel feature extraction system based on Convolutional Deep Belief Networks. Sliding window features are learned from word images in an unsupervised manner. The proposed features are evaluated both for template-based word spotting with Dynamic Time Warping and for learning-based word spotting with Hidden Markov Models. In an experimental evaluation on three benchmark data sets with historical and modern handwriting, it is shown that the proposed learned features outperform three standard sets of handcrafted features.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900165","","Computational modeling;Feature extraction;Hidden Markov models;Image segmentation;Machine learning;Training;Writing","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Person re-identification using CNN features learned from combination of attributes","T. Matsukawa; E. Suzuki","Faculty of Information Science and Electrical Engineering (ISEE), Kyushu University, Japan","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","2428","2433","This paper presents fine-tuned CNN features for person re-identification. Recently, features extracted from top layers of pre-trained Convolutional Neural Network (CNN) on a large annotated dataset, e.g., ImageNet, have been proven to be strong off-the-shelf descriptors for various recognition tasks. However, large disparity among the pre-trained task, i.e., ImageNet classification, and the target task, i.e., person image matching, limits performances of the CNN features for person re-identification. In this paper, we improve the CNN features by conducting a fine-tuning on a pedestrian attribute dataset. In addition to the classification loss for multiple pedestrian attribute labels, we propose new labels by combining different attribute labels and use them for an additional classification loss function. The combination attribute loss forces CNN to distinguish more person specific information, yielding more discriminative features. After extracting features from the learned CNN, we apply conventional metric learning on a target re-identification dataset for further increasing discriminative power. Experimental results on four challenging person re-identification datasets (VIPeR, CUHK, PRID450S and GRID) demonstrate the effectiveness of the proposed features.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900000","","Feature extraction;Image color analysis;Image recognition;Machine learning;Measurement;Training;Training data","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Analysis of massive industrial data using MapReduce framework for parallel processing","M. Aly; S. Yacout; Y. Shaban","&#x00C9;cole Polytechnique de Montr&#x00E9;al","2017 Annual Reliability and Maintainability Symposium (RAMS)","20170330","2017","","","1","6","With the emergence of the `Big Data' paradigm, more and more industrial data are now available for practitioners and professionals. This data is being generated faster due to the advancement of the new information technologies. For reliability and maintenance engineers, `Big Data' is an interesting source of information. If analyzed correctly, it can produce useful knowledge-base to help making decisions in an industrial organization. The availability of `Big Data' is now leading to a new area of researches that are dedicated to the analysis of such data. This paper shows how to analyze massive amount of data generated from an industrial system(s). Those massive data may range from terabytes to petabytes in size; analyzing such sizes cannot be performed on a single commodity computer due to the possibility of memory leakage as the data may not fit into the computer's resources, specifically CPUs. Even if it fits, it will take an unacceptable amount of time. For this purpose, processing industrial large size of data requires the involvement of high performance analytical systems running on distributed environments. Different algorithms can be considered to have such analysis done. Cloud Computing models provide the necessary scalable and flexible infrastructure(s) to adapt the standard analytics algorithms in a distributed manner. We introduce a new distributed training technique that combines the newly widely used framework for big dataflow, namely MapReduce, with the traditional structure of machine learning techniques such as matrix multiplication and linear regression. Parallel processing of the aforementioned types is based on different algorithms to be adapted to MapReduce and its framework. Our considered platform is deployed on top of Google Cloud Platform (App Engine and Compute Engine), also taking into consideration Cloud Amazon EMR services to see how we can benefit from the provisioned resources in each one of them, and make the analysis- and the extraction of useful information from the massive industrial data goes faster, i.e. in its computational time.","","Electronic:978-1-5090-5284-4; POD:978-1-5090-5285-1","10.1109/RAM.2017.7889681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889681","Big Data;Cloud Computing;Data mining;MapReduce;Parallel Processing","Algorithm design and analysis;Big Data;Cloud computing;Indexes;Linear regression;Machine learning algorithms;Parallel processing","Big Data;cloud computing;data analysis;decision making;learning (artificial intelligence);parallel processing","Big Data;Google cloud platform;MapReduce framework;app engine;big dataflow;cloud Amazon EMR services;cloud computing models;compute engine;data processing;decision making;distributed environments;distributed training technique;high performance analytical systems;industrial organization;information extraction;information source;knowledge-base;machine learning techniques;massive industrial data analysis;parallel processing","","","","","","","23-26 Jan. 2017","","IEEE","IEEE Conference Publications"
"Method of intrusion detection using deep neural network","Jin Kim; Nara Shin; S. Y. Jo; Sang Hyun Kim","Seculayer Co., Ltd., Seoul, Korea 04784","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","313","316","In this study, an artificial intelligence (AI) intrusion detection system using a deep neural network (DNN) was investigated and tested with the KDD Cup 99 dataset in response to ever-evolving network attacks. First, the data were preprocessed through data transformation and normalization for input to the DNN model. The DNN algorithm was applied to the data refined through preprocessing to create a learning model, and the entire KDD Cup 99 dataset was used to verify it. Finally, the accuracy, detection rate, and false alarm rate were calculated to ascertain the detection efficacy of the DNN model, which was found to generate good results for intrusion detection.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881684","","Biological neural networks;Data models;Intrusion detection;Machine learning algorithms;Support vector machines;Testing","learning (artificial intelligence);neural nets;security of data","DNN model;KDD Cup 99 dataset;artificial intelligence intrusion detection system;data normalization;data transformation;deep neural network;detection rate;false alarm rate;learning model;network attacks","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Mining Fashion Outfit Composition Using An End-to-End Deep Learning Approach on Set Data","Y. Li; L. Cao; J. Zhu; J. Luo","Department of Computer Science, University of Rochester, Rochester, USA.(email:yli@cs.rochester.edu)","IEEE Transactions on Multimedia","","2017","PP","99","1","1","Composing fashion outfits involves deep understanding of fashion standards while incorporating creativity for choosing multiple fashion items (e.g., Jewelry, Bag, Pants, Dress). In fashion websites, popular or high-quality fashion outfits are usually designed by fashion experts and followed by large audiences. In this paper, we propose a machine learning system to compose fashion outfits automatically. The core of the proposed automatic composition system is to score fashion outfit candidates based on the appearances and meta-data. We propose to leverage outfit popularity on fashion oriented websites to supervise the scoring component. The scoring component is a multi-modal multi-instance deep learning system that evaluates instance aesthetics and set compatibility simultaneously. In order to train and evaluate the proposed composition system, we have collected a large scale fashion outfit dataset with 195K outfits and 368K fashion items from Polyvore. Although the fashion outfit scoring and composition is rather challenging, we have achieved an AUC of 85% for the scoring component, and an accuracy of 77% for a constrained composition task.","1520-9210;15209210","","10.1109/TMM.2017.2690144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890387","","Context;Footwear;Image coding;Machine learning;Silicon;Visualization","","","","","","","","20170330","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Quality Assessment in Live Video Streaming","M. T. Vega; D. C. Mocanu; J. Famaey; S. Stavrou; A. Liotta","Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands","IEEE Signal Processing Letters","20170414","2017","24","6","736","740","Video content providers put stringent requirements on the quality assessment methods realized on their services. They need to be accurate, real-time, adaptable to new content, and scalable as the video set grows. In this letter, we introduce a novel automated and computationally efficient video assessment method. It enables accurate real-time (online) analysis of delivered quality in an adaptable and scalable manner. Offline deep unsupervised learning processes are employed at the server side and inexpensive no-reference measurements at the client side. This provides both real-time assessment and performance comparable to the full reference counterpart, while maintaining its no-reference characteristics. We tested our approach on the LIMP Video Quality Database (an extensive packet loss impaired video set) obtaining a correlation between 78% and 91% to the FR benchmark (the video quality metric). Due to its unsupervised learning essence, our method is flexible and dynamically adaptable to new content and scalable with the number of videos.","1070-9908;10709908","","10.1109/LSP.2017.2691160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892928","Deep learning (DL);multimedia video services;unsupervised learning (UL);video quality assessment","Feature extraction;Machine learning;Measurement;Quality assessment;Real-time systems;Streaming media;Video recording","unsupervised learning;video signal processing;video streaming","FR benchmark;LIMP Video Quality Database;extensive packet loss impaired video set;inexpensive no-reference measurements;offline deep unsupervised learning processes;online analysis;quality assessment methods;real-time analysis;real-time assessment;video assessment method;video content providers;video quality metric","","","","","","20170405","June 2017","","IEEE","IEEE Journals & Magazines"
"Fault Identification Tool Based on Deep Learning for Fault Big Data","Y. Tamura; S. Ashida; S. Yamada","Grad. Sch. of Sci. & Technol. for Innovation, Yamaguchi Univ., Ube, Japan","2016 International Conference on Information Science and Security (ICISS)","20170327","2016","","","1","4","Many open source software (OSS) are developed under the OSS projects all over the world. Then, the software faults detected in OSS projects are managed by the bug tracking systems. Also, many data sets are recorded on the bug tracking systems by many users and project members. In this paper, we propose the useful method based on the deep learning for the improvement activities of OSS reliability. In particular, we develop an application software for visualization of fault data recorded on OSS. Moreover, several numerical illustrations of the developed application software in the actual OSS project are shown in this paper. Furthermore, we discuss the analysis results based on the developed application software by using the fault data sets of actual OSS projects.","","Electronic:978-1-5090-5493-0; POD:978-1-5090-5494-7","10.1109/ICISSEC.2016.7885852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885852","","Application software;Computer bugs;Estimation;Machine learning;Servers;Software reliability","Big Data;data visualisation;learning (artificial intelligence);program debugging;public domain software;software fault tolerance;software tools","OSS reliability;bug tracking system;deep learning;fault Big Data;fault data visualization;fault identification tool;open source software;software fault detection","","","","","","","19-22 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep Hashing for Scalable Image Search","J. Lu; V. E. Liong; J. Zhou","Department of Automation, Tsinghua University, Beijing, China","IEEE Transactions on Image Processing","20170412","2017","26","5","2352","2367","In this paper, we propose a new deep hashing (DH) approach to learn compact binary codes for scalable image search. Unlike most existing binary codes learning methods, which usually seek a single linear projection to map each sample into a binary feature vector, we develop a deep neural network to seek multiple hierarchical non-linear transformations to learn these binary codes, so that the non-linear relationship of samples can be well exploited. Our model is learned under three constraints at the top layer of the developed deep network: 1) the loss between the compact real-valued code and the learned binary vector is minimized, 2) the binary codes distribute evenly on each bit, and 3) different bits are as independent as possible. To further improve the discriminative power of the learned binary codes, we extend DH into supervised DH (SDH) and multi-label SDH by including a discriminative term into the objective function of DH, which simultaneously maximizes the inter-class variations and minimizes the intra-class variations of the learned binary codes with the single-label and multi-label settings, respectively. Extensive experimental results on eight widely used image search data sets show that our proposed methods achieve very competitive results with the state-of-the-arts.","1057-7149;10577149","","10.1109/TIP.2017.2678163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870632","Scalable image search;deep learning;fast similarity search;hashing;multi-label learning","Binary codes;DH-HEMTs;Machine learning;Neural networks;Synchronous digital hierarchy;Training;Visualization","binary codes;image coding;image retrieval;learning (artificial intelligence);minimisation;neural nets","binary vector;compact binary code learning;compact real-valued code;deep hashing;deep neural network;inter-class variation maximization;intra-class variation minimization;multilabel SDH;multiple hierarchical nonlinear transformations;scalable image search;supervised DH","","","","","","20170303","May 2017","","IEEE","IEEE Journals & Magazines"
"A novel fingerprint classification method based on deep learning","Ruxin Wang; Congying Han; Tiande Guo","School of Mathematical Science, University of Chinese Academy of Sciences (UCAS), Beijing 100049, China","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","931","936","Fingerprint classification is an effective technique for reducing the candidate numbers of fingerprints in the stage of matching in automatic fingerprint identification system (AFIS). In recent years, deep learning is an emerging technology which has achieved great success in many fields, such as image processing, computer vision. In this paper, we have a preliminary attempt on the traditional fingerprint classification problem based on the new depth neural network method. For the four-class problem, only choosing orientation field as the classification feature, we achieve 91.4% accuracy using the stacked sparse autoencoders (SAE) with three hidden layers in the NIST-DB4 database. And then two classification probabilities are used for fuzzy classification which can effectively enhance the accuracy of classification. By only adjusting the probability threshold, we get the accuracy of classification is 96.1% (setting threshold is 0.85), 97.2% (setting threshold is 0.90) and 98.0% (setting threshold is 0.95) with a single layer SAE. Applying the fuzzy method, we obtain higher accuracy.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899755","","Databases;Feature extraction;Fingerprint recognition;Image reconstruction;Machine learning;Neural networks;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"On Deep Learning for Trust-Aware Recommendations in Social Networks","S. Deng; L. Huang; G. Xu; X. Wu; Z. Wu","College of Computer Science and Technology, Zhejiang University, Hangzhou, China","IEEE Transactions on Neural Networks and Learning Systems","20170417","2017","28","5","1164","1177","With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user’s trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users’ interests and their trusted friends’ interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.","2162-237X;2162237X","","10.1109/TNNLS.2016.2514368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7414528","Deep learning;recommender systems (RSs);social network;trust","Computer science;Machine learning;Motion pictures;Optimization;Recommender systems;Reliability;Social network services","","","","","","","","20160219","May 2017","","IEEE","IEEE Journals & Magazines"
"Instantaneous heart rate as a robust feature for sleep apnea severity detection using deep learning","R. K. Pathinarupothi; R. Vinaykumar; E. Rangan; E. Gopalakrishnan; K. P. Soman","Amrita Center for Wireless Networks","2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","20170413","2017","","","293","296","Automated sleep apnea detection and severity identification has largely focused on multivariate sensor data in the past two decades. Clinically too, sleep apnea is identified using a combination of markers including blood oxygen saturation, respiration rate etc. More recently, scientists have begun to investigate the use of instantaneous heart rates for detection and severity measurement of sleep apnea. However, the best-known techniques that use heart rate and its derivatives have been able to achieve less than 85% accuracy in classifying minute-to-minute apnea data. In our research reported in this paper, we apply a deep learning technique called LSTM-RNN (long short-term memory recurrent neural network) for identification of sleep apnea and its severity based only on instantaneous heart rates. We have tested this model on multiple sleep apnea datasets and obtained perfect accuracy. Furthermore, we have also tested its robustness on an arrhythmia dataset (that is highly probable in mimicking sleep apnea heart rate variability) and found that the model is highly accurate in distinguishing between the two.","","Electronic:978-1-5090-4179-4; POD:978-1-5090-4180-0","10.1109/BHI.2017.7897263","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897263","","Computer architecture;Electrocardiography;Heart rate;Machine learning;Sleep apnea;Testing;Training","","","","","","","","","16-19 Feb. 2017","","IEEE","IEEE Conference Publications"
"Towards a Framework for Closed-Domain Question Answering in Italian","E. Damiano; R. Spinelli; M. Esposito; G. D. Pietro","","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","20170424","2016","","","604","611","In the last years, Cognitive Systems are increasingly appearing, offering new ways for developing Question Answering solutions able to autonomously extract an answer for a question formulated in natural language. Currently, to the best of our knowledge, most of the available Question Answering solutions are designed for the English language and use SQL-like knowledge bases to provide factual answers to a natural language question. Starting from these considerations, this work presents a preliminary Question Answering framework for closed-domains, like Cultural Heritage. It has been expressly thought to extract factual answers from collections of documents by operating with the Italian language. Such a framework exploits a variety of NLP methods for the Italian language to help the understanding of user's questions and the extraction of precise answers from textual passages contained into documents. Moreover, Deep Learning techniques have been used to proficiently understand the topic of a question, whereas a rule-based approach relying on dictionaries has been applied for the annotation and indexing of collections of documents in Italian, enabling their usage into a state-of-the-art Information Retrieval engine. An experimental session has also been arranged, showing very promising preliminary results.","","Electronic:978-1-5090-5698-9; POD:978-1-5090-5699-6","10.1109/SITIS.2016.100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907527","Cognitive Computing;Italian Text;NLP;Question answering;Unstructured Information","Cultural differences;Data models;Knowledge based systems;Knowledge discovery;Machine learning;Natural languages;Pipelines","","","","","","","","","Nov. 28 2016-Dec. 1 2016","","IEEE","IEEE Conference Publications"
"Convolutional Self Organizing Map","H. Dozono; G. Niina; S. Araki","Dept. of Adv. Fusion Technol., Saga Univ., Saga, Japan","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","767","771","Recently, deep learning became very popular, and was applied to many fields. The convolutional neural networks are often used for representing the layers for deep learning. In this paper, we propose Convolutional Self Organizing Map, which can be applicable to deep learning. Conventional Self Organizing Map uses single layered architecture, and can visualizes and classifies the input data on 2 dimensional map. SOMs which uses multiple layers are already proposed. In this paper, we propose Self Organizing Map algorithms which include convolutional layers. 2 types of convolution methods, which are based on conventional method and inspired from Self Organizing Map algorithm are proposed, and the performance of both method is examined in the experiments of clustering image data.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881442","Convolutional neural network;Deep Learning;Self Organizing Map","Arrays;Convolution;Correlation;Data visualization;Kernel;Machine learning;Neural networks","data visualisation;feedforward neural nets;learning (artificial intelligence);pattern classification;pattern clustering;self-organising feature maps","2 dimensional map;convolutional layers;convolutional neural networks;convolutional self organizing map;deep learning;image data clustering;input data classification;input data visualization;single layered architecture","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Fast road scene segmentation using deep learning and scene-based models","V. John; K. Kidono; C. Guo; H. Tehrani; S. Mita; K. Ishimaru","Toyota Technological Institute, Japan","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3763","3768","Pixel-labeling approaches using semantic segmentation play an important role in road scene understanding. In recent years, deep learning approaches such as the deconvolutional neural network have been used for semantic segmentation, obtaining state-of-the-art results. However, the segmentation results have limited object delineation. In this paper, we adopt the de-convolutional neural network to perform the semantic segmentation of the road scene using colour and depth information. Moreover, we improve the network's limited object delineation within a computationally efficient framework using novel features that are learnt at the pixel-level and patch-level for different road scenes. The patch-level features represent the road scene geometry. On the other hand, the learnt pixel-level features represent the appearance and depth information. The features learnt for the different road scenes are indexed with the scene's pre-defined label. Following the indexing, the random forest classifier is trained to retrieve the relevant geometric and appearance-depth features for a given road scene. The retrieved features are then used to refine identified error regions in the initial semantic segmentation estimate. Our proposed algorithm is evaluated on an acquired dataset and compared with state-of-the-art baseline algorithms. We also perform a detailed parametric evaluation of our proposed framework. The experimental results show that our proposed algorithm reports better accuracy.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900220","","Feature extraction;Image color analysis;Image segmentation;Machine learning;Neural networks;Roads;Semantics","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"A novel based Hidden Markov Model approach for controlling the ACS-TSP evaporation parameter","S. Bouzbita; A. El Afia; R. Faizi","ENSIAS - Mohammed V University, Rabat, Morocco","2016 5th International Conference on Multimedia Computing and Systems (ICMCS)","20170424","2016","","","633","638","The aim of this paper is to propose a new method capable of dynamically controlling the evaporation parameter in an Ant Colony System (ACS) using a Hidden Markov Model. The purpose is to improve the performance of ACS by controlling the exploration and exploitation in the search space. To this end, two HMM approaches are proposed. The first is a training method that best suits the observed data of the Hidden Markov Model. The second is a method that dynamically controls the adapted parameter by applying several processes. To test our algorithm we used a set of Travelling Salesman Problem (TSP) instances.","","CD:978-1-5090-5145-8; Electronic:978-1-5090-5146-5; POD:978-1-5090-5147-2","10.1109/ICMCS.2016.7905544","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905544","Hidden Markov Model;dynamic adaptation;evaporation parameter","Algorithm design and analysis;Genetic algorithms;Heuristic algorithms;Hidden Markov models;Machine learning algorithms;Particle swarm optimization;Viterbi algorithm","","","","","","","","","Sept. 29 2016-Oct. 1 2016","","IEEE","IEEE Conference Publications"
"Exploring deep learning based solutions in fine grained activity recognition in the wild","Song Cao; R. Nevatia","Computer Science Department, University of Southern California, Los Angeles, 90089, United States of America","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","384","389","In this paper, we explore the usage of deep learning based solutions in fine grained activity recognition in the wild. As a powerful tool, deep learning has been widely used in image classification, object detection and activity recognition. We focus on implementing deep learning methods into the more complicated fine grained activity recognition problems. We test our solutions on MPII activity dataset with 410 activities. We find that due to the challenges of large intra class variances, small inter class variances, and limited training samples per activity, the classical two stream deep ConvNets method does not perform that well for fine grained activity recognition. Observing these issues, we propose a solution to directly use deep features learned from ImageNet in an SVM. In experiments, we achieve a 20 percent improvement compared to the classical two stream deep ConvNets solutions, on MPII fine grained activity challenge videos.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899664","","Activity recognition;Additives;Kernel;Machine learning;Streaming media;Support vector machines;Videos","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Implementation of a Coin Recognition System for Mobile Devices with Deep Learning","N. Capece; U. Erra; A. V. Ciliberto","","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","20170424","2016","","","186","192","This paper examines the application of a deep learning approach to automatic coin recognition, via a mobile device and client-server architecture. We show that a convolutional neural network is effective for coin identification. During the training phase, we determine the optimum size of the training dataset necessary to achieve high classification accuracy with low variance. In addition, we propose a client-server architecture that enables a user to identify coins by photographing it with a smartphone. The image provided by the user is matched with the neural network on a remote server. A high correlation suggests that the image is a match. The application is a first step towards the automatic identification of coins and may help coin experts in their study of coins and reduce the associated expense of numismatic applications.","","Electronic:978-1-5090-5698-9; POD:978-1-5090-5699-6","10.1109/SITIS.2016.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907464","coin recognition;deep learning;numismatic","Artificial neural networks;Biological neural networks;Feature extraction;Image recognition;Machine learning;Neurons;Training","","","","","","","","","Nov. 28 2016-Dec. 1 2016","","IEEE","IEEE Conference Publications"
"Tattoo detection and localization using region-based deep learning","Z. H. Sun; J. Baumes; P. Tunison; M. Turek; A. Hoogs","Kitware Inc., Clifton Park, NY 12065, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3055","3060","Tattoos have been increasingly used as a discriminative soft biometric for people identification, such as criminal and victim identification in forensics investigation and law enforcement. However, automatic detection of tattoo images and accurate localization of the regions of interest are challenged by the large variations in artistic composition, color, shape, texture, location on the body, local geometric shape (e.g. neck and finger), imaging conditions, and image quality. In this paper, we train a tattoo detector from the Tatt-C and PASCAL VOC 2007 image datasets using region-based deep learning. The detector can effectively determine if an image contains tattoos and the locations of tattoo regions. We carry out a comprehensive evaluation of our tattoo image classification and detection localization. The detector improves upon the state-of-the-art algorithms in the Tatt-C challenge, achieving a better detection error trade-off curve. It yields low confidence scores on randomly sampled non-tattoo images from 397 scene categories in the MIT-SUN dataset. In addition, the same detector is also validated on the NTU Tattoo Image Dataset with 10000 images.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900103","","Convolution;Detectors;Face;Histograms;Machine learning;Proposals;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multiple Instance Learning Convolutional Neural Networks for object recognition","M. Sun; T. X. Han; Ming-Chang Liu; A. Khodayari-Rostamabad","Electrical and Computer Engineering, University of Missouri, Columbia, 65211, United States of America","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3270","3275","Convolutional Neural Networks (CNN) have demonstrated its successful applications in computer vision, speech recognition, and natural language processing. For object recognition, CNNs might be limited by its strict label requirement and an implicit assumption that images are supposed to be target-object-dominated for optimal solutions. However, the labeling procedure, necessitating laying out the locations of target objects, is very tedious, making high-quality large-scale dataset prohibitively expensive. Data augmentation schemes are widely used when deep networks suffer the insufficient training data problem. All the images produced through data augmentation share the same label, which may be problematic since not all data augmentation methods are label-preserving. In this paper, we propose a weakly supervised CNN framework named Multiple Instance Learning Convolutional Neural Networks (MILCNN) to solve this problem. We apply MILCNN framework to object recognition and report state-of-the-art performance on three benchmark datasets: CIFAR10, CIFAR100 and ILSVRC2015 classification dataset.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900139","","Benchmark testing;Machine learning;Neural networks;Object recognition;Optimization;Prediction algorithms;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Semi-Supervised Multi-View Discrete Hashing for Fast Image Search","C. Zhang; W. S. Zheng","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Image Processing","20170412","2017","26","6","2604","2617","Hashing is an important method for fast neighbor search on large scale dataset in Hamming space. While most research on hash models are focusing on single-view data, recently the multi-view approaches with a majority of unsupervised multi-view hash models have been considered. Despite of existence of millions of unlabeled data samples, it is believed that labeling a handful of data will remarkably improve the searching performance. In this paper, we propose a semi-supervised multi-view hash model. Besides incorporating a portion of label information into the model, the proposed multi-view model differs from existing multi-view hash models in three-fold: 1) a composite discrete hash learning modeling that is able to minimize the loss jointly on multi-view features when using relaxation on learning hashing codes; 2) exploring statistically uncorrelated multi-view features for generating hash codes; and 3) a composite locality preserving modeling for locally compact coding. Extensive experiments have been conducted to show the effectiveness of the proposed semi-supervised multi-view hash model as compared with related multi-view hash models and semi-supervised hash models.","1057-7149;10577149","","10.1109/TIP.2017.2675205","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7864423","Hash function learning;fast search;multi-view modeling;semi-supervised methods","Binary codes;Data models;Labeling;Linear programming;Machine learning;Matrix decomposition;Semantics","","","","","","","","20170224","June 2017","","IEEE","IEEE Journals & Magazines"
"Palmprint recognition via discriminative index learning","J. Svoboda; J. Masci; M. M. Bronstein","Institute of Computational Science, University of Lugano, Switzerland","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","4232","4237","In the past years, deep convolutional neural networks (CNNs) have become extremely popular in the computer vision and pattern recognition community. The computational power of modern processors, efficient stochastic optimization algorithms, and large amounts of training data allowed training complex tasks-specific features directly from the data in an end-to-end fashion, as opposed to the traditional way of using hand-crafted feature descriptors. CNNs are currently state-of-the-art methods in many computer vision problems, and have been successfully used in biometric applications such as face, fingerpring, and voice recognition. In palmprint recognition applications, CNNs have not yet been explored, and the majority of methods still rely on hand-crafted representations which do not scale well to large datasets and that usually require a complex manual parameter tuning. In this work, we show that CNNs can be successfully used for palmprint recognition. The training of our network uses a novel loss function related to the d-prime index, which allows to achieve a better genuine/impostor score distribution separation than previous approaches with only little training data required. Our approach does not require cumbersome parameter tuning and achieves state-of-the-art results on the standard IIT Delhi and CASIA palmprint datasets.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900298","","Computer vision;Face recognition;Indexes;Machine learning;Standards;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"A core leader based label propagation algorithm for community detection","S. Liu; F. Zhu; H. Liu; Z. Du","School of Computer, Wuhan University, Wuhan, China","China Communications","20170417","2016","13","12","97","106","A large number of community discovery algorithms have been proposed in the last decade. Recently, the sharp increase of network scale has become a great challenge for traditional community discovery algorithms. Label propagation algorithm is a semi-supervised machine learning method, which has linear time complexity when coping with large scale networks. However, the output result has less stability and the quality of the output communities still remains to be improved. Therefore, we propose a novel core-leader based label propagation algorithm for community detection called CLBLPA. Firstly, we find core leaders of potential community by using a greedy method. Then we utilize the label influence potential to guide the process of label propagation. Thus we can accelerate the convergence of algorithm and improve the stability of the output. Experimental results on synthetic datasets and real networks show that CLBLPA can significantly improve the quality of the output communities.","1673-5447;16735447","","10.1109/CC.2016.7897535","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897535","community detection;coreleaders;label influence potential;label propagation;network analysis","Algorithm design and analysis;Clustering algorithms;Lips;Machine learning algorithms;Social network services;Stability analysis;Time complexity","complex networks;computational complexity;data mining;graph theory;learning (artificial intelligence);network theory (graphs)","CLBLPA;algorithm convergence;community detection;community discovery algorithm;complex network;core leader based label propagation algorithm;greedy method;label influence potential;linear time complexity;output stability;semisupervised machine learning","","","","","","","December 2016","","IEEE","IEEE Journals & Magazines"
"Deep Brain Stimulation Signal Classification Using Deep Belief Networks","P. Guillén-Rondon; M. D. Robinson","Center for Adv. Comput. & Data Syst., Univ. of Houston, Houston, TX, USA","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","155","158","An approach to modeling complex real-world data such as biomedical signals is to develop pattern recognition techniques and robust features that capture the relevant information. In this paper, we use a deep belief network (DBN) to predict subcortical structures of patients with Parkinson's disease based on microelectrode records (MER) obtained during deep brain stimulation (DBS). We report on experiments using a data set involving 52 MER for the structures: zona incerta (Zi), subthalamic nucleus (STN), thalamus nucleus (TAL), and substantia nigra (SNR). The results show that our chosen features and network architecture produces a 99.5% accuracy of detection and classification of the subcortical structures under study. Based on the results we conclude that deep belief networks could be used to predict subcortical structure-mainly the STN for neurostimulation.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881329","","Brain stimulation;Machine learning;Neurons;Parkinson's disease;Satellite broadcasting;Signal to noise ratio;Surgery","belief networks;brain;diseases;medical signal processing;signal classification","DBN;DBS;MER;Parkinson's disease;biomedical signals;deep belief networks;deep brain stimulation signal classification;microelectrode records;pattern recognition technique;subcortical structures classification;substantia nigra;subthalamic nucleus;thalamus nucleus;zona incerta","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"An Effective Intrusion Detection Classifier Using Long Short-Term Memory with Gradient Descent Optimization","T. T. H. Le; J. Kim; H. Kim","Sch. of Electr. & Comput. Eng., Pusan Nat. Univ., Busan, South Korea","2017 International Conference on Platform Technology and Service (PlatCon)","20170323","2017","","","1","6","Intrusion Detection System (IDS) is one of the important issues in network security. IDSs are built to detect both known and unknown malicious attacks. Several machine learning algorithms are used widely in IDS such as neural network, SVM, KNN etc. However, these algorithms have still some limitations such as high false positive and false alarm rate. In this paper, our contribution is to build a classifier of IDS following deep learning approach. We find the most suitable optimizer among six optimizes for Long Short-Term Memory Recurrent Neural Network (LSTM RNN) model applied in IDS. Through our experiments, we found that LSTM RNN model with Nadam optimizer outperforms to previous works. We demonstrate our approach is really efficiency to intrusion detection with accuracy is 97.54%, detection rate is 98.95%, and false alarm rate is reasonable with 9.98%.","","Electronic:978-1-5090-5140-3; POD:978-1-5090-5141-0","10.1109/PlatCon.2017.7883684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883684","","Intrusion detection;Logic gates;Machine learning algorithms;Optimization;Recurrent neural networks;Support vector machines","gradient methods;learning (artificial intelligence);recurrent neural nets;security of data","IDS;LSTM RNN model;Nadam optimizer;deep learning approach;detection rate;false alarm rate;gradient descent optimization;intrusion detection system;known malicious attack detection;long short-term memory recurrent neural network model;network security;unknown malicious attack detection","","","","","","","13-15 Feb. 2017","","IEEE","IEEE Conference Publications"
"Short-Term Residential Load Forecasting based on Resident Behaviour Learning","W. Kong; Z. Y. Dong; D. J. Hill; F. Luo; Y. Xu","","IEEE Transactions on Power Systems","","2017","PP","99","1","1","Residential load forecasting has been playing an increasingly important role in modern smart grids. Due to the variability of residents’ activities, individual residential loads are usually too volatile to forecast accurately. An LSTM based deep learning forecasting framework with appliance consumption sequences is proposed to address such volatile problem. It is shown that the forecasting accuracy can be notably improved by including appliance measurements in the training data. The effectiveness of the proposed method is validated through extensive comparison studies on a real-world dataset.","0885-8950;08858950","","10.1109/TPWRS.2017.2688178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7887751","Short-Term load forecasting;deep learning;meter-level load forecasting;recurrent neural network","Forecasting;Home appliances;Load forecasting;Load modeling;Machine learning;Predictive models;Recurrent neural networks","","","","","","","","20170327","","","IEEE","IEEE Early Access Articles"
"Deep learning of submerged body images from 2D sonar sensor based on convolutional neural network","S. Lee","Division of Mechanical and Automotive Engineering, Kongju University, Cheonan, 31080, Korea","2017 IEEE Underwater Technology (UT)","20170403","2017","","","1","3","Given the harsh working conditions such as high-speed flow rate, turbid watch, and steep terrain, it is a very challenging task to find submerged bodies in disaster site occurred at sea or river or for the military purpose. Therefore, if it is possible to utilize the unmanned robot, such as the USV(Unmanned Surface Vehicle) and UUV (Unmanned Underwater Vehicle) for the navigational operation of these special purpose, it has a great effect. Underwater ultrasound image information is pretty difficult to make the geometric modeling of submerged body due to heavy noise on its characteristics. This study presents the robust method of submerged body recognition based on the CNN(Convolutional Neural Network), which is one of the deep learning approach.","","Electronic:978-1-5090-5266-0; POD:978-1-5090-5267-7","10.1109/UT.2017.7890309","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890309","Convolutional Neural Network;Submerged Body Recognition;Underwater Sonar Image;Unmanned Surface Vehicle;Unmanned Underwater Vehicle","Kernel;Machine learning;Neural networks;Robot sensing systems;Sea surface;Sonar","image recognition;image sensors;learning (artificial intelligence);neural nets;sonar imaging","2D sonar sensor;CNN;USV;UUV;convolutional neural network;deep learning;disaster;geometric modeling;high-speed flow rate;military purpose;navigational operation;steep terrain;submerged body image recognition;turbid watch;underwater ultrasound image information;unmanned robot;unmanned surface vehicle;unmanned underwater vehicle","","","","","","","21-24 Feb. 2017","","IEEE","IEEE Conference Publications"
"Person re-identification with pre-trained deep learning models and attribute correlations","Ngoc-Bao Nguyen; Vu-Hoang Nguyen; Tien Do; Thanh Duc Ngo","Multimedia Communications Laboratory, University of Information Technology, VNU-HCM, Vietnam","2016 International Symposium on Electronics and Smart Devices (ISESD)","20170327","2016","","","242","247","This paper introduces an approach to employ deep features for person re-identification. In contrast to existing works, we focus on using pre-trained deep models and their concept-based output to enhance attribute presentations of person images. There are two main contributions. First, we investigate recent state-of-the-art deep learning models for the task and provide a comprehensive evaluation. Second, we present an approach to improve identification accuracy of a standard attribute-based person re-identification approach. By using pre-trained models, we avoid re-training new deep models which always require a huge amount of training data and high computational cost. The idea is to utilize the correlation between generic concepts learned by the deep models and specific pre-defined attributes commonly used for person re-identification. We employ the deeply learned features from generic concepts to represent person images. These images and their manually annotated attributes are then used to train attribute classifiers. Given the classifiers, attributes of the probe and gallery images can be automatically extracted to compose attribute-based feature vectors. Re-identification is done by matching the vectors. Experiments conducted on several benchmark datasets demonstrated the effectiveness of the proposed approach.","","Electronic:978-1-5090-3840-4; POD:978-1-5090-3841-1","10.1109/ISESD.2016.7886726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886726","Attribute;Deep Learning;Person Re-Identification","Cameras;Computational modeling;Correlation;Feature extraction;Machine learning;Measurement;Standards","feature extraction;image classification;learning (artificial intelligence);object recognition","attribute classifiers;attribute correlations;deep features;person image attribute presentations;person reidentification;pre-trained deep learning models","","","","","","","29-30 Nov. 2016","","IEEE","IEEE Conference Publications"
"A survey of news recommendation approaches","S. K. Dwivedi; C. Arya","Department of Computer Science, Babasaheb Bhimrao Ambedkar University, Lucknow, India","2016 International Conference on ICT in Business Industry & Government (ICTBIG)","20170406","2016","","","1","6","World Wide Web has reformed the traditional model of news reading. Online news reading has turned out to be extremely famous as the Internet provides an enormous number of sources to access news articles. News recommendation system is an automated approach built to provide the most appropriate information on the vast amount of data on the internet which represents the user's needs without the manual exertion of users. The fundamental thought behind the news recommender system is to assist man-machine interaction. In this paper, we survey various approaches to the news recommendation system and provide qualitative analysis of them, to bring insight to research scope in this direction.","","Electronic:978-1-5090-5515-9; POD:978-1-5090-5516-6","10.1109/ICTBIG.2016.7892681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892681","Demographic Approach;Hybrid approach;Recommendation system;collaborative approach;content-based approach","Collaboration;Machine learning algorithms;Predictive models;Recommender systems;Scalability","recommender systems","Internet;World Wide Web;man-machine interaction;news recommendation approach;online news reading;qualitative analysis","","","","","","","18-19 Nov. 2016","","IEEE","IEEE Conference Publications"
"Detection of distinctions in car fleets based on measured and simulated data","M. Hinz; F. Hienzsch; S. Bracke","University of Wuppertal","2017 Annual Reliability and Maintainability Symposium (RAMS)","20170330","2017","","","1","7","The main aim of this paper is the analysis of a fleet behavior and comparison of damaged and non-damaged vehicles using different machine learning algorithms to identify the main distinctions in a car fleet. For this purpose OBD (On Board Diagnostics) signals are recorded in three various car types (BMW X3, Peugeot 208, Seat Leon) and several hundred drives. Furthermore, thousands of drives are simulated based on the Discrete Fourier Transformation (DTF) and Monte Carlo simulation (MC) to provide a huge training data for the rule learning algorithms. The simulated data represents the car fleet with given (or assumed) testing conditions. For example it is assumed, that all the cars of the fleet don't exceed the maximum speed of 170 km/hour due to the specs of the product. All made assumptions are variable and can be changed after the analysis process. All signals (simulated and recorded) are analyzed in order to provide information about every single drive (e.g. out of the speed signal: max speed, max acceleration, duration of the drive are determined and stored in a data base).","","Electronic:978-1-5090-5284-4; POD:978-1-5090-5285-1","10.1109/RAM.2017.7889775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889775","On Board Diagnostics;Testing;field data analysis;machine algorithms;optimization of test procedures","Automobiles;Data models;Heuristic algorithms;Machine learning algorithms;Optimization;Reliability;Testing","Monte Carlo methods;automobiles;discrete Fourier transforms;drives;learning (artificial intelligence);production engineering computing","DTF;MC simulation;Monte Carlo simulation;OBD signal;car fleet;discrete Fourier transformation;distinction detection;machine learning algorithm;on board diagnostics signal;rule learning algorithm","","","","","","","23-26 Jan. 2017","","IEEE","IEEE Conference Publications"
"WMEVF: An outlier detection methods for categorical data","N. Rokhman; Subanar; E. Winarko","Gadjah Mada University, Department of Computer Science and Electronics, Yogyakarta, Indonesia","2016 International Conference on Informatics and Computing (ICIC)","20170424","2016","","","37","42","Outliers are uncommon events in real life. For a database processing, an outlier means unusual record comparing to the others. An outlier can be caused by a damage to a system, an intruder in a system, or a new fact in a system. Outlier detection is an important task to find an exceptional data.","","Electronic:978-1-5090-1648-8; POD:978-1-5090-1649-5","10.1109/IAC.2016.7905686","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7905686","categorical data;outlier detection;weighting function","Complexity theory;Computer science;Entropy;Informatics;Machine learning algorithms;Standards","","","","","","","","","28-29 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Faster RCNN-Based Pedestrian Detection System","X. Zhao; W. Li; Y. Zhang; T. A. Gulliver; S. Chang; Z. Feng","Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","2016 IEEE 84th Vehicular Technology Conference (VTC-Fall)","20170320","2016","","","1","5","Pedestrian detection systems are receiving increasing attention in both industry and academia with the rapid development of autonomous automobiles which employ artificial intelligence. These systems must detect specific classes of objects such as pedestrians rather than generic objects. In this paper, we present a faster RCNN based pedestrian detection system which improves upon previous solutions. The proposed model takes arbitrary size images as inputs and generates bounding boxes and confidence scores for pedestrians. The system achieves good performance and is faster than the well known and frequently used methods in the literature.","","Electronic:978-1-5090-1701-0; POD:978-1-5090-1702-7","10.1109/VTCFall.2016.7880852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880852","","Detectors;Feature extraction;Machine learning;Neural networks;Proposals;Training;Tuning","feedforward neural nets;learning (artificial intelligence);object detection;pedestrians;traffic engineering computing","ADAS;advanced driver assistance systems;arbitrary size images;artificial intelligence;autonomous automobiles;bounding boxes;confidence scores;deep learning;faster RCNN-based pedestrian detection system;region-based convolutional neural network","","","","","","","18-21 Sept. 2016","","IEEE","IEEE Conference Publications"
"Polarimetric SAR Feature Extraction With Neighborhood Preservation-Based Deep Learning","H. Liu; S. Yang; S. Gou; D. Zhu; R. Wang; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education, Xidian University, Xi'an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20170323","2017","10","4","1456","1466","As an advanced nonlinear technique, deep learning, which is based on deep neural networks (DNNs), has attracted considerable attentions. In this paper, we propose a novel neighborhood preserved deep neural network (NPDNN) for polarimetric synthetic aperture radar feature extraction and classification. The spatial relation between pixels is exploited by a jointly weighting strategy. Not only the spatial neighbors but also the pixels in the same superpixel are utilized to weight each pixel. This strategy maintains the spatial dependence leading to superior homogeneity of the terrains without extra computational memory. Moreover, a few labeled samples and their nearest neighbors are employed to train the multilayer NPDNN, which preserves the local structure and reduces the number of labeled samples for classification. Experimental results on synthesized and real PolSAR data show that the proposed NPDNN can improve the classification accuracy compared with state-of-the-art DNNs despite a few input samples.","1939-1404;19391404","","10.1109/JSTARS.2016.2618891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7752793","Deep learning;feature extraction (FE);polarimetric synthetic aperture radar (PolSAR)","Covariance matrices;Feature extraction;Iron;Machine learning;Scattering;Synthetic aperture radar;Training","geophysical techniques;synthetic aperture radar","NPDNN;advanced nonlinear technique;neighborhood preservation-based deep learning;polarimetric SAR feature extraction;polarimetric synthetic aperture radar feature extraction","","","","","","20161122","April 2017","","IEEE","IEEE Journals & Magazines"
"Convolutional Neural Network Based Transient Earth Voltage Detection","Y. Lu; R. Wei; J. Chen; J. Yuan","","2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)","20170424","2016","","","386","389","Partial Discharge Detection is an important method to find hidden dangers and safety problems of power equipment. The traditional Transient Earth Voltages (TEV) methods of the switchgear and GIS usually consist of four steps, i.e. data gathering, filtering, feature extraction and pattern recognition. These methods generate features using statistical analysis or waveform analysis of the signals, and then conduct the recognition and classification operations. In recent years, the increasingly developing deep learning methods have a huge effect on the pattern recognition, due to its outstanding abilities of recognition and feature extraction, which greatly offset the poor recognition performance of the traditional TEV methods. A novel Convolutional Neural Network (CNN) based TEV detection method is proposed in the paper, which needs no signal feature prepared by human and overcomes the detection problems resulted from an inappropriately selected feature. A CNN model is designed to train and classify the spectral image of the TEV. Although no sophisticated denoising method is adopted in the preprocessing, the proposed method approaches an extraordinary detection performance, which demonstrates the effectiveness of our CNN based TEV detection method.","","Electronic:978-1-5090-4152-7; POD:978-1-5090-4153-4","10.1109/ISPDC.2016.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7904322","deep learning;feature;partial discharge detection;pattern recognition","Discharges (electric);Feature extraction;Interference;Machine learning;Partial discharges;Switchgear;Time-frequency analysis","","","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"A Deep Learning Framework for Coreference Resolution Based on Convolutional Neural Network","J. L. Wu; W. Y. Ma","Inst. of Inf. Sci., Taipei, Taiwan","2017 IEEE 11th International Conference on Semantic Computing (ICSC)","20170330","2017","","","61","64","Recently many researches have shown that word embeddings are able to represent information from word related contexts or its nearest neighborhood words, and thus are applied in many NLP tasks successfully. In this paper, we propose convolutional neural network model to extent word embeddings to mention/antecedent representation. These representations are obtained through convoluting neighboring word embeddings and other contextual information for coreference resolution. We evaluate our system on the English portion of the CoNLL 2012 Shared Task dataset and show that the proposed system achieves a competitive performance compared with the state-of-the-art approaches. We also show that our proposed model especially improves the coreference resolution of long spans significantly.","","Electronic:978-1-5090-4284-5; POD:978-1-5090-4285-2","10.1109/ICSC.2017.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889505","convolutional neural network;coreference resolution;deep learning;mention embeddings;word embeddings","Context;Gold;Machine learning;Neural networks;Noise measurement;Numerical models;Semantics","feedforward neural nets;learning (artificial intelligence);natural language processing","CoNLL 2012 Shared Task dataset;English portion;NLP tasks;antecedent representation;convolutional neural network model;coreference resolution;deep learning framework;information representation;mention representation;nearest neighborhood words;neighboring word embeddings;word related contexts","","","","","","","Jan. 30 2017-Feb. 1 2017","","IEEE","IEEE Conference Publications"
"Epithelium-stroma classification via convolutional neural networks and unsupervised domain adaptation in histopathological images","Y. Huang; H. ZHENG; C. LIU; X. Ding; G. Rohde","Electrical Engineering Department and Biomedical Engineering Department, University of Virginia, VA, U.S.A.","IEEE Journal of Biomedical and Health Informatics","","2017","PP","99","1","1","Epithelium-stroma classification is a necessary preprocessing step in histopathological image analysis. Current deep learning based recognition methods for histology data require collection of large volumes of labeled data in order to train a new neural network when there are changes to the image acquisition procedure. However, it is extremely expensive for pathologists to manually label sufficient volumes of data for each pathology study in a professional manner, which results in limitations in real-world applications. A very simple but effective deep learning method, that introduces the concept of unsupervised domain adaptation to a simple convolutional neural network (CNN), has been proposed in this paper. Inspired by transfer learning, our work assumes that the training data and testing data follow different distributions, and there is an adaptation operation to more accurately estimate the kernels in CNN in feature extraction, in order to enhance performance by transferring knowledge from labeled data in source domain to unlabeled data in target domain. The model has been evaluated using three independent public epithelium-stroma datasets by cross-dataset validations. The experimental results demonstrate that for epithelium-stroma classification, the proposed framework outperforms the state-of-the-art deep neural network model, and it also achieves better performance than other existing deep domain adaptation methods. The proposed model can be considered to be a better option for real-world applications in histopathological image analysis, since there is no longer a requirement for large-scale labeled data in each specified domain.","2168-2194;21682194","","10.1109/JBHI.2017.2691738","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893702","convolutional neural networks;domain adaptation;epitheliumstroma classification;histopathological image analysis;transfer learning","Adaptation models;Feature extraction;Image analysis;Kernel;Machine learning;Neural networks;Training","","","","","","","","20170406","","","IEEE","IEEE Early Access Articles"
"Quality measurement classification for water treatment using neural network with reinforcement programming for weighting optimization","M. F. Dinniy; A. R. Barakhbah; E. M. Kusumaningtyas","Department of Information and Computer Engineering, Politeknik Elektronika Negeri Surabaya, Indonesia","2016 International Conference on Knowledge Creation and Intelligent Computing (KCIC)","20170323","2016","","","126","133","Water Quality is a basic need for human. If the quality level of the water is not appropriate, it will give dangerous impacts to the human life. Therefore, the measurement of the water quality becomes important because it needs specific treatments to make more acceptable for specific uses of the water such as drinkable water, paddy fields, river flow maintenance, water recreation or other environmental preservation purposes. in this paper we present measurement classification of water quality for treatment with involving some parameters of the water such as Biological Oxygen Demand, Chemical Oxygen Demand, Ph, Suspended Solid, etc. We use Neural Network to deal with the classification problems and make classification into 13 types for the water treatment. In this paper we propose our Reinforcement Programming algorithm to optimize weighting mechanism for Neural Network. Reinforcement Programming is an optimization algorithm derived from Reinforcement Learning, a new learning paradigm in machine learning that learns from the interaction with external environments to achieve a goal. Reinforcement Programming improved the Reinforcement Learning by shifting goal-based to function-based approach in order to solve the optimization problems in weighting mechanism of Neural Network. It updated the weights of Neural Network by implementing the exploitation and exploration of Neural Network weights, and then measured the differences of state values from a given state-function to assign a reward or punishment of the state. We applied our proposed Reinforcement Programming to optimize Neural Network weighting mechanism for water quality measurement classification and made series of experimental study with water quality treatment dataset provided by UCI Machine Learning Repository. To scrutinize the applicability of our proposed approach, we made performance comparison with common existing Neural. Neural weight update using Backpropagation. In the experimental results, our prop- sed Reinforcement Programming outperformed Backpropagation for weighting mechanism in precision and time.","","CD:978-1-5090-5229-5; Electronic:978-1-5090-5231-8; POD:978-1-5090-5232-5","10.1109/KCIC.2016.7883636","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883636","neural network;reinforcement programming;water quality classfication;water quality measurement;water treatment","Backpropagation;Machine learning algorithms;Neural networks;Optimization;Programming;Solids;Water pollution","environmental science computing;learning (artificial intelligence);neural nets;optimisation;pattern classification;water quality;water treatment","UCI machine learning repository;biological oxygen demand;chemical oxygen demand;classification problems;drinkable water;environmental preservation;function-based approach;goal-based approach;neural network;optimization algorithm;paddy fields;ph;quality measurement classification;reinforcement learning;reinforcement programming algorithm;river flow maintenance;suspended solid;water quality measurement;water recreation;water treatment;weighting mechanism;weighting optimization","","","","","","","15-17 Nov. 2016","","IEEE","IEEE Conference Publications"
"BiLoc: Bi-Modal Deep Learning for Indoor Localization With Commodity 5GHz WiFi","X. Wang; L. Gao; S. Mao","Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA","IEEE Access","20170424","2017","5","","4209","4220","In this paper, we study fingerprinting-based indoor localization in commodity 5-GHz WiFi networks. We first theoretically and experimentally validate three hypotheses on the channel state information (CSI) data of 5-GHz OFDM channels. We then propose a system termed BiLoc, which uses bi-modality deep learning for localization in the indoor environment using off-the-shelf WiFi devices. We develop a deep learning-based algorithm to exploit bi-modal data, i.e., estimated angle of arrivings and average amplitudes (which are calibrated CSI data using several proposed techniques), for both the off-line and online stages of indoor fingerprinting. The proposed BiLoc system is implemented using commodity WiFi devices. Its superior performance is validated with extensive experiments under three typical indoor environments and through comparison with three benchmark schemes.","2169-3536;21693536","","10.1109/ACCESS.2017.2688362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888438","5GHz commodity WiFi;Indoor localization;bi-modality fingerprinting;channel state information;deep learning;fingerprinting","Antenna measurements;Antennas;Data mining;Feature extraction;Machine learning;OFDM;Wireless fidelity","","","","","","","","20170328","2017","","IEEE","IEEE Journals & Magazines"
"Deep Learning Network Models to Categorize Texts According to Author's Gender and to Identify Text Sentiment","A. Sboev; T. Litvinova; I. Voronina; D. Gudovskikh; R. Rybka","NRC Kurchatov Inst., Moscow Technol. Univ., Moscow, Russia","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","1101","1106","In the present article, we consider a problem to evaluate the gain in accuracy of using deep learning network for two language tasks: the automatic text classification according to the authors gender and to identify text sentiment. A preexisting corpus of Russian-language texts RusPersonality labeled with information on their authors (gender, age, psychological testing and so on) has been used for gender task along with the materials of the SentiRuEval competition for evaluating the sentiment of tweets. We have performed the comparative study of machine learning techniques for both tasks on the Russian-language texts. In case of gender tasks the bias in topics and genre was deliberately removed. The obtained neuronet models of deep learning demonstrate accuracy close to the state-of-the-art and even higher: for the gender identification up to 0.86 +/- 0.03 in Accuracy, 0.86 in F1-score, for sentiment classification the best model demonstrates F1 scores with micro average of 0.57 and macro average of 0.61 for banks dataset, and F1-micro of 0.61 and F1-macro of 0.74 for telekom.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881503","CNN;LSTM;author's gender identification;deep neural network;sentiment analysis;text classification","Indexes;Machine learning;Neurons;Syntactics;Telecommunications;Training;Twitter","learning (artificial intelligence);text analysis","Russian-language texts;SentiRuEval competition;automatic text classification;deep learning network model;machine learning techniques;text categorization","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multilevel Cloud Detection in Remote Sensing Images Based on Deep Learning","F. Xie; M. Shi; Z. Shi; J. Yin; D. Zhao","Beijing Key Laboratory of Digital Media and the Image Processing Center, School of Astronautics, Beihang University, Beijing 100191, China&#x00A0;(e-mail: xfy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2017","PP","99","1","10","Cloud detection is one of the important tasks for remote sensing image processing. In this paper, a novel multilevel cloud detection method based on deep learning is proposed for remote sensing images. First, the simple linear iterative clustering (SLIC) method is improved to segment the image into good quality superpixels. Then, a deep convolutional neural network (CNN) with two branches is designed to extract the multiscale features from each superpixel and predict the superpixel as one of three classes including thick cloud, thin cloud, and noncloud. Finally, the predictions of all the superpixels in the image yield the cloud detection result. In the proposed cloud detection framework, the improved SLIC method can obtain accurate cloud boundaries by optimizing initial cluster centers, designing dynamic distance measure, and expanding search space. Moreover, different from traditional cloud detection methods that cannot achieve multilevel detection of cloud, the designed deep CNN model can not only detect cloud but also distinguish thin cloud from thick cloud. Experimental results indicate that the proposed method can detect cloud with higher accuracy and robustness than compared methods.","1939-1404;19391404","","10.1109/JSTARS.2017.2686488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7895175","Cloud detection;convolutional neural network (CNN);deep learning;remote sensing images;superpixel","Clouds;Clustering algorithms;Feature extraction;Image color analysis;Image segmentation;Machine learning;Remote sensing","","","","","","","","20170412","","","IEEE","IEEE Early Access Articles"
"Internal Fusion Functions","D. Paternain; M. J. Campion; R. Mesiar; I. Perfilieva; H. Bustince","","IEEE Transactions on Fuzzy Systems","","2017","PP","99","1","1","In this work we investigate a mechanism for fusing a set of inputs (values) in such a way that the procedure does not create new information during the process. In order to do so, we introduce internal fusion functions, a family of fusion functions in which the output always corresponds to some of the given inputs. We perform an in-depth theoretical study of internal fusion functions and, furthermore, we propose three different construction methods which are based on (1) an arbitrary fusion function and a partition of the domain; (2) a linear order and (3) a minimization mechanism using penalty functions. Finally, we illustrate this paper with the application of internal fusion functions in two image processing algorithms where a set of images must be fused, namely multi-focus image and denoised image fusion, as well as in an example of multi-class problem, where we fuse a set of score matrices obtained by several classification algorithms.","1063-6706;10636706","","10.1109/TFUZZ.2017.2686345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885066","Fusion functions;aggregation functions;image fusion;internal fusion functions;penalty functions","Biological system modeling;Fuses;Image fusion;Lattices;Machine learning algorithms;Minimization","","","","","","","","20170322","","","IEEE","IEEE Early Access Articles"
"A Collaborative Privacy-Preserving Deep Learning System in Distributed Mobile Environment","M. Liu; H. Jiang; J. Chen; A. Badokhon; X. Wei; M. C. Huang","EECS Dept., Case Western Reserve Univ., Cleveland, OH, USA","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","192","197","In the last couple years, deep learning gained great popularity in health and medical science. For analyzing personal health data, privacy of patients and their data is one of the biggest concerns. Traditional methods have the possibility of leaking data because of transferring raw data and storing all data in centralized houseware. Therefore, we proposed a collaborative privacy-preserving learning system based on deep neural network, which does not share local raw data. The system is implemented on an XMPP server and several mobile devices. In the experiments, reconstructed rate is proposed to evaluate the performance of distributed system compared with centralized training. The rate is over 90% in different scenarios. Furthermore, the network traffic while collaborative learning is also measured.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881336","Collaborative Deep Learning;Distributed System;Mobile Computing;Parameter Selection;Privacy Preserving","Collaboration;Computer architecture;Machine learning;Protocols;Round robin;Servers;Training","data analysis;data privacy;learning (artificial intelligence);mobile computing;neural nets","XMPP server;centralized training;collaborative privacy-preserving deep learning system;deep neural network;distributed mobile environment;personal health data analysis","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Smart Augmentation - Learning an Optimal Data Augmentation Strategy","J. Lemley; S. Bazrafkan; P. Corcoran","Collage of Engineering and Informatics, National University of Ireland Galway, Galway Ireland (Email: j.lemley2@nuigalway.ie)","IEEE Access","","2017","PP","99","1","1","A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks (DNN). There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method which we call Smart Augmentation and we show how to use it to increase the accuracy and reduce overfitting on a target network. Smart Augmentation works by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network.","2169-3536;21693536","","10.1109/ACCESS.2017.2696121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7906545","","Biological neural networks;Data models;Electronic mail;Informatics;Machine learning;Training","","","","","","","","20170424","","","IEEE","IEEE Early Access Articles"
"Deformable Patterned Fabric Defect Detection With Fisher Criterion-Based Deep Learning","Y. Li; W. Zhao; J. Pan","School of Electronic and Information Engineering, North China University of Technology, Beijing, China","IEEE Transactions on Automation Science and Engineering","20170405","2017","14","2","1256","1264","In this paper, we propose a discriminative representation for patterned fabric defect detection when only limited negative samples are available. Fabric patches are efficiently classified into defectless and defective categories by Fisher criterion-based stacked denoising autoencoders (FCSDA). First, fabric images are divided into patches of the same size, and both defective and defectless samples are utilized to train FCSDA. Second, test patches are classified through FCSDA into defective and defectless categories. Finally, the residual between the reconstructed image and defective patch is calculated, and the defect is located by thresholding. Experimental results demonstrate the effectiveness of the proposed scheme in the defect detection for periodic patterned fabric and more complex jacquard warp-knitted fabric.","1545-5955;15455955","","10.1109/TASE.2016.2520955","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398188","Deep learning;Fisher criterion;denoising autoencoder (DA);fabric defect detection;patterned fabric","Fabrics;Inspection;Machine learning;Neural networks;Noise reduction;Training;Transforms","fabrics;flaw detection;image classification;image reconstruction;image segmentation;object detection;production engineering computing;quality control","FCSDA;Fisher criterion-based deep learning;Fisher criterion-based stacked denoising autoencoders;deformable patterned fabric defect detection;fabric patches classification;image reconstruction;jacquard warp-knitted fabric;quality control;thresholding","","","","","","20160203","April 2017","","IEEE","IEEE Journals & Magazines"
"A pressure map dataset for posture and subject analytics","M. B. Pouyan; J. Birjandtalab; M. Heydarzadeh; M. Nourani; S. Ostadabbas","Quality of Life Technology Laboratory, The University of Texas at Dallas, Richardson, TX, 75080 USA","2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","20170413","2017","","","65","68","Monitoring sleep postures can provide critical information when analyzing an individual's sleep quality and in-bed behavior. Furthermore, tracking sleep posture over time can play an important role in preventing pressure ulcers (bedsores) in bed-bound patients who are unable to move and change their position frequently. Pressure sensing mats consist of gridded and flexible force sensors are now commercially available for continuously measuring pressure distribution under body parts in different in-bed postures. In this paper, we report the results of a data collection study conducted in two separate experimental sessions from 13 participants in various sleeping postures using two commercial pressure mats. This resource, released publicly, would benefit future research in the area of sleep behavior/quality and corresponding complications. Moreover, we have employed an algorithm based on deep learning for subject identification in the three common sleeping postures using statistical features extracted from the pressure distribution. Our experiments showed promising results in subject identification and further validated the personal sleeping style of each participant.","","Electronic:978-1-5090-4179-4; POD:978-1-5090-4180-0","10.1109/BHI.2017.7897206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897206","","Data collection;Feature extraction;Machine learning;Monitoring;Sensors;Sleep apnea;Standards","","","","","","","","","16-19 Feb. 2017","","IEEE","IEEE Conference Publications"
"Object-Based Convolutional Neural Network for High-Resolution Imagery Classification","W. Zhao; S. Du; W. J. Emery","Beijing Key Laboratory of Spatial Information Integration and Its Applications, Institute of Remote Sensing and Geographic Information System, Peking University, Beijing100871, China (e-mail: w.zhao@pku.edu.cn).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2017","PP","99","1","11","Timely and accurate classification and interpretation of high-resolution images are very important for urban planning and disaster rescue. However, as spatial resolution gets finer, it is increasingly difficult to recognize complex patterns in high-resolution remote sensing images. Deep learning offers an efficient strategy to fill the gap between complex image patterns and their semantic labels. However, due to the hierarchical abstract nature of deep learning methods, it is difficult to capture the precise outline of different objects at the pixel level. To further reduce this problem, we propose an object-based deep learning method to accurately classify the high-resolution imagery without intensive human involvement. In this study, high-resolution images were used to accurately classify three different urban scenes: Beijing (China), Pavia (Italy), and Vaihingen (Germany). The proposed method is built on a combination of a deep feature learning strategy and an object-based classification for the interpretation of high-resolution images. Specifically, high-level feature representations extracted through the convolutional neural networks framework have been systematically investigated over five different layer configurations. Furthermore, to improve the classification accuracy, an object-based classification method also has been integrated with the deep learning strategy for more efficient image classification. Experimental results indicate that with the combination of deep learning and object-based classification, it is possible to discriminate different building types in Beijing Scene, such as commercial buildings and residential buildings with classification accuracies above 90%.","1939-1404;19391404","","10.1109/JSTARS.2017.2680324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890382","Convolutional neural network (CNN);deep learning;high-resolution image;image classification","Feature extraction;Image segmentation;Machine learning;Neural networks;Remote sensing;Robustness;Spatial resolution","","","","","","","","20170330","","","IEEE","IEEE Early Access Articles"
"Evaluations of deep convolutional neural networks for automatic identification of malaria infected cells","Y. Dong; Z. Jiang; H. Shen; W. David Pan; L. A. Williams; V. V. B. Reddy; W. H. Benjamin; A. W. Bryan","Dept. of Electrical and Computer Engineering, University of Alabama in Huntsville, Huntsville, AL 35899, USA","2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","20170413","2017","","","101","104","This paper studied automatic identification of malaria infected cells using deep learning methods. We used whole slide images of thin blood stains to compile an dataset of malaria-infected red blood cells and non-infected cells, as labeled by a group of four pathologists. We evaluated three types of well-known convolutional neural networks, including the LeNet, AlexNet and GoogLeNet. Simulation results showed that all these deep convolution neural networks achieved classification accuracies of over 95%, higher than the accuracy of about 92% attainable by using the support vector machine method. Moreover, the deep learning methods have the advantage of being able to automatically learn the features from the input data, thereby requiring minimal inputs from human experts for automated malaria diagnosis.","","Electronic:978-1-5090-4179-4; POD:978-1-5090-4180-0","10.1109/BHI.2017.7897215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897215","","Diseases;Feature extraction;Machine learning;Neural networks;Support vector machines;Testing;Training","biology computing;cellular biophysics;diseases;neural nets;support vector machines","AlexNet;GoogLeNet;cell automatic identification;deep convolutional neural networks;deep learning;malaria infected cells;support vector machine;thin blood stains;whole slide images","","","","","","","16-19 Feb. 2017","","IEEE","IEEE Conference Publications"
"Finetuning Convolutional Neural Networks for visual aesthetics","Yeqing Wang; Yi Li; F. Porikli","Changzhou College of Information Technology, China","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3554","3559","Inferring the aesthetic quality of images is a challenging computer vision task due to its subjective and conceptual nature. Most image aesthetics evaluation approaches focused on designing handcrafted features, and only a few adopted learning of relevant and imperative characteristics in a data-driven manner. In this paper, we propose to attune Convolutional Neural Networks (CNNs) for image aesthetics. Unlike previous deep learning based techniques, we employ pretrained models, namely AlexNet [12] and the 16-layer VGGNet [20], and calibrate them to estimate visual aesthetic quality. This enables exploiting automatically the inherent information from much larger scale and more diversified image datasets. We tested our methods on AVA and CUHKPQ image aesthetics datasets on two different training-testing partitions, and compared the performance using both local and contextual information. Experimental results suggest that our strategy is robust, effective and superior to the state-of-the-art approaches.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900185","Deep learning;visual aesthetics","Computer vision;Feature extraction;Machine learning;Neural networks;Semantics;Training;Visualization","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Integrated Learning System for Object Recognition from Images Based on Convolutional Neural Network","H. J. Jeong; M. J. Lee; Y. G. Ha","Dept. of Comput. Sci. & Eng., Konkuk Univ., Seoul, South Korea","2016 International Conference on Computational Science and Computational Intelligence (CSCI)","20170320","2016","","","824","828","There has been an increase in the use of image processing for object recognition. However, traditional methods are not suitable in real-time system because they cannot satisfy human performance. Recently, deep learning with Convolutional Neural Network came to be known as a solution for image recognition. In fact, there are many great result with deep learning in object recognition. However, it needs a number of images to learn. In other words, it is necessary to manage images and categories. This paper proposes integrated object recognition system which manages and learns images. This system collects images automatically in classified categories and learns images in high accuracy. And multiple On-Board computer can share proposed learning system.","","Electronic:978-1-5090-5510-4; POD:978-1-5090-5511-1","10.1109/CSCI.2016.0160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881453","Convolutional Neural Network;crawler;deep learning;image recognition;ontology","Crawlers;Image recognition;Machine learning;Neural networks;Object recognition;Ontologies;Servers","learning (artificial intelligence);neural nets;object recognition","convolutional neural network;deep learning;image processing;image recognition;integrated learning system;integrated object recognition system;on-board computer","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multi-Objective based Spatio-Temporal Feature Representation Learning Robust to Expression Intensity Variations for Facial Expression Recognition","D. H. Kim; W. Baddar; J. Jang; Y. M. Ro","","IEEE Transactions on Affective Computing","","2017","PP","99","1","1","Facial expression recognition (FER) is increasingly gaining importance in various emerging affective computing applications. In practice, achieving accurate FER is challenging due to the large amount of inter-personal variations such as expression intensity variations. In this paper, we propose a new spatio-temporal feature representation learning for FER that is robust to expression intensity variations. The proposed method utilizes representative expression-states (e.g., onset, apex and offset of expressions) which can be specified in facial sequences regardless of the expression intensity. The characteristics of facial expressions are encoded in two parts in this paper. As the first part, spatial image characteristics of the representative expression-state frames are learned via a convolutional neural network. Five objective terms are proposed to improve the expression class separability of the spatial feature representation. In the second part, temporal characteristics of the spatial feature representation in the first part are learned with a long short-term memory of the facial expression. Comprehensive experiments have been conducted on a deliberate expression dataset (MMI) and a spontaneous micro-expression dataset (CASME II). Experimental results showed that the proposed method achieved higher recognition rates in both datasets compared to the state-of-the-art methods.","1949-3045;19493045","","10.1109/TAFFC.2017.2695999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7904596","Facial expression recognition (FER);deep learning;expression intensity variation;long short-term memory (LSTM);spatio-temporal feature representation","Face recognition;Feature extraction;Machine learning;Neural networks;Robustness;Three-dimensional displays;Training","","","","","","","","20170419","","","IEEE","IEEE Early Access Articles"
"Hybrid deep learning for Reflectance Confocal Microscopy skin images","P. Kaur; K. J. Dana; G. O. Cula; M. C. Mack","Department of Electrical and Computer Engineering, Rutgers University, NJ, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1466","1471","Reflectance Confocal Microscopy (RCM) is used for evaluation of human skin disorders and the effects of skin treatments by imaging the skin layers at different depths. Traditionally, clinical experts manually categorize the images captured into different skin layers. This time-consuming labeling task impedes the convenient analysis of skin image datasets. In recent automated image recognition tasks, deep learning with convolutional neural nets (CNN) has achieved remarkable results. However in many clinical settings, training data is often limited and insufficient for CNN training. For recognition of RCM skin images, we demonstrate that a CNN trained on a moderate size dataset leads to low accuracy. We introduce a hybrid deep learning approach which uses traditional texton-based feature vectors as input to train a deep neural network. This hybrid method uses fixed filters in the input layer instead of tuned filters, yet superior performance is achieved. Our dataset consists of 1500 images from 15 RCM stacks belonging to six different categories of skin layers. We show that our hybrid deep learning approach performs with a test accuracy of 82% compared with 51% for CNN. We also compare the results with additional proposed methods for RCM image recognition and show improved accuracy.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899844","","Epidermis;Histograms;Image recognition;Libraries;Machine learning;Neural networks","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Detection of groups in crowd considering their activity state","K. Nakamura; T. Ono; N. Babaguchi","Graduate School of Engineering, Osaka University, 2-1 Yamadaoka, Suita, 565-0871 Japan","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","277","282","In this paper, we focus on the problem of group detection in crowd, which is a task of partitioning a set of pedestrians in a scene into small subsets called groups based on their trajectories. Most of previous methods use only a single model for representing a relationship between trajectories of pedestrians who belong to the same group. However, such relationship would vary depending on the activity state (e.g. walking together, approaching, splitting, and so on) of the group. In this paper, we propose a novel group detection method which can cope with a variation of groups' activity state. The proposed method constructs different models for each activity state in order to appropriately evaluate the relationship of pedestrians' trajectories. In addition, our method regards groups' activity state as hidden variables and estimates their probability distributions, which is used for integrating the constructed models. The proposed method outperforms existing methods in the experiment on the public dataset.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899646","activity state of groups;group detection;structural SVM (SSVM)","Force;Legged locomotion;Machine learning algorithms;Support vector machines;Testing;Training;Trajectory","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"HD-MTL: Hierarchical Deep Multi-Task Learning for Large-Scale Visual Recognition","J. Fan; T. Zhao; Z. Kuang; Y. Zheng; J. Zhang; J. Yu; J. Peng","Department of Computer Science, The University of North Carolina at Charlotte, Charlotte, NC, USA","IEEE Transactions on Image Processing","20170329","2017","26","4","1923","1938","In this paper, a hierarchical deep multi-task learning (HD-MTL) algorithm is developed to support large-scale visual recognition (e.g., recognizing thousands or even tens of thousands of atomic object classes automatically). To achieve more effective accomplishment of the coarse-to-fine tasks for hierarchical visual recognition, multiple sets of deep features are first extracted from the different layers of deep convolutional neural networks (deep CNNs). A visual tree is then learned by assigning the visually-similar atomic object classes with similar learning complexities into the same group, and it can provide a good environment for identifying the inter-related learning tasks automatically. By leveraging the inter-task relatedness (inter-class similarities) to learn more discriminative group-specific deep representations, our deep multi-task learning algorithm can achieve the global optimum easily and obtain more discriminative node classifiers for distinguishing the visually-similar atomic object classes (in the same group) effectively. Our HD-MTL algorithm can control the inter-level error propagation effectively by using an end-to-end approach for jointly learning more representative deep CNNs (for image representation) and more discriminative tree classifier (for large-scale visual recognition) and updating them simultaneously. Our incremental deep learning algorithms can effectively adapt both the deep CNNs and the tree classifier to the new training images and the new object classes. Our experimental results have demonstrated that our HD-MTL algorithm can achieve very competitive results on both the accuracy rates and the computational efficiency for large-scale visual recognition.","1057-7149;10577149","","10.1109/TIP.2017.2667405","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849143","Large-scale visual recognition;group-specific deep representations;hierarchical deep multi-task learning (HD-MTL);incremental deep learning;soft prediction;tree classifier","Atomic layer deposition;Feature extraction;Image recognition;Image representation;Machine learning;Training;Visualization","feature extraction;image classification;image recognition;learning (artificial intelligence);neural nets;trees (mathematics)","HD-MTL;deep CNN;deep convolutional neural networks;deep feature extraction;group-specific deep representations;hierarchical deep multitask learning algorithm;incremental deep learning algorithms;inter-related learning tasks;large-scale visual recognition;visual tree","","","","","","20170209","April 2017","","IEEE","IEEE Journals & Magazines"
"Deep learning for facial expression recognition: A step closer to a smartphone that knows your moods","S. Bazrafkan; T. Nedelcu; P. Filipczuk; P. Corcoran","Center for Cognitive, Connected & Computational Imaging, College of Engineering & Informatics, NUI Galway, Ireland","2017 IEEE International Conference on Consumer Electronics (ICCE)","20170330","2017","","","217","220","By growing the capacity and processing power of the handheld devices nowadays, a wide range of capabilities can be implemented in these devices to make them more intelligent and user friendly. Determining the mood of the user can be used in order to provide suitable reactions from the device in different conditions. One of the most studied ways of mood detection is by using facial expressions, which is still one of the challenging fields in pattern recognition and machine learning science. Deep Neural Networks (DNN) have been widely used in order to overcome the difficulties in facial expression classification. In this paper it is shown that the classification accuracy is significantly lower when the network is trained with one database and tested with a different database. A solution for obtaining a general and robust network is given as well.","","Electronic:978-1-5090-5544-9; POD:978-1-5090-5545-6","10.1109/ICCE.2017.7889290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889290","","Conferences;Consumer electronics;Databases;Face;Feature extraction;Machine learning;Training","emotion recognition;face recognition;image classification;learning (artificial intelligence);neural nets;smart phones","DNN;deep neural network training;facial expression classification;handheld devices;machine learning science;pattern recognition;smartphone","","","","","","","8-10 Jan. 2017","","IEEE","IEEE Conference Publications"
"Similarity-Based Multiple Kernel Learning Algorithms for Classification of Remotely Sensed Images","S. Niazmardi; A. Safari; S. Homayouni","School of Surveying and Geospatial Engineering, College of Engineering, University of Tehran, Tehran, Iran","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20170412","2017","10","5","2012","2021","Multiple kernel learning (MKL) algorithms are proposed to address the problems associated with kernel selection of the kernel-based classification algorithms. Using a group of kernels rather than one single kernel, the MKL algorithms aim to provide better classification efficiency. This paper presents new similarity-based MKL algorithms to classify remote-sensing images. These algorithms find the optimal combination of kernels by maximizing the similarity between a combination of kernels and an ideal kernel. In this framework, we initially introduced three similarity measures to be used: kernel alignment, norm of kernel difference, and Hilbert-Schmidt independence criterion. Then, we proposed to solve the optimization problems of the MKL algorithm associated with each similarity measure adopting heuristic and convex optimization methods. The performances of the proposed algorithms were compared with a single kernel support vector machines as well as other MKL algorithms for classifying the features extracted from the high-resolution and hyperspectral images. The results demonstrated that the similarity-based MKL algorithms performed better than other algorithms, especially when their optimization problems were solved using the convex optimization methods or when few training samples were available. Moreover, when the optimization problems of these algorithms were solved using the heuristic optimization methods, they were able to yield acceptable performances and were faster than other MKL algorithms.","1939-1404;19391404","","10.1109/JSTARS.2017.2662484","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862816","Kernel-based classification;multiple kernel learning (MKL);remote-sensing image classification","Classification algorithms;Hyperspectral imaging;Kernel;Machine learning algorithms;Optimization;Support vector machines","feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);remote sensing","Hilbert-Schmidt independence criterion;classification efficiency;convex optimization method;feature extraction;heuristic optimization method;high-resolution image;hyperspectral image;kernel alignment;kernel-based classification algorithm;multiple kernel learning algorithm;remotely sensed image classification;single kernel SVM;support vector machine","","","","","","20170223","May 2017","","IEEE","IEEE Journals & Magazines"
"Deep learning-based intra prediction mode decision for HEVC","T. Laude; J. Ostermann","Institut f&#x00FC;r Informationsverarbeitung, Leibniz Universit&#x00E4;t Hannover, Appelstra&#x00DF;e 9a, 30167 Hannover, Germany","2016 Picture Coding Symposium (PCS)","20170424","2016","","","1","5","The High Efficiency Video Coding standard and its screen content coding extension provide superior coding efficiency compared to predecessor standards. However, this coding efficiency is achieved at the expense of very complex encoders. One major complexity driver is the comprehensive rate distortion (RD) optimization. In this paper, we present a deep learning-based encoder control which replaces the conventional RD optimization for the intra prediction mode with deep convolutional neural network (CNN) classifiers. Thereby, we save the RD optimization complexity. Our classifiers operate independently of any encoder decisions and reconstructed sample values. Thus, no additional systematic latency is introduced. Furthermore, the loss in coding efficiency is negligible with an average value of 0.52% over HM-16.6+SCM-5.2.","","Electronic:978-1-5090-5966-9; POD:978-1-5090-5967-6","10.1109/PCS.2016.7906399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7906399","","Complexity theory;Convolutional codes;Encoding;Machine learning algorithms;Optimization;Standards;Video coding","","","","","","","","","4-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"A character-level convolutional neural network with dynamic input length for Thai text categorization","T. Koomsubha; P. Vateekul","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2017 9th International Conference on Knowledge and Smart Technology (KST)","20170327","2017","","","101","105","A Character-level Convolutional Neural Network (Char-CNN) is an efficient text categorization method. It can be used in categorization task without a word segmentation step, which is necessary by traditional method for Thai. Currently, the existing model of Char-CNN uses a fixed input length and requires cutting off exceeding characters, which may lead to a missing of important content. In this paper, we propose a new Char-CNN model with a capability to accept any length of input by employing k-max pooling before a fully connected layer. The result shows that our model outperforms a Char-CNN model with a fixed input length on Thai news categorization. Moreover, our proposed method gives a better accuracy than many word-level methods: Naive Bayes, Logistic Regression, Support Vector Machine except a word-level CNN.","","Electronic:978-1-4673-9077-4; POD:978-1-4673-9078-1","10.1109/KST.2017.7886102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886102","Character-level Convolutional Neural Network;Deep Learning;Dynamic Input Length;Thai Text Categorization","Computational modeling;Computer architecture;Machine learning;Natural languages;Neural networks;Text categorization","information resources;neural nets;regression analysis;support vector machines;text analysis","Char-CNN model;Naive Bayes;Thai news categorization;Thai text categorization;character-level convolutional neural network;dynamic input length;k-max pooling;logistic regression;support vector machine;word segmentation step;word-level CNN;word-level methods","","","","","","","1-4 Feb. 2017","","IEEE","IEEE Conference Publications"
"Cascaded Hidden Space Feature Mapping, Fuzzy Clustering, and Nonlinear Switching Regression on Large Datasets","J. Wang; H. Liu; X. Qian; Y. Jiang; Z. Deng; S. Wang","School of Digital Media, Jiangnan University, Wuxi, China, 214122, Department of Radiology and BRIC, School of Medicine, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA, 27599, and Fujian Provincial Key Laboratory of Information Processing and Intelligent Control (Minjiang University), Fuzhou, China.","IEEE Transactions on Fuzzy Systems","","2017","PP","99","1","1","The success of fuzzy clustering heavily relies on the features of the input data. Based on the fact that deep architectures are able to more accurately characterize the data representations in a layer-by-layer manner, this paper proposes a novel feature mapping technique called cascaded hidden-space (CHS) feature mapping and investigates its combination with classical fuzzy c-means (FCM) and fuzzy c-regressions (FCR). Since the parameters between the layers of CHS feature mapping are randomly generated and need not be tuned layer-by-layer, CHS is easily implemented with less training data. By performing classical FCM in CHS, a novel fuzzy clustering framework called CHS-FCM is developed; several of its variants are presented using different dimension-reduction methods in CHS-FCM clustering framework. The combination of CHS-FCM with nonlinear switch regressions is called CHS-FCR, and it performs FCR in CHS. The proposed CHS-FCR provides better results than FCR for nonlinear process modeling. Both CHS-FCM and CHS-FCR exhibit low memory consumption and require less training data. The experimental results verify the superiority of the proposed methods over classical fuzzy clustering methods.","1063-6706;10636706","","10.1109/TFUZZ.2017.2687407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886302","Cascaded hidden-space feature mapping;fuzzy clustering;nonlinear switching regressions","Clustering algorithms;Clustering methods;Kernel;Machine learning algorithms;Prototypes;Switches;Training data","","","","","","","","20170324","","","IEEE","IEEE Early Access Articles"
"Native malware detection in smartphones with android OS using static analysis, feature selection and ensemble classifiers","S. Morales-Ortega; P. J. Escamilla-Ambrosio; A. Rodriguez-Mota; L. D. Coronado-De-Alba","Instituto Polit&#233;cnico Nacional, Centro de Investigaci&#243;n en Computaci&#243;n, Mexico","2016 11th International Conference on Malicious and Unwanted Software (MALWARE)","20170330","2016","","","1","8","The use of Smartphones (SPs)with Android Operating System (AOS) has reached unprecedented popularity. This is due to the many features that these devices offer as Internet connection, storage of information as well as the ability to perform diverse online transactions. As a result, these devices have become the main target of malware attacks that try to exploit the security vulnerabilities of AOS.Therefore, in order to mitigate these attacks, methods for malware analysis and detection are needed.In this work a method for analysis and detection of malware, which can run natively in the device, is proposed. The approach can analyze applications already installed on the device, monitor new apps installations or updates. Static analysis is used to determine the permissions, hardware and software features requested by applications. An application being analyzed is classified as malware or benign using a model based on ensemble machine learning classifiers and feature selection algorithms. To validate the proposed method, 1377 malware samples and 1377 benign samples, collected from different sources, were used.Results show that the proposed approach detects malware with 96.26%of accuracy. Additional tests were conducted in three different SPs devices to validate malware detection performance in a real environment andto obtain an average execution time. Results of these tests show that the proposed method detects malware with 94.48% of accuracy, getting the analysis results of an application in 35milliseconds.","","Electronic:978-1-5090-4542-6; POD:978-1-5090-4543-3","10.1109/MALWARE.2016.7888731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888731","","Androids;Classification algorithms;Feature extraction;Humanoid robots;Machine learning algorithms;Malware;Performance evaluation","Android (operating system);feature selection;invasive software;learning (artificial intelligence);pattern classification;program diagnostics;smart phones","AOS vulnerabilities;Android OS;Android operating system;SP;average execution time;ensemble machine learning classifiers;feature selection algorithms;malware analysis;malware attack mitigation;malware detection;smart phones;software features;static analysis","","","","","","","18-21 Oct. 2016","","IEEE","IEEE Conference Publications"
"Online Transfer Learning with Multiple Homogeneous or Heterogeneous Sources","Q. Wu; H. Wu; X. Zhou; M. Tan; Y. Xu; Y. Yan; T. Hao","School of Software, South China University of Technology (e-mail: qyw@ scut.edu.cn).","IEEE Transactions on Knowledge and Data Engineering","","2017","PP","99","1","1","Transfer learning techniques have been broadly applied in applications where labeled data in a target domain are difficult to obtain while a lot of labeled data are available in related source domains. In practice, there can be multiple source domains that are related to the target domain, and how to combine them is still an open problem. In this paper, we seek to leverage labeled data from multiple source domains to enhance classification performance in a target domain where the target data are received in an online fashion. This problem is known as the online transfer learning problem. To achieve this, we propose novel online transfer learning paradigms in which the source and target domains are leveraged adaptively. We consider two different problem settings: homogeneous transfer learning, and heterogeneous transfer learning. The proposed methods work in an online manner, where the weights of the source domains are adjusted dynamically. We provide the mistake bounds of the proposed methods and perform comprehensive experiments on real-world data sets to demonstrate the effectiveness of the proposed algorithms.","1041-4347;10414347","","10.1109/TKDE.2017.2685597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883886","Online transfer learning;heterogeneous transfer;multiple source domains","Computer vision;Data mining;Kernel;Machine learning algorithms;Silicon;Training;Training data","","","","","","","","20170321","","","IEEE","IEEE Early Access Articles"
"Learning to semantically segment high-resolution remote sensing images","K. Nogueira; M. Dalla Mura; J. Chanussot; W. R. Schwartz; J. A. dos Santos","Department of Computer Science, Universidade Federal de Minas Gerais, Brazil","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3566","3571","Land cover classification is a task that requires methods capable of learning high-level features while dealing with high volume of data. Overcoming these challenges, Convolutional Networks (ConvNets) can learn specific and adaptable features depending on the data while, at the same time, learn classifiers. In this work, we propose a novel technique to automatically perform pixel-wise land cover classification. To the best of our knowledge, there is no other work in the literature that perform pixel-wise semantic segmentation based on data-driven feature descriptors for high-resolution remote sensing images. The main idea is to exploit the power of ConvNet feature representations to learn how to semantically segment remote sensing images. First, our method learns each label in a pixel-wise manner by taking into account the spatial context of each pixel. In a predicting phase, the probability of a pixel belonging to a class is also estimated according to its spatial context and the learned patterns. We conducted a systematic evaluation of the proposed algorithm using two remote sensing datasets with very distinct properties. Our results show that the proposed algorithm provides improvements when compared to traditional and state-of-the-art methods that ranges from 5 to 15% in terms of accuracy.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900187","Deep Learning;Feature Learning;High-resolution Images;Land-cover Mapping;Pixel-wise Classification;Remote Sensing;Semantic Segmentation","Context;Feature extraction;Image segmentation;Machine learning;Remote sensing;Semantics;Visualization","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep learning for integrated hand detection and pose estimation","T. Y. Chen; M. Y. Wu; Y. H. Hsieh; L. C. Fu","Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, ROC","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","615","620","We propose a novel framework which integrates human hand detection and pose estimation into one single pipeline. Unlike most of previous works which only focus on the pose estimation part subject to some strong assumptions or relying on a weak detector to detect human hands, we employ a deep learning architecture to complete both aforementioned tasks. By letting three different neural networks share the convolutional layers, this deeply learning architecture can efficiently and accurately detect human hands and compute their hand pose configuration. Moreover, we propose a new energy function to optimize the predicted result of convolutional neural network. To validate the proposed framework, experiments have been conducted and the results show that our approach is highly reliable and suitable for real-world applications.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899702","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899702","convolutional neural network;deep learning;hand detection;pose estimation","Detectors;Feature extraction;Machine learning;Neural networks;Pose estimation;Proposals;Reliability","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Release Planning of Mobile Apps Based on User Reviews","L. Villarroel; G. Bavota; B. Russo; R. Oliveto; M. Di Penta","Free Univ. of Bozen-Bolzano, Bolzano, Italy","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","20170403","2016","","","14","24","Developers have to to constantly improve their apps by fixing critical bugs and implementing the most desired features in order to gain shares in the continuously increasing and competitive market of mobile apps. A precious source of information to plan such activities is represented by reviews left by users on the app store. However, in order to exploit such information developers need to manually analyze such reviews. This is something not doable if, as frequently happens, the app receives hundreds of reviews per day. In this paper we introduce CLAP (Crowd Listener for releAse Planning), a thorough solution to (i) categorize user reviews based on the information they carry out (e.g., bug reporting), (ii) cluster together related reviews (e.g., all reviews reporting the same bug), and (iii) automatically prioritize the clusters of reviews to be implemented when planning the subsequent app release. We evaluated all the steps behind CLAP, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. Also, given the availability of CLAP as a working tool, we assessed its practical applicability in industrial environments.","","Electronic:978-1-4503-3900-1; POD:978-1-5090-2071-3","10.1145/2884781.2884818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886888","","Computer bugs;Machine learning algorithms;Merging;Mobile communication;Planning;Software;Thesauri","mobile computing;software maintenance","CLAP;app store;crowd listener for release planning;information source;mobile applications;release planning;user review","","","","","","","14-22 May 2016","","IEEE","IEEE Conference Publications"
"Survey of scaling platforms for Deep Neural Networks","A. A. Ratnaparkhi; E. Pilli; R. C. Joshi","Department of Computer Science and Engineering, Graphic Era University, Dehradun, India","2016 International Conference on Emerging Trends in Communication Technologies (ETCT)","20170323","2016","","","1","6","Deep Neural Networks have become a state of the art approach in perception processing like speech recognition, image processing and natural language processing. Many state of the art benchmarks for these algorithms are using deep learning techniques. The deep neural networks in today's applications need to process very large amount of data. Different approaches have been proposed to solve scaling these algorithms. Few approach look for providing a solution over existing big data processing platform which usually runs over a large scale commodity cpu cluster. As training deep learning workload require many small computations to be done and large communication to pass the data between layers, General Purpose GPUs seems to the best platforms to train these networks. Different approaches have been proposed to scale processing on cluster of GPU servers. We have summarized various approaches used in this regard. The human brain is very good in processing perception and takes very little space and energy as compared to today's computing platforms. Neuromorphic hardware has been developed by different research groups to provide a brain like computing platform. We will look into IBM TrueNorth system in detail in this regard. Quantum computing gives another way to look in to this problem. Quantum computer can solve many complex problems as compared to classical computer. Though this field is still very nascent, people have suggested various ways to train neural network using quantum computers We will look in to recent quantum computers developed by different organizations like D-Wave and IBM. We will also look into state of the art proposed approaches to run deep neural network algorithms using quantum computer.","","Electronic:978-1-5090-4505-1; POD:978-1-5090-4506-8","10.1109/ETCT.2016.7882969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882969","big data;deep learning;deep neural network;neuromorphic machines;quantum computing","Computer architecture;Computers;Data models;Machine learning;Neural networks;Quantum computing;Training","Big Data;brain;general purpose computers;graphics processing units;learning (artificial intelligence);neural nets;quantum computing","Big Data processing;deep learning;deep neural networks;general purpose GPUs;human brain;neuromorphic hardware;perception processing;quantum computing","","","","","","","18-19 Nov. 2016","","IEEE","IEEE Conference Publications"
"Gradual Complex Numbers and Their Application for Performance Evaluation Classifiers","E. L. Silva; R. H. N. Santiago; A. M. P. Canuto; R. O. Nunes","","IEEE Transactions on Fuzzy Systems","","2017","PP","99","1","1","Usually, the evaluation of the classifiers performance is not an easy task to be performed, mainly when we analyze different criteria (output parameters). In this evaluation process, we can use quantitative measures (accuracy, specificity, among others), however when the output values are very close and we have several criteria, the results are difficult to be interpreted by users. This paper aims to propose a new linguistic model to evaluate the performance of several classifiers. It is based on the notion of Gradual Complex Numbers (GCN), proposed in [19]. In this paper, we present the theoretical basis of GCNs for classifier evaluator and we assess the performance of the proposed model (GCN) through an empirical study. In addition, the performance of GCN is compared with that of Fuzzy Complex Numbers (FCN),[6], and it reveals gains.","1063-6706;10636706","","10.1109/TFUZZ.2017.2688390","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888458","","Algorithm design and analysis;Classification algorithms;Cognition;Machine learning algorithms;Modules (abstract algebra);Performance evaluation;Pragmatics","","","","","","","","20170328","","","IEEE","IEEE Early Access Articles"
"Deep Relative Tracking","J. Gao; T. Zhang; X. Yang; C. Xu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Image Processing","20170329","2017","26","4","1845","1858","Most existing tracking methods are direct trackers, which directly exploit foreground or/and background information for object appearance modeling and decide whether an image patch is target object or not. As a result, these trackers cannot perform well when target appearance changes heavily and becomes different from its model. To deal with this issue, we propose a novel relative tracker, which can effectively exploit the relative relationship among image patches from both foreground and background for object appearance modeling. Different from direct trackers, the proposed relative tracker is robust to localize target object by use of the best image patch with the highest relative score to the target appearance model. To model relative relationship among large-scale image patch pairs, we propose a novel and effective deep relative learning algorithm through the convolutional neural network. We test the proposed approach on challenging sequences involving heavy occlusion, drastic illumination changes, and large pose variations. Experimental results show that our method consistently outperforms the state-of-the-art trackers due to the powerful capacity of the proposed deep relative model.","1057-7149;10577149","","10.1109/TIP.2017.2656628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828108","Visual tracking;deep learning;relative model","Machine learning;Robustness;Support vector machines;Target tracking;Training;Visualization","learning (artificial intelligence);neural nets;object tracking","background information;convolutional neural network;deep relative learning algorithm;deep relative tracking method;foreground information;large-scale image patch pairs;object appearance modeling;target appearance model;target object localization","","","","","","20170120","April 2017","","IEEE","IEEE Journals & Magazines"
"Applying Deep Learning in Augmented Reality Tracking","O. Akgul; H. I. Penekli; Y. Genc","","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","20170424","2016","","","47","54","An existing deep learning architecture has been adapted to solve the detection problem in camera-based tracking for augmented reality (AR). A known target, in this case a planar object, is rendered under various viewing conditions including varying orientation, scale, illumination and sensor noise. The resulting corpus is used to train a convolutional neural network to match given patches in an incoming image. The results show comparable or better performance compared to state of art methods. Timing performance of the detector needs improvement but when considered in conjunction with the robust pose estimation process promising results are shown.","","Electronic:978-1-5090-5698-9; POD:978-1-5090-5699-6","10.1109/SITIS.2016.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907444","augmented reality;deep learning;marker detection;marker tracker","Detectors;Feature extraction;Lighting;Machine learning;Robustness;Target tracking;Training","","","","","","","","","Nov. 28 2016-Dec. 1 2016","","IEEE","IEEE Conference Publications"
"Bad teacher or unruly student: Can deep learning say something in Image Forensics analysis?","P. Rota; E. Sangineto; V. Conotter; C. Pramerdorfer","CVL, Vienna University of Technology (Austria)","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","2503","2508","The pervasive availability of the Internet, coupled with the development of increasingly powerful technologies, has led digital images to be the primary source of visual information in nowadays society. However, their reliability as a true representation of reality cannot be taken for granted, due to the affordable powerful graphics editing softwares that can easily alter the original content, leaving no visual trace of any modification on the image making them potentially dangerous. This motivates developing technological solutions able to detect media manipulations without a prior knowledge or extra information regarding the given image. At the same time, the huge amount of available data has also led to tremendous advances of data-hungry learning models, which have already demonstrated in last few years to be successful in image classification. In this work we propose a deep learning approach for tampered image classification. To our best knowledge, this the first attempt to use the deep learning paradigm in an image forensic scenario. In particular, we propose a new blind deep learning approach based on Convolutional Neural Networks (CNN) able to learn invisible discriminative artifacts from manipulated images that can be exploited to automatically discriminate between forged and authentic images. The proposed approach not only detects forged images but it can be extended to localize the tampered regions within the image. This method outperforms the state-of-the-art in terms of accuracy on CASIA TIDE v2.0 dataset. The capability of automatically crafting discriminant features can lead to surprising results. For instance, detecting image compression filters used to create the dataset. This argument is also discussed within this paper.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900012","","Computer architecture;Feature extraction;Image forensics;Machine learning;Neural networks;Tides;Training","","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Superpixel-Based Multiple Local CNN for Panchromatic and Multispectral Image Classification","W. Zhao; L. Jiao; W. Ma; J. Zhao; J. Zhao; H. Liu; X. Cao; S. Yang","Key Laboratory of Intelligent Perception and Image Understanding, International Research Center of Intelligent Perception and Computation, Ministry of Education of China, School of Electronic Engineering, Xidian University, Xi'an 710071, China.","IEEE Transactions on Geoscience and Remote Sensing","","2017","PP","99","1","16","Recently, very high resolution (VHR) panchromatic and multispectral (MS) remote-sensing images can be acquired easily. However, it is still a challenging task to fuse and classify these VHR images. Generally, there are two ways for the fusion and classification of panchromatic and MS images. One way is to use a panchromatic image to sharpen an MS image, and then classify a pan-sharpened MS image. Another way is to extract features from panchromatic and MS images, respectively, and then combine these features for classification. In this paper, we propose a superpixel-based multiple local convolution neural network (SML-CNN) model for panchromatic and MS images classification. In order to reduce the amount of input data for the CNN, we extend simple linear iterative clustering algorithm for segmenting MS images and generating superpixels. Superpixels are taken as the basic analysis unit instead of pixels. To make full advantage of the spatial-spectral and environment information of superpixels, a superpixel-based multiple local regions joint representation method is proposed. Then, an SML-CNN model is established to extract an efficient joint feature representation. A softmax layer is used to classify these features learned by multiple local CNN into different categories. Finally, in order to eliminate the adverse effects on the classification results within and between superpixels, we propose a multi-information modification strategy that combines the detailed information and semantic information to improve the classification performance. Experiments on the classification of Vancouver and Xi'an panchromatic and MS image data sets have demonstrated the effectiveness of the proposed approach.","0196-2892;01962892","","10.1109/TGRS.2017.2689018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7904689","Convolution neural network (CNN);image classification;multiple local regions joint representation;panchromatic and multispectral (MS) images;superpixel-based.","Feature extraction;Image color analysis;Image segmentation;Machine learning;Neural networks;Remote sensing;Semantics","","","","","","","","20170419","","","IEEE","IEEE Early Access Articles"
"Selective Convolutional Descriptor Aggregation for Fine-Grained Image Retrieval","X. S. Wei; J. H. Luo; J. Wu; Z. H. Zhou","National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","IEEE Transactions on Image Processing","20170424","2017","26","6","2868","2881","Deep convolutional neural network models pre-trained for the ImageNet classification task have been successfully adopted to tasks in other domains, such as texture description and object proposal generation, but these tasks require annotations for images in the new domain. In this paper, we focus on a novel and challenging task in the pure unsupervised setting: fine-grained image retrieval. Even with image labels, fine-grained images are difficult to classify, letting alone the unsupervised retrieval task. We propose the selective convolutional descriptor aggregation (SCDA) method. The SCDA first localizes the main object in fine-grained images, a step that discards the noisy background and keeps useful deep descriptors. The selected descriptors are then aggregated and the dimensionality is reduced into a short feature vector using the best practices we found. The SCDA is unsupervised, using no image label or bounding box annotation. Experiments on six fine-grained data sets confirm the effectiveness of the SCDA for fine-grained image retrieval. Besides, visualization of the SCDA features shows that they correspond to visual attributes (even subtle ones), which might explain SCDA’s high-mean average precision in fine-grained retrieval. Moreover, on general image retrieval data sets, the SCDA achieves comparable retrieval results with the state-of-the-art general image retrieval approaches.","1057-7149;10577149","","10.1109/TIP.2017.2688133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7887720","Fine-grained image retrieval;selection and aggregation;unsupervised object localization","Automobiles;Birds;Buildings;Convolution;Dogs;Image retrieval;Machine learning","","","","","","","","20170327","June 2017","","IEEE","IEEE Journals & Magazines"
