"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7744274,7748351,7744063,7744176,7744378,7749470,7749471,7744333,7567585,7747813,7748849,7748161,7744399,7744227,7747859,7744396,7744298,7707437,7745359,7743283,7746237,7745277,7743331,7745276,7310882,7572934,7738692,7738685,7740326,7737773,7739685,7737125,7738061,7737926,7738193,7737812,7738244,7567531,7732275,7727380,7732150,7727613,7727660,7727439,7727696,7727248,7727393,7727392,7727423,7727351,7727416,7729849,7726148,7727290,7727821,7732101,7727538,7727352,7727698,7726890,7729458,7729007,7726261,7729043,7729038,7730813,7729290,7727665,7730798,7727672,7727429,7729859,7727656,7729674,7727798,7726684,7727549,7727415,7729396,7727481,7726229,7727631,7727776,7727386,7727520,7727622,7729387,7729846,7730327,7729116,7727642,7726188,7727634,7729856,7727770,7727607,7727366,7727349,7729678,7727563",2017/05/05 22:31:08
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An Imbalanced Data Classification Method Driven by Boundary Samples-Boundary-Boost","K. Li; X. Fang; J. Zhai; Q. Lu","Coll. of Comput. & Commun. Eng., China Univ. of Pet., Qingdao, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","194","199","Imbalanced data existed widely in various fields. The classification problem of imbalanced data is a hot issue in machine learning. Existing algorithms on imbalanced data classification processed data without putting enough attention on the positive boundary samples which were prone to misclassification, and the cost that the positive samples were misclassified is much larger than the cost that the negative samples were misclassified. Based on this background, this paper presented a new imbalanced data classification approach based on boundary samples named Boundary-Boost. At first, categorize positive sample as boundary sample and security sample. Then, synthesize the new positive samples according to the boundary sample to balance the imbalanced data. At the same time, classified all the samples by using Boosting. Next, deleted the synthesized samples which were misclassified to reduce the influence of synthesized error samples on the classification results. Experimental result shows that the approach of Boundary-Boost has advantages on imbalanced data classification problem.","","","10.1109/ICISCE.2016.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726148","Boosting;Boundary samples;Imbalanced data;Oversampling","Boosting;Classification algorithms;Computers;Lead;Machine learning algorithms;Standards;Training","learning (artificial intelligence);pattern classification","Boundary-Boost;imbalanced data classification method;machine learning;positive boundary samples;security sample;synthesized error samples","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"Complementary prioritized ensemble selection","K. H. Chang; D. S. Parker","Department of Computer Science, University of California, Los Angeles, USA","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","863","872","We present a complementary ensemble selection method that utilizes a novel priority queue-based diversity measure. The method considers voting weaknesses of the current ensemble in covering the training set, and finds a classifier that can remove the highest priority weaknesses. Individual classifiers are generated using different machine learning algorithms and different parameter settings. A key feature of our method is in selecting complementary classifiers, i.e., repeatedly adding individual classifiers that best complement incorrect voting patterns of the current ensemble in priority order. We refer to this approach as “complementarity”. To evaluate this approach, we have performed months of experiments, making comparisons between our complementary prioritized ensemble selection method and an “ensemble of ensembles” approach. The comparisons are based on the forward stepwise selection method from earlier work on 5 datasets, each of which consists of comparisons from 9 folds of validated data (from 2 fold to 10 fold cross validated data). Over 1600 different classifier types were considered, yielding a huge space of alternative ensembles. The experimental results showed that a small and compact complementary ensemble yielded performance as good as and sometimes better than a huge ensemble selected by a state-of-the-art Ensemble of Ensembles method.","","","10.1109/IJCNN.2016.7727290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727290","Ensemble Selection","Bagging;Boosting;Classification algorithms;Diversity reception;Machine learning algorithms;Search problems;Training","learning (artificial intelligence);pattern classification;queueing theory","complementary ensemble selection method;ensemble of ensembles method;forward stepwise selection method;individual classifiers;machine learning algorithms;parameter settings;priority queue-based diversity measurement","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Deep kernel-SVM network","I. Rebai; Y. BenAyed; W. Mahdi","Multimedia InfoRmation system and Advanced Computing Laboratory, University of Sfax, Tunisia","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1955","1960","Deep learning techniques have claimed state-of-the-art results in a wide range of tasks, including classification. Despite the promising results, there are limitations for these large networks. In fact, deep neural networks have a poor generalisation performance on small data sets, such as biologic data. This paper describes a new machine learning algorithm for classification tasks. We introduce a Multi-Layer Multiple Kernel Learning (ML-MKL) framework. The input data are first transformed through a set of weighted non-linear kernel functions in a multilayer structure. Then, an SVM classifier is used to make the final decision. The proposed network is trained to minimize the error function. Indeed, we propose to optimize the network over an adaptive backpropagation algorithm. The generalization performance of the proposed method is compared over various state-of-the-art multiple kernel algorithms on several benchmark and two real world applications, including object recognition and spoken language recognition. Experimental results show that the ML-MKL generally outperforms existing kernel methods.","","","10.1109/IJCNN.2016.7727439","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727439","","Backpropagation algorithms;Kernel;Machine learning;Neural networks;Nonhomogeneous media;Optimization;Support vector machines","backpropagation;generalisation (artificial intelligence);minimisation;neural nets;pattern classification;support vector machines","ML-MKL framework;SVM classifier;adaptive backpropagation algorithm;biologic data;classification tasks;deep kernel-SVM network;deep learning;deep neural networks;error function minimization;generalisation performance;machine learning algorithm;multilayer multiple kernel learning;weighted nonlinear kernel functions","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Adjusted bat algorithm for tuning of support vector machine parameters","E. Tuba; M. Tuba; D. Simian","Faculty of Computer Science, John Naisbitt University, Belgrade, Serbia","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","2225","2232","Support vector machines are powerful and often used technique of supervised learning applied to classification. Quality of the constructed classifier can be improved by appropriate selection of the learning parameters. These parameters are often tuned using grid search with relatively large step. This optimization process can be done computationally more efficiently and more precisely using stochastic search metaheuristics. In this paper we propose adjusted bat algorithm for support vector machines parameter optimization and show that compared to the grid search it leads to a better classifier. We tested our approach on standard set of benchmark data sets from UCI machine learning repository. Additionally, proposed algorithm was compared to other approaches from the literature where our algorithm obtained more accurate classifiers, with larger percent of correct classifications, especially in the more realistic cases where separate test sets were used instead of cross validation only.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744063","","Kernel;Machine learning algorithms;Optimization;Particle swarm optimization;Stochastic processes;Support vector machines;Training","learning (artificial intelligence);optimisation;pattern classification;search problems;stochastic processes;support vector machines","UCI machine learning repository;adjusted bat algorithm;classifier quality;grid search;learning parameter selection;stochastic search metaheuristics;supervised learning;support vector machine parameter optimization;support vector machine parameter tuning","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Two-layered ensemble Kohonen nets for imbalanced streaming data","A. Roy","Department of Information Systems, Arizona State University, Tempe, AZ 85287, USA","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","5215","5221","One of the dominant application areas of machine learning will be the industrial internet (Internet of Things), although most of the data will actually be confined to smaller internal networks and will not use the Internet. In this world of the industrial internet, streaming sensor data with rare events, such as machine or process failures and disruptions, will be the dominant form of data and it poses a particular problem for machine learning because its methods are generally not designed to handle imbalanced data. In this paper, I present a new classification algorithm for streaming imbalanced data that uses Kohonen nets at its core. To handle high-velocity streaming data, the proposed algorithm can be implemented on hardware to take advantage of massive parallelism. I provide an outline of the algorithm and some preliminary computational results.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7748351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748351","Kohonen nets;classification algorithm;ensemble learning;imbalanced data;industrial internet;streaming data","Classification algorithms;Decision trees;Hardware;Internet;Machine learning algorithms;Neural networks;Parallel processing","Internet;Internet of Things;data handling;learning (artificial intelligence);neural nets;pattern classification","Internet of Things;data classification algorithm;high-velocity streaming data;imbalanced streaming data;industrial Internet;machine learning;massive parallelism;sensor data streaming;two-layered ensemble Kohonen nets","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Terrain classification with Polarimetric SAR based on Deep Sparse Filtering Network","H. Liu; Q. Min; C. Sun; J. Zhao; S. Yang; B. Hou; J. Feng; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","64","67","A new method for Polarimetric Synthetic Aperture Radar (PolSAR) terrain classification based on Deep Sparse Filtering Network (DSFN) is proposed in this paper. It uses a novel deep learning network to learn features from the input raw data automatically. And the spatial information between pixels on PolSAR image is combined into the input data. Moreover, unlike the conventional deep networks, the DSFN only needs to tune very few parameters during pre-training and fine-tuning. A real PolSAR data is used to verify the proposed method. Experimental results show that the proposed DSFN is efficient with less parameters and effectively improves the classification accuracy compared with conventional deep networks.","","","10.1109/IGARSS.2016.7729007","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729007","Polarimetric Synthetic Aperture Radar (PolSAR);deep sparse filtering network;feature learning;spatial information","Classification algorithms;Feature extraction;Filtering;Machine learning;Remote sensing;Synthetic aperture radar;Training","geophysical image processing;image classification;radar polarimetry;remote sensing by radar;synthetic aperture radar;terrain mapping","Deep Sparse Filtering Network;Polarimetric Synthetic Aperture Radar;classification accuracy;deep learning network;polarimetric SAR;terrain classification","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Web Identification Image Recognition Based on Deep Learning","Y. Zhao; X. Zhang; M. Xu; Z. Sun; G. Liu; S. Li","Shandong Provincial Key Lab. of Comput. Networks, Shandong Comput. Sci. Center, Jinan, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","743","747","In big data era, digital information is growing rapidly. False and unlawful images influence our normal work and life, especially the exaggerated or fake propaganda of electronic commerce merchants. In this article, our purpose is to help people find out fake qualification certificate information automatically. Base on collecting and classifying web images, we apply Convolutional Neural Network (CNN) method to train a network and extract the corresponding models to recognize web identification images based on Caffe toolbox with GPU. It is saving costs on man power and material resources with high efficiency once the CNN model is trained. This model can be designed to find identification images and contrast in database. The experimental results show it is worked well in recognizing identification images with high efficiency.","","","10.1109/ICISCE.2016.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726261","Caffe;Convolutional Neural Network;deep learning;identification image recognition","Big data;Databases;Image recognition;Machine learning;Neural networks;Training;Visualization","Big Data;Internet;electronic commerce;graphics processing units;image classification;learning (artificial intelligence);neural nets","CNN;Caffe toolbox;GPU;Web identification image recognition;big data;convolutional neural network;deep learning;digital information;electronic commerce;image classification","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"Deep learning approach for large scale land cover mapping based on remote sensing data fusion","N. Kussul; A. Shelestov; M. Lavreniuk; I. Butko; S. Skakun","Space Research Institute NASU-SSAU, Kyiv, Ukraine","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","198","201","In the paper we propose the methodology for solving the large scale classification and area estimation problems in the remote sensing domain on the basis of deep learning paradigm. It is based on a hierarchical model that includes self-organizing maps (SOM) for data preprocessing and segmentation (clustering), ensemble of multi-layer perceptrons (MLP) for data classification and heterogeneous data fusion and geospatial analysis for post-processing. The proposed methodology is applied for generation of high resolution land cover and land use maps for the territory of Ukraine from 1990 to 2010 and 2015.","","","10.1109/IGARSS.2016.7729043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729043","Deep learning;Landsat;big data;geospatial analysis;neural network;remote sensing data","Agriculture;Big data;Earth;Machine learning;Monitoring;Remote sensing;Satellites","geophysical image processing;image classification;image fusion;image segmentation;land cover;learning (artificial intelligence);terrain mapping","AD 1990 to 2010;AD 2015;Ukraine;area estimation;data classification;data preprocessing;data segmentation;deep learning approach;geospatial analysis;heterogeneous data fusion;high-resolution land cover map;high-resolution land use map;large-scale classification;large-scale land cover mapping;multilayer perceptrons;remote sensing data fusion;self-organizing maps","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Face recognition from video using generalized mean deep learning neural network","P. Sharma; R. N. Yadav; K. V. Arya","Department of Computer Science & Engineering, Visvesvaraya National Institute of Technology, Nagpur, India","2016 4th International Symposium on Computational and Business Intelligence (ISCBI)","20161117","2016","","","195","199","Proposed algorithm is a face recognition algorithm from video using Generalized mean Deep Learning Neural Network. Generalized mean provides fast convergence of the feature set and Deep learning neural network is enhanced using wavelet transform as it improves the classification efficiency of the neural network. The performance of the proposed algorithm is evaluated on PaSC and Youtube dataset. The results proved that the proposed algorithm is better in terms of identification accuracy.","","CD:978-1-5090-3486-4; Electronic:978-1-5090-3488-8; POD:978-1-5090-3489-5; Paper:978-1-5090-3487-1","10.1109/ISCBI.2016.7743283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743283","Encoder;deep belief network;face recognition;video;wavelet","Classification algorithms;Databases;Face;Face recognition;Feature extraction;Machine learning;Neural networks","face recognition;feature extraction;learning (artificial intelligence);neural nets;social networking (online);wavelet transforms","PaSC dataset;Youtube dataset;face recognition;feature set convergence;generalized mean deep learning neural network;video data;wavelet transform","","","","","","","5-7 Sept. 2016","","IEEE","IEEE Conference Publications"
"Exploiting dark information resources to create new value added services to study Earth science phenomena","R. Ramachandran; M. Maskey; X. Li; K. Bugbee","NASA Marshall Space Flight Center, United States","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","182","185","This paper presents two research applications exploiting unused metadata resources in novel ways to aid data discovery and exploration capabilities. The results based on the experiments are encouraging and each application has the potential to serve as a useful standalone component or service in a data system.","","","10.1109/IGARSS.2016.7729038","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729038","","Hurricanes;Image retrieval;Machine learning;Metadata;NASA;Training","cataloguing;geophysical image processing;geophysical techniques;image retrieval;information storage;meta data;online front-ends","Earth science phenomena study;NASA Earth science metadata catalog;browse images;dark information resource;data collections;data files;exploration pathways;image retrieval service;information resources;operational activity;query based search;regular business activity;structured information;value added service","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"A kernel level composition of multiple local classifiers for nonlinear classification","W. Li; B. Zhou; J. Hu","Graduate School of Information, Product and Systems, Waseda University, 2-7 Hibikino, Wakamatsu, Kitakyushu-shi, Fukuoka, 808-0135, Japan","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3845","3850","Kernel functions based machine learning algorithms have been extensively studied over the past decades with successful applications in a variety of real-world tasks. In this paper, we formulate a kernel level composition method to embed multiple local classifiers (kernels) into one kernel function, so as to obtain a more flexible data-dependent kernel. Since such composite kernels are composed by multiple local classifiers interpolated with several localizing gating functions, a specific learning process is also introduced in this paper to pre-determine their parameters. Experimental results are provided to validate two major perspectives of this paper. Firstly, the introduced learning process is effective to detect local information, which is essential for the parameter pre-determination of the localizing gating functions. Secondly, the proposed composite kernel has a capacity to improve classification performance.","","","10.1109/IJCNN.2016.7727696","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727696","","Buildings;Kernel;Machine learning algorithms;Manifolds;Optimization;Redundancy;Support vector machines","interpolation;learning (artificial intelligence);pattern classification","gating functions;kernel function based machine learning algorithms;kernel level composition;local classifiers;local information detection;multiple local classifiers;nonlinear classification","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"An automated method for time-series human settlement mapping using Landsat data and existing land cover maps","H. Miyazaki; R. Shibasaki; M. Nagai","The University of Tokyo, Center for Spatial Information, 4-6-1 Komaba Meguro, 153-8505, Japan","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","1784","1787","Automation of satellite-based human settlement mapping is highly needed to utilize historical archives of satellite data for urgent issues of urban development in global scale. We developed an automated algorithm to detect human settlement from Landsat satellite data. A machine learning algorithm, Local and Global Consistency (LLGC), was applied with improvements for remote sensing data. The algorithm enables to use existing coarse-resolution land cover maps as a training dataset so that any manual process is not required for preparation of training data. In addition, for better robustness against uncertainty in satellite data, we proposed a method to combine several LLGC results for several dates in a certain period from a target date into a single human settlement map with a pixel-based median composition among the input LLGC results. Combination of the methods enabled to develop timeseries human settlement maps using Landsat data, single ones of which could be affected by cloud contaminations. We applied the algorithm to Landsat data of 838 WRS2 tiles for cities with more than one million people worldwide for 1990, 2000, 2005, and 2010. MCD12Q1, a MODIS-based global land cover map with 500-m resolution, was used as training data. Visual assessment of the results suggested next steps for improvement of the method.","","","10.1109/IGARSS.2016.7729458","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729458","Landsat;Learning with Local and Global Consistency;global human settlement mapping","Earth;Machine learning algorithms;Remote sensing;Satellites;Training data;Uncertainty;Urban areas","geophysical techniques","Landsat data;coarse-resolution land cover maps;local and global consistency;pixel-based median composition;remote sensing data;satellite-based human settlement mapping;time-series human settlement mapping","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"A graph based Feature Selection algorithm utilizing attribute intercorrelation","A. Basak; A. K. Das","Department of Computer Science and Technology, Indian Institute of Engineering Science and Technology, Shibpur, India","2016 IEEE 7th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)","20161117","2016","","","1","9","Recently, every enterprise generates large volumes of high dimensional data on a regular basis. Complex data mining and analysis techniques are used to feasibly analyse this data. Feature selection aids in this by providing a reduced representation of this data while maintaining integrity. We propose a graph-based feature selection algorithm utilizing feature intercorrelation to construct a weighted attribute graph, from which irrelevant attributes are iteratively removed to select only the most important features called reduct based on a scoring scheme. Disconnectivity of the graph serves as the point of termination for our algorithm. The performance of our algorithm on real valued and discretized datasets is evaluated statistically by generating the Receiver Operator Characteristic (ROC) curve and by measuring accuracies of various classifiers for each reduced dataset.","","Electronic:978-1-5090-0996-1; POD:978-1-5090-0997-8","10.1109/IEMCON.2016.7746237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7746237","Correlation;Data analysis;Feature selection;Graph theory","Algorithm design and analysis;Approximation algorithms;Correlation;Data mining;Heuristic algorithms;Machine learning algorithms;Prediction algorithms","data analysis;data integrity;data mining;feature selection;graph theory;sensitivity analysis;statistical analysis","ROC curve;attribute intercorrelation;data analysis technique;data mining technique;data representation reduction;feature intercorrelation;graph based feature selection algorithm;graph disconnectivity;integrity maintenance;receiver operator characteristic curve;scoring scheme;statistical analysis;weighted attribute graph","","","","","","","13-15 Oct. 2016","","IEEE","IEEE Conference Publications"
"Improving decision trees by Tsallis Entropy Information Metric method","Y. Wang; C. Song; S. T. Xia","Department of Computer Science and Technology, Tsinghua University, Beijing, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","4729","4734","The construction of efficient and effective decision trees remains a key topic in machine learning because of their simplicity and flexibility. A lot of heuristic algorithms have been proposed to construct near-optimal decision trees. Most of them, however, are greedy algorithms that have the drawback of obtaining only local optimums. Besides, conventional split criteria they used, e.g. Shannon entropy, Gain Ratio and Gini index, cannot select informative attributes efficiently. To address the above issues, we propose a novel Tsallis Entropy Information Metric (TEIM) algorithm with a new split criterion and a new construction method of decision trees. Firstly, the new split criterion is based on two terms of Tsallis conditional entropy, which is better than conventional split criteria. Secondly, the new construction method is based on a two-stage approach that avoids local optimum to a certain extent. The TEIM algorithm takes advantages of the generalization ability of Tsallis entropy and the low greediness property of two-stage approach. Experimental results on UCI datasets indicate that, compared with the state-of-the-art decision trees algorithms, the TEIM algorithm yields statistically significantly better decision trees in classification accuracy as well as tree complexity.","","","10.1109/IJCNN.2016.7727821","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727821","","Decision trees;Entropy;Gold;Indexes;Machine learning algorithms;Measurement;Random variables","decision trees;entropy;learning (artificial intelligence)","TEIM algorithm;Tsallis conditional entropy;Tsallis entropy information metric method;UCI datasets;construction method;decision trees;greediness property;heuristic algorithms;machine learning;split criterion;tree complexity","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A universal remote sensing image quality improvement method with deep learning","Y. Wei; Q. Yuan; H. Shen; L. Zhang","State Key Laboratory of Information Engineering, Survey Mapping and Remote Sensing, Wuhan University, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","6950","6953","In this paper, we introduced a deep learning model: Convolutional neural network(CNN) from the field of natural image classification and restoration, to solve general quality improving tasks for remote sensing images, including super-resolution, denoising and haze removal. To take advantage of the content similarity among aerial images and the learning ability of deep learning models, we proposed the idea of training CNN on datasets collected from aerial images with specific degenerating factors, then apply the model to matched tasks. Experiments showed that our network achieved superior performance in quantified results, and visually reconstructed a satisfying majority of missing details from low-quality observations.","","","10.1109/IGARSS.2016.7730813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730813","Convolutional neural network;blind denoising;image restoration;non-uniform haze removal;single image super-resolution","Image restoration;Machine learning;Noise reduction;Remote sensing;Spatial resolution;Training","geophysical image processing;image classification;image denoising;image restoration;learning (artificial intelligence);neural nets;remote sensing","aerial images;convolutional neural network;deep learning model;haze removal;image classification;image denoising;image restoration;remote sensing image quality improvement method","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"A study of sentiment analysis using deep learning techniques on Thai Twitter data","P. Vateekul; T. Koomsubha","Department of Computer Engineering Faculty of Engineering, Chulalongkorn University Bangkok, Thailand","2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20161121","2016","","","1","6","Sentiment analysis is very important for social listening, especially, when there are millions of Twitter users in Thailand nowadays. Almost all prior works are based on classical classification techniques, e.g., SVM, Naïve Bayes, etc. Recently, the deep learning techniques have shown promising accuracy in this domain on English tweet corpus. In this paper, we propose the first study that applies deep learning techniques to classify sentiment of Thai Twitter data. There are two deep learning techniques included in our study: Long Short Term Memory (LSTM) and Dynamic Convolutional Neural Network (DCNN). A proper data preprocessing has been conducted. Moreover, we also investigate an effect of word orders in Thai tweets. The results show that the deep learning techniques significantly outperform many classical techniques: Naïve Bayes and SVM, except Maximum Entropy.","","Electronic:978-1-5090-2033-1; POD:978-1-5090-2034-8","10.1109/JCSSE.2016.7748849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748849","Deep Learning;Dynamic Convolutional Neural Network;Long Short Term Memory;Sentiment Analysis;Thai Twitter Data","Biological neural networks;Computer architecture;Logic gates;Machine learning;Sentiment analysis;Support vector machines;Twitter","learning (artificial intelligence);neural nets;sentiment analysis;social networking (online)","DCNN;English tweet corpus;LSTM;Thai Twitter data;Twitter users;data preprocessing;deep learning;dynamic convolutional neural network;long short term memory;sentiment analysis;sentiment classify;social listening","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"A comparative study of HTM and other neural network models for online sequence learning with streaming data","Y. Cui; C. Surpur; S. Ahmad; J. Hawkins","Numenta, Inc, Redwood City, CA, United States","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1530","1538","Online sequence learning from streaming data is one of the most challenging topics in machine learning. Neural network models represent promising candidates for sequence learning due to their ability to learn and recognize complex temporal patterns. In this paper, we present a comparative study of Hierarchical Temporal Memory (HTM), a neurally-inspired model, and other feedforward and recurrent artificial neural network models on both artificial and real-world sequence prediction algorithms. HTM and long-short term memory (LSTM) give the best prediction accuracy. HTM additionally demonstrates many other features that are desirable for real-world sequence learning, such as fast adaptation to changes in the data stream, robustness to sensor noise and fault tolerance. These features make HTM an ideal candidate for online sequence learning problems.","","","10.1109/IJCNN.2016.7727380","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727380","ELM;ESN;HTM;LSTM;online learning;sequence learning;streaming data analysis","Adaptation models;Biological neural networks;Computational modeling;Data models;Machine learning algorithms;Neurons;Prediction algorithms","data analysis;feedforward neural nets;learning (artificial intelligence);recurrent neural nets","HTM;LSTM;feedforward artificial neural network models;hierarchical temporal memory;long-short term memory;machine learning;neurally-inspired model;online sequence learning;recurrent artificial neural network models;sequence prediction algorithms;streaming data analysis","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"SAR image classification based on the multi-layer network and transfer learning of mid-level representations","C. Kang; C. He","School of Electronic Information, Wuhan University, 430079, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","1146","1149","In this paper, a classification method based on multi-layer network and transfer learning has been developed for synthetic aperture radar (SAR) images inspired by recent successful deep learning methods. Multi-layer network has excellent performance in the classification of optical images, while its application for SAR images is restricted by the limited quantity of SAR imagery training data. Given this, transfer learning has been introduced into the classification of a small number of SAR images. Firstly, we use CIFAR-10 dataset to train a multi-layer network in order for an extraction of the mid-level representation, and then we utilize the intermediate layers of the network trained before to target SAR datasets at which the mid-level representation obtained can be used to train adaptive layers. The classification algorithm has been tested on a TerraSAR dataset and the results are more convincing and show greater potential for SAR image classification.","","","10.1109/IGARSS.2016.7729290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729290","SAR image classification;multi-layer network;transfer-learning","Adaptive optics;Feature extraction;Machine learning;Optical imaging;Support vector machines;Synthetic aperture radar;Training","geophysical image processing;image classification;image representation;learning (artificial intelligence);neural nets;remote sensing by radar;synthetic aperture radar","CIFAR-10 dataset;SAR imagery training data;TerraSAR dataset;deep learning methods;midlevel representation extraction;midlevel representations;multilayer network;optical image classification;synthetic aperture radar image classification method;transfer learning","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Low level visual feature extraction by learning of multiple tasks for Convolutional Neural Networks","H. Ide; T. Kurita","Faculty of Engineering, Hiroshima University, Japan","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3620","3627","Visual features trained from large scale image data by the deep convolutional neural network can be used for the other visual tasks. This paper investigates the effects of the learning of multiple tasks for such transfer learning from the source domains to the target domain. Two methods of the learning of multiple tasks are considered. Also we investigate which hidden layers should be re-trained for the target task in the fine-tuning process by selecting a subset of the hidden layers and updating only the parameters of the selected subset. Through a detail experiments, we confirmed the effectiveness of the learning of multiple tasks for pre-training. Also we showed that the first layer is not always required to be trained for the target task and the fully-connected layer, the classifier layer, and the last hidden layer should be retrained for the target task in the fine-tuning. These results suggests that the first and the second layers in the deep convolutional neural network trained by the learning of multiple tasks can extract general low level visual features.","","","10.1109/IJCNN.2016.7727665","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727665","","Biological neural networks;Convolution;Feature extraction;Machine learning;Neurons;Training;Visualization","feature extraction;image processing;learning (artificial intelligence);neural nets;task analysis","deep convolutional neural network;large scale image data;low level visual feature extraction;multiple tasks;transfer learning","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"On approximating networks centrality measures via neural learning algorithms","F. Grando; L. C. Lamb","Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","551","557","The analysis and study of complex networks are crucial to a number of applications. Vertex centrality measures are an important analysis mechanism to uncover or rank important elements of a given network. However, these metrics have high space and time complexity, which is a severe problem in applications that typically involve large networks. We propose and study the use of neural learning algorithms in such a way that the use of these metrics became feasible in networks of any size. We trained and tested 12 off-the-shelf learning algorithms on several networks. Our results show that the regression output of the machine learning algorithms successfully approximate the real metric values and are a robust alternative in real world applications. We also identified that the model generated by the multilayer layer network trained with the Levenberg-Marquardt algorithm achieved the best performance, both in process time and solution quality, among all the methodologies tested for this task.","","","10.1109/IJCNN.2016.7727248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727248","Complex networks;Neural networks;Regression task;Vertex centrality measures","Approximation algorithms;Complex networks;Machine learning algorithms;Mathematical model;Measurement;Neural networks;Training","approximation theory;complex networks;computational complexity;learning (artificial intelligence);regression analysis","Levenberg-Marquardt algorithm;approximating networks centrality measures;complex networks;machine learning;multilayer layer network;neural learning;regression output;space complexity;time complexity;vertex centrality measures","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Coreference between subjective expression and holder: A classification perspective","D. Das; S. Bhattacharya","Department of Computer Science and Engineering, Jadavpur University, Kolkata, West Bengal, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","535","541","Instead of applying the traditional keyword spotting approach, the presence of coreference between the holders and their subjective expressions often becomes important to identify and classify opinion and sentiment, accurately. In the present task, we have developed a classification system to resolve coreference of subjective expressions with their holders and thus automate the process of text annotations. The dependency parsed features in addition to sentiment words helped in classifying the corefered instances using machine learning framework.","","","10.1109/ICACCI.2016.7732101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732101","Coreference;Holder;Subjective Expression","Algorithm design and analysis;Clustering algorithms;Data mining;Feature extraction;Informatics;Machine learning algorithms;Tagging","learning (artificial intelligence);pattern classification;sentiment analysis","classification system;corefered instance classification;dependency parsed features;holders;machine learning;opinion classification;opinion identification;sentiment classification;sentiment identification;sentiment words;subjective expression;text annotations","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Gödel vs. aristotle: Algorithmic complexity, models of the Mind, and top representations","L. Perlovsky","Department of Psychology, Northeastern University, Boston, MA USA","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1787","1794","Brains learn much better than computers. But why? Is there a fundamental reason behind computers being slow learners? Often slow learning is described as computational complexity. This paper discusses that complexity of algorithms is as fundamental as Gödelian incompleteness of logic. Although the Gödel's theory is well recognized, its significance for engineering and modeling of the mind has not been appreciated. The mind-brain overcomes this fundamental difficulty, why computers cannot? I emphasize here that the reason is logical bases of machine learning. Aristotle explained that mind is not logical. The paper discusses that most neural networks and fuzzy systems require logical steps. A “nonlogical” mathematical theory overcoming computational complexity is described. It turns out to closely follow Aristotle's ideas. The new theory explains contents of the highest representations in the mind hierarchy, and related aesthetic emotions revealing the nature of the beautiful and the meaning of life. I discuss how it is possible that a non-logical mathematical technique can be computable, the function of logic in the mind, its relation to consciousness, and difficulties of understanding unconscious mechanisms.","","","10.1109/IJCNN.2016.7727416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727416","algorithms;cognition;combinations;complexity;consciousness;learning;logic;logical bias","Biological neural networks;Computational complexity;Computational modeling;Computers;Machine learning algorithms;Mathematical model","computational complexity;formal logic;fuzzy systems;learning (artificial intelligence);neural nets","Gödelian logic incompleteness;aesthetic emotions;algorithmic complexity;computational complexity;fuzzy systems;machine learning logical basis;mind hierarchy;mind model;neural networks;nonlogical mathematical technique;nonlogical mathematical theory;top representations;unconscious mechanisms","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"CRF learning with CNN features for hyperspectral image segmentation","F. I. Alam; J. Zhou; A. W. C. Liew; X. Jia","School of Information and Communication Technology, Griffith University, Nathan, QLD 4111, Australia","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","6890","6893","This paper proposes a method that uses both spectral and spatial information to segment remote sensing hyperspectral images. After a hyperspectral image is over-segmented into superpixels, a deep Convolutional Neural Network (CNN) is used to perform superpixel-level labelling. To further delineate objects from a hyperspectral scene, this paper attempts to combine the properties of CNN and Conditional Random Field (CRF). A mean-field approximation algorithm for CRF inference is used and formulated with Gaussian pairwise potentials as Recurrent Neural Network. This combined network is then plugged into the CNN which leads to a deep network that has robust characteristics of both CNN and CRF. Preliminary results suggest the usefulness of this framework to a promising extent.","","","10.1109/IGARSS.2016.7730798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730798","Conditional Random Field;Convolutional Neural Network;Deep Learning;Image Segmentation;Superpixel","Hyperspectral imaging;Image segmentation;Inference algorithms;Labeling;Machine learning;Neural networks","geophysical image processing;hyperspectral imaging;image resolution;image segmentation;learning (artificial intelligence);recurrent neural nets","CNN features;CRF learning;Conditional Random Field;Gaussian pairwise potentials;deep Convolutional Neural Network;hyperspectral image segmentation;hyperspectral scene;mean-field approximation algorithm;recurrent neural network;remote sensing hyperspectral images;spatial information;spectral information;superpixel-level labelling","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"An enhanced dominant sets clustering method","J. Hou; W. Liu; H. Cui","College of Engineering, Bohai University, Jinzhou 121013, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3674","3681","As a graph-based clustering approach, dominant sets clustering determines the number of clusters automatically and possesses some other nice properties. By applying histogram equalization transformation to the similarity matrix before clustering, we are able to accomplish the dominant sets clustering process without any user-specified parameters. However, this transformation usually leads to over-segmented clustering results. In this paper, we analyze the correlation between histogram equalization transformation and the over-segmentation tendency, and attribute the over-segmentation to the over-strict global density constraint imposed by the dominant set definition. Therefore we propose to relax the global density constraint to a local one, which is then used in dominant set extension. We test our algorithm in experiments of data clustering and image segmentation, and validate its effectiveness in comparison with the original dominant sets algorithm and other algorithms.","","","10.1109/IJCNN.2016.7727672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727672","","Algorithm design and analysis;Clustering algorithms;Compounds;Histograms;Image segmentation;Iris;Machine learning algorithms","image segmentation;matrix algebra;pattern clustering","data clustering;dominant set definition;dominant set extension;dominant sets algorithm;dominant sets clustering;graph-based clustering;histogram equalization transformation;image segmentation;over-segmentation tendency;over-segmented clustering;over-strict global density constraint;similarity matrix","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"ELM based multiple kernel k-means with diversity-induced regularization","Y. Zhao; Y. Dou; X. Liu; T. Li","National University of Defense Technology, National Laboratory for Parallel and Distributed Processing, Changsha, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2699","2705","Multiple-kernel k-means (MKKM) clustering has demonstrated good clustering performance by combining pre-specified kernels. In this paper, we argue that deep relationships within data and the complementary information among them can improve the performance of MKKM. To illustrate this idea, we propose a diversity-induced MKKM algorithm with extreme learning machine (ELM)-based feature extracting method. First, ELM, which has randomly chosen weights of hidden and output nodes, is applied to thoroughly extract features from data by generating different numbers of hidden nodes and using different functions. Second, an MKKM algorithm with diversity-induced regularization is utilized to explore the complementary information among kernels constructed from features. The problem could be solved efficiently by alternating optimization. Experimental results demonstrate that the proposed method outperforms state-of-the-art kernel methods.","","","10.1109/IJCNN.2016.7727538","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727538","","Clustering algorithms;Euclidean distance;Feature extraction;Kernel;Machine learning algorithms;Neural networks;Optimization","feature extraction;learning (artificial intelligence);pattern clustering","ELM-based feature extraction;MKKM clustering;diversity-induced regularization;extreme learning machine;kernel methods;multiple kernel k-means","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Learning from wireless: A prospective approach to Human-Centered Computing","Y. Lu; S. Lv; X. Yang; X. Wang; M. Li; X. Zhou","Science and Technology on Parallel and Distributed Processing Laboratory, National University of Defense Technology, Changsha, Hunan, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1883","1889","One of the most important topics in Human-Centered Computing (HCC) is to recognise human's activities. In this paper, the technology of wireless-based activity recognition is introduced. By using wireless signals, one can achieve Non-Line-Of-Sight (NLOS) recognition without carrying any devices. Also, it is easy to deploy a wireless-based recognition system due to the ubiquity of wireless communication systems. The basic idea is to detect different characteristics of signal propagation that correspond to the distinct human behaviors. As a result, action recognition is performed by analyzing the distinguishable features of signal propagation. This paper introduces the basic principles and applications of wireless-based activity recognition, and discusses the challenges and related performance metrics. Finally, open problems are discussed to point out the future research trends.","","","10.1109/IJCNN.2016.7727429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727429","","Acoustics;Feature extraction;Machine learning algorithms;Wireless communication;Wireless sensor networks","human computer interaction;pattern recognition;signal processing","HCC;NLOS recognition;human-centered computing;nonline-of-sight recognition;performance metrics;signal propagation features;wireless communication systems;wireless signals;wireless-based activity recognition;wireless-based recognition system","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Enhancing discrimination power with genetic feature construction: A grammatical evolution approach","P. Miquilini; R. C. Barros; V. V. de Melo; M. P. Basgalupp","Universidade Federal de S&#x00E3;o Paulo, Instituto de Ci&#x00EA;ncia e Tecnologia, S&#x00E3;o Jos&#x00E9; dos Campos, SP, Brazil","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","3824","3831","Data set preprocessing is a critical step for the successful application of machine learning algorithms in classification tasks. Even though we rely on learning algorithms to pinpoint the optimal decision boundaries in the feature space by properly detecting latent relationships among the input features, their performance is often bounded by the discriminative power of the available features. Therefore, much effort has been devoted to developing preprocessing methods that are capable of transforming the input data with the final goal of aiding the machine learning algorithm in building high-quality classification models. One such a method is feature construction, which is a flexible preprocessing procedure that exploits linear and nonlinear transformations of the original feature space in an attempt to capture useful information that is not explicit in the original data. Since the task of feature construction can be modelled as a heuristic search in the space of novel latent features, this paper investigates an evolutionary approach for performing such a task, namely grammatical evolution (GE). In our proposed approach, GE is employed for building an extra novel feature from the available input data in order to maximize the predictive performance of the learning algorithm in training data. Results show that many interesting implicit relationships are indeed found by the evolutionary approach, improving the performance of two well-known decision-tree induction algorithms.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744274","","Genetics;Grammar;Machine learning algorithms;Prediction algorithms;Sociology;Statistics;Training","decision trees;evolutionary computation;feature extraction;learning (artificial intelligence);pattern classification;search problems","data set preprocessing;decision-tree induction algorithms;feature construction;feature space;genetic feature construction;grammatical evolution;heuristic search;high-quality classification models;latent relationships;linear transformations;machine learning;nonlinear transformations;optimal decision boundaries","","1","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Emotion recognition using mobile phones","S. Shapsough; A. Hesham; Y. Elkhorazaty; I. A. Zualkernan; F. Aloul","Department of Computer Science & Engineering, American University of Sharjah, UAE","2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthcom)","20161121","2016","","","1","6","The availability of built-in sensors in mobile phones has enabled a host of innovative applications. One class of applications deals with detecting a user's emotions. Previous applications have primarily relied on recording and displaying self-reported emotions. This paper presents an intelligent emotion detection system for mobile phones implemented as a smart keyboard. The smart keyboard independently infers a user's emotional state using machine learning techniques. The system uses accelerometer readings and various aspect of typing behavior like speed, number of backspaces, and time delay between letters to train a classifier to predict emotions. Naïve Bayes, J48, IBK, Multi-response linear regression and SVM were evaluated and J48 was found to be the best classifier with over 90% accuracy and precision. In addition to providing emotive feedback to individual users, the system also uses geo-tagged data to collect and display emotional states of regions or countries through a website.","","Electronic:978-1-5090-3370-6; POD:978-1-5090-3371-3","10.1109/HealthCom.2016.7749470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749470","Emotion recognition;Machine intelligence;Mobile phones;Sensors","Classification algorithms;Emotion recognition;Keyboards;Machine learning algorithms;Mobile handsets;Sensors;Support vector machines","Bayes methods;behavioural sciences computing;emotion recognition;learning (artificial intelligence);mobile computing;mobile handsets;pattern classification;regression analysis;support vector machines","IBK;J48;SVM;accelerometer readings;classifier;emotion recognition;geo-tagged data;intelligent emotion detection system;machine learning techniques;mobile phones;multiresponse linear regression;naive Bayes;smart keyboard;typing behavior","","","","","","","14-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Contextual deep CNN based hyperspectral classification","H. Lee; H. Kwon","U.S. Army Research Laboratory, 2800 Powder Mill Rd, Adelphi, Maryland, U.S.A.","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","3322","3325","In this paper, we describe a novel deep convolutional neural networks (CNN) based approach called contextual deep CNN that can jointly exploit spatial and spectral features for hyperspectral image classification. The contextual deep CNN first concurrently applies multiple 3-dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image. The initial spatial and spectral feature maps obtained from applying the variable size convolutional filters are then combined together to form a joint spatio-spectral feature map. The joint feature map representing rich spectral and spatial properties of the hyperspectral image is then fed through fully convolutional layers that eventually predict the corresponding label of each pixel vector. The proposed approach is tested on two benchmark datasets: the Indian Pines dataset and the Pavia University scene dataset. Performance comparison shows enhanced classification performance of the proposed approach over the current state of the art on both datasets.","","","10.1109/IGARSS.2016.7729859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729859","contextual deep CNN;hyperspectral classification;joint spectral and spatial exploitation","Feature extraction;Hyperspectral imaging;Image classification;Machine learning;Neural networks;Training","feature extraction;geophysical image processing;hyperspectral imaging;image classification;neural nets","3D local convolutional filters;Indian Pines dataset;Pavia University scene dataset;convolutional neural networks;deep CNN based hyperspectral classification;hyperspectral image classification;spatial features;spatiospectral feature map;spectral features","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Life estimation based on unbalanced data for hydraulic pump","Y. Geng; S. Wang; C. Zhang","","2016 IEEE International Conference on Aircraft Utility Systems (AUS)","20161121","2016","","","796","801","This paper focuses on statistic method under small test samples through re-sampling for aeronautics pump. Based on the limit accelerated life testing samples and regular life testing samples, this paper presents a life evaluation method combing the Synthetic Minority Over-Sampling Technique (SMOTE) algorithm, Kolmogorov-Smirnov (KS) test and accumulated damage theory. SMOTE algorithm is used to solve the imbalance between sample groups, while KS is a classic way to evaluate the goodness of fitting. The maximum likelihood estimation of proposed method shows that the sample group can be expanded efficiently with the goodness-of-fit being guaranteed.","","DVD:978-1-5090-1086-8; Electronic:978-1-5090-1087-5; POD:978-1-5090-1088-2","10.1109/AUS.2016.7748161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748161","accelerated life test;accumulative damage;life estimation;re-sampling;regular life test","Distribution functions;Life estimation;Life testing;Machine learning algorithms;Maximum likelihood estimation;Strain","aerospace components;hydraulic systems;life testing;maximum likelihood estimation;pumps;sampling methods","KS test;Kolmogorov-Smirnov test;SMOTE algorithm;aeronautics pump;goodness-of-fit;hydraulic pump;life estimation;life evaluation method;limit accelerated life testing;maximum likelihood estimation;re-sampling;regular life testing;statistic method;synthetic minority over-sampling technique","","","","","","","10-12 Oct. 2016","","IEEE","IEEE Conference Publications"
"Class-wise deep dictionaries for EEG classification","P. Khurana; A. Majumdar; R. Ward","IIIT Delhi, New Delhi, India","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3556","3563","In this work we propose a classification framework called class-wise deep dictionary learning (CWDDL). For each class, multiple levels of dictionaries are learnt using features from the previous level as inputs (for first level the input is the raw training sample). It is assumed that the cascaded dictionaries form a basis for expressing test samples for that class. Based on this assumption sparse representation based classification is employed. Benchmarking experiments have been carried out on some deep learning datasets (MNIST and its variations, CIFAR and SVHN); our proposed method has been compared with Deep Belief Network (DBN), Stacked Autoencoder, Convolutional Neural Net (CNN) and Label Consistent KSVD (dictionary learning). We find that our proposed method yields better results than these techniques and requires much smaller run-times. The technique is applied for Brain Computer Interface (BCI) classification problems using EEG signals. For this problem our method performs significantly better than Convolutional Deep Belief Network(CDBN).","","","10.1109/IJCNN.2016.7727656","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727656","EEG;deep learning;dictionary learning","Benchmark testing;Dictionaries;Machine learning;Minimization;Neural networks;Sparse matrices;Training","belief networks;brain-computer interfaces;electroencephalography;feedforward neural nets;learning (artificial intelligence);medical signal processing;signal classification;signal representation","CDBN;CIFAR;CNN;CWDDL;EEG classification;EEG signals;MNIST;SVHN;brain computer interface classification problems;cascaded dictionaries;class-wise deep dictionary learning;convolutional deep belief network;convolutional neural net;deep learning datasets;label consistent KSVD;sparse representation based classification;stacked autoencoder","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"GenderMag experiences in the field: The whole, the parts, and the workload","C. Hill; S. Ernst; A. Oleson; A. Horvath; M. Burnett","School of EECS, Oregon State University, Corvallis, OR, USA","2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)","20161110","2016","","","199","207","Recent research has reported numerous studies bringing into question the gender inclusiveness of many kinds of software. Inclusiveness of software (gender or otherwise) matters because supporting diversity matters - it is well-known that the more diverse a group of problem-solvers, the higher the quality of the solution. To help software creators identify features within their software that are not gender-inclusive, we recently created a method known as GenderMag. In this paper, we investigate the experience of teams of software professionals using GenderMag to find problems with software they are building. Our results show a high engagement with GenderMag personas - more than twice that of other personas research - and a very high degree of accuracy (93%) most of the time. Finally, our results pinpointed situations that we term “detours” that were especially prone to errors, with teams 6 times more likely to make errors in detours than they did otherwise.","","Electronic:978-1-5090-0252-8; POD:978-1-5090-0253-5","10.1109/VLHCC.2016.7739685","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7739685","Cognitive walkthrough;Diversity;Field study;Gender inclusiveness;GenderMag;Personas","Companies;Encoding;Machine learning algorithms;Mobile communication;Problem-solving;Software;Software algorithms","gender issues;problem solving;software engineering","GenderMag;gender inclusiveness;problem solving","","","","","","","4-8 Sept. 2016","","IEEE","IEEE Conference Publications"
"Designing reconfigurable large-scale deep learning systems using stochastic computing","A. Ren; Z. Li; Y. Wang; Q. Qiu; B. Yuan","Dept. of Electrical Engineering & Computer Science, Syracuse University, NY 13244, USA","2016 IEEE International Conference on Rebooting Computing (ICRC)","20161110","2016","","","1","7","Deep Learning, as an important branch of machine learning and neural network, is playing an increasingly important role in a number of fields like computer vision, natural language processing, etc. However, large-scale deep learning systems mainly operate in high-performance server clusters, thus restricting the application extensions to personal or mobile devices. The solution proposed in this paper is taking advantage of the fantastic features of stochastic computing methods. Stochastic computing is a type of data representation and processing technique, which uses a binary bit stream to represent a probability number (by counting the number of ones in this bit stream). In the stochastic computing area, some key arithmetic operations such as additions or multiplications can be implemented with very simple components like AND gates or multiplexers, respectively. Thus it provides an immense design space for integrating a large amount of neurons and enabling fully parallel and scalable hardware implementations of large-scale deep learning systems. In this paper, we present a reconfigurable large-scale deep learning system based on stochastic computing technologies, including the design of the neuron, the convolution function, the back-propagation function and some other basic operations. And the network-on-chip technique is also proposed in this paper to achieve the goal of implementing a large-scale hardware system. Our experiments validate the functionality of reconfigurable deep learning systems using stochastic computing, and demonstrate that when the bit streams are set to be 8192 bits, classification of MNIST digits by stochastic computing can perform as low error rate as that by normal arithmetic operations.","","Electronic:978-1-5090-1370-8; POD:978-1-5090-1371-5","10.1109/ICRC.2016.7738685","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738685","Stochastic computing;deep learning;large-scale;neuron;reconfigurable","Biological neural networks;Encoding;Hardware;Machine learning;Neurons;Stochastic processes","backpropagation;data structures;learning (artificial intelligence);network-on-chip;neural nets;parallel architectures;probability;reconfigurable architectures","AND gates;MNIST digit classification;backpropagation function;data processing;data representation;high-performance server clusters;key arithmetic operations;large-scale hardware system;machine learning;mobile devices;multiplexers;network-on-chip;neural network;normal arithmetic operations;parallel scalable hardware implementations;personal devices;probability number;reconfigurable large-scale deep learning systems;stochastic computing","","1","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Deep learning with random neural networks","E. Gelenbe; Y. Yin","Intelligent Systems and Networks Group, Electrical & Electronic Engineering Department, Imperial College, London SW7 2AZ, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1633","1638","This paper introduces techniques for Deep Learning in conjunction with spiked random neural networks that closely resemble the stochastic behaviour of biological neurons in mammalian brains. The paper introduces clusters of such random neural networks and obtains the characteristics of their collective behaviour. Combining this model with previous work on extreme learning machines, we develop multilayer architectures which structure Deep Learning Architectures a a “front end” of one or two layers of random neural networks, followed by an extreme learning machine. The approach is evaluated on a standard - and large - visual character recognition database, showing that the proposed approach can attain and exceed the performance of techniques that were previously reported in the literature.","","","10.1109/IJCNN.2016.7727393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727393","","Brain modeling;Computer architecture;Machine learning;Mathematical model;Neural networks;Neurons;Stochastic processes","learning (artificial intelligence);neural nets","biological neurons;collective behaviour;deep learning architectures;extreme learning machines;mammalian brains;multilayer architectures;spiked random neural networks;stochastic behaviour;visual character recognition database","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"CaffePresso: An optimized library for Deep Learning on embedded accelerator-based platforms","G. Hegde; Siddhartha; N. Ramasamy; N. Kapre","School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798","2016 International Conference on Compliers, Architectures, and Sythesis of Embedded Systems (CASES)","20161117","2016","","","1","10","Off-the-shelf accelerator-based embedded platforms offer a competitive energy-efficient solution for lightweight deep learning computations over CPU-based systems. Low-complexity classifiers used in power-constrained and performance-limited scenarios are characterized by operations on small image maps with 2- 3 deep layers and few class labels. For these use cases, we consider a range of embedded systems with 5-20W power budgets such as the Xilinx ZC706 board (with MXP soft vector processor), NVIDIA Jetson TX1 (GPU), TI Keystone II (DSP) as well as the Adapteva Parallella board (custom multi-core with NoC). Deep Learning computations push the capabilities of these platforms to the limit through compute-intensive evaluations of multiple 2D convolution filters per layer, and high communication requirements arising from the movement of intermediate maps across layers. We present CaffePresso, a Caffe-compatible framework for generating optimized mappings of user-supplied ConvNet specifications to target various accelerators such as FPGAs, DSPs, GPUs, RISC-multicores. We use an automated code generation and auto-tuning approach based on knowledge of the ConvNet requirements, as well as platform-specific constraints such as on-chip memory capacity, bandwidth and ALU potential. While one may expect the Jetson TX1 + cuDNN to deliver high performance for ConvNet configurations, (1) we observe a flipped result with slower GPU processing compared to most other systems for smaller embedded-friendly datasets such as MNIST and CIFAR10, and (2) faster and more energy efficient implementation on the older 28nm TI Keystone II DSP over the newer 20nm NVIDIA TX1 SoC in all cases.","","Electronic:978-1-4503-4482-1; POD:978-1-5090-3589-2","10.1145/2968455.2968511","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745277","","Digital signal processing;Field programmable gate arrays;Graphics processing units;Machine learning;Neon;System-on-chip;Two dimensional displays","embedded systems;graphics processing units;learning (artificial intelligence);neural nets","Adapteva Parallella board;CaffePresso framework;ConvNet specifications;GPU processing;Xilinx ZC706 board;auto-tuning approach;automated code generation;embedded accelerator-based platform;embedded systems;graphics processing unit;lightweight deep learning computations;low-complexity classifiers;off-the-shelf accelerator-based embedded platform","","","","","","","2-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Using CNN-based high-level features for remote sensing scene classification","Z. Fang; W. Li; J. Zou; Q. Du","College of Information Science & Technology, Beijing University of Chemical Technology, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","2610","2613","In this paper, convolutional neural networks (CNNs) is employed for remote-sensing scene classification, which fully utilizes the semantic features extracted from the images while ignoring some traditional features. Consider the limited labeled samples, CaffeNet model as the pre-trained architecture is adopted. By fine-tuning the pre-trained models, the proposed method is expected to be robust and efficient. Its performance is evaluated with two remote-sensing scene datasets. From the experimental results, the proposed CNN-based scene classification method does provide more excellent performance and be superior to several state-of-the-art methods.","","","10.1109/IGARSS.2016.7729674","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729674","Scene classification;convolutional neural networks;deep learning;feature extraction","Convergence;Feature extraction;Machine learning;Neural networks;Remote sensing;Testing;Training","feature extraction;geophysical image processing;image classification;neural nets;remote sensing","CNN-based high-level features;CNN-based scene classification method;CaffeNet model;convolutional neural networks;fine-tuning;limited labeled samples;pretrained architecture;remote sensing scene classification;remote-sensing scene datasets;semantic features","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Self-reflective deep reinforcement learning","A. Altahhan","School of Computing, Electronics and Math., Coventry University, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","4565","4570","In this paper we present a new concept of self-reflection learning to support a deep reinforcement learning model. The self-reflective process occurs offline between episodes to help the agent to learn to navigate towards a goal location and boost its online performance. In particular, a so far optimal experience is recalled and compared with other similar but suboptimal episodes to reemphasize worthy decisions and deemphasize unworthy ones using eligibility and learning traces. At the same time, relatively bad experience is forgotten to remove its confusing effect. We set up a layer-wise deep actor-critic architecture and apply the self-reflection process to help to train it. We show that the self-reflective model seems to work well and initial experimental result on real robot shows that the agent accomplished good success rate in reaching a goal location.","","","10.1109/IJCNN.2016.7727798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727798","actor-critic;deep learning;neural networks;robot navigation;self-reflective deep reinforcement learning","Biological neural networks;Feature extraction;Learning (artificial intelligence);Machine learning;Navigation;Robots","learning (artificial intelligence)","layer-wise deep actor-critic architecture;robot;self-reflection process;self-reflective deep reinforcement learning","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A new margin-based AdaBoost algorithm: Even more robust than RobustBoost to class-label noise","O. R. Pouya","Biomedical Engineering Program, University of Manitoba, Winnipeg, Canada","2016 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20161103","2016","","","1","5","In this paper, we present a new modification of AdaBoost (Adaptive-Boosting) algorithm that improves its efficiency in presence of class-label noise. The proposed algorithm is significantly more robust against label noise than RobusBoost, the best available and implemented solution. Moreover, unlike RobusBoost, the proposed method does not need optimization toolbox or external parameters provided by user. The empirical results on 9 benchmark datasets showed the proposed method significantly outperforms RobustBoost in terms of classification accuracy and computation time in majority of the examined data sets.","","","10.1109/CCECE.2016.7726684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726684","AdaBoost;Class-label Noise;Margin Theory;Predictive Accuracy;Training Time","Benchmark testing;Classification algorithms;Machine learning algorithms;Noise measurement;Robustness;Signal processing algorithms;Training","learning (artificial intelligence);pattern classification","adaptive-boosting;class-label noise;classification accuracy;margin-based AdaBoost algorithm","","","","","","","15-18 May 2016","","IEEE","IEEE Conference Publications"
"kNN ensembles with penalized DTW for multivariate time series imputation","S. Oehmcke; O. Zielinski; O. Kramer","Computational Intelligence Group, Department of Computing Science, University Oldenburg, Germany","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2774","2781","The imputation of partially missing multivariate time series data is critical for its correct analysis. The biggest problems in time series data are consecutively missing values that would result in serious information loss if simply dropped from the dataset. To address this problem, we adapt the k-Nearest Neighbors algorithm in a novel way for multivariate time series imputation. The algorithm employs Dynamic Time Warping as distance metric instead of point-wise distance measurements. We preprocess the data with linear interpolation to create complete windows for Dynamic Time Warping. The algorithm derives global distance weights from the correlation between features and consecutively missing values are penalized by individual distance weights to reduce error transfer from linear interpolation. Finally, efficient ensemble methods improve the accuracy. Experimental results show accurate imputations on datasets with a high correlation between features. Further, our algorithm shows better results with consecutively missing values than state-of-the-art algorithms.","","","10.1109/IJCNN.2016.7727549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727549","","Algorithm design and analysis;Correlation;Heuristic algorithms;Interpolation;Machine learning algorithms;Sensors;Time series analysis","data mining;interpolation;time series","distance metric;dynamic time warping;error transfer reduction;global distance weights;k-nearest neighbors algorithm;kNN ensembles;knowledge discovery;linear interpolation;partially missing multivariate time series data imputation;penalized DTW;point-wise distance measurements","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Learning relations using semantic-based vector similarity","K. Budai; M. Dînşoreanu; I. Bărbănţan; R. Potolea","Department of Computer Science, Technical University of Cluj-Napoca, Romania","2016 IEEE 12th International Conference on Intelligent Computer Communication and Processing (ICCP)","20161110","2016","","","69","75","The amount of electronic medical documents is growing rapidly every day. While they carry much information, it becomes more and more difficult to manually process it. Our work represents small steps towards automatic knowledge extraction from medical documents using deep learning and similarity based methods. Our goal here is to identify in an unsupervised manner relations between known medical concepts employing a deep learning strategy with Word2Vec. The current solution requires concepts annotations, as it evaluates the similarities between concepts to identify the relationship between them. The experiments suggest that the strategy we considered (to include the POS as part of the information associated to concepts and relation) represents an important step towards a fully unsupervised learning strategy. Although the POS tags alone are not good enough predictors, the addition of other meta-information and sufficient (quantitative and qualitative) training data may enhance the relation identification process, allowing for a meta learning strategy.","","Electronic:978-1-5090-3899-2; POD:978-1-5090-3900-5; USB:978-1-5090-3898-5","10.1109/ICCP.2016.7737125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737125","data correlation;deep learning;relation extraction","Context;Feature extraction;Machine learning;Medical diagnostic imaging;Neural networks;Semantics;Training","document handling;knowledge acquisition;learning (artificial intelligence);medical administrative data processing","POS tag predictors;Word2Vec;automatic knowledge extraction;concept annotations;deep learning;electronic medical documents;medical concepts;metainformation;metalearning strategy;relation identification process;relation learning;semantic-based vector similarity;training data;unsupervised learning strategy","","","","","","","8-10 Sept. 2016","","IEEE","IEEE Conference Publications"
"Convolutional Neural Network based sentiment analysis using Adaboost combination","Yazhi Gao; W. Rong; Y. Shen; Z. Xiong","School of Computer Science and Engineering, Beihang University, 100191, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1333","1338","Sentimental polarity detection has long been a hot task in natural language processing since its applications range from product feedback analysis to user statement understanding. Recently a lot of machine learning approaches have been proposed in the literature, e.g., SVM, Naive Bayes, recursive neural network, auto-encoders and etc. Among these different models, Convolutional Neural Network (CNN) architecture have also demonstrated profound efficiency in NLP tasks including sentiment classification. In CNN, the width of convolutional filter functions alike number N in N-grams model. Thus, different filter lengths may influence the performance of CNN classifier. In this paper, we want to study the possibility of leveraging the contribution of different filter lengths and grasp their potential in the final polarity of the sentence. We then use Adaboost to combine different classifiers with respective filter sizes. The experimental study on commonly used datasets has shown its potential in identifying the different roles of specific N-grams in a sentence respectively and merging their contribution in a weighted classifier.","","","10.1109/IJCNN.2016.7727352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727352","Adaboost;Convolutional Neural Networks;Sentiment Analysis","Analytical models;Feature extraction;Machine learning;Neural networks;Sentiment analysis;Training;Vocabulary","learning (artificial intelligence);natural language processing;neural nets;pattern classification","Adaboost combination;CNN architecture;CNN classifier;N-grams model;NLP tasks;SVM;auto-encoders;convolutional filter functions;convolutional neural network;machine learning;naive Bayes;natural language processing;product feedback analysis;recursive neural network;respective filter;sentiment analysis;sentiment classification;sentimental polarity detection;user statement;weighted classifier","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Discriminant vector tranformations in neural network classifiers","S. S. Auddy; K. Tyagi; S. Nguyen; M. Manry","Department of Electrical Engineering, The University of Texas at Arlington, USA","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1780","1786","We review the fact that several kinds of neural networks can be trained to approximate other types of discriminant functions, thereby throwing some doubt upon the utility of the No Free Lunch theorem. Using a license plate recognition database with 36 classes, we then demonstrate that multilayer perceptrons estimate posterior probabilities very poorly when the number of classes is large. A method for generating desired posterior probability values is provided. Then an algorithm is developed and demonstrated for warping neural net discriminants into approximate posterior probabilities.","","","10.1109/IJCNN.2016.7727415","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727415","","Algorithm design and analysis;Classification algorithms;Licenses;Machine learning algorithms;Neural networks;Support vector machines;Training","approximation theory;multilayer perceptrons;pattern classification;probability;vectors","approximate posterior probabilities;discriminant functions;discriminant vector transformations;license plate recognition database;multilayer perceptrons;neural net discriminants;neural network classifiers;no free lunch theorem","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Improving false alarm rate in intrusion detection systems using Hadoop","Y. R. Mukund; S. S. Nayak; K. Chandrasekaran","Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Karnataka, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","837","843","Intrusion Detection Systems are a vital part of an organization's security. This paper gives an account of the existing algorithms for Intrusion Detection using Machine Learning, along with certain new ideas for improving the same. The paper mainly talks about employing the Decision Tree mechanism for Intrusion Detection and improve it with the distributed file system, Hadoop. Initially a method that uses a dirty-flags to check the consistency of the Decision Tree, which changes with every wrong classification of the system is employed. The wrong classification is identified by a certain user who informs the system about the same and helps it learn. In the further sections, a new method which does not use a dirty-flag, but rather modifies the Key-Value pair in the results of the reduce() function is tested as an improvement to the previous method. The two methods are compared, with the help of the Hadoop Simulation Tool - YARN. The main aim of the paper is to propose the use of the Distributed File System for Machine Learning along with some improvements to the current Hadoop File System, so that it reduces the total Time Taken, when Machine Learning algorithms are employed along with it.","","","10.1109/ICACCI.2016.7732150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732150","Decision Tree;Hadoop;Intrusion Detection","Clustering algorithms;Data models;Decision trees;Intrusion detection;Machine learning algorithms;Support vector machines;Training data","data handling;decision trees;distributed databases;learning (artificial intelligence);parallel processing;security of data","Hadoop file system;Hadoop simulation tool;YARN;decision tree mechanism;distributed file system;false alarm rate;intrusion detection systems;key-value pair;machine learning;organization security;reduce() function;total time taken reduction","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Theoretical analysis of the Minimum Sum of Squared Similarities sampling for Nyström-based spectral clustering","D. Bouneffouf; I. Birol","Canada's Michael Smith Genome Sciences Centre, British Columbia Cancer Agency, Vancouver, Canada","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3856","3862","Spectral clustering has shown a superior performance in analyzing the cluster structure. However, the exponentially computational complexity limits its application in analyzing large-scale data. To tackle this problem, many low-rank matrix approximating algorithms are proposed, of which the Nyström method is an approach with proved lower approximate errors. The algorithms commonly combine two powerful techniques in machine learning: spectral clustering algorithms and Nyström methods commonly used to obtain good quality low rank approximations of large matrices. This paper proposes to analyze a scalable Nyström-based clustering algorithm with a Minimum Sum of Squared Similarities (MSSS) sampling procedure. We provide theoretical analysis of the performance of the algorithm MSSS and demonstrate its theoretical performance in comparison to the leading spectral clustering methods that use Nyström sampling.","","","10.1109/IJCNN.2016.7727698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727698","Nyström sampling;clustering;subsampling","Algorithm design and analysis;Approximation algorithms;Clustering algorithms;Eigenvalues and eigenfunctions;Laplace equations;Machine learning algorithms;Symmetric matrices","learning (artificial intelligence);matrix algebra;pattern clustering;sampling methods","MSSS sampling;Nyström method;Nyström sampling;Nyström-based spectral clustering;approximate errors;cluster structure analysis;low-rank matrix approximating algorithms;machine learning;minimum sum of squared similarities sampling","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Deep Learning-Based Model Reduction for Distributed Parameter Systems","M. Wang; H. X. Li; X. Chen; Y. Chen","Department of Systems Engineering and Engineering Management, City University of Hong Kong, Hong Kong","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20161115","2016","46","12","1664","1674","This paper presents a deep learning-based model reduction method for distributed parameter systems (DPSs). The proposed method includes three phases. In phase I, numerical or experimental data of the spatiotemporal distribution is reduced into low-dimensional representations using the deep auto-encoder (DAE). In phase II, the low-dimensional representations are used to establish the reduced-order model. In phase III, the reduced model is then used to reconstruct the high-dimensional DPS. Experimental studies are conducted to validate the proposed method. The proposed method is compared with the classical proper orthogonal decomposition method and demonstrates better modeling accuracy and efficiency in the experiments.","2168-2216;21682216","","10.1109/TSMC.2016.2605159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7572934","Deep learning;distributed parameter system (DPS);model reduction;restricted Boltzmann machine (RBM);spatiotemporal dynamics","Distributed parameter systems;Machine learning;Mathematical model;Modeling;Reduced order systems;Spatiotemporal phenomena;Training","distributed parameter systems;learning (artificial intelligence)","DAE;deep auto-encoder;deep learning-based model reduction;distributed parameter systems;high-dimensional DPS;low-dimensional representations;orthogonal decomposition method;reduced-order model;spatiotemporal distribution","","","","","","20160921","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"Song year prediction using Apache Spark","P. Mishra; R. Garg; A. Kumar; A. Gupta; P. Kumar","Department of Computer Science and Engineering, The LNM Institute of Information Technology, Jaipur, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","1590","1594","In this paper, we aim to predict the year in which a particular song was officially released. Listeners often have particular affection for music from certain periods of their lives (such as high school), thus, the predicted release year of a song could be a useful basis for recommendation. Furthermore, a successful model of the variation in music characteristics, through the years, could throw light on the long-term evolution of popular music. In our study, different machine learning algorithms available in the Apache Spark Machine Learning library (MLlib) are applied on a sample of Million Song Dataset (MSD). Different learning algorithms were applied for training and prediction purpose. Also, the training times are compared for single and multinode cluster environment using Apache Spark.","","","10.1109/ICACCI.2016.7732275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732275","","Decision trees;Libraries;Linear regression;Machine learning algorithms;Music;Sparks;Training","learning (artificial intelligence);music","Apache Spark machine learning library;MLlib;MSD;machine learning algorithms;million song dataset;music characteristics;song release year;song year prediction","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Object detection in pleiades images using deep features","M. Dahmane; S. Foucher; M. Beaulieu; F. Riendeau; Y. Bouroubi; M. Benoit","Computer Research Institute of Montreal, Vision and Imaging Team, Canada","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","1552","1555","Extracting and identifying objects in very high resolution imagery has been a popular research topic in remote sensing. Since the beginning of this decade, deep learning techniques have revolutionized computer vision providing significant performance gains compared to traditional “shallow” techniques in various challenging vision problems. The training of deep neural networks usually requires very large training datasets. The advantage of using deep features is to exploit already trained Convolutional Neural Networks (CNN) in order to produce high level features without the burden of having to train a CNN from scratch. In this paper, we are investigating the use of deep features for the detection of small objects (cars and individual trees) in high resolution Pleiades imagery. Preliminary results show good detection performance and are very encouraging for future applications.","","","10.1109/IGARSS.2016.7729396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729396","Object detection;deep learning;very high resolution","Automobiles;Feature extraction;Machine learning;Neural networks;Object detection;Remote sensing;Vehicle detection","automobiles;geophysical image processing;learning (artificial intelligence);neural nets;object detection;remote sensing;vegetation","Pleiades imagery;Pleiades images;car detection;computer vision;convolutional neural network;deep learning technique;deep neural network;object detection;remote sensing;tree detection;very high resolution imagery","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Assessment of deep learning for gender classification on traditional datasets","M. D. Coco; P. Carcagnì; M. Leo; P. L. Mazzeo; P. Spagnolo; C. Distante","CNR-ISASI, Campus universitario Ecotekne, Via Monteroni s.n. - Lecce - 73100 - Italy","2016 13th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)","20161110","2016","","","271","277","Deep Learning has becoming a popular and effective way to address a large set of issues. In particular, in computer vision, it has been exploited to get satisfying recognition performance in unconstrained conditions. However, this wild race towards even better performance in extreme conditions has overshadowed an important step i.e. the assessment of the impact of this new methodology on traditional issues on which for years the researchers had worked. This is particularly true for biometrics applications where the evaluation of deep learning has been made directly on newest large and more challencing datasets. This lead to a pure data driven evaluation that makes difficult to analyze the relationships between network configurations, learning process and experienced outcomes. This paper tries to partially fill this gap by applying a DNN for gender recognition on the MORPH dataset and evaluating how a lower cardinality of examples used for learning can bias the recognition performance.","","Electronic:978-1-5090-3811-4; POD:978-1-5090-3812-1","10.1109/AVSS.2016.7738061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738061","","Databases;Face;Face recognition;Feature extraction;Machine learning;Neurons","computer vision;gender issues;image classification;learning (artificial intelligence)","DNN;MORPH dataset;biometrics applications;computer vision;data driven evaluation;deep learning;experienced outcomes;gender classification;gender recognition;learning process;recognition performance","","","","","","","23-26 Aug. 2016","","IEEE","IEEE Conference Publications"
"Evolutionary computation for feature manipulation: Key challenges and future directions","B. Xue; M. Zhang","School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","3061","3067","In machine learning and data mining, feature manipulation is a data pre-processing step to increase the quality of a feature space, which can significantly improve the performance of a learning algorithm in terms of the accuracy, the learning speed, and the complexity and the interpretability of the learnt models. However, feature manipulation is a difficult task and facing more challenges along with the trend that more and more data is collected in many domains. Evolutionary computation (EC) techniques have recently attracted much attention for dealing with complex feature manipulation problems. Current work has demonstrated some strengths of EC for feature manipulation, but also shown some limitations and issues that need to be addressed. More importantly, there are some highly interesting research topics in the EC for feature manipulation area, which could potentially result in promising approaches to data analysis in a variety of real-world applications. This position paper describes and discusses the main issues and key challenges of feature manipulation, and also provides a number of directions for further consideration in future research.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744176","","Computer science;Data mining;Evolutionary computation;Feature extraction;Machine learning algorithms;Optimization;Search problems","data analysis;data mining;evolutionary computation;learning (artificial intelligence)","EC techniques;complex feature manipulation problems;data analysis;data mining;evolutionary computation techniques;machine learning","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Loop closure detection for visual SLAM using PCANet features","Y. Xia; J. Li; L. Qi; H. Fan","Department of Computer Science and Technology, Ocean University of China, Qingdao, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2274","2281","Loop closure detection benefits simultaneous localization and mapping (SLAM) in building a consistent map of the environment by reducing the accumulate error. Handcrafted features have been successfully used in traditional approaches, whereas in this paper, we show that unsupervised features extracted by deep learning models, can improves the accuracy of loop closure detection. In particular, we employ a cascaded deep network, namely the PCANet, to extract features as image descriptors. We tested the performance of our proposed method on open datasets to compare with traditional approaches. We found that the PCANet features outperform state-of-the-art handcrafted competitors, and are computational efficient to be implemented in practical robotics.","","","10.1109/IJCNN.2016.7727481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727481","Loop Closure Detection;PCANet;Simultaneous Localization and Mapping","Feature extraction;Machine learning;Principal component analysis;Simultaneous localization and mapping;Visualization","SLAM (robots);feature extraction;learning (artificial intelligence);learning systems;neurocontrollers;object detection;principal component analysis;robot vision","PCANet;cascaded deep network;deep learning models;environment map;image descriptors;loop closure detection;principal component analysis;simultaneous localization and mapping;unsupervised feature extraction;visual SLAM","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Hierarchical classification for dealing with the Class imbalance problem","M. Bader-El-Den; E. Teitei; M. Adda","School of Computing, University of Portsmouth, PO1 3HE, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3584","3591","The aim of classification in machine learning is to utilize knowledge gained from applying learning algorithms on a given data so as determine what class an unlabelled data having same pattern belongs to. However, algorithms do not learn properly when a massive difference in size between data classes exist. This classification problem exists in many real world application domains and has been a popular area of focus by machine learning and data mining researchers. The class imbalance problem is further made complex with the presence of associative data difficult factors. The duo have proven to greatly deteriorate classification performance. This paper introduces a two-phased data level approach for binary classes which entails the temporary re-labelling of classes. The proposed approach takes advantage of the local neighbourhood of the minority instances to identify and treat difficult examples belonging to both classes. Its outcome was satisfactory when compared against various data-level methods using datasets extracted from KEEL and UCI datasets repository.","","","10.1109/IJCNN.2016.7727660","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727660","","Data mining;Data models;Electronic mail;Machine learning algorithms;Sensitivity;Training","data mining;learning (artificial intelligence);pattern classification","class imbalance problem;data mining;hierarchical classification;knowledge utilization;machine learning;unlabelled data","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Rule Reduction in Air Combat Belief Rule Base Based on Fuzzy-Rough Set","B. Wu; J. Huang; W. Gao; J. Kong","Dept. of Mechatron. Eng. & Autom., Nat. Univ. of Defense Technol., Changsha, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","593","596","Because of the complicated air combat situation, more condition attributes and attributes values are contained in the air combat maneuvers belief rule base (BRB). Tens of thousands of rules lead to ""combination explosion"" problem, which degrades the inference speed seriously. Based on fuzzy rough set theory, this paper introduces information entropy to measure the significance of condition attribute, and use k-prototypes to measure the similarity between attributes values. Experiments show the reduction algorithm has a great performance in rule reduction of air combat maneuvers.","","","10.1109/ICISCE.2016.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726229","BRB;fuzzy-rough set;information entropy;rule reduction","Algorithm design and analysis;Fuzzy sets;Inference algorithms;Information entropy;Information systems;Machine learning algorithms;Rough sets","fuzzy set theory;knowledge based systems;military computing;rough set theory","BRB;air combat maneuvers;attributes values;combat belief rule base;fuzzy rough set theory;inference speed;information entropy;reduction algorithm;rule reduction","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"Nonparametrically Guided Autoencoder with Laplace Approximation for dimensionality reduction","X. Jiang; X. Song; J. Gao; Z. Cai; D. Zhang","Hubei Key Laboratory of Intelligent Geo-Information Processing, School of Computer Science, China University of Geosciences, Wuhan, 430074, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3378","3384","Unsupervised learning aims to discovery latent representation embedded in the observation, which is useful for data visualization, dimensionality reduction, and density modeling. Autoencoders have been successfully used to learn the latent variations in data, especially with the recent reintroduction by deep learning. For some specific tasks, there are supervised information or labels that can be used to further guide the unsupervised autoencoder model for finding latent representation. The Non-Parametrically Guided Autoencoder (NPGA) has been proved to be an effective model. It tries to utilize Gaussian Process Regression (GPR) to model the unknown mapping from unknown latent representation to extra supervised information. However for the discrete label information in classification tasks, using GPR could be unwise and inefficient. In this paper, we propose the Non-Parametrically Guided Autoencoder with Laplace Approximation (NPGA-LA) to effectively handle discrete labels. The idea of NPGA-LA is to make use of Gaussian Process Classification (GPC) rather than GPR to model the transformation between the latent space and the discrete label space. The experimental results verify the excellent performance of the newly developed method.","","","10.1109/IJCNN.2016.7727631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727631","","Data models;Data visualization;Gaussian processes;Ground penetrating radar;Logistics;Machine learning;Neural networks","Gaussian processes;approximation theory;data reduction;data visualisation;nonparametric statistics;pattern classification;regression analysis;unsupervised learning","GPC;GPR;Gaussian process classification;Gaussian process regression;Laplace approximation;NPGA-LA;classification tasks;data visualization;deep learning;density modeling;dimensionality reduction;discrete label information;discrete label space;latent space;latent variations;nonparametrically guided autoencoder;supervised information;unknown latent representation;unknown mapping;unsupervised autoencoder model;unsupervised learning","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Adaboost-like method for inverse reinforcement learning","K. S. Hwang; H. y. Chiang; W. C. Jiang","Department of electrical engineering, National Sun Yat-sen University, Kaohsiung, Taiwan","2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20161110","2016","","","1922","1925","Reinforcement learning allows agents to use trial and error method to learn intelligent behaviors which like human beings. However, when the learning tasks become difficult, how to define the reward function is an imperative issue. So, inverse reinforcement learning is proposed to form the reward function that imitates the process of interaction between the expert and the environment. In this paper, an Adaboost-like inverse reinforcement learning methods is proposed. This method uses Adaboost classifier and upper confidence bounds to generate the reward function for a complex task. In the imitating process, the agent continuously compares the difference between itself and the expert, and then the difference decides a specific weight for each state through Adaboost classifier. The weight combines with state confidence by upper confidence bounds to form an approximate reward function. Finally, a simulation, maze environment is used to demonstrate that the proposed method can decrease the computation time.","","Electronic:978-1-5090-0626-7; POD:978-1-5090-0627-4; USB:978-1-5090-0625-0","10.1109/FUZZ-IEEE.2016.7737926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737926","Adaboost classifier;Inverse Reinforcement Learning;Reinforcement Learning;Upper Confidence Bounds(UCB)","Classification algorithms;Electrical engineering;Error analysis;Learning (artificial intelligence);Machine learning algorithms;Mathematical model;Sun","learning (artificial intelligence);pattern classification","Adaboost classifier;Adaboost-like method;approximate reward function;complex task;intelligent behaviors;inverse reinforcement learning;maze environment;trial and error method","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Offline Arabic Handwritten recognition system with dropout applied in Deep networks based-SVMs","M. Elleuch; R. Mokni; M. Kherallah","National School of Computer Science (ENSI), University of Manouba, Tunisia","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3241","3248","As a machine learning algorithms, deep learning algorithms developed in recent years, have been successfully practiced in many fields of computer vision, like face recognition, object detection and image classification. These Deep algorithms look for drawing out a very performing representation of the data, among which image and speech, through multi-layers in a deep hierarchical structure. In this study, a deep learning model based on Support Vector Machine (SVM) named Deep SVM (DSVM) is represented. We applied the dropout technique on the Deep SVM (DSVM). It is worth noting that this model has an inherent capacity to choose data points crucial to classify good generalization capacities. The deep SVM is built by a stack of SVMs permitting to extracting/learning automatically features from the raw images and to realize classification, too. We chose and tested the Multi-class Support Vector Machine with an RBF kernel, as non-linear discriminative features for classification, on Handwritten Arabic Characters Database (HACDB). Further to these advantages, our model is safeguarded against over-fitting because of strong performance of dropout. Simulation outcomes prove the efficiency of the suggested model.","","","10.1109/IJCNN.2016.7727613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727613","Deep SVM;Deep learning;arabic handwritten script;dropout;hand-crafted feature;over-fitting","Feature extraction;Handwriting recognition;Machine learning;Neural networks;Support vector machines;Text recognition;Training","computer vision;data structures;feature extraction;handwritten character recognition;image classification;learning (artificial intelligence);natural language processing;support vector machines","DSVM;HACDB;RBF kernel;computer vision;data representation;deep SVM;deep learning algorithms;dropout;feature extraction;feature learning;handwritten Arabic characters database;image classification;machine learning algorithm;multiclass support vector machine;nonlinear discriminative feature;offline Arabic handwritten recognition system;speech","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Multi-valued autoencoders for multi-valued neural networks","R. Hata; K. Murase","Graduate school of Engineering, University of Fukui, Japan","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","4412","4417","In order to reduce data dimensions, autoencoders with neural networks have been proposed by Hinton et al. Autoencoders are composed of input, one hidden, and output layers, which tune weights and biases by a back propagation to minimize an error between inputs and outputs. The learned weights have input features, and can be applied to pretrainings of deep neural networks. However, these autoencoders have been developed for real-valued neural networks. In this study, we propose complex and quaternion autoencoders for complex and quaternion neural networks, respectively. In the complex-valued autoencoder, inputs, weights, biases and outputs of the real-valued autoencoder are extended to complex numbers. In the quaternion autoencoder, these parameters are extended to quaternion numbers. We show the learning abilities of the proposed methods using handwritten digit images. The results show that the proposed methods can recognize the images as the real-valued methods.","","","10.1109/IJCNN.2016.7727776","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727776","autoencoder;complex-valued neural network;quaternion neural network;recognition","Image recognition;Machine learning;Neural networks;Quaternions;Sections;Speech recognition;Training","backpropagation;handwritten character recognition;neural nets;number theory;optical character recognition","backpropagation;complex numbers;complex-valued autoencoder;data dimension reduction;deep neural networks;error minimization;handwritten digit images;image recognition;learning abilities;multivalued autoencoders;multivalued neural networks;quaternion autoencoders;real-valued autoencoder","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"PointNet: A 3D Convolutional Neural Network for real-time object class recognition","A. Garcia-Garcia; F. Gomez-Donoso; J. Garcia-Rodriguez; S. Orts-Escolano; M. Cazorla; J. Azorin-Lopez","Department of Computer Technology, University of Alicante, Spain","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1578","1584","During the last few years, Convolutional Neural Networks are slowly but surely becoming the default method solve many computer vision related problems. This is mainly due to the continuous success that they have achieved when applied to certain tasks such as image, speech, or object recognition. Despite all the efforts, object class recognition methods based on deep learning techniques still have room for improvement. Most of the current approaches do not fully exploit 3D information, which has been proven to effectively improve the performance of other traditional object recognition methods. In this work, we propose PointNet, a new approach inspired by VoxNet and 3D ShapeNets, as an improvement over the existing methods by using density occupancy grids representations for the input data, and integrating them into a supervised Convolutional Neural Network architecture. An extensive experimentation was carried out, using ModelNet - a large-scale 3D CAD models dataset - to train and test the system, to prove that our approach is on par with state-of-the-art methods in terms of accuracy while being able to perform recognition under real-time constraints.","","","10.1109/IJCNN.2016.7727386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727386","","Computer architecture;Machine learning;Neural networks;Object recognition;Solid modeling;Three-dimensional displays;Two dimensional displays","CAD;computer vision;data structures;learning (artificial intelligence);neural net architecture;object recognition","3D ShapeNets;3D convolutional neural network;ModelNet;PointNet;VoxNet;computer vision;deep learning techniques;density occupancy grids representations;large-scale 3D CAD model dataset;real-time object class recognition;supervised convolutional neural network architecture","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Patient-aware adaptive ngram-based algorithm for epileptic seizure prediction using EEG signals","H. Alawieh; H. Hammoud; M. Haidar; M. H. Nassralla; A. M. El-Hajj; Z. Dawy","Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon","2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthcom)","20161121","2016","","","1","6","This work proposes a novel patient-aware approach that utilizes an n-gram based pattern recognition algorithm to analyze scalp electroencephalogram (EEG) data and predict epileptic seizures. The method addresses the major challenge of extracting distinctive features from EEG signals through a detection of spatio-temporal signatures related to neurological events. By counting the number of occurrences of amplitude patterns with predefined lengths, the algorithm generates a probabilistic measure (anomalies ratio) that is used as a prediction marker. These extracted ratios are classified using state of the art machine learning algorithms into seizure and non-seizure windows. The efficacy of the prediction model is tested on patient records from the Freiburg database with more than 100 hours of recordings per patient and for a total of 145 seizures. The proposed algorithm is further optimized to obtain the n-gram parameters for enhanced feature extraction. Results demonstrate an average accuracy of 93.83%, sensitivity of 96.12%, and false alarm rate of 8.44%.","","Electronic:978-1-5090-3370-6; POD:978-1-5090-3371-3","10.1109/HealthCom.2016.7749471","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749471","","Brain modeling;Electroencephalography;Epilepsy;Feature extraction;Machine learning algorithms;Prediction algorithms;Predictive models","diseases;electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;neurophysiology;pattern recognition;probability;signal detection","EEG signals;Freiburg database;electroencephalogram data;epileptic seizure prediction;feature extraction;machine learning;n-gram based pattern recognition;neurological events;patient records;patient-aware adaptive ngram-based algorithm;probabilistic measure;spatio-temporal signature detection","","","","","","","14-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"An evolutionary many-objective optimisation algorithm with adaptive region decomposition","H. L. Liu; L. Chen; Q. Zhang; K. Deb","Guangdong University of Technology, Guangzhou, China","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","4763","4769","When optimizing an multiobjective optimization problem, the evolution of population can be regarded as a approximation to the Pareto Front (PF). Motivated by this idea, we propose an adaptive region decomposition framework: MOEA/D-AM2M for the degenerated Many-Objective optimization problem (MaOP), where degenerated MaOP refers to the optimization problem with a degenerated PF in a subspace of the objective space. In this framework, a complex MaOP can be adaptively decomposed into a number of many-objective optimization subproblems, which is realized by the adaptively direction vectors design according to the present population's distribution. A new adaptive weight vectors design method based on this adaptive region decomposition is also proposed for selection in MOEA/D-AM2M. This strategy can timely adjust the regions and weights according to the population's tendency in the evolutionary process, which serves as a remedy for the inefficiency of fixed and evenly distributed weights when solving MaOP with a degenerated PF. Five degenerated MaOPs with disconnected PFs are generated to identify the effectiveness of proposed MOEA/D-AM2M. Contrast experiments are conducted by optimizing those MaOPs using MOEA/D-AM2M, MOEA/D-DE and MOEA/D-M2M. Simulation results have shown that the proposed MOEA/D-AM2M outperforms MOEA/D-DE and MOEA/D-M2M.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744399","","Algorithm design and analysis;Electronic mail;Machine learning algorithms;Optimization;Simulation;Sociology;Statistics","Pareto optimisation;evolutionary computation","MOEA/D-AM2M;MOEA/D-DE;MOEA/D-M2M;MaOP;PF;Pareto front;adaptive region decomposition framework;direction vector design;distributed weights;evolutionary many-objective optimisation algorithm;multiobjective optimization problem;population distribution","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Predicting user's multi-interests with network embedding in health-related topics","Z. Jin; R. Liu; Q. Li; D. D. Zeng; Y. Zhan; L. Wang","The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences Beijing 100190, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2568","2575","With the rapid growth of Web 2.0, social media has become a prevalent information sharing and seeking channel for health surveillance, in which users form interactive networks by posting and replying messages, providing and rating reviews, attending multiple discussion boards on health-related topics. Users' behaviors in these interactive networks reflect users' multiple interests. To provide better information service for users, it is necessary to analyze the user interactions and predict users' multi-interests. Most existing work in predicting users' multi-interests based on multi label network classification focuses on using approximate inference methods to leverage the dependency information to improve classification results. Inspired by deep learning techniques, DEEPWALK learns label independent latent representations of vertices in a network using local information obtained from truncated random walks, which provides an efficient way for predicting users multi-interests from user interactions. In this paper, we develop a user's multi-interests prediction model based on DEEPWALK, weight information of user interactions is considered when modeling a stream of short constrained random walks and SkipGram is employed to generate more accurate representations of user vertices, which help identify users' interests. Experimental results on two real world health-related datasets show the efficacy of the proposed model.","","","10.1109/IJCNN.2016.7727520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727520","DEEPWALK;multi-interests prediction;user interaction network;weight information","Feature extraction;Machine learning;Peer-to-peer computing;Predictive models;Surveillance;Twitter","human computer interaction;interactive systems;learning (artificial intelligence);medical information systems;pattern classification;random processes;social networking (online)","DEEPWALK;SkipGram;Web 2.0;approximate inference methods;deep learning;discussion boards;health surveillance;health-related topics;information seeking channel;information service;information sharing;interactive networks;label independent latent representations;multilabel network classification;network embedding;random walks;social media;user interactions;user multiinterests prediction model;user vertices;users behaviors;weight information","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Feature selection approach based on moth-flame optimization algorithm","H. M. Zawbaa; E. Emary; B. Parv; M. Sharawi","Faculty of Mathematics and Computer Science, Babes-Bolyai University, Romania","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","4612","4617","In this work, a feature selection algorithm based on moth-flame optimization (MFO) is proposed. Moth-flame optimization (MFO) is a recently proposed swarm intelligent optimization algorithm that mimics the motion of moths. The proposed algorithm is applied in the domain of machine learning for feature selection to find the optimal feature combination using wrapper-based feature selection mode. In wrapper-based feature selection, a machine learning technique is used in the evaluation step. Despite it is very costly in time, this technique proved to have a good performance in classification accuracy. MFO is exploited in this study as a searching method to find optimal feature set, maximizing classification performance. The proposed algorithm is compared against particle swarm optimization (PSO) and genetic algorithms (GA). A set of UCI data sets is used for comparison using different assessment indicators. Results prove the efficiency of the proposed algorithm in comparison to other algorithms.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744378","Bio-inspired Optimization;Feature Selection;Moth-Flame Optimization;Swarm Optimization","Genetic algorithms;Machine learning algorithms;Mathematical model;Moon;Optimization;Sociology;Spirals","feature selection;genetic algorithms;learning (artificial intelligence);particle swarm optimisation;pattern classification;swarm intelligence","GA;MFO;PSO;UCI data sets;classification performance maximization;feature selection approach;genetic algorithms;machine learning technique;moth-flame optimization algorithm;optimal feature combination;optimal feature set;particle swarm optimization;searching method;swarm intelligent optimization algorithm;wrapper-based feature selection mode","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Equity price direction prediction for day trading: Ensemble classification using technical analysis indicators with interaction effects","D. Van den Poel; C. Chesterman; M. Koppen; M. Ballings","Faculty of Economics and Business Administration, Ghent University, Tweekerkenstraat 2, Ghent, B-9000, Belgium","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","3455","3462","We investigate the performance of complex trading rules in equity price direction prediction, over and above continuous-valued indicators and simple technical trading rules. Ten of the most popular technical analysis indicators are included in this research. We use Random Forest ensemble classifiers using minute-by-minute stock market data. Results show that our models have predictive power and yield better returns than the buy-and-hold strategy when disregarding transaction costs both in terms of number of stocks with profitable trades as well as overall returns. Moreover, our findings show that two-way and three-way combinations, i.e., complex trading rules, are important to “beat” the buy-and-hold strategy.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744227","big data analytics;day trading;ensemble classification;equity price direction prediction;quantitative analysis;stock trading;systematic trading;technical analysis","Biological system modeling;Classification algorithms;Data models;Machine learning algorithms;Prediction algorithms;Predictive models;Support vector machines","learning (artificial intelligence);pattern classification;pricing;stock markets;transaction processing","complex trading rules;continuous-valued indicators;day trading;ensemble classification;equity price direction prediction;interaction effects;minute-by-minute stock market data;profitable trades;random forest ensemble classifiers;technical analysis indicators;technical trading rules;three-way combinations;transaction costs;two-way combinations","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Distributed Information-Theoretic Metric Learning in Apache Spark","Y. Su; H. Yang; I. King; M. Lyu","Shenzhen Key Laboratory of Rich Media Big Data Analytics and Applications, Shenzhen Research Institute, The Chinese University of Hong Kong, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3306","3313","Distance metric learning (DML) is an effective similarity learning tool to learn a distance function from examples to enhance the model performance in applications of classification, regression, and ranking, etc. Most DML algorithms need to learn a Mahalanobis matrix, a positive semidefinite matrix that scales quadratically with the number of dimensions of input data. This brings huge computational cost in the learning procedure, and makes all proposed algorithms infeasible for extremely high-dimensional data even with the low-rank approximation. Differently, in this paper, we take advantage of the power of parallel computation and propose a novel distributed distance metric learning algorithm based on a state-of-the-art DML algorithm, Information-Theoretic Metric Learning (ITML).More specifically, we utilize the property that each positive semidefinite matrix can be decomposed into a combination of rank-one and trace-one matrices and convert the original sequential training procedure into a parallel one. In most cases, the communication demands of the proposed method are also reduced from O(d<sup>2</sup>) to O(cd), where d is the number of dimensions of the data and c is the number of constraints in DML and can be smaller than d by appropriate selection. Moreover importantly, we present a rigorous theoretical analysis to upper bound the Bregman divergence between the sequential algorithm and the parallel algorithm, which guarantees the correctness and performance of the proposed algorithm. Our experiments on datasets with O(10<sup>5</sup>) features demonstrate the competitive scalability and the performance compared with the original ITML algorithm.","","","10.1109/IJCNN.2016.7727622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727622","","Algorithm design and analysis;Approximation algorithms;Covariance matrices;Eigenvalues and eigenfunctions;Machine learning algorithms;Matrix decomposition;Measurement","information theory;learning (artificial intelligence);matrix algebra;parallel algorithms","Apache Spark;Bregman divergence;DML algorithms;ITML;Mahalanobis matrix learning;distance function learning;distributed distance metric learning;distributed information-theoretic metric learning;high-dimensional data;low-rank approximation;original sequential training procedure;parallel algorithm;parallel computation;positive semidefinite matrix;rank-one matrices;sequential algorithm;similarity learning tool;trace-one matrices","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Hierarchical Representation Learning for Kinship Verification","N. Kohli; M. Vatsa; R. Singh; A. Noore; A. Majumdar","Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA","IEEE Transactions on Image Processing","20161121","2017","26","1","289","302","Kinship verification has a number of applications such as organizing large collections of images and recognizing resemblances among humans. In this paper, first, a human study is conducted to understand the capabilities of human mind and to identify the discriminatory areas of a face that facilitate kinshipcues. The visual stimuli presented to the participants determine their ability to recognize kin relationship using the whole face as well as specific facial regions. The effect of participant gender and age and kin-relation pair of the stimulus is analyzed using quantitative measures such as accuracy, discriminability index d', and perceptual information entropy. Utilizing the information obtained from the human study, a hierarchical kinship verification via representation learning (KVRL) framework is utilized to learn the representation of different face regions in an unsupervised manner. We propose a novel approach for feature representation termed as filtered contractive deep belief networks (fcDBN). The proposed feature representation encodes relational information present in images using filters and contractive regularization penalty. A compact representation of facial images of kin is extracted as an output from the learned model and a multi-layer neural network is utilized to verify the kin accurately. A new WVU kinship database is created, which consists of multiple images per subject to facilitate kinship verification. The results show that the proposed deep learning framework (KVRL-fcDBN) yields the state-of-the-art kinship verification accuracy on the WVU kinship database and on four existing benchmark data sets. Furthermore, kinship information is used as a soft biometric modality to boost the performance of face verification via product of likelihood ratio and support vector machine based approaches. Using the proposed KVRL-fcDBN framework, an improvement of over 20% is observed in the performance of face verification.","1057-7149;10577149","","10.1109/TIP.2016.2609811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7567585","Kinship verification;deep belief networks;face verification;soft biometrics","Entropy;Face;Face recognition;Indexes;Machine learning;Training","belief networks;face recognition;image representation;learning (artificial intelligence)","KVRL framework;KVRL-fcDBN framework;WVU kinship database;accuracy measure;contractive regularization penalty;discriminability index;facial region;fcDBN;feature representation;filtered contractive deep belief networks;hierarchical representation learning;human mind capability;human study;kin relationship;kin-relation pair;kinship verification;participant age;participant gender;perceptual information entropy;quantitative measure;unsupervised learning","","","","","","20160914","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Solar forecasting by K-Nearest Neighbors method with weather classification and physical model","Z. Liu; Z. Zhang","Department of Electrical and Computer Engineering, Binghamton University, SUNY Binghamton, New York","2016 North American Power Symposium (NAPS)","20161121","2016","","","1","6","With the increasing penetration of solar photovoltaic (PV) generation in the power system, the reliability of the distribution system and efficiency of PV systems have garnered increasing attention in recent years. Forecasting the PV output is one way to decrease the uncertainty of such power systems. In this study, we present a K-Nearest Neighbors algorithm based forecasting model, which can provide the estimated PV output by utilizing numerical weather and solar irradiance prediction data. This forecasting model also includes a weather condition classification process and a physical model of PV units. Numerical results are evaluated by using data from an existing 128kW rooftop PV system.","","Electronic:978-1-5090-3270-9; POD:978-1-5090-3271-6","10.1109/NAPS.2016.7747859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7747859","k-nearest neighbors;photovoltaic power system;physical model;solar forecasting;weather condition classification","Clouds;Forecasting;Machine learning algorithms;Meteorology;Numerical models;Prediction algorithms;Predictive models","building integrated photovoltaics;photovoltaic power systems;power generation reliability;sunlight","K-nearest neighbor method;distribution system reliability;numerical weather prediction data;physical model;power 128 kW;rooftop PV system;solar PV power system efficiency;solar forecasting model;solar irradiance prediction data;solar photovoltaic generation penetration;weather classification;weather condition classification process","","","","","","","18-20 Sept. 2016","","IEEE","IEEE Conference Publications"
"A deep learning approach to the classification of sub-decimetre resolution aerial images","J. R. Bergado; C. Persello; C. Gevaert","Dept. of Earth Observation Science, ITC, University of Twente, Enschede, The Netherlands","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","1516","1519","Spatial-contextual features play a vital role in the classification of very high resolution aerial images characterized by sub-decimetre resolution. However, manually extracting relevant contextual features is difficult and time-consuming in the analysis of sub-decimetre resolution images, where the objects of interest are significantly larger than the pixel size. Deep learning methods allow us to replace hand-crafted features by automatically learning contextual features from the image. In this paper, we investigate the use of convolutional neural networks (CNN) for the classification of urban areas using high resolution airborne images. We also analyse the sensitivity of network hyperparameters providing an interpretation of their effect on the extraction of spatial-contextual features. Experimental results show the effectiveness of CNN in learning discriminative contextual features leading to accurate classified maps and outperforming traditional classification methods based on the extraction of textural features.","","","10.1109/IGARSS.2016.7729387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729387","airborne imagery;deep learning;feature extraction;urban scene classification","Convolution;Feature extraction;Machine learning;Sensitivity analysis;Spatial resolution;Training","geophysical techniques;image classification;image resolution;neural nets","CNN;automatic learning contextual features;contextual feature extraction;convolutional neural networks;deep learning approach;deep learning methods;discriminative contextual features;hand-crafted features;high resolution aerial image classification;high resolution airborne images;network hyperparameter sensitivity;spatial-contextual feature extraction;spatial-contextual features;sub-decimetre resolution aerial image classification;sub-decimetre resolution characterization;sub-decimetre resolution image analysis;traditional classification methods;traditional textural extraction;urban area classification","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Context-dependent social mapping","K. Charalampous; I. Kostavelis; A. Gasteratos","Laboratory of Robotics and Automation, Production and Management Engineering Dept., Democritus University of Thrace, Greece","2016 IEEE International Conference on Imaging Systems and Techniques (IST)","20161110","2016","","","30","35","Advanced robotics systems in human frequented environments need to be equipped with avant-garde capabilities, so as to attain a social behavior acceptable by their human proprietors. Therefore, robots should learn and react properly when they share a common domain with humans and adjust their operation according to the activity of the people around. This paper proposes a social mapping method which makes use of 3D maps, action recognition and proxemics theory. In particular, as it moves around, the robot builds a metric map of the surroundings and arranges it in topological graphs. Meanwhile, it can detect any individual existing nearby and capitalizes on a deep learning technique to recognize its action. The recognized actions form the context-dependent social zones which are registered with specific proxemics rules to determine the robot's navigational behavior. The proposed method was assessed with an indoors navigating robot, equipped with an RGB-D sensor. The human and action recognition units showed superior operation rendering the navigation module capable of planning trajectories for the robot to move around humans.","","Electronic:978-1-5090-1817-8; POD:978-1-5090-1818-5","10.1109/IST.2016.7738193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738193","","Feature extraction;Machine learning;Measurement;Navigation;Robot kinematics;Robot sensing systems","SLAM (robots);graph theory;human-robot interaction;image colour analysis;learning systems;mobile robots;navigation;object recognition;path planning;robot vision;trajectory control","3D map;RGB-D sensor;action recognition;advanced robotics system;avant-garde capability;context-dependent social mapping;context-dependent social zone;deep learning technique;human frequented environment;human recognition;indoor navigating robot;metric map building;proxemics theory;robot learning;robot navigational behavior;social behavior;social mapping method;topological graph;trajectory planning","","","","","","","4-6 Oct. 2016","","IEEE","IEEE Conference Publications"
"Learning classifier system with deep autoencoder","K. Matsumoto; Y. Tajima; R. Saito; M. Nakata; H. Sato; T. Kovacs; K. Takadama","The University of Electro-Communications, Tokyo, Japan","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","4739","4746","This paper proposes a novel Learning Classifier System (LCS) which integrates Deep AutoEncoder named DAE to solve high-dimensional problems. In the proposed LCS, DAE starts to compress (encode) an environmental input as a high-dimensional information to an input of LCS as a low-dimensional information and decompresses (decodes) an output of LCS as a low-dimensional information to a system output as a high-dimensional information. Since the compressed inputs are encoded by real value, this paper employs XCSR (i.e., an LCS with real value coding) and combines XCSR with DAE. In order to investigate the effectiveness of the proposed LCS, XCSR with DAE, this paper conducts the preliminary experiment on the benchmark classification problem, i.e., 6-Multiplexer problem. The intensive experiments on the compression from 6 to 5 bits have revealed the following implications: (1) XCSR with DAE performs as well as XCSR even learning from the compressed input data; and (2) XCSR with DAE successfully decodes the compressed rules to extract the rules which are the same as those learned with not compressed input data.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744396","","Artificial neural networks;Benchmark testing;Electronic mail;Knowledge discovery;Machine learning;Sociology;Statistics","encoding;learning (artificial intelligence);pattern classification","6-multiplexer problem;DAE;LCS;XCSR;benchmark classification problem;compressed rules;deep autoencoder;high-dimensional information;learning classifier system;low-dimensional information;rule extraction","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Graph-based deep Convolutional networks for Hyperspectral image classification","J. Cao; Z. Chen; B. Wang","Key Laboratory for Information Science of Electromagnetic Waves (MoE), Fudan University, Shanghai 200433, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","3270","3273","Classification has been among the central issues of hyperspectral application. However, due to the well-known Hughes phenomenon, most of the methods suffer from the curse of dimensionality and deeply rely on traditional dimensional reduction like Principle Component Analysis (PCA). In this paper, combining spatial and spectral information jointly, we propose a novel deep classification framework. It consists of two parts: graph-based spatial fusion and Convolutional Neural Network (CNN). Spatial fusion acts as a pre-training stage that extracts spatial-spectral features from high-order data. CNN learns and infers spectrum efficiently from fused input via deep hierarchy with convolutional and pooling layers, thus forming a relationship between spectral-spatial features and class distribution. Experiment results show that the performance of the proposed classifier is competitive enough with other pixel-wise classifiers.","","","10.1109/IGARSS.2016.7729846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729846","Convolutional Neural Network;Deep Learning;Deep Neural Network;Hyperspectral Classification;Spectral Clustering;Support Vector Machine","Convolutional codes;Feature extraction;Hyperspectral imaging;Machine learning;Neural networks;Support vector machines;Training","hyperspectral imaging;image classification;neural nets;remote sensing","Hughes phenomenon;convolutional neural network;dimensional reduction;graph-based deep convolutional network;graph-based spatial fusion;hyperspectral image classification;pixel-wise classifier;principle component analysis","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Development of Real-Time Road Surface Condition Determination Algorithm Using an Automatic Weather System","M. Lee; M. Kim","Weather Inf. Service Engine Inst., Hankuk Univ. of Foreign Studies, Seoul, South Korea","2016 6th International Conference on IT Convergence and Security (ICITCS)","20161110","2016","","","1","2","A road weather observation system (RWOS), which is used for observing the weather and surface conditions of roads, cannot be installed for all sections of the road to provide high-resolution road weather information because the associated devices are expensive. Furthermore, because the road condition information that is most closely related to safe driving is weather conditions, e.g. ice, snow, and rain, road conditions should be determined by a nodelink when a high-resolution automatic weather system (AWS) is applied. Therefore, in this research, an algorithm was proposed for determining real-time road surface conditions using ensemble learning. Learning data was organized using time-series mapping of observed data from the RWOS and the AWS. The road condition determination model uses machine learning. As a result, weather conditions from nodelinks on major roads in Seoul, South Korea, were calculated and presented. Road conditions were determined and provided to drivers in real-time based on the corresponding data.","","Electronic:978-1-5090-3765-0; POD:978-1-5090-3766-7","10.1109/ICITCS.2016.7740326","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7740326","","Classification algorithms;Data models;Information systems;Machine learning algorithms;Meteorology;Real-time systems;Roads","data mining;driver information systems;geophysics computing;learning (artificial intelligence);road safety;time series;weather forecasting","AWS;RWOS;automatic weather system;data mining;ensemble learning;machine learning;real-time road surface condition determination;road weather observation system;safe driving;time series mapping","","","","","","","26-26 Sept. 2016","","IEEE","IEEE Conference Publications"
"How useful is region-based classification of remote sensing images in a deep learning framework?","N. Audebert; B. Le Saux; S. Lefèvre","ONERA, The French Aerospace Lab, F-91761 Palaiseau, France","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","5091","5094","In this paper, we investigate the impact of segmentation algorithms as a preprocessing step for classification of remote sensing images in a deep learning framework. Especially, we address the issue of segmenting the image into regions to be classified using pre-trained deep neural networks as feature extractors for an SVM-based classifier. An efficient segmentation as a preprocessing step helps learning by adding a spatially-coherent structure to the data. Therefore, we compare algorithms producing superpixels with more traditional remote sensing segmentation algorithms and measure the variation in terms of classification accuracy. We establish that superpixel algorithms allow for a better classification accuracy as a homogenous and compact segmentation favors better generalization of the training samples.","","","10.1109/IGARSS.2016.7730327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730327","Deep learning;Image classification;Remote sensing;Segmentation algorithms;Superpixels","Feature extraction;Image segmentation;Machine learning;Remote sensing;Semantics;Shape;Training","feature extraction;geophysical image processing;image classification;image segmentation;learning (artificial intelligence);remote sensing","SVM based classifier;deep learning framework;feature extractors;region based classification;remote sensing images;segmentation algorithms;spatially coherent structure","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"An XCS-based algorithm for multi-objective reinforcement learning","X. Cheng; G. Chen; M. Zhang","School of Engineering and Computer Science, Victoria University of Wellington","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","4007","4014","The real world is full of problems with multiple conflicting objectives. However, reinforcement learning traditionally deals with only a single learning objective. Recently, several multi-objective reinforcement learning algorithms have been proposed. Nevertheless, many of these algorithms rely on tabular representations of the value function which are only suitable for solving small-scaled problems. To address this limitation, various learning classifier systems have been developed to learn a scalable representation in the form of a population of classifiers. Among all learning classifier systems, XCS has been most popularly used for tackling single-objective reinforcement learning problems. Aimed at achieving multi-objective learning, a new algorithm has been developed in this paper based on XCS. Our algorithm is designed to learn a group of Pareto optimal solutions through a single learning process. For this purpose, four technical issues in XCS have been identified and addressed in this paper. Experimental studies on three bi-objective maze problems further demonstrate the effectiveness of our algorithm.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744298","","Algorithm design and analysis;Learning (artificial intelligence);Machine learning algorithms;Pareto optimization;Process control;Sociology","Pareto optimisation;learning (artificial intelligence);pattern classification","Pareto optimal solutions;XCS-based algorithm;learning classifier system;multi-objective reinforcement learning","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Data mining technique for the enhanced smoking cessation management system (Smoke Mind)","A. H. Alsharif; N. Philip","Management Information Systems, College of Science and Humanities Majmaah, University. KSA","2016 International Conference on Engineering & MIS (ICEMIS)","20161117","2016","","","1","1","Data mining can be defined as the use of complex tools of data analysis to discover previously unknown relationships and patterns in large datasets. The tools may include mathematical algorithms, statistical models and machine learning methods. Therefore, data mining comprises techniques that enable more processes than data collection and management, including data analysis and prediction. Healthcare databases have huge amounts of data, and with effective analysis tools, a great deal of hidden knowledge may be discovered. Therefore, data mining can be particularly useful for analysing and extracting hidden knowledge in huge amounts of data such as those obtained from smokers. Data mining has found an application in the healthcare system. Data mining in healthcare organisations can transform the raw data held by the organisation into useful knowledge with minimal intervention by the user, be it a doctor or an administrator. It also can help to discover new healthcare knowledge for clinical and administrative decision making, as well as producing scientific hypotheses from large sets of experimental data and clinical databases. In the analysis of smoking behaviour, there are a limited number of cases where data mining has been well utilised. A review of the literature on the subject reveals that there is an apparent lack of theoretical and empirical frameworks that address how data mining can be used to better understand smokers and smoking patterns in order to improve the design and content of smoking cessation programmes. This study aims to build a self-developing system for improving smoking cessation programmes using a data mining technique to detect smoker behaviour, and behaviour change therapy to determine the smokers quit plan. The system is based on a continuous acquisition of data, thereby improving its results regularly.","","Electronic:978-1-5090-5579-1; POD:978-1-5090-5580-7","10.1109/ICEMIS.2016.7745359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745359","Naïve Bayes technique;classification;data mining;decision table;smoking cessation","Data analysis;Data mining;Databases;Machine learning algorithms;Management information systems;Medical services;Prediction algorithms","data analysis;data mining;database management systems;decision making;health care;learning (artificial intelligence);pattern classification;smoke;statistics","administrative decision making;clinical decision making;data analysis;data mining;data prediction;healthcare databases;machine learning methods;mathematical algorithms;smoke mind;smoking cessation management system;statistical models","","","","","","","22-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Active learning based autoencoder for hyperspectral imagery classification","Y. Sun; J. Li; W. Wang; A. Plaza; Z. Chen","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, 430079, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","469","472","In this paper, we joint autoencoder with active learning for hyperspectral imagery classification. Specifically, we learn the classifier via autoencoder, where the most informative samples are acitvely selected through the interaction between the autoencoder and active learning. Experimental results, conducted using both the Kennedy Space Center and the Indian Pines hyperspectral images, show that driven by active learning, the performance of autoencoder can be greatly improved.","","","10.1109/IGARSS.2016.7729116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729116","Autoencoder;active learning;deep learning;hyperspectral imagery classification","Hyperspectral imaging;Indexing;Machine learning;Neural networks;Training","geophysical image processing;hyperspectral imaging;image classification;remote sensing","Indian Pines hyperspectral images;Kennedy Space Center hyperspectral images;active learning based autoencoder;classifier;hyperspectral imagery classification","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"A pseudoinverse incremental algorithm for fast training deep neural networks with application to spectra pattern recognition","K. Wang; P. Guo; Q. Yin; A. L. Luo; X. Xin","School of Computer Science and Technology, Beijing Institute of Technology, 100081, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3453","3460","Deep learning scheme has received significant attention during these years, particularly as a way of building hierarchical representations from unlabeled data for a variety of signal and information processing tasks. However, deep neural networks suffer from slow learning speed since most used training algorithms are based on variations of the gradient descent algorithms which require iterative optimization and thus are time-consuming. In addition, a series of control parameters need to be specified empirically which lacks of the theoretical guidance, and current learning algorithms for deep networks are not very suitable to incremental learning scenario. To address these issues, we propose a fast learning scheme in this paper. The basic idea of our approach is to pre-train basic units such as auto-encoders of the deep architecture in an analytical way without any iterative optimization procedure. This scheme is also extended to an incremental learning version. The experimental result shows the superiority of our approach over the state-of-the-art gradient descent based algorithms. To demonstrate the impact of our algorithm on complicated real world applications, we give an example of its performance in astronomical spectra pattern recognition.","","","10.1109/IJCNN.2016.7727642","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727642","","Algorithm design and analysis;Astronomy;Machine learning;Neural networks;Neurons;Pattern recognition;Training","gradient methods;iterative methods;learning (artificial intelligence);neural nets;optimisation;pattern recognition","astronomical spectra pattern recognition;auto-encoders;deep architecture;deep learning scheme;fast training deep neural networks;gradient descent algorithms;hierarchical representations;incremental learning scenario;information processing tasks;iterative optimization procedure;pseudoinverse incremental algorithm;real world applications;signal processing tasks","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Gabor Feature Based Convolutional Neural Network for Object Recognition in Natural Scene","H. Yao; L. Chuyi; H. Dan; Y. Weiyu","Sch. of Electron. & Inf. Eng., South China Univ. of Technol., Guangzhou, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","386","390","Feature extraction and classification are two important components in object recognition. While the traditional methods design these components individually, the deep neural networks jointly learn these two parts. In this paper, we propose a method of the convolutional neural network combined with Gabor filters for strengthening the learning of texture information. We called this model as Gabor-CNN below. Through experiments, the approach achieves the recognition rate of 81.53%, yielding a 1.26% promotion in the average accuracy rate compared with the results obtained using the convolutional neural network model alone on the ImageNet10 dataset, as well as significantly outperforming the traditional method based on Bag-of-Words model with SIFT.","","","10.1109/ICISCE.2016.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726188","CNN;Gabor;SIFT;object recognition","Biological neural networks;Feature extraction;Kernel;Machine learning;Neurons;Object recognition;Training","Gabor filters;feature extraction;image classification;image texture;natural scenes;neural nets;object recognition","Gabor feature based convolutional neural network;Gabor filters;Gabor-CNN;ImageNet10 dataset;deep neural networks;feature extraction;image classification;natural scene;object recognition;texture information learning","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"Filterbank learning for deep neural network based polyphonic sound event detection","E. Cakir; E. C. Ozan; T. Virtanen","Tampere University of Technology, Finland","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3399","3406","Deep learning techniques such as deep feedforward neural networks and deep convolutional neural networks have recently been shown to improve the performance in sound event detection compared to traditional methods such as Gaussian mixture models. One of the key factors of this improvement is the capability of deep architectures to automatically learn higher levels of acoustic features in each layer. In this work, we aim to combine the feature learning capabilities of deep architectures with the empirical knowledge of human perception. We use the first layer of a deep neural network to learn a mapping from a high-resolution magnitude spectrum to smaller amount of frequency bands, which effectively learns a filterbank for the sound event detection task. We initialize the first hidden layer weights to match with the perceptually motivated mel filterbank magnitude response. We also integrate this initialization scheme with context windowing by using an appropriately constrained deep convolutional neural network. The proposed method does not only result with better detection accuracy, but also provides insight on the frequencies deemed essential for better discrimination of given sound events.","","","10.1109/IJCNN.2016.7727634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727634","","Acoustics;Dogs;Event detection;Feature extraction;Hidden Markov models;Machine learning;Neural networks","acoustic signal processing;audio signal processing;channel bank filters;feature extraction;feedforward neural nets;learning (artificial intelligence);signal detection;signal resolution","acoustic features;constrained deep convolutional neural network;context windowing;deep architectures;deep learning techniques;deep neural network based polyphonic sound event detection;feature learning capabilities;filterbank learning;first hidden layer weights;frequency bands;high-resolution magnitude spectrum;human perception empirical knowledge;initialization scheme;perceptually motivated Mel filterbank magnitude response","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A Deep-Neuro-Fuzzy approach for estimating the interaction forces in Robotic surgery","A. I. Aviles; S. M. Alsaleh; E. Montseny; P. Sobrevilla; A. Casals","Research Center of Biomedical Engineering, Universitat Polit&#x00E8;cnica de Cataluya, Spain","2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20161110","2016","","","1113","1119","Fuzzy theory was motivated by the need to create human-like solutions that allow representing vagueness and uncertainty that exist in the real-world. These capabilities have been recently further enhanced by deep learning since it allows converting complex relation between data into knowledge. In this paper, we present a novel Deep-Neuro-Fuzzy strategy for unsupervised estimation of the interaction forces in Robotic Assisted Minimally Invasive scenarios. In our approach, the capability of Neuro-Fuzzy systems for handling visual uncertainty, as well as the inherent imprecision of real physical problems, is reinforced by the advantages provided by Deep Learning methods. Experiments conducted in a realistic setting have demonstrated the superior performance of the proposed approach over existing alternatives. More precisely, our method increased the accuracy of the force estimation and compared favorably to existing state of the art approaches, offering a percentage of improvement that ranges from about 35% to 85%.","","Electronic:978-1-5090-0626-7; POD:978-1-5090-0627-4; USB:978-1-5090-0625-0","10.1109/FUZZ-IEEE.2016.7737812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737812","","Estimation;Force;Machine learning;Robots;Three-dimensional displays;Uncertainty;Visualization","fuzzy neural nets;fuzzy set theory;medical robotics;surgery","deep learning methods;deep neuro fuzzy theory;deep-neuro-fuzzy strategy;force estimation;human-like solutions;interaction forces;neuro-fuzzy systems;robotic assisted minimally invasive scenarios;robotic surgery;unsupervised estimation;vagueness;visual uncertainty","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Multinomial Naive Bayes for real-time gender recognition","D. Vergara; S. Hernández; F. Jorquera","Geospatial Laboratory, Universidad Cat&#x00F3;lica del Maule, Talca, Chile","2016 XXI Symposium on Signal Processing, Images and Artificial Vision (STSIVA)","20161117","2016","","","1","6","Existing implementations of face recognition systems are created under controlled environments and tested using a limited amount of data. Also, these techniques have a high computational cost which forbids incremental learning that is required in real-time. We propose a gender estimation implementation based on Multinomial Naive Bayes and Local Binary Patterns. The method is tested in a modern age and gender recognition dataset with realistic examples. In order to get state-of-the-art results, Adaboost is also proposed and tested.","","Electronic:978-1-5090-3797-1; POD:978-1-5090-3798-8","10.1109/STSIVA.2016.7743331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743331","","Approximation algorithms;Computational efficiency;Databases;Machine learning algorithms;Principal component analysis;Real-time systems;Support vector machines","Bayes methods;estimation theory;face recognition;gender issues;learning (artificial intelligence);pattern recognition;real-time systems","face recognition systems;gender estimation;high computational cost;incremental learning;local binary patterns;multinomial naive Bayes;real-time gender recognition","","","","","","","Aug. 31 2016-Sept. 2 2016","","IEEE","IEEE Conference Publications"
"Assessing diffusion of spatial features in Deep Belief Networks","H. Tosun; B. Mitchell; J. Sheppard","Department of Computer Science, Montana State University, USA","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1625","1632","Deep learning has recently gained popularity in many machine learning applications, but a theoretical grounding for the strengths, weaknesses, and implicit biases of various deep learning methods is still a work in progress. Here, we analyze the role of spatial locality in Deep Belief Networks (DBN) and show that spatially local information is lost through diffusion as the network becomes deeper. We then analyze an approach we developed previously, based on partitioning of Restricted Boltzmann Machines (RBMs), to demonstrate that our method is capable of retaining spatially local information when training DBNs. Specifically, we find that spatially local features are completely lost in DBNs trained using the “standard” RBM method, but are largely preserved using our partitioned training method. In addition, reconstruction accuracy of the model is improved using our Partitioned-RBM training method.","","","10.1109/IJCNN.2016.7727392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727392","","Computer science;Correlation;Electronic mail;Machine learning;Partitioning algorithms;Standards;Training","Boltzmann machines;belief networks;learning (artificial intelligence)","DBN;deep belief networks;deep learning methods;machine learning applications;partitioned training method;partitioned-RBM training method;reconstruction accuracy;restricted Boltzmann machines;spatial feature diffusion assessment;spatial locality;spatially local features;spatially local information;standard RBM method","","1","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Hyperspectral image classification with small training set by deep network and relative distance prior","X. Ma; H. Wang; J. Geng; J. Wang","School of Information and Communication Engineering, Dalian University of Technology, 116024, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","3282","3285","This paper presents a hyperspectral image classification method based on deep network, which has shown great potential in various machine learning tasks. Since the quantity of training samples is the primary restriction of the performance of classification methods, we impose a new prior on the deep network to deal with the instability of parameter estimation under this circumstances. On the one hand, the proposed method adjusts parameters of the whole network to minimize the classification error as all supervised deep learning algorithm, on the other hand, unlike others, it also minimize the discrepancy within each class and maximize the difference between different classes. The experimental results showed that the proposed method is able to achieve great performance under small training set.","","","10.1109/IGARSS.2016.7729849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729849","Deep learning;Hyperspectral image;Supervised classification","Feature extraction;Hyperspectral imaging;Machine learning;Roads;Training","geophysical image processing;geophysical techniques;image classification","hyperspectral image classification;machine learning tasks;relative distance prior;supervised deep learning algorithm","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Hybrid network-on-chip architectures for accelerating deep learning kernels on heterogeneous manycore platforms","W. Choi; K. Duraisamy; R. G. Kim; J. R. Doppa; P. P. Pande; R. Marculescu; D. Marculescu","School of EECS, Washington State University, Pullman, 99164, U.S.A.","2016 International Conference on Compliers, Architectures, and Sythesis of Embedded Systems (CASES)","20161117","2016","","","1","10","In recent years, designing specialized manycore heterogeneous architectures for deep learning kernels has become an area of great interest. However, the typical on-chip communication infrastructures employed on conventional manycore platforms are unable to handle both CPU and GPU communication requirements efficiently. Hence, in this paper, our aim is to enhance the performance of heterogeneous manycore architectures through the design of a hybrid NoC consisting of both wireline and wireless links. To this end, we specifically target the resource-intensive backpropagation algorithm commonly used as the training method in deep learning. For backpropagation, the proposed hybrid NoC achieves 1.9× reduction in network latency and improves the network throughput by a factor of 2 with respect to a highly optimized mesh NoC. These network level improvements translate into 25% savings in full system energy-delay-product (EDP). This demonstrates the capability of the proposed hybrid and heterogeneous manycore architecture in accelerating deep learning kernels in an energy-efficient manner.","","Electronic:978-1-4503-4482-1; POD:978-1-5090-3589-2","10.1145/2968455.2968510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745276","Backpropagation;Deep learning;Heterogeneous;Manycore;NoC","Backpropagation;Computer architecture;Graphics processing units;Machine learning;Neural networks;System-on-chip;Wireless communication","learning (artificial intelligence);multiprocessing systems;network-on-chip","CPU communication requirements;EDP;GPU communication requirements;backpropagation;deep learning kernel;energy-delay-product;heterogeneous manycore platform;hybrid NoC;hybrid network-on-chip architecture;manycore heterogeneous architecture;network latency;network throughput;on-chip communication infrastructure","","","","","","","2-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Detection of Double Compressed AMR Audio Using Stacked Autoencoder","D. Luo; R. Yang; B. Li; J. Huang","College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Information Forensics and Security","20161121","2017","12","2","432","444","The adaptive multi-rate (AMR) audio codec adopted by many portable recording devices is widely used in speech compression. The use of AMR speech recordings as evidence in court is growing. Nowadays, it is easy to tamper with digital speech recordings, which makes audio forensics increasingly important. The detection of double compressed audio is one of the key issues in audio forensics. In this paper, we propose a framework for detecting double compressed AMR audio based on the stacked autoencoder (SAE) network and the universal background model-Gaussian mixture model (UBM-GMM). Instead of hand-crafted features, we used the SAE to learn the optimal features automatically from the audio waveforms. Audio frames are used as network input and the last hidden layer's output constitutes the features of a single frame. For an audio clip with many frames, the features of all the frames are aggregated and classified by UBM-GMM. Experimental results show that our method is effective in distinguishing single/double compressed AMR audio and outperforms the existing methods by achieving a detection accuracy of 98% on the TIMIT database. Exhaustive experiments demonstrate the effectiveness and robustness of the proposed method.","1556-6013;15566013","","10.1109/TIFS.2016.2622012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7707437","Adaptive multi-mate;audio forensics;double compressed AMR;stacked autoencoder","Codecs;Digital audio players;Feature extraction;Forensics;History;Machine learning;Speech","Gaussian processes;audio coding;codecs;mixture models","adaptive multirate audio codec;audio waveforms;double compressed AMR audio;speech compression;stacked autoencoder;universal background model-Gaussian mixture model","","","","","","20161026","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Deep Convolutional networks with superpixel segmentation for hyperspectral image classification","J. Cao; Z. Chen; B. Wang","Key Laboratory for Information Science of Electromagnetic Waves (MoE), Fudan University, Shanghai 200433, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","3310","3313","To combat the well-known Hughes phenomenon occurred in hyperspectral classification, most of the previous works adopt dimensionality reduction or manifold learning technique before supervised learning. While in this paper, we propose a different scheme: First, we design a pixel-wise classifier based on Convolutional Neural Network that could directly mapping observed spectrum to class distribution. Then, we conduct superpixel segmentation on the prediction map that learned by previous model and output the final classification results by spatial and spectral factors jointly. Varied from other deep learning method, our classification framework learns and infers spectrum efficiently via deep hierarchy with convolutional and pooling layers, thus forming a direct relationship between high-order data and class distribution. Moreover, superpixel segmentation helps further boost the accuracy of the classification by combining the spatial information. In experimental studies, multiple hyperspectral datasets with various context and spatial resolution are used to validate the proposed method. The experimental results show that the proposed method is efficient and competitive in practical uses.","","","10.1109/IGARSS.2016.7729856","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729856","Convolutional Neural Network;Deep Learning;Hyperspectral Image Classification;Superpixel Segmentation;Support Vector Machine","Feature extraction;Hyperspectral imaging;Machine learning;Neural networks;Supervised learning;Support vector machines;Training","convolution;geophysical image processing;hyperspectral imaging;image classification;image segmentation;learning (artificial intelligence);neural nets","Convolutional Neural Network;Hughes phenomenon;deep convolutional networks;hyperspectral image classification;manifold learning technique;superpixel segmentation;supervised learning","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Applications of turing machine as a string reverser for the three input characters — A review","G. S. Vinayagam; P. Ezhilarasu; J. Prakash","Department of Computer Science and Engineering, Hindusthan College of Engineering and Technology, Coimbatore, India","2016 10th International Conference on Intelligent Systems and Control (ISCO)","20161103","2016","","","1","7","Any computation that can be carried out by a mechanical means can be performed by some Turing machine. In this paper we have designed a Turing machine that can reverse any string which is the combination of any three variables. Turing machines founds applications in algorithmic information theory and complexity studies, software testing, high performance computing, machine learning, software engineering, computer networks and evolutionary computations. Hence adding additional feature to reverse a string will improve the efficiency of computations.","","","10.1109/ISCO.2016.7726890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726890","Automata;Reversing the string;Transition Diagram;Transition Table;Turing Machine","Algorithm design and analysis;Barium;Complexity theory;Computer science;Machine learning algorithms;Turing machines","Turing machines","Turing machine;string reverser","","","","","","","7-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Evolving type-2 recurrent fuzzy neural network","M. Pratama; E. Lughofer; M. J. Er; W. Rahayu; T. Dillon","Department of Computer Science and IT, La Trobe University, Melbourne, Australia","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1841","1848","Evolving intelligent system (EIS) is a machine learning algorithm, specifically designed to deal with learning from large data streams. Although the EIS research topic has attracted various contributions over the past decade, the issue of uncertainty, temporal system dynamic, and system order are relatively unexplored by existing studies. A novel EIS, namely evolving type-2 recurrent fuzzy neural network (eT2RFNN) is proposed in this paper. eT2RFNN features a novel recurrent network architecture, possessing double local recurrent connections. It generates a generalized interval type-2 fuzzy rule, where an interval type-2 multivariate Gaussian function constructs the rule premise, and the rule consequent is crafted by the nonlinear wavelet function. eT2RFNN adopts an open structure, where it can start learning process from scratch with an empty rule base. Fuzzy rules can be automatically generated according to degree of nonlinearity data stream conveys. It can performs a rule base simplification procedure by pruning and merging inactive, outdated and overlapping rules. eT2RFNN can deal with the high dimensionality problem, where an online dimensionality reduction method is integrated in the training process. The efficacy of the eT2RFNN has been numerically validated using two real-world data streams, where it provides high predictive accuracy, while retaining low complexity.","","","10.1109/IJCNN.2016.7727423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727423","Evolving Fuzzy Systems;Fuzzy Neural Networks;Sequential Learning;Type-2 Fuzzy Systems","Fuzzy neural networks;Fuzzy sets;Input variables;Machine learning algorithms;Network architecture;Training;Uncertainty","Gaussian processes;fuzzy neural nets;recurrent neural nets","EIS;dimensionality reduction method;double local recurrent connections;eT2RFNN;evolving intelligent system;evolving type-2 recurrent fuzzy neural network;interval type-2 multivariate Gaussian function;machine learning algorithm;nonlinear wavelet function;rule base simplification procedure","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Training deep neural networks on imbalanced data sets","S. Wang; W. Liu; J. Wu; L. Cao; Q. Meng; P. J. Kennedy","Advanced Analytics Institute, University of Technology Sydney, Australia","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","4368","4374","Deep learning has become increasingly popular in both academic and industrial areas in the past years. Various domains including pattern recognition, computer vision, and natural language processing have witnessed the great power of deep networks. However, current studies on deep learning mainly focus on data sets with balanced class labels, while its performance on imbalanced data is not well examined. Imbalanced data sets exist widely in real world and they have been providing great challenges for classification tasks. In this paper, we focus on the problem of classification using deep network on imbalanced data sets. Specifically, a novel loss function called mean false error together with its improved version mean squared false error are proposed for the training of deep networks on imbalanced data sets. The proposed method can effectively capture classification errors from both majority class and minority class equally. Experiments and comparisons demonstrate the superiority of the proposed approach compared with conventional methods in classifying imbalanced data sets on deep neural networks.","","","10.1109/IJCNN.2016.7727770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727770","data imbalance;deep neural network;loss function","Australia;Classification algorithms;Machine learning;Neural networks;Sampling methods;Standards;Training","data handling;learning (artificial intelligence);pattern classification","classification errors;data classification;deep learning;deep neural network training;imbalanced data sets;loss function;mean squared false error","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"On interval-valued possibilistic clustering with a generalized objective function","J. Mezei; P. Sarlin","IAMSR, &#x00C5;bo Akademi University, Turku, Finland","2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20161110","2016","","","824","830","Representing different types of uncertainty present in data is an important problem in developing machine learning algorithms. In this paper we focus on objective function-based fuzzy clustering methods, and propose an interval-valued extension of an approach based on a general objective function. In the model, both membership and possibilistic typicality values are incorporated to overcome various problems of previous clustering approaches. To illustrate the usefulness of the proposals, we perform numerical experiments on eight different fuzzy-possibilistic clustering methods and three data-sets to evaluate the performance in a binary classification problem. We find that the interval-valued extension offers improved performance compared to various approaches from the possibilistic clustering literature.","","Electronic:978-1-5090-0626-7; POD:978-1-5090-0627-4; USB:978-1-5090-0625-0","10.1109/FUZZ-IEEE.2016.7737773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737773","","Clustering algorithms;Clustering methods;Fuzzy sets;Linear programming;Machine learning algorithms;Proposals;Uncertainty","fuzzy set theory;learning (artificial intelligence);pattern classification;pattern clustering;possibility theory","binary classification problem;function-based fuzzy clustering;fuzzy-possibilistic clustering methods;generalized objective function;interval-valued extension;interval-valued possibilistic clustering;machine learning;possibilistic clustering","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Deep Learning of Part-Based Representation of Data Using Sparse Autoencoders With Nonnegativity Constraints","E. Hosseini-Asl; J. M. Zurada; O. Nasraoui","Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA","IEEE Transactions on Neural Networks and Learning Systems","20161116","2016","27","12","2486","2498","We demonstrate a new deep learning autoencoder network, trained by a nonnegativity constraint algorithm (nonnegativity-constrained autoencoder), that learns features that show part-based representation of data. The learning algorithm is based on constraining negative weights. The performance of the algorithm is assessed based on decomposing data into parts and its prediction performance is tested on three standard image data sets and one text data set. The results indicate that the nonnegativity constraint forces the autoencoder to learn features that amount to a part-based representation of data, while improving sparsity and reconstruction quality in comparison with the traditional sparse autoencoder and nonnegative matrix factorization. It is also shown that this newly acquired representation improves the prediction performance of a deep neural network.","2162-237X;2162237X","","10.1109/TNNLS.2015.2479223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310882","Autoencoder;deep architectures;feature learning;nonnegativity constraints;part-based representation","Artificial neural networks;Cost function;Encoding;Feature extraction;Image reconstruction;Machine learning;Training","constraint handling;data handling;data structures;learning (artificial intelligence)","constraining negative weights;data decomposition;data part-based representation;deep learning autoencoder network;deep neural network;image data sets;learning algorithm;nonnegative matrix factorization;nonnegativity constraint algorithm;nonnegativity constraints;nonnegativity-constrained autoencoder;reconstruction quality;sparse autoencoders;text data set","","5","","","","20151028","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"Efficient Distributed Density Peaks for Clustering Large Data Sets in MapReduce","Y. Zhang; S. Chen; G. Yu","School of Computer Science and Engineering, Northeastern University, Shenyang, China","IEEE Transactions on Knowledge and Data Engineering","20161104","2016","28","12","3218","3230","Density Peaks (DP) is a recently proposed clustering algorithm that has distinctive advantages over existing clustering algorithms. It has already been used in a wide range of applications. However, DP requires computing the distance between every pair of input points, therefore incurring quadratic computation overhead, which is prohibitive for large data sets. In this paper, we study efficient distributed algorithms for DP. We first show that a naive MapReduce solution (Basic-DDP) has high communication and computation overhead. Then, we propose LSH-DDP, an approximate algorithm that exploits Locality Sensitive Hashing for partitioning data, performs local computation, and aggregates local results to approximate the final results. We address several challenges in employing LSH for DP. We leverage the characteristics of DP to deal with the fact that some of the result values cannot be directly approximated in local partitions. We present formal analysis of LSH-DDP, and show that the approximation quality and the runtime can be controlled by tuning the parameters of LSH-DDP. Experimental results on both a local cluster and EC2 show that LSH-DDP achieves a factor of 1.7-70x speedup over the naive Basic-DDP and 2x speedup over the state-of-the-art EDDPC approach, while returning comparable cluster results. Compared to the popular K-means clustering, LSH-DDP also has comparable or better performance. Furthermore, LSH-DDP could achieve even higher efficiency with a lower accuracy requirement.","1041-4347;10414347","","10.1109/TKDE.2016.2609423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7567531","Density peaks;MapReduce;distributed clustering","Algorithm design and analysis;Approximation algorithms;Clustering algorithms;Density measurement;Machine learning algorithms;Partitioning algorithms","distributed algorithms;pattern clustering","DP;EC2;EDDPC approach;LSH-DDP;MapReduce solution;approximate algorithm;approximation quality;basic-DDP;data partitioning;distributed algorithms;distributed density peaks;formal analysis;k-means clustering;large data set clustering;local cluster;local computation;local partitions;locality sensitive hashing;quadratic computation overhead","","","","","","20160914","Dec. 1 2016","","IEEE","IEEE Journals & Magazines"
"Big-data-generated traffic flow prediction using deep learning and dempster-shafer theory","R. Soua; A. Koesdwiady; F. Karray","Centre for Pattern Analysis and Machine Intelligence (CPAMI), Department of Electrical and Computer Engineering, University of Waterloo, ON, N2L 3G1, Canada","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3195","3202","This work addresses short-term traffic flow prediction by proposing a big-data-based framework. The proposed framework uses data fusion to deal with heterogeneous data generated from various sources. The data are categorized into two types: streams of data and event-based data. In this work, Deep Belief Networks (DBNs) are used to independently predict traffic flow using streams of data, i.e., historical traffic flow and weather data, and event-based data, i.e., tweets. Furthermore, Dempster's conditional rule for updating belief is used to fuse evidence coming from streams of data and event-based data modules to achieve enhanced prediction. The experimental results using real-world data show the merit of the proposed framework compared to the state-of-the-art ones.","","","10.1109/IJCNN.2016.7727607","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727607","","Machine learning;Mathematical model;Meteorology;Neural networks;Roads;Social network services","Big Data;belief networks;inference mechanisms;sensor fusion;traffic engineering computing;uncertain systems","DBNs;Dempster conditional rule;Dempster-Shafer theory;big-data-generated traffic flow prediction;data fusion;data streams;deep belief networks;deep learning;event-based data;evidence fusion;heterogeneous data;short-term traffic flow prediction","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Optimization of artificial operon construction by consultation algorithms utilizing LCS","C. Han; K. Tsuge; H. Iba","Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo, Tokyo, Japan","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","4273","4280","How can we boost Escherichia coli (E. coli) growth (i.e., production) without modifying genes themselves? This remains a challenging and fruitful goal that would facilitate the mass production of biofuels, biomedicine, and engineered genomes in synthetic biology. In this paper, we focus on rear-ranging gene order within an operon to optimize gene expression. Optimizing more than five genes remains laborious without predictive modeling as the number of gene orders increases factorially - a five-gene operon possesses 120 gene orders, but a ten-gene operon possesses 3,628,800 gene orders. To handle a ten-gene operon, we propose consultation algorithms utilizing LCS to analyze the relationship between gene order and growth rate, and then verify predicted gene orders with high growth rates using wet-lab experiments. “Consultation” refers to optimizing gene orders in different machine learning algorithms and choosing gene orders with high growth rates in each algorithm to avoid over-fitting. We address the following research questions: (RQ1) How can we predict E. coli growth according to gene orders? (RQ2) Can definite rules easily understood by biologists be extracted? (RQ3) Can new E. coli strains surpass the highest growth rate of the dataset? Our first computational approach shows that consultation algorithms utilizing LCS can identify gene orders that significantly control E. coli growth and create novel E. coli strains with high growth rates using these operon construction rules.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7744333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744333","","Bioinformatics;Computational modeling;Gene expression;Genomics;Machine learning algorithms;Synthetic biology","biology computing;learning (artificial intelligence);optimisation;pattern classification","E. coli growth;Escherichia coli growth;LCS;artificial operon construction optimization;biofuels;biomedicine;consultation algorithms;engineered genomes;gene expression optimization;growth rate;learning classifier systems;machine learning algorithms;rear-ranging gene order;synthetic biology;ten-gene operon;wet-lab experiments","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Deep learning for analysing synchrotron data streams","B. Wang; Z. Guan; S. Yao; H. Qin; M. H. Nguyen; K. Yager; D. Yu","Department of Computer Science, Department of Biochemistry and Structure Biology, Stony Brook University, Stony Brook, U.S.A.","2016 New York Scientific Data Summit (NYSDS)","20161121","2016","","","1","5","The National Synchrotron Light Source II (NSLS-II) at Brookhaven National Laboratory (BNL) is now providing some of the world's brightest x-ray beams. A suite of imaging and diffraction methods, exploiting megapixel detectors with kilohertz frame-rates at NSLS-II beamlines, generate a variety of image streams in unprecedented velocities and volumes. A complete understanding of a complex material system often requires a cluster of x-ray characterization tools that can reveal its elemental, structural, chemical and physical properties at different length-scales and time-scales. The flourish and continuing refinement of x-ray probes enable that the same sample may be studied with different perspectives and granularities, and at different time and locations; these powerful tools generate a correspondingly daunting big data challenge, with multiple image streams that outpaces any manual efforts and traditional data analysis practice. In this paper, we applied deep learning methods, in particular, deep convolutional neural network (CNN) to automatically recognize image features from image streams from NSLS-II, and integrated our deep-learning methods into the Google Tensorflow to cluster and label both real and synthetic 2-D scattering image patterns. These methods would empower scientists by providing timely insights, allowing them to steer experiments efficiently during their precious x-ray beamtime allocation. Experiment shows that the CNN-based image labeling attains a 10% improvement over traditional K-mean and Support Vector Machine.","","Electronic:978-1-4673-9051-4; POD:978-1-4673-9052-1","10.1109/NYSDS.2016.7747813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7747813","CNN;Deep learning;X Ray Image Classification","Feature extraction;Machine learning;Neural networks;Scattering;Streaming media;X-ray imaging;X-ray scattering","X-ray imaging;image recognition;neural nets;pattern clustering;physics computing;synchrotrons","CNN-based image labeling;Google Tensorflow;K-means method;NSLS-II;National Synchrotron Light Source II;convolutional neural network;deep learning methods;image clustering;image feature recognition;image streams;support vector machine;synchrotron data stream analysis;synthetic 2-D scattering image patterns;x-ray beamtime allocation","","","","","","","14-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Generalized correntropy induced loss function for deep learning","L. Chen; H. Qu; J. Zhao","The School of Electronic and Information Engineering, Xi'an Jiaotong University, 710049, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1428","1433","Through multiple levels of abstraction, deep learning takes advantage of multiple layers models to find the complicated structure and learn the high level representations of data. In recent years, deep learning has made great progress in object detection, speech recognition, and many other domains. The robustness of learning systems with deep architectures is however rarely studied and needs further investigation. Especially, the mean square error(MSE), which is commonly used as optimization cost function in deep learning, is sensitive to outliers(or impulsive noises). To combat the harmful influences caused by outliers which are pervasive in many real world data, it is indispensable to improve the robustness in deep learning. In this paper, a robust deep learning method based on generalized correntropy is proposed and named generaliezed correntropy induced loss function(GC-loss) based SAE(GC-SAE). Generalized correntropy as a nonlinear measure of similarity is robust to outliers and can approximate different norms(from l<sub>0</sub> to l<sub>2</sub>) of data. By using generalized Gaussian density(GGD) function as its kernel, generalized correntropy achieves a more flexible shape and shows a better robustness for non-Gaussian noise when compared with the original correntropy with Gaussian kernel. The good robustness of the proposed method is confirmed by the experiments on MNIST benchmark dataset.","","","10.1109/IJCNN.2016.7727366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727366","","Bandwidth;Cost function;Kernel;Machine learning;Measurement;Neural networks;Robustness","Gaussian processes;entropy;learning (artificial intelligence);mean square error methods;optimisation","GC-SAE;GC-loss based SAE;GGD function;Gaussian kernel;MNIST benchmark dataset;MSE;data high level representation learning;generalized Gaussian density function;generalized correntropy induced loss function;mean square error;optimization cost function;robust deep learning method;similarity nonlinear measure","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Overcoming the Static Learning Bottleneck - the need for adaptive neural learning","C. M. Vineyard; S. J. Verzi","Sandia National Laboratories, Albuquerque, New Mexico 87185-1327, United States of America","2016 IEEE International Conference on Rebooting Computing (ICRC)","20161110","2016","","","1","3","Amidst the rising impact of machine learning and the popularity of deep neural networks, learning theory is not a solved problem. With the emergence of neuromorphic computing as a means of addressing the von Neumann bottleneck, it is not simply a matter of employing existing algorithms on new hardware technology, but rather richer theory is needed to guide advances. In particular, there is a need for a richer understanding of the role of adaptivity in neural learning to provide a foundation upon which architectures and devices may be built. Modern machine learning algorithms lack adaptive learning, in that they are dominated by a costly training phase after which they no longer learn. The brain on the other hand is continuously learning and provides a basis for which new mathematical theories may be developed to greatly enrich the computational capabilities of learning systems. Game theory provides one alternative mathematical perspective analyzing strategic interactions and as such is well suited to learning theory.","","Electronic:978-1-5090-1370-8; POD:978-1-5090-1371-5","10.1109/ICRC.2016.7738692","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738692","","Game theory;Games;Heuristic algorithms;Machine learning algorithms;Optimization;Support vector machines;Training","game theory;learning (artificial intelligence);neural nets","adaptive neural learning;deep neural networks;game theory;learning theory;machine learning algorithm;neuromorphic computing;static learning;von Neumann bottleneck","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Clustering of receptive fields in Autoencoders","B. O. Ayinde; J. M. Zurada","Electrical and Computer Engineering, University of Louisville, KY 40218, Kentucky","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1310","1317","In this paper, we demonstrate new techniques for data representation in the context of deep learning using agglomerative clustering. The results from previous work show that a good number of encoding and decoding filters of layered autoencoders are duplicative thereby enforcing two or more processing filters to extract the same features due to filtering redundancy. We propose a new way to circumvent this problem and our results show that such redundancy is eliminated, yields smaller networks and filters are able to extract distinct features. The concept is illustrated with Sparse Autoenconders (SAE) using MNIST and NORB datasets.","","","10.1109/IJCNN.2016.7727349","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727349","Agglomerative clustering;Autoencoder;Deep learning;Filter clustering;Receptive field","Clustering algorithms;Computer architecture;Encoding;Feature extraction;Machine learning;Redundancy;Training","data structures;learning (artificial intelligence);pattern clustering","MNIST datasets;NORB datasets;SAE;agglomerative clustering;autoencoders;data representation;decoding filters;deep learning;encoding filters;receptive fields;sparse autoenconders","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Distributed boosting for cloud detection","M. Le Goff; J. Y. Tourneret; H. Wendt; M. Ortner; M. Spigai","IRIT/ENSEEIHT/T&#x00E9;SA, University of Toulouse, France","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","2626","2629","The SPOT 6-7 satellite ground segment includes a systematic and automatic cloud detection step in order to feed a catalogue with a binary cloud mask and an appropriate confidence measure. In order to significantly improve the SPOT cloud detection and get rid of frequent manual re-labelings, we study a new automatic cloud detection technique that is adapted to large datasets. The proposed method is based on a modified distributed boosting algorithm. Experiments conducted using the framework Apache Spark on a SPOT 6 image database with various landscapes and cloud coverage show promising results.","","","10.1109/IGARSS.2016.7729678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729678","Cloud detection;big data;boosting;distributed processing;remote sensing","Boosting;Clouds;Distributed databases;Image resolution;Machine learning algorithms;Satellites;Training","clouds;geophysical image processing;remote sensing","Apache Spark;SPOT 6 image database;SPOT 6-7 satellite;SPOT cloud detection;binary cloud mask;cloud coverage;distributed boosting algorithm","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"FAST-MDL: Fast Adaptive Supervised Training of multi-layered deep learning models for consistent object tracking and classification","N. Doulamis; A. Voulodimos","National Technical University of Athens, 15773, Greece","2016 IEEE International Conference on Imaging Systems and Techniques (IST)","20161110","2016","","","318","323","In this paper, we propose a Fast Adaptive Supervised Training Algorithm, called FAST-MDL, for dynamically updating the parameters of a multi-layered deep learning structure in order to fit the current environmental conditions. The method provides promising results in consistent long term object labeling and detection under abruptly changing visual conditions, severe illumination changes and occlusions (either full or partial). The retraining algorithm trusts as much as possible the current conditions (discriminative constraints), while simultaneously providing a minimal modification of the already obtained knowledge of the network (generative constraints). Experimental results in real-life video sequences demonstrate the efficiency of the proposed method compared to existing techniques.","","Electronic:978-1-5090-1817-8; POD:978-1-5090-1818-5","10.1109/IST.2016.7738244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738244","Deep learning;object labeling;tracking","Adaptation models;Approximation algorithms;Classification algorithms;Data models;Machine learning;Supervised learning;Training","image classification;image sequences;learning (artificial intelligence);object tracking;video signal processing","FAST-MDL algorithm;discriminative constraints;fast adaptive supervised training;generative constraints;illumination change;multilayered deep learning models;object classification;object labeling;object tracking;occlusions;video sequences","","","","","","","4-6 Oct. 2016","","IEEE","IEEE Conference Publications"
"A general purpose intelligent surveillance system for mobile devices using Deep Learning","A. Antoniou; P. Angelov","School of Computing and Communications, Lancaster University, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2879","2886","In this paper the design, implementation, and evaluation of a general purpose smartphone based intelligent surveillance system is presented. It has two main elements; i) a detection module, and ii) a classification module. The detection module is based on the recently introduced approach that combines the well-known background subtraction method with the optical flow and recursively estimated density. The classification module is based on a neural network using Deep Learning methodology. Firstly, the architecture design of the convolutional neural network is presented and analyzed in the context of the four selected architectures (two of them recent successful types) and two custom modifications specifically made for the problem at hand. The results are carefully evaluated, and the best one is selected to be used within the proposed system. In addition, the system is implemented on both a PC (using Linux type OS) and on a smartphone (using Android). In addition to the compatibility with all modern Android-based devices, most GPU-powered platforms such as Raspberry Pi, Nvidia Tegra X1 and Jetson run on Linux. The proposed system can easily be installed on any such device benefiting from the advantage of parallelisation for faster execution. The proposed system achieved a performance which surpasses that of a human (classification accuracy of the top 1 class >95.9% for automatic recognition of a detected object into one of the seven selected categories. For the top-2 classes, the accuracy is even higher (99.85%). That means, at least, one of the two top classes suggested by the system is correct. Finally, a number of visual examples are showcased of the system in use in both PC and Android devices.","","","10.1109/IJCNN.2016.7727563","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727563","","Computer architecture;Feature extraction;Image motion analysis;Machine learning;Neural networks;Optical imaging;Surveillance","Android (operating system);convolution;image classification;image sequences;learning (artificial intelligence);mobile commerce;neural nets;object detection;smart phones;surveillance","Android;GPU-powered platforms;Jetson;Linux type OS;Nvidia Tegra X1;PC;Raspberry Pi;architecture design;background subtraction method;classification module;convolutional neural network;deep learning;detection module;general purpose intelligent surveillance system;general purpose smartphone;mobile devices;object detection;optical flow","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Deep self-organizing reservoir computing model for visual object recognition","Zhidong Deng; Chengzhi Mao; Xiong Chen","State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Department of Computer Science, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1325","1332","Reservoir computing becomes increasingly a hot spot in recent years. In this paper, we propose a deep self-organizing reservoir computing model for visual object recognition. First, through combination of Kohonen's self-organizing map and SHESN network, we present a self-organizing SHESN (SO-SHESN). In the new model, we adopt the same mechanism of generating reservoir as SHESN, but McCulloch-Pitts type reservoir neuron is replaced with radial basis function neuron. Correspondingly, unsupervised competitive learning is exploited to train both input weights and reservoir weights of SO-SHESN. Second, we propose a deep SO-SHESN model through a stack of well-trained reservoir layers. In such a stacked structure, a novel trial-and-readout learning algorithm is used for pre-training of layer-wise reservoir, in which each layer is trained independently from each other. Finally, the experimental results obtained on MNIST benchmark dataset show that our SO-SHESN achieves the test recognition error rate of 5.66%, which improves classical ESN and SHESN by 6.44% and 1.74%, respectively. Furthermore, the test error rate of our deep SO-SHESN could reach up to 1.39%, which outperforms SO-SHESN with single reservoir layer by 4.27% and approximately approaches the state-of-the-art result of 1% among existing traditional machine learning approaches with non-CNN features.","","","10.1109/IJCNN.2016.7727351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727351","deep learning;recurrent neural network;reservoir computing;ridge regression;self-organizing feature map","Biological neural networks;Computational modeling;Machine learning;Neurons;Reservoirs;Visualization","neural nets;object recognition;unsupervised learning","Kohonen self-organizing map;MNIST benchmark dataset;McCulloch-Pitts type reservoir neuron;SHESN network;deep SO-SHESN model;deep self-organizing reservoir computing model;layer-wise reservoir pretraining;machine learning approaches;nonCNN features;radial basis function neuron;self-organizing SHESN;trial-and-readout learning algorithm;unsupervised competitive learning;visual object recognition;weights training;well-trained reservoir layers","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
