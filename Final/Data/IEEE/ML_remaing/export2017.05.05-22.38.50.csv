"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7332513,7332502,7334095,7334292,7330451,7272105,7325900,7323027,7328189,7326150,7326432,7325773,7326782,7307121,7321439,7321420,7321454,7321463,7321440,7319209,7318462,7320414,7318482,7319008,7317959,7272047,7152946,7314704,7265055,7307573,7307823,7301554,7243357,7244241,7254179,7300975,7258382,7293666,7244231,7301269,7300325,7299406,7299084,7298629,7298854,7298862,7298968,7298731,7299143,7299024,7299067,7298717,7299016,7298712,7298880,7296215,7296368,7292925,6981951,7288043,7288226,7287985,7285297,7284164,7279298,7284547,7284964,7281139,7284873,7284440,7284785,7275914,7275822,7275709,7275858,7272910,7273701,7272932,7273627,7273702,7234886,7271555,7271508,7271619,7265332,7145470,7263620,7260552,7257043,7259513,7260555,7250227,7091007,7251437,7248453,7238525,7243232,7237129,7232886,7232789",2017/05/05 22:38:50
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Children story classification based on structure of the story","Harikrishna D M; K. S. Rao","School of Information Technology, Indian Institute of Technology, Kharagpur, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","1485","1490","The main objective of this work is to classify Hindi and Telugu stories based on their structure into three genres: Fable, Folk-tale and Legend. In this work, each story is divided into three parts: (i) introduction, (ii) main and (iii) climax. The objective of this work is to explore how story genre information is embedded in different parts of the story. We are proposing a framework for story classification using keyword and Part-of-speech (POS) based features. Keyword based features like Term Frequency (TF) and Term Frequency Inverse Document Frequency (TFIDF) are used. Classification performance is analyzed for different story parts using various combinations of features with three classifiers: (i) Naive Bayes (NB), (ii) k-Nearest Neighbour (KNN) and (iii) Support Vector Machine (SVM). From the experimental studies, it has been observed that classification performance has not significantly improved by combining linguistic (POS) and keyword based features. Among classifiers, SVM outperformed the other classifiers. The main part of the story has the highest classification accuracy compared to introduction and climax parts of the story.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275822","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275822","Climax;Introduction;KNN;Main;Naive Bayes;Part-of-Speech;SVM;Story Classification;Structure of Story;Text-to-Speech;Vector Space Model","Accuracy;Handheld computers;Informatics;Machine learning algorithms;Niobium;Support vector machines;Text categorization","Bayes methods;document handling;linguistics;natural language processing;pattern classification;speech synthesis;support vector machines","Hindi story classification;KNN classifier;NB classifier;POS based feature;SVM classifier;TFIDF;Telugu story classification;children story classification;classification performance;classify;fable;folk-tale;k-nearest neighbour classifier;keyword based features;legend;linguistic;naive Bayes classifier;part-of-speech;story genre information;story speech synthesis system;story structure;support vector machine classifier;term frequency inverse document frequency","","1","","17","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Automatic summarization of Polish news articles by sentence selection","K. Jassem; ≈Å. Pawluczuk","Adam Mickiewicz University in Pozna&#x0144; ul.Wieniawskiego 1, 61-712, Poland","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","337","341","This paper describes the automatic summarization system developed for the Polish language. The system implements sentence-based extractive summarization technique, which consists in determining most important sentences in document due to their computed salience. A structure of the system is presented, as well as the evaluation method and achieved results. The presented attempt is intended to serve as the baseline for future solutions, as it is the first summarization project evaluated against the Polish Summaries Corpus, the standardized corpus of summaries for the Polish language.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321463","","Computer science;Feature extraction;Machine learning algorithms;Pragmatics;Syntactics;Text analysis;Training","text analysis","Polish language;Polish news articles;Polish summaries corpus;automatic text summarization;evaluation method;extractive summarization technique;sentence selection","","","","12","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"An improved cluster analysis algorithm using for network traffic flow","S. Yong; S. Zhen-Chao; Z. Ran; Z. Geng; L. Shi-Dong","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","2015 10th International Conference on Computer Science & Education (ICCSE)","20150910","2015","","","111","115","With the rapid development of computer network and the network application, network has plays an increasingly important role in the social progress and economic development. Rapid development of information technology makes the network traffic behavior has become increasingly complex, and the reliability of the network becomes crucial. Cluster algorithm using for network traffic flow is an entry to analysis network status. Support Vector Machine (SVM) is a machine learning method to solve binary classification problem. An improved cluster analysis algorithm of combining SVM with supervised subset density clustering is proposed in this paper, and minimize the training set of SVM by means of clustering is researched. A supervised self-adaptive method for the improved density clustering is designed to make out multiple centers choosing and referring the samples to SVM. The experimental results show that the algorithm reduces the iteration time of the whole training process without compromising the accuracy and generalization capacity of the algorithm obviously.","","Electronic:978-1-4799-6600-4; POD:978-1-4799-6601-1; USB:978-1-4799-6599-1","10.1109/ICCSE.2015.7250227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7250227","SVM;cluster analysis;network traffic flow;self-adaptive center choosing;supervised subset density clustering","Accuracy;Algorithm design and analysis;Classification algorithms;Clustering algorithms;Machine learning algorithms;Support vector machines;Training","computer network reliability;iterative methods;learning (artificial intelligence);pattern classification;pattern clustering;support vector machines;telecommunication computing;telecommunication traffic","SVM;binary classification problem;cluster algorithm;computer network;economic development;improved cluster analysis algorithm;improved density clustering;information technology;iteration time;machine learning method;network application;network status analysis;network traffic behavior;network traffic flow;social progress;supervised self-adaptive method;supervised subset density clustering;support vector machine","","0","","11","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"A CGRA-Based Approach for Accelerating Convolutional Neural Networks","M. Tanomoto; S. Takamaeda-Yamazaki; J. Yao; Y. Nakashima","Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan","2015 IEEE 9th International Symposium on Embedded Multicore/Many-core Systems-on-Chip","20151112","2015","","","73","80","Convolutional neural network (CNN) is an emerging approach for achieving high recognition accuracy in various machine learning applications. To accelerate CNN computations, various GPU-based or application-specific hardware approaches have been recently proposed. However, since they require large computing hardware and absolute energy amount, they are not suitable for embedded applications. In this paper, we propose a novel approach to accelerate CNN computations using a CGRA (Coarse Grained Reconfigurable Architecture) for low-power embedded systems. We first present a new CGRA with distributed scratchpad memory blocks for efficient temporal blocking to reduce memory bandwidth pressure. We then show the architecture of our CNN accelerator using the CGRA with some dedicated software implementation. We evaluated our approach by comparing some existing platforms, such as high-end and mobile GPUs, and general multicore CPUs. The evaluation result shows that our proposal achieves 1.93x higher performance per memory bandwidth and 2.92x higher area performance, respectively.","","Electronic:978-1-4799-8670-5; POD:978-1-4799-8671-2","10.1109/MCSoC.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328189","Accelerator Architecture;CGRA;Convolutional Neural Networks","Acceleration;Arrays;Bandwidth;Convolution;Hardware;Machine learning;Neural networks","distributed memory systems;embedded systems;graphics processing units;learning (artificial intelligence);multiprocessing systems;neural nets;performance evaluation;reconfigurable architectures","CGRA-based approach;CNN accelerator;GPU-based hardware approach;application-specific hardware approach;coarse grained reconfigurable architecture;convolutional neural network;distributed scratchpad memory block;low-power embedded system;machine learning application;memory bandwidth pressure;multicore CPU","","1","","25","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Multimedia data mining using deep learning","P. Wlodarczak; J. Soar; M. Ally","Faculty of Business, Education, Law and Arts, University of Southern Queensland, Toowoomba, Australia","2015 Fifth International Conference on Digital Information Processing and Communications (ICDIPC)","20151112","2015","","","190","196","Due to the large amounts of Multimedia data on the Internet, Multimedia mining has become a very active area of research. Multimedia mining is a form of data mining. Data mining uses algorithms to segment data to identify useful patterns and to make predictions. Despite the successes in many areas, data mining remains a challenging task. In the past, multimedia mining was one of the fields where the results were often not satisfactory. Multimedia Data Mining extracts relevant data from multimedia files such as audio, video and still images to perform similarity searches, identify associations, entity resolution and for classification. As the mining techniques have matured, new techniques were developed. A lot of progress has been made in areas such as visual data mining and natural language processing using deep learning techniques. Deep learning is a branch of machine learning and has been used among other on Smartphones for face recognition and voice commands. Deep learners are a type of artificial neural networks with multiple data processing layers that learn representations by increasing the level of abstraction from one layer to the next. These methods have improved the state-of-the-art in multimedia mining, in speech recognition, visual object recognition, natural language processing and other areas such as genome mining and predicting the efficacy of drug molecules. This paper describes some of the deep learning techniques that have been used in recent research for multimedia data mining.","","CD-ROM:978-1-4673-6831-5; Electronic:978-1-4673-6832-2; POD:978-1-4673-6833-9","10.1109/ICDIPC.2015.7323027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7323027","artificial neural networks;data mining;deep learning;multimedia data mining;natural language processing;visual data mining","Backpropagation;Data mining;Feature extraction;Machine learning;Multimedia communication;Training;Visualization","Internet;data mining;information retrieval;learning (artificial intelligence);multimedia computing;neural nets;pattern classification","Internet;artificial neural networks;association identification;audio files;classification;data segmentation;deep learning;entity resolution;machine learning;multimedia data mining;multimedia files;multiple data processing layers;relevant data extraction;similarity search;still images;useful pattern identification;video files","","2","","29","","","7-9 Oct. 2015","","IEEE","IEEE Conference Publications"
"Haar wavelet transform and principal component analysis for fetal QRS classification from abdominal maternal ECG recordings","J. A. Delgado; M. Altuve; M. N. Homsi","Applied Biophysics and Bioengineering Group, Simon Bolivar University, Caracas, Venezuela","2015 20th Symposium on Signal Processing, Images and Computer Vision (STSIVA)","20151119","2015","","","1","6","Fetal heart rate monitoring plays an essential role in helping to decrease the perinatal mortality rate associated with abnormalities in the cardiovascular system of the fetus. In this sense, a new approach to detect fetal QRS (fQRS) complexes from abdominal maternal ECG signals is proposed in this paper. First, signals were segmented into contiguous frames of 250 ms duration and then labeled in four classes. Principal component analysis was applied on Haar-Wavelet transform for dimensionality reduction and feature extraction, and interquartile ranges and sampling without replacement were employed to deal with outliers and imbalanced class problems, respectively. K-nearest neighborhood (KNN), support vector machine (SVM) and Bayesian network (BN) were trained and tested on the ECG signals of four electrodes of the PhysioNet/CinC challenge 2013 dataset, using 10-fold stratified cross-validation. Results show that KNN and SVM got better average accuracies over BN, that reach to 89.59% and 89.19%, respectively. Although KNN yielded better results, SVM was less time-consuming in prediction. In addition, the fourth electrode signals are less noisy and contain more representative data that helps SVM reaches an accuracy about 80% for fQRS estimation.","","Electronic:978-1-4673-9461-1; POD:978-1-4673-9462-8; USB:978-1-4673-9460-4","10.1109/STSIVA.2015.7330451","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7330451","","Electrocardiography;Electrodes;Estimation;Machine learning algorithms;Principal component analysis;Support vector machines;Transforms","Haar transforms;belief networks;cardiovascular system;electrocardiography;medical signal processing;obstetrics;principal component analysis;signal classification;support vector machines;wavelet transforms","10-fold stratified cross-validation;Bayesian network;ECG signals;Haar wavelet transform;K-nearest neighborhood;KNN;SVM;abdominal maternal ECG recordings;abdominal maternal ECG signals;cardiovascular system;electrode signals;fQRS estimation;feature extraction;fetal QRS classification;fetal QRS complexes;fetal heart rate monitoring;fetus;imbalanced class problems;noisy;physioNet-CinC challenge 2013 dataset;principal component analysis;signal segmentation;support vector machine","","","","15","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"Simultaneous human-robot adaptation for effective skill transfer","M. A. Zamani; E. Oztop","Computer Science Department, Ozyegin University, Istanbul, Turkey","2015 International Conference on Advanced Robotics (ICAR)","20150910","2015","","","78","84","In this paper, we propose and implement a human-in-the loop robot skill synthesis framework that involves simultaneous adaptation of the human and the robot. In this framework, the human demonstrator learns to control the robot in real-time to make it perform a given task. At the same time, the robot learns from the human guided control creating a non-trivial coupled dynamical system. The research question we address is how this system can be tuned to facilitate faster skill transfer or improve the performance level of the transferred skill. In the current paper we report our initial work for the latter. At the beginning of the skill transfer session, the human demonstrator controls the robot exclusively as in teleoperation. As the task performance improves the robot takes increasingly more share in control, eventually reaching full autonomy. The proposed framework is implemented and shown to work on a physical cart-pole setup. To assess whether simultaneous learning has advantage over the standard sequential learning (where the robot learns from the human observation but does not interfere with the control) experiments with two groups of subjects were performed. The results indicate that the final autonomous controller obtained via simultaneous learning has a higher performance measured as the average deviation from the upright posture of the pole.","","Electronic:978-1-4673-7509-2; POD:978-1-4673-7510-8","10.1109/ICAR.2015.7251437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7251437","Human-Robot Interaction;Human-in-the-loop;Skill Transfer","Education;Machine learning algorithms;Real-time systems;Robot control;Service robots;Standards","human-robot interaction;intelligent robots;telerobotics","autonomous controller;human guided control;human-in-the loop robot skill synthesis framework;nontrivial coupled dynamical system;performance level improvement;physical cart-pole system;robot control;robot learning;simultaneous human-robot adaptation;simultaneous learning;skill transfer;teleoperation","","1","","30","","","27-31 July 2015","","IEEE","IEEE Conference Publications"
"Efficiency analysis of kernel functions in uncertainty based c-means algorithms","D. Mittal; B. K. Tripathy","School of Computing Science and Engineering, VIT University, Vellore, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","807","813","Application of clustering algorithms for investigating real life data has concerned many researchers and vague approaches or their hybridization with other analogous approaches has gained special attention due to their great effectiveness. Recently, rough intuitionistic fuzzy c-means algorithm has been proposed by Tripathy et al [3] and they established its supremacy over all other algorithms contained in the same set. Replacing the Euclidean distance metric with kernel induced metric makes it possible to cluster the objects which are linearly inseparable in the original space. In this paper a comparative analysis is performed over the Gaussian, hyper tangent and radial basis kernel functions by their application on various vague clustering approaches like rough c-means (RCM), intuitionistic fuzzy c-means (IFCM), rough fuzzy c-means (RFCM) and rough intuitionistic fuzzy c-means (RIFCM). All clustering algorithms have been tested on synthetic, user knowledge modeling and human activity recognition datasets taken from UCI repository against the standard accuracy indexes for clustering. The results reveal that for small sized datasets Gaussian kernel produces more accurate clustering than radial basis and hyper tangent kernel functions however for the datasets which are considerably large hyper tangent kernel is superior to other kernel functions. All experiments have been carried out using C language and python libraries have been used for statistical plotting.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275709","D index;DB index;clustering;fuzzy sets;gaussian kernel;hypertangent kernel;intuitionistic fuzzy sets;radial basis kernel;rough fuzzy sets;rough sets","Algorithm design and analysis;Approximation algorithms;Clustering algorithms;Euclidean distance;Indexes;Kernel;Machine learning algorithms","Gaussian processes;fuzzy set theory;pattern clustering;rough set theory","C language;Euclidean distance metric;Gaussian function;Gaussian kernel;Python libraries;RCM;RFCM;RIFCM;human activity recognition datasets;hyper tangent function;kernel functions;kernel induced metric;object clustering;radial basis kernel function;rough c-means;rough fuzzy c-means;rough intuitionistic fuzzy c-means algorithm;statistical plotting;uncertainty based c-means algorithms;user knowledge modeling;vague clustering approaches","","1","","24","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"An error-sensitive Q-learning approach for robot navigation","R. Tang; H. Yuan","College of Electronics and Information, Tongji University, Shanghai 201804, China","2015 34th Chinese Control Conference (CCC)","20150914","2015","","","5835","5840","Reinforcement learning can capture notions of optimal behavior occurring in natural systems. In the context of reinforcement learning, the learning rate controls how fast we modify our estimates. Generally Q-learning approach leverages the temporal-difference (TD) error to regulate Q-value, while utilizing a constant or decreasing learning rate, e.g., linear or polynomial learning rate, throughout the agent's life. Learning algorithm with polynomial learning rate learns faster at the cost of inferior trade-off between exploration and exploitation. None of them is evaluated based on the TD error. Whereas that cannot psychologically reflect the agent's true learning progress with unnecessary extra training episodes and exploration. This paper proposes an error-sensitive learning rate mechanism for Q-learning algorithm termed as (ESQL) to achieve better mitigation and faster learning. The agent is endowed sensibility to the TD error summed over the episodes. The derived method is implemented with indoor robot navigation task simulation in a stationary grid world environment. Experimental results are presented showing that ESQL approach achieves faster learning and latent better trade-off between exploration and exploitation compared with both constant and decreasing learning rate Q-learning approaches.","","Electronic:978-9-8815-6389-7; POD:978-1-4673-7443-9","10.1109/ChiCC.2015.7260552","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7260552","Error-sensitive;Learning rate;Q-learning;Reinforcement learning;Robot navigation;TD error","Heuristic algorithms;Learning (artificial intelligence);Machine learning algorithms;Navigation;Polynomials;Robots;Training","indoor navigation;learning systems;mobile robots;path planning","ESQL;TD error;error-sensitive Q-learning approach;indoor robot navigation task simulation;linear learning;polynomial learning;reinforcement learning;stationary grid world environment;temporal-difference error","","","","17","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Study and research of APT detection technology based on big data processing architecture","L. Shenwen; L. Yingbo; D. Xiongjie","National Computer Network Emergency, Response Technical Team/Coordination, Center of China, Beijing, China","2015 IEEE 5th International Conference on Electronics Information and Emergency Communication","20151001","2015","","","313","316","This paper researches and designs a APT detection system based on big data processing architecture, which includes data capturing, big data processing, APT Analyzing and application layer. The system can detect both known and unknown APT attacks with high performance, and provide alert and forensics function to APT.","","CD-ROM:978-1-4799-7282-1; Electronic:978-1-4799-7284-5; POD:978-1-4799-7285-2","10.1109/ICEIEC.2015.7284547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284547","APT;Big data;Hadoop;Information security","Big data;Computer architecture;Engines;Information security;Machine learning algorithms;Trojan horses","Big Data;security of data","APT detection technology;big data processing architecture;forensics function","","","","7","","","14-16 May 2015","","IEEE","IEEE Conference Publications"
"An optimized initialization center K-means clustering algorithm based on density","Q. Yuan; H. Shi; X. Zhou","University of Chinese Academy of Sciences, Wuxi CAS Ubiquitous Technology R&D Center CO. LTD., Beijing, China","2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","20151005","2015","","","790","794","Traditional K-means algorithm's clustering effect is affected by the initial cluster center points. To solve this problem, a method is proposed to optimize the K-means initial center points. The algorithm use density-sensitive similarity measure to compute the density of objects. Through computing the minimum distance between the point and any other point with higher density, the candidate points are chosen out. Then, combined with the average density, the outliers are screened out. Ultimately the initial centers for K-means algorithm are screened out. Experimental results show that the algorithm gets the initial center points with high accuracy, and can effectively filter abnormal points. The running time and the iterations of the K-means algorithm are decreased obviously.","","Electronic:978-1-4799-8730-6; POD:978-1-4799-8731-3; USB:978-1-4799-8729-0","10.1109/CYBER.2015.7288043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7288043","Clustering;Distance;Initial Center Points;K-means Algorithm;Neighborhood Density","Accuracy;Algorithm design and analysis;Clustering algorithms;Data mining;Machine learning algorithms;Partitioning algorithms;Software algorithms","iterative methods;pattern clustering","density-sensitive similarity measure;initialization center K-means clustering algorithm;iterations","","","","15","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Deep transfer metric learning","J. Hu; J. Lu; Y. P. Tan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","325","333","Conventional metric learning methods usually assume that the training and test samples are captured in similar scenarios so that their distributions are assumed to be the same. This assumption doesn't hold in many real visual recognition applications, especially when samples are captured across different datasets. In this paper, we propose a new deep transfer metric learning (DTML) method to learn a set of hierarchical nonlinear transformations for cross-domain visual recognition by transferring discriminative knowledge from the labeled source domain to the unlabeled target domain. Specifically, our DTML learns a deep metric network by maximizing the inter-class variations and minimizing the intra-class variations, and minimizing the distribution divergence between the source domain and the target domain at the top layer of the network. To better exploit the discriminative information from the source domain, we further develop a deeply supervised transfer metric learning (DSTML) method by including an additional objective on DTML where the output of both the hidden layers and the top layer are optimized jointly. Experimental results on cross-dataset face verification and person re-identification validate the effectiveness of the proposed methods.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298629","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298629","","Face;Face recognition;Learning systems;Machine learning;Measurement;Training;Visualization","face recognition;learning (artificial intelligence)","DSTML method;DTML method;conventional metric learning method;cross-dataset face verification;cross-domain visual recognition;deep metric network;deep transfer metric learning method;deeply supervised transfer metric learning method;discriminative information;discriminative knowledge;distribution divergence;hidden layer;hierarchical nonlinear transformation;interclass variation;intraclass variation;labeled source domain;person reidentification;real visual recognition;unlabeled target domain","","9","","40","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"DeepID-Net: Deformable deep convolutional neural networks for object detection","W. Ouyang; X. Wang; X. Zeng; Shi Qiu; P. Luo; Y. Tian; H. Li; Shuo Yang; Zhe Wang; Chen-Change Loy; X. Tang","Chinese Univ. of Hong Kong, Hong Kong, China","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","2403","2412","In this paper, we propose deformable deep convolutional neural networks for generic object detection. This new deep learning object detection framework has innovations in multiple aspects. In the proposed new deep architecture, a new deformation constrained pooling (def-pooling) layer models the deformation of object parts with geometric constraint and penalty. A new pre-training strategy is proposed to learn feature representations more suitable for the object detection task and with good generalization capability. By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of model averaging. The proposed approach improves the mean averaged precision obtained by RCNN [14], which was the state-of-the-art, from 31% to 50.3% on the ILSVRC2014 detection test set. It also outperforms the winner of ILSVRC2014, GoogLeNet, by 6.1%. Detailed component-wise analysis is also provided through extensive experimental evaluation, which provide a global view for people to understand the deep learning object detection pipeline.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298854","","Context modeling;Deformable models;Feature extraction;Machine learning;Object detection;Training;Visualization","image representation;learning (artificial intelligence);neural nets;object detection","DeepID-Net;GoogLeNet;ILSVRC2014 detection test set;RCNN;component-wise analysis;deep architecture;deep learning object detection framework;deep learning object detection pipeline;def-pooling layer model;deformable deep convolutional neural network;deformation constrained pooling layer method;feature representation;generalization capability;generic object detection;geometric constraint;mean averaged precision;net structure;object detection task;pre-training strategy","","19","","","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Effects of function translation and dimensionality reduction on landscape analysis","M. A. Mu√±oz; K. Smith-Miles","School of Mathematical Sciences, Monash University, Clayton, VIC Australia","2015 IEEE Congress on Evolutionary Computation (CEC)","20150914","2015","","","1336","1342","Exploratory Landscape Analysis (ELA) measures have been shown to predict algorithm performance; hence, they are being applied on critical tasks such as automatic algorithm selection and problem generation. This paper provides a cautionary examination on their use in black-box continuous optimization. We explore the effect that translations have on the measures, when the cost function is defined within a bound-constrained region. Furthermore, we examine the robustness of the neighborhood structure after dimensionality reduction. The results demonstrate that a measure may transition abruptly due a translation. Therefore, we should not generalize the measures of an instance nor report average values of a measure as belonging to the generating function. Moreover, dimensionality reduction could alter the neighborhood structure, such that the regions corresponding to significantly different functions overlap.","1089-778X;1089778X","Electronic:978-1-4799-7492-4; POD:978-1-4799-7493-1","10.1109/CEC.2015.7257043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7257043","Black-box continuous optimization;Exploratory landscape analysis;Fitness landscape analysis;Stochastic optimization","Algorithm design and analysis;Machine learning algorithms;Optimization;Prediction algorithms;Principal component analysis;Robustness;Visualization","optimisation;search problems;stochastic processes","ELA;black-box continuous optimization;dimensionality reduction;exploratory landscape analysis;function translation;stochastic search algorithm","","","","38","","","25-28 May 2015","","IEEE","IEEE Conference Publications"
"A feature selection approach implemented with the Binary Bat Algorithm applied for intrusion detection","A. C. Enache; V. Sg√¢rciu","Faculty of Automatic Control and Computer Science, University Politehnica of Bucharest, Romania","2015 38th International Conference on Telecommunications and Signal Processing (TSP)","20151012","2015","","","11","15","The large number and various technological solutions adopted by many enterprises, overwhelms security systems, which must acquire informations from all these diverse sources and interpret them. Furthermore, the proliferation of more complex cyber threats imposes a difficult task for information security assurance. Therefore, it is clear that new solutions are required. In this paper we propose a wrapper feature selection approach that combines an improved version of the Binary Bat Algorithm with two classifiers (C4.5 and SVM). We test our proposed model on the NSL-KDD dataset and empirically prove that our method can boost the performance of the classifiers and outperforms BBA and BPSO in terms of attack detection rate and false alarm rate, obtained after a fewer number of iterations. Furthermore, we reduced the number of features with almost 64% and improved the performances of the classifier, even for unknown intrusions.","","Electronic:978-1-4799-8498-5; POD:978-1-4799-8499-2; USB:978-1-4799-8497-8","10.1109/TSP.2015.7296215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296215","BBA;C4.5;Feature Selection;IDS;SVM","Decision trees;Feature extraction;Intrusion detection;Machine learning algorithms;Silicon;Support vector machines;Training","feature selection;pattern classification;security of data;support vector machines","BBA;BPSO;C4.5;NSL-KDD dataset;SVM;attack detection iteration;binary bat algorithm;cyber threat;false alarm rate;information security assurance;intrusion detection;overwhelm security systems;wrapper feature selection approach","","","","15","","","9-11 July 2015","","IEEE","IEEE Conference Publications"
"Deep Learning Based Feature Selection for Remote Sensing Scene Classification","Q. Zou; L. Ni; T. Zhang; Q. Wang","Sch. of Comput. Sci., Wuhan Univ., Wuhan, China","IEEE Geoscience and Remote Sensing Letters","20151104","2015","12","11","2321","2325","With the popular use of high-resolution satellite images, more and more research efforts have been placed on remote sensing scene classification/recognition. In scene classification, effective feature selection can significantly boost the final performance. In this letter, a novel deep-learning-based feature-selection method is proposed, which formulates the feature-selection problem as a feature reconstruction problem. Note that the popular deep-learning technique, i.e., the deep belief network (DBN), achieves feature abstraction by minimizing the reconstruction error over the whole feature set, and features with smaller reconstruction errors would hold more feature intrinsics for image representation. Therefore, the proposed method selects features that are more reconstructible as the discriminative features. Specifically, an iterative algorithm is developed to adapt the DBN to produce the inquired reconstruction weights. In the experiments, 2800 remote sensing scene images of seven categories are collected for performance evaluation. Experimental results demonstrate the effectiveness of the proposed method.","1545-598X;1545598X","","10.1109/LGRS.2015.2475299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272047","Deep belief network (DBN);feature learning;iterative deep learning;scene recognition;scene understanding","Feature extraction;Image reconstruction;Machine learning;Remote sensing;Satellites;Testing;Training","belief networks;feature selection;geophysical image processing;image classification;image representation;iterative methods;remote sensing","deep belief network;deep learning based feature selection;feature abstraction;feature reconstruction problem;high-resolution satellite images;image representation;iterative algorithm;remote sensing scene classification;remote sensing scene images;remote sensing scene recognition","","9","","17","","20150918","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Multi-GPU implementation of k-nearest neighbor algorithm","J. Masek; R. Burget; J. Karasek; V. Uher; M. K. Dutta","Brno University of Technology, Faculty of Electrical engineering, Department of Telecommunications, Czech Republic","2015 38th International Conference on Telecommunications and Signal Processing (TSP)","20151012","2015","","","764","767","Using modern Graphic Processing Units (GPUs) becomes very useful for computing complex and time consuming processes. GPUs provide high-performance computation capabilities with a good price. This paper deals with a multi-GPU OpenCL implementation of k-Nearest Neighbor (k-NN) algorithm. The proposed OpenCL algorithm achieves acceleration up to 750x in comparison with a single thread CPU version. The common k-NN was modified to be faster when the lower number of k neighbors is set. The performance of algorithm was verified with two GPUs dual-core NVIDIA GeForce GTX 690 and CPU Intel Core i7 3770 with 4.1 GHz frequency. The results of speed up were measured for one GPU, two GPUs, three and four GPUs. We performed several tests with data sets containing up to 4 million elements with various number of attributes.","","Electronic:978-1-4799-8498-5; POD:978-1-4799-8499-2; USB:978-1-4799-8497-8","10.1109/TSP.2015.7296368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296368","Artificial intelligence;GPU;OpenCL;big data;high performance computing;k-NN;multi-GPU","Acceleration;Graphics processing units;Java;Machine learning algorithms;Signal processing algorithms;Telecommunications;Testing","application program interfaces;graphics processing units;learning (artificial intelligence);parallel processing","CPU;Intel Core i7 3770;dual-core NVIDIA GeForce GTX 690;graphic processing units;high-performance computation capabilities;k-NN algorithm;k-nearest neighbor algorithm;multiGPU OpenCL implementation;multiGPU implementation","","","","17","","","9-11 July 2015","","IEEE","IEEE Conference Publications"
"PCANet: A Simple Deep Learning Baseline for Image Classification?","T. H. Chan; K. Jia; S. Gao; J. Lu; Z. Zeng; Y. Ma","MediaTek Inc., Hsinchu, Taiwan","IEEE Transactions on Image Processing","20150923","2015","24","12","5017","5032","In this paper, we propose a very simple deep learning network for image classification that is based on very basic data processing components: 1) cascaded principal component analysis (PCA); 2) binary hashing; and 3) blockwise histograms. In the proposed architecture, the PCA is employed to learn multistage filter banks. This is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus called the PCA network (PCANet) and can be extremely easily and efficiently designed and learned. For comparison and to provide a better understanding, we also introduce and study two simple variations of PCANet: 1) RandNet and 2) LDANet. They share the same topology as PCANet, but their cascaded filters are either randomly selected or learned from linear discriminant analysis. We have extensively tested these basic networks on many benchmark visual data sets for different tasks, including Labeled Faces in the Wild (LFW) for face verification; the MultiPIE, Extended Yale B, AR, Facial Recognition Technology (FERET) data sets for face recognition; and MNIST for hand-written digit recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state-of-the-art features either prefixed, highly hand-crafted, or carefully learned [by deep neural networks (DNNs)]. Even more surprisingly, the model sets new records for many classification tasks on the Extended Yale B, AR, and FERET data sets and on MNIST variations. Additional experiments on other public data sets also demonstrate the potential of PCANet to serve as a simple but highly competitive baseline for texture classification and object recognition.","1057-7149;10577149","","10.1109/TIP.2015.2475625","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7234886","Convolution Neural Network;Convolution neural network;Deep Learning;Face Recognition;Handwritten Digit Recognition;LDA Network;LDA network;Object Classification;PCA Network;PCA network;Random Network;deep learning;face recognition;handwritten digit recognition;object classification;random network","Face;Face recognition;Feature extraction;Histograms;Machine learning;Principal component analysis;Training","channel bank filters;face recognition;handwriting recognition;image classification;image texture;learning (artificial intelligence);neural nets;object recognition;principal component analysis","AR;DNN;FERET data sets;LDANet;LFW;MNIST;PCA network;PCANet;RandNet;binary hashing;blockwise histograms;cascaded principal component analysis;data processing components;deep learning baseline;deep neural networks;extended Yale B;face verification;facial recognition technology;handwritten digit recognition;image classification;labeled faces;linear discriminant analysis;multiPIE;multistage filter banks;object recognition;public data sets;texture classification;visual data sets;wild","","31","","65","","20150901","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Deep hashing for compact binary codes learning","V. E. Liong; Jiwen Lu; Gang Wang; P. Moulin; Jie Zhou","Advanced Digital Sciences Center, Singapore","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","2475","2483","In this paper, we propose a new deep hashing (DH) approach to learn compact binary codes for large scale visual search. Unlike most existing binary codes learning methods which seek a single linear projection to map each sample into a binary vector, we develop a deep neural network to seek multiple hierarchical non-linear transformations to learn these binary codes, so that the nonlinear relationship of samples can be well exploited. Our model is learned under three constraints at the top layer of the deep network: 1) the loss between the original real-valued feature descriptor and the learned binary vector is minimized, 2) the binary codes distribute evenly on each bit, and 3) different bits are as independent as possible. To further improve the discriminative power of the learned binary codes, we extend DH into supervised DH (SDH) by including one discriminative term into the objective function of DH which simultaneously maximizes the inter-class variations and minimizes the intra-class variations of the learned binary codes. Experimental results show the superiority of the proposed approach over the state-of-the-arts.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298862","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298862","","Binary codes;DH-HEMTs;Machine learning;Optimization;Synchronous digital hierarchy;Training;Visualization","binary codes;computer vision;file organisation;image retrieval;learning (artificial intelligence);neural nets","binary vector;compact binary codes learning;computer vision;deep hashing approach;deep neural network;interclass variation maximization;intraclass variation miminization;large scale visual search;linear projection;multiple hierarchical nonlinear transformation;objective function;real-valued feature descriptor","","10","","36","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Deep Learning and Music Adversaries","C. Kereliuk; B. L. Sturm; J. Larsen","DTU Compute, The Technical University of Denmark, Frederiksberg, Denmark","IEEE Transactions on Multimedia","20151026","2015","17","11","2059","2071","An adversary is an agent designed to make a classification system perform in some particular way, e.g., increase the probability of a false negative. Recent work builds adversaries for deep learning systems applied to image object recognition, exploiting the parameters of the system to find the minimal perturbation of the input image such that the system misclassifies it with high confidence. We adapt this approach to construct and deploy an adversary of deep learning systems applied to music content analysis. In our case, however, the system inputs are magnitude spectral frames, which require special care in order to produce valid input audio signals from network- derived perturbations . For two different train-test partitionings of two benchmark datasets, and two different architectures , we find that this adversary is very effective. We find that convolutional architectures are more robust compared to systems based on a majority vote over individually classified audio frames. Furthermore , we experiment with a new system that integrates an adversary into the training loop, but do not find that this improves the resilience of the system to new adversaries.","1520-9210;15209210","","10.1109/TMM.2015.2478068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254179","AEA-MIR content-based processing and music information retrieval;deep learning","Benchmark testing;Computer architecture;Machine learning;Neural networks;Rhythm;Training","audio signal processing;content management;convolution;image classification;information retrieval;learning (artificial intelligence);music;object recognition","audio frame classification;audio signal;classification system;convolutional architecture;deep learning system;image object recognition;magnitude spectral frame;music adversary;music content analysis;network derived perturbation;training loop","","3","","65","","20150910","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Hybrid approach to crime prediction using deep learning","J. Azeez; D. J. Aravindhar","Department of Computer Science & Engineering, Hindustan Institute of Technology & Science, Padur Chennai, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","1701","1710","Prevention is better that Cure. Preventing a crime from occurring is better than investigating what or how the crime had occurred. Just like vaccination is given to a child to prevent disease, in today's world with such higher crime rate and brutal crime happenings, it have become necessary to have a vaccination systems that prevents from crimes happening. By vaccinating society against crime it refers to various methods such as educating peoples, creating awareness, increasing efficiency and proactive policing methods and other deterrent techniques. Inspired by two different existing approach to crime prediction, the first one present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. Crime incident prediction has depends mainly on the historical crime record and various geospatial and demographic information <sup>[1]</sup>. Even though it's promising, they do not take into account the rich and rapidly expanding social & web media context that surrounds incidents of interest. Next approach is based on the semantic analysis and natural language processing of Twitter posts via latent Dirichlet allocation, Topic detection Sentiment analysis<sup>[3[4]]</sup>. But both the techniques faces inherent limitations. Crime that happens these days are have following key characteristics such as crimes repeating in a periodic fashion, crimes occurring as a result of some other activity and occurrence of crimes pre indicated by some other information.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275858","Deep Learning;LDA;RNN;STL;Sentiment Analysis;Undirected Probabilistic Graph","Algorithm design and analysis;Computational modeling;Data models;Informatics;Machine learning;Market research;Prediction algorithms","criminal law;demography;natural language processing;resource allocation;social networking (online)","Twitter posts;brutal crime;crime incident prediction;crime prevention;deep learning;demographic information;deployment decisions;geospatial information;historical crime record;hybrid approach;latent Dirichlet allocation;natural language processing;resource allocation;semantic analysis;sentiment analysis;topic detection;vaccination systems;visual analytics approach","","","","12","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Potential Component Leaks in Android Apps: An Investigation into a New Feature Set for Malware Detection","L. Li; K. Allix; D. Li; A. Bartel; T. F. Bissyand√©; J. Klein","SnT, Univ. of Luxembourg, Luxembourg, Luxembourg","2015 IEEE International Conference on Software Quality, Reliability and Security","20150924","2015","","","195","200","We discuss the capability of a new feature set for malware detection based on potential component leaks (PCLs). PCLs are defined as sensitive data-flows that involve Android inter-component communications. We show that PCLs are common in Android apps and that malicious applications indeed manipulate significantly more PCLs than benign apps. Then, we evaluate a machine learning-based approach relying on PCLs. Experimental validations show high performance for identifying malware, demonstrating that PCLs can be used for discriminating malicious apps from benign apps.","","Electronic:978-1-4673-7989-2; POD:978-1-4673-7990-8","10.1109/QRS.2015.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272932","","Androids;Feature extraction;Humanoid robots;Libraries;Machine learning algorithms;Malware;Training","Android (operating system);data flow computing;invasive software;learning (artificial intelligence)","Android apps;Android intercomponent communications;PCLs;component leakage;data-flows;machine learning-based approach;malicious applications;malware detection;potential component leaks","","1","","28","","","3-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Transformation of nominal features into numeric in supervised multi-class problems based on the weight of evidence parameter","E. Zdravevski; P. Lameski; A. Kulakov; S. Kalajdziski","Faculty of Computer Science and Engineering, Ss.Cyril and Methodius University, Skopje, Macedonia","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","169","179","Machine learning has received increased interest by both the scientific community and the industry. Most of the machine learning algorithms rely on certain distance metrics that can only be applied to numeric data. This becomes a problem in complex datasets that contain heterogeneous data consisted of numeric and nominal (i.e. categorical) features. Thus the need of transformation from nominal to numeric data. Weight of evidence (WoE) is one of the parameters that can be used for transformation of the nominal features to numeric. In this paper we describe a method that uses WoE to transform the features. Although the applicability of this method is researched to some extent, in this paper we extend its applicability for multi-class problems, which is a novelty. We compared it with the method that generates dummy features. We test both methods on binary and multi-class classification problems with different machine learning algorithms. Our experiments show that the WoE based transformation generates smaller number of features compared to the technique based on generation of dummy features while also improving the classification accuracy, reducing memory complexity and shortening the execution time. Be that as it may, we also point out some of its weaknesses and make some recommendations when to use the method based on dummy features generation instead.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321439","Weight of Evidence;WoE;categorical features;data transformation;dummy features;heterogeneous data;nominal features","Accuracy;Machine learning algorithms;Mathematical model;Measurement;Tin;Training;Transforms","data analysis;learning (artificial intelligence)","WoE based transformation;categorical features;classification accuracy;complex datasets;dummy features;evidence parameter;execution time;heterogeneous data;machine learning algorithms;nominal features;numeric features;scientific community;supervised multiclass problems;weight of evidence","","","","31","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"Personalized Decision-Strategy based Web Service Selection using a Learning-to-Rank Algorithm","M. S. Saleem; C. Ding; X. Liu; C. H. Chi","Department of Computer Science, Ryerson University, Toronto, Canada","IEEE Transactions on Services Computing","20151005","2015","8","5","727","739","In order to choose from a list of functionally similar services, users often need to make their decisions based on multiple QoS criteria they require on the target service. In this process, different users may follow different decision making strategies, some are compensatory in which only an overall value on all the criteria is evaluated, some evaluate one criterion at a time in the order of their importance levels, while others count on the number of winning criteria. Most of the current QoS-based service selection systems do not consider these decision strategies in the ranking process, which we believe are crucial for generating accurate ranking results for individual users. In this paper, we propose a decision strategy based service ranking model. Furthermore, considering that different users follow different strategies in different contexts at different times, we apply a machine learning algorithm to learn a personalized ranking model for individual users based on how they select services in the past. We have implemented and tested the proposed approach, and our experiment results show the effectiveness of the approach.","1939-1374;19391374","","10.1109/TSC.2014.2377724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981951","Decision Strategy;Learning to Rank;Quality of Service (QoS);Web Service Selection;Web service selection;decision strategy;learning to rank;quality of service (QoS)","Context;Decision making;History;Machine learning algorithms;Quality of service;Reliability;Web services","Web services;decision making;feature selection;learning (artificial intelligence);quality of service","QoS criteria;Web service selection;decision making strategy;learning-to-rank algorithm;machine learning algorithm;personalized ranking model;quality of service;service ranking model","","2","","26","","20141210","Sept.-Oct. 1 2015","","IEEE","IEEE Journals & Magazines"
"Glaucoma detection based on deep convolutional neural network","X. Chen; Y. Xu; D. W. Kee Wong; T. Y. Wong; J. Liu","Institute for Infocomm Research, Agency for Science, Technology and Research, 138632, Singapore","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","715","718","Glaucoma is a chronic and irreversible eye disease, which leads to deterioration in vision and quality of life. In this paper, we develop a deep learning (DL) architecture with convolutional neural network for automated glaucoma diagnosis. Deep learning systems, such as convolutional neural networks (CNNs), can infer a hierarchical representation of images to discriminate between glaucoma and non-glaucoma patterns for diagnostic decisions. The proposed DL architecture contains six learned layers: four convolutional layers and two fully-connected layers. Dropout and data augmentation strategies are adopted to further boost the performance of glaucoma diagnosis. Extensive experiments are performed on the ORIGA and SCES datasets. The results show area under curve (AUC) of the receiver operating characteristic curve in glaucoma detection at 0.831 and 0.887 in the two databases, much better than state-of-the-art algorithms. The method could be used for glaucoma detection.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318462","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318462","","Biomedical optical imaging;Diseases;Machine learning;Neural networks;Optical imaging;Prediction algorithms;Training","diseases;image representation;learning (artificial intelligence);medical image processing;neural nets;object detection","AUC;CNNs;DL architecture;ORIGA datasets;SCES datasets;area under curve;automated glaucoma diagnosis;data augmentation strategy;deep convolutional neural network;deep learning architecture;dropout augmentation strategy;glaucoma detection;glaucoma patterns;hierarchical image representation;irreversible eye disease;nonglaucoma patterns;receiver operating characteristic curve","","","","18","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Deep multiple instance learning for image classification and auto-annotation","J. Wu; Yinan Yu; Chang Huang; Kai Yu","Massachusetts Institute of Technology, USA","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","3460","3469","The recent development in learning deep representations has demonstrated its wide applications in traditional vision tasks like classification and detection. However, there has been little investigation on how we could build up a deep learning framework in a weakly supervised setting. In this paper, we attempt to model deep learning in a weakly supervised learning (multiple instance learning) framework. In our setting, each image follows a dual multi-instance assumption, where its object proposals and possible text annotations can be regarded as two instance sets. We thus design effective systems to exploit the MIL property with deep learning strategies from the two ends; we also try to jointly learn the relationship between object and annotation proposals. We conduct extensive experiments and prove that our weakly supervised deep learning framework not only achieves convincing performance in vision tasks including classification and image annotation, but also extracts reasonable region-keyword pairs with little supervision, on both widely used benchmarks like PASCAL VOC and MIT Indoor Scene 67, and also a dataset for image-and patch-level annotations.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298968","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298968","","Feature extraction;Machine learning;Neural networks;Noise measurement;Proposals;Supervised learning;Visualization","image classification;learning (artificial intelligence)","MIL;deep multiple instance learning;image annotation;image classification;supervised deep learning framework","","14","","49","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Using Random Undersampling to Alleviate Class Imbalance on Tweet Sentiment Data","J. Prusa; T. M. Khoshgoftaar; D. J. Dittman; A. Napolitano","Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE International Conference on Information Reuse and Integration","20151026","2015","","","197","202","Sentiment classification of tweets is used for a variety of social sensing tasks and provides a means of discerning public opinion on a wide range of topics. A potential concern when performing sentiment classification is that the training data may contain class imbalance, which can negatively affect classification performance. A classifier trained on imbalanced data may be biased in favor of the majority class. One possibile method of addressing this is to use data sampling to achieve a more balanced class distribution. In this work, we seek to observe how data sampling (using random undersampling with either a 50:50 or 35:65 positive:negative post-sampling class distribution ratio) affects the classification performance on tweet sentiment data. Our experimental results show that Random Undersampling significantly improves classification performance in comparison to not using any data sampling. Furthermore, there is no significant difference between selecting a 50:50 or 35:65 post-sampling class distribution ratio.","","Electronic:978-1-4673-6656-4; POD:978-1-4673-6657-1","10.1109/IRI.2015.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300975","classification;data sampling;sentiment analysis;tweet mining","Analysis of variance;Data mining;Feature extraction;Machine learning algorithms;Support vector machines;Training;Training data","data mining;pattern classification;sampling methods;social networking (online)","class distribution;classification performance;data sampling;random undersampling;social sensing tasks;tweet sentiment classification;tweet sentiment data","","4","","20","","","13-15 Aug. 2015","","IEEE","IEEE Conference Publications"
"EvoAE -- A New Evolutionary Method for Training Autoencoders for Deep Learning Networks","S. Lander; Y. Shang","Comput. Sci. Dept., Univ. of Missouri, Columbia, MO, USA","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","2","","790","795","Although deep learning has achieved outstanding performances on several difficult machine learning applications, there are multiple issues that make its application on new problems difficult: speed of training, local minima, and manual selection of hyper-parameters. To overcome these problems, this paper proposes a new evolutionary method, EvoAE, to train auto encoders for deep learning networks. By evolving a population of auto encoders, EvoAE learns multiple features in each auto encoder in the form of hidden nodes, evaluates the auto encoders based on their reconstruction quality, and generates new auto encoders using crossover and mutation with chromosomes made up of hidden nodes and associated connections and weights. EvoAE optimizes network weights and structures of auto encoders simultaneously and employs a mini-batch variant, called Evo-batch, to speed up auto encoder search on large datasets. Furthermore, EvoAE supports different training methods in data partitioning and selection, requires little manual intervention, and reduces overall training time drastically over traditional methods on large datasets.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273701","autoencoder;deep learning;evolutionary algorithm;neural networks","Backpropagation;Machine learning;Optimization;Sociology;Statistics;Testing;Training","evolutionary computation;learning (artificial intelligence)","Evo-batch;EvoAE;autoencoder search;chromosomes;crossover;data partitioning;data selection;deep learning networks;evolutionary method;large datasets;machine learning applications;minibatch variant;mutation;network weights optimization;reconstruction quality;training methods","","2","","10","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Automatic fusion and classification using random forests and features extracted with deep learning","A. Merentitis; C. Debes","AGT International, 64295 Darmstadt, Germany","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20151112","2015","","","2943","2946","Fusion of different sensor modalities has proven very effective in numerous remote sensing applications. However, in order to benefit from fusion, advanced feature extraction mechanisms that rely on domain expertise are typically required. In this paper we present an automated feature extraction scheme based on deep learning. The feature extraction is unsupervised and hierarchical. Furthermore, computational efficiency (often a challenge for deep learning methods) is a primary goal in order to make certain that the method can be applied in large remote sensing datasets. Promising classification results show the applicability of the approach for both reducing the gap between naive feature extraction and methods relying on domain expertise, as well as further improving the performance of the latter in two challenging datasets.","2153-6996;21536996","Electronic:978-1-4799-7929-5; POD:978-1-4799-7930-1; USB:978-1-4799-7928-8","10.1109/IGARSS.2015.7326432","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326432","","Correlation;Data integration;Feature extraction;Hyperspectral imaging;Laser radar;Machine learning","feature extraction;geophysical image processing;image classification;image fusion;remote sensing by laser beam","advanced feature extraction mechanisms;automated feature extraction scheme;automatic classification;automatic fusion;deep learning feature extraction;random forests;remote sensing applications;remote sensing datasets;sensor modality fusion","","1","","7","","","26-31 July 2015","","IEEE","IEEE Conference Publications"
"Generation of caption selection for news images using stemming algorithm","K. Vijay; D. Ramya","Dept. of Information Technology, Faculty of Computing, Sathyabama University, Chennai-600 119, Tamil Nadu, India","2015 International Conference on Computation of Power, Energy, Information and Communication (ICCPEIC)","20150914","2015","","","0536","0540","Image based search engine is the process of searching information by using related images. The huge resources of images are available on the web, In that many of the images are contain as with labeled and without labeled caption. The users are required to search the images depending on their needs. In that many of the users are unable to retrieve the relevant images because of their unpredicted suitable caption on their images. Our task is to generate an automatic caption for the images based on the related information. Earlier, the manual captioning model is available to generate a description for the pictures. It is difficult and expensive task. The proposed model learns to create a caption for the images that are embedded with the related news articles. Which is most related to the image based applications. This process makes the easy understanding of news by seeing the images with caption and without reading the whole content of the news in the news articles.","","CD-ROM:978-1-4673-6524-6; Electronic:978-1-4673-6525-3; POD:978-1-4673-6526-0","10.1109/ICCPEIC.2015.7259513","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7259513","Caption Generation;Content Selection;Image Annotation Model;Image Description;Topic Summarization","Algorithm design and analysis;Europe;Image segmentation;Machine learning algorithms;Manuals;Prediction algorithms;Servers","image retrieval;information resources;search engines","image based search engine;image caption selection generation;news images;relevant image retrieval;stemming algorithm","","","","16","","","22-23 April 2015","","IEEE","IEEE Conference Publications"
"Fast and Accurate Support Vector Machines on Large Scale Systems","A. Vishnu; J. Narasimhan; L. Holder; D. Kerbyson; A. Hoisie","Adv. Comput., Math. & Data Div., Pacific Northwest Nat. Lab., Richland, WA, USA","2015 IEEE International Conference on Cluster Computing","20151029","2015","","","110","119","Support Vector Machines (SVM) is a supervised Machine Learning and Data Mining (MLDM) algorithm, which has become ubiquitous largely due to its high accuracy and obliviousness to dimensionality. The objective of SVM is to find an optimal boundary -- also known as hyperplane -- which separates the samples (examples in a dataset) of different classes by a maximum margin. Usually, very few samples contribute to the definition of the boundary. However, existing parallel algorithms use the entire dataset for finding the boundary, which is sub-optimal for performance reasons. In this paper, we propose a novel distributed memory algorithm to eliminate the samples which do not contribute to the boundary definition in SVM. We propose several heuristics, which range from early (aggressive) to late (conservative) elimination of the samples, such that the overall time for generating the boundary is reduced considerably. In a few cases, a sample may be eliminated (shrunk) pre-emptively -- potentially resulting in an incorrect boundary. We propose a scalable approach to synchronize the necessary data structures such that the proposed algorithm maintains its accuracy. We consider the necessary trade-offs of single/multiple synchronization using in-depth time-space complexity analysis. We implement the proposed algorithm using MPI and compare it with libsvm -- de facto sequential SVM software -- which we enhance with OpenMP for multi-core/many-core parallelism. Our proposed approach shows excellent efficiency using up to 4096 processes on several large datasets such as UCI HIGGS Boson dataset and Offending URL dataset.","1552-5244;15525244","Electronic:978-1-4673-6598-7; POD:978-1-4673-6599-4","10.1109/CLUSTER.2015.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307573","Extreme Scale;MPI;Support Vector Machines","Accuracy;Algorithm design and analysis;Complexity theory;Data structures;Kernel;Machine learning algorithms;Support vector machines","computational complexity;data analysis;data mining;data structures;distributed memory systems;learning (artificial intelligence);parallel algorithms;support vector machines;synchronisation","MLDM algorithm;MPI;OpenMP;UCI HIGGS Boson dataset;boundary definition;data structures;distributed memory algorithm;hyperplane;large scale systems;many-core parallelism;multicore parallelism;multiple synchronization;offending URL dataset;parallel algorithms;sequential SVM software;single synchronization;supervised machine learning and data mining algorithm;support vector machines;time-space complexity analysis","","2","","32","","","8-11 Sept. 2015","","IEEE","IEEE Conference Publications"
"Bug report, feature request, or simply praise? On automatically classifying app reviews","W. Maalej; H. Nabil","University of Hamburg, Germany","2015 IEEE 23rd International Requirements Engineering Conference (RE)","20151105","2015","","","116","125","App stores like Google Play and Apple AppStore have over 3 Million apps covering nearly every kind of software and service. Billions of users regularly download, use, and review these apps. Recent studies have shown that reviews written by the users represent a rich source of information for the app vendors and the developers, as they include information about bugs, ideas for new features, or documentation of released features. This paper introduces several probabilistic techniques to classify app reviews into four types: bug reports, feature requests, user experiences, and ratings. For this we use review metadata such as the star rating and the tense, as well as, text classification, natural language processing, and sentiment analysis techniques. We conducted a series of experiments to compare the accuracy of the techniques and compared them with simple string matching. We found that metadata alone results in a poor classification accuracy. When combined with natural language processing, the classification precision got between 70-95% while the recall between 80-90%. Multiple binary classifiers outperformed single multiclass classifiers. Our results impact the design of review analytics tools which help app vendors, developers, and users to deal with the large amount of reviews, filter critical reviews, and assign them to the appropriate stakeholders.","1090-705X;1090705X","Electronic:978-1-4673-6905-3; POD:978-1-4673-6906-0","10.1109/RE.2015.7320414","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7320414","","Accuracy;Computer crashes;Google;Machine learning algorithms;Metadata;Natural language processing;Training","","","","16","","34","","","24-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"Convolutional neural networks for mammography mass lesion classification","J. Arevalo; F. A. Gonz√°lez; R. Ramos-Poll√°n; J. L. Oliveira; M. A. Guevara Lopez","Univ. Nacional de Colombia, Colombia","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","797","800","Feature extraction is a fundamental step when mammography image analysis is addressed using learning based approaches. Traditionally, problem dependent handcrafted features are used to represent the content of images. An alternative approach successfully applied in other domains is the use of neural networks to automatically discover good features. This work presents an evaluation of convolutional neural networks to learn features for mammography mass lesions before feeding them to a classification stage. Experimental results showed that this approach is a suitable strategy outperforming the state-of-the-art representation from 79.9% to 86% in terms of area under the ROC curve.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318482","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318482","","Breast cancer;Feature extraction;Lesions;Machine learning;Shape;Training","convolution;feature extraction;image classification;image representation;learning (artificial intelligence);mammography;medical image processing;neural nets;sensitivity analysis","area under the ROC curve;classification stage;content representation;convolutional neural networks;feature extraction;learning based approaches;mammography image analysis;mammography mass lesion classification;problem dependent handcrafted features","","4","","15","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Medical diagnosis support and accuracy improvement by application of total scoring from feature selection approach","W. Paja","Faculty of Mathematics and Natural Sciences, University of Rzesz&#x00F3;w, 1 Prof. S. Pigonia Street, 35-310, Poland","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","281","286","Melanoma is the most deadly form of skin cancer. Early detection and successful treatment of this disease often is possible. The main goal of this paper is to present results of application of feature selection method to find the most important or all important features that characterize melanocytic spots on the skin and in this way defining of a new Total Dermatoscopy Score formula. Thus, it is possible to decrease dimensionality of that problem. Results gathered during research focus on about six from thirteen descriptive attributes which are the most relevant and are stated as core attributes. Based on these attributes a simple total scoring method could be applied to improve prediction (diagnosis) results, additionally also reducing complexity of problem. Results were acquired by application of six different machine learning algorithms and estimated using several evaluation measures.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321454","","Lesions;Machine learning algorithms;Malignant tumors;Pigments;Skin;Support vector machines","cancer;feature selection;learning (artificial intelligence);medical information systems;patient diagnosis;skin","diagnosis improvement;disease detection;disease treatment;evaluation measures;feature selection approach;machine learning algorithms;medical diagnosis accuracy improvement;medical diagnosis support improvement;melanocytic spot characterization;melanoma;prediction improvement;skin cancer;total dermatoscopy score formula","","","","14","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"Fall detection system based on inertial mems sensors: Analysis design and realization","G. Shi; J. Zhang; C. Dong; P. Han; Y. Jin; J. Wang","Peking University Shenzhen Graduate School, Shenzhen, China","2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","20151005","2015","","","1834","1839","This paper presents the development and analysis of inertial MEMS sensor based system that can detect falls in real time. The system is a major part of mobile human airbag system which prevents the elderly from fall induced fractures. The fall detection system hardware was designed, which could monitor the motions of the feet and waist and detect the falls in real time. Micro Inertial Measurement Units (Œº IMUs) was applied in this system with Zigbee network and the fall detection algorithm what was constituted of three sub algorithms also was developed. The system was designed based on data analysis, in order to select the optimal parts for monitoring human motion and verify the algorithm performance, performance for different parts was compared by employing the pattern recognition based sub-algorithm and performance for different combination of human body segments and joints was also compared to get the better result. A wearable motion capture device was utilized to acquire the motion data. The effective extracting features were carried out and the motion classification performance was achieved and compared using the J48 decision tree classifier. Experimental results showed that the waist is the best location for motion monitoring with detection Sensitivity of 95.5%, the Specificity of 98.8% and the overall accuracy of 97.792%. Furthermore, the combination of the waist and feet sensing data was adopted with the Sensitivity of 98.9%, the Specificity of 98.5% and the overall accuracy of 98.565%. Based on the analysis, the system was designed to monitoring the motion of the combination, and the pattern recognition based sub-algorithm was also verified.","","Electronic:978-1-4799-8730-6; POD:978-1-4799-8731-3; USB:978-1-4799-8729-0","10.1109/CYBER.2015.7288226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7288226","J48 classifier;Sensitivity;Specificity;fall-detection;wearable device","Accuracy;Classification algorithms;Feature extraction;Foot;Machine learning algorithms;Sensitivity;Sensors","Zigbee;data acquisition;data analysis;decision trees;feature extraction;geriatrics;microsensors;motion measurement","ŒºIMU;J48 decision tree classifier;Zigbee network;data analysis;elderly;fall detection system;feature extraction;human body segmentation;human motion monitoring;inertial MEMS sensor;microinertial measurement unit;mobile human airbag system;motion classification;motion data acquisition;pattern recognition;wearable motion capture device","","1","","16","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Let's vote to classify authentic and manipulative online reviews: The role of comprehensibility, informativeness and writing style","S. Banerjee; A. Y. K. Chua; J. J. Kim","Wee Kim Wee School of Communication & Information, Nanyang Technological University, Singapore","2015 Science and Information Conference (SAI)","20150903","2015","","","77","83","Scholars increasingly seek to investigate differences between authentic and manipulative online reviews. A common line of research argues that authentic and manipulative reviews are distinguishable based on three textual characteristics, namely, comprehensibility, informativeness and writing style. Although recent studies have analyzed differences between authentic and manipulative reviews in terms of these textual characteristics, they often lack in terms of methodological rigor. For one, datasets used for analysis are not always representative. Moreover, only few machine learning algorithms are used to classify authentic and manipulative reviews. Recognizing the value of methodological rigor, this paper extends prior studies by examining textual differences between authentic and manipulative reviews using a more representative dataset. Moreover, authentic and manipulative reviews were classified using a voting among multiple classifiers that had been used in recent literature. The implications of the results are discussed.","","Electronic:978-1-4799-8547-0; POD:978-1-4799-8548-7; USB:978-1-4799-8546-3","10.1109/SAI.2015.7237129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237129","authentic;classification;comprehensibility;informativeness;manipulative;online reviews;voting;writing style","Accuracy;Internet;Logistics;Machine learning algorithms;Measurement;Support vector machines;Writing","learning (artificial intelligence);pattern classification;text analysis","authentic online review classification;comprehensibility;informativeness;machine learning algorithms;manipulative online review classification;textual characteristics;textual differences;writing style","","0","","29","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Unconstrained detection of freezing of Gait in Parkinson's disease patients using smartphone","H. Kim; H. J. Lee; W. Lee; S. Kwon; S. K. Kim; H. S. Jeon; H. Park; C. W. Shin; W. J. Yi; B. S. Jeon; K. S. Park","Graduate Program of Biomedical Engineering, Seoul National University, Korea","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","3751","3754","Freezing of gait (FOG) is a common motor impairment to suffer an inability to walk, experienced by Parkinson's disease (PD) patients. FOG interferes with daily activities and increases fall risk, which can cause severe health problems. We propose a novel smartphone-based system to detect FOG symptoms in an unconstrained way. The feasibility of single device to sense gait characteristic was tested on the various body positions such as ankle, trouser pocket, waist and chest pocket. Using measured data from accelerometer and gyroscope in the smartphone, machine learning algorithm was applied to classify freezing episodes from normal walking. The performance of AdaBoost.M1 classifier showed the best sensitivity of 86% at the waist, 84% and 81% in the trouser pocket and at the ankle respectively, which is comparable to the results of previous studies.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7319209","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319209","","Acceleration;Accelerometers;Classification algorithms;Machine learning algorithms;Parkinson's disease;Sensitivity;Sensors","accelerometers;diseases;gait analysis;learning (artificial intelligence);medical computing;medical disorders;mobile computing;smart phones","AdaBoost.M1 classifier;FOG symptoms;Parkinsons disease patients;accelerometer;ankle;chest pocket;freezing of gait;gait characteristic;gyroscope;machine learning algorithm;motor impairment;smartphone;smartphone-based system;trouser pocket;unconstrained detection;waist;walking","","","","17","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Saliency detection by multi-context deep learning","R. Zhao; W. Ouyang; H. Li; X. Wang","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Chuangyeyuan Rd, Longgang, Guangdong, China","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","1265","1274","Low-level saliency cues or priors do not produce good enough saliency detection results especially when the salient object presents in a low-contrast background with confusing visual appearance. This issue raises a serious problem for conventional approaches. In this paper, we tackle this problem by proposing a multi-context deep learning framework for salient object detection. We employ deep Convolutional Neural Networks to model saliency of objects in images. Global context and local context are both taken into account, and are jointly modeled in a unified multi-context deep learning framework. To provide a better initialization for training the deep neural networks, we investigate different pre-training strategies, and a task-specific pre-training scheme is designed to make the multi-context modeling suited for saliency detection. Furthermore, recently proposed contemporary deep models in the ImageNet Image Classification Challenge are tested, and their effectiveness in saliency detection are investigated. Our approach is extensively evaluated on five public datasets, and experimental results show significant and consistent improvements over the state-of-the-art methods.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298731","","Context;Context modeling;Machine learning;Object detection;Predictive models;Training;Visualization","image classification;learning (artificial intelligence);neural nets;object detection","ImageNet image classification challenge;contemporary deep model;convolutional neural network;deep neural network;low-contrast background;low-level saliency cue;multicontext deep learning framework;multicontext modeling;pre-training strategy;saliency detection;salient object detection;task-specific pre-training scheme;visual appearance","","39","","64","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Estimating crop yields with deep learning and remotely sensed data","K. Kuwata; R. Shibasaki","The University of Tokyo IIS, The University of Tokyo, 4-6-1 Komaba, Meguro-ku, Tokyo 153-8505, Japan","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20151112","2015","","","858","861","This paper describes Illinois corn yield estimation using deep learning and another machine learning, SVR. Deep learning is a technique that has been attracting attention in recent years of machine learning, it is possible to implement using the Caffe. High accuracy estimation of crop yield is very important from the viewpoint of food security. However, since every country prepare data inhomogeneously, the implementation of the crop model in all regions is difficult. Deep learning is possible to extract important features for estimating the object from the input data, so it can be expected to reduce dependency of input data. The network model of two InnerProductLayer was the best algorithm in this study, achieving RMSE of 6.298 (standard value). This study highlights the advantages of deep learning for agricultural yield estimating.","2153-6996;21536996","Electronic:978-1-4799-7929-5; POD:978-1-4799-7930-1; USB:978-1-4799-7928-8","10.1109/IGARSS.2015.7325900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325900","Caffe;Deep Learning;EVI;MODIS;crop yield","Agriculture;Data models;Feature extraction;Indexes;Machine learning;Meteorology;Remote sensing","estimation theory;learning (artificial intelligence);regression analysis;remote sensing;support vector machines;vegetation mapping","Caffe;RMSE;SVR;agricultural yield;crop model;crop yield estimation;crop yield estimatoin;deep learning data;food security;inner product layer;machine learning;remotely sensed data;support vector regression","","","","13","","","26-31 July 2015","","IEEE","IEEE Conference Publications"
"Heterogeneous Feature Selection With Multi-Modal Deep Neural Networks and Sparse Group LASSO","L. Zhao; Q. Hu; W. Wang","School of Computer Science and Technology, Tianjin University, Tianjin, China","IEEE Transactions on Multimedia","20151026","2015","17","11","1936","1948","Heterogeneous feature representations are widely used in machine learning and pattern recognition, especially for multimedia analysis. The multi-modal, often also high- dimensional , features may contain redundant and irrelevant information that can deteriorate the performance of modeling in classification. It is a challenging problem to select the informative features for a given task from the redundant and heterogeneous feature groups. In this paper, we propose a novel framework to address this problem. This framework is composed of two modules, namely, multi-modal deep neural networks and feature selection with sparse group LASSO. Given diverse groups of discriminative features, the proposed technique first converts the multi-modal data into a unified representation with different branches of the multi-modal deep neural networks. Then, through solving a sparse group LASSO problem, the feature selection component is used to derive a weight vector to indicate the importance of the feature groups. Finally, the feature groups with large weights are considered more relevant and hence are selected. We evaluate our framework on three image classification datasets. Experimental results show that the proposed approach is effective in selecting the relevant feature groups and achieves competitive classification performance as compared with several recent baseline methods.","1520-9210;15209210","","10.1109/TMM.2015.2477058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244241","Deep learning;feature selection;heterogeneous data;multi-modal;sparse representation","Data mining;Feature extraction;Kernel;Machine learning;Multimedia communication;Neural networks","","","","0","","55","","20150907","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Exploring the use of deep learning for feature location","C. S. Corley; K. Damevski; N. A. Kraft","The University of Alabama, Tuscaloosa, USA","2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)","20151123","2015","","","556","560","Deep learning models can infer complex patterns present in natural language text. Relative to n-gram models, deep learning models can capture more complex statistical patterns based on smaller training corpora. In this paper we explore the use of a particular deep learning model, document vectors (DVs), for feature location. DVs seem well suited to use with source code, because they both capture the influence of context on each term in a corpus and map terms into a continuous semantic space that encodes semantic relationships such as synonymy. We present preliminary results that show that a feature location technique (FLT) based on DVs can outperform an analogous FLT based on latent Dirichlet allocation (LDA) and then suggest several directions for future work on the use of deep learning models to improve developer effectiveness in feature location.","","Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3","10.1109/ICSM.2015.7332513","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332513","deep learning;document vectors;feature location;neural networks","Context;Machine learning;Natural languages;Neural networks;Semantics;Training;Voltage control","learning (artificial intelligence);neural nets;statistical analysis;text analysis","FLT;LDA;continuous semantic space;deep learning model;document vector;feature location technique;latent Dirichlet allocation;n-gram model;natural language text;source code;statistical pattern","","","","23","","","Sept. 29 2015-Oct. 1 2015","","IEEE","IEEE Conference Publications"
"A texture based approach for automatic identification of benign and malignant tumor from FNAC images","P. Das; T. Chatterjee; S. Chakraborty; D. Mondal; N. Das","Dept of Electronics and Communication Engineering, Neotia Institute of Technology Management and Science (NITMAS), Sarisha, West Bengal, India","2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS)","20150903","2015","","","249","254","Cancer is one of the most destructive diseases which if not detected in time, will surely lead to death. About 12 million people will be died due to cancer by 2030 as per the statistics, provided by the World Health Organization (WHO). Thus a big challenge and area of research emerges in front of both the medical practitioner and scientific researcher to fight against cancers. When a patient is suspected for the presence of malignant tumor they are advised for FNAC (Fine Needle Aspiration Cytology) test where specimens of cells can be taken in minimally invasive way with, e.g., tiny needles, with or without syringes. One of the main drawbacks of cytopathological diagnosis is the time required for an expert to visually inspect a specimen under a microscope, in search of malignant or suspicious cells and manually select them for further analysis. The present work tried to device an automated computer-aided diagnostic system specifically to reduce time and provide `second opinion' for pathologists in making diagnosis. A database of 100 FNAC images were taken on which k-fold cross-validation was performed, where k varied, for the diagnosis of malignancy. Initially, elimination of cytoplasm from the images consisting of multiple cells was done by performing saturation threshold segmentation and from the segmented nucleus boundary, meaningful texture and shape describing features are calculated using GLCM and LBP algorithms. The outcome of segmentation followed by feature extraction was tested by using the Logistic classifier which is a machine learning algorithm. The achieved diagnostic accuracy is 86%, when features obtained by combining GLCM and LBP methods, are used for classification.","","DVD:978-1-4799-8348-3; Electronic:978-1-4799-8349-0; POD:978-1-4799-8350-6","10.1109/ReTIS.2015.7232886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7232886","Benign-malignant-fine needle aspiration cytology-GLCM-LBP-Logistic classifier","Cancer;Classification algorithms;Feature extraction;Image color analysis;Image segmentation;Logistics;Machine learning algorithms","cancer;cellular biophysics;feature extraction;image classification;image segmentation;image texture;learning (artificial intelligence);medical image processing;tumours","FNAC images;GLCM algorithms;LBP algorithms;automated computer-aided diagnostic system;automatic tumor identification;benign tumor;cancer;cytopathological diagnosis;cytoplasm elimination;feature extraction;fine needle aspiration cytology;logistic classifier;machine learning algorithm;malignant tumor;saturation threshold segmentation;segmented nucleus boundary;texture based approach","","0","","11","","","9-11 July 2015","","IEEE","IEEE Conference Publications"
"O-glycosylation sites prediction using the meta-prediction approach","W. F. Lu; Y. H. Chen","Department of CSIE, Asia University, Taiwan","2015 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20151019","2015","","","1","5","Glycosylation is one of important post-translational modifications. It is the chemical modification of a protein after its translation. It is a common biological mechanism for regulating protein localization, function, cellular communication, and turnover. The function of a modified protein is often strongly affected by these modifications. Thus increased knowledge about the glycosylation of a target protein may increase our understanding of the molecular processes in these proteins. Many methods for predicting glycosylation sites in protein sequences have been developed. Finding effective meta-prediction strategies that integrate different kinds of glycosylation sites predictors to achieve higher prediction performance is highly required. In this paper, we use the framework of multiplicative update algorithms in on-line decision problem to obtain more accurate meta-predictors. The experimental results show that performances of our meta-predictor are better than Oglyc, DictyOGlyc, YinOYan, NetOGlyc, GlycoEP in O-glycosylation sites prediction.","","Electronic:978-1-4799-6926-5; POD:978-1-4799-6927-2","10.1109/CIBCB.2015.7300325","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300325","glycosylation;meta-predictor;multiplicative update algorithms;on-line decision problem","Diseases;Machine learning algorithms;Prediction algorithms;Protein engineering;Proteins;Tin;Training","biochemistry;bioinformatics;molecular biophysics;proteins","DictyOGlyc;GlycoEP;NetOGlyc;O-glycosylation sites prediction;Oglyc;YinOYan;metaprediction approach;on-line decision problem;post translational modifications;protein cellular communication;protein chemical modification;protein function;protein localization;protein turnover","","","","24","","","12-15 Aug. 2015","","IEEE","IEEE Conference Publications"
"Pedestrian detection aided by deep learning semantic tasks","Y. Tian; P. Luo; X. Wang; X. Tang","Department of Information Engineering, The Chinese University of Hong Kong, China","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","5079","5087","Deep learning methods have achieved great successes in pedestrian detection, owing to its ability to learn discriminative features from raw pixels. However, they treat pedestrian detection as a single binary classification task, which may confuse positive with hard negative samples (Fig.1 (a)). To address this ambiguity, this work jointly optimize pedestrian detection with semantic tasks, including pedestrian attributes (e.g. `carrying backpack') and scene attributes (e.g. `vehicle', `tree', and `horizontal'). Rather than expensively annotating scene attributes, we transfer attributes information from existing scene segmentation datasets to the pedestrian dataset, by proposing a novel deep model to learn high-level features from multiple tasks and multiple data sources. Since distinct tasks have distinct convergence rates and data from different datasets have different distributions, a multi-task deep model is carefully designed to coordinate tasks and reduce discrepancies among datasets. Extensive evaluations show that the proposed approach outperforms the state-of-the-art on the challenging Caltech [9] and ETH [10] datasets where it reduces the miss rates of previous deep models by 17 and 5.5 percent, respectively.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7299143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299143","","Barium;Data models;Detectors;Feature extraction;Machine learning;Semantics;Vehicles","feature extraction;image classification;learning (artificial intelligence);optimisation;pedestrians","binary classification task;deep learning method;feature learning;pedestrian detection optimization","","17","","37","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Network intrusion detection system using J48 Decision Tree","S. Sahu; B. M. Mehtre","School of Computer and Information Science, University of Hyderabad, CIAM Lab, IDRBT, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","2023","2026","As the number of cyber attacks have increased, detecting the intrusion in networks become a very tough job. For network intrusion detection system (NIDS), many data mining and machine learning techniques are used. However, for evaluation, most of the researchers used KDD Cup 99 data set, which has widely criticized for not showing current network situation. In this paper we used a new labelled network dataset, called Kyoto 2006+ dataset. In Kyoto 2006+ data set, every instant is labelled as normal (no attack), attack (known attack) and unknown attack. We use Decision Tree (J48) algorithm to classify the network packet that can be used for NIDS. For training and testing we used 134665 network instances. The generated rules works with 97.2% correctness for detecting the connection i.e., no attack, known attack or unknown attack.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275914","Data Mining;Decision tree;Intrusion Detection System;J48 algorithm;Kyoto data set","Accuracy;Data mining;Decision trees;Feature extraction;Intrusion detection;Machine learning algorithms;Support vector machines","decision trees;learning (artificial intelligence);pattern classification;security of data","J48 decision tree algorithm;KDD Cup 99 dataset;Kyoto 2006+ dataset;cyber attacks;data mining technique;machine learning technique;network intrusion detection system;network packet classification","","","","17","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Label propagation classification based on semi-supervised affinity propagation algorithm","Z. Xiao-yan","Nanjing Communications Institute of Technology, Nanjing 210094","2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","20151005","2015","","","476","481","Different position of labeled samples will bring about diverse results of Label Propagation (LP) classification algorithm. Labeled samples which are in the border region of class tend to decrease the effectiveness of LP. This paper proposes an improved LP classification method based on semi-supervised affinity propagation (AP) algorithm named as AP-LP. AP-LP runs clustering through semi-supervised AP firstly, and propagates labels of exemplars instead of labeled samples based on LP, finally transmits labels of exemplars to unlabeled samples in each cluster. LP classification does well in the case of the sampling distribution with both local consistency and global consistency. The algorithm analysis and experimental results show that the performance of AP-LP classification method is superior to LP as a whole.","","Electronic:978-1-4799-8730-6; POD:978-1-4799-8731-3; USB:978-1-4799-8729-0","10.1109/CYBER.2015.7287985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7287985","Affinity Propagation;Classification;Label Propagation;Semi-supervised","Accuracy;Algorithm design and analysis;Classification algorithms;Clustering algorithms;Iris;Machine learning algorithms;Manifolds","pattern classification;pattern clustering","AP-LP classification method;clustering;exemplars;global consistency;label propagation classification;local consistency;semisupervised affinity propagation algorithm","","","","11","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Interactive Multimodal Learning for Venue Recommendation","J. Zah√°lka; S. Rudinac; M. Worring","Intelligent Sensory Information Systems, University of Amsterdam, Amsterdam, Netherlands","IEEE Transactions on Multimedia","20151113","2015","17","12","2235","2244","In this paper, we propose City Melange, an interactive and multimodal content-based venue explorer. Our framework matches the interacting user to the users of social media platforms exhibiting similar taste. The data collection integrates location-based social networks such as Foursquare with general multimedia sharing platforms such as Flickr or Picasa. In City Melange, the user interacts with a set of images and thus implicitly with the underlying semantics. The semantic information is captured through convolutional deep net features in the visual domain and latent topics extracted using Latent Dirichlet allocation in the text domain. These are further clustered to provide representative user and venue topics. A linear SVM model learns the interacting user's preferences and determines similar users. The experiments show that our content-based approach outperforms the user-activity-based and popular vote baselines even from the early phases of interaction, while also being able to recommend mainstream venues to mainstream users and off-the-beaten-track venues to afficionados. City Melange is shown to be a well-performing venue exploration approach.","1520-9210;15209210","","10.1109/TMM.2015.2480007","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272105","Deep nets;interactive city exploration;location-based social networks;semantic concept detectors;topic models;user-centered design","Interactive systems;Machine learning;Recommender systems;Semantics;Social network services;Support vector machines","feature extraction;interactive systems;learning (artificial intelligence);pattern clustering;recommender systems;semantic networks;social networking (online);support vector machines;text analysis","City Melange;interactive multimodal learning;latent Dirichlet allocation;latent topic extraction;linear SVM model;semantic information;social media platform;text clustering;venue recommendation","","3","","35","","20150918","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Research on the Performance of Mining Packets of Educational Network for Malware Detection between PM and VM","J. Yang; J. Deng; B. Cui; H. Jin","Coll. of Comput. Sci., Beijing Univ. of posts & Telecommun., Beijing, China","2015 9th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing","20151001","2015","","","296","300","With the fast development of online education, the volume of education data traffic increased dramatically. Security information is potential to be mined from it. We can use data mining with some cloud computing platform for malware detection because the data volume is huge. The online education institutions need to virtualize their data centers and build cloud infrastructure for better using resources. So they should move data centers from physical machines(PMs) to virtual machines(VMs) for implementing the virtualization. But there are some risks such as the loss of computing ability, performance decline and so on. In this paper, we do a series of experiments to test performance of data mining algorithm based on Hadoop in physical machines and virtual machines. Through these experiments, we find that the performance of data mining algorithm based on Hadoop depends on disk I/O performance of Hadoop. The disk I/O performance of Hadoop deployed in PMs is better than that in VMs. Some iterative algorithms like k-means need more disk I/O, so we don't advise using VMs for computing. Other basic algorithms like Bayes classification need less disk I/O, so we advise computing in the VMs.","","CD-ROM:978-1-4799-8872-3; Electronic:978-1-4799-8873-0; POD:978-1-4799-8874-7","10.1109/IMIS.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284964","Cloud computing;Hadoop;Online education;Performance comparison;data mining","Classification algorithms;Cloud computing;Data mining;Education;Machine learning algorithms;Malware;Virtual machining","Bayes methods;cloud computing;computer centres;data handling;data mining;educational computing;invasive software;iterative methods;parallel processing;telecommunication traffic","Bayes classification;Hadoop;PM;VM;cloud computing;cloud infrastructure;data centers;data mining algorithm;education data traffic volume;educational network;iterative algorithms;k-means;malware detection;mining packets;online education institutions;physical machines;virtual machines","","1","","21","","","8-10 July 2015","","IEEE","IEEE Conference Publications"
"Rating Image Aesthetics Using Deep Learning","X. Lu; Z. Lin; H. Jin; J. Yang; J. Z. Wang","College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA","IEEE Transactions on Multimedia","20151026","2015","17","11","2021","2034","This paper investigates unified feature learning and classifier training approaches for image aesthetics assessment . Existing methods built upon handcrafted or generic image features and developed machine learning and statistical modeling techniques utilizing training examples. We adopt a novel deep neural network approach to allow unified feature learning and classifier training to estimate image aesthetics. In particular, we develop a double-column deep convolutional neural network to support heterogeneous inputs, i.e., global and local views, in order to capture both global and local characteristics of images . In addition, we employ the style and semantic attributes of images to further boost the aesthetics categorization performance . Experimental results show that our approach produces significantly better results than the earlier reported results on the AVA dataset for both the generic image aesthetics and content -based image aesthetics. Moreover, we introduce a 1.5-million image dataset (IAD) for image aesthetics assessment and we further boost the performance on the AVA test set by training the proposed deep neural networks on the IAD dataset.","1520-9210;15209210","","10.1109/TMM.2015.2477040","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243357","Automatic feature learning;deep neural networks;image aesthetics","Computer architecture;Image color analysis;Machine learning;Neural networks;Semantics;Training;Visualization","convolution;image classification;learning (artificial intelligence);neural nets","AVA dataset;IAD;classifier training approaches;content -based image aesthetics;double-column deep convolutional neural network;generic image aesthetics;image aesthetics assessment;machine learning;novel deep neural network approach;statistical modeling techniques;unified feature learning","","6","","32","","20150904","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"A Cooperative Coevolution Framework for Parallel Learning to Rank","S. Wang; Y. Wu; B. J. Gao; K. Wang; H. W. Lauw; J. Ma","Department of Computer Science and Information Systems, University of Jyv&#228;skyl&#228;, Mattilanniemi 2, Jyv&#228;skyl&#228;, Finland","IEEE Transactions on Knowledge and Data Engineering","20151104","2015","27","12","3152","3165","We propose CCRank, the first parallel framework for learning to rank based on evolutionary algorithms (EA), aiming to significantly improve learning efficiency while maintaining accuracy. CCRank is based on cooperative coevolution (CC), a divide-and-conquer framework that has demonstrated high promise in function optimization for problems with large search space and complex structures. Moreover, CC naturally allows parallelization of sub-solutions to the decomposed sub-problems, which can substantially boost learning efficiency. With CCRank, we investigate parallel CC in the context of learning to rank. We implement CCRank with three EA-based learning to rank algorithms for demonstration. Extensive experiments on benchmark datasets in comparison with the state-of-the-art algorithms show the performance gains of CCRank in efficiency and accuracy.","1041-4347;10414347","","10.1109/TKDE.2015.2453952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152946","Cooperative Coevolution;Cooperative coevolution;Genetic Programming;Immune Programming;Information Retrieval;Learning to Rank;genetic programming;immune programming;information retrieval;learning to rank","Cooperative systems;Evolutionary computation;Genetic programming;Information retrieval;Machine learning algorithms;Ranking (statistics);Sociology","divide and conquer methods;evolutionary computation;learning (artificial intelligence)","CC;CCRank;EA;benchmark datasets;complex structures;cooperative coevolution framework;divide-and-conquer framework;evolutionary algorithms;function optimization;learning efficiency;parallel learning to rank;search space","","0","","55","","20150708","Dec. 1 2015","","IEEE","IEEE Journals & Magazines"
"An Empirical Study of Classifier Combination for Cross-Project Defect Prediction","Y. Zhang; D. Lo; X. Xia; J. Sun","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","2","","264","269","To help developers better allocate testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on past history of buggy classes. These techniques work well as long as a sufficient amount of data is available to train a prediction model. However, there is rarely enough training data for new software projects. To deal with this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, has been proposed and is regarded as a new challenge for defect prediction. So far, only a few cross-project defect prediction techniques have been proposed. To advance the state-of-the-art, in this work, we investigate 7 composite algorithms, which integrate multiple machine learning classifiers, to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we perform experiments on 10 open source software systems from the PROMISE repository which contain a total of 5,305 instances labeled as defective or clean. We compare the composite algorithms with CODEP Logistic, which is the latest cross-project defect prediction algorithm proposed by Panichella et al., in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experiment results show that several algorithms outperform CODEP Logistic: Max performs the best in terms of F-measure and its average F-measure outperforms that of CODEP Logistic by 36.88%. Bagging J48 performs the best in terms of cost effectiveness and its average cost effectiveness outperforms that of CODEP Logistic by 15.34%.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273627","Classifier Combination;Cross-Project;Defect Prediction","Decision trees;Machine learning algorithms;Measurement;Prediction algorithms;Predictive models;Software;Training","learning (artificial intelligence);pattern classification;program debugging;program testing;public domain software","CODEP logistic;F-measure;PROMISE repository;buggy class;classifier combination;composite algorithm;cost effectiveness;cross-project defect prediction algorithm;cross-project defect prediction technique;evaluation metric;machine learning classifier;open source software system;performance evaluation;prediction model;software debugging;software defect prediction technique;software project;software testing","","5","","30","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Urban classification using PolSAR data and deep learning","S. De; A. Bhattacharya","Indian Institute of Technology Bombay","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20151112","2015","","","353","356","The urban classification of PolSAR images is made difficult by the characteristic of a rotated target to exhibit volume scattering. In this paper we use a deep learning technique in conjunction with some statistical parameters to learn to classify urban areas irrespective of the rotation. The learning algorithm was trained to differentiate urban from non-urban areas and was able to achieve a 8.5834% validation accuracy and 6.554% test accuracy.","2153-6996;21536996","Electronic:978-1-4799-7929-5; POD:978-1-4799-7930-1; USB:978-1-4799-7928-8","10.1109/IGARSS.2015.7325773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325773","Classification;Deep Learning;POLSAR","Accuracy;Machine learning;Scattering;Synthetic aperture radar;Training;Urban areas","geophysical image processing;geophysical techniques;remote sensing by radar;synthetic aperture radar","PolSAR data;PolSAR images;deep learning technique;learning algorithm;rotated target;urban classification;volume scattering","","2","","10","","","26-31 July 2015","","IEEE","IEEE Conference Publications"
"DeepContour: A deep convolutional feature learned by positive-sharing loss for contour detection","Wei Shen; Xinggang Wang; Yan Wang; Xiang Bai; Z. Zhang","Key Lab of Specialty Fiber Optics and Optical Access Networks, Shanghai University, China","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","3982","3991","Contour detection serves as the basis of a variety of computer vision tasks such as image segmentation and object recognition. The mainstream works to address this problem focus on designing engineered gradient features. In this work, we show that contour detection accuracy can be improved by instead making the use of the deep features learned from convolutional neural networks (CNNs). While rather than using the networks as a blackbox feature extractor, we customize the training strategy by partitioning contour (positive) data into subclasses and fitting each subclass by different model parameters. A new loss function, named positive-sharing loss, in which each subclass shares the loss for the whole positive class, is proposed to learn the parameters. Compared to the sofmax loss function, the proposed one, introduces an extra regularizer to emphasizes the losses for the positive and negative classes, which facilitates to explore more discriminative features. Our experimental results demonstrate that learned deep features can achieve top performance on Berkeley Segmentation Dataset and Benchmark (BSDS500) and obtain competitive cross dataset generalization result on the NYUD dataset.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7299024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299024","","Data models;Feature extraction;Machine learning;Neural networks;Shape;Standards;Training","computer vision;convolution;feature extraction;image segmentation;neural nets;visual databases","BSDS500;Berkeley segmentation dataset and benchmark;CNN;DeepContour;NYUD dataset;blackbox feature extractor;computer vision tasks;contour detection accuracy;convolutional neural networks;cross dataset generalization;deep convolutional feature;discriminative features;engineered gradient features;image segmentation;negative classes;object recognition;positive classes;positive-sharing loss;sofmax loss function;training strategy","","","","48","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Predictive Deep Boltzmann Machine for Multiperiod Wind Speed Forecasting","C. Y. Zhang; C. L. P. Chen; M. Gan; L. Chen","Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, China","IEEE Transactions on Sustainable Energy","20150916","2015","6","4","1416","1425","It is important to forecast the wind speed for managing operations in wind power plants. However, wind speed prediction is extremely complex and difficult due to the volatility and deviation of the wind. As existing forecasting methods directly model the raw wind speed data, it is difficult for them to provide higher inference accuracy. Differently, this paper presents a sophisticated deep-learning technique for short-term and long-term wind speed forecast, i.e., the predictive deep Boltzmann machine (PDBM) and corresponding learning algorithm. The proposed deep model forecasts wind speed by analyzing the higher level features abstracted from lower level features of the wind speed data. These automatically learnt features are very informative and appropriate for the prediction. The proposed PDBM is a deep stochastic model that can represent the wind speed very well, and is inspired by two aspects. 1) The stochastic model is suitable to capture the probabilistic characteristics of wind speed. 2) Recent developments in neural networks with deep architectures show that deep generative models have competitive capability to approximate nonlinear and nonsmooth functions. The evaluation of the proposed PDBM model is depicted by both hour-ahead and day-ahead prediction experiments based on real wind speed datasets. The prediction accuracy of the PDBM model outperforms existing methods by more than 10%.","1949-3029;19493029","","10.1109/TSTE.2015.2434387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7145470","Deep Boltzmann machine (DBM);deep learning;time series;wind speed prediction","Machine learning;Predictive models;Time series analysis;Training;Wind forecasting;Wind power generation;Wind speed","Boltzmann machines;load forecasting;power system management;stochastic processes;wind power plants","long-term wind speed forecast;multiperiod wind speed forecasting;predictive deep Boltzmann machine;short-term wind speed forecast;stochastic model;wind power plants;wind speed prediction","","7","","40","","20150701","Oct. 2015","","IEEE","IEEE Journals & Magazines"
"DeepEdge: A multi-scale bifurcated deep network for top-down contour detection","G. Bertasius; J. Shi; L. Torresani","University of Pennsylvania, Philadelphia, 19104, United States","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","4380","4389","Contour detection has been a fundamental component in many image segmentation and object detection systems. Most previous work utilizes low-level features such as texture or saliency to detect contours and then use them as cues for a higher-level task such as object detection. However, we claim that recognizing objects and predicting contours are two mutually related tasks. Contrary to traditional approaches, we show that we can invert the commonly established pipeline: instead of detecting contours with low-level cues for a higher-level recognition task, we exploit object-related features as high-level cues for contour detection.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7299067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299067","","Computer architecture;Convolutional codes;Feature extraction;Image edge detection;Machine learning;Object detection;Training","edge detection;image segmentation;image texture;object detection","DeepEdge;image saliency;image segmentation;image texture;multiscale bifurcated deep network;object detection systems;object-related features;top-down contour detection","","18","","34","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"A Preliminary Study on Deep-Learning Based Screaming Sound Detection","M. Z. Zaheer; J. Y. Kim; H. G. Kim; S. Y. Na","Dept. of Electron. & Comput. Eng., Chonnam Nat. Univ., Gwangju, South Korea","2015 5th International Conference on IT Convergence and Security (ICITCS)","20151008","2015","","","1","4","In addition to the traditional video surveillance, various audio processing techniques can also be added to the existing CCTV cameras. They can be used as additional features to help in analyzing the scene better and autonomously detecting violence or any unwanted activity in the scene. For this purpose, a deep learning based scream sound detection approach is proposed in this paper. MFCC features after interpolation are used as input of the system. The proposed system is experimented using a self-recorded scream database and with controlled and calculated parameters 100 % accuracy is achieved.","","Electronic:978-1-4673-6537-6; POD:978-1-4673-6538-3","10.1109/ICITCS.2015.7292925","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7292925","","Accuracy;Cameras;Feature extraction;Machine learning;Mel frequency cepstral coefficient;Surveillance;Training","audio signal processing;feature extraction;interpolation;learning (artificial intelligence);signal detection","CCTV cameras;MFCC features;audio processing techniques;deep learning based scream sound detection approach;interpolation;self-recorded scream database;video surveillance","","","","11","","","24-27 Aug. 2015","","IEEE","IEEE Conference Publications"
"Deep learning and its application to general image classification","P. H. Liu; S. F. Su; M. C. Chen; C. C. Hsiao","Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan","2015 International Conference on Informative and Cybernetics for Computational Social Systems (ICCSS)","20151001","2015","","","7","10","Deep learning has recently exhibited good performance in many applications. The convolution neural network is an often-used architecture for deep learning and has been widely used in computer vision and audio recognition, and outperformed other related handcraft designed feature in recent years. These techniques compared to other artificial intelligence algorithms and handcraft features need extremely much more time in training and testing and then were not widely used in the early days. Our study is about the impacts of different factors used in the convolution neural network. The considered factors are network depth, numbers of filters, and filter sizes. The used data set is the CIFAR dataset. According to our experiments, some suggestions about those factors are recommended in this study.","","CD-ROM:978-1-4673-7244-2; Electronic:978-1-4673-7245-9; POD:978-1-4673-7246-6","10.1109/ICCSS.2015.7281139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281139","CIFAR dataset;Deep learning;convolution neural network","Accuracy;Biological neural networks;Computer architecture;Convolution;Machine learning;Training","filtering theory;image classification;learning (artificial intelligence);multilayer perceptrons","CIFAR dataset;convolution neural network;deep learning;filters;image classification;multilayer perceptron;network depth","","","","17","","","13-15 Aug. 2015","","IEEE","IEEE Conference Publications"
"A comparative study for chest radiograph image retrieval using binary texture and deep learning classification","Y. Anavi; I. Kogan; E. Gelbart; O. Geva; H. Greenspan","Medical Image Processing Lab, Department of Biomedical Engineering, Faculty of Engineering, Tel Aviv University, Israel","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","2940","2943","In this work various approaches are investigated for X-ray image retrieval and specifically chest pathology retrieval. Given a query image taken from a data set of 443 images, the objective is to rank images according to similarity. Different features, including binary features, texture features, and deep learning (CNN) features are examined. In addition, two approaches are investigated for the retrieval task. One approach is based on the distance of image descriptors using the above features (hereon termed the ‚Äúdescriptor‚Äù-based approach); the second approach (‚Äúclassification‚Äù-based approach) is based on a probability descriptor, generated by a pair-wise classification of each two classes (pathologies) and their decision values using an SVM classifier. Best results are achieved using deep learning features in a classification scheme.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7319008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319008","","Biomedical imaging;Feature extraction;Heart;Machine learning;Measurement;Pathology;Support vector machines","diagnostic radiography;image classification;image retrieval;image texture;learning (artificial intelligence);medical image processing;probability;support vector machines","CNN;SVM classifier;X-ray image retrieval;binary features;binary texture;chest pathology retrieval;chest radiograph image retrieval;classification-based approach;decision values;deep learning classification;deep learning features;descriptor-based approach;image descriptors;pair-wise classification;probability descriptor;query image;texture features","","2","","12","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"A Deep Learning Method Combined Sparse Autoencoder with SVM","Y. Ju; J. Guo; S. Liu","Comput. Center Dept., East China Normal Univ., Shanghai, China","2015 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20151029","2015","","","257","260","In this paper, a novel unsupervised method for learning sparse features combined with support vector machines for classification is proposed. The classical SVM method has restrictions on the large-scale applications. This model uses sparse auto encoder, a deep learning algorithm, to improve the performance. Firstly, we use multiple layers of sparse auto encoder to learn the features of the data. Secondly, we use SVM to classify. Many experimental results show that compared with SVM, our proposed method can improve the classification rate. In particular, it can effectively deal with large-scale data sets.","","Electronic:978-1-4673-9200-6; POD:978-1-4673-9201-3","10.1109/CyberC.2015.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307823","SVM;deep learning;sparse autoencoder;unsupervised learning","Classification algorithms;Data models;Feature extraction;Kernel;Machine learning;Support vector machines;Training","encoding;pattern classification;support vector machines;unsupervised learning","SVM;data classification;deep learning algorithm;sparse autoencoder;support vector machine;unsupervised learning method","","","","13","","","17-19 Sept. 2015","","IEEE","IEEE Conference Publications"
"A-Wristocracy: Deep learning on wrist-worn sensing for recognition of user complex activities","P. Vepakomma; D. De; S. K. Das; S. Bhansali","Department of Electrical and Computer Engineering, Florida International University","2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN)","20151019","2015","","","1","6","In this work we present A-Wristocracy, a novel framework for recognizing very fine-grained and complex inhome activities of human users (particularly elderly people) with wrist-worn device sensing. Our designed A-Wristocracy system improves upon the state-of-the-art works on in-home activity recognition using wearables. These works are mostly able to detect coarse-grained ADLs (Activities of Daily Living) but not large number of fine-grained and complex IADLs (Instrumental Activities of Daily Living). These are also not able to distinguish similar activities but with different context (such as sit on floor vs. sit on bed vs. sit on sofa). Our solution helps accurate detection of in-home ADLs/ IADLs and contextual activities, which are all critically important for remote elderly care in tracking their physical and cognitive capabilities. A-Wristocracy makes it feasible to classify large number of fine-grained and complex activities, through Deep Learning based data analytics and exploiting multi-modal sensing on wrist-worn device. It exploits minimal functionality from very light additional infrastructure (through only few Bluetooth beacons), for coarse level location context. A-Wristocracy preserves direct user privacy by excluding camera/ video imaging on wearable or infrastructure. The classification procedure consists of practical feature set extraction from multi-modal wearable sensor suites, followed by Deep Learning based supervised fine-level classification algorithm. We have collected exhaustive home-based ADLs and IADLs data from multiple users. Our designed classifier is validated to be able to recognize very fine-grained complex 22 daily activities (much larger number than 6-12 activities detected by state-of-the-art works using wearable and no camera/ video) with high average test accuracies of 90% or more for two users in two different home environments.","2376-8886;23768886","Electronic:978-1-4673-7201-5; POD:978-1-4673-7202-2","10.1109/BSN.2015.7299406","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299406","","Accelerometers;Accuracy;Biomedical monitoring;Bluetooth;Context;Machine learning;Sensors","biomechanics;body sensor networks;geriatrics;patient care;telemedicine","A-Wristocracy system;Bluetooth;camera- video imaging;cognitive capability;data analytics;home environment;home-based IADL data;inhome ADL- IADL detection;inhome activity recognition;inhome user activity;multimodal wearable sensor suite;physical capability;remote elderly care;supervised fine-level classification algorithm;user complex activity recognition;user privacy;wrist-worn device sensing","","","","17","","","9-12 June 2015","","IEEE","IEEE Conference Publications"
"A hybrid recorded-synthetic sonar data set for validation of ASW classification algorithms","K. T. Hjelmervik; H. Berg; D. H. S. Stender; T. S. S√•stad","Norwegian Defence Research Establishment (FFI) Horten, Norway","OCEANS 2015 - Genova","20150921","2015","","","1","5","Modern anti-submarine warfare sonars are often designed with narrow beamwidths and wide frequency bandwidths in order to maximize spatial resolution and sonar performance. A known issue for high-resolution sonars in littoral environments, is the occurence of high false alarm rates. Increased false alarm rates increase the workload of sonar operators and also reduces the usefullness of automatic systems such as autonomous underwater vehicles, since their limited communication abilities hinder them from sharing large amounts of contacts. The false alarm rate may be reduced simply by increasing the threshold used in the detection process. However, this also reduces the probability of detecting actual targets. Automatic classification algorithms provide more sophisticated alternatives for false alarm reduction. The work presented here demonstrates an automatic classification algorithm on a data set collected in a littoral environment. The data set contains a large amount of false alarms, particularly close to the coast, but does not contain any submarine target detections. Synthetic submarine echoes are therefore added to the sonar data set. Six features are extracted from the hybrid synthetic-recorded data set. The features are fed into supervised machine learning schemes. The performance of each scheme is presented as receiver operating characteristic curves.","","Electronic:978-1-4799-8736-8; POD:978-1-4799-8737-5","10.1109/OCEANS-Genova.2015.7271508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271508","","Feature extraction;Machine learning algorithms;Neural networks;Signal to noise ratio;Sonar;Training;Underwater vehicles","autonomous underwater vehicles;echo suppression;electronic warfare;learning (artificial intelligence);object detection;sensitivity analysis;signal classification;sonar detection;sonar signal processing;synthetic aperture sonar","ASW classification algorithm;antisubmarine warfare sonar;false alarm rate;false alarm reduction;hybrid recorded synthetic sonar data set;littoral environment;receiver operating characteristic curve;spatial resolution maximisation;submarine target detection;supervised machine learning scheme;synthetic submarine echo","","1","","24","","","18-21 May 2015","","IEEE","IEEE Conference Publications"
"Deep hierarchical representation and segmentation of high resolution remote sensing images","J. Wang; Q. Qin; Z. Li; X. Ye; J. Wang; X. Yang; X. Qin","Institute of Remote Sensing and GIS, Peking University, Beijing, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20151112","2015","","","4320","4323","This paper presents a novel deep hierarchical representation and segmentation approach for high resolution remote sensing image understanding. An information extraction approach using deep hierarchical exploitation for remote sensing image is presented. The key idea is that we adopt a fast scanning image segmentation within a deep hierarchical feature representation framework, using a deep learning technique to split and merge over-segmented regions until they form meaningful objects. The contribution is to develop an effective procedure for multi-scale image representation to address the issue of information uncertainty in practical applications. We test our method on two optical high resolution remote sensing image datasets and produce promising experimental results in the form of multiple layer outputs, which confirm the effectiveness and robustness of the proposed procedure.","2153-6996;21536996","Electronic:978-1-4799-7929-5; POD:978-1-4799-7930-1; USB:978-1-4799-7928-8","10.1109/IGARSS.2015.7326782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326782","Hierarchical representation;High resolution remote sensing images;Image segmentation","Clustering algorithms;Image segmentation;Machine learning;Merging;Remote sensing;Spatial resolution","feature extraction;image representation;image segmentation;remote sensing","deep hierarchical feature representation framework;deep learning technique;feature extraction;high resolution remote sensing image segmentation;image representation;optical high resolution remote sensing image dataset","","1","","5","","","26-31 July 2015","","IEEE","IEEE Conference Publications"
"Symbolic Aggregate approXimation (SAX) under interval uncertainty","C. D. Stylios; V. Kreinovich","Laboratory of Knowledge and Intelligent Computing, Department of Computer Engineering, Technological Educational Institute of Epirus, 47100 Kostakioi, Arta, Greece","2015 Annual Conference of the North American Fuzzy Information Processing Society (NAFIPS) held jointly with 2015 5th World Conference on Soft Computing (WConSC)","20151001","2015","","","1","7","In many practical situations, we monitor a system by continuously measuring the corresponding quantities, to make sure that any abnormal deviation is detected as early as possible. Often, we do not have readily available algorithms to detect abnormality, so we need to use machine learning techniques. For these techniques to be efficient, we first need to compress the data. One of the most successful methods of data compression is the technique of Symbolic Aggregate approXimation (SAX); see, e.g., [10]. While this technique is motivated by measurement uncertainty, it does not explicitly take this uncertainty into account. In this paper, we show that we can further improve upon this techniques if we explicitly take measurement uncertainty into account.","","Electronic:978-1-4673-7248-0; POD:978-1-4673-7249-7; USB:978-1-4673-7247-3","10.1109/NAFIPS-WConSC.2015.7284164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284164","","Accuracy;Approximation methods;Integral equations;Machine learning algorithms;Measurement uncertainty;Monitoring;Optimization","data compression;learning (artificial intelligence);measurement uncertainty;uncertainty handling","SAX;abnormal deviation;data compression;interval uncertainty;machine learning technique;measurement uncertainty;symbolic aggregate approximation","","","","12","","","17-19 Aug. 2015","","IEEE","IEEE Conference Publications"
"Multi-manifold deep metric learning for image set classification","J. Lu; G. Wang; W. Deng; P. Moulin; J. Zhou","Advanced Digital Sciences Center, Singapore","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","1137","1145","In this paper, we propose a multi-manifold deep metric learning (MMDML) method for image set classification, which aims to recognize an object of interest from a set of image instances captured from varying viewpoints or under varying illuminations. Motivated by the fact that manifold can be effectively used to model the nonlinearity of samples in each image set and deep learning has demonstrated superb capability to model the nonlinearity of samples, we propose a MMDML method to learn multiple sets of nonlinear transformations, one set for each object class, to nonlinearly map multiple sets of image instances into a shared feature subspace, under which the manifold margin of different class is maximized, so that both discriminative and class-specific information can be exploited, simultaneously. Our method achieves the state-of-the-art performance on five widely used datasets.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298717","","Computational modeling;Face;Legged locomotion;Machine learning;Manifolds;Testing;Training","image classification;learning (artificial intelligence);object recognition","MMDML;class-specific information;discriminative information;image instances;image set classification;multimanifold deep metric learning;object recognition","","8","","40","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Parallel computation of information gain using Hadoop and MapReduce","E. Zdravevski; P. Lameski; A. Kulakov; S. Filiposka; D. Trajanov; B. Jakimovskik","Faculty of Computer Science and Engineering, Ss.Cyril and Methodius University, Skopje, Macedonia","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","181","192","Nowadays, companies collect data at an increasingly high rate to the extent that traditional implementation of algorithms cannot cope with it in reasonable time. On the other hand, analysis of the available data is a key to the business success. In a Big Data setting tasks like feature selection, finding discretization thresholds of continuous data, building decision threes, etc are especially difficult. In this paper we discuss how a parallel implementation of the algorithm for computing the information gain can address these issues. Our approach is based on writing Pig Latin scripts that are compiled into MapReduce jobs which then can be executed on Hadoop clusters. In order to implement the algorithm first we define a framework for developing arbitrary algorithms and then we apply it for the task at hand. With intent to analyze the impact of the parallelization, we have processed the FedCSIS AAIA'14 dataset with the proposed implementation of the information gain. During the experiments we evaluate the speedup of the parallelization compared to a one-node cluster. We also analyze how to optimally determine the number of map and reduce tasks for a given cluster. To demonstrate the portability of the implementation we present results using an on-premises and Amazon AWS clusters. Finally, we illustrate the scalability of the implementation by evaluating it on a replicated version of the same dataset which is 80 times larger than the original.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321440","Hadoop;MapReduce;feature ranking;information gain;parallelization","Entropy;Loading;Machine learning algorithms;Mathematical model;Parallel processing;Servers;Writing","Big Data;information dissemination;parallel processing","Amazon AWS cluster;Big data;FedCSIS AAIA'14 dataset;Hadoop;MapReduce;Pig Latin script;information gain;parallel computation","","1","","46","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"An improved deep learning architecture for person re-identification","E. Ahmed; M. Jones; T. K. Marks","University of Maryland, 3364 A.V. Williams, College Park, 20740, United States","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","3908","3916","In this work, we propose a method for simultaneously learning features and a corresponding similarity metric for person re-identification. We present a deep convolutional architecture with layers specially designed to address the problem of re-identification. Given a pair of images as input, our network outputs a similarity value indicating whether the two input images depict the same person. Novel elements of our architecture include a layer that computes cross-input neighborhood differences, which capture local relationships between the two input images based on mid-level features from each input image. A high-level summary of the outputs of this layer is computed by a layer of patch summary features, which are then spatially integrated in subsequent layers. Our method significantly outperforms the state of the art on both a large data set (CUHK03) and a medium-sized data set (CUHK01), and is resistant to over-fitting. We also demonstrate that by initially training on an unrelated large data set before fine-tuning on a small target data set, our network can achieve results comparable to the state of the art even on a small data set (VIPeR).","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7299016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299016","","Computer architecture;Convolution;Feature extraction;Image color analysis;Machine learning;Measurement;Training","image recognition;learning (artificial intelligence)","cross-input neighborhood differences;deep convolutional architecture;deep learning architecture;feature learning;local relationships;person reidentification;similarity metric","","40","1","32","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Constrained feature selection for localizing faults","T. D. B. Le; D. Lo; M. Li","School of Information Systems, Singapore Management University, Singapore","2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)","20151123","2015","","","501","505","Developers often take much time and effort to find buggy program elements. To help developers debug, many past studies have proposed spectrum-based fault localization techniques. These techniques compare and contrast correct and faulty execution traces and highlight suspicious program elements. In this work, we propose constrained feature selection algorithms that we use to localize faults. Feature selection algorithms are commonly used to identify important features that are helpful for a classification task. By mapping an execution trace to a classification instance and a program element to a feature, we can transform fault localization to the feature selection problem. Unfortunately, existing feature selection algorithms do not perform too well, and we extend its performance by adding a constraint to the feature selection formulation based on a specific characteristic of the fault localization problem. We have performed experiments on a popular benchmark containing 154 faulty versions from 8 programs and demonstrate that several variants of our approach can outperform many fault localization techniques proposed in the literature. Using Wilcoxon rank-sum test and Cliff's d effect size, we also show that the improvements are both statistically significant and substantial.","","Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3","10.1109/ICSM.2015.7332502","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332502","","Benchmark testing;Computer bugs;Feature extraction;Information systems;Machine learning algorithms;Software;Standards","feature selection;program debugging","Cliffs d effect size;Wilcoxon rank-sum test;classification instance;constrained feature selection algorithms;execution trace mapping;fault localization;programs","","1","","14","","","Sept. 29 2015-Oct. 1 2015","","IEEE","IEEE Conference Publications"
"How Many Ground Truths Should We Insert? Having Good Quality of Labeling Tasks in Crowdsourcing","T. Kubota; M. Aritsugi","Grad. Sch. of Sci. & Technol., Kumamoto Univ., Kumamoto, Japan","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","2","","796","805","Having a lot of labels of good quality by crowd sourcing has attracted considerable interest recently. Ground truths can be helpful to this end, but prior work does not adequately address how many ground truths should be used. This paper presents a method for determining the number of ground truths. The number is determined by iteratively calculating the expected quality of labels if a ground truth is inserted into labeling tasks and comparing it with the limit of estimation quality of labels expectedly obtained by crowd sourcing. Our method can be applied to general EM algorithm-based approaches to estimating consensus labels of good quality. We compare our method with an EM algorithm-based approach, which is adopted to our method in the discussions of this paper, in terms of both efficiency of collecting labels from crowd and quality of labels obtained from the collected ones.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273702","Condorcet Jury Theorem;EM algorithm;human computation","Computational complexity;Crowdsourcing;Estimation;Labeling;Machine learning algorithms;Mathematical model;Proposals","data analysis;expectation-maximisation algorithm;learning (artificial intelligence)","EM algorithm-based approach;consensus label estimation;crowdsourcing;labeling task quality;machine learning","","","","18","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"The implementation of reinforcement learning algorithms on the elevator control system","H. Li","Institute of Automation and Information System, Technische Universit&#x00E4;t M&#x00FC;nchen, Garching near Munich, Germany","2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA)","20151026","2015","","","1","4","The machine learning technology has been implemented in control systems successfully especially in the stochastic process. Among the machine learning algorithms, the reinforcement learning algorithm is fairly significant. On the other hand, the elevator, as a facility in daily life, is implemented with several heuristic control methods in the past practice. Simultaneously, the elevator working procedure can be viewed as a stochastic process, so this paper tries to discuss the implementation of several reinforcement learning algorithms on the elevator control system. Through the application of the reinforcement learning algorithms, the elevator system can perform better.","1946-0740;19460740","Electronic:978-1-4673-7929-8; POD:978-1-4673-7930-4; USB:978-1-4673-7928-1","10.1109/ETFA.2015.7301554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7301554","Q-learning;elevator control system;reinforcement algorithms","Algorithm design and analysis;Control systems;Elevators;Floors;Learning (artificial intelligence);Machine learning algorithms;Stochastic processes","control engineering computing;learning (artificial intelligence);lifts;stochastic systems","elevator control system;elevator working procedure;heuristic control methods;machine learning technology;reinforcement learning algorithms;stochastic process","","1","","13","","","8-11 Sept. 2015","","IEEE","IEEE Conference Publications"
"Interleaved text/image Deep Mining on a large-scale radiology database","H. C. Shin; Le Lu; L. Kim; A. Seff; J. Yao; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory Radiology and Imaging Sciences, National Institutes of Health Clinical Center, Bethesda, MD 20892-1182, United States","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","1090","1099","Despite tremendous progress in computer vision, effective learning on very large-scale (> 100K patients) medical image databases has been vastly hindered. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's picture archiving and communication system. Instead of using full 3D medical volumes, we focus on a collection of representative ~216K 2D key images/slices (selected by clinicians for diagnostic reference) with text-driven scalar and vector labels. Our system interleaves between unsupervised learning (e.g., latent Dirichlet allocation, recurrent neural net language models) on document- and sentence-level texts to generate semantic labels and supervised learning via deep convolutional neural networks (CNNs) to map from images to label spaces. Disease-related key words can be predicted for radiology images in a retrieval manner. We have demonstrated promising quantitative and qualitative results. The large-scale datasets of extracted key images and their categorization, embedded vector labels and sentence descriptions can be harnessed to alleviate the deep learning ‚Äúdata-hungry‚Äù obstacle in the medical domain.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298712","","Machine learning;Medical diagnostic imaging;Radiology;Semantics;Visualization","PACS;computer vision;data mining;image retrieval;learning (artificial intelligence);medical image processing;radiology;recurrent neural nets;text analysis","3D medical volume;CNN;computer vision;data-hungry obstacle;deep convolutional neural network;document-level text;embedded vector label;extracted key image;interleaved text/image deep learning system;interleaved text/image deep mining;large-scale radiology database;latent Dirichlet allocation;national research hospital;picture archiving and communication system;radiology image;recurrent neural net language model;retrieval manner;semantic interaction;semantic label;sentence description;sentence-level text;unsupervised learning;very large-scale medical image database","","3","","47","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Data mining technique for identification of diagnostic biomarker to predict Schizophrenia disorder","R. GeethaRamani; K. Sivaselvi","Department of Information Science and Technology, CEG, Anna University, Guindy, Chennai, India","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","8","In recent days, researchers are actively analysing the human brain to understand the underlying mechanism of heterogeneous psychiatric conditions. Schizophrenia is a severe neurological disorder which has been characterized by varying symptoms namely hallucinations, delusions and cognitive problems. In this paper, we have investigated the resting state fMRI images of 15 normal controls and 12 Schizophrenia patients by constructing functional connectome through image preprocessing techniques namely Realignment, temporal correction, filtering, etc., The parcellation of neuroimage is performed based on Automated Anatomical Labelling (AAL) atlas and 74 regions of interest (ROI) are identified. Functional connectome of each subject includes Pearson correlation values of mean time courses obtained between the regions. These region to region functional connectivity is considered as features and the feature selection technique namely Fisher filtering, ReliefF filtering and Runs filtering are applied. Then the features which are found by different filtering techniques are fed as input to the supervised non linear classifiers namely Random forest, C4.5, Cost sensitive classification and regression tree and K-Nearest Neighbour classification algorithm. These algorithms have produced classification rules which are used in the prediction of Schizophrenia disorder. C4.5 has achieved the higher predictive accuracy of 93% with leave-one out cross-validation and the predominant feature or diagnostic biomarker is obtained from the rule. This feature is one among the commonly identified feature of different feature selection techniques. The work has shown that the biomarker corresponds to the alterations in the functional connectivity between the brain regions namely Rolandic operculum and Postcentral gyrus of brain's left hemisphere which is involved in sensorimotor function of human.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238525","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238525","Classification;Feature selection;Functional connectivity;Resting state fMRI;Schizophrenia","Accuracy;Classification algorithms;Decision trees;Filtering;Filtering algorithms;Machine learning algorithms;Vegetation","biomedical MRI;data mining;diseases;filtering theory;image classification;learning (artificial intelligence);medical image processing;regression analysis;trees (mathematics)","AAL atlas;C4.5;Fisher filtering;Pearson correlation;Postcentral gyrus;ReliefF filtering;Rolandic operculum;Runs filtering;Schizophrenia disorder;automated anatomical labelling;cost sensitive classification;data mining technique;diagnostic biomarker identification;functional connectivity;image preprocessing technique;k-nearest neighbour classification algorithm;neurological disorder;random forest;regions of interest;regression tree;state fMRI images;supervised nonlinear classifiers","","0","","41","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Analyzing Android Encrypted Network Traffic to Identify User Actions","M. Conti; L. V. Mancini; R. Spolaor; N. V. Verde","Dipartimento di Matematica, Universit&#224; di Padova, Padua, Italy","IEEE Transactions on Information Forensics and Security","20151030","2016","11","1","114","125","Mobile devices can be maliciously exploited to violate the privacy of people. In most attack scenarios, the adversary takes the local or remote control of the mobile device, by leveraging a vulnerability of the system, hence sending back the collected information to some remote web service. In this paper, we consider a different adversary, who does not interact actively with the mobile device, but he is able to eavesdrop the network traffic of the device from the network side (e.g., controlling a Wi-Fi access point). The fact that the network traffic is often encrypted makes the attack even more challenging. In this paper, we investigate to what extent such an external attacker can identify the specific actions that a user is performing on her mobile apps. We design a system that achieves this goal using advanced machine learning techniques. We built a complete implementation of this system, and we also run a thorough set of experiments, which show that our attack can achieve accuracy and precision higher than 95%, for most of the considered actions. We compared our solution with the three state-of-the-art algorithms, and confirming that our system outperforms all these direct competitors.","1556-6013;15566013","","10.1109/TIFS.2015.2478741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265055","Cellular phones;information security;privacy","Cryptography;IP networks;Machine learning algorithms;Mobile communication;Mobile handsets;Privacy;Time series analysis","Web services;cryptography;data privacy;learning (artificial intelligence);mobile computing;smart phones;telecommunication traffic","Android encrypted network traffic;advanced machine learning technique;mobile application;mobile device;remote Web service;remote control","","3","","43","","20150914","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Study on weak bit in Vote Count and its application in k-Nearest Neighbors Algorithm","H. Shu; W. Jiang; R. Yu","Institute for Infocomm Research, A*STAR, Singapore 138632","2015 IEEE 10th Conference on Industrial Electronics and Applications (ICIEA)","20151123","2015","","","119","122","In the Vote Count for k-Nearest Neighbors (kNN) algorithm, the quantized projection values of query and training/reference vectors are compared and counted. In this process, not all quantized projection results are reliable for bit-matching and the search result may be distorted by these unreliable bit-matching. In this paper, the concept of weak bit is introduced to identify those unreliable bits after quantization and the corresponding bit-matching comparison is not executed. Simulation results show that, when weak bit is employed, the accuracy of kNN based on Vote Count can be improved significantly.","","Electronic:978-1-4799-8389-6; POD:978-1-4799-8467-1; USB:978-1-4673-7317-3","10.1109/ICIEA.2015.7334095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334095","Vote Count;Weak bit;k-Nearest Neighbors algorithm","Accuracy;Hamming distance;Machine learning algorithms;Quantization (signal);Radiation detectors;Reliability;Search problems","pattern matching;query processing;search problems","bit-matching comparison;k-nearest neighbor algorithm;kNN algorithm;quantized projection query values;training-reference vectors;vote count;weak bit","","1","","17","","","15-17 June 2015","","IEEE","IEEE Conference Publications"
"Large-Margin Multi-Modal Deep Learning for RGB-D Object Recognition","A. Wang; J. Lu; J. Cai; T. J. Cham; G. Wang","School of Computer Engineering, Nanyang Technological University (NTU), Singapore","IEEE Transactions on Multimedia","20151026","2015","17","11","1887","1898","Most existing feature learning-based methods for RGB-D object recognition either combine RGB and depth data in an undifferentiated manner from the outset, or learn features from color and depth separately, which do not adequately exploit different characteristics of the two modalities or utilize the shared relationship between the modalities. In this paper, we propose a general CNN-based multi-modal learning framework for RGB-D object recognition. We first construct deep CNN layers for color and depth separately, which are then connected with a carefully designed multi-modal layer. This layer is designed to not only discover the most discriminative features for each modality, but is also able to harness the complementary relationship between the two modalities. The results of the multi-modal layer are back-propagated to update parameters of the CNN layers, and the multi-modal feature learning and the back-propagation are iteratively performed until convergence. Experimental results on two widely used RGB-D object datasets show that our method for general multi-modal learning achieves comparable performance to state-of-the-art methods specifically designed for RGB-D data.","1520-9210;15209210","","10.1109/TMM.2015.2476655","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7258382","Deep learning;RGB-D object recognition;large-margin feature learning;multi-modality","Correlation;Feature extraction;Image color analysis;Labeling;Machine learning;Neural networks;Object recognition","backpropagation;convergence;convolution;learning (artificial intelligence);neural nets;object recognition","CNN layers;RGB data;RGB-D object recognition;backpropagation;convergence;convolutional neural networks;depth data;feature learning-based methods;large-margin multimodal deep learning","","8","","53","","20150911","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Deep Neural Networks in Machine Translation: An Overview","J. Zhang; C. Zong","Institute of Automation, Chinese Academy of Sciences","IEEE Intelligent Systems","20150904","2015","30","5","16","25","Deep neural networks (DNNs) are widely used in machine translation (MT). This article gives an overview of DNN applications in various aspects of MT.","1541-1672;15411672","","10.1109/MIS.2015.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243232","NLP;deep neural networks;intelligent systems;machine translation;natural language processing","Context;Hidden Markov models;History;Machine learning;Natural language processing;Neural networks;Semantics","language translation;neural nets","DNN;deep neural network;machine translation","","1","","32","","","Sept.-Oct. 2015","","IEEE","IEEE Journals & Magazines"
"Deep learning based FACS Action Unit occurrence and intensity estimation","A. Gudi; H. E. Tasli; T. M. den Uyl; A. Maroulis","Vicarious Perception Technologies, Amsterdam, The Netherlands","2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)","20151001","2015","06","","1","5","Ground truth annotation of the occurrence and intensity of FACS Action Unit (AU) activation requires great amount of attention. The efforts towards achieving a common platform for AU evaluation have been addressed in the FG 2015 Facial Expression Recognition and Analysis challenge (FERA 2015). Participants are invited to estimate AU occurrence and intensity on a common benchmark dataset. Conventional approaches towards achieving automated methods are to train multiclass classifiers or to use regression models. In this paper, we propose a novel application of a deep convolutional neural network (CNN) to recognize AUs as part of FERA 2015 challenge. The 7 layer network is composed of 3 convolutional layers and a max-pooling layer. The final fully connected layers provide the classification output. For the selected tasks of the challenge, we have trained two different networks for the two different datasets, where one focuses on the AU occurrences and the other on both occurrences and intensities of the AUs. The occurrence and intensity of AU activation are estimated using specific neuron activations of the output layer. This way, we are able to create a single network architecture that could simultaneously be trained to produce binary and continuous classification output.","","Electronic:978-1-4799-6026-2; POD:978-1-4799-6027-9","10.1109/FG.2015.7284873","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284873","","Conferences;Estimation;Face;Face recognition;Gold;Machine learning;Training","emotion recognition;face recognition;image classification;neural nets;regression analysis","AU occurrence estimation;CNN;FACS AU activation;FACS action unit occurrence;FG 2015 Facial Expression Recognition and Analysis challenge;binary classification output;continuous classification output;convolutional layers;deep convolutional neural network;deep learning;ground truth annotation;intensity estimation;max-pooling layer;multiclass classifiers;neuron activations;regression models;single network architecture","","5","","21","","","4-8 May 2015","","IEEE","IEEE Conference Publications"
"Reinforcement learning in a behaviour-based control architecture for marine archaeology","G. Frost; F. Maurelli; D. M. Lane","Ocean Systems Laboratory, School of Engineering & Physical Sciences, Heriot Watt University, EH14 4AS, Edinburgh, UK","OCEANS 2015 - Genova","20150921","2015","","","1","5","We present a novel path planner for adaptive behaviour of an Autonomous Underwater Vehicle (AUV). A behaviour-based architecture forms the foundation of the system with an extra layer which uses experience to learn a policy for modulating the behaviours' weights. In effect, this creates an abstract environment for the Reinforement Learning (RL) agent's state and action space. Subsequently, it simplifies the problem the RL agent is addressing, creating a more stable system. The Episodic Natural Actor Critic (ENAC) RL algorithm is used due to the continuous input and output domains and for the natural actor critic's convergence properties. Adaptiveness of the system is presented in a thruster failure scenario. RL is used in this failure scenario to learn an appropriate policy for the behaviours' weights under the new vehicle dynamics. We apply this control architecture to the domain of marine archaeology which has an inherent problem of navigation in unknown, potentially complex and dangerous environments. Simulated results of the proposed control architecture demonstrate its feasibility and performance.","","Electronic:978-1-4799-8736-8; POD:978-1-4799-8737-5","10.1109/OCEANS-Genova.2015.7271619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271619","","Adaptive systems;Learning (artificial intelligence);Machine learning algorithms;Modulation;Robots;Surges;Vehicles","adaptive control;archaeology;autonomous underwater vehicles;convergence;learning (artificial intelligence);marine navigation;path planning;vehicle dynamics","ENAC RL algorithm;RL agent state;action space;adaptive behaviour-based control architecture;autonomous underwater vehicle;behaviour weight modelling;episodic natural actor critic;marine archaeology;natural actor critic convergence;navigation;path planner;reinforcement learning;thruster failure;vehicle dynamics","","","","10","","","18-21 May 2015","","IEEE","IEEE Conference Publications"
"Multiview Deep Learning for Land-Use Classification","F. P. S. Luus; B. P. Salmon; F. van den Bergh; B. T. J. Maharaj","Dept. of Electr., Univ. of Pretoria, Pretoria, South Africa","IEEE Geoscience and Remote Sensing Letters","20151111","2015","12","12","2448","2452","A multiscale input strategy for multiview deep learning is proposed for supervised multispectral land-use classification, and it is validated on a well-known data set. The hypothesis that simultaneous multiscale views can improve composition-based inference of classes containing size-varying objects compared to single-scale multiview is investigated. The end-to-end learning system learns a hierarchical feature representation with the aid of convolutional layers to shift the burden of feature determination from hand-engineering to a deep convolutional neural network (DCNN). This allows the classifier to obtain problem-specific features that are optimal for minimizing the multinomial logistic regression objective, as opposed to user-defined features which trade optimality for generality. A heuristic approach to the optimization of the DCNN hyperparameters is used, based on empirical performance evidence. It is shown that a single DCNN can be trained simultaneously with multiscale views to improve prediction accuracy over multiple single-scale views. Competitive performance is achieved for the UC Merced data set, where the 93.48% accuracy of multiview deep learning outperforms the 85.37% accuracy of SIFT-based methods and the 90.26% accuracy of unsupervised feature learning.","1545-598X;1545598X","","10.1109/LGRS.2015.2483680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307121","Feature extraction;neural network applications;neural network architecture;remote sensing;urban areas","Accuracy;Machine learning;Neural networks;Neurons;Remote sensing;Storage tanks;Training","geophysical techniques;geophysics computing;land use;learning (artificial intelligence);neural nets;pattern classification","DCNN hyperparameters optimization;Multiview Deep Learning;SIFT-based methods;UC Merced data set;composition-based in- ference;convolutional layers;deep convolutional neural network;end-to-end learning sys- tem;feature determination;hand-engineering;heuristic approach;hierarchical feature representation;multinomial logistic re- gression objective;multiple single-scale views;multiscale input strategy;problem-specific fea- tures;size-varying objects;supervised multispectral land-use classification;unsupervised feature learning;user-defined features;well-known data set","","9","","15","","20151026","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Loop closure detection for visual SLAM systems using deep neural networks","X. Gao; T. Zhang","Department of Automation, Tsinghua University, Beijing, 100084, China","2015 34th Chinese Control Conference (CCC)","20150914","2015","","","5851","5856","The detection of loop closure is of essential importance in visual simultaneous localization and mapping systems. It can reduce the accumulating drift of localization algorithms if the loops are checked correctly. Traditional loop closure detection approaches take advantage of Bag-of-Words model, which clusters the feature descriptors as words and measures the similarity between the observations in the word space. However, the features are usually designed artificially and may not be suitable for data from new-coming sensors. In this paper a novel loop closure detection approach is proposed that learns features from raw data using deep neural networks instead of common visual features. We discuss the details of the method of training neural networks. Experiments on an open dataset are also demonstrated to evaluate the performance of the proposed method. It can be seen that the neural network is feasible to solve this problem.","","Electronic:978-9-8815-6389-7; POD:978-1-4673-7443-9","10.1109/ChiCC.2015.7260555","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7260555","Deep Neural Networks;Denoising Autoencoder;Loop Closure Detection;Simultaneous Localization and Mapping","Feature extraction;Machine learning;Neural networks;Simultaneous localization and mapping;Sparse matrices;Training;Visualization","SLAM (robots);neurocontrollers;robot vision","bag-of-words;deep neural networks;loop closure detection;visual SLAM systems;visual simultaneous localization and mapping systems","","2","","20","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Multimodal Deep Autoencoder for Human Pose Recovery","C. Hong; J. Yu; J. Wan; D. Tao; M. Wang","College of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China","IEEE Transactions on Image Processing","20151026","2015","24","12","5659","5670","Video-based human pose recovery is usually conducted by retrieving relevant poses using image features. In the retrieving process, the mapping between 2D images and 3D poses is assumed to be linear in most of the traditional methods. However, their relationships are inherently non-linear, which limits recovery performance of these methods. In this paper, we propose a novel pose recovery method using non-linear mapping with multi-layered deep neural network. It is based on feature extraction with multimodal fusion and back-propagation deep learning. In multimodal fusion, we construct hypergraph Laplacian with low-rank representation. In this way, we obtain a unified feature description by standard eigen-decomposition of the hypergraph Laplacian matrix. In back-propagation deep learning, we learn a non-linear mapping from 2D images to 3D poses with parameter fine-tuning. The experimental results on three data sets show that the recovery error has been reduced by 20%-25%, which demonstrates the effectiveness of the proposed method.","1057-7149;10577149","","10.1109/TIP.2015.2487860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293666","Human pose recovery;back propagation;deep learning;hypergraph;hypergraph, back propagation;multi-modal learning","Electronic mail;Feature extraction;Hidden Markov models;Machine learning;Neural networks;Three-dimensional displays;Visualization","backpropagation;eigenvalues and eigenfunctions;feature extraction;graph theory;image fusion;image representation;matrix decomposition;neural nets;pose estimation;video signal processing","backpropagation deep learning;hypergraph Laplacian matrix standard eigen-decomposition;image feature extraction;low-rank representation;multilayered deep neural network;multimodal deep autoencoder;multimodal fusion;nonlinear mapping;parameter fine tuning;pose retrieving process;video-based human pose recovery process","0","17","","43","","20151007","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Detecting Predatory Behavior in Game Chats","Y. G. Cheong; A. K. Jensen; E. R. Gu√∞nad√≥ttir; B. C. Bae; J. Togelius","Department of Computer Engineering, Sungkyunkwan University, South Korea","IEEE Transactions on Computational Intelligence and AI in Games","20150910","2015","7","3","220","232","While games are a popular social media for children, there is a real risk that these children are exposed to potential sexual assault. A number of studies have already addressed this issue, however, the data used in previous research did not properly represent the real chats found in multiplayer online games. To address this issue, we obtained real chat data from MovieStarPlanet, a massively multiplayer online game for children. The research described in this paper aimed to detect predatory behaviors in the chats using machine learning methods. In order to achieve a high accuracy on this task, extensive preprocessing was necessary. We describe three different strategies for data selection and preprocessing, and extensively compare the performance of different learning algorithms on the different data sets and features.","1943-068X;1943068X","","10.1109/TCIAIG.2015.2424932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091007","Chat;data mining;game data;natural language processing (NLP);preprocessing;sexual predator;text classification","Context;Feature extraction;Games;Labeling;Machine learning algorithms;Media;Social network services","computer games;computer mediated communication;data mining;learning (artificial intelligence);natural language processing;social aspects of automation;social networking (online)","MovieStarPlanet;children;data selection;game chats;machine learning methods;massively multiplayer online game;predatory behavior detection;sexual assault;social media","","0","","30","","20150421","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Heteroscedastic max-min distance analysis","B. Su; X. Ding; Changsong Liu; Ying Wu","Tsinghua University, Beijing, 100084, China","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","4539","4547","Many discriminant analysis methods such as LDA and HLDA actually maximize the average pairwise distances between classes, which often causes the class separation problem. Max-min distance analysis (MMDA) addresses this problem by maximizing the minimum pairwise distance in the latent subspace, but it is developed under the homoscedastic assumption. This paper proposes Heteroscedastic MMDA (HMMDA) methods that explore the discriminative information in the difference of intra-class scatters for dimensionality reduction. WHMMDA maximizes the minimal pairwise Chenoff distance in the whitened space. OHMMDA incorporates this objective and the minimization of class compactness into a trace quotient formulation and imposes an orthogonal constraint to the final transformation, which can be solved by a bisection search algorithm. Two variants of OHMMDA are further proposed to encode the margin information. Experiments on several UCI Machine Learning datasets and the Yale Face database demonstrate the effectiveness of the proposed HMMDA methods.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7299084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299084","","Eigenvalues and eigenfunctions;Gaussian distribution;Hidden Markov models;Machine learning algorithms;Search problems;Training;Upper bound","face recognition;learning (artificial intelligence);minimax techniques;minimisation","OHMMDA;UCI machine learning datasets;WHMMDA;Yale face database;average pairwise distance maximization;bisection search algorithm;class compactness minimization;class separation problem;dimensionality reduction;discriminant analysis methods;heteroscedastic MMDA;heteroscedastic max-min distance analysis;intraclass scatters;minimal pairwise Chenoff distance maximization;minimum pairwise distance maximization;orthogonal constraint;trace quotient formulation","","4","","30","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Toward avatar models to enhance performance and engagement in educational games","D. Kao; D. F. Harrell","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA","2015 IEEE Conference on Computational Intelligence and Games (CIG)","20151105","2015","","","246","253","This paper presents work toward better understanding the roles that avatars can play in supporting learning in educational games. Specifically, the paper presents results of empirical studies on the impact of avatar type on learner/player performance and engagement. These results constitute work establishing baseline understandings to inform our longer term goal of developing models that use dynamic avatars to best support learners in educational games. Our aim is motivated by a convergence of research in the social sciences establishing that identity plays an important role in learning. Of note, aspects of social identity (e.g., race, ethnicity, and gender) have been shown to impact student performance [1] via triggering stereotypes [2]. Recently, performance and engagement studies in our educational game for Science, Technology, Engineering and Mathematics (STEM) learning suggest these same phenomena can be activated through virtual avatars [3], [4]. Here, we present results of a comparative study between avatars in the likeness of players and avatars as geometric shapes. In our STEM learning game, results show that players that had selected and used a shape avatar had significantly higher performance than players that had customized and used a likeness avatar. Players using the shape avatar also had significantly higher self-reported engagement, despite having lower self-reported affect towards the avatar.","2325-4270;23254270","Electronic:978-1-4799-8622-4; POD:978-1-4799-8623-1","10.1109/CIG.2015.7317959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7317959","","Avatars;Computational modeling;Games;Machine learning algorithms;Pragmatics;Predictive models;Shape","avatars;computer aided instruction;computer games;human factors","STEM learning game;Science Technology Engineering and Mathematics;avatar model;dynamic avatars;educational games;geometric shapes;learner engagement;learner performance;learning support;player likeness;player performance;social identity;social science;student performance","","1","","41","","","Aug. 31 2015-Sept. 2 2015","","IEEE","IEEE Conference Publications"
"Mining maritime vessel traffic: Promises, challenges, techniques","L. Cazzanti; G. Pallotta","NATO STO Centre for Maritime Research and Experimentation (CMRE), La Spezia, Italy","OCEANS 2015 - Genova","20150921","2015","","","1","6","This paper discusses machine learning and data mining approaches to analyzing maritime vessel traffic based on the Automated Information System (AIS). We review recent efforts to apply machine learning techniques to AIS data and put them in the context of the challenges posed by the need for both algorithmic performance generalization and interpretability of the results in real-world maritime Situational Awareness settings. We also present preliminary work on discovering and characterizing vessel stationary areas using an unsupervised spatial clustering algorithm.","","Electronic:978-1-4799-8736-8; POD:978-1-4799-8737-5","10.1109/OCEANS-Genova.2015.7271555","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271555","","Data mining;Kernel;Machine learning algorithms;Measurement;Ports (Computers);Standards;Trajectory","data mining;geophysics computing;oceanographic techniques;unsupervised learning","algorithmic performance generalization;automated information system;data mining;machine learning;maritime vessel traffic;unsupervised spatial clustering algorithm","","1","","19","","","18-21 May 2015","","IEEE","IEEE Conference Publications"
"The cognitive cycle","J. F. Sowa","","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","11","16","In the twenty years from first grade to a PhD, students never learn any subject by the methods for which machine-learning algorithms have been designed. Those algorithms are useful for analyzing large volumes of data. But they don't enable a computer system to learn a language as quickly and accurately as a three-year-old child. They're not even as effective as a mother raccoon teaching her babies how to find the best garbage cans. For all animals, learning is integrated with the cognitive cycle from perception to purposeful action. Many algorithms are needed to support that cycle. But an intelligent system must be more than a collection of algorithms. It must integrate them in a cognitive cycle of perception, learning, reasoning, and action. That cycle is key to designing intelligent systems.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321420","","Games;Hidden Markov models;Machine learning;Mathematical model;Psychology;Solid modeling","cognition;data analysis;learning (artificial intelligence)","cognitive cycle;computer system;intelligent system;large data volume analysis;machine-learning algorithms","","","","34","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"A Continuous Learning Framework for Activity Recognition Using Deep Hybrid Feature Models","M. Hasan; A. K. Roy-Chowdhury","Department of CSE, University of California, Riverside, CA, USA","IEEE Transactions on Multimedia","20151026","2015","17","11","1909","1922","Most of the research on human activity recognition has focused on learning a static model, considering that all the training instances are labeled and present in advance, while in streaming videos new instances continuously arrive and are not labeled. Moreover, these methods generally use application- specific hand-engineered and static feature models, which are not suitable for continuous learning. Some recent approaches on activity recognition use deep-learning-based hierarchical feature models, but the large size of these networks constrain them from being used in continuous learning scenarios. In this work, we propose a continuous activity learning framework for streaming videos by intricately tying together deep hybrid feature models and active learning. This allows us to automatically select the most suitable features and take the advantage of incoming unlabeled instances to improve the existing model incrementally. Given the segmented activities from streaming videos, we learn features in an unsupervised manner using deep hybrid networks, which have the ability to take the advantage of both the local hand-engineered features and the deep model in an efficient way. Additionally, we use active learning to train the activity classifier using a reduced amount of manually labeled instances. Retraining the models with a huge amount of accumulated examples is computationally expensive and not suitable for continuous learning. Hence, we propose a method to select the best subset of these examples to update the models incrementally. We conduct rigorous experiments on four challenging human activity datasets to demonstrate the effectiveness of our framework.","1520-9210;15209210","","10.1109/TMM.2015.2477242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244231","Active learning;activity recognition;autoencoder;hybrid feature model;incremental learning","Computational modeling;Data models;Feature extraction;Labeling;Machine learning;Training;Videos","image classification;image motion analysis;learning (artificial intelligence);video streaming","activity classifier;activity recognition;continuous activity learning framework;deep hybrid feature model;deep-learning-based hierarchical feature model;local hand-engineered feature;static feature model;videos streaming","","1","","62","","20150907","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Deep Learning for Just-in-Time Defect Prediction","X. Yang; D. Lo; X. Xia; Y. Zhang; J. Sun","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","2015 IEEE International Conference on Software Quality, Reliability and Security","20150924","2015","","","17","26","Defect prediction is a very meaningful topic, particularly at change-level. Change-level defect prediction, which is also referred as just-in-time defect prediction, could not only ensure software quality in the development process, but also make the developers check and fix the defects in time. Nowadays, deep learning is a hot topic in the machine learning literature. Whether deep learning can be used to improve the performance of just-in-time defect prediction is still uninvestigated. In this paper, to bridge this research gap, we propose an approach Deeper which leverages deep learning techniques to predict defect-prone changes. We first build a set of expressive features from a set of initial change features by leveraging a deep belief network algorithm. Next, a machine learning classifier is built on the selected features. To evaluate the performance of our approach, we use datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 changes. We compare our approach with the approach proposed by Kamei et al. The experimental results show that on average across the 6 projects, Deeper could discover 32.22% more bugs than Kamei et al's approach (51.04% versus 18.82% on average). In addition, Deeper can achieve F1-scores of 0.22-0.63, which are statistically significantly higher than those of Kamei et al.'s approach on 4 out of the 6 projects.","","Electronic:978-1-4673-7989-2; POD:978-1-4673-7990-8","10.1109/QRS.2015.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272910","Cost Effectiveness;Deep Belief Network;Deep Learning;Just-In-Time Defect Prediction","Computer bugs;Feature extraction;Logistics;Machine learning;Measurement;Software quality;Training","just-in-time;learning (artificial intelligence);pattern classification;software quality","change-level defect prediction;deep learning;just-in-time defect prediction;machine learning classifier;machine learning literature;software quality","","2","","40","","","3-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Multi-class SVMs analysis of side-channel information of elliptic curve cryptosystem","E. Saeedi; M. S. Hossain; Yinan Kong","Department of Engineering, Macquarie University, Sydney, NSW 2109 Australia","2015 International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS)","20151001","2015","","","1","6","Cryptosystems, even after recent algorithmic improvements, can be vulnerable to side-channel attacks (SCA). In this paper, we investigate one of the powerful class of SCAs based on machine learning techniques in the forms of Principal Component Analysis (PCA) and multi-class classification. For this purpose, a support vector machine (SVM) is investigated as a robust and efficient multi-class classifier along with a proper kernel function and its appropriate parameters. Our experiment performed on data leakage of a FPGA implementation of elliptic curve cryptography (ECC), and the results, validated by cross-validation approach, compare the efficiency of different kernel functions and the influence of function parameters.","","Electronic:978-1-5108-1060-0; POD:978-1-4673-7351-7","10.1109/SPECTS.2015.7285297","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7285297","","Elliptic curve cryptography;Kernel;Machine learning algorithms;Principal component analysis;Support vector machines;Training","field programmable gate arrays;learning (artificial intelligence);principal component analysis;public key cryptography;support vector machines","ECC;FPGA;PCA;SCA;data leakage;elliptic curve cryptography;elliptic curve cryptosystem;field programmable gate arrays;kernel function;machine learning techniques;multiclass SVM analysis;multiclass classification;principal component analysis;side-channel attacks;side-channel information;support vector machine","","","","26","","","26-29 July 2015","","IEEE","IEEE Conference Publications"
"Efficient and dynamic bandwidth allocation for Non-Status Reporting Gigabit Passive Optical Networks (GPON)","A. Walid; A. Chen","Bell labs, Alcatel-Lucent, Murray Hill, NJ, USA","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","1000","1005","Upstream dynamic bandwidth allocation (DBA) for Gigabit Passive Optical Networks (GPON) is an important design problem since the shared uplink carries many bursty streams of different QoS requirements and there are various practical system constraints on processing loads in the OLT (Optical Line Terminal) and the ONUs (Optical Network Units). We propose self-adaptive bandwidth allocation solutions, where the OLT allocates bandwidth among the ONUs in an efficient and responsive manner, and importantly, without requiring buffer status reports from ONUs. These solutions could allow design of simpler ONUs. Our first solution is based on simple estimation by the OLT of the sample gradient of the ONU buffer content and application of stochastic approximation for sequential updates of bandwidth allocations that minimize buffer contents. The second approach is a closed form solution that minimizes the sum of weighted throughput across all ONUs. We compare our solutions with DBA algorithms that require buffer status reporting and empirically demonstrate their advantages.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7248453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7248453","","Bandwidth;Channel allocation;Machine learning algorithms;Optical buffering;Optical network units;Passive optical networks;Throughput","approximation theory;bandwidth allocation;passive optical networks","DBA;GPON;OLT;ONU;gigabit passive optical networks;optical line terminal;optical network units;self-adaptive bandwidth allocation solutions;stochastic approximation;upstream dynamic bandwidth allocation","","1","","15","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"The development of demand elasticity model for demand response in the retail market environment","M. Babar; P. H. Nguyen; V. Cuk; I. G. Kamphuis","Eindhoven University of Technology, Department of Electrical Engineering, Electrical Energy Systems, 5600 MB, the Netherlands","2015 IEEE Eindhoven PowerTech","20150903","2015","","","1","6","In the context of liberalized energy market, increase in distributed generation, storage and demand response has expanded the price elasticity of demand, thus causing the addition of uncertainty to the supply-demand chain of power system. In order to cope with the challenges of demand uncertainty under the unbundled electricity market, the concept of Market-based Control Mechanism (MCM) in retail market environment has been emerging. This paper presents the concept considering demand elasticity as an opportunity in retail market environment for inventing a new bid mechanism. This work formulates demand elasticity model as a Markov decision problem and implements pursuit algorithm as a machine learning technique to evaluate the price elasticity of demand by predicting the price. The performance of the algorithm is compared with the numerical calculation of price elasticity of demand for the given simulation settings.","","Electronic:978-1-4799-7693-5; POD:978-1-4799-7695-9","10.1109/PTC.2015.7232789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7232789","Demand Elasticity;Demand Response;Electricity Market;Pursuit Algorithm","Elasticity;Electricity supply industry;Machine learning algorithms;Markov processes;Numerical models;Pursuit algorithms;Smart homes","demand side management;learning (artificial intelligence);power markets;supply and demand","MCM;Markov decision problem;demand elasticity model;demand response;distributed generation;electricity market;liberalized energy market;machine learning technique;market based control mechanism;pursuit algorithm;retail market environment;supply-demand chain","","2","","16","","","June 29 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Wishart RBM based DBN for polarimetric synthetic radar data classification","Y. Guo; S. Wang; C. Gao; D. Shi; D. Zhang; B. Hou","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, P. R. China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20151112","2015","","","1841","1844","Deep Belief Network (DBN) is a classic deep learning model, and it can learn higher feature and do better classification job. We combine DBN's basic component Restricted Boltzmann Machines (RBM) with the statistic distribution of Polarimetric SAR (PolSAR) data. Based on it, we develop a deep learning classification method that is suitable for PolSAR data. To verify the effectiveness of the method, a real PolSAR dataset is tested. Experiment result confirms that the proposed method provides fine improvements both in classification accuracy and visual effect.","2153-6996;21536996","Electronic:978-1-4799-7929-5; POD:978-1-4799-7930-1; USB:978-1-4799-7928-8","10.1109/IGARSS.2015.7326150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326150","Wishart distribution;deep learning;feature learning;polarimetric synthetic radar data","Accuracy;Data models;Feature extraction;Geoscience and remote sensing;Machine learning;Support vector machines;Yttrium","radar polarimetry;synthetic aperture radar","DBN;PolSAR data;PolSAR dataset;RBM;Wishart RBM based DBN;classic deep learning model;deep belief network;polarimetric synthetic radar data classification;restricted Boltzmann machines;statistic distribution;visual effect","","2","","12","","","26-31 July 2015","","IEEE","IEEE Conference Publications"
"Improved Research to K-means Initial Cluster Centers","Z. Min; D. Kai-fei","Coll. of Inf. & Eng., Dalian Univ., Dalian, China","2015 Ninth International Conference on Frontier of Computer Science and Technology","20151102","2015","","","349","353","K-means in the field of clustering analysis algorithms is a kind of more traditional algorithm. It exists many shortcomings. For example, K value is easily affected by man-made subjective factors, and the algorithm is easy to fall into a local optimal solution, and the clustering result is not stable, etc, And K-means++ algorithm as the classic improved algorithm of K-means algorithm, but there is still a phenomenon of unstable cluster center. This paper is a kind of improvement aimed at the shortcoming of K-means++ algorithm, which introduces the concept of the variance in probability and mathematical statistics. Variance reflects the degree of density between samples and other samples. In the K-means++ algorithm when you select the first initial clustering center, you need to select minimum variance of sample points, which is in the position of the largest sample density, then you select the next cluster centers based on the weight method of D<sup>2</sup> which is described in the K-means++ algorithm. Experimental results show the accuracy is higher and stability is better.","2159-6301;21596301","CD-ROM:978-1-4673-9294-5; Electronic:978-1-4673-9295-2; POD:978-1-4673-9296-9","10.1109/FCST.2015.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314704","K-means++ algorithm;clustering;initial cluster centers;variance","Accuracy;Algorithm design and analysis;Clustering algorithms;Data collection;Iris;Machine learning algorithms;Probability","optimisation;pattern clustering;probability;sampling methods","cluster centers;clustering analysis algorithms;density degree;k value;k-means++ algorithm;local optimal solution;man-made subjective factors;mathematical statistics;minimum variance;probability;sample density;sample points;weight method","","","","9","","","26-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"Many Hands Make Light Work - On Ensemble Learning Techniques for Data Fusion in Remote Sensing","A. Merentitis; C. Debes","AGT R&D, Germany, AGT International, Darmstadt, 64295 Hessen, GERMANY","IEEE Geoscience and Remote Sensing Magazine","20150930","2015","3","3","86","99","In this paper we discuss the use of ensemble methods in remote sensing. After a review of the relevant state of the art in ensemble learning - inside and outside the remote sensing community - we provide the necessary theoretical background of this research field. This includes a discussion of the bias/variance tradeoff that is a key notion in machine learning and especially ensemble learning. We provide a review of three of the most relevant and prominent techniques in ensemble learning, namely the Random Forest, Extra Trees and the Gradient Boosted Regression Trees algorithms. All algorithms are assessed in terms of their theoretical properties as well as applicability for remote sensing use cases. Finally, in the experimental section we compare their performance in challenging remote sensing datasets with different properties, while discussing again the reasons that the mechanics of each algorithm might give it an advantage under certain conditions.","2473-2397;24732397","","10.1109/MGRS.2015.2432092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284785","","Learning systems;Machine learning algorithms;Mechanical factors;Radio frequency;Regression tree analysis;Remote sensing;Training;Vegetation mapping","geophysics computing;gradient methods;learning (artificial intelligence);random processes;regression analysis;remote sensing;sensor fusion;trees (mathematics)","data fusion;ensemble learning technique;extra tree algorithm;gradient boosted regression tree algorithm;machine learning;random forest algorithm;remote sensing community","","1","","62","","","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Nonlinear system identification using deep learning and randomized algorithms","E. de la Rosa; W. Yu; X. Li","Departamento de Control Automatico, CINVESTAV-IPN (National Polytechnic Institute), Mexico City, Mexico","2015 IEEE International Conference on Information and Automation","20151001","2015","","","274","279","Randomized algorithms have good performances for regression and classification problems by using random hidden weights and pseudoinverse computing for the output weights. They have one single hidden layer structure. On the other hand, deep learning techniques have been successfully used for pattern recognition due to their deep structure and effective unsupervised learning. In this paper, the randomized algorithm is modified by the deep learning method. There are multiple hidden layers, and the hidden weights are decided by the input data and modified restricted Boltzmann machines. The output weights are trained by normal randomized algorithms. The proposed deep learning with the randomized algorithms are validated with three benchmark datasets.","","Electronic:978-1-4673-9104-7; POD:978-1-4673-9105-4; USB:978-1-4673-9103-0","10.1109/ICInfA.2015.7279298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279298","deep learning;randomized algorithms;system identification","Accuracy;Computational modeling;Machine learning;Neural networks;Nonlinear systems;Probability distribution;Training","Boltzmann machines;pattern classification;randomised algorithms;regression analysis;unsupervised learning","classification problem;deep learning;nonlinear system identification;normal randomized algorithms;pattern recognition;pseudoinverse computing;random hidden weights;regression problem;restricted Boltzmann machines;unsupervised learning","","1","","42","","","8-10 Aug. 2015","","IEEE","IEEE Conference Publications"
"Deep learning of binary hash codes for fast image retrieval","K. Lin; H. F. Yang; J. H. Hsiao; C. S. Chen","Academia Sinica, Taiwan","2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20151026","2015","","","27","35","Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval. Encouraged by the recent advances in convolutional neural networks (CNNs), we propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are available, binary codes can be learned by employing a hidden layer for representing the latent concepts that dominate the class labels. The utilization of the CNN also allows for learning image representations. Unlike other supervised methods that require pair-wised inputs for binary code learning, our method learns hash codes and image representations in a point-wised manner, making it suitable for large-scale datasets. Experimental results show that our method outperforms several state-of-the-art hashing algorithms on the CIFAR-10 and MNIST datasets. We further demonstrate its scalability and efficacy on a large-scale dataset of 1 million clothing images.","2160-7508;21607508","Electronic:978-1-4673-6759-2; POD:978-1-4673-6760-8; USB:978-1-4673-6758-5","10.1109/CVPRW.2015.7301269","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7301269","","Binary codes;Image representation;Image retrieval;Machine learning;Neurons;Semantics;Visualization","binary codes;convolution;image representation;image retrieval;learning (artificial intelligence);neural nets","CIFAR-10 datasets;CNN;MNIST datasets;approximate nearest neighbor search;binary hash codes;class labels;convolutional neural networks;data labels;effective deep learning framework;fast image retrieval;hidden layer;image representations;large-scale datasets;latent concepts;pairwised inputs;supervised methods","","11","","32","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"A data mining model of knowledge discovery based on the deep learning","Y. Ma; Y. Tan; C. Zhang; Y. Mao","Application Management office of SINOPEC IT management Department, Beijing, 100728, China","2015 IEEE 10th Conference on Industrial Electronics and Applications (ICIEA)","20151123","2015","","","1212","1216","With the development of the database technology and the spread of the internet, the amount of the data in databases increases at an exponential speed, which yields the difficult problems of ‚Äúexcess data‚Äù and ‚Äúinformation explosion‚Äù, etc. The traditional database technology is restricted in reading and writing, querying and basic statics operations, but can't acquire the deep data attributes or implicit information. Facing with the huge database in all kinds of fields, it is more and more difficult to cope with the big data only by using conventional technology. New technique to deal with these data at a high level is eagerly demanded. Therefore, the KDD (Knowledge Discovery in Database) technology arises at the historic moment. KDD is an integrated process, which includes data input, iterative solving, user interface and many other custom requirements and design decisions, where the data mining (DM) is a key and specific step in KDD. This paper deeply analyzes state of the art technology of DM, and points out the challenge and technological bottleneck of DM. Moreover, a data mining model architecture of knowledge discovery based on deep learning is proposed.","","Electronic:978-1-4799-8389-6; POD:978-1-4799-8467-1; USB:978-1-4673-7317-3","10.1109/ICIEA.2015.7334292","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334292","KDD;data mining model;deep leaning","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Data mining;Data models;Databases;Machine learning","Internet;data mining;database management systems;iterative methods;learning (artificial intelligence);user interfaces","DM technology;Internet;KDD technology;custom requirements;data input;data mining model architecture;database technology development;deep learning;design decisions;integrated process;iterative solving;knowledge discovery;user interface","","","","26","","","15-17 June 2015","","IEEE","IEEE Conference Publications"
"A Feedback Effectiveness Oriented Math Word Problem E-Tutor for E-Learning Environment","K. Morton; Y. Qu","Sch. of Comput. Sci., Colorado Tech. Univ., Colorado Springs, CO, USA","2015 IEEE 15th International Conference on Advanced Learning Technologies","20150917","2015","","","301","302","E-Learning is gaining more traction as it is accepted and used by more students, as it provides time convenience, cost effectiveness, and location flexibility. E-Learning's key weakness is lacking of a cost effective way to support instructors to provide synchronous feedback to students. In addition, the help provided is usually not in real time and is missing an instructor's influence to a student's affective status in the feedback, which creates a practicality gap between e-Learning and feedback effectiveness. This paper proposes an e-Tutor framework for math word problem, and discusses various aspects of feedback effectiveness which is the central design concept of the e-Tutor.","2161-3761;21613761","Electronic:978-1-4673-7334-0; POD:978-1-4673-7335-7","10.1109/ICALT.2015.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265332","e-Learning;e-Tutor;feedback effectiveness","Computers;Electronic learning;Face;Fuzzy logic;Machine learning algorithms;Ontologies","intelligent tutoring systems;mathematics computing","e-learning environment;feedback effectiveness oriented math word problem e-tutor","","","","7","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"Further Improvement of AdaBoost Algorithm","L. Shaowen; Z. Jianqing; C. Yong","Inf. Technol. & Media Inst., Hexi Univ., Zhangye, China","2015 Seventh International Conference on Measuring Technology and Mechatronics Automation","20150914","2015","","","499","501","AdaBoost algorithm is a kind of very important feature classification machine learning algorithm, But if difficult samples exist in the training samples, With the iterative Number increasing, this easily leads to degeneration Phenomenon, and reduces the generalization ability of the classifier. In view of the face detection under complex background degeneration appeared problem, This article Proposes LWE-AdaBoost algorithm which can limit weight expansion, the experimental results indicate that the LWEAdaBoost algorithm can restrain the recurrence of degeneration Phenomenon well.","2157-1473;21571473","CD-ROM:978-1-4673-7142-1; Electronic:978-1-4673-7143-8; POD:978-1-4673-7144-5","10.1109/ICMTMA.2015.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7263620","AdaBoost algorithm;Cascaded classifier;Face detection;Integral image;Strong classifier;Weak classifier","Algorithm design and analysis;Classification algorithms;Face;Face detection;Machine learning algorithms;Training;Uncertainty","face recognition;feature extraction;iterative methods;learning (artificial intelligence);object detection","LWE-AdaBoost algorithm;degeneration phenomenon;face detection;feature classification;iterative number;machine learning algorithm;training samples","","","","8","","","13-14 June 2015","","IEEE","IEEE Conference Publications"
"ParLearning Keynotes","D. A. Bader; Y. Huang; A. Kalyanaraman","","2015 IEEE International Parallel and Distributed Processing Symposium Workshop","20151001","2015","","","1154","1156","Keynote Abstracts","","Electronic:978-1-4673-7684-6; POD:978-1-4673-7685-3","10.1109/IPDPSW.2015.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284440","","Analytical models;Big data;Computational modeling;Computer science;Data analysis;Data models;Machine learning algorithms","","","","","","","","","25-29 May 2015","","IEEE","IEEE Conference Publications"
"Hyper-class augmented and regularized deep learning for fine-grained image classification","S. Xie; T. Yang; Xiaoyu Wang; Yuanqing Lin","University of California, San Diego, USA","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","2645","2654","Deep convolutional neural networks (CNN) have seen tremendous success in large-scale generic object recognition. In comparison with generic object recognition, fine-grained image classification (FGIC) is much more challenging because (i) fine-grained labeled data is much more expensive to acquire (usually requiring domain expertise); (ii) there exists large intra-class and small inter-class variance. Most recent work exploiting deep CNN for image recognition with small training data adopts a simple strategy: pre-train a deep CNN on a large-scale external dataset (e.g., ImageNet) and fine-tune on the small-scale target data to fit the specific classification task. In this paper, beyond the fine-tuning strategy, we propose a systematic framework of learning a deep CNN that addresses the challenges from two new perspectives: (i) identifying easily annotated hyper-classes inherent in the fine-grained data and acquiring a large number of hyper-class-labeled images from readily available external sources (e.g., image search engines), and formulating the problem into multitask learning; (ii) a novel learning model by exploiting a regularization between the fine-grained recognition model and the hyper-class recognition model. We demonstrate the success of the proposed framework on two small-scale fine-grained datasets (Stanford Dogs and Stanford Cars) and on a large-scale car dataset that we collected.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298880","","Feature extraction;Image recognition;Machine learning;Neural networks;Search engines;Solid modeling;Visualization","image classification;learning (artificial intelligence)","FGIC;Stanford Cars;Stanford Dogs;deep CNN;deep convolutional neural networks;fine-grained image classification;fine-grained labeled data;fine-grained recognition model;fine-tuning strategy;hyper-class augmented deep learning;hyper-class recognition model;hyper-class-labeled images;image recognition;large intra-class variance;large-scale external dataset;large-scale generic object recognition;learning model;multitask learning;regularized deep learning;small inter-class variance;small-scale fine-grained datasets","","7","","43","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
