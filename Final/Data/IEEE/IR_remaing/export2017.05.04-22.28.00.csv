"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6197556,6156475,6195327,6192945,6194623,6194847,6194612,6194776,6194615,6195352,6193491,5749999,6189874,6189683,6190574,6189896,6188289,6184826,6188207,6188278,6187887,6184753,6188103,5728812,6185495,6184997,6186939,6185039,6185599,6184885,6184996,6187358,6182632,6182224,6182030,6182300,6182009,6182378,6182283,6182359,6182521,6181009,6180895,6181786,6182479,6165198,5871728,6178898,6177597,6173516,6174300,6035718,6172463,6081942,6169134,6168691,6170472,6169581,6169552,6169590,6169550,6168414,6169634,6167463,6167823,6167488,6166199,6164440,6164778,6166201,6164631,6164686,6163966,6163167,6144740,6163971,6163168,6158828,6162527,6159217,6161951,6159707,6158649,6162184,6135796,6158321,6157410,6156014,6156015,6156373,6156351,6009211,6154160,6154909,6154862,6154002,6148583,6152399,6152398,6152455",2017/05/04 22:28:00
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Investigating the Effects of Multiple Factors Towards More Accurate 3-D Object Retrieval","P. Daras; A. Axenopoulos; G. Litos","Informatics and Telematics Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece","IEEE Transactions on Multimedia","20120319","2012","14","2","374","388","This paper proposes a novel framework for 3-D object retrieval, taking into account most of the factors that may affect the retrieval performance. Initially, a novel 3-D model alignment method is introduced, which achieves accurate rotation estimation through the combination of two intuitive criteria, plane reflection symmetry and rectilinearity. After the pose normalization stage, a low-level descriptor extraction procedure follows, using three different types of descriptors, which have been proven to be effective. Then, a novel combination procedure of the above descriptors takes place, which achieves higher retrieval performance than each descriptor does separately. The paper provides also an in-depth study of the factors that can further improve the 3-D object retrieval accuracy. These include selection of the appropriate dissimilarity metric, feature selection/dimensionality reduction on the initial low-level descriptors, as well as manifold learning for re-ranking of the search results. Experiments performed on two 3-D model benchmark datasets confirm our assumption that future research in 3-D object retrieval should focus more on the efficient combination of low-level descriptors as well as on the selection of the best features and matching metrics, than on the investigation of the optimal 3-D object descriptor.","1520-9210;15209210","","10.1109/TMM.2011.2176111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081942","3-D object retrieval;descriptor extraction;feature selection;manifold learning;rotation estimation","Estimation;Feature extraction;Measurement;Principal component analysis;Shape;Solid modeling;Three dimensional displays","feature extraction;information retrieval;learning (artificial intelligence);pattern matching;solid modelling","3D model alignment method;3D object retrieval;appropriate dissimilarity metric;dimensionality reduction;feature selection;initial low-level descriptors;low-level descriptor extraction procedure;manifold learning;multiple factors effects;plane reflection rectilinearity;plane reflection symmetry;pose normalization stage;retrieval performance;rotation estimation","","17","","54","","20111115","April 2012","","IEEE","IEEE Journals & Magazines"
"Self-adaptive emergency topic tracking model based on CHI_LDA and timing characteristics","M. Liang; J. Du; Y. Yang","Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China","2011 4th IEEE International Conference on Broadband Network and Multimedia Technology","20120223","2011","","","647","651","According to some flaws in the existing topic tracking methods, a new method of self-adaptive emergency topic tracking model based on CHI_LDA and timing characteristics is proposed in this paper. Apply the CHI_LDA method to establish the model for the news topics and reports, not only resolving the problems of high dimension and sparseness in the feature space and semantic relevance, but also improving the time efficiency for the LDA method to realize the semantic mapping of the feature space. Then establish the topic tracker combined with the news topic timing characteristics, and meanwhile realize the self-adaptive updating of the topic model so as to track the dynamic changes in topic. Experimental results indicate that this method of topic tracking has a better performance, further improving the effect of topic tracking.","","Electronic:978-1-61284-159-5; POD:978-1-61284-158-8","10.1109/ICBNMT.2011.6156015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156015","CHI_LDA;Topic tracking;self-adaptive;timing characteristics;topic model","Accuracy;Adaptation models;Educational institutions;Mathematical model;Semantics;Timing;Training","data mining;information retrieval;probability","CHI_LDA;LDA method;feature space;self-adaptive emergency topic tracking model;self-adaptive updating;semantic mapping;semantic relevance;space relevance;time efficiency;topic model;topic timing characteristics;topic tracker","","0","","6","","","28-30 Oct. 2011","","IEEE","IEEE Conference Publications"
"Research on model of concept similarity computation based on domain ontology","Y. Yang; J. Du; M. Liang","Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China","2011 4th IEEE International Conference on Broadband Network and Multimedia Technology","20120223","2011","","","642","646","Analyze the cases that concepts in ontology are similar, establish a concept similarity computation model based on domain ontology; The computation of concept similarity not only considers the semantic distance between concepts, but also considers the conceptual layer factor and superior concepts coincidence degree, quantizing semantic similarity between concepts nodes in ontology network more comprehensively; Based on the food safety emergencies ontology compute the semantic similarity of some concepts, and the computation results show that the new model to the concept similarity computation is effective.","","Electronic:978-1-61284-159-5; POD:978-1-61284-158-8","10.1109/ICBNMT.2011.6156014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156014","concept similarity;domain ontology;food security emergency;semantic distance;superior concept coincidence degree","Analytical models;Computational modeling;Computers;Decision making;Ontologies;Safety;Semantics","food safety;information retrieval;medical computing;ontologies (artificial intelligence)","concept similarity computation;concepts coincidence degree;conceptual layer factor;domain ontology;food safety emergencies ontology;information retrieval;semantic distance;semantic similarity","","1","","9","","","28-30 Oct. 2011","","IEEE","IEEE Conference Publications"
"Data concentration and archival to SD card via hardware description language","O. Elkeelany; V. S. Todakar","","2011 IEEE GLOBECOM Workshops (GC Wkshps)","20120301","2011","","","625","630","Smart Grid (SG) is the next generation's power grid system. Delivering control, monitoring and management data to grid elements often requires the efficient archival of acquired information. The main objective of this research is to design an experimental platform for efficient, on-chip, real-time data concentrator for accessing data from a Secure Digital flash memory card using the SD bus protocol. All the hardware design is done using Verilog hardware descriptive language and implemented in Field Programmable Gate Array (FPGA). The data access from the SD card is implemented completely using Verilog and hence there is no use of any microcontroller or on-chip general purpose processors. And since the complete design is a single purpose system, no extra hardware is required. The design has four independent modules for the required different operations on the SD memory card. These four modules are for single block write, multiple block write, single block read, and multiple block read operations. A temporary data is either stored internally in an array of registers or externally in the Synchronous RAM for the analysis purposes. The bidirectional access takes place correctly and the data integrity has been verified using Cyclic Redundancy Code in both FPGA processor as well as the SD card controller. The design is implemented on the Altera's Cyclone II EP2C35F672C6 FPGA chip using 1GB SanDisk SD card and has shown a maximum data concentration rate of 25 Mbps.","2166-0077;21660077","Electronic:978-1-4673-0040-7; POD:978-1-4673-0039-1; USB:978-1-4673-0038-4","10.1109/GLOCOMW.2011.6162527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162527","Flash memory read/write;SD Protocol;Verilog HDL","Clocks;Field programmable gate arrays;Flash memory;Hardware;Hardware design languages;Program processors;Timing","data integrity;field buses;field programmable gate arrays;flash memories;hardware description languages;information retrieval;memory cards;power engineering computing;protocols;random-access storage;security of data;smart power grids","Altera;Cyclone II EP2C35F672C6 FPGA chip;FPGA processor;SD bus protocol;SD card via hardware description language;SD memory card controller;SanDisk SD card;Verilog hardware descriptive language;cyclic redundancy code;data access;data integrity;field programmable gate array;multiple block read operation;multiple block write operation;next generation power grid system;on-chip real-time data concentrator;secure digital flash memory card;secured digital card;single block read operation;single block write operation;smart grid;synchronous RAM;temporary data","","1","","13","","","5-9 Dec. 2011","","IEEE","IEEE Conference Publications"
"A comparison between keywords and key-phrases in text categorization using feature section technique","V. Nuipian; P. Meesad; P. Boonrawd","Institute of Computer and information Technology, Department of Information technology, Faculty of Information Technology, King Mongkut's University of Technology North, Bangkok, Bangkok, Thailand","2011 Ninth International Conference on ICT and Knowledge Engineering","20120216","2012","","","156","160","Text categorization is the main issue which affects search results. Moreover, most approaches suffer from the high dimensionality of feature space. To overcome this problem, the use of feature selection techniques with statistical text categorization is investigated. The methods were evaluated based on Chi-Square, Information Gain and Gain Ratio. The data used to test the system consisted of 1,510 documents from 2009-2010, word segmentation algorithm to key-phrase 4,408 attributes and single word 2,184 attributes. Classification techniques applied Decision Tree (ID3), Naïve Bayes (NB), Support Vector Machine (SVM) and k-nearest neighbor (KNN). Results showed that the Support Vector Machine was found to be the best technique with accuracy of a single word at 84% and key-phrase at 74% based on feature selection with Chi-Square, Information Gain and Gain Ratio with F-measure. In future research, application of text to the semantic system should be investigated further.","2157-0981;21570981","Electronic:978-1-4577-2162-5; POD:978-1-4577-2161-8","10.1109/ICTKE.2012.6152398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152398","digital library;feature selection;key-phrase;single word;text categorization","Bayesian methods;Classification algorithms;Entropy;Information technology;Niobium;Support vector machines;Text categorization","Bayes methods;decision trees;feature extraction;information retrieval;pattern classification;statistical analysis;support vector machines;text analysis;word processing","Chi-square technique;Naive Bayes;attributes;decision tree;feature selection techniques;gain ratio technique;information gain;k-nearest neighbor algorithm;key-phrases;keywords;semantic system;statistical text categorization;support vector machine;text classification;word segmentation algorithm","","0","","13","","","12-13 Jan. 2012","","IEEE","IEEE Conference Publications"
"The Linked Data Strategy for Global Identity","H. Glaser; H. Halpin","Seme4","IEEE Internet Computing","20120301","2012","16","2","68","71","The Web's promise for planet-scale data integration depends on solving the thorny problem of identity: given one or more possible identifiers, how can we determine whether they refer to the same or different things? Here, the authors discuss various ways to deal with the identity problem in the context of linked data.","1089-7801;10897801","","10.1109/MIC.2012.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6159217","World Wide Web;identity;linked data","Authentication;Data processing;Electronic publishing;Globalization;Identity-based encryption;Resource description framework;Semantics","data integration;information retrieval;semantic Web","World Wide Web;global identity;linked data strategy;planet-scale data integration","","3","","3","","","March-April 2012","","IEEE","IEEE Journals & Magazines"
"Redesigning of IPSec for interworking with satellite Performance Enhancing Proxies","M. N. M. Bhutta; H. Cruickshank; J. Ashworth; M. Moseley","Center for Communication Systems Research, University of Surrey, Guildford, GU2 7XH, UK","2011 6th International ICST Conference on Communications and Networking in China (CHINACOM)","20120227","2011","","","1104","1109","Performance Enhancing Proxies (PEPs) are used in satellite networks for better performance of the TCP/IP applications. Multi-layer IPSec (ML-IPSec) resolves the conflict between end-to-end security in standard IPSec and working of PEPs. This paper presents the concept and detailed design of ML-IPSec by breaking the IP datagram into three zones while enabling the intermediate nodes to access the TCP header and HTTP header information. The paper also presents an efficient interworking scheme between ML-IPSec and secure IP multicast using the Logical Key Hierarchy for key distribution.","","Electronic:978-1-4577-0101-6; POD:978-1-4577-0100-9","10.1109/ChinaCom.2011.6158321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158321","IPSec;ML-IPSec;PEP;TCP and HTTP","Authentication;Encryption;IP networks;Logic gates;Protocols","IP networks;computer network security;hypermedia;information retrieval;satellite communication;transport protocols","HTTP header information;IP datagram;ML-IPSec;PEP;TCP header;TCP-IP application;end-to-end security;interworking scheme;key distribution;logical key hierarchy;multilayer IPSec;satellite networks;satellite performance enhancing proxies;secure IP multicast;standard IPSec","","0","","20","","","17-19 Aug. 2011","","IEEE","IEEE Conference Publications"
"Towards Extracting Semantic Information from Texts","D. Trandabat","Fac. of Comput. Sci., Univ. Al. I. Cuza of Iasi, Iasi, Romania","2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","20120315","2011","","","199","206","This paper presents the general architecture of a system which creates a map of semantic information around a named entity (Person, Organization, etc.). Thus, after the user specifies a named entity, the system searches on the web and returns the first 200 web pages containing the specified entity, applies semantic roles on the returned paragraphs, and extracts a map of related actions involving the searched entity. This map of actions can then be chronologically ordered, thus illustrating the actions a certain entity has performed in a specific time frame (or at least the way it is reflected by the online world).","","Electronic:978-0-7695-4630-8; POD:978-1-4673-0207-4","10.1109/SYNASC.2011.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169581","information extraction;natural language processing;semantic roles","Computers;Feature extraction;Labeling;Natural language processing;Semantics;Training;Web pages","information retrieval;knowledge acquisition;natural language processing;semantic Web","Web pages;named entity;semantic information extraction;semantic role","","0","","21","","","26-29 Sept. 2011","","IEEE","IEEE Conference Publications"
"Case-based reasoning system based on Bayesian rough set and hierarchical mixture of experts model","Y. Li; M. Han","School of Electronic and Information Engineering, Dalian University of Technology, China","2011 3rd International Conference on Awareness Science and Technology (iCAST)","20120305","2011","","","339","343","An efficient case retrieval method and an adjustment strategy are proposed in this paper to build a case-based reasoning (CBR) system for oxygen calculation in Basic Oxygen Furnace (BOF) steelmaking. In the process of case retrieval, the Bayesian rough set technology is adopted to establish the weights of the case attributes. Then, the k nearest neighbors algorithm is implement to retrieval the most similar cases as a reference. The adjustment step executed by mixture of experts model is introduced to make up the gaps between current case's problem attributes and the retrieved case's. Finally, the parameters in mixture of experts model are optimized by Particle Swarm Optimization (PSO) method. Practical production data are used to test the CBR system. Using actual production data converter simulation Results show that proposed system is effective.","2325-5986;23255986","Electronic:978-1-4577-0888-6; POD:978-1-4577-0887-9","10.1109/ICAwST.2011.6163167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163167","case-based reasoning;hierarchical mixture of experts model;particle swarm optimization algorithm;rough set","Heating","case-based reasoning;furnaces;information retrieval;particle swarm optimisation;pattern classification;production engineering computing;rough set theory;steel manufacture","BOF steelmaking;Bayesian rough set technology;PSO method;adjustment strategy;basic oxygen furnace;case retrieval method;case-based reasoning system;experts model hierarchical mixture;k-nearest neighbor algorithm;oxygen calculation;particle swarm optimization;production data converter","","0","","11","","","27-30 Sept. 2011","","IEEE","IEEE Conference Publications"
"Research on using memcached in call center","Fajie Li; Shubo Zhan; Lili Li","State Key Laboratory of Networking and Switching, Beijing University of Posts and Telecommunications, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","1721","1723","In modern society, more and more companies have introduced call center system into their enterprise management to improve customer relationships. In the meantime, the scale of the call center system increases hugely. As a result, the traditional RDBMS cannot well satisfy the requirements of high-frequency access and performance becomes a key issue to be considered. Memcached is a high-performance, distributed memory object caching system, which is widely used in storage system to improve data access performance. This paper first briefly introduces the conception and features of memcached, and then discusses the integration of memcached with call center in detail. Finally, we promote a new idea to use memcached based on Web Service technology, which proves to be safe and flexible.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182300","CTI;Call Center;Memcached;NoSql;outbound call","Java;Servers;Simple object access protocol","Web services;cache storage;call centres;customer relationship management;information retrieval systems","Memcached system;RDBMS;Web service technology;call center system;customer relationships;data access performance;enterprise management;high-frequency access;high-performance distributed memory object caching system;storage system","","1","","7","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Managing semantic-based forestry information via web","E. J. Guerra-García; Y. M. Fernández-Ordóñez; R. C. Medina-Ramírez; J. Soria-Ruiz","Colegio de Postgraduados, Mexico","CONIELECOMP 2012, 22nd International Conference on Electrical Communications and Computers","20120426","2012","","","17","21","Among the services provided by Internet, intelligent access to information resources (IRs) seems necessary, in order to contribute to decision-making. Information management systems should recognize and register the contents of IRs for storage and treatment purposes due to their exponential appearances in the web; therefore it is necessary to develop systems that consider the contents of IRs whether they are stored locally or remotely. This paper describes an approach for managing heterogeneous IRs using forestry resources as case study. The approach builds a semantic forest memory for which a prototype system to validate results has been implemented.","","Electronic:978-1-4577-1325-5; POD:978-1-4577-1326-2","10.1109/CONIELECOMP.2012.6189874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189874","","Forestry;Information services;Ontologies;Organizations;Semantic Web;Semantics;XML","Internet;forestry;information resources;information retrieval","IR content register;Internet;Web;decision making;exponential appearance;forestry resource;heterogeneous IR;information resource access;semantic forest memory;semantic-based forestry information management system","","0","","13","","","27-29 Feb. 2012","","IEEE","IEEE Conference Publications"
"Balancing Wireless Data Broadcasting and Information Hovering for Efficient Information Dissemination","C. Liaskos; A. Xeros; G. I. Papadimitriou; M. Lestas; A. Pitsillides","Department of Informatics, Aristotle University, Thessaloniki, Greece","IEEE Transactions on Broadcasting","20120220","2012","58","1","66","76","Wireless data broadcasting is an efficient, bandwidth preserving way of data dissemination. However, as the amount of data increases, the waiting time of the clients becomes unacceptably high. The present paper proposes the combination of optimal wireless broadcasting and information hovering, as an effective means of performance improvement in vehicular networks with locality of demand. While state-of-the-art works exploit user collaboration only as a means of wireless coverage extension, the proposed scheme proposes parallel dissemination through broadcasting and user networking over the whole studied area. Optimal, periodic broadcast scheduling is adopted at the highest tier for data dissemination. At the lowest tier, users can exploit information hovering around selected anchoring points, in order to retrieve data faster than their next scheduled broadcast. The issue of sharing the dissemination load optimally between the broadcasting and the hovering subsystems is mapped to the classic pull-push balancing problem. Through analysis, the long-standing “optimal cut-off point” balancing method is shown to be suboptimal, and a new method is proposed which achieves lower client serving time in any of the cases. Simulation results in realistic VANETs show that the proposed dissemination scheme surpasses state-of-the-art works in terms of efficiency and client satisfaction.","0018-9316;00189316","","10.1109/TBC.2011.2163449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6009211","Information hovering;vehicular networks;wireless broadcast scheduling","Ad hoc networks;Bandwidth;Broadcasting;Collaboration;Schedules;Strain;Wireless communication","information dissemination;information retrieval;mobile computing;radio broadcasting;vehicular ad hoc networks","VANET;client satisfaction;data dissemination;data faster retrieval;information dissemination;information hovering;long-standing optimal cut-off point balancing method;optimal wireless broadcasting;parallel dissemination;periodic broadcast scheduling;pull-push balancing problem;vehicular networks;wireless data broadcasting","","11","","37","","20110905","March 2012","","IEEE","IEEE Journals & Magazines"
"Learning service behavior with progressive testing","J. Church; A. Motro","Computer Science Department, Volgenau School of Engineering, George Mason University Fairfax, VA 22030-4444, USA","2011 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)","20120309","2011","","","1","8","We describe a comprehensive methodology for discovering service similarity (substitutability) by testing. Our solutions do not rely on the service descriptions provided by their authors and they avoid common information retrieval techniques. Our work addresses a variety of challenges raised throughout the process. These include: (1) the generation of unbiased test samples based on individual domains and their statistical properties; (2) the use of progressive sampling and Rand index convergence to minimize sample size; (3) the classification of services by their input and output structures (single values, sets of values, sequences of values, and tables), and the development of corresponding similarity measures; (4) the optimal alignment of services that have multiple inputs and outputs of the same type; (5) the management of two types of service exceptions (null values); (6) the selection of clustering methods that are most appropriate to the sets of services being clustered; and (7) the caching of tests, results, similarities, clusters and other statistical information to enable cluster evolution. Initial testing with a prototype implementation validated our methodology, yielding high accuracy at surprisingly small test sizes.","2163-2871;21632871","Electronic:978-1-4673-0319-4; POD:978-1-4673-0318-7","10.1109/SOCA.2011.6166199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166199","","Clustering algorithms;Convergence;Indexes;Partitioning algorithms;Quality of service;Testing;Web services","convergence;information retrieval;pattern clustering;program testing;sampling methods;service-oriented architecture;statistical analysis","Rand index convergence;cluster evolution;clustering methods;information retrieval techniques;progressive sampling;progressive testing;prototype implementation;service behavior learning;service similarity;statistical properties;unbiased test samples","","3","","23","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Computational analysis of hybrid SVD-DCT image multiplexing-demultiplexing algorithm using variable quantization levels","M. M. Dixit; P. Salamani; P. Rane; V. M. Gada","Department of Electronics & Communication Engineering, S. D. M. College of Engineering & Technology, Dharwad, Karnataka, India","Electrical, Electronics and Computer Science (SCEECS), 2012 IEEE Students' Conference on","20120423","2012","","","1","5","The change from the cine film to digital methods of image exchange and archival is primarily motivated by the ease and flexibility of handling digital image information instead of the film media. The principal approach in data compression is the reduction of the amount of image data (bits) while preserving information (image details), so that the image can be stored or transferred more efficiently. Multiplexing uses the available channel capacity effectively. The discrete cosine transform (DCT) converts a signal into elementary frequency components. The proposed work explores the computational analysis of a hybrid SVD-DCT technique for image multiplexing using variable quantization levels and variable ranks. This paper primarily focuses on the significance of image multiplexing by incorporating compression with different quantization matrices and variable ranks. The efficiency of such a system is measured using Compression Ratio (CR), Peak Signal to Noise Ratio (PSNR) and image quality analysis visually. This technology is a key enabling factor in many imaging and multimedia concepts, where multiplexing and compression of image data is required.","","Electronic:978-1-4673-1515-9; POD:978-1-4673-1516-6","10.1109/SCEECS.2012.6184826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184826","CR;DCT;Image Compression;Image Multiplexing;PSNR;SVD","Color;Discrete cosine transforms;Image coding;Matrix decomposition;Multiplexing;PSNR;Quantization","channel capacity;data compression;data handling;demultiplexing;discrete cosine transforms;image coding;information retrieval systems;multimedia systems;multiplexing;quantisation (signal);visual databases","archival;channel capacity;compression ratio;computational analysis;digital image information handling;discrete cosine transform;elementary frequency components;hybrid SVD-DCT image multiplexing-demultiplexing algorithm;image data compression;image data reduction;image exchange;image quality analysis;image storage;information preservation;multimedia;peak signal to noise ratio;quantization matrices;variable quantization levels","","1","","11","","","1-2 March 2012","","IEEE","IEEE Conference Publications"
"Dashboard - a novel approach to re-find information in a website through building personalized navigational menus","P. Biswas; M. Debnath; S. Ghosh; S. Rahim; A. Mahamud; N. Chowdhury","Department of Computer Science, University of Texas at San Antonio, One UTSA Circle - SA, 78249 USA","14th International Conference on Computer and Information Technology (ICCIT 2011)","20120309","2011","","","173","178","Re-visitation or re-finding information in a website is a very frequent activity in web browsing. When a user re-visits a website especially after a long time, she encounters some problems among which being oblivious about the information structure of the site is very prominent. Another problem is that in a website, users have no way to organize the information space or the navigational structure of the website. In this paper, we have proposed a novel approach named Dashboard which supports building custom navigational menus system and allows each user build her own hierarchical information structure. We have also demonstrated how this new approach helps quickly re-finding information on re-visitation of a website.","","Electronic:978-1-61284-908-9; POD:978-1-61284-907-2","10.1109/ICCITechn.2011.6164778","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164778","Human Computer Interaction;Personalization;Re-visitation;Web Navigation","Engines;Navigation","Web sites;human computer interaction;information retrieval","Dashboard;Web browsing;Website;hierarchical information structure;information refinding;information revisitation;navigational structure;personalized navigational menus","","0","","17","","","22-24 Dec. 2011","","IEEE","IEEE Conference Publications"
"Using fuzzy code search to link code fragments in discussions to source code","N. Bettenburg; S. W. Thomas; A. E. Hassan","Software Anal. & Intell. Lab. (SAIL), Queen's Univ. Kingston, Kingston, ON, Canada","2012 16th European Conference on Software Maintenance and Reengineering","20120405","2012","","","319","328","When discussing software, practitioners often reference parts of the project's source code. Such references have different motivations, such as mentoring and guiding less experienced developers, pointing out code that needs changes, or proposing possible strategies for the implementation of future changes. The fact that particular parts of a source code are being discussed makes these parts of the software special. Knowing which code is being talked about the most can not only help practitioners to guide important software engineering and maintenance activities, but also act as a high-level documentation of development activities for managers. In this paper, we use clone- detection as specific instance of a code search based approach for establishing links between code fragments that are discussed by developers and the actual source code of a project. Through a case study on the Eclipse project we explore the traceability links established through this approach, both quantitatively and qualitatively, and compare fuzzy code search based traceability linking to classical approaches, in particular change log analysis and information retrieval. We demonstrate a sample application of code search based traceability links by visualizing those parts of the project that are most discussed in issue reports with a Treemap visualization. The results of our case study show that the traceability links established through fuzzy code search- based traceability linking are conceptually different than classical approaches based on change log analysis or information retrieval.","1534-5351;15345351","Electronic:978-0-7695-4666-7; POD:978-1-4673-0984-4","10.1109/CSMR.2012.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178898","","Europe;Software maintenance","data visualisation;fuzzy set theory;information retrieval;program diagnostics;software maintenance","Eclipse project;Treemap visualization;change log analysis;clone detection;code fragments;fuzzy code search-based traceability links;high-level documentation;information retrieval;link code fragments;maintenance activities;project source code;software engineering","","5","","32","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"A Network Monitoring Tool for CCN","W. Kang; B. Sim; J. Kim; E. Paik; Y. Lee","CNU, Daejeon, South Korea","2012 World Telecommunications Congress","20120315","2012","","","1","3","Recent discussions on the revolutionary Future Internet architecture have led to Content-Centric Networking (CCN) that puts emphasis on contents for the efficient information delivery. Since CCNx has been released as an early stage prototype of CCN, many projects are being developed on CCNx. However, a network monitoring function for CCN nodes or faces has not been implemented. In this paper, we propose a simple network monitoring method based on IETF IPFIX and SNMP for CCN. From IPFIX, we could easily find the detailed information on contents delivered in interest or data packets in the format of flows, while retrieving information on the CCN node and its tables in SNMP. Through our monitoring scheme, we could clearly diagnose the current status of CCN nodes and their data such as Content Stores, Pending Interest Table (PIT), and Forwarding Information Base (FIB).","","Electronic:978-4-88552-257-4; POD:978-1-4577-1459-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6170472","","Computer architecture;IP networks;Internet;Monitoring;Protocols;Servers;XML","IP networks;Internet;computer network management;content management;information retrieval;protocols","CCN;IETF;IPFIX;SNMP;content centric networking;data packets;future Internet architecture;information content delivery;information retrieval;network monitoring tool","","0","","11","","","5-6 March 2012","","IEEE","IEEE Conference Publications"
"Accuracy of data acquisition approaches with ground penetrating radar for subsurface utility mapping","S. W. Jaw; M. Hashim","Institute of Geospatial Science & Technology, Faculty of Geoinformation and Real Estate, Universiti Teknologi Malaysia, 81310 UTM Johor Bahru, Malaysia","2011 IEEE International RF & Microwave Conference","20120315","2011","","","40","44","Ground penetrating radar (GPR) is widely used in subsurface utility mapping for extracting the position (x, y) and depth (z) information of the utility. This information is crucial for subsurface facility management, in particular as reference in excavation works. The locational and depth information of the utility features is therefore of very important in subsurface mapping, apart from the reliability of the entire data acquisition and information retrieval method. This study investigates the effects of GPR data acquisition techniques to the locational and depth accuracy retrieved. The techniques examined are: (i) widely used perpendicular to pipe scanning; (ii) along pipe scanning; and (iii) variation angles scanning. Results indicated that along pipe scanning reported better penetrative power, higher detectability and best detection accuracy. Most importantly, this acquisition accuracy conforms to Quality Level A utility data requirements of the utility industries, hence offers the opportunities of GPR as measuring tool for underground cadastre system.","","Electronic:978-1-4577-1631-7; POD:978-1-4577-1628-7","10.1109/RFM.2011.6168691","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168691","accuracy;detectability;ground penetrating radar;scanning technique;subsurface utility mapping","Accuracy;Backscatter;Data acquisition;Ground penetrating radar;Industries;Materials;Permittivity","data acquisition;geophysics computing;ground penetrating radar;information retrieval;radar computing;reliability;remote sensing by radar","GPR data acquisition techniques;data acquisition reliability;ground penetrating radar;information retrieval method;pipe scanning;subsurface facility management;subsurface utility mapping;underground cadastre system;utility industries;variation angle scanning","","0","","20","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Person entity attributes association in list pages","Yongxing Tan; Meijuan Yin; Junyong Luo; Mingtao Li; Lin Lu","Zhengzhou Information Science and Technology Institute, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","1","","517","521","Person entity attributes association is a basic task in WePS, but it's still a challenging task because of heterogeneous web pages which can be classified into two categories, list page and detail page. In this paper, we study the problem of associating person entity attributes in various list pages. Our target is to find a consolidated solution as general as possible to deal with list pages in person entity attributes association. In contrast to most existing methods, we extract visual features and leverage Markov logic networks (MLNs) to effectively integrate all useful evidence by learning there importance automatically. The experimental results show a very encouraging performance.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182009","List Page;MLNs;Person entity;VIPs;attributes ass-ociation","Feature extraction;ISO standards;Markov processes","Internet;information retrieval;probabilistic logic","Person entity attributes association;WePS;heterogeneous web pages;leverage Markov logic networks;list pages","","0","","11","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Target estimation method for a udio-visual recorders based on users' operation history","T. Inoue; J. Ozawa","Panasonic Corporation, Japan","2012 IEEE International Conference on Consumer Electronics (ICCE)","20120301","2012","","","478","479","This paper proposes a target estimation method based on users' operation history in which the operation history is assumed to be based on the label-following strategy. The proposed method is applied for AV appliances, and the effectiveness of the method is assessed. A target function is estimated from the semantic similarity between the collection of words of the menu items and labels of remote controller buttons selected by the user. Experimental results show that the average rank of the estimated order of finding the target function from all the selection history data was 8.7.","2158-3994;21583994","Electronic:978-1-4577-0231-0; POD:978-1-4577-0230-3","10.1109/ICCE.2012.6161951","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6161951","","Aerospace electronics;Estimation;History;Home appliances;Semantics;Singular value decomposition;Vectors","audio-visual systems;consumer electronics;home automation;human computer interaction;information retrieval;natural language processing;recorders","AV appliances;audio-visual recorders;label-following strategy;remote controller buttons;semantic similarity;target estimation method;user operation history","","1","","7","","","13-16 Jan. 2012","","IEEE","IEEE Conference Publications"
"Open Innovation Portal: A collaborative platform for open city data sharing","M. Stephenson; G. Di Lorenzo; P. M. Aonghusa","IBM Dublin Research Laboratory, IBM Research, Dublin, Ireland","2012 IEEE International Conference on Pervasive Computing and Communications Workshops","20120510","2012","","","522","524","In recent years, many agencies and government authorities have been moving toward opening up their datasets, allowing external parties to create applications that can mash up this data. As the amount and the variety of data is increasing, it is important to create good metadata (descriptions, geographical boundaries, limitations, etc.) in order to allow individuals, who may not be domain experts, to easily search and consume data. In this paper we propose the Open Innovation Portal (OIP), a collaborative platform that allows Cities to annotate, publish and provide access to urban data from multiple sources in an intuitive, consistent and scalable way through open standards. In collaboration with Dublin City authorities and National University of Ireland Maynooth, we implemented a first prototype for Dublin. In the demo, we show how the collaborative metadata creation process works, from the raw data to the publishable information, and how the collaborative platform can be implemented both for a mobile-phone and web application.","","Electronic:978-1-4673-0907-3; POD:978-1-4673-0905-9","10.1109/PerComW.2012.6197556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197556","collaborative platform;open data;pervasive application","Cities and towns;Collaboration;Communities;Government;Portals;Servers;Technological innovation","Internet;electronic publishing;groupware;information retrieval;innovation management;meta data;mobile computing;mobile handsets;portals;public administration","Dublin City authorities;National University of Ireland Maynooth;Web application;collaborative metadata creation process;collaborative platform;data annotation;government authorities;mobile phone application;open city data sharing;open innovation portal;publishable information;urban data access","","1","","6","","","19-23 March 2012","","IEEE","IEEE Conference Publications"
"The Quantitative Model of User Interests Based on Web Log","Y. Qiu; G. Lin","Sch. of Comput. Sci. & Technol., CUMT, Xuzhou, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","3","","723","725","Based on user interests, the personalized service has become a popular research in academic and commercial applications. This paper analyzes the user interests in the domestic and foreign research situation. It come up with a way to obtain the User Interests data in Web log mining. What's more, in order to solve the dynamic updating user interests. This paper proposes a new quantitative model of user interests.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.433","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188207","Quantitative model;Web log mining;individuation;user interests","Analytical models;Computational modeling;Computer science;Computers;Educational institutions;Web mining","Internet;data mining;information retrieval","Web log mining;academic application;commercial application;domestic research situation;foreign research situation;personalized service;quantitative model;user interest","","0","","10","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Content retrieval using cloud-based DNS","R. Khosla; S. Fahmy; Y. C. Hu","Purdue University, USA","2012 Proceedings IEEE INFOCOM Workshops","20120503","2012","","","1","6","Cloud-computing systems are rapidly gaining momentum, providing flexible alternatives to many services. We study the Domain Name System (DNS) service, used to convert host names to IP addresses, which has historically been provided by a client's Internet Service Provider (ISP). With the advent of cloud-based DNS providers such as Google and OpenDNS, clients are increasingly using these DNS systems for URL and other name resolution. Performance degradation with cloud-based DNS has been reported, especially when accessing content hosted on highly distributed CDNs like Akamai. In this work, we investigate this problem in depth using Akamai as the content provider and Google DNS as the cloud-based DNS system. We demonstrate that the problem is rooted in the disparity between the number and location of servers of the two providers, and develop a new technique for geolocating data centers of cloud providers. Additionally, we explore the design space of methods for cloud-based DNS systems to be effective. Client-side, cloud-side, and hybrid approaches are presented and compared, with the goal of achieving the best client-perceived performance. Our work yields valuable insight into Akamai's DNS system, revealing previously unknown features.","","Electronic:978-1-4673-1017-8; POD:978-1-4673-1016-1","10.1109/INFCOMW.2012.6193491","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6193491","","Cloud computing;Geology;Google;IP networks;Servers;Space exploration","IP networks;cloud computing;information retrieval","Google;IP addresses;ISP;Internet service provider;OpenDNS;cloud based DNS;cloud computing systems;cloud providers;content retrieval;domain name system;geolocating data centers;host names;server location","","3","","26","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"The Target Quick Searching Strategy Based on Visual Attention","H. Wang; G. Liu; Y. Dang","Coll. of Comput. Sci. & Eng., Changchun Univ. of Technol., Changchun, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","3","","460","462","A target quick searching strategy based on visual attention under the known formal context is proposed in paper. It can improve the efficiency of target searching with the computer algorithm of visual attention. The merit of our paper is the improvement of visual attention top-down guiding algorithm. The total visual attention process is divided into the process of visual information extraction and visual attention guiding in paper. The algorithm of visual attention guiding layer is designed. It can find the key feature of the target based on the calculation among the feature information of all objects in formal context of current task to guide the formation of bottom-up saliency map, and it can improve the efficiency of target searching further.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188278","saliency map;target searching;top-down guiding;visual attention","Context;Data mining;Feature extraction;Image color analysis;Search problems;Shape;Visualization","feature extraction;information retrieval","bottom-up saliency map;formal context;target quick searching strategy;target searching efficiency improvement;total visual attention process;visual attention computer algorithm;visual attention guiding layer design;visual attention guiding process;visual attention top-down guiding algorithm;visual information extraction process","","1","","13","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Distributed matchmaking and ranking of Web APIs exploiting descriptions from Web sources","L. Panziera; M. Comerio; M. Palmonari; F. De Paoli","University of Milano-Bicocca, Milan, Italy","2011 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)","20120309","2011","","","1","8","Semantic Web service (SWS) technology promotes the definition of Web service descriptions with semantic annotations to better support Web service selection. Unfortunately, SWS descriptions tend to be huge and complex and their evaluation is characterized by limited scalability. The result is that very few descriptions exist in reality. Web service providers prefer to publish functional and non-functional properties (NFPs) of their RESTful services, also called Web APIs, by means of structured data (e.g., XML, JSON) or textual descriptions. In this paper we define an effective and efficient distributed matchmaking for Web API ranking based on: (i) techniques for the extraction of property descriptions from heterogeneous, dynamic and distributed information on the Web and (ii) a distributed architecture to improve the performance of the Web API matchmaking processes.","2163-2871;21632871","Electronic:978-1-4673-0319-4; POD:978-1-4673-0318-7","10.1109/SOCA.2011.6166201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166201","Web API matchmaking;Web data extraction;semantic techniques","","Web services;application program interfaces;data structures;information retrieval;semantic Web;software architecture;software performance evaluation","RESTful services;SWS descriptions;Web API matchmaking processes;Web API ranking;Web service descriptions;Web service selection;Web sources;data structure;distributed architecture;distributed matchmaking;distributed ranking;functional properties;nonfunctional properties;performance improvement;property description extraction;semantic Web service technology;semantic annotations","","2","","23","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"On Providing Integrity for Dynamic Data Based on the Third-party Verifier in Cloud Computing","S. Ni-Na; Z. Hai-Yan","Electron. Eng. Inst., Hefei, China","2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control","20120220","2011","","","521","524","Cloud Computing has been envisioned as the next-generation architecture of IT Enterprise. More and more users store data in ""clouds"". As such, it has become crucial for an archive service to be capable of providing evidence to demonstrate the integrity of data for which it is responsible. This work studies the problem of ensuring the integrity of data storage in Cloud Computing. In our work, we consider the task of allowing a third party verifier (TPV), on behalf of the cloud client, to verify the integrity of the dynamic data stored in the cloud. In particular, to achieve efficient data dynamics, we improve the Proof of Retrievability model by manipulating the classic Merkle Hash Tree (MHT) construction for block tag authentication. Extensive performance analysis show that the proposed scheme is highly efficient.","","Electronic:978-0-7695-4519-6; POD:978-1-4577-1367-5","10.1109/IMCCC.2011.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6154160","Merkle Hash Tree;cloud computing;integrity;public verifiability;third party verifier","Authentication;Cloud computing;Cryptography;Memory;Protocols;Servers","authorisation;business data processing;client-server systems;cloud computing;cryptography;data integrity;file organisation;information industry;information retrieval","IT enterprise;MHT construction;Merkle hash tree;block tag authentication;cloud client;cloud computing;dynamic data integrity;next-generation architecture;proof of retrievability model;third-party verifier","","1","","7","","","21-23 Oct. 2011","","IEEE","IEEE Conference Publications"
"Anesthesia Information Management System in cardiac surgery","M. Cossu; P. A. Furfori; A. Taddei; M. Mangione; P. Del Sarto","G. Monasterio CNR/Tuscany Region Foundation G. Pasquinucci Heart Hospital, Massa, Italy","2011 Computing in Cardiology","20120309","2011","","","577","580","A new Anesthesia Information Management System has been developed at Heart Hospital of G. Monasterio CNR - Tuscany Region Foundation in Massa. It is specialized in recording anesthesia-related perioperative patient data during cardiac surgery on either adult or pediatric patients. The system was aimed at integrating all patient data partly filled in by the operator, partly SQL-retrieved from the Hospital Information System, and partly gathered, by HL7, from Operating Room instrumentation. Software was developed in Java, achieving reliability and cross-platform capability. Operation reports for surgeon's convenience are automatically created in the HIS medical record at start of surgery. HTML reports are provided and printed out. AIMS was introduced in ORs since March 2011, using medical-grade computers close to patient bed. This system could be potentially deployed to other institutions, not limiting to cardiac interventions.","0276-6574;02766574","Electronic:978-1-4577-0611-0; POD:978-1-4577-0612-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164631","","Anesthesia;Databases;Graphical user interfaces;Heart;Hospitals;Information systems;Surgery","Java;SQL;cardiology;data integration;data recording;hospitals;hypermedia markup languages;information management;information retrieval;medical information systems;software reliability;surgery","AIMS;G. Monasterio CNR;HIS medical record;HL7;HTML reports;Java;Massa;Tuscany Region Foundation;anesthesia information management system;anesthesia-related perioperative patient data recording;cardiac surgery;heart hospital;hospital information system;operating room instrumentation;patient data integration","","0","","3","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"FoSSicker: A personalized search engine by location-awareness","M. Sun; W. Sun; L. Shu; M. Li; L. Xue","Software School, Dalian University of Technology, China 116620","2012 International Conference on Computing, Networking and Communications (ICNC)","20120312","2012","","","456","460","With the rapid growth of Web documents collection, achieving high precision at the top retrieved documents has become a major issue for the search engine users, especially for the different needs of users for the same query. The typical search engines retrieve the same search results to users that cannot satisfy users any more. In this paper, we introduce a location-aware search engine based on machine learning (FoSSicker) to enhance the precision of web search which takes information parsed from IP address as context to personalize the search results. Moreover, we use history (users' clickthrough data) to intelligentize the search engine to top the Web document which is mostly wanted. By experiments, this intelligent search engine is proved to be a faster reactor compared with the existing personalized search engines.","","Electronic:978-1-4673-0009-4; POD:978-1-4673-0008-7; USB:978-1-4673-0723-9","10.1109/ICCNC.2012.6167463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6167463","","Communities;Context;Educational institutions;IP networks;Search engines;Sun;Web search","document handling;information retrieval;learning (artificial intelligence);mobile computing;search engines","FoSSicker;IP address;Web documents collection;Web search;document retrieval;intelligent search engine;location-aware search engine;location-awareness;machine learning;personalized search engine;user clickthrough data","","1","","8","","","Jan. 30 2012-Feb. 2 2012","","IEEE","IEEE Conference Publications"
"Open sensor platform: Integration of sensors and mobile phones","A. Munawar; A. Masood; F. Bangash","Avionics Department, Institute of Avionics and Aeronautics, Air University, Islamabad, Pakistan","Proceedings of 2012 9th International Bhurban Conference on Applied Sciences & Technology (IBCAST)","20120403","2012","","","445","452","We propose an Open Sensor Platform, based on Open System Architecture design, for the integration of mobile phone (MP) and sensors. This platform utilizes commercial off-the-shelf (COTS) available hardware and software tools, thereby eliminating the need for custom-designed sensor's integration boards. The design involves Data Acquisition (DAQ) device, attached with Host PC, providing an interface to communicate with sensors. Sensors data is read from DAQ via Host PC application and on request wirelessly sent to MP. Mobile phone is used as an information retrieval agent, in order to retrieve the sensory data and onward forwarding the information to end user via Cellular or Web services. This integration eliminates the need for dedicated circuitry in sensors, allows the addition of several types of sensors and implements multiple wireless protocols (BT or Wi-Fi), keeping in view the requirement of range and data rate. Sensors history data is maintained on Host PC, where detailed analysis may be performed. Mobile phone applications are developed using Native language, while Host PC applications are developed in Graphical language, which results into full featured, efficient and user friendly applications development. The feasibility of our solution is supported by the case study under taken, where we validated our design with the help of prototype open sensor platform. Its multiple applications include; monitoring the test chamber's internal conditions, fetching environmental parameters, laboratory experimentations etc. This work successfully achieves the integration of sensors and mobile phone in a promising way.","2151-1403;21511403","Electronic:978-1-4577-1929-5; POD:978-1-4577-1928-8","10.1109/IBCAST.2012.6177597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6177597","Bluetooth;COTS;DAQ;Integration;Open Sensor;WSN;Wi-Fi","Communication cables;Hardware;IEEE 802.11 Standards;Logic gates;Silicon compounds;Software;Wireless sensor networks","Bluetooth;Web services;cellular radio;condition monitoring;data acquisition;information retrieval;mobile ad hoc networks;mobile computing;mobile handsets;open systems;protocols;telecommunication computing;wireless LAN;wireless sensor networks","BT;COTS;DAQ device;Web services;cellular services;commercial off-the-shelf;data acquisition device;dedicated circuitry;graphical language;hardware tools;host PC application;information retrieval agent;mobile phone applications;mobile phone integration;mobile phones;multiple wireless protocols;native language;open system architecture design;prototype open sensor platform;sensor integration boards;sensory data;software tools;user friendly applications development;wi-fi","","0","","22","","","9-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"Research on semi-supervised Chinese relation type discovery","Xiaofang Yang; Jinxiu Chen; Ruqi Lin; Jiazhen Zhang","Cognitive Science Department, Xiamen University, Fujian Key Laboratory of the Brain-like Intelligent Systems, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","2070","2074","In this paper, we propose a novel semi-supervised model to discover those missing relation types in labeled corpus and fulfill the aim of relation extraction automatically. We combine language information and structured information to represent candidate relation instances. First, we make use of Bootstrapping and Label Propagation algorithms to label the relation instances, whose types have existed in corpus. Second, we use unsupervised method to cluster the remaining relation instances and discover the missing relation types. Evaluation on the ACE2005 corpus shows that our proposed method can achieve ideal experimental results.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182378","Relation extraction;Semi-supervised learning;Type discovery","Business;Employment;Tagging","information retrieval;natural languages;unsupervised learning","ACE2005 corpus;bootstrapping algorithm;candidate relation instance representation;information extraction;label propagation algorithm;labeled corpus;language information;relation extraction;semi-supervised Chinese relation type discovery;structured information;unsupervised method","","0","","16","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Concept of stochastic memory & data retrieval using artificial neural networks increasing memory capacity and data security by data overlapping","S. Roy; A. Kundu","Department of Computer Science & Engineering, Indian School of Mines, Dhanbad, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","468","473","This paper presents the concept of a physical memory whose state is dependent on a stochastic variable. The stochastic parameter used is temperature. This gives way to efficient space utilization by overlapping data patches upon existing data and overcoming the upper limit of storage space, i.e. more storage data with less hardware and more data security. Furthermore, the paper goes on to present retrieval solutions, for such overlapped data patch structures, using Deep Belief Networks made up of layers of. Restricted Boltzmann machines (RBM), along with mapping with a Bidirectional Associative Memory (BAM).","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194623","Adaptive Learning;Bidirectional Associative Memory (BAM);Boltzmann machine (BM);Data Patch Structures;Deep Belief Nets;Gibb's sampling;Markov Chains;Parallel Tampering (PT);Restricted Boltzmann Machine (RBM);Stochastic memory","Associative memory;Data models;Floors;Machine learning;Neurons;Training;Vectors","Boltzmann machines;information retrieval;security of data;stochastic processes","BAM;RBM;artificial neural networks;bidirectional associative memory;data overlapping;data patch structures;data retrieval;data security;deep belief networks;memory capacity;physical memory;restricted Boltzmann machines;stochastic memory;stochastic parameter;stochastic variable;storage space","","0","","23","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"Aggnel: An Information Aggregation System of Partial Contents from Multiple Web Pages","Y. Tasaki; T. Fukuhara; T. Satoh","Grad. Sch. of Libr. Inf. & Media Studies, Univ. of Tsukuba, Tsukuba, Japan","2012 26th International Conference on Advanced Information Networking and Applications Workshops","20120419","2012","","","815","820","An information aggregation system that captures partial contents of a Web page across multiple Web pages is described. When we search on the Web, we often bookmark or print out Web pages. These kinds of actions are especially needed in order to survey a research field, or when we write a report on a topic. Current search engines do not support these activities, they only return whole Web pages. For facilitating a survey or writing a report, we need partial contents of a Web page which contains key information. In this paper, we propose an information aggregation method that extracts partial contents of a Web page. The proposed system called Aggnel is implemented as prototype system which aggregates partial contents from multiple Web pages. The effectiveness of proposed method is evaluated by experiment, so that it is concluded that users were able to aggregate key information.","","Electronic:978-0-7695-4652-0; POD:978-1-4673-0867-0","10.1109/WAINA.2012.213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185495","attention area;information aggregation;information extraction","Aggregates;Browsers;Data mining;HTML;Prototypes;Search engines;Web pages","Web sites;information retrieval;search engines","Aggnel;Web page bookmarking;Web page printing out;Web searching;information aggregation system;multiple Web pages;partial content extraction;search engines","","0","","6","","","26-29 March 2012","","IEEE","IEEE Conference Publications"
"Study on sparse microwave imaging","Yirong Wu","Science and Technology on Microwave Imaging Laboratory, Institute of Electronics, Chinese Academy of Sciences, China","Proceedings of 2011 IEEE CIE International Conference on Radar","20120301","2011","1","","9","9","Sparse signal processing is introduced to microwave imaging technology, which forms a new theory, new system and new methodology in microwave imaging. Defined as sparse microwave imaging, it means that by the sparse domain representation of the observed object, the sparse microwave signal is acquired by sparse sampling in space or time domain. After the signal processing and information extraction, the geometrical and physical characteristics of the observed object can be acquired with lower data rate and less hardware complexity of the imaging radar.","1097-5764;10975764","Electronic:978-1-4244-8443-0; POD:978-1-4244-8444-7","10.1109/CIE-Radar.2011.6159707","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6159707","","Earth;Microwave imaging;Microwave technology;Radar imaging;Signal processing algorithms","image representation;image sampling;information retrieval;microwave imaging;radar imaging;time-domain analysis","hardware complexity;information extraction;radar imaging;sparse domain representation;sparse microwave imaging technology;sparse microwave signal processing;sparse sampling;time domain","","0","","","","","24-27 Oct. 2011","","IEEE","IEEE Conference Publications"
"Leveraging knowledge based question answer technology to address user-interactive short domain question in natural language","M. Mishra; V. K. Mishra; H. R. Sharma","SOA, Bhuneshwar","2012 2nd National Conference on Computational Intelligence and Signal Processing (CISP)","20120426","2012","","","86","90","With the rapid growth of the Internet and database technologies in recent years, question answering systems (QAS) have emerged as important applications. Although many QAS have been implemented, little work has been done on the development of a user-centered evaluation for QAS. User-centered evaluation is used to understand a user's needs and identify important dimensions and factors in the development of an information system in order to improve its acceptance. This paper presents the application of understanding of short domain question in natural language to data query. The word segmentation tool, IK Analyzer, which is extended with the obtained domain dictionary, is used to segment the short text questions. From the segmentation results, the keywords are extracted to obtain query target and query requirement of the question and to generate a SQL statement for data query. The method proposed in this paper can be applied to question-answering system based on database and to develop a user-centered evaluation model for QAS from the user's perspective for enhancing the user satisfaction and acceptance of QAS.","","Electronic:978-1-4577-0720-9; POD:978-1-4577-0719-3","10.1109/NCCISP.2012.6189683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189683","Evaluation;Measurement;Question answering system;User satisfaction;domain dictionary;segmentation tool","Analytical models;Data mining;Data models;Databases;Dictionaries;Information systems;Natural languages","database management systems;natural language processing;query processing;question answering (information retrieval);user interfaces","Internet;SQL statement;Structured Query Language;data query;database technology;domain dictionary;information system;knowledge based question answer technology;natural language;query requirement;query target;short text question segmentation;user acceptance;user need;user satisfaction;user-centered evaluation;user-interactive short domain question;word segmentation tool","","1","","14","","","2-3 March 2012","","IEEE","IEEE Conference Publications"
"Estimating document frequencies in a speech corpus","D. Karakos; M. Dredze; K. Church; A. Jansen; S. Khudanpur","Human Language Technology Center of Excellence, Johns Hopkins University, Baltimore, MD, USA","2011 IEEE Workshop on Automatic Speech Recognition & Understanding","20120305","2011","","","407","412","Inverse Document Frequency (IDF) is an important quantity in many applications, including Information Retrieval. IDF is defined in terms of document frequency, df (w), the number of documents that mention w at least once. This quantity is relatively easy to compute over textual documents, but spoken documents are more challenging. This paper considers two baselines: (1) an estimate based on the 1-best ASR output and (2) an estimate based on expected term frequencies computed from the lattice. We improve over these baselines by taking advantage of repetition. Whatever the document is about is likely to be repeated, unlike ASR errors, which tend to be more random (Poisson). In addition, we find it helpful to consider an ensemble of language models. There is an opportunity for the ensemble to reduce noise, assuming that the errors across language models are relatively uncorrelated. The opportunity for improvement is larger when WER is high. This paper considers a pairing task application that could benefit from improved estimates of df. The pairing task inputs conversational sides from the English Fisher corpus and outputs estimates of which sides were from the same conversation. Better estimates of df lead to better performance on this task.","","Electronic:978-1-4673-0367-5; POD:978-1-4673-0365-1; USB:978-1-4673-0366-8","10.1109/ASRU.2011.6163966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163966","","Adaptation models;Computational modeling;Frequency estimation;Lattices;Speech;Training;Training data","document handling;information retrieval;speech processing","1-best ASR output;English Fisher corpus;information retrieval;inverse document frequency;language models;noise reduction;pairing task application;speech corpus;word error rate","","5","","12","","","11-15 Dec. 2011","","IEEE","IEEE Conference Publications"
"The Application of Broad First Minimum Spanning Tree Algorithm Based on Prim Algorithm in P2P Network","T. Xiang; J. Li","Grad. Dept., Yunnan Normal Univ., Kunming, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","3","","286","289","To improve information retrieval speed, it is the key of minimizing traffic and every required visit peer on the view of reducing traffic, combining the merit of width first search won't lead to redundant and P2P network's dynamic feature, We advanced adopting width first search in local bound-Broad first minimum spanning tree search. It can reduce redundant search packet in some scope. Meanwhile, It won't occupy much network resource in message exchange because of scope is small. The way have good feature in expansibility and robustness. It can adapt to dynamic change in P2P network.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188289","Algorithm;BFMST;P2P;Prim","Algorithm design and analysis;Complexity theory;Computers;Educational institutions;Heuristic algorithms;Peer to peer computing;Routing","information retrieval;peer-to-peer computing;telecommunication network management;telecommunication traffic;trees (mathematics)","P2P network dynamic feature change;Prim algorithm;broad first minimum spanning tree search algorithm;information retrieval;message exchange;network resource;redundant search packet;telecommunication traffic minimization;telecommunication traffic reduction","","1","","4","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Cloud Computing and Consumer Electronics: A Perfect Match or a Hidden Storm? [Soapbox]","P. M. Corcoran","","IEEE Consumer Electronics Magazine","20120322","2012","1","2","14","19","Cloud computing has emerged strongly into the consumer domain. As industry competes to gain market share from the rapidly growing multitudes of cloud-IT users, both network and data center infrastructures will grow more rapidly than anticipated driven bv new thin-client CE devices. The challenge for the designers of new devices and associated applications and services will be how to minimize the digital waste in terms of unnecessary data transport and network storage. Energy is a key mantra here - new devices need to be network savvy and designed to optimize data transport and storage in a wider resource context and time frame than in the past.","2162-2248;21622248","","10.1109/MCE.2011.2181895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6172463","","Cloud computing;Electricity;Energy consumption;Marketing and sales;Portable computers;Smart phones;Telecommunication traffic","cloud computing;consumer electronics;information retrieval;security of data;smart phones","cloud computing;cloud-IT users;consumer electronics;data access;data center infrastructure;data duplication;data storage;data transport;network infrastructure;smart phone;tablet devices;thin-client CE devices","","15","","13","","","April 2012","","IEEE","IEEE Journals & Magazines"
"LAMBDA -- The LSDF Execution Framework for Data Intensive Applications","T. Jejkal; V. Hartmann; R. Stotzka; J. Otte; A. Garcia; J. van Wezel; A. Streit","Inst. for Data Process. & Electron. (IPE), Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing","20120315","2012","","","213","220","To cope with the growing requirements of data intensive scientific experiments, models and simulations the Large Scale Data Facility (LSDF) at KIT aims to support many scientific disciplines. The LSDF is a distributed storage facility at Exabyte scale providing storage, archives, data bases and meta data repositories. Apart from data storage many scientific communities need to perform data processing operations as well. For this purpose the LSDF Execution Framework for Data Intensive Applications (LAMBDA) was developed to allow asynchronous high-performance data processing next to the LSDF. However, it is not restricted to the LSDF or any special feature only available at the LSDF. The main goal of LAMBDA is to simplify large scale data processing for scientific users by reducing complexity, responsibility and error-proneness. The description of an execution is realized as part of LAMBDA administration in the background via meta data that can be obtained from arbitrary sources. Thus, the scientific user has only to select which applications he wants to apply to his data.","1066-6192;10666192","Electronic:978-0-7695-4633-9; POD:978-1-4673-0226-5","10.1109/PDP.2012.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169552","Hadoop;LSDF;Large Scale Data Facility;data intensive science;data processing;meta data","Communities;Data processing;Microscopy;Monitoring;Reliability;Runtime;Software","distributed databases;information retrieval systems;large-scale systems;meta data;storage management","LAMBDA;LSDF execution framework;archives;asynchronous high-performance data processing;complexity reduction;data intensive applications;distributed databases;distributed storage facility;error-proneness reduction;exabyte scale providing storage;large scale data facility;large scale data processing;meta data repositories;responsibility reduction;scientific user","","3","","23","","","15-17 Feb. 2012","","IEEE","IEEE Conference Publications"
"A Novel Information Acquisition Technique for Mobile-Assisted Wireless Sensor Networks","F. Bai; K. S. Munasinghe; A. Jamalipour","School of Electrical and Information Engineering, University of Sydney, Sydney , Australia","IEEE Transactions on Vehicular Technology","20120508","2012","61","4","1752","1761","In this paper, we propose an adaptive data-harvesting approach for mobile-agent-assisted data collection in wireless sensor networks (WSNs) inspired by Behavioral Ecology. By using the marginal value theorem, we divide the entire sensor field into small patches and gather the correlated data from each patch. Each observation <i>X</i> gathered by a given sensor node to be considered to be a marginal information source with a relative standard deviation σ(<i>x</i>|<i>Y</i>, <i>I</i>), where <i>Y</i> is a set of previously collected observations by the mobile agent, and <i>I</i> is the background knowledge learned from the sensor field. The mobile agent estimates the correlation based on the available knowledge gathered from the current patch and the previous patches and then chooses the next visiting sensor node. The next node should have the maximum information gain obtained until σ(<i>x</i>|<i>Y</i>, <i>I</i>) is smaller than a predefined threshold (<i>TH</i>). Since, in a dynamically changing environment, the correlation varies among different patches, an efficient way to understand the correlation model is the key to efficient data harvesting. The proposed estimation technique of the marginal value theorem, which is called estimation technique based on the marginal value theorem (EMVT), is used to maintain the fidelity of the interested data with relatively fewer collected sensor observations.","0018-9545;00189545","","10.1109/TVT.2012.2188657","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156475","Behavioral ecology;data acquisition;marginal value theorem;mobile agents;wireless sensor networks (WSNs)","Correlation;Equations;Mobile agents;Mobile communication;Random variables;Robot sensing systems;Wireless sensor networks","data mining;information retrieval;mobile agents;mobile communication;wireless sensor networks","EMVT;WSN;adaptive data-harvesting approach;behavioral ecology;data harvesting;e marginal value theorem;information acquisition technique;marginal information source;mobile agent;mobile-agent-assisted data collection;mobile-assisted wireless sensor networks;sensor node","","8","","31","","20120222","May 2012","","IEEE","IEEE Journals & Magazines"
"Challenges and issues on online news management","W. M. S. Yafooz; S. Z. Z. Abidin; N. Omar","Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, MALAYSIA","2011 IEEE International Conference on Control System, Computing and Engineering","20120426","2011","","","482","487","Recently, the Internet usage spread in all areas of life. Online news is among the popular articles on the Internet, which occupies a large portion of online information. The online news will be viewed almost every second in order to follow the evolution of any desired global events. There are many organizations or political parties employ agents for tracking news by grouping the event. Therefore, news clustering is helpful and worthy for many researchers and online news readers in order to view events from multiple perspectives. Additionally, it can be used in online news summarization, topic detection and tracking for extracting and detecting new events or topics in the news articles. The news extraction can be applied on news articles in the form of monolingual or multilingual. On the other hand, news aggregation is the most important method for scrawling and collecting events based on topics or categorization. This paper investigates the challenges and issues that relate to online news research. The discussions include the overview of system architectures, online news techniques, and a few related computer applications for the above mentioned online news areas.","","Electronic:978-1-4577-1642-3; POD:978-1-4577-1640-9","10.1109/ICCSCE.2011.6190574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190574","Detect Topic and Tracking Named Entity Recognition;Multilingual News;News Clustering;News Summarization;Online News","Computer architecture;Conferences;Control systems;Data mining;HTML;Natural language processing;Synchronization","Internet;information retrieval;pattern clustering;text analysis","Internet usage;news aggregation;news clustering;news extraction;news tracking;online information;online news management;online news summarization;online news technique;topic detection","","3","","52","","","25-27 Nov. 2011","","IEEE","IEEE Conference Publications"
"Exploring Context and Content Links in Social Media: A Latent Space Method","G. J. Qi; C. Aggarwal; Q. Tian; H. Ji; T. Huang","University of Illinois at Urbana-Champaign, Urbana","IEEE Transactions on Pattern Analysis and Machine Intelligence","20120322","2012","34","5","850","862","Social media networks contain both content and context-specific information. Most existing methods work with either of the two for the purpose of multimedia mining and retrieval. In reality, both content and context information are rich sources of information for mining, and the full power of mining and processing algorithms can be realized only with the use of a combination of the two. This paper proposes a new algorithm which mines both context and content links in social media networks to discover the underlying latent semantic space. This mapping of the multimedia objects into latent feature vectors enables the use of any off-the-shelf multimedia retrieval algorithms. Compared to the state-of-the-art latent methods in multimedia analysis, this algorithm effectively solves the problem of sparse context links by mining the geometric structure underlying the content links between multimedia objects. Specifically for multimedia annotation, we show that an effective algorithm can be developed to directly construct annotation models by simultaneously leveraging both context and content information based on latent structure between correlated semantic concepts. We conduct experiments on the Flickr data set, which contains user tags linked with images. We illustrate the advantages of our approach over the state-of-the-art multimedia retrieval techniques.","0162-8828;01628828","","10.1109/TPAMI.2011.191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035718","Context and content links;latent semantic space;low-rank method;multimedia information networks.;social Media","Context;Context modeling;Large scale integration;Media;Multimedia communication;Semantics;Visualization","data mining;information retrieval;multimedia systems;social networking (online)","Flickr data set;content links;content-specific information;context links;context-specific information;correlated semantic concepts;geometric structure;latent feature vectors;latent semantic space;latent structure;multimedia annotation;multimedia mining;multimedia objects;multimedia retrieval algorithms;social media networks;user tags","Algorithms;Animals;Computer Communication Networks;Data Mining;Humans;Image Processing, Computer-Assisted;Information Storage and Retrieval;Models, Theoretical;Multimedia;Semantics;Social Media","32","","31","","20111006","May 2012","","IEEE","IEEE Journals & Magazines"
"FAQ Auto Constructing Based on Clustering","J. Mao; J. Zhu","Beijing Inst. of Technol., Beijing, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","1","","468","472","FAQ can make QA System easily constructed and effective and therefore can be used as one part of a complex QA System. As the base of the FAQ, FAQ database has an important impact on the performance of the whole QA system. In this paper, we improved the clustering method, and combine it with the similarity algorithm to automatically construct the FAQ database. This method helps to construct the FAQ automatically, and doesn't require too much manual intervention. Compared to other auto constructing methods, the coverage of the FAQ constructed by our method is extremely larger than others.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.229","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187887","Clustering;FAQ Auto Constructing;Question Answering System","Clustering algorithms;Clustering methods;Databases;Information filters;Sorting;Vectors","database management systems;pattern clustering;question answering (information retrieval)","FAQ auto constructing;FAQ database;QA system;clustering method","","0","","6","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Mechanism of determining page faults instantaneously via device driver based approach in Linux","S. M. Laeeq; D. R. Borade","Real Time Embedded Systems, Computer Engineering, M. S. Ramaiah School of Advanced Studies, Bangalore, India","Electrical, Electronics and Computer Science (SCEECS), 2012 IEEE Students' Conference on","20120423","2012","","","1","5","Page faults and the algorithm of paging used in the kernel are an important aspect of the overall functioning of the system. This does add an overhead to the overall processing. Numerous algorithms and their improvements exist for paging but miss an important point. The ability to statistically assess and gather data about major and minor page faults at run time are missing. In this paper, we propose an approach to solve this problem by the mechanism of adding our device driver in the kernel. The driver when invoked from kernel space gathers data from numerous data structures which the kernel maintains and computes. This computation then delivers the major and minor page faults occurred by user space applications at that instant. We believe by using our unique approach in measuring page faults by paging algorithms, these can be statistically backed and will help in optimizing the overall performance of the Linux kernel.","","Electronic:978-1-4673-1515-9; POD:978-1-4673-1516-6","10.1109/SCEECS.2012.6184753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184753","Demand Paging;Device driver;Linux Kernel;Page replacement Algorithms","Algorithm design and analysis;Hardware;Kernel;Linux;Memory management;Performance evaluation","Linux;data structures;device drivers;information retrieval;operating system kernels;paged storage;statistical analysis","Linux kernel performance;data asses;data structures;device driver based approach;kernel space;page fault determination;paging algorithm","","0","","7","","","1-2 March 2012","","IEEE","IEEE Conference Publications"
"Symbolic verification of web crawler functionality and its properties","K. S. Shetty; S. Bhat; S. Singh","Department of Information and Communication Technology, Manipal Institute of Technology, Manipal University, Manipal-576104, India","2012 International Conference on Computer Communication and Informatics","20120301","2012","","","1","6","Now a days people use search engines every now and then to retrieve documents from the Web. Web crawling is the process by which a search engine gather pages from the Web to index them and support a search engine. Web crawlers are the heart of search engines. Web crawlers continuously keep on crawling the web and find any new web pages that have been added to the web, pages that have been removed from the web. Due to growing and dynamic nature of the web, it has become a challenge to traverse through all URLs in the web documents and to handle these URLs. The entire crawling process may be viewed as traversing a web graph. The aim of this paper is to model check the crawling process and crawler properties using a symbolic model checker tool called NuSMV. The basic operation of a hypertext crawler and the crawler properties has been modeled in terms of CTL specification and it is observed that the system takes care of all the constraints by satisfying all the specifications.","","Electronic:978-1-4577-1583-9; POD:978-1-4577-1580-8","10.1109/ICCCI.2012.6158649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158649","Model Checker;NuSMV;Symbolic Model verifier;Web Crawler","Computer architecture;Computers;Crawlers;Informatics;Robots;Search engines;Web pages","Internet;document handling;formal specification;formal verification;graph theory;information retrieval;search engines","CTL specification;NuSMV;URL;Web crawler functionality;Web crawling;Web graph;Web pages;document retrieval;hypertext crawler;search engines;symbolic model checker tool;symbolic verification","","1","","11","","","10-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"Context-Based Electronic Health Record: Toward Patient Specific Healthcare","W. Hsu; R. K. Taira; S. El-Saden; H. Kangarloo; A. A. T. Bui","Department of Radiological Sciences , University of California, Los Angeles, USA","IEEE Transactions on Information Technology in Biomedicine","20120305","2012","16","2","228","234","Due to the increasingly data-intensive clinical environment, physicians now have unprecedented access to detailed clinical information from a multitude of sources. However, applying this information to guide medical decisions for a specific patient case remains challenging. One issue is related to presenting information to the practitioner: displaying a large (irrelevant) amount of information often leads to information overload. Next-generation interfaces for the electronic health record (EHR) should not only make patient data easily searchable and accessible, but also synthesize fragments of evidence documented in the entire record to understand the etiology of a disease and its clinical manifestation in individual patients. In this paper, we describe our efforts toward creating a context-based EHR, which employs biomedical ontologies and (graphical) disease models as sources of domain knowledge to identify relevant parts of the record to display. We hypothesize that knowledge (e.g., variables, relationships) from these sources can be used to standardize, annotate, and contextualize information from the patient record, improving access to relevant parts of the record and informing medical decision making. To achieve this goal, we describe a framework that aggregates and extracts findings and attributes from free-text clinical reports, maps findings to concepts in available knowledge sources, and generates a tailored presentation of the record based on the information needs of the user. We have implemented this framework in a system called Adaptive EHR, demonstrating its capabilities to present and synthesize information from neurooncology patients. This paper highlights the challenges and potential applications of leveraging disease models to improve the access, integration, and interpretation of clinical patient data.","1089-7771;10897771","","10.1109/TITB.2012.2186149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6144740","Data visualization;health information management;knowledge representation;natural language processing (NLP)","Biological system modeling;Diseases;Medical diagnostic imaging;Natural language processing;Ontologies","biomedical engineering;computer graphics;content-based retrieval;data integration;diseases;health care;information retrieval;medical information systems;neurophysiology;ontologies (artificial intelligence)","adaptive EHR;biomedical ontologies;context based electronic health record;data access;data integration;data intensive clinical environment;data interpretation;graphical disease models;medical decision making;neurooncology patients;patient specific healthcare","Database Management Systems;Electronic Health Records;Humans;Individualized Medicine;Models, Theoretical;Natural Language Processing;User-Computer Interface","21","","31","","20120201","March 2012","","IEEE","IEEE Journals & Magazines"
"Hadoop-HBase for large-scale data","Mehul Nalin Vora","Innovation Labs, PERC, Tata Consultancy Services (TCS) Ltd., Mumbai, India","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","1","","601","605","Today we are inundated with digital data. Yet we are very poor in managing and processing it. It is becoming increasingly difficult to store and analyze data efficiently and economically via conventional database management tools. Not only that, type of data, appearing in the databases, are also changing. Now a day, binary large objects are a standard integral part of any database. Researchers, all over the globe, are baffling with analysis of these ultra large databases. Apache HBase is one such attempt. HBase is a noSQL distributed database developed on top of Hadoop Distributed File System (HDFS). In this paper, we present an evaluation of hybrid architecture where HDFS contains the non-textual data like images and location of such data is stored in HBase. This hybrid architecture enables faster search and retrieval of the data which is a growing need in any organization who are flooded with data. The paper aims at evaluating the performance of random reads and random writes of data storage location information to HBase and retrieving and storing data in HDFS respectively. We also present a comparative study of HBase-HDFS architecture with MySQL-HDFS architecture.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182030","HBase;HDFS;Hadoop;Map Reduce;distributed storage;large-scale data;noSQL database","Computer architecture;Distributed databases;Fault tolerance;File systems;Hardware;Time factors","SQL;distributed databases;information retrieval","Apache HBase;HBase-HDFS architecture;Hadoop distributed file system;Hadoop-HBase;MySQL-HDFS architecture;conventional database management tools;data retrieval;data storage location information;hybrid architecture;large-scale data;noSQL distributed database;nontextual data;organization;random reads;random writes","","20","","20","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Searching Simulation Scenarios on the Grid with ELSIGExplorer","I. L. Muntean; L. M. Dansorean","Comput. Sci. Deptartment, Tech. Univ. of Cluj-Napoca, Cluj-Napoca, Romania","2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","20120315","2011","","","261","267","Grids became a commonplace for the computation of expensive numerical simulations. This work addresses the problem of searching for relevant simulations and for their results in a grid. This is challenging especially due to the large number of existing simulations, the small semantic differences between them, and the distributed nature of the grid environment. We propose a solution that addresses simultaneously these three challenges by integrating a latent semantic indexing algorithm a linguistic processing module with a grid application framework. This resulted in a novel prototype, ELSIG Explorer, capable of retrieving relevant scenarios computed with Grid SFEA on heterogeneous grids. We evaluated our approach on benchmark datasets from the medical domain and on a set of scenarios for simulating dynamic behavior of biological neural microcircuits in grid.","","Electronic:978-0-7695-4630-8; POD:978-1-4673-0207-4","10.1109/SYNASC.2011.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169590","","Accuracy;Buildings;Computational modeling;Engines;Indexing;Large scale integration;Semantics","finite element analysis;grid computing;indexing;information retrieval;medical computing;neurophysiology","ELSIGExplorer prototype;Grid SFEA;biological neural microcircuit;grid application framework;heterogeneous grid;latent semantic indexing algorithm;linguistic processing module;medical domain;numerical simulation;scenario retrieval;simulation scenario;singular finite element analysis","","0","","20","","","26-29 Sept. 2011","","IEEE","IEEE Conference Publications"
"Qualitative mapping model of humming melody extraction","W. j. Liu; J. l. Feng","College of Information Engineering, Shanghai Maritime University, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","1650","1653","Some of the humming retrieval system and the qualitative mapping are introduced briefly. Combining with the music theory, a qualitative mapping model for extracting humming melody and its algorithm are given in this paper. The key points of the algorithm are the method to choose the criterion of the note segmentation dynamically and the dynamic measure to determine the pitch of a note. Experiments show that not only a better result of choosing flexibly and reasonably the criterion of the note segmentation can be determined, but also the note pitch can be extracted accurately. Eventually, the contour of humming melody can be achieved too.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182283","melody code;note segmentation;pitch extraction;qualitative mapping","","feature extraction;information retrieval systems;music","dynamic measurement;humming melody extraction;humming retrieval system;music theory;note pitch determination;note segmentation;qualitative mapping model","","0","","13","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Wireless three-pad ECG system: Challenges, design, and evaluations","H. Cao; H. Li; L. Stocco; V. C. M. Leung","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada","Journal of Communications and Networks","20120227","2011","13","2","113","124","Electrocardiography (ECG) is a widely accepted approach for monitoring of cardiac activity and clinical diagnosis of heart diseases. Since cardiologists have been well-trained to accept 12-lead ECG information, a huge number of ECG systems are using such number of electrodes and placement configuration to facilitate fast interpretation. Our goal is to design a wireless ECG system which renders conventional 12-lead ECG information. We pro pose the three-pad ECG system (W3ECG). W3ECG furthers the pad design idea of the single-pad approach. Signals obtained from these three pads, plus their placement information, make it possible to synthesize conventional 12-lead ECG signals. We provide one example of pad placement and evaluate its performance by examining ECG data of four patients available from online database. Feasibility test of our selected pad placement positions show comparable results with respect to the EASI lead system. Experimental results also exhibit high correlations between synthesized and directly observed 12-lead signals (9 out of 12 cross-correlation coefficients higher than 0.75).","1229-2370;12292370","","10.1109/JCN.2011.6157410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6157410","12-lead transformation;electrocardiography (ECG);mobile healthcare","Electric potential;Electrocardiography;Electrodes;Heart;Lead;Vectors;Wireless communication","biomedical electrodes;diseases;electrocardiography;health care;information retrieval systems;information services;patient diagnosis;patient monitoring;telemedicine","cardiac activity monitoring;clinical diagnosis;cross-correlation coefficients;electrocardiography;electrodes;heart diseases;mobile health care;online database;placement configuration;wireless three-pad ECG system","","11","","31","","","April 2011","","IEEE","IEEE Journals & Magazines"
"Latent semantic analysis for question classification with neural networks","B. Loni; S. H. Khoshnevis; P. Wiggers","Department of Media and Knowledge Engineering, Delft University of Technology, PO Box 5031, 2600 GA, Netherlands","2011 IEEE Workshop on Automatic Speech Recognition & Understanding","20120305","2011","","","437","442","An important component of question answering systems is question classification. The task of question classification is to predict the entity type of the answer of a natural language question. Question classification is typically done using machine learning techniques. Most approaches use features based on word unigrams which leads to large feature space. In this work we applied Latent Semantic Analysis (LSA) technique to reduce the large feature space of questions to a much smaller and efficient feature space. We used two different classifiers: Back-Propagation Neural Networks (BPNN) and Support Vector Machines (SVM). We found that applying LSA on question classification can not only make the question classification more time efficient, but it also improves the classification accuracy by removing the redundant features. Furthermore, we discovered that when the original feature space is compact and efficient, its reduced space performs better than a large feature space with a rich set of features. In addition, we found that in the reduced feature space, BPNN performs better than SVMs which are widely used in question classification. Our result on the well known UIUC dataset is competitive with the state-of-the-art in this field, even though we used much smaller feature spaces.","","Electronic:978-1-4673-0367-5; POD:978-1-4673-0365-1; USB:978-1-4673-0366-8","10.1109/ASRU.2011.6163971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163971","","Accuracy;Feature extraction;Kernel;Neurons;Semantics;Support vector machines;Vectors","backpropagation;neural nets;question answering (information retrieval);support vector machines","SVM;back-propagation neural networks;large feature space;latent semantic analysis;machine learning techniques;natural language question;question answering systems;question classification;support vector machines","","1","","23","","","11-15 Dec. 2011","","IEEE","IEEE Conference Publications"
"Lifelogging: Archival and retrieval of continuously recorded audio using wearable devices","M. Shah; B. Mears; C. Chakrabarti; A. Spanias","SenSIP Center, School of ECEE, Arizona State University, Tempe, AZ 85287-5706, USA","2012 IEEE International Conference on Emerging Signal Processing Applications","20120216","2012","","","99","102","We propose a complete system for lifelogging where audio is continuously recorded using a smartphone or a wearable recorder. Recorded audio includes speech, music and environmental sounds. First, we describe a feature-based segmentation algorithm for breaking down a long piece of audio into smaller clips. In order to archive clips into a large database, we present methods for automatically indexing and annotating audio with relevant acoustic and semantic tags. Retrieval is performed using a Query-By-Example based approach. To support our claims, the results are demonstrated via a smart-phone application on the popular Android platform. Finally, we also propose a novel virtualization-based design framework to rapidly develop and test such systems for signal processing.","","Electronic:978-1-4673-0898-4; POD:978-1-4673-0899-1","10.1109/ESPA.2012.6152455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152455","Android;lifelogging;retrieval;tagging","Feature extraction;Hidden Markov models;Indexing;Speech;Trajectory;User interfaces","audio recording;information retrieval;wearable computers","acoustic tags;feature-based segmentation algorithm;lifelogging;query-by-example based approach;recorded audio;semantic tags;signal processing;wearable devices","","5","","10","","","12-14 Jan. 2012","","IEEE","IEEE Conference Publications"
"SpaceAnnotator: A high precision location based asset management system in indoor environment","Lei Song; Yongcai Wang","NEC Labs China","IET International Conference on Communication Technology and Application (ICCTA 2011)","20120507","2011","","","647","651","Asset management is urgently needed in supply chain which requires to solve two basic problems 1) what assets do we have; and 2) where they are? Existing methods exploit barcode and RFID technologies to retrieve the information and quantity of assets. However, the location of asset is still hard to obtain for the lack of suitable location technologies. In this paper, a high precision location based asset management system named SpaceAnnotator is proposed. SpaceAnnotator is implemented based on TOA positioning method using Ultrasound and RF signals. Leveraging the centimeter level positioning accuracy provided by the positioning system, SpaceAnnotator maps the IDs of objects to their locations. Based on the location information, location based service (LBS) in provided for asset management. Compared with conventional location based asset management system, SpaceAnnotator works well even in managing small volume objects for its high accuracy.","","Electronic:978-1-84919-470-9","10.1049/cp.2011.0748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6192945","Asset management system;LAMS;LBS;high precision positioning","","asset management;information retrieval;radiofrequency identification;signal processing;supply chain management;time-of-arrival estimation;ultrasonic applications","RF signal;RFID technology;SpaceAnnotator system;TOA positioning method;asset information retrieval;asset quantity retrieval;barcode technology;location based service;precision location based asset management system;radiofrequency identification;radiofrequency signal;supply chain;time-of-arrival;ultrasound signal","","0","1","","","","14-16 Oct. 2011","","IET","IET Conference Publications"
"Joint learning of named entity recognition and relation extraction","Qiuyan Xu; Fang Li","Dept. of Computer Science & Engineering, Shanghai Jiao Tong University, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","1978","1982","Named entities are important to extract relations. Accurate relation classification helps recognize named entities. The paper presents a joint approach of named entity recognition and relation identification. The identified relation is utilized to improve named entity recognition. The method has been applied to identify the names of persons and organizations and five relations between them. The result shows that the joint approach has improved the recall and F-measure of named entities without scarifying the precision. Meanwhile, the recall and F-measure are also improved in the relation extraction.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182359","joint learning;named entity recognition;relation extraction","Engineering profession;Joints;Organizations","information retrieval;learning (artificial intelligence);pattern classification","F-measure;joint approach;joint learning;named entity recognition;recall measure;relation classification;relation extraction;relation identification","","0","","16","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"A New Type of Learning Experience in Nomadic Inquiry: Use of Zydeco in the Science Center","W. T. Lo; I. Delen; C. Cahill; A. Kuhn; S. Schmoll; C. Quintana","Sch. of Educ., Univ. of Michigan, Ann Arbor, MI, USA","2012 IEEE Seventh International Conference on Wireless, Mobile and Ubiquitous Technology in Education","20120419","2012","","","57","61","Zydeco is a mobile and web based system that allows students to collect and annotate multi-modal data. With the support of Zydeco, students are expected to connect their learning experiences across different learning settings. In this case study, we shadowed four 7th grade students with different achievement levels from a science class and observed how they utilized Zydeco in a science center. We analyzed their data collected with Zydeco and their final project posters to explain how students connect learning experiences in nomadic inquiry.","","Electronic:978-0-7695-4662-9; POD:978-1-4673-0884-7","10.1109/WMUTE.2012.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184997","informal learning;mobile learning;nomadic inquiry","Education;Electricity;Generators;Portable media players;Reflection;Shadow mapping;Videos","Internet;computer aided instruction;information retrieval;mobile computing;natural sciences computing","7th grade students;Web based system;Zydeco;learning experience;learning settings;mobile system;multimodal data annotation;multimodal data collection;nomadic inquiry;science center;science class","","0","","15","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"An ontology-based approach for web information extraction","I. Jellouli; M. E. Mohajir","Computer sciences department, Faculty of sciences DharMahraz, University of Sidi Mohamed Ben Abdelah, Fez, Morocco","2011 Colloquium in Information Science and Technology","20120216","2011","","","5","5","Extracting structured information from pages published on the worldwide web is a problem with many facets that has gained growing interest in recent years. We propose a novel ontology-based approach that can achieve both the extraction and the semantic description of data contained in a web page. Existing methods addressing these issues range from pure manual methods based on rules to systems that can achieve wrapper induction automatically. Automatic systems require web pages with a list of records or a set of similar web pages to deduce the template used to generate them. In most cases, they cannot assign labels to extracted data. Ontology-based systems can automatically extract semantics, but they require an intensive and expertise consuming work to build anthologies that contain syntactic descriptions of attributes to be extracted. Our approach is fully automatic and is based on a ""seeded"" ontology that contains the basic information about the defined domain of interest. It uses an instance-based classifier to characterize the attributes of the ontology. In opposition to existing methods, our approach does not make any prior assumption on the design and the format of web pages, it is totally independent and it is able to achieve semantic extraction from a single web page with a single instance. Our method for localizing the data frame combines Information Retrieval techniques, instance-based classifying and a similarity-measure to the ontology. This combination permits achieving data-region localization, data extraction and label assignment, all in one single step. Experimental results obtained from different web pages of different web sites show that our approach is effective.","2327-185X;2327185X","Electronic:978-1-4673-0115-2; POD:978-1-4673-0116-9","10.1109/CIST.2011.6148583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6148583","Web Information Extraction;ontology;probablistic model classifier","Computers;Data mining;Ontologies;Semantics;Web pages","Web sites;information retrieval;ontologies (artificial intelligence);pattern classification;semantic Web","Web information extraction;Web page;Web sites;Worldwide Web;anthologies;data extraction;data frame;data region localization;information retrieval techniques;instance based classifying;label assignment;ontology based approach;seeded ontology;semantic description;structured information extraction","","1","","","","","11-12 May 2011","","IEEE","IEEE Conference Publications"
"Speaker retrieval based on minimum distance in HCT","Ji-Chen Yang; Yan-Xiong Li; Xiao-hui Feng; Qian-hua He; Jun He","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, 510640, China","IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011)","20120507","2011","","","274","277","In hierarchical cellar tree (HCT), this paper proposes a novel and effective speaker retrieval method based on minimum distance, which can be much better used to calculate the distance of unequal length vectors. In speaker indexing stage, minimum distance is used to control cell mitosis and HCT growing. In speaker retrieval stage, minimum distance is used to retrive the most relevant speakers. Experimental results have demonstrated that the minimum distance can be much better than some common used distance formulas.","","Electronic:978-1-84919-505-8","10.1049/cp.2011.0890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194847","Hierarchical cellar tree;Minimum distance;Speaker indexing;Speaker retrieval","","audio databases;database indexing;information retrieval","HCT;cell mitosis;hierarchical cellar tree;minimum distance;speaker indexing stage;speaker retrieval method;unequal-length vector distance","","0","","","","","14-16 Nov. 2011","","IET","IET Conference Publications"
"Extracting specific categories of text documents using ontology","H. Hajiabadi; M. Hajiabadi; A. H. Tabaraie","Birjand University of Technology, Iran","2011 IEEE International Conference on Computer Applications and Industrial Electronics (ICCAIE)","20120301","2011","","","489","491","Extracting category of web application is important in sharing and organizing information and also is valuable in some search engines. There are numerous resources available on the web that are needed to be categorized efficiently for more practices. But the number of tools which automatically extract the categories of web applications are limited. This paper proposes a novel technique to automatically extract categories of web applications using ontology, then a case study is developed and the results are explained.","","Electronic:978-1-4577-2059-8; POD:978-1-4577-2058-1","10.1109/ICCAIE.2011.6162184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162184","key phrase;key phrase extraction;ontology;text document","Data mining;Electronic publishing;Encyclopedias;Internet;Ontologies;Search engines","information retrieval;ontologies (artificial intelligence);text analysis","Web application category extraction;information organization;information sharing;ontology;search engines;text document category extraction","","0","","7","","","4-7 Dec. 2011","","IEEE","IEEE Conference Publications"
"Editorial: Inaugural issue","H. C. Chao","Inst. of Comput. Sci. & Inf. Eng., Nat. Ilan Univ., Ilan, Taiwan","IET Networks","20120419","2012","1","1","1","1","As its benefits become more and more vivid, the networks have generated business transactions from enterprises and the rest of the society as well at a rapid pace. Networks have already penetrated deeply into our society and people's lives with Mobile and Fixed and/or Wireless Broadband services so that multimedia over wired or wireless architecture can be accessed everywhere. A computer network, is sometimes considered a sub-discipline of electrical engineering, telecommunications, computer science, information technology or computer engineering, as it relies upon the theoretical and practical applications of these disciplines. Two devices are said to be in a network only where at least one process in one device is able to send/receive data to/from at least one process residing in a remote device. Therefore, network is a collection of hardware components and computers interconnected by communication channels that allow sharing of resources and information. Making use of networks will expand far beyond merely accessing Web and E-mail but social networking services. As virtually everything in our social infrastructures and most electrical appliances become connected with Internet through networking, an 'ubiquitous network industry' will provide services and products based upon our understanding of the latest technical trends of networks. Therefore booming business potentials in the forthcoming ubiquitous society are eagerly anticipated.","2047-4954;20474954","","10.1049/iet-net.2012.0065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6186939","","","Internet;broadband networks;electronic mail;information retrieval;multimedia computing;radio networks;resource allocation;social networking (online);transaction processing;ubiquitous computing;wireless channels","E-mail accessing;Internet;Web access;business transactions;communication channel;computer interconnection;computer network;electrical appliances;enterprises;information sharing;multimedia service;remote device;resource sharing;social infrastructure;social networking service;ubiquitous network industry;wired architecture;wireless architecture;wireless broadband services","","0","","","","","March 2012","","IET","IET Journals & Magazines"
"Empirical validation of an automated method of knowledge structure creation from single documents","H. W. Kim; M. Y. Yi","Knowledge Service Engineering Department, Korea Advanced Institution for Science and Technology, Daejeon, Republic of Korea","2011 Ninth International Conference on ICT and Knowledge Engineering","20120216","2012","","","161","165","The present study proposes a new method that automatically creates a knowledge structure from a single document. Knowledge structure refers to an organization of knowledge, represented through key concepts that make up the knowledge domain and their proximity relationships. We examine several alternative methods in inferring a knowledge structure from a document, and those methods are compared with the knowledge structures obtained from learners (before and after learning) and domain experts. The knowledge structure created by the method that utilizes paragraph co-occurrences with cosine similarity has been found to be the most successful in generating a knowledge structure from a document and its performance to be comparable to a human expert in terms of similarity and consistency. Findings of the study have the potential to significantly improve the current practice in information retrieval.","2157-0981;21570981","Electronic:978-1-4577-2162-5; POD:978-1-4577-2161-8","10.1109/ICTKE.2012.6152399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152399","co-occurrence analysis;concept extraction;knowledge elicitation;knowledge organization;knowledge structure","Data mining;Encyclopedias;Humans;Internet;Knowledge engineering;Periodic structures;Psychology","document handling;information retrieval;knowledge management","automated method;cosine similarity;document knowledge structure;human expert;information retrieval;key concepts;knowledge domain;knowledge structure creation;organization of knowledge;paragraph co-occurrences;proximity relationships;single documents","","0","","17","","","12-13 Jan. 2012","","IEEE","IEEE Conference Publications"
"Efficient Extended Boolean Retrieval","S. Pohl; A. Moffat; J. Zobel","The University of Melbourne, Melbourne","IEEE Transactions on Knowledge and Data Engineering","20120420","2012","24","6","1014","1024","Extended Boolean retrieval (EBR) models were proposed nearly three decades ago, but have had little practical impact, despite their significant advantages compared to either ranked keyword or pure Boolean retrieval. In particular, EBR models produce meaningful rankings; their query model allows the representation of complex concepts in an and-or format; and they are scrutable, in that the score assigned to a document depends solely on the content of that document, unaffected by any collection statistics or other external factors. These characteristics make EBR models attractive in domains typified by medical and legal searching, where the emphasis is on iterative development of reproducible complex queries of dozens or even hundreds of terms. However, EBR is much more computationally expensive than the alternatives. We consider the implementation of the p-norm approach to EBR, and demonstrate that ideas used in the max-score and wand exact optimization techniques for ranked keyword retrieval can be adapted to allow selective bypass of documents via a low-cost screening process for this and similar retrieval models. We also propose term-independent bounds that are able to further reduce the number of score calculations for short, simple queries under the extended Boolean retrieval model. Together, these methods yield an overall saving from 50 to 80 percent of the evaluation cost on test queries drawn from biomedical search.","1041-4347;10414347","","10.1109/TKDE.2011.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728812","Document-at-a-time;efficiency;extended Boolean retrieval;p-norm;query processing.","Biological system modeling;Computational modeling;Law;Optimization;Query processing;Systematics","Boolean functions;document handling;information retrieval;statistical analysis","EBR;complex concepts;document content;efficient extended Boolean retrieval;keyword retrieval;legal searching;medical searching;optimization techniques;statistics collection","","0","","29","","20110310","June 2012","","IEEE","IEEE Journals & Magazines"
"An Approach for Storage and Search of UDP Packet Data","Z. Jian; W. Dinggang; H. Kun; Y. Jin","China Ship Dev. & Design Center, Wuhan, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","2","","603","607","In the distributed data transmission, UDP protocol is commonly used by a large number of applications because of simple mechanism, small transmission delay and high transmission efficiency. For subsequent data-processing needs, UDP packet data transmitted between distributed applications are often stored and searched, especially in various simulation systems. Considering above requirements, this paper presents an approach for storage and search of UDP packet data. The approach has intuitive principle, simple implementation, and a perfect effect.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188103","Inverted Index;UDP;XSD","Computers;Indexes;Marine vehicles;Protocols;Search problems;XML","computer networks;data communication;information retrieval systems;information storage;transport protocols","UDP packet data;UDP protocol;data search;data storage;distributed data transmission","","0","","10","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Floating Car Data Augmentation Based on Infrastructure Sensors and Neural Networks","J. E. Naranjo; F. Jiménez; F. J. Serradilla; J. G. Zato","School of Computer Science, Technical University of Madrid (UPM), Madrid, Spain","IEEE Transactions on Intelligent Transportation Systems","20120227","2012","13","1","107","114","The development of new-generation intelligent vehicle technologies will lead to a better level of road safety and CO<sub>2</sub> emission reductions. However, the weak point of all these systems is their need for comprehensive and reliable data. For traffic data acquisition, two sources are currently available: (1) infrastructure sensors and (2) floating vehicles. The former consists of a set of fixed point detectors installed in the roads, and the latter consists of the use of mobile probe vehicles as mobile sensors. However, both systems still have some deficiencies. The infrastructure sensors retrieve information from static points of the road, which are spaced, in some cases, kilometers apart. This means that the picture of the actual traffic situation is not a real one. This deficiency is corrected by floating cars, which retrieve dynamic information on the traffic situation. Unfortunately, the number of floating data vehicles currently available is too small and insufficient to give a complete picture of the road traffic. In this paper, we present a floating car data (FCD) augmentation system that combines information from floating data vehicles and infrastructure sensors, and that, by using neural networks, is capable of incrementing the amount of FCD with virtual information. This system has been implemented and tested on actual roads, and the results show little difference between the data supplied by the floating vehicles and the virtual vehicles.","1524-9050;15249050","","10.1109/TITS.2011.2180377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6135796","Floating car data;neural networks;traffic flow","Artificial neural networks;Intelligent sensors;Neurons;Roads;Sensor systems;Vehicles","air pollution control;automated highways;automobiles;computerised instrumentation;data acquisition;information retrieval;neural nets;road safety;road traffic;sensor fusion;traffic information systems","FCD;carbon dioxide emission reduction;dynamic information retrieval;fixed point detector;floating car data augmentation;floating data vehicles;infrastructure sensors;mobile probe vehicles;mobile sensors;neural networks;new generation intelligent vehicle technologies;road safety;traffic data acquisition;virtual information;virtual vehicle","","9","","35","","20120123","March 2012","","IEEE","IEEE Journals & Magazines"
"A Federated Data Zone for the Arts and Humanities","D. Tonne; R. Stotzka; T. Jejkal; V. Hartmann; H. Pasic; A. Rapp; P. Vanscheidt; B. Neumair; A. Streit; A. Garcia; D. Kurzawe; T. K´lm´n; J. Rybicki; B. S. Bribian","Karlsruhe Inst. of Technol., Karlsruhe, Germany","2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing","20120315","2012","","","198","205","Digital methods and collaborative research in virtual research environments are gaining in importance for the arts and humanities. The EU-funded project DARIAH aims to enhance and support digitally-enabled research across these disciplines. The most basic but nevertheless fundamental task of DARIAH is to provide sustainable storage for research data. Information contained in data like images, texts or music needs to be secured and to remain accessible even if the original information carrier becomes lost or corrupted. The heterogeneity of the humanistic data and the need for distributed, performant access are the main challenges in designing an archiving system for the arts and humanities. Using the ""Virtual Scriptorium"", a digitisation project in Trier, Germany, this paper exemplary identifies the humanistic researchers' storage needs and derives requirements for an infrastructure. As a solution, a generic architecture for a federated data zone based on the iRODS technologies is proposed. The system implemented in Trier and Karlsruhe is described and will be extended to other locations as the researchers benefit from the initial set-up.","1066-6192;10666192","Electronic:978-0-7695-4633-9; POD:978-1-4673-0226-5","10.1109/PDP.2012.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169550","DARIAH;archiving;arts and humanities;data storage;zone federation","Art;Communities;Computer architecture;Distributed databases;Libraries;Servers","art;distributed databases;information retrieval","EU-funded project DARIAH;archiving system;arts;digital method;digitally-enabled research;digitisation project;federated data zone;humanistic data heterogeneity;humanities;iRODS technologies;image;information carrier;music;storage needs;text;virtual research environment;virtual scriptorium","","0","","27","","","15-17 Feb. 2012","","IEEE","IEEE Conference Publications"
"BFSM: Finite state machine learned as name boundary definer for bio named entity recognition","T. Munkhdalai; Meijing Li; E. Namsrai; O. E. Namsrai; K. H. Ryu","Database/Bioinformatics Laboratory, Chungbuk National University, Cheongju, South Korea","2011 3rd International Conference on Awareness Science and Technology (iCAST)","20120305","2011","","","344","349","One essential task in automated information extraction for biomedical literature is bio named entity recognition process, which basically defines the boundaries between typical words and technical terms of biomedical domain in particular text data and, classifies them based on the domain knowledge. Due to nature of bio named entity, purely defining boundary of the named entities in text data is still challenging. This paper proposes using the part-of-speech tags of tokens as target observation of name boundary definer tool. We proposed an approach for modeling finite state machine as the boundary definer. Aided by machine learning methods including frequent pattern mining method and Bayesian network, the finite state machine learns on part-of-speech tag of tokens in bio-text data. The finite state machine based on Bayesian network is named BFSM. In addition, we report the influence of part-of-speech tagger tool for learning of BFSM. Experimental results show that the named entity recognition system using the BFSM gives us high accuracy as F-score 85.8.","2325-5986;23255986","Electronic:978-1-4577-0888-6; POD:978-1-4577-0887-9","10.1109/ICAwST.2011.6163168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163168","Bayesian network;bio named entity recognition;frequent pattern mining;text mining","Biological system modeling;Hidden Markov models","belief networks;data mining;finite state machines;information retrieval;learning (artificial intelligence);medical computing;text analysis","BFSM;BFSM learning;Bayesian network;bio named entity recognition process;bio-text data;biomedical literature;domain knowledge;finite state machine;frequent pattern mining method;information extraction;machine learning methods;name boundary definer tool;token part-of-speech tagger tool","","2","","19","","","27-30 Sept. 2011","","IEEE","IEEE Conference Publications"
"Use of chatterbot for accessing learning objects on mobile devices with a data mining search engine","E. A. C. Moreno; M. Meza; J. M. Arteaga; A. Padilla; F. Padilla; F. J. A. Rodriguez","Universidad Aut&#x00F3;noma de Aguascalientes, Mexico","CONIELECOMP 2012, 22nd International Conference on Electrical Communications and Computers","20120426","2012","","","134","137","The use of learning objects across multiple platforms and the creation of learning repositories that are used to direct access into the learning objects and the deployment has been generated a new need in applying information, they are considered as educational resources that can be employed in technology-support learning, just like the use of a chatterbot, with his own search engine to locate learning objects using data mining.","","Electronic:978-1-4577-1325-5; POD:978-1-4577-1326-2","10.1109/CONIELECOMP.2012.6189896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189896","Data Mining;Learning Object;Search Engine","Data mining;Education;Media;Mobile handsets;Performance evaluation;Search engines;Search problems","computer aided instruction;data mining;information retrieval;search engines","chatterbot;data mining search engine;educational resource;learning objects access;learning repositories;mobile device;technology-support learning","","0","","14","","","27-29 Feb. 2012","","IEEE","IEEE Conference Publications"
"Customised approach for efficient data storing and retrieving from university database using Repetitive Frequency Indexing","P. S. Patil; S. R. Patil; S. Rao; S. B. Patil","MPSTME, NMIMS, Shirpur, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","511","514","Indexing provides efficient way of storing and retrieving the data from the database by mapping with the respective records. Storing and Retrieving the data from the databases of various universities always requires efficient algorithms or procedures because of huge amount of student information stored. In order to retrieve and store data from the database in more efficient manner, customized indexing methods becomes mandatory. The normal indexing with equal number of alphabets in the primary index results to more time complexity and wastage of the space for unallocated records. This paper proposes a customized and enhanced approach to search the information from such databases with reduced time complexity and latency time. This is achieved using Indexing with Repetitive Frequency to form the buckets with equal number of records.","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194612","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194612","Indexing;buckets;multilevel;time complexity","Complexity theory;Educational institutions;Indexing;Search problems;Time frequency analysis","computational complexity;database indexing;educational administrative data processing;educational institutions;information retrieval;records management","customized indexing method;data retrieval;data storage;latency time reduction;primary index;repetitive frequency indexing;space wastage;student information;time complexity reduction;unallocated records;university database","","0","","9","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"A method of adding an attribute into MathML for formula retrieval","Huifang Guo; Xuedong Tian; Fang Yang; Xinfu Li","College of Mathematics and Computer Science, Hebei University, Baoding, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","1390","1393","Towards the needs of retrieving mathematical formulas, this paper details the semantic descriptors of MathML by utilizing the extensibility of XML and the characteristics of mathematical formulas through the analysis of the existing mathematical formula marking languages. We define a description attribute on the basis of MathML for conversion and retrieval of mathematical formulas in various formats, and also realize the conversion between the extended MathML and LaTeX. Experiments show that this method can strengthen the capability to describe the semantic information of formulas and improve the precision and efficiency of conversion and retrieval of mathematical formulas.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182224","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182224","LaTeX;MathML;mathematical formula conversion;mathematical formula retrieval","","XML;information retrieval;mathematics computing","LaTeX;MathML;XML;attribute addition method;mathematical formula conversion;mathematical formula retrieval;semantic descriptors;semantic information","","0","","20","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"ECG waveform data extraction from paper ECG recordings by K-means method","G. Shi; G. Zheng; M. Dai","Tianjin University of Technology, Tianjin, China","2011 Computing in Cardiology","20120309","2011","","","797","800","Though modern ECG machine with digital-out has been applied for years, paper recordings are still chosen by medical organizations especially in China. But the recording paper is easily broken. These ECG data were necessarily to be extracted and keep the valuable ECG information as digital type for clinical information sharing, online diagnosing and ECG database establishing. A method based on K-means was proposed to extract ECG data from paper recordings. The ECG waveform and the background grid were separated well.105 patients' ECG paper recordings were adopted in the experiment. And the recordings are in different damage level, the paper are in different background color and made by different manufacturers. The result shows that ECG waveform can be extracted precisely and smoothly. The precision rate of RR interval, QRS interval, QT interval, ST slope, and R amplitude from ECG data which are digitalized by the approach in the paper could reach 99%.","0276-6574;02766574","Electronic:978-1-4577-0611-0; POD:978-1-4577-0612-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164686","","Colored noise;Electrocardiography;Feature extraction;Histograms;Image color analysis;Image edge detection","electrocardiography;information retrieval;medical information systems;medical signal processing;pattern clustering","China;ECG database;ECG information;ECG machine;ECG waveform data extraction;QRS interval;QT interval;R amplitude;RR interval;ST slope;clinical information sharing;k-means method;medical organizations;online diagnosing;paper ECG recording;precision rate","","0","","6","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Design and implementation of web crawler based on dynamic web collection cycle","K. S. Kim; K. Y. Kim; K. H. Lee; T. K. Kim; W. S. Cho","CoreEngineering, 643-6 Gack-ri, Ohchang, South Korea","The International Conference on Information Network 2012","20120309","2012","","","562","566","The amount of web information is increasing rapidly with advanced wireless networks and emergence of diverse smart devices like i-Phone, i-Pad and so on. The information is continuously being produced and updated in anywhere and anytime by means of easy web platforms, and social networks. Now, it is becoming a hot issue how frequently updated web data has to be refreshed in data integration and retrieval domain. In this paper, we propose dynamic web-data crawling methods, which include sensitive checking of web site changes, and dynamic retrieving of web pages from target web sites. Furthermore, we implemented a java-based web crawling application and compared performance between conventional static approaches and our proposed dynamic ones. Our experiment results showed 59% performance benefits compared to static crawling method.","1550-445X;1550445X","Electronic:978-1-4673-0250-0; POD:978-1-4673-0251-7","10.1109/ICOIN.2012.6164440","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164440","","Crawlers;Databases;Dynamic scheduling;Java;Libraries;Web pages","Internet;Java;data integration;information retrieval;search engines","Java based Web crawling application;Web data;Web information;Web sites;advanced wireless networks;data integration;data retrieval;dynamic Web collection cycle;dynamic Web data crawling methods;i-Pad;i-Phone;smart devices;social networks;static crawling method","","1","1","17","","","1-3 Feb. 2012","","IEEE","IEEE Conference Publications"
"ePUMA embedded parallel DSP processor with Unique Memory Access","D. Liu; A. Karlsson; J. Sohl; J. Wang; M. Petersson; W. Zhou","Dept of Electrical Engineering, Link&#x00F6;ping University, Sweden","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","5","Computing unto 100GOPS without cooling is essential for high-end embedded systems and much required by markets. A novel master-slave multi-SIMD architecture and its kernel (template) based parallel programming flow is thus introduced as a parallel signal processing platform, ePUMA, embedded Parallel DSP processor with Unique Memory Access. It is an on chip multi-DSP-processor (CMP) targeting to predictable signal processing for communications and multimedia. The essential technologies are to separate the processing of control stream from parallel computing, and to separate parallel data access from parallel arithmetic computing kernels. By separations, the computation and data access can be orthogonal both in hardware and in programs. Orthogonal operations can therefore be executed in parallel and the run time cost of data access can be minimized. Benchmark shows that the computing performance therefore reaches about 80% of the hardware limit. Less than 40% of the hardware limit can be reached by normal processors. The unique SIMD memory subsystem architecture offers programmable conflict free parallel data accesses. Programming flow and tools are also developed to support coding on the unique hardware architecture. A prototype on FPGA shows especially high performance over silicon cost.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6173516","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173516","CMP;Kernel;SIMD;ePUMA","Baseband;Computer architecture;Digital signal processing;Kernel;Multimedia communication;Power demand;Silicon","digital signal processing chips;embedded systems;field programmable gate arrays;information retrieval;memory architecture;parallel architectures;parallel programming","SIMD memory subsystem architecture;control stream processing;ePUMA embedded parallel DSP processor;free parallel data access;hardware limit;high-end embedded systems;kernel-based parallel programming flow;master-slave multiSIMD architecture;on chip multiDSP-processor;orthogonal operations;parallel arithmetic computing kernels;parallel computing;parallel data access;parallel signal processing platform;programming tools;unique memory access","","2","","9","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"LMF: A Framework for Linked Media","T. Kurz; S. Schaffert; T. Burger","Salzburg Res., Salzburg, Austria","2011 Workshop on Multimedia on the Web","20120312","2011","","","16","20","Multimedia is currently underrepresented in the Web of Data. This is due to the lack of integrated means to describe, publish, and interlink multimedia content. This paper presents a framework for the publication of media content and its metadata as Linked Data, the Linked Media Framework (LMF). The LMF enables to store and retrieve content and metadata for media resources and resource fragments in a unified way.","","Electronic:978-0-7695-4586-8; POD:978-1-4577-2043-7","10.1109/MMWeb.2011.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6167823","","Indexes;Media;Multimedia communication;Resource description framework;Semantics;Servers","Internet;information retrieval;meta data;multimedia computing","Web;content retrieval;content storage;linked media framework;media content publication;media resources;metadata;multimedia content;resource fragments","","4","","18","","","8-8 Sept. 2011","","IEEE","IEEE Conference Publications"
"New information content metric and nominalization relation for a new WordNet-based method to measure the semantic relatedness","M. A. Hadj Taieb; M. Ben Aouicha; M. Tmar; A. Ben Hamadou","MIRACL Laboratory, FSEGS, B.P. 1088, 3018 Sfax, Tunisia","2011 IEEE 10th International Conference on Cybernetic Intelligent Systems (CIS)","20120315","2011","","","51","58","Semantic similarity techniques are used to compute the semantic similarity (common shared information) between two concepts according to certain language or domain resources like ontologies, taxonomies, corpora, etc. Semantic similarity techniques constitute important components in most Information Retrieval (IR) and knowledge-based systems. Taking semantics into account passes by the use of external semantic resources coupled with the initial documentation on which it is necessary to have semantic similarity measurements to carry out comparisons between concepts. This paper presents a new approach for measuring semantic relatedness between words and concepts. It combines a new information content (IC) metric using the WordNet thesaurus and the nominalization relation provided by the Java WordNet Library (JWNL). Specifically, the proposed method offers a thorough use of the relation hypernym/hyponym (noun and verb “is a” taxonomy) without external corpus statistical information. Mainly, we use the subgraph formed by hypernyms of the concerned concept which inherits the whole features of its hypernyms and we quantify the contribution of each concept pertaining to this subgraph in its information content. When tested on a common data set of word pair similarity ratings, the proposed approach outperforms other computational models. It gives the highest correlation value 0.70 with a benchmark based on human similarity judgments and especially a large dataset composed of 260 Finkelstein word pairs (Appendix 1 and 2).","","Electronic:978-1-4673-0688-1; POD:978-1-4673-0687-4","10.1109/CIS.2011.6169134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169134","Information Content;JWNL;Nominalization;Semantic Similarity;WordNet","Humans;Integrated circuits;Intelligent systems;Joining processes;Measurement;Semantics;Taxonomy","Java;information retrieval;knowledge based systems;natural language processing;ontologies (artificial intelligence);semantic Web;statistical analysis","Finkelstein word pairs;Java WordNet library;WordNet based method;WordNet thesaurus;corpora;domain resources;human similarity judgments;information content metric;information retrieval;knowledge based systems;language resources;nominalization relation;ontologies;semantic relatedness;semantic similarity techniques;statistical information;taxonomies","","0","","28","","","1-2 Sept. 2011","","IEEE","IEEE Conference Publications"
"Trends and opportunities in consumer video content navigation and analysis","J. Jiang; X. P. Zhang","Department of Electrical and Computer Engineering, Ryerson University, Toronto, Canada","2012 International Conference on Computing, Networking and Communications (ICNC)","20120312","2012","","","578","582","In recent years, digital videos are becoming available at an ever-increasing rate. It has never been easier for ordinary people to record, edit, deliver, and publish their own home-made digital videos over Internet. However, the increasing availability of digital video has not been accompanied by an increase in its accessibility. In other words, the abundance of video data makes it increasingly difficult for users to manage and navigate their video collections. In this paper, we first review the existing methodologies and technologies in video content analysis by addressing the trends and opportunities in consumer video content navigation and analysis. We then introduce a novel video content analysis framework using video time density function (VTDF) to tackle the problems in consumer video processing.","","Electronic:978-1-4673-0009-4; POD:978-1-4673-0008-7; USB:978-1-4673-0723-9","10.1109/ICCNC.2012.6167488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6167488","Key Frame Extraction;Video Content Analysis;Video Shot Boundary Detection;Video Summarization;Video Time Density Function","Hidden Markov models;Navigation;Quantization;Rate-distortion;Semantics;Streaming media;Visualization","Internet;content management;information analysis;information retrieval;video signal processing","Internet;consumer video content analysis;consumer video content navigation;consumer video processing;home-made digital video;video collection;video time density function","","1","","34","","","Jan. 30 2012-Feb. 2 2012","","IEEE","IEEE Conference Publications"
"Simulation Analysis of CMS Data Replication and Production Activities","C. Dobre; V. Cristea","Dept. of Comput. Sci. & Eng., Univ. Politeh., Bucharest, Romania","2011 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20120220","2011","","","372","377","The scale, complexity and worldwide geographical spread of the LHC computing and data analysis problems are unprecedented in scientific research. The complexity of processing and accessing this data is increased substantially by the size and global span of the major experiments, combined with the limited wide area network bandwidth available. We present the latest generation of the MONARC (Models of Networked Analysis at Regional Centers) simulation framework, as a design and modeling tool for large scale distributed systems applied to HEP experiments. We present simulation experiments designed to evaluate the capabilities of the current real-world distributed infrastructure to support existing physics analysis processes and the means by which the experiments bands together to meet the technical challenges posed by the storage, access and computing requirements of LHC data analysis within the CMS experiment.","","Electronic:978-1-4244-9640-2; POD:978-1-4577-1448-1","10.1109/3PGCIC.2011.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6154909","CMS;LHC experiments;Modeling and simulation;evaluation;large scale distributed systems","Analytical models;Biological system modeling;Computational modeling;Data models;Databases;Large Hadron Collider;Throughput","data analysis;discrete event simulation;information retrieval;linear colliders;physics computing;replicated databases;wide area networks","CMS;HEP;LHC computing;MONARC;bandwidth availability;data access;data analysis;data replication;large Hadron collider;large scale distributed system;models of networked analysis at regional centers;simulation analysis;wide area network","","0","","8","","","26-28 Oct. 2011","","IEEE","IEEE Conference Publications"
"Challenges and recent trends in personalized Web search: A survey","K. Selvakumar; S. Sendhilkumar","Department of Information Science & Technology, College of Engineering Guindy Campus, Anna University, Chennai-25, India","2011 Third International Conference on Advanced Computing","20120409","2011","","","333","339","The exponential growth of the Web in last decade makes the largest publically available data source in the world. It integrates text, graphics, audio, video and hypertext. Web users approaches many searching techniques to access the enormous information available on the World Wide Web (WWW). Web search is a process to find information from the pile of documents, Web pages and Web sources. Search engines are playing vital role in Web search process. But the Web users and their essential content may vary among one another. Moreover the users are struggling for obtaining the most significant information while processing their desire content. The main objective of this paper is to provide a comparative analysis of the Web search concepts using Web mining techniques. This paper also highlights the Fuzzy Neural Networks approach in the history for enhancing Web search.","2377-6927;23776927","Electronic:978-1-4673-0671-3; POD:978-1-4673-0670-6","10.1109/ICoAC.2011.6165198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165198","Web content based search;Web search;Web structure based search;Web usage based search and Fuzzy-Neuro system","Artificial neural networks;Data mining;Data models;Feature extraction;Fuzzy neural networks;Web search","Internet;data mining;fuzzy neural nets;information retrieval;search engines","WWW;Web mining techniques;Web pages;Web search concepts;Web search process;Web sources;Web users;World Wide Web;documents;fuzzy neural networks;information searching techniques;personalized Web search;publically available data source;search engines","","1","","27","","","14-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"An research review on clustering analysis for spatio-temporal trajectories of moving point objects","X. Zhao","Shandong Polytech. Univ., Jinan, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","4","","2686","2690","As an information extraction technology, clustering analysis for spatio-temporal trajectories of moving point objects focuses on spatial and temporal distribution and principle of group movement behavior. Potential applications span a wide spectrum such as meteorology, traffic engineering, wildlife migration, mobile network allocation and logistics. Firstly some concepts related to clustering analysis for spatio-temporal trajectories of moving point objects are introduced. Then the current research progresses of this filed are elaborately summarized. Finally the open research problems are pointed out. Clustering analysis for spatio-temporal trajectories of moving point objects is a novel research field and many issues need to be solved. The review research on this topic has great theoretical and practical value.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182521","clustering analysis;moving point objects;spatio-temporal data mining","Equations;Mathematical model","data mining;information retrieval;pattern clustering;spatiotemporal phenomena","clustering analysis;group movement behavior;information extraction technology;moving point objects;spatial distribution;spatio-temporal trajectories;temporal distribution","","0","","27","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Audio fingerprinting based on local energy centroid","Xueqian Pan; Xiaoqing Yu; Jijun Deng; Wei Yang; Hongxue Wang","School of Communication and Information Engineering, Shanghai University, 200072, China","IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011)","20120507","2011","","","351","354","Audio fingerprint is an effective representation of an audio signal using low-level features and can be used to identify unlabeled audio based on its content. In this paper, we introduce a robust audio feature, local energy centroid (LEC), which can represent the energy conglomeration degree of the relative small region in the spectrum. Our audio fingerprint is generated based on the LEC feature which is conducive to enhance the robustness of system. In audio retrieval processing, an improved scoring strategy is proposed to resist the linear speed change. Experimental results show that the new fingerprinting system is quite robust in the present of noise and the proposed method can achieve satisfying recognition accuracy.","","Electronic:978-1-84919-505-8","10.1049/cp.2011.0907","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194776","Audio fingerprint;hash;local energy centroid;noise resistant","","audio signal processing;information retrieval;signal representation","LEC;audio fingerprinting;audio retrieval processing;audio signal representation;energy conglomeration degree;linear speed change;local energy centroid;low-level features;robust audio feature;signal recognition;unlabeled audio identification","","0","","","","","14-16 Nov. 2011","","IET","IET Conference Publications"
"Modified correlation based technique in micro array data analysis for searching differentially expressed genes","A. C. S. Rao; D. Somayajulu; H. Banka","Department of CSE, ISM Dhanbad, India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","20120507","2012","","","526","530","Modified correlation Technique has been proposed to analyze the Microarray data and to search gene related information. We have used mean absolute deviation as a new approach for the differential expression analysis instead of the existing standard deviation and variances approaches and for calculating co-expression we have used spearmen's correlation as a new technique for micro array analysis.","","Electronic:978-1-4577-0697-4; POD:978-1-4577-0694-3","10.1109/RAIT.2012.6194615","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194615","Microarray data;co-expression;differential expression;spearmen's correlation","Arrays;Bioinformatics;Correlation;Data mining;Gene expression;Genomics","bioinformatics;correlation methods;data analysis;genetics;information retrieval;lab-on-a-chip","differential expression analysis;differentially expressed gene search;gene related information search;mean absolute deviation;microarray data analysis;modified correlation based technique;spearmen correlation","","0","","19","","","15-17 March 2012","","IEEE","IEEE Conference Publications"
"Writer Retrieval and Writer Identification Using Local Features","S. Fiel; R. Sablatnig","Comput. Vision Lab., Vienna Univ. of Technol., Vienna, Austria","2012 10th IAPR International Workshop on Document Analysis Systems","20120507","2012","","","145","149","Writer identification determines the writer of one document among a number of known writers where at least one sample is known. Writer retrieval searches all documents of one particular writer by creating a ranking of the similarity of the handwriting in a dataset. This paper presents a method for writer retrieval and writer identification using local features and therefore the proposed method is not dependent on a binarization step. First the local features of the image are calculated and with the help of a predefined codebook an occurrence histogram can be created. This histogram is compared to determine the identity of the writer or the similarity of other handwritten documents. The proposed method has been evaluated on two datasets, namely the IAM dataset which contains 650 writers and the Trigraph Slant dataset which contains 47 writers. Experiments have shown that it can keep up with previous writer identification approaches. Regarding writer retrieval it outperforms previous methods.","","Electronic:978-0-7695-4661-2; POD:978-1-4673-0868-7","10.1109/DAS.2012.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6195352","local features;writer identification;writer retrieval","Databases;Hidden Markov models;Histograms;Text analysis;Wavelet transforms;Writing","document handling;handwritten character recognition;information retrieval","TrigraphSlant dataset;handwritten documents;local features;occurrence histogram;predefined codebook;writer identification;writer retrieval","","20","2","14","","","27-29 March 2012","","IEEE","IEEE Conference Publications"
"People and entity retrieval in implicit social networks","S. K. Pathapati; S. Venugopalan; A. P. Kumar; A. Bhamidipaty","IBM Research - India, Bangalore, Karnataka - 560045","2011 IEEE 5th International Conference on Internet Multimedia Systems Architecture and Application","20120223","2011","","","1","8","Online social networks can be viewed as implicit real world networks, that manage to capture a wealth of information about heterogeneous nodes and edges, which are highly interconnected. Such abundant data can be beneficial in finding and retrieving relevant people and entities within these networks. Effective methods of achieving this can be useful in systems ranging from recommender systems to people and entity discovery systems. Our main contribution in this paper is the proposal of a novel localized algorithm that operates on the sub graph of the social graph and retrieves relevant people or entities. We also demonstrate how such an algorithm can be used in large real world social networks and graphs to efficiently retrieve relevant people/entities.","","Electronic:978-1-4577-1328-6; POD:978-1-4577-1329-3","10.1109/IMSAA.2011.6156373","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156373","Implicit Social Networks;Retrieval;Social Graph;Social Networks","Complexity theory;Computer languages;Hamming distance;Internet;Network topology;Social network services;Topology","data mining;information retrieval;recommender systems;social networking (online)","entity discovery systems;entity retrieval;heterogeneous nodes;implicit real world networks;implicit social networks;online social networks;people retrieval;recommender systems;social graph","","0","","23","","","12-13 Dec. 2011","","IEEE","IEEE Conference Publications"
"Connected TV and beyond","S. Soursos; N. Doulamis","Intracom S.A. Telecom Solutions, Greece","2012 IEEE Consumer Communications and Networking Conference (CCNC)","20120412","2012","","","582","586","Nowadays, a paradigm shift is under way in the world of Digital Broadcast TV. This change, similar to that of the mobile market, promises a future where modern TV sets and set top boxes will become the merging point of TV and computers. The `Connected TV' will allow users to access content available either from the broadcast channels or the Internet. There are already some independent attempts in realizing this concept as well as standardization efforts that aim at closing the gap between different implementations. However, more focus is placed on the integration of Internet content while the traditional broadcast part is neglected. In this work, we outline the current status and propose a framework for creating a true hybrid solution, where end users can enrich broadcast content with Internet-based enhancements so that they can enjoy improved and personalized viewing experience. In fact, this approach allows for content composition, by merging the base (broadcast) content with add on (Internet) content. This will further facilitate the opening of the TV market, the emergence of new business models and the offering of more advanced and personalized services.","2331-9852;23319852","Electronic:978-1-4577-2071-0; POD:978-1-4577-2070-3","10.1109/CCNC.2012.6181009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181009","","Broadband communication;Context;Internet;Media;Streaming media;Synchronization;TV","Internet;broadcast channels;digital television;information retrieval;set-top boxes;television broadcasting;video on demand","Connected TV;Internet content;Internet-based enhancements;TV market;TV sets;TV-computer merging point;add-on content;base content;broadcast channels;broadcast content;business models;content access;content composition;digital broadcast TV;personalized viewing experience;set-top boxes","","6","","9","","","14-17 Jan. 2012","","IEEE","IEEE Conference Publications"
"A Design of Mobile Application for English Learning","C. C. Chi; C. H. Kuo; K. Y. Lin","Dept. of CSIE, Tamkang Univ., Taipei, Taiwan","2012 IEEE Seventh International Conference on Wireless, Mobile and Ubiquitous Technology in Education","20120419","2012","","","238","241","Learners can listen to music and read the synchronous lyrics using this mobile music playing application. The proposed system will make questions that correspond to lyrics for EFL (English as Foreign Language) learners studying. This approach focuses on retrieving verb-noun collocations and making appropriate questions automatically. BNC (British National Corpus) has been chosen to calculate mutual information to get the correct collocations, and the synset of Word Net has been used to make wrong candidates which people often make mistakes for using collocations. Therefore the learner can study anytime, anywhere by using mobile devices, proposed mobile application, lyrics reading and music listening.","","Electronic:978-0-7695-4662-9; POD:978-1-4673-0884-7","10.1109/WMUTE.2012.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185039","Lyrics;Mobile Learning;Mutual Information","Databases;Educational institutions;Mobile communication;Mobile handsets;Multimedia communication;Streaming media","computer aided instruction;information retrieval;mobile computing;music;natural languages","BNC;British National Corpus;EFL learner;English as foreign language;English learning;WordNet synset;mobile device;mobile music playing application;music listening;synchronous lyrics reading;verb-noun collocation retrieval","","0","","12","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"Towards accurate modeling for protein rigidity analysis","N. Fox; I. Streinu","Department of Computer Science, University of Massachusetts, Amherst, USA","2012 IEEE 2nd International Conference on Computational Advances in Bio and medical Sciences (ICCABS)","20120412","2012","","","1","6","We evaluate the performance of the modeling in KINARI, our pebble-game rigidity analysis system, on a benchmark data set of 32 PDB files used by the Gerstein Lab to validate the RigidFinder algorithm. For this we use a novel evaluation method, called the cluster decomposition score. This is adapted from the B-cubed score from the information retrieval literature, which is used as a comparative score on two clusterings of the same data. We focus on the the most extensively used tuning parameter in rigidity analysis, the hydrogen bond energy cutoff. We also propose a new modeling methodology for hydrogen bonds, where those with energies lower than the cutoff, instead of being discarded, are modeled with a weaker constraint. For the 5 largest proteins (501 residues or more), the KINARI decompositions scored significantly better than the crude baseline, indicating that the parameterization used is reliable for larger proteins. For most of the proteins including all hydrogen bonds leads to the best scores. For the others, where a cutoff improved the score, our new modeling methodology matched or improved results for 9 out of 10 PDBs. We investigate the sensitivity of the cluster decomposition score with case studies on pyruvate phosphate dikinase and phosphotransferase.","","Electronic:978-1-4673-1321-6; POD:978-1-4673-1320-9","10.1109/ICCABS.2012.6182632","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182632","hydrogen bonds;protein structure;rigidity","Algorithm design and analysis;Analytical models;Benchmark testing;Clustering algorithms;Fasteners;Games;Proteins","biochemistry;decomposition;hydrogen bonds;information retrieval;molecular biophysics;proteins","32 PDB files;B-cubed score;Gerstein lab;KINARI modeling;accurate modeling;benchmark data set;cluster decomposition score;crude baseline;hydrogen bond energy cutoff;information retrieval literature;modeling methodology;pebble-game rigidity analysis system;phosphotransferase;protein rigidity analysis;pyruvate phosphate dikinase;rigidfinder algorithm;rigidity analysis;tuning parameter","","2","","15","","","23-25 Feb. 2012","","IEEE","IEEE Conference Publications"
"Learning agent based knowledge management in Intelligent Tutoring System","S. S. Priya; R. Subhashini; J. Akilandeswari","Department of Computer Science and Engineering, Sona College of Technology, Salem, pin-636 005, Tamilnadu, India","2012 International Conference on Computer Communication and Informatics","20120301","2012","","","1","5","An Intelligent Tutoring System is helpful for the users who want to undertake a learning process. This paper presents an intelligent tutoring system based on learning agent and knowledge agents to improve the learning and teaching process of the tutoring session. The agents involved are knowledge acquirement agent, knowledge sharing agent, knowledge maintenance agent and learning agent. The knowledge acquirement agent is responsible for the construction of the student model and the domain knowledge base. The knowledge sharing agent is responsible for producing personalized teaching web pages to students dynamically. The knowledge maintenance agent is responsible for the maintenance of domain knowledge database and student profile database. The learning agent is used to obtain feedback from the students based on the learning process. The prioritization of the domains is performed depending on the feedback obtained from the students to improvise the tutoring system. This paper aims to provide the faster retrieval of information from the database and the effective teaching learning process to the users. The effectiveness is possible by the frequent updation of the domain knowledge to the prioritized domains.","","Electronic:978-1-4577-1583-9; POD:978-1-4577-1580-8","10.1109/ICCCI.2012.6158828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158828","Learning agent;feedback;intelligent tutoring system;knowledge agents;knowledge management;prioritization","Adaptation models;Databases;Education;Learning systems;Maintenance engineering;Materials","Internet;database management systems;information retrieval;intelligent tutoring systems;knowledge management;learning (artificial intelligence);multi-agent systems;software maintenance;teaching","domain knowledge base construction;domain knowledge database maintenance;information retrieval;intelligent tutoring system;knowledge acquirement agent;knowledge maintenance agent;knowledge sharing agent;learning agent based knowledge management;learning process;personalized teaching Web page production;student model construction;student profile database maintenance;teaching process;tutoring session","","1","","13","","","10-12 Jan. 2012","","IEEE","IEEE Conference Publications"
"Architecture for Inter-cloud Services Using IPsec VPN","M. S. Dayananda; A. Kumar","Dept. of CSE, RITM, Bangalore, India","2012 Second International Conference on Advanced Computing & Communication Technologies","20120315","2012","","","463","467","Cloud computing provides computation, software, data access, and storage services that do not require end-user knowledge of the physical location and configuration of the system that delivers the services. Cloud platform services, delivers a computing platform and/or solution stack as service, often consuming cloud infrastructure and sustaining cloud applications. In future cloud computing architecture enables many cloud services to connect to each other freely. Using IPsec VPN it will increase the complexity in terms of security policies along with the evolving cloud architecture. In this paper, we discuss how we can introduce IPsec VPN in inter-cloud computing architecture.","2327-0632;23270632","Electronic:978-0-7695-4640-7; POD:978-1-4673-0471-9","10.1109/ACCT.2012.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168414","Cloud Computing;IKEv2;IPsec;NHRP","Cloud computing;Computer architecture;Filtering;IP networks;Joining processes;Virtual private networks","IP networks;cloud computing;computational complexity;computer network security;information retrieval;virtual private networks","IPsec VPN;cloud computing architecture;cloud infrastructure;cloud platform service;data access;data storage service;end-user knowledge;intercloud computing architecture;intercloud service architecture;physical configuration;security policy","","0","","3","","","7-8 Jan. 2012","","IEEE","IEEE Conference Publications"
"Digital Game-Based Learning on Digital Archives: A Case Study of Taiwanese Classical Poems","T. H. Tsai; H. C. Lin; K. C. Huang","Dept. of Inf. & Learning Technol., Nat. Univ. of Tainan, Tainan, Taiwan","2012 IEEE Fourth International Conference On Digital Game And Intelligent Toy Enhanced Learning","20120419","2012","","","132","134","Taiwanese Classical Poems Database at the National Museum of Taiwan Literature (NMTL) is one of many ongoing digital-archive projects in Taiwan. Although this database is very important to the study of Taiwanese classical literature and past culture and history, most people in Taiwan are unfamiliar with these poems. To attract the general public to engage in learning Taiwanese classical poems, we had developed a digital game, named ""The Lost World: Taiwanese Classical Poems,"" on the database. The purpose of this article is to introduce NMTL's Taiwanese Classical Poems Database and the development of our digital game. The framework of our digital game with a learning management system is also described. To well integrate Taiwanese classical poems into our digital game, we analyze the six key features of the game based on the input-process-outcome (IPO) model. Our digital game has been presented to the general public at NMTL since October 22, 2011.","","Electronic:978-0-7695-4663-6; POD:978-1-4673-0885-4","10.1109/DIGITEL.2012.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185599","Taiwanese classical poems;digital archive input-process-outcome (IPO) model;digital game-based learning","Brushes;Computers;Databases;Education;Games;History;Least squares approximation","computer aided instruction;computer games;history;information retrieval systems;literature","National Museum of Taiwan Literature;Taiwanese Classical Poems Database;Taiwanese classical literature;Taiwanese history;Taiwanese past culture;The Lost World: Taiwanese Classical Poems;case study;digital archives;digital game-based learning;input-process-outcome model;learning management system","","0","","8","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"3DTown: The automatic urban awareness project","E. R. Corral-Soto; R. Tal; L. Wang; R. Persad; L. Chao; C. Solomon; B. Hou; G. Sohn; J. H. Elder","Dept. of Computer Science and Engineering / Dept. of Earth and Space Science and Engineering, York University","2012 IEEE Virtual Reality Workshops (VRW)","20120412","2012","","","87","88","In this work the goal is to develop a distributed system for sensing, interpreting and visualizing the real-time dynamics of urban life within the 3D context of a city focusing on typical, useful dynamic information such as walking pedestrians and moving vehicles captured by pan-tilt-zoom (PTZ) video cameras. Three-dimensionalization of the data extracted from video cameras is achieved by an algorithm that uses the Manhattan structure of the urban scene to automatically estimate the camera pose. Thus, if the pose of the video camera changes, our system will automatically update the corresponding projection matrix to maintain accurate geo-location of the scene dynamics.","1087-8270;10878270","Electronic:978-1-4673-1246-2; POD:978-1-4673-1247-9","10.1109/VR.2012.6180895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180895","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial;I.2.10 [Artificial Intelligence]: Vision and Scene Understanding — Video analysis;I.4.8 [Image Processing and Computer Vision]: Scene Analysis — Tracking;augmented and virtual realities","Cameras;Electronic mail;Real time systems;Solid modeling;Streaming media;Three dimensional displays;Vehicle dynamics","data visualisation;information retrieval;matrix algebra;natural scenes;pose estimation;video cameras;virtual reality","3D town;Manhattan structure;automatic urban awareness project;camera pose estimation;data extraction;distributed system;pan-tilt-zoom video camera;projection matrix;real-time scene dynamics;urban life;urban scene;visualisation","","0","","16","","","4-8 March 2012","","IEEE","IEEE Conference Publications"
"Upload Cache in Edge Networks","Y. Zhu; A. Nakao","Univ. of Tokyo, Tokyo, Japan","2012 IEEE 26th International Conference on Advanced Information Networking and Applications","20120419","2012","","","307","313","Research efforts have been put into content retrieval in the Internet, ranging from traditional web proxy to recent content-oriented network architectures. With the emerging trends of uploading large user-generated content, we argue that Internet should not only aid end users in downloading content from steadily available servers but also facilitate uploading content. In this paper, we propose upload cache in edge networks, a new edge-network mechanism assisting upload of user-generated content (UGC). Our proposed mechanism brings benefit for both end users and service providers. For end users, it shortens the duration while user must stay online for uploading their generated content. Also for service providers, it reduces peak traffic volume between edge networks and data centers by slightly shifting the upload timing without incurring much extra latency overhead added. Our analysis with replaying the captured traffic shows that this mechanism reduces upload tether time of 24% end users by more than half and flattens the traffic peak for the access service provider by 37%.","1550-445X;1550445X","Electronic:978-0-7695-4651-3; POD:978-1-4673-0714-7","10.1109/AINA.2012.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184885","caching system;traffic shaping;user-generated content","Internet;Logic gates;Proposals;Protocols;Schedules;Servers;Throughput","Internet;cache storage;content management;information retrieval","Internet;Web proxy;content retrieval;content-oriented network architectures;edge networks;upload cache;user-generated content","","3","","14","","","26-29 March 2012","","IEEE","IEEE Conference Publications"
"Analyzing Long-Term Access Locality to Find Ways to Improve Distributed Storage Systems","A. Miranda; T. Cortes","Barcelona Supercomput. Center, Barcelona, Spain","2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing","20120315","2012","","","544","553","An efficient design for a distributed file system originates from a deep understanding of common access patterns and user behavior which is obtained through a deep analysis of traces and snapshots. In this paper we analyze traces for eight distributed file systems that represent a mix of workloads taken from educational, research and commercial environments. We focused on characterizing block access patterns, amount of block sharing and working set size over long periods of time, and we tried to find common behaviors for all workloads that can be generalized to other storage systems. We found that most environments shared large amounts of blocks over time, and that block sharing was significantly affected by repetitive human behavior. We also found that block lifetimes tended to be short, but there were significant amounts of blocks with long lifetimes that were accessed over many consecutive days. Lastly, we determined that most daily accesses were made to a reduced set of blocks. We strongly believe that these findings can be used to improve long-term caching policies as well as data placement algorithms, thus increasing the performance of distributed storage systems.","1066-6192;10666192","Electronic:978-0-7695-4633-9; POD:978-1-4673-0226-5","10.1109/PDP.2012.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169634","","Aggregates;Animation;Distributed databases;Humans;Rendering (computer graphics);Satellite broadcasting;Servers","cache storage;distributed databases;information retrieval","block access pattern characterization;block lifetime;block sharing;commercial environment;common access pattern;data placement algorithm;distributed file system design;distributed storage system;educational environment;long-term access locality analysis;long-term caching policy;repetitive human behavior;research environment;user behavior","","3","","23","","","15-17 Feb. 2012","","IEEE","IEEE Conference Publications"
"Koios++: A Query-Answering System for Handwritten Input","M. Liwicki; B. Forcher; P. Jaeger; A. Dengel","Knowledge Manage. Dept., German Res. Center for AI (DFKI), Kaiserslautern, Germany","2012 10th IAPR International Workshop on Document Analysis Systems","20120507","2012","","","17","21","In this paper we propose KOIOS++, which automatically processes natural language queries provided by handwritten input. The system integrates several recent achievements in the area of handwriting recognition, natural language processing, information retrieval, and human computer interaction. It uses a knowledge base described by the resource description framework (RDF). Our generic approach first generates a lexicon as background information for the handwritten text recognition. After recognizing a handwritten query, several output hypotheses are sent to a natural language processing system in order to generate a structured query (SPARQL query). Subsequently, the query is applied to the given knowledge base and a result graph visualizes the retrieved information. At all stages, the user can easily adjust the intermediate results if there is any undesired outcome. The system is implemented as a web-service and therefore works for handwritten input on digital paper as well as on input on Pen-enabled interactive surfaces. Furthermore, we build on the generic RDF-representation of semantic knowledge which is also used by the linked open data (LOD) initiative. As such, our system works well in various scenarios. We have implemented prototypes for querying company knowledge bases, the DBPedia1, the DBLP computer science bibliography2, and a knowledge base of the DAS 2012.","","Electronic:978-0-7695-4661-2; POD:978-1-4673-0868-7","10.1109/DAS.2012.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6195327","HCI;Handwriting recognition;Information extraction;Natural language processing;Touch & Write;semantic search","Handwriting recognition;Knowledge based systems;Natural languages;Resource description framework;Semantics;Text recognition;User interfaces","Web services;handwritten character recognition;human computer interaction;image retrieval;information retrieval;interactive devices;knowledge representation;natural language processing;query processing;text detection","DAS 2012;DBLP computer science bibliography;DBPedia;KOIOS++;LOD initiative;RDF;SPARQL query;Web service;background information;company knowledge base querying;digital paper;generic RDF-representation;handwriting recognition;handwritten input;handwritten query recognition;handwritten text recognition;human computer interaction;information retrieval;lexicon generation;linked open data initiative;natural language query processing;pen-enabled interactive surfaces;query-answering system;resource description framework;semantic knowledge;structured query generation","","0","2","14","","","27-29 March 2012","","IEEE","IEEE Conference Publications"
"PodCastle and songle: Crowdsourcing-based web services for spoken document retrieval and active music listening","M. Goto; J. Ogata; K. Yoshii; H. Fujihara; M. Mauch; T. Nakano","National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki 305-8568, Japan","2012 Information Theory and Applications Workshop","20120412","2012","","","298","299","In this talk, we describe two web services for speech and music, PodCastle (Figure 1) and Songle (Figure 2), that collect and amplify voluntary contributions by anonymous users to improve user experiences. Our goal is to provide users with public web services based on speech recognition, music understanding, signal processing, machine learning, and crowdsourcing so that they can experience state-of-the-art research-level technologies through useful services.","","Electronic:978-1-4673-1472-5; POD:978-1-4673-1473-2","10.1109/ITA.2012.6181786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181786","","Digital audio broadcasting;Games;Multiple signal classification;Signal processing;Speech;Speech recognition;Web services","Web services;information retrieval;music;speech","Web Services;active music listening;machine learning;music understanding;research level technologies;signal processing;speech recognition;spoken document retrieval","","0","","11","","","5-10 Feb. 2012","","IEEE","IEEE Conference Publications"
"Finding Information in Multimedia Meeting Records","A. Popescu-Belis; D. Lalanne; H. Bourlard","Idiap Research Institute, Switzerland","IEEE MultiMedia","20120427","2012","19","2","48","57","This paper surveys the work carried out within two large consortia, AMI and IM2, on improving access to records of human meetings using multimodal interfaces called meeting browsers. Their design has emerged as an important goal, with both theoretical interest and practical applications. Meeting browsers are assistance tools that help humans navigate through multimedia records (audio, video, documents, and metadata) in order to obtain a general idea about what happened in a meeting or to find specific pieces of information, for discovery or verification. To explain the importance that meeting browsers have gained in time, the paper summarizes findings of user studies, discusses features of meeting browser prototypes developed in AMI/IM2, and outlines the main evaluation protocol proposed (BET). Reference scores are provided for future benchmarking. These achievements in meeting browsing are the result of an iterative software process, from user studies to prototypes and then to products.","1070-986X;1070986X","","10.1109/MMUL.2011.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5749999","evaluation;meeting browsers;meeting support technology;multimedia;user requirements","Browsers;Interviews;Meetings;Multimedia communication;Performance evaluation;User interfaces;Videoconferences","information retrieval;multimedia computing;records management","audio;documents;iterative software process;meeting browsers;metadata;multimedia meeting records;multimodal interfaces;video","","4","","19","","20110415","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Semantically enabled data mashups using ontology learning method for Web APIs","Y. J. Lee; J. H. Kim","School of Computer Information, Kyungpook National University, 386 Gajangdong, Sangju, Korea","2012 Computing, Communications and Applications Conference","20120220","2012","","","304","309","Data mashups enable users to create new applications by combining Web APIs from several data sources. However, the existing data mashup framework requires some programming knowledge, hence it is not suitable for use by non-expert users. In this paper, we present an ontology learning method that builds semantic ontologies automatically, and propose an interactive composition approach based on a similarity search method that supports the dynamic composition of APIs. These techniques allow mashup developers to automate the discovery and composition of Web APIs eliminating the need for programmer involvement.","","Electronic:978-1-4577-1719-2; POD:978-1-4577-1717-8","10.1109/ComComAp.2012.6154862","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6154862","Web API;data mashup;interactive composition;ontology learning;similarity searching","Clustering algorithms;Impedance matching;Mashups;Ontologies;Semantics;Simple object access protocol;Syntactics","Internet;application program interfaces;information retrieval;interactive systems;learning (artificial intelligence);ontologies (artificial intelligence)","Web API composition;Web API discovery;data sources;interactive composition;ontology learning method;programmer involvement;programming knowledge;semantic ontologies;semantically enabled data mashups;similarity search method","","3","","14","","","11-13 Jan. 2012","","IEEE","IEEE Conference Publications"
"Handling missing data in medical questionnaires using tensor decompositions","J. Dauwels; L. Garg; A. Earnest; L. K. Pang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","5","Questionnaires are often used to understand the quality of life of patients, treatment and disease burden and to obtain their feedback on the provided health care. However, a common problem with questionnaires is missing data. Some level of missing data is common and unavoidable. For example, patients may elect to leave one or more items unanswered either inadvertently or because they feel inhibited in responding to items dealing with a sensitive topic. Such missing data may lead to biased parameter estimates and inflated errors. In this paper, we propose an innovative collaborative filtering technique to complete missing data in medical questionnaires. The proposed technique is based on canonical tensor decomposition (CANDECOMP) and parallel factor decomposition (PARAFAC). It is very fast and effective especially with repeated medical questionnaires. To assess the different algorithms and our methods, we used SLEQOL questionnaires (“systemic lupus erythematosus-specific quality-of-life instrument”) completed by one hundred patients from TTSH and hospitals in China and Vietnam. Our results demonstrate that the tensor decomposition based method provides significant improvement on many existing methods and overcome their limitations in terms of various statistical measures.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6174300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6174300","CANDECOMP/PARAFAC (CP);medical questionnaires;missing data analysis;tensor decomposition;tensor factorization","Bioinformatics;Collaboration;Correlation;Estimation;Filtering;Root mean square;Tensile stress","collaborative filtering;data handling;diseases;health care;medical information systems;patient treatment;question answering (information retrieval)","CANDECOMP;Chinese hospitals;PARAFAC;SLEQOL questionnaires;Vietnamese hospitals;biased parameter estimates;canonical tensor decomposition;collaborative filtering technique;disease;health care;inflated errors;medical questionnaires;missing data handling;parallel factor decomposition;patient quality of life;patient treatment;systemic lupus erythematosus-specific quality of life instrument","","2","","28","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"DEAP: A Database for Emotion Analysis ;Using Physiological Signals","S. Koelstra; C. Muhl; M. Soleymani; J. S. Lee; A. Yazdani; T. Ebrahimi; T. Pun; A. Nijholt; I. Patras","Queen Mary, University of London, London","IEEE Transactions on Affective Computing","20120409","2012","3","1","18","31","We present a multimodal data set for the analysis of human affective states. The electroencephalogram (EEG) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the EEG signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of EEG, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.","1949-3045;19493045","","10.1109/T-AFFC.2011.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5871728","EEG;Emotion classification;affective computing.;pattern classification;physiological signals;signal processing","Databases;Electroencephalography;Face;Motion pictures;Multimedia communication;Videos;Visualization","Web sites;electroencephalography;emotion recognition;image classification;information retrieval;multimedia computing;neurophysiology;state estimation;video signal processing","DEAP;EEG signal frequencies;Web site;arousal;decision fusion;dominance;electroencephalogram;emotion analysis;familiarity;frontal face video;human affective states;multimedia content analysis;multimodal data set;music videos;online assessment tool;peripheral physiological signals;single-trial classification;state estimation methods;stimuli selection;video highlight detection","","240","","63","","20110609","Jan.-March 2012","","IEEE","IEEE Journals & Magazines"
"Browsing and Retrieval Tool of Slides and Related Lecture Movies","Y. Yaginuma; M. T. Suzuki; H. Kodama","Center of ICT & Distance Educ., Open Univ. of Japan, Chiba, Japan","2012 IEEE Seventh International Conference on Wireless, Mobile and Ubiquitous Technology in Education","20120419","2012","","","193","195","In this paper, a browsing and retrieval tool of slides and related lecture movies is proposed. This tool is developed as an Android application, and browsing of slides can be executed in offline environments. If high-speed network is available, users can browse related lecture movies. This tool has retrieval functions such as keyword retrieval and visual retrieval. In visual retrieval, users can retrieve slides without inputting keywords. This means that the proposed tool is suitable for smart phones, because the retrieval of slides can be realized only by touching smart phone displays.","","Electronic:978-0-7695-4662-9; POD:978-1-4673-0884-7","10.1109/WMUTE.2012.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184996","keyword retrieval;lecture movie;slide;visual retrieval","Ethics;Internet;Motion pictures;Smart phones;Solid modeling;Synchronization;Visualization","computer aided instruction;information retrieval;mobile computing;smart phones","Android application;high-speed network;keyword retrieval;lecture movies;offline environment;slide browsing tool;slide retrieval tool;smart phone;visual retrieval","","0","","6","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"Data rearrange based on mining block access sequence in Cloud Storage","Hongtao Du; Zhanhuai Li","Computer College, Northwestern Polytechnical University, Xi'An, Shaanxi 710072, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","4","","2507","2511","In Cloud Storage system, storage systems have to service for large numbers of scattered data access nodes, and data I/O almost are in random access form, in addition, the distribution storage of data result in data transmission between the Cloud nodes increases greatly, then the performance of the cloud storage system was be restricted remarkably. In this paper, we put forward a system for improving access performance in Cloud Storage system. Through the access trace, the process which doing disk I/O should be detected. The processes that are executed contemporaneous should be regarded as a group. Then, the block access sequences belong to same process groups could be mined based on the Frequent Sequence Mining. And the block relation could be obtained. Ultimately, the related blocks could be rearranged to the near location. It could reduce the head moving of disk during access and realize the mapping from random access to sequence access partly. Furthermore, the data could be migrated between the storage nodes according to the block relation and reducing the data transfer through network between nodes. We have also evaluated the benefits of the system. Our result using real system workloads show that with the data rearrange and data transfer, about 10%-20% I/O response time could be reduced.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182479","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182479","Cloud Storage;Data Rearrange;Mining Block Access Sequence","Educational institutions;Reliability;Servers","cloud computing;data communication;data mining;disc storage;information retrieval;software performance evaluation;storage area networks;storage management","I/O response time;access performance improvement;block access sequence mining;cloud nodes;cloud storage system;data rearange technique;data transfer;data transmission;disk I/O;disk head;distribution storage;frequent sequence mining;random access data I/O;scattered data access nodes","","1","","11","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Crowdsourcing annotation: Modelling keywords using low level features","Z. Theodosiou; N. Tsapatsoulis","Dept. of Communication and Internet Studies, Cyprus University of Technology, Limassol, Cyprus","2011 IEEE 5th International Conference on Internet Multimedia Systems Architecture and Application","20120223","2011","","","1","4","Tagging large collections is often prohibitive and manual tags are known to be imprecise, ambiguous, inconsistent and subject to many variations. A possible way to alleviate these problems and improve the annotation quality is to obtain multiple annotations per image by assigning several annotators into the task. In the current work we present an approach to model the view of several annotators using four MPEG-7 descriptors and a well known data classifier. We apply keywords modelling to the annotation data collected in the framework of Commandaria project where sixteen non-expert users annotated a set of a hundred images using a predefined set of keywords. The images sharing a common keyword are grouped together and used for the creation of the visual model corresponds to this keyword. Finally, the created models used to classify the images into the keyword classes in terms of 2-classes combinations using the 10-fold cross-validation technique. The experimental results are examined under two perspectives: First, in terms of the separation ability of the various keyword classes and second, in terms of the efficiency of the four visual descriptors as far as the image classification task is concerned.","","Electronic:978-1-4577-1328-6; POD:978-1-4577-1329-3","10.1109/IMSAA.2011.6156351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156351","","Accuracy;Image color analysis;Pipelines;Production;Training;Transform coding;Visualization","feature extraction;image classification;information retrieval;outsourcing","10-fold cross-validation technique;Commandaria project;MPEG-7 descriptors;annotation quality;crowdsourcing annotation;data classifier;image classification;keywords modelling;large collection tagging;low level features","","2","","14","","","12-13 Dec. 2011","","IEEE","IEEE Conference Publications"
"NASA computing needs assessment","J. McCabe; K. Petraska; M. Little","Perot Systems Incorporated","2012 IEEE Aerospace Conference","20120419","2012","","","1","9","NASA's complex IT environment tends to mask nuances in the generation, transport, and management of data sets for its Mission Communities, making it increasingly difficult to understand how, when, and where scientists use computing and storage resources. We therefore conducted a study of Mission Scientists' computing behaviors and workflows, to learn how science gets done, on which computing and storage resources, where and when throughout project lifecycles. In our approach we conducted in-depth interviews with scientists that actively use the spectrum of computing and storage resources across the agency; identifying, discussing, and analyzing behavioral patterns to discern computing and storage needs. In each interview we learned the stepwise processes (workflows) used to generate, transport, manage, and use data; including scientists' interactions with computing and storage resources, frequencies, durations, and types of interactions, and dependencies and constraints in progression through steps. During our study we identified a wide variety of usage scenarios across the target communities, however, we found underlying behaviors between scientists, the computing and storage resources they use, and the data sets they create; in particular, how scientists use their data and how they interact with various computing resources at each stage in their projects. These behaviors are influenced by limiting factors in the IT system, such as queues, consistency across resources, data set sizes, storage allocations, and retrieving data from offline storage. Limiting factors increase scientists' times to solution and reduce their effectiveness, by forcing them to adapt their behaviors to accommodate these factors, including: creatively using queues, reprocessing jobs instead of storing data sets, shuffling data sets across resources during processing, saving data at fewer intervals, and reducing scales, resolutions, and numbers of parameters of jobs. We found that, underl- ing scientists' computing and storage behaviors, and how they adapt to limiting factors in the IT system, are sets of dynamics between scientists, the computing and storage resources they use, and the data sets they create. We use the term behavioral dynamics to indicate behaviors that are conditioned by working environments, for our study consisting of subsets of scientists' IT (computing, storage, and networking) environments. We describe dynamics between performance and control, as well as between security and collaboration. We believe that behavioral dynamics such as these can be used to improve the effectiveness of science workflows and times to solution, by: tuning and balancing the IT system for Mission Communities; identifying major short and long-term drivers for computing, storage, and networking; and providing input into architectural decisions. Possible refinements to the IT system include: adopting a more consistent queue strategy across MRC and HEC resources; developing a brokering capability for these resources; exploring architectural implications of large data sets; and providing open and flexible environments for collaborations via proxy access, implementing open computing and storage, or outsourcing to public cloud services.","1095-323X;1095323X","Electronic:978-1-4577-0557-1; POD:978-1-4577-0556-4","10.1109/AERO.2012.6187358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187358","","Analytical models;Communities;Computational modeling;Data models;Interviews;Limiting;NASA","aerospace computing;data handling;database management systems;information retrieval;storage management","HEC resource;IT system;MRC resource;Mission Communities;Mission scientist computing behavior;NASA computing needs assessment;architectural decision;behavioral dynamics;behavioral patterns;computing resources;consistent queue strategy;data set management;data set shuffling;job reprocessing;networking;open computing;outsourcing;project lifecycles;proxy access;public cloud services;science workflows;stepwise process;storage resources;usage scenarios","","0","","7","","","3-10 March 2012","","IEEE","IEEE Conference Publications"
"Design and performance evaluation of tag caching router architecture for CGM content","H. Kurose","Department of Informatics, The Graduate University for Advanced Studies (SOKENDAI), Tokyo, Japan","2012 Computing, Communications and Applications Conference","20120220","2012","","","54","60","In recent years, social interest in viewing consumer-generated media (CGM) contents has been rapidly growing, so their network traffic has been increasing considerably. To cope with this new increase in network traffic, we propose a tag caching router (TCR) architecture that supports folksonomies-based search and content caching for CGM content. Folksonomies are key words or metadata attached to the associated content by CGM-content creators, providers, and viewers to characterize the CGM content. The falksonomies-based search helps a user to find his/her interesting content because it automatically collects from the network the information of candidate contents with the folksonomy specified by the user and presents it as a content list to the user. The TCR architecture caches both content lists for content search and the associated contents for content downloading. We call this enhanced caching method as content caching. The performance of the proposed caching architecture was evaluated by performing a simulation for a wide variety of CGM contents with different traffic characteristics. The simulation results indicate that under a network model with 5 × 5 mesh-topology TCRs, content caching enables the TCR architecture combined with a conventional URI-based search to support a maximum of six-times more CGM access requests due to content caching than the number of accesses that can be supported by a conventional TCP/IP-based end-to-end architecture with a URI-based search. The number of accesses supported by the TCR architecture combined with folksonomies-based search increases to 17-times the number of accesses supported by the conventional TCP/IP-based end-to-end architecture with a URI-based search.","","Electronic:978-1-4577-1719-2; POD:978-1-4577-1717-8","10.1109/ComComAp.2012.6154002","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6154002","Folksonomy;caching;consumer generated media;content delivery network;router;tag","Delay;IP networks;Peer to peer computing;Performance evaluation;Routing;Search engines;Simulation","cache storage;computer network performance evaluation;content management;information retrieval;meta data;multimedia systems;telecommunication network routing;telecommunication traffic","CGM-content creators;URI-based search;consumer-generated media content;content caching;content downloading;folksonomies based search;keywords;mesh topology TCR;metadata;network model;network traffic;performance evaluation;tag caching router architecture design","","0","","15","","","11-13 Jan. 2012","","IEEE","IEEE Conference Publications"
