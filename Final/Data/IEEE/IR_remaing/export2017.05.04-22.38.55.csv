"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5293043,5291526,5293479,5287615,5289106,5289014,5286693,5283948,5283914,5284269,5282348,5283152,5283851,5283055,5282340,5284180,5283382,5284081,5283461,5284222,5284519,5279607,5279885,5279620,5273930,5277535,5277733,5277569,5273961,5277689,5277575,5278361,5277619,5276732,5271733,5271789,5272079,5272135,5271795,5267789,5267749,5268087,5260633,5260875,5260834,5254347,5255417,5255387,5254357,5256728,5255388,5256709,5254315,5256723,5254579,5250711,5236362,5235647,5235956,5236210,5235711,5234523,5184801,5234684,5234687,5234688,5234379,5234603,5234594,5234619,5156260,5234100,5231851,5230507,5231732,5230728,5231731,5231875,5232109,5233332,5232456,5231882,5231543,5231314,5231738,5072272,5228044,5228284,5228501,5230162,5222934,5212311,5212380,5223369,5217932,5223346,5212332,5215657,5212336,5212576",2017/05/04 22:38:55
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Implicit Customer Relations Mining with the Event-Indexing Model","Y. Guo; Z. Shao; N. Hua","Dept. of Comput. Sci. & Eng., East China Univ. of Sci. & Technol., Shanghai, China","2009 ETP International Conference on Future Computer and Communication","20090915","2009","","","289","292","Exploration of explicit and, especially, implicit information of customers is a vital task for industrial enterprises and organizations. Text and data mining are two indispensable means to accomplish above task. This paper presents a hybrid mining system, EIREx, which processes unstructured (text documents) and structured (data tables from databases) information as a whole source. The construction of EIREx is inspired by a cognitive situation model, event-indexing model. EIREx monitors customer information in multidimensional vectors to simulate cognitive understanding processes of human beings. To ensure accuracy, EIREx implements syntactic parsing,lexical reference and semantic analysis in information extraction procedures from mining sources. In the procedures of information integration and cross referencing,EIREx delivers a structural description to reveal implicit connections among existing customers, which are valuable for further analysis of customer orders and purchase motivations or intentions, and dealing with customers' complaints and suggestions.","","POD:978-0-7695-3676-7","10.1109/FCC.2009.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5235647","Customer Relations Mining;Event-Indexing","Communication industry;Computer science;Data mining;Databases;Humans;Information analysis;Multidimensional systems;Psychology;Support vector machines;Text mining","customer relationship management;data mining;information retrieval;text analysis","EIREx;customer relationship management;data mining;event-indexing model;implicit customer relations mining;industrial enterprises;information extraction;lexical reference;semantic analysis;syntactic parsing;text documents;text mining","","0","","15","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Logo Detection in Document Images Based on Boundary Extension of Feature Rectangles","H. Wang; Y. Chen","Grad. Sch. at Shenzhen, Tsinghua Univ., Shenzhen, China","2009 10th International Conference on Document Analysis and Recognition","20091002","2009","","","1335","1339","A new method of logo detection in document images is proposed in this paper. It is based on the boundary extension of feature rectangles of which the definition is also given in this paper. This novel method takes advantage of a layout assumption that logos have background (white spaces) surrounding it in a document. Compared with other logo detection methods, this new method has the advantage that it is independent on logo shapes and very fast. After the logo candidates are detected, a simple decision tree is used to reduce the false positive from the logo candidate pool. We have tested our method on a public image database involving logos. Experiments show that our method is more precise and robust than the previous methods and is well qualified as an effective assistance in document retrieval.","1520-5363;15205363","POD:978-1-4244-4500-4","10.1109/ICDAR.2009.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277733","document retrieval;logo detection","Decision trees;Gray-scale;Image analysis;Image databases;Image recognition;Image segmentation;Shape;Spatial databases;Text analysis;White spaces","document image processing;information retrieval;object detection","boundary extension;document images;document retrieval;feature rectangles;image database;logo detection","","14","","13","","","26-29 July 2009","","IEEE","IEEE Conference Publications"
"Optimal Online Data Sampling or How to Hire the Best Secretaries","Y. Girdhar; G. Dudek","McGill Univ., Montreal, QC, Canada","2009 Canadian Conference on Computer and Robot Vision","20090904","2009","","","292","298","The problem of online sampling of data, can be seen as a generalization of the classical secretary problem. The goal is to maximize the probability of picking the k highest scoring samples in our data, making the decision to select or reject a sample online. We present a new and simple online algorithm to optimally make this selection. We then apply this algorithm to a sequence of images taken by a mobile robot, with the goal of identifying the most interesting and informative images.","","POD:978-1-4244-4211-9","10.1109/CRV.2009.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230507","GD-secretary problem;computer vision;optimal online sampling;secretary problem;sensor placement","Computer vision;Face detection;Image reconstruction;Image sampling;Image sensors;Mobile robots;Robot sensing systems;Robot vision systems;Sampling methods;Streaming media","decision support systems;information retrieval;robot vision;sampling methods","classical secretary problem;data picking probability;mobile robot images;online data sampling;online selection algorithm","","2","","11","","","25-27 May 2009","","IEEE","IEEE Conference Publications"
"Extracting Behavioral Models from WS-BPEL Processes for Service Discovery","Z. Xiao; D. Cao; C. You; H. Mei","Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China","2009 IEEE International Conference on Services Computing","20091013","2009","","","300","307","As service behavior plays a key role in service interaction, behavior-based service discovery has been increasingly recognized as a critical activity for service-based systems. However, little attention has been paid to the retrieval of behavioral models, which is critical for behavior-based discovery. This paper proposes an approach for extracting service behavioral models from WS-BPEL, which has been emerging as the prominent language for service orchestration. Our approach identifies all participants involved in a WS-BPEL process and abstracts the interaction of the process with its participants through behavioral models. Furthermore, we distinguish three types of ordering constraints between activities in behavioral models. Based on this, we present a mechanism to automatically adapt WS-BPEL processes to find and use other similar services when no service satisfies exactly the specified requirements. We have implemented a prototype to demonstrate and evaluate our approach.","","POD:978-1-4244-5183-8","10.1109/SCC.2009.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283948","WS-BPEL;behavioral model;service discovery","Abstracts;Chaos;Computer science;Computer science education;Educational technology;Laboratories;Law;Prototypes;Systems engineering education;Web services","Web services;behavioural sciences;business process re-engineering;information retrieval;software architecture;specification languages","WS-BPEL processes;behavioral model retrieval;service behavior;service discovery;service orchestration;service-based systems;service-oriented computing","","5","","19","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Content-Based Clustering for Tag Cloud Visualization","A. Zubiaga; A. P. García-Plaza; V. Fresno; R. Martínez","Dpto. Lenguajes y Sist. Informaticos, Univ. Nat. de Educ. a Distancia, Madrid, Spain","2009 International Conference on Advances in Social Network Analysis and Mining","20090904","2009","","","316","319","Social tagging systems are becoming an interesting way to retrieve web information from previously annotated data. These sites present a tag cloud made up by the most popular tags, where neither tag grouping nor their corresponding content is considered. We present a methodology to obtain and visualize a cloud of related tags based on the use of self-organizing maps, and where the relations among tags are established taking into account the textual content of tagged documents. Each map unit can be represented by the most relevant terms of the tags it contains, so that it is possible to study and analyze the groups as well as to visualize and navigate through the relevant terms and tags.","","POD:978-0-7695-3689-7","10.1109/ASONAM.2009.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231851","clustering;information access;social-tagging;visualization","Data visualization;Feeds;Navigation;Ontologies;Self organizing feature maps;Semantic Web;Social network services;Subscriptions;Tag clouds;Tagging","Internet;data visualisation;information retrieval;pattern clustering;self-organising feature maps;social networking (online)","content-based clustering;self-organizing maps;social tagging;tag cloud visualisation;tagged documents;textual content;web information retrieval","","6","","10","","","20-22 July 2009","","IEEE","IEEE Conference Publications"
"Two Stage Semantic Relation Extraction","J. Fu; X. Fan; J. Mao; X. Liu","Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China","2009 Ninth International Conference on Hybrid Intelligent Systems","20090922","2009","1","","327","331","Ontology is applied to a real-world Web intelligent question answering system in PC troubleshooting domain as an improvement, so semantic relations need to be extracted to construct ontology semi-automatically. The paper mainly pays attention to ""product-trouble"" relation and ""product-attribute"" relation. A two stage semantic relation extraction method is proposed. In stage one, relation identification is executed to produce high-precision relations instance as the seed for next stage; stage two is the actual relation extraction process, the related terms which describe troubleshooting information and attribute information are extracted based on association rules, then the terms is clustered to find target semantic relation. The relation extraction integrated the advantage of pattern-based and clustering-based methods. The experimental results show it is superior to individual pattern-based and clustering-based methods in precision and recall.","","POD:978-0-7695-3745-0","10.1109/HIS.2009.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254357","ontology learning;semantic relation extraction;two stage extraction","Association rules;Clustering methods;Computer architecture;Computer science;Data mining;Hybrid intelligent systems;Intelligent systems;Ontologies;Taxonomy","Internet;data mining;information retrieval;ontologies (artificial intelligence)","PC troubleshooting domain;Web intelligent question answering system;association rules;information extraction;ontology;product-attribute relation;product-trouble relation;semantic relation extraction","","1","","10","","","12-14 Aug. 2009","","IEEE","IEEE Conference Publications"
"CAF-SIAL: Concept aggregation framework for structuring informational aspects of linked open data","A. Latif; M. T. Afzal; A. U. Saeed; P. Hoefler; K. Tochtermann","Institute for Knowledge Management Graz University of Technology, Inffeldgasse 21a, 8010 Graz, Austria","2009 First International Conference on Networked Digital Technologies","20090929","2009","","","100","105","Linked Open Data (LOD) is becoming an essential part of the Semantic Web. Although LOD has amassed large quantities of structured data from diverse, openly available data sources, there is still a lack of user-friendly interfaces and mechanisms for exploring this huge resource. In this paper we highlight two critical issues related to the exploration of the semantic LOD pool by end users. We introduce a proof of concept application which helps users to search information about a concept without having to know the mechanics of the Semantic Web or Linked Data. We assume that this kind of application may lead to bridge the gap between semantic search and end users. With this application, we concentrated on two aspects: 1) A novel Concept Aggregation Framework to present the most relevant information of LOD resources in an easy to understand way. 2) A simplified search mechanism which hides the complex underlying semantic search logic. This research is intended to simplify the LOD end user interfaces so that they may be used by novice users who don't possess any prior knowledge of semantic structures.","2155-8728;21558728","POD:978-1-4244-4614-8","10.1109/NDT.2009.5272079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5272079","","Bridges;Keyword search;Knowledge management;Logic;Management information systems;Ontologies;Resource description framework;Semantic Web;User interfaces;Web sites","information resources;information retrieval;semantic Web","CAF-SIAL;concept aggregation framework;data sources;information search;linked open data;semantic Web;semantic search logic;semantic structure;structured data;user-friendly interface","","4","","18","","","28-31 July 2009","","IEEE","IEEE Conference Publications"
"User-Guided Wrapping of PDF Documents Using Graph Matching Techniques","T. Hassan","Database & Artificial Intell. Group, Vienna Univ. of Technol., Vienna, Austria","2009 10th International Conference on Document Analysis and Recognition","20091002","2009","","","631","635","There are a number of established products on the market for wrapping - semi-automatic navigation and extraction of data - from Web pages. These solutions make use of the inherent structure of HTML to locate instances of data to be wrapped. As PDF documents do not have such a structure, wrapping PDF documents has long been recognized as a challenging problem. We have developed a novel system for wrapping PDF documents, which is currently at a prototype stage. A PDF document is represented as an attributed relational graph, in which nodes represent physical items on the page and edges represent spatial and logical relationships. A wrapper is defined as a subgraph of the document with additional conditions, and can quickly and intuitively be created by a non-expert using the GUI. An algorithm based on subgraph isomorphism is then used to find the data instances and extract the required data. Experiments show that our approach achieves good results with good execution time.","1520-5363;15205363","POD:978-1-4244-4500-4","10.1109/ICDAR.2009.238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277569","PDF;document analysis;document understanding;graph matching;wrapping","Data mining;Databases;Graphical user interfaces;HTML;Information analysis;Navigation;Prototypes;Text analysis;Web pages;Wrapping","Internet;data structures;graph theory;graphical user interfaces;hypermedia markup languages;information retrieval;pattern matching","GUI;HTML;PDF document;Web page;attributed relational graph matching technique;data extraction;data instance;semiautomatic navigation;subgraph isomorphism;user-guided wrapping","","3","","9","","","26-29 July 2009","","IEEE","IEEE Conference Publications"
"A new keyword spotting approach","H. Bahi; N. Benati","Computer Science Department, University of Annaba, Algeria","2009 International Conference on Multimedia Computing and Systems","20090922","2009","","","77","80","Keyword spotting is the task of identifying the occurrences of certain desired keywords in an arbitrary speech signal. Keyword spotting has many applications one of them is telephone routing. In particular, we consider a big company which receives thousands of telephone calls daily. We are interested with the classification of these calls to route them to the appropriate department. State-of-the-art approaches in keyword spotting considered the speech signal as continuous speech, where keywords and non-keywords are modeled using hidden Markov models. In this paper, we suggest a perceptual approach, which exploit acoustic particularities of the predefined keywords to detect their frontiers, without modeling the out-of-vocabulary (OOV) words.","","POD:978-1-4244-3756-6","10.1109/MMCS.2009.5256728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5256728","acoustic characterisation;audio information retreival;keyword spotting;speech recognition","Acoustic noise;Acoustic signal detection;Computer science;Hidden Markov models;Routing;Signal processing;Speech recognition;Telephony;Training data;Vocabulary","acoustic signal processing;audio signal processing;hidden Markov models;information retrieval;speech processing;speech recognition;voice communication","OOV word;acoustic characterisation;arbitrary speech signal;audio information retreival;hidden Markov model;keyword spotting approach;out-of-vocabulary word;perceptual approach;speech recognition;telephone call classification;telephone routing","","5","","7","","","2-4 April 2009","","IEEE","IEEE Conference Publications"
"Stably extracting text contents from email messages with Python","S. Sun","Firstwave Technology, Australia","2009 Second International Conference on the Applications of Digital Information and Web Technologies","20091002","2009","","","199","203","Extracting text contents from email messages is a fundamental task in email processing, such as spam mail identifying and email filtering. Although Python is a rapid application development language, there is not a library in Python which can efficiently and stably accomplish this task when facing versatile email formats in a real application. This paper proposes an approach to fulfill the task with three software layers. How to automatically evaluate it in a busy server environment has also been documented. It has been deployed in our email processing platform to extract text content of email messages on 24 hours per day and 7 days per week base. Its stable and effective performance improves our email filtering service to our customers. The principles in the approach can also be adopted to stabilize the performance of other software.","","POD:978-1-4244-4456-4","10.1109/ICADIWT.2009.5273961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5273961","","Application software;Business;Data mining;Filtering;HTML;Intellectual property;Postal services;Protection;Sun;Unsolicited electronic mail","electronic mail;electronic messaging;hypermedia markup languages;information retrieval;software architecture;text analysis","HTML file;Python-rapid application development language;email message;email processing;software architecture;text content extraction","","0","","6","","","4-6 Aug. 2009","","IEEE","IEEE Conference Publications"
"A scientific workflow solution to the archiving of digital media","C. Y. Hou; I. Altintas; E. Jaeger-Frank; L. Gilbert; R. Moore; A. Rajasekar; R. Marciano","San Diego Supercomputer Center, UCSD, 9500 Gilman Drive, 92093-0505, California, USA","2006 Workshop on Workflows in Support of Large-Scale Science","20091009","2006","","","1","10","This work explores the challenges of embedding long-term preservation processes into existing video production workflows. The challenges are many: size of video data, bulk and parallel transfer into the archive, automation of the processes, elimination of human steps, automatic triggering of the preservation workflows, replication of content, automatic extraction of metadata, and most important mechanisms to ldquohardenrdquo the automation by providing recovery mechanisms in case of errors and discrepancies. We present production-quality solutions that automate this process and make use of Kepler scientific workflows and Storage Resource Broker (SRB) data grid environments.","2151-1373;21511373","POD:978-1-4244-5215-6","10.1109/WORKS.2006.5282348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5282348","","Data mining;Environmental management;History;Humans;Material storage;Production;Project management;Resource management;Storage automation;Supercomputers","grid computing;information retrieval systems;multimedia computing;video databases;workflow management software","Kepler scientific workflows;SRB data grid environment;digital media archiving;long-term preservation process;production-quality solutions;scientific workflow solution;storage resource broker;video production workflows","","0","","15","","","19-23 June 2006","","IEEE","IEEE Conference Publications"
"Robust Extraction of Text from Camera Images","S. P. Chowdhury; S. Dhar; A. K. Das; B. Chanda; K. McMenemy","Intell. Syst. & Control, QUB, UK","2009 10th International Conference on Document Analysis and Recognition","20091002","2009","","","1280","1284","Text within a camera grabbed image can contain a huge amount of meta data about that scene. Such meta data can be useful for identification, indexing and retrieval purposes.Detection of colored scene text is a new challenge for all camera based images.Common problems for text extraction from camera based images are the lack of prior knowledge of any kind of text features such as color, font, size and orientation.In this paper we propose a new algorithm for the extraction of text from an image which can overcome these problems. In addition, problems due to an unconstrained complex background in the scene has also been addressed.Here a new technique is applied to determine the discrete edges around the text boundaries. A novel methodology is also proposed to extract the text exploiting its appearance in terms of color and spatial distribution.","1520-5363;15205363","POD:978-1-4244-4500-4","10.1109/ICDAR.2009.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277689","Text extraction;camera image;discrete edge boundary;text localization;video frame","Control systems;Image recognition;Indexing;Intelligent control;Intelligent systems;Layout;Optical character recognition software;Robustness;Smart cameras;Text recognition","edge detection;image colour analysis;information retrieval;text analysis;video signal processing","camera image;colored scene text detection;robust text extraction;scene meta data;spatial distribution;video frame","","3","","11","","","26-29 July 2009","","IEEE","IEEE Conference Publications"
"CoScribe: Integrating Paper and Digital Documents for Collaborative Knowledge Work","J. Steimle; O. Brdiczka; M. Muhlhauser","Technische Universit&#x0E4;t Darmstadt, Darmstadt","IEEE Transactions on Learning Technologies","20090911","2009","2","3","174","188","This paper presents CoScribe, a concept and prototype system for the combined work with printed and digital documents, which supports a large variety of knowledge work settings. It integrates novel pen-and-paper-based interaction techniques that enable users to collaboratively annotate, link and tag both printed and digital documents. CoScribe provides for a very seamless integration of paper with the digital world, as the same digital pen and the same interactions can be used on paper and displays. As our second contribution, we present empirical results of three field studies on learning at universities. These motivated the design of CoScribe and were abstracted to a generic framework for the design of intuitive pen-and-paper user interfaces. The resulting interaction design comprising collaboration support and multiuser visualizations has been implemented and evaluated in user studies. The results indicate that CoScribe imposes only minimal overhead on traditional annotation processes and provides for a more efficient structuring and retrieval of documents.","1939-1382;19391382","","10.1109/TLT.2009.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5184801","Collaborative learning;computer-supported cooperative work;digital pen;hypertext navigation.;input devices and strategies;paper interfaces","Collaboration;Computer science;Educational institutions;Joining processes;Media;Tagging;User interfaces","data visualisation;document handling;groupware;information retrieval;interactive systems","CoScribe;collaborative knowledge work;digital documents;document retrieval;multiuser visualizations;pen-and-paper-based interaction;printed documents","","13","5","42","","20090731","July-Sept. 2009","","IEEE","IEEE Journals & Magazines"
"Color quantization and its impact on color histogram based image retrieval accuracy","K. Meskaldji; S. Boucherkha; S. Chikhi","MISC Laboratory Computer science department Mentouri University Constantine 25000 Algeria","2009 First International Conference on Networked Digital Technologies","20090929","2009","","","515","517","The comparison of color histograms is one of the most widely used techniques for content-based image retrieval. Before establishing a color histogram in a defined model (RGB, HSV or others), a process of quantization is often used to reduce the number of used colors. In this paper, we present the results of an experimental investigation studying the impact of this process on the accuracy of research results and thus will determine the number of intensities most appropriate for a color quantization for the best accuracy of research through tests applied on an image database of 500 color images.","2155-8728;21558728","POD:978-1-4244-4614-8","10.1109/NDT.2009.5272135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5272135","","Histograms;Image retrieval;Quantization","content-based retrieval;data compression;image coding;image colour analysis;image representation;image retrieval;information retrieval systems","CBIR system;HSV model;RGB model;color histogram;content-based image retrieval;image color quantization process;image database;image representation","","3","","7","","","28-31 July 2009","","IEEE","IEEE Conference Publications"
"A reusable data convergency model for integration of heterogeneous data resources","Feng Zhang; Yongshan Wei; Xin Chen","College of Information Science and Engineering, Shandong University of Science and Technology, Qingdao, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","463","467","With the rapid growth of the Internet, numerous data resources, which are distributed, autonomous and heterogeneous, are available for access. Consequently, the integration of heterogeneous data resources is a fundamental issue in the information integration. In this paper, a data convergency model based on XML is brought forward to present the integration process of the heterogeneous data resources. With this model users can construct reusable virtual data resources called VDR. The output structure of VDR is of semantic description, thus the users can choose existing VDRs to construct new VDR for their requirements.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234684","component;data convergency;reusability;virtual data resources","Data engineering;Data mining;Data models;Educational institutions;Electronic mail;Graphical user interfaces;Information science;Internet;Relational databases;XML","Internet;XML;information retrieval","XML;heterogeneous data resources integration;reusable data convergency model;reusable virtual data resources;the Internet","","0","","11","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Shared genomics: A platform for emerging interpretation of genetic epidemiology","D. Hoyle; M. Delderfield; L. Kitching; G. Smith; P. Crowther; I. Buchan","North West Institute for BioHealth Informatics, University of Manchester Jean McFarlane Building, University Place, Oxford Road, Manchester, M13 9PL, UK","2009 22nd IEEE International Symposium on Computer-Based Medical Systems","20090922","2009","","","1","6","The study of the genetics of diseases has been revolutionised by the advent of genome-wide genotyping technologies. Increasingly, genome-wide association studies are being used to identify positions within the human genome that have a link with a disease condition. These new data sets require the use of distributed resources, both for the statistical analysis and for the interpretation of the analysis results. Aiding the latter will be be crucial for the statistical analysis process to be successful. In this paper we report our experiences in developing a user-friendly High Performance Computing (HPC) statistical genetics analysis platform for use by clinical researchers. Specifically, we report work on supporting the interpretation process through the automatic annotation of the statistical analysis results with relevant biological information. Retrieval of the biological annotation is performed by high-volume invocation of multiple Web-services orchestrated via pre-existing scientific workflows. We also report work on developing tools to aid the capture and replay of the processes performed by a user when exploring analysis results.","1063-7125;10637125","POD:978-1-4244-4879-1","10.1109/CBMS.2009.5255387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255387","","Bioinformatics;Biological information theory;Biology computing;Diseases;Genetics;Genomics;Grid computing;Informatics;Performance analysis;Statistical analysis","Web services;bioinformatics;diseases;genetics;genomics;information retrieval;statistical analysis","Web-service;biological annotation retrieval;biological information;diseases;genetic epidemiology;genome-wide association;genomics;genotyping technology;statistical analysis;statistical genetics analysis;user-friendly high performance computing","","0","","9","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Novel Approach for Designing Indian Regional Language Based Raw-Text Extractor and Unicode Font-Mapping Tool","D. Bhattacharyya; P. Das; D. Ganguly; K. Mitra; S. Mukherjee; S. K. Bandyopadhyay; Tai-hoon-Kim","Comput. Sci. & Eng. Dept., Heritage Inst. of Technol., Kolkata, India","2009 International e-Conference on Advanced Science and Technology","20090904","2009","","","24","29","Extracting specific information from a collection of documents is called information extraction (IE). In general, the information on the a Web is well structured in HTML or XML format. And the work of IE from structured documents (in HTML or XML), basically uses learning techniques for pattern matching in the content. In this paper, we have proposed a novel approach for interactive information extraction technique. Here, we have described how this approach enables any naive user to extract Indian regional language based document from a Web document efficiently which is quite similar to a standard search engine. It is just similar to a pre-programmed information extraction engine.","","POD:978-0-7695-3672-9","10.1109/AST.2009.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231732","Corpus;HTML;Information Extraction;Mapped","Application software;Computer science;Data mining;Design engineering;HTML;Knowledge engineering;Natural languages;Pattern matching;Search engines;Web sites","XML;hypermedia markup languages;information retrieval;learning (artificial intelligence);natural language processing;pattern matching;text analysis","HTML;Indian regional language design;Unicode font-mapping tool;Web document;XML format;interactive information extraction technique;learning techniques;pattern matching;raw-text extractor;standard search engine","","0","","5","","","7-9 March 2009","","IEEE","IEEE Conference Publications"
"Evaluating a method to detect temporal trends of phrases in research documents","H. Abe; S. Tsumoto","Shimane University, School of Medicine, Japan","2009 8th IEEE International Conference on Cognitive Informatics","20090918","2009","","","378","383","In text mining processes, the importance indices of the technical terms play a key role in finding valuable patterns from various documents. Further, methods for finding emergent terms have attracted considerable attention as an important issue called temporal text mining. However, many conventional methods are not robust against changes in technical terms. In order to detect remarkable temporal trends of technical terms in given textual datasets robustly, we propose a method based on temporal changes in several importance indices by assuming the importance indices of the terms to be a dataset. Empirical studies show that two representative importance indices are applied to the documents from two research areas. After detecting the temporal trends, we compared the emergent trend of the technical phrases to some emergent phrases given by a domain expert.","","POD:978-1-4244-4642-1","10.1109/COGINF.2009.5250711","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5250711","Jaccard Coefficient;Linear Regression;TF-IDF;Text Mining;Trend Detection","Abstracts;Computational complexity;Data mining;Frequency;Hidden Markov models;Linear regression;Robustness;Sliding mode control;Statistics;Text mining","data mining;information retrieval;text analysis","temporal changes;temporal text mining;temporal trends;textual datasets;valuable patterns","","0","","14","","","15-17 June 2009","","IEEE","IEEE Conference Publications"
"XML with Recursive Querying","K. Taha; R. Elmasri","Dept. of Comput. Sci. & Eng., Univ. of Texas at Arlington, Arlington, TX, USA","2009 International Conference on Computational Science and Engineering","20091009","2009","1","","312","317","We introduce an XML search engine called XRQ. The search engine employs recursive querying techniques for answering XML loosely structured queries. Recursive querying allows a query to query the results of a previous application of itself or of another query. We experimentally evaluated the search quality and efficiency of XRQ and compared it with two search engines, XSeek and XKSearch.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283152","","Application software;Books;Buildings;Computer science;Database languages;Educational institutions;Labeling;Ontologies;Search engines;XML","XML;information retrieval system evaluation;query processing;search engines","XKSearch;XML loosely-structured query answering;XML search engine;XRQ search quality evaluation;XSeek;recursive querying technique","","0","","18","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"The Development of Multi-agent System Using Finite State Machine","Y. Al-Saawy; A. Al-Ajlan; K. Aldrawiesh; A. Bajahzer","Software Technol. Res. Lab. (STRL), De Montfort Univ., Leicester, UK","2009 International Conference on New Trends in Information and Service Science","20090925","2009","","","203","206","This paper sets out to develop and create a search agent that can retrieve requested information from two databases; the user will be able to search for a book by inputting variables such as title, author, ISBN and more significantly for this study the price. The system will identify the books requested, where they can be found and will show the cheapest available. SAS will work from the application software and will link to the two databases, the design will allow more databases to be incorporated in the future. Each of the two databases has the same names of the titles however each database may contain a different price. The agent will get the required information quickly, helping the user to find the cheapest and possibly nearest. The agent will connect to the database using the agent interface; there are two agents in the system, known as MAS. These agents collect the required data and send it to the agent handler.","","POD:978-0-7695-3687-3","10.1109/NISS.2009.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5260633","Finite State Machine;Java;Multi-Agent System JFLAP;and UML","Application software;Automata;Books;Databases;Java;Multiagent systems;Orbital robotics;Robot kinematics;Synthetic aperture sonar;Unified modeling language","finite state machines;information retrieval;multi-agent systems","MAS;agent handler;agent interface;finite state machine;information retrieval;multi-agent system","","0","","11","","","June 30 2009-July 2 2009","","IEEE","IEEE Conference Publications"
"Automatic extraction of definitions","C. Zhang; Peng Jiang","School of Software, School of Computer Science and Technology, Beijing Institute of Technology, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","364","368","The task of definition extraction aims to acquire definitions of terms from texts. This task is a subtask of terminology extraction, ontology construction, semantic relation learning, and question answering and so on. This paper presents a bootstrapping approach to automatic extracting definitions of domain-specific terms from unannotated Chinese free texts. Experimental results in three domains of computer, military, and archaeology show effectiveness of our algorithm. As an application of definition extraction, definitions identified by our method have been used to answer factual questions in a question answering system.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234687","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234687","bootstrapping method;definition extraction;domain-specific ontology;knowledge extraction;question answering","Classification algorithms;Computer science;Filtering;Machine learning;Machine learning algorithms;Military computing;Ontologies;Software;Sun;Terminology","data mining;information retrieval;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);text analysis","archaeology domain;automatic definition extraction;bootstrapping approach;computer domain;data mining;domain-specific term;military domain;ontology construction;question answering system;semantic relation learning;terminology extraction;unannotated Chinese free text","","3","","22","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Weblog extraction with fuzzy classification methods","E. Portmann","Information Systems Research Group, Department of Informatics - University of Fribourg, Boulevard de P&#233;rolles 90, 1700, Switzerland","2009 Second International Conference on the Applications of Digital Information and Web Technologies","20091002","2009","","","411","416","This paper uses folksonomies and fuzzy clustering algorithms to establish term-relevant related results. This paper will propose a meta search engine with the ability to search for vaguely associated terms and aggregate them into several meaningful cluster categories. The potential of the fuzzy Weblog extraction is illustrated using a simple example and added value and possible future studies are discussed in the conclusion.","","POD:978-1-4244-4456-4","10.1109/ICADIWT.2009.5273930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5273930","","Clustering algorithms;Fuzzy set theory;Fuzzy sets;Fuzzy systems;Graphical user interfaces;Metasearch;Ontologies;Search engines;Set theory;Tag clouds","Web sites;fuzzy set theory;information retrieval;pattern classification;pattern clustering;search engines","Weblog extraction;folksonomy;fuzzy classification method;fuzzy clustering algorithm;fuzzy set theory;information retrieval;meta search engine;vaguely associated term search","","0","","15","","","4-6 Aug. 2009","","IEEE","IEEE Conference Publications"
"Analysis of autonomous vehicle storage and retrieval system by open queueing network","S. S. Heragu; X. Cai; A. Krishnamurthy; C. J. Malmborg","Department of Industrial Engineering, University of Louisville, KY 40292, USA","2009 IEEE International Conference on Automation Science and Engineering","20090909","2009","","","455","459","Automated vehicle storage/retrieval system (AVS/RS) technology is a relatively new material handling technology. It is a flexible system that is a viable alternative to automated storage/retrieval systems (AS/RS). The manufacturing system performance analyzer (MPA) is an open queuing network (OQN) analyzer based on the parametric decomposition method. This paper models the AVS/RS and uses MPA to analyze the performance of an AVS/RS configuration. Experimental results are provided to show that the OQN methodology can be applied effectively to analyze an AVS/RS when vehicle utilization is between 60% and 85%. MPA is a better choice than simulation to quickly evaluate alternate configurations of the AVS/RS.","2161-8070;21618070","POD:978-1-4244-4578-3","10.1109/COASE.2009.5234100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234100","","Automotive engineering;Costs;Intelligent vehicles;Material storage;Materials handling;Mobile robots;Performance analysis;Queueing analysis;Remotely operated vehicles;Storage automation","information retrieval systems;queueing theory","autonomous vehicle storage;flexible system;parametric decomposition method;queueing network;retrieval system","","1","","9","","","22-25 Aug. 2009","","IEEE","IEEE Conference Publications"
"Research on CBR-Based Hybrid Intelligent System's Application in Equipment Intelligent Maintenance","C. j. Yao; X. h. Chen; X. p. Wang; Y. t. Zhou","501 Sect., Xi'an High-Tech Inst., Xi'an, China","2009 Second International Conference on Intelligent Computation Technology and Automation","20091016","2009","1","","456","459","The characteristics of complex equipment maintenance is analyzed. Then maintenance information resources and the demands of complex equipment intelligent maintenance are also analyzed. On this basis of the analysis, it designs equipment intelligent maintenance system based on CBR hybrid intelligent system, and analyzes the system's three tiers structures, which are data tier, service logic tier and performance tier. Also, the technologic designs are put forward, and the case knowledge representation and system's case retrieval are researched. Last the system is applied in one actual weapon equipment.","","POD:978-0-7695-3804-4","10.1109/ICICTA.2009.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287615","Cased-Based Reasoning;Data Mining;Hybrid Intelligent System","Artificial intelligence;Decision making;Hybrid intelligent systems;Intelligent structures;Knowledge management;Knowledge representation;Logic design;Maintenance;Performance analysis;Personnel","case-based reasoning;data mining;information retrieval;knowledge representation;maintenance engineering","CBR based hybrid intelligent system;actual weapon equipment;case knowledge representation;case-based research;data tier;equipment intelligent maintenance system;performance tier;service logic tier;system case retrieval","","0","","8","","","10-11 Oct. 2009","","IEEE","IEEE Conference Publications"
"Learning Causal Semantic Representation from Information Extraction","Z. Xin; W. LiMin; Z. Shuang","Sch. of Foreign Languages, ChangChun Univ. of Technol., Changchun, China","2009 International Symposium on Intelligent Ubiquitous Computing and Education","20090825","2009","","","404","407","For reasoning with uncertain knowledge causal semantic analysis is proposed to construct logical rules,which are extracted from decision tree induction and Bayes inference based on generalized information theory. These rules can represent multi-level semantic knowledge of the relationship between the data and information implicated. Empirical studies on a set of natural domains show that the semantic completeness of generalized information theory has clear advantage in representing semantic knowledge from different levels.","","POD:978-0-7695-3619-4","10.1109/IUCE.2009.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222934","causal semantic representation;generalized information theory;logical rules","Classification tree analysis;Competitive intelligence;Computer science education;Data mining;Decision trees;Educational technology;Inference algorithms;Information theory;Machine learning algorithms;Ubiquitous computing","decision trees;inference mechanisms;information retrieval;knowledge representation;learning (artificial intelligence)","Bayes inference;causal semantic representation learning;decision tree induction;generalized information theory;information extraction;logical rules;uncertain knowledge causal semantic analysis","","0","","8","","","15-16 May 2009","","IEEE","IEEE Conference Publications"
"Web Page Classification Using Social Tags","S. Aliakbary; H. Abolhassani; H. Rahmani; B. Nobakht","Sharif Univ. of Technol., Iran","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","588","593","Social tagging is a process in which many users add metadata to a shared content. Through the past few years, the popularity of social tagging has grown on the Web. In this paper we investigated the use of social tags for Web page classification: adding new Web pages to an existing Web directory. A Web directory is a general human-edited directory of Web pages. It classifies a collection of pages into a wide range of hierarchical categories. The problem with manual construction and maintenance of Web directories is the significant need of time and effort by human experts. Our proposed method is based on applying different automatic approaches of using social tags for extending Web directories with new URLs.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283851","Classification;Social Tagging;Web Directory","Bayesian methods;Computer science;Data mining;Humans;Information resources;Organizing;Tagging;Uniform resource locators;Watches;Web pages","Internet;classification;information retrieval;social networking (online)","URL;Web directory maintenance;Web page classification;meta data;social tagging","","6","","29","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"A new marketing effectiveness metric based on web data mining","L. Huang; X. Zhang","Department of Business Intelligence, B2B China, Alibaba Group Hangzhou, Zhejiang 310099, P.R. China","2009 1st IEEE Symposium on Web Society","20090929","2009","","","5","9","The dominance of the Internet in our lives sees permanent changes of how marketers conduct their marketing and measure their marketing performance. Traditional measurement methods fall short for not being timely and effective. In this study, we propose the use of Web data, in a quantitative metric, to assess market impact of brands. The metric consists of three independent dimensions, covering measures of public relation, government relation, customer awareness and satisfaction. This new marketing performance measure provides marketers with timely market information, including their current market position and instant customer feedback.","2158-6985;21586985","POD:978-1-4244-4157-0","10.1109/SWS.2009.5271733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5271733","","Business communication;Current measurement;Data mining;Feedback;Government;Internet;Libraries;Position measurement;Public relations;Search engines","Internet;consumer behaviour;customer satisfaction;data mining;information retrieval;marketing data processing;public relations;search engines","Internet;Web data mining;current market position;customer awareness;customer behaviour;customer satisfaction;government relation measure;information retrieval;instant customer feedback;marketing effectiveness metric;marketing performance measurement;public relation measure;search engine","","0","","9","","","23-24 Aug. 2009","","IEEE","IEEE Conference Publications"
"Mapping Social Networks into P2P Directory Service","L. Zaczek; A. Datta","PJIIT, Warsaw, Poland","2009 International Workshop on Social Informatics","20090904","2009","","","10","15","This paper presents our approach to use social network information in P2P networks in order to efficiently retrieve relevant information by exploiting existing trust relations of the social network links. The novelty of our work is to demonstrate that only a subset of the whole social network is adequate to build an efficient and reliable service. We use our P2P network, which is an adaptation of virtual ring routing mechanisms originally proposed for ad-hoc networks, to deploy a directory service facilitating search for friends - a common functionality required in online social networks as well. We expect our mechanism can be used in facilitating the deployment of peer-to-peer online social networks. Small scale experiment results, using both artificial as well as real social network graphs, show that with even only small subset of nodes from the whole social network, the approach achieves a high level of query success.","","POD:978-0-7695-3706-1","10.1109/SocInfo.2009.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230728","","","information retrieval;peer-to-peer computing;security of data;social networking (online)","P2P directory service;ad-hoc networks;peer-to-peer online social networks;social network links;trust relations;virtual ring routing mechanisms","","1","","22","","","22-24 June 2009","","IEEE","IEEE Conference Publications"
"Information seeking on the web: An integrated approach based on human collaboration and web 2.0","J. Jiang; Y. Wu; G. Yang; W. Zheng","Department of Computer Science and Technology Tsinghua National Laboratory of Information Science and Technology Tsinghua University, Beijing 100084, P. R. China","2009 1st IEEE Symposium on Web Society","20090929","2009","","","108","112","The explosion of contents on the Web poses a great challenge for users to find ldquorightrdquo information to meet their need. Though some tools exist that can provide help, they only meet the need from limited perspectives and as a result, users have to use multiple tools even for the same goal. This paper proposes an integrated system named Search 2.0 for information seeking on the Web. Specifically, it makes the following contributions: (1) collaboration support is introduced into traditional search engines, making information seeking a social process; (2) an automatic tag learning approach is put forward based on explicit user feedback and traditional search engines.","2158-6985;21586985","POD:978-1-4244-4157-0","10.1109/SWS.2009.5271795","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5271795","","Collaboration;Computer science;Explosions;Feedback;Humans;Information science;Laboratories;Search engines;Web pages;Web sites","Internet;groupware;information retrieval;search engines","Web 2.0;automatic tag learning approach;human collaboration support;information seeking;integrated approach;search engine;user feedback","","0","","22","","","23-24 Aug. 2009","","IEEE","IEEE Conference Publications"
"Where Information Searches for You: The Visible Past Ubiquitous Knowledge Environment for Digital Humanities","S. A. Matei; E. Wernert; T. Faas","Dept. of Commun., Purdue Univ., West Lafayette, IN, USA","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","1043","1047","Visible Past proposes a new class of interdisciplinary learning, documenting, knowledge production, and discovery experiences that are anchored in space and time indicators. The project is supported by a ubiquitous computing platform with Wiki, implicit social networking, and location aware capabilities. The environment can be used as an integrated framework for enhancing learning and research in social sciences and humanities. Its main benefit would be involving the student, the researcher, and/or the museum visitor in mobile interactive experiences which rely on social networking around common topics or spaces.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283055","3D;learning;location-aware;ubiquitous computing;wiki","Cellular phones;Cultural differences;Navigation;Organizing;Pervasive computing;Prototypes;Social network services;Spatial databases;Taxonomy;Virtual reality","humanities;information retrieval;interactive systems;mobile computing;social networking (online);social sciences computing","Wiki;digital humanity;information search;interdisciplinary learning;knowledge production;location aware capability;mobile interactive experience;social networking;social science;ubiquitous knowledge environment","","0","","13","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"Implicit measures of user interests through Geographical region and predicting users' future requests in WWW","A. Rajput; N. Mishra","School of Information Technology, Rajiv Gandhi Technological University, Bhopal, MP, India","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","380","384","Nowadays Web users are facing the problems of information overload and drowning due to the significant and rapid growth in the amount of information and the number of users. As a result, how to provide Web users with more exactly needed information is becoming a critical issue in Web-based information retrieval and Web applications. In this work, we aim to address improving the performance of Web information retrieval and Web presentation through developing and employing Web data mining paradigms.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234523","IP Address;Web-Mining;Web-Usage Mining;Web-log Web Personalization","Couplings;Data mining;Internet;Navigation;Search engines;Visual databases;Web pages;Web search;Web server;World Wide Web","Internet;data mining;information retrieval","Web data mining;Web user;Web-based information retrieval;World Wide Web;geographical region;information overload","","0","","18","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"The structure of the APEX (airborne prism experiment) Processing and Archiving Facility","A. Hueni; J. Bieseman; F. Dell'Endice; E. Alberti; K. Meuleman; M. Schaepman","Remote Sensing Laboratories, Department of Geography, University of Zurich, Switzerland","2009 First Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing","20091016","2009","","","1","4","APEX is a Swiss-Belgian project for the realization of an airborne imaging spectrometer within the framework of the ESA Prodex Programme. The project's emphasis is on delivering products characterized by high level accuracy to the user community. This objective relies on the concept and the actuation of two fundamental phases: (a) instrument calibration and (b) data processing. An accurate instrument calibration procedure is required in order to achieve a proper knowledge of the instrument behavior. The calibration information is structured into calibration cubes. These calibration cubes are then integrated into the specialized processing for data calibration to convert the raw system data into physical (spectral, radiometric, spatial) units. Higher-level products can be ordered and configured by the end users via according web interfaces. The dedicated APEX Processing and Archiving Facility (PAF) is hosted and operated by VITO.","2158-6268;21586268","POD:978-1-4244-4686-5","10.1109/WHISPERS.2009.5289106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5289106","Processing;archiving;calibration;imaging spectrometer","Calibration;Data processing;Geography;Instruments;Laboratories;Radiometry;Relational databases;Remote sensing;Spectroscopy;Storage area networks","data handling;geophysical signal processing;image processing;information retrieval systems;remote sensing","APEX archiving facility;APEX processing;Airborne Prism Experiment processing;ESA Prodex Programme;Swiss-Belgian project;Web interfaces;accurate instrument calibration procedure;airborne imaging spectrometer;calibration cubes;calibration information;data calibration processing;data processing;instrument calibration","","1","","12","","","26-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"Optimizing social life using online friend networks","S. Echegaray; J. Morales; W. Luo","Engineering Department, St. Mary's University, San Antonio, TX 78228, USA","2009 IEEE International Conference on System of Systems Engineering (SoSE)","20091009","2009","","","1","5","This paper presents an online application which ties to the popular social network Facebook. It aggregates data from other systems, including Yahoo! Local and Google Maps, to provide relevant information to users. This system of systems functions as an add-on to each user's Facebook profile. The user is able to store ratings, reviews, and places where he likes to go. Our proposed system uses all this data to create a profile of the user. It also takes into consideration the information from the user's network of friends in Facebook. This information is then combined with businesses information from Yahoo!. All the information gathered in the users profile is then used to recommend interesting places for him to visit when he logs in to our proposed system next time. Our system can display either places highly recommended by one's friends, or places which will hold a special event. The maps of business locations are automatically rendered using Google Maps APIs.","","POD:978-1-4244-4766-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5282340","Facebook;Google Map;Information Aggregation;Social Networking;System of Systems Engineering;Yahoo! Local","Aggregates;Application software;Displays;Facebook;MySpace;Organizing;Physics;Social network services;Software systems;Systems engineering and theory","information retrieval;search engines;social networking (online)","API;Facebook;Google Maps;Yahoo! Local;information aggregation;online friend networks;social life;social network;system of systems;users profile","","0","","15","","","May 30 2009-June 3 2009","","IEEE","IEEE Conference Publications"
"An assisted-teaching language platform based on internet","L. Zhu; X. Zhao; L. Yang; C. Kevin","The School of International Communication, Beijing International Studies University, 100024, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","545","548","The paper introduces a platform based on Internet, which is flexibility to teach languages such as English and Chinese, which not only enlarged teaching resource utilization, but only improved the quality of teaching. The platform presents the accumulation of knowledge resources, the formation of a unique case, the answer to the question of experience and knowledge in a flexible and effective way for students to improve phonetics, and to reduce costs, make learning anytime, anywhere. The paper analyzes the network environment of language corpus intelligent information retrieval, combined with the teaching of the specific application. It proves that the establishment of the assisted-teaching language platform can reduce the burden of learners in many areas, and it helps teachers to enhance teaching effectively.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236362","","Computer science education;Consumer electronics;Context modeling;Costs;Feedback;Internet;Laboratories;Learning systems;Natural languages;Speech recognition","Internet;computer aided instruction;information retrieval;linguistics;natural language processing;teaching","Internet;assisted-teaching language platform;language corpus intelligent information retrieval;quality of teaching","","0","","4","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Method of Web Information Extraction Based on Decision Tree","C. Hong-ye","Sch. of Inf. & Electron. Eng., Zhejiang Univ. of Sci. & Technol., Hangzhou, China","2009 International Forum on Information Technology and Applications","20090904","2009","1","","664","666","Due to the constantly updated characteristic of data in Web, this paper studies the decision tree technology and how to use in the field of Web information extraction. According to the datasets by information extraction, a decision tree of agricultural products market is constructed by C4.5/C5.0 algorithm, with constantly updated data to update the decision tree, and then generate the understandable rules. The experiment proves that it is feasible to realize the Web information extraction based on the decision tree.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.394","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231731","Web information extraction;classification;decision tree;information gain","Agricultural engineering;Classification tree analysis;Consumer electronics;Data engineering;Data mining;Decision trees;Information technology;Internet;Testing;Web pages","Internet;decision trees;information needs;information retrieval","C4.5/C5.0 algorithm;Web information extraction;World Wide Web;agricultural product market;decision tree technology","","1","","6","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Prying Data out of a Social Network","J. Bonneau; J. Anderson; G. Danezis","Comput. Lab. Univ. of Cambridge, Cambridge, UK","2009 International Conference on Advances in Social Network Analysis and Mining","20090904","2009","","","249","254","Preventing adversaries from compiling significant amounts of user data is a major challenge for social network operators. We examine the difficulty of collecting profile and graph information from the popular social networking Website Facebook and report two major findings. First, we describe several novel ways in which data can be extracted by third parties. Second, we demonstrate the efficiency of these methods on crawled data. Our findings highlight how the current protection of personal data is inconsistent with user's expectations of privacy.","","POD:978-0-7695-3689-7","10.1109/ASONAM.2009.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231875","privacy;social networks;web crawling","Collaboration;Computer networks;Context modeling;Cultural differences;Data mining;Data privacy;Facebook;Laboratories;Protection;Social network services","data privacy;information retrieval;social networking (online)","Website facebook;data extraction;graph information;social network;user privacy","","217","","24","","","20-22 July 2009","","IEEE","IEEE Conference Publications"
"Microarray Gene Cluster Identification and Annotation Through Cluster Ensemble and EM-Based Informative Textual Summarization","X. Hu; E. K. Park; X. Zhang","Henan Univ., Kaifeng, China","IEEE Transactions on Information Technology in Biomedicine","20090901","2009","13","5","832","840","Generating high-quality gene clusters and identifying the underlying biological mechanism of the gene clusters are the important goals of clustering gene expression analysis. To get high-quality cluster results, most of the current approaches rely on choosing the best cluster algorithm, in which the design biases and assumptions meet the underlying distribution of the dataset. There are two issues for this approach: 1) usually, the underlying data distribution of the gene expression datasets is unknown and 2) there are so many clustering algorithms available and it is very challenging to choose the proper one. To provide a textual summary of the gene clusters, the most explored approach is the extractive approach that essentially builds upon techniques borrowed from the information retrieval, in which the objective is to provide terms to be used for query expansion, and not to act as a stand-alone summary for the entire document sets. Another drawback is that the clustering quality and cluster interpretation are treated as two isolated research problems and are studied separately. In this paper, we design and develop a unified system Gene Expression Miner to address these challenging issues in a principled and general manner by integrating cluster ensemble, text clustering, and multidocument summarization and provide an environment for comprehensive gene expression data analysis. We present a novel cluster ensemble approach to generate high-quality gene cluster. In our text summarization module, given a gene cluster, our expectation-maximization based algorithm can automatically identify subtopics and extract most probable terms for each topic. Then, the extracted top <i>k</i> topical terms from each subtopic are combined to form the biological explanation of each gene cluster. Experimental results demonstrate that our system can obtain high-quality clusters and provide informative key terms for the gene clusters.","1089-7771;10897771","","10.1109/TITB.2009.2023984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5072272","Cluster ensemble;expectation–maximization (EM);microarray gene expression analysis;text mining","","bioinformatics;genetics;information retrieval;pattern clustering;statistical analysis","Gene Expression Miner;annotation;extractive approach;information retrieval;informative textual summarization;microarray gene cluster identification;query","Algorithms;Cluster Analysis;Databases, Genetic;Genes, Fungal;Models, Statistical;Multigene Family;Oligonucleotide Array Sequence Analysis;Vocabulary, Controlled;Yeasts","8","","27","","20090612","Sept. 2009","","IEEE","IEEE Journals & Magazines"
"A new web information extracting method based on multi-coordinate","Min Huang; Jian-Qing Xi; Bo Sun","School of Software Engineering, South China University of Technology, Guangzhou 510006, China","2009 International Conference on Machine Learning and Cybernetics","20090825","2009","3","","1488","1492","To sovle the problems of lower accuracy and higher re-build workload caused by single path-based data locating methods in the traditional Web information extracting, a new method called multi-coordinate locating of information extracting has been presented in the paper, which constructs three different coordinate systems such as global coordinate, local coordinate and random coordinate to locate the information in HTML page. And it is able to re-locate the path of data by the self-restoring of wrapper based on multi-coordinate systems when the HTML document changes. Each of the three coordinate locating methods has been described in detail. By developing a prototype system and doing some experiments, it can be proved from the results that the multi-coordinate method can improve the tolerance to Web page's changes of the wrapper without adding extra costs and decreasing its performance.","2160-133X;2160133X","POD:978-1-4244-3702-3","10.1109/ICMLC.2009.5212311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212311","Coordinate;Information extracting;Self-healing;Web;Web wrapper","Conference management;Cybernetics;Data mining;Engineering management;HTML;Machine learning;Paper technology;Software engineering;Technology management;Web pages","Internet;information retrieval","HTML page;Web information extracting method;Web page;multicoordinate locating method;single path-based data locating method","","0","","10","","","12-15 July 2009","","IEEE","IEEE Conference Publications"
"Reducing noise in hyperspectal data — A nonlinear data series analysis approach","D. G. Goodenough; Tian Han","Department of Computer Science, University of Victoria, Canada","2009 First Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing","20091016","2009","","","1","4","Hyperspectral data are subject to a variety of noise sources associated with the physical processes involved during data acquisition, which distort signal statistical properties and limit the applications of hyperspectral data for information extraction. Noise reduction is, therefore, a prerequisite for many hyperspectral data applications based on classification, target identification, and spectral unmixing. Studies have found that hyperspectral data are more complicated than realizations of linear stochastic processes, upon which many hyperspectral noise reduction algorithms are based. The noise in hyperspectral data may be non-Gaussian and signal dependent. Moreover, as demonstrated in our previous work, hyperspectral data exhibit apparent nonlinear characteristics, which suggests that the noise may exist in broad-band in the frequency domain. An algorithm is introduced in this paper with the intention to improve the noise reduction for hyperspectral data. The effectiveness of the algorithm is evaluated using multiple metrics focusing on both noise reduction and spectral shape preservation.","2158-6268;21586268","POD:978-1-4244-4686-5","10.1109/WHISPERS.2009.5289014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5289014","AVIRIS;hyperspectral;noise reduction;nonlinearity;time series analysis","Data acquisition;Data analysis;Data mining;Frequency domain analysis;Hyperspectral imaging;Multi-stage noise shaping;Noise reduction;Nonlinear distortion;Signal processing;Stochastic processes","data acquisition;data analysis;image denoising;information retrieval;principal component analysis;stochastic processes;time series","data acquisition;frequency domain;hyperspectal data imaging;hyperspectral denoising algorithms;hyperspectral noise reduction algorithms;information extraction;linear stochastic processes;nonGaussian noise;nonlinear data series analysis approach;principle component analysis;signal statistical properties;spectral shape preservation;target identification;time series analysis","","2","","12","","","26-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"Whither the Experts? Social Affordances and the Cultivation of Experts in Community Q&A Systems","H. T. Welser; E. Gleave; V. Barash; M. Smith; J. Meckes","Sociology, Ohio Univ., Athens, OH, USA","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","450","455","Community based question and answer systems have been promoted as Web 2.0 solutions to the problem of finding expert knowledge. This promise depends on systemspsila capacity to attract and sustain experts capable of offering high quality, factual answers. Content analysis of dedicated contributorspsila messages in the live QnA system found: (1) few contributors who focused on providing technical answers (2) a preponderance of attention paid to opinion and discussion, especially in non-technical threads. This paucity of experts raises an important general question: how do the social affordances of a site alter the ecology of roles found there? Using insights from recent research in online community, we generate a series of expectations about how social affordances are likely to alter the role ecology of online systems.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5284180","Q&A;affordances;computer mediated collective action;emergence;experts;online community;social media;social roles","Discussion forums;Environmental factors;Image converters;Information analysis;Information science;Internet;Programming profession;Signal to noise ratio;Sociology;Yarn","Internet;information retrieval","Web 2.0 solution;content analysis;expert cultivation;online community Q&A system;question and answer system;role ecology;social affordance","","3","","24","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"A New Method for Data Hiding Domain Classification","L. Jing; T. Guangming","Zhengzhou Inf. Sci. & Technol. Inst., Zhengzhou, China","2009 International Forum on Information Technology and Applications","20090904","2009","3","","260","263","Data hiding domain identification is very important for further steganalysis. A statistic feature-based method is advocated for identifying the hiding domain in this research. Different features in different domains that can reflect well statistical changes due to data hidden are extracted. In order to obtain better classification results, a process of adding noise is introduced to extract the feature that can classify spatial and DCT domain hiding. Based on the ""one-against-one"" SVM classifier, the experiment is implemented and the proposed method has performed satisfied classification results.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.280","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232109","""one-against-one"" SVM;adding noise;classification;data hiding domain;feature","Data encapsulation;Data mining;Discrete cosine transforms;Discrete wavelet transforms;Feature extraction;Information technology;Pixel;Steganography;Support vector machine classification;Support vector machines","data encapsulation;feature extraction;information retrieval;pattern classification;statistical analysis;steganography","DCT domain hiding;data extraction;data hiding domain classification;feature extraction;statistic feature-based method;steganalysis","","0","","6","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"A decision tree based article recommanding system","Mei-Yi Wu; Shang-Rong Tsai; Zi-Yi Yang","Department of Information Management, Chang Jung Christian University, Tainan, Taiwan","2009 4th International Conference on Computer Science & Education","20090901","2009","","","1646","1651","In this study, an article recommendation system for English reading comprehension improvement is proposed. The goal of this study is to find out the most important attributes that affect the difficulty of an article according to the levels granted by the General English Proficiency Test (GEPT). Using the determined attributes to classify the articles gathered by the crawler from the Internet everyday and recommending the proper ones to the user, the proposed system is designed to keep the users from being recommended the articles those are too hard or too simple and retain their learning enthusiasm. To determine the attributes that affect the difficulty of an article, the classification algorithms of decision tree are used to construct the classification rules. The experimental result shows that to classify article into the 3 levels defined as elementary, intermediate, and high-intermediate according to GEPT, require 5 attributes to achieve above 70% above accuracy; while to classify articles into just elementary and high-intermediate level, only 2 attributes are required for 80% above accuracy.","","POD:978-1-4244-3520-3","10.1109/ICCSE.2009.5228284","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228284","Adaptive English Learning System;English Article Recommendation System;General English Proficiency Test (GEPT);data mining","Classification tree analysis;Computer science;Computer science education;Crawlers;Data mining;Decision trees;Information management;Internet;Life testing;Web pages","Internet;computer aided instruction;decision trees;information retrieval;pattern classification","General English Proficiency Test;Internet;article recommendation system;article recommending system;classification algorithms;classification rules;decision tree;learning enthusiasm","","0","","8","","","25-28 July 2009","","IEEE","IEEE Conference Publications"
"Information Extraction from Semi-structured WEB Page Based on DOM Tree and its Application in Scientific Literature Statistical Analysis System","W. Li; Y. Dong; R. Wang; H. Tian","Sch. of Inf. Technol., Hebei Univ. of Econ. & Bus., Shijiazhuang, China","2009 IITA International Conference on Services Science, Management and Engineering","20090904","2009","","","124","127","To extract information automatically from semi-structured Web pages, this paper puts forward a method named IESS for discovering the record model based on DOM and maximal similar sub tree, to identify records automatically and correctly when there are some differences in expression models of records that belong to the same type. To test the performance of the method, a scientific literature statistical analysis system is designed. The practice shows that users can quickly understand the distribution of papers in their retrieving field and grasp the importance with the help of the system.","","POD:978-0-7695-3729-0","10.1109/SSME.2009.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5233332","Automatic information extraction;DOM;Scientific Literature;Statistical Analysis","Application software;Conference management;Data mining;Databases;Engineering management;HTML;Information management;Statistical analysis;Technology management;Web pages","Web sites;information retrieval;statistical analysis;tree data structures","DOM tree;IESS method;information extraction;maximal similar sub tree;scientific literature statistical analysis system;semistructured Web page","","1","","5","","","11-12 July 2009","","IEEE","IEEE Conference Publications"
"Information Extraction for a scenario from multi-documents with RBFNN and L-GEM","Wei-Wei Lai; W. W. Y. Ng; D. S. Yeung; Xin-Ru Bai; Jin-Cheng Li; B. B. Sun","Machine Learning and Cybernetics Research Center, School of Computer Science and Engineering, South China University of Technology, 510006, Guangzhou, China","2009 International Conference on Machine Learning and Cybernetics","20090825","2009","2","","1100","1105","The goal of information extraction (IE) is to find the specific information from documents composed by natural language for a particular scenario. With the development of IE methodologies, a lot of information extraction tools have been proposed and are playing an important role in information processing. However, the efficiency of these tools may not be satisfactory to users. One of those important reasons is that most of these IE tools extract information from a single document. In this paper, we propose a extracting method which combine current single document based named extraction (NE) tool with a multi-document based radial basis function neural networks (RBFNN) for multi-document IE. The RBFNN is trained by a minimization of the localized generalization error model (L-GEM) to enhance its generalization capability. We collect a set of news pages from the Internet for the same news. Interested names are extracted by the most frequent name extracted by the NE tool. Numbers and other information that can not be extracted by NE tool will be extracted by the RBFNN by a pattern classification approach. The scenario of company layoff is used as an example to show how we extract the corresponding company name, company major location and the number of layoffs. Experimental results show the proposed method is effective and accurate.","2160-133X;2160133X","POD:978-1-4244-3702-3","10.1109/ICMLC.2009.5212380","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212380","DF/IDF;Information Extraction;L-GEM;Multiple Documents;RBFNN","Computer science;Cybernetics;Data mining;Information processing;Internet;Machine learning;Natural languages;Search engines;Semantic Web;Web pages","Internet;generalisation (artificial intelligence);information retrieval;learning (artificial intelligence);natural languages;pattern classification;radial basis function networks","IE;Internet;L-GEM;NE;RBFNN;company layoff scenario;information extraction;localized generalization error model;multidocument scenario;named extraction tool;natural language;neural network training;pattern classification approach;radial basis function neural network","","0","","13","","","12-15 July 2009","","IEEE","IEEE Conference Publications"
"Bayesian Similarity Model Estimation for Approximate Recognized Text Search","A. Takasu","Nat. Inst. of Inf., Tokyo, Japan","2009 10th International Conference on Document Analysis and Recognition","20091002","2009","","","611","615","Approximate text search is a basic technique to handle recognized text that contains recognition errors. This paper proposes an approximate string search for recognized texturing a statistical similarity model focusing on parameter estimation. The main contribution of this paper is to propose a parameter estimation algorithm using variational Bayesian expectation maximization technique. We applied the obtained model to approximate substring detection problem and experimentally showed that the Bayesian estimation is effective.","1520-5363;15205363","POD:978-1-4244-4500-4","10.1109/ICDAR.2009.193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277575","VBEM algorithm;approximate string search;statistical model","Bayesian methods;Costs;Hidden Markov models;Matrices;Matrix converters;Maximum likelihood estimation;Optical character recognition software;Parameter estimation;Software libraries;Text recognition","Bayes methods;expectation-maximisation algorithm;hidden Markov models;information retrieval;parameter estimation;pattern recognition;text analysis;variational techniques","Bayesian similarity model estimation;approximate recognized text search technique;approximate substring detection problem;parameter estimation algorithm;statistical similarity model;texture recognition;variational Bayesian expectation maximization technique","","3","","8","","","26-29 July 2009","","IEEE","IEEE Conference Publications"
"Modeling and reconstruction of the statistical data from a system electronic application for administrative management in IPN through the filter of Kalman","P. Guevara-Lopez; J. J. Medel-Juarez; M. T. Z. Alvarez; A. T. R. Romero","Escuela Superior de Ingenier&#237;a Mec&#225;nica y El&#233;ctrica, Unidad Culhuac&#225;n - IPN, M&#233;xico D.F., Mexico","2009 52nd IEEE International Midwest Symposium on Circuits and Systems","20090915","2009","","","1081","1085","On the Management of Human Capital at the National Polytechnic Institute are developing information systems that seek improvements in administrative procedures, ensuring the acquisition complete of date, reliable and opportune, using technology available at the WEB. This aims to provide a quality service to more than 24,800 employees. In this case we propose the application forms via the Internet, because these employees carry data and digital documents. However, to provide the best service and sizing the server, it is necessary to analyze the accesses to the database and rebuild the system; for this is necessary to realize measurements using a free software tool and to analyze it as a system with parameter variations in time represented by an ARMA model using the Kalman filter as parameter estimator with good results.","1548-3746;15483746","POD:978-1-4244-4479-3","10.1109/MWSCAS.2009.5235956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5235956","","Application software;Databases;Humans;Internet;Kalman filters;Management information systems;Size measurement;Software measurement;Technology management;Web server","Internet;Kalman filters;autoregressive moving average processes;information retrieval;software tools","ARMA model;Internet;Kalman filter;Management of Human Capital at the National Polytechnic Institute;administrative management;software tool;statistical data reconstruction;system electronic application","","0","","13","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"Relation discovery by named entity recognition from Tibetan websites","H. Yu; T. Jiang; B. Zhang; X. Chen","State Key Laboratory of National Languages Information Technology, Northwest University for Nationalities No. 1 Xibei Xincun Lanzhou, Gansu, China","2009 1st IEEE Symposium on Web Society","20090929","2009","","","177","179","Discovering the significant relations embedded in the Web pages would be very useful for community discovery. In this paper, we propose an unsupervised method for relation discovery from Tibetan Web pages, which is based on co-occurrences of named entities in the pages. In order to find the relation, a rule-based named entity recognition algorithm has been proposed. Our experiment shows that the algorithm has got a high precision and recall by using 30.2 megabyte plain text from three large Tibetan Web sites. And we also give a relation strength formula combining the co-occurrence frequency and personal information, thus the relation in the Web pages can easily be fond according to the value of the relation strength.","2158-6985;21586985","POD:978-1-4244-4157-0","10.1109/SWS.2009.5271789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5271789","","Data processing;Encoding;Frequency;Information technology;Internet;Java;Laboratories;Libraries;Markup languages;Web pages","data mining;information retrieval;natural language processing;social networking (online);unsupervised learning","Tibetan Web pages;Tibetan Web sites;community network discovery;information retrieval;named entity co-occurrence frequency;personal information;relation discovery;relation strength formula;rule-based named entity recognition algorithm;social network discovery;unsupervised method","","0","","7","","","23-24 Aug. 2009","","IEEE","IEEE Conference Publications"
"Visualization User Interface for Decision Support Systems","S. Yu; L. Deng; Y. Zhang","Coll. of Software, Shenyang Normal Univ., Shenyang, China","2009 Ninth International Conference on Hybrid Intelligent Systems","20090922","2009","1","","63","66","Many users benefit from decision support systems (DSS), but sometimes they can't readily comprehend the nature or meaning of the outcome from DSS. In general, interpretation of data is much more intuitive if the results from the DSS are translated into charts, maps, and other graphical displays because visualization exploits our natural ability to recognize and understand visual patterns. In this paper we discuss the concept of visualization user interface (VUI) for DSS. An information visualization model for DSS is proposed, which consists of three elements. In addition, a visualized information retrieval engine based on fuzzy control is proposed.","","POD:978-0-7695-3745-0","10.1109/HIS.2009.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254347","Decision support systems;Fuzzy query;Information visualization;User interface","Application software;Computer interfaces;Data visualization;Decision support systems;Displays;Humans;Hybrid intelligent systems;Pattern recognition;User interfaces;Vehicles","data visualisation;decision support systems;fuzzy control;information retrieval;user interfaces","decision support system;fuzzy control;graphical display;visualization user interface;visualized information retrieval engine","","2","","12","","","12-14 Aug. 2009","","IEEE","IEEE Conference Publications"
"Understanding the Search Interfaces of the Deep Web Based on Domain Model","X. Yuan; H. Zhang; Z. Yang; Y. Wen","Coll. of Inf. Tech. Sci., Nankai Univ., Tianjin, China","2009 Eighth IEEE/ACIS International Conference on Computer and Information Science","20090825","2009","","","1194","1199","The Web has been rapidly deepened by many searchable databases online recently. Those databases can be accessed through form-based search interfaces that allow users to specify query conditions. For integrating Web databases, the very first challenge is to understand the search interface. Such a search interface can be considered as an interface schema with multiple attributes, however, the interface is created autonomously and its schema is not defined in HTML which makes the schema extraction of an interface a challenge task. In this paper, we propose a novel approach to automatic extraction of the logic attributes from search interfaces. First, we define a domain model for each deep Web domain as a global schema to guide the extraction process of the interface schema; second, we group the labels belonging to the same attribute of an interface, and produce a label tree of the interface; third, we find the related label of each element if it has one; last, we merge the results of the former two steps to complete the schema extraction. The last three steps are implemented based on the domain model. Our experiments show the promise of this approach-it achieves above 96.87% accuracy for extracting query attributes.","","POD:978-0-7695-3641-5","10.1109/ICIS.2009.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5223369","Deep web;domain model;serche interface","Application software;Automatic logic units;Computer interfaces;Data mining;Databases;Educational institutions;HTML;Humans;Information science;Web search","Internet;information retrieval systems;query processing;tree searching;user interfaces","automatic logic attribute extraction;deep Web search interface;domain model;form-based search interface;label tree;online database;query condition specification;schema extraction","","1","","13","","","1-3 June 2009","","IEEE","IEEE Conference Publications"
"Evaluating the Impact of Attacks in Collaborative Tagging Environments","M. Ramezani; J. J. Sandvig; T. Schimoler; J. Gemmell; B. Mobasher; R. Burke","Center for Web Intell., DePaul Univ., Chicago, IL, USA","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","136","143","The proliferation of social Web technologies such as collaborative tagging has led to an increasing awareness of their vulnerability to misuse. Attackers may attempt to distort the system's adaptive behavior by inserting erroneous or misleading annotations, thus altering the way in which information is presented to legitimate users. Prior work on recommender systems has shown that studying different attack types, their properties and their impact, can help identify robust algorithms that make these systems more secure and less vulnerable to manipulation.Unlike traditional recommender systems, a tagging system includes multiple retrieval algorithms to facilitate browsing of resources, users and tags. The challenge is, therefore, evaluating the impact of various types of attacks across different navigation options. In this paper we develop a framework for characterizing attacks against tagging systems. We then propose a methodology for evaluating their global impact based on PageRank. Using real data from a popular tagging systems, we empirically evaluate the effectiveness of several attack types. Our results help us understand how much effort is needed from an attacker to change the behavior of a tagging system and which attack types are more successful against such systems.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5284269","Attack;Folksonomy;Social Tagging Systems;Spam","Adaptive systems;Buildings;Collaborative work;Computational intelligence;Filtering;International collaboration;Navigation;Recommender systems;Robustness;Tagging","groupware;information filtering;information retrieval;security of data;social networking (online)","PageRank;Web browsing;collaborative tagging environment;misleading annotation;multiple retrieval algorithm;recommender system;social Web technologies","","2","","20","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"Introduction to China minority speech acoustic Parameter Database Platform","X. Zhou; Y. Zheng; H. Hu","Institute of Ethnology and Anthropology, Chinese Academy of Social Sciences, China","2009 Oriental COCOSDA International Conference on Speech Database and Assessments","20091002","2009","","","132","136","This paper introduces the current primary functionalities, characteristics and usages of Unified Minority Speech Parameter Database Platform Software as well as future-expanded functions. By using the platform, we can accomplish acoustic parameter retrieval, statistics and analysis of established Tibetan, Uigur and Yi broadcasting acoustic parameter databases. After adding acoustic parameters of more minority language speech into the platform, phonological analysis and comparison of languages within same language family can be achieved. Other important goals of designing the platform are to implement phonetic resources sharing, accumulation and protection of endangered minority language speech esc.","","CD-ROM:978-1-4244-4400-7","10.1109/ICSDA.2009.5278361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5278361","","Automatic speech recognition;Databases;Hidden Markov models;Labeling;Natural languages;Speech analysis;Speech synthesis;Strontium","audio databases;information retrieval;natural language processing;speech processing","China minority speech acoustic parameter database platform;Tibetan Lahsa vowel analysis;Tibetan Lahsa vowel statistics;Tibetan broadcasting acoustic parameter database;Uigur broadcasting acoustic parameter database;Unified Minority Speech Parameter Database Platform Software;Yi broadcasting acoustic parameter database;acoustic parameter retrieval;minority language speech;phonetic resource sharing;phonological analysis","","1","","5","","","10-12 Aug. 2009","","IEEE","IEEE Conference Publications"
"Text Mining on Semi-structured E-Government Digital Archives of China","H. Dong; S. Yu; Y. Jiang","Center for the Studies of Inf. Resources (CSIR), Wuhan Univ., Wuhan, China","2009 Second Pacific-Asia Conference on Web Mining and Web-based Application","20090904","2009","","","11","14","The Chinese government has devoted to e-government development for decades. Digital archives have been built up in almost every level of Chinese government hierarchy. The structure features of the archives in Chinese government are discussed first in this paper. Then, it proposes a practical approach for text mining of these semi-structured archives. With the help of semantic Web related technology, knowledge extracted through mining can be stored and managed in ontology base for administrators, and can be retrieved through ontology presentation system for end-users. Finally, a case study in a provincial archives bureau of China is introduced, which shows that knowledge among the archives especially dynamic knowledge can be easily mined and utilized in this way. It helps a lot in policy making, emergency decision support, and government routines.","","POD:978-0-7695-3646-0","10.1109/WMWA.2009.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232456","Digital Archives;E-Governamtn;Ontoloty OWL;Text Mining","Electronic government;Information resources;Knowledge management;Law;Legal factors;Ontologies;Production;Semantic Web;Technology management;Text mining","data mining;government data processing;information retrieval systems;knowledge representation languages;ontologies (artificial intelligence);semantic Web;text analysis","Chinese government hierarchy;ontology presentation system;semantic Web related technology;semistructured e-government digital archives;text mining","","2","","14","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Extraction of coexpression relationship among genes from biomedical text using dynamic conditional random fields","R. Tiwari; C. Zhang; W. B. Chen","Department of Computer and Information Sciences, University of Alabama at Birmingham, USA","2009 22nd IEEE International Symposium on Computer-Based Medical Systems","20090922","2009","","","1","4","Text mining tools and algorithms are being successfully used for information extraction especially on large corpus like biomedical publications. These tools not only aid in information extraction but also in forming new theories and relationships between various fields of biomedical research. Extraction of gene-gene or gene-disease relationship is one such application. In this paper, we introduce a method to detect coexpressed genes from text, using the grammatical dependencies among the words within sentences and Dynamic Conditional Random Fields (DCRFs). Determining the coexpression relationship between and among genes can help in identifying important concepts such as the functionality of gene(s) involved, their pathogenic mechanism, and in deciphering protein-protein interactions. This work attempts to extract relevant sentences by labeling the genes involved as well as the word representing the relationship, from full-length papers collected from PubMed. The results obtained were compared with that of Support Vector Machine (SVM) and Nearest Neighbor with generalization (NNge), and have been found to outperform both.","1063-7125;10637125","POD:978-1-4244-4879-1","10.1109/CBMS.2009.5255388","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255388","","Biomedical computing;Data mining;Graphical models;Hidden Markov models;Nearest neighbor searches;Proteins;Support vector machine classification;Support vector machines;Testing;Text mining","data mining;genetics;grammars;information retrieval;medical computing;random processes;text analysis","PubMed;biomedical text mining;coexpression relationship information extraction;dynamic conditional random field;gene-disease relationship;grammatical dependency;large corpus;nearest neighbor;pathogenic mechanism;protein-protein interaction;support vector machine","","0","","16","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"The research of an improved information gain method using distribution information of terms","Y. z. Yang; P. y. Liu; Z. f. Zhu; Y. Qiu","Department of Information Science and Engineering, Shandong Normal University, Ji'nan 250014, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","938","941","The inadequacy of the information gain is taken into account the situation that the term does not appear. But, in this paper, by analyzing the distribution information of terms, we find if the value of distribution information inside a class of the term becomes large, the distribution of the term inclines to imbalance, and if there is high imbalance of the term, the distribution information among classes will tend to a smaller value. Therefore, the distribution information inside a class and distribution information among classes are introduced to this paper to reduce the effect of the term does not appear, and improve the traditional information gain. After experimental verification, the improved algorithm (GDI) has a better performance than traditional feature selection algorithm in some fields, such as the information gain.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236210","","Chaos;Entropy;Frequency;Gain measurement;Information analysis;Information science;Mutual information;Performance gain;Text categorization","information retrieval;text analysis","distribution information of terms;experimental verification;improved information gain method","","2","","7","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Empirical Research on E-Government Based on Content Mining","Y. Shen; Z. Liu; S. Luo; H. Fu; Y. Li","Sch. of Inf. Manage., Wuhan Univ., Wuhan, China","2009 International Conference on Management of e-Commerce and e-Government","20091006","2009","","","91","94","According to acquiring data from the meta-search engine and getting information in specific websites, the author proposes an extraction model based on Web information which is used to construct network relationships of the subject based on its semantic link. Then based on the proposed model above, the author does content mining and semantic analysis on the Web data of five big cities (Beijing, Shanghai, Wuhan, Guangzhou, and Chengdu) with the help of self-made ROST Content Mining System, to get first 30 high-frequency e-government words respectively, and takes Shanghai for specific analysis; Meanwhile, the author, using ROST WebSpider to collect the web page from level 1 to 3 of governments' websites in Beijing, Shanghai, Wuhan, Guangzhou and Chengdu, constructs the evaluation model SCISS to do comparative analysis on the development of the five metropolis' e-government. Finally, the author comes up with some countermeasures, aiming to provide advice for the development of e-government in china, according to the empirical analysis.","","POD:978-0-7695-3778-8","10.1109/ICMeCG.2009.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5279885","E-government;content mining;meta-search engine;social network","Algorithm design and analysis;Conference management;Content management;Data mining;Electronic government;Frequency;Information analysis;Metasearch;Search engines;Web pages","Web sites;electronic commerce;government data processing;information retrieval;search engines","Beijing;Chengdu;Guangzhou;ROST Content Mining System;ROST WebSpider;Shanghai;Web information;Web sites;Wuhan;e-government;meta-search engine;semantic analysis","","0","","10","","","16-19 Sept. 2009","","IEEE","IEEE Conference Publications"
"Enabling single point access to e-resources: A Manipal University Health Sciences Library initiative","M. Rao; M. V. Mudhol","Health Sciences Library, Kasturba Medical College, Manipal University, 576 104, Karnataka, India","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","300","304","Begun with Kasturba Medical College, Manipal, India in 1953, Manipal University Health Sciences Library, India is one of the largest libraries in South East Asia. Library offers a rich array of information resources for pursuing discovery and research. The library has access to variety of e-resources, including 18 online databases, more than 2500 online journals and e-books which have been made available to library users via various interfaces. Frustrated with navigating these different interfaces, Manipal University became aware of the fact that Health Sciences Library required a solution to access all library e-resources from a single entry point. This paper goes into the details on the ERMSS software which has provided library users with a single point access for effective searching of e-resources held by library. ERMSS meets the challenge with a feature-rich system combined with a robust administrative module and enabling a single point of access to entire e-resource collection of the library.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234688","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234688","ERMSS;Health Sciences Library;Internet;Library Users;Single Point Access;e-Resources","Abstracts;Asia;Cities and towns;Databases;Educational institutions;Information resources;Information science;Internet;Navigation;Software libraries","academic libraries;electronic publishing;information resources;information retrieval","ERMSS software;Kasturba Medical College;Manipal University Health Sciences Library;e-books;e-resources;information resources;online journals;single point access","","0","","4","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Content Based Image Retrieval Using Unclean Positive Examples","J. Zhang; L. Ye","Sch. of Comput. Sci. & Software Eng., Univ. of Wollongong, Wollongong, NSW, Australia","IEEE Transactions on Image Processing","20090909","2009","18","10","2370","2375","Conventional content-based image retrieval (CBIR) schemes employing relevance feedback may suffer from some problems in the practical applications. First, most ordinary users would like to complete their search in a single interaction especially on the Web. Second, it is time consuming and difficult to label a lot of negative examples with sufficient variety. Third, ordinary users may introduce some noisy examples into the query. This correspondence explores solutions to a new issue that image retrieval using unclean positive examples. In the proposed scheme, multiple feature distances are combined to obtain image similarity using classification technology. To handle the noisy positive examples, a new two-step strategy is proposed by incorporating the methods of data cleaning and noise tolerant classifier. The extensive experiments carried out on two different real image collections validate the effectiveness of the proposed scheme.","1057-7149;10577149","","10.1109/TIP.2009.2026669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5156260","Classifier combination;content-based image retrieval (CBIR);feature aggregation;noise tolerant;support vector machine (SVM)","","content-based retrieval;image classification;image retrieval;information retrieval","CBIR scheme;content based image retrieval;image classification technology;multiple feature distance;noise tolerant classifier;relevance feedback;unclean positive example","Algorithms;Artificial Intelligence;Database Management Systems;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Pattern Recognition, Automated;Radiology Information Systems;Subtraction Technique","17","","33","","20090706","Oct. 2009","","IEEE","IEEE Journals & Magazines"
"Using Qtag to Extract Dominant Public Opinion in Very Large-Scale Conversation","S. E. Lee; T. Chun; ". S. Han","Proactive Project Group, NHN, Seoul, South Korea","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","753","758","These days VLSC (very large-scale conversation) is a particular type of online conversation, that is large scale, public, text-based, many-to-many and persistent. The nature of VLSC allows the accumulation of thousands of conversation in a fraction of time, and it often grows out of userspsila readable capacity. Therefore, extracting dominant public opinion on VLSC is usually impossible without causing an information overload. In this paper, Qtag is proposed to improve the VLSC environment by extracting public opinion easily, enhancing the value of conversation, and increasing the participantspsila willingness to engage. A simulation which mimics reality is built to create a VLSC environment, and two sets of questionnaire are conducted to compare userspsila experiences before and after Qtag trial.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283382","Collaborative Tagging;Interface;Public opinion;Qtag;Qualitative Tagging;VLSC","Atmosphere;Collaboration;Collaborative tools;Data mining;Graphical user interfaces;Large-scale systems;Prototypes;Tagging;Text analysis;Web and internet services","identification technology;information retrieval;text analysis","Qtag;dominant public opinion extraction;online conversation;text-based;very large-scale conversation","","0","","7","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"Web usage mining based on fuzzy clustering in identifying target group","J. Zhang; P. Zhao; L. Shang; L. Wang","Shandong institute of commerce and technology, Shandong, 250103, China","2009 ISECS International Colloquium on Computing, Communication, Control, and Management","20090929","2009","4","","209","212","Data mining focuses on the techniques of non-trivial extraction of implicit, previously unknown, and potentially useful information from very large amounts of data. Web mining can be defined simply as the application of data mining techniques to Web data. Web usage mining (WUM) is an important category in Web mining. Web usage mining is an important and fast developing area of Web mining where a lot of research has been done already. We improved the fuzzy clustering algorithm to find groups which share common interests and behaviors by analyzing the data collected in Web servers.","2154-9613;21549613","POD:978-1-4244-4247-8","10.1109/CCCM.2009.5267789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5267789","","Clustering algorithms;Communication system control;Data mining;Fuzzy control;Information analysis;Internet;Technology management;Web mining;Web pages;Web server","Internet;bank data processing;customer relationship management;data mining;information retrieval;marketing data processing;pattern clustering","Internet banking;WUM;Web data mining technique;Web server;Web usage mining;customer relationship management;fuzzy clustering algorithm;marketing;nontrivial information extraction;target group identification","","7","","10","","","8-9 Aug. 2009","","IEEE","IEEE Conference Publications"
"Exploring Emergent Semantic Communities from DBLP Bibliography Database","Z. Huang; Y. Yan; Y. Qiu; S. Qiao","Semantic Grid Lab., Southwest Univ., Chongqing, China","2009 International Conference on Advances in Social Network Analysis and Mining","20090904","2009","","","219","224","In this paper, we construct a word association network from DBLP bibliography records and detect its evolution progress based on community discovery algorithm CPM and CPMw. We found that the network is of complex network characteristics, and the detected semantic communities can be classified into two categories: giant community and small community. They differ in size and content, and behave differently in the network evolution. Discovering the evolution of network and the emergent semantic communities can help researchers grasp the state of arts of the related field, identify emergent issues and thus inspire new idea to solve scientific questions.","","POD:978-0-7695-3689-7","10.1109/ASONAM.2009.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231882","Clique Percolation Method;complex network;evolution;semantic community","Bibliographies;Clustering algorithms;Complex networks;Computer science;Databases;Frequency;Information analysis;Social network services;Software libraries;Web server","bibliographic systems;complex networks;information retrieval;text analysis","CPM algorithm;CPMw algorithm;DBLP bibliography database;DBLP bibliography record;Digital Bibliography & Library Project;clique percolation method;community discovery algorithm;complex network;emergent semantic community;giant community;network evolution;small community;word association network","","13","","17","","","20-22 July 2009","","IEEE","IEEE Conference Publications"
"The cost of doing science on the cloud: The Montage example","E. Deelman; G. Singh; M. Livny; B. Berriman; J. Good","USC Information Sciences Institute, Marina del Rey, CA, USA","2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis","20090825","2008","","","1","12","Utility grids such as the Amazon EC2 cloud and Amazon S3 offer computational and storage resources that can be used on-demand for a fee by compute and data-intensive applications. The cost of running an application on such a cloud depends on the compute, storage and communication resources it will provision and consume. Different execution plans of the same application may result in significantly different costs. Using the Amazon cloud fee structure and a real-life astronomy application, we study via simulation the cost performance tradeoffs of different execution and resource provisioning plans. We also study these trade-offs in the context of the storage and communication fees of Amazon S3 when used for long-term application data archival. Our results show that by provisioning the right amount of storage and compute resources, cost can be significantly reduced with no significant impact on application performance.","2167-4329;21674329","CD-ROM:978-1-4244-2835-9; POD:978-1-4244-2834-2","10.1109/SC.2008.5217932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5217932","","Astronomy;Cloud computing;Collaborative work;Computer applications;Costs;Grid computing;Information analysis;Marine technology;Optical computing;Permission","grid computing;information retrieval;search engines","Amazon EC2 cloud;Amazon S3;Amazon cloud fee structure;communication resources;cost performance tradeoffs;data archival;data-intensive applications;real-life astronomy application;resource provisioning plans;utility grids","","220","1","34","","","15-21 Nov. 2008","","IEEE","IEEE Conference Publications"
"A model of cross language retrieval for IT domain papers through a map of ACM Computing Classification System","G. Kembellec; I. Saleh; C. Sauvaget","Paragraphe Laboratory, Paris 8 University, Saint-Denis, France","2009 International Conference on Multimedia Computing and Systems","20090922","2009","","","162","168","This article presents a concept model, and the associated tool to help advanced learners to find adapted bibliography. The purpose is the use of an IT representation as educational research software for newcomers in research. We use an ontology based on the ACM's Computing Classification System in order to find scientific articles directly related to the new researcher's domain without any formal request. An ontology translation in French is automatically proposed and can be based on Web 2.0 enhanced by a community of users. A visualization and navigation model is proposed to make it more accessible and examples are given to show the interface of our tool: Ontology Navigator.","","POD:978-1-4244-3756-6","10.1109/MMCS.2009.5256709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5256709","Cross Language Research.;Digital Library;Domain Ontology;Information retrival;KBS;Metadata","Bibliographies;Internet;Knowledge based systems;Laboratories;Natural languages;Navigation;Ontologies;Search engines;Software libraries;Visualization","Internet;bibliographic systems;classification;computer aided instruction;information retrieval;ontologies (artificial intelligence)","ACM computing classification system;IT domain papers;Ontology Navigator;Web 2.0;adapted bibliography;cross language retrieval;educational research software","","0","","14","","","2-4 April 2009","","IEEE","IEEE Conference Publications"
"Explorations on Object-Oriented Classification for Ground Targets from High-Resolution Image","L. Lingjun; H. Yan","Inst. of Remote Sensing Applic., Chinese Acad. of Sci., Beijing, China","2009 International Forum on Information Technology and Applications","20090904","2009","1","","139","143","Under the constant advancement of remote sensing technology, more and more high spatial resolution data are becoming available, the developments not only greatly increased our capability and accuracy in information extraction but also opened new application opportunities. Existing research activities have focused on how to increase the utilization efficiency of high resolution data, particularly in a wide range of applications such as urban environment, urban-planning, precision agriculture, forest inventory and risk assessment, however, the overall level of automation is still low. The paper adopted the multi-feature information of high-resolution images, objected-oriented image analysis approaches and multi-scale image segmentation technology, established a corresponding relevant knowledge base to extract information. Also the results show the new approach provided a satisfying solution to improve the level of autoimmunization and intelligentization of high-resolution remote sensing data process and application.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.444","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231543","High-Resolution Image;Image Segmentation;Information Extraction;Object-oriented","Data mining;Image segmentation;Information technology;Intelligent sensors;Multispectral imaging;Object oriented modeling;Pixel;Remote sensing;Shape;Spatial resolution","geophysical signal processing;image classification;image segmentation;information retrieval;object-oriented methods;remote sensing","forest inventory;high spatial resolution data;high-resolution image;high-resolution remote sensing data process;information extraction;multiscale image segmentation technology;object-oriented classification;objected-oriented image analysis;risk assessment;urban environment;urban-planning","","1","","10","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"A Name Recommendation Photo Album Using Probability Neural Network","D. H. Chen; S. E. Tang","Dept. of Comput. Sci. & Inf., Southern Taiwan Univ., Yung-Kang, Taiwan","2009 Fifth International Conference on Information Assurance and Security","20091009","2009","1","","379","382","In this paper, we propose a name recommendation mechanism used in the photo albums. We apply a light compensation method to improve the image quality, and then a face detection algorithm is applied to detect the face region in each image. We adopt the modified probabilistic neural network (MPNN) to train the sample faces for each individualpsilas photos. After training, the new adding face photos can be recognized and a name tag is recommended to this face. The experiments show a promising result for an accurate name tag annotation. The proposed method is very appropriate to provide a name recommendation function applied in photo album.","","POD:978-0-7695-3744-3","10.1109/IAS.2009.358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5284081","face recommendation;image retrieval","Computer science;Computer security;Decision theory;Face detection;Face recognition;Humans;Information security;Neural networks;Probability density function;Training data","face recognition;information filters;information retrieval;learning (artificial intelligence);neural nets;probability","face detection algorithm;face recognition;image quality improvement;light compensation method;name recommendation photo album;name tag annotation;probability neural network training","","0","","11","","","18-20 Aug. 2009","","IEEE","IEEE Conference Publications"
"Realization of Access Methods for Image in Database","L. Ping","Coll. of Inf. Eng., Tianjin Univ. of Commerce, Tianjin, China","2009 International Conference on New Trends in Information and Service Science","20090925","2009","","","521","524","The cases of accessing images in the database are often encountered. Focusing on the reality of software development, the examples of several access methods of image in database in different software environment were recited, and their characteristics were analyzed in this paper. It provides a reference for developers.","","POD:978-0-7695-3687-3","10.1109/NISS.2009.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5260875","Visual Basic;Visual Basic.Net;database;image","Business;Data engineering;Educational institutions;Image databases;Multimedia databases;Multimedia systems;Power system management;Visual BASIC;Visual databases;Writing","information retrieval;programming languages;software engineering;visual databases","access method realization;software development;software environment;visual database","","0","","3","","","June 30 2009-July 2 2009","","IEEE","IEEE Conference Publications"
"Extraction of key phrases from document using statistical and linguistic analysis","S. Raje; S. Tulangekar; Rajshekhar Waghe; Rohit Pathak; Parikshit Mahalle","Department of Computer Engineering, Smt. Kashibai Navale College of Engineering, University of Pune (India)","2009 4th International Conference on Computer Science & Education","20090901","2009","","","161","164","The algorithm is being developed with a view to reduce the time of going through entire document. The tool will be able to summarize textual documents automatically using statistical as well as linguistic techniques. It will provide the much needed method for creating concise and yet precise documents.","","POD:978-1-4244-3520-3","10.1109/ICCSE.2009.5228501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228501","Extraction;Linguistic Analysis;Statistical Analysis;Text Summarization","Abstracts;Computer science;Computer science education;Costs;Educational institutions;Natural language processing;Statistical analysis;Statistics;Surface-mount technology","information retrieval;linguistics;statistical analysis;text analysis","key phrase extraction;linguistic analysis;statistical analysis;textual document summarization","","2","3","4","","","25-28 July 2009","","IEEE","IEEE Conference Publications"
"A novel music categorization method based on online user behaviors a special analysis of music search charts","Y. Yang; C. Chen","School of Electric and Information Engineering, Beijing Jiaotong University, Beijing, China","2009 ISECS International Colloquium on Computing, Communication, Control, and Management","20090929","2009","4","","158","161","With the rapid development of network, traditional music charts do not work well with the popularity of musical recordings. The search charts of music do pretty well with that. However, there are many new questions with search charts need to be concerned and solved. In this paper, we choose the special keywords on music search charts to study. The keywords of music search charts are special thanks to the online user behaviors. Based on the special keywords, we proposed a novel music categorization method. The criterion of our method is the correlation between the special keyword and the common one of the same song. We separate the music into three types with the method. Our study will be utilitarian in future because it is based on user behaviors.","2154-9613;21549613","POD:978-1-4244-4247-8","10.1109/CCCM.2009.5267749","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5267749","correlation;music industry;search charts;special keywords","CD recording;Communication system control;Engineering management;Europe;Information analysis;Internet","Internet;correlation methods;human factors;information retrieval;music","correlation estimation;music categorization method;music chart ranking;music search chart;musical recording;online user behavior;special keyword search","","0","","3","","","8-9 Aug. 2009","","IEEE","IEEE Conference Publications"
"Generating A Semi-structured Data Frame by First Order Logic","L. Ping","Comput. Sci. Coll., Southwest Univ. for Nat. (SWUN), Chengdu, China","2009 International Forum on Information Technology and Applications","20090904","2009","2","","26","29","There are many approaches toward semantic interpretation of natural language nowadays. Most follow the direction that is to extract key information from contexts in natural language and rearrange them into hierarchical structures. XML is one of such structures. The approach has been proved to be an effective and useful in many applications. XML-based semantic Web is striving to build up a Web that can make sense of what Web users want and how to provide meaningful responses for users. However, in term of the languages that interpret the structures, they are not quite expressive, e.g. typically RDF/RDFS and OWL. The consequence is the possibility of weak inference performance of those structures and a semantic Web needs much more than that. To address the issue, the method here is to generate wff sentences by rules of first order logic (FOL) from natural language text and translate the sentences into a semi-structured data frame which employs a structure similar to XML, in which way not only FOL's strictness of logic and its inference capability are preserved but also expressivity that is the same as that of XML is obtained.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231314","First Order Logic;Semantic interpretation;XML;expressivit;semi-structured data frame","Application software;Computer science;Data structures;Information technology;Logic;Natural languages;OWL;Resource description framework;Semantic Web;XML","XML;data structures;information retrieval;natural languages;semantic Web","OWL;XML;first order logic;information extraction;natural language;semantic Web;semistructured data frame","","0","","5","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"A Rotation Invariant Page Layout Descriptor for Document Classification and Retrieval","A. Gordo; E. Valveny","Comput. Vision Center, Univ. Autonoma de Barcelona, Barcelona, Spain","2009 10th International Conference on Document Analysis and Recognition","20091002","2009","","","481","485","Document classification usually requires of structural features such as the physical layout to obtain good accuracy rates on complex documents. This paper introduces a descriptor of the layout and a distance measure based on the cyclic dynamic time warping which can be computed in O(n<sup>2</sup>). This descriptor is translation invariant and can be easily modified to be scale and rotation invariant. Experiments with this descriptor and its rotation invariant modification are performed on the Girona archives database and compared against another common layout distance, the minimum weight edge cover. The experiments show that these methods outperform the MWEC both in accuracy and speed, particularly on rotated documents.","1520-5363;15205363","POD:978-1-4244-4500-4","10.1109/ICDAR.2009.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277619","Document classification;cyclic dynamic time warping;retrieval;rotation invariant","Computer vision;Databases;Earth;Feature extraction;Image segmentation;Optical character recognition software;Pixel;Text analysis;Time measurement;Tree graphs","classification;computational complexity;document handling;information retrieval","Girona archive database;computational complexity;cyclic dynamic time warping;document classification;document retrieval;minimum weight edge cover;rotation invariant page layout descriptor","","5","","10","","","26-29 July 2009","","IEEE","IEEE Conference Publications"
"A semantic wiki within moodle for Greek medical education","C. Bratsas; G. Kapsas; S. Konstantinidis; G. Koutsouridis; P. D. Bamidis","Lab. of Medical Informatics, Medical School, Aristotle University of Thessaloniki, P.O. Box 323, 54124, Thessaloniki, Greece","2009 22nd IEEE International Symposium on Computer-Based Medical Systems","20090922","2009","","","1","6","Medical education requires a learning environment that enables medical students to acquire knowledge in a ldquohands onrdquo and organized way. This, in turn, requires that content can be accessed, evaluated, organized and reused with ease by the students. Social Software (i.e. Weblogs, Wikis, ePortfolios, Instant Messaging) and Semantic Web technology could play an important role in such learning environments. Where Social Software gives users freedom to choose their own processes and supports the collaboration of people anytime, anywhere, Semantic Web technology gives the possibility to structure information for easy retrieval, reuse, and exchange between different systems and tools. In this article a very specific technology that combines Social Software and the Semantic Web, that is Semantic Wikis are presented, together with their possible role in medical education Moreover the first Medical Semantic Wiki in Greek Language and its use in medical education are illustrated.","1063-7125;10637125","POD:978-1-4244-4879-1","10.1109/CBMS.2009.5255417","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255417","","Collaboration;Collaborative software;Collaborative work;Educational technology;Internet;Navigation;Ontologies;Resource description framework;Search engines;Semantic Web","biomedical education;computer aided instruction;educational courses;information retrieval;natural languages;semantic Web","Greek Language;Greek medical education;Medical Semantic Wiki;Semantic Web technology;Weblogs;ePortfolios;information retrieval;instant messaging;learning environment;medical students;social software","","6","","12","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"Sentence Features Fusion for Text Summarization Using Fuzzy Logic","L. Suanmali; M. S. Binwahlan; N. Salim","Fac. of Sci. & Technol., Suan Dusit Rajabhat Univ., Bangkok, Thailand","2009 Ninth International Conference on Hybrid Intelligent Systems","20090922","2009","1","","142","146","The scoring mechanism of the text features is the unique way for determining the key ideas in the text to be presented as text summary. The efficiency of the technique used for scoring the text sentences could produce good summary. The feature scores are imprecise and uncertain, this marks the differentiation between the important features and unimportant is difficult task. In this paper, we introduce fuzzy logic to deal with this problem. Our approach used important features based on fuzzy logic to extract the sentences. In our experiment, we used 30 test documents in DUC2002 data set. Each document is prepared by preprocessing process: sentence segmentation, tokenization, removing stop word, and word stemming. Then, we use 9 important features and calculate their score for each sentence. We propose a method using fuzzy logic for sentence extraction and compare our results with the baseline summarizer and Microsoft Word 2007 summarizers. The results show that the highest average precision, recall, and F-measure for the summaries were obtained from fuzzy method.","","POD:978-0-7695-3745-0","10.1109/HIS.2009.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254315","fuzzy logic;sentence features;text summarization","Data mining;Frequency;Fuzzy logic;Fuzzy reasoning;Fuzzy sets;Genetic programming;Humans;Hybrid intelligent systems;Multivalued logic;Uncertainty","fuzzy logic;information retrieval;text analysis","Microsoft Word 2007 summarizer;fuzzy logic;scoring mechanism;sentence extraction;sentence feature fusion;sentence segmentation;sentence tokenization;text summarization;word stemming","","5","","17","","","12-14 Aug. 2009","","IEEE","IEEE Conference Publications"
"Improving the Table Boundary Detection in PDFs by Fixing the Sequence Error of the Sparse Lines","Y. Liu; K. Bai; P. Mitra; C. L. Giles","Coll. of Inf. Sci. & Technol., Penn State Univ., University Park, PA, USA","2009 10th International Conference on Document Analysis and Recognition","20091002","2009","","","1006","1010","As the rapid growth of PDF documents, recognizing the document structure and components are useful for document storage, classification and retrieval. Table, a ubiquitous document component, becomes an important information source. Accurately detecting the table boundary plays a crucial role for many applications, e.g., the increasing demand on the table data search. Rather than converting PDFs to image or HTML and then processing with other techniques (e.g., OCR), extracting and analyzing texts from PDFs directly is easy and accurate. However, text extraction tools face a common problem: text sequence error. In this paper, we propose two algorithms to recover the sequence of extracted sparse lines, which improve the table content collection. The experimental results show the comparison of the performance of both algorithms, and demonstrate the effectiveness of text sequence recovering for the table boundary detection.","1520-5363;15205363","POD:978-1-4244-4500-4","10.1109/ICDAR.2009.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277535","","Computer errors;Data mining;Educational institutions;Filtering;HTML;Image analysis;Image converters;Information analysis;Optical character recognition software;Text analysis","data structures;document handling;information retrieval;ubiquitous computing","PDF documents;document structure;sequence error;table boundary detection;text extraction tools;ubiquitous document component","","8","","7","","","26-29 July 2009","","IEEE","IEEE Conference Publications"
"Algorithm Research for the Noise of Information Extraction Based Vision and DOM Tree","T. Sun; Z. Li; Y. Liu; Z. Liu","Sch. of Comput. Sci., Northeast Normal Univ., Changchun, China","2009 International Symposium on Intelligent Ubiquitous Computing and Education","20090825","2009","","","81","84","Information extraction from Web sites is nowadays a relevant problem, usually performed by software modules called wrappers. Introduced the relevant information extraction technology. A combination of HTML pages to extract information of the theme and extract the contents. First of all, to remove noise combination of visual block, the vision-based DOM tree denoising methods to improve the efficiency of extraction.","","POD:978-0-7695-3619-4","10.1109/IUCE.2009.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5223346","DOM tree;information extraction;match technology;wrapper","Computer science;Computer science education;Data mining;Databases;HTML;Software algorithms;Software performance;Sun;Ubiquitous computing;Web pages","Web sites;hypermedia markup languages;information retrieval;trees (mathematics)","HTML pages;Web sites;information extraction;vision-based DOM tree denoising methods;wrappers software modules","","0","","9","","","15-16 May 2009","","IEEE","IEEE Conference Publications"
"Adding and Browsing Comments in E-newspaper: An Initial Experiment","D. Rigas; M. Alharbe","Sch. of Comput., Inf. & Media, Univ. of Bradford Bradford, Bradford, UK","2009 International Conference on CyberWorlds","20091006","2009","","","190","194","This paper describes an initial survey and an experiment that aimed to investigate usability issues when users add comments on articles in electronic newspapers. The work also measures the effectiveness of using multimodal communication metaphors, such as graphics and speech. In interfaces for e-newspaper. The survey was performed with 36 people and the experiment with 50 users. Usability was measured in a multimodal interface (experimental condition) compared to a traditional interface (control condition). Results indicate that using a new classification system to annotate articles in addition to sound recording is better approach than using the traditional approach to dasiaadd comments'.","","POD:978-1-4244-4864-7","10.1109/CW.2009.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5279620","Multimodal Adding Commitments (MMAC);Traditional Adding Commitments (TAC);Usability E-Newspaper","Communication system control;Consumer electronics;Graphics;Informatics;Internet;Speech;Telegraphy;Usability;User interfaces;Web sites","Internet;electronic publishing;information retrieval","classification system;e-newspaper;electronic newspaper;multimodal communication metaphor","","0","","14","","","7-11 Sept. 2009","","IEEE","IEEE Conference Publications"
"Clustering web search results using semantic information","Han Wen; Guo-Shun Huang; Zhao Li","School of Science, FOSHAN University, 528000, China","2009 International Conference on Machine Learning and Cybernetics","20090825","2009","3","","1504","1509","Clustering Web search results will help users finding relevant information quickly. Suffix tree clustering (STC) algorithm is well fit for clustering Web documents. This paper puts forward an improved Web search results clustering algorithm based on STC. It uses latent semantic indexing method to assist finding common descriptive and meaningful topic phrases for the final document clusters. Using semantic information for clustering web snippets is able to make search engine results easy to browse and help users quickly find Web information interested. Evaluation of experiment results demonstrates that clustering Web search results based on the improved suffix tree algorithm gets better performance in cluster label quality and snippets assignment precision.","2160-133X;2160133X","POD:978-1-4244-3702-3","10.1109/ICMLC.2009.5212332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212332","Latent semantic indexing;Singular value decomposition;Suffix tree clustering","Clustering algorithms;Cybernetics;Frequency;Indexing;Internet;Machine learning;Machine learning algorithms;Search engines;Singular value decomposition;Web search","document handling;indexing;information retrieval;online front-ends;pattern clustering;search engines;semantic Web;trees (mathematics)","Web browser;Web search results clustering;Web snippets;cluster label quality;clustering Web documents;document clusters;latent semantic indexing method;search engine;semantic information;snippets assignment precision;suffix tree clustering algorithm","","1","","15","","","12-15 July 2009","","IEEE","IEEE Conference Publications"
"A Content Management System for User-Driven Museums in Second life","K. Sookhanaphibarn; R. Thawonmas","Dept. of Human & Comput. Intell., Ritsumeikan Univ., Kusatsu, Japan","2009 International Conference on CyberWorlds","20091006","2009","","","185","189","Over two decades, a great expectation on digital museums has been addressed but most of them have been implemented based on web technologies. Emerging Second Life, which supports rich communication, virtual collaboration, and 3-D content creation, has brought a new platform to digital museums. As a result, a way to systematically manage and arrange a tremendous amount of information in SL museums is required. In addition, dynamic content and context to encourage audiences to return to the museum more frequently must be designed based on audience drives and preferences. In this paper, a Content Management System (CMS) of digital museums in Second Life is presented to cope with these issues. Six proposed modules are the integral parts of CMS to handle data mining approaches inspired by a visiting pattern retrieval system of audience activities and web-based recommender systems.","","POD:978-1-4244-4864-7","10.1109/CW.2009.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5279607","Content Management System (CMS);Digital museum;Second Life;User preference;Virtual environment;Visiting style","Avatars;Collaboration;Collision mitigation;Competitive intelligence;Content management;Context;Databases;Humans;Laboratories;Second Life","Web sites;content management;data mining;humanities;information retrieval;virtual reality","3D content creation;Web-based recommender systems;content management system;data mining;digital museums;pattern retrieval system;second life;user-driven museums;virtual collaboration;web technologies","","3","","26","","","7-11 Sept. 2009","","IEEE","IEEE Conference Publications"
"Adaptive business intelligence for an open negotiation environment","S. Aciar; P. Avesani; J. L. De la Rosa; N. Hormazabal; A. Serra","University of Girona, Campus Montilivi, 17071 Girona, Spain","2009 3rd IEEE International Conference on Digital Ecosystems and Technologies","20091002","2009","","","517","522","Engineering of negotiation model allows to develop effective heuristic for business intelligence. Digital ecosystems demand open negotiation models. To define in advance effective heuristics is not compliant with the requirement of openness. The new challenge is to develop business intelligence in advance exploiting an adaptive approach. The idea is to learn business strategy once new negotiation model rise in the e-market arena. In this paper we present how recommendation technology may be deployed in an open negotiation environment where the interaction protocol models are not known in advance. The solution we propose is delivered as part of the ONE Platform, open source software that implements a fully distributed open environment for business negotiation.","2150-4938;21504938","POD:978-1-4244-2345-3","10.1109/DEST.2009.5276732","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5276732","Intelligent Digital Ecosystems and Technologies","Business communication;Design engineering;Ecosystems;Electronic mail;Encoding;Intelligent agent;Open source software;Proposals;Protocols;Software agents","competitive intelligence;electronic commerce;information retrieval;learning (artificial intelligence)","adaptive business intelligence;digital ecosystem;e-market;interaction protocol model;learning technology;open negotiation environment;open source software;recommendation technology","","0","","16","","","1-3 June 2009","","IEEE","IEEE Conference Publications"
"Materialized community ground models for large-scale earthquake simulation","S. W. Schlosser; M. P. Ryan; R. Taborda; J. Lopez; D. R. O'Hallaron; J. Bielak","Intel Research Pittsburgh, USA","2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis","20090825","2008","","","1","12","Large-scale earthquake simulation requires source datasets which describe the highly heterogeneous physical characteristics of the earth in the region under simulation. Physical characteristic datasets are the first stage in a simulation pipeline which includes mesh generation, partitioning, solving, and visualization. In practice, the data is produced in an ad-hoc fashion for each set of experiments, which has several significant shortcomings including lower performance, decreased repeatability and comparability, and a longer <i>time</i> <i>to</i> <i>science</i>, an increasingly important metric. As a solution to these problems, we propose a new approach for providing scientific data to ground motion simulations, in which ground model datasets are fully materialized into octress stored on disk, which can be more efficiently queried (by up to two orders of magnitude) than the underlying community velocity model programs. While octrees have long been used to store spatial datasets, they have not yet been used at the scale we propose. We further propose that these datasets can be provided as a service, either over the Internet or, more likely, in a data center or supercomputing center in which the simulations take place. Since constructing these octrees is itself a challenge, we present three data-parallel techniques for efficiently building them, which can significantly decrease the build time from days or weeks to hours using commodity clusters. This approach typifies a broader shift toward <i>science</i> <i>as</i> <i>a</i> <i>service</i> techniques in which scientific computation and storage services become more tightly intertwined.","2167-4329;21674329","CD-ROM:978-1-4244-2835-9; POD:978-1-4244-2834-2","10.1109/SC.2008.5215657","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5215657","","Data visualization;Earthquakes;Jacobian matrices;Large-scale systems;Mesh generation;Permission;Pipelines;Sampling methods;Soil;Web and internet services","earthquakes;geophysics computing;information retrieval;information storage;octrees;parallel processing;visual databases","Internet;community ground models;community velocity model programs;data parallel techniques;data partitioning;data visualization;datacenter;ground model datasets;ground motion simulations;large scale earthquake simulation;mesh generation;octrees construction;physical characteristic datasets;problem solving;querying;scientific computation;source datasets;spatial dataset storage;storage services;supercomputing center","","3","","31","","","15-21 Nov. 2008","","IEEE","IEEE Conference Publications"
"Development of a Meeting Browser towards Supporting Public Involvement","S. Shiramatsu; T. Ozono; T. Shintani; K. Komatani; T. Ogata; T. Takahashi; H. G. Okuno","Grad. Sch. of Eng., Nagoya Inst. of Technol., Nagoya, Japan","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","717","722","This paper presents novel methods for support for browsing a long meeting record towards supporting public involvement. Facilitating public involvement in the consensus building process for community development needs a lot of effort and time for sharing context and concerns among citizens and stakeholders. A record of public meeting often becomes too long to overview and to understand for people who did not participate in it. The two issues we addressed relate to how to best provide support for these people. First, support for overviewing the changes in a long meeting to track and to find intended arguments. Second, support for understanding the background of arguments. The approaches to the issues are first, to visualize the transition of topics in the meeting, and second provide information related to a transient topic specified by a user. The meeting browser we developed is designed on the basis of Visual Information-Seeking Mantra, ""Overview first, zoom and filter, then details on demand."" To visualize a dynamic topic flow, a graph for visualizing the topic transition, SalienceGraph is used to track the dynamic transition of the salience of a word. To visualize related information, the search engine based on SalienceGraph retrieves passages related to a transient topic from past meeting records or documents. These approaches support citizens and stakeholders to find, to track, and to understand a target argument from a long meeting record.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283461","consensus building;information visualization;meeting browser;public involvement;salience","Decision making;Environmental management;Filters;Informatics;Paper technology;Risk management;Search engines;Spirals;Target tracking;Visualization","data visualisation;information retrieval;online front-ends;public administration;search engines","SalienceGraph;consensus building process;dynamic topic flow;graph visualizing;information visualization;long meeting record;meeting browser;public involvement;public meeting;search engine;topic transition visualization","","0","","29","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"A model of man-machine dialogue realized around an application","R. Djeradi; A. Djeradi","Speech communication and signal processing laboratory, Faculty of Electronics and computing, USTHB, Algiers, ALGERIA","2009 International Conference on Multimedia Computing and Systems","20090922","2009","","","91","95","The paper presents a modelling of the human machine dialogue in dual language (French and Arabic). According to the principle of our model the production of a speech result from an exchange between the human and the machine, that depends on the interlocutor's mental condition. It presents itself under the set of fundamental units of the memory (FUM). The hierarchical organization of these units permits by the exchange, to satisfy the speaker by allowing him to attain his goal.","","POD:978-1-4244-3756-6","10.1109/MMCS.2009.5256723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5256723","Arabian language;artificial intelligence;human machine dialogue;modelling of the dialogue;strategy of dialogue","Artificial intelligence;Communication channels;Humans;Laboratories;Man machine systems;Natural languages;Oral communication;Performance analysis;Signal processing;Speech analysis","human factors;information retrieval;interactive systems;man-machine systems;multi-agent systems;natural language processing;speech processing;speech-based user interfaces","FUM;artificial intelligence;dual language;fundamental units-of-memory;human machine dialogue;interlocutor mental condition;man-machine dialogue;speech production","","0","","15","","","2-4 April 2009","","IEEE","IEEE Conference Publications"
"A Case-Based Reasoning approach to support web service composition","Yong-Zhuang Liu; Shuang Qiu; Hai-Jun Tao; Tian-Yi Zang; Ya-Dong Wang","School of Computer Science & Technology, Harbin Institute of Technology, 150001, China","2009 International Conference on Machine Learning and Cybernetics","20090825","2009","3","","1471","1476","With the Internet development, lots of Web services have been exposed increasingly on the Internet. These web services always are owned by different companies and organizations, and are geographically distributed. How to compose these web services together to fulfill a business process is usually a challenge issue. Case-Based Reasoning (CBR) is a problem solving paradigm. It uses successful experiences in past to solve similar problems at present or/and in the future. In this paper, a set of approaches to support web service composition based on CBR is presented for case retrieval. The method of semantic-driven similarity assessment for web services is also described. The indexing technology is adopted to organize the case base to improve the retrieval efficiency. In addition, case adaptation strategy for web services is employed to make a CBR system more robust than usual. At last, the experiments and analysis processes are also addressed.","2160-133X;2160133X","POD:978-1-4244-3702-3","10.1109/ICMLC.2009.5212336","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212336","Case-Based Reasoning;Web services;Web services composition","Computer science;Cybernetics;Grounding;Indexing;Machine learning;Ontologies;Problem-solving;Robustness;Web and internet services;Web services","Web services;business data processing;information retrieval","Internet development;Web service composition;business process;case retrieval;case-based reasoning approach;semantic-driven similarity assessment","","0","","9","","","12-15 July 2009","","IEEE","IEEE Conference Publications"
"Fishery knowledge discovery based on SVM and fuzzy rule extraction","Yuan Hong-chun; Li Ying; Chen Ying","College of Information Technology, Shanghai Ocean University, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","167","171","In the area of ocean fisheries research, one hotspot is the use of marine environment factors for fisheries forecast. This paper fits in the category using fishery knowledge discovery based on support vector machine (SVM) and fuzzy rule extraction. It takes the Indian ocean big-eye tuna fishery as its testing ground. Firstly, the support vectors are obtained by training the SVM with some sample data. Then the rules are extracted by the fuzzy classifier method. Meanwhile, a fishery forecasting model is established based on support vector regression (SVR). Experimental results show that the fishery knowledge obtained is of a forceful interpretive capacity, which is ideal for explaining the formation mechanism of fishing grounds. The established fishery forecasting model provides a high level of information accuracy which can be further enhanced by additional fishing effort.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234379","Indian Ocean bigeye tuna;fuzzy classification;rule extraction;support vector machine;support vector regression","Aquaculture;Data mining;Fuzzy logic;Fuzzy set theory;Linear regression;Oceans;Predictive models;Support vector machine classification;Support vector machines;Testing","aquaculture;data mining;fuzzy set theory;information retrieval;support vector machines","Indian ocean big-eye tuna fishery;fishery forecasting model;fishery knowledge discovery;fuzzy classifier method;fuzzy rule extraction;marine environment factor;ocean fisheries;support vector machine;support vector regression","","0","","9","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"A simplified application of regular expressions: With the extraction of Chinese cultural terms as an example","Y. Zhenjun; J. Xiangyu","Dalian University of Technology, Dongbei University of Finance and Economics, Dalian, China","2009 ISECS International Colloquium on Computing, Communication, Control, and Management","20090929","2009","1","","439","442","This article aims to solve the problem of extracting the cultural terms and their correspondent English translations from the heterogeneous literature of the translation of the ancient Chinese classics. As the tool of text processing, regular expressions can help to realize the matching in the patterned text. This research focuses on design the target-oriented regular expressions to fit the pattern of the to-be-searched text so as to improve the operating efficiency. At the same time, the generator of regular expressions is designed to decrease the difficulty of its application.","2154-9613;21549613","POD:978-1-4244-4247-8","10.1109/CCCM.2009.5268087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5268087","Chinese cultural terms;pattern matching;regular expressions","Automatic programming;Communication system control;Cultural differences;Data mining;Finance;Financial management;Global communication;Pattern matching;Technology management;Text processing","information retrieval;language translation;natural language processing;string matching;text analysis","Chinese cultural term extraction;English translation;ancient Chinese classics translation;heterogeneous literature;pattern matching;target-oriented regular expression;text processing","","2","","10","","","8-9 Aug. 2009","","IEEE","IEEE Conference Publications"
"JabberWocky: Crowd-Sourcing Metadata for Files","V. Bhagwan; C. Maltzahn","IBM Almaden Res. Center, San Jose, CA, USA","2009 IEEE International Conference on Services Computing","20091013","2009","","","513","516","Finding relevant files in a personal file system continues to be a challenge. It is still easier to find stuff on the Web with its exponential growth than in one's personal file system. Yet, the exponential growth of personal data renders the current services of personal file systems increasingly inadequate. A reason for this failure is the ldquocold-startrdquo problem: algorithms that dramatically improve a user's ability to find documents on the Web become ineffective in personal file systems because there is not enough information about these documents. We propose JabberWocky, a service that allows users to manage the content of their personal file system by leveraging semantic relationships available on the Web. More specifically, JabberWocky is using keyword/resource associations of social bookmarking web sites as a basis for recommending keywords for files. We chose social bookmarking web sites because of their popularity and because the assignment of keywords (a process also referred to as ldquotaggingrdquo) is an established and popular way to manage photos, music, movies, and audio resources on the Web - very much the kind of resources that need to be managed in personal file systems. The goal of JabberWocky is to overcome the ldquocold-startrdquo problem of personal file systems and to provide recommendations in a scalable way while maintaining the user's privacy. In this work-in-progress report we describe the motivation and challenges of designing a system like JabberWocky, present the initial design of an on-going user study, and briefly discuss what we have learned so far.","","POD:978-1-4244-5183-8","10.1109/SCC.2009.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5283914","","Content based retrieval;Content management;File systems;Humans;Motion pictures;Privacy;Resource management;Tagging;Videos;YouTube","information retrieval;meta data;personal information systems;social networking (online)","cold start problem;crowd sourcing metadata;exponential growth;jabberwocky;personal file system;semantic relationships;social bookmarking Web sites","","1","","19","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Incorporating Participant Reputation in Community-Driven Question Answering Systems","L. Hong; Z. Yang; B. D. Davison","Dept. of Comput. Sci. & Eng., Lehigh Univ., Bethlehem, PA, USA","2009 International Conference on Computational Science and Engineering","20091009","2009","4","","475","480","Community-driven Question Answering services are gaining increasing attention with tens of millions of users and hundreds of millions of posts in recent years. Due to its size, there is a need for users to be able to search these large question answer archives and retrieve high quality content. Research work shows that user reputation modeling makes a contribution when incorporated with relevance models. However, the effectiveness of different link analysis approaches and how to embed topical information - as a user may have different expertise in various areas - are still open questions. In this work, we address these two research questions by first reviewing different link analysis schemes - especially discussing the use of PageRank-based methods since they are less commonly utilized in user reputation modeling. We also introduce Topical PageRank analysis for modeling user reputation on different topics. Comparative experimental results on data from Yahoo! Answers show that PageRank-based approaches are more effective than HITS-like schemes and other heuristics, and that topical link analysis can improve performance.","","POD:978-1-4244-5334-4","10.1109/CSE.2009.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5284222","Link Analysis;Question Answering;User Reputation","Computer science;Content based retrieval;Context modeling;Information analysis;Natural languages;Performance analysis;Portals;Search engines;Web pages","information networks;information retrieval","HITS-like scheme;PageRank-based method;Yahoo! Answers;community-driven question answering system;participant reputation;relevance model;topical PageRank analysis;topical link analysis;user reputation modeling","","3","","18","","","29-31 Aug. 2009","","IEEE","IEEE Conference Publications"
"Providing public standardized data access function: Lessons learned from accessing USGS Landsat archive","Xuanang Cheng; Y. Bai; L. Di; D. Nebert","Center for Spatial Information Science and Systems (CSISS), George Mason University, 6301 Ivy Lane, Suite 620 Greenbelt, Maryland, United States","2009 17th International Conference on Geoinformatics","20091023","2009","","","1","4","The geospatial community is experiencing a shift from having data locally to sharing them over the Web. However, not all the data accessing systems are built in compliance with open geospatial standards and thus are weak in terms of interoperability. The USGS Landsat data are now available through free electronic access though not yet through standard Web service interfaces. This paper intends to discuss the experience and lessons learned from integrating a public data access function to the USGS Landsat data archive into a geospatial workflow environment. Currently available systems and their problems, proposed solutions and application scenarios are discussed.","2161-024X;2161024X","POD:978-1-4244-4562-2","10.1109/GEOINFORMATICS.2009.5293043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5293043","Landsat;interoperability;public access","Authentication;Geology;Geoscience;ISO standards;Information science;Portals;Postal services;Remote sensing;Satellites;Web services","Web services;geology;information retrieval;open systems","USGS Landsat archive;United States Geological Survey;Web;Web service interfaces;free electronic access;geospatial community;geospatial workflow environment;interoperability;public standardized data access function","","0","","10","","","12-14 Aug. 2009","","IEEE","IEEE Conference Publications"
"WebGIS Resolution for Management Information System of Disaster Prevention","C. Yanhua; S. Youpo; L. Weiwei","Coll. of Civil Eng. & Archit., Hebei Polytech. Univ., Tangshan, China","2009 International Forum on Information Technology and Applications","20090904","2009","1","","676","679","Data share and publication of disaster prevention information is in urgent need, and WebGIS resolution of management information system (MIS) is the main problems for Internet publication. Through analyzing the technique function of WebGIS and the character of information publication, management information system of disaster prevention is investigated. The system application is developed based on MapXtreme in Windows 2000 Server operating system, the real-time browse in client and real-time publication of disaster prevention information in server are achieved. In order to improve the speed of data transmitting through Internet, ASP technique is combined with ActiveX controls. System application is developed with network language VBScript and JavaScript under the ASP environment. As an example application, MIS of disaster prevention for Internet publication in Tangshan City is worked out; Finally, some advice is proposed for the development of Internet publication system based on WebGIS.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.347","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231738","Internet;MIS;MapXtreme;WebGIS;data share;disaster prevention","Application specific processors;Cities and towns;Information analysis;Internet;Java;Management information systems;Network servers;Operating systems;Real time systems;Web server","Internet;authoring languages;disasters;geographic information systems;information retrieval;management information systems;operating systems (computers);real-time systems","ASP technique;ActiveX control;Internet publication system;JavaScript;MIS;MapXtreme;VBScript;WebGIS resolution;Windows 2000 server operating system;disaster prevention information publication;management information system;network language;real-time browse;real-time publication","","0","","9","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Tree classifier in spectral space","Ping He; Xiao-Hua Xu; Ling Chen","Department of Computer Science and Engineering, Nanjing University of Aeronautics and Astronautics, 210016, China","2009 International Conference on Machine Learning and Cybernetics","20090825","2009","1","","476","481","This paper proposes a novel nonlinear decision tree algorithm SSDT, spectral space decision tree. SSDT adopts spectral space transformation to extract the cluster information of data, employs decision tree to discover the decision boundary, and classifies test data with consistent mapping principle. Experimental results show that SSDT can produce higher classification accuracy and better generalization ability than the traditional decision tree algorithms.","2160-133X;2160133X","POD:978-1-4244-3702-3","10.1109/ICMLC.2009.5212576","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212576","Nonlinear tree classifier;Spectral space","Classification tree analysis;Clustering algorithms;Computer science;Cybernetics;Data mining;Decision trees;Machine learning;Partitioning algorithms;Testing;Training data","decision trees;information retrieval;pattern classification","cluster information extraction;consistent mapping principle;data classification;nonlinear decision tree algorithm;spectral space decision tree;spectral space transformation;tree classifier","","0","","19","","","12-15 July 2009","","IEEE","IEEE Conference Publications"
"Semi-automatic Acquisition of Semantic Descriptions of Web Sites","S. Agarwal","Karlsruhe Service Res. Inst. (KSRI), Univ. of Karlsruhe (TH), Karlsruhe, Germany","2009 Third International Conference on Advances in Semantic Processing","20091023","2009","","","103","108","In order to obtain the desired information or functionality in the Web, a user often needs to perform multiple interactions with the Web site, e.g. submitting Web forms filled up with appropriate information, and the further execution of such a Web process depends on the information provided by the user in the previous steps of the process. The formal models underlying existing systems for supporting users in coping with the Web do not capture the dynamics and data flow of Web processes. As a result, searching for information in the so called ""Deep Web"" or desired business processes offered via the Web still requires significant manual effort. In this paper, we present a semantic process description language and present a mapping of the dynamics and data flow of Web sites to our semantic process description language. In order to allow development of more sophisticated methods and tools that consider the dynamics and data flow inside or among Web sites, significant number of descriptions of Web sites are needed. We approach this bootstrapping problem by presenting a technique for semi-automatic acquisition of semantic descriptions of Web Sites.","","POD:978-1-4244-5044-2","10.1109/SEMAPRO.2009.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5291526","deep web;semantics;web processes","Automatic control;Books;Cities and towns;Credit cards;HTML;Informatics;Search engines;Web pages;Web services","Web sites;information retrieval","Web process data flow;Web process dynamics;Web sites;bootstrapping problem;business processes;formal models;semantic descriptions;semi-automatic acquisition","","4","","11","","","11-16 Oct. 2009","","IEEE","IEEE Conference Publications"
"Data Distribution Strategy Research on One Self-Managing Storage System","Y. Wang; C. Xie","Coll. of Comput. Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China","2009 Symposium on Photonics and Optoelectronics","20090901","2009","","","1","5","In this paper we describe Evolutionary Storage System, a Self-Managing Storage System that could adjust its storage strategy automatically according to the current running environment. In the evolutionary processes, ESS could automatically choose one system organizing strategy which fits for the current running environment best, to keep the dynamic balance of the whole storage system. One of the three evolutionary ways is data distribution evolutionary, the data distribution strategy considers both the application data accessing frequency and physical disk performance, and adjust the data distribution automatically to optimize the storage system read/write performance.We have constructed a simulation model to demonstrate how the system performance could be improved by applying the data distribution strategy.","2156-8464;21568464","POD:978-1-4244-4412-0","10.1109/SOPO.2009.5230162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230162","","Biological system modeling;Computer science;Distribution strategy;Educational institutions;Electronic switching systems;Evolution (biology);Frequency;Libraries;Organizing;Storage automation","evolutionary computation;information retrieval;optical disc storage;storage management","data accessing frequency;data distribution strategy research;evolutionary storage system;physical disk performance;self-managing storage system;storage strategy","","0","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Long-term digital archiving based on selection of repositories over P2P networks","T. Vignatti; L. C. E. Bona; M. S. Sunye; A. L. Vignatti","Federal University of Paran&#225;, Department of Informatics, Brazil","2009 IEEE Ninth International Conference on Peer-to-Peer Computing","20091009","2009","","","194","203","The importance of digital information is constantly increasing in the last years. Such information often needs to be preserved for a long-term and this is the responsibility of digital archiving systems. This paper proposes a reliable replication model of immutable digital content to be used in long-term archiving systems. The archiving system is modeled as a set of storage repositories where each repository has an independent fail probability assigned to it. Items are inserted with a reliability that is satisfied by replicating them in subsets of repositories. Through simulation, we evaluated three different proposed strategies to create replicas. It is also proposed a completely distributed archiving system using this model over a structured peer-to-peer (P2P) network. The communication between the nodes (repositories) of the network is organized in a distributed hash table and multiple hash functions are used to select repositories that will keep the replicas of each stored item. The system is evaluated through experiments in a real environment. The proposed model and the algorithms, combined with the structured P2P scalability made possible the construction of a reliable and totally distributed digital archiving system.","2161-3559;21613559","Electronic:978-1-4244-5067-1; POD:978-1-4244-5066-4","10.1109/P2P.2009.5284519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5284519","","Computer networks;Electronic mail;Environmental economics;Hardware;Informatics;Peer to peer computing;Scalability;Software libraries;Telecommunication network reliability;Web and internet services","digital libraries;file organisation;information retrieval systems;peer-to-peer computing;probability","distributed archiving system;distributed hash table;immutable digital content;independent fail probability;long-term digital archiving system;multiple hash function;reliable replication model;storage repository selection;structured peer-to-peer network scalability","","0","","20","","","9-11 Sept. 2009","","IEEE","IEEE Conference Publications"
"A novel Voting Algorithm of multi-class SVM for web page classification","P. Thamrongrat; L. Preechaveerakul; W. Wettayaprasit","Artificial Intelligence Research Laboratory, Computer Science Department, Prince of Songkla University, Thailand","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","327","331","The increasing numbers of Web pages on the cyber world result to the less effectiveness of document retrieval that matches the need of users. The classification of Web pages is one of the solutions to solve this problem. This paper proposes VAMSVM_WPC model which is a novel voting algorithm for classifying the Web pages, which uses a multi-class SVM method. First, feature is generated from text and title, and then reduces the number of features by two feature selection techniques. Use these two types of features to give input to multi-class SVM. Finally, on the output of SVM, a voting algorithm is used to determine the category of the Web pages. Results on CMU benchmark dataset show that using text and title feature with 1vsAll_Voting Algorithm gives the highest F-measure value.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234603","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234603","feature selection;support vector machine;web page classification voting","Artificial intelligence;Computer science;Equations;Laboratories;Performance gain;Support vector machine classification;Support vector machines;Testing;Voting;Web pages","Internet;information retrieval;pattern classification;support vector machines;text analysis","Web page classification;document retrieval;feature selection;multiclass support vector machine;text analysis","","0","","14","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Recognition of impurity in ampoules based on wavelet packet decomposition energy distribution and SVM","S. Jiedi; W. Jiangtao","Department of Information Science and Engineering, Yanshan University, QinHuangDao, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","162","166","It presents a feature extraction and recognition method in this paper based on wavelet packet decomposition energy and support vector machine to solve the problem of recognizing the visible impurity in ampoules. The ampoules pictures are taken by the automatic ampoule inspection machine. The zone containing impurity is segmented and called ROI (region of interesting) using the sequence difference and the key point detection. The conventional image processing method can't meet the requirements of fast processing in the industrial field. It proposes a method based on the information entropy of ROI to extract the useful information and generate a one-dimensional signal. The signal is decomposed by wavelet packet, and then the principal feature vectors are extracted using PCA from the wavelet packet energy components. As the input vectors of support vector machine, the impurity features can be classified rapidly by SMO (sequential minimal optimization). The different types of kernel functions and the corresponding parameters are selected for training and testing in the experiments. The results show that the time-consuming of SVM (support vector machine) is decreased by 60% and the identification accuracy is improved by 35%, compared with the BP network<i>.</i>","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234594","impurity type recognition;information entropy;principal component analysis;support vector machine;wavelet packet decomposition energy distribution","Data mining;Feature extraction;Image processing;Image segmentation;Impurities;Information entropy;Inspection;Support vector machine classification;Support vector machines;Wavelet packets","backpropagation;entropy;feature extraction;image segmentation;image sequences;information retrieval;object detection;object recognition;support vector machines;wavelet transforms","BP network;automatic ampoule inspection machine;feature extraction;impurity recognition;information entropy;information extraction;key point detection;region of interesting;sequence difference;sequential minimal optimization;support vector machine;wavelet packet decomposition energy distribution","","0","","11","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"An efficient framework for agent-based quality driven Web Services discovery","T. Rajendran; P. Balasubramanie","Department of Computer Science &Engineering SNS College of Technology, Coimbatore, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","2","Web service technology is playing a major role in today's distributed system computing. The wide adoption of Web services raises the challenging problem of service discovery. With an increasing number of Web services providing similar functionalities, quality of service (QoS) is becoming an important criterion for selecting of the best available service. We aim to refine the discovery process through designing a new framework that enhances retrieval algorithms by combining syntactic and semantic matching of services. We propose a model of QoS-based Web services discovery that combines an augmented UDDI registry to publish the QoS information.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228044","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228044","Quality of Services (QoS);SOAP;Service Registry;UDDI;WSDL;Web Service Agent;Web Services discovery;tModel","Algorithm design and analysis;Computer science;Data structures;Distributed computing;Educational institutions;Electronic mail;Process design;Quality of service;Service oriented architecture;Web services","Web services;information retrieval;quality of service;software agents","QoS;agent-based quality driven Web services discovery;distributed system computing;quality of service;retrieval algorithms enhancement;semantic matching;syntactic matching","","4","","5","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"Reusable Components Retrieval Based on Faceted Classification with Sem-library in Domain Component Library","C. Fu; H. Chang","Dept. of Comput. Sci., Sun Yat-sen Univ., Guangzhou, China","2009 International Conference on Interoperability for Enterprise Software and Applications China","20090925","2009","","","189","194","Faceted classification with strong extensibility has been widely used in the classification and retrieval of component library. However, owing to its hierarchy structure, it lacks of understanding of the domain knowledge in domain component library. Aimed at solving this problem, this paper proposes a sem-library to provide effective keyword proximity queries to express abundant domain knowledge in domain component library and release the users from esoteric vocabulary. Sem-library supports basic semantic relationships and incremental query construction. Moreover, it is feasible and extensible for more complicated semantic relationships.","","POD:978-0-7695-3652-1","10.1109/I-ESA.2009.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5260834","domain component library;facet;retrieval;semantic","Application software;Buildings;Computer science;Logic;Ontologies;Software libraries;Software reusability;Sun;Thesauri;Vocabulary","information retrieval;object-oriented programming;software libraries;software reusability","domain component library;esoteric vocabulary;faceted classification;incremental query construction;reusable components retrieval","","0","","12","","","21-22 April 2009","","IEEE","IEEE Conference Publications"
"Tag Suggestion Method Based on Association Pattern and Bigram Approach","H. Kim; K. Lee; H. Shin; H. J. Kim","Seoul Nat. Univ., Seoul, South Korea","2009 10th ACIS International Conference on Software Engineering, Artificial Intelligences, Networking and Parallel/Distributed Computing","20091013","2009","","","63","68","Recently, the number of articles, blog posts, photos and videos on the Web is dramatically increasing because of the increase of Internet usage. In this situation, the Web search is the most important thing in the Web. When we search, we can use text information from articles or blog posts. In the case of photos and videos, we can only use a title. If there are tags - significant keywords of that multimedia, we can use tag information to search. Tag is a keyword of text, blog post, or multimedia. Users have already recognized about the value and importance of tags but only a few users are using tags. They might be annoying to add tags or they don't know what to add for good search result. This is why tag suggestion system is needed. Our method analyzes crawled tag data and suggests appropriate tags to user using association pattern and bigram approach. By experiments, we conclude that our tag suggestion method suggests appropriate tags.","","POD:978-0-7695-3642-2","10.1109/SNPD.2009.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5286693","","Artificial intelligence;Information services;Intelligent networks;Internet;Software engineering;Tagging;User-generated content;Videos;Web search;Web sites","Internet;data mining;information retrieval;search engines;text analysis","Internet;Web search engine;association pattern;bigram approach;folksonomy;information retrieval;tag suggestion method;text information","","0","","10","","","27-29 May 2009","","IEEE","IEEE Conference Publications"
"Intelligent Searching System Based on Manufacturing Resource Personalized Service","X. Qingsheng; P. Weijie; L. Shaobo; Y. Guanci","Key Lab. of Adv. Manuf. Technol., Guizhou Univ., Guiyang, China","2009 ETP International Conference on Future Computer and Communication","20090915","2009","","","47","51","Currently, the traditional search techniques canpsilat meet peoplepsilas demand. Along with constantly improving the precision and recall ratio of search engine, the demand of personalized service becomes particularly outstanding. Intelligent search system of network manufacturing resource is a focused search engine which orients to network manufacturing resource. Meanwhile, the system includes personalized service to improve the intelligent level of search. In this article, considering the characteristics of network manufacturing resource environment, the author studies the personalized service model of retrieval system based on manufacturing resource, designs the architecture of the system, and scrutinizes the key techniques and core algorithms of the system. Lastly, the article shows the prototype system of intelligent searching system based on manufacturing resource personalized service.","","POD:978-0-7695-3676-7","10.1109/FCC.2009.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5235711","intelligent search;manufacturing resource;personalized retrieve;personalized service","Algorithm design and analysis;Computer aided manufacturing;Data mining;Information analysis;Intelligent manufacturing systems;Intelligent networks;Knowledge management;Laboratories;Search engines;Virtual manufacturing","Web services;artificial intelligence;information retrieval;manufacturing resources planning;search engines","intelligent searching system;manufacturing resource personalized service;retrieval system;search engine","","0","","5","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"An intelligent trade matching system for virtual community based on Google Earth","Huaiyu Xu; Wei Duan; Xiaoyu Hou; Yilai Xu; Mo Chen","Integrated Circuit Applied Software Lab, Software College, Northeastern University, Shenyang, China 110004","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","90","93","The trade in the virtual community based on Google Earth (GE) could not be accomplished well because the products of the sellers and the products of the buyers can not match quite well as a result of the massive amount of demand information. In this study, a system for trading between the buyers and sellers more easily and quickly is proposed, which is called Intelligent Trade Matching System (ITMS) in our paper. ITMS can provide good means to resolve the problem of product matching between the seller and the buyer in virtual community. The ITMS can collect, index, search and match products, and then rearrange the sort of products according to the relevance and seller's geographic information and then submit useful information automatically to the user. It is proved that the products provided by the system are updating constantly with the continuously changing positions of the users while they are walking in the virtual community. Also the relative degree is fairly high between the returned projects and the newest demand information published by the users.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234619","Google Earth;Intelligent Trade Matching System;Virtual Community","Buildings;Earth;Educational institutions;Intelligent systems;Joining processes;Legged locomotion;Oceans;Planets;Prototypes;Satellites","database indexing;electronic commerce;geographic information systems;information retrieval;pattern matching;search engines","Google Earth;geographic information system;intelligent trade matching system;product index;product search;virtual community","","0","","6","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Improved Spectral Clustering Algorithm for Community Discovery","S. Niu; D. Wang; S. Feng; G. Yu","Sch. of Inf. Sci. & Eng., Northeastern Univ. Shenyang, Shenyang, China","2009 Ninth International Conference on Hybrid Intelligent Systems","20090922","2009","3","","262","267","For discovering communities in social network, an improved spectral clustering method is presented in this paper. To make full use of the network feature, the core members are used in this method for mining communities. This goal has been achieved through the Page Rank method, which is common in directed graphs, for the reason that an undirected graph can be treated as the special case of the corresponding directed one. Following that, they can be used for initialization in the spectral clustering to avoid the sensitivity to the initial centroids. Applied to four datasets, the improved method turns out to be better than the traditional spectral clustering methods, whether in time or in accuracy aspect.","","POD:978-0-7695-3745-0","10.1109/HIS.2009.268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254579","Page Rank;community discovery;core member;spectral clustering","Biomedical engineering;Biomedical imaging;Clustering algorithms;Clustering methods;Hybrid intelligent systems;Information science;Laboratories;Partitioning algorithms;Social network services;Systems engineering education","data mining;directed graphs;information retrieval;network theory (graphs);pattern clustering;search engines;social networking (online)","Page Rank method;community discovery;directed graph;hierarchical clustering;social network mining;spectral clustering algorithm;undirected graph","","5","","19","","","12-14 Aug. 2009","","IEEE","IEEE Conference Publications"
"Improving accessibility to geospatial data using geographic search","J. E. Williams; M. L. Allison; J. B. Kozman","Schlumberger Information Solutions, Schlumberger, Houston, USA","2009 17th International Conference on Geoinformatics","20091023","2009","","","1","4","The goals of the proposed distributed national geoscience information network (GIN)<sup>[1]</sup> and other associated initiatives such as OneGeology (""create dynamic digital geological map data for the world"")<sup>[2]</sup> are to provide interoperable accessibility to geospatial data. The mission statement of one geology acknowledges that ldquomap data is essential to advancing science and education.rdquo In the United States, this involves a proposal to use Web services, open source standards and common protocols to link to multiple and disparately structured datasets. This approach will build on existing and developing data systems to access the thousands of existing databases, catalogues, and inventories maintained by the United States and individual state geological surveys. The GIN approach is in accord with a recent editorial in the journal Nature, that noted, ldquomaking standardized data openly available to both commercial and not-for-profit organizations could spur innovation of superior information services.rdquo<sup>[3]</sup> It is one of several initiatives within the public and private sectors that are developing and adapting applications to make use of the large quantities of public sector information. But to fully achieve the goal, a method of geographic search and referencing is required for the estimated 85 percent of all digital business and scientific information that was estimated to exist as unstructured data over a decade ago<sup>[4]</sup> and now commonly appears in reports, white papers, presentations, research papers, news, Web pages, and memos.","2161-024X;2161024X","POD:978-1-4244-4562-2","10.1109/GEOINFORMATICS.2009.5293479","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5293479","","Access protocols;Business;Data systems;Databases;Geology;Geoscience;Proposals;Technological innovation;Web pages;Web services","Web services;geographic information systems;information networks;information retrieval;open systems","OneGeology;Web services;distributed national geoscience information network;dynamic digital geological map data;geographic search;interoperable geospatial data accessibility;open source standards","","0","","6","","","12-14 Aug. 2009","","IEEE","IEEE Conference Publications"
