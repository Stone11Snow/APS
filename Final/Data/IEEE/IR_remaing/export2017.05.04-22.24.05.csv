"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6449910,6456047,6425607,6427342,6425790,6427606,6425760,6427558,6425776,6427599,6427341,6425654,6427591,6427539,6425683,6425711,6424347,6424527,6424624,6425234,6424415,6424244,6424851,6424879,6424524,6425152,6424227,6423124,6423105,6421253,6420785,6420771,6416587,6416824,6414994,6418639,6416585,6416573,6416628,6419106,6418100,6418091,6416610,6418097,6416554,6417782,6416598,6418191,6416852,6418288,6418809,6416809,6418665,6419502,6414956,6412089,6411779,6414497,6413000,6414159,6411797,6414103,6412273,6414485,6412186,6412269,6413337,6412324,6413607,6413620,6413017,6412037,6413602,6411769,6413668,6413771,6413368,6365823,6362232,6410103,6410091,6406303,6394660,6405245,6405277,6405699,6395190,6408574,6407283,6407901,6394657,6406646,6405337,6406277,6405820,6395014,6406505,6406817,6406627,6406446",2017/05/04 22:24:05
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Semantic Expansion of Tweet Contents for Enhanced Event Detection in Twitter","O. Ozdikis; P. Senkul; H. Oguztuzun","Dept. of Comput. Eng., Middle East Tech. Univ., Ankara, Turkey","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","20","24","This paper aims to enhance event detection methods in a micro-blogging platform, namely Twitter. The enhancement technique we propose is based on lexico-semantic expansion of tweet contents while applying document similarity and clustering algorithms. Considering the length limitations and idiosyncratic spelling in Twitter environment, it is possible to take advantage of word similarities and to enrich texts with similar words. The semantic expansion technique we implement is based on syntagmatic and paradigmatic relationships between words, extracted from their co-occurrence statistics. As our technique does not depend on an existing ontology or a lexicon database such as Word Net, it should be applicable for any language. The proposed technique is applied on a tweet set collected for three days from the users in Turkey. The results indicate earlier detection of events and improvements in accuracy.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425790","Clustering;Event Detection;Micro-blogging;Semantics;Tweets in Turkish;Twitter;Word Co-occurrences","Clustering algorithms;Event detection;Ontologies;Radar tracking;Semantics;Twitter;Vectors","information retrieval;pattern clustering;social networking (online);statistical analysis;text analysis","Turkey;Twitter;cooccurrence statistics;document clustering algorithm;document similarity algorithm;event detection method enhancement;idiosyncratic spelling;length limitations;lexico-semantic expansion technique;microblogging platform;paradigmatic relationships;syntagmatic relationships;tweet contents;word similarities","","4","","16","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Classification of RSS feed news items using ontology","S. Agarwal; A. Singhal; P. Bedi","Department of computer science, University of Delhi, India","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","491","496","Explosive growth of data on the web demand techniques, which would enable the user to access desired information. In Information retrieval Document Classification is prerequisite. In practice many classification techniques were and are in use. Term Frequency-Inverse Document Frequency (TF-IDF) is an approach which represents documents based on the frequency of terms in documents. Limitation of this approach is high dimensionality of data. Moreover it does not consider the relations among the terms, resulting in less precise and noisy end result. In our approach we are using weighted Concept Frequency-Inverse Document Frequency (CF-IDF) with background knowledge of domain Ontology, for classification of RSS feed News Items. Metadata information of news items has been used to assign weight to the identified concepts. No trained classifiers are required as Ontology itself acts as a classifier. We have designed ontology based on news industry standards. This classification approach considers relations among the concepts and properties. It results in reduction of noise in final output. It considers only the key concepts of a domain for classification instead of all the terms, which curbs the problem of dimensionality. Evaluation of experimental results reveals that proposed approach gives better classification results.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416587","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416587","CF-IDF;News Domain Ontology;RSS news feeds;Semantic classification","Decision support systems;Films;Helium;Intelligent systems","Internet;document handling;information retrieval;meta data;ontologies (artificial intelligence);pattern classification","CF-IDF;RSS feed news item classification;TF-IDF;Web demand techniques;concept frequency inverse document frequency;data dimensionality;information retrieval document classification;metadata information;ontology;term frequency-inverse document frequency","","1","","24","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"A heuristic as basis for an adaptive e-commerce recommender system","E. P. Wach","STI Innsbruck, University of Innsbruck, 6020, Austria","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","410","415","The research described in this paper proposes an evolution heuristic for realising an adaptive semantic e-commerce recommender system by establishing a feedback cycle. This recommender extracts questions from product domain ontologies (PDO) which are used in the dialogue of the recommendation process. The heuristic decides an automated PDO evolution (without a human inspection) in order to realise an automatic adaptation of the recommendation process. The feedback is derived from user interactions with the user interface of the recommender. This research shows that the automated PDO evolution outperforms a manual one. The evolution heuristic has been evaluated with an experiment and validated in real-world testing series.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416573","heuristics;ontology evolution;recommender systems;self-adapting information systems","Humans;Intelligent systems;Manuals;Ontologies;Recommender systems;Switches;User interfaces","electronic commerce;information retrieval;ontologies (artificial intelligence);recommender systems;semantic Web;user interfaces","adaptive semantic e-commerce recommender system;automated PDO evolution;automatic adaptation;evolution heuristic;feedback cycle;product domain ontologies;question extraction;real-world testing series;recommendation process;user interactions;user interface","","0","","11","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"An Ontology-Based Topical Crawling Algorithm for Accessing Deep Web Content","K. V. Arya; B. R. Vadlamudi","ABV-IIITM, Gwalior, India","2012 Third International Conference on Computer and Communication Technology","20130110","2012","","","1","6","Due to the large volume of the Web information and relatively high speed of information update, the coverage and quality of the retrieved pages by modern search engines is comparatively small. Given the volume of the Web and its frequency of content change, the coverage and quality of pages retrieved by modern search engines is relatively small since they crawl only hypertext links ignoring the search forms which are the entry points for accessing deep web content where two-thirds of information is resides. In this paper an algorithm has been designed to enable topical crawlers to access hidden web content by using domain based ontology to determine the forms' relevance to the domain. In this work scientific research publications domain has been considered. Experimental results show that proposed approach is better as compared to keyword based crawlers in terms of both relevancy and completeness.","","Electronic:978-0-7695-4872-2; POD:978-1-4673-3149-4","10.1109/ICCCT.2012.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394657","Deep web;Domain ontology;Focused crawler;Form processing","Arrays;Crawlers;Databases;HTML;Ontologies;Search engines;Web pages","Internet;information retrieval;ontologies (artificial intelligence);search engines","Web information;deep Web content access;domain based ontology;hypertext links;keyword based crawlers;ontology-based topical crawling algorithm;scientific research publications domain;search engines;topical crawlers","","0","","13","","","23-25 Nov. 2012","","IEEE","IEEE Conference Publications"
"Relational Similarity Measurement between Word-pairs Using Multi-Task Lasso","D. Yan; Z. Lu","Dept. of Comput. Sci. &amp; Technol., East China Normal Univ., Shanghai, China","2012 International Conference on Cloud and Service Computing","20130117","2012","","","180","184","Relational similarity measurement as a popular research area in the field of natural language processing, is widely used in information retrieval, word sense disambiguation, machine translation and so on. The existing approaches are mostly based on extracting semantic features as feature matrixes from the large-scale corpus and using the corresponding method to process these feature matrixes to compute the relational similarity between word-pairs. However, the extracted semantic features are loosely distributed, which make the sparseness of feature matrixes. This paper proposes a Multi-Task Lasso based Relational similarity measure method (MTLRel), which makes snippets retrieved from a web search engine as the semantic information sources of a word-pair, then builds the feature matrix by extracting predefined patterns from snippets, compress and denoise the feature matrix into a feature vector using a multi-task lasso method, finally measures the relational similarity between two word-pairs by computing the cosine of the angle between two feature vectors. The MTLRel approach achieves an accuracy rate of 50.3% by testing 374 SAT analogy questions with lower time consumption.","","Electronic:978-0-7695-4910-1; POD:978-1-4673-4724-2","10.1109/CSC.2012.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6414497","Lasso;Relational similarity;multi-task learning","Accuracy;Engines;Feature extraction;Mathematical model;Semantics;Vectors;Web search","information retrieval;matrix algebra;natural language processing;search engines","Web search engine;feature matrixes;feature vector;information retrieval;large-scale corpus;machine translation;multitask lasso based relational similarity measure method;natural language processing;semantic feature extraction;semantic information sources;snippets;word sense disambiguation;word-pairs","","0","","12","","","22-24 Nov. 2012","","IEEE","IEEE Conference Publications"
"Analysis of multimodal time series data of robotic environment","G. Radhakrishnan; D. Gupta; R. Abhishek; A. Ajith; T. Sudarshan","School of Engineering, Amrita Vishwa Vidyapeetham, Bangalore Campus, India","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","734","739","Autonomous mobile robots equipped with an array of sensors are being increasingly deployed in disaster environments to assist rescue teams. The sensors attached to the robots send multimodal time series data about the disaster environments which can be analyzed to extract useful information about the environment in which the robots are deployed. A set of data mining tasks that effectively cluster various robotic environments have been investigated. The effectiveness of these data mining techniques have been demonstrated using an available robotic dataset. The accuracy of the proposed technique has been measured using a manual reference cluster set.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416628","clustering;data mining;dynamic time warping;mobile robots;multi modal","Conferences;Data visualization;Decision support systems;Euclidean distance;Intelligent systems;Q measurement","data analysis;data mining;emergency management;information retrieval;mobile robots;pattern clustering;sensor arrays;time series","autonomous mobile robots;data mining tasks;disaster environments;information extraction;manual reference cluster set;multimodal time series data analysis;rescue team assistance;robotic dataset;robotic environment;sensor array","","3","","7","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"Automated question generator for Tagalog informational texts using case markers","C. S. Montenegro; V. G. Engle; M. G. J. Acuba; A. M. A. Ferrenal","Coll. of Comput. Studies, Silliman Univ., Dumaguete City, Philippines","TENCON 2012 IEEE Region 10 Conference","20130117","2012","","","1","5","This paper presents an automated natural language question generator for Tagalog informational texts. It takes a target text as an input and generates a set of what, where and who question and answer pairs extracted from the source text. The resulting questions are also ranked using a proposed acceptability criterion. The implementation consists of three modules: a part of speech tagger, an anaphora resolver, and a question ranker. Questions generated from the experiment were rated by three evaluators. Of the generated questions, 33% were rated as acceptable by the evaluators, 96% of which were in need of modifications.","2159-3442;21593442","Electronic:978-1-4673-4824-9; POD:978-1-4673-4823-2","10.1109/TENCON.2012.6412273","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412273","anaphora resolution;natural language;parsing;part of speech tagging;question generation","Educational institutions;Generators;Natural language processing;Semantics;Speech;Syntactics;Tagging","natural language processing;question answering (information retrieval);text analysis","Tagalog informational text;acceptability criterion;anaphora resolver;answer pairs;automated natural language question generator;automated question generator;case markers;part of speech tagger;question ranker;source text","","0","","7","","","19-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"Scan-based attack against DES cryptosystems using scan signatures","H. Kodera; M. Yanagisawa; N. Togawa","Department of Computer Science and Engineering, Waseda University, Japan","2012 IEEE Asia Pacific Conference on Circuits and Systems","20130124","2012","","","599","602","With the high integration of LSI in recent years, the importance of design-for-techniques has been increasing. A scan-path test is one of the useful design-for-test techniques, in which testers can observe and control registers inside the target LSI chip directly. On the other hand, the risk of side-channel attacks against cryptographic LSIs and modules has been pointed out. In particular, scan-based attacks which retrieve secret keys by analyzing scan data obtained from scan chains has been attracting attention. In this paper, we propose a scan-based attack method against DES using scan signatures. Our proposed method are based on focusing on particular bit-column-data in a set of scan data and observing their changes when given several plaintexts. We can retrieve secret keys by partitioning the S-BOX process into eight independent sub-processes and reducing the number of the round key candidates from 2<sup>48</sup> to 2<sup>6</sup>×8 = 512. Our proposed methods can retrieve secret keys even if a scan chain includes registers except a crypto module and attackers do not know when the encryption is really done in the crypto module. Experimental results demonstrate that we successfully retrieve the secret keys of a DES cryptosystem using at most 32 plaintexts.","","Electronic:978-1-4577-1729-1; POD:978-1-4577-1726-0","10.1109/APCCAS.2012.6419106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6419106","data encryption standard;scan chain;scan-based attack;side-channel attacks","Elliptic curve cryptography;Encryption;Large scale integration;Registers;Standards;Timing","cryptography;data analysis;design for testability;digital signatures;information retrieval;microprocessor chips","DES cryptosystems;LSI chip;S-BOX process;bit-column-data;data encryption standard;design-for-test techniques;scan chains;scan data analysis;scan signatures;scan-based attack method;scan-path test;secret key retrieval;side-channel attacks","","4","","6","","","2-5 Dec. 2012","","IEEE","IEEE Conference Publications"
"A Study on Difficulty Level Recognition of Piano Sheet Music","S. C. Chiu; M. S. Chen","Res. Center for Inf. Technol., Taipei, Taiwan","2012 IEEE International Symposium on Multimedia","20130131","2012","","","17","23","Looking for a piano sheet music with proper difficulty for a piano learner is always an important work to his/her teacher. In the paper, we study on a new and challenging issue of recognizing the difficulty level of piano sheet music. To analyze the semantic content of music, we focus on symbolic music, i.e., sheet music or score. Specifically, difficulty level recognition is formulated as a regression problem to predict the difficulty level of piano sheet music. Since the existing symbolic music features are not able to capture the characteristics of difficulty, we propose a set of new features. To improve the performance, a feature selection approach, RReliefF, is used to select relevant features. An extensive performance study is conducted over two real datasets with different characteristics to evaluate the accuracy of the regression approach for predicting difficulty level. The best performance evaluated in terms of the R2 statistics over two datasets reaches 39.9% and 38.8%, respectively.","","Electronic:978-0-7695-4875-3; POD:978-1-4673-4370-1","10.1109/ISM.2012.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424624","classification;computer music;difficulty recognition;sheet music analysis","Accuracy;Complexity theory;Feature extraction;Fingers;Instruments;Quantization;Training","classification;computer aided instruction;feature extraction;information retrieval;learning (artificial intelligence);music;regression analysis","RReliefF;difficulty level prediction;difficulty level recognition;feature selection;machine learning. technique;music classification;music education;music retrieval;piano sheet music;regression problem;score;semantic content analysis;symbolic music","","1","","24","","","10-12 Dec. 2012","","IEEE","IEEE Conference Publications"
"Secure Problems Solving Scheme","H. Yamaguchi; M. Gotaishi; S. Tsujii; P. C. Y. Sheu; C. V. Ramamoorchy","Chuo Univ., Tokyo, Japan","2012 IEEE First International Conference on Internet Operating Systems","20130131","2012","","","22","29","We propose the concept of service functions and features in knowledge society, including the problem, solutions and semantic themes, the private information retrieval theme, the privacy preserving data processing, and the new public key cryptosystem in which the problems of human-machine interaction, privacy preserving are resolved.","","Electronic:978-0-7695-4936-1; POD:978-1-4673-5092-1","10.1109/ICIOS.2012.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424527","Organization-based Encryption;Semantic Computing;Semantic Problem Solving Sychem;cryptographic Protocol;privacy","Cryptography;Natural languages;Organizations;Problem-solving;Protocols;Semantics","data privacy;human computer interaction;information retrieval;public key cryptography","human-machine interaction;knowledge society;privacy preserving data processing;private information retrieval theme;public key cryptosystem;secure problems solving scheme;semantic theme;service function","","1","","10","","","10-12 Dec. 2012","","IEEE","IEEE Conference Publications"
"Design of a Metacrawler for web document retrieval","K. R. R. Babu; A. P. Arya","Department of Information Technology, Government Engineering College, Idukki, India","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","478","484","Web Crawlers `browse' the World Wide Web (WWW) on behalf of search engine, to collect web pages from numerous collections of billions of documents. Metacrawler is similar to that of a meta search engine that combines the top web search results from popular search engines. World Wide Web is growing rapidly. This possesses great challenges to general purpose crawlers. This paper introduces an architectural framework of a Metacrawler. This crawler enables the user to retrieve information that is relevant to the topic from more than one traditional web search engines. The crawler works in such a way that it fetches only the pages that are relevant to the topic. The PageRank algorithm is often used in ranking web pages. But, the ranking causes the problem of topic-drift. So, modified PageRank algorithm is used to rank the retrieved web pages in such a way that it reduces this problem. The clustering method is used to combine the search results so that the user can easily select web pages from the clustered results based upon the requirement. Experimental results show the effectiveness of the Metacrawler.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416585","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416585","Clustering;Metacrawler;Ranking Algorithms;Search Engine;Web Crawler","Algorithm design and analysis;Clustering algorithms;Crawlers;Engines;Metasearch;Search engines;Web pages","Internet;Web sites;information retrieval;pattern clustering;search engines","Web crawlers;Web document retrieval;Web page retrieval;Web search engines;World Wide Web;architectural framework;clustering method;general purpose crawlers;information retrieval;metacrawler design;metasearch engines;modified PageRank algorithm;topic-drift problem","","1","","18","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"A Fast Privacy-Preserving Multi-keyword Search Scheme on Cloud Data","C. Yang; W. Zhang; J. Xu; J. Xu; N. Yu","Electron. Eng. &amp; Inf. Sci., Univ. of Sci. &amp; Technol. of China, Hefei, China","2012 International Conference on Cloud and Service Computing","20130117","2012","","","104","110","Nowadays, more and more people outsource their data to cloud servers for great flexibility and economic savings. Due to considerations on security, private data is usually protected by encryption before sending to cloud. How to utilize data efficiently while preserving user's privacy is a new challenge. In this paper, we focus on a efficient multi-keyword search scheme meeting a strict privacy requirement. First, we make a short review of two existing schemes supporting multi-keyword search, the kNN-based MRSE scheme and scheme based on bloom filter. Based on the kNN-based scheme, we propose an improved scheme. Our scheme adopt a product of three sparse matrix pairs instead of the original dense matrix pair to encrypt index, and thus get a significant improvement in efficiency. Then, we combine our improved scheme with bloom filter, and thus gain the ability for index updating. Simulation Experiments show proposed scheme indeed introduces low overhead on computation and storage.","","Electronic:978-0-7695-4910-1; POD:978-1-4673-4724-2","10.1109/CSC.2012.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6414485","Cloud Security;Multi-keyword Search;Privacy-preserving;Searchalbe Encryption;Secure KNN","Dictionaries;Encryption;Indexes;Privacy;Servers;Vectors","cloud computing;cryptography;data privacy;data structures;information retrieval;sparse matrices","bloom filter;cloud data;cloud servers;encryption;fast privacy-preserving multikeyword search scheme;kNN-based MRSE scheme;kNN-based multi-keyword ranked search over encrypted cloud;original dense matrix;private data;sparse matrix pairs;strict privacy requirement","","4","","19","","","22-24 Nov. 2012","","IEEE","IEEE Conference Publications"
"The research and design of the data acquisition system and the control system of KTX","J. An; K. Song; J. Yang; P. Cao","Dept. of Modern Phys., Univ. of Sci. &amp; Technol. of China, Hefei, China","2012 18th IEEE-NPSS Real Time Conference","20130124","2012","","","1","5","Reversed field pinch (RFP) is an important toroidal magnetic confinement device. The RFP scientific program can address issues relevant not only for RFP, but also more generally for magnetic confinement fusion. And the rich phenomena associated with the strong magnetic self-organization in RFP provide an unusually close connection to a set of important problems in plasma astrophysics. The objective of this paper is to build the control system and data acquisition system for the RFP called KTX which is in the construction in University of science and technology of China. The data acquisition system and the control system includes three ingredients: the master control system, the data acquisition and storage system, the plasma control system. The master control system is a core part of operation scheduling and Centralized management in the fusion experiments for monitoring the system operating situations, and coordinating operations of each module, synchronizing and inspecting. The data acquisition and storage system includes not only hardware modules such as analog to digital converter but also software platform for acquisition control and data access. The plasma control system is used for the control of plasma parameters during experiments. The design of the operating control system and data acquisition system is based on modularized design thoughts and adopt mainstream hardware platform that is easy to for maintaining and system upgrading.","","Electronic:978-1-4673-1084-0; POD:978-1-4673-1082-6","10.1109/RTC.2012.6418100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418100","","Control systems;Data acquisition;Discharges (electric);Plasmas;Process control;Real-time systems;Safety","Tokamak devices;analogue-digital conversion;computerised monitoring;data acquisition;information retrieval;physical instrumentation control;plasma toroidal confinement;reversed field pinch","China;KTX control system;RFP scientific program;University of science and technology;analog to digital converter;centralized management system;data access;data acquisition control;data acquisition system;hardware modules;hardware platform;magnetic confinement fusion;master control system;plasma astrophysics;plasma control system;plasma parameters;reversed field pinch;software platform;storage system;strong magnetic self-organization;toroidal magnetic confinement device","","0","","7","","","9-15 June 2012","","IEEE","IEEE Conference Publications"
"Computer vision to polarimetric SAR imaging","Y. Q. Jin","Key Lab. of Wave Scattering and Remote Sensing Information (WaSRSI), Fudan University, Shanghai, China","2012 International Conference on Computer Vision in Remote Sensing","20130128","2012","","","164","167","This paper presents some research progress in WaSRSI on theoretical modeling and numerical simulation for polarimetric scattering and SAR information retrievals, such as mono-static and bistatic SAR image simulation, reconstruction of buildings from mUlti-aspect SAR images, and using a SIMO system to simulate 3D scattering and reconstruction of an electric-large target above rough surface.","","DVD:978-1-4673-1273-8; Electronic:978-1-4673-1274-5; POD:978-1-4673-1272-1","10.1109/CVRS.2012.6421253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6421253","SAR imaging;information;polarimetric scattering modeling;simulation","Presses;Probabilistic logic","buildings (structures);computer vision;digital simulation;electromagnetic wave scattering;geophysical image processing;image reconstruction;information retrieval;radar imaging;radar polarimetry;remote sensing;rough surfaces;synthetic aperture radar","3D reconstruction;3D scattering;SAR information retrievals;SAR remote sensing;SIMO system;WaSRSI;bistatic SAR image simulation;building reconstruction;computer vision;electric-large target;mono-static SAR image simulation;multiaspect SAR images;numerical simulation;polarimetric SAR imaging;polarimetric scattering;rough surface;theoretical modeling","","0","","8","","","16-18 Dec. 2012","","IEEE","IEEE Conference Publications"
"A Sequential Multi-task Learning Neural Network with Metric-Based Knowledge Transfer","S. Yue; S. Ozawa","Grad. Sch. of Eng., Kobe Univ., Kobe, Japan","2012 11th International Conference on Machine Learning and Applications","20130110","2012","1","","671","674","In this paper, we propose a new sequential multitask pattern recognition model called Resource Allocating Network for Multi-Task Learning with Metric Learning (RAN-MTLML). RAN-MTLML has the following five functions: one-pass incremental learning, task-change detection, memory/retrieval of task knowledge, reorganization of classifier, and knowledge transfer. The knowledge transfer is actualized by transferring the metrics of all source tasks to a target task based on the task relatedness. Experimental results demonstrate the effectiveness of introducing the metric learning and the knowledge transfer on metric in the proposed RAN-MTLML.","","Electronic:978-0-7695-4913-2; POD:978-1-4673-4651-1","10.1109/ICMLA.2012.125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406646","incremental learning;multitask learning;neural networks;pattern recognition","Accuracy;Knowledge transfer;Machine learning;Measurement;Pattern recognition;Radio access networks;Training data","information retrieval;knowledge management;learning (artificial intelligence);neural nets;pattern classification;resource allocation","RAN-MTLML;classifier reorganization;metric learning;metric-based knowledge transfer;multitask learning with metric learning;one-pass incremental learning;resource allocating network;sequential multitask learning neural network;sequential multitask pattern recognition model;task knowledge memory;task knowledge retrieval;task relatedness;task-change detection","","0","","11","","","12-15 Dec. 2012","","IEEE","IEEE Conference Publications"
"Retrieving software maintenance history with topic models","S. Yu","Sch. of Comput. Sci., Fudan Univ., Shanghai, China","2012 28th IEEE International Conference on Software Maintenance (ICSM)","20130110","2012","","","621","624","Software maintenance history is a chronological record of significant maintenance events. It provides high level knowledge to software stakeholders, helps them to make important decisions. Unfortunately, retrieving software maintenance history is a heavy manual work so it can be invalid or even misleading. This paper use topic models to organize software maintenance documents such as bug reports into topics. Event detection tool is adopted to identify maintenance events from these topics. Finally, the identified events reconstruct software maintenance history. Retrieval results on 100,000 Eclipse bug reports are in accordance with Eclipse history records.","1063-6773;10636773","Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0","10.1109/ICSM.2012.6405337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405337","","Computer bugs;Conferences;Event detection;History;Maintenance engineering;Software maintenance","decision making;document handling;information retrieval;software maintenance;system documentation","Eclipse bug reports;Eclipse history records;chronological record;decision making;event detection tool;maintenance event identification;software maintenance documents organization;software maintenance history retrieval;software stakeholders;topic models","","2","","8","","","23-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Mapping Knowledge Activities with System Operations to Foster Information Systems for Knowledge Work","K. Widmann; I. Seeber; R. Maier","Dept. of Inf. Syst., Production & Logistics Manage., Univ. of Innsbruck, Innsbruck, Austria","2012 Eighth International Conference on Signal Image Technology and Internet Based Systems","20130110","2012","","","925","930","The (semi-) automatic detection of a user's system activity provides context that can be exploited for information retrieval, for recommendations or for adapting contents and services to this activity and thus improve task-technology-fit. Various approaches automatically detect user activities on the level of system operations. However, the approaches struggle with the challenge how to semantically connect these system operations with high level knowledge activities. Yet, this link is needed to meaningfully support users engaged in knowledge activities. This paper takes up on this challenge and maps a framework of knowledge activities to system operations on the basis of descriptions of work practices gathered from two European companies. The framework is intended to aid the meaningful connection of automatically detected system operations with knowledge activities on varying levels of granularity.","","Electronic:978-0-7695-4911-8; POD:978-1-4673-5152-2","10.1109/SITIS.2012.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6395190","context;design;information system;knowledge activity;knowledge work","Context;Electronic mail;Encoding;Europe;Organizations;Standards organizations","information retrieval;information systems;recommender systems","European companies;foster information systems;information retrieval;knowledge work;mapping knowledge activities;sem automatic detection;system operations","","0","","32","","","25-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"VIP: Video-assisted inter-vehicle positioning system","Andy An-Kai Jeng; Chien Chen; Rong-Hong Jan; Wai-Yee Fong; Huei-Ru Tseng","Information and Communications Research Labs, Industrial Technology Research Institute, Hsinchu, Taiwan 31040","2012 12th International Conference on ITS Telecommunications","20130131","2012","","","522","526","Intelligent Transportation System (ITS) provides various services for vehicular environments. Many of them require accuracy information about vehicle's position. However, the current positioning techniques may not satisfy the accuracy requirement, especially for safety applications. In this paper, we propose a Video-Assisted Inter-Vehicle Positioning (VIP) system. The system integrates processed image data from video sensors equipped on part of vehicles and inter-vehicle communication techniques. The system equips each vehicle with a GPS and inter-vehicle communication modules, and a part of vehicles are equipped with a video sensor. The data extracted from video sensors will be exchanged among vehicles and assist each vehicle to validate the position received from neighboring vehicles so as to improve the accuracy of cooperative positioning. Simulation results shown that our approach can achieve 30 percent of improvement in the position accuracy when only half of vehicles were fully equipped, and improve the accuracy by factor of 40 percent (within 3m) if all vehicles were fully equipped.","","DVD:978-1-4673-3068-8; Electronic:978-1-4673-3070-1; POD:978-1-4673-3071-8","10.1109/ITST.2012.6425234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425234","","Accuracy;Cameras;Global Positioning System;Image recognition;Nickel;Sensors;Vehicles","Global Positioning System;automated highways;cooperative communication;information retrieval;mobile communication;object recognition;video cameras;video surveillance","GPS;ITS;VIP;cooperative positioning;data exchange;data extraction;intelligent transportation system;intervehicle communication module;processed image integration;vehicular environment;video assisted intervehicle positioning;video sensor","","0","","12","","","5-8 Nov. 2012","","IEEE","IEEE Conference Publications"
"DFCloud: A TPM-based secure data access control method of cloud storage in mobile devices","J. Shin; Y. Kim; W. Park; C. Park","Department of Computer Science and Technology, Pohang University of Science and Technology, Pohang 790-784, Korea","4th IEEE International Conference on Cloud Computing Technology and Science Proceedings","20130204","2012","","","551","556","Using the cloud storage services, users can access their data in any time, at any place, even with any computing device including mobile devices. Although these properties provide flexibility and scalability in handling data, security issues should be handled especially when mobile devices try to access data stored in cloud storage. Currently, a typical cloud storage service, Dropbox, offers server-side data encryption for security purpose. However, we think such method is not secure enough because all the encryption keys are managed by software and there is no attestation on the client software integrity. Moreover, a simple user identification based on user ID and Password is also easy to be compromised. Data sharing which is critical in enterprise environment is significantly restricted because it is not easy to share encryption key among users. In this paper, we propose DFCloud, a secure data access control method of cloud storage services to handle these problems found in the typical cloud storage service Dropbox. DFCloud relies on Trusted Platform Module (TPM) [1] to manage all the encryption keys and define a key sharing protocol among legal users. We assume that each client is mobile device using ARM TrustZone [2] technology. The DFCloud server prototype is implemented using ARM Fastmodel 7.1 and Open Virtualization software stack for ARM TrustZone. For DFCloud client, TPM functions are developed in the secure domain of ARM TrustZone because most ARM-based mobile devices are not equipped with TPM chip. The DFCloud framework defines TPM-based secure channel setup, TPM-based key management, remote client attestation, and a secure key share protocol across multiple users/devices. It is shown that our concept works correctly through a prototype implementation.","","Electronic:978-1-4673-4510-1; POD:978-1-4673-4511-8; USB:978-1-4673-4509-5","10.1109/CloudCom.2012.6427606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427606","ARM TrustZone;TPM;cloud storage service;security","Cloud computing;Encryption;Protocols;Servers","cloud computing;information retrieval;information storage;integrated software;microcontrollers;mobile computing;private key cryptography;service-oriented architecture;virtualisation","ARM Fastmodel 7.1;ARM TrustZone technology;ARM-based mobile devices;DFCloud client;DFCloud server prototype;Dropbox;Password based user identification;TPM;TPM-based key management;TPM-based secure channel setup;TPM-based secure data access control method;client software integrity;cloud storage services;computing device;data handling;data sharing;key sharing protocol;legal users;mobile devices;open virtualization software stack;remote client attestation;secure key share protocol;security issues;server-side data encryption keys;trusted platform module;user ID-based user identification","","4","1","20","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Efficient Graph Models for Retrieving Top-k News Feeds from Ego Networks","R. Pickhardt; T. Gottron; A. Scherp; S. Staab; J. Kunze","Inst. for Web Sci. &amp; Technol., Univ. of Koblenz-Landau, Koblenz, Germany","2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing","20130110","2012","","","123","133","A key challenge of web platforms like social networking sites and services for news feed aggregation is the efficient and targeted distribution of new content items to users. This can be formulated as the problem of retrieving the top-k news items out of the d-degree ego network of each given user, where the set of all users producing feeds is of size n, with n ≫ d ≫ k and typically k <; 20. Existing approaches employ either expensive join operations on global indices or suffer from high redundancy through denormalization. This makes retrieval of different top-k news feeds for thousands of users per second very inefficient in a large social network. In this paper, we propose two graph models GRAPHITY and STOU to address this problem. GRAPHITY is optimized for fast retrieval of news feeds and has a runtime of O(k log(k)). The GRAPHITY index does not involve data redundancy. An update of the index upon insertion of a new item to the feed is possible in a runtime linear to the nodes' indegree din. New content can be stored in STOU in O(1) at the cost of slower retrieval speed of O(d log(d)). We verify the theoretical runtime complexity of GRAPHITY and STOU on two data sets of different characteristics and size. We show that on a single machine GRAPHITY is able to retrieve more than 10 000 unique news feeds per second in a network with more than one million users. Our evaluation confirms that retrieval of news feeds with GRAPHITY is independent of the node degree d of a user's ego network and network size n and does scale to networks of arbitrary size.","","Electronic:978-0-7695-4848-7; POD:978-1-4673-5638-1","10.1109/SocialCom-PASSAT.2012.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406277","graph data base;graph index;graphity;scalability;social network;social news feed;top k join","Complexity theory;Data models;Feeds;Indexes;Runtime;Social network services;Sorting","graph theory;information retrieval;social networking (online)","GRAPHITY graph models;STOU graph models;d-degree ego networks;denormalization;global indices;graph models;join operations;news feed aggregation;social networking sites;top-k news feed retrieval","","0","","17","","","3-5 Sept. 2012","","IEEE","IEEE Conference Publications"
"Music-genre classification system based on spectro-temporal features and feature selection","S. C. Lim; J. S. Lee; S. J. Jang; S. P. Lee; M. Y. Kim","Department of Information and Communication Engineering, Sejong University, Seoul, Korea","IEEE Transactions on Consumer Electronics","20130124","2012","58","4","1262","1268","An automatic classification system of the music genres is proposed. Based on the timbre features such as mel-frequency cepstral coefficients, the spectro-temporal features are obtained to capture the temporal evolution and variation of the spectral characteristics of the music signal. Mean, variance, minimum, and maximum values of the timbre features are calculated. Modulation spectral flatness, crest, contrast, and valley are estimated for both original spectra and timbre-feature vectors. A support vector machine (SVM) is used as a classifier where an elaborated kernel function is defined. To reduce the computational complexity, an SVM ranker is applied for feature selection. Compared with the best algorithms submitted to the music information retrieval evaluation exchange (MIREX) contests, the proposed method provides higher accuracy at a lower feature dimension for the GTZAN and ISMIR2004 databases.","0098-3063;00983063","","10.1109/TCE.2012.6414994","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6414994","Music genre classification;SVM;feature selection;modulation spectrum;music informationretrieval","Accuracy;Feature extraction;Mel frequency cepstral coefficient;Modulation;Support vector machines;Timbre","cepstral analysis;computational complexity;information retrieval;music;signal classification;support vector machines","GTZAN databases;ISMIR2004 databases;MIREX contests;SVM ranker;automatic classification system;computational complexity;feature selection;kernel function;maximum values;mean values;mel-frequency cepstral coefficients;minimum values;modulation spectral flatness;music genres;music information retrieval evaluation exchange contests;music signal;spectral characteristics;spectrotemporal features;support vector machine;temporal evolution;temporal variation;timbre features;variance values","","12","","32","","","November 2012","","IEEE","IEEE Journals & Magazines"
"Mapping Intelligence Research Domain in China","W. Li; Z. Jiang; H. Wang; P. Li; C. Zhao; Y. Zhang","Coll. of Inf. Syst. &amp; Manage, Nat. Univ. of Defense Technol., Changsha, China","2012 Fourth International Conference on Multimedia Information Networking and Security","20130110","2012","","","824","827","A global view of intelligence research can reveal the intellectual structure of this domain. This research can also find the set of core researchers, show the literature citation network and institutional collaboration, and dig the research hotspot. All of the useful information can help both experts and newcomers in this domain gain a faster and deeper understanding of contemporary status to intelligence subject. This paper meets this need by using a global view framework through analysis intelligence domain literature data. The data were crawled from one of the biggest literature data website in China through a depth-first data crawler that we developed. The framework of this paper construct from four type of perspectives: (1) the basic analysis of the quantity of intelligence literature which can discern the core researchers, (2) confirm the property that the literature citation network has small-world property, the in degree distribution of the citation network accord with power-law distribution, simultaneously the out degree distribution also possess power-law distribution after we smooth the ""crew cut"" phenomena, (3) analysis to the research institutional collaboration pattern through Google map technique, so we can ascertain the main research city and the collaboration pattern among cities.","2162-8998;21628998","Electronic:978-0-7695-4852-4; POD:978-1-4673-3093-0","10.1109/MINES.2012.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405820","citation network;domain analysis;intelligence;literature","Artificial intelligence;Cities and towns;Collaboration;Educational institutions;Informatics;Information science;Visualization","Web sites;citation analysis;data analysis;educational institutions;information retrieval;literature;search engines;tree searching","Chinese intelligence research domain;Google map technique;crew cut phenomena;depth-first data crawler;global view framework;institutional collaboration;intelligence domain literature data analysis;literature citation network;literature data Web site;outdegree distribution;power-law distribution;research institutional collaboration pattern analysis","","0","","10","","","2-4 Nov. 2012","","IEEE","IEEE Conference Publications"
"An application for the game of Go: Automatic live Go recording and searchable Go database","A. Srisuphab; P. Silapachote","Fac. of Inf. &amp; Commun. Technol., Mahidol Univ., Nakhon Pathom, Thailand","TENCON 2012 IEEE Region 10 Conference","20130117","2012","","","1","6","The key to become a skillful Go player is to learn from experience, analyzing and reflecting on previously played games. Rich in strategy, the game of Go requires a player to recognize winning or losing configurations of game pieces on the board. Knowing how to respond is essential, and training to do so requires an extensive study of various different tactics used by a diverse group of players, especially professionals. The benefit of recording Go games has undeniably been realized. Hand-recording has been attempted but it is neither efficient nor practical. Described in this work is an automatic Computer Vision system to record Go games - AutoGoRecorder. Incorporating advanced technologies, AutoGoRecorder automatically records a live Go game in real time. Additionally, it maintains a dynamic database of Go games that is easily accessible and searchable. It is an invaluable tool for any Go organization to record a tournament. Individuals can use it to review certain games or to familiarize themselves with strategies to respond to particular configurations of Go stones. Coaches and tutors can use it as an teaching aid to give suggestions or comments, reading the game to amateur players.","2159-3442;21593442","Electronic:978-1-4673-4824-9; POD:978-1-4673-4823-2","10.1109/TENCON.2012.6412186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412186","","Computer architecture;Computer vision;Databases;Games;Image edge detection;User interfaces;Webcams","computer aided instruction;computer games;computer vision;information retrieval;professional aspects;real-time systems;video recording;visual databases","AutoGoRecorder;Game of Go;Go stones;accessible Go game database;amateur players;automatic computer vision system;automatic live Go recording;dynamic Go game database;game tactics;losing configuration recognition;professional players;real-time recording;searchable Go database;skillful Go player;teaching aid;winning configuration recognition","","0","","14","","","19-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"Context-Oriented Data Acquisition and Integration Platform for Internet of Things","Y. S. Chen; Y. R. Chen","Dept. of Comput. Sci., Nat. Taipei Univ. of Educ., Taipei, Taiwan","2012 Conference on Technologies and Applications of Artificial Intelligence","20130110","2012","","","103","108","In this paper, a data acquisition and integration platform for internet of things is proposed. The platform is developed under a cloud computing environment using context-oriented approaches. It collects sensor data from different types of sensor devices, including such as RFID, ZigBee sensors, GPS devices, temperature sensors, humidity sensors, luminance sensors, etc. First we are devoted to the study of deployment, management, and control of different types of sensors for automatic acquisition of sensor data and its related ambient information, both of which will be stored in the IoT repository in a cloud environment. Then, context-oriented mechanisms are developed to produce context data. With the devised context broker, the data retrieved from the IoT repository can be used to produce the contextual portfolio, which is annotated with semantic description. The contextual portfolio will then be stored into a cloud database as the User Portfolio. Finally, services for accessing the User Portfolio in the cloud are developed on a middleware platform, which is compliant with the OSGi standard. With the proposed platform, the acquired data is integrated into semantic contexts, which can be easily shared and reused among different mobile applications. Also, the context information can enhance mobile applications' usability by adapting to conditions that directly affect their operations.","2376-6816;23766816","Electronic:978-0-7695-4919-4; POD:978-1-4673-4976-5","10.1109/TAAI.2012.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6395014","Context Data;Internet of Things;Middleware;Wireless Sensor Networks","Context;Internet;Middleware;Ontologies;Portfolios;Semantics;Temperature sensors","Internet of Things;cloud computing;computerised instrumentation;data acquisition;data integration;information retrieval;middleware;mobile computing;sensor placement;wireless sensor networks","Internet of Things;IoT repository;OSGi standard;ambient information storage;automatic context-oriented sensor data acquisition platform;automatic context-oriented sensor data integration platform;cloud computing environment;cloud database;contextual portfolio;data annotation;data retrieval;middleware platform;mobile application usability enhancement;semantic description;sensor control;sensor data collection;sensor deployment;sensor management;user portfolio","","6","","10","","","16-18 Nov. 2012","","IEEE","IEEE Conference Publications"
"Word Spotting Based Retrieval of Urdu Handwritten Documents","A. Abidi; A. Jamil; I. Siddiqi; K. Khurshid","Nat. Univ. of Sci. & Technol., Islamabad, Pakistan","2012 International Conference on Frontiers in Handwriting Recognition","20130131","2012","","","331","336","Urdu being one of the most popular languages adopted during different swatches of history has a valuable collection of handwritten scripts in different state libraries of South Asia. Digitizing these collections can serve not only to preserve them but also to make them available to general public. Non existence of an Urdu OCR, however, limits the concept of a digital Urdu library to scanning and manual search of documents only. We present a word spotting based search method for Urdu handwritten text. The text is first segmented into partial words and a set of features is computed from each partial word. The user queries the system using word image. The partial words in the query image are then matched with those in the database and the matched partial words are merged into complete words. The proposed method evaluated on 90 handwritten documents reported encouraging precision and recall rates.","","Electronic:978-0-7695-4774-9; POD:978-1-4673-2262-1","10.1109/ICFHR.2012.289","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424415","Partial Words;Run length smoothing alogrithm;Urdu handwritten text detection","Feature extraction;Handwriting recognition;Image segmentation;Indexing;Libraries;Vectors","digital libraries;document image processing;handwritten character recognition;information retrieval;natural languages;optical character recognition","Urdu OCR;Urdu handwritten document;Urdu handwritten text;digital Urdu library;handwritten script;partial word;precision rate;query image;recall rate;word image;word spotting based retrieval","","3","","18","","","18-20 Sept. 2012","","IEEE","IEEE Conference Publications"
"Subjective similarity of music: Data collection for individuality analysis","S. Kawabuchi; C. Miyajima; N. Kitaoka; K. Takeda","Nagoya Univ., Nagoya, Japan","Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference","20130117","2012","","","1","5","We describe a method of estimating subjective music similarity from acoustic music similarity. Recently, there have been many studies on the topic of music information retrieval, but there continues to be difficulty improving retrieval precision. For this reason, in this study we analyze the individuality of subjective music similarity. We collected subjective music similarity evaluation data for individuality analysis using songs in the RWC music database, a widely used database in the field of music information processing. A total of 27 subjects listened to pairs of music tracks, and evaluated each pair as similar or dissimilar. They also selected the components of the music (melody, tempo/rhythm, vocals, instruments) that were similar. Each subject evaluated the same 200 pairs of songs, thus the individuality of the evaluation can be easily analyzed. Using the collected data, we trained individualized distance functions between songs, in order to estimate subjective similarity and analyze individuality.","","Electronic:978-0-6157-0050-2; POD:978-1-4673-4863-8","10.1121/1.4709083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6411779","","Feature extraction;Instruments;Measurement;Rhythm;Vectors","acoustic signal detection;acoustic signal processing;information retrieval;music","RWC music database;acoustic music similarity;data collection;individuality analysis;music information retrieval;subjective music similarity evaluation data","","0","","14","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Fine-grained Product Features Extraction and Categorization in Reviews Opinion Mining","S. Huang; X. Liu; X. Peng; Z. Niu","Sch. of Comput. Sci. &amp; Technol., Beijing Inst. of Technol., Beijing, China","2012 IEEE 12th International Conference on Data Mining Workshops","20130110","2012","","","680","686","With the growth of user-generated contents on the Web, product reviews opinion mining increasingly becomes a research practice of great value to e-commerce, search and recommendation. Unfortunately, the number of reviews is rising up to hundreds or even thousands, especially for some popular items, which makes it a laborious work for the potential buyers and the manufacturers to read through them to make a wise decision. Besides, the free format and the uncertainty of reviews expressions, make fine-grained product features extraction and categorization a more difficult task than traditional information extraction techniques. In this work, we propose to treat product feature extraction as a sequence labeling task and employ a discriminative learning model using Conditional Random Fields (CRFs) to tackle it. We innovatively incorporate the part-of-speech features and the sentence structure features into the CRFs learning process. For product feature categorization, we introduce the semantic knowledge-based and distributional context-based similarity measures to calculate the similarities between product feature expressions, then an effective graph pruning based categorizing algorithm is proposed to classify the collection of feature expressions into different semantic groups. The empirical studies have proved the effectiveness and efficiency of our approaches compared with other counterpart methods.","2375-9232;23759232","Electronic:978-1-4673-5164-5; POD:978-1-4799-1707-5","10.1109/ICDMW.2012.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406505","conditional random fields;extraction and categorization;product features;similarity calculation","Batteries;Context;Entropy;Feature extraction;Lenses;Semantics;Syntactics","data mining;decision making;electronic commerce;feature extraction;graph theory;information retrieval;knowledge based systems;learning (artificial intelligence);random processes","CRF learning process;conditional random fields;decision making;discriminative learning model;distributional context-based similarity measures;e-commerce;fine-grained product feature categorization;fine-grained product feature extraction;graph pruning based categorizing algorithm;part-of-speech features;product feature expression collection classification;product review opinion mining;semantic groups;semantic knowledge-based similarity measures;sentence structure features;sequence labeling task;user-generated contents","","3","","24","","","10-10 Dec. 2012","","IEEE","IEEE Conference Publications"
"Composer Classification in Symbolic Data Using PPM","A. D. D. C. Junior; L. V. Batista","Inst. de Mat. e Estatistica, Univ. de Sao Paulo, Sao Paulo, Brazil","2012 11th International Conference on Machine Learning and Applications","20130110","2012","2","","345","350","The aim of this work is to propose four methods for composer classification in symbolic data based on melodies making use of the Prediction by Partial Matching (PPM) algorithm, and also to propose data modeling inspired on psycho physiological aspects. Rhythmic and melodic elements are combined instead of using only melody or rhythm alone. The models consider the perception of pitch changing and note durations articulations then the models are used to classify melodies. On the evaluation of our approach, we applied the PPM method on a small set of monophonic violin melodies of five composers in order to create models for each composer. The best accuracy achieved was of 86%, which is relevant for a problem domain that by now can be considered classic in MIR.","","Electronic:978-0-7695-4913-2; POD:978-1-4673-4651-1","10.1109/ICMLA.2012.176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406817","PPM;melody;pattern;rhythm","Context;Context modeling;Data models;Databases;Pattern recognition;Physiology;Rhythm","data models;information retrieval;music;pattern classification;symbol manipulation","PPM algorithm;composer classification;data modeling;melodic elements;monophonic violin melodies;note duration articulations;pitch changing perception;prediction by partial matching algorithm;psychophysiological aspects;rhythmic elements;symbolic data","","1","","24","","","12-15 Dec. 2012","","IEEE","IEEE Conference Publications"
"UserProfile-based personalized research paper recommendation system","Kwanghee Hong; Hocheol Jeon; Changho Jeon","Dept. of Comput. Sci. &amp; Eng., Hanyang Univ., Seoul, South Korea","2012 8th International Conference on Computing and Networking Technology (INC, ICCIS and ICMIC)","20130124","2012","","","134","138","This paper proposed UserProfile-based PRPRS (Personalized Research Paper Recommendation System) and an algorithm for extracting keyword is designed and implemented by keyword extraction and keyword inference. Whenever collected research papers by topic are selected, a renewal of user profile increases the frequency of each Domain, Topic and keyword. Each ratio of occurrence is recalculated and reflected on UserProfile. PRPRS calculates the similarity between given topic and collected papers by using Cosine Similarity which is used to recommend initial paper for each topic in Information retrieval. We measured satisfaction and accuracy for each system-recommended paper to test and evaluated performances of the suggested system. Finally PRPRS represents high level of satisfaction and accuracy.","","Electronic:978-89-94364-18-6; POD:978-1-4673-1326-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418639","Personalization;Profile;Recommendation System","Abstracts;Crawlers;Information filters;Silicon","inference mechanisms;information retrieval;recommender systems;user interfaces","cosine similarity;information retrieval;keyword extraction;keyword inference;personalized research paper recommendation system;user profile renewal;userprofile-based PRPRS","","0","","20","","","27-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Leveraging natural language analysis of software: Achievements, challenges, and opportunities","L. Pollock","Dept. of Comput. &amp; Inf. Sci., Univ. of Delaware, Newark, DE, USA","2012 28th IEEE International Conference on Software Maintenance (ICSM)","20130110","2012","","","4","4","Summary form only given. Studies continue to report that more time is spent reading, locating, and comprehending code than actually writing code. The increasing size and complexity of software systems makes it significantly more challenging for humans to perform maintenance tasks on software without automated and semi-automated tools to support them, especially in the error-prone tasks. Thus, software engineers increasingly rely on software engineering tools to automate maintenance tasks as much as possible. The program analyses that drive today's software engineering tools have historically focused on analyzing the program's data and control flow, dependencies, and other structural information about the program to uncover and prove program properties. Yet, a software system is more than just the source code and its structure. To build effective software tools, the underlying automated analyses need to use all the information available to make the tools as intelligent and useful as possible. By adapting natural language processing (NLP) to source code analysis, and integrating information retrieval (IR), NLP, and traditional program analyses, we can expect significant improvement in automated and semi-automated software engineering tools for many different software engineering tasks. In this talk, I will overview research in text analysis of software and discuss our achievements to date, the challenges faced in text analysis, and the opportunities for text analysis of software in the future.","1063-6773;10636773","Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0","10.1109/ICSM.2012.6405245","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405245","","Computer science;Educational institutions;Maintenance engineering;Natural language processing;Software;Software engineering;Text analysis","information retrieval;natural language processing;program diagnostics;software maintenance;text analysis","IR;NLP;code comprehension;code location;code reading;code writing;error-prone task;information retrieval;natural language analysis;natural language processing;program analysis;software analysis;software engineering tool;software maintenance task;source code analysis;text analysis","","1","","","","","23-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Design and Development of Audit Central Data Bank at Ibiden Philippines, Inc. (IPI)","R. B. Caldo; R. Y. Yap","","TENCON 2012 IEEE Region 10 Conference","20130117","2012","","","1","6","In most of the companies in the Philippines, audit findings and results are monitored manually. This method offers inaccessible and unreliable data that invokes downtime in audit issuance, audit response, audit verification and implementation, and audit closure as well. It showcased a process system of less priority and consideration on Productivity, Quality, Cost, Delivery and Morale. The proponent thought of a way to develop a central repository or data bank of audit findings to easily retrieve the audits conducted by IQA, PQA, IEA, TPM and other auditing bodies and to provide robust monitoring of Audit Issuance, Audit Response, Audit Verification (Verification of Implementation) and Audit Closure (Verification of Effectiveness). Audit Central Data Bank in Ibiden Philippines, Inc. is a PC-based centralized macro program. It is software that consolidates all audit results of each auditing body (IQA, PQA, IEA, TPM, YIP and External Supplier). It performs common tasks and functions understood and applied by entire IPI community.","2159-3442;21593442","Electronic:978-1-4673-4824-9; POD:978-1-4673-4823-2","10.1109/TENCON.2012.6412269","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412269","Ibiden Philippines, Inc.;audit findings;consolidation;data bank;macro program","Companies;Environmental management;ISO standards;Monitoring;Software","auditing;bank data processing;information retrieval","IEA;IPI;IQA;Ibiden Philippines Inc;PC-based centralized macroprogram;PQA;TPM;audit central data bank design;audit central data bank development;audit closure;audit findings;audit implementation;audit issuance;audit response;audit results;audit retrieval;audit verification;central repository;cost;delivery;inaccessible data;morale;productivity;quality;robust monitoring;unreliable data;verification of effectiveness;verification of implementation","","0","","5","","","19-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"LINSEN: An efficient approach to split identifiers and expand abbreviations","A. Corazza; S. Di Martino; V. Maggio","Dipt. di Sci. Fis., Univ. of Naples &#x201C;Federico II&#x201D;, Naples, Italy","2012 28th IEEE International Conference on Software Maintenance (ICSM)","20130110","2012","","","233","242","Information Retrieval (IR) techniques are being exploited by an increasing number of tools supporting Software Maintenance activities. Indeed the lexical information embedded in the source code can be valuable for tasks such as concept location, clustering or recovery of traceability links. The application of such IR-based techniques relies on the consistency of the lexicon available in the different artifacts, and their effectiveness can worsen if programmers introduce abbreviations (e.g: rect) and/or do not strictly follow naming conventions such as Camel Case (e.g: UTFtoASCII). In this paper we propose an approach to automatically split identifiers in their composing words, and expand abbreviations. The solution is based on a graph model and performs in linear time with respect to the size of the dictionary, taking advantage of an approximate string matching technique. The proposed technique exploits a number of different dictionaries, referring to increasingly broader contexts, in order to achieve a disambiguation strategy based on the knowledge gathered from the most appropriate domain. The approach has been compared to other splitting and expansion techniques, using freely available oracles for the identifiers extracted from 24 C/C++ and Java open source systems. Results show an improvement in both splitting and expanding performance, in addition to a strong enhancement in the computational efficiency.","1063-6773;10636773","Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0","10.1109/ICSM.2012.6405277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405277","Expansion;Program Comprehension;Source Code Identifiers;Splitting","Approximation algorithms;Conferences;Context;Dictionaries;Software algorithms;Software maintenance","C++ language;Java;information retrieval;pattern clustering;public domain software;software maintenance","C-C++;IR-based techniques;Java open source systems;LINSEN;abbreviation expansion;approximate string matching technique;camel case;concept location;dictionary;disambiguation strategy;identifier splitting;information retrieval techniques;lexical information;oracles;software maintenance activities;traceability links clustering;traceability links recovery","","6","","20","","","23-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"High-performance scalable information service for the ATLAS experiment","S. Kolos; G. Boutsioukis; R. Hauser","University of California, Irvine, USA","2012 18th IEEE-NPSS Real Time Conference","20130124","2012","","","1","5","The ATLAS experiment is being operated by highly distributed computing system which is constantly producing a lot of status information which is used to monitor the experiment operational conditions as well as to assess the quality of the physics data being taken. For example the ATLAS High Level Trigger(HLT) algorithms are executed on the online computing farm consisting from about 1500 nodes. Each HLT algorithm is producing few thousands histograms, which have to be integrated over the whole farm and carefully analyzed in order to properly tune the event rejection. In order to handle such non-physics data the Information Service (IS) facility has been developed in the scope of the ATLAS Trigger and Data Acquisition (TDAQ) project. The IS provides high-performance scalable solution for information exchange in distributed environment. In the course of an ATLAS data taking session the IS handles about hundred gigabytes of information which is being constantly updated with the update interval varying from a second to few tens of seconds. IS provides access to any information item on request as well as distributing notification to all the information subscribers. In latter case IS subscribers receive information within few milliseconds after it was updated. IS can handle arbitrary types of information including histograms produced by the HLT applications and provides C++, Java and Python API. The Information Service is a primarily and in most cases a unique source of information for the majority of the online monitoring analysis and GUI applications, used to control and monitor the ATLAS experiment. Information Service provides streaming functionality allowing efficient replication of all or part of the managed information. This functionality is used to duplicate the subset of the ATLAS monitoring data to the CERN public network with the latency of few milliseconds, allowing efficient real-time monitoring of the data taking from outside the protected ATLAS network. Ea- h information item in IS has an associated URL which can be used to access that item online via HTTP protocol. This functionality is being used by many online monitoring applications which can run in a WEB browser, providing real-time monitoring information about ATLAS experiment over the globe. This paper will describe design and implementation of the IS and present performance results which have been taken in the ATLAS operational environment.","","Electronic:978-1-4673-1084-0; POD:978-1-4673-1082-6","10.1109/RTC.2012.6418091","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418091","","Information services;Message systems;Mirrors;Monitoring;Receivers;Servers;Software","C++ language;Internet;Java;application program interfaces;computerised monitoring;condition monitoring;data acquisition;data handling;graphical user interfaces;high energy physics instrumentation computing;information retrieval;online front-ends;real-time systems;transport protocols;trigger circuits","ATLAS HLT algorithms;ATLAS TDAQ project;ATLAS Trigger and Data Acquisition project;ATLAS experiment;ATLAS high level trigger algorithms;ATLAS monitoring data;C++;CERN public network;GUI applications;HTTP protocol;IS facility;Java API;Python API;URL;WEB browser;distributed computing system;experiment operational condition monitoring;high-performance scalable information service;information exchange;information service facility;information subscribers;nonphysics data handling;online computing farm;online information access;online monitoring analysis;physics data quality assessment;real-time data monitoring","","2","","4","","","9-15 June 2012","","IEEE","IEEE Conference Publications"
"Transcription of multi-genre media archives using out-of-domain data","P. J. Bell; M. J. F. Gales; P. Lanchantin; X. Liu; Y. Long; S. Renals; P. Swietojanski; P. C. Woodland","Centre for Speech Technology Research, University of Edinburgh, Edinburgh EH8 9AB, UK","2012 IEEE Spoken Language Technology Workshop (SLT)","20130131","2012","","","324","329","We describe our work on developing a speech recognition system for multi-genre media archives. The high diversity of the data makes this a challenging recognition task, which may benefit from systems trained on a combination of in-domain and out-of-domain data. Working with tandem HMMs, we present Multi-level Adaptive Networks (MLAN), a novel technique for incorporating information from out-of-domain posterior features using deep neural networks. We show that it provides a substantial reduction in WER over other systems, with relative WER reductions of 15% over a PLP baseline, 9% over in-domain tandem features and 8% over the best out-of-domain tandem features.","","Electronic:978-1-4673-5126-3; POD:978-1-4673-5125-6; USB:978-1-4673-5124-9","10.1109/SLT.2012.6424244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424244","cross-domain adaptation;media archives;speech recognition;tandem","Acoustics;Adaptation models;Hidden Markov models;Neural networks;Speech;Training;Training data","hidden Markov models;information retrieval systems;records management;speech recognition","MLAN;deep neural networks;hidden Markov model;in-domain tandem features;multigenre media archives transcription;multilevel adaptive networks;out-of-domain posterior features;relative WER reductions;speech recognition system;tandem HMM","","7","","22","","","2-5 Dec. 2012","","IEEE","IEEE Conference Publications"
"Prediction of risk score for heart disease using associative classification and hybrid feature subset selection","M. A. jabbar; P. Chandra; B. L. Deekshatulu","Aurora's Engineering College, Bhongir A.P, INDIA","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","628","634","Medical data mining is the search for relationships and patterns within the medical data that could provide useful knowledge for effective medical diagnosis. Extracting useful information from these data bases can lead to discovery of rules for later diagnosis tools. Generally medical data bases are highly voluminous in nature. If a training data set contains irrelevant and redundant features classification may produce less accurate results. Feature selection as a pre-processing step in used to reduce dimensionality, removing irrelevant data and increasing accuracy and improves comprehensibility. Associative classification is a recent and rewarding technique that applies the methodology of association into classification and achieves high classification accuracy. Most associative classification algorithms adopt exhaustive search algorithms like in Apriori, and generate huge no. of rules from which a set of high quality of rules are chosen to construct efficient classifier. Hence generating a small set of high quality rules to build classifier is a challenging task. Cardiovascular diseases are the leading cause of death globally and in India more deaths are due to CHD. Cardiovascular disease is an increasingly an important cause of death in Andhra Pradesh. Hence there is an urgent need to develop a system to predict the heart disease of people. This paper discusses prediction of risk score for heart disease in Andhra Pradesh. We generated class association rules using feature subset selection. These generated rules will help physicians to predict the heart disease of a patient.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416610","Andhra Pradesh;Associative classification;Feature subset selection;Genetic search;Heart disease","Accuracy;Association rules;Classification algorithms;Diseases;Genetics;Heart","cardiology;data mining;data reduction;diseases;feature extraction;information retrieval;medical diagnostic computing;pattern classification","Andhra Pradesh;CHD;India;associative classification algorithms;cardiovascular diseases;comprehensibility improvement;dimensionality reduction;heart disease prediction;hybrid feature subset selection;information extraction;irrelevant data removal;medical data bases;medical data mining;medical diagnosis;risk score prediction;rules discovery;search algorithms;training data set","","5","","24","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"GRADE: Graceful Degradation in Byzantine Quorum Systems","J. Lin; B. Luo; J. Jing; X. Zhang","State Key Lab. of Inf. Security, Inst. of Inf. Eng., Beijing, China","2012 IEEE 31st Symposium on Reliable Distributed Systems","20130131","2012","","","171","180","Distributed storage systems are expected to provide correct services in the presence of Byzantine failures, which do not have any assumptions about the behavior of faulty servers and clients. In designing such systems, we often encounter the paradox of fault tolerance vs. performance (or efficiency), because better fault tolerance usually requires a tradeoff of system performance. In this paper, we present GRADE, a Byzantine-fault-tolerant (BFT) distributed storage system that enables graceful degradation. Two Byzantine quorum systems (BQSs) are supported on each GRADE server: a masking BQS storing generic data and a dissemination BQS storing self-verifying ones. Based on the system status and the environment, servers dynamically and seamlessly switch between two BQSs, without converting the stored data. Therefore, GRADE provides high performance in a normal running-state, and degrades performance to maintain high fault tolerance in emergency situations. The computation and communication costs of the running-state switch are very low, and the switch is completely transparent to clients. Our performance analysis and experimental results demonstrate that GRADE provides a balance between performance and fault tolerance.","1060-9857;10609857","Electronic:978-0-7695-4784-8; POD:978-1-4673-2397-0","10.1109/SRDS.2012.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424851","Byzantine fault tolerance;Byzantine quorum system;graceful degradation;storage","Fault tolerance;Fault tolerant systems;Frequency modulation;Protocols;Registers;Servers;Switches","distributed databases;emergency services;failure analysis;fault tolerance;file servers;information dissemination;information retrieval systems","BFT distributed storage system;BQS;BQS storing generic data masking;Byzantine failures;Byzantine quorum systems;Byzantine-fault-tolerant distributed storage system;GRADE server;communication costs;data storage;dissemination BQS storing self-verification;dynamically servers;emergency situations;fault tolerance maintenance;faulty servers;graceful degradation;performance analysis;running-state switch","","0","","31","","","8-11 Oct. 2012","","IEEE","IEEE Conference Publications"
"A novel wavelet based no-search fractal image compression algorithm: How to use the landscape properties","M. Mobasher; M. H. Tayarani-N; M. Beheshti","","2011 1st International eConference on Computer and Knowledge Engineering (ICCKE)","20130117","2011","","","120","125","Fractal Image Compression (FIC) problem is a combinatorial optimization problem which has recently become one of the most promising encoding technologies in the generation of compressed images. In order to exploit the information laid in Discrete Wavelet Transform (DWT) coefficients of the images, this paper proposes a novel wavelet based FIC method to both speed up the compression process and retain the quality of the retrieved images. In the proposed algorithm at first the wavelet coefficients of the image are extracted. Then according to the wavelet coefficients of the range blocks the search strategy for each range block is determined. For smooth blocks a no-search algorithm is applied. For the horizontal and vertical edges, if the no-search algorithm does not provide an appropriate result, the wavelet based search algorithm starts its search process. For vertical range blocks, just the vertical domain blocks and for horizontal range blocks, just the horizontal and for orthogonal range blocks just the orthogonal domain blocks are considered for the search process. In order to explain how such an algorithm works, some statistical analysis on the landscape of fractal image compression problem is performed on 8 different pictures with different textures. The proposed algorithm is compared with the GA-based and original version of fractal image compression algorithms and experimental results show improvement both in speed and the quality of the decoded images.","","Electronic:978-1-4673-5713-5; POD:978-1-4673-5712-8","10.1109/ICCKE.2011.6413337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413337","","Algorithm design and analysis;Correlation;Equations;Fractals;Image coding;Wavelet domain;Wavelet transforms","combinatorial mathematics;data compression;discrete wavelet transforms;feature extraction;fractals;image coding;image texture;information retrieval;optimisation;search problems;statistical analysis","DWT coefficients;combinatorial optimization problem;discrete wavelet transform coefficients;encoding technology;horizontal range blocks;image quality;image retrieval;image texture;landscape property;orthogonal domain blocks;orthogonal range blocks;smooth blocks;statistical analysis;vertical domain blocks;vertical range blocks;wavelet coefficient extraction;wavelet-based FIC method;wavelet-based no-search fractal image compression algorithm","","0","","27","","","13-14 Oct. 2011","","IEEE","IEEE Conference Publications"
"A Multi-label and Adaptive Genre Classification of Web Pages","C. Jebari; M. A. Wani","Comput. Sci. Dept., Fac. of Sci. of Tunis, Tunis, Tunisia","2012 11th International Conference on Machine Learning and Applications","20130110","2012","1","","578","581","This paper proposes a new centroid-based approach to classify web pages by genre using character ngrams extracted from different information sources such as URL, title, headings and anchors. To deal with the complexity of web pages and the rapid evolution of web genres, our approach implements a multi-label and adaptive classification scheme in which web pages are classified one by one and each web page can affect more than one genre. According to the similarity between the new page and each genre centroid, our approach either adapts the genre centroid under consideration or considers the new page as noise page and discards it. The experiment results show that our approach is very fast and achieves better results than existing multi-label classifiers.","","Electronic:978-0-7695-4913-2; POD:978-1-4673-4651-1","10.1109/ICMLA.2012.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406627","Multi-label;adaptive;centroid;classification;genre","Classification algorithms;Complexity theory;Data mining;Search engines;Training;Vectors;Web pages","Web sites;classification;information retrieval","URL;Web genre;Web page classification;adaptive genre classification scheme;anchors;character ngram;genre centroid;headings;information source extraction;multilabel genre classification scheme;noise page;title","","1","","10","","","12-15 Dec. 2012","","IEEE","IEEE Conference Publications"
"A Quantitative Comparison of Reactive and Proactive Replicated Storage Systems","R. Motta; J. Pasquale","Dept. of Comput. Sci. & Eng., Univ. of California, La Jolla, La Jolla, CA, USA","2012 IEEE 31st Symposium on Reliable Distributed Systems","20130131","2012","","","384","389","Replicated storage systems allow their stored data objects to outlive the life of the nodes storing them through replication. In this paper, we focus on durability, and more specifically on the concept of an object's lifetime, i.e., the duration of time between the creation of an object and when it is permanently irretrievable from the system. We analyze two main replication strategies: reactive, in which replication occurs in response to failures, and proactive, in which replication occurs in anticipation of failures. Our work presents a quantitative analysis that compares reactive and proactive through analytical models and simulations, considering exponentially distributed failures and reactive repairs, and periodic proactive replications. We also present a derivation of the analytical formula for the variance of the lifetime in the reactive model. Our results indicate that a proactive strategy leads to multiple times higher storage requirements than a reactive strategy. In addition, reactive systems are only moderately bursty in terms of bandwidth consumption, with rare peaks of at most five times the bandwidth consumption in proactive systems (given input parameter values that are compatible with real systems). Finally, for both strategies, the standard deviation is very close to the expected lifetime, and consequently, the lifetimes close to being exponentially distributed.","1060-9857;10609857","Electronic:978-0-7695-4784-8; POD:978-1-4673-2397-0","10.1109/SRDS.2012.1","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424879","Distributed;Replicated;Storage","Analytical models;Availability;Bandwidth;Dispersion;Histograms;Maintenance engineering;Standards","failure analysis;information retrieval systems;replicated databases","bandwidth consumption;exponentially distributed failures;failure response;failures anticipation;object creation;periodic proactive replication strategies;proactive replicated storage systems;reactive repairs;reactive replication strategies;reactive systems;standard deviation;storage requirements;system irretrievable","","0","","15","","","8-11 Oct. 2012","","IEEE","IEEE Conference Publications"
"EigenSP: A More Accurate Shortest Path Distance Estimation on Large-Scale Networks","K. Maruhashi; J. Shigezumi; N. Yugami; C. Faloutsos","","2012 IEEE 12th International Conference on Data Mining Workshops","20130110","2012","","","234","241","Estimating the distances of the shortest path between given pairs of nodes in a graph is a basic operation in a wide variety of applications including social network analysis, web retrieval, etc. Such applications require a response on the order of a few milliseconds, but exact algorithms to compute the distance of the shortest path exactly do not work on real-world large-scale networks, because of their infeasible time complexities. The landmark-based methods approximate distances by using a few nodes as landmarks, and can accurately estimate shortest-path distances with feasible time complexities. However, they fail at estimating small distances, as it is difficult for a few selected landmarks to cover the shortest paths of many close node pairs. To tackle this problem, we present a novel method EigenSP, that estimates the shortest-path distance by using an adjacency matrix approximated by a few eigenvalues and eigenvectors. The average relative error rate of EigenSP is lower than that of the landmark-based methods on large graphs with many short distances. Empirical results suggest that EigenSP estimates small distances better than the landmark-based methods.","2375-9232;23759232","Electronic:978-1-4673-5164-5; POD:978-1-4799-1707-5","10.1109/ICDMW.2012.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406446","eigenvalues and eigenvectors;large scale network;shortest path distance","Approximation algorithms;Approximation methods;Eigenvalues and eigenfunctions;Equations;Error analysis;Estimation","Internet;approximation theory;estimation theory;graph theory;information retrieval;matrix algebra;social networking (online)","EigenSP;EigenSP method;Web retrieval;adjacency matrix;landmark based methods approximate distances;large-scale networks;more accurate shortest path distance estimation;social network analysis","","0","","30","","","10-10 Dec. 2012","","IEEE","IEEE Conference Publications"
"User Centric Retrieval of Learning Objects in LMS","A. S. Sabitha; D. Mehrotra","Dept. of CS &amp; IT, Krishna Eng. Coll., Ghaziabad, India","2012 Third International Conference on Computer and Communication Technology","20130110","2012","","","14","19","Research and Academic Institutions own and archive a great number of documents like lesson plan, study material and research related resources, which are needed to be stored and used over for a longer period of time by lecturers and researchers. In order to achieve this it is required to convert these educational resources into Learning Objects and store them in structured & meaningful way via a learning management system (LMS) thus enriching classical teaching. Also with enhancement of e-learning environment there is a great need of managing the LMS repositories by storing information resources as Learning object, a digital entity which can be used in electronic learning environment. These learning objects are stored in repositories and are managed by Learning Management Systems. It aids teaching and learning process and helps in communications between users. Many designs of LMS are non user-centric and has limited capabilities in delivering user preferred learning material. Searching through keywords or metadata of learning material will result in display of huge quantity of information. Thus there is an earnest need to identify the techniques that can provide more efficient mechanism for information retrieval. Recommendation techniques have shown to be successful in many domains (e.g. movies, books, music, etc.). Thus there is a need to deploy a recommending system in the E-Learning domain to extend the functionality of standard-based learning management systems with providing the user based retrieval. In this paper a model is being proposed that can enhance the search and delivery of a relevant learning object based on his/her preferences and further ranking & clustering of learning objects are done through K-Mean and Self Organising Maps for a personalised learning environment.","","Electronic:978-0-7695-4872-2; POD:978-1-4673-3149-4","10.1109/ICCCT.2012.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394660","Clustering;K-mean;Learning Objects (LO);Quality Metrics;Ranking;Self Organizing Map","Data mining;Electronic learning;Least squares approximation;Measurement;Search problems;Standards","computer aided instruction;educational institutions;information resources;information retrieval;pattern clustering;recommender systems;self-organising feature maps;teaching","LMS;academic institutions;classical teaching;e-learning environment;educational resources;electronic learning environment;information resources;information retrieval;k-mean clustering;learning material;learning object clustering;learning object ranking;learning process;lesson plan;personalised learning environment;recommendation techniques;recommending system;research institutions;self organising maps;standard-based learning management systems;study material;user based retrieval;user centric retrieval","","3","","36","","","23-25 Nov. 2012","","IEEE","IEEE Conference Publications"
"Personalized Information Gathering System Based on Micromedia","M. Sawada; T. Toda","Dept. of Electr. Eng., Nihon Univ., Tokyo, Japan","2012 IEEE First International Conference on Internet Operating Systems","20130131","2012","","","9","12","Even as the sheer volume of information on the Web continues to expand, not everyone is able to find the information they seek using the conventional search methods available. Here we propose a solution in the form of a system that first assesses a user's circumstances and preferences in real time based on micromedia comments posted to the Web, then infers and recommends information desired by the user. Using content analysis focused on objects and predicates used in micromedia comments posted on Twitter, blogs, and social network services (SNSs), the system builds a user profile by monitoring and storing information relating to the user's circumstances and experiences. Search terms are then extracted based on the user's profile, which provides personalized search and search results.","","Electronic:978-0-7695-4936-1; POD:978-1-4673-5092-1","10.1109/ICIOS.2012.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424524","Behavioral targeting;Recommended Information;Semantic WEB;collaborative filtering","Blogs;Google;History;Search problems;Semantic Web;Twitter;Web pages","Internet;information retrieval;social networking (online)","SNS;Twitter;Web;blogs;content analysis;conventional search methods;micromedia comments;personalized information gathering system;social network services;user circumstance;user preference;user profile","","0","","10","","","10-12 Dec. 2012","","IEEE","IEEE Conference Publications"
"Truthful auction mechanism design for short-interval secondary spectrum access market","Shun-Cheng Zhan; Shi-Chung Chang; P. B. Luh; Hao-Huai Lieu","Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan","2012 12th International Conference on ITS Telecommunications","20130131","2012","","","140","145","With the emergence of dynamic spectrum access technology and quick growth in demands for broadband mobile access, exploitation of short-interval spectrum availability offers an opportunity to better utilize spectrum. A short-interval secondary spectrum (SiSS) market is proposed in this paper, where a Mobile Network Operator (MNO) rents out multiple units of homogeneous spectrum units to Mobile Virtual Network Operators (MVNO) on a short-interval basis via a SiSS broker. The mandated SiSS broker not only presides over the trading but also manages an online database which is significant to the communication between MNO and MVNOs. For the purpose of efficient trading, we adopt the Vickrey-Clarke-Groves (VCG) auction as the basis to design a truthful SiSS auction. There are a few innovations. The first is a highly expressive cumulative bidding format, which allows maximum bidding options to MVNOs and eliminates the need for iterative bid refinement. The second is incremental bid constraint with reserve price to ensure bid per unit higher than the reserve price. Thirdly, an iterative allocation and payment calculation is so designed that per unit payments of winning MVNOs are higher than the reserve price set by MNO while maintaining the VCG merit of truthful bidding. A rational MNO is thus incentivized to put lowly utilized spectrum units for rent. Preliminary numerical experimentation demonstrates that the truthful SiSS auction generates to MNO in average 23% higher revenue per spectrum unit than the VCG auction. Computation time for broker to clear the auction is within 10 seconds for up to 50 bidders and 200 spectrum units, which suits SiSS applications.","","DVD:978-1-4673-3068-8; Electronic:978-1-4673-3070-1; POD:978-1-4673-3071-8","10.1109/ITST.2012.6425152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425152","MNO;MVNO;SiSS market;VCG-based auction;broker;cumulative bidding format;incremental bid constraint;iterative allocation;reserve price;revenue deficiency;truthful","Availability;Educational institutions;Indexes;Mobile communication;Mobile computing;Resource management;Standards","broadband networks;commerce;information retrieval systems;iterative methods;mobile radio","MVNO;SiSS broker;SiSS market;VCG merit;Vickrey-Clarke-Groves;bid refinement;broadband mobile access;dynamic spectrum access technology;high expressive cumulative bidding format;iterative allocation;mobile virtual network operators;online database;payment calculation;short-interval secondary spectrum access market;truthful auction mechanism design","","0","","15","","","5-8 Nov. 2012","","IEEE","IEEE Conference Publications"
"Research of FTP Search Engine Indexing Technology Based on Kademlia Model","X. m. Shi; K. j. Liu","Sch. of Math. &amp; Comput. Eng., Xihua Univ., Chengdu, China","2012 International Conference on Control Engineering and Communication Technology","20130117","2012","","","278","282","By Kademlia algorithm of the P2P network analysis and discussion, In this paper, it mainly puts forward an indexing algorithm which integrates the resource location information and combines with the structure characteristics of the distribution resources of FTP site and its file name features in a peer-to-peer network environment. Theoretical analysis and simulation result show that improved algorithm can accelerate resource locating speed and improve retrieval accuracy of distributed FTP search engine.","","Electronic:978-0-7695-4881-4; POD:978-1-4673-4499-9","10.1109/ICCECT.2012.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6414103","FTP search engine;Kademlia;P2P","Algorithm design and analysis;IP networks;Indexing;Peer to peer computing;Routing;Search engines","indexing;information retrieval;peer-to-peer computing;search engines","FTP search engine;FTP site;Kademlia model;P2P network analysis;file transfer protocol;indexing algorithm;peer-to-peer network;resource locating speed;resource location information;search engine indexing technology;search engine retrieval accuracy","","1","","13","","","7-9 Dec. 2012","","IEEE","IEEE Conference Publications"
"Using linkage information to improve the detection of relevant comment in social media","R. Thammasudjarit; C. Pleumpitiwiriyawej","Fac. of Inf. &amp; Commun. Technol., Mahidol Univ., Nakhonpathom, Thailand","2012 Tenth International Conference on ICT and Knowledge Engineering","20130110","2012","","","71","76","The vector space retrieval model relies on the notion of each comment is independence where the keywords influence to the document topic. However, such notion might not fit enough in the social media document called `comment'. In social media comment, the occurrence of keywords does not guarantee the topic relevancy. Moreover, the absence of keywords does not guarantee the topic non-relevancy. These circumstances effect to the model accuracy because the social media language is relatively informal. Thus, people do not necessary to strict with the word usage in the proper meaning with respect to the conventional dictionary. We use the linkage information to create an augmented algorithm which improves the accuracy of the vector space retrieval model. Our experiment shows that our algorithm enhances the accuracy of the traditional vector space retrieval.","2157-0981;21570981","Electronic:978-1-4673-2317-8; POD:978-1-4673-2316-1","10.1109/ICTKE.2012.6408574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6408574","Comment dependency;Linkage information;Social media;Text-chat behavioral-based synonym;Text-chat behavioral-based wordsense ambiguity","Companies;Computational linguistics;Consumer electronics;Context;Couplings;Electronic publishing;Media","dictionaries;information retrieval;relevance feedback;social networking (online);text analysis;word processing","augmented algorithm;dictionary;informal social media language;keywords;linkage information;relevant comment detection improvement;social media comment;social media document topic nonrelevancy;social media document topic relevancy;vector space retrieval model accuracy improvement;word usage","","0","","24","","","21-23 Nov. 2012","","IEEE","IEEE Conference Publications"
"A Methodology for Exploiting Oceans of Data within Territorial Dynamic Applications","J. Legrand; F. Rousseaux; E. Soulier; F. Bugeaud; P. Saurel; H. Neffati","Univ. Paris 2, Paris, France","2012 Second International Workshop on Advanced Information Systems for Enterprises","20130114","2012","","","78","84","The current approaches aiming at collective intelligence modelling often rely on traditional methods (ontologies, graphs). Even if those traditional methods may have reached their limitations, fin front of demanding emerging practices. The major conceptual tools enrolled for current and future Web are deeply rooted in the information storage and retrieval practices. The focus is on developing more original technologies for capturing, analyzing, exploiting and visualizing data. The agencements and the arrangements provide the appropriate epistemological context of our contribution. The simplicial complexes are the mathematical support of the methodology. The result is a shift from networks studied towards graph theory to higher dimensional networks structures. The representation is more than graphs, or even hyper graphs. A geometric perspective shows the arrangement as assembling polyhedra of all sizes. Their contacts can form chains of adjacencies. It not only generalized the notion of path graphs but also made available a range of quantitative and qualitative tools on the structure. Thus, the separate parts, more or less strongly linked, and the length of paths to traverse, and even loops or ""missing parts"", are meaningful metadata representations.","","Electronic:978-0-7695-4845-6; POD:978-1-4673-4791-4","10.1109/IWAISE.2012.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6410103","agencement;arrangement;dynamic knowledge;emerging knowledge;simplicial complex","Abstracts;Biological system modeling;Communities;Graph theory;Ontologies;Semantics;Topology","data analysis;data visualisation;graph theory;information retrieval;information storage;meta data","collective intelligence modelling;data analysis;data visualization;epistemological context;graph theory;hypergraphs;information retrieval practices;information storage practices;mathematical support;metadata representations;path graphs;polyhedra assembling;territorial dynamic applications","","0","","26","","","10-12 Nov. 2012","","IEEE","IEEE Conference Publications"
"Knowing a Good Show When You See One","J. Lanagan","Technicolor, Cesson-Sevigne, France","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","215","219","Social media has become an integral part of the web, and its popularity continues to provide an outlet for people's opinions and discussion about any topic of interest. In this paper we examine the interest around a number of television series that are broadcast on a weekly basis. Our aim is to show that by observing solely the initial interactions of fans or users of a web forum, we can extrapolate the longer-term interest in particular episodes. We do so by observing the temporal dynamics of the conversation, and performing a clustering so as to judge how much time is required before reasonable conclusions can be drawn about the level of interest surrounding an episode. We find that early interaction trends have strong similarities with the overall conversation patterns.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425760","Clustering;Time Series;Web Forums","Fans;Indexes;Market research;Media;Shape;TV;Time series analysis","extrapolation;human computer interaction;information retrieval;social networking (online);television broadcasting","Web forum;discussion;extrapolation;people opinion;social media;television series broadcasting;temporal dynamics;user interaction","","0","","12","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Discovering emerging topic about the East Japan Great Earthquake in video sharing website","T. Hashimoto; T. Kuboyama; B. Chakraborty; Y. Shirota","Commerce &amp; Econ., Chiba Univ. of Commerce, Chiba, Japan","TENCON 2012 IEEE Region 10 Conference","20130117","2012","","","1","6","Once a disaster occurs, people discuss various topics in social media such as electronic bulletin boards, SNSs and video sharing website, and their decision-making tends to be affected by discussions in social media. Under this circumstances, a mechanism to detect topics in social media has become important. This paper targets the East Japan Great Earthquake, and proposes a method for topic discovering from the emergent time series. In this paper, our proposed method analyzes user comments in video sharing websites, and adopts directed graphs to show topic structures in social media. Then clusters are formed using modularity measure which expresses the quality of division of a network into modules or communities. Topic structures are visualized dynamically, so that we can understand emerging topics easily. An experimental result using actual user comments in the video sharing website is shown as well.","2159-3442;21593442","Electronic:978-1-4673-4824-9; POD:978-1-4673-4823-2","10.1109/TENCON.2012.6412324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412324","Computational Intelligence;Data Mining;Graph-based Analysis;Social Media Analysis;Web Mining","Communities;Data visualization;Earthquakes;Educational institutions;Media;Time series analysis;Visualization","Internet;data mining;data visualisation;directed graphs;disasters;earthquakes;geophysics computing;human computer interaction;information retrieval;social networking (online);time series;user interfaces","East Japan Great Earthquake;SNS;Web mining;data mining;decision-making;directed graphs;electronic bulletin boards;emerging topic discovery;modularity measure;social media;social networking sites;time series;topic structures;user comments;video sharing Web site","","0","","15","","","19-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"Ensuring correctness of range searches on encrypted cloud data","F. K. Tseng; Y. H. Liu; R. J. Chen","Department of Computer Science National Chiao-Tung University Hsinchu, Taiwan","4th IEEE International Conference on Cloud Computing Technology and Science Proceedings","20130204","2012","","","570","573","We target at one newly introduced security concern which is not fully addressed when moving (encrypted) data to the cloud, namely, the security of the search results from the cloud. The cloud storage provider (CSP) might be compromised or simply act maliciously for their own good, which yields incorrect search results. In this paper, we exploit hidden vector encryption to tackle this important security problem. Our construction enables CSPs to provide a proof of the search results to be verified later by the cloud storage users. In particular, this proposed scheme handles equality and range searches on encrypted data. Users can verified the correctness of the search results without decrypting for the corresponding file contents. Any tampering with the search results by CSPs will be caught, while any incorrect charge against CSPs for tampering search results can be rectified. Finally, we present extensive security and performance analysis to show the security and practicality of our scheme.","","Electronic:978-1-4673-4510-1; POD:978-1-4673-4511-8; USB:978-1-4673-4509-5","10.1109/CloudCom.2012.6427558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427558","cloud computing;cloud storage;correctness of search result;hidden vector encryption;range search","Authentication;Cloud computing;Encryption;Radiation detectors;Vectors","cloud computing;cryptography;information retrieval;storage management","CSP;cloud data encryption;cloud storage provider;cloud storage user;hidden vector encryption;search result tampering;security","","1","","9","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Enhanced approach for latent semantic indexing using wavelet transform","T. Jaber; A. Amira; P. Milligan","Fac. of Comput. & Inf. Technol., King Abdulaziz Univ., Jeddah, Saudi Arabia","IET Image Processing","20130110","2012","6","9","1236","1245","Latent semantic indexing (LSI) is a technique used for intelligent information retrieval (IR). It can be used as an alternative to traditional keyword matching IR and is attractive in this respect because of its ability to overcome problems with synonymy and polysemy. This study investigates various aspects of LSI: the effect of the Haar wavelet transform (HWT) as a preprocessing step for the singular value decomposition (SVD) in the key stage of the LSI process; and the effect of different threshold types in the HWT on the search results. The developed method allows the visualisation and processing of the term document matrix, generated in the LSI process, using HWT. The results have shown that precision can be increased by applying the HWT as a preprocessing step, with better results for hard thresholding than soft thresholding, whereas standard SVD-based LSI remains the most effective way of searching in terms of recall value.","1751-9659;17519659","","10.1049/iet-ipr.2011.0498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6407283","","","Haar transforms;information retrieval;singular value decomposition;wavelet transforms","Haar wavelet transform;intelligent information retrieval;keyword matching IR;latent semantic indexing;polysemy problem;preprocessing step;singular value decomposition;synonymy problem;term document matrix;visualisation","","1","","","","","December 2012","","IET","IET Journals & Magazines"
"Exploiting the Semantic Web for unsupervised spoken language understanding","L. Heck; D. Hakkani-Tür","Microsoft Research","2012 IEEE Spoken Language Technology Workshop (SLT)","20130131","2012","","","228","233","This paper proposes an unsupervised training approach for SLU systems that leverages the structured semantic knowledge graphs of the emerging Semantic Web. The approach creates natural language surface forms of entity-relation-entity portions of knowledge graphs using a combination of web search retrieval and syntax-based dependency parsing. The new forms are used to train an SLU system in an unsupervised manner. This paper tests the approach on the problem of intent detection, and shows that the unsupervised training procedure matches the performance of supervised training over operating points important for commercial applications.","","Electronic:978-1-4673-5126-3; POD:978-1-4673-5125-6; USB:978-1-4673-5124-9","10.1109/SLT.2012.6424227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424227","intent detection;semantic web;spoken language understanding;structured knowledge-based search","Companies;Detectors;Knowledge based systems;Motion pictures;Semantic Web;Semantics;Training","Web sites;entity-relationship modelling;graph theory;information retrieval;natural language processing;semantic Web;unsupervised learning","SLU systems;Web search retrieval;entity-relation-entity portions;intent detection;knowledge graphs;natural language surface;semantic Web;structured semantic knowledge graphs;syntax-based dependency parsing;unsupervised spoken language understanding;unsupervised training approach;unsupervised training procedure","","17","4","17","","","2-5 Dec. 2012","","IEEE","IEEE Conference Publications"
"The Tag Navigation recommendation with adaptive learning method","W. Jiang; X. l. Pang","Sch. of Manage., Harbin Inst. of Technol., Harbin, China","2012 International Conference on Management Science & Engineering 19th Annual Conference Proceedings","20130117","2012","","","46","52","Social Tags are widely used in web 2.0, and they bring the new chance and challenge to the recommender system, which is used to help users deal with information overload and provide personalized services. There are three respects of work done in this paper: firstly, the n-gram based Tag Navigation is presented to provide the assistant support for tag retrieval; secondly, the Average Mutual Information based tag similarity measure is detailed, furthermore this kind of semantic relation is applied to the retrieval intention expansion; thirdly, an approach of ranking based recommendation is presented, and the adaptive learning mechanism is explored. The experiments verify above methods, and result shows the complex features adopted in the recommendation bring improvement by 13.39%.","2155-1847;21551847","Electronic:978-1-4673-3014-5; POD:978-1-4673-3015-2","10.1109/ICMSE.2012.6414159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6414159","Average Mutual Information;Tag Navigation;adaptive learning algorithm;personal recommendation;retrieval intention expansion","Collaboration;Equations;Frequency measurement;Mathematical model;Mutual information;Navigation;Recommender systems","information retrieval;learning (artificial intelligence);recommender systems;social networking (online)","Web 2.0;adaptive learning method;average mutual information;n-gram based tag navigation;personalized services;recommender system;retrieval intention expansion;social tags;tag navigation recommendation;tag retrieval;tag similarity measure","","0","","22","","","20-22 Sept. 2012","","IEEE","IEEE Conference Publications"
"Present status of the ITER real-time Plasma Control System development","A. Winter; P. Makijarvi; S. Simrock; J. Snipes; A. Wallander; L. Zabeo","ITER Organization, Route de Vinon-sur-Verdon, 13115 St. Paul Lez Durance, France","2012 18th IEEE-NPSS Real Time Conference","20130124","2012","","","1","6","ITER will be the world's largest magnetic confinement tokamak fusion device and is currently under construction in southern France. The ITER Plasma Control System (PCS) is a fundamental component of the ITER Control, Data Access and Communication system (CODAC). It will control the evolution of all plasma parameters that are necessary to operate ITER throughout all phases of the discharge. The design and implementation of the PCS poses a number of unique challenges. The timescales of phenomena to be controlled spans three orders of magnitude, ranging from a few milliseconds to seconds. Novel control schemes, which have not been implemented at present-day machines need to be developed, and control schemes that are only done as demonstration experiments today will have to become routine. In addition, advances in computing technology and available physics models make the implementation of real-time or faster-than-real-time calculations to forecast and subsequently to avoid disruptions or undesired plasma regimes feasible. A further novel feature is a sophisticated event handling system, which provides a means to deal with plasma related events (such as MIlD instabilities or LH transitions) or component failure. Finally, the schedule for design and implementation poses another unique challenge. The beginning of ITER operation will be in late 2020, but the conceptual design activity has already commenced as required by the on-going development of diagnostics and actuators in the domestic agencies and the need for integration and testing. In this paper, an overview about the functional requirements for the plasma control system will be given. The main focus will be on the requirements and possible options for a real-time framework for ITER and its interfaces to other ITER CODAC systems (networks, other applications, etc.). The limited amount of commissioning time foreseen for plasma control will make extensive testing and validation necessary. This should be done in an - nvironment that is as close to the PCS version running the machine as possible. Furthermore, the integration with an Integrated Modeling Framework will lead to a versatile tool that can also be employed for pulse validation, control system development and testing as well as the development and validation of physics models. An overview of the requirements and possible structure of such an environment will also be presented.","","Electronic:978-1-4673-1084-0; POD:978-1-4673-1082-6","10.1109/RTC.2012.6418097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418097","","Safety;Schedules","Tokamak devices;actuators;control engineering computing;control system synthesis;discharges (electric);fusion reactor design;fusion reactor operation;information retrieval;physical instrumentation control;plasma diagnostics;plasma instability;plasma magnetohydrodynamics;plasma toroidal confinement;real-time systems","ITER CODAC systems;ITER operation;ITER real-time framework;ITER real-time plasma control system;L-H transitions;MHD instabilities;PCS design;communication system;component failure;computing technology;data access;design activity;discharge phases;domestic agencies;event handling system;integrated modeling framework;magnetic confinement tokamak fusion device;novel control schemes;plasma parameters;plasma regimes;real-time calculations;southern France","","4","","13","","","9-15 June 2012","","IEEE","IEEE Conference Publications"
"Personalized music emotion recognition via model adaptation","J. C. Wang; Y. H. Yang; H. M. Wang; S. K. Jeng","Dept. of Electr. Eng., Nat. Taiwan Univ., Taipei, Taiwan","Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference","20130117","2012","","","1","7","In the music information retrieval (MIR) research, developing a computational model that comprehends the affective content of music signal and utilizes such a model to organize music collections have been an essential topic. Emotion perception in music is in nature subjective. Consequently, building a general emotion recognition system that performs equally well for every user could be insufficient. In contrast, it would be more desirable for one's personal computer/device being able to understand his/her perception of music emotion. In our previous work, we have developed the acoustic emotion Gaussians (AEG) model, which can learn the broad emotion perception of music from general users. Such a general music emotion model, called the background AEG model in this paper, can recognize the perceived emotion of unseen music from a general point of view. In this paper, we go one step further to realize the personalized music emotion modeling by adapting the background AEG model with a limited number of emotion annotations provided by a target user in an online and dynamic fashion. A novel maximum a posteriori (MAP)-based algorithm is proposed to achieve this in a probabilistic framework. We carry out quantitative evaluations on a well-known emotion annotated corpus, MER60, to validate the effectiveness of the proposed method for personalized music emotion recognition.","","Electronic:978-0-6157-0050-2; POD:978-1-4673-4863-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6411797","","Adaptation models;Computational modeling;Emotion recognition;Feature extraction;Music;Vectors","audio databases;electronic music;emotion recognition;information retrieval;music","MAP-based algorithm;MER60;MIR research;acoustic emotion Gaussians model;affective content;background AEG model;broad emotion perception;emotion annotated corpus;emotion annotations;general music emotion model;maximum a posteriori;model adaptation;music collections;music information retrieval;personalized music emotion recognition;probabilistic framework","","1","","29","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Separation of text from non-text doodles of poet Rabindranath Tagore's manuscripts","B. B. Chaudhuri; A. Saraf; A. Kumari; S. Borah; A. Goyal","C.V.P.R. Unit, Indian Stat. Inst., Kolkata, India","2012 NATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION SYSTEMS","20130117","2012","","","1","5","As gaining popularity of internet facilities have given a convenient and faster approach to mine a warehouse of both historical and contemporary handwritten documents; this has led to a continuous research and development in the field of information retrieval algorithm. In such handwritten documents, graphics and images are combined with text and often overlap one another. This paper presents a technique for separating textual data from non-textual information. The technique is based on some already published works. It is implemented in poet Rabindranath Tagore's manuscript. The approach generates connected components as basic primitive and tries to classify them as text or non-text based on a comparison between the total number of pixels and the number of boundary pixels constituting the component. A window is generated and further separation is done on the basis of the stroke width computed for each window. The paper also contains a brief review on some of the already published works.","","Electronic:978-1-4673-1953-9; POD:978-1-4673-1952-2","10.1109/NCCCS.2012.6413000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413000","Connected Components;Non text Doodles;Rabindranath Tagore;Stroke Width;Text;pixels","Accuracy;Algorithm design and analysis;Computers;Feature extraction;Graphics;Image analysis;Labeling","Internet;data warehouses;handwritten character recognition;history;information retrieval;text analysis;text detection","Internet;Rabindranath Tagore manuscripts;contemporary handwritten document warehouse;historical handwritten document warehouse;information retrieval algorithm;nontext doodles;nontextual information;poet;research and development;text graphics;text images;textual data separation","","0","","17","","","21-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"Ranking News Articles Based on Popularity Prediction","A. Tatar; P. Antoniadis; M. D. de Amorim; S. Fdida","LIP6, Sorbonne Univ., Paris, France","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","106","110","News articles are a captivating type of online content that capture a significant amount of Internet users' interest. They are particularly consumed by mobile users and extremely diffused through online social platforms. As a result, there is an increased interest in promptly identifying the articles that will receive a significant amount of user attention. This task falls under the broad scope of content popularity prediction and has direct implications in various contexts such as caching strategies or online advertisement policies. In this paper we address the problem of predicting the popularity of news articles based on user comments. We formulate the prediction task into a ranking problem where the goal is not to infer the precise attention that a content will receive but to accurately rank articles based on their predicted popularity. To this end, we analyze the ranking performance of three prediction models using a dataset of articles covering a four-year period and published by 20minutes.fr, an important French online news platform. Our results indicate that prediction methods improve the ranking performance and we observed that for our dataset a simple linear prediction method outperforms more dedicated prediction methods.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425776","News articles;popularity;prediction;ranking","Accuracy;Adaptation models;Correlation;Mathematical model;Predictive models;Social network services","data mining;electronic publishing;information retrieval;social networking (online)","Internet;content popularity prediction;linear prediction method;news article;online social platform;ranking problem;user comment","","5","1","16","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Reducing extra storage in searchable symmetric encryption scheme","H. Lu; D. Gu; C. Jin; Y. Tang","Lab of Cryptography and Computer Security Shanghai Jiao Tong University Shanghai, China","4th IEEE International Conference on Cloud Computing Technology and Science Proceedings","20130204","2012","","","255","262","In order to protect the data privacy, cloud users usually outsource the encrypted form of their data to the cloud servers, which brings a challenge when they want to search their encrypted data in cloud. Searchable encryption techniques solve this problem by allowing the cloud servers to search on the encrypted data without decrypting the ciphertext or the searching keywords. In this paper, we propose a construction which can dramatically reduce the size of extra storage in the searchable symmetric encryption schemes and still remain efficiency. And security analysis shows that our construction can achieve non-adaptive secure. Further investigation and experiments show that our construction is suitable for not only single keyword search but also more complex search including conjunctive search, disjunctive search and phrase search.","","Electronic:978-1-4673-4510-1; POD:978-1-4673-4511-8; USB:978-1-4673-4509-5","10.1109/CloudCom.2012.6427599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427599","Conjunctive Search;Disjunctive Search;Phrase Search;Searchable Symmetric Encryption","Encryption;Indexes;Keyword search;Merging;Servers","Web services;cloud computing;cryptography;data privacy;information retrieval","ciphertext decryption;cloud computing;cloud server;conjunctive search;data privacy protection;disjunctive search;keyword searching;nonadaptive security;phrase search;searchable symmetric encryption scheme;security analysis","","1","","16","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Using domain specific generated rules for automatic ontology population","C. Faria; R. Girardi; P. Novais","UFMA, Computer Science Department, Sao Luiz, Maranhao, Brazil","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","297","302","This article proposes a process for automatic population of ontologies from text that applies natural language processing and information extraction techniques to acquire and classify ontology instances. The work is part of HERMES, an FCT/CAPES research project looking for techniques and tools for automating the process of ontology learning and population. Two experiments using a legal and a tourism corpora were conducted in order to evaluate it. The results indicate that our approach can extract and classify instances with high effectiveness with the additional advantage of domain independence.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416554","information extraction;knowledge engineering;natural language processing;ontologies;ontology population","Logic gates;Ontologies;Sociology;Statistics","classification;information retrieval;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);text analysis","automatic ontology population;domain specific generated rules;information extraction technique;legal corpora;natural language processing technique;ontology instance acquisition;ontology instance classification;ontology learning process;tourism corpora","","2","","21","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"Clustering of duration patterns in speech for Text-to-Speech Synthesis","K. S. Sreelekshmi; D. P. Gopinath","Department of Electronics and Communication, College of Engineering, Trivandrum, Kerala, India - 695017","2012 Annual IEEE India Conference (INDICON)","20130128","2012","","","1122","1127","Synthesis of natural sounding speech is the greatest challenge in a Text-to-Speech Synthesis (TTS) system. In natural speech, duration, intensity and pitch are dynamically varied which is manifested as rhythm or prosody of speech. If these variations are not recreated, the synthesized speech will sound robotic. Synthesis of good quality speech depends on how well the duration and intonation patterns are imposed on speech segments. The best way to improve naturalness in speech is to mimic the way human brain imposes rhythm. We speak in a particular style by varying the duration of the speech segments in words and phrases as per certain specific duration patterns. Brain might be retrieving the corresponding patterns at the time of speaking for generating a discourse in a particular style (news reading, bible reading, story telling etc.). The main objective of this work is to investigate the existence of duration patterns in natural speech using cluster analysis. Speech uttered in Malayalam, an Indian language was taken for analysis. Cluster analysis was done on isolated words, as well as on words and phrases in continuous speech. Results of cluster analysis when observed using silhouette plot showed the existence of duration patterns in speech.","2325-940X;2325940X","Electronic:978-1-4673-2272-0; POD:978-1-4673-2270-6","10.1109/INDCON.2012.6420785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6420785","Speech synthesis;cluster analysis;duration models;k-means clustering;silhouette plot","Data models;Databases;Humans;Natural languages;Predictive models;Rhythm;Speech","human-robot interaction;information retrieval;natural language processing;pattern clustering;speech synthesis;statistical analysis;word processing","Malayalam;cluster analysis;human brain impose rhythm;natural sounding speech synthesis;pattern clustering;pattern duration;pattern retrieval;silhouette plot;sound robot;speak style;speech prosody;speech segments;text-to-speech synthesis;word processing","","0","","15","","","7-9 Dec. 2012","","IEEE","IEEE Conference Publications"
"Improving Data Processing Time with Access Sequence Prediction","P. Boonserm; B. Wang; S. See; T. Achalakul","Dept. of Comput. Eng., King Mongkut's Univ. of Technol. Thonburi, Bangkok, Thailand","2012 IEEE 18th International Conference on Parallel and Distributed Systems","20130117","2012","","","770","775","Genomic research nowadays often faces the problem of big data. The data size from genome sequencing process can grow very quickly and continuously creating the problem with storage and processing. BGI, one of the renowned genomic research institutes in China also faces the similar problem. The research at BGI depends on several sequencing machines. One machine pipeline may generate temporary data of around 1.4 terabytes. In addition, multiple read and write operations occur continuously during processing time. The I/O bottleneck thus degrades research throughput tremendously. Using a high performance computing system alone is not sufficiently effective in experimental results processing. In order to hide the I/O latency, an effective big data management framework is needed at BGI. In this paper, we proposed the hybrid prediction model for data access pattern. The goal is to predict the next pieces of data needed in the processor and preload them into the memory in order to improve the overall processing time. From the results obtained from the initial experiments, the proposed model can deliver high prediction accuracy in linear-time. Moreover, the error rate is low at 1.85%, which is better than the common methods used, such as Prediction Graph, ANN and ARMA. We believe that with some further fine-tuning, the model can be used as a part of the big data management framework deployed at BGI in the near future.","1521-9097;15219097","Electronic:978-0-7695-4903-3; POD:978-1-4673-4565-1","10.1109/ICPADS.2012.125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413607","Big Data;Hybrid ARMA Model;I/O Bottleneck;Paired t-Test","Autoregressive processes;Complexity theory;Computational modeling;Data models;Mathematical model;Prediction algorithms;Predictive models","genomics;information retrieval;medical information systems;pipeline processing","BGI;I/O bottleneck;I/O latency;data access pattern;data access sequence prediction;data management framework;data processing time improvement;data storage;genome sequencing process;hybrid prediction model;pipeline processing;read and write operation;sequencing machine","","0","","19","","","17-19 Dec. 2012","","IEEE","IEEE Conference Publications"
"Web Data Management through Crowdsourcing Upon Social Networks","M. Brambilla; A. Bozzon","Dipt. di Elettron. e Inf., Politec. di Milano, Milan, Italy","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","1123","1127","Retrieval and management of Web data is becoming a more and more complex problem, due to the amount of information to be dealt with, to the diversity of the information sources and of the data formats, and to the evolving expectations of users. In particular, some tasks such as quality assessment, opinion making, and sense extraction cannot be completely delegated to automatic procedures. More and more users are increasingly relying on social interaction to complete and validate the results of their online activities. For instance, scouting ""interesting"" results, or suggesting new, unexpected search directions in information seeking processes occurs in most times aside of the search systems and processes, possibly instrumented and mediated by a social network. In this paper we propose paradigm that embodies crowds and social network communities as first-class sources for the information management and extraction on the Web. Our approach aims at filling the gap between traditional Web systems (CMS, search engines and others), which operate upon world-wide information, with social systems, capable of interacting with real people, in real time, to capture their opinions, suggestions, and emotions by leveraging crowd sourcing practices and making them viable upon a social network. This enormously enriches the data manipulation experience for the user can be enormously enriched.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425607","Social network;Web information system;crowdsourcing;semantic Web","Communities;Data models;Engines;Facebook;Humans;Object oriented modeling","data handling;information retrieval;outsourcing;search engines;semantic Web;social networking (online)","CMS;Web data management;Web data retrieval;Web systems;crowdsourcing practices;data formats;data manipulation;information extraction;information management;information seeking processes;information sources;search engines;search processes;search systems;semantic Web;social interaction;social network communities","","1","","8","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Let Tagging be More Interesting","S. Beldjoudi; H. Seridi; C. Faron-Zucker","Lab. of Electron. Document Manage. LabGED, Badji Mokhtar Univ., Annaba, Algeria","2012 Second International Workshop on Advanced Information Systems for Enterprises","20130114","2012","","","2","8","In these recent years, the social semantic web has recognized a real attention by the majority of researchers in the world. We propose in this paper an original approach concerning a powerful technology which has recognized a great success in the social web area, we talk about folksonomies. The aim of our contribution is to provide another view about the semantics missed in the social web technologies and show how we can use the methods of Data mining to extract the meaning of tags in folksonomies. Especially we will present how we can analyze user profiles according to their tags in order to personalize the recommendation of pertinent resources and surmount the lack of semantic links between tags for improving the quality of results returned by the current folksonomies.","","Electronic:978-0-7695-4845-6; POD:978-1-4673-4791-4","10.1109/IWAISE.2012.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6410091","Association Rules;Folksonomie;Resource Recommendation;Semantics;Spelling Variations;Tags Ambiguity;Web 2.0","Association rules;Communities;Databases;Measurement;Ontologies;Semantics","data mining;information retrieval;recommender systems;semantic Web;social networking (online)","data mining;folksonomies;recommendation personalization;semantic links;social Web technologies;social semantic Web;tag meaning extraction;user profile analysis","","0","","17","","","10-12 Nov. 2012","","IEEE","IEEE Conference Publications"
"Extraction of unique information on sensor and target locations in SAR imaging scenarios with large apertures and scenes","E. H. Bleszynski; M. K. Bleszynski; T. Jaroszewicz","Monopole Research, Thousand Oaks, CA 91360, U.S.","2012 IEEE International Conference on Wireless Information Technology and Systems (ICWITS)","20130124","2012","","","1","4","We consider airborne SAR imaging of large scenes from large and curvilinear synthetic apertures, in a situation when the platform trajectory and the target locations are known only approximately, but the distances (ranges) between sensor locations and the (point) targets can be determined to a better accuracy, possibly comparable to the wavelength. In these circumstances, we examine different SAR scenarios which provide different amount of simultaneous information on the sensor and target locations.","","Electronic:978-1-4673-0948-6; POD:978-1-4673-0947-9","10.1109/ICWITS.2012.6417782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6417782","","Accuracy;Apertures;Image reconstruction;Signal processing algorithms;Synthetic aperture radar;Trajectory;Vectors","information retrieval;radar imaging;synthetic aperture radar","SAR imaging scenarios;SAR scenarios;airborne SAR imaging;curvilinear synthetic apertures;large apertures;large scenes;sensor locations;target locations;unique information extraction","","0","","11","","","11-16 Nov. 2012","","IEEE","IEEE Conference Publications"
"Unsupervised document summarization using clusters of dependency graph nodes","A. El-Kilany; I. Saleh","Faculty of Computers and Information, Cairo University, Egypt","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","20130124","2012","","","557","561","In this paper, we investigate the problem of extractive single document summarization. We propose an unsupervised summarization method that is based on extracting and scoring keywords in a document and using them to find the sentences that best represent its content. Keywords are extracted and scored using clustering and dependency graphs of sentences. We test our method using different corpora including news, events and email corpora. We evaluate our method in the context of news summarization and email summarization tasks and compare the results with previously published ones.","2164-7143;21647143","Electronic:978-1-4673-5119-5; POD:978-1-4673-5117-1","10.1109/ISDA.2012.6416598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416598","Dependency graph;Email summarization;Extractive summarization;Louvain clustering;ROUGE","Conferences;Context;Electronic mail;Feature extraction;Gold;USA Councils","electronic mail;graph theory;information resources;information retrieval;pattern clustering;text analysis","dependency graph node clusters;email corpora;email summarization;events;extractive single document summarization problem;keyword extraction;keyword scoring;news summarization;unsupervised document summarization;unsupervised summarization method","","1","","24","","","27-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"Simulation and control integrated framework for modular snake robots locomotion research","K. Melo; J. Leon; J. Monsalve; V. Fernandez; D. Gonzalez","KM-ROBOTA Research Group, KM-ROBOTA S.A.S., Tv 5 No 41-15 Of. 402, Bogota D.C., Colombia","2012 IEEE/SICE International Symposium on System Integration (SII)","20130204","2012","","","523","528","Executing challenging tasks in field robotics, commonly depends on the locomotive capabilities of the robot. Particularly, modular snake robots have shown an increasing ability to perform mobility and manipulation tasks in different environments. However, its locomotion strategies are not trivial and the modeling of such type of motion is still an important research goal. Consequently, robust controlling software to command motion and retrieve data is needed. Since the execution of experiments with these robots is expensive and time consuming, computer aided dynamics simulation becomes an indispensable tool to reduce the gap between modeling and real experiments validations. In this paper, a framework architecture to control and simultaneously simulate the modular snake robot locomotion behavior is presented. Using this integrated tool, experiments with real robots can be carried out, simulations of a virtual robot in a user-defined environment can be run and the retrieval of useful data from real or virtual outputs can be performed in a log file.","","Electronic:978-1-4673-1497-8; POD:978-1-4673-1496-1","10.1109/SII.2012.6427341","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427341","","Computer architecture;Physics;Protocols;Real-time systems;Robot sensing systems","control engineering computing;digital simulation;information retrieval;mobile robots","computer aided dynamics simulation;control integrated framework;data retrieval;framework architecture;locomotion strategies;log file;manipulation tasks;mobility tasks;modular snake robot locomotion behavior;motion command;motion modeling;robust controlling software;simulation framework;virtual robot simulations","","4","","19","","","16-18 Dec. 2012","","IEEE","IEEE Conference Publications"
"How can an orbit prediction module speed up the TTFF and help to authenticate the position?","M. Lytvyn; A. Kemetinger; P. Berglez","TeleConsult Austria GmbH, Graz, Austria","2012 6th ESA Workshop on Satellite Navigation Technologies (Navitec 2012) & European Workshop on GNSS Signals and Signal Processing","20130131","2012","","","1","6","Many GNSS applications require both, fast and trusted positioning. For example, in road toll collection this two requirements are extremely critical in order to provide fair road fee charges. One of the most effective measure to shorten the time to first fix is the usage of an assistance server to provide actual ephemeris and almanac information to the user. On the another hand, information from the assistance server can also be used as trusted reference data, which can help to detect spoofing attacks. The drawback is that a permanent connection to assistance server is required, in order to retrieve the latest ephemeris and almanac data. To overcome this problem the assistance server must be able to calculate and provide predicted orbits having a validity over a long period (e.g., up to 1-2 weeks). This paper describes a modular and cost-effective GNSS orbit prediction algorithm for reducing time to first fix as well as trusted positioning. The presented algorithm is implemented in the Positioning And Navigation Data Assistance Server, developed by TeleConsult Austria GmbH.","2325-5439;23255439","Electronic:978-1-4673-2011-5; POD:978-1-4673-2010-8","10.1109/NAVITEC.2012.6423124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6423124","","Acceleration;Earth;Global Navigation Satellite Systems;Orbits;Satellite broadcasting;Satellites;Servers","Global Positioning System;astronomical ephemerides;information retrieval;message authentication;telecommunication security","GNSS;TTFF;almanac data retrieval;assistance server;ephemeris data retrieval;orbit prediction module;position authentication;satellite navigation data assistance server;satellite positioning data assistance server;spoofing attack detection;time to first fix;trusted positioning","","2","","22","","","5-7 Dec. 2012","","IEEE","IEEE Conference Publications"
"Web Accessibility for Disabled: A Case Study of Government Websites in Pakistan","M. Bakhsh; A. Mehmood","Dept. of Comput. Sci., Allama Iqbal Open Univ. Islamabad Pakistan, Pakistan","2012 10th International Conference on Frontiers of Information Technology","20130131","2012","","","342","347","It is the era of information technology and governments around the world opting for electronic government and official websites are now under the use of a diverse population for the purpose of information retrieval. A number of disabled persons are becoming the part of this society but they are ignored when web projects are planned and developed. If this practice of software development is kept continuing then disabled persons would not take the advantage in the electronic government era. This study evaluates the websites of central government in Pakistan including all ministries and divisions using accessibility evaluation tools based on World Wide Web Consortium's (W3C) web accessibility standards. Functional accessibility evaluator and total validator are the tools which are used for the evaluation process. The results shows that most of the web sites are not developed according to the accessibility standards for disabled persons. In the light of these results, recommendations are made to improve the accessibility of these websites for disable persons.","","Electronic:978-0-7695-4927-9; POD:978-1-4673-4946-8","10.1109/FIT.2012.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424347","Information and communication technology;WWW;Web accessibility;e-Government;people with disability;web design framework","Electronic government;Guidelines;HTML;Navigation;Standards;Web sites","Web sites;government data processing;information retrieval","Pakistan;W3C Web accessibility standard;World Wide Web Consortium;disabled person;electronic government;functional accessibility evaluator;government Web site;information retrieval;information technology;software development;total validator","","5","","21","","","17-19 Dec. 2012","","IEEE","IEEE Conference Publications"
"Prototyping control and data acquisition for the ITER Neutral Beam Test Facility","A. Luchetta; G. Manduchi; C. Taliercio; A. Soppelsa; F. Paolucci; F. Sartori; P. Barbato; R. Capobianco; M. Breda; F. Molon; M. Moressa; S. Polato; P. Simionato; E. Zampiva","Consorzio RFX. Corso Stati Uniti 4, 35127 Padova Italy","2012 18th IEEE-NPSS Real Time Conference","20130124","2012","","","1","7","The ITER Neutral Beam Test Facility will be the project's R&D facility for heating neutral beam injectors (HNB) for fusion research operating with H/D negative ions. Its mission is to develop technology to build the HNB prototype injector meeting the stringent HNB requirements (16.5 MW injection power, -1 MVe acceleration energy, 40 A ion current and one hour continuous operation). Two test-beds will be built in sequence in the facility: first SPIDER, the ion source test-bed, to optimize the negative ion source performance, second MITICA, the actual prototype injector, to optimize ion beam acceleration and neutralization. The SPIDER control and data acquisition system is under design. To validate the main architectural choices, a system prototype has been assembled and performance tests have been executed to assess the prototype's capability to meet the control and data acquisition system requirements. The prototype is based on open-source software frameworks running under Linux. EPICS is the slow control engine, MDSplus is the data handler and MARTe is the fast control manager. The prototype addresses low and high-frequency data acquisition, 10 kS/s and 10 MS/s respectively, camera image acquisition, data archiving, data streaming, data retrieval and visualization, real time fast control with 100 μs control cycle and supervisory control. The paper shows how the proposed prototype architecture can address the most critical requirements of SPIDER control.","","Electronic:978-1-4673-1084-0; POD:978-1-4673-1082-6","10.1109/RTC.2012.6418191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418191","","Data acquisition;Ion sources;Memory;Prototypes;Servers;Structural beams;Synchronization","Linux;Tokamak devices;cameras;data acquisition;data handling;data visualisation;information retrieval;ion sources;negative ions;physical instrumentation control;plasma beam injection heating;plasma sources;plasma toroidal confinement;plasma transport processes;public domain software;research and development","D negative ions;H negative ions;HNB prototype injector meeting;ITER neutral beam test facility;Linux;MARTe;MDSplus;MITICA;R and D facility;SPIDER control;camera image acquisition;control engine;current 40 A;data acquisition system;data archiving;data handler;data retrieval;data streaming;data visualization;high-frequency data acquisition;ion beam acceleration;ion beam neutralization;ion current;ion source test-bed;negative ion source performance;neutral beam injection heating;open-source software frameworks;power 16.5 MW;prototype architecture;prototype control;real time fast control","","0","","17","","","9-15 June 2012","","IEEE","IEEE Conference Publications"
"An Erasure Coded Archival Storage System","P. Misra; N. Roy; S. Naskar; S. Dey","TCS Innovation Lab., Tata Consultancy Services Ltd., Kolkata, India","2012 IEEE 18th International Conference on Parallel and Distributed Systems","20130117","2012","","","720","721","There is an ever increasing need of storage capacity for storage of digital archives and historical data-digital preservation, because of regulatory and compliance requirements. There is an increasing interest in disk based archival system. Major technical challenges in creating large disk based storage archive are - providing large capacity at low costs, large read and write throughput, data integrity and sustaining hardware and operating system refresh. In this paper we present the architecture and working principle of an archival storage system that uses an erasure-coded redundancy scheme. We present the design of a Quality of Service (QoS) framework that tries to achieve an optimum balance between file availability, performance and system availability. The design includes a file encoding and placement scheme that allows files to be read from the archive without the need to access any metadata. Finally, we present the results obtained from running an experimental setup on Amazon Web Services.","1521-9097;15219097","Electronic:978-0-7695-4903-3; POD:978-1-4673-4565-1","10.1109/ICPADS.2012.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413620","QoS;archival storage;erasure coding;long term storage;regeneration","Availability;Bandwidth;Encoding;Operating systems;Quality of service;Servers;Throughput","disc storage;information retrieval systems;quality of service;records management","QoS;compliance requirements;data integrity;digital archives;disk based archival system;erasure coded archival storage system;file encoding;hardware system;historical data-digital preservation;metadata;operating system;quality of service;storage capacity","","0","","7","","","17-19 Dec. 2012","","IEEE","IEEE Conference Publications"
"A Model for Dynamic Integration of Data Sources","M. Obali; B. Dursun","","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","844","849","Online and offline data is the key to Intelligence Agents, but these data cannot be fully analyzed due to the wealth and complexity and non-integrated nature of the information available. In the field of security and intelligence, there is a huge number of data coming from heterogonous data sources in different formats. The integration and the management of these data are very costly and time consuming. The result is a great need for dynamic integration of these intelligent data. In this paper, we propose a complete model that integrates different online and offline data sources. This model takes part between the data sources and our applications.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425654","data source;information fusion;infotype;offline;online","Adaptation models;Data mining;Data models;Data structures;Feature extraction;Ontologies;Security","data integration;distributed databases;information retrieval systems;security of data;software agents","data management;data security;dynamic integration model;dynamic intelligent data integration;heterogonous data sources;information fusion;intelligent agents;offline data sources;online data sources","","1","","10","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Machine learning approach for argument extraction of bio-molecular events","A. Majumder; M. Hasanuzzaman; A. Ekbal; S. Saha","Dept. of MCA, Acad. of Technol., Hooghly, India","2012 NATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION SYSTEMS","20130117","2012","","","1","5","The main goal of Biomedical Natural Language Processing (BioNLP) is to capture biomedical phenomena from textual data by extracting relevant entities and information or relations between biomedical entities such as proteins and genes. Previous research was focussed on extracting only binary relations, but in recent times the focus is shifted towards extracting more complex relations in the form of bio-molecular events that may include several entities or other relations. In this paper we propose a machine learning approach based on Conditional Random Field (CRF) to extract the arguments of bio-molecular events. The overall task involves identification of event triggers from texts, classification of them into some predefined categories and determining the arguments of these events. We identify and implement a set of features in the forms of statistical and linguistic features that represent various morphological, syntactic and contextual information. Experiments on the benchmark setup of BioNLP 2009 shared task show the recall, precision and F-measure values of 45.75%, 78.93% and 57.91%, respectively.","","Electronic:978-1-4673-1953-9; POD:978-1-4673-1952-2","10.1109/NCCCS.2012.6413017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413017","Bio-molecular event;Conditional Random Field;Machine Learning","Context;Data mining;Event detection;Feature extraction;Machine learning;Proteins;Training","classification;feature extraction;information retrieval;learning (artificial intelligence);linguistics;medical computing;natural language processing;random processes;statistical analysis;text analysis","BioNLP 2009;CRF;argument extraction;binary relation extraction;biomedical entities;biomedical natural language processing;biomolecular events;conditional random field;contextual information;event identification;feature identification;information extraction;linguistic features;machine learning;morphological information;predefined categories;relevant entity extraction;statistical features;syntactic information;text classification;textual data","","0","","12","","","21-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"Ascertaining the More Knowledgeable Other among peers in collaborative e-learning environment","A. Safia; T. Mala","Department of Information Technology, MIT Campus, Anna University, Chennai, India","2012 Fourth International Conference on Advanced Computing (ICoAC)","20130124","2012","","","1","7","Collaborative E-Learning is an environment where in learners learn through interaction among peer group mates using computers. Evaluating learners in terms of collaboration capabilities in a collaborative e-learning session can be quantified based on several parameters. These parameters include learner's contribution in the collaborative e-learning sessions; collaboration history of a learner in collaborative e-learning sessions and the level of knowledge of the learner in the group in which he participates. In respect to this finding the More Knowledgeable Other (MKO) person refers to someone who has a better understanding and higher ability level than other learners, with respect to a particular task, process, or concept. He can make others learn effectively. By finding out the MKO it is possible to form effective and efficient group where in learner's learning capabilities in a group can be enhanced so that the peers in the group participate to maximum extent and there is an increase in knowledge level. In this paper, a fuzzy model is introduced to find out an MKO using an intelligent inference system to improve learner's learning capabilities in terms of a proposed metric called fuzzy associative matrix. This matrix can be utilized to guide the collaborative e-learning system for finding out the MKO as the best choice for very effective collaborative e-learning. Simulation study using NetLogo has been carried out to evaluate the performance of the proposed strategy. Simulation results show that the proposed strategy provides an optimal solution in ascertaining an MKO among peers in collaborative E-learning environments.","2377-6927;23776927","Electronic:978-1-4673-5584-1; POD:978-1-4673-5583-4","10.1109/ICoAC.2012.6416852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416852","Collaboration-Index;Collaborative E-Learning;E-Learning;Fuzzy Associative matrix;Intelligent Inference system;NetLogo","Collaboration;Collaborative work;Educational institutions;Electronic learning;History","computer aided instruction;fuzzy logic;fuzzy reasoning;groupware;information retrieval;multi-agent systems;object-oriented programming;software performance evaluation","MKO person;NetLogo;collaborative e-learning session;collaborative e-learning system;fuzzy associative matrix;fuzzy model;intelligent inference system;learner evaluation;learner knowledge level;learning capability improvement;more knowledgeable other person;peer group mates;performance evaluation","","1","","21","","","13-15 Dec. 2012","","IEEE","IEEE Conference Publications"
"Forensic analysis of compromised systems","A. Baláž; R. Hlinka","Department of Computers and Informatics, Technical University of Ko&#x0161;ice, Letn&#x00E1; 9, 04200, Slovakia","2012 IEEE 10th International Conference on Emerging eLearning Technologies and Applications (ICETA)","20130124","2012","","","27","30","This article presents a study on whether and how may forensic analysis contribute to a compromised system. It explores the use of specific procedures for conducting security examinations of such a system, allowing gaining and store relevant evidence. Test results in laboratory-scale environment demonstrate the feasibility of performing general methods on live computer systems, operations systems in particular, all intended for the scale of forensic analyses. The study also weighs the relative contributions of possible forensic data sources which may a forensic analyst reveal throughout the analysis, especially important data obtained from operation systems Windows and Linux, whereby it is possible to extract valuable information. Finally, the exploratory activities result in the list of procedures applicable to Linux operating system that are seen to satisfy the security requirements for important data. The present study also intends to examine the mediating role of computer security as a process or mechanism by which to explain the relationship between forensic analysis and computing systems.","","Electronic:978-1-4673-5122-5; POD:978-1-4673-5120-1","10.1109/ICETA.2012.6418288","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418288","","Computers;Digital forensics;Linux;Operating systems;Security","Linux;digital forensics;information retrieval","Linux;Windows;compromised systems;computer security;computer systems;data security requirements;forensic analysis;forensic data sources;information extraction;laboratory-scale environment;operation systems;security examinations","","2","","13","","","8-9 Nov. 2012","","IEEE","IEEE Conference Publications"
"An efficient Public Key Encryption with Conjunctive Keyword Search scheme based on pairings","M. Ding; F. Gao; Z. Jin; H. Zhang","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China","2012 3rd IEEE International Conference on Network Infrastructure and Digital Content","20130124","2012","","","526","530","The Public Key Encryption with Conjunctive Keyword Search (PECK) scheme enables one to search a document included multiple encrypted keywords without compromising any original data information. The existing PECK schemes mostly depend on pairings and authenticated channel to achieve searchable encryption. In this paper, we propose a new PECK scheme based on pairings, where no pairing operations are involved in the encryption and trapdoor phases and no secure channel is needed between server and users. In comparison with previous schemes, our scheme can achieve high efficiencies in both computation and communication. And then we further discuss on the consistency, efficiency and security of the proposed scheme.","2374-0272;23740272","Electronic:978-1-4673-2204-1; POD:978-1-4673-2201-0","10.1109/ICNIDC.2012.6418809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418809","Searchable encryption;bilinear pairing;public key encryption with conjunctive keyword search;secure channel free","Encryption;Keyword search;Public key;Receivers;Servers","information retrieval;message authentication;public key cryptography;text analysis","PECK scheme;authenticated channel;conjunctive keyword search scheme;data information;document search;encrypted keyword;pairings;public key encryption;searchable encryption;trapdoor phase","","7","","15","","","21-23 Sept. 2012","","IEEE","IEEE Conference Publications"
"Classification of durian characteristics for semantic representation from web documents","Z. A. Bakar; K. N. Ismail","Department of Computer Science, Faculty of Computer and Mathematical Sciences, Shah Alam, Selangor, Malaysia","2012 IEEE Symposium on E-Learning, E-Management and E-Services","20130121","2012","","","1","5","The Web contains enormous size of information that is represented in various document structures. The information is scattered and redundant. Currently, search engine is the main medium for retrieving this information. Yet, the most popular search engine cannot satisfy user query. Alternatively, semantic technology can alleviate this problem. In this paper, only relevant web HTML documents on durian also known as king of fruits are chosen. The characteristics of durian will be extracted from those HTML documents. These characteristics are then employed in semantic representation and stored along with their Uniform Resource Identifier (URI) in Resource Description Framework (RDF). The RDF provides the ontology link to many other web documents on durian. Experiment on 40 HTML documents provides eleven new characteristics of durian that can be represent in RDF for semantic search engine.","","Electronic:978-1-4673-2389-5; POD:978-1-4673-2390-1","10.1109/IS3e.2012.6414956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6414956","Durian;HTML;RDF;semantic","Agriculture;Government;HTML;Ontologies;Resource description framework;Semantics","Internet;agricultural products;document handling;food products;hypermedia markup languages;information retrieval;pattern classification;search engines;semantic Web","RDF;URI;Web HTML documents;durian characteristics;fruits;information retrieval;ontology link;resource description framework;search engine;semantic representation;semantic technology;uniform resource identifier","","1","","47","","","21-24 Oct. 2012","","IEEE","IEEE Conference Publications"
"Strengthening government decision making process through integrated SPIDER & e-MANCHITRA Online Portals","L. R. Yadav; N. Kapoor; R. S. Singh","Dept. of Electron. &amp; Inf. Technol., GoI, Lucknow, India","2012 Third International Conference on Emerging Applications of Information Technology","20130110","2012","","","223","226","Decentralized, integrated district and local level plannings are being implemented to promote balanced development, especially in rural areas. The 73rd and 74th amendments to the Indian Constitution have bestowed greater responsibilities and powers to the local bodies, positioning them as the third tier of governance. Inter-regional disparities are persisting as a problem in the development process even after continuous efforts by the government. An Online SPIDER Portal developed for data entry/updation and retrieval of information for all the villages, blocks, districts, divisions, regions and state for the years 1995 to 2011 and preparation of 2012 SP is in progress. GIS cells have been established in all the districts and at state head quarter of planning department during the year 2009-10. An Online e-MANCHITRA Geo Portal has been developed for strengthening government decision making process using Arc GIS Web Server with .Net ADF for generating online thematic maps at state, regional, divisional, district, block and village panchayat levels based on SPIDER portal indicators. In this paper introduction, Online SPIDER Portal, e-MANCHITRA Geo Portal, Architectural View, Salient Features, Challenges Faced and Conclusion will be shared in detail.","","Electronic:978-1-4673-1827-3; POD:978-1-4673-1828-0","10.1109/EAIT.2012.6407901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6407901","ADF;API;ESD;GIS;GoI;GoUP;NIC;NeGP;SDE;SOC;SOM;SP;SPIDER;e-MANCHITRA","Databases;Decision making;Geographic information systems;Government;Planning;Portals;Servers","Internet;cartography;decision making;file servers;geographic information systems;information retrieval;portals;town and country planning",".Net ADF;Arc GIS Web Server;GIS cells;Indian Constitution;SPIDER online portals;architectural view;data entry;data updation;district plannings;e-MANCHITRA online portals;government decision making process;information retrieval;interregional disparity;local level plannings;online e-MANCHITRA Geo portal;online thematic maps;rural areas;salient features","","0","","20","","","Nov. 30 2012-Dec. 1 2012","","IEEE","IEEE Conference Publications"
"Efficient multilingual keyword search using bloom filter for cloud computing applications","S. K. Pal; P. Sardana; K. Yadav","Defence R&D Organization, SAG, Metcalfe House, Delhi, India","2012 Fourth International Conference on Advanced Computing (ICoAC)","20130124","2012","","","1","7","Efficient keyword search in electronic documents has been an important problem in computer science for the last many decades. With the popularity of cloud services, some applications require searching in multilingual environment. Other applications require data to be stored in the cloud in encrypted form and outsourced to a third party for processing. This paper proposes an algorithm using bloom filters to perform efficient multilingual search on data stored in the cloud in plain or encrypted form. When the user sends in a keyword to be searched, its language is first determined and its corresponding language list bloom filters are checked for presence of the keyword. To make the algorithm more efficient and accurate, we have created two categories of bloom filters namely primary and secondary bloom filter. The list of documents having the keyword is returned to the user. For secure applications, the encrypted documents and its corresponding bloom filters are stored in the server. When user wants to perform a search in stored encrypted documents it sends the keyword to the server. The server applies similar technique to return the encrypted documents having the keyword and the client uses the key to decrypt the documents if required. While searching for keywords, we test the word against the bloom filter of documents which enables these to be stored in encrypted form. Checking of a word against the bloom filter of its documents takes constant time. Experimental results show that searching for a word in encrypted documents can be performed quite efficiently using this scheme even if the environment is multilingual.","2377-6927;23776927","Electronic:978-1-4673-5584-1; POD:978-1-4673-5583-4","10.1109/ICoAC.2012.6416809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416809","Bloom Filter;Cloud Computing;Cloud Security;Encrypted Multilingual Search","Algorithm design and analysis;Cloud computing;Cryptography;Filtering algorithms;Matched filters;Servers;Standards","cloud computing;cryptography;data structures;document handling;information retrieval","cloud computing applications;computer science;electronic documents;encrypted documents;encrypted form;language list bloom filters;multilingual environment;multilingual keyword search;secure applications","","2","1","45","","","13-15 Dec. 2012","","IEEE","IEEE Conference Publications"
"HRTF magnitude modeling using a non-regularized least-squares fit of spherical harmonics coefficients on incomplete data","J. Ahrens; M. R. P. Thomas; I. Tashev","Microsoft Res., Redmond, WA, USA","Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference","20130117","2012","","","1","5","Head-related transfer functions (HRTFs) represent the acoustic transfer function from a sound source at a given location to the ear drums of a human. They are typically measured from discrete source positions at a constant distance. Spherical harmonics decompositions have been shown to provide a flexible representation of HRTFs. Practical constraints often prevent the retrieval of measurement data from certain directions, a circumstance that complicates the decomposition of the measured data into spherical harmonics. A least-squares fit of coefficients is a potential approach to determining the coefficients of incomplete data. However, a straightforward non-regularized fit tends to give unrealistic estimates for the region were no measurement data is available. Recently, a regularized least-squares fit was proposed, which yields well-behaved results for the unknown region at the expense of reducing the accuracy of the data representation in the known region. In this paper, we propose using a lower-order non-regularized least-squares fit to achieve a well-behaved estimation of the unknown data. This data then allows for a high-order non-regularized least-squares fit over the entire sphere. We compare the properties of all three approaches applied to modeling the magnitudes of the HRTFs measured from a manikin. The proposed approach reduces the normalized mean-square error by approximately 7 dB in the known region and 11 dB in the unknown region compared to the regularized fit.","","Electronic:978-0-6157-0050-2; POD:978-1-4673-4863-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412037","extrapolation;head-related transfer functions;interpolation;regularization;spherical harmonics","Acoustics;Data models;Ear;Estimation;Extrapolation;Harmonic analysis;Transfer functions","acoustic generators;acoustic signal processing;data structures;estimation theory;harmonics;information retrieval;least squares approximations;mean square error methods;transfer functions","HRTF magnitude modeling;acoustic transfer function;discrete source positions;flexible HRTF representation;head-related transfer functions;human ear drums;incomplete data;lower-order straightforward nonregularized least-squares fit;measurement data retrieval;normalized mean-square error;regularized least-squares fit;sound source;spherical harmonics coefficients;spherical harmonics decompositions","","1","","12","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Enhancing Cloud Object Storage Performance Using Dynamic Replication Approach","K. Jindarak; P. Uthayopas","Dept. of Comput. Eng., Kasetsart Univ., Bangkok, Thailand","2012 IEEE 18th International Conference on Parallel and Distributed Systems","20130117","2012","","","800","803","The cloud storage is a new paradigm of data storage. Because of the internet connection speed increasing, everyone can store data on the cloud storage. Some data is shared for many user accesses, some data is private data. It has different characteristic of access pattern. In this work, the adaptive dynamic replication is presented. The model of dynamic replication is discussed. We propose the object-based storage as our cloud storage architecture. The storage object life time is used for handle our dynamic replication mechanism. The experimental results show the distribution of storage object workload that has some characteristic that relate with storage object life time and other factors.","1521-9097;15219097","Electronic:978-0-7695-4903-3; POD:978-1-4673-4565-1","10.1109/ICPADS.2012.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413602","cloud computing;cloud storage;object placement;object-based storage;replication","Aerospace electronics;Cloud computing;Computer architecture;Educational institutions;Market research;Servers","Internet;cloud computing;data privacy;information retrieval;replicated databases;storage management","Internet connection;cloud object storage performance evaluation;cloud storage architecture;data access pattern;data privacy;data shared;data storage;dynamic replication approach;object-based storage;storage object workload distribution;user access","","0","","14","","","17-19 Dec. 2012","","IEEE","IEEE Conference Publications"
"A spoken dialogue system using virtual conversational agent with augmented reality","S. Miyake; A. Ito","Grad. Sch. of Eng., Tohoku Univ., Sendai, Japan","Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference","20130117","2012","","","1","4","We have developed a spoken dialogue system using virtual conversational agent with augmented reality. The proposed system has architecture based on question and answer database that contains many question and answer pairs. Additionally, we have developed two agents displayed using augmented reality, which behave as avatars of objects to be operated. We evaluated user's impression as well as response accuracy of our proposed system. As a result, the existence of an agent increased user's feeling of vividness of conversation and easiness to talk to the system. In addition, the system with an agent showed better response accuracy than the system without agents.","","Electronic:978-0-6157-0050-2; POD:978-1-4673-4863-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6411769","Augmented reality;Spoken dialogue system;Virtual agent","Accuracy;Augmented reality;Cameras;Databases;Indium tin oxide;Speech;TV","augmented reality;avatars;interactive systems;question answering (information retrieval)","augmented reality;avatars;question and answer database;spoken dialogue system;virtual conversational agent","","1","","16","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Object oriented memory recollection and retrieval based on spatial log in the iSpace","K. Saito; A. Yoshimura; J. H. Lee","","2012 IEEE/SICE International Symposium on System Integration (SII)","20130204","2012","","","271","276","In this paper, we propose a memory recollection and retrieval system using spatial log data in daily living which allows users to see behavior of the past, unconscious behavior and object-oriented behavior in the Intelligent Space. The proposed system consists of multiple camera devices and microphone and it utilizes various kinds of data; human identification, human motion, object instance, weather information, lighting intensity, heuristic information, etc. We constructed the system, focused on objects, in the Intelligent Space. To generate Metadata, based on collected log data to achieve the system of Recollection and Retrieval, several algorithms were used. This paper presents the prototype of Recollection and Retrieval System, and original dataset, useful for various purposes in the Intelligent Space.","","Electronic:978-1-4673-1497-8; POD:978-1-4673-1496-1","10.1109/SII.2012.6427342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427342","","Cameras;Head;Histograms;Humans;Object recognition;Robots;Sensors","cameras;information retrieval;meta data;object-oriented methods;ubiquitous computing","daily living;heuristic information;human identification;human motion;iSpace;intelligent space;lighting intensity;metadata;microphone;multiple camera devices;object instance;object oriented memory recollection;object oriented memory retrieval;object-oriented behavior;spatial log data;weather information","","1","","13","","","16-18 Dec. 2012","","IEEE","IEEE Conference Publications"
"Character-based search with data confidentiality in the clouds","V. Maheshwari; A. Nourian; M. Maheswaran","School of Computer Science McGill University Montreal, QC H3A 2A7, Canada","4th IEEE International Conference on Cloud Computing Technology and Science Proceedings","20130204","2012","","","895","899","Recently, searching over encrypted data has become a hot research topic. Basic idea of privacy enhanced search is to generate an intermediate representation of the original text data and use it to perform the search. Prior research has used hash maps, tries, and other data structures to create the intermediate representation. We use a texture scheme for representing the characters. To enhance the privacy the textures are split and noise is added to each of the portions such that all portions of a texture needs to be collected to recover the original data in an unambiguous manner. One of the key advantages of our scheme is the ability to implement most of the search schemes (e.g., wildcard searches) that are performed with plain text searches. This paper fully describes our data representation scheme and presents the experimental data we gathered by implementing the scheme in a server cluster.","","Electronic:978-1-4673-4510-1; POD:978-1-4673-4511-8; USB:978-1-4673-4509-5","10.1109/CloudCom.2012.6427591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427591","cloud computing;cloud security;data confidentiality;data obfuscation;keyword search","Cloud computing;Cryptography;Gaussian noise;Noise measurement;PSNR","character recognition;cloud computing;cryptography;data privacy;data structures;image retrieval;image texture;information retrieval;text analysis","character-based search;clouds;data confidentiality;data encryption;data structures;hash maps;intermediate text data representation;plain text searches;privacy enhanced search;server cluster;texture privacy;texture scheme","","0","","14","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Paraphrase extraction from interactive Q&A communities","Hu Hongsi; Zhang Wenbo; Yao Tianfang","UDS-SJTU Joint Research Lab for Language Technology, Shanghai Jiaotong University, China","2012 8th International Conference on Computing and Networking Technology (INC, ICCIS and ICMIC)","20130124","2012","","","268","272","Paraphrase is widely researched in last decade. Most of the researches are focused on acquisition of paraphrase from various language resources and generation of paraphrase. It is a hot topic that how to build large scale of paraphrase corpus, and it is the first step for paraphrase exploration as well. Interactive question answering communities which are a kind of special Q&A platform skipping over natural language understood by computer but just providing a platform for communication among people, have corpus with quick growing rate and sentences in diversified expressions. These advantages provide great value for paraphrase research and extend paraphrase corpus in huge scale. We propose a method on how to extract paraphrase from interactive Q&A community in this paper. The experiment results show the precision, recall and f-measure can reach to 0.7725, 0.7349 and 0.7532 respectively, and paraphrase could be extracted effectively.","","Electronic:978-89-94364-18-6; POD:978-1-4673-1326-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418665","","Abstracts;Communities;Tin","natural language processing;pattern classification;question answering (information retrieval);support vector machines","f-measure;interactive Q-and-A community;language resource;paraphrase acquisition;paraphrase corpus;paraphrase exploration;paraphrase extraction;paraphrase generation;precision measure;question-and-answer community;recall measure","","0","","13","","","27-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"An Ontology Term Extracting Method Based on Latent Dirichlet Allocation","Y. Jing; W. Junli; Z. Xiaodong","Res. Center of CAD, Tongji Univ., Shanghai, China","2012 Fourth International Conference on Multimedia Information Networking and Security","20130110","2012","","","366","369","Ontology plays an important part on Semantic Web, Information Retrieval, and Intelligent Information Integration etc. Ontology learning gets widely studied due to many problems in totally manual ontology construction. Term extraction influences many respects of ontology learning as it's the basis of ontology learning hierarchical structure. This paper mines topics of the corpus based on Latent Dirichlet Allocation (LDA) which uses Variational Inference and Expectation-Maximization (EM) Algorithm to estimate model parameters. With the help of irrelevant vocabulary, the paper provides better experimental results which show that the distribution of topics on terms reveals latent semantic features of the corpus and relevance among words.","2162-8998;21628998","Electronic:978-0-7695-4852-4; POD:978-1-4673-3093-0","10.1109/MINES.2012.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405699","LDA; topic mining; ontology learning; Variational Inference; EM algorithm; LDA","Data mining;Educational institutions;Inference algorithms;Ontologies;Probabilistic logic;Semantics;Vocabulary","data mining;expectation-maximisation algorithm;inference mechanisms;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);semantic Web","EM algorithm;LDA;expectation-maximization algorithm;information retrieval;intelligent information integration;latent Dirichlet allocation;model parameter estimation;ontology construction;ontology learning hierarchical structure;ontology term extracting method;semantic Web;term extraction;variational inference algorithm","","1","","9","","","2-4 Nov. 2012","","IEEE","IEEE Conference Publications"
"HPPC-Hierarchical Petri-Net based Privacy nominal model approach for Cloud","D. Chandramohan; T. Vengattaraman; P. Dhavachelvan","Department of Computer Science, Pondicherry University, India","2012 Annual IEEE India Conference (INDICON)","20130128","2012","","","1047","1052","This paper focusing on the data collected ubiquitously and conserved by cloud providers are assured that, the clients and users can assess that information globally as per their versatility, where as the cloud providers should gave some limited transparency policy to maintain client's secrecy. Usually the private data collected by the service providers can be shared with in their other platforms. Highest risk of data exposure occurs for cloud providers due to the breach of client's secrecy. In cloud architecture privacy policies and its standards is one of the main issues of cloud computing. Many researchers have been vigorously working in these issues. We studied these researchers work, frontward us to propose HPBP (Hierarchical Petri-net based Privacy nominal model for Cloud) architecture. Our proposed model facilitates clients, to have an augment trust on cloud providers as a pledge to maintain their high secrecy. The privacy of the proposed technique is analyzed briefly.","2325-940X;2325940X","Electronic:978-1-4673-2272-0; POD:978-1-4673-2270-6","10.1109/INDCON.2012.6420771","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6420771","Authentication;Cloud Computing;Petri-net;Privacy;Security","Cloud computing;Computational modeling;Computer architecture;Data privacy;Mathematical model;Privacy;Security","Petri nets;cloud computing;data acquisition;data privacy;information retrieval;risk analysis;trusted computing;ubiquitous computing","HPBP nominal model;HPPC;client secrecy;cloud architecture privacy policy;cloud computing;cloud providers;data exposure;hierarchical Petri net based privacy;information access;limited transparency policy;risk analysis;trust;ubiquitous data collection","","7","","27","","","7-9 Dec. 2012","","IEEE","IEEE Conference Publications"
"Capturing Tag Dynamics by Prediction for Pervasive Internet-of-Things Applications","Y. Huang; X. Ma; Y. Yang","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China","2012 IEEE 18th International Conference on Parallel and Distributed Systems","20130117","2012","","","416","423","Efficient detection of RFID-tagged physical objects is one of the key enabling technologies to build pervasive Internet-of-Things applications. However, the detection of tagged-objects is faced with the critical challenge of tag dynamics, which mainly arises from the movement of tagged physical objects. To capture tag dynamics, the application needs to detect the presence/absence of tags in an accurate, timely and cost-effective way. To address these challenges, we propose the Prediction of Tag Dynamics (PTD) algorithm. PTD achieves runtime detection of tagged-objects by i) streaming of the temporally-correlated tag readings obtained from persistent tracking of the tagged-object, and ii) runtime prediction of tag dynamics based on the streaming of tag readings. The performance of PTD is investigated based on real implementation and experimental evaluation, where PTD processes tag readings gathered with high fidelity from persistent tracking of real activities of tagged objects. The evaluation results demonstrate the accuracy, timeliness and cost-effectiveness of PTD.","1521-9097;15219097","Electronic:978-0-7695-4903-3; POD:978-1-4673-4565-1","10.1109/ICPADS.2012.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413668","Internet of Things;RFID;prediction;tag dynamics;tagged-objects","Accuracy;Delay;Heuristic algorithms;Jitter;Noise measurement;Radiofrequency identification;Tracking","Internet of Things;information retrieval;radiofrequency identification","PTD;RFID-tagged physical objects;pervasive Internet-of-things applications;prediction of tag dynamics algorithm;tag readings","","0","","21","","","17-19 Dec. 2012","","IEEE","IEEE Conference Publications"
"Learning Semantic Signatures for 3D Object Retrieval","B. Gong; J. Liu; X. Wang; X. Tang","Department of Computer Science, University of Southern California","IEEE Transactions on Multimedia","20130115","2013","15","2","369","377","In this paper, we propose two kinds of semantic signatures for 3D object retrieval (3DOR). Humans are capable of describing an object using attribute terms like “symmetric” and “flyable”, or using its similarities to some known object classes. We convert such qualitative descriptions into attribute signature (AS) and reference set signature (RSS), respectively, and use them for 3DOR. We also show that AS and RSS can be understood as two different quantization methods of the same semantic space of human descriptions of objects. The advantages of the semantic signatures are threefold. First, they are much more compact than low-level shape features yet working with comparable retrieval accuracy. Therefore, the proposed semantic signatures require less storage space and computation cost in retrieval. Second, the high-level signatures are a good complement to low-level shape features. As a result, by incorporating the signatures we can improve the performance of state-of-the-art 3DOR methods by a large margin. To the best of our knowledge, we obtain the best results on two popular benchmarks. Third, the AS enables us to build a user-friendly interface, with which the user can trigger a search by simply clicking attribute bars instead of finding a 3D object as the query. This interface is of great significance in 3DOR considering the fact that while searching, the user usually does not have a 3D query at hand that is similar to his/her targeted objects in the database.","1520-9210;15209210","","10.1109/TMM.2012.2231059","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365823","3D object retrieval;attribute;reference set;semantic signature;user-friendly interface","Databases;Detectors;Educational institutions;Humans;Search problems;Semantics;Shape","information retrieval;learning (artificial intelligence);quantisation (signal);solid modelling;user interfaces","3D object retrieval;3D query;attribute signature;flyable attribute term;high-level signature;low-level shape feature;qualitative description;quantization method;reference set signature;semantic signature learning;symmetric attribute term;user-friendly interface","","13","","44","","20121130","Feb. 2013","","IEEE","IEEE Journals & Magazines"
"An approach to integration of contextual information in case-based recommender systems","H. Supic","Dept. of Comput. Sci., Univ. of Sarajevo, Sarajevo, Bosnia-Herzegovina","2012 IX International Symposium on Telecommunications (BIHTEL)","20130117","2012","","","1","5","In this paper we describe a case based approach to product recommendation process in which contextual information are integrated. The integration of contextual information into recommender systems adds an additional information value to the recommender data model. In order to evaluate the effects of the integration of contextual information, the case representation with integrated contextual information is compared with the case representation without contextual information. We compare these two approaches to case representation in terms of the two metrics widely used in information retrieval (recall and precision).","","Electronic:978-1-4673-4876-8; POD:978-1-4673-4875-1; USB:978-1-4673-4874-4","10.1109/BIHTEL.2012.6412089","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6412089","case representation;case-based recommendation;integration of contextual information","Cognition;Context;Context modeling;Data models;Motion pictures;Recommender systems","case-based reasoning;information retrieval;recommender systems","case representation;case-based recommender systems;contextual information integration;information retrieval","","0","","9","","","25-27 Oct. 2012","","IEEE","IEEE Conference Publications"
"Research and Implementation of Internet Public Opinion of Information Processing System","X. h. Wu","Dept. of Inf. Technol., Shenyang Railway Mech. Coll., Shenyang, China","2012 International Conference on Control Engineering and Communication Technology","20130117","2012","","","616","618","At present, the collection, analysis and processing of the internet public opinion has become an effective means of organs and departments to get people thinking and recommendations, corporate mining opportunities, this paper through to the internet public opinion of information collection and processing, proposed to automatically obtain information for the network forums, automatic classification, automatic extraction of keywords, automatic analysis of hot topics and the result is stored in the public opinion information servers and processing and management information management model of internet public opinion. The model will be achieved with minimal manpower and resources overhead to achieve the optimal effects of public opinion analysis, the end of this paper experiment verify the validity and rationality of the model.","","Electronic:978-0-7695-4881-4; POD:978-1-4673-4499-9","10.1109/ICCECT.2012.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413771","Automatic Extraction;Hot Topics;Information Processing Model;Internet Public Opinion","Communications technology;Control engineering","Internet;classification;data mining;information retrieval;psychology;text analysis","Internet public opinion;automatic classification;automatic hot topics analysis;automatic keyword extraction;corporate mining opportunities;information collection;information management model;information processing system;model rationality;model validity;network forums;public opinion analysis;public opinion information servers","","0","","4","","","7-9 Dec. 2012","","IEEE","IEEE Conference Publications"
"Enhanced 3-layer hierarchical replication algorithm for Data Grid","N. Mansouri; G. Dastghaibyfard","Dept. of Comput. Sci. &amp; Eng., Shiraz Univ., Shiraz, Iran","2011 1st International eConference on Computer and Knowledge Engineering (ICCKE)","20130117","2011","","","297","302","In Data Grid, large quantity of data files are generated and many users around the world need to access such data for their research and experiments. Replication is a key optimization technique to manage such a huge amount of data by replicating data in multiple grid sites. Replication goals are how to decrease bandwidth consumption, improve fault tolerance, and enhance scalability. Due to dynamic network characteristic and user behavior the main challenges are when and where to replicate data in order to achieve replication goals. Other challenges are improvement of data access efficiency since number and size of storage devices available in grid are limited while large sizes of data files are produced. In this paper, the performance of the 3-layer hierarchical replication algorithm is enhanced by placing the replica in the appropriate sites i.e. best site that has the highest number of access for that particular replica and uses an economic model for file deletion when there is not enough space for replica. The economic model is based on future value of a data file. The proposed algorithm is implemented by OptorSim, European Data Grid simulator. Experiment results show that the proposed strategy achieves better performance by minimizing the data access time and avoiding unnecessary replication.","","Electronic:978-1-4673-5713-5; POD:978-1-4673-5712-8","10.1109/ICCKE.2011.6413368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413368","Data Grid;Replication;Simulation","Bandwidth;Computational modeling;Data models;Distributed databases;Economics;Local area networks;Optimization","file organisation;grid computing;information retrieval;minimisation;software fault tolerance;software performance evaluation","3-layer hierarchical replication algorithm;European Data Grid simulator;OptorSim;bandwidth consumption reduction;data access efficiency improvement;data access time minimization;data files;data replication;dynamic network characteristics;economic model;fault tolerance improvement;file deletion;optimization technique;performance enhancement;scalability enhancement;storage devices;user behavior","","0","","21","","","13-14 Oct. 2011","","IEEE","IEEE Conference Publications"
"Reduced navigation data for a fast first fix","M. Anghileri; M. Paonni; E. Gkougkas; B. Eissfeller","ISTA, University FAF Munich, Germany","2012 6th ESA Workshop on Satellite Navigation Technologies (Navitec 2012) & European Workshop on GNSS Signals and Signal Processing","20130131","2012","","","1","7","Every GNSS user is interested in having high accuracy PVT solutions. However, for most mass market applications like location based services or road navigation, having a first position fix within few seconds is more important than waiting some time for an accurate solution. One of the biggest contributions to the TTFF is the time needed to retrieve the navigation data coming with the data message. The concept presented in this paper aims at improving the TTFF performance of navigation receivers by defining a set of clock and ephemeris data (CED) with reduced size. This newly defined message types could be added into the transmission schemes of today's and future GNSS to allow for higher CED repetition rates and thus shorter TTFF. Like other parameters, satellite ephemeris and clock corrections are delivered to the users in binary form. The reduction of the size of these data is therefore corresponding to a reduction of the accuracy with which the parameters describing the satellite's orbit and clock drift are represented and delivered to the users. The idea behind the concept of transmitting reduced CED is that mass market users might tolerate an initial degraded accuracy to have the possibility of a faster first position fix. In order to simplify the generation of this new set of data, rather than computing new parameters from scratch, a very straightforward approach is proposed. The algorithm should take the broadcast CED that are already available in the satellites and obtain the new parameters by a simple reduction of the number of bits assigned to them. The concept has been implemented with an experimental design based on the current data of the GPS L1 C/A code signal, aiming at minimizing the number of bits while not exceeding a horizontal position error of 100 m. After achieving a volume reduction of about 52%, the compliance to the requirement was verified by applying the reduction algorithm to the CED issues broadcast by GPS during the last 10 years, and- estimating the horizontal user position error for each of them over the four hours of their validity interval. Some application possibilities for the proposed concept are mentioned, like the inclusion of this data into the transmission pattern of todays and future GNSS signals, increasing the CED repetition rates. In particular the suitability for a new kind of acquisition aiding signal has been underlined. Concerning future work on this concept, there are already plans for a detailed design, tailored to specific GNSS messages, like the Galileo I/NAV. Moreover advanced optimization techniques for the implementation of the reduction algorithm will be investigated.","2325-5439;23255439","Electronic:978-1-4673-2011-5; POD:978-1-4673-2010-8","10.1109/NAVITEC.2012.6423105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6423105","Initial accuracy;Navigation data;TTFF;URE","Accuracy;Clocks;Global Navigation Satellite Systems;Global Positioning System;Receivers;Satellite broadcasting;Satellites","Global Positioning System;artificial satellites;data reduction;direct broadcasting by satellite;information retrieval;message passing;optimisation;radio receivers;signal detection","FFD;GNSS receiver;GPS L1 C/A code signal;Galileo I/NAV;PVT solutions;TTFF;broadcast CED;clock and ephemeris data;clock drift;data message;data reduction;data retrieval;first-fix data;location based service;mass market;message transmission scheme;optimization;position error estimation;road navigation;satellite ephemeris;satellite orbit;signal acquisition","","0","","11","","","5-7 Dec. 2012","","IEEE","IEEE Conference Publications"
"Using frequency distance filteration for reducing database search workload on GPU-based cloud service","S. T. Lee; C. Y. Lin; C. L. Hung; H. Y. Huang","Dept. of Comput. Sci. &amp; Inf. Eng., Chang Gung Univ., Taoyuan, Taiwan","4th IEEE International Conference on Cloud Computing Technology and Science Proceedings","20130204","2012","","","735","740","The Smith-Waterman algorithm is the most widely used algorithm to analyze the similarity between protein and DNA sequences and suitable for the database search due to its high sensitivity. However, Smith-Waterman still is a very time-consuming method. CUDA programming can efficiently improve the computations by using the computing power of the massive computing hardware as GPUs. In this paper, we proposed an efficient frequency based filter method instead of just speed up the Smith-Waterman comparison but waste computing resource to deal with those unnecessary comparisons. We implemented the Smith-Waterman algorithm by introduction of the techniques from earlier researches and add in our real-time filter method on Graphic Processing Units to filter unnecessary comparisons. We also design a user friendly interface to provide the service in the potential clouding computing environment. In our research we choose two data sets, H1N1 VH protein database and Human protein database then compare CUDA-SW and CUDA-SW with filter, we called CUDA-SWf we can obtain up to 41% performance improve from reduce unnecessary sequence alignments.","","Electronic:978-1-4673-4510-1; POD:978-1-4673-4511-8; USB:978-1-4673-4509-5","10.1109/CloudCom.2012.6427539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427539","CUDA;GPGPU;Smith-Waterman;alignment;filter;sequence","Algorithm design and analysis;Arrays;Databases;Filtering algorithms;Graphics processing units;Instruction sets;Proteins","biology computing;cloud computing;database management systems;graphics processing units;information retrieval;parallel architectures;proteins;user interfaces","CUDA programming;CUDA-SWf;DNA sequences;GPU-based cloud service;H1N1 VH protein database;Smith-Waterman algorithm;cloud computing environment;database search workload reduction;frequency based filter method;frequency distance filteration;graphics processing units;human protein database;real-time filter method;sequence alignments;user friendly interface design","","1","","29","","","3-6 Dec. 2012","","IEEE","IEEE Conference Publications"
"Beyond Text QA: Multimedia Answer Generation by Harvesting Web Information","L. Nie; M. Wang; Y. Gao; Z. J. Zha; T. S. Chua","School of Computing, National University of Singapore","IEEE Transactions on Multimedia","20130115","2013","15","2","426","441","Community question answering (cQA) services have gained popularity over the past years. It not only allows community members to post and answer questions but also enables general users to seek information from a comprehensive set of well-answered questions. However, existing cQA forums usually provide only textual answers, which are not informative enough for many questions. In this paper, we propose a scheme that is able to enrich textual answers in cQA with appropriate media data. Our scheme consists of three components: answer medium selection, query generation for multimedia search, and multimedia data selection and presentation. This approach automatically determines which type of media information should be added for a textual answer. It then automatically collects data from the web to enrich the answer. By processing a large set of QA pairs and adding them to a pool, our approach can enable a novel multimedia question answering (MMQA) approach as users can find multimedia answers by matching their questions with those in the pool. Different from a lot of MMQA research efforts that attempt to directly answer questions with image and video data, our approach is built based on community-contributed textual answers and thus it is able to deal with more complex questions. We have conducted extensive experiments on a multi-source QA dataset. The results demonstrate the effectiveness of our approach.","1520-9210;15209210","","10.1109/TMM.2012.2229971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6362232","CQA;medium selection;question answering;reranking","Communities;Educational institutions;Humans;Media;Multimedia communication;Streaming media","Internet;multimedia systems;question answering (information retrieval);text analysis","MMQA approach;Web information harvesting;answer medium selection component;community question answering service;community-contributed textual answer;media information;multimedia answer generation;multimedia data presentation component;multimedia data selection component;multisource QA dataset;query generation component;text QA","","39","","59","","20121127","Feb. 2013","","IEEE","IEEE Journals & Magazines"
"Towards Social Networking: A Proof-of-Concept Model","Y. Sato; H. Shimokawa; S. Ata; I. Oka","Fac. of Maritime Safety Technol., Japan Coast Guard Acad., Hiroshima, Japan","2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing","20130110","2012","","","526","531","The structure of the current Internet does not fully reflect the structure of human relationships in the real world. Human relationships are structured as various community networks, however IP-based network is essentially not structured in terms of information retrieval and sharing. In the communication style on the current network, end node can obtain information and contents from the whole of the network. In social-centric networking, information is likely to be diffused and shared within community network that is related to the topic of the information, members of community network can obtain information related to the community more efficiently and rapidly. We believe that a social-centric networking paradigm would be a fundamental principle of communications in the future. In this paper, we propose a social-centric network architecture that leverages multiple network structures. One of our objectives is elimination of inefficiency on information diffusion due to gaps between the current network structure and the real world human relationships and community structure. We also propose a proof-of-concept model to evaluate efficiency of information diffusion in consideration of workload of node. We then show the improvement of load-balancing and efficiency of information retrieval through the results of mathematical analysis and simulation.","","Electronic:978-0-7695-4848-7; POD:978-1-4673-5638-1","10.1109/SocialCom-PASSAT.2012.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406303","Internet;communication;model;network structure;social networking","Communities;Convergence;Humans;Internet;Mathematical model;Measurement;Social network services","Internet;information retrieval;resource allocation;social networking (online)","IP-based network;Internet;human relationships;information diffusion;information retrieval;information sharing;load-balancing;mathematical analysis;proof-of-concept model;social-centric network architecture","","0","","10","","","3-5 Sept. 2012","","IEEE","IEEE Conference Publications"
"Development of phylogenetic tree based on Kimura's Method","P. Bhambri; O. P. Gupta","Department Of Information Technology, Guru Nanak Dev Engineering College, Ludhiana, Punjab, India","2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing","20130207","2012","","","721","723","The research in bioinformatics has accumulated large amount of data. The biological data is available in different formats and is comparatively more complex. The term bioinformatics is related to study of bio-molecules information. The informatics techniques are applied to understand and organize the information associated with these molecules. Substitutional of an alignment is one of the applications of the bioinformatics. Multiple Sequence Alignment is used to align the biological sequences along a column. As the process generates distances of multiple alignments among the pairs of different species, phylogenetic tree is being formulated. Multiple sequence alignment arranges the sequences in such a way that evolutionarily equivalent positions across all sequences are matched. Alignment of Substitutions made into two categories: Jukes Cantor Method and Kimura's Method. The Tree is being formulated from different tree building methods so as to retrieve an optimal tree. These tree building methods are divided into two categories: UPGMA method and NJ method. Web based format such as FASTA is used to organize the sequences of data and using these sequences, distances are obtained and these distances are helpful to construct an optimal tree.","","Electronic:978-1-4673-2925-5; POD:978-1-4673-2922-4","10.1109/PDGC.2012.6449910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6449910","Bioinformatics;FASTA;Phylogenetic Tree;Substitutional Methods;UPGMA","Agriculture","Internet;bioinformatics;genetics;information retrieval;molecular biophysics;tree data structures","FASTA;Jukes Cantor method;Kimura method;NJ method;UPGMA method;Web-based format;ali sequences;bioinformatics;biological data;biological sequence alignment;biomolecule information;data sequence organization;information organization;multiple sequence alignment;optimal tree retrieval;phylogenetic tree development;tree building method","","0","","9","","","6-8 Dec. 2012","","IEEE","IEEE Conference Publications"
"User Interests Modeling in Online Forums","N. Ni; Y. Li","Inst. of Autom., Beijing, China","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","708","709","This paper studies the problem of user modeling in online forums from a personality viewpoint. A novel hierarchical user profiling mechanism is proposed, which utilizes the user-generated content, the reply relations among users and the topics of the discussions. The hierarchical model represent the users' interests across different topics. The obtained user profiles are applied to three forum-related tasks: new discussions recommendation, external news articles recommendation and user retrieval. The experimental results show that, comparing with the traditional methods, the hierarchical user profiling approach achieves a better performance in all three tasks.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425683","hierarchical model;online forum;user modeling","Analytical models;Blogs;Collaboration;Measurement;Media;Social network services;Training","information retrieval;interactive programming;recommender systems;social networking (online);user interfaces","discussions recommendation;external news articles recommendation;hierarchical user profiling mechanism;online forums;personality viewpoint;user interests modeling;user retrieval","","0","","2","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"STUN: Spatio-Temporal Uncertain (Social) Networks","C. Kang; A. Pugliese; J. Grant; V. S. Subrahmanian","Comput. Sci. Dept., Univ. of Maryland, College Park, MD, USA","2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","20130204","2012","","","543","550","STUN is an extension of social networks in which the edges are characterized by spatio-temporal annotations, as well as uncertainty allowing us to express not only relationships between vertices, but when and where these relationships were true, and how certain we are that the relationships hold. We propose a STUN query language that consists of sub graphs with spatio-temporal constraints and uncertainty requirements. We then develop an index structure to store STUN graphs, together with an algorithm to answer such queries. We describe experiments with a real-world YouTube social network data set and show that our algorithm performs well on graphs with over a million edges.","","Electronic:978-0-7695-4799-2; POD:978-1-4673-2497-7","10.1109/ASONAM.2012.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425711","","Educational institutions;Electronic mail;Facebook;Indexes;Knowledge based systems;Uncertainty","network theory (graphs);query languages;question answering (information retrieval);social networking (online);spatiotemporal phenomena;uncertainty handling","STUN;YouTube;index structure;query language;question answering system;social network;spatiotemporal constraint;spatiotemporal uncertain network;subgraph;uncertainty requirement","","0","","13","","","26-29 Aug. 2012","","IEEE","IEEE Conference Publications"
"Programming tools used in forensic approach for the internet sites contents discovering","L. M. Stefanović; J. Mirčevski","JKP BVK, Beograd, Deligradska 28, 11000 Beograd, Srbija","2012 20th Telecommunications Forum (TELFOR)","20130124","2012","","","1492","1495","This paper presents authors experiens in the software tools using in the forensic purpose. With program was detected the sound files currently existing on the web site and throw that was proved the copyright security violation. The program performance which used in world forensic praxis were discussed and the parts of output files and retrieving results are presented. The capabilities and limities are evaluated.","","Electronic:978-1-4673-2984-2; POD:978-1-4673-2983-5","10.1109/TELFOR.2012.6419502","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6419502","Forenzički programski alati;intelektualna svojina;off line pretaživanje;skidanje sadržaja web sajta","Cloud computing;Electronic mail;Forensics;HTML;Manuals;Telecommunications","Internet;Web sites;copyright;digital forensics;information retrieval;software tools","Internet Web site content discovery;copyright security violation;file detection;forensic praxis;software programming tools","","0","","9","","","20-22 Nov. 2012","","IEEE","IEEE Conference Publications"
"Study of Real-time Database Based on Common Information Model","Y. Li; J. Jun; L. Ling","Shandong Polytech., Jinan, China","2013 Third International Conference on Intelligent System Design and Engineering Applications","20130207","2013","","","1312","1315","In electric power company, there are some different application information systems for different departments. Lack of unified planning, design, a large number of data information is repeated input, maintenance, waste of a lot of manpower. IEC 61970/61968 common information model (CIM) and component interface specification (CIS) are used for deal with these problems. This paper proposes a real-time database design using CIM. CIM XML files and MySQL database are used for electric power grid data model saving. Based on Light OPC, the real-time data access mode is realized. A prototype is presented and verifies the IEC 61970 the feasibility of application of OPC.","","Electronic:978-0-7695-4923-1; POD:978-1-4673-4893-5","10.1109/ISDEA.2012.310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6456047","Common Information Model;Object Oriented;Real-Time Database","Computer integrated manufacturing;IEC standards;Object oriented modeling;Real-time systems;Servers;XML","IEC standards;SQL;XML;database management systems;information retrieval;power engineering computing;power grids;real-time systems","CIM XML files;CIS;IEC 61968 standard;IEC 61970 standard;Light OPC;MySQL database;OLE for process control;OPC;application information systems;common information model;component interface specification;electric power grid data model;real-time data access mode;real-time database design","","1","","5","","","16-18 Jan. 2013","","IEEE","IEEE Conference Publications"
"Improved Question Answering System by semantic refomulation","M. Umamehaswari; M. Ramprasath; S. Hariharan","J. J. College of engineering and technology Department CSE, Trichy, India","2012 Fourth International Conference on Advanced Computing (ICoAC)","20130124","2012","","","1","4","A unbearable amount of textual information accessible in electronic form and need to deliver correct answer to user question is important task in Question Answering System (QAS). Question answer system is the form of information retrieval system which aims to deliver the exact answer to the user question rather than whole document. To answer this user need semantic based reformulation techniques can be used to retrieve the accurate answer from enormous number of document retrieved from the search engine. The goal is to generate the pattern from the web based on lexical semantic and syntactic constrain. These constrain should be defined in the question answering system to evaluate and rank the candidate answer. Here we used TREC-8, TREC-9, and TREC-10 collection as training set. Different types of question and corresponding answer can use from TREC collection. The proposed system retrieves the answer automatically from TREC collection. Word net can be used to help the semantic relation and syntactic tag between the questions and answer pair. Finally weight can be given to each candidate answer according to their length, the level of semantic similarity between question and answer pair and distance between the key word. The proposed QAS be different from other reformulation based Question answering system. The experiments on the TREC data set will show the better result which can be calculated with help of the precision and recall.","2377-6927;23776927","Electronic:978-1-4673-5584-1; POD:978-1-4673-5583-4","10.1109/ICoAC.2012.6416824","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416824","Question Answering System (QAS);Semantic based reformulation system;Text reterieval Conference(TREC);Web Search engine;WordNet","Knowledge discovery;NIST;Pragmatics;Search engines;Semantics;Syntactics","question answering (information retrieval);search engines;semantic Web","QAS;TREC data set;TREC-10;TREC-8;TREC-9;electronic form;information retrieval system;lexical semantic;question answering system;search engine;semantic based reformulation techniques;syntactic constrain;textual information","","0","","21","","","13-15 Dec. 2012","","IEEE","IEEE Conference Publications"
