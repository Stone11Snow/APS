"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7162579,7094223,6920094,7155853,7159310,7160842,7160900,7159492,7160185,7160265,7160055,6881749,7154738,7155011,7154781,7152609,7152571,7149025,7152575,7150570,7150302,7148398,7150294,7148149,7148105,7148382,7145925,7139745,7130869,7131215,7129092,7129495,7131796,7130158,7129801,7130457,7130342,7129809,7130444,7130447,7126186,7129870,7130287,7102989,7124778,7122532,7123035,7119729,7119721,7117005,7119130,6963383,7116011,7117742,7095595,6879441,6945901,7113179,7113655,7107596,7101499,7100375,7100708,7093752,7090813,7093402,7092591,7089079,7087825,7086616,7087203,7087030,7070704,7081945,7079049,7079148,7079116,6883187,7079363,7077807,7073023,7078591,7078698,7074259,7075244,7069529,7066727,7066643,7066645,7066464,7068167,7066648,7068202,7066425,7064376,7064375,7063061,7061895,7063092,7059719",2017/05/04 23:31:06
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Classification with Extreme Learning Machine and ensemble algorithms over randomly partitioned data","F. Ö. Çatak","Siber Guvenlik Enstitusu, TUBITAK BILGEM, Kocaeli, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","228","231","In this age of Big Data, machine learning based data mining methods are extensively used to inspect large scale data sets. Deriving applicable predictive modeling from these type of data sets is a challenging obstacle because of their high complexity. Opportunity with high data availability levels, automated classification of data sets has become a critical and complicated function. In this paper, the power of applying MapReduce based Distributed AdaBoosting of Extreme Learning Machine (ELM) are explored to build reliable predictive bag of classification models. Thus, (i) dataset ensembles are build; (ii) ELM algorithm is used to build weak classification models; and (iii) build a strong classification model from a set of weak classification models. This training model is applied to the publicly available knowledge discovery and data mining datasets.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7129801","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129801","AdaBoost;Big Data;Ensemble Methods;Extreme Learning Machine;MapReduce","Big data;Data mining;Data models;Partitioning algorithms;Predictive models;Reliability;Skin","Big Data;data mining;learning (artificial intelligence);pattern classification","Big Data;ELM;MapReduce based distributed AdaBoosting;data set classification;ensemble algorithms;extreme learning machine;knowledge discovery;machine learning based data mining methods;predictive bag of classification models;randomly partitioned data","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Predicting source gaze fixation duration: A machine learning approach","T. Saikh; S. Bangalore; M. Carl; S. Bandyopadhyay","CSE Department, Jadavpur University, Kolkata, India","2015 International Conference on Cognitive Computing and Information Processing(CCIP)","20150504","2015","","","1","6","In this paper an attempt has been made to predict the gaze fixation duration at source text words using supervised learning method, namely Support Vector Machine. The machine learning models used in the present work make use of lexical, syntactic and semantic information for predicting the gaze fixation duration. Different features are extracted from the data and models are built by combining the features. Our best set up achieves close to 50% classification accuracy.","","Electronic:978-1-4799-7171-8; POD:978-1-4799-7172-5","10.1109/CCIP.2015.7100708","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100708","Eye Tracking;Gaze fixation duration;Machine Learning;Support Vector Machine","Accuracy;Correlation coefficient;Entropy;Feature extraction;Linear regression;Predictive models;Syntactics","feature extraction;gaze tracking;image classification;learning (artificial intelligence);support vector machines","classification accuracy;feature extraction;lexical information;machine learning approach;semantic information;source gaze fixation duration prediction;source text words;supervised learning method;support vector machine;syntactic information","","0","","16","","","3-4 March 2015","","IEEE","IEEE Conference Publications"
"Study on feature selection and machine learning algorithms for Malay sentiment classification","A. Alsaffar; N. Omar","Center for AI Technology, FTSM, University Kebangsaan Malaysia, UKM, 43000 Bangi Selangor, Malaysia","Proceedings of the 6th International Conference on Information Technology and Multimedia","20150326","2014","","","270","275","Online social media is used to show the sentiments of different individuals about various subjects. Sentiment analysis or opinion mining has recently been considered as one of the highly dynamic research fields in natural language processing, Web mining, and machine learning. There has been a very limited amount of research that focuses on sentiment analysis in the Malay language. This study investigates how feature selection methods contribute to the improvement of Malay sentiment classification performance. Three supervised machine-learning classifiers and seven feature selection methods are used to conduct a series of experiments for the effective selection of the appropriate methods for the automatic sentiment classification of online Malay-written reviews. Findings show that the classifications of Malay sentiment improve using feature selections approaches. This work demonstrates that all feature reduction methods generally improve classifier performance. Support Vector Machine (SVM) approach provide the highest accuracy performance of features selection in order to classify Malay sentiment comparing with other classifications approaches such as PCA and CHI square. SVM records 87% as experimental accuracy result of feature selection.","","Electronic:978-1-4799-5423-0; POD:978-1-4799-5424-7","10.1109/ICIMU.2014.7066643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066643","Classifications;Feature Selection;Machine Learning;NLP;Sentiment analysis","Classification algorithms;Niobium;Principal component analysis;Sentiment analysis;Support vector machine classification;Training","feature selection;learning (artificial intelligence);natural language processing;pattern classification;social networking (online);support vector machines","Malay language;Malay sentiment classification performance improvement;SVM approach;automatic sentiment classification;feature reduction methods;feature selection;online Malay-written reviews;online social media;opinion mining;sentiment analysis;supervised machine-learning classifiers;support vector machine approach","","4","","25","","","18-20 Nov. 2014","","IEEE","IEEE Conference Publications"
"Machines Learning Culture","A. Kelliher","Carnegie Mellon University","IEEE MultiMedia","20150622","2015","22","2","18","22","Recent interdisciplinary explorations, integrating computer science, math, the digital humanities, and the arts, point to the utilitarian and expressive capabilities of machine-learning approaches in creating work with diverse appeal. These initiatives include research within the relatively traditional domain of historical art analysis, a growing collection of body-tracking work using machine learning in the background, and a variety of provocative art installations that place algorithmic computing front and center. While these projects tackle their subject at varying levels of scale and depth and in different contexts, each contributes to building the public discourse about the impact, role, and reach of machine learning in our lives.","1070-986X;1070986X","","10.1109/MMUL.2015.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130457","big data;data analysis;graphics;machine learning;multimedia;visualization","Art;Artificial intelligence;Digital art;Machine vision;Media;Motion pictures;Visualization","art;learning (artificial intelligence)","computer science;digital humanities;historical art analysis;machine learning approach;provocative art installations;public discourse","","0","","4","","","Apr.-June 2015","","IEEE","IEEE Journals & Magazines"
"Machine-learning-integrated load scheduling for peak electricity reduction","M. Sung; Y. Ko","Dept. of Mechanical and Information Engineering, University of Seoul, Korea","2015 IEEE International Conference on Consumer Electronics (ICCE)","20150326","2015","","","309","310","The scheduling of household electrical loads can contribute to a significant reduction in peak demand. This paper introduces a load scheduling scheme that integrates an SVM (Support Vector Machine) model for demand prediction. The experiment results confirm the strength of the proposed scheme, showing its ability to achieve the intended performance in consideration of the trade-off among peak reduction, temperature band violation, and switch count.","2158-3994;21583994","CD-ROM:978-1-4799-7542-6; Electronic:978-1-4799-7543-3; POD:978-1-4799-7544-0","10.1109/ICCE.2015.7066425","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066425","","Electricity;Job shop scheduling;Load modeling;Predictive models;Refrigerators;Support vector machines;Switches","learning (artificial intelligence);power engineering computing;power generation scheduling;support vector machines","SVM;demand prediction;household electrical load scheduling;integrated load scheduling;machine learning;peak electricity reduction;support vector machine","","1","","2","","","9-12 Jan. 2015","","IEEE","IEEE Conference Publications"
"An improved algorithm model based on machine learning","Z. Ke; W. Huan; W. Ruo-fan; Q. Xin","School of Advanced Engineering, University of Science & Technology Beijing, Beijing, China, 100083","The 27th Chinese Control and Decision Conference (2015 CCDC)","20150720","2015","","","3754","3757","In the last decades, Reinforcement Learning (RL) algorithm has attracted more and more attention, and become the research focus in the field of machine learning. This paper leads the typical RL algorithm, Q-learning algorithm, into computer game platform (Connect6), and proposes an improved method. We adjust reward parameter according to the shape of Connect6, and optimize the adjustment of evaluation function to achieve the global optimization. Moreover, the optimization of the reward makes the valueless units away from the evaluation, to reduce the interference of valueless units for optimal results and improve the convergence speed, thereby reducing the overall time of self-learning process.","1948-9439;19489439","CD-ROM:978-1-4799-7016-2; Electronic:978-1-4799-7017-9; POD:978-1-4799-7018-6","10.1109/CCDC.2015.7162579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7162579","Computer Game;Connect6;Evaluation Function;Machine Learning;Q-learning","Algorithm design and analysis;Computers;Convergence;Games;Learning (artificial intelligence);Shape;Training","computer games;convergence;learning (artificial intelligence);optimisation","Connect6;Q-learning algorithm;RL algorithm;computer game platform;convergence speed;evaluation function;global optimization;machine learning;reinforcement learning algorithm;reward parameter;self-learning process","","0","","19","","","23-25 May 2015","","IEEE","IEEE Conference Publications"
"Optimizing dynamic trace signal selection using machine learning and linear programming","C. S. Zhu; S. Malik","Princeton University, Princeton, NJ 08544 USA","2015 Design, Automation & Test in Europe Conference & Exhibition (DATE)","20150423","2015","","","1289","1292","The success of post-silicon validation is limited by the low observability of the signals on the chip under debug. Trace buffers are used to enhance visibility of a subset of the internal signals during the chip's operation. These trace signals can be selected statically, i.e. the same trace signals are used through an entire debugging run, or dynamically where a different set of signals can be used in different parts of a debugging run. The focus of this work is on dynamic trace signal selection. Our technique uses machine learning for classification of different groups of inputs that are likely to trigger different faults, and a linear programming based optimization method for selecting the different sets of trace signals for different combinations of inputs and states. In contrast to existing methods, this technique is applicable to both transient and permanent faults.","1530-1591;15301591","Electronic:978-3-9815-3705-5; POD:978-1-4799-6404-8","10.7873/DATE.2015.0573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092591","","Circuit faults;Debugging;Decision trees;Heuristic algorithms;Multiplexing;Registers;Transient analysis","learning (artificial intelligence);linear programming;observability;signal classification;signal processing","chip operation;dynamic trace signal selection optimization;internal signals;linear programming;linear programming based optimization method;machine learning;permanent faults;post-silicon validation;transient faults","","0","","9","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Cloud-Based Machine Learning Tools for Enhanced Big Data Applications","A. Cuzzocrea; E. Mumolo; P. Corona","ICAR, Univ. of Calabria, Cosenza, Italy","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","20150709","2015","","","908","914","We propose Cloud-based machine learning tools for enhanced Big Data applications, where the main idea is that of predicting the ""next"" workload occurring against the target Cloud infrastructure via an innovative ensemble-based approach that combine the effectiveness of different well-known classifiers in order to enhance the whole accuracy of the final classification, which is very relevant at now in the specific context of Big Data. So-called workload categorization problem plays a critical role towards improving the efficiency and the reliability of Cloud-based big data applications. Implementation-wise, our method proposes deploying Cloud entities that participate to the distributed classification approach on top of virtual machines, which represent classical ""commodity"" settings for Cloud-based big data applications. Preliminary experimental assessment and analysis clearly confirm the benefits deriving from our classification framework.","","Electronic:978-1-4799-8006-2; POD:978-1-4799-8007-9","10.1109/CCGrid.2015.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152575","","Benchmark testing;Big data;Discrete cosine transforms;Hidden Markov models;Machine learning algorithms;Training;Virtual machining","Big Data;cloud computing;learning (artificial intelligence);pattern classification;reliability;virtual machines","cloud entities;cloud infrastructure;cloud-based big data applications;cloud-based machine learning tools;enhanced Big Data applications;innovative ensemble-based approach;virtual machines;workload categorization problem","","0","","50","","","4-7 May 2015","","IEEE","IEEE Conference Publications"
"MALMOS: Machine Learning-Based Mobile Offloading Scheduler with Online Training","H. Eom; R. Figueiredo; H. Cai; Y. Zhang; G. Huang","Adv. Comput. & Inf. Syst. Lab., Univ. of Florida, Gainesville, FL, USA","2015 3rd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering","20150625","2015","","","51","60","This paper proposes and evaluates MALMOS, a novel framework for mobile offloading scheduling based on online machine learning techniques. In contrast to previous works, which rely on application-dependent parameters or predefined static scheduling policies, MALMOS provides an online training mechanism for the machine learning-based runtime scheduler such that it supports a flexible policy that dynamically adapts scheduling decisions based on the observation of previous offloading decisions and their correctness. To demonstrate its practical applicability, we integrated MALMOS with an existing Java-based, offloading-capable code recapturing framework, Partner. Using this integration, we performed quantitative experiments to evaluate the performance and cost for three machine learning algorithms: instance-based learning, perception, and naive Bays, with respect to classifier training time, classification time, and scheduling accuracy. Particularly, we examined the adaptability of MALMOS to various network conditions and computing capabilities of remote resources by comparing the scheduling accuracy with two static scheduling cases: threshold-based and linear equation-based scheduling policies. Our evaluation uses an Android-based prototype for experiments, and considers benchmarks with different computation/communication characteristics, and different computing capabilities of remote resources. The evaluation shows that MALMOS achieves 10.9%~40.5% higher scheduling accuracy than two static scheduling policies.","","Electronic:978-1-4799-8977-5; POD:978-1-4799-8978-2","10.1109/MobileCloud.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130869","computation offloading;machine learning;mobile platform;online training;runtime scheduler","Accuracy;Dynamic scheduling;Mobile communication;Processor scheduling;Runtime;Training","Bayes methods;Java;learning (artificial intelligence);mobile computing;pattern classification;scheduling;software maintenance","Android-based prototype;DPartner;Java-based offloading-capable code refactoring framework;MALMOS;application-dependent parameters;classification time;classifier training time;flexible policy;instance-based learning;linear equation-based scheduling policies;machine learning-based mobile offloading scheduler;machine learning-based runtime scheduler;naive Bayes;online machine learning techniques;online training;online training mechanism;perceptron;scheduling accuracy;static scheduling cases;static scheduling policies;threshold-based scheduling policies","","1","","20","","","March 30 2015-April 3 2015","","IEEE","IEEE Conference Publications"
"Machine learning approaches to improving pronunciation error detection on an imbalanced corpus","X. Yang; A. Loukina; K. Evanini","Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, 61801, USA","2014 IEEE Spoken Language Technology Workshop (SLT)","20150402","2014","","","300","305","In this paper, we investigate the task of phone-level pronunciation error detection as a binary classification problem, the performance of which is heavily affected by the imbalanced distribution of the classes in a manually annotated data set of non-native English. In order to address problems caused by this extreme class imbalance, methods for cost-sensitive learning (weighting inversely proportional to class frequencies) and over-sampling of synthetic instances (SMOTE) are investigated in order to improve classification performance. Experiments using classifiers consisting of features based on acoustic phonetics and word identity demonstrate that these machine learning approaches lead to performance improvements over the baseline system based on the extremely imbalanced data. In addition, several different types of classifiers were compared. Finally, the paper analyzes the robustness of classifier performance across different phones.","","Electronic:978-1-4799-7129-9; POD:978-1-4799-7130-5; USB:978-1-4799-7128-2","10.1109/SLT.2014.7078591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078591","Imbalanced Learning;Pronunciation Error Detection;Sampling Methods;Spoken Language Assessment","Abstracts;Acoustics;Pragmatics;Speech","computer based training;learning (artificial intelligence);pattern classification;sampling methods;speech processing","SMOTE;acoustic phonetics;binary classification problem;cost-sensitive learning;imbalanced corpus;machine learning approaches;nonnative English;phone-level pronunciation error detection;pronunciation error detection;synthetic instances over-sampling;word identity","","0","","17","","","7-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"Extreme learning machine with dead zone and its application to WiFi based indoor positioning","X. Lu; C. Yu; H. Zou; H. Jiang; L. Xie","School of Electrical and Electrical Engineering, Nanyang Technological University, Singapore","2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)","20150323","2014","","","625","630","Extreme learning machine (ELM) as an emergent technology has shown its good performance in regression applications as well as in large dataset classification applications. It has been broadly embedded in many applications due to its fast speed of computation and accuracy. How to make good use of machine learning techniques in Indoor Positioning System (IPS) is a hot research topic in recent years. Some existing IPSs have already adopted ELM, but it suffers from signal variation and environmental dynamics in indoor settings. In this paper, extreme learning machine with dead zone (DZ-ELM) is proposed to address this problem. The consistency of this approach should be applied is studied. Simulations are also conducted to compare the performance of DZ-ELM and ELM. Lastly, real-world experimental results show that the proposed algorithm can not only provide higher accuracy but also improve the repeatability of IPSs.","","Electronic:978-1-4799-5199-4; POD:978-1-4799-5200-7; USB:978-1-4799-5198-7","10.1109/ICARCV.2014.7064376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064376","","Accuracy;Calibration;IEEE 802.11 Standards;Noise;Testing;Training;Vectors","indoor navigation;indoor radio;learning (artificial intelligence);wireless LAN","WiFi based indoor positioning;dataset classification;dead zone;extreme learning machine;indoor positioning system;machine learning techniques","","1","","16","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Performance Analysis of Unsupervised Machine Learning Techniques for Network Traffic Classification","H. Singh","Lovely Prof. Univ., Phagwara, India","2015 Fifth International Conference on Advanced Computing & Communication Technologies","20150406","2015","","","401","404","Network traffic classification is important for QoS, Network management and security monitoring. Current method for traffic classification such as port based or payload based suffered many problems. Newly emerged application uses encryption and dynamic port numbers to avoid detection. So we use unsupervised machine learning approach to classify the network traffic. In this paper unsupervised K-means and Expectation Maximization algorithm are used to cluster the network traffic application based on similarity between them. Performance of these two algorithms is compared in terms of classification accuracy between them. The experiment results show that K-Means and EM perform well but accuracy of K-Means is better than EM and it form better cluster.","2327-0632;23270632","Electronic:978-1-4799-8488-6; POD:978-1-4799-8489-3","10.1109/ACCT.2015.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079116","Clustering;K-Means;Machine learning;Network traffic;unsupervised","Accuracy;Classification algorithms;Clustering algorithms;Internet;Machine learning algorithms;Ports (Computers);Telecommunication traffic","computer networks;cryptography;expectation-maximisation algorithm;learning (artificial intelligence);telecommunication network management","QoS;dynamic port numbers;encryption;expectation maximization algorithm;network management;network traffic classification;security monitoring;unsupervised K-means;unsupervised machine learning techniques","","0","","12","","","21-22 Feb. 2015","","IEEE","IEEE Conference Publications"
"Pattern recognition with novel support vector machine learning method","M. Lehtokangas","Digital and Computer Systems Laboratory, Tampere University of Technology, P.O. Box 553, Tampere, Finland","2000 10th European Signal Processing Conference","20150402","2000","","","1","4","The concept of optimal hyperplane has been recently proposed in the context of statistical learning theory. The important property of an optimal hyperplane is that it provides maximum margins to each class to be separated. Obviously, such a decision boundary is expected to yield good generalization. Currently, the support vector machines (SVM) are probably one of the very few models (if not the only ones) that make use of the optimal hyperplane concept. In this study we investigate the basic SVM method and point out some problems that may arise especially in large scale problems with abundant data. Moreover, we propose a novel SVM type method that aims to avoid the problems found in the basic method. The experimental results demonstrate that the proposed method can give very good classification performance. However, the results also point out another potential problem in the SVM scheme which should be considered in the future studies.","","POD:978-952-1504-43-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7075244","","Databases;Learning systems;Neural networks;Optimization;Support vector machines;Training;Vectors","","","","0","","","","","4-8 Sept. 2000","","IEEE","IEEE Conference Publications"
"Wireless Sensor Network for Distributed Event Detection Based on Machine Learning","S. Rashid; U. Akram; S. Qaisar; S. A. Khan; E. Felemban","Nat. Univ. of Sci. & Technol., Rawalpindi, Pakistan","2014 IEEE International Conference on Internet of Things (iThings), and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom)","20150316","2014","","","540","545","Pipelines are one of the most widely used means for oil/gas and water transportation worldwide. These pipelines are often subject to failures like erosion, sabotage and theft, causing high financial, environmental and health risks. Therefore, detecting leakages, estimating its size and location is very important. Current pipeline monitoring systems needs to be more automated, efficient and accurate methods for continuous inspection/reporting about faults. For this purpose, several pattern recognition and data mining techniques have been brought into the research community. In light of the issues of low efficiency and high false alarm rates in traditional pipeline condition monitoring, in this paper, we have used negative pressure wave (NPW) coupled with intelligent machine learning techniques integrated in distributed wireless sensor network (WSN) to identify specific events beased on raw data gathered by individual sensor nodes. This collaborative approach reduces communication overhead to minimum by processing raw data on sensor nodes directly and reporting the detected events only. We apply the methods of support vector machine (SVM), K-nearest neighbor (KNN) and Gaussian mixture model (GMM) in multi-dimensional feature space. The suggested technique is validated using a serial publication of experimentation on a field deployed test bed, with regard to performance of detection of leakages in pipelines.","","Electronic:978-1-4799-5967-9; POD:978-1-4799-5968-6","10.1109/iThings.2014.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7059719","Gaussian Mixture Model (GMM);K-nearest neighbor (KNN);Negative pressure wave (NPW);Support Vector Machine (SVM);Wireless sensor network (WSN)","Accuracy;Event detection;Feature extraction;Noise;Pipelines;Support vector machines","Gaussian processes;condition monitoring;data mining;leak detection;learning (artificial intelligence);mixture models;pattern recognition;pipelines;support vector machines;wireless sensor networks","Gaussian mixture model;K-nearest neighbor;data mining technique;distributed event detection;distributed sensor network;gas pipelines;intelligent machine learning technique;leakage detection;multidimensional feature space;negative pressure wave;oil pipelines;pattern recognition;pipeline monitoring system;support vector machine;water pipelines;wireless sensor network","","3","","12","","","1-3 Sept. 2014","","IEEE","IEEE Conference Publications"
"Weighted Tanimoto Extreme Learning Machine with Case Study in Drug Discovery","W. M. Czarnecki","Faculty of Mathematics and Computer Science, Jagiellonian University, Krakow, Poland","IEEE Computational Intelligence Magazine","20150716","2015","10","3","19","29","Machine learning methods are becoming more and more popular in the field of computer-aided drug design. The specific data characteristic, including sparse, binary representation as well as noisy, imbalanced datasets, presents a challenging binary classification problem. Currently, two of the most successful models in such tasks are the Support Vector Machine (SVM) and Random Forest (RF). In this paper, we introduce a Weighted Tanimoto Extreme Learning Machine (T-WELM), an extremely simple and fast method for predicting chemical compound biological activity and possibly other data with discrete, binary representation. We show some theoretical properties of the proposed model including the ability to learn arbitrary sets of examples. Further analysis shows numerous advantages of T-WELM over SVMs, RFs and traditional Extreme Learning Machines (ELM) in this particular task. Experiments performed on 40 large datasets of thousands of chemical compounds show that T-WELMs achieve much better classification results and are at the same time faster in terms of both training time and further classification than both ELM models and other state-of-the-art methods in the field.","1556-603X;1556603X","","10.1109/MCI.2015.2437312","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160842","","Biological system modeling;Compounds;Computational modeling;Design automation;Drugs;Fingerprint recognition;Machine learning","drug delivery systems;learning (artificial intelligence);medical computing;pattern classification;support vector machines","RF;SVM;T-WELM;binary classification problem;chemical compound biological activity prediction;computer-aided drug design;data characteristic;drug discovery;random forest;support vector machine;weighted Tanimoto extreme learning machine method","","6","","45","","","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"An efficient unstructured big data analysis method for enhancing performance using machine learning algorithm","A. K. Reshmy; D. Paulraj","Anna University, Chennai, Tamil Nadu","2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]","20150716","2015","","","1","7","In this modern world, data mining technology holds an essential position in all the major Engineering fields. Handling of Unstructured Big Data is an essential task of this era. At present, making the maximum advantage of parallel processing know-hows and the task of rapid examination of huge data steadily and continuously transmitted or received from various sources is becoming popular or conventional. The big data analytics job is fragmented into smaller jobs and ran over tens, hundreds or thousands of product servers by the parallel processing architecture. This helps in maintaining the data center cost efficient and facilitates easy handling of the enormous work in an efficient way. In this paper, proposed solution takes online consumer purchase. The online system has unrivalled bank of data on online consumer purchasing behavior that can be mined from its 100 million customers accounts. They use customer click-stream data and historical purchase data of all those 100 million customers and each user is shown personalized results on customized web pages. For improving Big Data performance the Machine Learning Method i.e. K-Nearest Neighbour algorithm used to support to take good analysis. Hadoop simulator is used to solve this kind of task.","","DVD:978-1-4799-7074-2; Electronic:978-1-4799-7075-9; POD:978-1-4799-7076-6","10.1109/ICCPCT.2015.7159492","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7159492","Hadoop Frame Work;Machine Learning Algorithm;Parallel Processing Technologies;Unstructured Big Data","Big data;Business;Computers;Data mining;Databases;Industries;Machine learning algorithms","Big Data;Web sites;data analysis;learning (artificial intelligence);parallel processing","Hadoop simulator;K-nearest neighbour algorithm;Web pages;customer click-stream data;historical purchase data;machine learning algorithm;unstructured big data analysis method","","0","","11","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Machine learning and its applications in e-learning systems","M. Krendzelak","Technical University of Kosice, TUKE FEI KPI, Kosice, Slovakia","2014 IEEE 12th IEEE International Conference on Emerging eLearning Technologies and Applications (ICETA)","20150514","2014","","","267","269","Exploiting the ceaselessly enhancing, online learning frameworks assumes a paramount part for adjusting toward oneself, particularly on account of working individuals. All things considered, learning frameworks don't for the most part adjust to learners' profiles. Learners need to invest a ton of time before arriving at the learning objective that is perfect with their insight foundation. This paper investigates Machine learning and its applications in E-Learning frameworks. Machine learning, we may say, is a sort of artificial intelligence (AI) that gives machines the capacity to learn without being expressly customized. Machine learning concentrates on the advancement of machine projects that can develop themselves and change when presented to new information [8].","","CD-ROM:978-1-4799-7738-3; Electronic:978-1-4799-7740-6; POD:978-1-4799-7741-3","10.1109/ICETA.2014.7107596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107596","","Adaptation models;Electronic learning;Organizations;Predictive models","computer aided instruction;learning (artificial intelligence)","AI;artificial intelligence;e-learning systems;machine learning","","0","","10","","","4-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Categorize the video server in P2P networks based on seasonal and normal popularity videos using machine learning approach","M. Narayanan; C. Arun","Faculty of Computer Science and Engineering, Department of Computer Science and Engineering, Sathyabama University, Chennai","2015 2nd International Conference on Electronics and Communication Systems (ICECS)","20150618","2015","","","1220","1228","There is a wide-ranging use of Peer-to-Peer (P2P) computing and applications in majority of the key areas of Engineering and Technology. Devoid of any centralized server, they can share their content since peers are linked with each other. This is the reason why P2P computing gives enhanced communication among peers. It is essential for the video server to maintain the data content link in cache memory so the cache memory sizes will be enlarged to a definite level and also the cache needs to be securely sustained by each and every peers. By utilizing the Machine Learning method, the proposed method centers its concentration on classifying the video server depending on seasonal and non seasonal popularity. Two supervised Machine Learning algorithms are utilized in this paper and are explained as follows. The Case-Based Reasoning algorithm is utilized in order to sort out well-liked videos and the Averaged One-Dependence Estimators (AODE) algorithm is utilized to sort out video server into seasonal and non-seasonal. The first algorithm is based on Retrieve, Reuse, Revise and Retain methods and the latter algorithm sorts out the video server into seasonal and non-seasonal based video servers. The work simulated by Java programming language.","","Electronic:978-1-4799-7225-8; POD:978-1-4799-7226-5","10.1109/ECS.2015.7124778","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7124778","Averaged One-Dependence Estimators;Case-Based Reasoning;Machine Learning Approach;P2P Networks;Video on Demand Service","Classification algorithms;Cognition;Entertainment industry;Machine learning algorithms;Media;Servers;Streaming media","cache storage;case-based reasoning;learning (artificial intelligence);peer-to-peer computing;video on demand;video servers","AODE algorithm;Java programming language;P2P computing;P2P networks;averaged one-dependence estimators algorithm;cache memory sizes;case-based reasoning algorithm;centralized server;communication enhancement;content sharing;data content link;normal popularity videos;peer-to-peer computing;retain method;retrieve method;reuse method;revise method;seasonal popularity videos;supervised machine learning algorithms;video server;video-on-demand service","","0","","15","","","26-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"Arabic keyphrases extraction using a hybrid of statistical and machine learning methods","N. G. Ali; N. Omar","Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, 43600 Bangi, Selangor, Malaysia","Proceedings of the 6th International Conference on Information Technology and Multimedia","20150326","2014","","","281","286","Keyphrases are single-word or multi-word lexemes that concisely and accurate describe the subject or side of the subject discuss in a document. Manually assigning keyphrases is tedious and time consuming, especially because of Web proliferation. Thus, automatic keyphrase generation systems are urgently needed. This study proposes a keyphrase extraction method that combines several keyphrase extraction methods with the use of machine learning approaches (linear logistic regression, linear discriminant analysis, and support vector machines). The proposed methods use the output of several keyphrase extraction methods as input features for a machine learning algorithm, which then determines whether each term is a keyphrase. Results show that the SVM algorithm achieves the best performance with F1-measures 88.31%. These values are relatively high and comparable with those of previous keyphrase extraction models for the Arabic language.","","Electronic:978-1-4799-5423-0; POD:978-1-4799-5424-7","10.1109/ICIMU.2014.7066645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066645","arabic decoment machine learning;features;keyphrase extraction","Data mining;Feature extraction;Information technology;Learning systems;Logistics;Semantics;Support vector machines","feature extraction;learning (artificial intelligence);natural language processing;pattern classification;regression analysis;support vector machines;text analysis","Arabic keyphrase extraction;Web proliferation;linear discriminant analysis;linear logistic regression;machine learning method;statistical method;support vector machine","","0","","17","","","18-20 Nov. 2014","","IEEE","IEEE Conference Publications"
"Network State-Based Algorithm Selection for Power Flow Management Using Machine Learning","J. E. King; S. C. E. Jupe; P. C. Taylor","Parsons Brinckerhoff, Godalming, Surrey, U.K.","IEEE Transactions on Power Systems","20150717","2015","30","5","2657","2664","This paper demonstrates that machine learning can be used to create effective algorithm selectors that select between power system control algorithms depending on the state of a network, achieving better performance than always using the same algorithm for every state. Also presented is a novel method for creating algorithm selectors that consider two objectives. The method is used to develop algorithm selectors for power flow management algorithms on versions of the IEEE 14- and 57-bus networks, and a network derived from a real distribution network. The selectors choose from within a diverse set of power flow management algorithms, including those based on constraint satisfaction, optimal power flow, power flow sensitivity factors, and linear programming. The network state-based algorithm selectors offer performance benefits over always using the same power flow management algorithm for every state, in terms of minimizing the number of overloads while also minimizing the curtailment applied to generators.","0885-8950;08858950","","10.1109/TPWRS.2014.2361792","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6920094","Algorithms;machine learning;power system control;power systems;smart grids","Feature extraction;Generators;Machine learning algorithms;Prediction algorithms;Testing;Training;Training data","constraint satisfaction problems;distribution networks;learning (artificial intelligence);linear programming;load flow;power system control;power system management;sensitivity analysis","IEEE 14-bus network;IEEE 57-bus network;constraint satisfaction;distribution network;linear programming;machine learning;network state-based algorithm selection;optimal power flow;power flow management algorithm;power flow sensitivity factor;power system control algorithm","","1","","27","","20141013","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Implementation of machine learning applications on a fixed-point DSP","K. S. Bharati; A. Jhunjhunwala","Dept. of Electrical Engineering, Indian Institute of Technology Madras, India","2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)","20150625","2015","","","1458","1463","In this paper, we discuss efficient implementation of machine learning algorithms on DSPs. Specifically, we implement OCR and speech recognition on DSP and show how they can be optimized using fixed point routines. We illustrate the optimal usage of DSP resources like MAC units, shifters and software pipelining through assembly code structuring which massively reduces the MIPS consumed by the processor. We also describe how floating point overheads can be reduced by equivalent fixed point routines for real time implementations. Though the Blackfin-533 DSP is chosen for this illustration, the ideas presented here apply to other fixed point DSPs as well.","0840-7789;08407789","Electronic:978-1-4799-5829-0; POD:978-1-4799-5830-6; USB:978-1-4799-5828-3","10.1109/CCECE.2015.7129495","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129495","","Digital signal processing;Feature extraction;Hidden Markov models;Mel frequency cepstral coefficient;Optical character recognition software;Speech;Speech recognition","digital signal processing chips;learning (artificial intelligence);optical character recognition;real-time systems;speech recognition","Blackfin-533 DSP;MAC units;OCR;assembly code structuring;equivalent fixed point routines;fixed point routines;machine learning applications;real time implementations;shifters;software pipelining;speech recognition","","1","","12","","","3-6 May 2015","","IEEE","IEEE Conference Publications"
"Machine Learning Prediction for 13X Endurance Enhancement in ReRAM SSD System","T. O. Iwasaki; S. Ning; H. Yamazawa; C. Sun; S. Tanakamaru; K. Takeuchi","Chuo Univ., Tokyo, Japan","2015 IEEE International Memory Workshop (IMW)","20150706","2015","","","1","4","The variable behavior of ReRAM memory cells is modeled with machine learning. Two types of prediction are investigated, reset in the next-cycle and cell fail in the long term. A new proposal, Proactive Bit Redundancy, introduces a ML-trained Prediction Engine into the SSD controller, to predict fail cells and replace them proactively - before actual failure- by redundancy. With the Invalid Masking technique, predicted cells are marked in-place within the page, so that no extra address table is needed. Thus, with ninimal overhead, 2.85x bit error rate reduction or 13x endurance improvement is obtained based on a 50nm AlxOy testchip.","2159-483X;2159483X","Electronic:978-1-4673-6933-6; POD:978-1-4673-6934-3; USB:978-1-4673-6932-9","10.1109/IMW.2015.7150294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150294","","Accuracy;Data models;Engines;Error correction codes;Predictive models;Proposals;Redundancy","learning (artificial intelligence);redundancy;resistive RAM","Al<sub>x</sub>O<sub>y</sub>;ML-trained prediction engine;ReRAM SSD system;ReRAM memory cells;SSD controller;address table;bit error rate reduction;endurance enhancement;fail cells;invalid masking technique;machine learning prediction;proactive bit redundancy;size 50 nm;variable behavior","","2","","9","","","17-20 May 2015","","IEEE","IEEE Conference Publications"
"Machine learning for wear forecasting of naval assets for condition-based maintenance applications","A. Coraddu; L. Oneto; A. Ghio; S. Savio; M. Figari; D. Anguita","DITEN, Univ. of Genova, Genoa, Italy","2015 International Conference on Electrical Systems for Aircraft, Railway, Ship Propulsion and Road Vehicles (ESARS)","20150507","2015","","","1","5","Economic sustainability of running Naval Propulsion Plants is a key element to cope with, and maintenance costs represent a large slice of total operational expenses: last decades' approaches, based on a repairing-replacing methodology, are being trespassed by more effective approaches, relying on effective continuous monitoring of assets wear. In this framework, Condition-Based Maintenance (CBM) is becoming key thanks to the enhancing capabilities of monitoring the propulsion equipment by exploiting heterogeneous sensors: this enables diagnosis and prognosis of the propulsion system's components and of their potential future failures. The success of CBM is based on the capability of developing effective predictive models, for which purpose state-of-the-art Machine Learning (ML) methods must be developed. Nevertheless, testing the performance of ML models for CBM purposes is not straightforward, mostly due to the lack of publicly available datasets for benchmarking purposes: thus, we present in this work a new dataset, that will be freely distributed to the community working on ML models for CBM, generated from an accurate simulator of a naval vessel Gas Turbine propulsion plant. The latter is then used for benchmarking the effectiveness of two state-of-the-art ML techniques in the considered maritime domain.","2165-9400;21659400","Electronic:978-1-4799-7400-9; POD:978-1-4799-7401-6; USB:978-1-4799-7399-6","10.1109/ESARS.2015.7101499","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7101499","Condition-Based Maintenance;Machine Learning;Naval Propulsion Plant;Publicly Distributed Dataset","Data models;Maintenance engineering;Marine vehicles;Numerical models;Predictive models;Propulsion;Turbines","condition monitoring;fault diagnosis;learning (artificial intelligence);maintenance engineering;marine propulsion;mechanical engineering computing;wear","condition-based maintenance;continuous monitoring;failure diagnosis;failure prognosis;machine learning;naval assets;naval propulsion plants;repairing-replacing methodology;wear forecasting","","1","","25","","","3-5 March 2015","","IEEE","IEEE Conference Publications"
"Multi-label classification method based on extreme learning machines","R. Venkatesan; M. J. Er","School of Electrical and Electronics Engineering, Nanyang Technological Institute, Singapore","2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)","20150323","2014","","","619","624","In this paper, an Extreme Learning Machine (ELM) based technique for Multi-label classification problems is proposed and discussed. In multi-label classification, each of the input data samples belongs to one or more than one class labels. The traditional binary and multi-class classification problems are the subset of the multi-label problem with the number of labels corresponding to each sample limited to one. The proposed ELM based multi-label classification technique is evaluated with six different benchmark multi-label datasets from different domains such as multimedia, text and biology. A detailed comparison of the results is made by comparing the proposed method with the results from nine state of the arts techniques for five different evaluation metrics. The nine methods are chosen from different categories of multi-label methods. The comparative results shows that the proposed Extreme Learning Machine based multi-label classification technique is a better alternative than the existing state of the art methods for multi-label problems.","","Electronic:978-1-4799-5199-4; POD:978-1-4799-5200-7; USB:978-1-4799-5198-7","10.1109/ICARCV.2014.7064375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064375","Classification;Extreme Learning Machines;Machine Learning;Multi-label Learning","Accuracy;Classification algorithms;Decision trees;Machine learning algorithms;Measurement;Support vector machines;Training","learning (artificial intelligence);pattern classification","ELM based technique;binary classification problem;evaluation metrics;extreme learning machine;input data sample;multiclass classification problem;multilabel classification method;multilabel classification technique;multilabel dataset;multilabel problem","","0","","17","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Scaling Machine Learning for Target Prediction in Drug Discovery using Apache Spark","D. Harnie; A. E. Vapirev; J. K. Wegner; A. Gedich; M. Steijaert; R. Wuyts; W. D. Meuter","Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","20150709","2015","","","871","879","In the context of drug discovery, a key problem is the identification of candidate molecules that affect proteins associated with diseases. Inside Janssen Pharmaceutical, the Chemo genomics project aims to derive new candidates from existing experiments through a set of machine learning predictor programs, written in single-node C++. These programs take a long time to run and are inherently parallel, but do not use multiple nodes. We show how we reimplementation the pipeline using Apache Spark, which enabled us to lift the existing programs to a multi-node cluster without making changes to the predictors. We have benchmarked our Spark pipeline against the original, which shows almost linear speedup up to 8 nodes. In addition, our pipeline generates fewer intermediate files while allowing easier check pointing and monitoring.","","Electronic:978-1-4799-8006-2; POD:978-1-4799-8007-9","10.1109/CCGrid.2015.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152571","chemogenomics;clusters;distributed computing;life sciences;machine learning;spark","Compounds;Drugs;Pipelines;Predictive models;Proteins;Sparks;Training data","C++ language;bioinformatics;checkpointing;diseases;drugs;learning (artificial intelligence);pattern clustering;pipeline processing;proteins","Apache spark;Chemogenomics project;Janssen Pharmaceutica;Spark pipeline;candidate molecule identification;checkpointing;drug discovery;machine learning predictor programs;machine learning scaling;multinode cluster;single-node C++;target prediction","","2","","28","","","4-7 May 2015","","IEEE","IEEE Conference Publications"
"Performance evaluation of machine learning techniques for screening of cervical cancer","A. Sarwar; M. Ali; J. Suri; V. Sharma","Dept. of Computer Sc. & IT University of Jammu, INDIA","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","880","886","This paper presents comparative analysis of various machine learning algorithms in order to evaluate their predictive performance for screening of cervical cancer by characterization and classification of Pap smear images. Papanicolaou smear (also referred to as Pap smear) is a microscopic examination of samples of human cells scraped from the lower, narrow part of the uterus, called cervix. The sample is observed under microscope for any unusual developments indicating any precancerous and potentially precancerous changes. Examining the cell images for abnormalities in the cervix provides grounds for provision of prompt action and thus reducing incidence and deaths from cervical cancer. Pap smear test, if done with a regular screening programs and proper follow-up, can reduce cervical cancer mortality by up to 80% [1]. Authors have applied fifteen different machine learning algorithms under different platforms over two databases and evaluated their screening performances for prognosis of cervical cancer. The results indicate that among all the algorithms implemented, the Ensemble of nested dichotomies (END) is the best predictor and Naïve Bayes was the worst performer.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100375","Pap smear;artificial intelligence;cervical cancer;machine learning","Algorithm design and analysis;Artificial intelligence;Cervical cancer;Classification algorithms;Databases;Machine learning algorithms;Training","cancer;learning (artificial intelligence);medical image processing","Naïve Bayes;cervical cancer mortality;ensemble of nested dichotomies;machine learning techniques;pap smear images;papanicolaou smear;regular screening programs","","0","","23","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Executive Roundtable Series: Machine Learning and Cognitive Computing","S. Earley","Earley Information Science","IT Professional","20150716","2015","17","4","56","60","Machine learning and cognitive computing are today's newest buzzwords, and considerable hype surrounds them. This article is based on a recent webinar on analytics produced by IT Professional, the Journal of Applied Marketing Analytics, and consultancy Technology Business Research (TBR), along with the Content Wrangler; it was hosted by Earley Information Science (EIS). The goal is to help organizations understand what's practical and what's possible in the fast-growing fields of machine learning and cognitive computing, and how these fields are related to artificial intelligence (AI).","1520-9202;15209202","","10.1109/MITP.2015.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160900","artificial intelligence;cognitive computing;data analysis;machine learning","Artificial intelligence;Cognitive computing;Interviews;Machine learning algorithms","learning (artificial intelligence)","AI;artificial intelligence;cognitive computing;machine learning","","0","","","","","July-Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Measuring GPU-accelerated parallel SVM performance using large datasets for multi-class machine learning problem","M. A. H. B. Sulaiman; A. Suliman; A. R. Ahmad","College of Information Technology (COIT), Universiti Tenaga Nasional (UNITEN), Kajang, Selangor, Malaysia","Proceedings of the 6th International Conference on Information Technology and Multimedia","20150326","2014","","","299","302","This paper presents performance evaluation of GPU-accelerated Support Vector Machines (SVMs) using large datasets. Although SVMs algorithm is popular among machine learning researchers and data mining practitioners, its computational time is too long and impractical for large datasets due to its complex Quadratic Programming (QP) solver. The result shows that using GPU-accelerated SVMs can significantly reduce computational time for training phase of SVMs and it can be a viable solution for any project that require real-time forecasting output.","","Electronic:978-1-4799-5423-0; POD:978-1-4799-5424-7","10.1109/ICIMU.2014.7066648","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066648","Graphics Processing Unit;Support Vector Machines;parallel computing;performance measurement","Data mining;Graphics processing units;Information technology;Machine learning algorithms;Multimedia communication;Support vector machines;Training","data mining;graphics processing units;parallel processing;quadratic programming;support vector machines","GPU-accelerated parallel SVM performance measurement;GPU-accelerated support vector machines;QP solver;data mining;multiclass machine learning problem;performance evaluation;quadratic programming solver;real-time forecasting output","","0","","18","","","18-20 Nov. 2014","","IEEE","IEEE Conference Publications"
"A Fast Incremental Learning Algorithm Based on Twin Support Vector Machine","Y. Hao; H. Zhang","Coll. of Comput. Sci. & Technol., Nanjing Univ. of Sci. & Technol., Nanjing, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","2","","92","95","Twin support vector machine is a novel classifier, it construct two nonparallel hyper planes instead of a single hyper plane to obtain four times faster than the usual SVM. With the result of traditional incremental learning method of SVM, we analyze the characteristics of twin support vector machine and the distribution of the training sample set. In this paper, we propose a fast incremental learning algorithm based on twin support vector machine. It can deal with the newly added training samples and utilize the result of the previous training effectively. Experimental results prove that the given algorithm has excellent classification performance on runtime and recognition rate, and therefore confirm the above conclusion further.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081945","Karush-Kulm-Tucker conditons;incremental learning;support vectors;twin support vector machine","Accuracy;Breast;Classification algorithms;Kernel;Machine learning algorithms;Support vector machines;Training","learning (artificial intelligence);pattern classification;support vector machines","classification performance;incremental learning algorithm;nonparallel hyper plane classifier;twin support vector machine","","1","","15","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Threat prediction using honeypot and machine learning","V. Mehta; P. Bahadur; M. Kapoor; P. Singh; S. Rajpoot","Mphasis-An Hp Company, Magarpatta Cyber City, Pune, India","2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE)","20150713","2015","","","278","282","Data is an abstraction which encapsulates information. In today's era businesses are data driven which gives insight to predict the destiny of the business by making predictions but another side of the coin is data also helps in placing the present health of the business under our radar and looking back in our past and answer some important questions: what exactly went wrong in the past?. In this paper we try to look into the architecture of frameworks which can predict threat using Honeypot as the source of data and various machine learning algorithms to make precise prediction using OSSEC as Host Intrusion Detection System [HIDS], SNORT for Network Intrusion Detection System [NIDS] and Honeyd an open source Honeypot.","","CD-ROM:978-1-4799-8432-9; Electronic:978-1-4799-8433-6; POD:978-1-4799-8434-3","10.1109/ABLAZE.2015.7155011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155011","High Interaction Honeypots (HIH);Host Intrusion Detection System (HIDS);Low Interaction Honeypots (LIH);Network Intrusion Detection System (NIDS)","Computer hacking;Conferences;IP networks;Intrusion detection;Market research;Operating systems;Ports (Computers)","business data processing;computer network security;data encapsulation;learning (artificial intelligence);public domain software","HIDS;Honeyd;NIDS;OSSEC;SNORT;business prediction;data source;frameworks architecture;host intrusion detection system;information encapsulation;machine learning;network intrusion detection system;open source honeypot;threat prediction","","0","","17","","","25-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"MAS a scalable framework for research effort evaluation by unsupervised machine learning-Hybrid plagiarism model","S. V. Shinde; S. Z. Gawali; D. M. Thakore","Information Technology, B.V.D.U.s College of Engineering, Pune, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","5","In the era of web new information is upcoming day by day. Researches add their work for their research domains. Detecting of originality of research work is in hype. In Academic sector students researchers bring in innovative ideas, algorithms stating that their work outperforms prior research. They may implement NULL Hypothesis or alternative Hypothesis, detecting their effort is a challenge. By means of plagiarism detectors such academic efforts can be evaluated or graded. This reflects the essence of research in the field of Plagiarized content detection and grading. Some of our research issue highlights to technical scenario to design an algorithm which is adaptable to changing nature of dataset. The dataset grows, as new research work is added in due course of time. Data extraction from unstructured information is challenging, as no standard pattern is yet defined. Such patterns vary from research to research and are domain specific. A document in question i.e plagiarized or not? Is a join of one or more sentences that originate by the authors research or referenced from previous publications. Authors to prove originality use paraphrasing which may have semantic similarity, also some of the contents act as metaphor for upcoming research work. It is complex task point out such an activity. Methodology states that a document in question is a join of sentences, whereas each sentence is a join of terms. Thus we conclude by fork and join operations; plagiarism detection is possible in effective way. Document in question is split to produce a sentence vector. A term vector is generated by forking sentence to terms for each sentence in sentence vector. Mapper is implemented that maps term to sentence and sentence to source document. To enhance the accuracy of the model a Multi Agent Based System MAS frame is recommended to adapt varying similarity functions. Achieve parallelism in system and adaptability of new similarity measures as well remove one which are not sui- able any more to the task.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087030","Cosine similarity;Document in Question;EMA;Inverted Index;MAS;Mapper;PMA;SMA;Sentence vector;Term Vector;Unsupervised Learning;WEMA;WPMA;WSMA;fork;join","Accuracy;Algorithm design and analysis;Classification algorithms;Data mining;Plagiarism;Semantics;Silicon","Internet;information retrieval;multi-agent systems;text analysis;unsupervised learning","MAS;MAS frame;NULL hypothesis;academic sector student researchers;alternative hypothesis;data extraction;innovative ideas;multiagent based system frame;paraphrasing;plagiarism detection;plagiarism detectors;plagiarized content detection;plagiarized content grading;research effort evaluation;scalable framework;semantic similarity;sentence vector;similarity functions;unstructured information;unsupervised machine learning-hybrid plagiarism model","","0","","22","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"A Comparative Assessment of Predictive Accuracies of Conventional and Machine Learning Scoring Functions for Protein-Ligand Binding Affinity Prediction","H. M. Ashtawy; N. R. Mahapatra","Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, 48823","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20150406","2015","12","2","335","347","Accurately predicting the binding affinities of large diverse sets of protein-ligand complexes efficiently is a key challenge in computational biomolecular science, with applications in drug discovery, chemical biology, and structural biology. Since a scoring function (SF) is used to score, rank, and identify potential drug leads, the fidelity with which it predicts the affinity of a ligand candidate for a protein's binding site has a significant bearing on the accuracy of virtual screening. Despite intense efforts in developing conventional SFs, which are either force-field based, knowledge-based, or empirical, their limited predictive accuracy has been a major roadblock toward cost-effective drug discovery. Therefore, in this work, we explore a range of novel SFs employing different machine-learning (ML) approaches in conjunction with a variety of physicochemical and geometrical features characterizing protein-ligand complexes. We assess the scoring accuracies of these new ML SFs as well as those of conventional SFs in the context of the 2007 and 2010 PDBbind benchmark datasets on both diverse and protein-family-specific test sets. We also investigate the influence of the size of the training dataset and the type and number of features used on scoring accuracy. We find that the best performing ML SF has a Pearson correlation coefficient of 0.806 between predicted and measured binding affinities compared to 0.644 achieved by a state-of-the-art conventional SF. We also find that ML SFs benefit more than their conventional counterparts from increases in the number of features and the size of training dataset. In addition, they perform better on novel proteins that they were never trained on before.","1545-5963;15455963","","10.1109/TCBB.2014.2351824","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6883187","Drug discovery;machine learning;protein-ligand binding affinity;scoring function;scoring power;virtual screening","Accuracy;Barium;Databases;Drugs;Feature extraction;Proteins;Training","biochemistry;bioinformatics;drugs;learning (artificial intelligence);molecular biophysics;proteins","PDBbind benchmark datasets;Pearson correlation coefficient;drug discovery;machine learning scoring functions;protein-ligand binding affinity prediction;protein-ligand complexes;virtual screening","Computational Biology;Databases, Protein;Drug Discovery;Ligands;Machine Learning;Protein Binding;Proteins","2","","40","","20140826","March-April 1 2015","","IEEE","IEEE Journals & Magazines"
"Characterization between child and adult voice using machine learning algorithm","G. Aggarwal; L. Singh","Department of Computer Science and Engineering, ITM University, Gurgaon, India","International Conference on Computing, Communication & Automation","20150706","2015","","","246","250","Speech Feature Detection is a technique employed in speech processing in which different features of speech are used to distinguish between speech in different age groups. This paper implements a new approach for the extraction and classification of the speech features using the Mel-frequency cepstral coefficient, and Support Vector Machine. This paper presents the Mel-frequency cepstral coefficients (MFCC) for extracting the speech features of child and adult voices. Using the support vector machine, we classify the datasets in a child and an adult's speech.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148382","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148382","Mel-frequency cepstral coefficient (MFCC);Support Vector Machine (SVM);speech feature extraction","Feature extraction;Fourier transforms;Mel frequency cepstral coefficient;Speech;Speech processing;Speech recognition;Support vector machines","cepstral analysis;feature extraction;signal classification;speech recognition;support vector machines","MFCC;Mel-frequency cepstral coefficient;adult voice characterization;age groups;child voice characterization;dataset classification;machine learning algorithm;speech feature classification;speech feature detection;speech feature extraction;speech processing;support vector machine","","0","","21","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"Combining Pixel- and Object-Based Machine Learning for Identification of Water-Body Types From Urban High-Resolution Remote-Sensing Imagery","X. Huang; C. Xie; X. Fang; L. Zhang","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20150717","2015","8","5","2097","2110","Water is one of the vital components for the ecological environment, which plays an important role in human survival and socioeconomic development. Water resources in urban areas are gradually decreasing due to the rapid urbanization, especially in developing countries. Therefore, the precise extraction and automatic identification of water bodies are of great significance and urgently required for urban planning. It should be noted that although some studies have been reported regarding the water-area extraction, to our knowledge, few papers concern the identification of urban water types (e.g, rivers, lakes, canals, and ponds). In this paper, a novel two-level machine-learning framework is proposed for identifying the water types from urban high-resolution remote-sensing images. The framework consists of two interpretation levels: 1) water bodies are extracted at the pixel level, where the water/shadow/vegetation indexes are considered and 2) water types are further identified at the object level, where a set of geometrical and textural features are used. Both levels employ machine learning for the image interpretation. The proposed framework is validated using the GeoEye-1 and WorldView-2 images, over two mega cities in China, i.e, Wuhan and Shenzhen, respectively. The experimental results show that the proposed method achieved satisfactory accuracies for both water extraction [95.4% (Shenzhen), 96.2% (Wuhan)], and water type classification [94.1% (Shenzhen), 95.9% (Wuhan)] in complex urban areas.","1939-1404;19391404","","10.1109/JSTARS.2015.2420713","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7094223","High resolution;machine learning;object-oriented;water detection;water extraction;water index","Feature extraction;Indexes;Lakes;Remote sensing;Rivers;Vegetation mapping;Water resources","geophysical image processing;hydrological techniques;image classification;image resolution;learning (artificial intelligence);water resources","China;GeoEye-1 images;Shenzhen;WorldView-2 images;Wuhan;automatic water-body type identification;canals;ecological environment;geometrical features;high-resolution remote-sensing imagery;human survival development;image interpretation;lakes;object-based machine learning;pixel-based machine learning;ponds;rivers;shadow index;socioeconomic development;textural features;two-level machine-learning framework;urban areas;urban high-resolution remote-sensing images;urban planning;urbanization;vegetation index;water index;water resources;water type classification;water-area extraction","","6","","43","","20150424","May 2015","","IEEE","IEEE Journals & Magazines"
"A comparison of different machine learning algorithms using single channel EEG signal for classifying human sleep stages","K. A. I. Aboalayon; W. S. Almuhammadi; M. Faezipour","Department of Computer Science and Engineering University of Bridgeport, CT 06604, USA","2015 Long Island Systems, Applications and Technology","20150716","2015","","","1","6","In recent years, the estimation of human sleep disorders from Electroencephalogram (EEG) signals have played an important role in developing automatic detection of sleep stages. A few methods exist in the market presently towards this aim. However, sleep physicians may not have full assurance and consideration in such methods due to concerns associated with systems accuracy, sensitivity and specificity. This paper presents a novel and efficient technique that can be implemented in a microcontroller device to identify sleep stages in an effort to assist physicians in the diagnosis and treatment of related sleep disorders by enhancing the accuracy of the developed algorithm using a single channel of EEG signals. First, the dataset of EEG signal is filtered and decomposed into delta, theta, alpha, beta and gamma subbands using Butterworth band-pass filters. Second, a set of sample statistical discriminating features are derived from each frequency band. Finally, sleep stages consisting of Wakefulness, Rapid Eye Movement (REM) and Non-Rapid Eye Movement (NREM) are classified using several supervised machine learning classifiers including multi-class Support Vector Machines (SVM), Decision Trees (DT), Neural Networks (NN), K-Nearest Neighbors (KNN) and Naive Bayes (NB). This paper combines REM with Stage 1 NREM due to data similarities. Performance is then compared based on single channel EEG signals that were obtained from 20 healthy subjects. The results show that the proposed technique using DT classifier efficiently achieves high accuracy of 97.30% in differentiating sleeps stages. Also, a comparison of our method with some recent available works in the literature reiterates the high classification accuracy performance.","","Electronic:978-1-4799-8643-9; POD:978-1-4799-8644-6","10.1109/LISAT.2015.7160185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160185","Butterworth band-pass filter;EEG;EEG sub-bands;Machine Learning Algorithms;sleep stages","Accuracy;Databases;Electroencephalography;Feature extraction;Sleep;Support vector machines;Testing","decision trees;electroencephalography;filtering theory;learning (artificial intelligence);medical signal processing;microcontrollers;neural nets;signal classification;support vector machines","DT;EEG signal decomposition;EEG signal filtering;KNN;NB;NN;NREM stage;REM stage;SVM;alpha subband;beta subband;decision trees;delta subband;electroencephalography;gamma subband;human sleep disorders estimation;human sleep stage classification;k-nearest neighbors;machine learning algorithms;microcontroller device;multiclass support vector machines;naive Bayes;neural networks;non-rapid eye movement stage;rapid eye movement stage;single channel EEG signal;statistical discriminating features;supervised machine learning classifiers;theta subband;wakefulness stage","","2","","26","","","1-1 May 2015","","IEEE","IEEE Conference Publications"
"Towards Developing a Tool to Detect Phishing URLs: A Machine Learning Approach","R. B. Basnet; T. Doleck","","2015 IEEE International Conference on Computational Intelligence & Communication Technology","20150402","2015","","","220","223","Despite efforts to curb online fraud, there continues to be a significant proliferation of fraud in the online space. In the same vein, Phishing attacks are a significant and growing problem for users, and carrying out certain actions such as mouse hovering, clicking, etc., on malicious URLs may cause unwary users to unwittingly fall victim to identity theft and problems. In this paper, we propose a methodology that could be used towards developing an anti-phishing URL tool to thwart a phishing attack by either masking the potentially phishing URL or by alerting the user about the potential threat.","","Electronic:978-1-4799-6023-1; POD:978-1-4799-6024-8","10.1109/CICT.2015.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078698","machine learning;phishing;phishing URLs;tools","Error analysis;Feature extraction;Google;IP networks;Search engines;Uniform resource locators","computer crime;learning (artificial intelligence);unsolicited e-mail","antiphishing URL tool;clicking;identity theft;machine learning approach;mouse hovering;online fraud;online space;phishing attacks","","1","","21","","","13-14 Feb. 2015","","IEEE","IEEE Conference Publications"
"Machine Learning Based Session Drop Prediction in LTE Networks and Its SON Aspects","B. Daroczy; P. Vaderna; A. Benczur","Inst. for Comput. Sci. & Control, Budapest, Hungary","2015 IEEE 81st Vehicular Technology Conference (VTC Spring)","20150702","2015","","","1","5","Abnormal bearer session release (i.e. bearer session drop) in cellular telecommunication networks may seriously impact the quality of experience of mobile users. The latest mobile technologies enable high granularity real-time reporting of all conditions of individual sessions, which gives rise to use data analytics methods to process and monetize this data for network optimization. One such example for analytics is Machine Learning (ML) to predict session drops well before the end of session. In this paper a novel ML method is presented that is able to predict session drops with higher accuracy than using traditional models. The method is applied and tested on live LTE data offline. The high accuracy predictor can be part of a SON function in order to eliminate the session drops or mitigate their effects.","1550-2252;15502252","Electronic:978-1-4799-8088-8; POD:978-1-4799-8089-5","10.1109/VTCSpring.2015.7145925","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7145925","","Accuracy;Interference;Kernel;Signal to noise ratio;Support vector machines;Time series analysis;Uplink","Long Term Evolution;cellular radio;learning (artificial intelligence);quality of experience;telecommunication network management","LTE networks;SON;abnormal bearer session release;bearer session drop;cellular telecommunication networks;data analytics;machine learning based session drop prediction;mobile technologies;mobile users;quality of experience","","1","","13","","","11-14 May 2015","","IEEE","IEEE Conference Publications"
"Machine learning approach to point localization system","J. Žácek; M. Janošek","Centre of Excellence IT4Innovations division of the University of Ostrava, Institute for Research and Applications of Fuzzy Modeling, Czech Republic","2015 IEEE 13th International Symposium on Applied Machine Intelligence and Informatics (SAMI)","20150319","2015","","","313","317","The article introduces point localization systems in 3D Euclidean space based on neural networks. There are two models presented. The first one identified distances between a randomly generated point and a reference points in the defined domain. Then a neural network uses the obtained distances as its inputs to determine the actual position of the point in the domain space. Due to a relatively good accuracy that was obtained during the experimental study, the proposed model based on neural networks was used in the second model as an acoustic Motion Capturing system (MoCap). MoCap system is represented by a neural network that uses obtained distances between transmitters and a receiver as its inputs to determine an actual position of the receiver in space. We also propose a new way to minimize a training set by using ANFIS approach in this specific problem. All obtained results are summarized in the conclusion.","","Electronic:978-1-4799-8221-9; POD:978-1-4799-8222-6; USB:978-1-4799-8220-2","10.1109/SAMI.2015.7061895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061895","","Acoustics;Neural networks;Receivers;Three-dimensional displays;Topology;Training;Transmitters","acoustic signal processing;fuzzy neural nets;learning (artificial intelligence)","3D Euclidean space;ANFIS approach;MoCap system;acoustic motion capturing system;machine learning approach;neural networks;point localization system;randomly generated point;reference points;training set minimization","","0","","14","","","22-24 Jan. 2015","","IEEE","IEEE Conference Publications"
"Web Page Ranking Using Machine Learning Approach","V. Chauhan; A. Jaiswal; J. Khan","","2015 Fifth International Conference on Advanced Computing & Communication Technologies","20150406","2015","","","575","580","This article gives an overview of the currently available literature on web page ranking algorithm using machine learning. Web page ranking algorithm, a well-known approach to rank the web pages available on cyber world. It helps us to know - how the search engine exactly works and how a machine learn itself while giving priority to the page that which page is important to successfully fulfills the user query need and which page is worth less. Machine learning approach also helps us in understanding the complex part of page priority criteria in most popular search engines like Google, yahoo, AltaVista, dog pile and many more search engines like that. Page ranking mainly unrevealed the structure of web. This article gives an overview of available literature in the field of web page ranking algorithm and it also highlights the main point based on machine leaning approach in web page ranking algorithm.","2327-0632;23270632","Electronic:978-1-4799-8488-6; POD:978-1-4799-8489-3","10.1109/ACCT.2015.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079148","CRAWLER;INDEXER;SEACH ENGINE;Web page ranking using machine learning approach","Algorithm design and analysis;Crawlers;Engines;Google;Machine learning algorithms;Search engines;Web pages","Internet;learning (artificial intelligence);query processing;search engines","AltaVista;Dogpile;Google;Web page ranking algorithm;Yahoo;cyber world;machine learning approach;search engine;user query","","1","","14","","","21-22 Feb. 2015","","IEEE","IEEE Conference Publications"
"Processing smart plug signals using machine learning","A. Ridi; C. Gisler; J. Hennebert","University of Applied Sciences Western Switzerland, College of Engineering and Architecture of Fribourg, iCoSys Institute","2015 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)","20150618","2015","","","75","80","The automatic identification of appliances through the analysis of their electricity consumption has several purposes in Smart Buildings including better understanding of the energy consumption, appliance maintenance and indirect observation of human activities. Electric signatures are typically acquired with IoT smart plugs integrated or added to wall sockets. We observe an increasing number of research teams working on this topic under the umbrella Intrusive Load Monitoring. This term is used as opposition to Non-Intrusive Load Monitoring that refers to the use of global smart meters. We first present the latest evolutions of the ACS-F database, a collections of signatures that we made available for the scientific community. The database contains different brands and/or models of appliances with up to 450 signatures. Two evaluation protocols are provided with the database to benchmark systems able to recognise appliances from their electric signature. We present in this paper two additional evaluation protocols intended to measure the impact of the analysis window length. Finally, we present our current best results using machine learning approaches on the 4 evaluation protocols.","","Electronic:978-1-4799-8760-3; POD:978-1-4799-8761-0; USB:978-1-4799-8759-7","10.1109/WCNCW.2015.7122532","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122532","Appliance Identification;Intrusive Load Monitoring (ILM);Signal length impact","Accuracy;Databases;Hidden Markov models;Home appliances;Monitoring;Protocols;Training","learning (artificial intelligence);power engineering computing;power supplies to apparatus","ACS-F database;IoT smart plugs;machine learning approaches;smart buildings;smart plug signals;umbrella intrusive load monitoring","","0","","18","","","9-12 March 2015","","IEEE","IEEE Conference Publications"
"A study on mammography computer aided diagnosis system using machine learning methods","K. Dinakaran; V. Sivakrithika","","IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013)","20150611","2013","","","333","341","Early diagnosis is an important aspect of successful treatment for breast cancer. Mammogram is the most reliable imaging technique available. It is a challenging task for radiologists to detect the abnormalities in the mammograms. Computing helps the radiologists in diagnosing the abnormalities in the mammogram. Computer Aided Diagnosis System involves computerized biomedical image analysis to classify the mammography into benign or malign. In a decade of research work number of algorithms had been proposed to classify the image that employ data mining techniques, image processing methods, machine learning methods and pattern recognition. In this paper such algorithms in previous research work is studied and their performance is discussed.","","Paper:978-1-78561-030-1","10.1049/ic.2013.0334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119721","Classifiers;Computer Aided Diagnosis;Data Mining;Machine Learning Methods;Mammogram Classification;Medical Image Analysis","","biological organs;cancer;data mining;image classification;learning (artificial intelligence);mammography;medical image processing","abnormality detection;benign;breast cancer treatment;computerized biomedical image analysis;data mining;image classification;image processing;machine learning methods;malign;mammogram classification;mammography computer aided diagnosis system;pattern recognition;radiologists","","0","","","","","12-14 Dec. 2013","","IET","IET Conference Publications"
"Satire Detection from Web Documents Using Machine Learning Methods","T. Ahmad; H. Akhtar; A. Chopra; M. W. Akhtar","Dept. of Comput. Eng., Jamia Millia Islamia Univ., Delhi, India","2014 International Conference on Soft Computing and Machine Intelligence","20150406","2014","","","102","105","Satire exposes humanity's vices and foibles through the use of irony, wit, and sometimes sarcasm too. It is also frequently used in online communities. Recognition of satire can help in many NLP applications like dialogue system and review summarization. In this paper we filter online news articles as satirical or true news documents using SVM (Support Vector Machine) classification method combined with machine learning techniques. With ample training documents SVM tends to give good classification results. For obtaining promising results with SVM an understanding of its working and ways to influence its accuracy is required. We also use various feature extraction strategies and conclude that TF-IDF-BNS feature extraction gives maximum accuracy for detection of satire in web content.","","Electronic:978-1-4673-6751-6; POD:978-1-4799-7879-3","10.1109/ISCMI.2014.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079363","SVM;Satire detection;bi-normal separation;classification;feature extraction","Accuracy;Equations;Feature extraction;Mathematical model;Support vector machines;Text categorization;Training","document handling;information filtering;learning (artificial intelligence);pattern classification;support vector machines","NLP applications;SVM;TF-IDF-BNS feature extraction;Web documents;dialogue system;machine learning methods;online communities;online news article filtering;review summarization;satire Recognition;satire detection;satirical news documents;support vector machine classification;training documents;true news documents","","0","","8","","","26-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Non-negative pre-image in machine learning for pattern recognition","M. Kallas; P. Honeine; C. Richard; C. Francis; H. Amoud","Institut Charles Delaunay (CNRS), UMR, LM2S, Universit&#x00E9; de Technologie de Troyes, France","2011 19th European Signal Processing Conference","20150402","2011","","","931","935","Moreover, in order to have a physical interpretation, some constraints should be incorporated in the signal or image processing technique, such as the non-negativity of the solution. This paper deals with the non-negative pre-image problem in kernel machines, for nonlinear pattern recognition. While kernel machines operate in a feature space, associated to the used kernel function, a pre-image technique is often required to map back features into the input space. We derive a gradient-based algorithm to solve the pre-image problem, and to guarantee the non-negativity of the solution. Its convergence speed is significantly improved due to a weighted stepsize approach. The relevance of the proposed method is demonstrated with experiments on real datasets, where only a couple of iterations are necessary.","2076-1465;20761465","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7074259","","Kernel;Linear programming;Noise reduction;Optimization;Pattern recognition;Principal component analysis;Signal processing","convergence;gradient methods;image recognition;learning (artificial intelligence)","convergence speed;feature space;gradient-based algorithm;image processing technique;kernel machines;machine learning;nonlinear pattern recognition;nonnegative pre-image problem;physical interpretation;real datasets;signal processing technique;weighted stepsize approach","","0","","15","","","Aug. 29 2011-Sept. 2 2011","","IEEE","IEEE Conference Publications"
"Machine-learning-integrated load scheduling for reduced peak power demand","M. Sung; Y. Ko","Department of Mechanical and Information Engineering, University of Seoul, Seoul, Korea","IEEE Transactions on Consumer Electronics","20150708","2015","61","2","167","174","Load scheduling over cyclic electrical devices can reduce the peak power demand. In this paper, we propose a machine-learning-integrated load control (MILC) scheme for improved performance and reliability. By dynamic capacity adjustment and interactive load heuristic, MILC tries to reduce the power deviation while keeping the temperature violation ratio and switching counts within an acceptable range. A prototype of the proposed scheme has been implemented and, through experiments using load traces from a real home, we evaluate the performance of MILC. The results show that MILC reduces the peak demand from 4993 W to 4236 W and successfully decreases the power deviation by 12.1% on average.","0098-3063;00983063","","10.1109/TCE.2015.7150570","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150570","Electric load scheduling;dynamic capacity adjustment;machine learning;peak power reduction","Dynamic scheduling;Performance evaluation;Refrigerators;Support vector machines;Switches;Temperature measurement","demand side management;learning (artificial intelligence);load regulation;power engineering computing","MILC scheme;machine-learning-integrated load scheduling;reduced peak power demand","","0","","16","","","May 2015","","IEEE","IEEE Journals & Magazines"
"Optimizing testing efforts based on change proneness through machine learning techniques","A. K. Tripathi; K. Sharma","Department of computer Eng, Delhi Technological University, Delhi, India","2014 6th IEEE Power India International Conference (PIICON)","20150604","2014","","","1","4","For any software organization, understanding the software quality is desirable in order to increase user experience of the software. When we talk about security software this factor becomes even more important. This paper aims to develop models for predicting the change proneness for object oriented system. The developed models may be used to predict the change prone classes at early phase of software development. Rigorous testing and allocation of some extra resources to those change prone classes may lead to better quality and it may also reduce our work at the maintenance phase. We apply one statistical and 10 machine learning techniques to predict the models. The results are analyzed from Receiver Operating Characteristics (ROC) analysis using Area under the Curve (AUC) obtained from ROC. Adaboost and Random forest method have shown the best result and hence, based on these results we can claim that quality models have a good relevance with Object Oriented systems.","","Electronic:978-1-4799-6042-2; POD:978-1-4799-6043-9","10.1109/POWERI.2014.7117742","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7117742","Empirical Validation;Machine Learning;Object Oriented;Receiver Operating Characteristics;Statistical Methods;change Prediction","Maintenance engineering;Measurement;Object oriented modeling;Predictive models;Security;Software;Unified modeling language","learning (artificial intelligence);object-oriented methods;optimisation;program testing;security of data;sensitivity analysis;software maintenance;software quality;statistical analysis;user interfaces","AUC;Adaboost;ROC analysis;area under the curve;change proneness;machine learning techniques;maintenance phase;object oriented system;optimizing testing efforts;random forest method;receiver operating characteristics;rigorous testing;security software;software development;software organization;software quality;statistical techniques;user experience","","0","","17","","","5-7 Dec. 2014","","IEEE","IEEE Conference Publications"
"Machine Learning for Predictive Maintenance: A Multiple Classifier Approach","G. A. Susto; A. Schirru; S. Pampuri; S. McLoone; A. Beghi","Department of Information Engineering, University of Padova, Padova, Italy","IEEE Transactions on Industrial Informatics","20150602","2015","11","3","812","820","In this paper, a multiple classifier machine learning (ML) methodology for predictive maintenance (PdM) is presented. PdM is a prominent strategy for dealing with maintenance issues given the increasing need to minimize downtime and associated costs. One of the challenges with PdM is generating the so-called “health factors,” or quantitative indicators, of the status of a system associated with a given maintenance issue, and determining their relationship to operating costs and failure risk. The proposed PdM methodology allows dynamical decision rules to be adopted for maintenance management, and can be used with high-dimensional and censored data problems. This is achieved by training multiple classification modules with different prediction horizons to provide different performance tradeoffs in terms of frequency of unexpected breaks and unexploited lifetime, and then employing this information in an operating cost-based maintenance decision system to minimize expected costs. The effectiveness of the methodology is demonstrated using a simulated example and a benchmark semiconductor manufacturing maintenance problem.","1551-3203;15513203","","10.1109/TII.2014.2349359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6879441","Classification algorithms;data mining;ion implantation;machine learning (ML);predictive maintenance (PdM);semiconductor device manufacture","Availability;Informatics;Manufacturing;Predictive maintenance;Production;Training","data mining;learning (artificial intelligence);pattern classification;production engineering computing;semiconductor device manufacture","PdM;censored data problem;data mining;dynamical decision rules;health factors;high-dimensional problem;maintenance management;multiple classifier machine learning methodology;operating cost-based maintenance decision system;predictive maintenance;quantitative indicators;semiconductor manufacturing maintenance problem","","10","","28","","20140818","June 2015","","IEEE","IEEE Journals & Magazines"
"21.8 A 16-ch patient-specific seizure onset and termination detection SoC with machine-learning and voltage-mode transcranial stimulation","M. A. B. Altaf; C. Zhang; J. Yoo","Masdar Institute of Science and Technology, Abu Dhabi, United Arab Emirates","2015 IEEE International Solid-State Circuits Conference - (ISSCC) Digest of Technical Papers","20150319","2015","","","1","3","Multichannel EEG seizure detection SoCs are widely used in medical practice and in research [1]-[3]. Due to huge variation in seizure patterns, patient-specific seizure detection is very crucial. [1], [2] presents 8-channel (ch) SoCs with moderate latency (~2s) but without seizure termination detection and stimulation. [3] implements a closed-loop SoC but is not patient-specific, and moreover, is invasive. This paper presents an ultra-low power 16-ch ""non-invasive, patient-specific"" seizure onset and termination detection SoC with channels multiplexing AFE and pulsating voltage transcranial electrical stimulation (PVTES).","0193-6530;01936530","Electronic:978-1-4799-6224-2; POD:978-1-4799-6225-9","10.1109/ISSCC.2015.7063092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063092","","Band-pass filters;Electroencephalography;Impedance;Iron;Multiplexing;System-on-chip;Training","electroencephalography;learning (artificial intelligence);medical signal detection;medical signal processing","PVTES;SoC termination detection;closed-loop SoC;machine-learning;multichannel EEG seizure detection;patient-specific seizure detection;pulsating voltage transcranial electrical stimulation;ultralow power 16-ch noninvasive patient-specific seizure onset;voltage-mode transcranial stimulation","","2","","8","","","22-26 Feb. 2015","","IEEE","IEEE Conference Publications"
"Machine Learning Facilitated Rice Prediction in Bangladesh","M. M. Rahman; N. Haq; R. M. Rahman","Electr. & Comput. Eng. Dept., North South Univ., Dhaka, Bangladesh","2014 Annual Global Online Conference on Information and Computer Technology","20150601","2014","","","1","4","The climate of a region is often determined by its landscape and amount of vegetation present in it. Environment parameters such as rainfall, wind-speed and humidity are highly influenced by these alluvial features. Bangladesh, a country situated on the banks of the Himalaya, does not have a homogeneous topography. Human settlement over the course of centuries has led to pockets of micro-regions. Each of those regions has a different micro climate. An entrepreneur involved in the food industry therefore has to carefully choose regions of land that will give him/her the desirable production. In this study a research initiative has been taken to predict the yield of crops using machine learning models. The models were at first trained on the correlation between past environmental patterns and crop production rate. Then the models are compared to measure their effectiveness on unknown climatic variables.","","Electronic:978-1-4799-8311-7; POD:978-1-4799-8312-4","10.1109/GOCICT.2014.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113655","Bangladesh climate;Bangladesh rice yield;decision tree;ensemble learning;generalized linear regression (GLM);k-means clustering;linear regression;neural network;regression tree;self organizing maps (SOM)","Agriculture;Humidity;Linear regression;Production;Regression tree analysis;Vegetation","crops;learning (artificial intelligence)","Bangladesh;crop production rate;machine learning;rice prediction","","0","","17","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Estimating solar radiation by machine learning methods","E. Ertuğrul; M. Şahin; F. Ağgün","Elektrik-Elektron. Muhendisligi Bolumu, Siirt Univ., Siirt, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1611","1614","Solar energy, which is clean and renewable energy source, is a popular subject. The estimation of solar radiation can be done instead of long term measurements. Therefore, the satellite and meteorological values of 53 different locations of Turkey were used for estimations of solar radiation. In this study a hybrid approach was proposed. The train dataset was reduced by employing two times similarity and the reduced dataset was utilized with support vector machine to predict global solar radiation. Additionally, the proposed method was validated by employing neural network, linear regression, k nearest neighbor, extreme learning machine, Gaussian process regression and kernel smooth regression. This study was showed that the machine learning methods can be used instead of long term measurement before investments.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130158","Machine Learning;Regression;Solar Radiation","Atmospheric modeling;Data models;Ground penetrating radar;Lead","Gaussian processes;learning (artificial intelligence);neural nets;power engineering computing;regression analysis;solar power;sunlight;support vector machines","Gaussian process regression;Turkey;extreme learning machine;global solar radiation;k nearest neighbor;kernel smooth regression;linear regression;machine learning methods;neural network;renewable energy source;solar energy;solar radiation estimation;support vector machine","","0","","24","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Detection of fraudulent financial reports with machine learning techniques","P. Seemakurthi; S. Zhang; Y. Qi","University of Virginia","2015 Systems and Information Engineering Design Symposium","20150608","2015","","","358","361","This paper describes our efforts to apply various advanced supervised machine learning and natural language processing techniques, including Binomial Logistic Regression, Support Vector Machines, Neural Networks, Ensemble Techniques, and Latent Dirichlet Allocation (LDA), to the problem of detecting fraud in financial reporting documents available from the United States' Security and Exchange Commission EDGAR database. Specifically, we apply LDA to a collection of type 10-K financial reports and to generate document-topic frequency matrix, and then submit these data to a series of advanced classification algorithms. We then apply evaluation metrics, such as Precision, Receiver Operating Characteristic Curve, and Area Under the Curve to evaluate the performance of each algorithm. We conclude that these methods show promise and suggest applying the approach to a larger set of input documents.","","Electronic:978-1-4799-1832-4; POD:978-1-4799-1833-1","10.1109/SIEDS.2015.7117005","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7117005","Ensemble;Financial Fraud Detection;Latent Dirichlet Allocation;Machine Learning;Natural Language Processing;Support Vector Machines","Accuracy;Classification algorithms;Correlation;Logistics;Natural language processing;Neural networks;Support vector machines","document handling;financial data processing;fraud;learning (artificial intelligence);matrix algebra;natural language processing;neural nets;pattern classification;regression analysis;security of data;support vector machines","EDGAR database;LDA;Security and Exchange Commission;United States;area under the curve;binomial logistic regression;classification algorithms;document-topic frequency matrix;ensemble techniques;evaluation metrics;financial reporting documents;fraudulent financial reports detection;latent Dirichlet allocation;natural language processing techniques;neural networks;precision;receiver operating characteristic curve;supervised machine learning techniques;support vector machines","","0","","3","","","24-24 April 2015","","IEEE","IEEE Conference Publications"
"Stylistic analysis of paintings usingwavelets and machine learning","S. Jafarpour; G. Polatkan; E. Brevdo; S. Hughes; A. Brasoveanu; I. Daubechies","Depts. of Electr. Eng., Comput. Sci., & Math., Princeton Univ., Princeton, NJ, USA","2009 17th European Signal Processing Conference","20150406","2009","","","1220","1224","Wavelet transforms and machine learning tools can be used to assist art experts in the stylistic analysis of paintings. A dual-tree complex wavelet transform, Hidden Markov Tree modeling and Random Forest classifiers are used here for a stylistic analysis of Vincent van Gogh's paintings with results on two stylometry challenges that concern “dating, resp. extracting distinguishing features”.","","POD:978-161-7388-76-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7077807","","Abstracts;Image resolution;Radio frequency;Support vector machines","art;hidden Markov models;image classification;learning (artificial intelligence);trees (mathematics)","Vincent van Gogh paintings;dual tree complex wavelet transform;hidden Markov tree modeling;machine learning;painting stylistic analysis;random forest classifier;wavelet transforms","","0","","","","","24-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"Machine Learning-Based Coding Unit Depth Decisions for Flexible Complexity Allocation in High Efficiency Video Coding","Y. Zhang; S. Kwong; X. Wang; H. Yuan; Z. Pan; L. Xu","Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China","IEEE Transactions on Image Processing","20150413","2015","24","7","2225","2238","In this paper, we propose a machine learning-based fast coding unit (CU) depth decision method for High Efficiency Video Coding (HEVC), which optimizes the complexity allocation at CU level with given rate-distortion (RD) cost constraints. First, we analyze quad-tree CU depth decision process in HEVC and model it as a three-level of hierarchical binary decision problem. Second, a flexible CU depth decision structure is presented, which allows the performances of each CU depth decision be smoothly transferred between the coding complexity and RD performance. Then, a three-output joint classifier consists of multiple binary classifiers with different parameters is designed to control the risk of false prediction. Finally, a sophisticated RD-complexity model is derived to determine the optimal parameters for the joint classifier, which is capable of minimizing the complexity in each CU depth at given RD degradation constraints. Comparative experiments over various sequences show that the proposed CU depth decision algorithm can reduce the computational complexity from 28.82% to 70.93%, and 51.45% on average when compared with the original HEVC test model. The Bjøntegaard delta peak signal-to-noise ratio and Bjøntegaard delta bit rate are -0.061 dB and 1.98% on average, which is negligible. The overall performance of the proposed algorithm outperforms those of the state-of-the-art schemes.","1057-7149;10577149","","10.1109/TIP.2015.2417498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070704","Coding Unit;High Efficiency Video Coding;High efficiency video coding;Machine Learning, Support Vector Machine;coding unit;machine learning;support vector machine","Classification algorithms;Complexity theory;Image coding;Joints;Prediction algorithms;Support vector machines;Video coding","binary decision diagrams;communication complexity;decision theory;decision trees;image classification;learning (artificial intelligence);quadtrees;rate distortion theory;video coding","Bjøntegaard delta bit rate;Bjøntegaard delta peak signal-to-noise ratio;HEVC;RD cost constraint;RD-complexity model;coding unit depth decision method;computational complexity;flexible complexity allocation;hierarchical binary decision problem;high efficiency video coding;machine learning;multiple binary classifier;quadtree CU depth decision process;rate-distortion cost constraint;three-output joint classifier","","18","","26","","20150327","July 2015","","IEEE","IEEE Journals & Magazines"
"A lyapunov based stable online learning algorithm for nonlinear dynamical systems using extreme learning machines","V. M. Janakiraman; X. Nguyen; D. Assanis","Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA","The 2013 International Joint Conference on Neural Networks (IJCNN)","20150423","2013","","","1","8","Extreme Learning Machine (ELM) is a promising learning scheme for nonlinear classification and regression problems and has shown its effectiveness in the machine learning literature. ELM represents a class of generalized single hidden layer feed-forward networks (SLFNs) whose hidden layer parameters are assigned randomly resulting in an extremely fast learning speed along with superior generalization performance. It is well known that the online sequential learning algorithm (OS-ELM) based on recursive least squares [1] might result in ill-conditioning of the Hessian matrix and hence instability in the parameter estimation. To address this issue, the stability theory of Lyapunov is utilized to develop an online learning algorithm for temporal data from dynamic systems and time series. The developed algorithm results in parameter estimation that is asymptotically stable leading to boundedness in model states. Simulations results of the developed algorithm compared against online sequential ELM (OS-ELM) and the offline batch learning ELM (O-ELM) show that the Lyapunov ELM algorithm can perform online learning at reduced computation, comparable accuracy and with a guarantee on the boundedness of the estimated system.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.7090813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090813","","Convergence;Heuristic algorithms;Mathematical model;Nonlinear systems;Prediction algorithms;Predictive models;Training","Hessian matrices;Lyapunov methods;asymptotic stability;feedforward neural nets;learning (artificial intelligence);nonlinear dynamical systems;parameter estimation;regression analysis","Hessian matrix;Lyapunov based stable online learning algorithm;O-ELM;OS-ELM;SLFN;asymptotic stability;extreme learning machines;generalized single hidden layer feed-forward networks;nonlinear classification problem;nonlinear dynamical systems;offline batch learning ELM;online sequential learning algorithm;parameter estimation;regression problems;time series","","3","","21","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"A machine learning approach to cognitive radar detection","J. Metcalf; S. D. Blunt; B. Himed","Radar Systems Lab (RSL), University of Kansas, USA","2015 IEEE Radar Conference (RadarCon)","20150625","2015","","","1405","1411","We consider the requirements of cognitive radar detection in the presence of non-Gaussian clutter. A pair of machine learning approaches based on non-linear transformations of order statistics are examined with the goal of adaptively determining the optimal detection threshold within the low sample support regime. The impact of these algorithms on false alarm rate is also considered. It is demonstrated that the adaptive threshold estimate is effective even when the distribution in question is unknown to the machine learning algorithm.","1097-5659;10975659","CD-ROM:978-1-4799-8231-8; Electronic:978-1-4799-8232-5; POD:978-1-4799-8233-2","10.1109/RADAR.2015.7131215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131215","","Clutter;Covariance matrices;Detectors;Libraries;Radar detection;Shape","cognitive radio;estimation theory;learning (artificial intelligence);radar clutter;radar detection;statistical analysis","adaptive threshold estimation;cognitive radar detection;false alarm rate;machine learning approach;non-Gaussian clutter;nonlinear transformation;optimal detection threshold;order statistics","","1","","33","","","10-15 May 2015","","IEEE","IEEE Conference Publications"
"Determination of the variables affecting the maximal oxygen uptake of cross-country skiers by using machine learning and feature selection algorithms","F. Abut; M. F. Akay","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x00C7;ukurova &#x00DC;niversitesi, Adana, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","156","159","Maximal oxygen uptake (VO<sub>2</sub>max) is one of the most important determinants that directly affects the performance of cross-country skiers during races. In this study, various models have been developed to predict the VO<sub>2</sub>max of cross-country skiers by combining different machine learning methods with the Relief-F feature selection algorithm. Machine learning methods used in this study include General Regression Neural Network (GRNN), Gene Expression Programming (GEP), Group Method of Data Handling Polynomial Network (GMDH) and Single Decision Tree (SDT). The predictor variables used to develop prediction models are age, gender, weight, height, heart rate (HR), heart rate at lactate threshold (HRLT) and exercise time. By using 10-fold cross-validation on the dataset, the performance of the prediction models has been evaluated by calculating their multiple correlation coefficient (R) and standard error of estimate (SEE). The results show that the GRNN-based model including all predictor variables yields the highest R (0.92) and the lowest SEE (2.98 ml kg<sup>-1</sup> min<sup>-1</sup>).","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130342","feature selection;machine learning;maximal oxygen uptake","Gene expression;Heart rate;Neural networks;Oxygen;Polynomials;Programming;Support vector machines","data handling;decision trees;feature selection;genetic algorithms;health care;learning (artificial intelligence);neural nets;regression analysis","GEP;GMDH;GRNN-based model;HRLT;SDT;cross-country skiers;exercise time;gene expression programming;general regression neural network;group method of data handling polynomial network;heart rate at lactate threshold;machine learning;maximal oxygen uptake;multiple correlation coefficient;relief-F feature selection algorithm;single decision tree;standard error of estimate","","0","","19","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Development of new upper body power prediction models for cross-country skiers by using different machine learning methods","S. Daneshvar; F. Abut; I. Yıldız; M. F. Akay","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x00C7;ukurova &#x00DC;niversitesi, Adana, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","260","263","Upper Body Power (UBP) is one of the most important determinants that directly affects the performance of cross-country skiers during races. In this study, new models have been developed to predict the 10-second UBP (UBP<sub>10</sub>) and 60-second UBP (UBP<sub>60</sub>) of cross-country skiers by using different machine learning methods including Cascade Correlation Network (CCN), Radial Basis Function Neural Network (RBF) and Decision Tree Forest (DTF). The predictor variables used to develop prediction models are age, gender, body mass index (BMI), heart rate (HR), maximal oxygen uptake (VO<sub>2</sub>max) and exercise time. By using 10-fold cross-validation on the dataset, the performance of the prediction models has been evaluated by calculating their multiple correlation coefficient (R) and standard error of estimate (SEE). The results show that the CCN-based model including the predictor variables age, gender, BMI and VO<sub>2</sub>max yields the lowest SEE both for the prediction of UBP<sub>10</sub> and UBP<sub>60</sub>.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7129809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129809","machine learning;regression;upper body power","Decision trees;Heart rate;Learning systems;Predictive models;Radial basis function networks;Support vector machines","biomechanics;decision trees;learning (artificial intelligence);radial basis function networks;regression analysis;sport","10-fold cross-validation;10-second UBP prediction;60-second UBP;BMI variable;CCN;DTF;HR variable;RBF;SEE;UBP<sub>10</sub>;UBP<sub>60</sub>;VO<sub>2</sub>max variable;age variable;body mass index variable;cascade correlation network;cross-country skiers;decision tree forest;exercise time variable;gender variable;heart rate variable;machine learning methods;maximal oxygen uptake variable;multiple correlation coefficient;performance evaluation;predictor variables;radial basis function neural network;standard error-of-estimate;upper body power prediction model development","","0","","11","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Developing machine learning tools for long-lead heavy precipitation prediction with multi-sensor data","Y. Di; W. Ding; Y. Mu; D. L. Small; S. Islam; N. B. Chang","Department of Computer Science, University of Massachusetts Boston, USA","2015 IEEE 12th International Conference on Networking, Sensing and Control","20150604","2015","","","63","68","A large number of extreme floods were closely related to heavy precipitation which lasted for several days or weeks. Long-lead prediction of extreme precipitation, i.e., prediction of 6-15 days ahead of time, is important for understanding the prognostic forecasting potential of many natural disasters, such as floods. Yet, long-lead flood forecasting is a challenging task due to the cascaded uncertainty with prediction errors from measurements to modeling, which makes the current physics-based numerical simulation models extremely complex and inaccurate. In this paper, we formulate the modeling work as a machine learning problem and introduce a complementary data mining framework for heavy precipitation prediction. Heavy precipitation that may lead to extreme floods is a rare event. Long-lead prediction requires the corresponding feature space to be sampled from extremely high spatio-temporal dimensions. Such a complexity makes long-lead heavy precipitation prediction a high dimensional and imbalanced machine learning problem. In this work, we firstly define the extreme precipitation and non-extreme precipitation clusters and then design the Nearest-Sample Choosing method to handle the imbalanced data sets. We introduce streaming feature selection and subspace learning to extract the most relevant features from high dimensional data. We evaluate the machine learning tools using historical flood data collected in the State of Iowa, the United States and associated hydrometeorological variables from 1948 to 2010.","","Electronic:978-1-4799-8069-7; POD:978-1-4799-8070-3; USB:978-1-4673-6900-8","10.1109/ICNSC.2015.7116011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116011","Fast Online Streaming Feature Selection;Heavy Precipitation Predicition;Machine Learning;Nearest Sample Choosing","Accuracy;Classification algorithms;Data mining;Floods;Forecasting;Predictive models;Training data","atmospheric precipitation;data mining;disasters;feature extraction;feature selection;floods;geophysics computing;learning (artificial intelligence);sensor fusion","State of Iowa;United States;data mining framework;feature extraction;hydrometeorological variables;imbalanced machine learning problem;long-lead flood forecasting;long-lead heavy precipitation prediction;machine learning problem;machine learning tools;multisensor data;natural disasters;nearest-sample choosing method;nonextreme precipitation clusters;physics-based numerical simulation models;prediction errors;prognostic forecasting potential;spatio-temporal dimensions;streaming feature selection;subspace learning","","3","","26","","","9-11 April 2015","","IEEE","IEEE Conference Publications"
"Predicting upper body power of cross-country skiers using machine learning methods combined with feature selection","D. Akgöl; M. F. Akay","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Osmaniye Korkut Ata &#x00DC;niversitesi, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","148","151","Upper body power (UBP) is one of the most important determinants of cross-country ski race performance. In this study, General Regression Neural Networks (GRNN), Radial Basis Function Neural Network (RBF), Decision Tree Forest (DTF) combined with a feature selection algorithm have been used to developed prediction models for estimating 10-second UBP (UBP<sub>10</sub>) and 60-second UBP (UBP<sub>60</sub>) of cross-country skiers. By using the Relief-F attribute selection algorithm, the score of each attribute has been calculated. Seven different UBP<sub>10</sub> and UBP<sub>60</sub> prediction models have been developed by removing the attribute with the lowest score at a time. By using 10-fold cross-validation on the data set, the performance of the prediction models has been evaluated by calculating their multiple correlation coefficients (R) and standard error of estimate (SEE). The results show that gender and VO<sub>2</sub>max are the most effective variables for prediction of UBP<sub>10</sub> and UBP<sub>60</sub>.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130287","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130287","decision tree forest;general regression neural networks;radial basis function neural networks;upper body power","Predictive models;Reliability","decision trees;learning (artificial intelligence);radial basis function networks;regression analysis;sport","DTF;GRNN;RBF;Relief-F attribute selection algorithm;cross-country skiers;decision tree forest;feature selection;general regression neural network;machine learning;radial basis function neural network;ski race performance;upper body power","","0","","11","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Comparison of machine learning methods for the sequence labelling applications","M. F. Amasyali; M. Bi̇lgi̇n","Bilgisayar Muhendisligi, Yildiz Teknik Univ., I&#x0307;stanbul, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","503","506","In this study, on artificial data sets, it was compared condition random fields(CRF) and classical machine learning(CML) types. First part of this study, the performances of CRF and CML types were measured on artificial data sets. As the result of studies, CML types, except Naive Bayes, performanced higher than CRF. The success of NR and CRF is high when the outputs consist of one distribution, in other case it stays low. Besides in this study, it was evaluated the effect of education set size on success. The second study was made to test this situation.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7129870","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129870","Conditional Random Fields;Sequence Labeling","Bagging;Data mining;Data models;Hidden Markov models;Labeling;Niobium;Probabilistic logic","learning (artificial intelligence);pattern recognition;random processes","CML type;CRF;classical machine learning;condition random field;sequence labelling application","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Machine learning schemes in augmented reality for features detection","G. Dandachi; A. Assoum; B. Elhassan; F. Dornaika","Doctoral School for science and technology, Azm Center, Lebanese University, Tripoli Lebanon","2015 Fifth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)","20150601","2015","","","101","105","Augmented Reality (AR) is a relatively old concept technology, which reached the large public very recently. We can use it to enhance our environments, by augmenting the image, the voice and delivering details and annotations about the surrounding space. Augmented reality (AR) is a growing field, with many diverse applications ranging from TV and film production, to industrial maintenance, medicine, education, entertainment and games. This paper presents an improved approach for image augmented-reality, by acting on two axes in the augmented reality process. First, a machine learning step is added to the detection part. Second, the registration of augmented image is processed by using the following techniques: statistical appearance models, and covariance matrices of dense image descriptors. A tuning of the used techniques and algorithms will be done in order to obtain a reliable and real-time image augmentation. We give a detailed description on how we chose the methods, and we compare our approach with other methods used in this domain. Finally, an evaluation of the proposed technique is presented as well as a performance study for a given use case.","","CD-ROM:978-1-4799-4130-8; Electronic:978-1-4799-4129-2; POD:978-1-4799-4128-5","10.1109/DICTAP.2015.7113179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113179","Augmented reality;features extraction and detection;graph search;image processing;image registration;machine learning","Augmented reality;Classification algorithms;Computer vision;Covariance matrices;Feature extraction;Image registration;Support vector machines","augmented reality;covariance matrices;image segmentation;learning (artificial intelligence);statistical analysis","AR;augmented image segmentation;augmented reality process;covariance matrices;dense image descriptors;feature detection;machine learning schemes;real-time image augmentation;statistical appearance models","","0","","22","","","April 29 2015-May 1 2015","","IEEE","IEEE Conference Publications"
"Modeling Finite-Element Constraint to Run an Electrical Machine Design Optimization Using Machine Learning","P. H. Arnoux; P. Caillard; F. Gillon","Laboratory of Electrical Engineering and Power Electronics, &#201;cole Centrale de Lille, Villeneuve d&#x2019;Ascq, France","IEEE Transactions on Magnetics","20150423","2015","51","3","1","4","This paper proposes a method to the model constraints from different models to run an optimization over models with different granularities. Through machine learning, the proposed method has proven to be able to accurately map the constraints and minimize the number of call to the model. It handles both continuous and discrete variables and mixes design rules to statistic approach to create a surrogate of the model.","0018-9464;00189464","","10.1109/TMAG.2014.2364031","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093402","Constraint modeling;finite-element (FE) model;machine learning;optimal design;random forest","Algorithm design and analysis;Computational modeling;Entropy;Iron;Optimization;Prediction algorithms;Vegetation","electric machines;finite element analysis;learning (artificial intelligence);minimisation;power engineering computing;statistical analysis","continuous variables;discrete variables;electrical machine design optimization;finite element constraint model;machine learning;statistic approach","","0","","11","","","March 2015","","IEEE","IEEE Journals & Magazines"
"Machine learning for arbitrary downsizing of pre-encoded video in HEVC","Luong Pham Van; J. De Praeter; G. Van Wallendael; J. De Cock; R. Van de Walle","Ghent University - iMinds, ELIS - Multimedia Lab, Belgium","2015 IEEE International Conference on Consumer Electronics (ICCE)","20150326","2015","","","406","407","In this paper, we propose a machine learning based transcoding scheme for arbitrarily downsizing a pre-encoded High Efficiency Video Coding video. The spatial scaling factor can be freely selected to adapt the output bit rate to the bandwidth of the network. Furthermore, machine learning techniques can exploit the correlation between input and output coding information to predict the split-flag of coding units in a P-frame. We analyzed the performance of both offline and online training in the learning phase of transcoding. The experimental results show that the proposed techniques significantly reduce the transcoding complexity and achieve trade-offs between coding performance and complexity. In addition, we demonstrate that online training performs better than offline training.","2158-3994;21583994","CD-ROM:978-1-4799-7542-6; Electronic:978-1-4799-7543-3; POD:978-1-4799-7544-0","10.1109/ICCE.2015.7066464","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066464","","Bit rate;Complexity theory;Predictive models;Training;Transcoding;Video coding","learning (artificial intelligence);transcoding;video coding","HEVC;arbitrary downsizing;high efficiency video coding;machine learning;output bit rate;pre-encoded video;spatial scaling factor;transcoding complexity;transcoding scheme","","1","","5","","","9-12 Jan. 2015","","IEEE","IEEE Conference Publications"
"Diabetic Retinopathy using morphological operations and machine learning","J. Lachure; A. V. Deorankar; S. Lachure; S. Gupta; R. Jadhav","CSE, GCOEAmravati, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","617","622","Diabetic Retinopathy that is DR which is a eye disease that affect retina and further later at severe stage it lead to vision loss. Early detection of DR is helpful to improve the screening of patient to prevent further damage. Retinal micro-aneurysms, haemorrhages, exudates and cotton wool spots are kind of major abnormality to find the Non- Proliferative Diabetic Retinopathy (NPDR) and Proliferative Diabetic Retinopathy (PDR). The main objective of our proposed work is to detect retinal micro-aneurysms and exudates for automatic screening of DR using Support Vector Machine (SVM) and KNN classifier. To develop this proposed system, a detection of red and bright lesions in digital fundus photographs is needed. Micro-aneurysms are the first clinical sign of DR and it appear small red dots on retinal fundus images. To detect retinal micro-aneurysms, retinal fundus images are taken from Messidor, DB-rect dataset. After pre-processing, morphological operations are performed to find micro-aneurysms and then features are get extracted such as GLCM and Structural features for classification. In order to classify the normal and DR images, different classes must be represented using relevant and significant features. SVM gives better performance over KNN classifier.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154781","KNN;NPDR;PDR;SVM;diabetic retinopathy;exudates;micro-aneurysms","Estimation;Feature extraction;Image segmentation;Retina;Support vector machines","diseases;eye;learning (artificial intelligence);medical image processing;patient treatment;support vector machines","KNN classifier;NPDR;SVM;cotton wool spots;digital fundus photographs;exudates;eye disease;haemorrhages;machine learning;morphological operations;non-proliferative diabetic retinopathy;patient screening;retinal fundus images;retinal micro-aneurysms;support vector machine;vision loss","","3","","13","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"MobDBTest: A machine learning based system for predicting diabetes risk using mobile devices","K. Sowjanya; A. Singhal; C. Choudhary","Department of Computer Science and Engineering, Rungta College of Engineering & Technology, Bhilai, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","397","402","Diabetes mellitus (DM) is reaching possibly epidemic proportions in India. The degree of disease and destruction due to diabetes and its potential complications are enormous, and originated a significant health care burden on both households and society. The concerning factor is that diabetes is now being proven to be linked with a number of complications and to be occurring at a comparatively younger age in the country. In India, the migration of people from rural to urban areas and corresponding modification in lifestyle are all moving the degree of diabetes. Deficiency of knowledge about diabetes causes untimely death among the population at large. Therefore, acquiring a proficiency that should spread awareness about diabetes may affect the people in India. In this work, a mobile/android application based solution to overcome the deficiency of awareness about diabetes has been shown. The application uses novel machine learning techniques to predict diabetes levels for the users. At the same time, the system also provides knowledge about diabetes and some suggestions on the disease. A comparative analysis of four machine learning (ML) algorithms were performed. The Decision Tree (DT) classifier outperforms amongst the 4 ML algorithms. Hence, DT classifier is used to design the machinery for the mobile application for diabetes prediction using real world dataset collected from a reputed hospital in the Chhattisgarh state of India.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154738","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154738","Android Application;Decision Tree;Diabetes;Diabetes Dataset;Machine learning algorithms","Classification algorithms;Decision trees;Diabetes;Machine learning algorithms;Multilayer perceptrons;Prediction algorithms;Support vector machines","Android (operating system);decision trees;diseases;epidemics;health care;learning (artificial intelligence);medical computing;mobile computing;pattern classification","Android application;DM;DT classifier;India;MobDBTest;decision tree classifier;diabetes level prediction;diabetes mellitus;diabetes risk prediction;epidemic proportions;health care;machine learning based system;mobile application;mobile devices","","1","","12","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"Real-time network anomaly detection system using machine learning","S. Zhao; M. Chandrashekar; Y. Lee; D. Medhi","Computer Science & Electrical Engineering Department, University of Missouri-Kansas City, USA","2015 11th International Conference on the Design of Reliable Communication Networks (DRCN)","20150709","2015","","","267","270","The ability to process, analyze, and evaluate realtime data and to identify their anomaly patterns is in response to realized increasing demands in various networking domains, such as corporations or academic networks. The challenge of developing a scalable, fault-tolerant and resilient monitoring system that can handle data in real-time and at a massive scale is nontrivial. We present a novel framework for real time network traffic anomaly detection using machine learning algorithms. The proposed prototype system uses existing big data processing frameworks such as Apache Hadoop, Apache Kafka, and Apache Storm in conjunction with machine learning techniques and tools. Our approach consists of a system for real-time processing and analysis of the real-time network-flow data collected from the campus-wide network at the University of Missouri-Kansas City. Furthermore, the network anomaly patterns were identified and evaluated using machine learning techniques. We present preliminary results on anomaly detection with the campus network data.","","Electronic:978-1-4799-7795-6; POD:978-1-4799-7796-3; USB:978-1-4799-7794-9","10.1109/DRCN.2015.7149025","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7149025","","Accuracy;Fasteners;IP networks;Ports (Computers);Real-time systems;Storms;Support vector machines","Big Data;fault tolerant computing;learning (artificial intelligence)","Big data processing frameworks;University of Missouri-Kansas City;campus network data;machine learning algorithms;real-time network anomaly detection system;scalable fault-tolerant resilient monitoring system","","0","","19","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Video quality assessment and machine learning: Performance and interpretability","J. Søgaard; S. Forchhammer; J. Korhonen","Technical University of Denmark, 2800 Kgs Lyngby, Denmark","2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX)","20150706","2015","","","1","6","In this work we compare a simple and a complex Machine Learning (ML) method used for the purpose of Video Quality Assessment (VQA). The simple ML method chosen is the Elastic Net (EN), which is a regularized linear regression model and easier to interpret. The more complex method chosen is Support Vector Regression (SVR), which has gained popularity in VQA research. Additionally, we present an ML-based feature selection method. Also, it is investigated how well the methods perform when tested on videos from other datasets. Our results show that content-independent cross-validation performance on a single dataset can be misleading and that in the case of very limited training and test data, especially in regards to different content as is the case for many video datasets, a simple ML approach is the better choice.","","Electronic:978-1-4799-8958-4; POD:978-1-4799-8959-1","10.1109/QoMEX.2015.7148149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148149","","Complexity theory;Correlation;Estimation;Quality assessment;Standards;Support vector machines;Training","data mining;data reduction;feature selection;learning (artificial intelligence);regression analysis;support vector machines;video signal processing","EN;ML;SVR;VQA;elastic net;feature selection method;linear regression model;machine learning;support vector regression;video dataset;video quality assessment","","2","","25","","","26-29 May 2015","","IEEE","IEEE Conference Publications"
"Automatic Thread-Level Canvas Analysis: A machine-learning approach to analyzing the canvas of paintings","L. van der Maaten; R. G. Erdmann","Delft Univ. of Technol., Delft, Netherlands","IEEE Signal Processing Magazine","20150612","2015","32","4","38","45","Canvas analysis is an important tool in art-historical studies, as it can provide information on whether two paintings were made on canvas that originated from the same bolt. Canvas analysis algorithms analyze radiographs of paintings to identify (ir)regularities in the spacings between the canvas threads. To reduce noise, current state-of-the-art algorithms do this by averaging the signal over a number of threads, which leads to information loss in the final measurements. This article presents an algorithm capable of performing thread-level canvas analysis: the algorithm identifies each of the individual threads in the canvas radiograph and directly measures between-distances and angles of the identified threads. We present two case studies to illustrate the potential merits of our thread-level canvas analysis algorithm, viz. on a small collection of paintings ostensibly by Nicholas Poussin and on a small collection of paintings by Vincent van Gogh.","1053-5888;10535888","","10.1109/MSP.2015.2407091","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123035","","Algorithm design and analysis;Art;Feature extraction;Information analysis;Instruction sets;Painting;Radiography;Signal processing algorithms","art;learning (artificial intelligence)","art-historical study;automatic thread-level canvas analysis algorithm;canvas radiograph analysis;machine-learning approach;noise reduction;painting canvas analysis","","3","","21","","","July 2015","","IEEE","IEEE Journals & Magazines"
"PolyNet: A Polynomial-Based Learning Machine for Universal Approximation","M. S. Pukish; P. Różycki; B. M. Wilamowski","Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA","IEEE Transactions on Industrial Informatics","20150602","2015","11","3","708","716","Currently, there is a need in all disciplines for efficient and powerful machine learning (ML) algorithms for handling offline and real-time nonlinear data. Industrial applications abound from real-time control systems to modeling and simulation of complex systems and processes. Certain ML methods have become popular with researchers and engineers. Such techniques include fuzzy systems (FSs), artificial neural networks (ANNs), radial basis function (RBF) networks, and support vector regression (SVR) machines. Historically, polynomial-based learning machines (PLMs) based on the group method of data handling (GMDH) model have enjoyed usage similar to that of these other methods. However, unwieldy kernel functions in the form of large high-order polynomials, and relatively limited computer speed and capacity, have limited the use of PLMs to comparatively small problems with low dimensionality and simple functional relationships. Thus, true polynomial-based ML solutions have drifted out of vogue for at least two decades. This work attempts to reinvigorate the interest in PLMs by introducing a novel practical implementation called PolyNet. It will be shown that once certain algorithms are applied to the generation, training, and functional operation of PLMs, they can compete on par with or better than methods currently in use.","1551-3203;15513203","","10.1109/TII.2015.2426012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095595","Artificial neural networks;Artificial neural networks (ANNs);GMDH;group method of data handling (GMDH);industrial electronics;industrial electronics (IE);machine learning;machine learning (ML);multivariate regression;polynomial networks","Algorithm design and analysis;Approximation algorithms;Approximation methods;Artificial neural networks;Kernel;Polynomials;Training","data handling;fuzzy systems;learning (artificial intelligence);polynomial approximation;radial basis function networks;regression analysis;support vector machines","ANN;FS;GMDH model;PLM;PolyNet;RBF;SVR;SVR machines;artificial neural networks;fuzzy systems;group method of data handling;offline data handling;polynomial-based ML solutions;polynomial-based learning machine;radial basis function;radial basis function networks;real-time nonlinear data handling;support vector regression machines;universal approximation","","3","","36","","20150427","June 2015","","IEEE","IEEE Journals & Magazines"
"Energy Hub optimal sizing in the smart grid; machine learning approach","A. Sheikhi; M. Rayati; A. M. Ranjbar","Electrical Engineering Department, Sharif University of Technology, Tehran, Iran","2015 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)","20150625","2015","","","1","5","The interests in “Energy Hub” (EH) and “Smart Grid” (SG) concepts have been increasing, in recent years. The synergy effect of the coupling between electricity and natural gas grids and utilizing intelligent technologies for communicating, may change energy management in the future. A new solution entitling “Smart Energy Hub” (S. E. Hub) that models a multi-carrier energy system in a SG environment studied in this paper. Moreover, the optimal size of CHP, auxiliary boiler, absorption chiller, and also transformer unit as main elements of a S. E. Hub is determined. Authors proposed a comprehensive cost and benefit analysis to optimize these elements and apply Reinforcement Learning (RL) algorithm for solving the optimization problem. To confirm the proposed method, a residential customer has been investigated as an S. E. Hub in a dynamic electricity pricing market.","","Electronic:978-1-4799-1785-3; POD:978-1-4799-1786-0; USB:978-1-4799-1784-6","10.1109/ISGT.2015.7131796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131796","Energy Management System;Optimal size;Reinforcement Learning (RL);Smart Energy Hub (S. E. Hub);Smart Grids;financial analysis","Absorption;Boilers;Cogeneration;Energy management;Learning (artificial intelligence);Natural gas;Smart grids","boilers;cogeneration;learning (artificial intelligence);power markets;pricing;smart power grids;transformers","CHP;EH;RL algorithm;SE Hub;SG;absorption chiller;auxiliary boiler;benefit analysis;cost analysis;electricity pricing market;energy hub optimal sizing;energy management;intelligent technology;machine learning approach;multicarrier energy system;natural gas grid;optimization problem;reinforcement learning algorithm;smart energy hub;smart grid;synergy effect;transformer unit","","0","","26","","","18-20 Feb. 2015","","IEEE","IEEE Conference Publications"
"Diagnosis of machining outcomes based on machine learning with Logical Analysis of Data","Y. Shaban; S. Yacout; M. Balazinski; M. Meshreki; H. Attia","&#x00C9;cole Polytechnique de Montr&#x00E9;al, Qu&#x00E9;bec, Canada","2015 International Conference on Industrial Engineering and Operations Management (IEOM)","20150427","2015","","","1","8","Force is considered to be one of the indicators that best describe the machining process. Measured force can be used to evaluate the quality and geometric profile of the machined part. In this paper, a combinatorial optimization approach is used to characterize the effect of force on the quality of a machined part made of Carbon Fiber Reinforced Polymers (CFRP) material. The approach is called Logical Analysis of Data (LAD) and is based on machine learning and pattern recognition. LAD is used in order to map the machining conditions, in terms of force and torque that lead to conforming products and those which lead to nonconforming products. In this paper, the LAD technique is applied to the drilling of CFRP plates, and the results, based on data obtained experimentally, are reported. A discussion of the potential use of LAD in manufacturing concludes the paper.","","Electronic:978-1-4799-6065-1; POD:978-1-4799-6066-8","10.1109/IEOM.2015.7093752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093752","Logical Analysis of Data Introduction;Machine learning;Machining;fault diagnosis","Delamination;Drilling machines;Force;Machining;Torque;Training","carbon fibre reinforced plastics;drilling;fault diagnosis;force measurement;learning (artificial intelligence);plates (structures);production engineering computing;quality control","CFRP materials;CFRP plates;LAD technique;carbon fiber reinforced polymers;combinatorial optimization;drilling;force measurement;logical analysis of data;machine learning;machining","","0","","19","","","3-5 March 2015","","IEEE","IEEE Conference Publications"
"Comparative study on machine learning techniques in predicting the QoS-values for web-services recommendations","S. Kumar; M. K. Pandey; A. Nath; K. Subbiah; M. K. Singh","Department of Computer Science, Banaras Hindu University, Varanasi-221005, India","International Conference on Computing, Communication & Automation","20150706","2015","","","161","167","This is an era of Internet computing and computing as a service on the internet is called cloud computing. Mainly three services like SaaS (applications), PaaS, and IaaS are being accessed through internet on demand, pay as per usage basis. Quality of Service (QoS) is the main issue in internet based computing for service providers and user-dependent as well as user-independent QoS parameters. In the current work we compared different machine learning algorithms for predicting the response time and throughput QoS values using past usage data. Bagging and support vector machines are found to be better performing prediction methods in comparison with other learning algorithms.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148398","Bagging;Cloud Computing;Customer Centric QoS attributes;Prediction;SVM;Web Services","Bagging;Cloud computing;Quality of service;Standards;Throughput;Time factors","Web services;cloud computing;learning (artificial intelligence);quality of service;recommender systems;support vector machines","IaaS;Internet computing;PaaS;QoS-values prediction;SaaS;Web-service recommendation;bagging;cloud computing;machine learning technique;quality of service;response time;support vector machines;user-dependent QoS parameters;user-independent QoS parameters","","3","","37","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"Intrusion Detection System Using Bagging Ensemble Method of Machine Learning","D. P. Gaikwad; R. C. Thool","Dept. of Comput. Eng., AISSMS Coll. of Eng., Pune, India","2015 International Conference on Computing Communication Control and Automation","20150716","2015","","","291","295","Intrusion detection system is widely used to protect and reduce damage to information system. It protects virtual and physical computer networks against threats and vulnerabilities. Presently, machine learning techniques are widely extended to implement effective intrusion detection system. Neural network, statistical models, rule learning, and ensemble methods are some of the kinds of machine learning methods for intrusion detection. Among them, ensemble methods of machine learning are known for good performance in learning process. Investigation of appropriate ensemble method is essential for building effective intrusion detection system. In this paper, a novel intrusion detection technique based on ensemble method of machine learning is proposed. The Bagging method of ensemble with REPTree as base class is used to implement intrusion detection system. The relevant features from NSL_KDD dataset are selected to improve the classification accuracy and reduce the false positive rate. The performance of proposed ensemble method is evaluated in term of classification accuracy, model building time and False Positives. The experimental results show that the Bagging ensemble with REPTree base class exhibits highest classification accuracy. One advantage of using Bagging method is that it takes less time to build the model. The proposed ensemble method provides competitively low false positives compared with other machine learning techniques.","","Electronic:978-1-4799-6892-3; POD:978-1-4799-6893-0","10.1109/ICCUBEA.2015.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155853","Bagging;Ensemble;False positives;Machine learning;REPTree;intrusion detection","Accuracy;Bagging;Classification algorithms;Feature extraction;Hidden Markov models;Intrusion detection;Training","data analysis;learning (artificial intelligence);neural nets;security of data;statistical analysis;trees (mathematics)","NSL-KDD dataset;REPTree;classification accuracy;intrusion detection system;machine learning techniques;neural network;physical computer networks;statistical models;using bagging ensemble method;virtual computer networks","","1","","16","","","26-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"18.4 A matrix-multiplying ADC implementing a machine-learning classifier directly with data conversion","J. Zhang; Z. Wang; N. Verma","Princeton University, Princeton, NJ","2015 IEEE International Solid-State Circuits Conference - (ISSCC) Digest of Technical Papers","20150319","2015","","","1","3","Embedded sensing systems conventionally perform A-to-D conversion followed by signal analysis. In many applications, the analysis of interest is inference (e.g., classification), but the sensor signals involved are too complex to model analytically. Machine learning is gaining prominence because it enables data-driven training of classifiers, overcoming the need for analytical models. This work presents: 1) an algorithmic formulation, where feature extraction and classification are combined into a single matrix, reducing the total multiplications needed, and 2) a matrix-multiplying ADC (MMADC) that enables multiplication of input samples by a programmable matrix. Thus, the MMADC combines feature extraction and classification with data conversion, mitigating the need for further computations. Two systems are demonstrated: an ECG-based cardiac-arrhythmia detector and an image-pixel-based gender detector.","0193-6530;01936530","Electronic:978-1-4799-6224-2; POD:978-1-4799-6225-9","10.1109/ISSCC.2015.7063061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063061","","Algorithm design and analysis;Attenuation;Classification algorithms;Feature extraction;Hardware;Support vector machine classification;Training","analogue-digital conversion;electrocardiography;embedded systems;learning (artificial intelligence);matrix multiplication;object detection;signal classification","A-to-D conversion;ECG-based cardiac-arrhythmia detector;MMADC;data conversion;data-driven training;embedded sensing systems;feature extraction;image-pixel-based gender detector;machine-learning classifier;matrix-multiplying ADC;programmable matrix;sensor signals;signal analysis","","5","","5","","","22-26 Feb. 2015","","IEEE","IEEE Conference Publications"
"Machine learning and BCI","K. R. Müller","Machine Learning Group, TU Berlin, Marchstr 23, 10587 Berlin, Germany","The 3rd International Winter Conference on Brain-Computer Interface","20150402","2015","","","1","1","Summary from only given. A main motivation for multimodal imaging has been the possibility to enhance medical diagnosis[1]. Beyond this original medical motivation the fusion of multiple modalities has created successful interesting research opportunities that have furthered our understanding of the brain and cognition[15]. In BCI recently multimodal fusion concepts have received great attention under the label hybrid BCI[13]. Fusing information has also been a very common practice in the sciences and engineering [17]. Recently a family of novel multimodal data analysis methods have emerged that can extract nonlinear relations between data[1,2,5-10]. They are rooted in the modern machine learning and signal processing techniques that are now available for analysing EEG, for decoding mental states etc[3,11,12,14,16]. The talk will first discuss recent multimodal analysis techniques such as SPoC[5-7]. Furthermore if time permits we will discuss a novel reliable method for estimating the Hurst exponent, a quantity that has recently become popular for describing network properties and is being used for diagnostic purposes[4]. Both nonlinear techniques allow for a better and more reliable and robust analysis of complex phenomena in neurophysiological data.","","Electronic:978-1-4799-7495-5; POD:978-1-4799-7496-2","10.1109/IWW-BCI.2015.7073023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073023","","Abstracts;Decision support systems","brain-computer interfaces;cognition;data analysis;electroencephalography;learning (artificial intelligence);medical signal processing;neurophysiology;patient diagnosis","EEG;Hurst exponent;SPoC;cognition;fusing information;label hybrid BCI;machine learning;medical diagnosis;medical motivation;mental state decoding;multimodal analysis techniques;multimodal data analysis method;multimodal fusion concept;multimodal imaging;neurophysiological data;nonlinear relations extraction;robust analysis;signal processing techniques","","0","","17","","","12-14 Jan. 2015","","IEEE","IEEE Conference Publications"
"Predicting Systolic Blood Pressure Using Machine Learning","T. H. Wu; G. K. H. Pang; E. W. Y. Kwong","Department of Elee. & Electronic Engg., The University of Hong Kong, Pokfulam, Hong Kong","7th International Conference on Information and Automation for Sustainability","20150330","2014","","","1","6","In this paper, a new study based on machine learning technique, specifically artificial neural network, is investigated to predict the systolic blood pressure by correlated variables (BMI, age, exercise, alcohol, smoke level etc.). The raw data are split into two parts, 80% for training the machine and the remaining 20% for testing the performance. Two neural network algorithms, back-propagation neural network and radial basis function network, are used to construct and validate the prediction system. Based on a database with 498 people, the probabilities of the absolute difference between the measured and predicted value of systolic blood pressure under 10mm Hg are 51.9% for men and 52.5% for women using the back-propagation neural network With the same input variables and network status, the corresponding results based on the radial basis function network are 51.8% and 49.9% for men and women respectively. This novel method of predicting systolic blood pressure contributes to giving early warnings to young and middle-aged people who may not take regular blood pressure measurements. Also, as it is known an isolated blood pressure measurement is sometimes not very accurate due to the daily fluctuation, our predictor can provide another reference value to the medical staff. Our experimental result shows that artificial neural networks are suitable for modeling and predicting systolic blood pressure.","2151-1802;21511802","Electronic:978-1-4799-4598-6; POD:978-1-4799-4597-9","10.1109/ICIAFS.2014.7069529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069529","Systolic blood pressure;artificial neural network;hypertension;prediction","Artificial neural networks;Biomedical monitoring;Blood pressure;Databases;Pressure measurement;Stress;Training","backpropagation;blood pressure measurement;medical computing;patient diagnosis;patient monitoring;radial basis function networks","artificial neural network;back-propagation neural network algorithm;blood pressure prediction system construction;blood pressure prediction system validation;blood pressure reference value;blood pressure-BMI correlation;blood pressure-age correlation;blood pressure-alcohol correlation;blood pressure-body mass index;blood pressure-exercise correlation;blood pressure-smoke level correlation;daily blood pressure fluctuation;early blood pressure warning;isolated blood pressure measurement;machine learning technique;machine performance testing;machine training;neural network algorithms;predicted blood pressure value;pressure 10.00 mm Hg;radial basis function network algorithm;regular blood pressure measurements;systolic blood pressure modeling","","0","","29","","","22-24 Dec. 2014","","IEEE","IEEE Conference Publications"
"A machine learning adaptive approach to remove impurities over Bigdata","A. Devgun","Computer Science Engineering, National Institute of Technology, Jalandhar, India","2014 International Conference on Electronics, Communication and Computational Engineering (ICECCE)","20150416","2014","","","220","225","A Bigdata is the vast information storage collected from various locations and sources. Bigdata is defined as centralized repository with a standard structural specification. But the information driven from various sources are not always appropriate for this structure. This kind of information suffers from number of associated impurities. These impurities include incompleteness, duplicate information, lack of association between dataset attributes etc. To represent this information in organized and structured form, there is the requirement of some algorithmic approach that can identify these impurities and accept the validated data. In this present work, a two stage mode is defined under machine learning approach to transformed unstructured data to structured form. In first stage of this model, a fuzzy based model is defined to analyze this user data. The analysis is performed here under the impurity type analysis and the association analysis. The fuzzy rule is implied here to identify the degree of impurity and the associativity. Once the analysis is performed, the final stage of work is the transformation approach. During this stage, the transformation of this unstructured data to structured data is performed. An ontology driven work is defined to define such mapping. The mapping is here performed under the domain constructs and the data constructs. The work is implemented in java environment. The obtained results from system shows the reliable and robust information mapping so that the effective information tracking over the dataset is obtained.","","DVD:978-1-4799-5747-7; Electronic:978-1-4799-5748-4; POD:978-1-4799-5749-1","10.1109/ICECCE.2014.7086616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7086616","Bigdata;Fuzzy Effective;Impurities;machine learning;structured analysis","Analytical models;Big data;File systems;Impurities;Machine learning algorithms;Reliability;Servers","Big Data;Java;fuzzy set theory;learning (artificial intelligence);ontologies (artificial intelligence);storage management","Big Data;Java environment;algorithmic approach;association analysis;associativity degree;centralized repository;dataset attributes;duplicate information;fuzzy based model;fuzzy rule;impurities identification;impurities removal;impurity degree;impurity type analysis;incompleteness impurities;information mapping;information storage;information tracking;machine learning adaptive approach;ontology driven work;standard structural specification;structured form;unstructured data transformation;user data","","0","","13","","","17-18 Nov. 2014","","IEEE","IEEE Conference Publications"
"Optimization technique, curve fitting and machine learning used to detect Brain Tumor in MRI","S. Khare; N. Gupta; V. Srivastava","TIEIT, Bhopal India","Proceedings of IEEE International Conference on Computer Communication and Systems ICCCS14","20150326","2014","","","254","259","Image processing has a sub-branch of Image Segmentation in which images are segmented to collect information regarding image or a particular region. There are various application of Image Segmentation among them Medical Image Analysis is a popular application. Analysis of Medical Image provides information to the doctor for the treatment from MRI or CT images. Volumes of tissues, Brain Tumor detection are some of the applications of image segmentation in medical image analysis. Many researches have been occurred in order to detect tumor present in the brain, the area of tumor, the type of tumor present. The following paper proposes a new algorithm for the detection of brain tumor using MRI. The proposed method is implemented using Optimization Technique, Machine Learning and Curve Fitting Techniques to detect tumor. The proposed method proves to be efficient, 16.39% accurate and 9.53% precised then the existing work.","","Electronic:978-1-4799-3672-4; POD:978-1-4799-3673-1","10.1109/ICCCS.2014.7068202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7068202","Brain Tumor;Curve Fitting and Support Vector Machine;Genetic Algorithm;MRI image","Curve fitting;Feature extraction;Genetic algorithms;Image segmentation;Sociology;Statistics;Tumors","biomedical MRI;curve fitting;image segmentation;learning (artificial intelligence);medical image processing;object detection;optimisation;tumours","MRI;brain tumor detection;curve fitting;image segmentation;machine learning;optimization technique","","1","","9","","","20-21 Feb. 2014","","IEEE","IEEE Conference Publications"
"Driving Timing Convergence of FPGA Designs through Machine Learning and Cloud Computing","N. Kapre; B. Chandrashekaran; H. Ng; K. Teo","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","2015 IEEE 23rd Annual International Symposium on Field-Programmable Custom Computing Machines","20150716","2015","","","119","126","Machine learning and cloud computing techniques can help accelerate timing closure for FPGA designs without any modification to original RTL code. RTL is generally frozen closer to system delivery target to avoid injecting new unforeseen bugs or significantly affecting design characteristics. In these circumstances, developers trying to close timing are either at the mercy of random trials through placement seed exploration or through vendor-provided design space exploration tools that run a few compilation trials with changes to the CAD tool options (or parameters). Instead, we propose evaluating multiple CAD runs in parallel on the cloud, supported by a Bayesian learning and classification framework for generating multiple CAD parameter combinations most likFPGA CAD tool parametersely to help attain timing closure. We maintain a database of FPGA CAD tool parameters (input) along with associated variations in timing slack (output)to enable the learning process. A key engineering resource we use here is cheap and abundant parallelism made possible through cloud computing frameworks such as the Google Compute Engine. Across a range of open-source benchmarks, we show that learning helps improve total negative slack (TNS) scores by 10.5× (geomean) when compared to a single baseline run of Quart us 14.1 and by 7× (geomean) when compared to Alter a Quart us 14.1 Design Space Explorer (DSE).","","Electronic:978-1-4799-9969-9; POD:978-1-4799-9970-5","10.1109/FCCM.2015.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160055","","Cloud computing;Convergence;Databases;Design automation;Field programmable gate arrays;Proposals;Timing","cloud computing;field programmable gate arrays;learning (artificial intelligence);logic CAD;parallel processing;pattern classification","Bayesian learning;DSE;FPGA CAD tool parameters;FPGA designs;Google compute engine;Quart us 14.1 design space explorer;RTL code;TNS;classification framework;cloud computing techniques;machine learning;multiple CAD parameter combinations;open-source benchmarks;placement seed exploration;timing convergence;total negative slack;vendor-provided design space exploration tools","","5","","12","","","2-6 May 2015","","IEEE","IEEE Conference Publications"
"Prediction of maximum oxygen uptake with different machine learning methods by using submaximal data","İ. Yıldız; M. F. Akay","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x00C7;ukurova &#x00DC;niversitesi, Adana, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","184","187","Maximum oxygen uptake (VO<sub>2</sub>max) is the highest amount of oxygen used by the body during intense exercise and is an important component to determine cardiorespiratory fitness. In this study, models have been developed for predicting VO<sub>2</sub>max with four different machine learning methods. These methods are Treeboost (TB), Decision Tree Forest (DTF), Gene Expression Programming (GEP) and Single Decision Tree (SDT). The predictor variables used to develop prediction models include gender, age, weight, height, treadmill speed, heart rate and stage. The performance of the prediction models have been evaluated by calculating Standard Error of Estimate (SEE) and Multiple Correlation Coefficient (R) and using 10-fold cross validation. Results show that compared to the SEE's of TB, the maximum percentage decrement rates in SEE's of DTF, GEP and SDT are 8.38%, 12.97% and 23.07%, respectively.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130444","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130444","machine learning;maximal oxygen uptake;prediction","Art;Decision trees;Gene expression;Oxygen;Predictive models;Programming;Support vector machines","decision trees;estimation theory;genetic algorithms;health care;learning (artificial intelligence)","DTF;GEP;SDT;cardiorespiratory fitness;decision tree forest;gene expression programming;machine learning method;maximum oxygen uptake;multiple correlation coefficient;prediction model;single decision tree;standard error of estimate;submaximal data;treeboost","","0","","14","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Accelerating Machine Learning Kernel in Hadoop Using FPGAs","K. Neshatpour; M. Malik; H. Homayoun","","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","20150709","2015","","","1151","1154","Big data applications share inherent characteristics that are fundamentally different from traditional desktop CPU, parallel and web service applications. They rely on deep machine learning and data mining applications. A recent trend for big data analytics is to provide heterogeneous architectures to allow support for hardware specialization to construct the right processing engine for analytics applications. However, these specialized heterogeneous architectures require extensive exploration of design aspects to find the optimal architecture in terms of performance and cost. % Considering the time dedicated to create such specialized architectures, a model that estimates the potential speedup achievable through offloading various parts of the algorithm to specialized hardware would be necessary. This paper analyzes how offloading computational intensive kernels of machine learning algorithms to a heterogeneous CPU+FPGA platform enhances the performance. We use the latest Xilinx Signboards for implementation and result analysis. Furthermore, we perform a comprehensive analysis of communication and computation overheads such as data I/O movements, and calling several standard libraries that can not be offloaded to the accelerator to understand how the speedup of each application will contribute to its overall execution in an end-to-end Hadoop MapReduce environment.","","Electronic:978-1-4799-8006-2; POD:978-1-4799-8007-9","10.1109/CCGrid.2015.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152609","Acceleration;Big Data;FPGA","Acceleration;Big data;Computer architecture;Field programmable gate arrays;Hardware;Kernel;Machine learning algorithms","Big Data;data analysis;data mining;field programmable gate arrays;learning (artificial intelligence);parallel processing","Big data applications;FPGA;Hadoop;Web service applications;Xilinx Zynq boards;data I/O movements;data mining applications;deep machine learning application;desktop CPU;end-to-end Hadoop MapReduce environment;heterogeneous CPU+FPGA platform;heterogeneous architectures;machine learning algorithms;machine-learning kernels;optimal architecture;processing engine","","4","","10","","","4-7 May 2015","","IEEE","IEEE Conference Publications"
"Machine Learning for Wideband Localization","T. Van Nguyen; Y. Jeong; H. Shin; M. Z. Win","Dept. of Electron. & Radio Eng., Kyung Hee Univ., Yongin, South Korea","IEEE Journal on Selected Areas in Communications","20150619","2015","33","7","1357","1380","Wireless localization has a great importance in a variety of areas including commercial, service, and military positioning and tracking systems. In harsh indoor environments, it is hard to localize an agent with high accuracy due to non-line-of-sight (NLOS) radio blockage or insufficient information from anchors. Therefore, NLOS identification and mitigation are highlighted as an effective way to improve the localization accuracy. In this paper, we develop a robust and efficient algorithm to enhance the accuracy for (ultrawide bandwidth) time-of-arrival localization through identifying and mitigating NLOS signals with relevance vector machine (RVM) techniques. We also propose a new localization algorithm, called the two-step iterative (TSI) algorithm, which converges fast with a finite number of iterations. To enhance the localization accuracy as well as expand the coverage of a localizable area, we continue to exploit the benefits of RVM in both classification and regression for cooperative localization by extending the TSI algorithm to a centralized cooperation case. For self-localization setting, we then develop a distributed cooperative algorithm based on variational Bayesian inference to simplify message representations on factor graphs and reduce communication overheads between agents. In particular, we build a refined version of Gaussian variational message passing to reduce the computational complexity while maintaining the localization accuracy. Finally, we introduce the notion of a stochastic localization network to verify proposed cooperative localization algorithms.","0733-8716;07338716","","10.1109/JSAC.2015.2430191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102989","Cooperative localization;IEEE 802.15.4-2011;NLOS mitigation;non-line-of-sight (NLOS);relevance vector machine (RVM);ultrawide bandwidth (UWB);variational message passing (VMP)","Accuracy;Bandwidth;Delays;Distance measurement;IEEE 802.15 Standards;Noise;Support vector machines","Gaussian processes;computational complexity;inference mechanisms;iterative methods;learning (artificial intelligence);radio networks;telecommunication computing;time-of-arrival estimation","Gaussian variational message passing;NLOS identification;NLOS radio blockage;RVM techniques;TSI algorithm;centralized cooperation case;computational complexity;distributed cooperative algorithm;factor graphs;harsh indoor environments;machine learning;message representations;military positioning;non-line-of-sight;relevance vector machine;time-of-arrival localization;tracking systems;two-step iterative algorithm;variational Bayesian inference;wideband localization;wireless localization","","5","","67","","20150506","July 2015","","IEEE","IEEE Journals & Magazines"
"Underwater robot-object contact perception using machine learning on force/torque sensor feedback","N. Jamali; P. Kormushev; A. C. Viñas; M. Carreras; D. G. Caldwell","Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego, 30, 16163 Genova, Italy","2015 IEEE International Conference on Robotics and Automation (ICRA)","20150702","2015","","","3915","3920","Autonomous manipulation of objects requires reliable information on robot-object contact state. Underwater environments can adversely affect sensing modalities such as vision, making them unreliable. In this paper we investigate underwater robot-object contact perception between an autonomous underwater vehicle and a T-bar valve using a force/torque sensor and the robot's proprioceptive information. We present an approach in which machine learning is used to learn a classifier for different contact states, namely, a contact aligned with the central axis of the valve, an edge contact and no contact. To distinguish between different contact states, the robot performs an exploratory behavior that produces distinct patterns in the force/torque sensor. The sensor output forms a multidimensional time-series. A probabilistic clustering algorithm is used to analyze the time-series. The algorithm dissects the multidimensional time-series into clusters, producing a one-dimensional sequence of symbols. The symbols are used to train a hidden Markov model, which is subsequently used to predict novel contact conditions. We show that the learned classifier can successfully distinguish the three contact states with an accuracy of 72% ± 12 %.","1050-4729;10504729","Electronic:978-1-4799-6923-4; POD:978-1-4799-6924-1; USB:978-1-4799-6922-7","10.1109/ICRA.2015.7139745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7139745","","Force;Grippers;Hidden Markov models;Robot sensing systems;Torque;Valves","force sensors;hidden Markov models;learning (artificial intelligence);mobile robots;time series;underwater vehicles","T-bar valve;autonomous manipulation;autonomous underwater vehicle;edge contact;force-torque sensor feedback;hidden Markov model;learned classifier;machine learning;multidimensional time-series;probabilistic clustering algorithm;reliable information;robot object contact state;robot proprioceptive information;time-series analysis;underwater environments;underwater robot object contact perception","","0","","12","","","26-30 May 2015","","IEEE","IEEE Conference Publications"
"Machine Learning in Bioinformatics: A Novel Approach for DNA Sequencing","P. Dixit; G. I. Prajapati","Dept. of Inf. Technol., Shri S'ad Vidya Mandal Inst. of Technol., Bharuch, India","2015 Fifth International Conference on Advanced Computing & Communication Technologies","20150406","2015","","","41","47","Machine learning is the adaptive process that makes computers improve from experience, by example, and by analogy. So It is a discipline of methodologies that provides, in one form or another, intelligent information processing capabilities for handling real life. Bioinformatics is one of the application of Machine Learning. Bioinformatics is the interdisciplinary science of interpreting biological data using information technology and computer science. Machine learning (ML) focuses on automatic learning from data set. Machine learning includes the learning speed, the guarantee of convergence, and how the data can be learned incrementally. We usually refer to methods like Artificial Neural Networks (ANNs), Genetic algorithms (GAs), and Fuzzy systems along with hybrid methods including a combination of some of these methods. One of the major problems is to classify the normal genes and the invalid genes which are infected by some kind of diseases. In genomic research, classifying DNA sequences into existing categories is used to learn the functions of a new protein. So, it is important to identify those genes and classify them. In order to identify the infected genes and the normal genes with the use of classification methods here we use the machine learning techniques. This paper gives a review on the mechanisms of gene sequence classification using Machine Learning techniques, which includes a brief detail on bioinformatics, literature survey and key issues in DNA Sequencing using Machine Learning.","2327-0632;23270632","Electronic:978-1-4799-8488-6; POD:978-1-4799-8489-3","10.1109/ACCT.2015.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079049","Bioinformatics;Classification;DNA Sequencing;Machine Learning Techniques","Artificial neural networks;Bioinformatics;DNA;Genomics;Proteins;Sequential analysis;Support vector machines","bioinformatics;genetics;learning (artificial intelligence);pattern classification","DNA sequencing;ML;bioinformatics;gene sequence classification;machine learning","","0","","16","","","21-22 Feb. 2015","","IEEE","IEEE Conference Publications"
"Machine learning based biomedical named entity recognition","N. Kanya; T. Ravi","Manonmanium Sundaranar Univ., Tirunelveli, India","IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013)","20150611","2013","","","380","384","The biomedical society makes wide use of text mining technology. Named Entity (NE) extraction is one of the most primary and significant tasks in biomedical information extraction of text mining technology. Named Entity Recognition (NER) involves processing structured and unstructured documents to recognize the definite kinds of entities and categorization of them into some predefined classes. Several Named Entity Recognition systems have been developed for the Biomedical Domain based on the Rule-Based, Dictionary based and Machine Learning based techniques. Implementing the best approach is not possible in all domains. Machine learning based approaches have many advantages than other approaches. In this paper we are proposing a Machine learning based framework for recognizing named entities from biomedical abstracts. For this study we used benchmarked datasets such as GENETAG and JNLPBA.","","Paper:978-1-78561-030-1","10.1049/ic.2013.0342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119729","CRF;Machine Learning;NER","","data mining;learning (artificial intelligence);medical computing;text analysis","NE extraction;NER;biomedical abstracts;biomedical domain;biomedical information extraction;biomedical society;dictionary based techniques;machine learning based biomedical named entity recognition system;rule-based techniques;structured document processing;text mining technology;unstructured document processing","","0","","","","","12-14 Dec. 2013","","IET","IET Conference Publications"
"Wind farm performance validation through machine learning: Sector-wise Honest Brokers","S. C. Evans; Z. Zhang; S. Iyengar; P. Gregg; M. Jonkhof","GE Global Research, USA","2015 IEEE Aerospace Conference","20150608","2015","","","1","8","Recent methods to optimize wind farm performance require new methods to assess and validate wind farm level performance. This paper introduces a machine learning approach based on sector wise honest brokers in order to determine expectation of wind energy and validate performance improvements. The approach treats every turbine in the wind farm as a virtual Metmast. Farm level expectation of power is determined based on machine learning models trained on baseline data with input features reflecting “Honest Brokers”: turbines that experience similar conditions in both a training interval and a testing interval in which we are expecting a change in farm performance. Our approach is able to validate farm level improvements even in the face of farm optimization technologies for controlling wakes that change the wind profile within the farm.","1095-323X;1095323X","Electronic:978-1-4799-5380-6; POD:978-1-4799-5381-3; USB:978-1-4799-5378-3","10.1109/AERO.2015.7119130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119130","","Data models;Training;Transfer functions;Wind energy","learning (artificial intelligence);optimisation;power engineering computing;wakes;wind power plants;wind turbines","machine learning approach;optimization technology;sector wise honest broker;virtual Metmast;wake control;wind energy;wind farm performance validation;wind turbine","","0","","10","","","7-14 March 2015","","IEEE","IEEE Conference Publications"
"A Machine Learning Approach for Accurate Annotation of Noncoding RNAs","Y. Song; C. Liu; Z. Wang","School of Electronics and Information Science, Jiangsu University of Science and Technology Zhenjiang, Jiangsu, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20150602","2015","12","3","551","559","Searching genomes to locate noncoding RNA genes with known secondary structure is an important problem in bioinformatics. In general, the secondary structure of a searched noncoding RNA is defined with a structure model constructed from the structural alignment of a set of sequences from its family. Computing the optimal alignment between a sequence and a structure model is the core part of an algorithm that can search genomes for noncoding RNAs. In practice, a single structure model may not be sufficient to capture all crucial features important for a noncoding RNA family. In this paper, we develop a novel machine learning approach that can efficiently search genomes for noncoding RNAs with high accuracy. During the search procedure, a sequence segment in the searched genome sequence is processed and a feature vector is extracted to represent it. Based on the feature vector, a classifier is used to determine whether the sequence segment is the searched ncRNA or not. Our testing results show that this approach is able to efficiently capture crucial features of a noncoding RNA family. Compared with existing search tools, it significantly improves the accuracy of genome annotation.","1545-5963;15455963","","10.1109/TCBB.2014.2366758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945901","Noncoding RNAs;classifier;feature vector;genome annotation;noncoding RNAs;secondary structure","Bioinformatics;Computational modeling;Genomics;Hidden Markov models;RNA","RNA;bioinformatics;genetics;genomics;learning (artificial intelligence);molecular biophysics;molecular configurations","RNA sequences;accurate noncoding RNA annotation;bioinformatics;feature vector;genomes;machine learning;noncoding RNA genes;secondary structure;single structure model;structural alignment","0","0","","30","","20141104","May-June 1 2015","","IEEE","IEEE Journals & Magazines"
"Recent advances on kernel fuzzy support vector machine model for supervised learning","P. Arumugam; P. Jose","Department of Statistics, Manonmaniam Sundaranar University, Tirunelveli - 12, Tamilnadu, India","2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]","20150716","2015","","","1","5","A most fashionable off-the-shelf classifier is the Support Vector Machine. It is a powerful recent proceed of the data mining practitioner. A computing world has a lot to gain of new generation learning system. Statistical learning theory is a latest advances in supervised learning community. It is a feed forward network and binary learning machine with highly elegant properties. It plays a vital role in the reduction of machine learning problem into optimization problem, convex problems, linear programming, smaller quadratic programming, convex analysis, second order cone programming and so on. The SVM has enthused and established by the way of kernel learning algorithm. That maps data into some dot product feature space perform the linear algorithm. This kernel function is implemented by Platt's sequential minimal optimization algorithm used in function estimation that can train efficiently and fast with Polykernel, Normalized poly kernel, Pearson VII function based Universal Kernel (PUK), Radial basis function. In this paper we focus Kernel Fuzzy Support Vector Machine to tune the kernel parameters to gain high performance from the classifier model. The trendy parameter technique k fold cross validation adopted under various kernel function and efficiency is empirically evaluate and observed a significant progress whilst the dataset is not linearly separable.","","DVD:978-1-4799-7074-2; Electronic:978-1-4799-7075-9; POD:978-1-4799-7076-6","10.1109/ICCPCT.2015.7159310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7159310","Support vector machine;data mining;fuzzy support vector machine;kernel trick;machine learning","Accuracy;Classification algorithms;Data mining;Kernel;Optimization;Support vector machines;Training","convex programming;data mining;fuzzy set theory;learning (artificial intelligence);linear programming;quadratic programming;radial basis function networks;statistical analysis;support vector machines","PUK;Pearson VII function based universal kernel;convex analysis;convex problems;data mining;function estimation;kernel fuzzy support vector machine model;linear programming;machine learning;new generation learning system;normalized polykernel;off-the-shelf classifier;optimization problem;quadratic programming;radial basis function;second order cone programming;statistical learning;supervised learning","","0","","23","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Accurate pollutant modeling and mapping: Applying machine learning to participatory sensing and urban topology data","A. Schulz; J. Karolus; F. Janssen; I. Schweizer","Technische Universit&#x00E4;t Darmstadt, Telecooperation Lab","2015 International Conference and Workshops on Networked Systems (NetSys)","20150420","2015","","","1","8","As sensor networks and mobile and participatory sensing mature, large environmental datasets become available. Environmental scientist are not prepared to use these vast and noisy datasets for environmental modeling. Today, environmental pollutants (e.g., noise) are simulated and the resulting model is verified by a small number of stationary measurements. These models are updated infrequently and provide only limited time resolution. Recently, people have started to apply regression to train environmental models. This has shown great promise, but the complexity of regression models might not always be needed. Classification, however, has not been investigated as a mean to provide high-resolution environmental models from noisy data. The main contribution of this paper is a thorough investigation on the application of classification to environmental modeling (using noise as example pollutant). We present an end-to-end classification pipeline that predicts six classes of noise pollution with a precision of 80.89% and a recall of 80.90% using 10-fold cross-validation. Furthermore, we show the advantages of our approach regarding robustness to underline the applicability of classification for real-world scenarios.","","Electronic:978-1-4799-5804-7; POD:978-1-4799-5805-4","10.1109/NetSys.2015.7089079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7089079","","Accuracy;Buildings;Data models;Meteorology;Noise;Pipelines;Topology","environmental monitoring (geophysics);geophysical techniques;noise (working environment);noise pollution;remote sensing","accurate pollutant mapping;accurate pollutant modeling;classification application;environmental modeling;environmental pollutants;high-resolution environmental model;machine learning application;noisy pollution;participatory sensing;regression model complexity;train environmental model;urban topology data","","1","","31","","","9-12 March 2015","","IEEE","IEEE Conference Publications"
"Energy-Efficient Transmission Scheduling in Mobile Phones Using Machine Learning and Participatory Sensing","Z. Tang; S. Guo; P. Li; T. Miyazaki; H. Jin; X. Liao","Sch. of Comput. Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China","IEEE Transactions on Vehicular Technology","20150714","2015","64","7","3167","3176","Energy efficiency is important for smartphones because they are powered by batteries with limited capacity. Existing work has shown that the tail energy of the third-generation (3G)/fourth-generation (4G) network interface on a mobile device would lead to low energy efficiency. To solve the tail energy minimization problem, some online scheduling algorithms have been proposed, but with a big gap from the offline algorithms that work depending on the knowledge of future transmissions. In this paper, we study the tail energy minimization problem by exploiting the techniques of machine learning and participatory sensing. We design a client-server architecture, in which the training process is conducted in a server, and mobile devices download the constructed predictor from the server to make transmission decisions. A system is developed and deployed on real hardware to evaluate the performance of our proposal. The experimental results show that it can significantly improve the energy efficiency of mobile devices while incurring minimum overhead.","0018-9545;00189545","","10.1109/TVT.2014.2350510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6881749","Energy efficiency;machine learning (ML);participatory sensing","Delays;Energy consumption;Mobile handsets;Sensors;Servers;Training;Vectors","3G mobile communication;4G mobile communication;client-server systems;energy conservation;learning (artificial intelligence);minimisation;mobile computing;smart phones;telecommunication power management;telecommunication scheduling","3G network;4G network;client-server architecture;energy efficiency improvement;energy minimization problem;energy-efficient transmission online scheduling algorithm;fourth-generation network;machine learning;mobile phone;participatory sensing;smart phone;third-generation network","","2","","22","","20140821","July 2015","","IEEE","IEEE Journals & Magazines"
"Domain Adaptation Extreme Learning Machines for Drift Compensation in E-Nose Systems","L. Zhang; D. Zhang","College of Computer Science, Chongqing University, Chongqing, China","IEEE Transactions on Instrumentation and Measurement","20150605","2015","64","7","1790","1801","This paper addresses an important issue known as sensor drift, which exhibits a nonlinear dynamic property in electronic nose (E-nose), from the viewpoint of machine learning. Traditional methods for drift compensation are laborious and costly owing to the frequent acquisition and labeling process for gas samples' recalibration. Extreme learning machines (ELMs) have been confirmed to be efficient and effective learning techniques for pattern recognition and regression. However, ELMs primarily focus on the supervised, semisupervised, and unsupervised learning problems in single domain (i.e., source domain). To our best knowledge, ELM with cross-domain learning capability has never been studied. This paper proposes a unified framework called domain adaptation extreme learning machine (DAELM), which learns a robust classifier by leveraging a limited number of labeled data from target domain for drift compensation as well as gas recognition in E-nose systems, without losing the computational efficiency and learning ability of traditional ELM. In the unified framework, two algorithms called source DAELM (DAELM-S) and target DAELM (DAELM-T) are proposed in this paper. In order to perceive the differences among ELM, DAELM-S, and DAELM-T, two remarks are provided. Experiments on the popular sensor drift data with multiple batches collected using E-nose system clearly demonstrate that the proposed DAELM significantly outperforms existing drift-compensation methods without cumbersome measures, and also bring new perspectives for ELM.","0018-9456;00189456","","10.1109/TIM.2014.2367775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6963383","Domain adaptation (DA);drift compensation;electronic nose (E-nose);extreme learning machine (ELM);transfer learning;transfer learning.","Communities;Electronic noses;Optimization;Pattern recognition;Target recognition;Training;Vectors","electronic noses;error compensation;learning (artificial intelligence);measurement errors;pattern classification","DAELM-S;DAELM-T;E-nose systems;domain adaptation extreme learning machines;drift compensation;electronic nose systems;gas recognition;gas sample recalibration;machine learning;nonlinear dynamic property;sensor drift;source DAELM;target DAELM","","27","","37","","20141120","July 2015","","IEEE","IEEE Journals & Magazines"
"Crawler intelligence with machine learning and Data Mining integration","A. Darshakar","Dept. of Electronics and Telecommunication, Pune Institute of Computer Technology, Katraj, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","6","This paper presents a study conducted on intelligent crawlers used in search engines, competitive intelligence etc. Data mining algorithms identified by IEEE International Conference on Data Mining (ICDM) were used to aid machine learning and introduce intelligence into the crawler. A statistical analysis of performance of intelligent crawler is presented in this paper. Further in this paper the data mining algorithms are compared on basis of usability in crawlers.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087203","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087203","C4.5;Crawler;Data mining;K-mean;Machine Learning;Support Vector Machine;Web Intelligence","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Crawlers;Data mining;Support vector machines;Training data","data mining;learning (artificial intelligence);search engines;statistical analysis","competitive intelligence;crawler intelligence;data mining integration;intelligent crawlers;machine learning;search engines;statistical analysis","","0","","19","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Scalable and parallel machine learning algorithms for statistical data mining - Practice & experience","M. Riedel; M. Goetz; M. Richerzhagen; P. Glock; C. Bodenstein; A. S. Memon; M. S. Memon","Forschungszentrum Juelich, Juelich Supercomputing Centre, Germany","2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20150716","2015","","","204","209","Many scientific datasets (e.g. earth sciences, medical sciences, etc.) increase with respect to their volume or in terms of their dimensions due to the ever increasing quality of measurement devices. This contribution will specifically focus on how these datasets can take advantage of new `big data' technologies and frameworks that often are based on parallelization methods. Lessons learned with medical and earth science data applications that require parallel clustering and classification techniques such as support vector machines (SVMs) and density-based spatial clustering of applications with noise (DBSCAN) are a substantial part of the contribution. In addition, selected experiences of related `big data' approaches and concrete mining techniques (e.g. dimensionality reduction, feature selection, and extraction methods) will be addressed too. In order to overcome identified challenges, we outline an architecture framework design that we implement with open available tools in order to enable scalable and parallel machine learning applications in distributed systems.","","DVD:978-9-5323-3085-4; Electronic:978-9-5323-3082-3; POD:978-1-4799-8174-8","10.1109/MIPRO.2015.7160265","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160265","","Algorithm design and analysis;Clustering algorithms;Concrete;Data mining;Machine learning algorithms;Standards;Support vector machines","Big Data;data mining;learning (artificial intelligence);parallel processing;pattern classification;pattern clustering;statistical analysis;support vector machines","Big Data technology;DBSCAN;SVMs;architecture framework design;classification techniques;concrete mining techniques;density-based spatial clustering of applications with noise;distributed systems;measurement device quality;parallel clustering;parallel machine learning algorithms;scalable machine learning algorithms;statistical data mining;support vector machines","","1","","27","","","25-29 May 2015","","IEEE","IEEE Conference Publications"
"Mobile keylogger detection using machine learning technique","S. Gunalakshmii; P. Ezhumalai","Department of Computer Science and Engineering, RMD Engineering College, Anna University, Kavaraipettai, Chennai","Proceedings of IEEE International Conference on Computer Communication and Systems ICCCS14","20150326","2014","","","051","056","Keylogger, a tool intended to record every keystroke made on the machine and offers the attacker the ability to steal large amounts of sensitive information without the permission of the owner of the message. The primary objective of this project is to detect keylogger applications and prevent data loss and sensitive information leakage. This project aims to identify the set of permissions and storage levels owned by each of the applications and hence differentiate applications with proper permissions and keylogger applications that can abuse permissions. The keyloggers are detected using Black-box technique. Black-box approach is based on behavioral characteristics which can be applied to all keyloggers and it does not rely on the structural characteristics of the keylogger. This project aims to develop detection system on mobile phones based on machine learning algorithm to detect keylogger applications.","","Electronic:978-1-4799-3672-4; POD:978-1-4799-3673-1","10.1109/ICCCS.2014.7068167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7068167","Black-box;Keylogger;Smartphone;Spyware;machine learning;malware","Androids;Conferences;Humanoid robots;Malware;Mobile communication;Mobile handsets;Support vector machines","data protection;learning (artificial intelligence);mobile computing;security of data","black-box technique;data loss prevention;machine learning algorithm;mobile keylogger detection;sensitive information leakage prevention","","0","","10","","","20-21 Feb. 2014","","IEEE","IEEE Conference Publications"
"High dimensional datasets using hadoop mahout machine learning algorithms","A. Srinivasulu; C. D. V. Subbarao; J. K. Y","Coll. of Eng., Dept. of CSE, JNTUA, Anantapur, India","International Conference on Computing and Communication Technologies","20150326","2014","","","1","1","Summary only from given. High dimensional data concerns large-volume, complex, growing data sets with multiple, and autonomous sources. As the Data increasing very drastically day-to-day, it is a major issue to manage and organize the data very efficiently. This emerged the necessity of machine learning techniques. With the Fast development of Networking, data storage and the data collection capacity, Machine learning cluster algorithms are now rapidly expanding in all science and engineering domains such as Pattern recognition, data mining, bioinformatics, and recommendation systems. So as to support the scalable machine learning framework with MapReduce and Hadoop support, we are using Apache Mahout to manage the High Voluminous data. Various Cluster problems such as Cluster Tendency, Partitioning, Cluster Validity, and Cluster Performance can be easily overcome by Mahout clustering algorithms. Mahout manages data in four steps i.e., fetching data, text mining, clustering, classification and collaborative filtering. In the proposed approach, various datatypes such as Numeric, Characters and Image datasets are classified in the several categories i.e., Collaborative Filtering, Clustering, Classification or Frequent Item set Mining. Some of the Pre-clustering techniques are also implemented such as EDBE, ECCE, and Extended Co-VAT. A non-Hadoop Clusternamed Taste recommendation Frame work is also implemented.","","Electronic:978-1-4799-8150-2; POD:978-1-4799-8151-9","10.1109/ICCCT2.2014.7066727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066727","Classification;Clustering;Distributed Stream Process;ECCE;EDBE;Extended Co-VAT;Hadoop;High Dimensional Data;Machine Learning;Mahout;Map Reduce;Recommendations","Abstracts","data acquisition;data handling;learning (artificial intelligence);pattern clustering","Apache Mahout clustering algorithms;ECCE;EDGE;Hadoop Mahout machine learning algorithms;bioinformatics;collaborative filtering;data collection capacity;data mining;data storage;extended Co-VAT;fetching data;frequent item set mining;high dimensional datasets;high voluminous data;machine learning cluster algorithms;nonHadoop clusternamed taste recommendation frame work;pattern recognition;preclustering techniques;recommendation systems;text mining","","0","","","","","11-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Development of new non-exercise maximum oxygen uptake models by using different machine learning methods","E. Genç; M. F. Akay","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x00C7;ukurova &#x00DC;niversitesi, Adana, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","196","199","Maximal oxygen consumption (VO<sub>2</sub>max) is the highest amount of oxygen used by the body during intense exercise. In this study, new non-exercise models have been developed by using different machine learning methods for predicting the VO<sub>2</sub>max values of healthy individuals aged between 18 and 65 years. The models include the non-exercise physiological variables (gender, age, weight and height) and questionnaire data. Cascade Correlation Network (CCN), Group Method of Data Handling (GMDH), Decision Tree Forest (DTF) and Single Decision Tree (SDT) methods have been used for developing the prediction models. The performance of the prediction models has been evaluated by calculating their multiple correlation coefficient (R) and standard error of estimate (SEE). The results show that CCN-based prediction models yield 24.54% on the average lower SEE's than the ones obtained by other methods.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130447","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130447","machine learning;maximum oxygen uptake;regression","Decision trees;Impedance;Mathematical model;Oxygen;Physiology;Predictive models;Support vector machines","decision trees;identification;learning (artificial intelligence);oxygen","CCN;CCN-based prediction models;GMDH;SEE;VO<sub>2</sub>max values;cascade correlation network;decision tree forest;group method of data handling;healthy individuals;machine learning method;maximal oxygen consumption;nonexercise maximum oxygen uptake model;prediction models;single decision tree;standard error of estimate","","0","","14","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Quality assessment of adaptive bitrate videos using image metrics and machine learning","J. Søgaard; S. Forchhammer; K. Brunnström","Technical University of Denmark, Kgs Lyngby, Denmark","2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX)","20150706","2015","","","1","2","Adaptive bitrate (ABR) streaming is widely used for distribution of videos over the internet. In this work, we investigate how well we can predict the quality of such videos using well-known image metrics, information about the bitrate levels, and a relatively simple machine learning method. Quality assessment of ABR videos is a hard problem, but our initial results are promising. We obtain a Spearman rank order correlation of 0.88 using content-independent cross-validation.","","Electronic:978-1-4799-8958-4; POD:978-1-4799-8959-1","10.1109/QoMEX.2015.7148105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148105","","Bit rate;Correlation;Quality assessment;Training;Video recording;Videos","adaptive signal processing;learning (artificial intelligence);quality of experience;video streaming","ABR streaming;ABR videos;Internet;Spearman rank order correlation;adaptive bitrate streaming;adaptive bitrate videos;bitrate levels;content-independent cross-validation;image metrics;machine learning;quality assessment;video quality;videos distribution","","0","","11","","","26-29 May 2015","","IEEE","IEEE Conference Publications"
"Kernel-based machine learning using radio-fingerprints for localization in wsns","S. Mahfouz; F. Mourad-Chehade; P. Honeine; J. Farah; H. Snoussi","Universite de Technologie de Troyes Troyes, France","IEEE Transactions on Aerospace and Electronic Systems","20150622","2015","51","2","1324","1336","This paper introduces an original method for sensors localization in WSNs. Based on radio-location fingerprinting and machine learning, the method consists of defining a model whose inputs and outputs are, respectively, the received signal strength indicators and the sensors locations. To define this model, several kernel-based machine-learning techniques are investigated, such as the ridge regression, support vector regression, and vector-output regularized least squares. The performance of the method is illustrated using both simulated and real data.","0018-9251;00189251","","10.1109/TAES.2015.140061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7126186","","Computational modeling;Databases;Kernel;Mathematical model;Optimization;Sensors;Wireless sensor networks","learning (artificial intelligence);regression analysis;sensor placement;support vector machines;telecommunication computing;wireless sensor networks","WSNS;kernel-based machine-learning techniques;radio-location fingerprinting;received signal strength indicators;ridge regression;sensors localization;support vector regression;vector-output regularized least squares","","0","","39","","","April 2015","","IEEE","IEEE Journals & Magazines"
"A machine learning approach to identify DNA replication proteins from sequence-derived features","R. Yang; C. Zhang; R. Gao; L. Zhang","School of Control Science and Engineering, Shandong University, Jinan, 250061, China","2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)","20150625","2015","","","13","18","DNA replication, a critical step in cell division and proliferation, is a process of producing two identical replicas from one original DNA molecule. Although great advances have been made in DNA replication research, the detailed mechanism of DNA replication is still unresolved. Faithful DNA replication requires the cooperation of many proteins. Failures in DNA replication leave mutations in the genome, which can cause cancers and other diseases. Therefore, accurately identifying these important DNA replication proteins may assist in understanding the molecular mechanisms of DNA replication and drug development. As the experimental methods are expensive and labor intensive, it is highly desired to develop an accurate computational method for identifying DNA replication proteins. In this paper, a machine learning approach to identify DNA replication proteins has been developed using a Naïve Bayes classifier and sequence-derived features. The prediction performance of features extracted from the Reduced Amino Acid Composition (RAAC) and two Pseudo Amino Acid Composition (PseAAC) models is investigated, respectively. Prediction results indicate that the PseAAC (type 2) model yields the best performance. Then, based on the PseAAC (type 2) model, we compare our method with the similarity search method on the independent test dataset. The comparison results reveal that it is feasible to identify DNA replication proteins by machine learning algorithms. The proposed method may provide candidate DNA replication proteins for future experimental verification to assist in understanding the molecular mechanisms of DNA replication and drug development for the treatment of human diseases.","0840-7789;08407789","Electronic:978-1-4799-5829-0; POD:978-1-4799-5830-6; USB:978-1-4799-5828-3","10.1109/CCECE.2015.7129092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129092","","Accuracy;Amino acids;DNA;Diseases;Feature extraction;Proteins;Sensitivity","Bayes methods;DNA;biology computing;drugs;genetics;learning (artificial intelligence);proteins","DNA molecule;DNA replication protein;cell division;drug development;genome;machine learning;molecular mechanism;naive Bayes classifier;pseudo amino acid composition;reduced amino acid composition;sequence-derived feature","","0","","33","","","3-6 May 2015","","IEEE","IEEE Conference Publications"
"N-gram based malicious code detection using Support Vector Machine learning approach","S. Santhosh; Shreeja R","Department of Computer Science and Engineering, Mes College of Engineering, Kuttippuram, India","Fourth International Conference on Advances in Recent Technologies in Communication and Computing (ARTCom2012)","20150420","2012","","","237","239","The development of Information and Communication gives a lot of convenience in our life, but on the other hand the new cyber threat such as viruses and computer intrusions also increases. This work discussed about the various classification algorithms such as K Nearest Neighbor (K-NN), Naive Bayes (NB) classifier and Support Vector Machine (SVM). Since it has been found that the SVM classification was efficient among the three classifiers as it can effectively perform linear classification and nonlinear classification of data, detects unknown and known malicious codes and has the capacity to handle large amount of features than the other two classifiers. This work focus on the detection of malicious code based on N-Gram and Support Vector Machine (SVM). It has been found that this approach can efficiently detect and classify the malicious data than other classifiers discussed here.","","Electronic:978-1-84919-929-2","10.1049/cp.2012.2536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087825","Information Gain;K-Nearest Neighbour;Malicious Code;Naive Bayes;Support Vector Machine;Term Frequency","","","","","0","","","","","19-20 Oct. 2012","","IET","IET Conference Publications"
"Performance Prediction of Large-Scale 1S1R Resistive Memory Array Using Machine Learning","Z. Jiang; P. Huang; L. Zhao; S. Kvatinsky; S. Yu; X. Liu; J. Kang; Y. Nishi; H. S. P. Wong","Dept. of Electr. Eng., Stanford Univ., Stanford, CA, USA","2015 IEEE International Memory Workshop (IMW)","20150706","2015","","","1","4","A methodology to analyze device-to-circuit characteristics and predict memory array performance is presented. With a five- parameter characterization of the selection device and a compact model of RRAM, we are able to capture the behaviors of reported selection devices and simulate 1S1R cell/array performance with RRAM compact modeling using HSPICE. To predict the performance of the memory array for a variety of selectors, machine-learning algorithms are employed, using device characteristics and circuit simulation results as the training data. The influence of selector parameters on the 1S1R cell and array behavior is investigated and projected to large Gbit arrays. The machine learning methods enable time-efficient and accurate estimates of 1S1R array performance to guide large-scale memory design.","2159-483X;2159483X","Electronic:978-1-4673-6933-6; POD:978-1-4673-6934-3; USB:978-1-4673-6932-9","10.1109/IMW.2015.7150302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150302","","Arrays;Circuit simulation;Computational modeling;Feature extraction;Integrated circuit modeling;Machine learning algorithms;Prediction algorithms","SPICE;integrated circuit modelling;learning (artificial intelligence);resistive RAM","1S1R cell-array performance;HSPICE;RRAM compact modeling;circuit simulation results;device characteristics;device-to-circuit characteristics;five-parameter characterization;large Gbit arrays;large-scale memory design;machine-learning algorithms;memory array performance;selection device;training data","","2","","13","","","17-20 May 2015","","IEEE","IEEE Conference Publications"
