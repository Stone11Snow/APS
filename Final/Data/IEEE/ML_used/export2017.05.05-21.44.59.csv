"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7545947,7546090,7544878,7372485,7214310,7543198,7194819,7542332,7542334,7542319,7467544,7538895,7527475,7538957,7538346,7527443,7538616,7536719,7539110,7527510,7542173,7536567,7527508,7536853,7539852,7539317,7532066,7533704,7531941,7532172,7530704,7535868,7468471,7265007,7529309,7528144,7528314,7528302,7527995,7528017,7530037,7530234,7533407,7528274,7529410,7533264,7533401,7530231,7529346,7528449,7527781,7530445,7529010,7529042,7526947,7525636,7526967,7526941,7526949,7526945,7522520,7339682,7521620,7523814,7522336,7522163,7521226,7521506,7489032,7421975,7421991,7519221,7435229,7519929,7519437,7519262,7519773,7519386,7519249,7486113,7515895,7516377,7515713,7518067,7518496,7508921,7515437,7517806,7518292,7493657,7514620,7509630,7514636,7412616,7515118,7312964,7339672,7514247,7509811,7510922",2017/05/05 21:44:59
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Recognition of handwritten digits using the signature features and Optimum-Path Forest Classifier","G. Siebra Lopes; D. Clifte da Silva; A. W. Oliveira Rodrigues; P. P. Reboucas Filho","Inst. Fed. de Educ., Cienc. e Tecnol. do Ceara, Fortaleza, Brazil","IEEE Latin America Transactions","20160803","2016","14","5","2455","2460","There is a growing need for recognition of digits manuscripts for use in various situations, such as recognition of handwritten postal address digits for automated redirection of letters in the mail, acknowledgment of nominal values in bank checks. Recognition of handwritten digits faces great difficulty in dealing with intra-class variation due to different writing styles, different degrees of inclination of the characters. Optical character recognition systems, also known as OCR, identifying and recognizing printed characters through images, an already widespread functionality in scanners, mobile devices, among others. This paper presents the use of the classifier Optimum-Path Forest (OPF) applied in handwriting recognition digits. A new feature extraction method is proposed using signature of the characters, and the OPF algorithm is used in the classification. According to the results presented, it appears that the detection and recognition of characters are being carried out satisfactorily in the Manhattan distance stood out with an average accuracy of 99.53%, and get training times and test lower than the other methods such as It is the characteristic of OPF method.","1548-0992;15480992","","10.1109/TLA.2016.7530445","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530445","Computer Vision;Digital Image Processing;Machine learning;OCR Applications;OPF;Optimum-Path Forest;Pattern Recognition","Artificial neural networks;Character recognition;Handwriting recognition;Nonlinear distortion;Optical character recognition software;Optimized production technology","feature extraction;handwritten character recognition;image classification;learning (artificial intelligence);object detection;optical character recognition","OCR;OPF;character detection;characters inclination;digits manuscripts recognition;feature extraction;handwritten digits recognition;intra-class variation;machine learning;optical character recognition systems;optimum-path forest classifier;printed characters identification;printed characters recognition;signature features;writing styles","","","","","","","May 2016","","IEEE","IEEE Journals & Magazines"
"A super fast vector support classifier using novelty detection and no synaptic tuning","R. Dogaru; I. Dogaru","University &#x201C;Politehnica&#x201D; of Bucharest, Natural Computing Laboratory, Applied Electronics and Information Engineering, Romania","2016 International Conference on Communications (COMM)","20160804","2016","","","373","376","A novel classifier architecture is introduced and its performances are evaluated against state of the art shallow classifiers. Its main advantage consists in a very fast learning ensured by a novelty detection algorithm, selecting a list of prototypes among the training samples, used as centers in a radial basis functions neurons layer. Only the radius of the basis functions is optimized to improve generalization in conjunction with an overlapping parameter and there is no need for synaptic tuning. Compared to state of the art models such as SVM (Support Vector Machine) or ELM (Extreme Learning Machine) our SFSVC (Super Fast Vector Support Classifier) it offers equal performance while having a more compact and fast algorithm. Thus SFSVC is well suited for embedded processing of big collections of data such as data from satellite remote sensing units, automotive sensors etc. with a good potential of being directly integrated into sensing platforms.","","DVD:978-1-4673-8196-3; Electronic:978-1-4673-8197-0; POD:978-1-4673-8198-7","10.1109/ICComm.2016.7528302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528302","extreme learning machines;machine learning;neural networks;radial basis functions;support vector machines","Classification algorithms;Kernel;Prediction algorithms;Support vector machine classification;Training;Tuning","feature extraction;optimisation;pattern classification;radial basis function networks;support vector machines","SFVSC;novelty detection;parameter optimization;radial basis function neuron layer;superfast vector support classifier;synaptic tuning","","1","","","","","9-10 June 2016","","IEEE","IEEE Conference Publications"
"Glaucoma-Specific Gait Pattern Assessment Using Body-Worn Sensors","Y. Ma; R. Fallahzadeh; H. Ghasemzadeh","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA","IEEE Sensors Journal","20160718","2016","16","16","6406","6415","Many studies have reported that glaucoma patients experience mobility issues, such as walking slowly and bumping into obstacles frequently. However, little is known to date about how a person's gait is impacted due to glaucoma. This paper presents design and development of a gait analysis approach using a shoe-integrated sensing system and accompanying machine learning techniques to quantitatively examine gait patterns in glaucoma patients. The customized sensor platform is utilized in a clinical trial conducted with nine glaucoma patients and ten age-matched healthy participants. The signal processing and machine learning algorithms automatically detect effective gait cycles and extract both steady-state and spatio-temporal gait features from the signal segments. We perform machine learning algorithms to distinguish glaucoma patients from healthy controls, and identify several prominent features with high discriminability between the two groups. The results demonstrate that classification algorithms can be used to identify the gait patterns of glaucoma patients with an accuracy higher than 94% in a 10-m-walk test. It is also demonstrated that gait features such as evenness of the sway speed along medio-lateral direction between the two feet are significantly different (p-value <; 0.001) between older adults with and without glaucoma. These results suggest that emerging solutions, such as wearable sensing technologies, can be used for continuous and real-time assessment of gait and mobility problems in individuals with low vision, and may open new avenues for using changes in gait patterns for preventing life threatening situations such as falls.","1530-437X;1530437X","","10.1109/JSEN.2016.2582083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493657","Gait analysis;glaucoma;machine learning;wearable sensors","Acceleration;Accelerometers;Algorithm design and analysis;Diseases;Feature extraction;Sensors;Support vector machines","biomedical transducers;body sensor networks;feature extraction;gait analysis;learning (artificial intelligence);medical signal detection;signal classification","age-matched healthy participant;body-worn sensor;distance 10 m;gait cycle detection;glaucoma-specific gait pattern assessment;machine learning technique;shoe-integrated sensing system;signal processing;spatiotemporal gait feature;steady-state gait feature;wearable sensing technology","","","","40","","20160616","Aug.15, 2016","","IEEE","IEEE Journals & Magazines"
"Fuzzy Self-Learning Controllers for Elasticity Management in Dynamic Cloud Architectures","P. Jamshidi; A. Sharifloo; C. Pahl; H. Arabnejad; A. Metzger; G. Estrada","Imperial Coll. London, London, UK","2016 12th International ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)","20160721","2016","","","70","79","Cloud controllers support the operation and quality management of dynamic cloud architectures by automatically scaling the compute resources to meet performance guarantees and minimize resource costs. Existing cloud controllers often resort to scaling strategies that are codified as a set of architecture adaptation rules. However, for a cloud provider, deployed application architectures are black-boxes, making it difficult at design time to define optimal or pre-emptive adaptation rules. Thus, the burden of taking adaptation decisions often is delegated to the cloud application. We propose the dynamic learning of adaptation rules for deployed application architectures in the cloud. We introduce FQL4KE, a self-learning fuzzy controller that learns and modifies fuzzy rules at runtime. The benefit is that we do not have to rely solely on precise design-time knowledge, which may be difficult to acquire. FQL4KE empowers users to configure cloud controllers by simply adjusting weights representing priorities for architecture quality instead of defining complex rules. FQL4KE has been experimentally validated using the cloud application framework ElasticBench in Azure and OpenStack. The experimental results demonstrate that FQL4KE outperforms both a fuzzy controller without learning and the native Azure auto-scaling.","","Electronic:978-1-5090-2567-1; POD:978-1-5090-2568-8","10.1109/QoSA.2016.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515437","Cloud Architectures;Fuzzy Control;Machine Learning;Q-Learning;Self-adaptive Systems;Self-learning","Cloud computing;Computational modeling;Computer architecture;Fuzzy logic;Monitoring;Runtime;Time factors","cloud computing;fuzzy control;learning (artificial intelligence)","Azure auto-scaling;ElasticBench;FQL4KE;OpenStack;black-boxes;cloud application framework;cloud controllers;cloud provider;design-time knowledge;dynamic cloud architectures;elasticity management;fuzzy self-learning controllers;modifies fuzzy rules;optimal adaptation rules;preemptive adaptation rules","","2","","","","","5-8 April 2016","","IEEE","IEEE Conference Publications"
"Data-Driven Learning of a Union of Sparsifying Transforms Model for Blind Compressed Sensing","S. Ravishankar; Y. Bresler","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA","IEEE Transactions on Computational Imaging","20160805","2016","2","3","294","309","Compressed sensing is a powerful tool in applications such as magnetic resonance imaging (MRI). It enables accurate recovery of images from highly undersampled measurements by exploiting the sparsity of the images or image patches in a transform domain or dictionary. In this work, we focus on blind compressed sensing (BCS), where the underlying sparse signal model is a priori unknown, and propose a framework to simultaneously reconstruct the underlying image as well as the unknown model from highly undersampled measurements. Specifically, our model is that the patches of the underlying image(s) are approximately sparse in a transform domain. We also extend this model to a union of transforms model that better captures the diversity of features in natural images. The proposed block coordinate descent type algorithms for BCS are highly efficient, and are guaranteed to converge to at least the partial global and partial local minimizers of the highly nonconvex BCS problems. Our numerical experiments show that the proposed framework usually leads to better quality of image reconstructions in MRI compared to several recent image reconstruction methods. Importantly, the learning of a union of sparsifying transforms leads to better image reconstructions than a single adaptive transform.","2333-9403;23339403","","10.1109/TCI.2016.2567299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468471","Compressed sensing;dictionary learning;inverse problems;machine learning;magnetic resonance imaging;medical imaging;sparse representations;sparsifying transforms","Compressed sensing;Convergence;Dictionaries;Image reconstruction;Magnetic resonance imaging;Transforms","compressed sensing;image coding;image reconstruction;learning (artificial intelligence);minimisation;transforms","MRI;blind compressed sensing;block coordinate descent type algorithms;data-driven learning;image patches;image reconstruction methods;image recovery;image sparsity;magnetic resonance imaging;nonconvex BCS problems;partial global minimizers;partial local minimizers;sparse signal model;sparsifying transform model","","","","","","20160511","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"On the Privacy of Frequently Visited User Locations","Z. Riaz; F. Dürr; K. Rothermel","Inst. of Parallel & Distrib. Syst., Univ. of Stuttgart, Stuttgart, Germany","2016 17th IEEE International Conference on Mobile Data Management (MDM)","20160721","2016","1","","282","291","With the fast adoption of location-enabled devices, Location-based Applications (LBAs) have become widely popular. While LBAs enable highly useful concepts such as geo-social networking, their use also raises serious privacy concerns as it involves sharing of location data with non-trusted third parties. In this respect, we propose an approach that protects the frequently visited locations of users, e.g., a bar, against inferences from long-term monitoring of their location data. Such inferences equate a privacy leak as they reveal a user's personal behavior and interests to possibly malicious non-trusted parties. To this end, we first present a study of a dataset of location check-ins to show the existence of this threat among users of LBAs. We then propose our approach to protect visit-frequency of the users to different locations by distributing their location data among multiple third-party Location Servers. This distribution not only serves to avoid a single point of failure for privacy in our system, it also allows the users to control which LBA accesses what information about them. We also describe a number of possible attacks against our privacy approach and evaluate them on real-data from the check-ins dataset. Our results show that our approach can effectively hide the frequent locations while supporting good quality-of-service for the LBAs.","","Electronic:978-1-5090-0883-4; POD:978-1-5090-0884-1","10.1109/MDM.2016.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517806","Frequent locations;Geo-social networking;Location History;Location Privacy;Location Servers;Location-based Applications;Machine Learning;Non-trusted systems;Semantic Locations;Visit-Frequency","Data privacy;Privacy;Quality of service;Semantics;Servers;Sociology;Statistics","Internet;authorisation;data privacy;mobile computing","frequently visited user location privacy;location check-ins;location-based application;location-enabled device;multiple third-party location server;privacy leak;quality-of-service","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"A design of HTM spatial pooler for face recognition using memristor-CMOS hybrid circuits","T. Ibrayev; A. P. James; C. Merkel; D. Kudithipudi","Electrical and Electronic Engineering, Nazarbayev University, Astana, Kazakhstan","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","1254","1257","Hierarchical Temporal Memory (HTM) is a machine learning algorithm that is inspired from the working principles of the neocortex, capable of learning, inference, and prediction for bit-encoded inputs. Spatial pooler is an integral part of HTM that is capable of learning and classifying visual data such as objects in images. In this paper, we propose a memristor-CMOS circuit design of spatial pooler and exploit memristors capabilities for emulating the synapses, where the strength of the weights is represented by the state of the memristor. The proposed design is validated on a challenging application of single image per person face recognition problem using AR database resulting in a recognition accuracy of 80%.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7527475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527475","Hierarchical Temporal Memory;feature extraction;machine learning;memristor;neuromorphic design;pattern recognition","Algorithm design and analysis;Face;Face recognition;Feature extraction;Memristors;Prediction algorithms;Training","CMOS integrated circuits;face recognition;integrated circuit design;learning (artificial intelligence);memristor circuits;visual databases","AR database;HTM spatial pooler design;bit-encoded inputs;face recognition accuracy;hierarchical temporal memory;machine learning algorithm;memristor-CMOS hybrid circuit design;neocortex;synapses","","1","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"Data Randomization and Cluster-Based Partitioning for Botnet Intrusion Detection","O. Y. Al-Jarrah; O. Alhussein; P. D. Yoo; S. Muhaidat; K. Taha; K. Kim","Electrical and Computer Engineering Department, Khalifa University of Science Technology and Research, Abu Dhabi, UAE","IEEE Transactions on Cybernetics","20160715","2016","46","8","1796","1806","Botnets, which consist of remotely controlled compromised machines called bots, provide a distributed platform for several threats against cyber world entities and enterprises. Intrusion detection system (IDS) provides an efficient countermeasure against botnets. It continually monitors and analyzes network traffic for potential vulnerabilities and possible existence of active attacks. A payload-inspection-based IDS (PI-IDS) identifies active intrusion attempts by inspecting transmission control protocol and user datagram protocol packet's payload and comparing it with previously seen attacks signatures. However, the PI-IDS abilities to detect intrusions might be incapacitated by packet encryption. Traffic-based IDS (T-IDS) alleviates the shortcomings of PI-IDS, as it does not inspect packet payload; however, it analyzes packet header to identify intrusions. As the network's traffic grows rapidly, not only the detection-rate is critical, but also the efficiency and the scalability of IDS become more significant. In this paper, we propose a state-of-the-art T-IDS built on a novel randomized data partitioned learning model (RDPLM), relying on a compact network feature set and feature selection techniques, simplified subspacing and a multiple randomized meta-learning technique. The proposed model has achieved 99.984% accuracy and 21.38 s training time on a well-known benchmark botnet dataset. Experiment results demonstrate that the proposed methodology outperforms other well-known machine-learning models used in the same detection task, namely, sequential minimal optimization, deep neural network, C4.5, reduced error pruning tree, and randomTree.","2168-2267;21682267","","10.1109/TCYB.2015.2490802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312964","Botnet intrusion detection;efficient learning;ensembles;feature selection;machine-learning (ML)","Accuracy;Clustering algorithms;Computational modeling;Data models;Feature extraction;Intrusion detection;Partitioning algorithms","computer network security;digital signatures;learning (artificial intelligence);pattern clustering;telecommunication traffic;transport protocols","PI-IDS;RDPLM;T-IDS;active attacks;active intrusion;attack signatures;benchmark botnet dataset;botnet intrusion detection;cluster-based partitioning;compact network feature set;critical detection-rate;distributed platform;feature selection techniques;intrusion detection system;multiple randomized meta-learning technique;network traffic;packet encryption;packet header analysis;payload-inspection-based IDS;randomized data partitioned learning model;remotely-controlled compromised machines;subspacing technique;traffic-based IDS;transmission control protocol;user datagram protocol packet payload","","","","53","","20151030","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Analysis and Prediction of Application Usage in Android Phones","S. Acharya; A. Shenoy; M. Lewis; N. Desai","St. Joseph Engineering College, Mangaluru, INDIA","2016 2nd International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB)","20160811","2016","","","530","534","Predictive Analytics analyze the present and the historical informations and make future predictions utilizing data mining or machine learning techniques. Predictive models usually check for some patterns and relationships leading to certain behaviours based on the dependent variables. This paper proposes a mechanism named Analysis and Prediction of Application Usage (APAU) in Android Phones for providing recommendations to a smart phone user while selecting applications of their interest like mail checking, messaging and making calls. APAU mainly focuses on identifying usage patterns and investigating the human behaviour during application selections by extracting the generic behavioural patterns to predict and provide useful set of recommendations.","","Electronic:978-1-4673-9745-2; POD:978-1-4673-9746-9","10.1109/AEEICB.2016.7538346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538346","Follower;Machine Learning;Notifications;Pattern;Prediction;Recommendations;Trigger","Androids;Context;Databases;Humanoid robots;Real-time systems;Smart phones;Software","data mining;learning (artificial intelligence);mobile computing;smart phones","APAU;Analysis and Prediction of Application Usage;Android phones;application selections;application usage;data mining;generic behavioural patterns;historical informations;human behaviour;machine learning techniques;mail checking;messaging;predictive analytics;predictive models;smart phone user;usage patterns","","","","","","","27-28 Feb. 2016","","IEEE","IEEE Conference Publications"
"Tool and evaluation method for idea creation support","R. Takeshima; K. Nagao","Department of Media Science, Graduate School of Information Science, Nagoya University, Japan","2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)","20160801","2015","01","","358","363","We have developed a new idea creation support tool in which (1) each idea is represented by a tree structure, (2) the idea is automatically evaluated on the basis of the tree structure so that the relative advantages among several alternative ideas is found, (3) the ideas are presented in a poster format, and (4) the ideas are shared by multiple users so that the ideas can be quoted and expanded upon by individual users. In this work, we explain the mechanisms of this tool, including the evaluation and poster conversion of ideas and collaborative idea creation, and briefly discuss our plan for the future.","","Electronic:978-9-8975-8164-9; POD:978-1-5090-1967-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526941","Collaboration;Digital Poster;Idea Creation;Idea Evaluation;Machine Learning;Meeting Support","Collaboration;Electronic publishing;Encyclopedias;Internet;Semantics;Videos","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Low-power manycore accelerator for personalized biomedical applications","A. Page; N. Attaran; C. Shea; H. Homayoun; T. Mohsenin","Dept. of Computer Science & Electrical Engineering, University of Maryland, Baltimore County","2016 International Great Lakes Symposium on VLSI (GLSVLSI)","20160815","2016","","","63","68","Wearable personal health monitoring systems can offer a cost effective solution for human healthcare. These systems must provide both highly accurate, secured and quick processing and delivery of vast amount of data. In addition, wearable biomedical devices are used in inpatient, outpatient, and at home e-Patient care that must constantly monitor the patient's biomedical and physiological signals 24/7. These biomedical applications require sampling and processing multiple streams of physiological signals with strict power and area footprint. The processing typically consists of feature extraction, data fusion, and classification stages that require a large number of digital signal processing and machine learning kernels. In response to these requirements, in this paper, a low-power, domain-specific manycore accelerator named Power Efficient Nano Clusters (PENC) is proposed to map and execute the kernels of these applications. Experimental results show that the manycore is able to reduce energy consumption by up to 80% and 14% for DSP and machine learning kernels, respectively, when optimally parallelized. The performance of the proposed PENC manycore when acting as a coprocessor to an Intel Atom processor is compared with existing commercial off-the-shelf embedded processing platforms including Intel Atom, Xilinx Artix-7 FPGA, and NVIDIA TK1 ARM-A15 with GPU SoC. The results show that the PENC manycore architecture reduces the energy by as much as 10X while outperforming all off-the-shelf embedded processing platforms across all studied machine learning classifiers.","","Electronic:978-1-4503-4274-2; POD:978-1-5090-2979-2","10.1145/2902961.2902986","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543198","FPGA;Low power;accelerator;biomedical;digital signal processing;embedded processors;machine learning;manycore","Computer architecture;Digital signal processing;Field programmable gate arrays;Finite impulse response filters;Graphics processing units;Kernel;Parallel processing","coprocessors;digital signal processing chips;feature extraction;learning (artificial intelligence);low-power electronics;multiprocessing systems;parallel architectures;pattern classification;performance evaluation;power aware computing;sensor fusion","DSP;GPU SoC;Intel Atom processor;NVIDIA TK1 ARM-A15;PENC manycore architecture;Xilinx Artix-7 FPGA;digital signal processing;domain-specific manycore accelerator;e-Patient care;energy consumption reduction;human healthcare;low-power manycore accelerator;machine learning classifiers;machine learning kernels;off-the-shelf embedded processing platforms;patient biomedical and physiological signals;personalized biomedical applications;power efficient nano clusters;wearable biomedical devices;wearable personal health monitoring systems","","2","","","","","18-20 May 2016","","IEEE","IEEE Conference Publications"
"Data Sampling and Supervised Learning for HIV Literature Screening","H. Almeida; M. J. Meurs; L. Kosseim; A. Tsang","Centre for Structural and Functional Genomics (CSFG), Concordia University, Montreal, QC, Canada","IEEE Transactions on NanoBioscience","20160812","2016","15","4","354","361","This paper presents a supervised learning approach to support the screening of HIV literature. The manual screening of biomedical literature is an important task in the process of systematic reviews. Researchers and curators have the very demanding, time-consuming, and error-prone task of manually identifying documents that should be included in a systematic review concerning a specific problem. We developed a supervised learning approach to support screening tasks, by automatically flagging potentially relevant documents from a list retrieved by a literature database search. To overcome the main issues associated with the automatic literature screening task, we evaluated the use of data sampling, feature combinations, and feature selection methods, generating a total of 105 classification models. The models yielding the best results were composed of a Logistic Model Trees classifier, a fairly balanced training set, and feature combination of Bag-Of-Words and MeSH terms. According to our results, the system correctly labels the great majority of relevant documents, making it usable to support HIV systematic reviews to allow researchers to assess a greater number of documents in less time.","1536-1241;15361241","","10.1109/TNB.2016.2565481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467544","Artificial intelligence;HIV;health information management;machine learning;text classification;triage","Computational modeling;Databases;Human immunodeficiency virus;Manuals;Measurement;Supervised learning;Systematics","feature selection;learning (artificial intelligence);medical computing;medical information systems;microorganisms;sampling methods;trees (mathematics)","Bag-Of-Words terms;HIV literature screening;HIV systematic reviews;MeSH terms;biomedical literature;classification models;data sampling;feature combinations;feature selection methods;literature database search;logistic model trees classifier;screening tasks;supervised learning","","","","","","20160510","June 2016","","IEEE","IEEE Journals & Magazines"
"EOG signal processing module for medical assistive systems","A. López; D. Fernández; F. J. Ferrero; M. Valledor; O. Postolache","Department of Electrical and Electronic Engineering, University of Oviedo, Campus of Gij&#243;n, Spain","2016 IEEE International Symposium on Medical Measurements and Applications (MeMeA)","20160808","2016","","","1","5","Electrooculography (EOG) is one of the occulography methods used for the estimation of eye orientation. These signals, generated by eye movements, can be used in an efficient way as input in different control systems. So, the signal processing of the EOG signal is a key point when performing complex tasks, for instance, in a Human-Machine Interface (HMI). In this sense machine learning algorithms allow patterns in data to be identified, and then, to predict future actions using those patterns that have been learned. This paper presents a signal processing module for EOG signals, applying Wavelets Transform (WT) as a denoising procedure and AdaBoost as a machine learning algorithm.","","Electronic:978-1-4673-9172-6; POD:978-1-4673-9173-3","10.1109/MeMeA.2016.7533704","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533704","AdaBoost;Wavelet Transform (WT);denoising;electrooculography (EOG);machine learning;signal processing","Discrete wavelet transforms;Electrooculography;Machine learning algorithms;Signal processing","biomechanics;electro-oculography;learning (artificial intelligence);man-machine systems;medical signal processing;signal denoising;wavelet transforms","AdaBoost;EOG signal processing module;complex tasks;control systems;data patterns;denoising procedure;electrooculography;eye movements;eye orientation estimation;human-machine interface;machine learning algorithms;medical assistive systems;occulography methods;wavelets transform","","","","","","","15-18 May 2016","","IEEE","IEEE Conference Publications"
"One-Class Classification-Based Real-Time Activity Error Detection in Smart Homes","B. Das; D. J. Cook; N. C. Krishnan; M. Schmitter-Edgecombe","Intel Corporation, Santa Clara, CA, USA","IEEE Journal of Selected Topics in Signal Processing","20160725","2016","10","5","914","923","Caring for individuals with dementia is frequently associated with extreme physical and emotional stress, which often leads to depression. Smart home technology and advances in machine learning techniques can provide innovative solutions to reduce caregiver burden. One key service that caregivers provide is prompting individuals with memory limitations to initiate and complete daily activities. We hypothesize that sensor technologies combined with machine learning techniques can automate the process of providing reminder-based interventions. The first step toward automated interventions is to detect when an individual faces difficulty with activities. We propose machine learning approaches based on one-class classification that learn normal activity patterns. When we apply these classifiers to activity patterns that were not seen before, the classifiers are able to detect activity errors, which represent potential prompt situations. We validate our approaches on smart home sensor data obtained from older adult participants, some of whom faced difficulties performing routine activities and thus committed errors.","1932-4553;19324553","","10.1109/JSTSP.2016.2535972","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7421975","Smart homes;activity recognition;machine learning;one-class classification","Dementia;Psychology;Real-time systems;Signal processing algorithms;Smart homes;Streaming media;Temperature measurement","assisted living;image classification;learning (artificial intelligence);object detection","automated interventions;caregivers;face detection;machine learning techniques;one-class classification-based real-time activity error detection;reminder-based interventions;sensor technologies;smart home technology","","","","","","20160229","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"A multilevel deep learning method for big data analysis and emergency management of power system","X. Z. Wang; J. Zhou; Z. L. Huang; X. L. Bi; Z. Q. Ge; L. Li","East China Electric Power Dispatching and Control Center, East China Grid Co., Ltd., Shanghai 200120, China","2016 IEEE International Conference on Big Data Analysis (ICBDA)","20160714","2016","","","1","5","The general focus of this study is to design a multilevel deep learning model that provides big data analytics and emergency management knowledge. A big data covariance analysis approach has been used to find multilevel representations of data based on prior knowledge from large scale power systems. For purpose of meeting requirements of incremental knowledge discovery, an adaptive regression algorithm is presented. Given the multilevel operating status and development trend of power system, the emergency management techniques are then proposed to produce intelligent decision making support. In this paper, a multilevel clustered hidden Markov model based global optimization approach is considered for power system emergency management problem, which is an extension of the conventional optimal power flow problem. The objective is defined to generate operation mode that minimizes multilevel cost while satisfying different constraints. To demonstrate the effectiveness of the presented approach, this paper carefully compared the discriminatory power of knowledge discovery models that utilize deep learning with dimensionality reduction based method and machine learning without dimensionality reduction based method. The experimental results showed that the proposed multilevel deep learning approach consistently outperformed the traditional machine learning method. The emergency management of large scale power system may also benefit from the modified hidden Markov model and global optimization.","","CD-ROM:978-1-4673-9589-2; Electronic:978-1-4673-9591-5; POD:978-1-4673-9592-2","10.1109/ICBDA.2016.7509811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7509811","Big data;Emergency management;Machine learning;Power system modeling;Smart grid","Algorithm design and analysis;Big data;Emergency services;Hidden Markov models;Kernel;Machine learning;Power system stability","Big Data;covariance analysis;data analysis;data mining;decision making;emergency management;hidden Markov models;learning (artificial intelligence);load flow;minimisation;power engineering computing;power systems;regression analysis","adaptive regression algorithm;big data covariance analysis approach;incremental knowledge discovery;intelligent decision making support;multilevel clustered hidden Markov model based global optimization;multilevel cost minimization;multilevel deep learning method;optimal power flow problem;power system emergency management;power system multilevel operating status","","","","","","","12-14 March 2016","","IEEE","IEEE Conference Publications"
"Privacy-Preserving Data Classification and Similarity Evaluation for Distributed Systems","Q. Jia; L. Guo; Z. Jin; Y. Fang","Dept. of Electr. & Comput. Eng., Binghamton Univ., Binghamton, NY, USA","2016 IEEE 36th International Conference on Distributed Computing Systems (ICDCS)","20160811","2016","","","690","699","Data classification is a widely used data mining technique for big data analysis. By training massive data collected from the real world, data classification helps learners discover hidden data patterns. In addition to data training, given a trained model from collected data, a user can classify whether a new incoming data belongs to an existing class, or, multiple distributed entities may collaborate to test the similarity of their trained results. However, due to data locality and privacy concerns, it is infeasible for large-scale distributed systems to share each individual's datasets with each other for data similarity check. On the one hand, the trained model is an entity's private asset and may leak private information, which should be well protected from all other non-collaborative entities. On the other hand, the new incoming data may contain sensitive information which cannot be disclosed directly for classification. To address the above privacy issues, we propose a privacy-preserving data classification and similarity evaluation scheme for distributed systems. With our scheme, neither new arriving data nor trained models are directly revealed during the classification and similarity evaluation procedures. The proposed scheme can be applied to many fields using data classification and evaluation. Based on extensive real-world experiments, we have also evaluated the privacy preservation, feasibility, and efficiency of the proposed scheme.","1063-6927;10636927","Electronic:978-1-5090-1483-5; POD:978-1-5090-1484-2","10.1109/ICDCS.2016.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536567","Data Classification;Machine Learning;Privacy Preservation;Similarity Evaluation","Data models;Data privacy;Distributed databases;Protocols;Receivers;Support vector machines;Training","Big Data;data mining;data privacy;distributed processing;pattern classification","Big Data analysis;data locality;data mining;data similarity evaluation;data training;distributed systems;hidden data patterns;large-scale distributed systems;noncollaborative entities;privacy-preserving data classification","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Neuromorphic computing with hybrid memristive/CMOS synapses for real-time learning","D. Ielmini; S. Ambrogio; V. Milo; S. Balatti; Z. Q. Wang","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano and IU.NET, Milano, Italy","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","1386","1389","Resistive (or memristive) devices, including resistive switching memory (RRAM), phase change memory (PCM) an spin-transfer torque memory (STTRAM), are strong candidates for future high-density memory, embedded memory and storage class memory. The availability of resistive-device technology in the industry would pave the way for several other applications in advanced computing, such as neuromorphic cognitive systems and other non-von Neumann approaches to computing. However, the building-block design, functionality and power consumption need to be carefully evaluated to assess all the advantages of the resistive devices with respect to standard CMOS technology. This work will review the recent progress in developing hybrid memristive/CMOS synapses based on either RRAM or PCM, showing the circuit design, the operation concept and the demonstration of real-time spike-based learning and recognition of visual patterns. The learning accuracy and power consumption of the novel synapse blocks will be finally discussed.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7527508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527508","Neuromorphic computing;machine learning;phase change memory (PCM);resistive switching memory (RRAM);spike-timing dependent plasticity (STDP)","CMOS integrated circuits;Fires;Neuromorphics;Neurons;Phase change materials;Power demand;Switches","CMOS integrated circuits;memristors;neural chips;random-access storage","CMOS technology;PCM;RRAM;STTRAM;building-block design;circuit design;embedded memory;functionality;high-density memory;hybrid memristive/CMOS synapses;memristive devices;neuromorphic cognitive systems;neuromorphic computing;phase change memory;power consumption;real-time learning;real-time spike-based learning;resistive switching memory;resistive-device technology;spin-transfer torque memory;storage class memory;visual pattern recognition","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"Salivary Markers for Quantitative Dehydration Estimation during Physical Exercise","M. Ring; C. Lohmueller; M. Rauh; J. Mester; B. Eskofier","M. Ring is with the Digital Sports Group, Pattern Recognition Lab, Friedrich-Alexander-Universit&#x00E4;t Erlangen- N&#x00FC;rnberg (FAU), Germany, Haberstr. 2, 91058 Erlangen, Germany.(email:matthias.ring@cs.fau.de)","IEEE Journal of Biomedical and Health Informatics","","2016","PP","99","1","1","Salivary markers have been proposed as noninvasive and easy-to-collect indicators of dehydrations during physical exercise. It has been demonstrated that threshold-based classifications can distinguish dehydrated from euhydrated subjects. However, considerable challenges were reported simultaneously, for example, high inter-subject variabilities in these markers. Therefore, we propose a machine learning approach to handle the inter-subject variabilities and to advance from binary classifications to quantitative estimations of total body water (TBW) loss. For this purpose, salivary samples and reference values of TBW loss were collected from ten subjects during a 2-h running workout without fluid intake. The salivary samples were analyzed for previously investigated markers (osmolality, proteins) as well as additional unexplored markers (amylase, chloride, cortisol, cortisone, potassium). Processing all these markers with a Gaussian process approach showed that quantitative TBW loss estimations are possible within an error of 0.34 l, roughly speaking, a glass of water. Furthermore, a data analysis illustrated that the salivary markers grow nonlinearly during progressive dehydration, which is in contrast to previously reported, linear observations. This insight could help to develop more accurate physiological models for salivary markers and TBW loss. Such models, in turn, could facilitate even more precise TBW loss estimations in the future.","2168-2194;21682194","","10.1109/JBHI.2016.2598854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539317","dehydration;machine learning;physical exercise;saliva;total body water","Biomedical measurement;Data collection;Estimation;Informatics;Plasmas;Potassium;Proteins","","","","","","","","20160810","","","IEEE","IEEE Early Access Articles"
"Kicking motion design of humanoid robots using gradual accumulation learning method based on Q-learning","J. Wang; Z. Liang; Z. Zhou; Y. Zhang","College of Automation, Nanjing University of Posts and Telecommunications, Nanjing 210046, China","2016 Chinese Control and Decision Conference (CCDC)","20160808","2016","","","5274","5279","This paper manly presented kicking design motion of humanoid robots using a reinforcement learning method which is based on the Q-learning. First, this method build a multidirectional fixed-point kicking model, which is based on the offset of kicking point, the foot space motion trajectory and ZMP stability criterion, and that makes subsequent train costs much less time. Besides, discretization of state set is also used to improve the training method. Compared to other machine learning algorithms, this method reduces the dimension of the system and solves the problem of excessive train when kicking in long distance. A series of experiments proves that the method described in this paper is feasible and effective.","","CD-ROM:978-1-4673-9713-1; Electronic:978-1-4673-9714-8; POD:978-1-4673-9715-5","10.1109/CCDC.2016.7531941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7531941","Q-learning;kicking design;machine learning;reinforcement learning","Foot;Interpolation;Legged locomotion;Splines (mathematics);Training;Trajectory","control system synthesis;humanoid robots;learning systems;mobile robots;motion control;stability;trajectory control","Q-learning;ZMP stability criterion;foot space motion trajectory;gradual accumulation learning method;humanoid robots;kicking motion design;kicking point;multidirectional fixed-point kicking model;reinforcement learning;state set discretization","","","","","","","28-30 May 2016","","IEEE","IEEE Conference Publications"
"A fully analog memristor-based neural network with online gradient training","E. Rosenthal; S. Greshnikov; D. Soudry; S. Kvatinsky","Department of Electrical Engineering, Technion, Israel Institute of Technology, Haifa, Israel 3200003","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","1394","1397","In recent years, Neural Networks (NNs) have become widely popular for the execution of different machine learning algorithms. Training an NN is computationally intensive since it requires numerous multiplications of matrices that represent synaptic weights. It is therefore appealing to build a hardware-based NN accelerator to gain parallelism and efficient computation. Recently, we have proposed a compact circuit of a non-volatile synaptic weight based on two CMOS transistors and a memristor. In this paper, we present a fully analog NN design based on our previously proposed synapse with a full design of the different layers and their supporting CMOS circuits. We show that the presented NN significantly reduces the area as compared to a CMOS-based NN, while executing online gradient training with similar accuracy and computational speed improvement as a software implementation.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7527510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527510","CMOS;Multilayer Neural Networks;RRAM;backpropagation;machine learning;memristor;neuromorphic","Artificial neural networks;Biological neural networks;CMOS integrated circuits;Memristors;Neurons;Training;Transistors","CMOS analogue integrated circuits;analogue storage;gradient methods;integrated circuit design;memristor circuits;neural nets","CMOS circuits;fully analog NN design;fully analog memristor-based neural network;online gradient training","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"Smart city technology based architecture for refuse disposal management","J. O. Adeyemo; O. O. Olugbara; E. Adetiba","ICT and Society Research Group, Durban University of Technology, Durban, 4001, South Africa","2016 IST-Africa Week Conference","20160808","2016","","","1","8","Many modern cities are currently encumbered with various challenges among which is the need to promote the culture of environmental sanitation for healthy living. However, advances in information communications technology have given birth to the concept of smart city, which is rapidly being applied to address some of the challenges being faced in such cities. This paper presents the development of an architecture based on smart city technology, for refuse disposal management in communities. A proof of concept prototype was implemented for the proposed architecture using Arduino UNO microcontroller board, proximity sensor, breadboard, refuse bin and a personal computer. The proximity sensor was interfaced with the Arduino board to capture dataset that correspond to the five different positions calibrated on a refuse bin. The dataset was shown to be of good quality since the graph of the mean voltages against the distances is similar to the proximity sensor characteristic graph. To determine the appropriate classifier for realizing the pattern classification unit of the prototype, an experiment was performed using the acquired dataset to train five different variants of the K-NN classifier. The 1-NN classifier was nominated for the prototype because it is simple and it gave higher values of accuracy, precision and recall.","","Electronic:978-1-9058-2455-7; POD:978-1-5090-1955-7","10.1109/ISTAFRICA.2016.7530704","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530704","K-NN;Machine Learning;Refuse;Sensor","Computer architecture;Microcontrollers;Prototypes;Smart cities;Waste materials;Web servers","microcontrollers;pattern classification;public utilities;sanitary engineering;smart cities;waste disposal","1-NN classifier;Arduino UNO microcontroller board;K-NN classifier;breadboard;environmental sanitation;healthy living;information communications technology;pattern classification unit;personal computer;proximity sensor;refuse bin;refuse disposal management;smart city technology","","","","","","","11-13 May 2016","","IEEE","IEEE Conference Publications"
"Fusion with sentiment scores for market research","S. Das; A. Das","Machine Analytics, Belmont, MA, USA","2016 19th International Conference on Information Fusion (FUSION)","20160804","2016","","","1003","1010","The recent surge in electronic and social media has led to an explosion of sentiment data embedded in public and private documents, fueling interest in sentiment analysis, especially as individuals, brands and corporations look to manage their reputational risk which is directly correlated to company performance. In this paper, we describe two approaches to score sentiments from a large unstructured text corpus1 to fuse with other relevant structured relational data: 1) a simple but effective and fast lexicon-based approach where the score of a document is based on the occurrences of stemmed words representing positive and negative sentiments; and 2) a supervised machine learning approach where the score is derived by making use of a kernel-based classification model created from the training documents. Example applications of these techniques can be found in our text analytics tool called aText which can compute sentiment scores of product reviews from Amazon and TripAdvisor to gain market insight to products and services. Another example is the computation of sentiment scores using aText for public and private companies from credible financial sources which is further fused with market data (stock price) to create a composite index for financial analysts and traders.","","Electronic:978-0-9964-5274-8; POD:978-1-5090-2012-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527995","Machine Learning;Natural Language Processing;Sentiment Analysis;Text Analytics","Bayes methods;Context;Data models;Hidden Markov models;Image color analysis;Light emitting diodes;Sentiment analysis","data mining;learning (artificial intelligence);marketing data processing;sentiment analysis;stock markets","aText;kernel-based classification;lexicon-based approach;market research;private document;public document;sentiment analysis;sentiment score;structured relational data;supervised machine learning;text analytics tool","","","","","","","5-8 July 2016","","IEEE","IEEE Conference Publications"
"Experimental study of indoor tracking using UWB measurements and particle filtering","V. Savic; E. G. Larsson","Dept. of Electrical Engineering (ISY), Link&#x00F6;ping University, Sweden","2016 IEEE 17th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","20160811","2016","","","1","5","Target tracking with ultra-wideband (UWB) signals in indoor environments is a challenging problem due to the presence of multipath and non-line-of-sight conditions (NLOS). A solution to this problem is to use particle filtering (PF), which is able to handle both nonlinear models and non-Gaussian uncertainties that typically appear in the presence of NLOS. In this paper, we compare four different PF variants, that differ in terms of how NLOS measurements are handled. According to our experimental results, based on the measurements from a basement tunnel, multiple features from the UWB impulse response should be used, and the ranging likelihood function should make use of both LOS and NLOS measurements. Standard time-of-arrival (TOA) based methods, even with NLOS rejection, are not good enough. Instead we advocate TOA-based algorithms that can actively mitigate errors due to NLOS.","","Electronic:978-1-5090-1749-2; POD:978-1-5090-1750-8","10.1109/SPAWC.2016.7536853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536853","machine learning;particle filtering;target tracking;time of arrival;ultra-wideband","Atmospheric measurements;Distance measurement;Ground penetrating radar;Nonlinear optics;Particle measurements;Standards;Target tracking","multipath channels;particle filtering (numerical methods);target tracking;time-of-arrival estimation;transient response","LOS measurements;NLOS measurements;PF variants;TOA based methods;UWB measurements;basement tunnel;impulse response;indoor tracking;multipath conditions;non-Gaussian uncertainties;nonline-of-sight conditions;nonlinear models;particle filtering;ranging likelihood function;standard time-of-arrival based methods;target tracking;ultrawideband signals","","","","","","","3-6 July 2016","","IEEE","IEEE Conference Publications"
"Identification of outliers in pollution concentration levels using anomaly detection","T. R. V. Anandharajan; K. K. Vignajeth; G. A. Hariharan; R. Jijendiran","Velammal Institute Of Technology, Tamil Nadu 601204, India","2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT)","20160718","2016","","","433","438","Anomaly detection is generally an identification of any odd or anomalous data sometimes even called as an outlier from a give pattern of data. It involves machine learning technique to learn the data and determine the outliers based on a probability condition. Machine learning, a branch of artificial intelligence plays a vital role in analyzing the data and identifies the outliers with a good probability. The objective of this paper is to determine the outlier of pollutant's concentration based on anomaly detection techniques and describe the air quality standards of the particular area.","","Electronic:978-1-5090-0082-1; POD:978-1-5090-0083-8","10.1109/ICCTICT.2016.7514620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514620","Air Pollution;Air quality Index;Anomaly detection;Machine Learning","Air quality;Gases;Gaussian distribution;Indexes;Pollution;Pollution measurement;Training","artificial intelligence;learning (artificial intelligence);security of data","air quality standards;anomaly detection;artificial intelligence;machine learning technique;pollutant concentration;pollution concentration levels;probability condition","","","","","","","11-13 March 2016","","IEEE","IEEE Conference Publications"
"A self-learning framework to detect the intruded integrated circuits","F. K. Lodhi; I. Abbasi; F. Khalid; O. Hasan; F. Awwad; S. R. Hasan","Sch. of Elect. Engg. and Comp. Sc., National University of Sciences and Technology (NUST), Islamabad, Pakistan","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","1702","1705","Globalization trends in integrated circuit (IC) design using deep submicron (DSM) technologies are leading to increased vulnerability of ICs against malicious intrusions. These malicious intrusions are referred as hardware Trojans. One way to address this threat is to utilize unique electrical signatures of ICs. However, this technique requires analyzing extensive sensor data to detect the intruded integrated circuits. In order to overcome this limitation, we propose to combine the signature extraction mechanism with machine learning algorithms to develop a self-learning framework that can detect the intruded integrated circuits. The proposed approach applies the lazy, eager or probabilistic learners to generate self-learning prediction model based on the electrical signatures. In order to validate this framework, we applied it on a recently proposed signature based hardware Trojan detection technique. The cross validation comparison of these learner shows that eager learners are able to detect the intrusion with 96% accuracy and also require less amount of memory and processing power compared to other machine learning techniques.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7538895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538895","Asynchronous pipeline;Hardware Trojan;MSMA;Machine Learning;Rapid Miner Studio","Delays;Hardware;Integrated circuit modeling;Pipelines;Trojan horses","digital signatures;integrated circuit design;invasive software;learning (artificial intelligence);pipeline processing","deep submicron technologies;extensive sensor data;integrated circuit design;intruded integrated circuits;machine learning algorithms;malicious intrusions;self-learning framework;self-learning prediction model;signature based hardware Trojan detection technique;signature extraction mechanism;unique electrical signatures","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"Very Short-Term Nonparametric Probabilistic Forecasting of Renewable Energy Generation— With Application to Solar Energy","F. Golestaneh; P. Pinson; H. B. Gooi","Electrical and Electronic Engineering, Nanyang technological university, Singapore, Singapore","IEEE Transactions on Power Systems","20160817","2016","31","5","3850","3863","Due to the inherent uncertainty involved in renewable energy forecasting, uncertainty quantification is a key input to maintain acceptable levels of reliability and profitability in power system operation. A proposal is formulated and evaluated here for the case of solar power generation, when only power and meteorological measurements are available, without sky-imaging and information about cloud passages. Our empirical investigation reveals that the distribution of forecast errors do not follow any of the common parametric densities. This therefore motivates the proposal of a nonparametric approach to generate very short-term predictive densities, i.e., for lead times between a few minutes to one hour ahead, with fast frequency updates. We rely on an Extreme Learning Machine (ELM) as a fast regression model, trained in varied ways to obtain both point and quantile forecasts of solar power generation. Four probabilistic methods are implemented as benchmarks. Rival approaches are evaluated based on a number of test cases for two solar power generation sites in different climatic regions, allowing us to show that our approach results in generation of skilful and reliable probabilistic forecasts in a computationally efficient manner.","0885-8950;08858950","","10.1109/TPWRS.2015.2502423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372485","Extreme machine learning;forecasting;quantile regression;solar power;uncertainty quantification","Clouds;Forecasting;Probabilistic logic;Reliability;Solar power generation;Uncertainty;Wind forecasting","learning (artificial intelligence);load forecasting;power engineering computing;power generation economics;power generation reliability;profitability;regression analysis;solar power","ELM;climatic region;extreme learning machine;fast regression model;power system operation;profitability;reliability;renewable energy generation;solar energy;solar power generation;uncertainty quantification;very short-term nonparametric probabilistic forecasting","","","","","","20160105","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Probabilistic forecasting of day-ahead electricity prices for the Iberian electricity market","R. Moreira; R. Bessa; J. Gama","FEP - Faculty of Economics, University of Porto, Portugal","2016 13th International Conference on the European Energy Market (EEM)","20160728","2016","","","1","5","With the liberalization of the electricity markets, price forecasting has become crucial for the decision-making process of market agents. The unique features of electricity price, such as non-stationary, non-linearity and high volatility make this a very difficult task. For this reason, rather than a simple point forecast, market participants are more interested in a probabilistic forecast that is essential to estimate the uncertainty involved in the price. By focusing on this issue, the aim of this paper is to analyze the impact of external factors in the electricity price and present a methodology for probabilistic forecasting of day-ahead electricity prices from the Iberian electricity market. The models are built using regression techniques and aim to obtain, for each hour, the quantiles of 5% to 95% by steps of 5%.","","Electronic:978-1-5090-1298-5; POD:978-1-5090-1299-2","10.1109/EEM.2016.7521226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7521226","Day-ahead forecast;Iberian electricity market;machine learning;probabilistic forecasting;quantile regression","Electricity supply industry;Forecasting;Probabilistic logic;Production;Wind forecasting;Wind power generation","economic forecasting;power markets;pricing;regression analysis","Iberian electricity market;day-ahead electricity price probabilistic forecasting;decision-making process;market agents;market participants;regression technique;uncertainty estimation","","","","","","","6-9 June 2016","","IEEE","IEEE Conference Publications"
"IP prefix hijack detection using BGP connectivity monitoring","H. Alshamrani; B. Ghita","Centre for security, Communications and Network Research, (CSCAN) Plymouth University, Plymouth, UK","2016 IEEE 17th International Conference on High Performance Switching and Routing (HPSR)","20160801","2016","","","35","41","In spite of significant on-going research, the Border gateway protocol (BGP) still encompasses conceptual vulnerability issues regarding impersonating the ownership of IP prefixes for ASes (Autonomous Systems). In this context, a number of research studies focused on securing BGP through historical-based and statistical-based behavioural models. This paper suggests a novel method based on tracking the connectivity of suspicious ASes, which are received from a program tracing IP prefix hijacking signature. The paper uses Full Cross-Validation test to investigate the accuracy of the invented method and studies the similarity and differences between malicious and benign observations before they are classified. Classification might not be the appropriate technique to deal with IP prefix hijack detection on its own; therefore we propose to combine the two methods (signature and classification-based) in order to cover the limitations of both techniques. From a processing perspective, the outputs from signature-based method are used as inputs for the classification-based. The main features are extracted from the ASpath attributes of potentially suspicious ASes. The features are considered a mixture of the behavioural characteristics of connectivity among routers. The best five supervised classifiers were used in the previous researches and go with the characteristics of dataset will be used in this paper to evaluate the detection method. Under different learning algorithms, Random Forest and J48 classifiers, the detection method is able to detect the hijacks with 81% accuracy.","","Electronic:978-1-4799-8950-8; POD:978-1-4799-8951-5","10.1109/HPSR.2016.7525636","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7525636","ASN;BGP4;IP prefix hijack;MOAS;Machine learning;RIRs Whois databases;features;route;routes","Databases;Feature extraction;IP networks;Internet;Machine learning algorithms;Routing;Security","IP networks;computer network security;learning (artificial intelligence);pattern classification;routing protocols;statistical analysis","AS;ASpath attributes;BGP connectivity monitoring;IP prefix hijack detection;IP prefix hijacking signature;J48 classifiers;autonomous systems;behavioural characteristics;border gateway protocol;conceptual vulnerability issues;full cross-validation test;historical-based behavioural models;learning algorithms;random forest;signature-based method;statistical-based behavioural models","","","","","","","14-17 June 2016","","IEEE","IEEE Conference Publications"
"Enhancing academic literature review through relevance recommendation: Using bibliometric and text-based features for classification","T. R. P. M. Rúbio; C. A. S. J. Gulo","LIACC - Artificial Intelligence and Computer Science Laboratorym DEI - Faculty of Engineering, University of Porto, Porto, Portugal","2016 11th Iberian Conference on Information Systems and Technologies (CISTI)","20160728","2016","","","1","6","The growing number of scientific publications and the availability of information in online repositories enable researchers to discover, analyze and maintain an updated state of the art bibliography. Indeed, few works explore this scenario in order to support researchers on the literature review step. Literature reviewing comprises a fundamental part of the scientific writing, in which publications are evaluated and selected by relevance. Different approaches for relevance are possible, whether a more qualitative (semantic) approach with text-based techniques either more quantitative (numerical) approaches that use article's metadata, such as bibliometric measures. Bibliometrics provide direct evidences of relevance and could represent good attributes for automatic classification. Our insight is that if a bibliometric-based cannot outperform text-based approaches, a hybrid model using both could benefit from it enhancing the classification performance (in terms of accuracy, precision and recall). In this paper we presented a novel approach, using Machine Learning (ML), namely the ID3 algorithm for a classification model that learn from specialist annotated data and recommend relevant papers for a specific research. Experiments showed good results on learning performance when using a hybrid approach, increasing testing performance in 12%, achieving 89.05% in accuracy when classifying a paper as relevant.","","Electronic:978-9-8998-4346-2; POD:978-1-5090-1226-8","10.1109/CISTI.2016.7521620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7521620","Bibliometric;Classification;Machine Learning;Systematic Literature Review (SLR);Text Mining","Analytical models;Bibliographies;Bibliometrics;Classification algorithms;Measurement;Metadata;Semantics","electronic publishing;information analysis;information retrieval;learning (artificial intelligence);pattern classification;recommender systems;scientific information systems;text analysis","ID3 algorithm;ML;academic literature review;bibliometric features;classification model;machine learning;metadata;online repositories;relevance recommendation;scientific publications;scientific writing;text-based features","","","","","","","15-18 June 2016","","IEEE","IEEE Conference Publications"
"In-Memory Computing Architectures for Sparse Distributed Memory","M. Kang; N. R. Shanbhag","Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL, USA","IEEE Transactions on Biomedical Circuits and Systems","20160727","2016","10","4","855","863","This paper presents an energy-efficient and high-throughput architecture for Sparse Distributed Memory (SDM)-a computational model of the human brain [1]. The proposed SDM architecture is based on the recently proposed in-memory computing kernel for machine learning applications called Compute Memory (CM) [2], [3]. CM achieves energy and throughput efficiencies by deeply embedding computation into the memory array. SDM-specific techniques such as hierarchical binary decision (HBD) are employed to reduce the delay and energy further. The CM-based SDM (CM-SDM) is a mixed-signal circuit, and hence circuit-aware behavioral, energy, and delay models in a 65 nm CMOS process are developed in order to predict system performance of SDM architectures in the autoand hetero-associative modes. The delay and energy models indicate that CM-SDM, in general, can achieve up to 25 × and 12 × delay and energy reduction, respectively, over conventional SDM. When classifying 16 ×16 binary images with high noise levels (input bad pixel ratios: 15%-25%) into nine classes, all SDM architectures are able to generate output bad pixel ratios (B<sub>o</sub>) ≤ 2%. The CM-SDM exhibits negligible loss in accuracy, i.e., its B<sub>o</sub> degradation is within 0.4% as compared to that of the conventional SDM.","1932-4545;19324545","","10.1109/TBCAS.2016.2545402","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489032","Associative memory;Compute Memory;brain-inspired computing;machine learning;pattern recognition;sparse distributed memory","Computational modeling;Computer architecture;Delays;Integrated circuit modeling;Radiation detectors;Random access memory;Throughput","associative processing;binary decision diagrams;biocomputing;brain models;learning (artificial intelligence)","CMOS process;Compute Memory;energy efficient architecture;hierarchical binary decision;high throughput architecture;human brain;in-memory computing architecture;machine learning;mixed signal circuit;sparse distributed memory","","","","","","20160610","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"The monitoring of the spacecraft equipment thermal modes","A. Y. Istratov; I. I. Khomenko; A. V. Pogodin","Moscow Institute of Electronics and Mathematics, Higher School of Economics, Russia","2016 Third International Conference on Digital Information Processing, Data Mining, and Wireless Communications (DIPDMWC)","20160804","2016","","","319","323","In this paper the approach to the temperature parameters forecasting to avoid overheating of the spacecraft equipment at the end of the data transmission session is considered. To determine temperature values at the indicated times of the spacecraft components algorithms of historical data processing are proposed. The software is provided. The conducted experiments proved the ability to reveal anomaly situations.","","CD-ROM:978-1-4673-9378-2; Electronic:978-1-4673-9379-9; POD:978-1-4673-9380-5","10.1109/DIPDMWC.2016.7529410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529410","Forecasting;Machine Learning;Neural Network;Spacecraft;Thermal Mode","Antenna feeds;Biological neural networks;Neurons;Software;Space vehicles;Temperature sensors;Training","aerospace computing;space vehicles;temperature distribution","data transmission session;spacecraft equipment thermal mode;temperature parameter","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"Bayesian logistic regression using Vectorial Centroid for interval type-2 fuzzy sets","K. M. N. K. Khalif; A. Gegov","School of Computing, University of Portsmouth, PO1 3HE, U.K.","2015 7th International Joint Conference on Computational Intelligence (IJCCI)","20160804","2015","2","","69","79","It is necessary to represent the probabilities of fuzzy events based on a Bayesian knowledge. Inspired by such real applications, in this research study, the theoretical foundations of Vectorial Centroid of interval type-2 fuzzy sets with Bayesian logistic regression is introduced. This includes official models, elementary operations, basic properties and advanced application. The Vectorial Centroid method for interval type-2 fuzzy set takes a broad view by exampled labelled by a classical Vectorial Centroid defuzzification method for type-1 fuzzy sets. Rather than using type-1 fuzzy sets for implementing fuzzy events, type-2 fuzzy sets are recommended based on the involvement of uncertainty quantity. It also highlights the incorporation of fuzzy sets with Bayesian logistic regression allows the use of fuzzy attributes by considering the need of human intuition in data analysis. It is worth adding here that this proposed methodology then applied for BUPA liver-disorder dataset and validated theoretically and empirically.","","Electronic:978-9-8975-8165-6; POD:978-1-5090-1968-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533264","Bayesian Logistic Regression;Defuzzification;Human Intuition;Interval Type-2 Fuzzy Sets;Machine Learning;Uncertainty;Vectorial Centroid","Bayes methods;Frequency selective surfaces;Fuzzy sets;Gold;Learning systems;Logistics;Uncertainty","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"An Unsupervised Graph Based Continuous Word Representation Method for Biomedical Text Mining","Z. Jiang; L. Li; D. Huang","School of Computer Science and Technology Dalian University of Technology, Dalian, Liaoning, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20160805","2016","13","4","634","642","In biomedical text mining tasks, distributed word representation has succeeded in capturing semantic regularities, but most of them are shallow-window based models, which are not sufficient for expressing the meaning of words. To represent words using deeper information, we make explicit the semantic regularity to emerge in word relations, including dependency relations and context relations, and propose a novel architecture for computing continuous vector representation by leveraging those relations. The performance of our model is measured on word analogy task and Protein-Protein Interaction Extraction (PPIE) task. Experimental results show that our method performs overall better than other word representation models on word analogy task and have many advantages on biomedical text mining.","1545-5963;15455963","","10.1109/TCBB.2015.2478467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265007","Natural language processing;connectionism and neural nets;machine learning;object representation","Biological system modeling;Context;Context modeling;Protein engineering;Proteins;Semantics;Training","biomedical engineering;data mining;medical computing;proteins;semantic networks","PPIE task;biomedical text mining task;context relation;dependency relation;protein-protein interaction extraction;semantic regularity;shallow-window based model;unsupervised graph based continuous word representation method;word analogy task","","","","","","20150914","July-Aug. 1 2016","","IEEE","IEEE Journals & Magazines"
"Techniques and applications of emotion recognition in speech","S. Lugović; I. Dunđer; M. Horvat","Zagreb University of Applied Sciences, Department of Computer Science and Information Technology, Vrbik 8, Zagreb, Croatia","2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20160728","2016","","","1278","1283","Affective computing opens a new area of research in computer science with the aim to improve the way how humans and machines interact. Recognition of human emotions by machines is becoming a significant focus in recent research in different disciplines related to information sciences and Human-Computer Interaction (HCI). In particular, emotion recognition in human speech is important, as it is the primary communication tool of humans. This paper gives a brief overview of the current state of the research in this area with the aim to underline different techniques that are being used for detecting emotional states in vocal expressions. Furthermore, approaches for extracting speech features from speech datasets and machine learning methods with special emphasis on classifiers are analysed. In addition to the mentioned techniques, this paper also gives an outline of the areas where emotion recognition could be utilised such as healthcare, psychology, cognitive sciences and marketing.","","CD-ROM:978-953-233-088-5; Electronic:978-953-233-086-1; POD:978-1-5090-2543-5","10.1109/MIPRO.2016.7522336","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7522336","acoustic signal processing;affective computing;emotion recognition;human-computer interaction;linguistic speech features;machine learning;speech analysis","Affective computing;Databases;Emotion recognition;Feature extraction;Pragmatics;Speech;Speech recognition","emotion recognition;human computer interaction;learning (artificial intelligence);speech recognition","HCI;computer science;emotion recognition;human emotions;human speech;human-computer interaction;machine learning methods;speech datasets;speech features;vocal expressions","","","","","","","May 30 2016-June 3 2016","","IEEE","IEEE Conference Publications"
"Learning-based distance evaluation in robot vision: A comparison of ANFIS, MLP, SVR and bilinear interpolation models","H. Fraihat; K. Madani; C. Sabourin","I LISSI / EA 3956 Lab., University Paris-Est Creteil, Senart-FB Institute of Technology, 36-37 Rue Charpak, 77127 Lieusaint, France","2015 7th International Joint Conference on Computational Intelligence (IJCCI)","20160804","2015","3","","168","173","This paper deals with visual evaluation of object distances using Soft-Computing based approaches and pseudo-3D standard low-cost sensor, namely the Kinect. The investigated technique points toward robots' vision and visual metrology of the robot's surrounding environment. The objective is providing the robot the ability of evaluating distances between objects in its surrounding environment. In fact, although presenting appealing advantages, the Kinect has not been designed for metrological aims. The investigated approach offers the possibility to use this low-cost pseudo-3D sensor for distance evaluation avoiding 3D feature extraction and thus exploiting the simplicity of only 2D image' processing. Experimental results show the viability of the proposed approach and provide comparison between different machine learning techniques as Adaptive-network-based fuzzy inference (ANFIS), Multi-layer Perceptron (MLP), Support vector regression (SVR), Bilinear interpolation.","","Electronic:978-9-8975-8165-6; POD:978-1-5090-1968-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533407","ANFIS;Bilinear Interpolation;Kinect;MLP;Machine Learning;SVR;Soft-Computing;Visual Distance Evaluation;Visual Information Processing","Databases;Feature extraction;Interpolation;Neurons;Robot sensing systems;Visualization","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Sparse Computation for Large-Scale Data Mining","D. S. Hochbaum; P. Baumann","Department of Industrial Engineering and Operations Research, University of California, Berkeley, CA","IEEE Transactions on Big Data","20160721","2016","2","2","151","174","Leading machine learning techniques rely on inputs in the form of pairwise similarities between objects in the data set. The number of pairwise similarities grows quadratically in the size of the data set which poses a challenge in terms of scalability. One way to achieve practical efficiency for similarity-based techniques is to sparsify the similarity matrix. However, existing sparsification approaches consider the complete similarity matrix and remove some of the non-zero entries. This requires quadratic time and storage and is thus intractable for large-scale data sets. We introduce here a method called sparse computation that generates a sparse similarity matrix which contains only relevant similarities without computing first all pairwise similarities. The relevant similarities are identified by projecting the data onto a low-dimensional space in which groups of objects that share the same grid neighborhood are deemed of potential high similarity whereas pairs of objects that do not share a neighborhood are considered to be dissimilar and thus their similarities are not computed. The projection is performed efficiently even for massively large data sets. We apply sparse computation for the K-nearest neighbors algorithm (KNN), for graph-based machine learning techniques of supervised normalized cut and K-supervised normalized cut (SNC and KSNC) and for support vector machines with radial basis function kernels (SVM), on realworld classification problems. Our empirical results show that the approach achieves a significant reduction in the density of the similarity matrix, resulting in a substantial reduction in tuning and testing times, while having a minimal effect (and often none) on accuracy. The low-dimensional projection is of further use in massively large data sets where the grid structure allows to easily identify groups of “almost identical” objects. Such groups of objects are then replaced by representatives, thus- reducing the size of the matrix. This approach is effective, as illustrated here for data sets comprising up to 8.5 million objects.","","","10.1109/TBDATA.2016.2576470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486113","$K$ -nearest neighbor algorithm;Big data;data mining;similarity-based machine learning;sparsification;supervised normalized cut;support vector machines","Big data;Clustering algorithms;Kernel;Machine learning algorithms;Sparse matrices;Support vector machines;Training","data analysis;data mining;learning (artificial intelligence);pattern classification;pattern matching;radial basis function networks;sparse matrices;support vector machines","K-nearest neighbor algorithm;K-supervised normalized cut;KNN;KSNC;graph-based machine learning techniques;grid structure;large-scale data mining;low-dimensional projection;low-dimensional space;pairwise similarities;radial basis function kernels;similarity-based techniques;sparse computation;sparse similarity matrix;support vector machines","","1","","41","","20160607","June 1 2016","","IEEE","IEEE Journals & Magazines"
"Filtering unwanted messages from OSN walls","P. Salunkhe; S. Bharne; P. Padiya","Department of Computer Engineering, Ramrao Adik Institute of Technology, Nerul, Navi Mumbai","2016 International Conference on Innovation and Challenges in Cyber Security (ICICCS-INBUSH)","20160815","2016","","","261","264","Online Social Networking sites (OSNs) helps to connect people easily. There are various online social sites that are available like Facebook, Twitter etc. which brought world closer. In OSN, user creates an account on social sites after which they are able to perform various actions like adding friends, sharing videos and images. OSN sites provide some space or area to post the status such a space is called Wall. But sometimes people post offensive messages on a particulars wall which may cause a serious problem to user's reputation. To avoid such kind of serious problem we can apply Information Filtering (IF) technique. Information filtering can be used for formless data in contrast to database application in which data required is in ordered manner. There are various types of Information Filtering methods namely Content-based filtering method, Policy-based filtering method and Collaboration filtering method. This paper focuses on analyzing methodology Information Filtering on social networks.","","Electronic:978-1-5090-2084-3; POD:978-1-5090-2085-0","10.1109/ICICCS.2016.7542319","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542319","Collaborative Filtering;Information Filtering Strategy;Machine Learning Technique","Collaboration;Facebook;Information filters;Text categorization","collaborative filtering;content-based retrieval;social networking (online)","Facebook;IF technique;OSN walls;Twitter;collaboration filtering method;content-based filtering method;formless data;information filtering technique;online social networking sites;policy-based filtering method;social site account;unwanted message filtering;user reputation","","","","","","","3-5 Feb. 2016","","IEEE","IEEE Conference Publications"
"Design of energy-efficient on-chip EEG classification and recording processors for wearable environments","M. A. B. Altaf; C. Zhang; L. Radakovic; J. Yoo","Masdar Institute of Science and Technology, Abu Dhabi, UAE","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","1126","1129","Classification of EEG under wearable environment faces many challenges including motion artifact, electrode DC offset, noise and limited available energy source. This paper describes the design consideration of a multi-channel machine-learning based EEG classification and recording processors for wearable form-factor sensors. The goal is to optimize the detection performance while balancing the analog and digital signal processing to optimize its energy consumption. On-chip classification significantly helps achieving energy-efficiency by reducing the communication overhead of the data. With epileptic seizure detection and recording system examples, we start from choosing number of channels, the sampling rate, and how to effectively extract features out of the down-sampled data. After that, classification algorithms are also discussed in detail. When verified with the Children's Hospital Boston-Massachusetts Institute of Technology (CHB-MIT) EEG database, based on Repeated Random Sub-Sampling validation, the seizure detection sensitivity and specificity of the Non-Linear SVM are improved by 12.4%P and 3.56%P, respectively, compared to the Linear-SVM. The LSVM and NLSVM processors are fabricated in 0.18μm 1P6M CMOS and consume 1.52μJ/classification and 1.34μJ/classification, respectively. Finally, the on-chip memory requirements for storing the raw seizure data is discussed.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7527443","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527443","Electroencephalography (EEG);epilepsy;machine learning;on-chip classification;patient-specific;seizure detection;wearable sensor","Biomedical monitoring;Electrodes;Electroencephalography;Program processors;Support vector machines;System-on-chip;Training","electroencephalography;learning (artificial intelligence);medical disorders;medical signal processing;support vector machines","EEG recording processors;Repeated Random Sub-Sampling validation;detection performance;electrode DC offset;epileptic seizure detection;motion artifact;multichannel machine learning;noise;nonLinear SVM;on-chip EEG classification;sampling rate;wearable environments","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"CONDENSE: A Reconfigurable Knowledge Acquisition Architecture for Future 5G IoT","D. Vukobratovic; D. Jakovetic; V. Skachek; D. Bajovic; D. Sejdinovic; G. Karabulut Kurt; C. Hollanti; I. Fischer","Department of Power, Electronics and Communications Engineering, University of Novi Sad, Novi Sad, Serbia","IEEE Access","20160721","2016","4","","3360","3378","In forthcoming years, the Internet of Things (IoT) will connect billions of smart devices generating and uploading a deluge of data to the cloud. If successfully extracted, the knowledge buried in the data can significantly improve the quality of life and foster economic growth. However, a critical bottleneck for realizing the efficient IoT is the pressure it puts on the existing communication infrastructures, requiring transfer of enormous data volumes. Aiming at addressing this problem, we propose a novel architecture dubbed Condense which integrates the IoT-communication infrastructure into the data analysis. This is achieved via the generic concept of network function computation. Instead of merely transferring data from the IoT sources to the cloud, the communication infrastructure should actively participate in the data analysis by carefully designed en-route processing. We define the Condense architecture, its basic layers, and the interactions among its constituent modules. Furthermore, from the implementation side, we describe how Condense can be integrated into the Third Generation Partnership Project (3GPP) machine type communications (MTCs) architecture, as well as the prospects of making it a practically viable technology in a short time frame, relying on network function virtualization and software-defined networking. Finally, from the theoretical side, we survey the relevant literature on computing atomic functions in both analog and digital domains, as well as on function decomposition over networks, highlighting challenges, insights, and future directions for exploiting these techniques within practical 3GPP MTC architecture.","2169-3536;21693536","","10.1109/ACCESS.2016.2585468","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508921","Internet of things (IoT);big data;machine learning;network coding;network function computation;wireless communications","3GPP;5G mobile commuinication;Big data;Cloud computing;Computer architecture;Data analysis;Internet of things;Machine learning;Smart devices;Wireless communication","5G mobile communication;Internet of Things","3GPP;5G IoT;Internet of Things;IoT sources;IoT-communication;MTC architecture;communication infrastructures;data analysis;data volumes;generic concept;machine type communications;network function computation;network function virtualization;reconfigurable knowledge acquisition architecture;smart devices;software defined networking;third generation partnership project","","1","","88","","20160711","2016","","IEEE","IEEE Journals & Magazines"
"Wearable band for hand gesture recognition based on strain sensors","A. Ferrone; F. Maita; L. Maiolo; M. Arquilla; A. Castiello; A. Pecora; X. Jiang; C. Menon; A. Ferrone; L. Colace","IMM - Istituto per la Microelettronica e i Microsistemi, CNR - Consiglio Nazionale delle Ricerche, Via del fosso del cavaliere n.100, 0133, Rome, Italy","2016 6th IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob)","20160728","2016","","","1319","1322","A novel fully wearable system based on a smart wristband equipped with stretchable strain gauge sensors and readout electronics have been assembled and tested to detect a set of movements of a hand crucial in rehabilitation procedures. The high sensitivity of the active devices embedded on the wristband do not need a direct contact with the skin, thus maximizing the comfort on the arm of the tester. The gestures done with the device have been auto-labeled by comparing the signals detected in real-time by the sensors with a commercial infrared device (Leap motion). Finally, the system has been evaluated with two machine-learning algorithms Linear Discriminant Analysis (LDA) and Support Vector Machine (SVM), reaching a reproducibility of 98% and 94%, respectively.","","Electronic:978-1-5090-3287-7; POD:978-1-5090-3288-4","10.1109/BIOROB.2016.7523814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523814","gesture recognition;machine learning;smart wristband;strain gauge sensors;wearable device","Biomedical monitoring;Sensor systems;Skin;Support vector machines;Thumb","gesture recognition;learning (artificial intelligence);medical computing;palmprint recognition;patient rehabilitation;readout electronics;strain gauges;strain sensors;support vector machines;wearable computers","LDA;SVM;hand gesture recognition;linear discriminant analysis;machine-learning;readout electronics;rehabilitation procedure;smart wristband;strain sensor;stretchable strain gauge sensor;support vector machine;wearable band","","1","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Social Interaction Assistant: A Person-Centered Approach to Enrich Social Interactions for Individuals With Visual Impairments","S. Panchanathan; S. Chakraborty; T. McDaniel","Center for Cognitive Ubiquitous Computing (CUbiC), Arizona State University, Tempe, AZ, USA","IEEE Journal of Selected Topics in Signal Processing","20160725","2016","10","5","942","951","Social interaction is a central component of human experience. The ability to interact with others and communicate effectively within an interactive context is a fundamental necessity for professional success as well as personal fulfillment. Individuals with visual impairment face significant challenges in social communication, which if unmitigated, may lead to lifelong needs for extensive social and economic support. Unfortunately, today's multimedia technologies largely cater to the needs of the “able” population, resulting in solutions that mostly meet the needs of that community. Individuals with disabilities (such as visual impairment) have largely been absent in the design process, and have to adapt themselves (often unsuccessfully) to available solutions. In this paper, we propose a social interaction assistant for individuals who are blind or visually impaired, incorporating novel contributions in: 1) person recognition through batch mode active learning; 2) reliable multimodal person recognition through the conformal predictions framework; and 3) facial expression recognition through topic models. Moreover, individuals with visual impairments often have specific requirements that necessitate a personalized, adaptive approach to multimedia computing. To address this challenge, our proposed solutions place emphasis on understanding the individual user's needs, expectations and adaptations toward designing, and developing and deploying effective multimedia solutions. Our empirical results demonstrate the significant potential in using person centered multimedia solutions to enrich the lives of individuals with disabilities.","1932-4553;19324553","","10.1109/JSTSP.2016.2543681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435229","Computer Vision;Machine Learning;Person-centered Multimedia Computing;Social Interaction Assistant","Face;Face recognition;Sociology;Statistics;Vibrations;Visualization","face recognition;handicapped aids;interactive systems;learning (artificial intelligence);multimedia computing","batch mode active learning;blind individuals;conformal predictions framework;facial expression recognition;individuals with disabilities;interactive context;multimedia computing;multimodal person recognition;person centered multimedia solutions;person-centered approach;personalized adaptive approach;social communication;social interaction assistant;topic models;visually impaired individuals","","1","","","","20160317","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Gaussian Nonlinear Line Attractor for learning multidimensional data","T. H. Aspiras; V. K. Asari; W. Sakla","Department of Electrical and Computer Engineering, University of Dayton, U.S.A.","2015 7th International Joint Conference on Computational Intelligence (IJCCI)","20160804","2015","3","","130","137","The human brain's ability to extract information from multidimensional data modeled by the Nonlinear Line Attractor (NLA), where nodes are connected by polynomial weight sets. Neuron connections in this architecture assumes complete connectivity with all other neurons, thus creating a huge web of connections. We envision that each neuron should be connected to a group of surrounding neurons with weighted connection strengths that reduces with proximity to the neuron. To develop the weighted NLA architecture, we use a Gaussian weighting strategy to model the proximity, which will also reduce the computation times significantly. Once all data has been trained in the NLA network, the weight set can be reduced using a locality preserving nonlinear dimensionality reduction technique. By reducing the weight sets using this technique, we can reduce the amount of outputs for recognition tasks. An appropriate distance measure can then be used for comparing testing data and the trained data when processed through the NLA architecture. It is observed that the proposed GNLA algorithm reduces training time significantly and is able to provide even better recognition using fewer dimensions than the original NLA algorithm. We have tested this algorithm and showed that it works well in different datasets, including the EO Synthetic Vehicle database and the Sheffield face database.","","Electronic:978-9-8975-8165-6; POD:978-1-5090-1968-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533401","Machine Learning;Multidimensional Data;Neural Networks;Nonlinear Line Attractor","Biological neural networks;Brain modeling;Computer architecture;Data models;Manifolds;Mathematical model;Neurons","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Methods for Person-Centered Continuous Pain Intensity Assessment From Bio-Physiological Channels","M. Kächele; P. Thiam; M. Amirian; F. Schwenker; G. Palm","Institute of Neural Information Processing, Ulm University, Ulm, Germany","IEEE Journal of Selected Topics in Signal Processing","20160725","2016","10","5","854","864","In this work, we present methods for the personalization of a system for the continuous estimation of pain intensity from bio-physiological channels. We investigate various ways to estimate the similarity of persons and to retrieve the most informative ones using meta-information, personality traits, and machine learning techniques. Given this information, specialized classifiers can be created that are both, more efficient in terms of complexity and training times and also more accurate than classifiers trained on the complete data. To capture the most information in the different bio-physiological channels, we cover a broad spectrum of different feature extraction algorithms. Furthermore, we show that the system is capable of running in real-time and discuss issues that arise when dealing with incremental data processing. In extensive experiments we verify the validity of our approach.","1932-4553;19324553","","10.1109/JSTSP.2016.2535962","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7421991","Pain intensity estimation;machine learning;personalization;semi-supervised learning","Biomedical monitoring;Electromyography;Entropy;Feature extraction;Pain;Time-frequency analysis","bioelectric potentials;feature extraction;learning (artificial intelligence);mechanoception;medical signal processing","Person-centered continuous pain intensity assessment;bio-physiological channels;feature extraction algorithms;incremental data processing;machine learning techniques","","1","","","","20160229","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Request distribution with pre-learning for distributed SSL reverse proxies","H. Dong; J. Yang; Y. Sheng","Key Laboratory of Noise and Vibration Research, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China","2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20160721","2016","","","161","167","As network data security becoming more and more universalized, distributed Secure Sockets Layer (SSL) reverse proxies are often used in Web systems to offload CPU exhausting SSL operations from Web servers and improve the execution performance of the SSL protocol. The distribution strategy of user requests to the SSL reverse proxies is a significant factor affecting the system's performance in processing SSL operations. Aiming at improving the quality of request distribution decisions, this paper proposes a new approach for SSL reverse proxy load estimation, i.e. the family of algorithms called Load Estimation with Pre-Learning (LEPL), which estimates load using pre-learned machine learning models. Using LEPL, high accuracy of load estimation can be achieved, so that better request distribution decisions can be made. Our experimental results show that by using pre-learning, the SSL reverse proxy system's average response time can be shortened by about 30% - 50%.","","Electronic:978-1-5090-2239-7; POD:978-1-5090-0804-9","10.1109/SNPD.2016.7515895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515895","SSL reverse proxy;Web system;distributed system;load estimation;machine learning;request distribution","Algorithm design and analysis;Decision trees;Estimation;Load modeling;Machine learning algorithms;Real-time systems;Training","Internet;file servers;learning (artificial intelligence);security of data","LEPL;SSL protocol;Web servers;Web systems;distributed SSL reverse proxies;distributed secure sockets layer reverse proxies;load estimation with pre-learning;network data security;pre-learned machine learning;request distribution decisions","","","","","","","May 30 2016-June 1 2016","","IEEE","IEEE Conference Publications"
"A decision tree based approach for controlled islanding of microgrids","R. Azim; F. Li","Dept. of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, 37996, USA","2016 IEEE/PES Transmission and Distribution Conference and Exposition (T&D)","20160725","2016","","","1","5","This paper presents a decision tree based systematic approach for controlled islanding of grid-connected microgrids. The objective of the proposed approach is to develop an adaptive controlled islanding methodology to be implemented as a preventive control component in emergency control strategy for microgrid operations. A contingency-oriented decision tree classifier is trained with event database generated from offline simulations of system events. The trained decision tree classifier is capable of identifying system events that warrant controlled islanding of microgrids as a preventive control measure. Real time voltage and current measurements are utilized in conjunction with the trained decision tree classifier for online decision support on controlled islanding strategy of microgrids. A microgrid test system model consisting of multiple distributed generations and energy storage systems is employed to demonstrate the performance of the proposed approach.","","Electronic:978-1-5090-2157-4; POD:978-1-5090-2158-1","10.1109/TDC.2016.7519929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519929","Microgrids;controlled islanding;decision trees;distributed generations;machine learning","Computational modeling;Current measurement;Decision trees;Microgrids;Training;Voltage control;Voltage measurement","control engineering computing;decision trees;distributed power generation;electric current measurement;energy storage;learning (artificial intelligence);pattern classification;power generation control;power grids;voltage measurement","adaptive controlled islanding methodology;contingency-oriented decision tree classifier;decision tree based systematic approach;emergency control strategy;energy storage system;event database;grid-connected microgrid controlled islanding;microgrid operations;microgrid test system model;multiple distributed generations;online decision support;preventive control component;real time current measurement;real time voltage measurement;system event identification;system event offline simulation;trained decision tree classifier","","","","","","","3-5 May 2016","","IEEE","IEEE Conference Publications"
"A framework for measuring infection level on cacao pods","D. S. Tan; R. N. Leong; A. F. Laguna; C. A. Ngo; A. Lao; D. Amalin; D. Alvindia","De La Salle University, Manila, Philippines","2016 IEEE Region 10 Symposium (TENSYMP)","20160725","2016","","","384","389","Cacao farms worldwide lose up to 40% of their crops annually due to several diseases. To reduce the damage, farmers and agricultural technicians regularly monitor the well-being of their crops. But at present many still rely on visual inspection to assess the degree of infection on their crops, resulting to several errors and inconsistencies due to the subjective nature of the assessment procedure. To improve the inspection procedure, this research developed a framework for detecting and segmenting the infected parts of the fruit to measure the level of infection on the cacao pods based on k-means algorithm supplemented by a Support Vector Machine (SVM) using image colors as features. The highest attained accuracy was 89.2% using k=4 clusters. Results of this research provides promise in the implementation of the proposed framework in developing a more accurate assessment of infection level; thus, potentially improving decision support for managing cacao diseases.","","Electronic:978-1-5090-0931-2; POD:978-1-5090-0932-9","10.1109/TENCONSpring.2016.7519437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519437","cacao;color features;defect segmentation;image segmentation;machine learning;smart farming","Clustering algorithms;Diseases;Image color analysis;Image segmentation;Regions;Support vector machines;Training","crops;image colour analysis;pattern classification;production engineering computing;support vector machines","SVM;agricultural technicians;cacao pods;decision support;diseases;image colors;k-means algorithm;measuring infection level;support vector machine;visual inspection","","","","","","","9-11 May 2016","","IEEE","IEEE Conference Publications"
"Multi-sensor image fusion and target classification for improved maritime domain awareness","M. Pothitos; M. Tummala; J. Scrofani; J. McEachen","Operational Evaluations Directorate at Hellenic Fleet HQ, Hellenic Navy, Athens, Greece","2016 19th International Conference on Information Fusion (FUSION)","20160804","2016","","","1170","1177","In this paper, we propose a scheme for classification of maritime targets through fusion of images collected from dissimilar sensors with an objective to improve maritime domain awareness. Low- and medium-level fusion methods are applied to three types of image data-visual, thermal, multi-spectral-using features obtained from the speeded-up robust features algorithm. The goal was to implement the classification scheme using machine learning techniques. Results indicate that multi-spectral images from low-level fusion yielded the best classification performance. Artificial neural networks are used to derive the classification results and demonstrate the ability to obtain results in a timely manner that could accommodate near real-time classification.","","Electronic:978-0-9964-5274-8; POD:978-1-5090-2012-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528017","feature selection;image fusion;machine learning;neural networks;speeded-up robust features","Feature extraction;Histograms;Image fusion;Image sensors;Robustness;Sensor fusion","feature extraction;image classification;image fusion;learning (artificial intelligence);marine engineering;neural nets","SURF algorithm;artificial neural network;machine learning;maritime domain awareness;multisensor image fusion;multispectral image data;speeded-up robust features algorithm;target classification;thermal image data;visual image data","","","","","","","5-8 July 2016","","IEEE","IEEE Conference Publications"
"Intrusion detection system: Classification and techniques","S. S. Soniya; S. M. C. Vigila","CSE Department, Loyola Institute of Technology & Science, Thovalai-629302, TamilNadu, India","2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT)","20160804","2016","","","1","7","Today's world is made of electronic networks. Everyday huge amount of sensitive data are passed through these networks. These networks are the backbones of the industries like banking, transportation, healthcare, defense, communication etc. So securing the data passed through these networks is essential. Organizations are investing more and more money to secure their data from the attackers. On the other hand, the attackers are getting stronger day by day. In this research various Intrusion Detection Systems (IDS) techniques are surveyed. This IDS techniques are used to protect the network from the attackers. Also in the coming days our research will focus on building an improved system to detect the intruders and to secure the network from the attackers.","","DVD:978-1-5090-1276-3; Electronic:978-1-5090-1277-0; POD:978-1-5090-1278-7","10.1109/ICCPCT.2016.7530231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530231","Anomaly Detection;IDS;Machine Learning Techniques;Security;Types of attacks","Classification algorithms;Computers;Genetic algorithms;Hidden Markov models;Intrusion detection;Monitoring;Support vector machines","pattern classification;security of data","IDS;classification;data security;electronic networks;intrusion detection system;network protection","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Applying neural network on image up-sampling to promote the efficiency of texture matching","I. L. Chung; C. W. Huang; C. M. Chou","Dept. of Computer Science and Information Engineering, Chien Hsin University of Science and Technology No. 229, Jianxing Rd., Zhongli Dist., Taoyuan City 32097, Taiwan","2016 International Conference on Applied System Innovation (ICASI)","20160811","2016","","","1","2","The objective of image up-sampling is to produce the correlated high resolution image from a low resolution image. In this project, we propose to apply neural network on texture database mapping to achieve a more time efficient image up-sampling algorithm. A texture database of high-resolution images will be built in advance before the up-sampling procedure starts. The proposed method consists of two stages: 1. Train a set of neural networks (NNs) for classifying textures; 2. Match each pixel to its corresponding NN of high-resolution textures. In the first stage, we train a set of neural networks (one NN for each kind of texture) from the high-resolution texture database. After the set of NNs is well trained, a high resolution pixel value can be obtained by passing a low resolution pixel into a NN of its corresponding texture. In the second stage, for an input low resolution image, we firstly segment it according to its textures (texture segmentation), then match each pixel to its corresponding NN of high-resolution textures in the database. A super-resolution image can be obtained after all pixels have been matched. In order to avoid excessive human artificial results, the outputs of the proposed method have to be down-sampled and compared with the original low resolution image for further adjusting. The up-sampled image will not be output until the difference between the down-sampled image and original image is within a predefined constraint.","","Electronic:978-1-4673-9888-6; POD:978-1-4673-9889-3","10.1109/ICASI.2016.7539852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539852","machine learning;neural network;super-resolution;up-sampling","Decision support systems;Feature extraction;Neural networks;Training","image classification;image matching;image resolution;image sampling;image segmentation;image texture;neural nets","correlated high resolution image;high resolution pixel;high-resolution texture database mapping;image texture segmentation;image up-sampling;low resolution image;low resolution pixel;neural network;pixel matching;superresolution image;texture classification;texture matching","","","","","","","26-30 May 2016","","IEEE","IEEE Conference Publications"
"An efficient local receptive field feature extractor for handwriting recognition","R. Dogaru; I. Dogaru","University &#x201C;Politehnica&#x201D; of Bucharest, Natural Computing Laboratory, Applied Electronics and Information Engineering, Romania","2016 International Conference on Communications (COMM)","20160804","2016","","","105","108","The performance of a simple yet efficient local receptive field feature extractor is evaluated on state of the art handwritten databases showing that after the proper optimization of its parameters, very good accuracy performances can be obtained using a shallow classifier (e.g. the support vector machine), close to the ones achieved using more sophisticated techniques such as deep-learning classifiers. Particularly useful is the computing speed acceleration of more than one order of magnitude in both training and prediction modes, as a result of reducing the effective size of the feature vector to an order of tens inputs instead hundreds as in the case of applying the input samples directly. Consequently such feature extraction techniques can be conveniently embedded into smart sensing units with various applications from intelligent sensors to portable biometric authentication systems.","","DVD:978-1-4673-8196-3; Electronic:978-1-4673-8197-0; POD:978-1-4673-8198-7","10.1109/ICComm.2016.7528274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528274","cellular automata;handwriting recognition;local receptive fields;machine learning;support vector machines","Automata;Databases;Feature extraction;Handwriting recognition;Neurons;Support vector machines;Training","cellular automata;feature extraction;handwriting recognition;image classification","art handwritten database;biometric authentication;cellular automata based simple local receptive field;handwriting recognition;intelligent sensor;local receptive field feature extraction;parameter optimization;shallow classifier","","","","","","","9-10 June 2016","","IEEE","IEEE Conference Publications"
"Spammer detection based on comprehensive features in Sina Microblog","Shanshan Gao; Xiujuan Ma; Lidong Wang; Yan Yu","School of Economics and Management, Beihang University, Beijing, China","2016 13th International Conference on Service Systems and Service Management (ICSSSM)","20160811","2016","","","1","6","The popularity and accessibility of Sina Microblog have attracted a large number of spammers to conduct spamming behaviors. They can spread advertisements, disseminate pornography, virus and expose phishing. All of these behaviors are extremely harmful to legitimate users. It is necessary to detect spammers from legitimate users in Sina Microblog. In this paper, we defined two kinds of spammers, advertising spammers and following spammers. We extracted six features to distinguish advertising spammers, following spammers and legitimate users. To verify the effectiveness of our method, we use four kind machine learning algorithms, including Bayes Network, Naive Bayes, SVM and Random Forest to evaluate the spammer detection performance on our dataset. The results of these experiments show that most of the classifiers can achieve more than 90% precision rate, recall rate and F-measure rate. Bayes Network classifier was proved to the best on our dataset.","","Electronic:978-1-5090-2842-9; POD:978-1-5090-2843-6","10.1109/ICSSSM.2016.7538616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538616","machine learning;social network;spammer detection","Computers;Feature extraction;Support vector machines","belief networks;learning (artificial intelligence);social networking (online);support vector machines;unsolicited e-mail","Bayes network algorithm;F-measure rate;SVM algorithm;Sina Microblog;advertising spammers;feature extraction;following spammers;machine learning algorithm;naive Bayes algorithm;precision rate;random forest algorithm;recall rate;spammer detection;spamming behavior;support vector machines","","","","","","","24-26 June 2016","","IEEE","IEEE Conference Publications"
"Distributed data replication and access optimization for LHCb storage system: A position paper","M. Hushchyn; P. Charpentier; A. Ustyuzhanin","Yandex School of Data Analysis, Moscow, Russian Federation","2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)","20160801","2015","01","","537","540","This paper presents how machine learning algorithms and methods of statistics can be implemented to data management in hybrid data storage systems. Basicly, two different storage types are used to store data in the hybrid data storage systems. Keeping rarely used data on cheap and slow storages of type one and often used data on fast and expensive storages of type two helps to achieve optimal performance/cost ratio for the system. We use classification algorithms to estimate probability that the data will often used in future. Then, using the risks analysis we define where the data should be stored. We show how to estimate optimal number of replicas of the data using regression algorithms and Hidden Markov Model. Based on the probability, risks and the optimal number of data replicas our system finds optimal data distribution in the hybrid data storage system. We present the results of simulation of our method for LHCb hybrid data storage.","","Electronic:978-9-8975-8164-9; POD:978-1-5090-1967-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526967","Data Management;Hybrid Data Storage Systems;Information Extraction;LHCb;Machine Learning;Structured Data Analysis and Statistical Methods","Algorithm design and analysis;Data storage systems;Distributed databases;Hidden Markov models;History;Prediction algorithms;Time series analysis","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"OptCon: An Adaptable SLA-Aware Consistency Tuning Framework for Quorum-Based Stores","S. Sidhanta; W. Golab; S. Mukhopadhyay; S. Basu","Louisiana State Univ., Baton Rouge, LA, USA","2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)","20160721","2016","","","388","397","Users of distributed datastores that employquorum-based replication are burdened with the choice of asuitable client-centric consistency setting for each storage operation. The above matching choice is difficult to reason about asit requires deliberating about the tradeoff between the latencyand staleness, i.e., how stale (old) the result is. The latencyand staleness for a given operation depend on the client-centricconsistency setting applied, as well as dynamic parameters such asthe current workload and network condition. We present OptCon, a novel machine learning-based predictive framework, that canautomate the choice of client-centric consistency setting underuser-specified latency and staleness thresholds given in the servicelevel agreement (SLA). Under a given SLA, OptCon predictsa client-centric consistency setting that is matching, i.e., it isweak enough to satisfy the latency threshold, while being strongenough to satisfy the staleness threshold. While manually tunedconsistency settings remain fixed unless explicitly reconfigured, OptCon tunes consistency settings on a per-operation basis withrespect to changing workload and network state. Using decisiontree learning, OptCon yields 0.14 cross validation error in predictingmatching consistency settings under latency and stalenessthresholds given in the SLA. We demonstrate experimentally thatOptCon is at least as effective as any manually chosen consistencysettings in adapting to the SLA thresholds for different usecases. We also demonstrate that OptCon adapts to variationsin workload, whereas a given manually chosen fixed consistencysetting satisfies the SLA only for a characteristic workload.","","Electronic:978-1-5090-2453-7; POD:978-1-5090-2454-4","10.1109/CCGrid.2016.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515713","SLA;machine learning;matching consistency;optimal trade off;quorum-replicated store","Data models;Mathematical model;Predictive models;Runtime;Throughput;Training data;Tuning","contracts;data integrity;decision trees;distributed processing;learning (artificial intelligence);storage management","OptCon;SLA thresholds;adaptable SLA-aware consistency tuning framework;client-centric consistency setting;decision tree learning;machine learning-based predictive framework;quorum-based distributed data stores;service level agreement;staleness thresholds;user-specified latency","","1","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Deep learning neural networks optimization using hardware cost penalty","R. Doshi; K. W. Hung; L. Liang; K. H. Chiu","Department of Computer Science, Princeton University, Princeton, USA","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","1954","1957","As deep learning neural networks (DNNs) advance and increase in computational complexity, particularly in terms of memory cost, it becomes difficult to implement DNNs in fixed-point memory-sparse environments (e.g. integrated circuits in consumer electronics). Thus, the training of DNNs must be reformulated to balance the hardware costs needed to represent the often millions of parameter weights in such machine learning models. This paper proposes a novel optimization approach that simultaneously minimizes complexity (total memory) and maximizes accuracy. Specifically, a bit-depth complexity penalty is induced to urge the DNN model towards a state of lower memory using a numerical gradient in optimization iterations. Experimental results on the MNIST (Mixed National Institute of Standards and Technology) handwritten digit classification benchmark demonstrate a minimal loss (1%) in DNN accuracy with a significant reduction (37%) of memory cost on average.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7538957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538957","bit depth;complexity;deep learning;fixed-point;limited precision;machine learning;memory cost;neural networks","Complexity theory;Cost function;Feature extraction;Neural networks;Quantization (signal);Training","computational complexity;gradient methods;learning (artificial intelligence);neural nets;optimisation;storage management","DNN model;bit-depth complexity penalty;computational complexity;deep learning neural network optimization;fixed-point memory-sparse environments;hardware cost penalty;machine learning;numerical gradient;optimization iterations","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"From the Service-Oriented Architecture to the Web API Economy","W. Tan; Y. Fan; A. Ghoneim; M. A. Hossain; S. Dustdar","IBM T.J. Watson Research Center","IEEE Internet Computing","20160802","2016","20","4","64","68","As Web APIs become the backbone of Web, cloud, mobile, and machine learning applications, the services computing community will need to expand and embrace opportunities and challenges from these domains.","1089-7801;10897801","","10.1109/MIC.2016.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529010","Big Data;Internet/Web technologies;SOA;Web API;cloud computing;intelligent systems;machine learning;service-oriented architecture;services computing","Big data;Cloud computing;Internet of things;Machine learning;Mobile communication;Service computing;Service-oriented architecture;Web and Internet services","application program interfaces;cloud computing;learning (artificial intelligence);mobile computing;service-oriented architecture","Web API economy;cloud computing;machine learning;mobile computing;service computing community;service-oriented architecture","","","","","","","July-Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Phish-IDetector: Message-ID based automatic phishing detection","R. Verma; N. Rai","Department of Computer Science, University of Houston, 4800 Calhoun Road, Texas, U.S.A.","2015 12th International Joint Conference on e-Business and Telecommunications (ICETE)","20160721","2015","04","","427","434","Phishing attacks are a well known problem in our age of electronic communication. Sensitive information like credit card details, login credentials for account, etc. are targeted by phishers. Emails are the most common channel for launching phishing attacks. They are made to resemble genuine ones as much as possible to fool recipients into divulging private and sensitive data, causing huge monetary losses every year. This paper presents a novel approach to detect phishing emails, which is simple and effective. It leverages the unique characteristics of the Message-ID field of an email header for successful detection and differentiation of phishing emails from legitimate ones. Using machine learning classifiers on n-gram features extracted from Message-IDs, we obtain over 99% detection rate with low false positives.","","Electronic:978-9-8975-8140-3; POD:978-1-4673-8532-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518067","Machine Learning;Message-ID;N-gram;Phishing","Algorithm design and analysis;Decision trees;Electronic mail;Feature extraction;Machine learning algorithms;Postal services;Prediction algorithms","","","","","","","","","20-22 July 2015","","IEEE","IEEE Conference Publications"
"Learning-Based Power/Performance Optimization for Many-Core Systems With Extended-Range Voltage/Frequency Scaling","E. Cai; D. C. Juan; S. Garg; J. Park; D. Marculescu","Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20160715","2016","35","8","1318","1331","Near-threshold computing has emerged as a promising solution to significantly increase the energy efficiency of next-generation multicore systems. This paper evaluates and analyzes the behavior of dynamic voltage and frequency scaling for multicore systems operating under extended range: including near-threshold, nominal, and turbo modes. We adapt the model selection technique from machine learning to determine the relationship between performance and power. The theoretical results show that the resulting models satisfy convexity, which efficiently determines the optimal voltage/frequency operating points for: 1) minimizing energy consumption under throughput constraints or 2) maximizing throughput under a given power budget. We validate our models on FinFET-based chip-multiprocessors. Considering process variations (PVs), experimental results show that at 30% PV levels, our proposed method: 1) reduces energy consumption by 31.09% at iso-performance condition and 2) increases throughput by 11.46% at iso-power when compared with variation-agnostic nominal case.","0278-0070;02780070","","10.1109/TCAD.2015.2504330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339672","Chip-multiprocessor (CMP);FinFET;convex optimization;dynamic voltage and frequency scaling (DVFS);machine learning;power management;process variation (PV)","FinFETs;Integrated circuit modeling;Multicore processing;Optimization;Semiconductor device modeling;Threshold voltage;Throughput","MOSFET;multiprocessing systems;optimisation;power aware computing","FinFET-based chip-multiprocessors;energy efficiency;extended-range voltage/frequency scaling;learning-based power/performance optimization;many-core systems;model selection technique;near-threshold computing;next-generation multicore systems;process variations;throughput constraints","","","","45","","20151130","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"FPGA kernels for classification rule induction","P. Škoda; B. M. Rogina","Ru&#273;er Bo&#353;kovi&#263; Institute, Zagreb, Croatia","2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20160728","2016","","","337","342","Classification is one of the core tasks in machine learning data mining. One of several models of classification are classification rules, which use a set of if-then rules to describe a classification model. In this paper we present a set of FPGA-based compute kernels for accelerating classification rule induction. The kernels can be combined to perform specific procedures in rule induction process, such as evaluating rule coverage, or estimating out-of-bag-error. Since classification problems are getting increasingly larger, there is a need for faster implementations of classification rule induction. One of the platforms that offer great potential for accelerating data mining tasks is FPGA (field programmable gate array), which provides the means for implementing application specific accelerators.","","CD-ROM:978-953-233-088-5; Electronic:978-953-233-086-1; POD:978-1-5090-2543-5","10.1109/MIPRO.2016.7522163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7522163","FPGA;classification rules;dataflow;machine learning","Benchmark testing;Field programmable gate arrays;Hardware;Kernel;Radiation detectors;Random access memory;Throughput","data mining;field programmable gate arrays;learning (artificial intelligence);pattern classification","FPGA kernels;classification rule induction;field programmable gate array;machine learning data mining","","","","","","","May 30 2016-June 3 2016","","IEEE","IEEE Conference Publications"
"Hybrid sentiment analyser for Arabic tweets using R","S. Alhumoud; T. Albuhairi; W. Alohaideb","College of Computer and Information Science, Al-Imam Muhammad Ibn Saud Islamic University, Riyadh, Saudi Arabia","2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)","20160801","2015","01","","417","424","Harvesting meaning out of massively increasing data could be of great value for organizations. Twitter is one of the biggest public and freely available data sources. This paper presents a Hybrid learning implementation to sentiment analysis combining lexicon and supervised approaches. Analysing Arabic, Saudi dialect Twitter tweets to extract sentiments toward a specific topic. This was done using a dataset consisting of 3000 tweets collected in three domains. The obtained results confirm the superiority of the hybrid learning approach over the supervised and unsupervised approaches.","","Electronic:978-9-8975-8164-9; POD:978-1-5090-1967-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526949","Data Mining;Hybrid Learning;Machine Learning;Sentiment Analysis;Supervised Approach","Buildings;Classification algorithms;Computer languages;Data mining;Training;Twitter","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"A Survey on Evolutionary Computation Approaches to Feature Selection","B. Xue; M. Zhang; W. N. Browne; X. Yao","Evolutionary Computation Research Group, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Evolutionary Computation","20160728","2016","20","4","606","626","Feature selection is an important task in data mining and machine learning to reduce the dimensionality of the data and increase the performance of an algorithm, such as a classification algorithm. However, feature selection is a challenging task due mainly to the large search space. A variety of methods have been applied to solve feature selection problems, where evolutionary computation (EC) techniques have recently gained much attention and shown some success. However, there are no comprehensive guidelines on the strengths and weaknesses of alternative approaches. This leads to a disjointed and fragmented field with ultimately lost opportunities for improving performance and successful applications. This paper presents a comprehensive survey of the state-of-the-art work on EC for feature selection, which identifies the contributions of these different algorithms. In addition, current issues and challenges are also discussed to identify promising areas for future research.","1089-778X;1089778X","","10.1109/TEVC.2015.2504420","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339682","Classification;data mining;evolutionary computation;feature selection;machine learning","Computational efficiency;Data mining;Evolutionary computation;Feature extraction;Machine learning algorithms;Optimization;Search problems","data mining;evolutionary computation;feature selection;learning (artificial intelligence);pattern classification","data classification algorithm;data dimensionality reduction;data mining;evolutionary computation;feature selection;machine learning","","11","","","","20151130","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Arabic sentiment analysis using WEKA a hybrid learning approach","S. Alhumoud; T. Albuhairi; M. Altuwaijri","College of Computer and Information Science, Al-Imam Muhammad Ibn Saud Islamic University, Riyadh, Saudi Arabia","2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)","20160801","2015","01","","402","408","Data has become the currency of this era and it is continuing to massively increase in size and generation rate. Large data generated out of organisations' e-transactions or individuals through social networks could be of a great value when analysed properly. This research presents an implementation of a sentiment analyser for Twitter's tweets which is one of the biggest public and freely available big data sources. It analyses Arabic, Saudi dialect tweets to extract sentiments toward a specific topic. It used a dataset consisting of 3000 tweets collected from Twitter. The collected tweets were analysed using two machine learning approaches, supervised which is trained with the dataset collected and the proposed hybrid learning which is trained on a single words dictionary. Two algorithms are used, Support Vector Machine (SVM) and K-Nearest Neighbors (KNN). The obtained results by the cross validation on the same dataset clearly confirm the superiority of the hybrid learning approach over the supervised approach.","","Electronic:978-9-8975-8164-9; POD:978-1-5090-1967-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526947","Data Mining;Hybrid Learning Approach;Machine Learning;Sentiment Analysis;Supervised Approach","Buildings;Classification algorithms;Data mining;Sentiment analysis;Support vector machines;Training;Twitter","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Research on Q-ELM algorithm in robot path planning","H. Ren; R. Yin; F. Li; W. Wang; M. Huo","College of Electrical Engineering, North China University of Science and Technology, Tangshan 063009, China","2016 Chinese Control and Decision Conference (CCDC)","20160808","2016","","","5975","5979","In view of high dimension, the difficulty of training, the problem of slow learning speed in the application of BP neural network in mobile robot path planning, an algorithm of reinforcement Q learning based on extreme learning machine (Q-ELM algorithm) is proposed in this paper. Firstly, the characteristic of reinforcement learning is combining the dynamic network with supervised learning, and the algorithm obtains the state information of the environment and the robot by the characteristic. After that, it is used to analyze the state to get the rewards and punishments of the current state by extreme learning machine. Secondly, it is used to solve the problem of slow training speed by the characteristic of less parameter settings and better generalization performance; Finally the autonomic learning performance of the learning algorithm is verified. The experimental results show that the Q-ELM learning algorithm not only improves the initiative of machine learning, but also improves the learning rate of 4 times than TD reinforcement learning methods, and verifies the stability and convergence of the algorithm.","","CD-ROM:978-1-4673-9713-1; Electronic:978-1-4673-9714-8; POD:978-1-4673-9715-5","10.1109/CCDC.2016.7532066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532066","Autonomous Learning;Extreme learning machine;Mobile robot;Path planning;Reinforcement Q learning","Heuristic algorithms;Learning (artificial intelligence);Mobile robots;Path planning;Robot kinematics;Training","backpropagation;collision avoidance;mobile robots","BP neural network;Q-ELM learning algorithm;algorithm convergence;algorithm stability;autonomic learning performance;dynamic network;extreme learning machine;learning rate improvement;mobile robot path planning;reinforcement Q learning;state information;supervised learning","","","","","","","28-30 May 2016","","IEEE","IEEE Conference Publications"
"A Cloud Platform for classification and resource management of complex electromagnetic problems","A. Kapsalis; P. Kasnesis; P. C. Theofanopoulos; P. K. Gkonis; C. S. Lavranos; D. I. Kaklamani; I. S. Venieris; G. A. Kyriacou","Intelligent Communications and Broadband Networks Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Greece","2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)","20160801","2015","01","","388","393","Most scientific applications tend to have a very resource demanding nature and the simulation of such scientific problems often requires a prohibitive amount of time to complete. Distributed computing offers a solution by segmenting the application into smaller processes and allocating them to a cluster of workers. This model was widely followed by Grid Computing. However, Cloud Computing emerges as a strong alternative by offering reliable solutions for resource demanding applications and workflows that are of scientific nature. In this paper we propose a Cloud Platform that supports the simulation of complex electromagnetic problems and incorporates classification (SVM) and resource allocation (Ant Colony Optimization) methods for the effective management of these simulations.","","Electronic:978-9-8975-8164-9; POD:978-1-5090-1967-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7526945","Ant Colony Optimization;Cloud Computing;Eigenanalysis;Finite Difference;Machine Learning;Resource Allocation;SVM","Algorithm design and analysis;Cloud computing;Computational modeling;Monitoring;Resource management;Support vector machines;Virtual machining","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"A Speech-to-Text Interface for MammoClass","R. S. Rocha; P. Ferreira; I. Dutra; R. Correia; R. Salvini; E. Burnside","CRACS-INESC TEC, Porto, Portugal","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","1","6","Mammoclass is a web tool that allows users to enter a small set of variable values that describe a finding in a mammography, and produces a probability of this finding being malignant or benign. The tool requires that the user types in every variable a value in order to perform a prediction. In this work, we present a speech-to-text interface integrated to MammoClass that allows radiologists to speak up a mammography report instead of typing it in. This new MammoClass module can take audio content, transcribe it into written words, and automatically extract the variable values by applying a parser to the recognized text. Results of spoken mammography reports show that the same variables are extracted for both types of input: typed in or dictated text.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545947","BI-RADS;machine learning;mammography;parsing;speech recognition","Breast;Medical services;Radiology;Software;Speech;Speech recognition;Text recognition","Internet;grammars;mammography;medical computing;speech recognition;speech-based user interfaces","MammoClass Web tool;audio content;parser;speech-to-text interface;spoken mammography reports","","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"Minimizing Fatigue Damage in Aircraft Structures","M. Ruotsalainen; J. Jylhä; A. Visa","Tampere University of Technology","IEEE Intelligent Systems","20160718","2016","31","4","22","29","Aircraft structural health monitoring (SHM) refers to a process in which sensors assess the current (and predict the future) state of a structure in terms of its aging and deterioration to assure users or operators of its safety and performance. In addition to preventing failures, SHM extends aircraft life cycles. Consequently, adopting SHM is strongly motivated not only by flight safety but also by economic considerations. This article focuses on the optimization of aircraft usage as a new aspect of SHM and discusses a knowledge discovery approach based on dynamic time warping and genetic programming. In addition, it points out some of the challenges faced in applying artificial intelligence to aircraft SHM. This novel work reveals that AI provides a means to gain valuable knowledge for decision making on cost-efficient future usage of an aircraft fleet.","1541-1672;15411672","","10.1109/MIS.2016.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412616","applications and expert knowledge-intensive systems;artificial intelligence;computing methodologies;decision support;engineering;evolutionary computing and genetic algorithms;intelligent systems;machine learning;pattern recognition","Aerospace electronics;Aircraft;Artificial intelligence;Military aircraft;Monitoring;Structural engineering;Wireless sensor networks","aerospace safety;aircraft;condition monitoring;data mining;fatigue;genetic algorithms;mechanical engineering computing;socio-economic effects","SHM;aircraft fleet;aircraft structural health monitoring;aircraft structures;artificial intelligence;dynamic time warping;economic considerations;fatigue damage minimization;flight safety;genetic programming;knowledge discovery approach","","","","15","","20160218","July-Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Three-Tier Modular Structural Health Monitoring Framework Using Environmental and Operational Condition Clustering for Data Normalization: Validation on an Operational Wind Turbine System","M. W. Häckell; R. Rolfes; M. B. Kane; J. P. Lynch","Institute of Structural Analysis, W&#246;lfel Engineering, Leibniz Universit&#x00E4;t Hannover, Hannover, H&#xf6;chberg, GermanyGermany","Proceedings of the IEEE","20160718","2016","104","8","1632","1646","This paper proposes a three-tier algorithmic framework as the basis for the flexible design of data-driven structural health monitoring (SHM) systems. The three major functions of the SHM system, including data normalization, feature extraction, and hypothesis testing (HT), are mapped to the three layers of the framework. The first tier of the framework is devoted to data normalization. Machine learning (ML) methods are adopted to normalize available data sets by binning data sets to similar environmental and operational conditions (EOCs) of the system. Specifically, affinity propagation clustering is used to delineate data into groups of similar EOC. Once data are normalized by EOC, the second tier of the framework extracts features from the data to serve as condition parameters (CPs) for damage assessment. To ascertain the health state of the structure, the third tier of the framework is devoted to statistical analysis of the CP through HT. An intrinsic goal of the study is to explore the modularity of the three tier framework as a means of offering SHM system designers opportunity to explore and test different computational block sets at each layer to maximize the detection capability of the SHM system. Various realizations of the three-tier modular framework are presented and applied to acceleration and EOC data collected from an operational 3-kW wind turbine. In total, 354 data sets are collected from the turbine, including tower lateral accelerations in two orthogonal directions at six heights, wind speed and wind direction; 317 of the data sets correspond to the wind turbine in a healthy state and 37 with the wind turbine in a damage state. Using quantitative metrics derived from receiver operating characteristic (ROC) curves, the damage classification capabilities of the framework are validated and shown to accurately identify intentionally introduced damage in the turbine.","0018-9219;00189219","","10.1109/JPROC.2016.2566602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7509630","Condition parameters (CPs);hypothesis testing (HT);machine learning (ML);parameter estimation;probability;statistical analysis;structural health monitoring (SHM);wind turbines","Algorithm design and analysis;Condition monitoring;Data mining;Feature extraction;Machine learning;Monitoring;Parameter estimation;Structural engineering;Wind turbines","condition monitoring;learning (artificial intelligence);pattern clustering;structural engineering computing;wind turbines","CP;EOC;HT;ML;ROC;SHM;computational block sets;condition parameters;damage classification capabilities;data normalization;detection capability;environmental and operational conditions clustering;feature extraction;hypothesis testing;machine learning methods;operational wind turbine system;receiver operating characteristic curves;three-tier modular structural health monitoring framework","","1","","25","","20160712","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Big data analytics in healthcare: A survey approach","D. Ramesh; P. Suraj; L. Saini","Department of Computer Science and Engineering, Indian School of Mines, Dhanbad, Jharkhand - 826004, India","2016 International Conference on Microelectronics, Computing and Communications (MicroCom)","20160728","2016","","","1","6","The development of the concept of business intelligence and analysis has emphasized the importance of the collection, integration, processing of data and reporting of underlying knowledge and how this knowledge can help to make more appropriate business decisions, acquire a better understanding of market behaviors and trends. Tremendous growth of the data has enabled us to uncover the hidden knowledge from data. We can use the Big Data analysis for effective decision making in healthcare domain using the existing machine learning algorithms with some modification to it This paper summarizes the role of Big Data analysis in healthcare and various shortcomings of traditional machine learning algorithms.","","Electronic:978-1-4673-6621-2; POD:978-1-4673-6622-9","10.1109/MicroCom.2016.7522520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7522520","Big Data;Healthcare;Machine Learning","Big data;Classification algorithms;Data mining;Decision trees;Machine learning algorithms;Medical services;Support vector machines","Big Data;competitive intelligence;data analysis;decision making;health care;learning (artificial intelligence)","Big Data analytics;business intelligence;decision making;health care;machine learning algorithm","","","","","","","23-25 Jan. 2016","","IEEE","IEEE Conference Publications"
"An Automated Aero-Engine Thrust Detecting Method Based on Sound Recognition","T. Teng; Z. Zhihua","Nat. Key Lab. of Sci. & Technol. on Vessel Integrated Power Syst., Naval Univ. of Eng., Wuhan, China","2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)","20160721","2015","","","565","569","In order to confirm the aero-engine thrust before a carrier aircraft is launched, an automated aero-engine thrust detecting method based on sound recognition has been presented. Using the flight simulation software, it is possible to obtain an aero-engine's sound signal which can be divided into sections and put into the frequency domain by using FFT (Fast Fourier Transform). A 3-layer BP (Back Propagation) neural network is introduced to classify the spectrum of sound signal sections. In training the network, the L-BFGS algorithm is used to optimize the network parameters to make the accuracy of the network up to 99% in terms of test data. The result proves the algorithm to be effective. In practical application, the decision logic for 3 continuous sections is used to make the misjudgment rate for the launching thrust less than one millionth. The automated aero-engine thrust detecting method based on sound recognition can be adopted for a real-time detection of the aero-engine thrust, thereby replacing the current artificial confirmation methods of engine thrust to increase the efficiency and reliability of carrier aircraft launch.","","Electronic:978-1-4673-7211-4; POD:978-1-4673-7212-1","10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518292","BP neural network;automated aero-engine thrust detection;decision logic;machine learning","Aerospace simulation;Aircraft;Aircraft propulsion;Engines;Neural networks;Software;Training","acoustic signal detection;aerospace computing;aerospace engines;backpropagation;fast Fourier transforms;frequency-domain analysis;neural nets;signal classification","3-layer BP neural network;3-layer back propagation neural network;FFT;automated aero-engine thrust detecting method;fast Fourier transform;flight simulation software;frequency domain;sound recognition;sound signal section spectrum classification","","","","","","","10-14 Aug. 2015","","IEEE","IEEE Conference Publications"
"Machine Learned Replacement of N-Labels for Basecalled Sequences in DNA Barcoding","E. Ma; S. Ratnasingham; S. Kremer","School of Computer Science, University of Guelph, Guelph, Ontario, Canada (e-mail: ema@uoguelph.ca)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2017","PP","99","1","1","This study presents a machine learning method that increases the number of identified bases in Sanger Sequencing. The system post-processes a KB basecalled chromatogram. It selects a recoverable subset of N-labels in the KB-called chromatogram to replace with basecalls (A,C,G,T). An N-label correction is defined given an additional read of the same sequence, and a human finished sequence. Corrections are added to the dataset when an alignment determines the additional read and human agree on the identity of the N-label. KB must also rate the replacement with quality value of > 60 in the additional read. Corrections are only available during system training. Developing the system, nearly 850 000 N-labels are obtained from Barcode of Life Datasystems, the premier database of genetic markers called DNA Barcodes. Increasing the number of correct bases improves reference sequence reliability, increases sequence identification accuracy, and assures analysis correctness. Keeping with barcoding standards, our system maintains an error rate of < 1%. Our system only applies corrections when it estimates low rate of error. Tested on this data, our automation selects and recovers: 79% of N-labels from COI (animal barcode); 80% from matK and rbcL (plant barcodes); and 58% from non-protein-coding sequences (across eukaryotes).","1545-5963;15455963","","10.1109/TCBB.2016.2598752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542173","Bioinformatics (genome or protein) databases;Biology and genetics;Decision support;Machine learning;Neural nets","DNA;Error analysis;Sequential analysis;Support vector machines;Training","","","","","","","","20160811","","","IEEE","IEEE Early Access Articles"
"GEML: Evolutionary unsupervised and semi-supervised learning of multi-class classification with Grammatical Evolution","J. M. Fitzgerald; R. M. A. Azad; C. Ryan","Biocomputing and Developmental Systems Group, University of Limerick, Ireland","2015 7th International Joint Conference on Computational Intelligence (IJCCI)","20160804","2015","1","","83","94","This paper introduces a novel evolutionary approach which can be applied to supervised, semi-supervised and unsupervised learning tasks. The method, Grammatical Evolution Machine Learning (GEML) adapts machine learning concepts from decision tree learning and clustering methods, and integrates these into a Grammatical Evolution framework. With minor adaptations to the objective function the system can be trivially modified to work with the conceptually different paradigms of supervised, semi-supervised and unsupervised learning. The framework generates human readable solutions which explain the mechanics behind the classification decisions, offering a significant advantage over existing paradigms for unsupervised and semi-supervised learning. GEML is studied on a range of multi-class classification problems and is shown to be competitive with several state of the art multi-class classification algorithms.","","Electronic:978-9-8975-8165-6; POD:978-1-5090-1968-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529309","Evolutionary Computation;Grammatical Evolution;Machine Learning;Multi-class Classification;Semi-supervised Learning;Unsupervised Learning","Clustering algorithms;Clustering methods;Decision trees;Evolution (biology);Semisupervised learning;Supervised learning;Unsupervised learning","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Sentiment analysis of top colleges in India using Twitter data","N. Mamgain; E. Mehta; A. Mittal; G. Bhatt","Department of Computer Science, Graphic Era University, Dehradun, India","2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT)","20160718","2016","","","525","530","In today's world, opinions and reviews accessible to us are one of the most critical factors in formulating our views and influencing the success of a brand, product or service. With the advent and growth of social media in the world, stakeholders often take to expressing their opinions on popular social media, namely Twitter. While Twitter data is extremely informative, it presents a challenge for analysis because of its humongous and disorganized nature. This paper is a thorough effort to dive into the novel domain of performing sentiment analysis of people's opinions regarding top colleges in India. Besides taking additional preprocessing measures like the expansion of net lingo and removal of duplicate tweets, a probabilistic model based on Bayes' theorem was used for spelling correction, which is overlooked in other research studies. This paper also highlights a comparison between the results obtained by exploiting the following machine learning algorithms: Naïve Bayes and Support Vector Machine and an Artificial Neural Network model: Multilayer Perceptron. Furthermore, a contrast has been presented between four different kernels of SVM: RBF, linear, polynomial and sigmoid.","","Electronic:978-1-5090-0082-1; POD:978-1-5090-0083-8","10.1109/ICCTICT.2016.7514636","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514636","Machine Learning;Natural Language Processing;Neural Network;Opinion Mining;Sentiment Analysis;Twitter","Dictionaries;Kernel;Machine learning algorithms;Neural networks;Sentiment analysis;Support vector machines;Twitter","Internet;multilayer perceptrons;social networking (online);support vector machines","Bayes theorem;India;Naïve Bayes;Twitter data;artificial neural network model;duplicate tweets;multilayer perceptron;probabilistic model;sentiment analysis;social media;spelling correction;support vector machine","","1","","","","","11-13 March 2016","","IEEE","IEEE Conference Publications"
"Taiga: performance optimization of the C4.5 decision tree construction algorithm","Y. Yang; W. Chen","Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China","Tsinghua Science and Technology","20160811","2016","21","4","415","425","Classification is an important machine learning problem, and decision tree construction algorithms are an important class of solutions to this problem. RainForest is a scalable way to implement decision tree construction algorithms. It consists of several algorithms, of which the best one is a hybrid between a traditional recursive implementation and an iterative implementation which uses more memory but involves less write operations. We propose an optimized algorithm inspired by RainForest. By using a more sophisticated switching criterion between the two algorithms, we are able to get a performance gain even when all statistical information fits in memory. Evaluations show that our method can achieve a performance boost of 2.8 times in average than the traditional recursive implementation.","","","10.1109/TST.2016.7536719","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536719","C4.5; RainForest; decision trees; machine learning; performance optimization","Algorithm design and analysis;Arrays;Decision trees;Machine learning algorithms;Optimization;Training","","","","","","","","","Aug. 2016","","TUP","TUP Journals & Magazines"
"A Novel Method for Seizure Detection in Intracranial Eeg Recordings","M. Javed; A. Akhtar; I. Ahmed; R. Faisal","Dept. of Comput. Eng., Jamia Millia Islamia, New Delhi, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","237","241","Nearly 1 out of every 100 person on the planet is afflicted to Epilepsy, which is characterized by the occurrence of spontaneous seizures[8]. A victim maybe be given sufficiently high dose of anticonvulsant medication, in order to prevent seizures, but they may suffer from side effects. In 20-40% of cases with epilepsy, medication is not effective, even after surgical removal of brain tissues that cause epilepsy, many continue to still experience unprompted seizures. In spite of the fact that seizures occur sporadically, the patients suffer from persistent anxiety, due to possibility of a seizure occurring. The potential to help the patients in leading a more normal life can be done with the help of Seizure forecasting systems. If we are able to predict seizures as early as possible then we have the chance of effectively aborting the seizure using responsive neurostimulation. However if we fail to detect the seizure in its early stages then it becomes very hard to abort seizures. This model aims to create a suitable model to detect the seizure in its early stages so that proper actions can be taken.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546090","eeg;intercranial;machine learning;random forest","Brain modeling;Correlation;Dogs;Electroencephalography;Epilepsy;Medical diagnostic imaging;Medical treatment","electroencephalography;medical disorders;medical information systems;medical signal processing;neuromuscular stimulation","anxiety;epilepsy;intracranial EEG recordings;responsive neurostimulation;seizure detection;seizure forecasting systems;seizure prediction;seizure prevention","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"A genetic algorithm for training recognizers of latent abnormal behavior of dynamic systems","V. Shcherbinin; V. Kostenko","Department of Computational Mathematics and Cybernetics, Moscow State University, Russia","2015 7th International Joint Conference on Computational Intelligence (IJCCI)","20160804","2015","1","","358","365","We consider the problem of automatic construction of algorithms for recognition of abnormal behavior segments in phase trajectories of dynamic systems. The recognition algorithm is trained on a set of trajectories containing normal and abnormal behavior of the system. The exact position of segments corresponding to abnormal behavior in the trajectories of the training set is unknown. To construct recognition algorithm, we use axiomatic approach to abnormal behavior recognition. In this paper we propose a novel two-stage training algorithm which uses ideas of unsupervised learning and evolutonary computation. The results of experimental evaluation of the proposed algorithm and its variations on synthetic data show statistically significant increase in recognition quality for the recognizers constructed by the proposed algorithm compared to the existing training algorithm.","","Electronic:978-9-8975-8165-6; POD:978-1-5090-1968-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529346","Abnormal behavior;Algebraic Approach;Axiomatic Approach;Clustering;Dynamic System;Genetic Algorithm;Machine Learning;Supervised Learning;Training Set;Unsupervised Learning","Heuristic algorithms;Linear programming;Nonlinear distortion;Sensors;Training;Trajectory","","","","","","","","","12-14 Nov. 2015","","IEEE","IEEE Conference Publications"
"Hairstyle recommendation system for women","W. Sunhem; K. Pasupa; P. Jansiripitikul","Faculty of Information Technology, King Mongkuts Institute of Technology Ladkrabang, Bangkok 10520, Thailand","2016 Fifth ICT International Student Project Conference (ICT-ISPC)","20160725","2016","","","166","169","A perfect hairstyle enhanced anyone's self-confidence, especially women. However, in order to choose a good hairstyle, one was limited to rely on knowledge of a beauty expert. This paper presented a hairstyle recommendation system for women based on hairstyle experts' knowledge and a face shape classification scheme that the authors devised in a previous study. The system showed a user's face with a recommended or not recommended hairstyle on a monitor.","","CD-ROM:978-1-5090-1123-0; Electronic:978-1-5090-1125-4; POD:978-1-5090-1126-1","10.1109/ICT-ISPC.2016.7519262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519262","face shape classification;hairstyle recommendation system;machine learning","Face;Feature extraction;Monitoring;Presses;Shape;Support vector machines;Tutorials","face recognition;humanities;image classification;recommender systems;shape recognition","face shape classification scheme;hairstyle experts knowledge;hairstyle recommendation system;women","","","","","","","27-28 May 2016","","IEEE","IEEE Conference Publications"
"Sequence Prediction of Driving Behavior Using Double Articulation Analyzer","T. Taniguchi; S. Nagasaka; K. Hitomi; N. P. Chandrasiri; T. Bando; K. Takenaka","Department of Human and Computer Intelligence, Ritsumeikan University, Kusatsu, Japan","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20160816","2016","46","9","1300","1313","A sequence prediction method for driving behavior data is proposed in this paper. The proposed method can predict a longer latent state sequence of driving behavior data than conventional sequence prediction methods. The proposed method is derived by focusing on the double articulation structure latently embedded in driving behavior data. The double articulation structure is a two-layer hierarchical structure originally found in spoken language, i.e., a sentence is a sequence of words and a word is a sequence of letters. Analogously, we assume that driving behavior data comprise a sequence of driving words and a driving word is a sequence of driving letters. The sequence prediction method is obtained by extending a nonparametric Bayesian unsupervised morphological analyzer using a nested Pitman-Yor language model (NPYLM), which was originally proposed in the natural language processing field. This extension allows the proposed method to analyze incomplete sequences of latent states of driving behavior and to predict subsequent latent states on the basis of a maximum a posteriori criterion. The extension requires a marginalization technique over an infinite number of possible driving words. We derived such a technique on the basis of several characteristics of the NPYLM. We evaluated this proposed sequence prediction method using three types of data: 1) synthetic data; 2) data from test drives around a driving course at a factory; and 3) data from drives on a public thoroughfare. The results showed that the proposed method made better long-term predictions than did the previous methods.","2168-2216;21682216","","10.1109/TSMC.2015.2465933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214310","Bayesian nonparametrics;driving behavior data;machine learning;prediction","Context;Data models;Hidden Markov models;Predictive models;Time series analysis;Vehicles","Bayes methods;behavioural sciences computing;driver information systems;embedded systems;maximum likelihood estimation;natural language processing","NPYLM;double articulation analyzer;double articulation structure;driving behavior data;driving letters;driving word;latent state sequence;maximum-a-posteriori criterion;natural language processing;nested Pitman-Yor language model;nonparametric Bayesian unsupervised morphological analyzer;sequence prediction method;two-layer hierarchical structure","","2","","","","20150820","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Incorporating learning modules improves aspects of resilience of supervisory cyber-physical systems","P. Kannappan; K. Karydis; H. G. Tanner; A. Jardine; J. Heinz","Department of Mechanical Engineering, University of Delaware, Newark, DE 19716 USA","2016 24th Mediterranean Conference on Control and Automation (MED)","20160808","2016","","","996","1001","The paper demonstrates that aspects of resilience of supervisory Cyber-Physical Systems (CPSs) can be improved through the inclusion of appropriate learning modules in the subordinate autonomous agents. During normal operation, individual agents keep track of their supervisor's commands and utilize the learning module, based on Grammatical Inference, to learn aspects of the organizational structure of the general system and role assignments. It is shown that in cases that the supervisor fails or communication to subordinates is disrupted, these agents are able to recover normalcy of operations. Guaranteeing normalcy recovery in supervisory CPSs is critical in cases of a catastrophic failure or malicious attack.","","Electronic:978-1-4673-8345-5; POD:978-1-4673-8347-9","10.1109/MED.2016.7535868","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7535868","Cyber-Physical Systems;Grammatical Inference;Machine Learning;Resilience","Automata;Cyber-physical systems;Electronic mail;Formal languages;Grammar;Resilience;Synchronization","SCADA systems;cyber-physical systems;fault tolerant control;inference mechanisms;learning (artificial intelligence)","CPS<sub>S</sub>;SCADA;grammatical inference;learning modules;normalcy recovery;resilience;subordinate autonomous agents;supervisory control and data acquisition;supervisory cyber-physical systems","","1","","","","","21-24 June 2016","","IEEE","IEEE Conference Publications"
"A process for human-aided Multi-Entity Bayesian Networks learning in Predictive Situation Awareness","C. Young Park; K. Blackmond Laskey; P. C. G. Costa; S. Matsumoto","The Sensor Fusion Lab & Center of Excellence in C4I, George Mason University, MS 4B5, Fairfax, VA 22030-4444 U.S.A.","2016 19th International Conference on Information Fusion (FUSION)","20160804","2016","","","2116","2124","Predictive Situation Awareness (PSAW) is the ability to estimate and predict aspects of a temporally evolving situation. PSAW systems reason about complex and uncertain situations involving multiple targets observed by multiple sensors at different times. Multi-Entity Bayesian Networks (MEBN) are rich enough to represent and reason about uncertainty in complex, knowledge-rich domains, and have been applied to representation and reasoning for PSAW. To overcome a labor-intensive and insufficiently agile process for manual MEBN modeling by a domain expert, MEBN machine learning was developed. Although technologies for machine learning have improved dramatically, the necessary capabilities to build a MEBN model efficiently do not yet exist. The search space for components of an MEBN model is too large and complex to investigate all possible structures, variables, and parameters. For this reason, this paper proposes a method which relies partially on expert knowledge and insight to reduce the search space. The proposed method, a process for Human-aided MEBN learning in PSAW, is a framework to develop a MEBN model from the domain expert's knowledge combined with relational data. This paper presents the process for Human-aided MEBN learning in PSAW and a case study to evaluate the process on development of a defense system in PSAW.","","Electronic:978-0-9964-5274-8; POD:978-1-5090-2012-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528144","Bayesian Networks;Data Fusion;Human-aided Machine Learning;Modeling Process;Multi-Entity Bayesian Networks;Predictive Situation Awareness;Situation Awareness","Bayes methods;Context;Object oriented modeling;Probabilistic logic;Surface acoustic waves;Uncertainty;Vehicles","belief networks;learning (artificial intelligence)","MEBN machine learning;MEBN modeling;PSAW systems;agile process;defense system;domain expert;human-aided MEBN learning;human-aided multi-entity Bayesian networks learning;knowledge-rich domains;multiple sensors;predictive situation awareness;relational data;search space;uncertain situations","","","","","","","5-8 July 2016","","IEEE","IEEE Conference Publications"
"Analyzing and assessing the security-related defects","A. Bansal; R. Malhotra; K. Raje","Department of Information Technology, Netaji Subhas Institute of Technology, Delhi University, Delhi-110078","2016 International Conference on Innovation and Challenges in Cyber Security (ICICCS-INBUSH)","20160815","2016","","","21","25","The use of the Internet has become an integral part of everyone's life. Due to this, the introduction of virus and other malicious crackers is increasing everyday. This in turn leads to the introduction of defects which adversely affect the security. Thus, protecting vital information in this cyber world is not an easy task. We need to deal with security related defects to ensure failure free and smooth functioning of the software. Thus, in this paper, we intend to study and analyze various aspects of security-related defects by analyzing the defect reports available in various open-source software repositories. Besides this, prediction models can also be constructed which can be used by researchers and practitioners to predict various aspects of security - related defects. Such prediction models are especially beneficial for large-scale systems, where testing experts need to focus their attention and resources to the problem areas of the system under development. Thus, application of software prediction models in the early phases of the software life cycle contributes to efficient defect removal and results in delivering more reliable and better quality software products. Empirical studies lack the use of proper research methodology and thus result in reporting inconsistent results. This study will review the sequence of steps followed in the research process for carrying empirical and replicated studies. The steps include (a) literature survey and definition of variables (b) data collection (c) report findings using statistical and machine learning techniques (d) analyzing performance measures for evaluating the performance of the predicted models and (e) interpretation of the obtained results for developing a software prediction model. These steps are explained with the help of experimental public domain data set. In addition, the paper provides an overview of repositories for mining software engineering data, tools for analyzing this data and various categorie- of machine learning methods. It also discusses existing research avenues and provides future research directions in this area.","","Electronic:978-1-5090-2084-3; POD:978-1-5090-2085-0","10.1109/ICICCS.2016.7542332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542332","Empirical Validation;Machine Learning;Security Vulnerabilities;Security-Related Defects;Statistical Methods","Analytical models;Data models;Predictive models;Security;Software engineering;Software quality","data mining;learning (artificial intelligence);safety-critical software;software performance evaluation;software quality","data analyzing tools;data collection;information protection;large-scale systems;machine learning technique;open-source software repositories;performance measure analysis;public domain data set;security related defects;security-related defect analysis;security-related defect assess;software engineering data mining;software life cycle;software prediction models;software product quality;statistical technique","","","","","","","3-5 Feb. 2016","","IEEE","IEEE Conference Publications"
"Sequence Prediction With Sparse Distributed Hyperdimensional Coding Applied to the Analysis of Mobile Phone Use Patterns","O. J. Räsänen; J. P. Saarinen","Department of Signal Processing and Acoustics, Aalto University, Aalto, Finland","IEEE Transactions on Neural Networks and Learning Systems","20160815","2016","27","9","1878","1889","Modeling and prediction of temporal sequences is central to many signal processing and machine learning applications. Prediction based on sequence history is typically performed using parametric models, such as fixed-order Markov chains (n-grams), approximations of high-order Markov processes, such as mixed-order Markov models or mixtures of lagged bigram models, or with other machine learning techniques. This paper presents a method for sequence prediction based on sparse hyperdimensional coding of the sequence structure and describes how higher order temporal structures can be utilized in sparse coding in a balanced manner. The method is purely incremental, allowing real-time online learning and prediction with limited computational resources. Experiments with prediction of mobile phone use patterns, including the prediction of the next launched application, the next GPS location of the user, and the next artist played with the phone media player, reveal that the proposed method is able to capture the relevant variable-order structure from the sequences. In comparison with the n-grams and the mixed-order Markov models, the sparse hyperdimensional predictor clearly outperforms its peers in terms of unweighted average recall and achieves an equal level of weighted average recall as the mixed-order Markov chain but without the batch training of the mixed-order model.","2162-237X;2162237X","","10.1109/TNNLS.2015.2462721","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194819","Machine learning;prediction methods;real-time systems;sequences;time series analysis","Context;Data models;Encoding;History;Markov processes;Predictive models;Standards","Markov processes;approximation theory;human factors;learning (artificial intelligence);mobile computing;mobile radio","fixed-order Markov chains;high-order Markov process approximation;higher order temporal structures;lagged bigram models;machine learning;mixed-order Markov models;mobile phone use pattern analysis;n-grams;parametric models;real-time online learning;sequence history;sequence structure;signal processing;sparse distributed hyperdimensional coding;sparse hyperdimensional coding;sparse hyperdimensional predictor;temporal sequence modeling;temporal sequence prediction","","0","","45","","20150813","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"ABIS: A prototype of Android Botnet Identification System","C. Tansettanakorn; S. Thongprasit; S. Thamkongka; V. Visoottiviseth","Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand","2016 Fifth ICT International Student Project Conference (ICT-ISPC)","20160725","2016","","","1","5","According to the advanced wireless technology in nowadays, most people mainly use their mobile phones as an essential tool. At the same time, threats of the mobile phones such as virus, botnets, and other malware are also increasing as well. However, most users have the limited of knowledge about mobile threats. Therefore, we would like to reduce the number of botnet-infected mobile phones before the users install an application on their phones. We develop a system called ABIS (Android Botnet Identification System) to check Android applications whether they are possibly be malware or not. In order to identify the Android botnets, our system learns the characteristics of each Android botnet family from the dataset provided by the University of New Brunswick [1]. We analyze the Android APK files, extract important features, and find an appropriate machine learning technique. As the results, we found that our system can classify the Android botnets with about 96.9% of recall.","","CD-ROM:978-1-5090-1123-0; Electronic:978-1-5090-1125-4; POD:978-1-5090-1126-1","10.1109/ICT-ISPC.2016.7519221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519221","Android;botnet;machine learning;malware identification","Androids;Humanoid robots;Mobile communication;Servers","Android (operating system);computer viruses;learning (artificial intelligence);smart phones","ABIS;Android APK files;Android botnet identification system;University of New Brunswick;botnet-infected mobile phones;feature extraction;machine learning technique;malware;mobile threats;virus","","","","","","","27-28 May 2016","","IEEE","IEEE Conference Publications"
"An Efficient Framework for 2-Dimensional Gesture Based Telugu Character Recognition","C. Nagadeepa; N. Balaji; V. Padmaja","Dept. of ECE, VNR-VJIET, Hyderabad, India","2016 IEEE 6th International Conference on Advanced Computing (IACC)","20160818","2016","","","446","450","Gesture identification plays a vital role in today's human-computer interaction. In this paper, we proposed a sensor based gesture recognition system which makes the teacher to write in Telugu language on digital board from anywhere within the class room. Various classification algorithms k-Nearest Neighbor (KNN), Support Vector Machine (SVM) and Decision tree are individually used for hand gesture based Telugu character recognition. Here, we assess the performance of three classification algorithms which are compared with 16 different Telugu character vowel gestures. Each gesture is collected by using an inertial sensor based embedded device. The dataset contains 16 gestures, each gesture repeated for eleven times from three different people. The gesture identification accuracy for k-Nearest Neighbor classification is 97.2%, SVM is 92.8% and Decision tree is 86.5%.","","Electronic:978-1-4673-8286-1; POD:978-1-4673-8287-8","10.1109/IACC.2016.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544878","Decision tree;Gesture recognition;Machine learning;SVM;Telugu character gesture dataset;inertial sensor;k-Nearest Neighbor","Accelerometers;Character recognition;Classification algorithms;Decision trees;Feature extraction;Gesture recognition;Support vector machines","character recognition;gesture recognition;human computer interaction;image classification;natural language processing;support vector machines;trees (mathematics)","2-dimensional gesture based Telugu character recognition;KNN;SVM;Telugu character vowel gestures;Telugu language;class room;classification algorithm;decision tree;digital board;gesture identification;hand gesture based Telugu character recognition;human-computer interaction;inertial sensor based embedded device;k-nearest neighbor classification;sensor based gesture recognition system;support vector machine","","","","","","","27-28 Feb. 2016","","IEEE","IEEE Conference Publications"
"Fast H.264/AVC to HEVC transcoder based on data mining and decision trees","G. Correa; L. Agostini; L. A. da Silva Cruz","Group of Architectures and Integrated Circuits, Federal University of Pelotas, Pelotas, Brasil","2016 IEEE International Symposium on Circuits and Systems (ISCAS)","20160811","2016","","","2539","2542","High Efficiency Video Coding (HEVC) is gradually replacing its predecessor, the H.264/AVC standard, as the state-of-the-art technology for video compression. However, H.264/AVC has dominated the market for over a decade, so that there is an enormous amount of legacy content that must be migrated. This paper proposes a fast transcoder based on an extensive data mining process on H.264/AVC decoding attributes. The data mining allowed identifying relevant information from the H.264/AVC decoding process, which was conveyed to the C4.5 machine learning algorithm to build a set of decision trees that simplify the complex Coding Unit (CU) size decision in HEVC. Experimental results have shown an average reduction of 44% in the transcoding time, with a small bit rate increase of 1.67%. These results outperform any previous works available in the literature.","","Electronic:978-1-4799-5341-7; POD:978-1-4799-5342-4; USB:978-1-4799-5340-0","10.1109/ISCAS.2016.7539110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539110","H.264/AVC;HEVC;complexity reduction;data mining;machine learning;transcoding;video coding","Complexity theory;Copper;Data mining;Decision trees;Decoding;Transcoding","data compression;data mining;decision trees;learning (artificial intelligence);transcoding;video coding","AVC decoding process;C4.5 machine learning algorithm;H.264 decoding process;HEVC transcoder;complex coding unit size decision;data mining process;decision trees;high efficiency video coding;size decision reduction;video compression","","","","","","","22-25 May 2016","","IEEE","IEEE Conference Publications"
"Comparative analysis of automated classifiers applied to volcano event identification","R. Lara-Cueva; E. V. Carrera; J. F. Morejon; D. Benitez","Grupo de Investigacion en Sistemas Inteligentes (WiCOM-Energy) and Ad Hoc Networks Research Center (CIRAD), Electrical and Electronic Department, Universidad de las Fuerzas Armadas ESPE, Sangolqui-Ecuador, 171-5-231B","2016 IEEE Colombian Conference on Communications and Computing (COLCOM)","20160721","2016","","","1","6","The correct classification of several types of volcanic events can be used to determine the intrinsic behavior of a volcano. This information could be useful to provide an early alarm in the case of imminent volcanic activity. Therefore, finding an efficient algorithm capable of identifying seismic activity can be beneficial for this purpose. In such sense, this work evaluates several machine learning techniques, that have been previously applied to classify seismic events, taking into account quality and performance parameters. In order to test the algorithms, a seismic database from the Cotopaxi volcano in Ecuador was used. This database was collected by the Geophysical Institute at Escuela Politécnica Nacional between January and June of 2010. The analysis was focused in two major types of seismic events: long period and volcano tectonic. For each event, 79 key features in time and frequency domain were extracted. These features were used to train 3 well known classifiers: k-nearest neighbors, decision trees and neural networks. Finally, a feature selection technique was employed to find those features with greater impact improving the classifier performance. Our approach allow us to reach an accuracy of 98% by identifying 3 main features and using the k-NN classifier.","","Electronic:978-1-5090-1084-4; POD:978-1-5090-1085-1","10.1109/ColComCon.2016.7516377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516377","Volcanic events;feature selection;machine learning;signal classification","Artificial neural networks;Classification algorithms;Databases;Feature extraction;Machine learning algorithms;Monitoring;Volcanoes","decision trees;feature selection;frequency-domain analysis;learning (artificial intelligence);neural nets;time-domain analysis;volcanology","automated classifiers;decision trees;feature extraction;feature selection technique;frequency domain;k-NN classifier;k-nearest neighbors;machine learning techniques;neural networks;time domain;volcano event identification","","","","","","","27-29 April 2016","","IEEE","IEEE Conference Publications"
"Market model and optimal pricing scheme of big data and Internet of Things (IoT)","D. Niyato; M. A. Alsheikh; P. Wang; D. I. Kim; Z. Han","School of Computer Engineering, Nanyang Technological University (NTU), Singapore","2016 IEEE International Conference on Communications (ICC)","20160714","2016","","","1","6","Big data has been emerging as a new approach in utilizing large datasets to optimize complex system operations. Big data is fueled with Internet-of-Things (IoT) services that generate immense sensory data from numerous sensors and devices. While most current research focus of big data is on machine learning and resource management design, the economic modeling and analysis have been largely overlooked. This paper thus investigates the big data market model and optimal pricing scheme. We first study the utility of data from the data science perspective, i.e., using the machine learning methods. We then introduce the market model and develop an optimal pricing scheme afterward. The case study shows clearly the suitability of the proposed data utility functions. The numerical examples demonstrate that big data and IoT service provider can achieve the maximum profit through the proposed market model.","","Electronic:978-1-4799-6664-6; POD:978-1-4799-6665-3","10.1109/ICC.2016.7510922","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7510922","Machine learning;data-as-a-service;market;pricing","Big data;Data mining;Data models;Internet of things;Machine learning algorithms;Pricing;Sensors","Big Data;Internet of Things;learning (artificial intelligence);pricing;profitability","Internet of things;IoT;big data market model;complex system operations;data science perspective;data utility functions;economic modeling;machine learning;maximum profit;optimal pricing scheme;resource management design;sensory data","","1","","","","","22-27 May 2016","","IEEE","IEEE Conference Publications"
"Investigation of website classification methods based on data mining techniques","A. N. Rukavitsyn; M. S. Kupriyanov; A. V. Shorov; I. V. Petukhov","Faculty of Computer Science and Technology, Saint Petersburg Electrotechnical University &#8220;LETI&#8221;, Russia","2016 XIX IEEE International Conference on Soft Computing and Measurements (SCM)","20160725","2016","","","333","336","The article describes the development of a Web page classification model using data mining techniques. The model allows to perform a multi-label soft classification of Web pages. In order to develop this classification model we combined new, with already existing methods. The experiments show an increased classification precision.","","Electronic:978-1-4673-8919-8; POD:978-1-4673-8920-4","10.1109/SCM.2016.7519773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519773","data mining;machine learning;text processing;web page classification","Classification algorithms;Computational modeling;Data mining;Internet;Mathematical model;Training;Web pages","Web sites;data mining;pattern classification;text analysis","Web page classification model;Web site classification method;data mining techniques;multilabel soft classification","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Text classification: The case of multiple labels","V. Bobicev","Applied Informatics Department, Technical University of Moldova, Computers, Informatics and Microelectronics faculty, Chi&#x015F;in&#x0103;u, Moldova","2016 International Conference on Communications (COMM)","20160804","2016","","","39","42","Analysis of subjectivity is the actively developed direction of research in text mining. The paper presents machine learning experiments on classification of sentiments in forum texts. We explore the difficult task of classification when texts are labeled by several sentiment labels and in this condition we reach the average F-measure equal to 0.805.","","DVD:978-1-4673-8196-3; Electronic:978-1-4673-8197-0; POD:978-1-4673-8198-7","10.1109/ICComm.2016.7528314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528314","machine learning;multi-label classification;natural language processing;sentiment analysis;text classification","Context;Machine learning algorithms;Message systems;Niobium;Support vector machines;Tagging;Twitter","data mining;learning (artificial intelligence);pattern classification;sentiment analysis","forum text classification;machine learning;natural language processing;sentiment classification;sentiment labels;subjectivity analysis;text mining","","","","","","","9-10 June 2016","","IEEE","IEEE Conference Publications"
"Navigation Method for Teleoperated Single-Port Access Surgery With Soft Tissue Interaction Detection","C. J. Perez del Pulgar; I. Garcia-Morales; I. Rivas Blanco; V. F. Munoz","The authors are with the System Engineering and Automation Department, Universidad de M&#x00E1;laga, Andaluc&#x00ED;a Tech, M&#x00E1;laga 29071, Spain (e-mail: carlosperez@uma.es).","IEEE Systems Journal","","2016","PP","99","1","12","In recent years, single-port access surgery has been on the cutting edge of robotic research. This technique entails the insertion of several instruments with articulated distal tips through a common multiport trocar. When these instruments are handled by external manipulators, a kinematic constraint arises because all the movements have to be performed while taking into account the insertion point, which must be known. A variety of techniques has been used to identify this point using multiaxial force–torque sensors placed on the robot end effector. However, because this kind of sensor provides information regarding exerted forces throughout the instrument, it is difficult to separate abdominal and internal soft tissue interaction forces. Therefore, the aim of this work was to develop a navigation method to teleoperate two manipulators that handle surgical instruments for single-port access surgery. The method can move both instruments inside the abdominal cavity, taking into consideration the insertion point. This point is estimated using the measured force and torque throughout the instruments. To avoid estimation error due to the interaction of instruments with soft tissue inside the abdomen, hidden Markov models have been used to encode the surgeon's gestures and detect the interaction. Finally, a set of experiments has been carried out to validate the proposed method.","1932-8184;19328184","","10.1109/JSYST.2016.2570118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514247","Force control;machine learning;medical robotics;robot control;robot motion","Abdomen;Biological tissues;Instruments;Manipulators;Navigation;Surgery","","","","","","","","20160715","","","IEEE","IEEE Early Access Articles"
"A mobile application of American sign language translation via image processing algorithms","C. M. Jin; Z. Omar; M. H. Jaward","Faculty of Electrical Engineering, Universiti Teknologi Malaysia, 81310 Skudai, Malaysia","2016 IEEE Region 10 Symposium (TENSYMP)","20160725","2016","","","104","109","Due to the relative lack of pervasive sign language usage within our society, deaf and other verbally-challenged people tend to face difficulty in communicating on a daily basis. Our study thus aims to provide research into a sign language translator applied on the smartphone platform, due to its portability and ease of use. In this paper, a novel framework comprising established image processing techniques is proposed to recognise images of several sign language gestures. More specifically, we initially implement Canny edge detection and seeded region growing to segment the hand gesture from its background. Feature points are then extracted with Speeded Up Robust Features (SURF) algorithm, whose features are derived through Bag of Features (BoF). Support Vector Machine (SVM) is subsequently applied to classify our gesture image dataset; where the trained dataset is used to recognize future sign language gesture inputs. The proposed framework has been successfully implemented on smartphone platforms, and experimental results show that it is able to recognize and translate 16 different American Sign Language gestures with an overall accuracy of 97.13%.","","Electronic:978-1-5090-0931-2; POD:978-1-5090-0932-9","10.1109/TENCONSpring.2016.7519386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519386","Computer Vision;Gesture Recognition;Image Processing;Machine Learning;Sign Language","Assistive technology;Feature extraction;Gesture recognition;Image color analysis;Image edge detection;Image segmentation;Support vector machines","computer vision;edge detection;feature extraction;image classification;image segmentation;language translation;mobile computing;sign language recognition;smart phones;support vector machines","American sign language translation;BoF;Canny edge detection;SURF algorithm;SVM;bag of features;feature point extraction;gesture image classification;hand gesture segmentation;image processing algorithm;mobile application;seeded region growing;smart phone platform;speeded up robust features algorithm;support vector machine","","","","","","","9-11 May 2016","","IEEE","IEEE Conference Publications"
"Computer-Aided Discovery: Toward Scientific Insight Generation with Machine Support","V. Pankratius; J. Li; M. Gowanlock; D. M. Blair; C. Rude; T. Herring; F. Lind; P. J. Erickson; C. Lonsdale","Massachusetts Institute of Technology","IEEE Intelligent Systems","20160718","2016","31","4","3","10","The process of scientific discovery is traditionally assumed to be entirely executed by humans. This article highlights how increasing data volumes and human cognitive limits are challenging this traditional assumption. Relevant examples are found in observational astronomy and geoscience, disciplines that are undergoing transformation due to growing networks of space-based and ground-based sensors. The authors outline how intelligent systems for computer-aided discovery can routinely complement and integrate human scientists in the insight generation loop in scalable ways for next-generation science. The pragmatics of model-based computer-aided discovery systems go beyond feature detection in empirical data to answer fundamental questions, such as how empirical detections fit into hypothesized models and model variants to ease the scientist's work of placing large ensembles of detections into a theoretical context. The authors demonstrate successful applications of this paradigm in several areas, including ionospheric studies, volcanics, astronomy, and planetary landing site identification for spacecraft and robotic missions.","1541-1672;15411672","","10.1109/MIS.2016.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515118","big data;cloud computing;computer-aided discovery;data mining;discovery science;intelligent analytics;intelligent systems;machine learning","Analytical models;Computational modeling;Computer aided analysis;Data models;Global Positioning System;Planets;Space research","cognitive systems;natural sciences computing","data volumes;feature detection;geoscience;ground-based sensors;human cognitive limits;intelligent systems;ionospheric studies;machine support;model-based computer aided discovery systems;next generation science;observational astronomy;planetary landing site identification;robotic missions;scientific discovery;scientific insight generation;space-based sensors;spacecraft;volcanics","","1","","15","","","July-Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Scalable Overlapping Community Detection","I. El-Helw; R. Hofman; W. Li; S. Ahn; M. Welling; H. Bal","Vrije Univ. Amsterdam, Amsterdam, Netherlands","2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","20160804","2016","","","1463","1472","Recent advancements in machine learning algorithms have transformed the data analytics domain and provided innovative solutions to inherently difficult problems. However, training models at scale over large data sets remains a daunting challenge. One such problem is the detection of overlapping communities within graphs. For example, a social network can be modeled as a graph where the vertices and edges represent individuals and their relationships. As opposed to the problem of graph partitioning or clustering, an individual can be part of multiple communities which significantly increases the problem complexity. In this paper, we present and evaluate an efficient parallel and distributed implementation of a Stochastic Gradient Markov Chain Monte Carlo algorithm that solves the overlapping community detection problem. We show that the algorithm can scale and process graphs consisting of billions of edges and tens of millions of vertices on a compute cluster of 65 nodes. To the best of our knowledge, this is the first time that the problem of deducing overlapping communities has been learned for problems of such a large scale.","","Electronic:978-1-5090-3682-0; POD:978-1-5090-3683-7","10.1109/IPDPSW.2016.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530037","Distributed computing;High performance computing;Machine learning;Parallel programming;Performance analysis","Algorithm design and analysis;Clustering algorithms;Electronic mail;Heuristic algorithms;Monte Carlo methods;Parallel processing;Stochastic processes","Markov processes;Monte Carlo methods;data analysis;graph theory;learning (artificial intelligence);parallel processing","data analytics domain;distributed implementation;machine learning algorithms;parallel implementation;scalable overlapping community detection;stochastic gradient Markov chain Monte Carlo algorithm","","1","","","","","23-27 May 2016","","IEEE","IEEE Conference Publications"
"Personal CGPA planning system for undergraduates: Towards achieving the first class CGPA","Yeap Chun Sheng; M. B. Mustafa; S. Alam; S. H. Hamid; A. A. Sani; A. Gani","Department of Software Engineering, Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, Malaysia","2016 Fifth ICT International Student Project Conference (ICT-ISPC)","20160725","2016","","","113","116","Academic qualification is a necessity for an individual to compete in today's competitive environment. Employers' selection criteria of potential candidate are usually based on the grade point average (GPA). Despite a student's intellectual ability, planning is a crucial step in ensuring good GPA. However, many students do not have the necessary skills and time to plan and control their GPA. An automated education planner system will be very helpful to assist the student in aiming for the best CGPA based on their current capabilities. Despite of the existence of course plan systems, students still fail distressingly to achieve their goals. In recent times, educational data mining techniques have been adopted to discover the knowledge of the educational environment and to improve the students' performance. Several techniques which are used in educational data mining are - Artificial Neural Network, Support Vector Machine, naïve Bayesian, Decision tree, etc. This research aims to explore the use of Genetic Algorithm (GA) as an assistive tool for university students to plan and improve their academic performance. The proposed personalized web-based academic planner is developed as an online record storage that keeps all of the students' academic records. Based on the student's current achievement, the system will propose the best path to enable the undergraduates to reach their goals using GA.","","CD-ROM:978-1-5090-1123-0; Electronic:978-1-5090-1125-4; POD:978-1-5090-1126-1","10.1109/ICT-ISPC.2016.7519249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519249","Academic Planner;GPA;Genetic Algorithm;Machine Learning;University Students","","Internet;data mining;educational administrative data processing;genetic algorithms;learning (artificial intelligence)","GA;Web-based academic planner;academic qualification;artificial neural network;automated education planner system;course plan systems;cumulative graded point average;decision tree;educational data mining techniques;educational environment;employers selection criteria;genetic algorithm;naive Bayesian;online record storage;personal CGPA planning system;student assistance;student intellectual ability;student performance;support vector machine","","","","","","","27-28 May 2016","","IEEE","IEEE Conference Publications"
"Adaptive process control and sensor fusion for process analytical technology","N. O' Mahony; T. Murphy; K. Panduru; D. Riordan; J. Walsh","IMAR Technology Gateway, Institute of Technology Tralee, Ireland","2016 27th Irish Signals and Systems Conference (ISSC)","20160804","2016","","","1","6","Increased globalisation and competition are drivers for process analytical technologies (PAT) that enable seamless process control, greater flexibility and cost efficiency in the process industries. This research aims to introduce an integrated process control approach, embedding novel sensors for monitoring in real time the critical control parameters of key processes in the minerals, ceramics, non-ferrous metals, and chemical process industries. The paper will discuss smart sensors, data fusion and process modelling and control in industrial applications with an emphasis on solutions enabling the real-time data analytics of sensor measurements that PAT demands.","","Electronic:978-1-5090-3409-3; POD:978-1-5090-3410-9","10.1109/ISSC.2016.7528449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528449","Machine learning;data fusion;predictive control;process analytical technology","Biological neural networks;Data integration;Industries;Intelligent sensors;Neurons;Process control;Sensor fusion","adaptive control;centralised control;intelligent sensors;process control;sensor fusion","PAT;adaptive process control;data fusion;industrial control;integrated process control approach;process analytical technology;process industries;process modelling;sensor fusion;sensor measurement data analytics;smart sensors","","","","","","","21-22 June 2016","","IEEE","IEEE Conference Publications"
"CSI-based autoencoder classification for Wi-Fi indoor localization","C. Xu; Z. Jia; P. Chen; B. Wang","College of Information Science and Engineering, Northeastern University, NO. 3-11 Wenhua Road Heping District, Shenyang 110819, China","2016 Chinese Control and Decision Conference (CCDC)","20160808","2016","","","6523","6528","Recently, indoor localization problem has drawn a wide range of attention. However, there are few researches that can keep balance between accuracy and expense, and few plans can achieve both device-free and accuracy. To solve this problem, the scheme of CSI-based autoencoder classification for Wi-Fi indoor localization is proposed. Only one wireless router and one computer are placed as signal emitter and receiver respectively. With so few ordinary devices, expenses have been decreased to a large extent. Device-free is achieved by performing localization based on Wi-Fi signal. Channel State Information (CSI) is measured and calculated to decrease the multipath effect, which reaches a higher accuracy. With the use of CSI, a mass of data are obtained. Machine learning including autoencoder and BP network are utilized owing to their advantage of processing mass data. In our experiment, this plan achieves 2-dim localizing with an accuracy of 50 cm.","","CD-ROM:978-1-4673-9713-1; Electronic:978-1-4673-9714-8; POD:978-1-4673-9715-5","10.1109/CCDC.2016.7532172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532172","Autoencoder;Channel State Information;Classification;Indoor Localization;Machine Learning","Antenna measurements;Buildings;Fingerprint recognition;Receiving antennas;Transmitting antennas","backpropagation;encoding;indoor radio;multipath channels;wireless LAN","BP network;CSI-based autoencoder classification;Wi-Fi indoor localization;Wi-Fi signal;channel state information;machine learning;multipath effect;receiver;signal emitter;wireless router","","","","","","","28-30 May 2016","","IEEE","IEEE Conference Publications"
"Validating an Insider Threat Detection System: A Real Scenario Perspective","I. Agrafiotis; A. Erola; J. Happa; M. Goldsmith; S. Creese","Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK","2016 IEEE Security and Privacy Workshops (SPW)","20160804","2016","","","286","295","There exists unequivocal evidence denoting the dire consequences which organisations and governmental institutions face from insider threats. While the in-depth knowledge of the modus operandi that insiders possess provides ground for more sophisticated attacks, organisations are ill-equipped to detect and prevent these from happening. The research community has provided various models and detection systems to address the problem, but the lack of real data due to privacy and ethical issues remains a significant obstacle for validating and designing effective and scalable systems. In this paper, we present the results and our experiences from applying our detection system into a multinational organisation, the approach followed to abide with the ethical and privacy considerations and the lessons learnt on how the validation process refined the system in terms of effectiveness and scalability.","","Electronic:978-1-5090-3690-5; POD:978-1-5090-3691-2","10.1109/SPW.2016.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527781","Insider threat;anomaly detection;machine learning;real world case study","Conferences;Data privacy;Feature extraction;Privacy;Psychology;Scalability;Security","computer crime;data privacy;ethical aspects","ethical issues;insider threat detection system;multinational organisation;privacy issues","","","","","","","22-26 May 2016","","IEEE","IEEE Conference Publications"
"GATE: Classification and clustering of text for semi-vowel/j/-morphophonemic approach","K. S. Reddy; K. Sasanka; S. Prasanna; R. Venkatesan","CSE, SRC-Sastra University, Kumbakonam","2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT)","20160804","2016","","","1","7","In recent years, many successful machine learning applications have been developed. Classification & Clustering is one such. This application is cross-disciplinary, now that it is based on data mining algorithms on the technical side and on graphemes and morphophonemic on the linguistic side. It will thus map the correspondence between grapheme 〈y〉 and related phonemes via morphemes in a given context. The grapheme 〈y〉 is often realized as an approximant /j/ (a consonant phoneme), as in 〈yacht〉 or as vowel / i / as in 〈racy〉, or a diphthong / ai / as in 〈sky〉, etc. The objective, that is to say, of this text analysis is to map the various articulators//phonemic realizations of the grapheme 〈y〉. This experiment will thus help the study the occurrence of 〈y〉 in different positions in words, word initially, finally or elsewhere, as in these examples. The training data (or corpus) chosen for this experimentation is a set of English literary texts [Harry Potter part 1, part 2, The complete works of William Shakespeare By William Shakespeare, The Adventures of Sherlock Holmes By Arthur Conan Doyle, (A Christmas carol) By Charles Dickens's. As for the tools, the alphabet recognizer is used for retrieving information and categorizing the data as noun, adjective, etc. Then, GATE Developer, the Text engineering tool is used to analyze the dataset and to derive the output with statistical data of global distribution 〈y〉 as in all the input documents. This project is particularly relevant because it offers, as will be demonstrated, a solution to problems due to lack of one-to-one correspondence between spelling and pronunciation in English, as for instance, in the context of la- guage pedagogy. Glossary of technical terms (of both linguistics & computing) is appended, now that the paper is inter-disciplinary.","","DVD:978-1-5090-1276-3; Electronic:978-1-5090-1277-0; POD:978-1-5090-1278-7","10.1109/ICCPCT.2016.7530234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530234","Clustering and Classification;GATE;NLP;Text mining;grapheme;machine learning;mapping;morpheme;morphophonemic;phoneme","Classification algorithms;Clustering algorithms;Computers;Logic gates;Pragmatics;Text mining","classification;computational linguistics;data mining;learning (artificial intelligence);pattern clustering;statistical analysis;text analysis","GATE developer;alphabet recognizer;articulator;data mining;graphemes;language pedagogy;machine learning;morphemes;phonemic realization;semivowel/j/-morphophonemic approach;statistical data;text analysis;text classification;text clustering;text engineering tool","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Analyzing and evaluating security features in software requirements","R. Malhotra; A. Chug; A. Hayrapetian; R. Raje","Department of Software Engineering, Delhi Technological University, Shahbad, Bawana, Delhi - 110042, India","2016 International Conference on Innovation and Challenges in Cyber Security (ICICCS-INBUSH)","20160815","2016","","","26","30","Software requirements, for complex projects, often contain specifications of non-functional attributes (e.g., security-related features). The process of analyzing such requirements is laborious and error prone. Due to the inherent free-flowing nature of software requirements, it is tempting to apply Natural Language Processing (NLP) based Machine Learning (ML) techniques for analyzing these documents from the point of view of comprehensiveness and consistency. In this paper, we propose novel semi-automatic methodology that can assess the security requirements of the software system from the perspective of completeness, contradiction, and inconsistency. Security standards introduced by the ISO are used to construct a model for classifying security-based requirements using NLP-based ML techniques. Hence, this approach aims to identify the appropriate structures that underlie software requirement documents. Once such structures are formalized and empirically validated, they will provide guidelines to software organizations for generating comprehensive and unambiguous requirement specification documents as related to security-oriented features. The proposed solution will assist organizations during the early phases of developing secure software and reduce overall development effort and costs.","","Electronic:978-1-5090-2084-3; POD:978-1-5090-2085-0","10.1109/ICICCS.2016.7542334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542334","Concept Graphs;Machine Learning;Natural Language Processing;Quality of Service;Security;Software Requirements","Authentication;Encryption;Natural language processing;Software;Standards;Technological innovation","ISO standards;learning (artificial intelligence);natural language processing;pattern classification;security of data;software engineering","ISO;NLP-based ML techniques;machine learning techniques;natural language processing;secure software development;security feature evaluation;security standards;security-oriented features;semi-automatic methodology;software organizations;software requirement documents;software system security requirements","","","","","","","3-5 Feb. 2016","","IEEE","IEEE Conference Publications"
"Professional Poker players' modeling using data-mining","N. Silva; L. P. Reis","EEUM/DSI - Escola de Engenharia da Universidade do Minho e Centro ALGORITMI, Guimar&#227;es, Portugal","2016 11th Iberian Conference on Information Systems and Technologies (CISTI)","20160728","2016","","","1","6","Poker has been gradually gaining the attention of the scientific community, mostly in researchers on Artificial Intelligence. The main reason is concerned with the fact that Poker provides great challenges to the research in the area. Unlike many other games, poker is a stochastic game of imperfect information, which creates a high amount of possibilities to every state of the game. In this work a different line of thought is followed by trying to create an agent capable of reproducing the way a professional Poker human player plays for all stages in a Texas Hold'em Poker game. For this purpose, a high level data model able to comprehend the maximum of information relevant to every state of the game was built, loaded with data from a database containing millions of plays made by a professional poker players, by using Talend Data Integration. To execute Data mining techniques Weka software package was used. The final results show that it is possible to create a virtual poker player that make very similar decisions of a professional poker player.","","Electronic:978-9-8998-4346-2; POD:978-1-5090-1226-8","10.1109/CISTI.2016.7521506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7521506","CRISP-DM;Data Mining;Games;Machine Learning;Poker;Talend;Weka","Adaptation models;Data integration;Data mining;Data models;Games;Rivers;Software","behavioural sciences computing;data integration;data mining;software packages","Texas hold'em poker game;Weka software package;artificial intelligence;data-mining;imperfect information;professional poker player modeling;scientific community;stochastic game;talend data integration;virtual poker player","","","","","","","15-18 June 2016","","IEEE","IEEE Conference Publications"
"Predicting Dropout-Prone Students in E-Learning Education System","M. A. A. Dewan; F. Lin; D. Wen; Kinshuk","Sch. of Comput. & Inf. Syst., Athabasca Univ., Edmonton, AB, Canada","2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)","20160721","2015","","","1735","1740","High rate of students dropout in courses has been a major problem for many universities or educational institutions that offer online education. If the dropout-prone students can be identified in their early stages, the dropout rate can be reduced by providing individualized care to the students at-risk. Due to the electronic nature of the e-learning courses, various attributes of the student progress can be monitored and analyzed automatically over time. In this paper, a technique for predicting students who are prone to dropout from the online courses has been proposed that progressively analyzes a set of per-learner attributes of the students' activities overtime. Since a single machine learning technique may fail to accurately identify some dropout-prone students whereas others may succeed, this technique uses a combination of multiple classifiers (ensemble of classifiers) for this analysis. The results of the validation found the technique to be promising in predicting dropout-prone students.","","Electronic:978-1-4673-7211-4; POD:978-1-4673-7212-1","10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.315","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518496","dropout prediction;e-learning;enseble of classifiers;machine learning;per-learner attributes","Electronic learning;Internet;Logistics;Monitoring;Support vector machines;Training","Internet;computer aided instruction;educational courses;educational institutions;pattern classification","classifier ensemble;dropout-prone student prediction;e-learning education system;educational institution;online course;per-learner attribute","","","","","","","10-14 Aug. 2015","","IEEE","IEEE Conference Publications"
"What Is Algorithm Governance?","D. Doneda; V. A. F. Almeida","Rio de Janeiro State University","IEEE Internet Computing","20160802","2016","20","4","60","63","With algorithms' increased use to fulfill complex tasks comes the risk of algorithms' use for manipulation, biases, censorship, social discrimination, violations of privacy and property rights, and more. To address such risks, the process of algorithm governance should be considered.","1089-7801;10897801","","10.1109/MIC.2016.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529042","Internet governance;Internet/Web technologies;algorithm governance;information privacy;machine learning","Algorithm design and analysis;Internet governance;Machine learning;Privacy;Web and internet services","data privacy;social aspects of automation","algorithm governance;biases;censorship;manipulation;privacy violations;property rights;social discrimination","","","","","","","July-Aug. 2016","","IEEE","IEEE Journals & Magazines"
