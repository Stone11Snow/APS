"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7439550,7438567,7437685,7439943,7390065,7435815,7435719,7435482,7436992,7434221,7435009,7434400,7433712,7434238,7412638,7229282,7434616,7088593,6945857,7432966,7432973,7433472,7433261,7430957,7087364,7426879,7427515,7428468,7426878,7426894,7428324,7426895,7427400,7429425,7428207,7169584,7313038,7422608,7426084,7425594,7425969,7425797,7425926,7350148,7426350,7096978,7424026,7423996,7424027,7424124,7111343,7424880,7424009,7424657,7115131,7423070,7315046,7424085,7424088,7423528,7424201,7424041,7423527,7424031,7424131,7424091,7368090,7358047,7420323,7421104,7006341,7302597,7420679,7416896,7416902,7384674,7416901,7294640,7370876,7401069,7042360,7416345,7415176,7413623,7412219,7091000,7409386,7408071,7411241,7365484,7353201,7409718,7405598,7405812,7407105,7407518,7400344,7406326,7406328,7405831",2017/05/05 21:47:39
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Predicting the Absorption Potential of Chemical Compounds through a Deep Learning Approach","M. Shin; D. Jang; H. Nam; K. H. Lee; D. Lee","Moonshik Shin is with the Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, Korea. E&#8208;mail:{msshin.kr, djjang, khlee, dhlee}@kaist.ac.kr","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2016","PP","99","1","1","The human colorectal carcinoma cell line (Caco-2) is a commonly used in-vitro test that predicts the absorption potential of orally administered drugs. In-silico prediction methods, based on the Caco-2 assay data, may increase the effectiveness of the high-throughput screening of new drug candidates. However, previously developed in-silico models that predict the Caco-2 cellular permeability of chemical compounds use handcrafted features that may be dataset-specific and induce over-fitting problems. Deep Neural Network (DNN) generates high-level features based on non-linear transformations for raw features, which provides high discriminant power and, therefore, creates a good generalized model. We present a DNNbased binary Caco-2 permeability classifier. Our model was constructed based on 663 chemical compounds with in-vitro Caco-2 apparent permeability data. 209 molecular descriptors are used for generating the high-level features during DNN model generation. Dropout regularization is applied to solve the over-fitting problem and the non-linear activation. The Rectified Linear Unit (ReLU) is adopted to reduce the vanishing gradient problem. The results demonstrate that the high-level features generated by the DNN are more robust than handcrafted features for predicting the cellular permeability of structurally diverse chemical compounds in Caco-2 cell lines.","1545-5963;15455963","","10.1109/TCBB.2016.2535233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420679","Caco-2 permeability;Machine learning;absorption prediction;deep learning;neural nets","Absorption;Chemical compounds;Chemicals;Compounds;Drugs;Permeability;Predictive models","","","","","","","","20160226","","","IEEE","IEEE Early Access Articles"
"Interpretation of DGA for transformer fault diagnosis with complementary SaE-ELM and arctangent transform","S. Li; G. Wu; B. Gao; C. Hao; D. Xin; X. Yin","Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Dielectrics and Electrical Insulation","20160307","2016","23","1","586","595","This paper presents a novel approach for power transformer incipient fault diagnosis through the analysis of dissolved gas in oil. The proposed approach is implemented for improving the diagnosis accuracy by dissolved gas analysis (DGA) of power transformer based on the combined use of a multi-classification algorithm self-adaptive evolutionary extreme learning machine (SaE-ELM) and a simple arctangent transform (AT). On the one hand, the SaE-ELM algorithm has the ability to approximate any nonlinear functions with its structure parameters, i.e. hidden node biases and output weights, optimized self-sufficiently. On the other hand, the AT can alter the data structure of the experiment data, which will enhance the generalization capability for SaE-ELM as well as other machine learning algorithms. Thus, the combination of SaEELM and AT can complement each other and improve the diagnosis accuracy from the aspect of both algorithm and data structure. The performances of the proposed approach are compared with that derived from ANN, SVM, and ELM methods, respectively. Experimental results with both published and power utility provided data indicate that the developed approach can significantly improve the accuracies for power transformer fault diagnosis.","1070-9878;10709878","","10.1109/TDEI.2015.005410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422608","Dissolved gas analysis (DGA);arctangent transform;fault diagnosis;self-adaptive evolutionary extreme learning machine","Artificial neural networks;Fault diagnosis;Oil insulation;Power transformers;Support vector machines;Training;Transforms","fault diagnosis;learning (artificial intelligence);power engineering computing;power transformers;transforms","ANN;DGA;ELM methods;SVM;SaE-ELM;arctangent transform;complementary SaE-ELM;data structure;dissolved gas analysis;machine learning algorithms;multiclassification algorithm;nonlinear functions;power transformer fault diagnosis;power transformer incipient fault diagnosis;self-adaptive evolutionary extreme learning machine","","3","","35","","","February 2016","","IEEE","IEEE Journals & Magazines"
"Text chunker for Malayalam using Memory-Based Learning","Rekha Raj C. T.; Reghu Raj P. C.","Department of Computer Science and Engineering, Government Engineering College, Sreekrishnapuram, Kerala, India 678633","2015 International Conference on Control Communication & Computing India (ICCC)","20160314","2015","","","595","599","Text chunking consists of dividing a text into syntactically correlated parts of words. Given the words and their morphosyntactic class, a chunker will decide which words can be grouped as chunks. Malayalam is a free word order language and has relatively unrestricted phrase structures that make the problem of chunking quite challenging. This paper aims to develop a text chunker for Malayalam using Memory-Based Learning (MBL) approach. Memory-Based Learning is a machine learning methodology based on the idea that the direct reuse of examples using analogical reasoning is more suited for solving language processing problems than the application of rules extracted from those examples. The chunker was trained using the tool Memory-Based Tagger (MBT) with words and their POS tags as features. The chunker demonstrated an accuracy of 97.14%.","","CD-ROM:978-1-4673-7348-7; Electronic:978-1-4673-7349-4; POD:978-1-4673-7350-0","10.1109/ICCC.2015.7432966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7432966","Machine Learning;Malayalam Chunking;Memory Based Learning;Memory Based Natural Language Processing;Natural Language Processing;POS Tagging;Shallow parsing","Compounds;Context;Hidden Markov models;Measurement;Speech;Tagging;Training","case-based reasoning;learning (artificial intelligence);natural language processing;text analysis","MBL approach;MBT;Malayalam;POS tag;analogical reasoning;language processing problem;machine learning;memory-based learning;memory-based tagger;morphosyntactic class;text chunker;unrestricted phrase structure","","","","18","","","19-21 Nov. 2015","","IEEE","IEEE Conference Publications"
"Door Knob Hand Recognition System","X. Qu; D. Zhang; G. Lu; Z. Guo","Hong Kong Polytechnic University, Hong Kong.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2016","PP","99","1","12","Biometric applications have been used globally in everyday life. However, conventional biometrics is created and optimized for high-security scenarios. Being used in daily life by ordinary untrained people is a new challenge. Facing this challenge, designing a biometric system with prior constraints of ergonomics, we propose ergonomic biometrics design model, which attains the physiological factors, the psychological factors, and the conventional security characteristics. With this model, a novel hand-based biometric system, door knob hand recognition system (DKHRS), is proposed. DKHRS has the identical appearance of a conventional door knob, which is an optimum solution in both physiological factors and psychological factors. In this system, a hand image is captured by door knob imaging scheme, which is a tailored omnivision imaging structure and is optimized for this predetermined door knob appearance. Then features are extracted by local Gabor binary pattern histogram sequence method and classified by projective dictionary pair learning. In the experiment on a large data set including 12,000 images from 200 people, the proposed system achieves competitive recognition performance comparing with conventional biometrics like face and fingerprint recognition systems, with an equal error rate of 0.091%. This paper shows that a biometric system could be built with a reliable recognition performance under the ergonomic constraints.","2168-2216;21682216","","10.1109/TSMC.2016.2531675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433472","Biometrics;ergonomics;feature extraction;image processing;machine learning;optical imaging;pattern recognition;user-centered design","Biological system modeling;Ergonomics;Feature extraction;Imaging;Iris recognition;Sensors","","","","","","","","20160314","","","IEEE","IEEE Early Access Articles"
"Selectively Inhibiting Learning Bias for Active Sampling","D. P. D. Santos; A. C. P. L. F. d. Carvalho","Inst. de Cienc. Mat. e Comput., Univ. de Sao Paulo, Sao Carlos, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","62","67","Efficient training of machine learning algorithms requires a reliable labeled set from the application domain. Usually, data labeling is a costly process. Therefore, a selective approach is desirable. Active learning has been successfully used to reduce the labeling effort, due to its parsimonious process of querying the labeler. Nevertheless, many active learning strategies are dependent on early predictions made by learning algorithms. This might be a major problem when the learner is still unable to provide reliable information. In this context, agnostic strategies can be convenient, since they spare internal learners - usually favoring exploratory queries. On the other hand, prospective queries could benefit from a learning bias. In this article, we highlight the advantages of the agnostic approach and propose how to explore some of them without foregoing prospect ion. A simple hybrid strategy and a visualization tool called ranking curves, are proposed as a proof of concept. The tool allowed to see clearly when the presence of a learner was possibly detrimental. Finally, the hybrid strategy was successfully compared to its counterpart in the literature, to pure agnostic strategies and to the usual baseline of the field.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423996","active learning;agnostic;machine learning","Correlation;Labeling;Mathematical model;Measurement uncertainty;Prediction algorithms;Training;Uncertainty","data visualisation;learning (artificial intelligence)","active learning bias;active learning strategies;active sampling;data labeling;hybrid strategy;labeler;labeling effort;machine learning algorithms;parsimonious process;pure agnostic strategies;ranking curves;visualization tool","","","","29","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"N-scheme model: An approach towards reducing Arabic language sparseness","M. A. Ben Mohamed; S. Zrigui; A. Zouaghi; M. Zrigui","Faculty of Sciences of Monastir, Tunisia","2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)","20160310","2015","","","1","5","In addition to traditional characteristics of natural languages like implicitly or ambiguity or imprecision, Arabic is known by its sparseness which explains the difficulty of its automatic processing. But on the other hand, Arabic language is characterized by an interesting property; lemmas are generated by derivation based on roots and schemes. Schemes are kinds of molds allowing changing the form of root by actions involving elongation, or repetition, or even adding characters. Schemes can also give meaning to generated word. In this work we have studied the statistical characteristics of the Arabic language at the level of schemes; we have emphasized the attenuation of the sparseness at this level. Then we explored the possibility of building natural language processing tools for Arabic by relying on schemes. We discovered that schemes have great potential in building accurate natural language processing tools for Arabic. Based entirely or partially on schemes we built an n-scheme statistical model and a text classification system.","","Electronic:978-1-4673-8749-1; POD:978-1-4673-8750-7","10.1109/ICTA.2015.7426895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426895","Arabic language;Derivation;N-Scheme Statistical Model;Roots;Schemes;Supervised Machine Learning;Text Classification","Buildings;Computational modeling;Natural language processing;Neural networks;Silicon;Training;Vocabulary","natural language processing;statistical analysis;text analysis","Arabic language sparseness;n-scheme statistical model;natural language processing tools;statistical characteristics;text classification system","","","","26","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Efficient and Robust Learning for Sustainable and Reacquisition-Enabled Hand Tracking","M. A. Abul Aziz; J. Niu; X. Zhao; X. Li","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China","IEEE Transactions on Cybernetics","20160315","2016","46","4","945","958","The use of machine learning approaches for long-term hand tracking poses some major challenges such as attaining robustness to inconsistencies in lighting, scale and object appearances, background clutter, and total object occlusion/disappearance. To address these issues in this paper, we present a robust machine learning approach based on enhanced particle filter trackers. The inherent drawbacks associated with the particle filter approach, i.e., sample degeneration and sample impoverishment, are minimized by infusing the particle filter with the mean shift approach. Moreover, to instill our tracker with reacquisition ability, we propose a rotation invariant and efficient detection framework named beta histograms of oriented gradients. Our robust appearance model operates on the red, green, blue color histogram and our newly proposed rotation invariant noise compensated local binary patterns descriptor, which is a noise compensated, rotation invariant version of the local binary patterns descriptor. Through our experiments, we demonstrate that our proposed hand tracker performs favorably against state-of-the-art algorithms on numerous challenging video sequences of hand postures, and overcomes the largely unsolved problem of redetecting hands after they vanish and reappear into the frame.","2168-2267;21682267","","10.1109/TCYB.2015.2418275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7088593","Computer vision;histograms of oriented gradient (HOG);local binary pattern (LBP);machine learning;mean shift implanted particle filter","Detectors;Lighting;Robustness;Support vector machines;Target tracking;Training","","","","1","","55","","20150417","April 2016","","IEEE","IEEE Journals & Magazines"
"Medical Checkup and Image Data Analysis for Preventing Life Style Diseases: A Research Survey of Japan Society for the Promotion of Science with Grant-in-Aid for Scientific Research (A) (Grant number 25240038)","M. Nii; M. Momimoto; S. Kobashi; N. Kamiura; Y. Hata; K. i. Sorachi","Univ. of Hyogo, Himeji, Japan","2015 7th International Conference on Emerging Trends in Engineering & Technology (ICETET)","20160307","2015","","","117","122","To prevent lifestyle diseases, this paper studies disease prediction using periodical health checkup data, daily monitoring to maintain healthy condition, and early life disease detection with medical imaging. To analyse periodical health checkup data, three approaches are introduced. The first approach is based on fuzzy set. It converts all attributes of health checkup data into fuzzy degrees by defining fuzzy membership functions. It enables us to manipulate all attributes in the same scale. The second approach analyses relationships between attributes of specific health examination data to cope with lifestyle diseases. It uses self-organizing maps, and clarifies the relationships among hemoglobin A1c (HbA1c), glutamic-oxaloacetic transaminase, glutamic-pyruvic transaminase, gamma-glutamyl transpeptidase, and triglyceride. The third approach predicts HbA1c fluctuations using decision tree. If we can predict the fluctuation, we can extract knowledge about what element will trigger developing diabetes. Through our examination, BMI will be the largest influencer about HbA1c fluctuations. Daily understanding of own condition is the first step of maintaining our health. A MEMS-based small and flexible monitoring device has been developed by the ERATO Maenaka human-sensing fusion project. We propose a condition estimation method using the monitoring device and FNN-based condition estimation. Experimental results show that it is a promising method for condition understanding. Cerebral vascular disease is one of major lifestyle diseases, and is caused by cerebral aneurysms. To predict the diseases, we should analyse cerebral arteries and aneurysms using magnetic resonance angiography images. This paper introduces an automated analysis method for early detection of aneurysms.","","Electronic:978-1-4673-8305-9; POD:978-1-4673-8306-6; USB:978-1-4673-8304-2","10.1109/ICETET.2015.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425594","MEMS;health examination data;lifestyle diseases;machine learning;magnetic resonance imaging","Biomedical imaging;Diabetes;Diseases;Labeling;Monitoring;Neurons;Training data","bioMEMS;biomedical MRI;data analysis;decision trees;diseases;fuzzy neural nets;fuzzy set theory;knowledge acquisition;medical image processing;patient monitoring;self-organising feature maps","ERATO Maenaka human-sensing fusion project;FNN-based condition estimation method;HbA1c fluctuation prediction;Japan society;MEMS-based small monitoring device;cerebral aneurysm analysis;cerebral artery analysis;cerebral vascular disease;decision tree;diabetes;disease prediction;early life disease detection;flexible monitoring device;fuzzified neural networks;fuzzy membership functions;fuzzy set theory;gamma-glutamyl transpeptidase;glutamic-oxaloacetic transaminase;glutamic-pyruvic transaminase;grant-in-aid;health examination data attributes;hemoglobin A1c;image data analysis;knowledge extraction;life style disease prevention;magnetic resonance angiography images;medical checkup analysis;medical imaging;periodical health checkup data;science promotion;scientific research;self-organizing maps;triglyceride","","","","13","","","18-20 Nov. 2015","","IEEE","IEEE Conference Publications"
"Detection and Prevention of Code Injection Attacks on HTML5-Based Apps","X. Xiao; R. Yan; R. Ye; Q. Li; S. Peng; Y. Jiang","Grad. Sch. at Shenzhen, Tsinghua Univ., Shenzhen, China","2015 Third International Conference on Advanced Cloud and Big Data","20160321","2015","","","254","261","Security on mobile devices is becoming increasingly important. HTML5 are widely used to develop mobile applications due to its portability on multi platforms. However it is allowed to mix data and code together in Web technology. HTML5-based applications are prone to suffer from code injection attacks that are similar to XSS. In this paper, at first, we introduce a more hidden type of code injection attacks, coding-based attacks. In the new type of code injection attacks, JavaScript code is encoded in a human-unreadable form. Then we use classification algorithms of machine learning to determine whether an app suffers from the code injection attack or not. The experimental result shows that the Precision of our detection method reaches 95.3%. Compare with the other method, our approach improves a lot in detection speed with the precision nearly unchanged. Furthermore, an improved access control model is proposed to mitigate the attack damage. In addition, filters are adopted to remove JavaScript code from data to prevent the attacks. The effectiveness and rationality have been validated through extensive simulations.","","Electronic:978-1-4673-8537-4; POD:978-1-4673-8538-1","10.1109/CBD.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435482","access control model;classification algorithm;code injection;filter;machine learning","Big data;Encoding;Feature extraction;HTML;Mobile applications;Smart phones","Java;application program interfaces;authorisation;hypermedia markup languages;learning (artificial intelligence);mobile computing;source code (software)","HTML5-based applications;JavaScript code;Web technology;access control model;attack damage mitigation;code injection attack detection;code injection attack prevention;coding-based attacks;hidden-type code injection attacks;human-unreadable code form;machine learning classification algorithms;mobile devices;precision value","","","","31","","","Oct. 30 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Drug discovery for breast cancer based on big data analytics techniques","R. Mennour; M. Batouche","Constantine 2 University - Abdelhamid Mehri, Faculty of NTIC, MISC Laboratory, Constantine 25000, Algeria","2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)","20160310","2015","","","1","6","Scientific research are nowadays faced to very massive data processing, which consume relatively too much time and effort, that's why researchers have turned to high performance computational (HPC) techniques. In the same context, research on drug discovery has reached a place where it has no choice but using HPC and Big Data Processing Systems to accomplish its objectives in reasonable periods of time, Virtual Screening (VS) is considered as one of the most computationally intensive and heavy process, it plays an important role in designing new drugs and has to be done as fast as possible in order to effectively dock ligands in huge databases to a given protein receptor. On the other hand, breast cancer is one of the most dangerous diseases of world, in the last decade; more than 1.5 million new cases are diagnosed each year, with more than 400 thousands deaths. These statistics give very great importance to drug research for this disease. In this context, and in order to ameliorate the drug designing process for breast cancer, we propose in this work, to use Machine Learning Algorithms that are designed for Big Data analysis on top of MapReduce and Mahout in order to pre-filter the huge set of ligands to effectively do virtual screening for the breast cancer protein receptor.","","Electronic:978-1-4673-8749-1; POD:978-1-4673-8750-7","10.1109/ICTA.2015.7426894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426894","Big Data analytics;Breast Cancer;Docking;Machine Learning;Mahout;MapReduce;Virtual Screening","Big data;Breast cancer;Chemicals;Drugs;Libraries;Proteins;Software","","","","","","33","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Automatic Stem Cell Detection in Microscopic Whole Mouse Cryo-Imaging","P. Wuttisarnwattana; M. Gargesha; W. van't Hof; K. R. Cooke; D. L. Wilson","Department of Computer Engineering, Chiang Mai University, Chiang Mai, Thailand","IEEE Transactions on Medical Imaging","20160303","2016","35","3","819","829","With its single cell sensitivity over volumes as large as or larger than a mouse, cryo-imaging enables imaging of stem cell biodistribution, homing, engraftment, and molecular mechanisms. We developed and evaluated a highly automated software tool to detect fluorescently labeled stem cells within very large (~ 200 GB) cryo-imaging datasets. Cell detection steps are: preprocess, remove immaterial regions, spatially filter to create features, identify candidate pixels, classify pixels using bagging decision trees, segment cell patches, and perform 3D labeling. There are options for analysis and visualization. To train the classifier, we created synthetic images by placing realistic digital cell models onto cryo-images of control mice devoid of cells. Very good cell detection results were (precision=98.49%, recall=99.97%) for synthetic cryo-images, (precision=97.81%, recall=97.71%) for manually evaluated, actual cryo-images, and <; 1% false positives in control mice. An α-multiplier applied to features allows one to correct for experimental variations in cell brightness due to labeling. On dim cells (37% of standard brightness), with correction, we improved recall (49.26%→ 99.36%) without a significant drop in precision (99.99%→ 99.75%). With tail vein injection, multipotent adult progenitor cells in a graft-versus-host-disease model in the first days post injection were predominantly found in lung, liver, spleen, and bone marrow. Distribution was not simply related to blood flow. The lung contained clusters of cells while other tissues contained single cells. Our methods provided stem cell distribution anywhere in mouse with single cell sensitivity. Methods should provide a rational means of evaluating dosing, delivery methods, cell enhancements, and mechanisms for therapeutic cells.","0278-0062;02780062","","10.1109/TMI.2015.2497285","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7315046","Biodistribution;cell;cell detection;cryo-imaging;fluorescent imaging;image processing;machine learning;optical imaging;segmentation;stem cell homing;visualization","Electronic mail;Fluorescence;Image color analysis;Liver;Lungs;Mice;Solid modeling","biomedical optical imaging;bone;cellular biophysics;fluorescence;geriatrics;image classification;image sequences;liver;lung;medical image processing;orthopaedics","3D labeling;automatic stem cell detection;bagging decision trees;blood flow;bone marrow;cell enhancements;dim cells;dosing;engraftment;fluorescently labeled stem cells;graft-versus-host-disease model;highly automated software tool;homing;large cryo-imaging datasets;liver;lung contained clusters;microscopic whole mouse cryo-imaging;multipotent adult progenitor cells;pixel classification;realistic digital cell models;segment cell patches;single cell sensitivity;spleen;stem cell biodistribution;stem cell distribution;synthetic cryo-imaging;tail vein injection;therapeutic cell mechanisms;tissues","","1","","47","","20151102","March 2016","","IEEE","IEEE Journals & Magazines"
"Temporal relation classification with deep neural network","Hyun Woo Do; Y. S. Jeong","Department of Computer Science, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon 305-701, South Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","454","457","We proposed neural network architecture based on Convolution Neural Network(CNN) for temporal relation classification in sentence. First, we transformed word into vector by using word embedding. In Feature Extraction, we extracted two type of features. Lexical level feature considered meaning of marked entity and Sentence level feature considered context of the sentence. Window processing was used to reflect local context and Convolution and Max-pooling operation were used for global context. We concatenated both feature vectors and used softmax operation to compute confidence score. Because experiment results didn't outperform the state-of-the-art methods, we suggested some future works to do.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425969","Machine Learning Convolution Neural Network Temporal Relation Extraction","Computer architecture;Context;Convolution;Feature extraction;Neural networks;Syntactics;Training","feature extraction;natural language processing;neural net architecture;pattern classification","CNN;Window processing;confidence score;convolution neural network;deep neural network;feature extraction;feature vectors;lexical level feature;marked entity feature;max-pooling operation;neural network architecture;sentence level feature;softmax operation;temporal relation classification;word embedding","","","","9","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Indoor Pedestrian Tracking by On-Body Multiple Receivers","A. Correa; M. Barcelo Llado; A. Morell; J. L. Vicario","Telecommunications and Systems Engineering Department, Universitat Aut&#242;noma de Barcelona, Barcelona, Spain","IEEE Sensors Journal","20160225","2016","16","8","2545","2553","During the past years, the development of indoor localization systems has been a hot topic in research, because the global navigation satellite systems suffer from a significant performance degradation due to the fact that the line of sight to the satellites is not available. The proposed system employs the received signal strength indicator from multiple anchor nodes from an operating wireless sensor network (WSN). In addition, we place multiple receivers around the user's body and thanks to machine learning techniques; we are able to estimate the distance and angle between the user and any of the anchor nodes of the WSN. This allows us to estimate the heading of the user without the use of inertial sensors or magnetometers. Finally, the user's position estimation is refined using an extended Kalman filter that considers the constant velocity kinematic model. The system has been validated in multiple real scenarios obtaining a root mean squared error around the meter for the different tests performed.","1530-437X;1530437X","","10.1109/JSEN.2016.2518872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7384674","Kalman filters;Navigation;indoor localization;machine learning;wireless sensor networks","Estimation;Linear regression;Neural networks;Receivers;Sensors;Training;Wireless sensor networks","Kalman filters;indoor environment;nonlinear filters;pedestrians;receivers;wireless sensor networks","constant velocity kinematic model;extended Kalman filter;indoor pedestrian tracking;machine learning techniques;multiple anchor nodes;on-body multiple receivers;position estimation;received signal strength indicator;root mean squared error;wireless sensor network","","2","","32","","20160118","April15, 2016","","IEEE","IEEE Journals & Magazines"
"Data-Driven Soft Decoding of Compressed Images in Dual Transform-Pixel Domain","X. Liu; X. Wu; J. Zhou; D. Zhao","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Image Processing","20160225","2016","25","4","1649","1659","In the large body of research literature on image restoration, very few papers were concerned with compression-induced degradations, although in practice, the most common cause of image degradation is compression. This paper presents a novel approach to restoring JPEG-compressed images. The main innovation is in the approach of exploiting residual redundancies of JPEG code streams and sparsity properties of latent images. The restoration is a sparse coding process carried out jointly in the DCT and pixel domains. The prowess of the proposed approach is directly restoring DCT coefficients of the latent image to prevent the spreading of quantization errors into the pixel domain, and at the same time, using online machine-learned local spatial features to regulate the solution of the underlying inverse problem. Experimental results are encouraging and show the promise of the new approach in significantly improving the quality of DCT-coded images.","1057-7149;10577149","","10.1109/TIP.2016.2526910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401069","Compressed image restoration;machine learning;soft decoding;sparse coding","Decoding;Degradation;Discrete cosine transforms;Image coding;Image restoration;Quantization (signal)","data compression;image coding;image restoration;learning (artificial intelligence)","DCT coefficients;DCT-coded images;JPEG code streams;JPEG-compressed images;compressed images;compression-induced degradations;data-driven soft decoding;dual transform-pixel domain;image degradation;image restoration;latent images;online machine-learned local spatial features;pixel domains;sparsity properties","","5","","39","","20160208","April 2016","","IEEE","IEEE Journals & Magazines"
"Twitter Sentiment Analysis -- A More Enhanced Way of Classification and Scoring","S. Sahu; S. K. Rout; D. Mohanty","IIT Kharagpur, Midnapore, India","2015 IEEE International Symposium on Nanoelectronic and Information Systems","20160317","2015","","","67","72","In this paper we present a novel approach to Twitter Sentiment Analysis. The approach adopted is to analyse the lexicon features of the tweets for classifying its sentiment (positive, negative and neutral). The training data is made more exhaustive by including various manually labelled tweets, in addition to the existing word stock to keep up with the changing micro logging trends. For Data Preprocessing, a novel spell checking algorithm is introduced, an operation for disjoining compound words such as ""high hopes"" is implemented and emoticons are replaced by suitable emotion words like happy or sad. After this initial preprocessing, the machine learning algorithms are (Support vector machines and Maximum entropy) are applied. We also propose an avant-garde sentiment scoring mechanism to estimate the degree of the sentiment. Our approach is able to assign sentiments to tweets with an accuracy of 80%.","","Electronic:978-1-4673-9692-9; POD:978-1-4673-9693-6","10.1109/iNIS.2015.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434400","Twitter;machine learning;sentiment classification","Algorithm design and analysis;Classification algorithms;Dictionaries;Entropy;Support vector machines;Training;Twitter","learning (artificial intelligence);pattern classification;sentiment analysis;social networking (online);support vector machines","Twitter sentiment analysis;data preprocessing;machine learning algorithms;maximum entropy;sentiment classification;sentiment scoring mechanism;spell checking algorithm;support vector machines;tweet lexicon features","","","","13","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"A faster face detection method combining Bayesian and Haar Cascade Classifiers","É. K. Shimomoto; A. Kimura; R. Belém","Universidade do Estado do Amazonas, Manaus, AM - Brazil","2015 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON)","20160215","2015","","","7","12","Face Recognition is one of the most studied topics in computer vision. But before recognizing, it is necessary to detect a face. Many methods have been developed in order to perform this but the biggest problem they face is the time it takes to detect the object. This was greatly solved with the creation of the Haar Cascade Classifiers, which made possible the real time detection. However, depending on the application, it can still be time consuming. This work presents a faster way to detect faces by combining a Bayesian classifier with Haar Cascade classifiers.","","Electronic:978-1-4673-8756-9; POD:978-1-4673-8757-6","10.1109/Chilecon.2015.7400344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400344","Bayesian classifier;Face Detection;Haar Cascade Classifier;Machine Learning","Bayes methods;Computer vision;Decision support systems;Face;Face recognition;Indexes;Real-time systems","computer vision;face recognition;image classification;learning (artificial intelligence);object detection","Bayesian classifier;Haar cascade classifier;computer vision;face detection method;face recognition;object detection","","","","13","","","28-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"An Approach to Named Entity Extraction from Mongolian Historical Documents","B. Batjargal; G. Khaltarkhuu; A. Maeda","Res. Organ. of Sci. & Technol, Ritsumeikan Univ., Kusatsu, Japan","2015 International Conference on Culture and Computing (Culture Computing)","20160314","2015","","","205","206","In this poster, we demonstrate a named entity extraction method for digitized ancient Mongolian documents by using the features of characters' appearance in a word. Named entities such as personal names and place names will be extracted by employing Support Vector Machine that aims to reduce the labor-intensive analysis on historical text. The preliminary results of our experiment show that the proposed method has gained 0.6993, 0.5679 and 0.6268 of precision, recall and F-measure, respectively.","","CD-ROM:978-1-4673-8231-1; Electronic:978-1-4673-8232-8; POD:978-1-4673-8233-5","10.1109/Culture.and.Computing.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433261","digital humanities;historical documents;machine learning;support vector machine;traditional Mongolian script","Feature extraction;Information retrieval;Libraries;Natural language processing;Support vector machines;Text analysis","document handling;history;natural language processing;support vector machines","Mongolian historical documents;character appearance;digitized ancient Mongolian documents;labor intensive analysis;named entity extraction;personal names;support vector machine","","","","7","","","17-19 Oct. 2015","","IEEE","IEEE Conference Publications"
"Recognizing FM, BPSK and 16-QAM using supervised and unsupervised learning techniques","M. Bari; A. Khawar; M. Doroslovački; T. C. Clancy","Electrical and Computer Engineering, The George Washington University","2015 49th Asilomar Conference on Signals, Systems and Computers","20160229","2015","","","160","163","In this paper, we explore the use of supervised and unsupervised machine learning for signal classification in the joint presence of AWGN, carrier offset, asynchronous sampling and symbol intervals and correlated fast fading. Three simple features are studied to classify frequency modulation, binary phase shift keying and 16 point quadrature amplitude modulation. Support vector machines and self-organizing maps are used to classify the signals.","","CD-ROM:978-1-4673-8574-9; Electronic:978-1-4673-8576-3; POD:978-1-4673-8577-0","10.1109/ACSSC.2015.7421104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7421104","Signal classification;k-means;machine learning;self-organizing maps;spectrum sensing","Binary phase shift keying;Fading channels;Frequency modulation;Neurons;Radio frequency;Support vector machines","frequency modulation;learning (artificial intelligence);phase shift keying;quadrature amplitude modulation;signal classification;support vector machines","16 point quadrature amplitude modulation;16-QAM;AWGN;BPSK;asynchronous sampling;binary phase shift keying;carrier offset;correlated fast fading;frequency modulation;machine learning;self-organizing maps;signal classification;support vector machines;symbol intervals;unsupervised learning techniques","","1","","15","","","8-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"A 1.83 <formula formulatype=""inline""><tex Notation=""TeX"">$mu$</tex></formula>J/Classification, 8-Channel, Patient-Specific Epileptic Seizure Classification SoC Using a Non-Linear Support Vector Machine","M. A. Bin Altaf; J. Yoo","Masdar Institute of Science and Technology, Abu Dhabi, United Arab Emirates","IEEE Transactions on Biomedical Circuits and Systems","20160225","2016","10","1","49","60","A non-linear support vector machine (NLSVM) seizure classification SoC with 8-channel EEG data acquisition and storage for epileptic patients is presented. The proposed SoC is the first work in literature that integrates a feature extraction (FE) engine, patient specific hardware-efficient NLSVM classification engine, 96 KB SRAM for EEG data storage and low-noise, high dynamic range readout circuits. To achieve on-chip integration of the NLSVM classification engine with minimum area and energy consumption, the FE engine utilizes time division multiplexing (TDM)-BPF architecture. The implemented log-linear Gaussian basis function (LL-GBF) NLSVM classifier exploits the linearization to achieve energy consumption of 0.39 μ J/operation and reduces the area by 28.2% compared to conventional GBF implementation. The readout circuits incorporate a chopper-stabilized DC servo loop to minimize the noise level elevation and achieve noise RTI of 0.81 μ Vrms for 0.5-100 Hz bandwidth with an NEF of 4.0. The 5 × 5 mm<sup>2</sup> SoC is implemented in a 0.18 μm 1P6M CMOS process consuming 1.83 μ J/classification for 8-channel operation. SoC verification has been done with the Children's Hospital Boston-MIT EEG database, as well as with a specific rapid eye-blink pattern detection test, which results in an average detection rate, average false alarm rate and latency of 95.1%, 0.94% (0.27 false alarms/hour) and 2 s, respectively.","1932-4545;19324545","","10.1109/TBCAS.2014.2386891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042360","Continuous health monitoring;classification processor;electroencephalogram (EEG);epilepsy;machine learning;neurological disorder;seizure detection;support vector machine (SVM)","Accuracy;Electroencephalography;Engines;Feature extraction;Iron;Support vector machines;System-on-chip","Gaussian distribution;data acquisition;diseases;electroencephalography;feature extraction;medical signal processing;support vector machines;system-on-chip;time division multiplexing","8-channel EEG data acquisition;Children Hospital Boston-MIT;NLSVM;SoC;detection rate;energy consumption;epileptic patients;feature extraction;log-linear Gaussian basis function;noise level elevation;nonlinear support vector machine;patient-specific epileptic seizure classification;rapid eye-blink pattern detection test;time division multiplexing","","3","","48","","20150213","Feb. 2016","","IEEE","IEEE Journals & Magazines"
"Convolutional Neural Networks in Automatic Recognition of Trans-differentiated Neural Progenitor Cells under Bright-Field Microscopy","B. Jiang; X. Wang; J. Luo; X. Zhang; Y. Xiong; H. Pang","Guangzhou Inst. of Biomed. & Health, Guangzhou, China","2015 Fifth International Conference on Instrumentation and Measurement, Computer, Communication and Control (IMCCC)","20160215","2015","","","122","126","The study of cell morphology changes leads the investigation of the cell fate decision and its function. Bright-field imaging analysis allow us to use a labeling free and non-invasive approach to measure the morphological dynamics during cellular reprogramming, which includes induced pluripotent stem cells (iPSCs), and trans-differentiated neural progenitor cells (NPCs) from somatic cell source. However, the traditional method to study the NPC differentiation and its related function involves staining, and cell lysis, which can not materialized further for the clinical uses. In order to automatically, non-invasively, non-labelled analyze and cultivate cells, a system classifying NPCs under bright-field microscopic imaging is necessary. In this paper, we propose a novel recognition system based on convolutional neural networks, which could pre-process images and classify NPCs and non-NPCs. Experimental results prove that the proposed system provides a new tool for fundamental research in iPSCs and NPCs based generation medicine.","","Electronic:978-1-4673-7723-2; POD:978-1-4673-7724-9","10.1109/IMCCC.2015.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405812","bright-field microscopy;convolutional neural networks;deep learning;machine learning;non-invasive;non-labelled;trans-differentiated neural progenitor cells","Biological neural networks;Electronic mail;Feature extraction;Image recognition;Machine learning;Microscopy;Morphology","cellular biophysics;image classification;medical image processing;neural nets;optical microscopy","NPC classification;automatic recognition;bright-field microscopic imaging analysis;convolutional neural networks;image pre-processing;nonNPC classification;trans-differentiated neural progenitor cells","","","","17","","","18-20 Sept. 2015","","IEEE","IEEE Conference Publications"
"A Study of Conceptual Recommender System for Big Data Platform","J. Kim; S. T. Hwang","Coll. of Inf. & Commun. Eng., Sungkyunkwan Univ., Suwon, South Korea","2015 8th International Conference on Database Theory and Application (DTA)","20160317","2015","","","22","25","Although there has been much work done in the industry and academia on developing the theory and application of social networks as well as recommender systems, the relation between these research areas is still unclear. An innovative idea, which enables to integrate these areas, and applies recommendation systems to the big data systems, is proposed in this paper. Recommendation systems for machine learning and data mining differ from the typical kinds of recommendation solutions, since they suggest human beings to other ones rather than inanimate goods. Thus, conventional recommendation methods should be enhanced by their features of the networks and their members. This paper presents the result of the study on the recommendation framework for cloud environment. It also contains an overview of recent approaches to recommendation systems.","","Electronic:978-1-4673-9849-7; POD:978-1-4673-9850-3","10.1109/DTA.2015.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433712","Big Data System;Machine Learning;Recommendation System","Databases","Big Data;data mining;learning (artificial intelligence);recommender systems;social networking (online)","big data platform;conceptual recommender system;data mining;machine learning;social networks","","","","30","","","25-28 Nov. 2015","","IEEE","IEEE Conference Publications"
"Towards a Hybrid Imputation Approach Using Web Tables","A. Ahmadov; M. Thiele; J. Eberius; W. Lehner; R. Wrembel","Sch. of Electr. & Comput. Eng., Dresden Univ. of Technol., Dresden, Germany","2015 IEEE/ACM 2nd International Symposium on Big Data Computing (BDC)","20160215","2015","","","21","30","Data completeness is one of the most important data quality dimensions and an essential premise in data analytics. With new emerging Big Data trends such as the data lake concept, which provides a low cost data preparation repository instead of moving curated data into a data warehouse, the problem of data completeness is additionally reinforced. While traditionally the process of filling in missing values is addressed by the data imputation community using statistical techniques, we complement these approaches by using external data sources from the data lake or even the Web to lookup missing values. In this paper we propose a novel hybrid data imputation strategy that, takes into account the characteristics of an incomplete dataset and based on that chooses the best imputation approach, i.e. either a statistical approach such as regression analysis or a Web-based lookup or a combination of both. We formalize and implement both imputation approaches, including a Web table retrieval and matching system and evaluate them extensively using a corpus with 125M Web tables. We show that applying statistical techniques in conjunction with external data sources will lead to a imputation system which is robust, accurate, and has high coverage at the same time.","","Electronic:978-0-7695-5696-3; POD:978-1-5090-0340-2","10.1109/BDC.2015.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406326","Data preprocessing;Machine learning;Web mining","Big data;Companies;Data analysis;Data mining;Indexes;Industries;Lakes","Internet;pattern matching;table lookup","Web table matching system;Web table retrieval;Web-based lookup;data completeness;hybrid data imputation strategy;regression analysis","","","","18","","","7-10 Dec. 2015","","IEEE","IEEE Conference Publications"
"MRSL: Autonomous Neural Network-Based 3-D Positioning System","H. Hedayati; N. Tabrizi","Dept. of Comput. Sci., East Carolina Univ., Greenville, NC, USA","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","170","174","Stabilizing and localizing the positioning systems autonomously in the areas without GPS accessibility is a difficult task. In this paper we describe a methodology called Most Reliable Straight Line (MRSL) for stabilizing and positioning camera-based objects in 3-D space. The camera-captured images are used to identify easy-to-track points ""interesting points"" and track them on two consecutive images. The distance between each of interesting points on the two consecutive images are compared and one with the maximum length is assigned to MRSL, which is used to indicate the deviation from the original position. To correct this our trained algorithm is deployed to reduce the deviation by issuing relevant commands, this action is repeated until MRSL converges to zero. To test the accuracy and robustness, the algorithm was deployed to control positioning of a Quadcopter. It was demonstrated that the Quadcopter (a) was highly robust to any external forces, (b) can fly even if the Quadcopter experiences loss of engine, (c) can fly smoothly and positions itself on a desired location.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424085","Artificial Intelligence;Machine Learning;Neural Networks","Artificial neural networks;Brushless motors;Cameras;Convergence;Feature extraction;Robustness","helicopters;image capture;neural nets;object tracking;position control","MRSL;autonomous neural network-based 3D positioning system;camera-based object positioning;camera-captured images;easy-to-track points;interesting points;most reliable straight line methodology;quadcopter positioning control","","","","16","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Probabilistic Fuzzy Naive Bayes","G. Moura; M. Roisenberg","Dept. of Inf. & Stat., Fed. Univ. of Santa Catarina, Florianopolis, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","246","251","Bayesian networks are probabilistic graphical models capable of modeling statistical uncertainty and are widely applied in many classification problems. Specifically, Naive Bayesian networks are largely used due to their simple, naive structure, while still producing precise results. Fuzzy systems, on the other hand, are a well known technique capable of dealing with linguistic vagueness by representing knowledge with simple and interpretable rules and membership functions. As traditional fuzzy systems are unable to model statistical uncertainty, Probabilistic Fuzzy Systems were developed in order to account for both kinds of uncertainties. In this work we propose the Probabilistic Fuzzy Naive Bayes classifier as a combination of both probabilistic fuzzy systems and naive bayesian networks, also capable of simultaneously modeling both kinds of uncertainties. The proposed model is firstly applied in a very simple classification problem in order to show its potential and advantage over traditional naive bayes classifiers, while maintaining their interpretability. For validation, experiments were done using benchmark classification data sets from the UCI machine learning repository and the results are then compared with other similar alternate methods.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424027","Probabilistic fuzzy systems;bayesian networks;machine learning;naive bayes classifiers;uncertainty","Bayes methods;Fuzzy systems;Pragmatics;Probabilistic logic;Probability density function;Uncertainty","belief networks;computational linguistics;fuzzy systems;learning (artificial intelligence);pattern classification;probability","Naive Bayesian networks;UCI machine learning repository;knowledge representation;linguistic vagueness;probabilistic fuzzy Naive Bayes classifier;probabilistic fuzzy systems;probabilistic graphical models;statistical uncertainty modeling","","","","23","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"Comparative analysis of nature inspired algorithms on data clustering","P. Agarwal; S. Mehta","Department of Computer Science and Information Technology, Jaypee Institute of Information Technology, Noida, India","2015 IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)","20160317","2015","","","119","124","K-Means clustering is well accepted clustering algorithm that huddle similar data objects in a simple and quick way. The convergence speed of K-Means clustering is quite appreciable but it has drawback of getting stuck into local optima. Hence, optimal clustering results are not attained. Nature inspired algorithm when integrated with clustering algorithm provides global optimal solution. The paper analyzes three nature inspired algorithms i.e. firefly algorithm, bat algorithm, and flower pollination algorithm integrated with K-Means clustering. The study is performed on four real life datasets obtained from UCI machine learning repository and two simulated datasets. Algorithms are evaluated on the basis of number of fitness function and CPU time per run. It is observed from experimental study that integrated flower pollination algorithm with K-Means overrule the other two algorithm on each datasets.","","CD-ROM:978-1-4673-6734-9; Electronic:978-1-4673-6735-6; POD:978-1-4673-6736-3","10.1109/ICRCICN.2015.7434221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434221","Bat algorithm;CPU time per run;Firefly algorithm;Flower pollination algorithm;K-Means;Nature Inspired Algorihms;fitness function;machine learning repository","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Information technology;Machine learning algorithms;Particle swarm optimization;Prediction algorithms","evolutionary computation;learning (artificial intelligence);pattern clustering","K-means clustering;UCI machine learning repository;bat algorithm;data clustering;firefly algorithm;flower pollination algorithm;nature inspired algorithm","","","","22","","","20-22 Nov. 2015","","IEEE","IEEE Conference Publications"
"Model Based Sampling - Fitting an Ensemble of Models into a Single Model","T. Lindgren","Dept. of Comput. & Syst. Sci., Stockholm Univ., Kista, Sweden","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","186","191","Large ensembles of classifiers usually outperform single classifiers. Unfortunately ensembles have two major drawbacks compared to single classifier, interpretability and classifications times. Using the Combined Multiple Models (CMM) framework for compressing an ensemble of classifiers into a single classifier the problems associated with ensembles can be avoided while retaining almost similar classification power as that of the original ensemble. One open question when using CMM concerns how to generate values that constitute the synthetic example. In this paper we present a novel method for generating synthetic examples by utilizing the structure of the ensemble. This novel method is compared with other methods for generating synthetic examples using the CMM framework. From the comparison it is concluded that the novel method outperform the other methods.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424088","Approximation algorithms;Machine learning algorithms;Sampling methods;Supervised learning","Coordinate measuring machines;Data models;Gaussian distribution;Predictive models;Standards;Training;Training data","learning (artificial intelligence);pattern classification;sampling methods","CMM framework;classifier ensemble compression;combined-multiple models;ensemble structure;model-based sampling fitting","","","","8","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Soccer Events Summarization by Using Sentiment Analysis","S. Jai-Andaloussi; I. E. Mourabit; N. Madrane; S. B. Chaouni; A. Sekkaki","Fac. of Sci., Hassan II Univ. - Casablanca, Casablanca, Morocco","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","398","403","In this paper, we propose a framework for automatic textual soccer summarization based on real-time sentiment analysis of Twitter events. The interaction of fans on Twitter is marked by the expression of their sentiments through their tweets, they can be positive or negative depending on the event in soccer games. Our framework analyzes the sentiments expressed on Twitter with the goal to detect and predict the team supported by each fan as well as actors (the team(s) and player(s) concerned(s)) and the details associated with each event. All this information is used to draw up a summary of soccer matches. The summary is constructed using machine learning and KDD process that allows the extraction of knowledge from data in the context of large databases. Through the realized experiments, we confirm that the results are promising and this work has allowed us to verify the feasibility and efficiency of soccer events summarization by using sentiment analysis in media streams.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424124","Machine learning;Sentiment Analysis;Soccer Events Summarization;Text Mining","Data mining;Databases;Fans;Games;Sentiment analysis;Tagging;Twitter","Web sites;data mining;learning (artificial intelligence);media streaming;sentiment analysis;sport","KDD process;Twitter event;automatic textual soccer summarization;knowledge extraction;machine learning;media stream;real-time sentiment analysis;soccer events summarization;soccer game;soccer match","","","","8","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Playing the Odds: Decision Support and Risk Assessment in an Elastic Framework","D. Clarke; J. Jarrett; M. B. Blake","Dept. of Comput. Sci., Univ. of Miami, Coral Gables, FL, USA","2015 IEEE Conference on Collaboration and Internet Computing (CIC)","20160303","2015","","","99","105","Crowd sourcing is a paradigm where activities are outsourced to human actors (i.e. The crowd) with the aim of discovering and evaluating solutions. This paradigm can also be extended to develop a collective intelligence of large-scale crowd communities that when combined with traditional computing resources can derive solutions that neither humans nor machines can solve alone. Such hybrid systems, or elastic systems, could involve large numbers of people with varying expertise, skills, interests, and incentives and varied computing resources. Elastic frameworks have been proposed to improve the performance of these systems to make them more efficient, robust, and scalable. To meet these requirements, we investigate a novel approach that provides decision support and risk assessment in an elastic framework. In our approach, we infer a probabilistic framework of a hybrid system and use probabilistic odds as a quantitative measure of the capability of human and computing resources to execute a task. As new evidence becomes available, we propagate updated odds throughout our framework to update our prior belief and risks for computing elements. In this approach, the elastic framework can exploit this information in such a way that self-learning is coupled with the ability to extract actionable insights that optimize judgment under uncertainty.","","Electronic:978-1-5090-0089-0; POD:978-1-5090-0090-6","10.1109/CIC.2015.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423070","crowdsourcing;elastic framework;machine learning","Bayes methods;Computational efficiency;Face recognition;Image recognition;Probabilistic logic;Risk management;Uncertainty","Internet;decision support systems;probability;risk management","collective intelligence;computing resources;crowd sourcing;decision support;elastic framework;human capability;large-scale crowd communities;participative online activity;prior belief;probabilistic framework;probabilistic odds;risk assessment;self-learning","","","","24","","","27-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"Building the Dresden Web Table Corpus: A Classification Approach","J. Eberius; K. Braunschweig; M. Hentsch; M. Thiele; A. Ahmadov; W. Lehner","Database Syst. Group, Tech. Univ. Dresden, Dresden, Germany","2015 IEEE/ACM 2nd International Symposium on Big Data Computing (BDC)","20160215","2015","","","41","50","In recent years, researchers have recognized relational tables on the Web as an important source of information. To assist this research we developed the Dresden Web Tables Corpus (DWTC), a collection of about 125 million data tables extracted from the Common Crawl (CC) which contains 3.6 billion web pages and is 266TB in size. As the vast majority of HTML tables are used for layout purposes and only a small share contains genuine tables with different surface forms, accurate table detection is essential for building a large-scale Web table corpus. Furthermore, correctly recognizing the table structure (e.g. horizontal listings, matrices) is important in order to understand the role of each table cell, distinguishing between label and data cells. In this paper, we present an extensive table layout classification that enables us to identify the main layout categories of Web tables with very high precision. We therefore identify and develop a plethora of table features, different feature selection techniques and several classification algorithms. We evaluate the effectiveness of the selected features and compare the performance of various state-of-the-art classification algorithms. Finally, the winning approach is employed to classify millions of tables resulting in the Dresden Web Table Corpus (DWTC).","","Electronic:978-0-7695-5696-3; POD:978-1-5090-0340-2","10.1109/BDC.2015.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406328","Classification;Data preprocessing;Machine learning;Web mining","Buildings;Decision trees;Discrete wavelet transforms;Feature extraction;HTML;Layout;Web pages","Internet;data mining;feature extraction;pattern classification","DWTC;Dresden Web table corpus;HTML tables;Web pages;common crawl;feature selection techniques;table layout classification;table structure","","","1","22","","","7-10 Dec. 2015","","IEEE","IEEE Conference Publications"
"Relevant evidence acquisition and appraisal using knowledge-intensive queries","M. Afzal; S. Lee","Department of Computer Engineering, Kyung Hee University, Seocheon-dong, Republic of Korea, 446-701","2016 18th International Conference on Advanced Communication Technology (ICACT)","20160303","2016","","","703","709","Information needs of the users have grown exponentially with the advent of advancements in information and communication technology. The traditional ways of searching information from the online resources has been evolved and the tendency is geared more towards getting quality contents. In healthcare domain, the clinical researchers and physicians are even more interested to find quality information to use as a clinical evidence in decision making. An increasing number of potential articles in the form of MEDLINE articles are readily available to be retrieved, helps in evidence-based clinical decisions, however, the retrieval methods pose several challenges to clinicians. The first challenge is to automatically reformulate the user query into a knowledge-intensive query in order to acquire articles that are relevant to user needs. The second challenge is to re-evaluate the retrieved articles in order to get quality studies and filter-out all the low quality articles. In this paper, we approach to solve these challenges by proposing two methods to construct knowledge-intensive query for relevant evidence acquisition and statistical model for quality evidence appraisal. The construction of knowledge-intensive query is based on the term expansion using domain model, name variants, and terminological variants. The statistical model is learnt on a corpus prepared through automatic construction of feature vectors from data and metadata features. We evaluate the results at two levels; 1) pre-appraisal stage, 2) post-appraisal stage. We compared the results based on the retrieved result sets with knowledge-intensive query approach and simple query approach. The proposed knowledge-intensive query approach successfully retrieves the potential evidences with average 12.33% improved accuracy in contrast to simple query approach. Furthermore, we performed human evaluation to identify the overall satisfaction of the proposed approach. From the user input, we learned - hat the proposed approach contributes to maximizing the clinical throughput of clinicians by minimizing the unnecessary intermediary manual steps in evidence retrieval and the appraisal process.","","CD:978-8-9968-6507-0; Electronic:978-8-9968-6506-3","10.1109/ICACT.2016.7423528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423528","Content-based retrieval;Evidence Appraisal;Information filtering;Keyword search;Machine learning","Appraisal;Cavity resonators;Chemotherapy;Classification algorithms;Databases;Kernel;Lymph nodes","decision making;feature extraction;health care;information needs;learning (artificial intelligence);meta data;query formulation;query processing;statistical analysis","MEDLINE articles;article quality;clinical evidence;clinical physicians;clinical research;clinical throughput maximization;content quality;decision making;domain model;evidence retrieval;evidence-based clinical decision;feature vector;healthcare domain;information and communication technology;information needs;information searching;knowledge-intensive queries;metadata features;name variant;online resources;relevant evidence acquisition;relevant evidence appraisal;statistical model learning;term expansion;terminological variant;user query reformulation","","","","26","","","Jan. 31 2016-Feb. 3 2016","","IEEE","IEEE Conference Publications"
"Fingerprint Liveness Detection Using Convolutional Neural Networks","R. F. Nogueira; R. de Alencar Lotufo; R. Campos Machado","Department of Computer Science, New York University, New York, NY, USA","IEEE Transactions on Information Forensics and Security","20160323","2016","11","6","1206","1213","With the growing use of biometric authentication systems in the recent years, spoof fingerprint detection has become increasingly important. In this paper, we use convolutional neural networks (CNNs) for fingerprint liveness detection. Our system is evaluated on the data sets used in the liveness detection competition of the years 2009, 2011, and 2013, which comprises almost 50 000 real and fake fingerprints images. We compare four different models: two CNNs pretrained on natural images and fine-tuned with the fingerprint images, CNN with random weights, and a classical local binary pattern approach. We show that pretrained CNNs can yield the state-of-the-art results with no need for architecture or hyperparameter selection. Data set augmentation is used to increase the classifiers performance, not only for deep architectures but also for shallow ones. We also report good accuracy on very small training sets (400 samples) using these large pretrained networks. Our best model achieves an overall rate of 97.1% of correctly classified samples-a relative improvement of 16% in test error when compared with the best previously published results. This model won the first prize in the fingerprint liveness detection competition 2015 with an overall accuracy of 95.5%.","1556-6013;15566013","","10.1109/TIFS.2016.2520880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390065","Fingerprint recognition;machine learning;neural networks;supervised learning","Convolution;Feature extraction;Fingerprint recognition;Kernel;Neural networks;Principal component analysis;Support vector machines","feedforward neural nets;fingerprint identification;learning (artificial intelligence);object detection","biometric authentication systems;convolutional neural networks;data sets;fingerprint liveness detection;fingerprint recognition;local binary pattern approach;machine learning;random weights;supervised learning","","4","","45","","20160122","June 2016","","IEEE","IEEE Journals & Magazines"
"Fest: A feature extraction and selection tool for Android malware detection","K. Zhao; D. Zhang; X. Su; W. Li","College of Computer Science and Electronics Engineering, Hunan University, Changsha, China","2015 IEEE Symposium on Computers and Communication (ISCC)","20160215","2015","","","714","720","Android has become one of the most popular mobile operating systems because of numerous applications (apps) it provides. However, Android malware downloaded from third-party markets threatens users' privacy, and most of them remain undetected because of the lack of efficient and accurate detecting techniques. Prior efforts on Android malware detection attempted to build precise classification models by manually choosing features, and few of them has used any feature selection algorithms to help pick typical features. In this paper, we present Feature Extraction and Selection Tool (Fest), a feature-based machine learning approach for malware detection. We first implement a feature extraction tool, AppExtractor, which is designed to extract features, such as permissions or APIs, according to the predefined rules. Then we propose a feature selection algorithm, FrequenSel. Unlike existing selection algorithms which pick features by calculating their importance, FrequenSel selects features by finding the difference their frequencies between malware and benign apps, because features which are frequently used in malware and rarely used in benign apps are more important to distinguish malware from benign apps. In experiments, we evaluate our approach with 7972 apps, and the results show that Fest gets nearly 98% accuracy and recall, with only 2% false alarms. Moreover, Fest only takes 6.5s to analyze an app on a common PC, which is very time-efficient for malware detection in Android markets.","","Electronic:978-1-4673-7194-0; POD:978-1-4673-7195-7","10.1109/ISCC.2015.7405598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405598","feature selection;machine learning;malware;privacy","Algorithm design and analysis;Androids;Feature extraction;Humanoid robots;Machine learning algorithms;Malware;Support vector machines","Android (operating system);feature extraction;feature selection;invasive software;learning (artificial intelligence)","Android malware detection;AppExtractor;FEST;FrequenSel;feature extraction and selection tool;feature-based machine learning approach;mobile operating systems;precise classification models","","","","19","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"A novel sparse ensemble pruning algorithm using a new diversity measure","S. Shukla; J. Sharma; S. Khare; S. Kochkar; V. Dharni","CSE department, MANIT, Bhopal, India 462003","2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)","20160321","2015","","","1","4","Extreme learning machine is state of art supervised machine learning technique for classification and regression. A single ELM classifier can however generate faulty or skewed results due to random initialization of weights between input and hidden layer. To overcome this instability problem ensemble methods can be employed. Ensemble methods may have problem of redundancy i.e. ensemble may contain several redundant classifiers which can be weak or highly correlated classifiers. Ensemble pruning can be used to remove these redundant classifiers. The pruned ensemble should not only be accurate but diverse as well in order to correctly classify boundary instances. This work proposes an ensemble pruning algorithm which tries to establish a tradeoff between accuracy and diversity. The paper also proposes a metric which scores classifiers based on their diversity and contribution towards the ensemble. The results show that the pruned ensemble performs equally well or in some cases even better as compared to the unpruned set in terms of accuracy and diversity. The results of the experiments show that the proposed algorithm performs better than VELM. The proposed algorithm reduces the ensemble size to less than 60 % of the original ensemble size (original ensemble size is set to 50).","","CD-ROM:978-1-4799-7847-2; Electronic:978-1-4799-7849-6; POD:978-1-4799-7850-2","10.1109/ICCIC.2015.7435815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435815","Accuracy and Diversity;Classification;Ensemble Pruning;Extreme Learning Machine;Voting Based Extreme Learning Machine","Classification algorithms;Conferences;Measurement;Neurons;Prediction algorithms;Time complexity","learning (artificial intelligence);pattern classification","ELM classifier;boundary instance classification;ensemble pruning algorithm;ensemble size;extreme learning machine;hidden layer;highly correlated classifiers;instability problem;random initialization;regression;supervised machine learning technique","","","","24","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers","C. Verma; M. Hart; S. Bhatkar; A. Parker-Wood; S. Dey","Department of Electrical and Computer EngineeringMobile Systems Design Laboratory, University of California at San Diego, San Diego, CA, USA","IEEE Access","20160301","2016","4","","204","215","Enterprise knowledge workers have been overwhelmed by the growing rate of incoming data in recent years. In this paper, we present a recommendation system with the goal of helping knowledge workers in discovering useful new content. In particular, our system builds personalized user models based on file activities on enterprise network file servers. Our models use novel features that are derived from file metadata and user collaboration. Through extensive evaluation on real-world enterprise data, we demonstrate the effectiveness of our system with high precision and recall values. Unfortunately, our experiments reveal that per-user models are unable to handle heavy workloads. To address this limitation, we propose a novel optimization technique, active feature-based model selection, that predicts the user models that should be applied on each test file. Such a technique can reduce the classification time per file by as much as 23 times without sacrificing accuracy. We also show how this technique can be extended to improve the scalability exponentially at marginal cost of prediction accuracy, e.g., we can gain 169 times faster performance on an average across all shares by sacrificing 4% of F-score.","2169-3536;21693536","","10.1109/ACCESS.2015.2513000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368090","Enterprise;File systems;Information Retrieval;Information retrieval;Machine Learning;enterprise;file systems;machine learning","Computational modeling;Feature extraction;File systems;Information retrieval;Machine learning;Metadata;Predictive models","feature selection;information retrieval;meta data;optimisation;recommender systems","active feature-based model selection;enterprise knowledge workers;file metadata;information retrieval;novel optimization technique;personalized recommendation systems;personalized user models;user collaboration","","","","24","","20151229","2016","","IEEE","IEEE Journals & Magazines"
"Comparing PCA to information gain as a feature selection method for Influenza-A classification","N. Shaltout; M. Moustafa; A. Rafea; A. Moustafa; M. ElHefnawi","Computer Science & Engineering Department; Biology, Department, School of Sciences and Engineering. The American University of Cairo., New Cairo, Cairo 11835, Egypt","2015 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)","20160324","2015","","","279","283","The paper compares the use of Principal Component Analysis (PCA) to Information Gain (IG) as a feature selection method for improving the classification of Influenza-A antiviral resistance. Neural networks were used as the classification method of choice. The experiment was conducted on cDNA viral segments of Influenza-A belonging to the H1N1 strain. Sequences from each segment were further divided into Adamantane-resistant, and non-Adamantane-resistant. Accuracy, sensitivity, specificity precision and time were used as performance measures. Using PCA for feature selection increased preprocessing speeds from an average processing time of 1.5 hours to 5 minutes, as opposed to IG. The performance also stayed comparable with that of the previous results achieved using IG.","","Electronic:978-1-4799-8562-3; POD:978-1-4799-8563-0; USB:978-1-4799-8561-6","10.1109/ICIIBMS.2015.7439550","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439550","Influenza-A;PCA;antiviral-resistance classification;bioinformatics;feature selection;information gain;machine learning;neural networks","Bioinformatics;Feature extraction;Hidden Markov models;Immune system;Principal component analysis;Proteins;Strain","biocomputing;bioinformatics;feature selection;neural nets;principal component analysis;two-dimensional electron gas","H1N1 strain;Influenza-A classification;PCA;cDNA viral segment;feature selection method;information gain;neural network;nonAdamantane-resistant;principal component analysis","","","","13","","","28-30 Nov. 2015","","IEEE","IEEE Conference Publications"
"Sentiment analysis of a document using deep learning approach and decision trees","A. S. Zharmagambetov; A. A. Pak","LLC AlemResearch, Almaty, Kazakhstan","2015 Twelve International Conference on Electronics Computer and Computation (ICECCO)","20160225","2015","","","1","4","The given paper describes modern approach to the task of sentiment analysis of movie reviews by using deep learning recurrent neural networks and decision trees. These methods are based on statistical models, which are in a nutshell of machine learning algorithms. The fertile area of research is the application of Google's algorithm Word2Vec presented by Tomas Mikolov, Kai Chen, Greg Corrado and Jeffrey Dean in 2013. The main idea of Word2Vec is the representations of words with the help of vectors in such manner that semantic relationships between words preserved as basic linear algebra operations. The extra advantage of the mentioned algorithm above the alternatives is computational efficiency. This paper focuses on using Word2Vec model for text classification by their sentiment type.","","Electronic:978-1-5090-0200-9; POD:978-1-5090-0201-6","10.1109/ICECCO.2015.7416902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416902","NLP;deep learning;machine learning;sentiment analysis;text classification","Classification algorithms;Computational modeling;Machine learning;Motion pictures;Semantics;Sentiment analysis;Text categorization","decision trees;document handling;learning (artificial intelligence);sentiment analysis","Google algorithm Word2Vec;Word2Vec model;basic linear algebra operations;computational efficiency;deep learning recurrent neural networks;document;fertile area;machine learning algorithms;movie reviews;nutshell;sentiment analysis;sentiment type;statistical models;text classification","","","","18","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Application of Support Vector Machine to Recognize Trans-differentiated Neural Progenitor Cells for Bright-Field Microscopy","B. Jiang; X. Wang; Q. Gao; Z. Lin; R. Zhang; X. Zhang","Guangzhou Inst. of Biomed. & Health, Guangzhou, China","2015 Fifth International Conference on Instrumentation and Measurement, Computer, Communication and Control (IMCCC)","20160215","2015","","","215","219","One possible solution of the investigation of the cell fate decision and its function is the study of cell morphology. Bright-field imaging analysis allow us to use a labeling free and non-invasive approach to measure the morphological dynamics during cellular reprogramming, which includes induced pluripotent stem cells (iPSCs), and trans-differentiated neural progenitor cells (NPCs) from somatic cell source. In order to automatically analyze and cultivate cells, a system classifying NPCs under bright-field microscopic imaging is necessary. In this paper, we investigate the use of support vector machine (SVM) based on a set of features for this task. The results illustrate that such a data driven approach has remarkable recognition and generalization performance.","","Electronic:978-1-4673-7723-2; POD:978-1-4673-7724-9","10.1109/IMCCC.2015.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405831","bright-field microscopy;cell recognition;machine learning;support vector machine;trans-differentiated neural progenitor cells","Cells (biology);Electronic mail;Feature extraction;Image recognition;Microscopy;Support vector machines;Training","biology computing;microscopy;support vector machines","NPC;SVM;bright-field imaging analysis;bright-field microscopy;cell fate decision;cell morphology;cellular reprogramming;data driven approach;iPSC;induced pluripotent stem cells;labeling free approach;noninvasive approach;somatic cell source;support vector machine;transdifferentiated neural progenitor cells","","","","19","","","18-20 Sept. 2015","","IEEE","IEEE Conference Publications"
"A parallel dynamic programming approach for data analysis","A. Deepak; K. S. Shravya; K. Chandrasekaran","Department of Computer Science and Engineering, National Institute of Technology, Surathkal, Mangalore Karnataka","2015 IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)","20160317","2015","","","214","219","In spite of presence of many classical and modified data analysis techniques, data analysis in the field of software engineering still remains a challenge because of the presence of large number of both continuous and discreet explanatory variables judging the outcome of one and more than one dependant variables. Requirement for an efficient multivariate data analysis technique which fulfils the constraints associated with software data led to the design of OSR (optimized set reduction) which uses a greedy algorithm for data analysis using both the principles of machine learning and conventional statistics. With the incoming of big data and other increasing dimensions of data set, we, through this paper, try to propose a new algorithm, based on the similar lines of optimised set reduction, using its strength to extract subsets. As the current trend of programming demands an algorithm to execute in parallel, we also propose a modification to our algorithm for it to run in a multicore platform with good efficiency.","","CD-ROM:978-1-4673-6734-9; Electronic:978-1-4673-6735-6; POD:978-1-4673-6736-3","10.1109/ICRCICN.2015.7434238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434238","Data Analysis;Machine Learning;Optimised Set Reduction;Pattern Recognition;Predictive Models;Software Engineering","Algorithm design and analysis;Data analysis;Entropy;Heuristic algorithms;Prediction algorithms;Software;Software algorithms","data analysis;dynamic programming;learning (artificial intelligence);multiprocessing systems;parallel programming;software engineering","OSR;conventional statistics;data analysis;greedy algorithm;machine learning;multicore platform;optimized set reduction;parallel dynamic programming approach;software engineering;subset extraction","","","","15","","","20-22 Nov. 2015","","IEEE","IEEE Conference Publications"
"Frechet distance for model observer training data selection","I. Lorente; J. G. Brankov","Electrical and Computer Engineering Department, Illinois Institute of Technology, Chicago, 60616 USA","2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)","20160314","2014","","","1","3","In medical imaging, it has become widely accepted that image quality should be assessed using a task-based approach in which, for example, one evaluates human observer detection accuracy for a specific diagnostic task. These evaluations should be integral part of an imaging system optimization and testing. However, human observer studies with expert readers are costly and time-demanding. Consequently, model observers (MO) have been used as surrogates to predict human diagnostic performance. MOs use features derived from the images to accomplish these predictions. Some types of MOs require a set of data evaluated by humans for model tuning. In this work we present a methodology for tuning data selection. This selection is based on the Frechet distance between image-feature distributions. Specifically, in our experiments we show that MO, based on the Relevance Vector Machine (RVM), trained with the selected small subset of data has excellent performance in predicting human observer for diagnostic tasks.","","Electronic:978-1-4799-6097-2; POD:978-1-4799-6098-9","10.1109/NSSMIC.2014.7430957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7430957","Active Learning;Bayesian Learning;Frechet Distance;Image Quality Assessment;Machine Learning;Model observer;SPECT","Bayes methods;Biomedical imaging;Feature extraction;Image quality;Image reconstruction;Observers;Support vector machines","biomedical optical imaging;feature extraction;medical image processing;support vector machines","Frechet distance;RVM;Relevance Vector Machine;human diagnostic performance;image quality;image-feature distributions;medical imaging;model observer training data selection;model tuning","","","","14","","","8-15 Nov. 2014","","IEEE","IEEE Conference Publications"
"Gene expression profiles based Human cancer diseases classification","H. Salem; G. Attiya; N. El-Fishawy","Communications & Computer Department, Faculty of Engineering, Delta University, Mansoura, Egypt","2015 11th International Computer Engineering Conference (ICENCO)","20160225","2015","","","181","187","Cancers are a large family of diseases that involve abnormal cell growth with the potential to spread to other parts of the body. A cancer disease in any of its forms represents a major cause of death worldwide. In cancer diagnosis, classification of different tumor types is of the greatest significance. Accuracy for prediction of various tumor types gives better treatment and minimization of toxicity on patients. Accordingly, creating methodologies that can effectively differentiate between cancer subtypes is essential. This paper presents a new methodology to classify Human cancer diseases based on the gene expression profiles. The proposed methodology combines both Information gain (IG) and Deep Genetic Algorithm (DGA). It first uses IG for feature selection, then uses Genetic Algorithm (GA) for feature reduction and finally uses Genetic Programming (GP) for cancer types' classification. The proposed system is evaluated by classifying cancer diseases in seven cancer datasets and the results are compared with most recent approaches.","","Electronic:978-1-5090-0275-7; POD:978-1-5090-0276-4","10.1109/ICENCO.2015.7416345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416345","Cancer Diagnosis/Classification;Decision Support System;Feature Selection;Gene Expression;Genetic Algorithm;Information Gain;Machine Learning","Cancer;Colon;Diseases;Lungs;Morphology;Tumors","cancer;cellular biophysics;feature selection;genetic algorithms;genetics;medical computing;patient treatment;pattern classification","DGA;abnormal cell growth;cancer diagnosis;cancer types classification;deep genetic algorithm;feature reduction;feature selection;gene expression profiles;genetic programming;human cancer diseases classification;information gain;patient treatment;toxicity minimization;tumor type classification","","","","43","","","29-30 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Support Vector Machine-Based Framework for Detection of Covert Timing Channels","P. L. Shrestha; M. Hempel; F. Rezaei; H. Sharif","Department of Computer and Electronics Engineering, University of Nebraska-Lincoln 1110 S. 67th St., Omaha, NE","IEEE Transactions on Dependable and Secure Computing","20160310","2016","13","2","274","283","Covert channels exploit side channels within existing network resources to transmit secret messages. They are integrated into the elements of network resources that were not even designed for the purpose of communication. This means that traditional security features like firewalls cannot detect them. Their ability to evade detection makes covert channels a grave security concern. Hence, it is imperative to detect and disrupt them. However, a generic mechanism that can be used to detect a large variety of covert channels is missing. In this paper, we propose a support vector machine (SVM)-based framework for reliable detection of covert communications. The machine learning framework utilizes the fingerprints derived from the traffic under investigation to classify the traffic as covert or overt. We trained our classifier using the fingerprints from four popular and diverse covert timing channel algorithms and tested each of them independently. We have shown that the machine learning framework has great potential to blindly detect covert channels, even when the covert message size is reduced.","1545-5971;15455971","","10.1109/TDSC.2015.2423680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087364","Covert Channels;Covert channels;Detection;Machine Learning;Traffic Fingerprints;detection;machine learning;traffic fingerprints","Classification algorithms;Delays;Entropy;Fingerprint recognition;Receivers;Support vector machines","learning (artificial intelligence);pattern classification;security of data;support vector machines","SVM;covert communication detection;covert timing channel detection;generic mechanism;machine learning;secret message transmission;side channels;support vector machine-based framework;traffic classification","","1","","23","","20150416","March-April 1 2016","","IEEE","IEEE Journals & Magazines"
"Kernel Methods for Accurate UWB-Based Ranging With Reduced Complexity","V. Savic; E. G. Larsson; J. Ferrer-Coll; P. Stenumgaard","Department of Electrical Engineering (ISY), Link&#246;ping University, Link&#x00F6;ping, Sweden","IEEE Transactions on Wireless Communications","20160308","2016","15","3","1783","1793","Accurate and robust positioning in multipath environments can enable many applications, such as search-and-rescue and asset tracking. For this problem, ultra-wideband (UWB) technology can provide the most accurate range estimates, which are required for range-based positioning. However, UWB still faces a problem with non-line-of-sight (NLOS) measurements, in which the range estimates based on time-of-arrival (TOA) will typically be positively biased. There are many techniques that address this problem, mainly based on NLOS identification and NLOS error mitigation algorithms. However, these techniques do not exploit all available information in the UWB channel impulse response. Kernel-based machine learning methods, such as Gaussian process regression (GPR), are able to make use of all information, but they may be too complex in their original form. In this paper, we propose novel ranging methods based on kernel principal component analysis (kPCA), in which the selected channel parameters are projected onto a nonlinear orthogonal high-dimensional space, and a subset of these projections is then used as an input for ranging. We evaluate the proposed methods using real UWB measurements obtained in a basement tunnel, and found that one of the proposed methods is able to outperform state-of-the-art, even if little training samples are available.","1536-1276;15361276","","10.1109/TWC.2015.2496584","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7313038","Gaussian process regression;Ranging;kernel principal component analysis;machine learning;positioning;ranging;time-of arrival;time-of-arrival;ultra-wideband","Distance measurement;Eigenvalues and eigenfunctions;Ground penetrating radar;Kernel;Nonlinear optics;Principal component analysis;Training","learning (artificial intelligence);operating system kernels;principal component analysis;telecommunication computing;time-of-arrival estimation;transient response;ultra wideband communication;wireless channels","NLOS error mitigation algorithm;NLOS identification algorithm;TOA estimation;UWB channel impulse response;UWB measurement;UWB-based ranging;basement tunnel;complexity reduction;kPCA;kernel principal component analysis;kernel-based machine learning method;multipath environment;nonline-of-sight measurement;nonlinear orthogonal high-dimensional space;range-based positioning;robust positioning;time-of-arrival estimation;ultra-wideband technology","","1","","26","","20151030","March 2016","","IEEE","IEEE Journals & Magazines"
"Drug discovery for breast cancer based on big data analytics techniques","R. M. Constantine; M. Batouche","Constantine 2 University - Abdelhamid Mehri, Faculty of NTIC, Computer Science Department, Constantine 25000, Algeria","2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)","20160310","2015","","","1","6","Scientific research are nowadays faced to very massive data processing, which consume relatively too much time and effort, that's why researchers have turned to high performance computational (HPC) techniques. In the same context, research on drug discovery has reached a place where it has no choice but using HPC and Big Data Processing Systems to accomplish its objectives in reasonable periods of time, Virtual Screening (VS) is considered as one of the most computationally intensive and heavy process, it plays an important role in designing new drugs and has to be done as fast as possible in order to effectively dock ligands in huge databases to a given protein receptor. On the other hand, breast cancer is one of the most dangerous diseases of world, in the last decade; more than 1.5 million new cases are diagnosed each year, with more than 400 thousands deaths. These statistics give very great importance to drug research for this disease. In this context, and in order to ameliorate the drug designing process for breast cancer, we propose in this work, to use Machine Learning Algorithms that are designed for Big Data analysis on top of MapReduce and Mahout in order to pre-filter the huge set of ligands to effectively do virtual screening for the breast cancer protein receptor.","","Electronic:978-1-4673-8749-1; POD:978-1-4673-8750-7","10.1109/ICTA.2015.7426878","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426878","Big Data analytics;Breast Cancer;Docking;Machine Learning;Mahout;MapReduce;Virtual Screening","Big data;Breast cancer;Chemicals;Drugs;Libraries;Proteins;Software","Big Data;cancer;data analysis;drugs;information filters;learning (artificial intelligence);medical computing;parallel processing","Big Data analytics techniques;Mahout;MapReduce;breast cancer protein receptor;drug discovery;machine learning algorithms;prefilter;virtual screening","","","","33","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Learning matte extraction in green screen images with MLP classifiers and the back-propagation algorithm","R. Rosas-Romero; O. Lopez-Rincon; E. David Rojas; N. P. Jacobo","Universidad de las Am&#233;ricas Puebla","2016 International Conference on Electronics, Communications and Computers (CONIELECOMP)","20160324","2016","","","148","155","This paper considers the problem of automatically extracting a foreground element with its alpha matte in green screen images by training a multi-layer perceptron (MLP) with the back-propagation algorithm. The classifier learns to identify green backgrounds, foreground object contours, and the corresponding alpha values for subsequent digital compositing. We developed our own dataset to train and test the MLP for alpha matte extraction. To speed up the generation of the training set, a second method for semi-automatic alpha matte extraction is proposed. Different experiments show that automatic matte extraction, based on the MLP, generates high-quality matting visually and it is also shown that results depend on the training and the architecture of the classifier. To the best of our knowledge, this is the first effort that applies neural networks to the problem of alpha matte extraction.","","Electronic:978-1-5090-0079-1; POD:978-1-5090-0080-7","10.1109/CONIELECOMP.2016.7438567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438567","Alpha matting;back-propagation algorithm;digital compositing;green screen;machine learning","Brightness;Feature extraction;Films;Image color analysis;Image segmentation;Laplace equations;Training","backpropagation;image colour analysis;multilayer perceptrons","MLP classifiers;automatic matte extraction;back-propagation algorithm;foreground element extraction;foreground object contours;green screen images;high-quality matting;learning matte extraction;multi-layer perceptron;neural networks;semi-automatic alpha matte extraction;subsequent digital compositing;training set","","","","22","","","24-26 Feb. 2016","","IEEE","IEEE Conference Publications"
"Exploiting Feature Selection Algorithm on Group Events Data Based on News Data","Z. Wang; K. Hu; L. Chen; H. Du; S. Wang; Z. Wang; X. Cui","Int. Sch. of Software, Wuhan Univ., Wuhan, China","2015 International Conference on Identification, Information, and Knowledge in the Internet of Things (IIKI)","20160310","2015","","","62","65","As traditional media and new media such as Weibo and WeChat are increasingly used, Internet has become the main supporter of thoughts of groups or individuals, which plays a key role in guidance of our daily life and society development. This study aims to investigate/propose a note feature extraction algorithm of data processing in massive news data, extracting the key words in the news and clarifying the important ones. We try to propose a revised STF algorithm and have comparisons between efficiency of various algorithms. Experiments showed that the proposed algorithm is 4% higher on the classification accuracy than other algorithms.","","Electronic:978-1-4673-8637-1; POD:978-1-4673-8638-8","10.1109/IIKI.2015.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7428324","Feature Exaction;Feature Selection;Group Event;Machine learning;STF","Algorithm design and analysis;Classification algorithms;Feature extraction;Machine learning algorithms;Mutual information;Principal component analysis;Software","Internet;feature extraction;feature selection","Internet;feature extraction algorithm;feature selection algorithm;group event data;news data","","","","9","","","22-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"You Look Suspicious!!: Leveraging Visible Attributes to Classify Malicious Short URLs on Twitter","R. K. Nepali; Y. Wang","","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","2648","2655","Twitter is one of the most popular Online Social Networks (OSN). It is used by millions of users worldwide everyday. Due to the text limitation on Twitter (140 characters per tweet), URL (Uniform Resource Locator) shortening services are widely used, however they are not free from risks. Shortened URLs are completely different from the original URLs, and hence users have no idea where the short URLs will direct them to. Attackers leverage this knowledge to their advantage to spread malicious URLs. Most of the approaches proposed for classifying malicious URLs utilize information from both social networks and URL shorting service providers. In this paper, we propose a novel approach to detect malicious short URLs using only visible features of tweets and user profiles. We test four machine learning algorithms, i.e., Naïve Bayes, random forest, support vector machine, and logistic regression and obtain an accuracy of up to 97% using random forest when classifying malicious short URLs. Our testing results indicate that the approach using visible features from social networks to detect malicious URLs is practicable.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427515","Machine Learning;Malicious URLs;Online Social Networks;Short URLs","Context;Feature extraction;Market research;Security;Twitter;Uniform resource locators","Bayes methods;data compression;invasive software;learning (artificial intelligence);regression analysis;social networking (online);support vector machines;text analysis","OSN;Twitter;URL shorting service providers;Uniform Resource Locator shortening services;logistic regression algorithm;machine learning algorithms;malicious-short URL;naïve Bayes algorithm;online social networks;random forest algorithm;support vector machine algorithm;tweets;user profiles;visible attribute leveraging","","","","24","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Big Data and mHealth Drive Asthma Self-Management","Q. Do; S. Tran; K. Robinson","Comput. Sci. Dept., New Mexico State Univ., Las Cruces, NM, USA","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","806","809","This paper reports our effort to establish the desirable characteristics for the next generation asthma APP for an underserved population. Proposed asthma mobile APP aims to promote older adults' positive adjustment to this chronic disease by being an effective tool for patients to track their personal asthma triggers, predict asthma attacks, support asthma self-management and communicate with healthcare provider. Management of asthma is a dynamic process and varies by individual. For that reason, a personalized asthma APP is necessary to control this chronic disease. Environmental indicators, personal triggers, symptoms monitoring, medication use, peak flow, and blood oxygen monitoring data are analyzed to predict an asthma attack or indicate control. Other non-asthma symptom monitoring, such as fatigue, and biometric measures, like blood pressure, may be added as requested by end user.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424201","asthma self-management;big data analysis;eHealth;machine learning","Blood;Diseases;Medical diagnostic imaging;Monitoring;Sociology;Statistics","Big Data;diseases;medical computing;mobile computing;patient monitoring","asthma attacks;asthma mobile app;big data;biometric measures;blood oxygen monitoring data;blood pressure;chronic disease;mHealth drive asthma self-management;next generation asthma APP;nonasthma symptom monitoring;personal asthma triggers;personalized asthma app;underserved population","","","","10","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Predicting Overtemperature Events in Graphics Cards Using Regression Models","F. C. M. Rodrigues; L. P. Queiroz; J. P. P. Gomes; J. C. Machado","Comput. Sci. Dept., Fed. Univ. of Ceara, Fortaleza, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","328","332","Graphics cards are complex electronic systems designed for high performance applications. Due to its processing power, graphics cards may operate at high temperatures, leading its components to a significant degradation level. This fact is even more present when any of the heat exchange components is not working properly. In such cases, graphics cards may operate in temperatures that are higher than the specified by the manufacturers. This work presents a methodology to detect over temperature events in graphics cards using regression models. The proposed approach was tested in real graphics cards from different manufacturers. The final model achieved promising results.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424041","fault detection;graphics cards;machine learning","Clocks;Graphics;Graphics processing units;Monitoring;Temperature;Testing","computer graphic equipment;regression analysis","graphics card;overtemperature event prediction;regression model","","","","16","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"A Study on Techniques for Proactively Identifying Malicious URLs","A. S. Popescu; D. B. Prelipcean; D. T. Gavrilut","Bitdefender Labs., Al. I. Cuza Univ., Iasi, Romania","2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)","20160307","2015","","","204","211","As most of the malware nowadays use Internet as their main doorway to infect a new system, it has become imperative for security vendors to provide cloud-based solutions that can filter and block malicious URLs. This paper presents different practical considerations related to this problem. The key points that we focus on are the usage of different machine learning techniques and unsupervised learning methods for detecting malicious URLs with respect to memory footprint. The database that we have used in this paper was collected during a period of 48 weeks and consists in approximately 6,000,000 benign and malicious URLs. We also evaluated how detection rate and false positive rate evolved during that period and draw some conclusions related to current malware landscape and Internet attack vectors.","","Electronic:978-1-5090-0461-4; POD:978-1-5090-0462-1","10.1109/SYNASC.2015.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426084","large data sets;machine learning;malicious URLs;unsupervised learning","Feature extraction;Internet;Malware;Servers;Testing;Uniform resource locators","cloud computing;computer network security;invasive software;unsupervised learning","Internet attack vectors;cloud-based solutions;detection rate;false positive rate;machine learning techniques;malicious URL detection;malicious URL filtering;malicious URL identification;malware;unsupervised learning methods","","","","13","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"Dynamic and Fault-Tolerant Clustering for Scientific Workflows","W. Chen; R. F. da Silva; E. Deelman; T. Fahringer","Information Sciences Institute, University of Southern California, Marina del Rey, Los Angeles, CA","IEEE Transactions on Cloud Computing","20160304","2016","4","1","49","62","Task clustering has proven to be an effective method to reduce execution overhead and to improve the computational granularity of scientific workflow tasks executing on distributed resources. However, a job composed of multiple tasks may have a higher risk of suffering from failures than a single task job. In this paper, we conduct a theoretical analysis of the impact of transient failures on the runtime performance of scientific workflow executions. We propose a general task failure modeling framework that uses a maximum likelihood estimation-based parameter estimation process to model workflow performance. We further propose three fault-tolerant clustering strategies to improve the runtime performance of workflow executions in faulty execution environments. Experimental results show that failures can have significant impact on executions where task clustering policies are not fault-tolerant, and that our solutions yield makespan improvements in such scenarios. In addition, we propose a dynamic task clustering strategy to optimize the workflow's makespan by dynamically adjusting the clustering granularity when failures arise. A trace-based simulation of five real workflows shows that our dynamic method is able to adapt to unexpected behaviors, and yields better makespans when compared to static methods.","2168-7161;21687161","","10.1109/TCC.2015.2427200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096978","Scientific workflows;failure;fault tolerance;job grouping;machine learning;parameter estimation;task clustering","Cloud computing;Delays;Fault tolerance;Fault tolerant systems;Maximum likelihood estimation;Runtime;Shape","fault tolerant computing;maximum likelihood estimation;parameter estimation;pattern clustering;scientific information systems;system recovery","computational granularity;distributed resources;execution overhead;fault-tolerant clustering strategies;makespan improvements;maximum likelihood estimation-based parameter estimation process;scientific workflow executions;scientific workflow tasks;task clustering policies;task failure modeling framework;trace-based simulation;transient failures;workflow makespan","","2","","62","","20150428","Jan.-March 1 2016","","IEEE","IEEE Journals & Magazines"
"Looking at the Bottom and the Top: A Hybrid Logical Relational Learning System Based on Answer Sets","V. Guimarães; A. Paes","Dept. of Comput. Sci., Univ. Fed. Fluminense, Rio de Janeiro, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","240","245","Traditional machine learning algorithms require a dataset composed of homogeneous objects, randomly sampled from a single relation. However, real world tasks such as link prediction and entity resolution, require the representation of multiple relations, heterogeneous and structured data. Inductive Logic Programming (ILP) is a sub area of machine learning that induces structured hypotheses from multi-relational examples and background knowledge (BK) represented as logical clauses. With a few exceptions, most of the systems developed in ILP induce Horn-clauses and uses Prolog as their baseline inference engine. However, the recent development of efficient Answer Set Programming solvers points out that these can be a viable option to be the reasoning component of ILP systems, especially to address nonmonotonic reasoning. In this paper, we present dASBoT, a system that is capable of inducing extended normal rules mined from answer sets yielded from the examples and the BK. We show empirical evidence that dASBoT can support the task of relational identification by learning rules in three link prediction and two entity resolution tasks.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424026","Answer Set Programming;Extended Logic Programs;Inductive Logic programming;Relational Machine Learning","Cognition;Engines;Inference mechanisms;Logic programming;Machine learning algorithms;Standards","Horn clauses;PROLOG;inductive logic programming;knowledge representation;learning (artificial intelligence);nonmonotonic reasoning","BK representation;Horn-clause;ILP system;Prolog;answer set programming solver;background knowledge representation;baseline inference engine;dASBoT;hybrid logical relational learning system;inductive logic programming;logical clause;machine learning algorithm;nonmonotonic reasoning;relational identification","","","","18","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"Discovery of research interests of authors over time using a topic model","Y. S. Jeong; Sang-Hun Lee; G. Gweon","Department of Computer Science, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon 305-701, South Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","24","31","With a growing number of Web documents, many approaches have been proposed for knowledge discovery on Web documents. The documents do not always provide keywords or categories, so unsupervised approaches are desirable, and topic modeling is such an approach for knowledge discovery without using labels. Further, Web documents usually have time information such as publish years, so knowledge patterns over time can be captured by incorporating the time information. In this paper, we propose a new topic model called the Author Topic-Flow (ATF) model whose objective is to capture temporal patterns of research interests of authors over time, where each topic is associated with a research domain. The design of the ATF model is based on the hypothesis that direct topic flows are better than indirect topic flows in the state-of-the-art Temporal Author Topic (TAT) model, which is the most similar approach to ours. We prove the hypothesis by showing the effectiveness of the ATF model compared to the TAT model.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425797","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425797","Bayesian networks;Knowledge discovery;Machine learning;Topic mining","Analytical models;Electronic mail;Knowledge discovery;Market research;Resource management;Semantics","Internet;data mining;document handling;pattern recognition","ATF model;TAT model;Web documents;author topic-flow model;direct topic flows;indirect topic flows;research interests of authors;temporal author topic model;temporal pattern capture","","","","24","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Passive RFID for Object and Use Detection during Trauma Resuscitation","S. Parlak; I. Marsic; A. Sarcevic; W. U. Bajwa; L. J. Waterhouse; R. S. Burd","Qualcomm Technologies Inc., Santa Clara, CA","IEEE Transactions on Mobile Computing","20160303","2016","15","4","924","937","We evaluated passive radio-frequency identification (RFID) technology for detecting the use of objects and related activities during trauma resuscitation. Our system consists of RFID tags and antennas, optimally placed for object detection, as well as algorithms for processing RFID data to infer object use. To evaluate our approach, we tagged 81 objects in the resuscitation room and recorded RFID signal strength during 32 simulated resuscitations performed by trauma teams. We then analyzed RFID data to identify cues for recognizing resuscitation activities. Using these cues, we extracted descriptive features and applied machine-learning techniques to monitor interactions with objects. Our results show that an instance of a used object can be detected with accuracy rates greater than 90 percent in a crowded and fast-paced medical setting using off-the-shelf RFID equipment, and the time and duration of use can be identified with up to 83 percent accuracy. We conclude with insights into the limitations of passive RFID and areas in which RFID needs to be complemented with other sensing technologies.","1536-1233;15361233","","10.1109/TMC.2015.2436393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7111343","Machine learning;RFID;activity recognition;emergency medicine;medical information systems;medicine and science;object-based sensing;sensors;sensors ---RFID;trauma resuscitation","Antennas;Feature extraction;Fluids;Mobile computing;Passive RFID tags","feature extraction;injuries;learning (artificial intelligence);medical signal detection;object detection;radiofrequency identification","RFID signal strength;RFID tag;antenna;descriptive feature extraction;machine-learning technique;medical setting;object detection;passive RFID;passive radiofrequency identification technology;trauma resuscitation;use detection","","1","","32","","20150521","April 1 2016","","IEEE","IEEE Journals & Magazines"
"Event-Driven Gait Recognition Method Based on Dynamic Temporal Segmentation","X. Lai; G. Zhou; C. Lin; K. Yim","Key Lab. for Ubiquitous Network & Service Software of Liaoning Province, Dalian Univ. of Technol., Dalian, China","2015 10th International Conference on Broadband and Wireless Computing, Communication and Applications (BWCCA)","20160303","2015","","","522","527","Recognizing human gait with Body Sensor Networks (BSNs) is a significant research in pervasive computing. A real-time gait recognition method driven by leg movements is proposed which uses gyroscopes as main sensors for collecting angular velocities of legs and waist. According to the fluctuation of legs' angular velocities, sensor data can be segmented into gait cycles. And then from the segmented data in each cycle, a serial of features are extracted which will be given to a classification model for gait recognition. By experimenting four commonly used machine learning algorithms, the best classifier for gait recognition is determined as the final classification model. Experimental results show that our proposed method can recognize 12 kinds of gaits effectively. Compare to other methods, it has the characteristics of more recognizable actions, higher accuracy, better real-time performance and less calculation.","","Electronic:978-1-4673-8315-8; POD:978-1-4673-8316-5","10.1109/BWCCA.2015.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424880","Body Sensor Network;event-driven;gait recognition;heuristic features;machine learning","Angular velocity;Data collection;Feature extraction;Gait recognition;Legged locomotion;Wireless communication;Wireless sensor networks","body sensor networks;feature extraction;gait analysis;gyroscopes;image classification;image motion analysis;image segmentation;image sensors;learning (artificial intelligence)","BSNs;body sensor networks;classification model;dynamic temporal segmentation;event-driven gait recognition method;feature extraction;gyroscopes;leg angular velocity collection;leg movements;machine learning algorithms;pervasive computing;sensor data;waist angular velocity collection","","","","17","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Computational methods for the identification of mature microRNAs within their Pre-miRNA","Y. Wang; X. Dai; J. Ru; D. Lv; J. Li","Network Information Center, Qiqihar University, Qiqihar, China College of Automation, Harbin Engineering, University Harbin, China","2015 8th International Congress on Image and Signal Processing (CISP)","20160218","2015","","","1241","1245","The urgent demand in miRNA research has call for the high performance computational methods for mature miRNA identification to supplement the biological experiment methods. In this study, we analyzed the secondary structure of pre-miRNA and extracted the important features. Then the current computational methods are investigated, and the flow chart of mature miRNAs location prediction methods is summarized. In addition, the current methods and algorithms are classified and assessed. Notably, we compare five machine learning algorithms of Naive Bayes, SVM, Random Forest, the Conditional Random Field and Adaboosting for mature miRNA-located prediction. Empirical findings indicated that SVM algorithm could achieve better performance than Naive Bayes method. And the Random Forest method is comparable to the performance of SVM, it shows good performance in this subject.","","Electronic:978-1-4673-9098-9; POD:978-1-4673-9099-6; USB:978-1-4673-9097-2","10.1109/CISP.2015.7408071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7408071","algorithm;computational methods;machine learning;microRNA;pre-miRNA","Algorithm design and analysis;Biology;Classification algorithms;Feature extraction;Prediction algorithms;Support vector machines;Training","Bayes methods;RNA;biology computing;feature extraction;learning (artificial intelligence);molecular biophysics;molecular configurations;random processes;support vector machines","Naive Bayes method;Random Forest method;SVM algorithm;adaboosting;biological experiment method;conditional random field;feature extraction;flow chart;high performance computational method;machine learning algorithms;mature miRNA identification;mature miRNA location prediction method;mature microRNA;pre-miRNA;secondary structure","","","","19","","","14-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Software complexity metric-based defect classification using FARM with preprocessing step CFS and SMOTE a preliminary study","M. F. Naufal; S. Rochimah","Informatics Department, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2015 International Conference on Information Technology Systems and Innovation (ICITSI)","20160324","2015","","","1","6","One criteria for assessing the software quality is ensuring that there is no defect in the software which is being developed. Software defect classification can be used to prevent software defects. More earlier software defects are detected in the software life cycle, it will minimize the software development costs. This study proposes a software defect classification using Fuzzy Association Rule Mining (FARM) based on complexity metrics. However, not all complexity metrics affect on software defect, therefore it requires metrics selection process using Correlation-based Feature Selection (CFS) so it can increase the classification performance. This study will conduct experiments on the NASA MDP open source dataset that is publicly accessible on the PROMISE repository. This datasets contain history log of software defects based on software complexity metric. In NASA MDP dataset the data distribution between defective and not defective modules are not balanced. It is called class imbalanced problem. Class imbalance problem can affect on classification performance. It needs a technique to solve this problem using oversampling method. Synthetic Minority Oversampling Technique (SMOTE) is used in this study as oversampling method. With the advantages possessed by FARM in learning on dataset which has quantitative data attribute and combined with the software complexity metrics selection process using CFS and oversampling using SMOTE, this method is expected has a better performance than the previous methods.","","Electronic:978-1-4673-6664-9; POD:978-1-4673-6665-6","10.1109/ICITSI.2015.7437685","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437685","Bugs;Correlation-based Feature Selection;Defect;Fault;Fuzzy Association Rule Mining;Machine Learning;Software Defect Classification;Synthetic Minority Oversampling Technique","Complexity theory;Data mining;NASA;Software;Software metrics;Training","aerospace computing;data mining;feature selection;fuzzy set theory;learning (artificial intelligence);program testing;sampling methods;software metrics;software quality","CFS;FARM;NASA-MDP open source dataset;PROMISE repository;SMOTE;class imbalanced problem;correlation-based feature selection;data distribution;defective module;fuzzy association rule mining;history log;learning;nondefective module;quantitative data attribute;software complexity metric selection process;software complexity metric-based defect classification;software development cost minimization;software life cycle;software quality assessment;synthetic minority oversampling technique","","","","16","","","16-19 Nov. 2015","","IEEE","IEEE Conference Publications"
"Smart Preprocessing Improves Data Stream Mining","H. Hu; M. Kantardzic","","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","1749","1757","Most studies on stream mining frameworks handles model retraining and preprocessing together. We propose Smart Preprocessing for Streaming Data (SPSD) approach which separates normalization of each numeric features from model retraining. The goal of SPSD is to reduce the number of new models needed in a stream mining framework while maintaining comparable quality. The approach re-normalizes data based on two metrics calculated with min-max value in each chunk of data. In experiments with real world data we showed that SPSD is able to maintain quality of classification in approximately 50% of all data chunks by only re-normalize the data without building new classification models. In our comparison with traditional stream mining frameworks we showed that traditional frameworks can benefit from SPSD in approximately 30% to 50% of total data chunks. Benefits include eliminating training cost of new models in these chunks and reducing overall total number of models.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427400","machine learning;normalization;preprocessing;stream mining","Adaptation models;Algorithm design and analysis;Classification algorithms;Data mining;Data models;Measurement;Numerical models","data mining;feature extraction;pattern classification","SPSD approach;classification models;data renormalization;data stream mining;feature normalization;min-max value;model retraining;smart preprocessing for streaming data approach","","","","20","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Ensembling Classifiers for Detecting User Intentions behind Web Queries","A. Figueroa; J. Atkinson","Yahoo Research, Universidad Diego Portales, and Universidad Andres Bello, Santiago, Chile","IEEE Internet Computing","20160226","2016","20","2","8","16","Discovering user intentions behind Web search queries is key to improving user experience. Usually, this task is seen as a classification problem, in which a sample of annotated user query intentions are provided to a supervised machine learning algorithm or classifier that learns from these examples and then can classify unseen user queries. This article proposes a new approach based on an ensemble of classifiers. The method combines syntactic and semantic features so as to effectively detect user intentions. Different setting experiments show the promise of this linguistically motivated ensembling approach, by reducing the ranking variance of single classifiers across user intentions.","1089-7801;10897801","","10.1109/MIC.2015.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006341","Internet/Web technologies;Web search;ensemble learning;machine learning;natural language processing","Feature extraction;Internet;Machine learning;Natural language processing;Navigation;Query processing;Search engines;Search methods;Supervised learning;Support vector machines;Web and internet services","Internet;learning (artificial intelligence);pattern classification;query processing","Web search queries;annotated user query intentions;classifier ensembling;linguistically motivated ensembling approach;semantic features;supervised machine learning algorithm;syntactic features;user experience;user intention detection;user intentions;user query classification problem","","1","","12","","20150112","Mar.-Apr. 2016","","IEEE","IEEE Journals & Magazines"
"Cost-Optimal Consumption-Aware Electric Water Heating Via Thermal Storage Under Time-of-Use Pricing","J. J. Shah; M. C. Nielsen; T. S. Shaffer; R. L. Fittro","Envision Energy USA, Houston, TX, USA","IEEE Transactions on Smart Grid","20160218","2016","7","2","592","599","Time-of-use electricity pricing is touted as one of the solutions toward optimal load distribution in the future of smart grid. However, the benefits of such an approach are limited as human electricity usage can often be described as inelastic in nature, or not sensitive to pricing in economic theory. Water heating constitutes one of the largest components of such usage. This paper proposes technology to enable residential water heating to be converted from an inelastic to an elastic demand, which would respond to pricing incentives. This is accomplished by utilizing consumer hot water use patterns combined with thermal storage to calculate a user-specific temperature profile. Results demonstrated that such an approach could not only reduce electrical water heating costs significantly and allow for realization of large-scale grid benefits, but also improve customer experience as thermal storage capability would enable more hot water to be delivered at times of peak consumption.","1949-3053;19493053","","10.1109/TSG.2015.2483502","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7353201","Consumer behavior;economics;energy consumption;energy storage;load management;machine learning;smart grids;water storage","Cogeneration;Mathematical model;Pricing;Resistance heating;Thermal loading;Water conservation;Water heating","cost reduction;heating;power system economics;pricing;smart power grids;thermal energy storage","consumer hot water use patterns;cost-optimal consumption-aware electric water heating;customer experience;economic theory;elastic demand;electrical water heating cost reduction;human electricity usage;inelastic demand;large-scale grid benefit;optimal load distribution;peak consumption;pricing incentives;residential water heating;smart grid;thermal storage capability;time-of-use electricity pricing;user-specific temperature profile","","1","","23","","20151211","March 2016","","IEEE","IEEE Journals & Magazines"
"Relevant evidence acquisition and appraisal using knowledge-intensive queries","M. Afzal; S. Lee","Department of Computer Engineering, Kyung Hee University, Seocheon-dong, Republic of Korea, 446-701","2016 18th International Conference on Advanced Communication Technology (ICACT)","20160303","2016","","","1","1","Information needs of the users have grown exponentially with the advent of advancements in information and communication technology. The traditional ways of searching information from the online resources has been evolved and the tendency is geared more towards getting quality contents. In healthcare domain, the clinical researchers and physicians are even more interested to find quality information to use as a clinical evidence in decision making. An increasing number of potential articles in the form of MEDLINE articles are readily available to be retrieved, helps in evidence-based clinical decisions, however, the retrieval methods pose several challenges to clinicians. The first challenge is to automatically reformulate the user query into a knowledge-intensive query in order to acquire articles that are relevant to user needs. The second challenge is to re-evaluate the retrieved articles in order to get quality studies and filter-out all the low quality articles. In this paper, we approach to solve these challenges by proposing two methods to construct knowledge-intensive query for relevant evidence acquisition and statistical model for quality evidence appraisal. The construction of knowledge-intensive query is based on the term expansion using domain model, name variants, and terminological variants. The statistical model is learnt on a corpus prepared through automatic construction of feature vectors from data and metadata features. We evaluate the results at two levels; 1) pre-appraisal stage, 2) post-appraisal stage. We compared the results based on the retrieved result sets with knowledge-intensive query approach and simple query approach. The proposed knowledge-intensive query approach successfully retrieves the potential evidences with average 12.33% improved accuracy in contrast to simple query approach. Furthermore, we performed human evaluation to identify the overall satisfaction of the proposed approach. From the user input, we learned - hat the proposed approach contributes to maximizing the clinical throughput of clinicians by minimizing the unnecessary intermediary manual steps in evidence retrieval and the appraisal process.","","CD:978-8-9968-6507-0; Electronic:978-8-9968-6506-3","10.1109/ICACT.2016.7423527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423527","Content-based retrieval;Information filtering;Keyword search;Machine learning","","","","","","","","","","Jan. 31 2016-Feb. 3 2016","","IEEE","IEEE Conference Publications"
"Multi-task Rank Learning for Image Quality Assessment","L. Xu; J. Li; W. Lin; Y. Zhang; L. Ma; Y. Fang; Y. Yan","Long Xu is with the Key Laboratory of Solar Activity, National Astronomical Observatories, Chinese Academy of Sciences, Beijing 100012, China and also with the School of Computer and Software, Jiangsu Engineering Center of Network Monitoring, Nanjing University of Information Science and Technology, Nanjing 210044, China. (email: lxu@nao.cas.cn)","IEEE Transactions on Circuits and Systems for Video Technology","","2016","PP","99","1","1","In practice, images are distorted by more than one distortions. For image quality assessment (IQA), the existing machine learning (ML) based methods generally established a unified model for all the distortion types, or each model is trained independently for each distortion type, which is therefore distortion-aware. In distortion-aware methods, the common features among different distortions were not exploited. In addition, there were fewer training samples for each model training, which may result in overfitting. To address these problems, we propose a multi-task learning framework to train multiple IQA models together, each model is for each distortion type; however all the training samples are associated with each model training. Thus, the common features among different distortion types, and the said underlying relatedness among all the learning tasks are exploited, which would benefit the generalization ability of trained models and prevent overfitting possibly. In addition, pairwise image quality ranking instead of image quality rating is optimized in our learning task, which is fundamentally departed from the traditional ML based IQA methods toward better performance. The experimental results confirm that the proposed Multi-task Rank Learning based IQA (MRLIQ) metric is prominent against all state-of-the-art NR-IQA approaches.","1051-8215;10518215","","10.1109/TCSVT.2016.2543099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434616","MOS;image quality assessment;machine learning;pairwise comparison;rank learning","Distortion;Electronic mail;Image quality;Predictive models;Solid modeling;Training;Transform coding","","","","2","","","","20160316","","","IEEE","IEEE Early Access Articles"
"Personality classification based on Twitter text using Naive Bayes, KNN and SVM","B. Y. Pratama; R. Sarno","Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, 60111, Indonesia","2015 International Conference on Data and Software Engineering (ICoDSE)","20160321","2015","","","170","174","Personality is a fundamental basis of human behavior. Personality affects the interaction and preferences of an individual. People are required to take a personality test to find out their personality. Social media is a place where users express themselves to the world. Posts made by users of social media can be analyzed to obtain their personal information. This experiment uses text classification to predict personality based on text written by Twitter users. The languages used are English and Indonesian. Classification methods implemented are Naive Bayes, K-Nearest Neighbors and Support Vector Machine. Testing results showed Naive Bayes slightly outperformed the other methods.","","CD-ROM:978-1-4673-8427-8; Electronic:978-1-4673-8430-8; POD:978-1-4673-8431-5","10.1109/ICODSE.2015.7436992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436992","machine learning;personality identification;social media;text classification","Classification algorithms;Employee welfare;Media;Support vector machines;Testing;Text categorization;Twitter","Bayes methods;pattern classification;social networking (online);support vector machines;text analysis","English language;Indonesian language;KNN method;SVM method;Twitter text;Twitter users;human behavior;k-nearest neighbor method;naive Bayes method;personal information;personality classification;personality prediction;personality test;social media;support vector machine method;text classification;user interaction;user preferences","","1","","18","","","25-26 Nov. 2015","","IEEE","IEEE Conference Publications"
"Fast training on large genomics data using distributed Support Vector Machines","N. Theera-Ampornpunt; S. G. Kim; A. Ghoshal; S. Bagchi; A. Grama; S. Chaterji","Purdue University, West Lafayette, Indiana, USA","2016 8th International Conference on Communication Systems and Networks (COMSNETS)","20160324","2016","","","1","8","The field of genomics has seen a glorious explosion of high-quality data, with tremendous strides having been made in genomic sequencing instruments and computational genomics applications meant to make sense of the data. A common use case for genomics data is to answer the question if a specific genetic signature is correlated with some disease manifestations. Support Vector Machine (SVM) is a widely used classifier in computational literature. Previous studies have shown success in using these SVMs for the above use case of genomics data. However, SVMs suffer from a widely-recognized scalability problem in both memory use and computational time. It is as yet an unanswered question if training such classifiers can scale to the massive sizes that characterize many of the genomics data sets. We answer that question here for a specific dataset, in order to decipher whether some regulatory module of a particular combinatorial epigenetic “pattern” will regulate the expression of a gene. However, the specifics of the dataset is likely of less relevance to the claims of our work. We take a proposed theoretical technique for efficient training of SVM, namely Cascade SVM, create our classifier called EP-SVM, and empirically evaluate how it scales to the large genomics dataset. We implement Cascade SVM on the Apache Spark platform and open source this implementation1. Through our evaluation, we bring out the computational cost on each application process, the way of distributing the overall workload among multiple processes, which can potentially execute on different cores or different machines, and the cost of data transfer to different cores or different machines. We believe we are the first to shed light on the computational and network costs of training an SVM on a multi-dimensional genomics dataset. We also evaluate the accuracy of the classifier result as a function of the parameters of the SVM model.","","Electronic:978-1-4673-9622-6; POD:978-1-4673-9623-3","10.1109/COMSNETS.2016.7439943","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439943","classifier training;computational cost;computational genomics;machine learning;network cost","Bioinformatics;DNA;Distributed databases;Gene expression;Genomics;Support vector machines;Training","genetic engineering;genomics;support vector machines","Apache spark platform;SVM;combinatorial epigenetic pattern;data transfer;distributed support vector machines;fast training;genomic sequencing instruments;genomics data;multidimensional genomics dataset;scalability problem;support vector machine","","","","36","","","5-10 Jan. 2016","","IEEE","IEEE Conference Publications"
"A Memory Based approach to Malayalam noun generation","Reji Rahmath K; P. C. R. Raj","Department of Computer Science and Engineering, Govt. Engineering College, Sreekrishnapuram, Kerala, India 678633","2015 International Conference on Control Communication & Computing India (ICCC)","20160314","2015","","","634","637","Words are the important building blocks of every language. Morphological generator is used to get the inflected form of a word, given its root word and a set of properties such as lexical category and morphological properties. Morphological Generation and analysis are necessary for developing computational grammars as well as machine translation systems. This paper presents a morphological generator for Malayalam nouns using Memory Based Language Processing (MBLP) approach. MBLP is an approach to language processing based on exemplar storage during learning, and analogical reasoning during processing. For training the system, a training corpus is created. It contains the basic examples of root words and their features. The feature set for this Malayalam noun generation system includes number, case, and the last syllable of the root word. Tilburg Memory based Learner (TiMBL) is used for training the system. The system doesn't require a dictionary or rules for its working. It gives a satisfactory result, having an accuracy of 93.68%.","","CD-ROM:978-1-4673-7348-7; Electronic:978-1-4673-7349-4; POD:978-1-4673-7350-0","10.1109/ICCC.2015.7432973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7432973","Machine Learning;Malayalam Morphological Analysis;Memory Based Language Processing;Morphology","Cognition;Dictionaries;Generators;Instruments;Measurement;Natural language processing;Training","case-based reasoning;learning (artificial intelligence);mathematical morphology;natural language processing","MBLP approach;Malayalam noun generation system;TiMBL;Tilburg memory-based learner;analogical reasoning;computational grammars;machine translation system;memory-based approach;memory-based language processing approach;morphological generator;training corpus","","","","14","","","19-21 Nov. 2015","","IEEE","IEEE Conference Publications"
"A neuro-genetic model to predict hepatitis disease risk","S. Mishra; B. K. Mishra; H. K. Tripathy","C. V. Raman College of Engineering, Bhubaneswar, India","2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)","20160321","2015","","","1","3","In the present scenario, large quantity of data is generated in the field of medicine. This data contain valuable information which can be utilized in decision making. Machine learning is an active area which may be useful to healthcare experts. Hepatitis disease is a common disease in the world, which may cause damage to hepatocytes. Machine learning techniques can be implemented to reduce the risk of Hepatitis. Our study has demonstrated an intelligent hybrid system for the efficient risk prediction of Hepatitis disease. We developed an intelligent combination of Genetic search algorithm and Multilayer Perceptron technique named MLP-GS. Our proposed system model was analyzed and computed with the help of several performance parameters like Accuracy, Root Mean-Squared Error, Precision, Recall and F-Measure. It was observed that MLP-GS model performs better on Hepatitis data.","","CD-ROM:978-1-4799-7847-2; Electronic:978-1-4799-7849-6; POD:978-1-4799-7850-2","10.1109/ICCIC.2015.7435719","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435719","F-Measure;Genetic Search Introduction;Machine learning;Precision;RMSE;Recall","Artificial intelligence;Computational modeling;Data models;Diseases;Genetics;Multilayer perceptrons","data handling;decision making;diseases;genetic algorithms;health care;learning (artificial intelligence);medical administrative data processing;multilayer perceptrons","MLP-GS model;decision making;genetic search algorithm;health care experts;hepatitis disease risk prediction;hepatocytes;intelligent hybrid system;machine learning;medicine;multilayer perceptron technique;neurogenetic model","","","","11","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Review on Synergistic Learning","C. Li; Y. Li","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Access","20160229","2016","4","","119","134","In neuroscience, it is widely believed that learning and memory are primarily based on synaptic plasticity which is a neural mechanism that modifies the strength of connections between neurons. As a counterpart in machine learning, the modification of connection strength (weight) endows artificial neural networks with a powerful learning capability to solve various problems. Independent of modification for synaptic strength, recent experimental results have revealed that a single neuron also has the ability to change its intrinsic excitability to fit the synaptic input. This mechanism is referred to as neuronal intrinsic plasticity (IP) in the literature. Computational learning rules for IP have been developed based on the hypothesis of information maximization with a stable response level. With the discovery of this novel plasticity mechanism, a series of studies has focused on how IP plays a role in biological neural systems and how they benefit the learning performance of artificial neural networks. In this review, corresponding research on synergies between IP and synaptic plasticity mechanisms is presented in both the computational modeling of biological neural systems and the applications of artificial neural networks, and this combination in artificial learning systems is defined as synergistic learning.","2169-3536;21693536","","10.1109/ACCESS.2015.2509005","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358047","Intrinsic plasticity;artificial neural networks;homeostasis;machine learning;sparse coding;synaptic plasticity;synergistic learning","Computational modeling;Hebbian theory;IP networks;Learning systems;Neuroscience;Synergistic learning","learning (artificial intelligence);neural nets","artificial learning systems;artificial neural networks;biological neural systems;machine learning;neural mechanism;neuronal intrinsic plasticity;synaptic plasticity;synergistic learning","","","","111","","20151217","2016","","IEEE","IEEE Journals & Magazines"
"Galileo bionic hand: sEMG activated approaches for a multifunction upper-limb prosthetic","J. Fajardo; A. Lemus; E. Rohmer","Turing Researh Laboratory, FISICC, Universidad Galileo, Guatemala, Guatemala","2015 IEEE Thirty Fifth Central American and Panama Convention (CONCAPAN XXXV)","20160310","2015","","","1","6","Surface electromyography (sEMG) commonly used in upper-limb prostheses requires expensive medical equipment to get accurate results, and even then only a few actions can be classified. We propose an sEMG activated embedded system based on Digital Signal Processing and Machine Learning, to interpret the user intention with the purpose of controlling a low-cost 3D printed hand prosthesis with multiple Degrees of Freedom (DOF). The system has three different operating modes with a user-friendly Human Machine Interface (HMI), in order to increase the amount of customized hand postures that can be performed by the user, providing functionalities that fit on their daily chores and allowing to use inexpensive surface mounted passive electrodes in order to keep a low cost approach. Inasmuch as sEMG activation allows the user to consciously perform the desired action, on the other hand a touchscreen enables the possibility to select different predefined actions and operating modes, as well as provide necessary visual feedback. Moreover, in another operating mode, a speech recognition module recognizes user speech in 3 different languages, allowing the user more sEMG activated postures. Finally, an operating mode based on Artificial Neural Networks (ANN) classifies 5 hand gestures that can be easily accomplished by below elbow amputees. The system was tested and obtained high accuracy and great responsiveness on the different modes of operation.","","Electronic:978-1-4673-7872-7; POD:978-1-4673-7873-4","10.1109/CONCAPAN.2015.7428468","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7428468","Artificial Neural Networks;Digital Signal Processing;Electromyography;Embedded Systems;Human Machine Interface;Machine Learning;Upper-Limb Prostheses","Artificial neural networks;Electrodes;Electromyography;Feature extraction;Muscles;Prosthetics;Speech recognition","biocybernetics;biomedical equipment;electromyography;human computer interaction;medical signal processing;neural nets;prosthetics;speech recognition","ANN;DOF;Galileo bionic hand;HMI;activated embedded system;artificial neural networks;digital signal processing;human machine interface;low-cost 3D printed hand prosthesis;machine learning;medical equipment;multifunction upper-limb prosthetic;multiple degrees of freedom;sEMG activated approach;speech recognition;surface electromyography;visual feedback","","","","23","","","11-13 Nov. 2015","","IEEE","IEEE Conference Publications"
"Identification of relations from IndoWordNet for Indian languages using Support Vector Machine","M. Garg; B. Sinha; S. Chandra","Department of Electronics and Information Technology, New Delhi, India","2015 International Conference on Computing and Network Communications (CoCoNet)","20160218","2015","","","547","552","Identification and classification of relations between synsets in a low resource language is a challenging and difficult task, which requires intensive Natural Language Processing (NLP). This paper presents Support Vector Machine (SVM) based approach for learning, classifying and automatically predicting relationships between Hindi Synsets. The average accuracy obtained using SVM is 71.87%, which can be further improved through introduction of language based knowledge. The system performance has been validated using the performance measures namely Precision, Recall and F-score.","","Electronic:978-1-4673-7309-8; POD:978-1-4673-7310-4","10.1109/CoCoNet.2015.7411241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7411241","IndoWordNet;Machine learning;Ontology;Relations;Support Vector Machine","Databases;Feature extraction;Metadata;Natural language processing;Semantics;Support vector machines;Training","learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);pattern classification;support vector machines;word processing","F-score;Hindi Synsets;Indian languages;IndoWordNet;NLP;SVM based approach;automatic relationship prediction;language based knowledge;learning;low resource language;natural language processing;precision;recall;relation identification;support vector machine based approach;synsets relation classification","","1","","22","","","16-19 Dec. 2015","","IEEE","IEEE Conference Publications"
"Voxel-based diagnosis of Alzheimer's disease using classifier ensembles","R. Armananzas; M. Iglesias; D. A. Morales; L. Alonso-Nanclares","Ruben Armananzas is with the Krasnow Institute for Advanced Study, George Mason University, Fairfax, VA 22030, USA. (email: rarmanan@gmu.edu)","IEEE Journal of Biomedical and Health Informatics","","2016","PP","99","1","1","Functional magnetic resonance imaging (fMRI) is one of the most promising non-invasive techniques for early Alzheimer’s disease (AD) diagnosis. In this paper, we explore the application of different machine learning techniques to the classification of fMRI data for this purpose. The functional images were firstly preprocessed using the statistical parametric mapping toolbox to output individual maps of statistically activated voxels. A fast filter was applied afterwards to select voxels commonly activated across demented and non-demented groups. Four feature ranking selection techniques were embedded into a wrapper scheme using an inner-outer loop for the selection of relevant voxels. The wrapper approach was guided by the performance of six pattern recognition models, three of which were ensemble classifiers based on stochastic searches. Final classification performance was assessed from the nested internal and external cross-validation loops taking several voxel sets ordered by importance. Numerical performance was evaluated using statistical tests, and the best combination of voxel selection and classification reached a 97.14% average accuracy. Results repeatedly pointed out Brodmann regions with distinct activation patterns between demented and non demented profiles, indicating that the machine learning analysis described is a powerful method to detect differences in several brain regions between both groups.","2168-2194;21682194","","10.1109/JBHI.2016.2538559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426350","Alzheimer’s disease;Feature selection;Machine learning;Supervised classification;fMRI","Dementia;Indexes;Informatics;Pattern recognition;Vegetation","","","","","","","","20160304","","","IEEE","IEEE Early Access Articles"
"Adaptation of Discourse Parsing Models for the Portuguese Language","E. G. Maziero; G. Hirst; T. A. S. Pardo","Dept. of Comput. Sci., Univ. of Toronto, Toronto, ON, Canada","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","140","145","Discourse parsing in Portuguese has two critical limitations. The first is that the task has been explored using only symbolic approaches, i.e., Using manually extracted lexical patterns. The second is related to the domain of the lexical patterns, which were extracted through the analysis of a corpus of academic texts, generating many domain-specific patterns. For English, many approaches have been explored using machine learning with features based on a prominent lexicon-syntax notion of dominance sets. In this paper, two works were adapted to Portuguese, improving the results, outperforming the baselines and previous works for Portuguese, considering the task of rhetorical relation identification.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424009","Adaptation for Portuguese;Machine Learning;Rhetorical Relation Identification;Rhetorical Structure Theory","Adaptation models;Feature extraction;Machine learning algorithms;Magnetic heads;Natural language processing;Satellites;Syntactics","grammars;natural language processing;text analysis","Portuguese language;discourse parsing model;lexical pattern;symbolic approach","","","","29","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"Transducer State Prediction System for Smart Environment Intelligent Control","M. B. d. Freitas; G. D. C. Cavalcanti; R. Sabourin","Centro de Inf., Univ. Fed. de Pernambuco, Recife, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","270","275","Smart environments possess devices that collaborate to help the user non-intrusively. One possible aid smart environment offer is to anticipate user's tasks and perform them on his/her behalf or facilitate the action completion. In this paper, we propose a framework that predicts user's actions by learning his/her behavior when interacting with the smart environment. We prepare the datasets and train a predictor that is responsible to decide whether a target transducer value should be changed or not. Our solution achieves a significant improvement for all target transducers studied and most combinations of parameters yields better results than the base case.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424031","Ambient Assisted Living;Intelligent Control;Machine Learning;Smart Environment;Ubiquitous Computing","Actuators;Intelligent sensors;Prediction algorithms;Smart homes;Training;Transducers","assisted living;intelligent control;learning (artificial intelligence);ubiquitous computing","smart environment intelligent control;target transducer value;transducer state prediction system","","","","15","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"Automatic generation of fuzzy logic components for enhancing the mechanism of learner's modeling while using educational games","M. A. Khenissi; F. Essalmi","Research Laboratory LaTICE, ENSIT, University of TUNIS, Tunisia","2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)","20160310","2015","","","1","6","Working memory is the system used by every human for temporarily storing and managing the information required to carry out complex cognitive tasks such as learning, reasoning and comprehension. In particular, working memory capacity plays an important role in learning process, because learner often have to hold information in mind while engaged in a learning activities. Having information about learners' WMC could be helpful to support them during the learning process. Khenissi et al. [1] proposed an approach based on fuzzy logic for learner's modeling while using educational games and/or e-learning system. This paper will detail the description of the mechanism proposed by Khenissi et al. [1]. Furthermore, it will describe how the system architecture will be improved by the automatic generation of the fuzzy logic components. In particular, the machine learning, web services and the model of educational games are adopted for automatically generate the components of the fuzzy logic system. The automatic generation of these components will help the expert in parameterizing them, and thus better estimation of the learner's WMC.","","Electronic:978-1-4673-8749-1; POD:978-1-4673-8750-7","10.1109/ICTA.2015.7426879","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426879","Fuzzy Logic;Games Model;Learner Model;Machine Learning;Web Services;Working Memory Capacity","Cognition;Fuzzy logic;Games;Linearity;Navigation;Pragmatics;Systems architecture","Web services;cognition;computer aided instruction;computer games;fuzzy logic;learning (artificial intelligence)","Web services;educational games;fuzzy logic components automatic generation;learners WMC;learners modeling;machine learning;working memory capacity","","","","22","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Selection of the most prominent lines of research in ICT domain","R. I. Muhamedyev; Y. N. Amirgaliyev; M. N. Kalimoldayev; A. N. Khamitov; A. Abdilmanova","IICT, Ministry of Education and Science of the Republic of Kazakhstan 125 Pushkina st., Almaty 050010, Kazakhstan","2015 Twelve International Conference on Electronics Computer and Computation (ICECCO)","20160225","2015","","","1","7","The paper is devoted to selection of the most crucial directions of research in ICT domain that could be implemented in the Republic of Kazakhstan. In the paper we evaluated the dynamics of the annual changes in the number of publications and convergence of ICT sub-domains based on data of Scopus, EBSCO (Information Science & Technology Abstracts, Academic Search Complete) and Google Scholar. To analyze the place of Kazakhstan, we considered indexes shown in the Global Competitiveness Report. As a result, the most rapidly developing areas of research were revealed (big data, machine learning, 5G, augmented reality, and etc.). The semantic network of the most modern concepts of the ICT domain was constructed that visualizes the binary relationship between the components and their relative importance. By using comparative analysis of the number of publications in the leading countries and some other countries including Kazakhstan, we selected some key domains which need to be seriously improved onto the way of development science in RK.","","Electronic:978-1-5090-0200-9; POD:978-1-5090-0201-6","10.1109/ICECCO.2015.7416901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416901","5G;Augmented Reality;Big Data;Bioinformatics;Cloud computing;Cyber-Physical systems;Embedded systems;Human-machine systems;ICT domain;Information Security;Internet of Things;Machine Learning;Machine to Machine;Mobile computing;Multi agent systems;Neural Networks;Robotics;SDN;Visualization;e-Governance;scientometric databases;taxonomy","5G mobile communication;Augmented reality;Big data;Cloud computing;Mobile computing;Semantics","Big Data;Internet of Things;augmented reality;cloud computing;learning (artificial intelligence);mobile computing;research initiatives;semantic networks","5G;EBSCO data;Google Scholar data;ICT domain;Republic of Kazakhstan;Scopus data;augmented reality;big data;machine learning;research selection;semantic network","","","","18","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Battery Health Prognosis for Electric Vehicles Using Sample Entropy and Sparse Bayesian Predictive Modeling","X. Hu; J. Jiang; D. Cao; B. Egardt","Nat. Active Distrib. Network Technol. Res. Center, Beijing Jiaotong Univ., Beijing, China","IEEE Transactions on Industrial Electronics","20160308","2016","63","4","2645","2656","Battery health monitoring and management is of extreme importance for the performance and cost of electric vehicles. This paper is concerned with machine-learning-enabled battery state-of-health (SOH) indication and prognosis. The sample entropy of short voltage sequence is used as an effective signature of capacity loss. Advanced sparse Bayesian predictive modeling (SBPM) methodology is employed to capture the underlying correspondence between the capacity loss and sample entropy. The SBPM-based SOH monitor is compared with a polynomial model developed in our prior work. The proposed approach allows for an analytical integration of temperature effects such that an explicitly temperature-perspective SOH estimator is established, whose performance and complexity is contrasted to the support vector machine (SVM) scheme. The forecast of remaining useful life is also performed via a combination of SBPM and bootstrap sampling concepts. Large amounts of experimental data from multiple lithium-ion battery cells at three different temperatures are deployed for model construction, verification, and comparison. Such a multi-cell setting is more useful and valuable than only considering a single cell (a common scenario). This is the first known application of combined sample entropy and SBPM to battery health prognosis.","0278-0046;02780046","","10.1109/TIE.2015.2461523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169584","Bayesian Inference;Bayesian inference;Electric Vehicle;Energy Storage;Health Monitoring;Lithium-ion Battery;Machine Learning;electric vehicle;energy storage;health monitoring;lithium-ion battery;machine learning","Aging;Batteries;Bayes methods;Data models;Degradation;Entropy;Monitoring","battery management systems;electric vehicles;entropy;secondary cells;support vector machines","SVM;battery health management;battery health monitoring;battery health prognosis;bootstrap sampling;capacity loss;electric vehicles;lithium-ion battery cells;machine-learning-enabled battery state-of-health indication;polynomial model;sparse Bayesian predictive modeling;support vector machine","","6","","51","","20150728","April 2016","","IEEE","IEEE Journals & Magazines"
"Memristor Based Arbiter PUF: Cryptanalysis Threat and Its Mitigation","U. Chatterjee; R. S. Chakraborty; J. Mathew; D. K. Pradhan","Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kharagpur, Kharagpur, India","2016 29th International Conference on VLSI Design and 2016 15th International Conference on Embedded Systems (VLSID)","20160317","2016","","","535","540","Physically Unclonable Function (PUF) circuits are promising hardware security primitives. Recently a hybrid CMOS-memristor based lightweight PUF circuit was described by Mathew et al., and shown to be resistant against machine learning based model building attack. In this paper we demonstrate that such a PUF is vulnerable to cryptanalysis. We then propose a modification to the circuit to make it resistant against cryptanalysis, while retaining its robustness against machine learning attacks, and its low hardware footprint. We demonstrate the suitability of our proposed PUF through extensive simulation results and statistical characterization.","","Electronic:978-1-4673-8700-2; POD:978-1-4673-8701-9","10.1109/VLSID.2016.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435009","Cryptnalysis;Machine Learning Attacks;Memristor;Physical Unclonable Function (PUF)","CMOS integrated circuits;Cryptography;Hardware;MOS devices;Memristors;Resistance","CMOS integrated circuits;integrated circuit modelling;learning (artificial intelligence);memristor circuits","Arbiter PUF;CMOS-memristor;cryptanalysis;machine learning attacks;model building attack;physically unclonable function circuits","","2","","20","","","4-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"On-Chip Droop-Induced Circuit Delay Prediction Based on Support-Vector Machines","F. Ye; F. Firouzi; Y. Yang; K. Chakrabarty; M. B. Tahoori","Qualcomm Atheros Inc., San Jose, CA, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20160317","2016","35","4","665","678","Voltage droop is a major reliability concern in nano-scale very large-scale integration designs. Undesirable voltage droop is often a result of excessive IR drop. On the other hand, Ldi/dt-induced droop occurs when logic gates in the circuit draw high-switching current from the on-chip power supply network, and this problem is exacerbated at high-clock frequencies and smaller technology nodes. A consequence of voltage droop is usually an increase in path delays and the occurrence of intermittent faults during circuit operation. The addition of conservative timing margins, also known as guardbands, is a common practice to tackle the problem of voltage droop. However, such static and pessimistic guardbands, which are calculated at design time based on worst-case conditions, lead to significant performance loss. Dynamic frequency scaling is an alternative approach that enables the dynamic adjustment of clock frequency based on the actual voltage droop seen during runtime. For dynamic voltage-frequency to be effective, accurate and real-time prediction of voltage droop is essential. We propose a support-vector machine (SVM)-based regression method to predict voltage droop due to pattern-dependent IR drop based on inputs to the chip at runtime. Moreover, we reduce the amount of data needed for accurate prediction by using correlation-based feature selection. Several benchmarks from ITC'99 and International Work on Logic and Synthesis'05 highlight the effectiveness of the proposed method in terms of delay-prediction accuracy. Since real-time droop prediction requires hardware implementation of the predictor, we present the hardware design and synthesis results to demonstrate that the hardware overhead for the SVM predictor is negligible for large circuits.","0278-0070;02780070","","10.1109/TCAD.2015.2474392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7229282","Feature selection;Hardware implementation;feature selection;hardware implementation;machine learning;resilient system;support-vector machine;support-vector machine (SVM);voltage droop","Delays;Hardware;Logic gates;Support vector machines;Training;Voltage control","VLSI;electronic engineering computing;integrated circuit design;integrated circuit reliability;regression analysis;support vector machines","IR drop;ITC 99;SVM predictor;conservative timing margins;correlation-based feature selection;delay-prediction accuracy;design time;dynamic frequency scaling;dynamic voltage-frequency;hardware design;hardware overhead;high-clock frequency;high-switching current;intermittent faults;international work-logic-and-synthesis 05;logic gates;nanoscale very-large-scale integration design;on-chip droop-induced circuit delay prediction;on-chip power supply network;path delays;pattern-dependent IR drop;performance loss;pessimistic guardband;real-time droop prediction;regression method;reliability concern;static guardband;support-vector machine;support-vector machines;voltage droop","","0","1","29","","20150828","April 2016","","IEEE","IEEE Journals & Magazines"
"A classification system for jamu efficacy based on formula using support vector machine and k-means algorithm as a feature selection","M. N. Puspita; W. A. Kusuma; A. Kustiyo; R. Heryanto","Department of Computer Science, Faculty of Matematics and Natural Science Bogor Agricultural University, Bogor, Indonesia","2015 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20160225","2015","","","215","220","Jamu is an Indonesia herbal medicine made from natural materials such as roots, leaves, fruits, and animals. The purpose of this research is to develop a classification system for jamu efficacy based on the composition of plants using Support Vector Machine (SVM) and to implement the k-means clustering algorithm as a feature selection method. The result of this study was compared to the previous research that using SVM method without feature selection. This study used variances to evaluate the results of clustering. The total of 3138 data herbs and 465 plant species were grouped into 100 clusters with the variance of 0.0094. The managed group succesfully reduced the data dimension into 3047 of jamu sample and 236 species of herbs and plants as features. The result of SVM classification using feature selection yielded the accuracy of 71.5%.","","Electronic:978-1-5090-0363-1; POD:978-1-5090-0364-8; USB:978-1-5090-0362-4","10.1109/ICACSIS.2015.7415176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415176","classification;feature selection;jamu;k-means;machine learning;support vector machine","Kernel;Support vector machines","botany;feature selection;medical computing;pattern classification;pattern clustering;support vector machines","Indonesia herbal medicine;Jamu efficacy;SVM classification;classification system;data dimension reduction;feature selection method;k-means algorithm;k-means clustering algorithm;support vector machine","","","","8","","","10-11 Oct. 2015","","IEEE","IEEE Conference Publications"
"Stock selection model based on advanced AdaBoost algorithm","S. Yutong; H. Zhao","International School, Beijing University of Posts and Telecommunications, Beijing, China","2015 7th International Conference on Modelling, Identification and Control (ICMIC)","20160218","2015","","","1","7","Stock market is a complex non-linear dynamic system which is affected by many factors. Traditional analysis and forecasting methods are insufficient to accurately reveal the inherent pattern of the stock market, resulting in a big difference between expected and observed results. In recent years, machine learning analytical methods are applied to the stock selection model more often than before and have achieved good results so far. This paper introduces the application of machine learning in stock selection and conducts detailed research on AdaBoost algorithm. The aim is to establish a multi-factor stock selection model based on AdaBoost algorithm, by which we select stock through the analysis of various indicators of a stock. Furthermore, being aware of the flaws of the basic AdaBoost model, we optimize the stock selection model based on actual characteristics of stock selecting process. We also conduct an empirical analysis on Shanghai A-share Stock excluding the ones which were listed before 2010 and which are suspended. We compare the practicality and accuracy of the basic AdaBoost model and the advanced one. Based on experiment results, the advanced AdaBoost model outperforms the basic one by a substantial margin.","","Electronic:978-0-9567-1575-3; POD:978-1-4673-6501-7","10.1109/ICMIC.2015.7409386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7409386","AdaBoost;Machine learning;Stock selection factors","Algorithm design and analysis;Classification algorithms;Error analysis;Investment;Prediction algorithms;Training","learning (artificial intelligence);stock markets","Shanghai A-share Stock;advanced AdaBoost algorithm;complex nonlinear dynamic system;machine learning analytical method;stock market;stock selection model","","","","14","","","18-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"An approach to spam comment detection through domain-independent features","Jong Myoung Kim; Zae Myung Kim; Kwangjo Kim","School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","273","276","Previous research in spam detection, especially in email spam filtering, mainly focused on learning a set of discriminative features that are often present in the spam contents. Nowadays, these commercially oriented spams are well detected; the real challenge lies in filtering rather vague spams that do not exhibit distinctive spam keywords. We investigate two ways of detecting such spams: 1) By comparing the similarity between the publisher posts and user comments, and 2) by learning a single representative meta-feature such as user name or ID. The first measure relieves us from repetitively learning a set of domain-dependent spam features, and the second measure enables us to detect potential spam users even before the aggressive actions are performed. Prior to the language model comparison in the first method, we supplement the background information, normalize the text, perform co-reference resolution, and conduct word-to-word similarity measure in hope of enriching the language models to improve the classification accuracy. To evaluate the first measure, experiments on detecting blog-spam comments are conducted. As for the second measure, we employ SVM on the ID space of e-mail data collected by “Apache Spam Assassin”.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425926","machine learning;spam filtering;spam user detection","Blogs;Electronic mail;Encyclopedias;Feature extraction;Information filtering;Support vector machines","electronic mail;text analysis","Apache spam assassin;SVM;co-reference resolution;domain-dependent spam features;domain-independent features;email spam filtering;single representative meta-feature;spam comment detection;word-to-word similarity measure","","","","12","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"A Review of Image Segmentation Techniques for Tracking the Velum","A. Sana; J. L. Perry; N. Tabrizi","Dept. of Comput. Sci., East Carolina Univ., Greenville, NC, USA","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","433","436","Several studies have used 2D and 3D modeling to visualize the velum. Very few attempts have been made to track the velum and plot its movement against time. Image segmentation has been used widely for various purposes. However, its proficiency in tracking the velum is questionable at the moment. Two image segmentation methods, EdgeTrak and the Hidden Markov Model, are reviewed in this report. EdgeTrak, a software developed at VIMS Lab, has been proven to track the surface of a human tongue during speech production. An attempt was made to similarly track the velum during speech production using EdgeTrak but the results were disappointing. Also, synchronized audio mapping using the Hidden Markov Model was only partially successful. This paper describes the challenges image segmentation faces with regards to tracking the velum.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424131","Image segmentation;machine learning;soft palate;tracking;velum","Hidden Markov models;Image edge detection;Image segmentation;Software;Speech;Tongue;Tracking","edge detection;hidden Markov models;image segmentation;speech","2D modeling;3D modeling;EdgeTrak;VIMS Lab;hidden Markov model;human tongue surface tracking;image segmentation method;speech production;synchronized audio mapping;velum tracking","","","","17","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Scaling-up resistive synaptic arrays for neuro-inspired architecture: Challenges and prospect","S. Yu; P. Y. Chen; Y. Cao; L. Xia; Y. Wang; H. Wu","Arizona State University, Tempe, AZ 85281, USA","2015 IEEE International Electron Devices Meeting (IEDM)","20160218","2015","","","17.3.1","17.3.4","The crossbar array architecture with resistive synaptic devices is attractive for on-chip implementation of weighted sum and weight update in the neuro-inspired learning algorithms. This paper discusses the design challenges on scaling up the array size due to non-ideal device properties and array parasitics. Circuit-level mitigation strategies have been proposed to minimize the learning accuracy loss in a large array. This paper also discusses the peripheral circuits design considerations for the neuro-inspired architecture. Finally, a circuit-level macro simulator is developed to explore the design trade-offs and evaluate the overhead of the proposed mitigation strategies as well as project the scaling trend of the neuro-inspired architecture.","","Electronic:978-1-4673-9894-7; POD:978-1-4673-9895-4","10.1109/IEDM.2015.7409718","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7409718","Resistive memory;crossbar array;machine learning;neuromorphic computing;synaptic device","Algorithm design and analysis;Arrays;Encoding;Neuromorphics;Switching circuits;Wires","learning (artificial intelligence);neural chips","array parasitics;circuit-level macro simulator;circuit-level mitigation strategy;crossbar array architecture;design challenge;learning accuracy loss minimization;neuro-inspired architecture;neuro-inspired learning algorithms;nonideal device properties;on-chip implementation;peripheral circuit design consideration;resistive synaptic arrays;resistive synaptic devices;weight update;weighted sum","","9","","13","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Multivariate Approximation Methods Using Polynomial Models: A Comparative Study","I. Lopez-Peña; A. Kuri-Morales","Posgrado en Cienc. e Ing. de la Comput., IIMAS-UNAM, Mexico City, Mexico","2015 Fourteenth Mexican International Conference on Artificial Intelligence (MICAI)","20160310","2015","","","131","138","A frequent problem in artificial intelligence is the one associated with the so-called supervised learning: the need to find an expression of a dependent variable as a function of several independent ones. There are several algorithms that allow us to find a solution to the bivariate problems. However, the true challenge arises when the number of independent variables is large. Relatively new tools have been developed to tackle this kind of problems. Thus, multi-Layer Perceptron networks (MLPs) may be seen as multivariate approximation algorithms. However, a commonly cited disadvantage of MLPs is that they remain a ""black-box"" kind of method: they do not yield an explicit closed expression to the solution. Rather, we are left with the need of expressing it via the architecture of the MLP and the value of the trained connections. In this paper we explore three methods that allow us to express the solution to multivariate problems in a closed form: a) Fast Ascent (FA), b) Levenberg-Marquardt (LM) and c) Powell's Dog-Leg (PM) algorithms. These yield closed expressions when presented with multiple independent variable problems. In this paper we discuss and compare these four methods and their possible application to pattern recognition in mobile robot environments and artificial intelligence in general.","","Electronic:978-1-5090-0323-5; POD:978-1-5090-0324-2","10.1109/MICAI.2015.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429425","Genetic algorithms;Machine Learning;Multivariate Approximation;Pattern Recognition","Approximation algorithms;Approximation error;Artificial intelligence;Damping;Jacobian matrices;Urban areas","approximation theory;learning (artificial intelligence);multilayer perceptrons;polynomials","Levenberg-Marquardt algorithm;MLP;Powell Dog-Leg algorithm;artificial intelligence;bivariate problem;fast ascent algorithm;multilayer perceptron network;multivariate approximation method;polynomial model;supervised learning","","","","32","","","25-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"Augmenting a classifier ensemble with automatically generated class level patterns for higher accuracy","A. Venkataraman","BOS-Botworks, Wipro Technologies, Bangalore, India","2015 Conference on Technologies and Applications of Artificial Intelligence (TAAI)","20160215","2015","","","266","272","Different types of classifiers were investigated in the context of classification of problem tickets in the Enterprise domain. There were still challenges in building an accurate classifier post data cleaning and other accuracy improving pre-processing techniques. Creating an ensemble of classifiers gave better accuracy than individual classifiers. The maximum accuracy was got by enhancing the ensemble with an additional automatically generated domain specific class wise keyword list. Use of this system gave us greater than 4 percent improvement over the techniques of just using the ensemble classifier. A further improvement in accuracy was obtained when a semi-supervised approach was followed where the automatically generated class level keys are further reviewed by domain team before usage.","","Electronic:978-1-4673-9606-6; POD:978-1-4673-9607-3","10.1109/TAAI.2015.7407105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407105","Accuracy;Classification;Committee-based approach;F-score;Feature extraction;Latent Semantic Analysis;Machine Learning;Natural Language Processing;Term Frequency Inverse Document Frequency;ensemble","Context;Predictive models","business data processing;learning (artificial intelligence);natural language processing;pattern classification","class level keys;class level patterns;classifier ensemble;data cleaning;data preprocessing techniques;enterprise domain;keyword list;machine learning;natural language processing;semisupervised approach;tickets classification","","","","19","","","20-22 Nov. 2015","","IEEE","IEEE Conference Publications"
"Characterization of Traffic Analysis based video stream source identification","Y. Shi; S. Biswas","Electrical and Computer Engineering, Michigan State University, East Lansing, USA","2015 IEEE International Conference on Advanced Networks and Telecommuncations Systems (ANTS)","20160225","2015","","","1","6","This paper presents the concept and characterization of Traffic Analysis (TA) for identifying sources of tunneled video streaming traffic. Such identification can be used in enterprise firewalls for blocking unauthorized viewing of tunneled video. We attempt to characterize and evaluate the impacts of the primary TA-influencing factors, namely, streaming protocol, codec, and the actual video content. A test environment is built to study the influence of those factors while Packet Size Distribution is used as the classification feature during Traffic Analysis. Analysis done on data obtained from the test environment has shown that the streaming protocols provide the most dominant source identification distinction. Also, while the codecs provide some weak distinctions, the influence of video content is marginal. In addition to in-laboratory experiments, a real-world verification for corroborating those observations is also made with commercial streaming service providers. Such long-haul experiments indicate that the end-to-end network conditions between the streaming server and video client can act as an additional influencing factor for traffic analysis towards video stream source identification. Overall, the results suggest the feasibility of TA for unknown video stream source identification with sufficiently diverse video examples.","","Electronic:978-1-5090-0293-1; POD:978-1-5090-0294-8","10.1109/ANTS.2015.7413623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413623","adaptive video streaming;classifiers;machine learning;smooth streaming;traffic analysis","Codecs;Cryptography;Firewalls (computing);Protocols;Servers;Streaming media;Virtual private networks","image classification;protocols;telecommunication traffic;video codecs;video signal processing;video streaming","TA characterization;classification feature;codec;commercial streaming service providers;end-to-end network conditions;enterprise firewalls;packet size distribution;primary TA-influencing factors;source identification distinction;streaming protocol;streaming server;test environment;traffic analysis based video stream source identification characterization;tunneled video streaming traffic sources;video client;video content","","","","13","","","15-18 Dec. 2015","","IEEE","IEEE Conference Publications"
"Automated super-voxel based features classification of urban environments by integrating 3D point cloud and image content","P. Babahajiani; L. Fan; J. Kamarainen; M. Gabbouj","Department of Signal Processing, Tampere University of Technology, Tampere, Finland","2015 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)","20160225","2015","","","372","377","In this paper we present a novel street scene semantic recognition framework, which takes advantage of 3D point cloud captured by a high definition LiDAR laser scanner. An important problem in object recognition is the need for sufficient labeled training data to learn robust classifiers. We show how to significantly reduce the need for manually labeled training data by reduction of scene complexity using non-supervised ground and building segmentation. Our system first automatically segments grounds point cloud. Then, using binary range image processing building facades will be detected. Remained point cloud will grouped into voxels which are then transformed to super voxels. Local 3D features extracted from super voxels are classified by trained boosted decision trees and labeled with semantic classes e.g. tree, pedestrian, car. Given labeled 3D points cloud and 2D image with known viewing camera pose, the proposed association module aligned collections of 3D points to the groups of 2D image pixel to parsing 2D cubic images.","","Electronic:978-1-4799-8996-6; POD:978-1-4799-8997-3","10.1109/ICSIPA.2015.7412219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412219","3D point cloud;Classification;Feature extraction;Image alignment;LiDAR;Machine learning;Mobile laser scanner;Segmentation;Street view","Buildings;Feature extraction;Image segmentation;Laser radar;Robustness;Three-dimensional displays","decision trees;feature extraction;geophysical image processing;image classification;image segmentation;object recognition;optical radar;optical scanners;radar imaging;stereo image processing","2D cubic images;2D image pixel;3D features;3D point cloud;LiDAR laser scanner;automated super-voxel based features classification;binary range image processing;building facades;building segmentation;decision trees;ground point cloud;image content;nonsupervised ground;object recognition;semantic classes;street scene semantic recognition;viewing camera pose","","","","15","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Determining Utterance Timing of a Driving Agent With Double Articulation Analyzer","T. Taniguchi; K. Furusawa; H. Liu; Y. Tanaka; K. Takenaka; T. Bando","Coll. of Inf. Sci. & Eng., Ritsumeikan Univ., Kusatsu, Japan","IEEE Transactions on Intelligent Transportation Systems","20160226","2016","17","3","810","821","In-vehicle speech-based interaction between a driver and a driving agent should be performed without affecting the driving behavior. A driving agent provides information to the driver and helps his/her driving behavior and non-driving-related tasks, e.g., selecting music and giving weather information. In this paper, we focus on a method for determining utterance timings when a driving agent provides non-driving-related information. If a driving agent provides a driver with non-driving-related information at an inappropriate moment, it will distract his/her driving behavior and deteriorate his/her safety driving. To solve or to mitigate the problem, we propose a novel method for determining the utterance timing of a driving agent on the basis of a double articulation analyzer, which is an unsupervised nonparametric Bayesian machine learning method for detecting contextual change points. To verify the effectiveness of the method, we conduct two experiments. One is an experiment on a short circuit around a park in an urban area, and the other is an experiment on a long course in a town. The results show that the proposed method enables a driving agent to avoid inappropriate timing better than baseline methods.","1524-9050;15249050","","10.1109/TITS.2015.2484421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7302597","Driving agent;driver distraction;driving data;machine learning;nonparametric Bayes","Hidden Markov models;Intelligent vehicles;Meteorology;Navigation;Timing;Vehicles","multi-agent systems;road traffic;traffic engineering computing;unsupervised learning","double articulation analyzer;driving agent;driving behavior;in-vehicle speech-based interaction;unsupervised nonparametric Bayesian machine learning method;utterance timings determination","","","","33","","20151026","March 2016","","IEEE","IEEE Journals & Magazines"
"Efficient Bit Rate Transcoding for High Efficiency Video Coding","L. Pham Van; J. De Praeter; G. Van Wallendael; S. Van Leuven; J. De Cock; R. Van de Walle","Department of Electronics and Information Systems, Ghent University&#8212;iMinds, Ghent, Belgium","IEEE Transactions on Multimedia","20160218","2016","18","3","364","378","High efficiency video coding (HEVC) shows a significant advance in compression efficiency and is considered to be the successor of H.264/AVC. To incorporate the HEVC standard into real-life network applications and a diversity of other applications, efficient bit rate adaptation (transrating) algorithms are required. A current problem of transrating for HEVC is the high computational complexity associated with the encoder part of such a cascaded pixel domain transcoder. This paper focuses on deriving an optimal strategy for reducing the transcoding complexity with a complexity-scalable scheme. We propose different transcoding techniques which are able to reduce the transcoding complexity in both CU and PU optimization levels. At the CU level, CUs can be evaluated in top-to-bottom or bottom-to-top flows, in which the coding information of the input video stream is utilized to reduce the number of evaluations or to early terminate certain evaluations. At the PU level, the PU candidates are adaptively selected based on the probability of PU sizes and the co-located input PU partitioning. Moreover, with the use of different proposed methods, a complexity-scalable transrating scheme can be achieved. Furthermore, the transcoding complexity can be effectively controlled by the machine learning based approach. Simulations show that the proposed techniques provide a superior transcoding performance compared to the state-of-the-art related works. Additionally, the proposed methods can achieve a range of trade-offs between transrating complexity and coding performance. From the proposed schemes, the fastest approach is able to reduce the complexity by 82% while keeping the bitrate loss below 3%.","1520-9210;15209210","","10.1109/TMM.2015.2512231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7365484","Machine learning;bit rate adaptation;complexity scalable transcoding;high efficiency video coding","Bit rate;Complexity theory;Standards;Streaming media;Transcoding;Video coding","","","","2","","35","","20151224","March 2016","","IEEE","IEEE Journals & Magazines"
"Optimal Fair Opportunistic Scheduling For Wireless Systems Via Classification Framework","P. Nguyen; B. Rao","Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA","IEEE Transactions on Cognitive Communications and Networking","20160225","2015","1","2","185","199","In this work, we exploit historical channel data via linear programming and machine learning tools to perform opportunistic scheduling for multiuser wireless systems under temporal fairness constraints. We first derive linear program-based scheduling (LPS) algorithms that compute the scheduling decisions from a window of past user metrics. The proposed linear program scheduling policies approach the optimal policy as the window size gets large. However, as demonstrated via simulations, even with a short window, the performance of the proposed policies can be very close to optimal. For stationary environments, we introduce a new interpretation of the scheduling problem that casts the resource allocation problem as one of statistical classification. We then propose a novel supervised classification-based scheduling (SCS) framework, which uses the LPS decisions to obtain labeled samples for training a multiclass classifier and obtaining optimal scheduling decision boundaries. In addition, as applications of the proposed classification framework, we devise efficient classification methods to learn the scheduling offsets for existing offset-driven scheduling policies.","","","10.1109/TCCN.2015.2488652","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294640","Opportunistic scheduling;classifier design;fairness;linear programming;machine learning;multiuser diversity;supervised learning","Linear programming;Measurement;Optimal scheduling;Processor scheduling;Scheduling;Wireless communication","learning (artificial intelligence);linear programming;multi-access systems;resource allocation;statistical analysis;telecommunication scheduling","LPS algorithm;SCS framework;classification framework;historical channel data;linear program-based scheduling algorithm;linear programming;machine learning;multiclass classifier;multiuser wireless system;offset-driven scheduling policy;optimal fair opportunistic scheduling;optimal scheduling decision boundary;resource allocation problem;statistical classification;supervised classification-based scheduling framework;temporal fairness constraint","","","","23","","20151008","June 2015","","IEEE","IEEE Journals & Magazines"
"Semi-Supervised Nonlinear Distance Metric Learning via Forests of Max-Margin Cluster Hierarchies","D. M. Johnson; C. Xiong; J. J. Corso","Department of Computer Science and Engineering, SUNY at Buffalo, Buffalo, NY","IEEE Transactions on Knowledge and Data Engineering","20160304","2016","28","4","1035","1046","Metric learning is a key problem for many data mining and machine learning applications, and has long been dominated by Mahalanobis methods. Recent advances in nonlinear metric learning have demonstrated the potential power of non-Mahalanobis distance functions, particularly tree-based functions. We propose a novel nonlinear metric learning method that uses an iterative, hierarchical variant of semi-supervised max-margin clustering to construct a forest of cluster hierarchies, where each individual hierarchy can be interpreted as a weak metric over the data. By introducing randomness during hierarchy training and combining the output of many of the resulting semi-random weak hierarchy metrics, we can obtain a powerful and robust nonlinear metric model. This method has two primary contributions: first, it is semi-supervised, incorporating information from both constrained and unconstrained points. Second, we take a relaxed approach to constraint satisfaction, allowing the method to satisfy different subsets of the constraints at different levels of the hierarchy rather than attempting to simultaneously satisfy all of them. This leads to a more robust learning algorithm. We compare our method to a number of state-of-the-art benchmarks on $k$-nearest neighbor classification, large-scale image retrieval and semi-supervised clustering problems, and find that our algorithm yields results comparable or superior to the state-of-the-art.","1041-4347;10414347","","10.1109/TKDE.2015.2507130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350148","Clustering;and association rules;classification;data mining;image/video retrieval;machine learning;similarity measures","Clustering algorithms;Data mining;Data models;Measurement;Semantics;Training","data mining;learning (artificial intelligence);pattern clustering","Mahalanobis methods;constraint satisfaction approach;data mining;large-scale image retrieval;machine learning application;max-margin cluster hierarchy;nearest neighbor classification;nonMahalanobis distance function;semisupervised clustering problems;semisupervised max-margin clustering;semisupervised nonlinear distance metric learning;tree-based functions","","","","35","","20151209","April 1 2016","","IEEE","IEEE Journals & Magazines"
"APE: A Data-Driven, Behavioral Model-Based Anti-Poaching Engine","N. Park; E. Serra; T. Snitch; V. S. Subrahmanian","Department of Computer Science, The University of Maryland, College Park, MD, USA","IEEE Transactions on Computational Social Systems","20160215","2015","2","2","15","37","We consider the problem of protecting a set of animals such as rhinos and elephants in a game park using D drones and R ranger patrols (on the ground) with R ≥ D. Using two years of data about animal movements in a game park, we propose the probabilistic spatio-temporal graph (pSTG) model of animal movement behaviors and show how we can learn it from the movement data. Using 17 months of data about poacher behavior, we also learn the probability that a region in the game park will be targeted by poachers. We formalize the anti-poaching problem as that of finding a coordinated route for the drones and ranger patrols that maximize the expected number of animals that are protected, given these two models as input and show that it is NP-complete. Because of this, we fine tune classical local search and genetic algorithms to the case of anti-poaching by taking specific advantage of the nature of the anti-poaching problem and its objective function. We develop a measure of the quality of an algorithm to route the drones and ranger patrols called “improvement ratio.” We develop a dynamic programming based APE_Coord_Route algorithm and show that it performs very well in practice, achieving an improvement ratio over 90%.","2329-924X;2329924X","","10.1109/TCSS.2016.2517452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407518","Anti-poaching;geo-spatial inference;human and animal behavior modeling;machine learning;optimization","Animal behavior;Drones;Machine learning;Optimization;Prediction algorithms","dynamic programming;ecology;genetic algorithms;graph theory;probability;search problems;zoology","APE_Coord_Route algorithm;NP-complete;animal movement behavior;antipoaching engine;dynamic programming;game park;genetic algorithm;improvement ratio;local search;probabilistic spatio-temporal graph","","1","","39","","","June 2015","","IEEE","IEEE Journals & Magazines"
"A Stochastic Approach for Finding Optimal Context in a Contextual Pattern Analysis Task","U. Garain","Indian Statistical Institute","IEEE Intelligent Systems","20160317","2016","31","2","21","28","This article concerns contextual pattern analysis tasks. As different contexts give different performances, models for finding the optimal context are revisited here. Random field models for the input data are assumed. An underlying random field is represented by a set of parameters capturing the spatial dependence. Next, a Bayesian approach is revisited to develop a decision rule for choosing appropriate context. The relevance of this approach is explored for three pattern analysis tasks, namely, handwriting analysis, image compression, and word sense disambiguation.","1541-1672;15411672","","10.1109/MIS.2016.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412638","Bayesian statistics;contextual information;image processing;intelligent systems;machine learning;natural language processing;optimal context;pattern recognition;random field models","Bayes methods;Computational modeling;Context awareness;Context modeling;Hidden Markov models;Image coding;Image processing;Machine learning;Natural language processing;Pattern analysis","Bayes methods;data compression;handwriting recognition;image coding;natural language processing;random processes;stochastic processes","Bayesian approach;contextual pattern analysis tasks;handwriting analysis;image compression;input data;optimal context;random field model;spatial dependence;stochastic approach;word sense disambiguation","","","","35","","20160218","Mar.-Apr. 2016","","IEEE","IEEE Journals & Magazines"
"Automatic Extraction of Main Thesis Documents Fields Using Decision Trees","A. M. Sobhy; Y. M. Kamal; A. Z. Ghalwash","Coll. of Comput. & Inf. Technol., Arab Acad. for Sci. Technol. & Maritime Transp., Cairo, Egypt","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","203","208","Thesis documents are underestimated even though they hold large sets of useful information -- as they include most of the research information -- , but since they are harder to obtain, researchers were lead to depend on research papers even though they have a size limitation and lack elaboration. A lot of time and effort are invested in research, so having a linkage among researchers based on their work would somehow facilitate solving the research problem process. A major step to tackle this goal is to structure thesis documents by extracting some fields such as title, author and abstract. This paper presents a way to structure a semi-structured thesis documents using decision trees in 4 different ways (Simple, Medium, Complex and using KNIME), they scored an overall accuracy of 99.2%.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424091","Decision Trees;Machine Learning;Semi-structured Data;Structured Data;Thesis Documents","Data mining;Databases;Decision trees;Feature extraction;Predictive models;Testing;Training","decision trees;document handling;feature extraction;learning (artificial intelligence)","KNIME decision tree;automatic document extraction;complex decision tree;main thesis documents;medium decision tree;research information;simple decision tree","","","","13","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Intrinsic Scene Properties from a Single RGB-D Image","J. T. Barron; J. Malik","Department of Electrical Engineering and Computer Science, University of California at Berkeley, Berkeley, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20160303","2016","38","4","690","703","In this paper, we present a technique for recovering a model of shape, illumination, reflectance, and shading from a single image taken from an RGB-D sensor. To do this, we extend the SIRFS (“shape, illumination and reflectance from shading”) model, which recovers intrinsic scene properties from a single image [1] . Though SIRFS works well on neatly segmented images of objects, it performs poorly on images of natural scenes which often contain occlusion and spatially-varying illumination. We therefore present Scene-SIRFS, a generalization of SIRFS in which we model a scene using a mixture of shapes and a mixture of illuminations, where those mixture components are embedded in a “soft” segmentation-like representation of the input image. We use the noisy depth maps provided by RGB-D sensors (such as the Microsoft Kinect) to guide and improve shape estimation. Our model takes as input a single RGB-D image and produces as output an improved depth map, a set of surface normals, a reflectance image, a shading image, and a spatially varying model of illumination. The output of our model can be used for graphics applications such as relighting and retargeting, or for more broad applications (recognition, segmentation) involving RGB-D images.","0162-8828;01628828","","10.1109/TPAMI.2015.2439286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7115131","Computer vision;depth sensing;illumination estimation;intrinsic images;machine learning;normalized cuts;segmentation;shape estimation;shape from shading","Computational modeling;Image segmentation;Lighting;Noise;Noise measurement;Rendering (computer graphics);Shape","computer vision;image segmentation;image sensors;learning (artificial intelligence)","Microsoft Kinect;RGB-D sensor;SIRFS;computer vision;image segmentation;intrinsic scene properties;machine learning;shape, illumination and reflectance from shading model;single RGB-D image","","0","","35","","20150601","April 1 2016","","IEEE","IEEE Journals & Magazines"
"Pedestrian detection algorithm for overlapping and non-overlapping conditions","B. Amirgaliyev; K. Perizat; C. Kenshimov","IITU, Almaty, Kazakhstan","2015 Twelve International Conference on Electronics Computer and Computation (ICECCO)","20160225","2015","","","1","4","The aim of this paper is to present the algorithms that were developed for detecting human in the conditions of overlapping and non-overlapping. Overlapping means when person is not fully visible in the image and occluded by another person at the front or right/left side. In order to achieve this goal, three steps were implemented. The algorithms were implemented in C++ with the help of Open Source Computer Vision (OpenCV) library. The first step was human detection when single person's body occupied most of the image. For this, three machine learning techniques were examined: K - Nearest Neighbour algorithm (KNN), Support Vector Machine (SVM), and Decision Tree learning. Their performances were compared and optimal classifier was chosen. The results of experiments have shown that SVM, in comparison with others, had the highest accuracy rate. It exceeded others for about 10-12%. So, SVM was taken as a classifier which detected human at an accuracy rate of about 95%. The second step was implementation of sliding window approach to detect multiple people in the image. And the last, third main step was people detection in conditions of occlusion. As it's known, SVM gives the decision value (confidence) for detection, negative value is for person and positive value is for non-person. Our approach was based on the assumption that if it is occluded person which overlap with detected person, its confidence should be smaller than confidences of its neighbour windows so that occluded person would be more `human like' with respect to neighbours. So, we found local minima within the windows, which intersect with a window of detected for person more than 45%. The results of tests for detection of occluded people indicated the accuracy rate of about 54% is electronic document is a ""live"" template and already defines the components of your paper.","","Electronic:978-1-5090-0200-9; POD:978-1-5090-0201-6","10.1109/ICECCO.2015.7416896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416896","classification;human detection;image processing;machine learning;occlusion;overlapping;supervised learning","Classification algorithms;Computer vision;Decision trees;Detectors;Machine learning algorithms;Support vector machines;Training","computer vision;decision trees;learning (artificial intelligence);object detection;pattern classification;pedestrians;support vector machines","C++;KNN;OpenCV library;SVM;decision tree learning;electronic document;human detection;k-nearest neighbour algorithm;machine learning technique;multiple people detection;negative value;nonoverlapping condition;open source computer vision;optimal classifier;pedestrian detection algorithm;positive value;sliding window approach;support vector machine","","","","7","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Hardware Accelerator for Probabilistic Inference in 65-nm CMOS","O. U. Khan; D. D. Wentzloff","Department of Electrical Engineering, University of California at Berkeley, Berkeley, CA, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20160223","2016","24","3","837","845","A hardware accelerator is presented to compute the probabilistic inference for a Bayesian network (BN) in distributed sensing applications. For energy efficiency, the accelerator is operated at a near-threshold voltage of 0.5 V, while achieving a maximum clock frequency of 33 MHz. Clique-tree message passing algorithm is leveraged to compute the probabilistic inference. The theoretical maximum size of a factor that the proposed hardware accelerator can handle is 2<sup>(8×20)</sup>=160 entries, which is sufficient for handling massive BNs, such as PATHFINDER, MUNIN, and so on (>1000 nodes). A Logical Alarm Reduction Mechanism (ALARM) BN is used to benchmark the performance of the accelerator. The accelerator consumes 76 nJ to execute the ALARM network using a clique-tree message-passing algorithm, while the same algorithm executed on an ultralow-power microcontroller consumes 20 mJ.","1063-8210;10638210","","10.1109/TVLSI.2015.2420663","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091000","Bayesian network (BN);clique-tree;embedded machine learning;hardware accelerator;intelligent sensor node;message passing;probabilistic graphical model;probabilistic inference","Bayes methods;Hardware;Indexes;Inference algorithms;Message passing;Probabilistic logic;Registers","Bayes methods;CMOS integrated circuits;distributed sensors;energy conservation;inference mechanisms;low-power electronics;microcontrollers","ALARM network;Bayesian network;CMOS integrated circuit;PATHFINDER;a logical alarm reduction mechanism;clique-tree message passing algorithm;clock frequency;distributed sensing applications;energy 20 mJ;energy efficiency;frequency 33 MHz;hardware accelerator;probabilistic inference;size 65 nm;ultralow-power microcontroller;voltage 0.5 V","","0","","23","","20150421","March 2016","","IEEE","IEEE Journals & Magazines"
"Adapting an Ensemble of One-Class Classifiers for a Web-Layer Anomaly Detection System","R. Kozik; M. Choras","Inst. of Telecommun. & Comput. Sci., Univ. of Sci. & Technol., Bydgoszcz, Poland","2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)","20160303","2015","","","724","729","The problem of web-layer security has recently become an important research topic. This happens due to the fact that it is relatively easier to identify an exploit in a vulnerable web page than in the operating system or a web-server, for instance. Therefore, these have become a common element in many attack vectors. In this paper we propose a machine-learning web-layer anomaly detection system that adapts a packet segmentation mechanism and an ensemble of one-class classifiers. In our approach we particularly focus on packet structure analysis, classifiers hybridisation, and the problem of data imbalance. Our experiments conducted on publicly available benchmark database show that the proposed technique allows us to achieve better results than a classical approach using payload statistics.","","CD-ROM:978-1-4673-8317-2; Electronic:978-1-4673-9473-4; POD:978-1-4673-9474-1","10.1109/3PGCIC.2015.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424657","ensemble of classifiers;machine learning;web-layer anomaly detection","Color;Feature extraction;Payloads;Protocols;Security;Web servers","Internet;learning (artificial intelligence);pattern classification;security of data","Web-layer anomaly detection system;classifiers hybridisation;data imbalance problem;machine-learning;one-class classifier ensemble;packet segmentation mechanism;packet structure analysis;payload statistics","","","","30","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"HRI in an ecological dynamic experiment: The GEE corpus based approach for the Emox robot","L. Guillaume; V. Aubergé; R. Magnani; F. Aman; C. Cottier; Y. Sasa; C. Wolf; F. Nebout; N. Neverova; N. Bonnefond; A. Nègre; L. Tsvetanova; M. Girard-Rivier","University Grenoble Alps, LIG, UMR CNRS 5217, France","2015 IEEE International Workshop on Advanced Robotics and its Social Impacts (ARSO)","20160310","2015","","","1","6","As part of a human-robot interaction project, the gestural modality is one of many ways to communicate. In order to develop a relevant gesture recognition system associated to a smart home butler robot, our methodology is based on an IQ game-like Wizard of Oz experiment to collect spontaneous and implicitly produced gestures in an ecological context where the robot is the referee. These gestures are compared with explicitly produced gestures to determine a relevant ontology of gestures. This preliminary qualitative analysis will be the base to build a big data corpus in order to optimize acceptance of the gesture dictionary in coherence with the “socio-affective glue” dynamics.","","Electronic:978-1-4673-8029-4; POD:978-1-4673-8030-0; USB:978-1-4673-8028-7","10.1109/ARSO.2015.7428207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7428207","Human-Robot Interaction;Wizard of Oz experiment;gesture recognition;machine learning;¿¿¿socio-affective glue¿¿¿","Cameras;Electronic mail;Gesture recognition;Service robots;Smart homes;Training","Big Data;gesture recognition;home automation;human-robot interaction;intelligent robots;ontologies (artificial intelligence);robot vision;service robots","Emox robot;GEE corpus based approach;HRI;IQ game-like Wizard of Oz experiment;big data corpus;ecological context;ecological dynamic experiment;gesture dictionary;gesture ontology;gesture recognition system;human-robot interaction project;qualitative analysis;smart home butler robot;socio-affective glue dynamics","","","","22","","","June 30 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Urban Air Pollution Monitoring System With Forecasting Models","K. Bashir Shaban; A. Kadri; E. Rezk","Qatar University, Doha, Qatar","IEEE Sensors Journal","20160225","2016","16","8","2598","2606","A system for monitoring and forecasting urban air pollution is presented in this paper. The system uses low-cost air-quality monitoring motes that are equipped with an array of gaseous and meteorological sensors. These motes wirelessly communicate to an intelligent sensing platform that consists of several modules. The modules are responsible for receiving and storing the data, preprocessing and converting the data into useful information, forecasting the pollutants based on historical information, and finally presenting the acquired information through different channels, such as mobile application, Web portal, and short message service. The focus of this paper is on the monitoring system and its forecasting module. Three machine learning (ML) algorithms are investigated to build accurate forecasting models for one-step and multi-step ahead of concentrations of ground-level ozone (O<sub>3</sub>), nitrogen dioxide (NO<sub>2</sub>), and sulfur dioxide (SO<sub>2</sub>). These ML algorithms are support vector machines, M5P model trees, and artificial neural networks (ANN). Two types of modeling are pursued: 1) univariate and 2) multivariate. The performance evaluation measures used are prediction trend accuracy and root mean square error (RMSE). The results show that using different features in multivariate modeling with M5P algorithm yields the best forecasting performances. For example, using M5P, RMSE is at its lowest, reaching 31.4, when hydrogen sulfide (H<sub>2</sub>S) is used to predict SO<sub>2</sub>. Contrarily, the worst performance, i.e., RMSE of 62.4, for SO<sub>2</sub> is when using ANN in univariate modeling. The outcome of this paper can be significantly useful for alarming applications in areas with high air pollution levels.","1530-437X;1530437X","","10.1109/JSEN.2016.2514378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7370876","Air quality monitoring;forecasting;machine learning algorithms;wireless sensors network","Air pollution;Atmospheric modeling;Data models;Forecasting;Market research;Monitoring;Predictive models","air pollution measurement;air quality;environmental monitoring (geophysics);environmental science computing;gas sensors;geophysics computing;meteorological instruments;neural nets;support vector machines;wireless sensor networks","M5P model trees;NO<sub>2</sub>;O<sub>3</sub>;SO<sub>2</sub>;Web portal;air pollution forecasting models;artificial neural networks;gaseous sensor;ground level ozone concentration;historical information;intelligent sensing platform;low cost air quality monitoring motes;machine learning algorithms;meteorological sensor;mobile application;multivariate forecasting model;nitrogen dioxide concentration;short message service;sulfur dioxide concentration;support vector machines;univariate forecasting model;urban air pollution monitoring system","","3","","34","","20160104","April15, 2016","","IEEE","IEEE Journals & Magazines"
"Evolving decision trees to detect anomalies in recurrent ICS networks","J. Hosic; J. Lamps; D. H. Hart","Sandia National Laboratories, Albuquerque, New Mexico 87123, United States","2015 World Congress on Industrial Control Systems Security (WCICSS)","20160229","2015","","","50","57","Researchers have previously attempted to apply machine learning techniques to network anomaly detection problems. Due to the staggering amount of variety that can occur in normal networks, as well as the difficulty in capturing realistic data sets for supervised learning or testing, the results have often been underwhelming. These challenges are far less pronounced when considering industrial control system (ICS) networks. The recurrent nature of these networks results in less noise and more consistent patterns for a machine learning algorithm to recognize. We propose a method of evolving decision trees through genetic programming (GP) in order to detect network anomalies, such as device outages. Our approach extracts over a dozen features from network packet captures and netflows, normalizes them, and relates them in decision trees using fuzzy logic operators. We used the trees to detect three specific network events from three different points on the network across a statistically significant number of runs and achieved 100% accuracy on five of the nine experiments. When the trees attempted to detect more challenging events at points of presence further from the occurrence, the accuracy averaged to above 98%. On cases where the trees were many hops away and not enough information was available, the accuracy dipped to roughly 50%, or that of a random search. Using our method, all of the evolutionary cycles of the GP algorithm are computed a-priori, allowing the best resultant trees to be deployed as semi-real-time sensors with little overhead. In order for the trees to perform optimally, buffered packets and flows need to be ingested at twenty minute intervals.","","Electronic:978-1-9083-2058-2; POD:978-1-4673-8339-4; USB:978-1-9083-2057-5","10.1109/WCICSS.2015.7420323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420323","Anomaly Detection;ICS Networks;Machine Learning","Decision trees;Feature extraction;Industrial control;Machine learning algorithms;Security;Sensors;Testing","decision trees;feature extraction;fuzzy logic;genetic algorithms;industrial control;learning (artificial intelligence);security of data;statistical analysis","GP algorithm;ICS network;decision tree;evolutionary cycle;feature extraction;fuzzy logic operator;genetic programming;industrial control system network;machine learning technique;network across;network anomaly detection;network anomaly detection problem;network packet;recurrent ICS network;semi-real-time sensor;statistically significant number;supervised learning","","","","18","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Online Adaptable Learning Rates for the Game Connect-4","S. Bagheri; M. Thill; P. Koch; W. Konen","Faculty of Engineering and Computer Science, Cologne University of Applied Sciences, Cologne, Germany","IEEE Transactions on Computational Intelligence and AI in Games","20160315","2016","8","1","33","42","Learning board games by self-play has a long tradition in computational intelligence for games. Based on Tesauro's seminal success with TD-Gammon in 1994, many successful agents use temporal difference learning today. But in order to be successful with temporal difference learning on game tasks, often a careful selection of features and a large number of training games is necessary. Even for board games of moderate complexity like Connect-4, we found in previous work that a very rich initial feature set and several millions of game plays are required. In this work we investigate different approaches of online-adaptable learning rates like Incremental Delta Bar Delta (IDBD) or temporal coherence learning (TCL) whether they have the potential to speed up learning for such a complex task. We propose a new variant of TCL with geometric step size changes. We compare those algorithms with several other state-of-the-art learning rate adaptation algorithms and perform a case study on the sensitivity with respect to their meta parameters. We show that in this set of learning algorithms those with geometric step size changes outperform those other algorithms with constant step size changes. Algorithms with nonlinear output functions are slightly better than linear ones. Algorithms with geometric step size changes learn faster by a factor of 4 as compared to previously published results on the task Connect-4.","1943-068X;1943068X","","10.1109/TCIAIG.2014.2367105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945857","Board games;learning rates;machine learning;n-tuple systems;online adaptation;reinforcement learning;self-adaptation;self-play;temporal coherence;temporal difference learning (TDL)","Coherence;Complexity theory;Games;Indexes;Machine learning algorithms;Training;Vectors","computational complexity;computer games;learning (artificial intelligence)","Connect-4;IDBD;board games;computational intelligence;incremental delta bar delta;machine learning;online adaptable learning rates;temporal difference learning","","2","","34","","20141104","March 2016","","IEEE","IEEE Journals & Magazines"
