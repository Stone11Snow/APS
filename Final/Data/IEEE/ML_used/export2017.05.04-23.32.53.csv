"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7002120,7004474,7002949,7004419,7000278,7000371,6998241,6997492,6996133,6919341,6993127,6993990,6993439,6993354,6987044,6986617,6987029,6984345,6982703,6985424,6984454,6985047,6982888,6984804,6984888,6981062,6979541,6976724,6977645,6975465,6977257,6977563,6977288,6969418,6969572,6974093,6974321,6970672,6972886,6974024,6973907,6968553,6967592,6969008,6968612,6968571,6913270,6968552,6968669,6962064,6805162,6961829,6958863,6958903,6957856,6960635,6952766,6949363,6949050,6948866,6946144,6942859,6944856,6944608,6943592,6943834,6945099,6947634,6947999,6851844,6899419,6899418,6936498,6936100,6935253,6934816,6934483,6933015,6927659,6927124,6927158,6927552,6930622,6927633,6927290,6923301,6921958,6922250,6922081,6921494,6921718,6920481,6920485,6920477,6917738,6918213,6917602,6918224,6918964,6646319",2017/05/04 23:32:53
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Hajj human event classification system using machine learning techniques","H. M. Zawbaa; E. Emary; A. E. Hassanien; M. F. Tolba","Faculty of Computers and Information, BeniSuef University, Egypt","13th International Conference on Hybrid Intelligent Systems (HIS 2013)","20141013","2013","","","191","196","In this paper, we proposed the new system for Hajj event classification in diverse and realistic Hajj videos and image scenes is investigated based on machine learning techniques. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. The main contribution of this work is to address the limitation and investigate the use of video for automatic annotation of human event classification. The proposed system consist of three main phases. Firstly, preprocessing phase which apply shot boundary detection algorithm for Hajj videos. After that feature extraction phase applying sparse coding based on Scale Invariant Feature Transform (SIFT) features. Finally, the event classification phase by applying several machine learning techniques including the K-Nearest Neighbor (KNN), Support Vector Machine (SVM), and Random Forests (RF) classifiers. Experiments with real data sets revealed the significant performance advantage of the machine learning techniques over the scale invariant feature transform (SIFT) features selection method. Receiver operating characteristics (ROC) analysis is used to compare classifier performance.","","Electronic:978-1-4799-2439-4; POD:978-1-4799-2440-0","10.1109/HIS.2013.6920481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6920481","","Filtering;Legged locomotion;Radio frequency;Support vector machines","feature extraction;humanities;image classification;image coding;learning (artificial intelligence);support vector machines;transforms;video signal processing","Hajj human event classification system;Hajj image scenes;Hajj videos;K-nearest neighbor;KNN;RF classifiers;ROC analysis;SIFT features;SVM;automatic human event classification annotation;event classification phase;feature extraction phase;machine learning techniques;preprocessing phase;random forests classifiers;receiver operating characteristics analysis;scale invariant feature transform features;shot boundary detection algorithm;sparse coding;support vector machine","","0","","26","","","4-6 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic Tagging Web Services Using Machine Learning Techniques","M. Lin; D. W. Cheung","Dept. of Comput. Sci., Univ. of Hong Kong, Hong Kong, China","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","2","","258","265","Web services have become popular and increasingly important in e-business and e-commerce applications especially in large scale distributed systems. As a result, increasing number of web services has been developed. However, this abundance creates a vast collection of web services which makes the task of locating a suitable one more challenging and more difficult. Automatic clustering of web services groups together web services with similar functions. Clustering could greatly boost the power of web service search engines and generate tags to improve the search accuracy of tag-based service recommendation. In this paper, we propose a web service clustering technique based on Carrot search clustering and K-means to group similar services together to generate tags and we use naive bayes algorithm to classify web services. We also develop a tag-based service recommendation for WSDL documents. We demonstrate that the proposed clustering approach is effective for web service discovery.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927633","Clustering;Web Service","Clustering algorithms;Feature extraction;Search engines;Tagging;Vectors;Web services;XML","Bayes methods;Web services;document handling;learning (artificial intelligence);pattern classification;pattern clustering;recommender systems","Carrot search clustering;K-means clustering;WSDL documents;Web service classification;Web service clustering technique;Web service discovery;automatic Web service tagging;machine learning techniques;naive Bayes algorithm;similar services group;tag-based service recommendation","","0","","19","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Features in Identification Approaches for MicroRNA Precursors Based on Machine Learning","Z. Hongjun; P. Haiqing; W. Xiuqin; L. Yongqiang","Coll. of Inf. Sci. & Eng., Yanshan Univ., Qinhuangdao, China","2014 Fifth International Conference on Intelligent Systems Design and Engineering Applications","20141206","2014","","","483","488","MicroRNAs (miRNAs) are a group of non-coding small RNA of ~ 22 nucleotides in length. They play important roles in gene regulation in animals and plants. The machine learning approach has become an important way to discover miRNAs, which is complement to experimental approaches. Feature selection is the key step of machine learning approaches to discover miRNA precursors. The performance and generalization ability of classifier is affected by the feature set. Features of miRNA precursors used in machine learning approaches were summarized in this review. According to the properties of features to distinguish the miRNA precursors and the non-miRNA precursors, features were categorized into three classes: sequence features, structure features, structure sequence features.","","CD-ROM:978-1-4799-4262-6; Electronic:978-1-4799-4261-9; POD:978-1-4799-7889-2","10.1109/ISDEA.2014.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977645","features;machine learning approaches;miRNA precursor;microRNA","Bioinformatics;Feature extraction;Genomics;Periodic structures;RNA;Sequential analysis;Support vector machines","RNA;feature selection;generalisation (artificial intelligence);genetics;learning (artificial intelligence)","MicroRNA precursors;animals;feature selection;feature set;gene regulation;generalization ability;identification approach;machine learning approach;noncoding small RNA;nucleotides;plants;structure-sequence features","","0","","38","","","15-16 June 2014","","IEEE","IEEE Conference Publications"
"Machine Learning in Wireless Sensor Networks: Algorithms, Strategies, and Applications","M. A. Alsheikh; S. Lin; D. Niyato; H. P. Tan","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","IEEE Communications Surveys & Tutorials","20141120","2014","16","4","1996","2018","Wireless sensor networks (WSNs) monitor dynamic environments that change rapidly over time. This dynamic behavior is either caused by external factors or initiated by the system designers themselves. To adapt to such conditions, sensor networks often adopt machine learning techniques to eliminate the need for unnecessary redesign. Machine learning also inspires many practical solutions that maximize resource utilization and prolong the lifespan of the network. In this paper, we present an extensive literature review over the period 2002-2013 of machine learning methods that were used to address common issues in WSNs. The advantages and disadvantages of each proposed algorithm are evaluated against the corresponding problem. We also provide a comparative guide to aid WSN designers in developing suitable machine learning solutions for their specific application challenges.","1553-877X;1553877X","","10.1109/COMST.2014.2320099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6805162","Wireless sensor networks;clustering;compressive sensing;data aggregation;data integrity;data mining;event detection;fault detection;localization;machine learning;medium access control;query processing;security","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Machine learning algorithms;Principal component analysis;Routing;Wireless sensor networks","learning (artificial intelligence);wireless sensor networks","AD 2002-13;machine learning;network lifespan;resource utilization;wireless sensor networks","","39","","152","","20140424","Fourthquarter 2014","","IEEE","IEEE Journals & Magazines"
"Automatic Nile Tilapia fish classification approach using machine learning techniques","M. M. M. Fouad; H. M. Zawbaa; N. El-Bendary; A. E. Hassanien","Arab Academy for Science, Technology, and Maritime Transport, Cairo, Egypt","13th International Conference on Hybrid Intelligent Systems (HIS 2013)","20141013","2013","","","173","178","Commonly, aquatic experts use traditional methods such as casting nets or underwater human monitoring for detecting existence and quantities of different species of fish. However, the recent breakthrough in digital cameras and storage abilities, with consequent cost reduction, can be utilized for automatically observing different underwater species. This article introduces an automatic classification approach for the Nile Tilapia fish using support vector machines (SVMs) algorithm in conjunction with feature extraction techniques based on Scale Invariant Feature Transform (SIFT) and Speeded Up Robust Features (SURF) algorithms. The core of this approach is to apply the feature extraction algorithms in order to describe local features extracted from a set of fish images. Then, the proposed approach classifies the fish images using a number of support vector machines classifiers to differentiate between fish species. Experimental results obtained show that the support vector machines algorithm outperformed other machine learning techniques, such as artificial neural networks (ANN) and k-nearest neighbor (k-NN) algorithms, in terms of the overall classification accuracy.","","Electronic:978-1-4799-2439-4; POD:978-1-4799-2440-0","10.1109/HIS.2013.6920477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6920477","Feature Description;Feature Extraction;Fish classification;Fish recognition;Image processing","Accuracy;Artificial neural networks;Biology;Biomedical monitoring;Monitoring;Robustness;Support vector machines","aquaculture;feature extraction;image classification;learning (artificial intelligence);support vector machines;transforms","SIFT;SURF algorithms;SVM algorithm;aquatic experts;automatic Nile Tilapia fish classification approach;casting nets;digital cameras;feature extraction;fish images;machine learning;scale invariant feature transform;speeded up robust features algorithms;support vector machines;traditional methods;underwater human monitoring","","1","","27","","","4-6 Dec. 2013","","IEEE","IEEE Conference Publications"
"War against mobile malware with cloud computing and machine learning forces","F. Idrees; R. Muttukrishnan","City Univ. London, London, UK","2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)","20141201","2014","","","278","280","Today's smart phones are used for wider range of activities. This extended range of functionalities has also seen the infiltration of new security threats. The malicious parties are using highly stealthy techniques to perform the targeted operations, which are hard to detect by the conventional signature and behavior based approaches. Besides, the limited resources of mobile device are inadequate to perform the computationally extensive malware detection tasks and to sustain the device's clean status. In this paper, we propose an effective and resource rich detection system which uses certain distinguishing combinations of permissions and intents used by the apps to identify the malware apps. Different machine learning algorithms are investigated for classification of apps into benign or malware types. To the best of our knowledge, this is the first ever work in which both the permissions and intents have been amalgamated for malware detection using cloud computing paradigm. Effectiveness of our approach is verified by testing the real-world malware and benign apps collected from various sources.","","Electronic:978-1-4799-2730-2; POD:978-1-4799-2732-6; USB:978-1-4799-2727-2","10.1109/CloudNet.2014.6969008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969008","Permission model;classification;cloud computing;intent model","Classification algorithms;Machine learning algorithms;Malware;Mobile communication;Smart phones","cloud computing;invasive software;learning (artificial intelligence);mobile computing;smart phones","cloud computing;machine learning;malware detection task;mobile malware;security threat;smart phones","","0","","7","","","8-10 Oct. 2014","","IEEE","IEEE Conference Publications"
"Detection of epileptic convulsions from accelerometry signals through machine learning approach","M. Milošević; A. Van de Vel; B. Bonroy; B. Ceulemans; L. Lagae; B. Vanrumste; S. Van Huffel","Department of Electrical Engineering (ESAT), STADIUS, KU Leuven, Belgium","2014 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)","20141120","2014","","","1","6","A seizure detection system in the non-clinical environment would enable long-term monitoring and give better insights into the number of seizures and their characteristics. Moreover, an alarm at seizure onset is important for alerting the parents or care-givers so they could comfort the child and optionally give the treatment. Therefore, we developed a patient-independent automatic algorithm for registration and detection of (tonic-)clonic seizures based on four accelerometers attached to the wrists and ankles. The objective is to classify two second epochs as seizure or non-seizure epochs employing supervised learning techniques. Starting from 140 features found in similar publications, a filter method based on mutual information is applied to remove irrelevant and redundant features. A least-squares support vector machine classifier is used to distinguish seizure and non-seizure epochs based on the selected features. For seizures longer than 30 seconds, median sensitivity of 100%, false detection rate of 0.39 h<sup>-1</sup> and alarm delay of 15.2 s over all patients are reached.","1551-2541;15512541","Electronic:978-1-4799-3694-6; POD:978-1-4799-3695-3","10.1109/MLSP.2014.6958863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6958863","Seizure detection;accelerometers;children;home monitoring","Electroencephalography;Monitoring;Pediatrics;Support vector machines;Testing;Vectors;Wrist","learning (artificial intelligence);medical signal processing;signal detection;support vector machines","accelerometry signals;epileptic convulsion detection;least-squares support vector machine classifier;machine learning approach;nonclinical environment;nonseizure epochs;patient-independent automatic algorithm;seizure detection system;supervised learning techniques;tonic-clonic seizure detection;tonic-clonic seizure registration","","2","","14","","","21-24 Sept. 2014","","IEEE","IEEE Conference Publications"
"Applying Machine Learning to Reduce Overhead in DTN Vehicular Networks","L. P. Portugal-Poma; C. A. C. Marcondes; H. Senger; L. Arantes","Dept. de Comput., Univ. Fed. de Sao Carlos, Sao Carlos, Brazil","2014 Brazilian Symposium on Computer Networks and Distributed Systems","20141020","2014","","","94","102","VANETs benefit from Delay Tolerant Networks (DTNs) routing algorithms when connectivity is intermittent because of the fast movement of vehicles. Multi-copy DTN algorithms spread message copies to increase the delivery probability but increasing network overhead. In this work we apply machine learning algorithms to reduce network overhead by discriminating the worst intermediate nodes for the transmission of copies. The scenario is a VANET of public buses that follow specific routes and schedules. This repetitive behavior creates an opportunity for applying trained classifiers to predict the occurrence of performance-related events. As the main contribution, our method decreases overhead without degrading delivery probability.","","Electronic:978-1-4799-5612-8; POD:978-1-4799-5613-5","10.1109/SBRC.2014.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927124","DTN;VANET;machine learning;routing","Data collection;Decision trees;Delays;Machine learning algorithms;Routing;Training;Vehicles","delay tolerant networks;learning (artificial intelligence);vehicular ad hoc networks","DTN routing algorithms;DTN vehicular networks;VANET;connectivity;delay tolerant networks;delivery probability;machine learning algorithms;multicopy DTN algorithms;network overhead;performance-related events;public buses;repetitive behavior","","0","","20","","","5-9 May 2014","","IEEE","IEEE Conference Publications"
"Area wise high resolution water availability estimation using heterogeneous remote sensing and ensemble machine learning","C. Li; R. Dutta; D. Smith","CSIRO Digital Productivity and Services Flagship CSIRO Hobart, Tasmania 7001, Australia","IEEE SENSORS 2014 Proceedings","20141215","2014","","","1992","1995","In this paper a novel remote sensing data integration framework has been developed using ensemble machine learning to estimate large area wise ground water balance. Heterogeneous spatio-temporal database including `Australian Water Availability Project (AWAP) database', `Australian Digital Elevation data (ADED)', and `NASA MODIS Vegetation Index (VI) data' were processed and integrated. An irrigated farming area (covering 20km × 20km) in Tasmania described by S 42°36 Latitude and E 147°29 Longitude, where weekly data from the period Jan 2007 - Dec 2013 (total 320 weeks) were studied. An ensemble machine learning framework combining Sugano type Adaptive Neuro Fuzzy Inference System (ANFIS), Elman (ENN), Cascade Feed Forward (CFFNN), and Function fitting neural networks (FFNN) were trained with combined training inputs of VI and ADED demographic data against the AWAP based water balance estimations as training targets. Based on the spatial distribution of the training performance, different trained estimators were selected to estimate water balance at various spatial locations purely based on VI and ADED inputs, where no AWAP data were available. A high-resolution (250m) water availability map was created for the whole area on a weekly temporal scale, which could potentially provide accurate irrigation management support over a very large area.","1930-0395;19300395","Electronic:978-1-4799-0162-3; POD:978-1-4799-0160-9; USB:978-1-4799-0161-6","10.1109/ICSENS.2014.6985424","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6985424","","Australia;Availability;Estimation;MODIS;Mathematical model;Sensors;Spatial resolution","digital elevation models;fuzzy reasoning;geophysics computing;groundwater;irrigation;learning (artificial intelligence);neural nets;radiometry;remote sensing;vegetation;water resources","AD 2007 01 to 2013 12;ADED;ADED demographic data training input;ANFIS;AWAP based water balance estimation;AWAP database;Australian Water Availability Project database;Australian digital elevation data;CFFNN;ENN;Elman;FFNN;NASA MODIS vegetation index data;Sugano type adaptive neuro fuzzy;Tasmania;VI demographic data training input;accurate irrigation management;area wise high resolution water availability estimation;cascade feed forward;ensemble machine learning;ensemble machine learning framework;function fitting neural network;heterogeneous remote sensing;heterogeneous spatio-temporal database;high-resolution water availability map;irrigated farming area;large area wise ground water balance;remote sensing data integration framework;training performance spatial distribution;weekly temporal scale","","0","","30","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"An automatic flower classification approach using machine learning algorithms","H. M. Zawbaa; M. Abbass; S. H. Basha; M. Hazman; A. E. Hassenian","Faculty of Mathematics and Computer Science, Babes-Bolyai University, Romania","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","895","901","This work aims to develop an effective flower classification approach using machine learning algorithms. Eight flower categories were analyzed in order to extract their features. Scale Invariant Feature Transform (SIFT) and Segmentation-based Fractal Texture Analysis (SFTA) algorithms are used to extract flower features. The proposed approach consists of three phases namely: segmentation, feature extraction, and classification phases. In segmentation phase, the flower region is segmented to remove the complex background from the images dataset. Then flower image features are extracted. Finally for classification phase, the proposed approach applied Support Vector Machine (SVM) and Random Forests (RF) algorithms to classify different kinds of flowers. An experiment was carried out using the proposed approach on a dataset of 215 flower images. It shows that Support Vector Machine (SVM) based algorithm provides better accuracy compared to the Random Forests (RF) algorithm when using the SIFT as a feature extraction algorithm. While, Random Forests (RF) algorithm provides its better accuracy with SFTA. Moreover, the system is capable of automatically recognize the flower name with a high degree of accuracy.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968612","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968612","Features Extraction;Flower Classification;Image Classification;Image Segmentation;Random Forest (RF);Scale Invariant Feature Transform (SIFT);Segmentation-based Fractal Texture Analysis (SFTA);Support Vector Machine (SVM)","Image recognition;Image segmentation;Learning systems","biology computing;botany;feature extraction;image classification;image segmentation;image texture;learning (artificial intelligence);support vector machines","RF;SFTA algorithm;SIFT algorithm;SVM;automatic flower classification approach;classification phase;feature extraction;feature extraction phase;flower categories;machine learning algorithms;random forests;scale invariant feature transform;segmentation phase;segmentation-based fractal texture analysis;support vector machine","","1","","22","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"COD and NH<inf>4</inf>-N estimation in the inflow of Wastewater Treatment Plants using Machine Learning Techniques","P. Kern; C. Wolf; D. Gaida; M. Bongards; S. McLoone","Department of Electronic Engineering at the National University of Ireland Maynooth, Co. Kildare, IRELAND","2014 IEEE International Conference on Automation Science and Engineering (CASE)","20141030","2014","","","812","817","The in-line measurement of COD and NH<sub>4</sub>-N in the WWTP inflow is crucial for the timely monitoring of biological wastewater treatment processes and for the development of advanced control strategies for optimized WWTP operation. As a direct measurement of COD and NH<sub>4</sub>-N requires expensive and high maintenance in-line probes or analyzers, an approach estimating COD and NH<sub>4</sub>-N based on standard and spectroscopic in-line inflow measurement systems using Machine Learning Techniques is presented in this paper. The results show that COD estimation using Radom Forest Regression with a normalized MSE of 0.3, which is sufficiently accurate for practical applications, can be achieved using only standard in-line measurements. In the case of NH<sub>4</sub>-N, a good estimation using Partial Least Squares Regression with a normalized MSE of 0.16 is only possible based on a combination of standard and spectroscopic in-line measurements. Furthermore, the comparison of regression and classification methods shows that both methods perform equally well in most cases.","2161-8070;21618070","Electronic:978-1-4799-5283-0; POD:978-1-4799-5284-7","10.1109/CoASE.2014.6899419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899419","","Estimation;Kernel;Probes;Standards;Support vector machines;Temperature measurement;Wastewater","learning (artificial intelligence);least mean squares methods;regression analysis;wastewater treatment","COD;WWTP inflow;biological wastewater treatment processes;chemical oxygen demand;in-line probe maintenance;machine learning techniques;normalized MSE;partial least squares regression;radom forest regression;spectroscopic in-line inflow measurement systems;wastewater treatment plants","","0","","21","","","18-22 Aug. 2014","","IEEE","IEEE Conference Publications"
"Robust extreme learning machine for regression problems with its application to wifi based indoor positioning system","Xiaoxuan Lu; Yushen Long; H. Zou; Chengpu Yu; Lihua Xie","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","2014 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)","20141120","2014","","","1","6","We propose two kinds of robust extreme learning machines (RELMs) based on the close-to-mean constraint and the small-residual constraint respectively to solve the problem of noisy measurements in indoor positioning systems (IPSs). We formulate both RELMs as second order cone programming problems. The fact that feature mapping in ELM is known to users is exploited to give the needed information for robust constraints. Real-world indoor localization experimental results show that, the proposed algorithms can not only improve the accuracy and repeatability, but also reduce the deviations and worst case errors of IPSs compared with basic ELM and OPT-ELM based IPSs.","1551-2541;15512541","Electronic:978-1-4799-3694-6; POD:978-1-4799-3695-3","10.1109/MLSP.2014.6958903","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6958903","Indoor positioning system;Robust extreme learning machine;Second order cone programming","Calibration;IEEE 802.11 Standards;Robustness;Support vector machines;Testing;Training;Vectors","indoor radio;learning (artificial intelligence);regression analysis;wireless LAN","IPS;RELM;WiFi;close-to-mean constraint;feature mapping;indoor positioning system;regression problems;robust extreme learning machines;second order cone programming problems;small-residual constraint","","0","","13","","","21-24 Sept. 2014","","IEEE","IEEE Conference Publications"
"SpikeGUI: Software for rapid interictal discharge annotation via template matching and online machine learning","J. Jin; J. Dauwels; S. Cash; M. B. Westover","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","4435","4438","Detection of interictal discharges is a key element of interpreting EEGs during the diagnosis and management of epilepsy. Because interpretation of clinical EEG data is time-intensive and reliant on experts who are in short supply, there is a great need for automated spike detectors. However, attempts to develop general-purpose spike detectors have so far been severely limited by a lack of expert-annotated data. Huge databases of interictal discharges are therefore in great demand for the development of general-purpose detectors. Detailed manual annotation of interictal discharges is time consuming, which severely limits the willingness of experts to participate. To address such problems, a graphical user interface “SpikeGUI” was developed in our work for the purposes of EEG viewing and rapid interictal discharge annotation. “SpikeGUI” substantially speeds up the task of annotating interictal discharges using a custom-built algorithm based on a combination of template matching and online machine learning techniques. While the algorithm is currently tailored to annotation of interictal epileptiform discharges, it can easily be generalized to other waveforms and signal types.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6944608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6944608","","Discharges (electric);Educational institutions;Electroencephalography;Euclidean distance;Graphical user interfaces;Manuals;Navigation","electroencephalography;graphical user interfaces;learning (artificial intelligence);medical signal detection;pattern matching","SpikeGUI;clinical EEG data;electroencephalography;epilepsy diagnosis;epilepsy management;graphical user interface;interictal discharge detection;interictal epileptiform discharge;online machine learning;rapid interictal discharge annotation;spike detectors;template matching","","3","","24","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"A hyper-box approach using relational databases for large scale machine learning","S. E. Papadakis; V. A. Stykas; G. Mastorakis; C. X. Mavromoustakis","Technological Educational Institute of Crete, Department of Business Administration, Ag. Nikolaos, Greece","2014 International Conference on Telecommunications and Multimedia (TEMU)","20141009","2014","","","69","73","In this paper We follow a simple approach which allows the implementation of machine learning (ML for short) techniques to large data sets. More specifically, we study the case of on-demand dynamic creation of a local model in the neighborhood of a target datum instead of creating a global one on the whole training data set. This approach exploits the advanced data structures and algorithms, embedded in modern relational databases, to identify the neighborhood of a target datum, rapidly. Preliminary experimental results from a large scale classification problem (HIGGS dataset) show that the typical machine learning techniques are applicable to large data sets through this approach, under particular conditions. We highlight some restrictions of the method and some issues arising by implementing it.","","Electronic:978-1-4799-3200-9; POD:978-1-4799-3201-6; USB:978-1-4799-3199-6","10.1109/TEMU.2014.6917738","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6917738","Big Data;Higgs;Hyper-box;Machine Learning;Support Vector Machines","Complexity theory;Computational modeling;Relational databases;Support vector machines;Testing;Training","learning (artificial intelligence);pattern classification;relational databases","HIGGS dataset;global ML model;hyper-box approach;large scale classification problem;large scale machine learning;local ML model;relational database","","1","","25","","","28-30 July 2014","","IEEE","IEEE Conference Publications"
"Using metabolomic and transportomic modeling and machine learning to identify putative novel therapeutic targets for antibiotic resistant Pseudomonad infections","P. E. Larsen; F. R. Collart; Y. Dai","Biosciences Division, Argonne National Laboratory, Argonne IL 60439","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","314","317","Hospital acquired infections sicken or kill tens of thousands of patients every year. These infections are difficult to treat due to a growing prevalence of resistance to many antibiotics. Among these hospital acquired infections, bacteria of the genus Pseudomonas are among the most common opportunistic pathogens. Computational methods for predicting potential novel antimicrobial therapies for hospital acquired Pseudomonad infections, as well as other hospital acquired infectious pathogens, are desperately needed. Using data generated from sequenced Pseudomonad genomes and metabolomic and transportomic computational approaches developed in our laboratory, we present a support vector machine learning method for identifying the most predictive molecular mechanisms that distinguish pathogenic from non-pathogenic Pseudomonads. Predictions were highly accurate, yielding F-scores between 0.84 and 0.98 in leave one out cross validations. These mechanisms are high-value targets for the development of new antimicrobial therapies.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6943592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6943592","","Biochemistry;Bioinformatics;Genomics;Metabolomics;Microorganisms;Predictive models;Support vector machines","antibacterial activity;biomedical engineering;diseases;genomics;learning (artificial intelligence);microorganisms;patient treatment;support vector machines","Pseudomonad genomes;Pseudomonas;antibiotic resistant Pseudomonad infection;antimicrobial therapy;bacteria;computational method;hospital acquired Pseudomonad infection;hospital acquired infectious pathogen;metabolomic modeling;molecular mechanism;opportunistic pathogen;support vector machine learning method;therapeutic target;transportomic modeling","","0","","17","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Portfolio-Based Selection of Robust Dynamic Loop Scheduling Algorithms Using Machine Learning","N. Sukhija; B. Malone; S. Srivastava; I. Banicescu; F. M. Ciorba","Dept. of Comput. Sci. & Eng., Mississippi State Univ., Starkville, MS, USA","2014 IEEE International Parallel & Distributed Processing Symposium Workshops","20141204","2014","","","1638","1647","The execution of computationally intensive parallel applications in heterogeneous environments, where the quality and quantity of computing resources available to a single user continuously change, often leads to irregular behavior, in general due to variations of algorithmic and systemic nature. To improve the performance of scientific applications, loop scheduling algorithms are often employed for load balancing of their parallel loops. However, it is a challenge to select the most robust scheduling algorithms for guaranteeing optimized performance of scientific applications on large-scale computing systems that comprise resources which are widely distributed, highly heterogeneous, often shared among multiple users, and have computing availabilities that cannot always be guaranteed or predicted. To address this challenge, in this work we focus on a portfolio-based approach to enable the dynamic selection and use of the most robust dynamic loop scheduling (DLS) algorithm from a portfolio of DLS algorithms, depending on the given application and current system characteristics including workload conditions. Thus, in this paper we provide a solution to the algorithm selection problem and experimentally evaluate its quality. We propose the use of supervised machine learning techniques to build empirical robustness prediction models that are used to predict DLS algorithm's robustness for given scientific application characteristics and system availabilities. Using simulated scientific applications characteristics and system availabilities, along with empirical robustness prediction models, we show that the proposed portfolio-based approach enables the selection of the most robust DLS algorithm that satisfies a user-specified tolerance on the given application's performance obtained in the particular computing system with a certain variable availability. We also show that the portfolio-based approach offers higher guarantees regarding the robust performance of the app- ication using the automatically selected DLS algorithms when compared to the robust performance of the same application using a manually selected DLS algorithm.","","Electronic:978-1-4799-4116-2; POD:978-1-4799-4115-5","10.1109/IPDPSW.2014.183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969572","Dynamic loop scheduling;algorithm selection;empirical robustness prediction models;machine learning techniques;robustness;variable system availability","Availability;Dynamic scheduling;Heuristic algorithms;Prediction algorithms;Predictive models;Program processors;Robustness","learning (artificial intelligence);parallel processing;processor scheduling;resource allocation;scientific information systems","DLS algorithms;algorithm selection problem;computationally intensive parallel applications;computing availabilities;computing resources;dynamic selection;heterogeneous environments;large-scale computing systems;load balancing;optimized performance;parallel loops;portfolio-based approach;portfolio-based selection;robust dynamic loop scheduling algorithms;scientific application characteristics;supervised machine learning techniques;system availabilities;system characteristics;user-specified tolerance;workload conditions","","1","","31","","","19-23 May 2014","","IEEE","IEEE Conference Publications"
"An adaptive machine learning decision system for flexible predictive maintenance","G. A. Susto; J. Wan; S. Pampuri; M. Zanon; A. B. Johnston; P. G. O'Hara; S. McLoone","National University of Ireland, Maynooth, Ireland","2014 IEEE International Conference on Automation Science and Engineering (CASE)","20141030","2014","","","806","811","Process monitoring and Predictive Maintenance (PdM) are gaining increasing attention in most manufacturing environments as a means of reducing maintenance related costs and downtime. This is especially true in industries that are data intensive such as semiconductor manufacturing. In this paper an adaptive PdM based flexible maintenance scheduling decision support system, which pays particular attention to associated opportunity and risk costs, is presented. The proposed system, which employs Machine Learning and regularized regression methods, exploits new information as it becomes available from newly processed components to refine remaining useful life estimates and associated costs and risks. The system has been validated on a real industrial dataset related to an Ion Beam Etching process for semiconductor manufacturing.","2161-8070;21618070","Electronic:978-1-4799-5283-0; POD:978-1-4799-5284-7","10.1109/CoASE.2014.6899418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899418","Feature Extraction;Industrial Modeling;Optical Emission Spectroscopy;Predictive Maintenance;Regularization Methods;Semiconductor Manufacturing;Sparse Principal Component Analysis","Etching;Feature extraction;Ion beams;Manufacturing;Predictive maintenance;Principal component analysis","cost reduction;decision support systems;etching;flexible manufacturing systems;ion beam applications;learning (artificial intelligence);maintenance engineering;process monitoring;regression analysis;remaining life assessment;scheduling;semiconductor industry","adaptive PdM based flexible maintenance scheduling decision support system;adaptive machine learning decision system;data intensive industries;downtime reduction;flexible predictive maintenance;industrial dataset;ion beam etching process;maintenance cost reduction;manufacturing environments;opportunity costs;process monitoring;regularized regression methods;remaining useful life estimation;risk costs;semiconductor manufacturing","","0","","19","","","18-22 Aug. 2014","","IEEE","IEEE Conference Publications"
"A framework for Internet data real-time processing: A machine-learning approach","M. Di Mauro; C. Di Sarno","University of Salerno, Department of Engineering and Applied Maths, Salerno, Italy","2014 International Carnahan Conference on Security Technology (ICCST)","20141218","2014","","","1","6","Nowadays, the Internet Service Providers have to keep track of and in some cases to analyze for legal issues, a great amount of Internet data. Real-time big data processing and analysis introduce new challenges that must be addressed by system engineers. This is because: 1) traditional technologies exploiting databases are not designed to process a huge amount of data in real-time 2) classic machine learning algorithms implemented by widely adopted tools as Weka or R are not designed to perform “on the fly” analysis on streamed data. In this paper the authors propose an architecture that makes the real-time big data processing and analysis possible. The proposed architecture is based on two main components: a stream processing engine called Apache Storm and a framework called Yahoo SAMOA allowing to perform data analysis through distributed streaming machine learning algorithms. Our architecture is tested for Skype traffic recognition within network traffic generated by several Personal Computers in a streamed way. Experimental results have shown the effectiveness of proposed solution.","1071-6572;10716572","Electronic:978-1-4799-3532-1; POD:978-1-4799-3533-8; USB:978-1-4799-3531-4","10.1109/CCST.2014.6987044","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987044","Big Data;Distributed Machine Learning;SAMOA;Storm","Computer architecture;Databases;Engines;Machine learning algorithms;Real-time systems;Storms;Training","Big Data;Internet;data analysis;learning (artificial intelligence);microcomputers","Apache Storm;Internet data real-time processing;Internet service providers;R tools;Skype traffic recognition;Weka tools;Yahoo SAMOA;distributed streaming machine learning algorithms;legal issues;machine learning algorithms;machine learning approach;network traffic;on the fly analysis;personal computers;real-time big data analysis;real-time big data processing","","4","","30","","","13-16 Oct. 2014","","IEEE","IEEE Conference Publications"
"Practical concerns of implementing machine learning algorithms for W-LAN location fingerprinting","J. Schäfer","Frankfurt University of Applied Sciences, Faculty of Computer Science and Engineering, Nibelungenplatz 1, D-60318 Frankfurt am Main","2014 6th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)","20150108","2014","","","310","317","In the past, fingerprinting algorithms have been suggested as a practical and cost-effective means for deploying localisation services. Previous research, however, often assumes an (idealised) laboratory environment rather than a realistic set-up. In our work we analyse challenges occurring from a university environment which is characterised by hundreds of access points deployed and by heterogeneous mobile handsets of unknown technical specifications and quality. Our main emphasis lies on classification results for room detection. We analyse the problems caused by the huge number of access points available and by the heterogenous handsets. We show that standard techniques well-known in machine learning such as feature selection and dimensionality reduction do work. We also provide evidence that pre-processing techniques suggested previously in a laboratory set-up do not improve accuracy.","2157-0221;21570221","Electronic:978-1-4799-5291-5; POD:978-1-4799-5292-2; USB:978-1-4799-5290-8","10.1109/ICUMT.2014.7002120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7002120","","Context;Educational institutions;Machine learning algorithms;Principal component analysis;Support vector machines;Training;Vectors","feature selection;learning (artificial intelligence);mobile handsets;wireless LAN","W-LAN location fingerprinting algorithms;access point deployment;dimensionality reduction;feature selection;heterogeneous mobile handsets;localisation service deployment;machine learning algorithm implementation;preprocessing techniques;room detection;university environment;unknown quality;unknown technical specifications","","0","","18","","","6-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Machine learning plug-ins for GNU Radio Companion","R. Anil; R. Danymol; H. Gawande; R. Gandhiraj","Centre for Excellence in Computational Engineering and Networking, Amrita School of Engineering, Amrita VishwaVidyapeetham, Coimbatore - 641112, India","2014 International Conference on Green Computing Communication and Electrical Engineering (ICGCCEE)","20141016","2014","","","1","5","This paper gives an insight about how to create classifier plug-ins (signal processing blocks) using hard-code input for GNU Radio Companion (GRC). GNU Radio Companion is an open source Visual programming language for any real time signal processing applications. At present there is no classifier block available inside this GRC tool. Here we are introducing a low cost classifier which utilizes the basic machine learning algorithms:linear regression and logistic regression. The creation of classifier plug-ins in an open source software enables easy manipulation of real time classification problems during the transmission and reception of signals in Software Defined Radios. So this workdescribes the development of signal processing block that can be done by changing the Python code and C++ codes of the `gr-modtool' package. It is highly cost effective and with great potential since GNU Radio software is open source and free.","","Electronic:978-1-4799-4982-3; POD:978-1-4799-4981-6","10.1109/ICGCCEE.2014.6922250","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6922250","Gradient Descent method;Linear Regression;Logistic Regression;Machine Learning;Real Time Classification;Signal Processing Blocks","Linear regression;Logistics;Real-time systems;Signal processing;Signal processing algorithms;Software;Software radio","C++ language;learning (artificial intelligence);public domain software;regression analysis;signal classification;software radio;telecommunication computing;visual programming","C++ codes;GNU Radio Companion;GNU radio software;GRC tool;Python code;classifier plug-ins;grmodtool package;hard-code input;linear regression;logistic regression;machine learning plug-ins;open source software;open source visual programming language;real time signal processing applications;software defined radios","","0","","10","","","6-8 March 2014","","IEEE","IEEE Conference Publications"
"Parkinson's disease prediction using machine learning approaches","Gokul S.; Sivachitra M.; Vijayachitra S.","Department of EEE, Kongu Engineering College, Perundurai, India","2013 Fifth International Conference on Advanced Computing (ICoAC)","20141016","2013","","","246","252","This paper proposes the application of a Fully Complex-Valued Radial Basis Function network (FC-RBF), Meta-Cognitive Fully Complex-Valued Radial Basis Function network (Mc-FCRBF) and Extreme Learning Machine (ELM) for the prediction of Parkinson's disease. With the help of Unified Parkinson's Disease Rating Scale (UPDRS), the severity of the Parkinson's disease is predicted and for untreated patients, the UPDRS scale spans the range (0-176). The FC-RBF network uses a fully complex valued activation function sech, which maps c<sup>n</sup> → c. The performance of the complex RBF network depends on the number of neurons and initialization of network parameters. The implementation of the self-regulatory learning mechanism in the FC-RBF network results in Mc-FCRBF network. It has two components: a cognitive component and a meta-cognitive component. The meta-cognitive component decides how to learn, what to learn and when to learn based on the knowledge acquired by the FC-RBF network. Extreme learning mechanism uses sigmoid activation function and it works with fast speed. In ELM network, the real valued inputs and targets are applied to the network. The result indicates that the Mc-FCRBF network has good prediction accuracy than ELM and FC-RBF network.","2377-6927;23776927","CD-ROM:978-1-4799-3447-8; Electronic:978-1-4799-3448-5; POD:978-1-4799-3449-2","10.1109/ICoAC.2013.6921958","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921958","Extreme Learning Machine (ELM);Fully Complex-Valued Radial Basis Function Networks (FC-RBF);Meta-Cognitive Radial Basis Function Networks (Mc-FCRBF);Neural Networks;Parkinson's Disease (PD)","Biological neural networks;Biomedical measurement;Educational institutions;Learning systems;Neurons;Noise measurement;Vectors","cognitive systems;diseases;learning (artificial intelligence);medical computing;radial basis function networks","ELM network;FC-RBF network;Mc-FCRBF network;Parkinson's disease prediction;UPDRS;cognitive component;extreme learning machine;fully complex valued activation function;fully complex-valued radial basis function network;machine learning;meta-cognitive component;meta-cognitive fully complex-valued radial basis function network;network parameters;prediction accuracy;self-regulatory learning;sigmoid activation function;unified Parkinson's disease rating scale","","2","","35","","","18-20 Dec. 2013","","IEEE","IEEE Conference Publications"
"Application of statistical machine learning in identifying candidate biomarkers of resistant to anti-cancer drugs in ovarian cancer","S. Nabavi; M. Maitituoheti; M. Yamada; P. Tonellato","Center for Biomedical Informatics, Beth Israel Deaconess Medical Center Harvard Medical School Boston, MA, USA","2014 40th Annual Northeast Bioengineering Conference (NEBEC)","20141204","2014","","","1","2","Drug resistance is one of the major challenges in the treatment of ovarian cancer. To facilitate identification of candidate biomarkers of resistant to platinum-based chemotherapy in ovarian cancer, we employed statistical machine learning techniques and integrative genomic data analysis. We used gene expression, somatic mutation and copy number aberration data of platinum sensitive and resistant tumors from the cancer genome atlas. Using regression tree and module network analysis, we identified genes that both contain mutations (copy number aberration and/or point mutation) and their expressions influence groups of their co-regulated genes for resistant and sensitive tumors. Finally, we compared these two gene lists and their associated pathways to extract a short list of genes as potential biomarkers of resistant to platinum-based chemotherapy.","2160-6986;21606986","Electronic:978-1-4799-3728-8; POD:978-1-4799-3729-5","10.1109/NEBEC.2014.6972886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972886","copy number aberration;gene expression;integrative analysis;module network analysis;regression tree","Bioinformatics;Cancer;Gene expression;Genomics;Immune system;Regulators;Tumors","cancer;drugs;genomics;learning (artificial intelligence);patient treatment;regression analysis;trees (mathematics);tumours","anticancer drugs;cancer genome atlas;candidate biomarkers;copy number aberration data;drug resistance;gene expression;genomic data analysis;module network analysis;ovarian cancer;platinum sensitive tumors;platinum-based chemotherapy;regression tree;resistant tumors;somatic mutation;statistical machine learning technique","","0","","4","","","25-27 April 2014","","IEEE","IEEE Conference Publications"
"Robustness and prediction accuracy of Machine Learning for objective visual quality assessment","A. Hines; P. Kendrick; A. Barri; M. Narwaria; J. A. Redi","Trinity College Dublin, Ireland","2014 22nd European Signal Processing Conference (EUSIPCO)","20141113","2014","","","2130","2134","Machine Learning (ML) is a powerful tool to support the development of objective visual quality assessment metrics, serving as a substitute model for the perceptual mechanisms acting in visual quality appreciation. Nevertheless, the reliability of ML-based techniques within objective quality assessment metrics is often questioned. In this study, the robustness of ML in supporting objective quality assessment is investigated, specifically when the feature set adopted for prediction is suboptimal. A Principal Component Regression based algorithm and a Feed Forward Neural Network are compared when pooling the Structural Similarity Index (SSIM) features perturbed with noise. The neural network adapts better with noise and intrinsically favours features according to their salient content.","2219-5491;22195491","Electronic:978-0-9928-6261-9; POD:978-1-4799-4603-7; USB:978-0-9928-6262-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952766","SSIM;image quality assessment;machine learning;neural networks","Image quality;Noise;Noise level;Noise measurement;Quality assessment;Sensitivity","feedforward neural nets;image processing;learning (artificial intelligence);principal component analysis;regression analysis","ML-based techniques;SSIM features;feature set;feed forward neural network;objective visual quality assessment metrics;perceptual mechanisms;prediction accuracy;principal component regression based algorithm;salient content;structural similarity index features;substitute model;visual quality appreciation","","1","","23","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Machine learning-based techniques for incremental functional diagnosis: A comparative analysis","C. Bolchini; L. Cassano","Dip. Elettronica, Informazione e Bioingegneria - Politecnico di Milano, Italy","2014 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)","20141124","2014","","","246","251","Incremental functional diagnosis is the process of iteratively selecting a test, executing it and based on the collected outcome deciding either to execute one more test or to stop the process since a faulty candidate component can be identified. The aim is to minimise the cost and the duration of the diagnosis process. In this paper we compare six engines based on machine learning techniques for driving the diagnosis. The comparison has been carried out under a twofold point of view: on the one hand, we analysed the issues related to the use of the considered techniques for the design of incremental diagnosis engines; on the other hand, we carried out a set of experiments on three synthetic but realistic scenarios to assess accuracy and efficiency.","1550-5774;15505774","Electronic:978-1-4799-6155-9; POD:978-1-4799-6156-6","10.1109/DFT.2014.6962064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6962064","Board-level diagnosis;Faulty components;Incremental Adaptive Functional Diagnosis;Machine Learning","Accuracy;Artificial neural networks;Data mining;Engines;Fault diagnosis;Neurons;Support vector machines","fault diagnosis;iterative methods;learning (artificial intelligence)","faulty candidate component;incremental diagnosis engines;incremental functional diagnosis;iterative test;machine learning","","6","","13","","","1-3 Oct. 2014","","IEEE","IEEE Conference Publications"
"Detection of Tumor Cell Spheroids from Co-cultures Using Phase Contrast Images and Machine Learning Approach","N. Bayramoglu; M. Kaakinen; L. Eklund; M. Åkerfelt; M. Nees; J. Kannala; J. Heikkilä","Center for Machine Vision Res., Univ. of Oulu, Oulu, Finland","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3345","3350","Automated image analysis is demanded in cell biology and drug development research. The type of microscopy is one of the considerations in the trade-offs between experimental setup, image acquisition speed, molecular labelling, resolution and quality of images. In many cases, phase contrast imaging gets higher weights in this optimization. And it comes at the price of reduced image quality in imaging 3D cell cultures. For such data, the existing state-of-the-art computer vision methods perform poorly in segmenting specific cell type. Low SNR, clutter and occlusions are basic challenges for blind segmentation approaches. In this study we propose an automated method, based on a learning framework, for detecting particular cell type in cluttered 2D phase contrast images of 3D cell cultures that overcomes those challenges. It depends on local features defined over super pixels. The method learns appearance based features, statistical features, textural features and their combinations. Also, the importance of each feature is measured by employing Random Forest classifier. Experiments show that our approach does not depend on training data and the parameters.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.576","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977288","","Feature extraction;Histograms;Image segmentation;Imaging;Three-dimensional displays;Training;Tumors","computer vision;image classification;image segmentation;learning (artificial intelligence);medical image processing;optimisation;statistical analysis","appearance based features;automated image analysis;blind segmentation approaches;cell biology;computer vision methods;drug development research;image acquisition speed;image quality;image resolution;machine learning approach;molecular labelling;optimization;phase contrast images;random forest classifier;statistical features;textural features;tumor cell spheroid detection","","1","","25","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Application of statistical and machine learning models for grassland yield estimation based on a hypertemporal satellite remote sensing time series","I. Ali; F. Cawkwell; S. Green; N. Dwyer","Department of Geography, University College Cork, Cork, Ireland","2014 IEEE Geoscience and Remote Sensing Symposium","20141106","2014","","","5060","5063","More than 80% of agricultural land in Ireland is grassland, providing a major feed source for the pasture based dairy farming and livestock industry. Intensive grass based systems demand high levels of intervention by the farmer, with estimation of pasture cover (biomass) being the most important variable in land use management decisions, as well as playing a vital role in paddock and herd management. Many studies have been undertaken to estimate grassland biomass using satellite remote sensing data, but rarely in systems like Ire-lands intensively managed, small scale pastures, where grass is grazed as well as harvested for winter fodder. The objective of this study is to estimate grassland yield (kgDM/ha) from MODIS derived vegetation indices on a near weekly basis across the entire 300+ day growing season using three different methods (Multiple Linear Regression (MLR), Artificial Neural Networks (ANN) and Adaptive Neuro-Fuzzy Inference Systems (ANFIS)). The results show that ANFIS model produced best result (R<sup>2</sup> = 0.86) as compare to the ANN (R<sup>2</sup> = 0.57) and MLR (R<sup>2</sup> = 0.31).","2153-6996;21536996","Electronic:978-1-4799-5775-0; POD:978-1-4799-5314-1; USB:978-1-4799-5774-3","10.1109/IGARSS.2014.6947634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6947634","ANFIS;ANN;Grassland;MODIS time series;biomass prediction","Adaptation models;Adaptive systems;Artificial neural networks;Biological system modeling;Biomass;Remote sensing;Vegetation mapping","land use;remote sensing;vegetation","ANFIS model;Adaptive Neuro-Fuzzy Inference Systems;Artificial Neural Networks;Ireland;MODIS derived vegetation index;Multiple Linear Regression;agricultural land;dairy farming;grassland biomass;grassland yield estimation;herd management;hypertemporal satellite remote sensing time series;intensive grass based systems;land use management;livestock industry;machine learning model;pasture cover estimation;statistical model;winter fodder","","1","","16","","","13-18 July 2014","","IEEE","IEEE Conference Publications"
"Investigation into machine learning algorithms as applied to motor cortex signals for classification of movement stages","R. L. Hollingshead; D. Putrino; S. Ghosh; T. Tan","Curtin University, GPO Box U1987, Perth, Western Australia","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","1290","1293","Neuroinformatics has recently emerged as a powerful field for the statistical analysis of neural data. This study uses machine learning techniques to analyze neural spiking activities within a population of neurons with the aim of finding spiking patterns associated with different stages of movement. Neural data was recorded during many experimental trials of a cat performing a skilled reach and withdrawal task. Using Weka and the LibSVM classifier, movement stages of the skilled task were identified with a high degree of certainty achieving an area-under-curve (AUC) of the Receiver Operating Characteristic of between 0.900 and 0.997 for the combined data set. Through feature selection, the identification of significant neurons has been made easier. Given this encouraging classification performance, the extension to automatic classification and updating of control models for use with neural prostheses will enable regular adjustments capable of compensating for neural changes.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6943834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6943834","","Australia;Electronic mail;Feature extraction;Neurons;Radio frequency;Sociology;Statistics","bioelectric potentials;brain;cellular biophysics;feature selection;learning (artificial intelligence);medical signal processing;neurophysiology;sensitivity analysis;signal classification;support vector machines","LibSVM classifier;Weka classifier;area-under-curve;feature selection;machine learning algorithms;motor cortex signals;movement stage classification;neural prostheses;neural spiking activity analysis;neuroinformatics;neuron identification;receiver operating characteristic analysis;statistical analysis","","0","","8","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Hybrid improved gravitional search algorithm and kernel based extreme learning machine method for classification problems","C. Ma; J. Ouyang; J. Guan","College of Computer Science and Technology, Jilin University, Changchun, China","Proceedings 2014 IEEE International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)","20141215","2014","","","299","304","In this paper, we hybridize the improved gravitational search algorithm (IGSA) with kernel based extreme learning machine (KELM) method. Based on this, a novel hybrid system IGSA-KELM is proposed to improve the generalization performance for classification problems. In this system, IGSA is designed by combining the search strategy of particle swarm optimization and GSA to effectively reduce the problem of slow convergence rate, moreover, the continuous-value IGSA and binary IGSA are integrated in one algorithm in order to optimize the KELM parameters and feature subset selection simultaneously. This proposed hybrid algorithm is evaluated on several well-known UCI machine learning datasets. The results indicate that the superiority of the proposed model in terms of classification accuracy. Our hybrid method not only can select the most relevant feature subset, but also achieves a high classification accuracy over other similar state-of-the-art classifier systems.","","CD-ROM:978-1-4799-5352-3; Electronic:978-1-4799-5353-0; POD:978-1-4799-5354-7","10.1109/SPAC.2014.6982703","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982703","feature selection;gravitational search algorithm;hybrid system;kernel based extreme learning machine;parameter optimization","Accuracy;Algorithm design and analysis;Classification algorithms;Decision support systems;Machine learning algorithms;Testing;Training","data mining;feature selection;generalisation (artificial intelligence);learning (artificial intelligence);particle swarm optimisation;pattern classification","IGSA-KELM;KELM parameters;UCI machine learning datasets;binary IGSA;continuous-value IGSA;convergence rate;feature subset selection;generalization performance;hybrid system;improved gravitational search algorithm;kernel-based extreme learning machine method;particle swarm optimization","","1","","19","","","18-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"Salad leaf disease detection using machine learning based hyper spectral sensing","R. Dutta; D. Smith; Y. Shu; Q. Liu; P. Doust; S. Heidrich","CSIRO Digital Productivity and Services Flagship, CSIRO Hobart, Tasmania 7001, Australia","IEEE SENSORS 2014 Proceedings","20141215","2014","","","511","514","In this paper a novel application of salad leaf disease detection has been developed using a combination of machine learning algorithms and Hyper Spectral sensing. Various field experiments were conducted to acquire different vegetation reflectance spectrum profiles using a portable high resolution ASD FieldSpec4 Spectroradiometer, at a farm located in Richmond, Tasmania, Australia, (-42.36, 147.29), A total of 105 spectral samples were collected through three different experiments with baby salad leaves. In this study, Principal Component Analysis (PCA), Multi-Statistics Feature ranking and Linear Discriminant Analysis (LDA) Classifiers were used to classify disease affected salad leaves from the healthy salad leaves with 84% classification accuracy. This study concluded that the machine learning based approach along with a high resolution hyper Spectroradiometer could potentially provide a novel mechanism to use in the farm for rapid detection of salad leaf disease.","1930-0395;19300395","Electronic:978-1-4799-0162-3; POD:978-1-4799-0160-9; USB:978-1-4799-0161-6","10.1109/ICSENS.2014.6985047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6985047","","Absorption;Diseases;Principal component analysis;Sensors;Soil;Spectroradiometers;Variable speed drives","agricultural engineering;condition monitoring;learning (artificial intelligence);plant diseases;principal component analysis;spectrometers;vegetation mapping","ASD FieldSpec4 spectroradiometer;Australia;LDA classifiers;PCA;Richmond;Tasmania;hyper spectral sensing;linear discriminant analysis;machine learning;multistatistics feature ranking;principal component analysis;salad leaf disease detection;vegetation reflectance spectrum profiles","","1","","11","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Recognition of similar shaped isolated handwritten Gurumukhi characters using machine learning","R. Kaur; S. Gujral","Computer Science and Engineering, Chandigarh University, Gharuan, India","2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)","20141110","2014","","","251","256","Existence of similar shaped handwritten characters in any script affects its automated recognition. Effective recognition of similar shaped characters increases overall performance of automated handwritten character recognition. It is intensive research area because of its application in wide ambit of real human beings problems like postal address interpretation and signature verification in bank cheque processing etc. In this work, people in the age group of 20-50 years were asked to write characters of Gurumukhi Script in their natural writing style. Preprocessing steps were applied on the collected data and zoning based structural & region features were extracted. Data set was created using the extracted features and recognition was done using Random Forest and C4.5 machine learning algorithms.","","CD-ROM:978-1-4799-4237-4; Electronic:978-1-4799-4236-7; POD:978-1-4799-4235-0","10.1109/CONFLUENCE.2014.6949050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949050","Feature Extraction;Machine Learning;Region Based Features;Zoning Based Structural Features","Accuracy;Character recognition;Feature extraction;Handwriting recognition;Shape;Support vector machines;Vegetation","feature extraction;handwritten character recognition;learning (artificial intelligence);natural language processing;random processes","C4.5 machine learning algorithms;Gurumukhi script;automated handwritten character recognition;bank cheque processing;features extraction;natural writing style;postal address interpretation;random forest;signature verification;similar shaped isolated handwritten Gurumukhi characters recognition","","1","","26","","","25-26 Sept. 2014","","IEEE","IEEE Conference Publications"
"Freight transport prediction using electronic waybills and machine learning","S. Bakhtyar; L. Henesey","Department of Computer Science & Engineering, Blekinge Institute of Technology, Karlskrona, Sweden","Proceedings 2014 International Conference on Informative and Cybernetics for Computational Social Systems (ICCSS)","20141120","2014","","","128","133","A waybill is a document that accompanies the freight during transportation. The document contains essential information such as, origin and destination of the freight, involved actors, and the type of freight being transported. We believe, the information from a waybill, when presented in an electronic format, can be utilized for building knowledge about the freight movement. The knowledge may be helpful for decision makers, e.g., freight transport companies and public authorities. In this paper, the results from a study of a Swedish transport company are presented using order data from a customer ordering database, which is, to a larger extent, similar to the information present in paper waybills. We have used the order data for predicting the type of freight moving between a particular origin and destination. Additionally, we have evaluated a number of different machine learning algorithms based on their prediction performances. The evaluation was based on their weighted average true-positive and false-positive rate, weighted average area under the curve, and weighted average recall values. We conclude, from the results, that the data from a waybill, when available in an electronic format, can be used to improve knowledge about freight transport. Additionally, we conclude that among the algorithms IBk, SMO, and LMT, IBk performed better by predicting the highest number of classes with higher weighted average values for true-positive and false-positive, and recall.","","CD-ROM:978-1-4799-4753-9; Electronic:978-1-4799-4752-2; POD:978-1-4799-4751-5","10.1109/ICCSS.2014.6961829","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6961829","IBk;LMT;SMO;Waybill;freight mobility;machine learning","Accuracy;Cities and towns;Classification algorithms;Companies;Databases;Machine learning algorithms;Prediction algorithms","decision making;freight handling;learning (artificial intelligence)","IBk algorithm;LMT algorithm;SMO algorithm;Swedish transport company;customer ordering database;decision makers;electronic waybills;freight destination;freight movement;freight origin;freight transport companies;freight transport prediction;machine learning algorithms;public authorities;weighted average false-positive rate;weighted average recall values;weighted average true-positive rate","","1","","16","","","9-10 Oct. 2014","","IEEE","IEEE Conference Publications"
"Novel building management system based on machine learning and a cloud-based SOA for Ambient Living","S. Kyriazakos; G. Labropoulos; N. Zonidis; M. Foti","Converge ICT Solutions & Services S.A. 74, Panormou str., 11523 Athens, Greece","2014 4th International Conference on Wireless Communications, Vehicular Technology, Information Theory and Aerospace & Electronic Systems (VITAE)","20141023","2014","","","1","5","In this paper we present a novel Building Management System (BMS) that is based on advanced pattern matching algorithms and is utilizing a cloud-based Service Oriented Architecture (SOA) to offer a number of rich personalized applications for Ambient Living. The novelty presented in this paper is deriving from the evolution of a proprietary BMS product, namely Ecosystem, which is enhanced with the features presented in this paper, to address high demand for personalization and service adaptation in the new era of Information and Communication Technologies.","","Electronic:978-1-4799-4624-2; POD:978-1-4799-4623-5","10.1109/VITAE.2014.6934483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6934483","CBR;Ecosystem;SOA;machine learning;service elements","Buildings;Cognition;Ecosystems;Machine learning algorithms;Sensors;Supervised learning;Training","assisted living;building management systems;cloud computing;control engineering computing;learning (artificial intelligence);pattern matching;service-oriented architecture","BMS;SOA;ambient living;building management system;cloud-based service oriented architecture;machine learning;pattern matching algorithms","","0","","15","","","11-14 May 2014","","IEEE","IEEE Conference Publications"
"Empirical validation of website quality using statistical and machine learning methods","P. Dhiman; Anjali","Department of Software Engineering, Delhi Technological University, India","2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)","20141110","2014","","","286","291","The analysis of quantitative measure of large set of websites plays a significant role in evaluating the quality of websites. The paper, computes 22 metrics using a tool developed in MATLAB. Website quality prediction is developed using statistical and some machine learning methods. The work has been validated using dataset collected from webby awards web site. The results are analyzed using Area Under the Curve (AUC) obtained from Receiver Operating Characteristics (ROC) analysis. The results show that the model predicted using the random forest and Bayes Net methods outperformed over all the other models. Hence, based on these results it is reasonable to claim that quality models have a significant relevance with design metrics and the machine learning methods have a comparable performance with statistical methods. Univariate analysis results provide an empirical view for website design guidance and suggest which metrics are more important for website development.","","CD-ROM:978-1-4799-4237-4; Electronic:978-1-4799-4236-7; POD:978-1-4799-4235-0","10.1109/CONFLUENCE.2014.6949363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949363","Empirical Validation;Machine Learning;Receiver Operating Characteristics;Statistical Methods;Web page","Analytical models;Awards activities;Learning systems;Measurement;Predictive models;Statistical analysis;Web pages","Bayes methods;Web design;belief networks;learning (artificial intelligence);sensitivity analysis;statistical analysis","AUC analysis;Bayes net methods;MATLAB;ROC analysis;Website design guidance;Website development;Website quality evaluation;Website quality prediction;area under the curve analysis;empirical Website quality validation;machine learning methods;random forest;receiver operating characteristics analysis;statistical methods;univariate analysis","","1","","21","","","25-26 Sept. 2014","","IEEE","IEEE Conference Publications"
"Methodologies and application of machine learning algorithms to classify the performance of high performance cluster components","P. Romero; C. Idler","High Performance Computing 1, Los Alamos National Laboratory, USA","2014 IEEE International Conference on Cluster Computing (CLUSTER)","20141201","2014","","","400","407","High Performance Computing Clusters are designed to host highly parallelized applications, often in excess of thousands of nodes allocated to a job. These jobs, especially those that require a high level of synchronous communication, can be greatly affected by a single poor, or even sub-standard performing component. These components, often referred to as a node, are typically comprised of CPUs, accelerator processors, memory, a communication bus, and so on. Consequently it is important to identify and eliminate these sub-standard performing nodes before a job is scheduled onto them. In this paper we will describe the process used to measure and the methodology used to quantify poor performing nodes or classify suspect performing nodes into groups, or clusters, that can be later used to identify future performance issues. This process is more involved than simply running a scientific calculation across all the nodes, finding one that was “slow”, and labeling it as a bad node. At Los Alamos, this methodology has been used successfully to find problem nodes and has helped characterize the components of other clusters to aid in the proactive elimination of potential problems.","1552-5244;15525244","Electronic:978-1-4799-5548-0; POD:978-1-4799-5549-7; USB:978-1-4799-5547-3","10.1109/CLUSTER.2014.6968669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968669","","Bandwidth;Clustering algorithms;Graphics processing units;Principal component analysis;Standards;Testing","learning (artificial intelligence);parallel processing;performance evaluation","CPU;accelerator processors;high performance computing clusters;parallelized applications;poor performing nodes;scientific calculation;suspect performing nodes;synchronous communication","","0","","8","","","22-26 Sept. 2014","","IEEE","IEEE Conference Publications"
"Feature extraction and classification by machine learning methods for biometric recognition of face and iris","M. Oravec","Institute of Computer Science and Mathematics, Faculty of Electrical Engineering and Information Technology, Slovak, University of Technology in Bratislava, Ilkovi&#x010D;ova 3, 812 19, Bratislava, Slovak Republic","Proceedings ELMAR-2014","20141016","2014","","","1","4","Biometric recognition became an integral part of our living. This paper deals with machine learning methods for recognition of humans based on face and iris biometrics. The main intention of machine learning area is to reach a state when machines (computers) are able to respond without humans explicitly programming them. This area is closely related to artificial intelligence, knowledge discovery, data mining and neurocomputing. We present relevant machine learning methods with main focus on neural networks. Some aspects of theory of neural networks are addressed such as visualization of processes in neural networks, internal representations of input data as a basis for new feature extraction methods and their applications to image compression and classification. Machine learning methods can be efficiently used for feature extraction and classification and therefore are directly applicable to biometric systems. Biometrics deals with the recognition of people based on physiological and behavioral characteristics. Biometric recognition uses automated methods for recognition and this is why it is closely related to machine learning. Face recognition is discussed in this presentation - it covers the aspects of face detection, detection of facial features, classification in face recognition systems, state-of-the-art in biometric face recognition, face recognition in controlled and uncontrolled conditions and single-sample problem in face recognition. Iris recognition is analyzed from the point of view of state-of-the art in iris recognition, 2D Gabor wavelets, use of convolution kernels and possibilities for the design of new kernels. Software and hardware implementations of face and iris recognition systems are discussed and an implementation of a multimodal interface (face and iris part of a system) is presented. Also a contribution of Machine Learning Group working at FEI SUT Bratislava (http://www.uim.elf.stuba.sk/kaivt/MLgroup) to this research area is shown.","1334-2630;13342630","Electronic:978-953-184-199-3; POD:978-1-4799-5395-0","10.1109/ELMAR.2014.6923301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6923301","Biometric recognition;classification;face;feature extraction;iris;machine learning;multimodal interface;visualization","Face;Face recognition;Feature extraction;Iris recognition;Kernel;Neural networks","convolution;data mining;face recognition;feature extraction;image classification;iris recognition;learning (artificial intelligence);neural nets;wavelet transforms","2D Gabor wavelets;FEI SUT Bratislava;artificial intelligence;behavioral characteristics;biometric recognition;controlled conditions;convolution kernels;data mining;face detection;face recognition;facial feature detection;feature classification;feature extraction;human recognition;image classification;image compression;iris recognition;knowledge discovery;machine learning methods;multimodal interface;neural networks;neurocomputing;physiological characteristics;single-sample problem;uncontrolled conditions","","1","","19","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Feature Mining for Machine Learning Based Compilation Optimization","F. Li; F. Tang; Y. Shen","Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China","2014 Eighth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing","20141206","2014","","","207","214","Compilation optimization is critical for software performance. Before a product releases, the most effective algorithm combination should be chosen to minimize the object file size or to maximize the running speed. Compilers like GCC usually have hundreds of optimization algorithms, in which they have complex relationships. Different combinations of algorithms will lead to object files with different performance. Usually developers select the combination manually, but it's unpractical since a combination for one project can't be reused for another one. In order to conquer this difficulty some approaches like iterative search, heuristic search and machine learning based optimization have been proposed. However these methods still need improvements at different aspects like speed and precision. This paper researches machine learning based compilation optimization especially on feature processing which is important for machine learning methods. Program features can be divided into static features and dynamic features. Apart from user defined static features, we design a method to generate lots of static features by template and select best ones from them. Furthermore, we observe that feature value changes during different optimization phases and implement a feature extractor to extract feature values at specific phases and predict optimization plan dynamically. Finally, we implement the prototype on GCC version 4.6 with GCC plug in system and evaluate it with benchmarks. The results show that our system has a 5% average speed up for object file running speed than GCC O3 optimization level.","","CD-ROM:978-1-4799-4333-3; Electronic:978-1-4799-4331-9; POD:978-1-4799-7891-5","10.1109/IMIS.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975465","Compiler optimization;Feature mining;Machine learning","Benchmark testing;Computational modeling;Feature extraction;Optimization;Predictive models;Training;Vectors","data mining;learning (artificial intelligence);program compilers","GCC compiler;GCC plug in system;compilation optimization;dynamic features;feature mining;feature processing;heuristic search;iterative search;machine learning;software performance;static features","","0","","22","","","2-4 July 2014","","IEEE","IEEE Conference Publications"
"Exploiting machine learning algorithms for cognitive radio","V. Sharma; V. Bohara","Department of Computer Science and Engineering, Indraprastha Institute of Information Technology Delhi, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1554","1558","Cognitive radio is an intelligent radio that has the ability to sense and learn from its environment. Basic core of cognitive radio contains a learning engine and it plays an important role in every application of cognitive radio from spectrum sensing to spectrum management. Learning engine implements different learning algorithms. In this paper we discuss various learning algorithms and their application in solving specific problems of cognitive radio. Some of the prominent learning algorithms discussed in this paper are Genetic Algorithm (GA), Artificial Neural Networks (ANN) and Hidden Markov Model (HMM).","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968571","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968571","Artificial Neural Networks (ANN);Cognitive Radio;Genetic Algorithm (GA);Hidden Markov Model (HMM);Machine Learning","Bit error rate;Cognitive radio;Genetic algorithms;Hidden Markov models;Machine learning algorithms;Sociology;Statistics","cognitive radio;genetic algorithms;hidden Markov models;learning (artificial intelligence);neural nets","artificial neural networks;cognitive radio;genetic algorithm;hidden Markov model;intelligent radio;learning engine;machine learning algorithms;spectrum management;spectrum sensing","","2","","15","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Correcting abnormalities in meteorological data by machine learning","M. K. Lee; S. H. Moon; Y. H. Kim; B. R. Moon","School of Computer Science and Engineering, Seoul National University, Korea","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","888","893","Meteorological data collected from automatic weather stations have played an important role in forecasting and analyzing a large variety of phenomena. However, abnormal values are abundant in meteorological data due to manifold faults in observation systems. In this paper, we attempt to recover abnormal values. We present three estimation models based on machine learning techniques and compare them with traditional estimation methods, interpolations. Unlike the interpolation methods, which use only the target attribute, the proposed models utilize the additional information consisting of the associated attributes of the target station and the relevant data of the neighbor weather stations. Experiments were conducted for 692 locations in South Korea from 2007 to 2012. The results showed that the proposed approaches estimated target values better than the interpolation methods for all weather elements except one and the additional information helped achieve better performance.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974024","","Decision trees;Estimation;Humidity;Interpolation;Wind speed","environmental science computing;interpolation;learning (artificial intelligence);weather forecasting","South Korea;automatic weather stations;estimation models;interpolation methods;machine learning techniques;meteorological data abnormality correction;observation systems;weather elements","","1","","27","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Applying Adaptive Technology in Machine Learning","R. L. Stange; J. Jose","Univ. Tecnol. Fed. do Parana, Curitiba, Brazil","IEEE Latin America Transactions","20141106","2014","12","7","1298","1306","Incremental learning requires a learning mechanism based on the information extracted from dynamically accumulated experiments. The term “adaptivity” means the ability of a learning process to change its own set of rules in response to events occurred during the learning process. This work purposes to investigate the application of adaptive techniques in machine learning process. In order to achieve this target, the use of adaptive devices to represent the knowledge gathered through incremental learning is proposed.","1548-0992;15480992","","10.1109/TLA.2014.6948866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948866","Adaptive Technology;Adaptivity;Incremental Learning;Machine Learning","Abstracts;Adaptation models;Data mining;Irrigation;Laser radar;Learning systems","adaptive systems;learning (artificial intelligence)","adaptive techniques;adaptive technology;incremental learning;information extraction;learning mechanism;learning process;machine learning","","0","","","","","Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Joint layer based deep learning framework for bilingual machine transliteration","S. P; A. K. M","Center for Excellence in Computational Engineering and Networking, Amrita Vishwa Vidyapeetham, Tamil Nadu, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1737","1743","Between the growth of Internet or World Wide Web (WWW) and the emersion of the social networking site like Friendster, Myspace etc., information society started facing exhilarating challenges in language technology applications such as Machine Translation (MT) and Information Retrieval (IR). Nevertheless, there were researchers working in Machine Translation that deal with real time information for over 50 years since the first computer has come along. Merely, the need for translating data has become larger than before as the world was getting together through social media. Especially, translating proper nouns and technical terms has become openly challenging task in Machine Translation. The Machine transliteration was emerged as a part of information retrieval and machine translation projects to translate the Named Entities based on phoneme and grapheme, hence, those are not registered in the dictionary. Many researchers have used approaches such as conventional Graphical models and also adopted other machine translation techniques for Machine Transliteration. Machine Transliteration was always looked as a Machine Learning Problem. In this paper, we presented a new area of Machine Learning approach termed as a Deep Learning for improving the bilingual machine transliteration task for Tamil and English languages with limited corpus. This technique precedes Artificial Intelligence. The system is built on Deep Belief Network (DBN), a generative graphical model, which has been proved to work well with other Machine Learning problem. We have obtained 79.46% accuracy for English to Tamil transliteration task and 78.4 % for Tamil to English transliteration.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968553","Artificial Intelligence;Computational Linguistics;Deep Belief Networks;Deep Learning;Machine Transliteration;Natural Language Processing;Restricted Boltzmann Machine","Computers;Dictionaries;Joints;Neurons;Support vector machines;Training;Vectors","belief networks;computational linguistics;information retrieval;language translation;natural language processing","DBN;English languages;Friendster;IR;Internet;MT;Myspace;Tamil languages;Tamil-to-English transliteration;World Wide Web;bilingual machine transliteration;computational linguistics;deep belief network;generative graphical model;grapheme;information retrieval;information society;joint layer based deep learning framework;language technology applications;machine learning problem;machine translation;named entities;phoneme;proper nouns;real time information;social media;social networking site;technical terms","","0","","29","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Traffic engineering framework with machine learning based meta-layer in software-defined networks","L. Yanjun; L. Xiaobo; Y. Osamu","Graduate School of Information, Production and Systems, Waseda University, Fukuoka, Japan","2014 4th IEEE International Conference on Network Infrastructure and Digital Content","20150105","2014","","","121","125","Software-defined networks is an emerging architecture that separates the control plane and data plane. This paradigm enables flexible network resource allocations for traffic engineering, which aims to gain better network capacity and improved delay and loss performance. As we know, many heuristic algorithms have been developed to solve the dynamic routing problem. Whereas they lead to a high computational time cost, which results in a crucial problem whether such a heuristic approach to this NP-complete problem is of any use in practice. This paper proposes a framework with supervised machine learning based meta-layer to solve the dynamic routing problem in real time. We construct multiple machine learning modules in meta-layer, whose training set is consist of heuristic algorithm's input and its corresponding output. We show that after training process, the meta-layer will give heuristic-like results directly and independently, substituting for the time-consuming heuristic algorithm. We demonstrate, by analysis and simulation, our framework effectively enhance the network performance. Finally, the meta-layer architecture is quite universal and can be extended in numerous ways to accommodate a variety of traffic engineering scenarios in the network.","2374-0272;23740272","CD-ROM:978-1-4799-5624-1; Electronic:978-1-4799-4734-8; POD:978-1-4799-4733-1","10.1109/ICNIDC.2014.7000278","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000278","machine learning;meta-layer;routing;software-defined networks;traffic engineering","Delays;Heuristic algorithms;Machine learning algorithms;Network topology;Routing;Topology;Training","learning (artificial intelligence);resource allocation;software defined networking;telecommunication network routing;telecommunication traffic","control plane;data plane;delay performance;dynamic routing problem;flexible network resource allocations;heuristic algorithms;loss performance;machine learning modules;network capacity;software-defined networks;supervised machine learning based meta-layer;traffic engineering framework","","0","","12","","","19-21 Sept. 2014","","IEEE","IEEE Conference Publications"
"A survey of feature selection and feature extraction techniques in machine learning","S. Khalid; T. Khalil; S. Nasreen","Software Engineering Department, Bahria University Islamabad, Pakistan","2014 Science and Information Conference","20141009","2014","","","372","378","Dimensionality reduction as a preprocessing step to machine learning is effective in removing irrelevant and redundant data, increasing learning accuracy, and improving result comprehensibility. However, the recent increase of dimensionality of data poses a severe challenge to many existing feature selection and feature extraction methods with respect to efficiency and effectiveness. In the field of machine learning and pattern recognition, dimensionality reduction is important area, where many approaches have been proposed. In this paper, some widely used feature selection and feature extraction techniques have analyzed with the purpose of how effectively these techniques can be used to achieve high performance of learning algorithms that ultimately improves predictive accuracy of classifier. An endeavor to analyze dimensionality reduction techniques briefly with the purpose to investigate strengths and weaknesses of some widely used dimensionality reduction methods is presented.","","CD-ROM:978-0-9893-1932-4; Electronic:978-0-9893193-1-7; POD:978-1-4799-3981-7","10.1109/SAI.2014.6918213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918213","Age Related Macula Degeneration (AMD);Correlation Based Method;FSA's;Feature Extraction/Transformation;Feature Selection;Feature Subset Selection;ICA;PCA;RELIEF","Accuracy;Algorithm design and analysis;Correlation;Feature extraction;Noise;Principal component analysis;Redundancy","data mining;feature extraction;feature selection;learning (artificial intelligence)","dimensionality reduction;feature extraction techniques;feature selection;learning accuracy;learning algorithms;machine learning;pattern recognition;redundant data","","7","","29","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"An efficient inference in meanfield approximation by adaptive manifold filtering (Machine learning & data mining)","S. E. Nasab; S. Ramezanpur; S. Kasaei; E. Sanaei","Sharif University of Technology Tehran, Iran","2014 4th International Conference on Computer and Knowledge Engineering (ICCKE)","20141222","2014","","","581","585","A new method for speeding up the approximate maximum posterior marginal (MPM) inference in meanfield approximation of a fully connected graph is introduced. Weight of graph edges is measured by mixture of Gaussian kernels. This fully connected graph is used for segmentation of image data. The bottleneck of the inference in meanfield approximation is where the similar bilateral filtering is needed for updating the marginal in the message passing step. To speed up the inference, the adaptive manifold high dimensional Gaussian filter is used. As its time complexity is 0(ND), it leads to accelerating the marginal update in the message passing step. Its time complexity is linear and relative to the dimension and number of graph nodes. To improve the accuracy of segmentation, instead of the bilateral filter, the non-local mean filter is used. The proposed inference method is more accurate and needs less computations when compared to other existing methods.","","Electronic:978-1-4799-5487-2; POD:978-1-4799-5488-9","10.1109/ICCKE.2014.6993439","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993439","adaptive manifold;conditional random filed;high dimensioanl Gaussian filtering;inference;maximom posteriror marginal;non-local means","Acceleration;Approximation methods;Filtering;Lattices;Manifolds;Message passing;Time complexity","Gaussian processes;computational complexity;data mining;image segmentation;inference mechanisms;learning (artificial intelligence)","Gaussian kernels;MPM inference;adaptive manifold filtering;adaptive manifold high dimensional Gaussian filter;approximate maximum posterior marginal inference;bilateral filtering;data mining;fully connected graph;graph edges;image data segmentation;machine learning;meanfield approximation;message passing step;nonlocal mean filter;time complexity","","0","","13","","","29-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Machine Learning Approach to SPARQL Query Performance Prediction","R. Hasan; F. Gandon","Wimmics, INRIA Sophia Antipolis, Sophia-Antipolis, France","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","266","273","In this paper we address the problem of predicting SPARQL query performance. We use machine learning techniques to learn SPARQL query performance from previously executed queries. Traditional approaches for estimating SPARQL query cost are based on statistics about the underlying data. However, in many use-cases involving querying Linked Data, statistics about the underlying data are often missing. Our approach does not require any statistics about the underlying RDF data, which makes it ideal for the Linked Data scenario. We show how to model SPARQL queries as feature vectors, and use k-nearest neighbors regression and Support Vector Machine with the nu-SVR kernel to accurately predict SPARQL query execution time.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927552","Linked Data;SPARQL","Feature extraction;Measurement;Resource description framework;Support vector machines;Training;Vectors","learning (artificial intelligence);query languages;query processing;regression analysis;support vector machines","SPARQL query execution time;SPARQL query performance prediction;feature vector;k-nearest neighbor regression;linked data;machine learning;nu-SVR kernel;statistics;support vector machine","","5","","25","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Predicting GPU Performance from CPU Runs Using Machine Learning","I. Baldini; S. J. Fink; E. Altman","","2014 IEEE 26th International Symposium on Computer Architecture and High Performance Computing","20141204","2014","","","254","261","Graphics processing units (GPUs) can deliver considerable performance gains over general purpose processors. However, GPU performance improvement vary considerably across applications. Porting applications to GPUs by rewriting code with GPU-specific languages requires significant effort. In consequence, it is desirable to predict which applications would benefit most before porting to the GPU. This paper shows that machine learning techniques can build accurate predictive models for GPU acceleration. This study presents an approach which applies supervised learning algorithms to infer predictive models, based on dynamic profile data collected via instrumented runs on general purpose processors. For a set of 18 parallel benchmarks, the results show that a small set of easily-obtainable features can predict the magnitude of GPU speedups on two different high-end GPUs, with accuracies varying between 77% and 90%, depending on the prediction mechanism and scenario. For already-ported applications, similar models can predict the best device to run an application with an effective accuracy of 91%.","1550-6533;15506533","Electronic:978-1-4799-6905-0; POD:978-1-4799-6906-7","10.1109/SBAC-PAD.2014.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970672","","Accuracy;Analytical models;Benchmark testing;Graphics processing units;Predictive models;Support vector machines;Training","graphics processing units;learning (artificial intelligence);performance evaluation;specification languages","CPU runs;GPU acceleration;GPU performance improvement;GPU performance prediction;GPU speedups;GPU-specific languages;code rewriting;dynamic profile data;general purpose processors;graphics processing units;high-end GPU;machine learning techniques;porting applications;predictive models;supervised learning algorithms","","1","","28","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"Machine learning approach for forecasting crop yield based on climatic parameters","S. Veenadhari; B. Misra; C. Singh","MGCGV, Chitrakoot, Madhya Pradesh, India","2014 International Conference on Computer Communication and Informatics","20141016","2014","","","1","5","With the impact of climate change in India, majority of the agricultural crops are being badly affected interms of their performance over a period of last two decades. Predicting the crop yield well ahead of its harvest would help the policy makers and farmers for taking appropriate measures for marketing and storage. Such predictions will also help the associated industries for planning the logistics of their business. Several methods of predicting and modeling crop yields have been developed in the past with varying rateof success, as these don't take into account characteristicsoftheweather, a n d aremostly empirical. In the present study a software tool named `Crop Advisor' has been developed as an user friendly web page for predicting the influence of climatic parameters on the crop yields.C4.5 algorithm is used to find out the most influencing climatic parameter on the crop yields of selected crops in selected districts of Madhya Pradesh. This software provides an indication of relative influence of different climatic parameters on the crop yield, other agro-input parameters responsible for crop yield are not considered in this tool, since, application of these input parameters varies with individual fields in space and time.","","Electronic:978-1-4799-2352-6; POD:978-1-4799-2354-0","10.1109/ICCCI.2014.6921718","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921718","C4.5 alogarithm;Climate;agricultural productivity;prediction","Accuracy;Agriculture;Data mining;Decision trees;Meteorology;Predictive models;Software","agriculture;crops;learning (artificial intelligence)","C4.5 algorithm;Crop Advisor software tool;India;Madhya Pradesh;agricultural crops;agro-input parameters;climate change;climatic parameters;crop yield forecasting;machine learning approach;marketing measure;storage measure","","0","","15","","","3-5 Jan. 2014","","IEEE","IEEE Conference Publications"
"Emotion classification based on bio-signals emotion recognition using machine learning algorithms","E. H. Jang; B. J. Park; S. H. Kim; M. A. Chung; M. S. Park; J. H. Sohn","Biohealth IT Convergence Technology Research, Department & Future Technology Research Department, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea","2014 International Conference on Information Science, Electronics and Electrical Engineering","20141106","2014","3","","1373","1376","Emotions are complex processes involving multiple response channels, including physiological systems, facial expressions and voices. Bio-signals reflect sequences of neural activity, which result in changes in autonomic and neuroendocrine systems induced by emotional events. Therefore in human-computer interaction researches, one of the most current interesting topics in emotion recognition is to recognize human's feeling using bio-signals. The aim of this study is to classify emotions (joy, sadness, anger, fear, surprise, and neutral) that human have often experienced in real life from multichannel bio-signals using machine learning algorithms. We have measured physiological responses of three-hundred participants for acquisition of bio-signals such as electrodermal activity, electrocardiograph, skin temperature, and photoplethysmo-graph during six emotions induction. Also, for emotion classification, we have extracted eighteen features from the signals and performed emotion classification using four algorithms, linear discriminant analysis, Naïve Bayes, classification and regression tree and support vector machine. The used algorithms were evaluated by only training, 10-fold cross-validation and repeated random sub-sampling validation. We have obtained recognition accuracy from 56.4 to 100% for only training and 39.2 to 53.9% for testing. Also, the result for testing showed that an accuracy of emotion recognition by Naïve Bayes was highest (53.9%) and lowest by support vector machine (39.2%). This means that Naïve Bayes is the best emotion recognition algorithm for basic emotions. This result can be helpful to provide the basis for the emotion recognition technique in human-computer interaction.","","CD-ROM:978-1-4799-3195-8; Electronic:978-1-4799-3197-2; POD:978-1-4799-3198-9","10.1109/InfoSEEE.2014.6946144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6946144","bio-signal;emotion;machine learning algorithm","Classification algorithms;Emotion recognition;Feature extraction;Machine learning algorithms;Physiology;Support vector machines;Testing","Bayes methods;electrocardiography;emotion recognition;feature extraction;human computer interaction;learning (artificial intelligence);physiology;regression analysis;signal classification;support vector machines;trees (mathematics)","10-fold cross-validation;Naïve Bayes;autonomic system;bio-signal acquisition;biosignals emotion recognition;electrocardiograph;electrodermal activity;emotion classification;emotional events;emotions induction;facial expressions;feature extraction;human feeling recognition;human-computer interaction;linear discriminant analysis;machine learning algorithms;multichannel biosignals;neural activity;neuroendocrine system;photoplethysmo-graph;physiological responses;physiological systems;random subsampling validation;regression tree;skin temperature;support vector machine","","3","","16","","","26-28 April 2014","","IEEE","IEEE Conference Publications"
"Poster abstract: A machine learning approach for vehicle classification using passive infrared and ultrasonic sensors","E. U. Warriach; C. Claudel","Department of Mathematics and Computer Science, University of Groningen, The Netherlands","2013 ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","20141009","2013","","","333","334","This article describes the implementation of four different machine learning techniques for vehicle classification in a dual ultrasonic/passive infrared traffic flow sensors. Using k-NN, Naive Bayes, SVM and KNN-SVM algorithms, we show that KNN-SVM significantly outperforms other algorithms in terms of classification accuracy. We also show that some of these algorithms could run in real time on the prototype system.","","Electronic:978-1-4503-1959-1; POD:978-1-4799-6471-0","10.1145/2461381.2461434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6917602","Clustering;K-NN;Naive Bayes;SVM;Vehicle Classification","Acoustics;Clustering algorithms;Machine learning algorithms;Support vector machines;Temperature sensors;Vehicles","infrared detectors;learning (artificial intelligence);pattern classification;support vector machines;ultrasonic devices;wireless sensor networks","KNN-SVM algorithm;k-NN algorithm;k-nearest neighbor;machine learning techniques;naive Bayes algorithm;passive infrared traffic flow sensors;support vector machine;ultrasonic traffic flow sensors;vehicle classification","","1","","4","","","8-11 April 2013","","IEEE","IEEE Conference Publications"
"Machine learning techniques applied to intruder detection in networks","J. L. Henao R; J. E. Espinosa O","Politecnico Colombiano &#x201C;Jaime Isaza Cadavid&#x201D;, Medellin, Colombia","2013 47th International Carnahan Conference on Security Technology (ICCST)","20141016","2013","","","1","6","The intrusion in data networks, are a constant problem faced by networks administrators. Because of this, it is necessary identify, study and propose techniques to detect the moment in which the network is attacked, with the purpose of take measures to mitigate these threats. In this paper was conducted a study of the threats taxonomy that could lead to an attack in a data network. For this, we have identified the most relevant characteristics of the network traffic in order to be processed and classified using machine learning techniques, specifically the normalization (Z-Score), dimensionality reduction (PCA) and classification based on artificial neural networks (ANN) to suggest an intrusion detection system (IDS).","1071-6572;10716572","Electronic:978-1-4799-0889-9; POD:978-1-4799-0888-2","10.1109/CCST.2013.6922081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6922081","IDS;Intruder Detection Systems;Threat;classification;dimensionality reduction;network attacks;neural networks;normalization","Artificial neural networks;Boolean functions;Data structures;Vectors","learning (artificial intelligence);neural nets;pattern classification;principal component analysis;security of data","ANN classification;IDS;PCA;Z-score;artificial neural networks;data networks;dimensionality reduction;intruder detection;intrusion detection system;machine learning techniques;network traffic;normalization;principal component analysis;threat mitigation;threats taxonomy","","0","","11","","","8-11 Oct. 2013","","IEEE","IEEE Conference Publications"
"Machine learning identification of diabetic retinopathy from fundus images","N. Gurudath; M. Celenk; H. B. Riley","School of Electrical Engineering and Computer Science Stocker Center, Ohio University Athens, OH 45701 USA","2014 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)","20150108","2014","","","1","7","Diabetic retinopathy may potentially lead to blindness without early detection and treatment. In this research, an approach to automate the identification of the presence of diabetic retinopathy from color fundus images of the retina has been proposed. Classification of an input fundus image into one of the three classes, healthy/normal, Non-Proliferative Diabetic Retinopathy (NPDR) and Proliferative Diabetic Retinopathy (PDR) has been achieved. Blood vessel segmentation from the input image is achieved by Gaussian filtering. An adaptive, input - driven approach is considered for the mask generation and thresholding is accomplished using local entropy. The processed image obtained is characterized by second order textural feature, contrast, in four different orientations- 0°, 45°, 90° and 135° and structural features namely, fractal dimension and lacunarity. The research incorporates a three layered artificial neural network (ANN) and support vector machines (SVM) to classify the retinal images. The efficiency of the proposed approach has been evaluated on a set of 106 images from the DRIVE and DIARETB1 databases. The experimental results indicate that this method can produce a 97.2% and 98.1% classification accuracy using ANN and SVM respectively invariant of rotation, translation and scaling in input retinal images as opposed to a fixed mask based on the matched filter method.","","Electronic:978-1-4799-8184-7; POD:978-1-4799-8185-4","10.1109/SPMB.2014.7002949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7002949","Diabetic retinopathy;Gaussian filtering;artificial neural network;contrast;fractal dimension;fundus images;lacunarity;machine learning;support vector machines;texture","Artificial neural networks;Biomedical imaging;Blood vessels;Diabetes;Fractals;Retina;Retinopathy","Gaussian processes;biomedical optical imaging;blood vessels;entropy;eye;feature extraction;image classification;image segmentation;image texture;learning (artificial intelligence);matched filters;medical image processing;neural nets;support vector machines","ANN;DIARETB1 databases;DRIVE databases;Gaussian filtering;NPDR;SVM;artificial neural network;blindness;blood vessel segmentation;color fundus images;fractal dimension;fractal lacunarity;healthy-normal diabetic retinopathy;image processing;local entropy;machine learning identification;mask generation;matched filter method;nonproliferative diabetic retinopathy;retinal image classification;second order textural feature;structural features;support vector machines","","0","","28","","","13-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Handling intrusion and DDoS attacks in Software Defined Networks using machine learning techniques","J. Ashraf; S. Latif","CSE Dept, MCS, National University of Sciences and Technologies, Islamabad, Pakistan","2014 National Software Engineering Conference","20141229","2014","","","55","60","Software-Defined Networking (SDN) is an emerging concept that intends to replace traditional networks by breaking vertical integration. It does so by separating the control logic of network from the underlying switches and routers, suggesting logical centralization of network control, and allowing to program the network. Although SDN promises more flexible network management, there are numerous security threats accompanied with its deployment. This paper aims at studying SDN accompanied with OpenFlow protocol from the perspective of intrusion and Distributed Denial of Service (DDoS) attacks and suggest machine learning based techniques for mitigation of such attacks.","","Electronic:978-1-4799-6162-7; POD:978-1-4799-6163-4","10.1109/NSEC.2014.6998241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6998241","Distributed Denial of Service Attack;Intrusion Detection;Machine Learning;Software Defined Networking (SDN)","Artificial neural networks;Bayes methods;Classification algorithms;Genetics;Silicon;Support vector machine classification;Training","computer network security;learning (artificial intelligence);software defined networking","DDoS attacks;OpenFlow protocol;SDN;distributed denial of service;intrusion attack mitigation;machine learning techniques;software defined networks","","2","","35","","","11-12 Nov. 2014","","IEEE","IEEE Conference Publications"
"Sentiment Categorization on a Creole Language with Lexicon-Based and Machine Learning Techniques","A. A. Ríos; P. J. Amarilla; G. A. G. Lugo","Fac. Politec., Univ. Nac. de Asuncion, San Lorenzo, Paraguay","2014 Brazilian Conference on Intelligent Systems","20141215","2014","","","37","43","We propose polarity detection from colloquial expressions distinctive of a bilingual population. The hybrid language we address it's called ""Jopara"", composed by Spanish and Guaraní, spoken in Paraguay, similar to the ""Louisiana's Creole"" in the United States. We categorize polarity in three classes (positive, negative and neutral) and address this problem by applying both lexicon-based and machine-learning approaches. In this document it's shown the application scenario, the building process of the bilingual lexicon and the attributes preprocessing to create the classifiers' input. The input data is retrieved from Twitter so the expressions are similar to natural language. Finally, results are displayed to compare performance of these techniques when applied on this kind of language. It's shown that classical classifiers have very good performances, with correction rates of over 80% even with small training sets, if their parameters are properly adjusted along with an adequate selection of attributes.","","Electronic:978-1-4799-5618-0; POD:978-1-4799-7859-5","10.1109/BRACIS.2014.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984804","cross-lingual issues;emotion detection;lexical resources;micro blogging;multi-lingual","Classification algorithms;Companies;Kernel;Sentiment analysis;Support vector machine classification;Training","learning (artificial intelligence);natural language processing;pattern classification;social networking (online)","Guaraní;Jopara;Louisiana Creole language;Paraguay;Spanish;Twitter;United States;attribute preprocessing;attribute selection;bilingual lexicon;bilingual population;classifier input data retrieval;colloquial expressions;correction rates;hybrid language;lexicon-based technique;machine learning technique;natural language;negative class;neutral class;polarity detection;positive class;sentiment categorization;training sets","","0","","11","","","18-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Machine Learning Based Method for Staff Removal","I. d. S. Montagner; R. Hirata; N. S. T. Hirata","Inst. of Math. & Stat., Univ. of Sao Paulo, Matao, Brazil","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3162","3167","Staff line removal is an important pre-processing step to convert content of music score images to machine readable formats. Many heuristic algorithms have been proposed for staff removal and recently a competition was organized in the 2013 ICDAR/GREC conference. Music score images are often subject to different deformations and variations, and existing algorithms do not work well for all cases. We investigate the application of a machine learning based method for the staff removal problem. The method consists in learning multiple image operators from training input-output pairs of images and then combining the results of these operators. Each operator is based on local information provided by a neighborhood window, which is usually manually chosen based on the content of the images. We propose a feature selection based approach for automatically defining the windows and also for combining the operators. The performance of the proposed method is superior to several existing methods and is comparable to the best method in the competition.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977257","","Accuracy;Algorithm design and analysis;Learning systems;Machine learning algorithms;Prototypes;Three-dimensional displays;Training","feature selection;image recognition;learning (artificial intelligence);music","feature selection based approach;heuristic algorithms;learning multiple image operators;local information;machine learning based method;machine readable formats;music score images;neighborhood window;optical music recognition system;staff line removal;training input-output pairs","","4","","18","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Review of Machine Learning techniques for glaucoma detection and prediction","T. Khalil; S. Khalid; A. M. Syed","Software Eng. Dept., Bahria Univ., Islamabad, Pakistan","2014 Science and Information Conference","20141009","2014","","","438","442","Glaucoma is a silent thief of sight. Detecting glaucoma at early stages is almost impossible and presently there is no cure of glaucoma at later stages. Different automated glaucoma detection systems were thoroughly analyzed in this study. A detailed literature survey of preprocessing, feature extraction, feature selection, Machine Learning (ML) techniques and data sets used for testing and training purpose was conducted. Automated prediction of glaucoma is very important and unfortunately a little work has been done in this regard and minimum accuracy has been achieved. However automated detection of glaucoma at latter stage is at a mature level and most of the ML techniques are able to detect 85% of glaucoma cases accurately. Optical Coherence Tomography (OCT) can be used effectively for prediction of glaucoma.","","CD-ROM:978-0-9893-1932-4; Electronic:978-0-9893193-1-7; POD:978-1-4799-3981-7","10.1109/SAI.2014.6918224","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918224","Feature Extraction;Feature Selection;Glaucoma Detection;Glaucoma Prediction;Machine Learning","Accuracy;Biomedical imaging;Diseases;Feature extraction;Neural networks;Optical imaging","feature extraction;learning (artificial intelligence);medical image processing","ML techniques;OCT;automated glaucoma detection systems;automated prediction;feature extraction;feature selection;glaucoma prediction;machine learning techniques;optical coherence tomography","","4","","18","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"Towards effective feature selection in machine learning-based botnet detection approaches","E. Biglar Beigi; H. Hadian Jazi; N. Stakhanova; A. A. Ghorbani","Information Security Center of Excellence, Faculty of Computer Science, University of New Brunswick, Fredericton, Canada","2014 IEEE Conference on Communications and Network Security","20141229","2014","","","247","255","Botnets, as one of the most formidable cyber security threats, are becoming more sophisticated and resistant to detection. In spite of specific behaviors each botnet has, there exist adequate similarities inside each botnet that separate its behavior from benign traffic. Several botnet detection systems have been proposed based on these similarities. However, offering a solution for differentiating botnet traffic (even those using same protocol, e.g. IRC) from normal traffic is not trivial. Extraction of features in either host or network level to model a botnet has been one of the most popular methods in botnet detection. A subset of features, usually selected based on some intuitive understanding of botnets, is used by the machine learning algorithms to classify/ cluster botnet traffic. These approaches, tested against two or three botnet traces, have mostly showed satisfactory detection results. Even though, their effectiveness in detection of other botnets or real traffic remains in doubt. Additionally, effectiveness of different combination of features in terms of providing more detection coverage has not been fully studied. In this paper we revisit flow-based features employed in the existing botnet detection studies and evaluate their relative effectiveness. To ensure a proper evaluation we create a dataset containing a diverse set of botnet traces and background traffic.","","Electronic:978-1-4799-5890-0; POD:978-1-4799-5891-7","10.1109/CNS.2014.6997492","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6997492","","Accuracy;Feature extraction;IP networks;Peer-to-peer computing;Ports (Computers);Protocols;Security","invasive software;learning (artificial intelligence)","botnet detection;botnet traffic;cyber security threat;feature selection;flow-based feature;machine learning","","5","","40","","","29-31 Oct. 2014","","IEEE","IEEE Conference Publications"
"Machine learning model for aircraft performances","M. Hrastovec; F. Solina","Slovenia Control Ltd., Slovenia","2014 IEEE/AIAA 33rd Digital Avionics Systems Conference (DASC)","20141211","2014","","","8C4-1","8C4-10","This paper presents new idea how trajectory calculations could be improved in order to match real flights better. Exact trajectory calculation is important for future of air traffic control, because it is one of the enablers for safe traffic increase. Methods used to calculate trajectories are based on aircraft types and their performances mainly. However, we believe that there are many other influencing factors which should be taken into account. We collect available data about flights and store them into a multi-dimensional database. Knowledge accumulated in this database is the basis for aircraft performances prediction using machine learning methods. In that way the prediction is not based on aircraft type alone, but also on other attributes like aerodrome of departure, destination and operator. There attributes indirectly imply to procedures, operator's best practices, local airspace characteristics, etc. and enable us to make better predictions of aircraft performances. Predictions in this case are not static but tailored to every particular flight.","2155-7195;21557195","Electronic:978-1-4799-5001-0; POD:978-1-4799-5000-3","10.1109/DASC.2014.6979541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6979541","","Air traffic control;Aircraft;Atmospheric modeling;Databases;Radar tracking;Trajectory","aerospace computing;air traffic control;aircraft;data acquisition;database management systems;learning (artificial intelligence)","aerodrome;air traffic control;aircraft performance prediction;aircraft types;local airspace characteristics;machine learning methods;multidimensional database;trajectory calculations","","0","","14","","","5-9 Oct. 2014","","IEEE","IEEE Conference Publications"
"A combination forecasting model using machine learning and Kalman filter for statistical arbitrage","J. P. Nóbrega; A. L. I. Oliveira","Centro de Inform&#x00E1;tica, Universidade Federal de Pernambuco, Recife, Brazil","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","1294","1299","In this paper we evaluate the combination of Extreme Learning Machine (ELM) and Support Vector Regression (SVR) with a Kalman filter regression model for financial time series forecasting. We also compare the forecast performance with a set of linear regression combination methods. The application of the traditional Kalman Filter for the statistical arbitrage strategy improves the statistical performance of ELM and SVR individual forecasts. The accuracy of the models is statistically tested and an investigation is performed to confirm the impact of the forecasts combination in terms of annualized returns and volatility.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974093","Extreme Learning Machine;Forecast Combinations;Kalman Filter;Pair Trading;Statistical Arbitrage;Support Vector Regression","Forecasting;Kalman filters;Mathematical model;Predictive models;Support vector machines;Time series analysis;Training","Kalman filters;financial management;learning (artificial intelligence);regression analysis;statistical testing;support vector machines;time series","ELM;Kalman filter regression model;SVR;extreme learning machine;financial time series forecasting;forecasting model;linear regression combination methods;statistical arbitrage strategy;statistical performance;statistical testing;support vector regression","","1","","21","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Promoting education: A state of the art machine learning framework for feedback and monitoring E-Learning impact","H. R. Joseph","Dept. of Electrical Engineering and Information Technology, Technische Universit&#x00E4;t M&#x00FC;nchen","2014 IEEE Global Humanitarian Technology Conference - South Asia Satellite (GHTC-SAS)","20141201","2014","","","251","254","A serious impediment in E-Learning is that these systems seem to have failed to consider the advantages of the supervision of a teacher. Teachers are able to monitor the progress made by several students, irrespective of their learning abilities and attempt to channel all students towards a common learning goal. E-Learning systems today don't possess a monitoring component. Most approaches customize content to suit differing learning abilities, resulting in different learning goals. However, this study attempts to apply machine learning methods that customizes not the content, but the presentation of the content assuming almost common learning goals - just like how a teacher would modify the content presentation, if some aspects are not clear to students based on their feedback. The primary challenge towards developing such a monitoring system is to decide what aspects of the interaction are to be monitored and how these are to interpreted as feedback with actionable insights - that is, to decide the learning schema, and then apply learning algorithms to gauge the interest or disinterest of the learner in the content presented.","","CD-ROM:978-1-4799-4098-1; Electronic:978-1-4799-4097-4; POD:978-1-4799-4096-7","10.1109/GHTC-SAS.2014.6967592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967592","","Databases;Electronic learning;Learning systems;Media;Monitoring;Real-time systems","computer aided instruction;learning (artificial intelligence);teaching","actionable insights;content presentation;e-learning impact;education promotion;learner disinterest;learner interest;learning schema;machine learning framework;students;teacher supervision","","0","","7","","","26-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Fast H.264/AVC to HEVC transcoding based on machine learning","E. Peixoto; B. Macchiavello; R. L. de Queiroz; E. M. Hung","Departamento de Engenharia El&#x00E9;trica, Universidade de Bras&#x00ED;lia, Campus Universit&#x00E1;rio Darcy Ribeiro, Brasil","2014 International Telecommunications Symposium (ITS)","20141106","2014","","","1","4","Since the HEVC codec has become an ITU-T and ISO/IEC standard, efficient transcoding from previous standards, such as the H.264/AVC, to HEVC is highly needed. In this paper, we build on our previous work with the goal to develop a faster transcoder from H.264/AVC to HEVC. The transcoder is built around an established two-stage transcoding. In the first stage, called the training stage, full re-encoding is performed while the H.264/AVC and the HEVC information are gathered. This information is then used to build a CU classification model that is used in the second stage (called the transcoding stage). The solution is tested with well-known video sequences and evaluated in terms of rate-distortion and complexity. The proposed method is 3.4 times faster, on average, than the trivial transcoder, and 1.65 times faster than a previous transcoding solution.","","Electronic:978-1-4799-3743-1; POD:978-1-4799-3744-8","10.1109/ITS.2014.6947999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6947999","","Rate-distortion;Standards;Streaming media;Training;Transcoding;Video coding","IEC standards;ISO standards;learning (artificial intelligence);rate distortion theory;transcoding;video coding","CU classification model;HEVC codec;IEC standard;ISO standard;ITU-T standard;high efficiency video coding;machine learning;rate-distortion;transcoding solution;two-stage transcoding;video sequences","","5","1","18","","","17-20 Aug. 2014","","IEEE","IEEE Conference Publications"
"Android Malware Detection Using Parallel Machine Learning Classifiers","S. Y. Yerima; S. Sezer; I. Muttik","Centre for Secure Inf. Technol. (CSIT), Queen's Univ., Belfast, UK","2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies","20141215","2014","","","37","42","Mobile malware has continued to grow at an alarming rate despite on-going mitigation efforts. This has been much more prevalent on Android due to being an open platform that is rapidly overtaking other competing platforms in the mobile smart devices market. Recently, a new generation of Android malware families has emerged with advanced evasion capabilities which make them much more difficult to detect using conventional methods. This paper proposes and investigates a parallel machine learning based classification approach for early detection of Android malware. Using real malware samples and benign applications, a composite classification model is developed from parallel combination of heterogeneous classifiers. The empirical evaluation of the model under different combination schemes demonstrates its efficacy and potential to improve detection accuracy. More importantly, by utilizing several classifiers with diverse characteristics, their strengths can be harnessed not only for enhanced Android malware detection but also quicker white box analysis by means of the more interpretable constituent classifiers.","2161-2889;21612889","CD-ROM:978-1-4799-5072-0; Electronic:978-1-4799-5073-7; POD:978-1-4799-5074-4","10.1109/NGMAST.2014.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982888","Android;data mining;machine learning;malware detection;mobile security;parallel classifiers;static analysis","Accuracy;Androids;Classification algorithms;Feature extraction;Humanoid robots;Malware;Training","Android (operating system);invasive software;learning (artificial intelligence);mobile computing;parallel processing","Android malware detection;mobile malware;mobile smart devices market;open platform;parallel machine learning classifiers","","3","","20","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Application of machine learning for NonHolonomic mobile robot trajectory controlling","M. Gohari; M. Tahmasebi; A. Nozari","Faculty of Mechanical Engineering, Arak University of Technology Arak, Iran","2014 4th International Conference on Computer and Knowledge Engineering (ICCKE)","20141222","2014","","","42","46","Mobile robots are very interested by researchers over the last few years because of their applications and physical characteristics. The workspace of mobile robots is not always ideal, but typically filled with disturbances (known or unknown) such as uneven surface terrain, natural friction, uncertainties, and parametric changes. In this study, a new approach namely active force control (AFC) scheme integrating artificial neural network (ANN) has been suggested to cope on the disturbances and thus improve the trajectory tracking characteristic of the system. Therefore, a two wheeled mobile robot has been simulated, and ANN technique is explicitly employed for the estimation of the inertia matrix that is needed in the inner feedback control loop of the AFC scheme. The robustness and efficiency of the identified control scheme are studied considering various forms of loading and operating conditions. For the purpose of benchmarking, the AFC scheme performance has been compared to PID controller.","","Electronic:978-1-4799-5487-2; POD:978-1-4799-5488-9","10.1109/ICCKE.2014.6993354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993354","Active Force Control;Artificial Neural Network;Differentially Driven Mobile Robot;Machin learning;Nonholonomic System","Artificial neural networks;Force control;Frequency control;Mobile robots;Trajectory;Wheels","feedback;force control;learning (artificial intelligence);matrix algebra;mobile robots;neural nets;trajectory control","AFC scheme;ANN technique;PID controller;active force control scheme;artificial neural network;inner feedback control loop;machine learning;nonholonomic mobile robot trajectory control;physical characteristics;trajectory tracking characteristics;two wheeled mobile robot","","0","","16","","","29-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"A machine learning approach for Twitter spammers detection","C. Meda; F. Bisio; P. Gastaldo; R. Zunino","University of Genoa, DITEN, Via all'Opera Pia 11a, 16145, Genova, Italy","2014 International Carnahan Conference on Security Technology (ICCST)","20141218","2014","","","1","6","The ever-increasing popularity of Social Networks offers unprecedented opportunities to aggregate people and exchange information, but, at the same time, opens new modalities for cyber-crime perpetrations. The spamming phenomenon, so spread-out in emails, is now affecting microblogs, and exploits specific mechanisms of the messaging process. The paper proposes an inductive-learning method for the detection of Twitter-spammers, and applies a Random-Forest approach to a limited set of features that are extracted from traffic. Experimental results show that the proposed method outperforms existing approaches to this problem.","1071-6572;10716572","Electronic:978-1-4799-3532-1; POD:978-1-4799-3533-8; USB:978-1-4799-3531-4","10.1109/CCST.2014.6987029","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987029","Machine Learning;Social Network Security;Twitter Spam Detection","Classification algorithms;Feature extraction;Training;Twitter;Unsolicited electronic mail;Vegetation","computer crime;feature extraction;learning (artificial intelligence);learning by example;social networking (online);tree searching;unsolicited e-mail","Twitter spammer detection;cyber-crime perpetrations;feature extraction;inductive-learning method;machine learning approach;messaging process;microblogs;random-forest approach;social networks;spamming phenomenon","","3","","14","","","13-16 Oct. 2014","","IEEE","IEEE Conference Publications"
"Book Recommendation Using Machine Learning Methods Based on Library Loan Records and Bibliographic Information","K. Tsuji; F. Yoshikane; S. Sato; H. Itsumura","Fac. of Libr., Inf. & Media Sci., Univ. of Tsukuba, Tsukuba, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","76","79","We propose a method to recommend books through machine learning modules based on several features, including library loan records. We evaluated the most effective method among ones using (a) a Support Vector Machine (SVM), (b) Random Forest and (c) Adaboost, as well as the most effective combination of relevant features among (1) library loan records, (2) book titles, (3) Nippon Decimal Classification categories, (4) publication year and (5) frequencies at which books were borrowed. We performed an experiment involving 40 subjects who are students at T University. The books that our methods recommended and the loan records that we used were obtained from the T University Library. The results show that books recommended by the SVM based on features (1), (2), (3) and (5) were rated most favorably by the subjects. Our method outperforms preceding ones, such as the method proposed by Tsuji et al. (2013), and is comparable in performance to the recommendation by the website Amazon.co.jp.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913270","Adaboost;Book Recommendation;Library Loan Records;Random Forest;Recommender System;SVM;Support Vector Machine","Association rules;Books;Educational institutions;Learning systems;Libraries;Support vector machines;Training data","academic libraries;bibliographic systems;learning (artificial intelligence);recommender systems;support vector machines","Adaboost;SVM;bibliographic information;book recommendation;library loan records;machine learning methods;random forest;support vector machine","","2","","13","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Bus load forecasting via a combination of machine learning algorithms","I. P. Panapakidis; G. K. Papagiannis; G. C. Christoforidis","School of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece","2014 49th International Universities Power Engineering Conference (UPEC)","20141023","2014","","","1","6","Aim of this work is to develop a novel hybrid model for the day-ahead prediction of a distribution substation feeder load. The model comprises an unsupervised machine learning stage, where a clustering of daily load curves takes place, and an Artificial Neural Network (ANN), based on the clustering output, which performs the prediction. The model is tested on the day-ahead prediction of a complete year, where the load corresponds to a bus that refers to a sub-urban area in Northern Greece. The proposed model is compared with the one that has been developed for the Greek interconnected system. Experimental results indicate that the model leads to increased accuracy and is able to simulate the high nonlinearities of the bus load.","","CD-ROM:978-1-4799-6556-4; Electronic:978-1-4799-6557-1; POD:978-1-4799-6558-8","10.1109/UPEC.2014.6934816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6934816","load forecasting;load profiling;machine learning;neural networks;time series analysis","Artificial neural networks;Clustering algorithms;Forecasting;Load modeling;Neurons;Predictive models;Training","distribution networks;learning (artificial intelligence);load forecasting;neural nets;power engineering computing;substations","ANN;Greek interconnected system;Northern Greece;artificial neural network;bus load forecasting;clustering output;daily load curves;day-ahead prediction;distribution substation feeder load;machine learning algorithms;unsupervised machine learning stage","","0","","18","","","2-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"An automatic visual inspection method based on supervised machine learning for rapid on-site evaluation in EUS-FNA","H. Inoue; K. Ogo; M. Tabuchi; N. Yamane; H. Oka","Department of Pathology, Okayama University Hospital, Okayama-shi, Japan","2014 Proceedings of the SICE Annual Conference (SICE)","20141027","2014","","","1114","1119","In this paper, an automatic visual inspection method based on supervised machine learning is proposed to assist rapid on-site evaluation (ROSE) for endoscopic ultrasound-guided fine needle aspiration (EUS-FNA) biopsy. The aim of this method is to learn relations between content of cellular tissue including tumor cells and aspect of specimen image removed by the needle aspiration. For this purpose, a stationary Gaussian mixture model (GMM) is applied to classify the local statistics of the specimen images, because stationary GMM is known to be effective to estimate universal model. In this paper, some specimen images with their definitive diagnosis information are used as training images in GMM learning. The training images are also used in the supervised learning with their diagnosis information as teacher data, i.e. the rank of tumor cells content. Thus, the learning of statistical relation between the local image aspect and its rank of tumor cells content may be linked by the class index of GMM, using the training images. A simulation result shows that the proposed method is effective to assist on-site visual inspection of cellular tissue in ROSE for EUS-FNA, indicating highly probable area including tumor cells.","","Electronic:978-4-9077-6446-3; POD:978-1-4799-6548-9","10.1109/SICE.2014.6935253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935253","EUS-FNA;Gaussian mixture model;automatic visual inspection;rapid on-site evaluation;supervised machine leaning","Biomedical imaging;Educational institutions;Indexes;Inspection;Training;Tumors;Visualization","Gaussian processes;endoscopes;image classification;inspection;learning (artificial intelligence);medical image processing;mixture models;tumours","EUS-FNA biopsy;GMM learning;ROSE;automatic visual inspection method;cellular tissue;diagnosis information;endoscopic ultrasound-guided fine needle aspiration;rapid on-site evaluation;specimen image classification;stationary GMM;stationary Gaussian mixture model;supervised machine learning;teacher data;tumor cells;universal model estimation","","0","","5","","","9-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Applicability of machine-learning techniques in predicting customer defection","N. Prasasti; H. Ohwada","School of Business and Management, Bandung Institute of Technology, Indonesia","2014 International Symposium on Technology Management and Emerging Technologies","20141027","2014","","","157","162","Machine learning is an established method of predicting customer defection from a contractual business. However, no systematic comparison or evaluation of the different machine-learning techniques has been performed. In this study, we provide a comprehensive comparison of different machine-learning techniques with three different data sets of a software company to predict customer defection. The evaluation criteria of the techniques are understandability of the model, convenience of using the model, time efficiency in running the learning model, and performance of predicting customer defection.","","CD-ROM:978-1-4799-3703-5; Electronic:978-1-4799-3704-2; POD:978-1-4799-3705-9","10.1109/ISTMET.2014.6936498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936498","Classification;Customer defection;J48 Decision Tree;Machine learning;Neural network;Random forest;SVM","Classification algorithms;Decision trees;Kernel;Neural networks;Predictive models;Radio frequency;Support vector machines","customer satisfaction;decision trees;learning (artificial intelligence)","contractual business;customer defection;machine-learning","","1","","20","","","27-29 May 2014","","IEEE","IEEE Conference Publications"
"A machine learning approach to vehicle occupancy detection","B. Xu; P. Paul; Y. Artan; F. Perronnin","Xerox Innovation Group, Xerox Corporation, Webster, NY 14580 USA","17th International IEEE Conference on Intelligent Transportation Systems (ITSC)","20141120","2014","","","1232","1237","To manage ever increasing traffic volume on modern highways, transportation agencies have introduced special managed lanes where only vehicles with a certain occupancy level are allowed. This encourages highway users to ride together, thus, in theory, more efficiently transporting people through the highway system. In order to be effective, however, adherence to the vehicle occupancy rules has to be enforced. Recent studies have shown that the traditional approach of dispatching traffic law enforcement officers to perform roadside visual inspections is not only expensive and dangerous, but also ineffective for managed lane enforcement. In this paper, we describe an image-based machine learning approach for automatic or semi-automatic vehicle occupancy detection. Our method localizes windshield regions by constructing an elastic deformation model from sets of uniquely defined landmark points along the front windshield. From the localized windshield region, the method calculates image-level feature representations, which are then applied to a trained classifier for classifying the vehicle into violator and non-violator classes.","2153-0009;21530009","Electronic:978-1-4799-6078-1; POD:978-1-4799-6079-8; USB:978-1-4799-6077-4","10.1109/ITSC.2014.6957856","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957856","","Automotive components;Cameras;Error analysis;Face;Feature extraction;Road transportation;Vehicles","feature extraction;image representation;inspection;learning (artificial intelligence);object detection;traffic engineering computing","elastic deformation model;highway system;image-based machine learning approach;image-level feature representations;modern highways;nonviolator classes;roadside visual inspections;semi-automatic vehicle occupancy detection;traffic law enforcement;traffic volume;transportation agencies","","3","","23","","","8-11 Oct. 2014","","IEEE","IEEE Conference Publications"
"A unified machine learning method for task-related and resting state fMRI data analysis","X. Song; N. k. Chen","Department of Electrical Engineering, Widener University, Chester, PA 19013 USA","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","6426","6429","Functional magnetic resonance imaging (fMRI) aims to localize task-related brain activation or resting-state functional connectivity. Most existing fMRI data analysis techniques rely on fixed thresholds to identify active voxels under a task condition or functionally connected voxels in the resting state. Due to fMRI non-stationarity, a fixed threshold cannot adapt to intra- and inter-subject variation and provide a reliable mapping of brain function. In this work, a machine learning method is proposed for a unified analysis of both task-related and resting state fMRI data. Specifically, the mapping of brain function in a task condition or resting state is formulated as an outlier detection process. Support vector machines are used to provide an initial mapping and refine mapping results. The method does not require a fixed threshold for the final decision, and can adapt to fMRI non-stationarity. The proposed method was evaluated using experimental data acquired from multiple human subjects. The results indicate that the proposed method can provide reliable mapping of brain function, and is applicable to various quantitative fMRI studies.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6945099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945099","","Correlation;Feature extraction;Kernel;Prototypes;Reliability;Support vector machines;Training","biomedical MRI;brain;learning (artificial intelligence);medical image processing;support vector machines","brain function;functional magnetic resonance imaging;resting state fMRI data analysis;resting state functional connectivity;support vector machines;task related brain activation;task related fMRI data analysis;unified machine learning method","","0","","15","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Machine learning and interactive visualization applied to TB-sized images of stem cells","J. Amelot; P. Bajcsy; A. Plant; M. Brady","Information Technology Laboratory, National Institute of Standards and Technology, Gaithersburg, USA","2014 IEEE International Conference on Big Data (Big Data)","20150108","2014","","","4","4","In order to characterize the growth and properties of stem cell colonies with high statistical significance, we address the problem of applying machine learning and interactive web visualizations to TB-sized images. Overcoming the computational challenges and designing advanced visualizations enabled knowledge discovery and quantitative analysis at unprecedented scales in cell microscopy.","","Electronic:978-1-4799-5666-1; POD:978-1-4799-5667-8","10.1109/BigData.2014.7004474","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004474","Big Data;Image Processing;Interactive Data Visualization;Machine Learning;Parallel Computing;Predictive Modeling","Big data;Computational modeling;Data visualization;Feature extraction;Laboratories;Predictive models;Stem cells","Internet;data visualisation;learning (artificial intelligence);medical image processing;microscopy","TB-sized images;cell microscopy;interactive Web visualizations;machine learning;stem cell colonies","","0","","","","","27-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Application of Machine Learning to Algorithm Selection for TSP","J. Pihera; N. Musliu","Vienna PhD Sch. of Inf., Vienna Univ. of Technol., Vienna, Austria","2014 IEEE 26th International Conference on Tools with Artificial Intelligence","20141215","2014","","","47","54","The Travelling Salesman Problem (TSP) has been extensively studied in the literature and various solvers are available. However, none of the state-of-the-art solvers for TSP outperforms the others in all problem instances within a given time limit. Therefore, the prediction of the best performing algorithm can save computational resources and optimise the results. In this paper, the TSP is studied in context of automated algorithm selection. Our aim is to identify the relevant features of problem instances and tackle this scenario as a machine learning task. We extend the set of existing features in the literature and propose several novel features to better characterise the problem. The contribution of the new features is statistically analysed and experiments show that adding our new features improves the prediction accuracy. We identified that our features based on kNN graph transformation are especially helpful. To create the training datasets, two state-of-the-art (meta-) heuristic algorithms are systematically evaluated on more than 2000 problems. Overall, we show that our prediction can be substantially more accurate than simple preference of an algorithm with the best performance for a majority of problem instances.","1082-3409;10823409","Electronic:978-1-4799-6572-4; POD:978-1-4799-6573-1","10.1109/ICTAI.2014.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984454","TSP;algorithm selection;features;machine learning","Algorithm design and analysis;Clustering algorithms;Feature extraction;Machine learning algorithms;Prediction algorithms;Runtime;Training","graph colouring;graph grammars;learning (artificial intelligence);statistical analysis;travelling salesman problems","NP-hard problem;TSP;automated algorithm selection;computational resources;kNN graph transformation;machine learning;meta-heuristic algorithms;statistical analysis;travelling salesman problem","","2","","24","","","10-12 Nov. 2014","","IEEE","IEEE Conference Publications"
"Darwin, Lamarck, or Baldwin: Applying Evolutionary Algorithms to Machine Learning Techniques","A. Holzinger; D. Blanchard; M. Bloice; K. Holzinger; V. Palade; R. Rabadan","Res. Unit HCI, Inst. for Med. Inf., Stat. & Documentation, Graz, Austria","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","2","","449","453","Evolutionary Algorithms (EAs), inspired by biological mechanisms observed in nature, such as selection and genetic changes, have much potential to find the best solution for a given optimisation problem. Contrary to Darwin, and according to Lamarck and Baldwin, organisms in natural systems learn to adapt over their lifetime and allow to adjust over generations. Whereas earlier research was rather reserved, more recent research underpinned by the work of Lamarck and Baldwin, finds that these theories have much potential, particularly in upcoming fields such as epigenetics. In this paper, we report on some experiments with different evolutionary algorithms with the purpose to improve the accuracy of data mining methods. We explore whether and to what extent an optimisation goal can be reached through a calculation of certain parameters or attribute weightings by use of such evolutionary strategies. We provide a look at different EAs inspired by the theories of Darwin, Lamarck, and Baldwin, as well as the problem solving methods of certain species. In this paper we demonstrate that the modification of well-established machine learning techniques can be achieved in order to include methods from genetic algorithm theory without extensive programming effort. Our results pave the way for much further research at the cross section of machine learning optimisation techniques and evolutionary algorithm research.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927659","Data Mining;Evolutionary Algorithms;Machine Learning;Optimization","Biological cells;Evolution (biology);Evolutionary computation;Genetic algorithms;Genetics;Machine learning algorithms;Optimization","data mining;evolutionary computation;learning (artificial intelligence);problem solving","Baldwin theory;Darwin theory;EA;Lamarck theory;biological mechanisms;data mining;evolutionary algorithms;machine learning;natural systems;optimisation;problem solving","","0","","24","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Machine Learning to Data Fusion Approach for Cooperative Spectrum Sensing","A. M. Mikaeil; B. Guo; Z. Wang","Sch. of Electron. & Inf. Eng., Changchun Univ. of Sci. & Technol., Changchun, China","2014 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20141215","2014","","","429","434","Cooperative spectrum sensing has been shown to be an effective method to improve the detection performance of the licensed user availability by exploiting spatial diversity. However, cooperation among cognitive radio (CR) users may also introduce a variety of overheads due to the extra sensing time, delay, energy, and operations that limit achievable cooperative gain. In responding to this paper, we propose a machine learning based fusion center algorithm that can provide real time per frame training and decision based cooperative spectrum sensing. The new fusion algorithm based on training a machine learning classifier over a set containing some frame energy test statistics along with their corresponding decisions about the presence or absence of the primary user (PU) transmission, so as to predict the decisions for new frames with new energy test statistics. The simulation and numerical results show that the new approach performs the same as the current fusion rule with less sensing time, delay and operations. In this paper we also present a simulation comparison of four supervised machine learning classifiers: K-nearest neighbor (KNN), support vector machine (SVM), Naive Bayes (NB), and Decision Tree (DT) in classifying 1000 testing frames after training these classifiers over a set containing 1000 frames. It shows that KNN and DT classifier outperform the other two classifiers in the accuracy of classifying the new frames.","","Electronic:978-1-4799-6236-5; POD:978-1-4799-6237-2","10.1109/CyberC.2014.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984345","cooperative spectrum sensing;data fusion;machine learning classifier;per frame decision sensing","Accuracy;Data integration;Decision trees;Noise;Sensors;Support vector machines;Training","Bayes methods;cognitive radio;decision trees;learning (artificial intelligence);pattern classification;radio spectrum management;sensor fusion;signal detection;statistics;support vector machines;telecommunication computing","DT classifier;K-nearest neighbor;KNN classifier;NB classifier;Naive Bayes;SVM;cognitive radio;data fusion approach;decision based cooperative spectrum sensing;decision tree;frame energy test statistics;machine learning based fusion center algorithm;primary user transmission;supervised machine learning classifiers;support vector machine","","0","","15","","","13-15 Oct. 2014","","IEEE","IEEE Conference Publications"
"A hybrid wind speed forecasting strategy based on Hilbert-Huang transform and machine learning algorithms","N. Tomin; D. Sidorov; V. Kurbatsky; V. Spiryaev; A. Zhukov; P. Leahy","Melentiev Energy Systems Institute, Siberian Branch, Russian Academy of Sciences, Irkutsk, 664033, Russia","2014 International Conference on Power System Technology","20141222","2014","","","2980","2986","Precise wind resource assessment is one of the more imminent challenges. In the present work, we develop an adaptive approach to wind speed forecasting. The approach is based on a combination of the efficient apparatus of non-stationary time series of wind speed retrospective data analysis based on the Hilbert-Huang transform and machine learning models. Models that are examined include neural networks, support vector machines, the regression trees approach: random forest and boosting trees. Evaluation results are presented for the Irish power system based on the Atlantic offshore buoy data.","","Electronic:978-1-4799-5032-4; POD:978-1-4799-5033-1","10.1109/POWERCON.2014.6993990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993990","Hilbert-Huang transform;forecasting;machine learning;power systems;wind power","Data models;Forecasting;Predictive models;Wind forecasting;Wind power generation;Wind speed","Hilbert transforms;data analysis;learning (artificial intelligence);neural nets;regression analysis;support vector machines;time series;wind power","Hilbert-Huang transform;boosting trees;hybrid wind speed forecasting strategy;machine learning algorithms;neural networks;nonstationary time series;precise wind resource assessment;random forest;regression trees;support vector machines;wind speed retrospective data analysis","","0","","26","","","20-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"Sentiment Classification at the Time of the Tunisian Uprising: Machine Learning Techniques Applied to a New Corpus for Arabic Language","J. Akaichi","Comput. Sci. Dept., ISG-Univ. of Tunis, Le Bardo, Tunisia","2014 European Network Intelligence Conference","20141215","2014","","","38","45","Sentiment analysis is the field of study that analyzes people's opinions, sentiments, attitudes, and emotions from written language. It is one of the most active research areas in natural language processing and is also widely studied in data mining, web mining, and text mining. In recent years, text mining and sentiment analysis are being in almost every business and social domain which study all human activities and key influencers of our behaviors. Even though there are, at present, several studies related to this theme, most of them focus mainly on English texts. The resources available for opinion mining in other languages, such as Arabic, are still limited. In this paper, we propose a new sentiment analysis system destined to classify users' opinions which is performed with a new corpus for Arabic language gathered from users' posts at the time of the Tunisian revolution. Furthermore, different experiments have been carried out on this corpus, using machine learning algorithms such as Support Vector Machines and Naïve Bayes.","","Electronic:978-1-4799-6914-2; POD:978-1-4799-6915-9; USB:978-1-4799-6913-5","10.1109/ENIC.2014.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984888","Abstract Sentiment analysis is the field of study that analyzes","Facebook;Sentiment analysis;Support vector machines;Testing;Text mining","Bayes methods;behavioural sciences computing;data mining;learning (artificial intelligence);natural language processing;pattern classification;support vector machines","Arabic language;English texts;Tunisian revolution;Tunisian uprising;behaviors;human activities;machine learning techniques;naïve Bayes;natural language processing;opinion mining;people attitudes;people emotions;people opinions;people sentiments;sentiment analysis;sentiment classification;support vector machines;text mining;users opinions classification;written language","","1","","34","","","29-30 Sept. 2014","","IEEE","IEEE Conference Publications"
"Decoding color of stimuli given to a human subject from functional magnetic resonance imaging voxel patterns using machine learning algorithm","N. Koike; Y. Hatakeyama; S. Yoshida","Information Systems Engineering Course, Kochi University of technology, Japan","2014 World Automation Congress (WAC)","20141027","2014","","","681","686","A brain decoding of visual stimuli using various machine learning is proposed in order to make a foundation of brain computer interface. Visual stimuli that are representations of objects, shapes, colors, and so on, are important information for human perception. Some of properties of processing of visual information in human brain are revealed, for example existence of neuron responding an orientation of line segment. This research reveals the precision of pattern recognition using supervised machine learning of human brain activity when human see color circle drawn In a display. Support vector machine with various kernel, neural network, random forest, and sparse logistic regression are employed in this research and compared among each other. The result shows that the highest precision Is 71% for predicting color of circle from three colors using sparse logistic regression.","2154-4824;21544824","Electronic:978-1-8893-3549-0; POD:978-1-4799-7255-5; USB:978-1-8893-3550-6","10.1109/WAC.2014.6936100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936100","","Accuracy;Educational institutions;Frequency modulation;Kernel;Supervised learning;Support vector machines;Visualization","biomedical MRI;brain;brain-computer interfaces;learning (artificial intelligence);support vector machines","brain computer interface;brain decoding;functional magnetic resonance imaging voxel patterns;human brain activity;human perception;machine learning algorithm;neural network;pattern recognition;random forest;sparse logistic regression;supervised machine learning;support vector machine;visual stimuli","","0","","21","","","3-7 Aug. 2014","","IEEE","IEEE Conference Publications"
"Improving the performance of machine learning classifiers for Breast Cancer diagnosis based on feature selection","N. Pérez; M. A. Guevara; A. Silva; I. Ramos; J. Loureiro","Institute of Mechanical Engineering and Industrial Management (INEGI), Campus da FEUP, 4200-465 Porto, Portugal","2014 Federated Conference on Computer Science and Information Systems","20141023","2014","","","209","217","This paper proposed a comprehensive algorithm for building machine learning classifiers for Breast Cancer diagnosis based on the suitable combination of feature selection methods that provide high performance over the Area Under receiver operating characteristic Curve (AUC). The new developed method allows both for exploring and ranking search spaces of image-based features, and selecting subsets of optimal features for feeding Machine Learning Classifiers (MLCs). The method was evaluated using six mammography-based datasets (containing calcifications and masses lesions) with different configurations extracted from two public Breast Cancer databases. According to the Wilcoxon Statistical Test, the proposed method demonstrated to provide competitive Breast Cancer classification schemes reducing the number of employed features for each experimental dataset.","","Electronic:978-83-60810-58-3; POD:978-1-4799-2853-8; USB:978-8-3608-1057-6","10.15439/2014F249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933015","","Breast cancer;Databases;Feature extraction;Lesions;Niobium;Support vector machines","cancer;feature selection;image classification;learning (artificial intelligence);mammography;medical image processing;statistical testing","AUC;MLC;Wilcoxon statistical test;area under receiver operating characteristic curve;breast cancer diagnosis;calcifications;feature selection methods;machine learning classifiers;mammography-based datasets;masses lesions;public breast cancer databases","","2","","50","","","7-10 Sept. 2014","","IEEE","IEEE Conference Publications"
"Design and Implementation of Multiple-Vehicle Detection and Tracking Systems with Machine Learning","S. F. Hsiao; G. F. Yeh; J. C. Chen","Dept. of Comput. Sci. & Eng., Nat. Sun Yat-Sen Univ., Kaohsiung, Taiwan","2014 17th Euromicro Conference on Digital System Design","20141020","2014","","","551","558","A vehicle detection system is realized in two stages: hypothesis generation (HG) and hypothesis verification (HV). HG adopts frame division and shadow detection to find possible candidates of vehicles within a plausible region of the image frame. Then, during HV, object ratio constraint is first used to eliminate unreasonable hypotheses. Afterward, based on the training results of the support vector machine (SVM) with the proposed vehicle feature extraction, the kernel function is found and employed in the classifier to find the real vehicles. Both pure software and combined software/hardware (SW/HW) implementations of the proposed vehicle detection system are presented where the combined SW/HW implementation can achieve correct detection rate of more than 90% in most test conditions.","","Electronic:978-1-4799-5793-4; POD:978-1-4799-7135-0","10.1109/DSD.2014.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927290","driver-assisted system (DAS);support vector machine;vehicle detection","Feature extraction;Hardware;Image edge detection;Support vector machines;Training;Vehicle detection;Vehicles","feature extraction;image classification;intelligent transportation systems;learning (artificial intelligence);object detection;object tracking;support vector machines;traffic engineering computing","HG stage;HV stage;SVM;feature classification;hypothesis generation stage;hypothesis verification stage;image frame;kernel function;machine learning;multiple vehicle detection system;multiple vehicle tracking system;object ratio constraint;software-hardware implementation;support vector machine;vehicle feature extraction","","0","","14","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"Putting the Scientist in the Loop -- Accelerating Scientific Progress with Interactive Machine Learning","O. M. Aodha; V. Stathopoulos; G. J. Brostow; M. Terry; M. Girolami; K. E. Jones","Dept. of Comput. Sci., Univ. Coll. London, London, UK","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","9","17","Technology drives advances in science. Giving scientists access to more powerful tools for collecting and understanding data enables them to both ask and answer new kinds questions that were previously beyond their reach. Of these new tools at their disposal, machine learning offers the opportunity to understand and analyze data at unprecedented scales and levels of detail. The standard machine learning pipeline consists of data labeling, feature extraction, training, and evaluation. However, without expert machine learning knowledge, it is difficult for scientists to optimally construct this pipeline to fully leverage machine learning in their work. Using ecology as a motivating example, we analyze a typical scientist's data collection and processing workflow and highlight many problems facing practitioners when attempting to capitalize on advances in machine learning and pattern recognition. Understanding these shortcomings allows us to outline several novel and underexplored research directions. We end with recommendations to motivate progress in future cross-disciplinary work.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976724","biodiversity;computer vision;data visualization;ecology;human-computer interaction;interactive machine learning","Biological system modeling;Data models;Educational institutions;Feature extraction;Labeling;Pipelines;Training","data analysis;feature extraction;learning (artificial intelligence)","data analysis;data evaluation;data labeling;data training;feature extraction;interactive machine learning;pattern recognition","","1","","75","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"SQL Injection detection using machine learning","A. Joshi; V. Geetha","Dept. of Information Technology, National Institute of Technology, Karnataka, Surathkal, India","2014 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT)","20141222","2014","","","1111","1115","In the present world, the web is the firmest and most common medium of communication and business interchange. Every day, millions of data are loaded through various channels on the web by users and user input can be malicious. Therefore, security becomes a very important aspect of web applications. Since they are easily accessible, they are prone to many vulnerabilities which if neglected can cause harm. The attackers make use of these loopholes to gain unauthorized access by performing various illegal activities. SQL Injection is one such attack which is easy to perform but difficult to detect because of its varied types and channel. This may result in theft, leak of personal data or loss of property. In this paper we have analyzed the existing solutions to the problems such as AMNESIA [1] and SQLrand [3] and their limitations. We have devised a classifier for detection of SQL Injection attacks. The proposed classifier uses combination of Naïve Bayes machine learning algorithm and Role Based Access Control mechanism for detection. The proposed model is tested based on the test cases derived from the three SQLIA attacks: comments, union and tautology.","","CD-ROM:978-1-4799-4193-3; Electronic:978-1-4799-4190-2; POD:978-1-4799-4189-6","10.1109/ICCICCT.2014.6993127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993127","Machine Learning;Web Application;Web Security","Accuracy;Classification algorithms;Feature extraction;Instruments;Machine learning algorithms;Pattern matching;Security","Bayes methods;Internet;SQL;Web sites;authorisation;learning (artificial intelligence)","AMNESIA;Naive Bayes machine learning algorithm;SQL injection attack detection;SQLrand;Web applications;business interchange;illegal activities;loopholes;personal data leak;role based access control mechanism;unauthorized access","","2","","8","","","10-11 July 2014","","IEEE","IEEE Conference Publications"
"Machine learning approach for correcting preposition errors using SVD features","A. Aravind; A. K. M","Centre for Excellence in Computational Engineering and Networking, Amrita Vishwa Vidyapeetham, Coimbatore, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20141201","2014","","","1731","1736","Non-native English writers often make preposition errors in English language. The most commonly occurring preposition errors are preposition replacement, preposition missing and unwanted preposition. So, in this method, a system is developed for finding and handling the English preposition errors in preposition replacement case. The proposed method applies 2-Singular Value Decomposition (SVD<sup>2</sup>) concept for data decomposition resulting in fast calculation and these features are given for classification using Support Vector Machines (SVM) classifier which obtains an overall accuracy above 90%. Features are retrieved using novel SVD<sup>2</sup> based method applied on trigrams which is having a preposition in the middle of the context. A matrix with the left and right vectors of each word in the trigram is computed for applying SVD<sup>2</sup> concept and these features are used for supervised classification. Preliminary results show that this novel feature extraction and dimensionality reduction method is the appropriate method for handling preposition errors.","","Electronic:978-1-4799-3080-7; POD:978-1-4799-3081-4; USB:978-1-4799-3079-1","10.1109/ICACCI.2014.6968552","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968552","Preposition error correction;Singular Value Decomposition;Support Vector Machines","Context;Manuals;Support vector machines;Vectors","feature extraction;learning (artificial intelligence);matrix algebra;natural language processing;pattern classification;singular value decomposition;support vector machines","2-singular value decomposition;English language;English preposition errors;SVD<sup>2</sup>;SVM classifier;data decomposition;dimensionality reduction;feature extraction;machine learning;matrix vectors;nonnative English writers;preposition errors correction;preposition missing;preposition replacement;supervised classification;support vector machines classifier;trigrams;unwanted preposition","","0","","19","","","24-27 Sept. 2014","","IEEE","IEEE Conference Publications"
"Spectrum Decision in Wireless Sensor Networks Employing Machine Learning","V. F. Silva; D. F. Macedo; J. L. Leoni","Comput. Sci. Dept., Univ. Fed. de Minas Gerais, Belo Horizonte, Brazil","2014 Brazilian Symposium on Computer Networks and Distributed Systems","20141020","2014","","","386","393","Wireless Sensor Networks (WSNs) employ ISM spectrum bands for communication, which are overloaded due to various technologies such as WLANs and other WSNs. Therefore, such networks must employ intelligent methods such as Cognitive Radio to coexist with other networks. This study evaluates the use of Supervised Machine Learning (ML) for channel selection in WSNs, considering the channel quality and communication metrics. The methods were evaluated experimentally and compared with energy-based methods. The results show that ML-based methods increase the communication performance by reducing the number of transmission attempts and therefore also reducing the delivery delay.","","Electronic:978-1-4799-5612-8; POD:978-1-4799-5613-5","10.1109/SBRC.2014.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927158","Cognitive Radio;Machine Learning;Wireless Sensor Networks","Additives;IEEE 802.11 Standards;Irrigation;Quality of service;RNA;Regression tree analysis;Wireless sensor networks","cognitive radio;learning (artificial intelligence);radio spectrum management;telecommunication computing;wireless channels;wireless sensor networks","ISM spectrum bands;ML-based methods;WLANs;WSNs;channel quality;channel selection;cognitive radio;communication metrics;delivery delay;spectrum decision;supervised machine learning;wireless sensor networks","","0","","","","","5-9 May 2014","","IEEE","IEEE Conference Publications"
"Machine learning-based jamming detection for IEEE 802.11: Design and experimental evaluation","O. Puñal; I. Aktaş; C. J. Schnelke; G. Abidin; K. Wehrle; J. Gross","Communication and Distributed Systems, RWTH Aachen University, Germany","Proceeding of IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks 2014","20141009","2014","","","1","10","Jamming is a well-known reliability threat for mass-market wireless networks. With the rise of safety-critical applications this is likely to become a constraining issue in the future. Thus, the design of accurate jamming detection algorithms becomes important to react to ongoing jamming attacks. With respect to experimental work, jamming detection has been mainly studied for sensor networks. However, many safety-critical applications are also likely to run over 802.11-based networks where the proposed approaches do not carry over. In this paper we present a jamming detection approach for 802.11 networks. It uses metrics that are accessible through standard device drivers and performs detection via machine learning. While it allows for stand-alone operation, it also enables cooperative detection. We experimentally show that our approach achieves remarkably high detection rates in indoor and mobile outdoor scenarios even under challenging link conditions.","","Electronic:978-1-4799-4786-7; POD:978-1-4799-4785-0; USB:978-1-4799-4787-4","10.1109/WoWMoM.2014.6918964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918964","","Accuracy;Context;Crawlers;IEEE 802.11 Standards;Jamming;Measurement;Noise","cooperative communication;jamming;learning (artificial intelligence);telecommunication network reliability","IEEE 802.11;cooperative detection;jamming attacks;jamming detection algorithms;machine learning;mass-market wireless networks;sensor networks","","1","","24","","","19-19 June 2014","","IEEE","IEEE Conference Publications"
"Multi-layer hybrid machine learning techniques for anomalies detection and classification approach","A. S. A. Aziz; A. E. Hassanien; S. E. O. Hanaf; M. F. Tolba","Universite Francaise d'Egypte (UFE), Cairo, Egypt","13th International Conference on Hybrid Intelligent Systems (HIS 2013)","20141013","2013","","","215","220","Intrusion detection systems (IDS) are well-known research area for the detection of anomalous activities in a system from both inside and outside intruders. In this article, a multi-layer hybrid machine learning intrusion detection system is designed and developed to achieve high efficiency and improve the detection and classification rate accuracy inspired by immune systems with negative selection approach. In the first layer, principal component analysis (PCA) algorithm was used for feature selection. Then, genetic algorithm was applied to generate anomaly detectors, which are able to discriminate between normal and anomalous behaviors in the second layer. It is followed by applying classification using several classifiers including naive bayes, multilayer perceptron neural network, and decision trees to increase the detection accuracy and obtain more information on the detected anomalies. The selected classifiers are trained and applied to label the detected anomalies in both the normal and anomalous traffic. The principle interest of this work is to benchmark the performance of the proposed multi-layer IDS system by using NSL-KDD benchmark data set used by IDS researchers. The obtained results demonstrated that naive bayes classifier has better classification accuracy in the case of lower presented attacks such as U2R and R2L, while the J48 decision tree classifier gives high accuracy up to 82% for DoS attacks and 65.4% for probe attacks in the anomaly traffic.","","Electronic:978-1-4799-2439-4; POD:978-1-4799-2440-0","10.1109/HIS.2013.6920485","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6920485","Artificial Immune System;Intrusion Classification;Machine Learning;Network Intrusion Detection","Niobium;Probes","Bayes methods;computer network security;decision trees;feature selection;genetic algorithms;learning (artificial intelligence);pattern classification;principal component analysis;telecommunication traffic","DoS attacks;IDS;J48 decision tree classifier;NSL-KDD benchmark data set;PCA algorithm;R2L;U2R;anomalies detection;anomalous traffic;anomaly detectors;classification approach;feature selection;genetic algorithm;immune systems;multilayer hybrid machine learning intrusion detection system;multilayer perceptron neural network;naive Bayes classifier;negative selection approach;normal traffic;principal component analysis algorithm;probe attacks","","1","","25","","","4-6 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Augmented Lagrangian Method for l2,1-Norm Minimization Problems in Machine Learning","L. Shulun; L. Jie","Jiyuan Vocational & Tech. Coll., Jiyuan, China","2014 Fifth International Conference on Intelligent Systems Design and Engineering Applications","20141206","2014","","","138","140","In the fields of computer version, text classification and biomedical informatics, it needs to find the joint feature among serval learning tasks. Generally, resent results show that it can be realized by solving a ℓ<sub>2,1</sub>-norm minimization problem. However, due to the non-smoothness of the norm, solving the resulting optimization problem is always challenging. This thesis designs an augmented Lagrange function method which is used to solve ℓ<sub>2,1</sub>-norm minimization problem. In this thesis the convergence property of the algorithm is discussed. The numerical experiments indicate that the convergence of this algorithm is easily followed and the algorithm's executing efficiency is very good.","","CD-ROM:978-1-4799-4262-6; Electronic:978-1-4799-4261-9; POD:978-1-4799-7889-2","10.1109/ISDEA.2014.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977563","augmented Lagrangian function;machine learning;multi-task feature learning;real data set","Algorithm design and analysis;Convergence;Joints;Lagrangian functions;Machine learning algorithms;Minimization;Training","bioinformatics;learning (artificial intelligence);minimisation;text analysis","ℓ<sub>2,1</sub>-norm minimization problems;augmented Lagrangian method;biomedical informatics;computer version;machine learning;optimization problem;text classification","","0","","9","","","15-16 June 2014","","IEEE","IEEE Conference Publications"
"Implementation of a fast coral detector using a supervised machine learning and Gabor Wavelet feature descriptors","E. Tusa; A. Reynolds; D. M. Lane; N. M. Robertson; H. Villegas; A. Bosnjak","Unidad Academica de Ingenier&#x00ED;a Civil, Universidad Tecnica de Machala, Machala, Ecuador","2014 IEEE Sensor Systems for a Changing Ocean (SSCO).","20150105","2014","","","1","6","The task of reef restoration is very challenging for volunteer SCUBA divers, if it has to be carried out at deep sea, 200 meters, and low temperatures. This kind of task can be properly performed by an Autonomous Underwater Vehicle (AUV); able to detect the location of reef areas and approach them. The aim of this study is the development of a vision system for coral detections based on supervised machine learning. In order to achieve this, we use a bank of Gabor Wavelet filters to extract texture feature descriptors, we use learning classifiers, from OpenCV library, to discriminate coral from non-coral reef. We compare: running time, accuracy, specificity and sensitivity of nine different learning classifiers. We select Decision Trees algorithm because it shows the fastest and the most accurate performance. For the evaluation of this system, we use a database of 621 images (developed for this purpose), that represents the coral reef located in Belize: 110 for training the classifiers and 511 for testing the coral detector.","","Electronic:978-1-4799-5948-8; POD:978-1-4799-5949-5","10.1109/SSCO.2014.7000371","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000371","","Accuracy;Decision trees;Feature extraction;Image color analysis;Machine learning algorithms;Support vector machines;Vectors","Gabor filters;autonomous underwater vehicles;decision trees;learning (artificial intelligence);oceanographic equipment;oceanographic techniques","AUV;Belize;Gabor wavelet feature descriptor;Gabor wavelet filter;OpenCV library;autonomous underwater vehicle;coral detector testing;decision tree algorithm;deep sea;fast coral detector implementation;image database;learning classifier;learning classifier accuracy;learning classifier running time;learning classifier sensitivity;learning classifier specificity;noncoral reef discrimination;reef area location detection;reef restoration task;supervised machine learning;system evaluation;texture feature descriptor extraction;vision system development;volunteer SCUBA diver","","3","","18","","","13-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"A 1 TOPS/W Analog Deep Machine-Learning Engine With Floating-Gate Storage in 0.13 µm CMOS","J. Lu; S. Young; I. Arel; J. Holleman","Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, United States","IEEE Journal of Solid-State Circuits","20141224","2015","50","1","270","281","An analog implementation of a deep machine-learning system for efficient feature extraction is presented in this work. It features online unsupervised trainability and non-volatile floating-gate analog storage. It utilizes a massively parallel reconfigurable current-mode analog architecture to realize efficient computation, and leverages algorithm-level feedback to provide robustness to circuit imperfections in analog signal processing. A 3-layer, 7-node analog deep machine-learning engine was fabricated in a 0.13 μm standard CMOS process, occupying 0.36 mm 2 active area. At a processing speed of 8300 input vectors per second, it consumes 11.4 μW from the 3 V supply, achieving 1×10 12 operation per second per Watt of peak energy efficiency. Measurement demonstrates real-time cluster analysis, and feature extraction for pattern recognition with 8-fold dimension reduction with an accuracy comparable to the floating-point software simulation baseline.","0018-9200;00189200","","10.1109/JSSC.2014.2356197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6919341","Analog signal processing;current mode arithmetic;deep machine learning;floating gate;neuromorphic engineering;translinear circuits","Computer architecture;Engines;Feature extraction;Learning systems;Logic gates;Training;Tunneling","CMOS digital integrated circuits;feature extraction;pattern clustering;random-access storage;real-time systems;unsupervised learning","8-fold dimension reduction;algorithm-level feedback;analog signal processing;deep machine-learning engine;feature extraction;floating-point software simulation baseline;massively parallel reconfigurable current-mode analog architecture;nonvolatile floating-gate analog storage;online unsupervised trainability;pattern recognition;power 11.4 muW;real-time cluster analysis;size 0.13 mum;standard CMOS process;voltage 3 V","","11","","30","","20141009","Jan. 2015","","IEEE","IEEE Journals & Magazines"
"A Machine Learning Approach for Dead-Reckoning Navigation at Sea Using a Single Accelerometer","R. Diamant; Y. Jin","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, Canada","IEEE Journal of Oceanic Engineering","20141009","2014","39","4","672","684","Dead-reckoning (DR) navigation is used when Global Positioning System (GPS) reception is not available or its accuracy is not sufficient. At sea, DR requires the use of inertial sensors, usually a gyrocompass and an accelerometer, to estimate the orientation and distance traveled by the tracked object with respect to a reference coordinate system. In this paper, we consider the problem of DR navigation for vessels located close to or on the sea surface, where motion is caused by ocean waves. In such cases, the vessel pitch angle is fast time varying and its estimation by direct measurements of orientation is prone to drifts and noises of the gyroscope. Regarding this problem, we propose a method to compensate for the vessel pitch angle using a single acceleration sensor. Using a constraint expectation-maximization (EM) algorithm, our method classifies acceleration measurements into states of similar pitch angles. Subsequently, for each class, we project acceleration measurements into the reference coordinate system along the vessel heading direction, and obtain distance estimations by integrating the projected measurements. Results in both simulated and actual sea environments demonstrate that, by using only acceleration measurements, our method achieves accurate results.","0364-9059;03649059","","10.1109/JOE.2013.2279421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6646319","Dead reckoning (DR);expectation–maximization (EM) classification;naval navigation","Accelerometers;Dead reckoning;Expectation-maximization algorithms;Machine learning;Marine navigation;Noise measurement","acceleration measurement;accelerometers;compasses;compensation;computerised instrumentation;distance measurement;expectation-maximisation algorithm;geophysics computing;gyroscopes;inertial navigation;inertial systems;learning (artificial intelligence);object tracking;ocean waves;oceanographic equipment;position measurement","DR navigation;acceleration measurement;acceleration sensor;accelerometer;constraint EM algorithm;dead reckoning navigation;distance estimation;expectation-maximization algorithm;gyrocompass;gyroscope;inertial sensor;machine learning approach;object tracking;ocean wave;orientation measurement;reference coordinate system;sea surface;vessel heading direction estimation;vessel pitch angle compensation","","2","","25","","20131024","Oct. 2014","","IEEE","IEEE Journals & Magazines"
"Prediction of magnetic remanence of NdFeB magnets by using novel machine learning intelligence approach — Support vector regression","W. Cheng","School of Mathsmatics and Physics, Chongqing University of Sceince and Technology, Chongqing, China","2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing","20141016","2014","","","431","435","A novel model using support vector regression (SVR) combined with particle swarm optimization (PSO) integrating leave-one-out cross validation (LOOCV) was employed to construct mathematical model for prediction of the magnetic remanence of the NdFeB magnets. The leave-one-out cross validation of SVR model test results show that the mean absolute error doesnot exceed 0.0036, the mean absolute percentage error is only 0.53%, and the correlation coefficient (R<sup>2</sup>) is as high as 0.839. This investigation suggests that the SVR-LOOCV is not only an effective and practical method to simulate the remanence of NdFeB, but also a powerful tool to optimize designing or controlling the experimental process.","","Electronic:978-1-4799-6081-1; POD:978-1-4799-6082-8","10.1109/ICCI-CC.2014.6921494","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921494","NdFeB magnet;Support vector regression;machine learning intelligence;regression analysis","Alloying;Mathematical model;Particle swarm optimization;Predictive models;Remanence;Superconducting magnets;Support vector machines","materials science computing;particle swarm optimisation;permanent magnets;rare earth metals;regression analysis;support vector machines","LOOCV;NdFeB;PSO;SVR;correlation coefficient;leave-one-out cross validation;machine learning intelligence approach;magnetic remanence prediction;mean absolute percentage error;particle swarm optimization;rare earth permanent magnet;support vector regression","","0","","13","","","18-20 Aug. 2014","","IEEE","IEEE Conference Publications"
"Machine learning and image processing in astronomy with sparse data sets","J. Jenkinson; A. Grigoryan; M. Hajinoroozi; R. Díaz Hernández; H. Peregrina Barreto; A. Ortiz Esquivel; L. Altamirano; V. Chavushyan","Department of Electrical and Computer Engineering, University of Texas at San Antonio, 78249, USA","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","200","203","Automated classification systems have allowed for the rapid development of digital large sky surveys. Such systems increase the independence of human intervention in the analysis stage of star and galaxy classification. Artificial neural networks, hierarchical classifiers and ensembles of classifiers have been used as the methods of classification in these systems. This paper investigates the development of an automated classification system for galaxies in astronomical images based on the method of sparse representation. The dependency of classification based on image enhancement by the alpha-rooting, heap-, and paired-transforms is secondarily investigated.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973907","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973907","","Conferences;Cybernetics;Nickel","astronomical image processing;galaxies;image classification;image enhancement;image representation;learning (artificial intelligence);stars;transforms","alpha-rooting;artificial neural networks;astronomical images;automated classification systems;classifier ensembles;digital large sky surveys;galaxy classification;heap-transforms;hierarchical classifiers;image enhancement;paired-transforms;sparse representation;star classification","","1","","15","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Machine Learning System to Improve Heart Failure Patient Assistance","G. Guidi; M. C. Pettenati; P. Melillo; E. Iadanza","Department of Information Engineering, University of Florence, Florence, Italy","IEEE Journal of Biomedical and Health Informatics","20141103","2014","18","6","1750","1756","In this paper, we present a clinical decision support system (CDSS) for the analysis of heart failure (HF) patients, providing various outputs such as an HF severity evaluation, HF-type prediction, as well as a management interface that compares the different patients' follow-ups. The whole system is composed of a part of intelligent core and of an HF special-purpose management tool also providing the function to act as interface for the artificial intelligence training and use. To implement the smart intelligent functions, we adopted a machine learning approach. In this paper, we compare the performance of a neural network (NN), a support vector machine, a system with fuzzy rules genetically produced, and a classification and regression tree and its direct evolution, which is the random forest, in analyzing our database. Best performances in both HF severity evaluation and HF-type prediction functions are obtained by using the random forest algorithm. The management tool allows the cardiologist to populate a “supervised database” suitable for machine learning during his or her regular outpatient consultations. The idea comes from the fact that in literature there are a few databases of this type, and they are not scalable to our case.","2168-2194;21682194","","10.1109/JBHI.2014.2337752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6851844","Heart failure (HF);machine learning;telemonitoring","Artificial intelligence;Biomedical monitoring;Decision support systems;Machine learning;Medical treatment;Support vector machines","cardiology;decision support systems;fuzzy neural nets;learning (artificial intelligence);medical disorders;medical information systems;patient monitoring;random processes;regression analysis;support vector machines;telemedicine;user interfaces","CDSS;HF severity evaluation;HF special-purpose management tool;HF-type prediction functions;NN;artificial intelligence training;cardiologist;classification;clinical decision support system;direct evolution;fuzzy rules;heart failure patient analysis;heart failure patient assistance;intelligent core;machine learning system;management interface;neural network;patient follow-ups;random forest algorithm;regression tree;regular outpatient consultations;smart intelligent functions;supervised database;support vector machine","0","4","","22","","20140710","Nov. 2014","","IEEE","IEEE Journals & Magazines"
"Learning machines for computational epidemiology","M. Boman; D. Gillblad","SICS Swedish ICT and KTH/ICT/SCS, Electrum, SE-16429 Kista, Sweden","2014 IEEE International Conference on Big Data (Big Data)","20150108","2014","","","1","5","Resting on our experience of computational epidemiology in practice and of industrial projects on analytics of complex networks, we point to an innovation opportunity for improving the digital services to epidemiologists for monitoring, modeling, and mitigating the effects of communicable disease. Artificial intelligence and intelligent analytics of syndromic surveillance data promise new insights to epidemiologists, but the real value can only be realized if human assessments are paired with assessments made by machines. Neither massive data itself, nor careful analytics will necessarily lead to better informed decisions. The process producing feedback to humans on decision making informed by machines can be reversed to consider feedback to machines on decision making informed by humans, enabling learning machines. We predict and argue for the fact that the sensemaking that such machines can perform in tandem with humans can be of immense value to epidemiologists in the future.","","Electronic:978-1-4799-5666-1; POD:978-1-4799-5667-8","10.1109/BigData.2014.7004419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004419","","Big data;Computational modeling;Data models;Diseases;Sociology;Statistics;Surveillance","complex networks;decision making;diseases;feedback;learning (artificial intelligence);monitoring","artificial intelligence;communicable disease;complex networks;computational epidemiology;decision making;digital services;feedback;human assessments;machine learning;monitoring;syndromic surveillance data","","1","","38","","","27-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Comparison of machine learning methods for estimating energy consumption in buildings","E. Mocanu; P. H. Nguyen; M. Gibescu; W. L. Kling","Eindhoven University of Technology, Department of Electrical Engineering, 5600 MB Eindhoven, The Netherlands","2014 International Conference on Probabilistic Methods Applied to Power Systems (PMAPS)","20141120","2014","","","1","6","The increasing number of decentralized renewable energy sources together with the grow in overall electricity consumption introduce many new challenges related to dimensioning of grid assets and supply-demand balancing. Approximately 40% of the total energy consumption is used to cover the needs of commercial and office buildings. To improve the design of the energy infrastructure and the efficient deployment of resources, new paradigms have to be thought up. Such new paradigms need automated methods to dynamically predict the energy consumption in buildings. At the same time these methods should be easily expandable to higher levels of aggregation such as neighborhoods and the power grid. Predicting energy consumption for a building is complex due to many influencing factors, such as weather conditions, performance and settings of heating and cooling systems, and the number of people present. In this paper, we investigate a newly developed stochastic model for time series prediction of energy consumption, namely the Conditional Restricted Boltzmann Machine (CRBM), and evaluate its performance in the context of building automation systems. The assessment is made on a real dataset consisting of 7 weeks of hourly resolution electricity consumption collected from a Dutch office building. The results showed that for the energy prediction problem solved here, CRBM outperforms Artificial Neural Networks (ANNs), and Hidden Markov Models (HMMs).","","Electronic:978-1-4799-3561-1; POD:978-1-4799-3562-8","10.1109/PMAPS.2014.6960635","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6960635","Artificial Neural Networks;Conditional Restricted Boltzmann Machines;Energy prediction;Hidden Markov Models;Stochastic method","Artificial neural networks;Buildings;Energy consumption;Hidden Markov models;Lighting;Mathematical model;Neurons","Boltzmann machines;building management systems;cooling;demand side management;heating;learning (artificial intelligence);power consumption;power engineering computing;power grids;stochastic processes;time series","ANN;CRBM;Dutch office building;HMM;artificial neural networks;automated methods;building automation system;building energy consumption estimation;conditional restricted Boltzmann machine;cooling system;decentralized renewable energy sources;electricity consumption;energy infrastructure;heating system;hidden Markov model;machine learning methods;power grid assets;stochastic model;supply-demand balancing;time series prediction","","5","","26","","","7-10 July 2014","","IEEE","IEEE Conference Publications"
"An impact analysis: Real time DDoS attack detection and mitigation using machine learning","B. S. Kiruthika Devi; G. Preetha; G. Selvaram; S. Mercy Shalinie","Dept. of Computer Science and Engineering, Thiagarajar College of Engineering, Affiliated to Anna University, Thiruparankundram, Madurai, Tamilnadu, India, 625 015","2014 International Conference on Recent Trends in Information Technology","20141229","2014","","","1","7","Distributed Denial of service (DDoS) attacks is the most devastating attack which tampers the normal functionality of critical services in internet community. DDoS cyber weapon is highly motivated by several aspects including hactivitism, personal revenge, anti-government force, disgruntled employers/customers, ideological and political cause, cyber espionage and so on. IP spoofing is the powerful technique used by attackers to disrupt the availability of services in the internet network by impersonating as a trusted source. Since the spoofed traffic shares the same resources as that of the legitimate one's detection and filtering becomes very essential. The proposed model consists of online monitoring system (OMS), spoofed traffic detection module and interface based rate limiting (IBRL) algorithm. OMS provides DDoS impact measurements in real time by monitoring the degradation in host and network performance metrics. The spoofed traffic detection module incorporates hop count inspection algorithm (HCF) to check the authenticity of incoming packet by means of source IP address and its corresponding hops to destined victim. HCF coupled with support vector machine (SVM) provides 98.99% accuracy with reduced false positive. Followed with, IBRL algorithm restricts the traffic aggregates at victim router when exceeding system limits in order to provide sufficient bandwidth for remaining flows.","","DVD:978-1-4799-4990-8; Electronic:978-1-4799-4989-2; POD:978-1-4799-7868-7","10.1109/ICRTIT.2014.6996133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996133","DDoS;IP spoofing;hop count inspection algorithm;rate limiting;support vector machine","Aggregates;Computer crime;Filtering;IP networks;Limiting;Measurement;Support vector machines","IP networks;Internet;computer network performance evaluation;computer network security;learning (artificial intelligence);support vector machines","DDoS cyber weapon;HCF;IBRL algorithm;IP spoofing;Internet community;Internet network;OMS;SVM;antigovernment force;cyber espionage;devastating attack;disgruntled employers;distributed denial of service attacks;hactivitism;hop count inspection algorithm;impact analysis;interface based rate limiting algorithm;machine learning;network performance metrics;normal functionality;online monitoring system;personal revenge;real time DDoS attack detection;real time DDoS attack mitigation;source IP address;spoofed traffic detection module;spoofed traffic shares;support vector machine","","0","","36","","","10-12 April 2014","","IEEE","IEEE Conference Publications"
"Machine-Learning-Based Identification of Defect Patterns in Semiconductor Wafer Maps: An Overview and Proposal","F. Adly; P. D. Yoo; S. Muhaidat; Y. Al-Hammadi","Dept. ECE, Khalifa Univ., Abu Dhabi, United Arab Emirates","2014 IEEE International Parallel & Distributed Processing Symposium Workshops","20141204","2014","","","420","429","Wafers are formed from very thin layers of a semiconductor material, hence, they are highly susceptible to various kinds of defects. The defects are most likely to occur during the lengthy and complex fabrication process, which can include hundreds of steps. Wafer defects are generally caused by machine inaccuracy, chemical stains, physical damages, human mistakes, and atmospheric conditions. The defective chips tend to have several unique spatial patterns across the wafer, namely ring, spot, repetitive and cluster patterns. To locate such defect patterns, wafer maps are used to visualize and ultimately lead to better understanding of what happened during the process failure. To identify the unique patterns of defects and to find the point of manufacturing process that causes such defects accurately, nature-inspired model-free machine-learning techniques have been well accepted. This paper thus reviews the theoretical and experimental literature of such models with a focus on model learnability and efficiency-related issues involving data reduction and transformation techniques, which could be seen as the key model properties to deal with big data applications.","","Electronic:978-1-4799-4116-2; POD:978-1-4799-4115-5","10.1109/IPDPSW.2014.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969418","and classification;nature-inspired machine-learning;wafer defect patterns;wafer map","Accuracy;Classification algorithms;Feature extraction;Pattern matching;Semiconductor device modeling;Support vector machines;Vectors","crystal defects;learning (artificial intelligence);semiconductor materials;semiconductor technology","defect patterns;machine learning based identification;process failure;semiconductor material;semiconductor wafer maps;wafer defects","","1","","26","","","19-23 May 2014","","IEEE","IEEE Conference Publications"
"A Machine Learning Approach to Detection of Core Region of Online Handwritten Bangla Word Samples","S. Baral; S. Bhattacharya; A. Chakraborty; U. Bhattacharya; S. K. Parui","Comput. Vision & Pattern Recognition Unit, Indian Stat. Inst., Kolkata, India","2014 14th International Conference on Frontiers in Handwriting Recognition","20141215","2014","","","458","463","Core region detection of handwritten cursive words is an important step towards their automatic recognition. Several preprocessing operations such as height normalization, slant estimation etc. Are often based on this core region. This is particularly useful for word recognition of major Indian scripts, which have large character sets. The main parts of majority of these characters belong to the core region that is bounded above by a headline and bounded below by an imaginary base line. Only a few such characters or their parts appear either above or below the core region. A few approaches are available in the literature for detection of such a core region of offline handwritten word samples of Latin script. Also, a similar region is often determined for recognition of images of printed Indian scripts. However, none of these approaches have studied detection of core region of an unconstrained online handwritten word. In this article, we propose a novel method for detection of the core region of online handwritten word samples of Bangla, a major Indian script. For this we first perform smoothing on the samples and then segment a stroke into sub strokes. We compute certain novel positional features from each such sub stroke. Using these features, a multilayer perceptron (MLP) is trained by back propagation (BP) algorithm. On the basis of the output of the MLP, we determine the position of both the headline and the baseline. We have tested this approach on a recently developed large database of online unconstrained handwriting Bangla word samples. The proposed approach would also work on similar samples of Devanagari, another major Indian script. Experimental results are encouraging.","2167-6445;21676445","Electronic:978-1-4799-4334-0; POD:978-1-4799-7892-2; USB:978-1-4799-4335-7","10.1109/ICFHR.2014.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981062","Detection of core region of handwritten words;Machine learning based appoach;Online handwriting recognition","Compounds;Databases;Feature extraction;Histograms;Shape;Training;Vectors","handwritten character recognition;learning (artificial intelligence);multilayer perceptrons;natural language processing;object recognition","BP;Devanagari;Indian script;Latin script;MLP;backpropagation algorithm;core region detection;handwritten cursive words;height normalization;imaginary base line;machine learning approach;multilayer perceptron;online handwritten Bangla word samples;printed Indian scripts;slant estimation;unconstrained online handwritten word;word recognition","","0","","14","","","1-4 Sept. 2014","","IEEE","IEEE Conference Publications"
"Combined passive radiofrequency identification and machine learning technique to recognize human motion","S. Amendola; L. Bianchi; G. Marrocco","University of Rome &#x201C;Tor Vergata&#x201D;, Roma, Italy","2014 44th European Microwave Conference","20141218","2014","","","1044","1047","Moving limbs within an electromagnetic field radiated by an interrogating antenna will generate a modulation of the backscattered field sensed by a receiver. The measured signals may therefore carry raw information about the human motion. Moreover, the proper placement of UHF passive Radiofrequency Identification (RFID) tags over body segments will increase the amount of collected signals. This paper investigate the potentiality of a possible synergy between Electromagnetics and Machine Learning technology at the purpose to recognize and classify, for the first time, the gestures of arms and legs by using only passive transponders. Electromagnetic signals backscattered from the tags during limb motion are collected by a fixed reader antenna and then processed by the Support Vector Machine (SVM) algorithm. Experimental results demonstrated a degree of accuracy in the classification of periodic movements that is fully comparable with that of more complex systems involving active wearable transponders.","","Electronic:978-2-8748-7035-4; POD:978-1-4799-5598-5","10.1109/EuMC.2014.6986617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986617","Body motion;Werable Antennas;classification;passive RFID sensors;wearable antennas Machine Learning","Antenna measurements;Antennas;Biomedical monitoring;Classification algorithms;Legged locomotion;Passive RFID tags","gesture recognition;learning (artificial intelligence);radiofrequency identification;support vector machines;telecommunication computing","RFID tags;active wearable transponders;combined passive radiofrequency identification;electromagnetic signals backscattering;human motion recognition;machine learning technique;moving limbs;support vector machine algorithm","","2","","10","","","6-9 Oct. 2014","","IEEE","IEEE Conference Publications"
"A machine learning approach for real-time reachability analysis","R. E. Allen; A. A. Clark; J. A. Starek; M. Pavone","Department of Aeronautics and Astronautics, Stanford University, CA, 94305, USA","2014 IEEE/RSJ International Conference on Intelligent Robots and Systems","20141106","2014","","","2202","2208","Assessing reachability for a dynamical system, that is deciding whether a certain state is reachable from a given initial state within a given cost threshold, is a central concept in controls, robotics, and optimization. Direct approaches to assess reachability involve the solution to a two-point boundary value problem (2PBVP) between a pair of states. Alternative, indirect approaches involve the characterization of reachable sets as level sets of the value function of an appropriate optimal control problem. Both methods solve the problem accurately, but are computationally intensive and do no appear amenable to real-time implementation for all but the simplest cases. In this work, we leverage machine learning techniques to devise query-based algorithms for the approximate, yet real-time solution of the reachability problem. Specifically, we show that with a training set of pre-solved 2PBVP problems, one can accurately classify the cost-reachable sets of a differentially-constrained system using either (1) locally-weighted linear regression or (2) support vector machines. This novel, query-based approach is demonstrated on two systems: the Dubins car and a deep-space spacecraft. Classification errors on the order of 10% (and often significantly less) are achieved with average execution times on the order of milliseconds, representing 4 orders-of-magnitude improvement over exact methods. The proposed algorithms could find application in a variety of time-critical robotic applications, where the driving factor is computation time rather than optimality.","2153-0858;21530858","DVD:978-1-4799-6931-9; Electronic:978-1-4799-6934-0; POD:978-1-4799-6935-7","10.1109/IROS.2014.6942859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6942859","","Chebyshev approximation;Equations;Machine learning algorithms;Support vector machines;Training;Vectors","boundary-value problems;learning (artificial intelligence);mobile robots;optimal control;query processing;reachability analysis;regression analysis;set theory;support vector machines","Dubins car;computation time;cost-reachable sets;deep-space spacecraft;differentially-constrained system;dynamical system;locally-weighted linear regression;machine learning approach;machine learning techniques;optimal control problem;presolved 2PBVP problems;query-based algorithms;query-based approach;reachability assessment;real-time reachability analysis;support vector machines;time-critical robotic applications;two-point boundary value problem","","2","","16","","","14-18 Sept. 2014","","IEEE","IEEE Conference Publications"
"Histogram-based classification of iPSC colony images using machine learning methods","H. Joutsijoki; M. Haponen; I. Baldin; J. Rasku; Y. Gizatdinova; M. Paci; J. Hyttinen; K. Aalto-Setälä; M. Juhola","School of Information Sciences, University of Tampere, FI-33014, Finland","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","2611","2617","This paper focuses on induced pluripotent stem cell (iPSC) colony image classification using machine learning methods and different feature sets obtained from the intensity histograms. Intensity histograms are obtained from the whole iPSC colony images and as a baseline for it they are determined only from the iPSC colony area of images. Furthermore, we apply to both of the datasets two simple feature selection methods having altogether four datasets. Altogether, 30 different classification methods are tested and we perform thorough experimental tests. The best accuracy (55%) is obtained for the feature set evaluated from the whole image using Directed Acyclic Graph Support Vector Machines (DAGSVM). DAGSVM is also the best choice when intensity histograms are evaluated only from the iPSC colony area. By this means accuracy of 54% is achieved. The obtained results are promising for further research where, for instance, more sophisticated feature selection and extraction methods and other multi-class extensions of SVM will be examined. However, intensity histograms are not alone adequate for iPSC colony image classification.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6974321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974321","Induced pluripotent stem cells;image classification;k nearest neighbor method;machine learning;support vector machines","Accuracy;Correlation;Histograms;Kernel;Polynomials;Support vector machines;Weight measurement","cellular biophysics;directed graphs;feature extraction;feature selection;image classification;learning (artificial intelligence);medical image processing;support vector machines","DAGSVM;directed acyclic graph support vector machines;feature extraction method;feature selection method;feature sets;histogram-based classification;iPSC colony images;induced pluripotent stem cell colony image classification;intensity histograms;machine learning methods;multiclass SVM extensions","","2","","25","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Design of Palatable Credit Scorecards as a Highly Automated Analytic Service by Combining Machine Learning with Domain Expertise","G. Fahner","Anal. Sci., Fair Isaac Corp., San Jose, CA, USA","2014 IEEE International Conference on Services Computing","20141020","2014","","","850","851","Lenders require accurate and interpretable credit scoring models palatable to regulators, financial services staff and consumers. Expert-designed segmented scorecards fill this need. Building such models is a laborious data-guided task for experienced modelers. It can take weeks to hone a model for deployment. Lenders would like to design, update and test models, predictors and segmentation schemes more frequently, objectively and cost-effectively, as environments change fast and as new data emerge. We propose scorecard design as an automated analytic computing service used by domain experts, comprising data-driven machine learning with expert-imposed palatability restrictions and model visualization, in two stages: Stage I fits a tree ensemble model to render a best-fit score and a list of segmentation candidates. Stage II uses this information to generate optimal palatable segmented scorecards subject to restrictions provided by the experts. When implemented on a computer cluster, our process yields close to deployment-ready scorecards within minutes to hours, which can be rapidly honed and upon approval deployed into a separate scoring service. While motivated by transparency needs of credit scoring, such a service can be valuable for any application requiring highly predictive yet palatable scoring algorithms.","","Electronic:978-1-4799-5066-9; POD:978-1-4799-5067-6","10.1109/SCC.2014.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6930622","cluster computing;credit scoring;design;domain expertise;scorecard;segmentation;tree ensembles;visualization","Analytical models;Clustering algorithms;Computational modeling;Load modeling;Predictive models;Stochastic processes;Vegetation","data visualisation;expert systems;financial data processing;learning (artificial intelligence)","automated analytic computing service;credit scorecard design;credit scoring models;domain expertise;expert-imposed palatability restrictions;financial services;machine learning;model visualization;tree ensemble model","","0","","2","","","June 27 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"On the effect of subliminal priming on subjective perception of images: A machine learning approach","P. Kumar; F. Mahmood; D. M. Mohan; K. Wong; A. Agrawal; M. Elgendi; R. Shukla; J. Dauwels; A. H. D. Chan","INRIA Sophia Antipolis-M&#x00E9;diterran&#x00E9;e","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","5438","5441","The research presented in this article investigates the influence of subliminal prime words on peoples' judgment about images, through electroencephalograms (EEGs). In this cross domain priming paradigm, the participants are asked to rate how much they like the stimulus images, on a 7-point Likert scale, after being subliminally exposed to masked lexical prime words, with EEG recorded simultaneously. Statistical analysis tools are used to analyze the effect of priming on behavior, and machine learning techniques to infer the primes from EEGs. The experiment reveals strong effects of subliminal priming on the participants' explicit rating of images. The subjective judgment affected by the priming makes visible change in event-related potentials (ERPs); results show larger ERP amplitude for the negative primes compared with positive and neutral primes. In addition, Support Vector Machine (SVM) based classifiers are proposed to infer the prime types from the average ERPs, which yields a classification rate of 70%.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6944856","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6944856","","Discrete wavelet transforms;Educational institutions;Electroencephalography;Feature extraction;Frequency-domain analysis;Semantics;Support vector machines","bioelectric potentials;electroencephalography;learning (artificial intelligence);statistical analysis;support vector machines","7-point Likert scale;EEG;ERP amplitude;SVM;cross domain priming paradigm;electroencephalograms;event-related potentials;machine learning approach;neutral primes;positive primes;statistical analysis;subjective image perception;subliminal priming;support vector machine","","1","","13","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
