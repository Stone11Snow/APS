"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5073088,5070613,5012345,4983354,4776455,4959112,4960721,4939738,4939641,4925736,4938676,4917741,4919641,4907653,4909497,4907654,4812072,4906675,4906553,4906669,4806127,4839429,4813238,4812438,4813465,4813783,4811318,4810674,4809049,4809069,4798934,4028526,4028129,4028652,4028508,4028499,4786106,4786325,4783985,4783606,4781223,4778053,4774267,4777196,4771801,4772064,4766574,4766846,4762828,4766535,4761645,4762310,4761259,4755460,4752040,4746809,4747340,4746040,4747609,4739562,4739561,4740571,4739719,4740869,4738466,4736917,4731071,4732894,4732896,4731948,4732201,4725027,4725025,4725073,4725041,4724996,4725172,4721407,4722758,4725013,4711961,4664428,4697558,4696447,4698183,4696798,4685473,4677510,4682362,4674432,4669812,4666844,4665144,4664681,4664796,4659299,4654736,4650035,4648026,4638549",2017/05/04 23:44:26
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Intelligible machine learning with malibu","R. E. Langlois; H. Lu","Department of Bioengineering, University of Illinois at Chicago, 60607, USA","2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20081014","2008","","","3795","3798","malibu is an open-source machine learning work-bench developed in C/C++ for high-performance real-world applications, namely bioinformatics and medical informatics. It leverages third-party machine learning implementations for more robust bug free software. This workbench handles several well-studied supervised machine learning problems including classification, regression, importance-weighted classification and multiple-instance learning. The malibu interface was designed to create reproducible experiments ideally run in a remote and/or command line environment. The software can be found at: http://proteomics.bioengr. uic.edu/malibu/index.html","1094-687X;1094687X","CD-ROM:978-1-4244-1815-2; POD:978-1-4244-1814-5","10.1109/IEMBS.2008.4650035","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4650035","","Application software;Bioinformatics;Biomedical engineering;Computer languages;Java;Machine learning;Machine learning algorithms;Open source software;Performance evaluation;Reproducibility of results","","","Algorithms;Artificial Intelligence;Computational Biology;Database Management Systems;Databases, Factual;Humans;Information Storage and Retrieval;Programming Languages;Software;User-Computer Interface","1","","34","","","20-25 Aug. 2008","","IEEE","IEEE Conference Publications"
"Reduction of power consumption in sensor network applications using machine learning techniques","G. M. Shafiullah; A. Thompson; P. J. Wolfs; S. Ali","Centre for Railway Engineering, Faculty of Sciences, Engineering & Health, Central Queensland University, Rockhampton, QLD-4702, Australia","TENCON 2008 - 2008 IEEE Region 10 Conference","20090127","2008","","","1","6","Wireless sensor networking (WSN) and modern machine learning techniques have encouraged interest in the development of vehicle monitoring systems that ensure safe and secure operations of the rail vehicle. To make an energy-efficient WSN application, power consumption due to raw data collection and pre-processing needs to be kept to a minimum level. In this paper, an energy-efficient data acquisition method has investigated for WSN applications using modern machine learning techniques. In an existing system, four sensor nodes were placed in each railway wagon to collect data to develop a monitoring system for railways. In this system, three sensor nodes were placed in each wagon to collect the same data using popular regression algorithms, which reduces power consumption of the system. This study was conducted using six different regression algorithms with five different datasets. Finally the best suitable algorithm have suggested based on the performance metrics of the algorithms that include: correlation coefficient, root mean square error (RMSE), mean absolute error (MAE), root relative squared error (RRSE), relative absolute error (RAE) and computation complexity.","2159-3442;21593442","CD-ROM:978-1-4244-2409-2; POD:978-1-4244-2408-5","10.1109/TENCON.2008.4766574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4766574","Wireless sensor networking;machine learning techniques;railway wagons;regression analysis","Communication system security;Condition monitoring;Data acquisition;Energy consumption;Energy efficiency;Machine learning;Rail transportation;Sensor systems;Vehicle safety;Wireless sensor networks","computerised monitoring;least mean squares methods;railway engineering;regression analysis;wireless sensor networks","energy-efficient data acquisition method;machine learning techniques;mean absolute error;power consumption reduction;regression algorithms;relative absolute error;root mean square error;root relative squared error;vehicle monitoring systems;wireless sensor networking","","1","2","31","","","19-21 Nov. 2008","","IEEE","IEEE Conference Publications"
"Extreme learning machine based phase angle control for stator-doubly-fed doubly salient motor for electric vehicles","Xiangxin Kong; Ming Cheng; Yagang Shu","School of Electrical Engineering, Southeast University, Nanjing 210096, China","2008 IEEE Vehicle Power and Propulsion Conference","20081118","2008","","","1","5","This paper develops a novel advanced angle control scheme for the stator-doubly-fed doubly salient (SDFDS) motor for electric vehicles (EVs) based on the extreme learning machine (ELM) so as to satisfy the requirement of EVs. The SDFDS motor runs with constant torque below the base speed and with constant power by field weakening over the base speed. To achieve high torque at low speed for cranking and widen speed operation range fro cruising, phase angle of armature current must be advanced. Hence phase angle control is the key factor. As a new learning algorithm for single-hidden layer feed-forward neural networks (SLFNs), the extreme learning machine (ELM) can solve the nonlinear relationships among phase angle, torque and speed. Thus phase angle control based on extreme learning machine is presented in this paper, in which the experimental data is applied to train the SLFNs in off-line way and afterwards, the trained data is applied to control the motor on-line. The experimental results verify the effectiveness of the developed control scheme.","1938-8756;19388756","CD-ROM:978-1-4244-1849-7; POD:978-1-4244-1848-0","10.1109/VPPC.2008.4677510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4677510","Electric Vehicles;Phase Angle Control;SLFNs;Special Learning Machine;Stator-Doubly-Fed Doubly Salient Motor","Electric vehicles;Feedforward neural networks;Feedforward systems;Machine learning;Neural networks;Permanent magnet motors;Propulsion;Reluctance motors;Stators;Torque","control engineering computing;electric motors;electric vehicles;feedforward neural nets;learning (artificial intelligence);power engineering computing;stators","base speed;electric vehicles;extreme learning machine based phase angle control;field weakening;single-hidden layer feed-forward neural networks;speed operation range;stator-doubly-fed doubly salient motor","","3","1","8","","","3-5 Sept. 2008","","IEEE","IEEE Conference Publications"
"Robotics, signal processing, decision making and self-reproducing machine learning","J. K. Huang","School of Information Science, Beijing Language and Culture University, 100083, China","2008 IEEE International Conference on Granular Computing","20081031","2008","","","306","311","In 2005, inspired by Von Neumannpsilas self-reproducing automata, the author had introduced self-reproducing machine learning (SRML). In this article the author is trying to explore the nature of self-reproducing machine learning, SRML architectures, formal structures, mathematical structures and its integrated systems software engineering principles. The author will demonstrate SRML technology to robotics, image processing, signal processing, Web mining and social sciences decision management and so on as its applications. These applications disclose the power of SRMLpsilas model, principles, theory, and methodology as machine learning and data mining technology.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664681","","Application software;Computer architecture;Decision making;Learning automata;Machine learning;Power engineering and energy;Robotics and automation;Robots;Signal processing;System software","Internet;data mining;decision making;image processing;learning (artificial intelligence);robots;self-reproducing automata;social sciences computing","Web mining;decision making;image processing;integrated systems software engineering principle;robotics;self-reproducing automata;self-reproducing machine learning;signal processing;social sciences decision management","","1","","23","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"Multi-category bioinformatics dataset classification using extreme learning machine","T. Helmy; Z. Rasheed","Information and Computer Science Department, College of Computer Science and Engineering, King Fahd University of Petroleum and Minerals, Dhahran 31261, Kingdom of Saudi Arabia","2009 IEEE Congress on Evolutionary Computation","20090529","2009","","","3234","3240","This paper presents recently introduced learning algorithm called extreme learning machine (ELM) for single-hidden layer feed-forward neural-networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. The ELM avoids problems like local minima, improper learning rate and over fitting commonly faced by iterative learning methods and completes the training very fast. We have evaluated the multicategory classification performance of ELM on five different data sets related to bioinformatics namely, the Breast Cancer Wisconsin data set, the Pima Diabetes data set, the Heart-Statlog data set, the Hepatitis data set and the Hypothyroid data set. A detailed analysis of different activation functions with varying number of neurons is also carried out which concludes that Algebraic Sigmoid function outperforms all other activation functions on these data sets. The evaluation results indicate that ELM produces better classification accuracy with reduced training time and implementation complexity compared to earlier implemented models.","1089-778X;1089778X","POD:978-1-4244-2958-5","10.1109/CEC.2009.4983354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4983354","Bayesian Network;Bioinformatics;Classification;Decision Tree;Extreme Learning Machine;SVM","Algorithm design and analysis;Bioinformatics;Breast cancer;Diabetes;Feedforward systems;Iterative algorithms;Iterative methods;Learning systems;Liver diseases;Machine learning","bioinformatics;cancer;data handling;learning (artificial intelligence);neural nets","Algebraic Sigmoid function;Breast Cancer Wisconsin data set;Heart-Statlog data set;Hepatitis data set;Hypothyroid data set;Pima Diabetes data set;extreme learning machine;multicategory bioinformatics dataset classification;single-hidden layer feed-forward neural-networks","","8","","16","","","18-21 May 2009","","IEEE","IEEE Conference Publications"
"Feature selection for learning-machine numerical observer","J. G. Brankov; P. Hendrik Pretorius","ECE Department., Illinois Institute of Technology, Chicago, 60616, USA","2008 IEEE Nuclear Science Symposium Conference Record","20090206","2008","","","4440","4443","It is now accepted that image quality should be evaluated using task-based criteria, such as human-observer (HO) performance in a lesion-detection task. Because an HO study is costly and time consuming, the development of a numerical observer (NO) surrogate is highly desirable. NO, like the channelized Hotelling observer (CHO), typically uses some features, i.e. numerical values, extracted from images to predict HO performance. Recently, we proposed and successfully tested a supervised-learning approach for modeling HOs with a machine-learning algorithm (namely a support vector machine). In the supervised-learning approach the goal is to identify the relationship between measured image features and HO defect likelihood scores. In this work we further explore the proposed learning approach by evaluating the image feature selection. Our preliminary results use, as a starting point, the image features as those used in CHO methodology, namely the outputs of four constant-Q frequency-band filters intended to model the human visual system, indicating that the features have significant influence on the NO accuracy in predicting HO performance.","1082-3654;10823654","POD:978-1-4244-2714-7","10.1109/NSSMIC.2008.4774267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4774267","","Biomedical imaging;Filters;Frequency;Humans;Image quality;Medical diagnostic imaging;Predictive models;Support vector machines;Testing;Visual system","","","","0","","16","","","19-25 Oct. 2008","","IEEE","IEEE Conference Publications"
"Machine Learning Algorithm Selection for Forecasting Behavior of Global Institutional Investors","J. J. Ann; Suk Jun Lee; Kyong Joo Oh; Tae Yoon Kim; Hyoung Yong Lee; Min Sik Kim","Dept. of Inf. & Ind. Eng., Yonsei Univ., Seoul","2009 42nd Hawaii International Conference on System Sciences","20090120","2009","","","1","9","Recently Son et al. proposed early warning system (EWS) monitoring the behaviors of global institutional investors (GII) against their possible massive pullout from the local emerging stock market. They used machine learning algorithm for lag l classifier to forecast the behavior of GII. The main aim of this article is to implement various machine learning algorithms in constructing the EWS and to compare their performances to select the proper one. Our results address various important issues for machine learning forecasting problem. In particular, a proper machine learning algorithm will be recommended for both long term and short term forecasting. This is empirically studied for the Korean stock market.","1530-1605;15301605","POD:978-0-7695-3450-3","10.1109/HICSS.2009.297","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4755460","","Acceleration;Alarm systems;Economic forecasting;Electric shock;Industrial engineering;Machine learning;Machine learning algorithms;Monitoring;Statistics;Stock markets","economic forecasting;investment;learning (artificial intelligence);pattern classification;stock markets","Korean stock market;early warning system;global institutional investor behavior forecasting;machine learning algorithm selection;pattern classification","","0","","35","","","5-8 Jan. 2009","","IEEE","IEEE Conference Publications"
"Statistical Machine Learning in Natural Language Understanding: Object Constraint Language Translator for Business Process","Li Zhao; F. Li","Department of Mechanism, ChangChun University, ChangChun, P.R. China. zhaolcn@126.com","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","1056","1059","Natural language is used to represent human thoughts and human actions. Business rules described by natural language are very hard for machine to understand. In order to let machine know the business rules, parts of business process, we need to translate them into a language which machine can understand. Object constraint language is one of those languages. In this paper we present a statistical machine learning method to understand the natural business rules and then translate them into object constraint language. Subsequently a translation algorithm for business process modeling is also provided. A real case, air cargo load planning process is proposed to illustrate the efficiency and effective of the method and the algorithm. The result has shown that this method and algorithm enrich business process modeling technology and enhance the efficiency of software developers in business process modeling.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810674","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810674","Business Process;Object Constraint Language;Statistical Machine Translation","Constraint optimization;Humans;Laboratories;Learning systems;Machine learning;Machine learning algorithms;Natural languages;Power system modeling;Programming;Unified modeling language","business process re-engineering;language translation;learning (artificial intelligence);natural languages;statistical analysis","business process modeling technology;natural business rules;natural language understanding;object constraint language translator;statistical machine learning","","0","","14","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Distance Metric Learning and Support Vector Machines for Classification of Mass Spectrometry Proteomics Data","Q. Liu; M. Qiao; A. H. Sung","Comput. Sci. Dept., New Mexico Inst. of Min. & Technol., Socorro, NM, USA","2008 Seventh International Conference on Machine Learning and Applications","20081222","2008","","","631","636","Mass spectrometry becomes the most widely used measurement in proteomics research. High dimensionality of features and small dataset are two major limitations restrict the accuracy of classification in mass spectrum data analysis. To improve the data mining result, two major issues need to be highlighted, which are feature extraction and feature selection. The quality of the feature set determines the reliability of the prediction of disease status. A well-known approach is to detect peak values and apply support vector machine recursive feature elimination (SVMRFE) to choose feature sets for classification. In this article, we successfully apply a distance metric learning to classify proteomics mass spectrometry data. Experimental results show that distance metric learning can successfully be applied to the classification of proteomics data and the results are comparable to the best results by applying SVM to the feature sets chosen with the use of SVMRFE.","","POD:978-0-7695-3495-4","10.1109/ICMLA.2008.91","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725041","Proteomics;classification;distance metric learning;feature selection;mass spectrum","Chemicals;Data mining;Feature extraction;Machine learning;Mass spectroscopy;Noise generators;Noise reduction;Proteomics;Support vector machine classification;Support vector machines","biology computing;data analysis;data mining;diseases;feature extraction;mass spectroscopy;pattern classification;proteomics;recursive estimation;support vector machines","data mining;disease status;distance metric learning;feature extraction;feature selection;for classification;mass spectrometry proteomics data;mass spectrum data analysis;proteomics mass spectrometry data;support vector machine recursive feature elimination;support vector machines","","3","","28","","","11-13 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Machine Learning Approach for Efficient Traffic Classification","W. Li; A. W. Moore","Comput. Lab., Univ. of Cambridge, Cambridge","2007 15th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems","20081117","2007","","","310","317","Traffic classification is of fundamental importance to track the evolution of network applications and model their behaviours. Further, classified traffic is required to understand how the Internet is being used, and to effectively control the services that traffic receives. In this paper we present a machine-learning approach that accurately classifies live traffic using C4.5 decision tree. By collecting 12 features at the start of the flows, without inspecting the packet payload, our method can identify live traffic of different types of applications with 99.8% total accuracy. Moreover, accuracy is not our only concern; we also consider the latency and throughput as of high importance.","1526-7539;15267539","CD-ROM:978-1-4244-1854-1; POD:978-1-4244-1853-4","10.1109/MASCOTS.2007.2","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4674432","","Classification tree analysis;Communication system traffic control;Decision trees;Inspection;Internet telephony;Intrusion detection;Machine learning;Payloads;Protocols;Traffic control","Internet;learning (artificial intelligence);telecommunication computing;telecommunication traffic","C4.5 decision tree;Internet;machine learning approach;network applications;traffic classification efficiency","","33","","24","","","24-26 Oct. 2007","","IEEE","IEEE Conference Publications"
"Predicting Multiple Metrics for Queries: Better Decisions Enabled by Machine Learning","A. Ganapathi; H. Kuno; U. Dayal; J. L. Wiener; A. Fox; M. Jordan; D. Patterson","Comput. Sci. Div., Univ. of California at Berkeley, Berkeley, CA","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","592","603","One of the most challenging aspects of managing a very large data warehouse is identifying how queries will behave before they start executing. Yet knowing their performance characteristics - their runtimes and resource usage - can solve two important problems. First, every database vendor struggles with managing unexpectedly long-running queries. When these long-running queries can be identified before they start, they can be rejected or scheduled when they will not cause extreme resource contention for the other queries in the system. Second, deciding whether a system can complete a given workload in a given time period (or a bigger system is necessary) depends on knowing the resource requirements of the queries in that workload. We have developed a system that uses machine learning to accurately predict the performance metrics of database queries whose execution times range from milliseconds to hours. For training and testing our system, we used both real customer queries and queries generated from an extended set of TPC-DS templates. The extensions mimic queries that caused customer problems. We used these queries to compare how accurately different techniques predict metrics such as elapsed time, records used, disk I/Os, and message bytes. The most promising technique was not only the most accurate, but also predicted these metrics simultaneously and using only information available prior to query execution. We validated the accuracy of this machine learning technique on a number of HP Neoview configurations. We were able to predict individual query elapsed time within 20% of its actual time for 85% of the test queries. Most importantly, we were able to correctly identify both the short and long-running (up to two hour) queries to inform workload management and capacity planning.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812438","database performance prediction;machine learning;operational business intelligence","Capacity planning;Computer science;Data engineering;Data warehouses;Databases;Machine learning;Measurement;Milling machines;System testing;USA Councils","learning (artificial intelligence);query processing;software metrics;very large databases","database queries;machine learning;performance metrics;very large data warehouse","","40","","23","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Improving Sequence Tagging using Machine-Learning Techniques","W. Jiang; X. l. Wang; Y. Guan","School of Computer Science and Technology, Harbin Institute of Technology, 150001, Harbin, P.R. China. E-MAIL: jiangwei@insun.hit.edu.cn","2006 International Conference on Machine Learning and Cybernetics","20090304","2006","","","2636","2641","This paper presents an excel sequence tagging approach based on the combined machine learning methods. Firstly, conditional random fields (CRF) is presented as a new kind of discriminative sequential model, it can incorporate many rich features, and well avoid the label bias problem that is the limitation of maximum entropy Markov models (MEMM) and other discriminative finite-state models. Secondly, support vector machine is improved to adapt the sequential tagging task. Finally, these improved models and other existing models are combined together, which have achieved the state-of-the-art performance. Experimental results show that CRF approach achieves 0.70% improvement in POS tagging and 0.67% improvement in shallow parsing. Moreover, our combination method achieves F-measure 93.73% and 93.69% in above two tasks respectively, which is better than any sub-model","2160-133X;2160133X","POD:1-4244-0061-9","10.1109/ICMLC.2006.258917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028508","Conditional random fields;Multi-model combination;Sequence tagging;Support vector machine","Biological system modeling;Computer science;Cybernetics;Entropy;Hidden Markov models;Labeling;Learning systems;Machine learning;Performance analysis;RNA;Support vector machines;Tagging","learning (artificial intelligence);sequences;support vector machines","conditional random fields;discriminative finite-state models;discriminative sequential model;excel sequence tagging;machine-learning techniques;maximum entropy Markov models;support vector machine","","1","","14","","","13-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Nano-scale fault tolerant machine learning for cognitive radio","J. Peltonen; M. A. Uusitalo; J. Pajarinen","Helsinki University of Technology, Department of Information and Computer Science, P.O.Box 5400, FI-02015 TKK, Finland","2008 IEEE Workshop on Machine Learning for Signal Processing","20081121","2008","","","163","168","We introduce a machine learning based channel state classifier for cognitive radio, designed for nano-scale implementation. The system uses analog computation, and consists of cyclostationary feature extraction and a radial basis function network for classification. The description of the system is partially abstract, but our design choices are motivated by domain knowledge and we believe the system will be feasible for future nanotechnology implementation. We describe an error model for the system, and simulate experimental performance and fault tolerance of the system in recognizing WLAN signals, under different levels of input noise and computational errors. The system performs well under the expected non-ideal manufacturing and operating conditions.","1551-2541;15512541","CD-ROM:978-1-4244-2376-7; POD:978-1-4244-2375-0","10.1109/MLSP.2008.4685473","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685473","","Analog computers;Cognitive radio;Computational modeling;Computer networks;Fault tolerance;Fault tolerant systems;Feature extraction;Machine learning;Nanotechnology;Radial basis function networks","cognitive radio;feature extraction;learning (artificial intelligence);nanotechnology;radial basis function networks;telecommunication computing;wireless LAN","WLAN signals;channel state classifier;cognitive radio;cyclostationary feature extraction;error model;machine learning;nanoscale fault tolerance;nanotechnology;radial basis function network;signal classification","","0","","15","","","16-19 Oct. 2008","","IEEE","IEEE Conference Publications"
"Detecting Web-Based Attacks by Machine Learning","L. c. Cao","School of Computer and Communication, Lanzhou University of Technology, Lanzhou 730050, China. E-MAIL: caolaicheng@163.com","2006 International Conference on Machine Learning and Cybernetics","20090304","2006","","","2737","2742","Web-based vulnerabilities represent a substantial portion of the security exposures of computer networks. Unfortunately, many anomaly Web-based intrusion detection systems (IDS) take on higher false alarm rate (FAR) and false negative rate (FNR). In this paper, we build this system using Adaboost, a prevailing machine learning algorithm, and its detecting model adopts a dynamic load-balancing algorithm, which can avoid packet loss and false negatives in high-performance Web severs with handling heavy traffic loads in real-time and can enhance the efficiency of detecting work. The experiments demonstrate that our system can achieve an especially low false positive rate (approximating 0.3%) and false negative rate (approaching 0.4%) while keeping an extremely low computational complexity","2160-133X;2160133X","POD:1-4244-0061-9","10.1109/ICMLC.2006.258990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028526","Intrusion detection systems (IDS);false alarm rate (FAR);false negative rate (FNR);machine learning","Computational complexity;Computer networks;Cybernetics;Entropy;Intrusion detection;Machine learning;Machine learning algorithms;Real time systems;Support vector machines;Telecommunication traffic;Web server","Internet;computational complexity;learning (artificial intelligence);resource allocation;security of data","FAR;FNR;Web severs;Web-based attack detection;Web-based intrusion detection system;computational complexity;computer networks;dynamic load-balancing algorithm;false alarm rate;false negative rate;machine learning algorithm","","1","","17","","","13-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Grasping force estimation detecting slip by tactile sensor adopting machine learning techniques","A. M. Mazid; A. B. M. Shawkat Ali","Faculty of Sciences, Engineering & Health, Central Queensland University, Rockhampton, Australia","TENCON 2008 - 2008 IEEE Region 10 Conference","20090127","2008","","","1","6","Adequate grasping force estimation and slip detection is a vital problem in wider applications of robots and manipulators in industries as well as in our everyday life. In this paper, a new methodology for slip detection during grasping by robot grippers/end-effectors using tactile sensor has been presented. During the object slippage, the tactile sensor in touch with the object surface travels along the peaks and valleys of surface texture of the object which creates vibratory motions in the tactile. A newly developed mathematical model is used to compute the scattered energy of vibrations, which contains parameters of surface texture geometry as well as trial grasping force, and other relevant parameters. Using the scattered energy of vibrations predicted by soft computing techniques, an attempt to instantly estimate the adequate grasping force has been reasonably successful. Surface texture data, for experimental estimation of grasping force, were collected from a huge number of machined specimens and were used to build four different machine learning estimation techniques. Experimental results using linear regression (LR), simple linear regression (SLR), pace regression (PR) and support vector machine (SVM) demonstrate a relatively better technique for industrial applications.","2159-3442;21593442","CD-ROM:978-1-4244-2409-2; POD:978-1-4244-2408-5","10.1109/TENCON.2008.4766846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4766846","intelligent grasping;slip detection;support vector machine;surface roughness;tactile sensor","Force sensors;Life estimation;Linear regression;Machine learning;Manipulators;Robot sensing systems;Service robots;Support vector machines;Surface texture;Tactile sensors","end effectors;grippers;learning (artificial intelligence);regression analysis;support vector machines;surface texture;tactile sensors","grasping force estimation;linear regression;machine learning techniques;manipulators;pace regression;robot end-effectors;robot grippers;simple linear regression;slip detection;soft computing techniques;support vector machine;surface texture geometry;tactile sensor;vibration scattered energy","","2","","22","","","19-21 Nov. 2008","","IEEE","IEEE Conference Publications"
"Life log management based on machine learning technique","K. S. Hwang; S. B. Cho","Department of Computer Science, Yonsei University, Seoul, Korea","2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems","20081010","2008","","","691","696","Mobile devices have already shown great potential in terms of providing customized services to users because they can record meaningful and private information continually for long periods of time, so the research for understanding and managing the life log of human has received increasing attention in recent years. In this paper, we propose a novel method for life log management based on the machine learning, which summarizes and manages the experiences of human. The method uses an effective probabilistic network model for analyzing various kinds of log data in mobile environments, which were modularized to decrease complexity. We also propose a mobile life browser, which visualizes and searches humanpsilas mobile life based on the contents and context of personal information. The mobile life browser is for searching the personal information effectively collected on his/her mobile device and for supporting the concept-based searching method by using concept networks and Bayesian networks.","","CD-ROM:978-1-4244-2144-2; POD:978-1-4244-2143-5","10.1109/MFI.2008.4648026","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4648026","Context-aware Computing;Life Log;Mobile Application","Bayesian methods;Computer science;Conference management;Context-aware services;Data visualization;Humans;Information technology;Machine learning;Message service;Mobile computing","belief networks;data recording;learning (artificial intelligence);mobile computing","Bayesian networks;concept networks;concept-based searching method;customized services;life log management;machine learning technique;mobile environments;mobile life browser","","3","","20","","","20-22 Aug. 2008","","IEEE","IEEE Conference Publications"
"A Comparative Study of Machine Learning Techniques for Caries Prediction","R. D. Montenegro; A. L. I. Oliveira; G. G. Cabral; C. R. T. Katz; A. Rosenblatt","Dept. of Comput. & Syst., Pernambuco State Univ., Recife","2008 20th IEEE International Conference on Tools with Artificial Intelligence","20081111","2008","2","","477","481","There are striking disparities in the prevalence of dental disease by income. Poor children suffer twice as much dental caries as their more affluent peers, but are less likely to receive treatment. This paper presents an experimental study of the application of machine learning methods to the problem of caries prediction. For this paper a data set collected from interviews with children under five years of age, in 2006, in Recife, the capital of Pernambuco, a state in northeast Brazil, was built. Four different data mining techniques were applied to this problem and their results were confronted in terms of the classification error and area under the ROC curve (AUC). Results showed that the MLP neural network classifier out performed the other machine learning methods employed in the experiments, followed by the support vector machine (SVM) predictor. In addition, the results also show that some rules (extracted by decision tress) may be useful for understanding the most important factors that influence the occurrence of caries in children.","1082-3409;10823409","POD:978-0-7695-3440-4","10.1109/ICTAI.2008.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4669812","Machine learning;caries;classifiers;odontology","Artificial intelligence;Data mining;Dentistry;Diseases;Learning systems;Machine learning;Medical diagnostic imaging;Pediatrics;Support vector machine classification;Support vector machines","data mining;dentistry;diseases;learning (artificial intelligence);medical computing;multilayer perceptrons;support vector machines","MLP neural network classifier;caries prediction;data mining;dental disease;machine learning techniques;support vector machine","","0","","26","","","3-5 Nov. 2008","","IEEE","IEEE Conference Publications"
"Palmprint recognition via Locality Preserving Projections and extreme learning machine neural network","Jiwen Lu; Yongwei Zhao; Yanxue Xue; Junlin Hu","Department of Information Science, Xi&#191;an University of Technology, 710048, China","2008 9th International Conference on Signal Processing","20081208","2008","","","2096","2099","This paper proposes an efficient palmprint recognition method using locality preserving projections (LPP) and extreme learning machine (ELM) neural network. Firstly, two-dimensional discrete wavelet transformation (DWT) is applied in the region of interest (ROI) of each palmprint image and then principal component analysis (PCA) and LPP are used for dimensionality reduction. Finally, we construct a single-hidden layer forward network (SLFN) to construct one extreme learning machine (ELM) to quickly classify the palmprint images. Experiments on the PolyU palmprint database demonstrate the effectiveness of the proposed method.","2164-5221;21645221","CD-ROM:978-1-4244-2179-4; POD:978-1-4244-2178-7","10.1109/ICOSP.2008.4697558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4697558","Extreme Learning Machine (ELM);Locality Preserving Projections (LPP);Palmprint Recognition","Biometrics;Discrete wavelet transforms;Feature extraction;Humans;Image recognition;Machine learning;Neural networks;Pattern recognition;Power system security;Principal component analysis","data reduction;discrete wavelet transforms;feature extraction;image classification;learning (artificial intelligence);neural nets;principal component analysis","PCA;dimensionality reduction;discrete wavelet transformation;extreme learning machine neural network;feature extraction;locality preserving projection;palmprint image classification;palmprint image recognition method;principal component analysis;single-hidden layer forward network","","2","","22","","","26-29 Oct. 2008","","IEEE","IEEE Conference Publications"
"Ranking Web Pages Using Machine Learning Approaches","S. L. Yong; M. Hagenbuchner; A. C. Tsoi","Univ. of Wollongong, Wollongong, NSW","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","677","680","One of the key components which ensures the acceptance of web search service is the web page ranker - a component which is said to have been the main contributing factor to the early successes of Google. It is well established that a machine learning method such as the Graph Neural Network (GNN) is able to learn and estimate Google's page ranking algorithm. This paper shows that the GNN can successfully learn many other Web page ranking methods e.g. TrustRank, HITS and OPIC. Experimental results show that GNN may be suitable to learn any arbitrary web page ranking scheme, and hence, may be more flexible than any other existing web page ranking scheme. The significance of this observation lies in the fact that it is possible to learn ranking schemes for which no algorithmic solution exists or is known.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740869","Machine learning;Web page ranking","Computer architecture;Information retrieval;Intelligent agent;Learning systems;Machine learning;Neural networks;Neurons;Web pages;Web search;World Wide Web","Web services;Web sites;graph theory;learning (artificial intelligence);neural nets;search engines","Google;HITS;OPIC;TrustRank;Web page ranking;graph neural network;machine learning method;web search service","","3","","12","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Learning Algorithms for Human–Machine Interfaces","Z. Danziger*; A. Fishbach; F. A. Mussa-Ivaldi","Northwestern Univ., Evanston, IL","IEEE Transactions on Biomedical Engineering","20090526","2009","56","5","1502","1511","The goal of this study is to create and examine machine learning algorithms that adapt in a controlled and cadenced way to foster a harmonious learning environment between the user and the controlled device. To evaluate these algorithms, we have developed a simple experimental framework. Subjects wear an instrumented data glove that records finger motions. The high-dimensional glove signals remotely control the joint angles of a simulated planar two-link arm on a computer screen, which is used to acquire targets. A machine learning algorithm was applied to adaptively change the transformation between finger motion and the simulated robot arm. This algorithm was either LMS gradient descent or the Moore-Penrose (MP) pseudoinverse transformation. Both algorithms modified the glove-to-joint angle map so as to reduce the endpoint errors measured in past performance. The MP group performed worse than the control group (subjects not exposed to any machine learning), while the LMS group outperformed the control subjects. However, the LMS subjects failed to achieve better generalization than the control subjects, and after extensive training converged to the same level of performance as the control subjects. These results highlight the limitations of coadaptive learning using only endpoint error reduction.","0018-9294;00189294","","10.1109/TBME.2009.2013822","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4776455","Adaptive learning;hand posture;human–machine interface;machine learning","Computational modeling;Computer simulation;Control systems;Data gloves;Electronic mail;Fingers;Instruments;Least squares approximation;Machine learning;Machine learning algorithms;Postal services","biocybernetics;data gloves;gradient methods;human-robot interaction;learning (artificial intelligence);least mean squares methods;telecontrol","Moore-Penrose pseudoinverse transformation;data glove;finger motions;high dimensional glove signals;human-machine interfaces;least mean square gradient descent;machine learning algorithms;remote control;simulated planar two link arm;simulated robot arm","Algorithms;Artificial Intelligence;Communication Aids for Disabled;Hand;Humans;Man-Machine Systems;Multivariate Analysis;Posture;Psychomotor Performance;Robotics;Signal Processing, Computer-Assisted;User-Computer Interface","19","","31","","20090206","May 2009","","IEEE","IEEE Journals & Magazines"
"Automatic Feature Generation for Machine Learning Based Optimizing Compilation","H. Leather; E. Bonilla; M. O'Boyle","Sch. of Inf., Univ. of Edinburgh, Edinburgh","2009 International Symposium on Code Generation and Optimization","20090505","2009","","","81","91","Recent work has shown that machine learning can automate and in some cases outperform hand crafted compiler optimizations. Central to such an approach is that machine learning techniques typically rely upon summaries or features of the program. The quality of these features is critical to the accuracy of the resulting machine learned algorithm; no machine learning method will work well with poorly chosen features. However, due to the size and complexity of programs, theoretically there are an infinite number of potential features to choose from. The compiler writer now has to expend effort in choosing the best features from this space. This paper develops a novel mechanism to automatically find those features which most improve the quality of the machine learned heuristic. The feature space is described by a grammar and is then searched with genetic programming and predictive modeling. We apply this technique to loop unrolling in GCC 4.3.1 and evaluate our approach on a Pentium 6. On a benchmark suite of 57 programs, GCC's hard-coded heuristic achieves only 3% of the maximum performance available, while a state of the art machine learning approach with hand-coded features obtains 59%. Our feature generation technique is able to achieve 76% of the maximum available speedup, outperforming existing approaches.","","POD:978-0-7695-3576-0","10.1109/CGO.2009.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907653","","Genetic programming;Humans;Informatics;Learning systems;Machine learning;Machine learning algorithms;Optimizing compilers;Predictive models;Program processors;Tree data structures","genetic algorithms;grammars;learning (artificial intelligence);program compilers","Pentium 6;automatic feature generation;compilation;compiler writer;feature generation technique;genetic programming;grammar;loop unrolling;machine learning;predictive modeling","","20","2","22","","","22-25 March 2009","","IEEE","IEEE Conference Publications"
"Tumor Targeting for Lung Cancer Radiotherapy Using Machine Learning Techniques","T. Lin; L. Cervino; X. Tang; N. Vasconcelos; S. B. Jiang","Dept. of Radiat. Oncology, Univ. of California San Diego, La Jolla, CA","2008 Seventh International Conference on Machine Learning and Applications","20081222","2008","","","533","538","Accurate lung tumor targeting in real time plays a fundamental role in image-guide radiotherapy of lung cancers. Precise tumor targeting is required for both respiratory gating and tracking. Gating is considered as the current state of the art for precise lung cancer radiotherapy, which irradiates the tumor when it moves into a predefined gating window. Tracking seems to be a next-generation technique, and it operates in a more aggressive fashion by following the tumor position with radiation beam in real time. Existing methods for gating and tracking often rely on observed motion patterns of external surrogates or implanted fiducial markers. However, external surrogates suffer from certain degrees of inaccuracy, and implanted fiducial markers are in limited uses due to the risk of pneumothorax. Therefore, direct tumor targeting techniques without implanting fiducial markers are desired. Previous studies in fluoroscopic markerless targeting are mainly based on template matching methods, which may fail when tumor boundary is unclear in fluoroscopic images. In this paper, we propose a novel framework of markerless gating and tracking based on machine learning algorithms. Specifically, gating is treated as a two-class classification problem, which is solved by principal component analysis (PCA) and artificial neural network (ANN). Further, we formulate the tracking problem as a regression task, which employs the correlation between the tumor position and nearby surrogate anatomic features in the image. Four regression methods were tested in this study: 1-degree and 2-degree linear regression, artificial neural network (ANN), and support vector machine (SVM). Finally, we demonstrate the superb performance of the proposed markerless gating and tracking algorithms on 10 fluoroscopic image sequences of 9 patients. For gating, the target coverage (the precision) ranges from 90% to 99%, with mean of 96.5%. For tracking, the mean localization error is about 2.1 pixels and the- - maximum error at 95% confidence level is about 4.6 pixels (pixel size is about 0.5 mm).","","POD:978-0-7695-3495-4","10.1109/ICMLA.2008.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725025","lung cancer;radiotherapy;tumor motion","Artificial neural networks;Cancer;Linear regression;Lung neoplasms;Machine learning;Machine learning algorithms;Principal component analysis;Support vector machines;Target tracking;Testing","cancer;image resolution;image sequences;learning (artificial intelligence);medical image processing;neural nets;principal component analysis;radiation therapy;support vector machines;tumours","artificial neural network;fluoroscopic images;image-guide radiotherapy;lung cancer radiotherapy;machine learning techniques;next-generation technique;pneumothorax;principal component analysis;radiation beam;regression task;respiratory gating;support vector machine;template matching methods","","0","6","11","","","11-13 Dec. 2008","","IEEE","IEEE Conference Publications"
"Incremental machine learning techniques for document layout understanding","S. Ferilli; M. Biba; T. M. A. Basile; F. Esposito","Dipartimento di Informatica - Universit&#224; di Bari, Italy","2008 19th International Conference on Pattern Recognition","20090123","2008","","","1","4","In real-world digital libraries, artificial intelligence techniques are essential for tackling the automatic document processing task with sufficient flexibility. The great variability in document kind, content and shape requires powerful representation formalisms to catch all the domain complexity. The continuous flow of new documents requires adaptable techniques that can progressively adjust the acquired knowledge on documents as long as new evidence becomes available, even extending if needed the set of recognized document types. Both these issues have not yet been thoroughly studied. This paper presents an incremental first-order logic learning framework for automatically dealing with various kinds of evolution in digital repositories content: evolution in the definition of class definitions, evolution in the set of known classes and evolution by addition of new unknown classes. Experiments show that the approach can be applied to real-world.","1051-4651;10514651","CD-ROM:978-1-4244-2175-6; POD:978-1-4244-2174-9","10.1109/ICPR.2008.4761259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4761259","","Artificial intelligence;Automatic logic units;Data mining;Digital systems;Learning systems;Machine learning;Production systems;Shape;Software libraries;Technology management","digital libraries;document image processing;learning (artificial intelligence)","artificial intelligence;digital libraries;document layout understanding;domain complexity;first-order logic learning;incremental machine learning;representation formalisms","","0","","8","","","8-11 Dec. 2008","","IEEE","IEEE Conference Publications"
"Machine Learning Methods for Protein Structure Prediction","J. Cheng; A. N. Tegge; P. Baldi","Comput. Sci. Dept., Univ. of Missouri, Columbia, MO","IEEE Reviews in Biomedical Engineering","20081209","2008","1","","41","49","Machine learning methods are widely used in bioinformatics and computational and systems biology. Here, we review the development of machine learning methods for protein structure prediction, one of the most fundamental problems in structural biology and bioinformatics. Protein structure prediction is such a complex problem that it is often decomposed and attacked at four different levels: 1-D prediction of structural features along the primary sequence of amino acids; 2-D prediction of spatial relationships between amino acids; 3-D prediction of the tertiary structure of a protein; and 4-D prediction of the quaternary structure of a multiprotein complex. A diverse set of both supervised and unsupervised machine learning methods has been applied over the years to tackle these problems and has significantly contributed to advancing the state-of-the-art of protein structure prediction. In this paper, we review the development and application of hidden Markov models, neural networks, support vector machines, Bayesian methods, and clustering methods in 1-D, 2-D, 3-D, and 4-D protein structure predictions.","1937-3333;19373333","","10.1109/RBME.2008.2008239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664428","Bioinformatics;machine learning;protein folding;protein structure prediction","Amino acids;Bioinformatics;Biology computing;Hidden Markov models;Learning systems;Neural networks;Protein engineering;Sequences;Support vector machines;Systems biology","Bayes methods;bioinformatics;hidden Markov models;learning (artificial intelligence);medical expert systems;molecular biophysics;neural nets;proteins;support vector machines","3D prediction;4D quaternary structure prediction;Bayesian methods;amino acids;bioinformatics;clustering methods;computational biology;hidden Markov models;machine learning methods;multiprotein complex;neural networks;protein structure prediction;protein tertiary structure;spatial relationship prediction;structural biology;support vector machines;systems biology","Bayes Theorem;Markov Chains;Models, Molecular;Neural Networks (Computer);Protein Conformation;Proteins;Sequence Analysis, Protein","15","","123","","20081105","2008","","IEEE","IEEE Journals & Magazines"
"Building virtual community in computational intelligence and machine learning [Research Frontier]","J. M. Zurada; M. A. Mazurowski; R. Ragade; A. Abdullin; J. Wojtudiak; J. Gentle","University of Louisville, USA","IEEE Computational Intelligence Magazine","20090123","2009","4","1","43","54","This paper tackles the issue of building a large-scale virtual organization for individuals and institutions that are associated with the field of computational intelligence (CI) and machine learning (ML). It begins with a few scenarios that will help illustrate the need for a virtual community in CIML.","1556-603X;1556603X","","10.1109/MCI.2008.930986","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4762310","","Collaboration;Collaborative software;Collaborative work;Computational intelligence;Geoscience;Grid computing;Machine learning;Pattern analysis;Search engines;Wikipedia","commerce;learning (artificial intelligence)","computational intelligence;large-scale virtual organization;machine learning;virtual community","","5","","8","","","February 2009","","IEEE","IEEE Journals & Magazines"
"A Machine Learning Based Reputation System for Defending Against Malicious Node Behavior","R. Akbani; T. Korkmaz; G. V. S. Raju","Dept. of Comput. Sci., Univ. of Texas, San Antonio, TX","IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference","20081208","2008","","","1","5","Reputation systems (RS) are designed to detect malicious nodes in a network and thwart their attacks, such as the spreading of viruses or worms, or attacking known vulnerabilities. They do this by collecting information about past transactions of a node and utilizing that to predict its future behavior. Traditionally, RSs have been designed by manually devising specific models or equations that use historical data to defend against certain types of attacks. In this paper, we propose a machine learning based RS that automates the process of devising the RS model and defends against many patterns of attacks. We discuss the merits of this approach and propose using support vector machines as the basis of the RS. We delineated the factors associated with building the SVM based RS and then proposed and evaluated our technique. We compared the performance of our RS with another RS found in the literature, called TrustGuard, and showed that our RS significantly outperforms TrustGuard. Our RS correctly distinguishes between good and malicious nodes with high accuracy, even when the proportion of malicious nodes in the network is very high.","1930-529X;1930529X","POD:978-1-4244-2324-8","10.1109/GLOCOM.2008.ECP.408","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4698183","","Buffer overflow;Feedback;Integral equations;Machine learning;Network servers;Peer to peer computing;Protocols;Support vector machines;System testing;Wireless sensor networks","computer viruses;learning (artificial intelligence);support vector machines;telecommunication security","TrustGuard;attack thwarting;machine learning based reputation system;malicious node behavior detection;support vector machine;virus spread;worms spread","","2","","11","","","Nov. 30 2008-Dec. 4 2008","","IEEE","IEEE Conference Publications"
"Adapting Pervasive Environments through Machine Learning and Dynamic Personalization","S. McBurney; E. Papadopoulou; N. Taylor; H. Williams","Heriot-Watt Univ., Edinburgh, UK","2008 IEEE International Symposium on Parallel and Distributed Processing with Applications","20081222","2008","","","395","402","Current pervasive environments should contain mechanisms, such as personalization, that adapt the environment to help the user meet their individual needs. However, manually creating, maintaining and utilizing a preference set is no easy task for a user, requiring continued time and effort. A more desirable approach is to implicitly build and maintain the preference set by using monitoring and learning mechanisms and apply such preferences when required on behalf of the user. This paper introduces the Daidalos Personalization and Learning system which monitors user behaviour and context to not only build and maintain dynamic preferences but also to apply them in a dynamic fashion. An example scenario is presented to demonstrate how such mechanisms are used to adapt a pervasive environment on a userÂ¿s behalf.","2158-9178;21589178","POD:978-0-7695-3471-8","10.1109/ISPA.2008.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725172","Dynamic;learning;personalization;pervasive;preferences","Computer network management;Distributed processing;Environmental management;Intelligent networks;Learning systems;Machine learning;Monitoring;Pervasive computing;Proposals;Technological innovation","learning (artificial intelligence);ubiquitous computing","Daidalos Personalization and Learning system;adapting pervasive environments;context;dynamic personalization;dynamic preferences;learning mechanisms;machine learning;user behaviour","","3","","18","","","10-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Improvement of MicroRNA Target Prediction Using An Enhanced Feature Set: A Machine Learning Approach","R. Mitra; S. Bandyopadhyay","Machine Intelligence Unit, Indian Statistical Institute 203, B. T. Road, Kolkata-700108, India. Email: rmitra","2009 IEEE International Advance Computing Conference","20090331","2009","","","428","433","MicroRNAs (miRNAs) are small non-coding RNA molecules that post-transcrlptionally regulate gene expression by base-pairing to mRNAs. Prediction of microRNA (miRNA)- target transcript pair is now in the forefront of current research. A number of experimental and computational approaches have already detected thousands of targets for hundreds of human miRNAs. However, most of the computational target prediction methods suffer from high false positive and false negative rate. One reason for this is the marked deficiency of negative examples or non-target data. Current machine learning based target prediction algorithms suffer from lack of sufficient number of negative examples to train the machine properly because only a limited number of biologically verified negative miRNA-target transcripts have been identified with respect to true miRNA- target examples. Hence researchers have to rely on artificial negative examples. But, it has been observed that these artificially generated negative examples can not provide a good prediction accuracy for the independent test data set. Therefore it is necessary to generate more confident artificial negative examples. In the proposed article we have predicted potential miRNA- target pairs with higher sensitivity and specificity based on a new way of generating negative examples. Firstly, artificial miRNAs are generated that are believed not to be a true miRNA. In this regard, we use a novel approach K-mer exchange between key and non-key regions of the miRNA. Based on the false miRNAs we search their potential targets by scanning entire 3' untranslated regions (UTRs) using the target prediction algorithm miRanda. Based on the newly generated negative examples and a set of biologically verified positive examples we trained the classifier SVM and classify a set of independent test samples. In this regard we have generated a set of 90 experimentally verified context specific features. Our prediction algorithm has been validated with - - an independent experimental data and we obtained a much higher prediction accuracy. The robust performance of the proposed method is mainly the result of using a large high-quality artificial negative examples and the integration of many biologically verified known and novel context specific features.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809049","","Accuracy;Gene expression;Humans;Machine learning;Machine learning algorithms;Prediction algorithms;Prediction methods;RNA;Sensitivity and specificity;Testing","biology computing;learning (artificial intelligence);macromolecules;molecular biophysics;support vector machines","artificial miRNA;classifier SVM;enhanced feature set;high-quality artificial negative examples;machine learning;microRNA target prediction","","1","","21","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"A machine learning based system for multichannel fluorescence analysis in pancreatic tissue bioimages","J. Herold; S. Abouna; L. Zhou; S. Pelengaris; D. B. A. Epstein; M. Khan; T. W. Nattkemper","Faculty of Technology, Biodata Mining & Applied Neuroinformatics Group, University of Bielefeld, 33615 Germany","2008 8th IEEE International Conference on BioInformatics and BioEngineering","20081208","2008","","","1","6","Fluorescence microscopy has regained much attention in the last years especially in the field of systems biology. It has been recognized as a rich source of information extending the existing sources since it allows simultaneous collection of spatial and temporal protein information. In order to enable a high-throughput and high-content image analysis, sophisticated image processing routines become essential. We present a machine learning based approach for semantic image annotation i.e. identifying biologically meaningful objects. A semantic annotation becomes necessary, if image variables have to be associated to single biological objects, for example cells. We apply our method to pancreatic tissue sample images to detect and annotate cells of the Islets of Langerhans and whole pancreas. Based on the annotation, aligned multichannel fluorescence images are evaluated for cell type classification allowing accurate and rapid determination of the cell number and mass. This high-throughput analytical technique, requiring only few parameters, should be of great value in diabetes studies and for screening of new anti-diabetes treatments.","","CD-ROM:978-1-4244-2845-8; POD:978-1-4244-2844-1","10.1109/BIBE.2008.4696798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696798","","Fluorescence;Image analysis;Image processing;Information resources;Learning systems;Machine learning;Microscopy;Pancreas;Proteins;Systems biology","biological tissues;bioluminescence;cellular biophysics;diseases;fluorescence;image classification;learning (artificial intelligence);medical computing;medical image processing;molecular biophysics","Islets of Langerhans cells;diabetes treatment;fluorescence microscopy;high content image analysis;image processing routines;machine learning based system;multichannel fluorescence analysis;pancreas cells;pancreatic tissue bioimages;protein information;semantic image annotation;systems biology","","1","","20","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
"Clustering Description Extraction Based on Statistical Machine Learning","C. Zhang; H. Xu","Dept. of Inf. Manage., Nanjing Univ. of Sci. & Technol., Nanjing","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","22","26","Clustering description problem is one of key issues of the traditional document clustering algorithm. The traditional document algorithm can cluster the objects, but it can not give concept description for the clustered results. Document clustering description is a problem of labeling the clustered results of document collection clustering. It can help users determine whether one of the clusters is relevant to users' information requirement. Therefore, labeling a clustered set of documents is an important and challenging work in document clustering applications. To resolve the problem of the weak readability of the traditional document clustering results, a method of automatic labeling documents clusters based on machine learning is put forward. Experimental results show that the method based on SVM will provide users with more concise and comprehensive document clustering results. It also reflects the linear trend of clustering description problem.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739719","Clustering Description;Document Clustering;Statistical Machine Learning","Clustering algorithms;Data mining;Frequency;Information management;Information technology;Labeling;Learning systems;Machine learning;Machine learning algorithms;Support vector machines","document handling;learning (artificial intelligence);pattern clustering;statistical analysis","clustered document labeling;document clustering description extraction;document collection clustering;statistical machine learning","","2","","15","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"feedback free DVC architecture using machine learning","J. L. Martinez; G. Fernandez-Escribano; H. Kalva; W. A. R. J. Weerakkody; W. A. C. Fernando; A. Garrido","Albacete Research Institute of Informatics. Universidad de Castilla-La Mancha. 02071, Spain","2008 15th IEEE International Conference on Image Processing","20081212","2008","","","1140","1143","Most of the reported distributed video coding (DVC) architectures have a serious limitation that hinders its practical application. The uses of a feedback channel between the encoder and the decoder require an interactive decoding procedure which is a limitation for applications such as offline processing. On the other hand, the decoder needs an efficient way to estimate the probability of error without assuming the availability of the original video at the decoder. In this paper we continue with our previous works into a more practical DVC architecture which solves both problems based on the use of machine learning. The proposed approach is based on extracting the relationships that exist between the residual frame and the number of requests over this feedback channel. We apply these concepts to pixel-domain Wyner-Ziv coding demonstrating significant savings in bitrates with a little loss of quality.","1522-4880;15224880","POD:978-1-4244-1765-0","10.1109/ICIP.2008.4711961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711961","DVC;Feedback Channel;Machine Learning;Turbo Codes;Wyner-Ziv coding","Bit error rate;Cameras;Computer architecture;Computer science;Feedback;Informatics;Iterative decoding;Machine learning;Video coding;Wireless sensor networks","decoding;error statistics;estimation theory;learning (artificial intelligence);probability;video coding","distributed video coding architectures;feedback channel;interactive decoding procedure;machine learning;offline processing;pixel-domain Wyner-Ziv coding","","13","","9","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Corrections to “Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies” [May 08 397-415]","Y. Jin; B. Sendhoff","","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","20090414","2009","39","3","373","373","In the above titled paper (ibid., vol. 38, no. 3, pp. 397-415, May 08), there are three sites where an inequality is put wrongly. The corrections are presented here.","1094-6977;10946977","","10.1109/TSMCC.2009.2018893","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813238","","","","","","6","","1","","20090410","May 2009","","IEEE","IEEE Journals & Magazines"
"Machine Learning Techniques Applied to Dynamic Video Adapting","R. Eisinger; R. A. F. Romero; R. Goularte","Adapmedia","2008 Seventh International Conference on Machine Learning and Applications","20081222","2008","","","819","822","In the past years, mobile devices were limited to textual content. However, the current generation has started to access richer multimedia content such as video, increasing the diversity of devices accessing the Web. Then, a problem arises as some of those devices characteristics like memory capacity or screen resolution turn the access to a content restricted. The present work considers the use of machine learning techniques as part of a dynamic video adaptation process, comparing the results from two of the most used approaches for data analysis, Multilayer Perceptron and Bayesian Inference, as part of a Decision Engine, analyzing data like device's capabilities, user's preferences and network condition in order to take the most appropriate way to adapt a video stream.","","POD:978-0-7695-3495-4","10.1109/ICMLA.2008.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725073","Bayesian Inference;Context-Aware Computing;Machine Learning;Neural Netqwork;Ubiquitous Computing;Video Adapting","Bandwidth;Bayesian methods;Computational efficiency;Data analysis;IPTV;Machine learning;Multilayer perceptrons;Search engines;Streaming media;Videoconference","Bayes methods;Internet;data analysis;inference mechanisms;learning (artificial intelligence);mobile handsets;multilayer perceptrons;video signal processing;video streaming","Bayesian inference;World Wide Web;content restricted;data analysis;decision engine;dynamic video adaptation process;dynamic video adapting;machine learning techniques;memory capacity;mobile devices;multilayer perceptron;multimedia content;screen resolution;textual content;video stream","","0","","13","","","11-13 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Class-Incremental Learning Method for Multi-Class Support Vector Machines in Text Classification","B. f. Zhang; J. s. Su; X. Xu","School of Computer, National University of Defense Technology, Changsha 410073, China. E-MAIL: bfzhang@nudt.edu.cn","2006 International Conference on Machine Learning and Cybernetics","20090304","2006","","","2581","2585","To solve multi-class problems of support vector machines (SVM) more efficiently, a novel framework, which we call class-incremental learning (CIL), is proposed in this paper. CIL consists of two phases: incremental feature selection and incremental training, for updating the knowledge of old SVM classifiers in text classification when new classes are added to the system. CIL reuses the old models of the classifier and learns only one binary sub-classifier with an additional phase of feature selection when a new class comes. In the testing phase, current classifier is applied to the vectors' projections on the sub-spaces concerned. CIL can serve as a flexible approach for all binary classification algorithms in text classification. Our experiment shows that the CIL-based SVM was not only substantially faster in training time than the popular batch SVM learning methods such as 1-against-rest, 1-against-1 and divide-by-2 but also almost competed to the best performances in effectiveness of them","2160-133X;2160133X","POD:1-4244-0061-9","10.1109/ICMLC.2006.258853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028499","Internet information filtering;Machine learning;class-incremental learning;feature selection;support vector machines;text classification","Automation;Cybernetics;Decision trees;Electronic mail;Information filtering;Information filters;Learning systems;Machine learning;Support vector machine classification;Support vector machines;Text categorization","Internet;classification;feature extraction;information filtering;learning (artificial intelligence);support vector machines;text analysis","Internet information filtering;SVM classifier;binary classification algorithm;class-incremental learning method;incremental feature selection;incremental training;multiclass support vector machine;text classification","","9","","10","","","13-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Applying Machine learning Algorithms for Email Management","T. Ayodele; S. Zhou","Department of Electronics and Computer Engineering, University of Portsmouth, United Kingdom. taiwo.ayodele@port.ac.uk","2008 Third International Conference on Pervasive Computing and Applications","20090213","2008","1","","339","344","This paper presents the design and implementation of a new system to predict whether email received require a reply, group emails and summarize email messages. The system uses not only subjects and headers fields but also content of email messages to classify emails based on users' activities and generate summaries of each incoming message with unsupervised learning approach. Our framework tackles the problem of email overload, congestion, difficulties in prioritizing and difficulties in finding previously archived messages in the mail box.","","CD-ROM:978-1-4244-2021-6; POD:978-1-4244-2020-9","10.1109/ICPCA.2008.4783606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4783606","email grouping;emails;reply prediction;summarization;unsupervised learning","Algorithm design and analysis;Business communication;Costs;Design engineering;Engineering management;Frequency;Machine learning algorithms;Postal services;Productivity;Unsupervised learning","electronic mail;learning (artificial intelligence)","email management;email overload;group emails;machine learning algorithms;summarize email messages;unsupervised learning","","1","","9","","","6-8 Oct. 2008","","IEEE","IEEE Conference Publications"
"A Machine Learning Approach to Fault Diagnosis of Rolling Bearings","M. Cococcioni; P. Forte; S. Manconi; C. Sacchi","Dipartimento di Ingegneria, dell'Informazione, University of Pisa, Via Diotisalvi, 2, 56122 Pisa, Italy, m.cococcioni@iet.unipi.it","2008 IEEE International Conference on Computational Cybernetics","20081222","2008","","","209","214","This paper presents a method based on classification techniques for automatic fault diagnosis of rolling element bearings. Experimental results achieved on vibration signals collected by an accelerometer on an experimental test rig show that the method can automatically detect different types of faults. Furthermore, the method is able, once trained on an appropriate representative set of basic faults, to recognize more serious faults, provided they are of the same type. We also analyzed the trend of correct classification of bearing faults on variation of the signal-to-noise ratio achieving high levels of robustness.","","CD-ROM:978-1-4244-2875-5; POD:978-1-4244-2874-8","10.1109/ICCCYB.2008.4721407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721407","Automatic Fault Detection;Pattern Classification;Rolling Bearings Vibrations Analysis","Fault detection;Fault diagnosis;Frequency;Machine learning;Monitoring;Robustness;Rolling bearings;Signal analysis;Testing;Vibrations","fault diagnosis;learning (artificial intelligence);pattern classification;rolling bearings;vibrations","accelerometer;fault diagnosis;machine learning;pattern classification;rolling bearings;vibration signals","","2","","9","","","27-29 Nov. 2008","","IEEE","IEEE Conference Publications"
"Analysis of machine learning techniques for context extraction","M. Granitzer; M. Kroll; C. Seifert; A. S. Rath; N. Weber; O. Dietzel; S. Lindstaedt","Knowledge Management Institute, Graz University of Technology, Austria","2008 Third International Conference on Digital Information Management","20090109","2008","","","233","240","dasiaContext is keypsila conveys the importance of capturing the digital environment of a knowledge worker. Knowing the userpsilas context offers various possibilities for support, like for example enhancing information delivery or providing work guidance. Hence, user interactions have to be aggregated and mapped to predefined task categories. Without machine learning tools, such an assignment has to be done manually. The identification of suitable machine learning algorithms is necessary in order to ensure accurate and timely classification of the userpsilas context without inducing additional workload. This paper provides a methodology for recording user interactions and an analysis of supervised classification models, feature types and feature selection for automatically detecting the current task and context of a user. Our analysis is based on a real world data set and shows the applicability of machine learning techniques.","","CD-ROM:978-1-4244-2917-2; POD:978-1-4244-2916-5","10.1109/ICDIM.2008.4746809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4746809","","Context modeling;Information retrieval;Knowledge management;Learning systems;Machine learning;Machine learning algorithms;Mutual information;Pattern matching;Support vector machine classification;Support vector machines","learning (artificial intelligence);pattern classification;user interfaces","context extraction;feature selection;machine learning techniques;supervised classification models;user interactions","","0","","11","","","13-16 Nov. 2008","","IEEE","IEEE Conference Publications"
"Machine learning techniques for diagnosing and locating faults through the automated monitoring of power electronic components in shipboard power systems","A. J. Mair; E. M. Davidson; S. D. J. McArthur; S. K. Srivastava; K. Schoder; D. A. Cartes","Institute for Energy and Environment, University of Strathclyde, Glasgow, UK","2009 IEEE Electric Ship Technologies Symposium","20090502","2009","","","469","476","The management and control of shipboard medium voltage AC (MVAC) and medium voltage DC (MVDC) power system architectures under fault conditions present a number of challenges. The use and resulting interaction of multiple power electronic components in mesh-like power distribution architectures possibly result in the effects of faults being detectable throughout the system, for example, line-to-hull faults on DC systems with high resistive grounding.","","POD:978-1-4244-3438-1","10.1109/ESTS.2009.4906553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906553","","Computerized monitoring;Condition monitoring;Control systems;Energy management;Machine learning;Medium voltage;Power electronics;Power system faults;Power system management;Voltage control","belief networks;decision trees;fault location;learning (artificial intelligence);power electronics;power engineering computing;ships;support vector machines","Bayesian networks;automated monitoring;decision trees;fault diagnosis;fault location;machine learning;medium voltage DC power system architectures;nearest neighbour classifiers;power electronic components;radial basis function networks;shipboard medium voltage AC;shipboard power systems;support vector machines","","4","","23","","","20-22 April 2009","","IEEE","IEEE Conference Publications"
"Optimal Cleaning Rule Selection Model Design Based on Machine Learning","H. Yan; X. c. Diao",".nstitute of Command Autom., PL A Univ.ofSci. & Tech., Nanjing","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","598","600","Considering the limited extensibility and the uneven capacity of the cleaning rule in current data cleaning work, this paper proposes an optimal cleaning rule selection model based on the machine learning. By establishing a cleaning rule performance evaluation system, the model realizes the optimal cleaning rule selection. It implements dynamic expansion of cleaning rule by the support of rules base. The model ensures the results of the data cleaning process and improves the performance of the data cleaning.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732896","cleaning rule;optimal","Cleaning;Data analysis;Humans;Information management;Information processing;Knowledge acquisition;Learning systems;Machine learning;Management information systems;Quality management","data analysis;data mining;knowledge based systems;learning (artificial intelligence)","machine learning;optimal data cleaning rule selection model design;performance evaluation system;rule base support","","0","","5","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Improving Job Scheduling in GRID Environments with Use of Simple Machine Learning Methods","D. Vladuic; A. Cernivec; B. Slivnik","XLAB d.o.o., Ljubljana","2009 Sixth International Conference on Information Technology: New Generations","20090610","2009","","","177","182","This paper presents an attempt to improve job scheduling over heterogeneous GRID nodes by employing machine learning methods. Our proposed architecture takes into account the fact that GRID frameworks and their modules are not easy to modify or re-implement. It is therefore our aim to provide a plug-in which can be easily added to existing frameworks, thus avoiding significant and time-consuming modifications. Furthermore, we assume that existing scheduling algorithm in the framework should not be completely overridden, but rather modified only if there are chances, based on historical data, that the modification will yield a better result. Finally, we focus on use of off-the-shelf simple machine learning methods in a black-box manner with internal parameter optimization. We present three experiments within a simulated environment, performed with synthetic data aimed at congestion of the system. The results show that improvements over the simple scheduling algorithms can be made.","","POD:978-1-4244-3770-2","10.1109/ITNG.2009.228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5070613","GRID;adaptive systems;distributed systems;machine learning;scheduling","Artificial intelligence;Decision trees;Information technology;Learning systems;Machine learning;Machine learning algorithms;Mesh generation;Processor scheduling;Round robin;Scheduling algorithm","grid computing;learning (artificial intelligence);scheduling","GRID environment;heterogeneous GRID nodes;job scheduling;machine learning;parameter optimization;plug-in;scheduling algorithm","","4","","15","","","27-29 April 2009","","IEEE","IEEE Conference Publications"
"Machine learning approaches to Information Retrieval and its applications to the web, medical informatics and health care","Xiangji Huang","York University, Toronto, Canada","2008 IEEE International Conference on Granular Computing","20081031","2008","","","39","40","With the ever-increasing large amount of digital information available, the need for advanced information retrieval (IR) systems increases. this wealth of digital information presents a major data-analysis challenge for us. How to manipulate, analyze and understand large quantities of complex data becomes extremely important. Over the past decades, significant progress has been made in IR. However, many challenges remain. First, most Web search engines take a short text query as input and output a ranked list of documents. The retrieval decision is made primarily based on the current query and document collection. Web search engines generally treat search requests in isolation. The results for a given query are identical, independent of the user or the context in which the user makes the request. However, it is unlikely that different users are so similar in their interests that one standardized way of retrieving information fits all needs. Different users may have different information needs. They may use the same query to search for different kinds of information. Moreover, even the same user may use identical queries to express different information needs. For example, a person may use ldquoIRIXrdquo to mean information retrieval in context at one time, but IRIX operating systems at another time. It is impossible for the current Web search engines to distinguish these two cases because the userpsilas search context is not considered. Second, IR is, in general, an interactive process. A userpsilas information need is rarely satisfied with just one iteration of search. With the current document-centered retrieval paradigm, interactive retrieval is treated as a sequence of independent simple retrieval decision-making steps. The information about search history is ignored, which makes the retrieval performance of existing IR systems inherently non-optimal. However, it has been brought into attention that analysis of task-oriented user sessions provides useful insight- - into the query behavior of the users. Third, most of present IR systems including general search engines (e.g. Google and Yahoo) and scientific literature search engines (e.g. PubMed and ACM Digital Library) use keywords to query and index documents. However, this traditional keyword-based IR model provides little semantic context for the understanding of user information needs. For example, a keyword usually has several senses and its meaning is ambiguous without context. In addition, one meaning can be expressed by many keywords. Thus, the integration of semantic context according to the userpsilas information need and the userpsilas understanding of the documents in the collection into IR systems will definitely improve the IR performance.","","POD:978-1-4244-2512-9","10.1109/GRC.2008.4664796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664796","","Biomedical informatics;Decision making;History;Information retrieval;Machine learning;Medical services;Operating systems;Search engines;Software libraries;Web search","data analysis;health care;learning (artificial intelligence);medical information systems;query formulation;search engines","Web search engines;data analysis;decision-making steps;document collection;document-centered retrieval paradigm;health care;information retrieval systems;literature search engines;machine learning;medical informatics","","0","","","","","26-28 Aug. 2008","","IEEE","IEEE Conference Publications"
"A Machine Learning Method for Dynamic Traffic Control and Guidance on Freeway Networks","K. Wen; S. Qu; Y. Zhang","Coll. of Autom., Northwestern Polytech. Univ., Xi'an","2009 International Asia Conference on Informatics in Control, Automation and Robotics","20090206","2009","","","67","71","A distributed approach to reinforcement learning in tasks of ramp metering and dynamic route guidance is presented. The problem domain, a freeway integration control application, is formulated as a distributed reinforcement learning problem. The DRL approach was implemented via a multi-agent control architecture where the decision agent was assigned to each of the on-ramp or VMS. The return of each agent is simultaneously updating a single shared policy. The control strategypsilas efficiency is demonstrated through its application to the simple freeway network. Analyses of simulation results using this approach show significant improvement over traditional local control, especially for the case of large traffic demand. Using the DRL approach, the TTS of the Network has been reduced by 20% under the heavy demands.","1948-3414;19483414","POD:978-0-7695-3519-7","10.1109/CAR.2009.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777196","freeway;reinforcement learning;traffic control;traffic model","Asia;Automatic control;Communication system traffic control;Geometry;Informatics;Learning systems;Road vehicles;Robot control;Robotics and automation;Traffic control","control engineering computing;learning (artificial intelligence);multi-agent systems;road traffic;traffic control;traffic engineering computing","DRL approach;VMS;dynamic route guidance;dynamic traffic control;freeway integration control application;freeway networks;guidance;machine learning method;multi-agent control architecture;ramp metering;reinforcement learning","","2","","8","","","1-2 Feb. 2009","","IEEE","IEEE Conference Publications"
"Machine learning approaches for soil classification in a multi-agent deficit irrigation control system","D. Smith; W. Peng","Tasmanian ICT Centre, CSIRO, Australia","2009 IEEE International Conference on Industrial Technology","20090519","2009","","","1","6","We propose a novel approach to automating soil texture classification from in situ sensors in the field. This approach exploits the features of a soil water retention model using machine learning algorithms. Knowledge of the soil textures is then used to learn the composition of the field and its soil horizons. We discuss the role of soil texture classification within our multi-agent irrigation control system and then conduct a preliminary experiment with soil water retention data from the UNSODA database. The system is evaluated with respect to six classifiers. A maximum classification rate of 85.11% was achieved with a MLP neural network, although performance was relatively consistent across all classifiers.","","POD:978-1-4244-3506-7","10.1109/ICIT.2009.4939641","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4939641","","Australia;Control systems;Geophysical measurements;Irrigation;Machine learning;Neural networks;Sensor systems;Soil measurements;Soil moisture;Soil texture","irrigation;learning (artificial intelligence);multi-agent systems;neural nets;soil","MLP neural network;UNSODA database;machine learning;multi-agent deficit irrigation control system;soil texture classification;soil water retention data;soil water retention model","","0","","16","","","10-13 Feb. 2009","","IEEE","IEEE Conference Publications"
"Support vector machine learning from positive and unlabeled samples","Ai-bing Ji; Qi-ming Niu; Ming-hu Ha","College of Medicine, Hebei University, Baoding 071000, China","2008 3rd International Conference on Intelligent System and Knowledge Engineering","20081230","2008","1","","978","982","In many machine learning settings, labeled samples are difficult to collect while unlabeled samples are abundant. We investigate in this paper the design of support vector machine classification algorithms learning from positive and unlabeled samples only. We first find the minimum bounding sphere that enclosed all the positive samples, and then use this minimum bounding sphere to pick out the negative samples from the unlabeled samples, at last we train the support vector machine using the training set which consists of the given positive samples and the negative samples picked out from the unlabeled samples. Experiments indicate that support vector machine learning from positive and unlabeled samples achieves the desired high test precision and prediction accuracy.","","POD:978-1-4244-2196-1","10.1109/ISKE.2008.4731071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731071","","Algorithm design and analysis;Classification algorithms;Data mining;Intelligent systems;Knowledge engineering;Learning systems;Machine learning;Medical diagnostic imaging;Support vector machine classification;Support vector machines","learning (artificial intelligence);pattern classification;support vector machines","classification algorithms;support vector machine learning","","0","","11","","","17-19 Nov. 2008","","IEEE","IEEE Conference Publications"
"A survey of techniques for internet traffic classification using machine learning","T. T. T. Nguyen; G. Armitage","Swinburne University of Technology, Melbourne, Australia","IEEE Communications Surveys & Tutorials","20090106","2008","10","4","56","76","The research community has begun looking for IP traffic classification techniques that do not rely on `well known' TCP or UDP port numbers, or interpreting the contents of packet payloads. New work is emerging on the use of statistical traffic characteristics to assist in the identification and classification process. This survey paper looks at emerging research into the application of Machine Learning (ML) techniques to IP traffic classification - an inter-disciplinary blend of IP networking and data mining techniques. We provide context and motivation for the application of ML techniques to IP traffic classification, and review 18 significant works that cover the dominant period from 2004 to early 2007. These works are categorized and reviewed according to their choice of ML strategies and primary contributions to the literature. We also discuss a number of key requirements for the employment of ML-based traffic classifiers in operational IP networks, and qualitatively critique the extent to which the reviewed works meet these requirements. Open issues and challenges in the field are also discussed.","1553-877X;1553877X","","10.1109/SURV.2008.080406","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4738466","Flow clustering;Internet Protocol;Machine Learning;Payload inspection;Real Time;Statistical traffic properties;Traffic classification","Government;Inspection;Internet;Intrusion detection;Machine learning;Payloads;Protocols;TCPIP;Telecommunication traffic;Telephony","","","","329","9","68","","","Fourth Quarter 2008","","IEEE","IEEE Journals & Magazines"
"Genetic machine learning approach for data fusion applications in dense Wireless Sensor Networks","A. R. Pinto; B. Bitencort; M. A. R. Dantas; C. B. Montez; F. Vasques","Automation and Systems Department, Federal University of Santa Catarina, Brazil","2008 IEEE International Conference on Emerging Technologies and Factory Automation","20081003","2008","","","1177","1180","Wireless sensor networks (WSN) are being targeted for use in applications like security, resources monitoring and factory automation. However, the reduced available resources raise a lot of technical challenges. Self-organization in WSN is a desirable characteristic that can be achieved by means of data fusion techniques when delivering reliable data to users. In this paper it is proposed a genetic machine learning algorithm (GMLA) approach that makes a trade-off between quality of information and communication efficiency. GMLA is based on genetic algorithms and it can adapt itself dynamically to environment modifications. The main target of the proposed approach is to achieve self-organization in a WSN application with data fusion. Simulations demonstrate that the proposed approach can optimize communication efficiency in a dense WSN.","1946-0740;19460740","CD-ROM:978-1-4244-1506-9; POD:978-1-4244-1505-2","10.1109/ETFA.2008.4638549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4638549","","Application software;Base stations;Computer science;Condition monitoring;Genetics;Machine learning;Machine learning algorithms;Manufacturing automation;Master-slave;Wireless sensor networks","genetic algorithms;learning (artificial intelligence);sensor fusion;telecommunication computing;wireless sensor networks","WSN self-organization;data fusion;dense wireless sensor networks;genetic machine learning","","1","","11","","","15-18 Sept. 2008","","IEEE","IEEE Conference Publications"
"A machine learning based approach of robust parameter design","Q. Cui; Z. He; N. Cui","Department of Industrial Engineering, Tianjin University, 300072, China","2006 International Technology and Innovation Conference (ITIC 2006)","20090119","2006","","","443","448","Dual response surface methodology (DRSM) and nonparametric methodology (NPM) are main approaches used to achieve robust parameter design (RPD) of industrial processes and products. When the relationship between influential input factors and output quality characteristic of a process is very complex, both approaches have their limitations. For DRSM, it fails to fit the real response surfaces of process mean and variance by using the second order polynomial models. For NPM, it is hard to optimize parameters of fitting equation, and it needs more experiments as well. From a machine learning perspective, this paper generalizes RPD as a restricted active learning problem and proposes a new approach to achieve it. It fits process mean and variance responses by support vector machines (SVM), and then optimizes levels of design parameters by genetic algorithm. In order to reduce experiment times, the influence of priori knowledge on generalized error of fitting model is studied. Then a prior knowledge based experiment design is developed. Moreover, the approach selects the form of kernel function and optimizes parameters in SVM by comparing the upper bounds of generalized error of different SVM models without extra samples. The example given in the paper shows that, the generalized error and the experiment times of the approach decrease by no less than 45% and 39% respectively, compared with traditional approaches. All these results demonstrate the adaptability and superiority of the approach proposed in the paper.","0537-9989;05379989","Paper:0-86341-696-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4752040","Product design;parameter estimation;quality control;robust;support vector machines","","","","","0","","","","","6-7 Nov. 2006","","IET","IET Conference Publications"
"Multi-output Support Vector Machine Regression and Its Online Learning","H. Gensheng; L. Dong","Educ. Dept. Key Lab. of IC & SP, Anhui Univ., Hefei","2008 International Conference on Computer Science and Software Engineering","20081222","2008","4","","878","881","This paper introduces multi-output support vector machine regression (M-SVR) by using the re-weight iterative algorithm. Then the problem of online learning of M-SVR is solved by given the iterative formula for the weight of regression function using the gradient descent algorithm of instantaneous risk. Computer experiments show that the accuracy and workload of the algorithm are superior to that using several one-dimensional output SVRs algorithm.","","POD:978-0-7695-3336-0","10.1109/CSSE.2008.1024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722758","multi-output regression;online learning;support vector machine","Computer science;Hilbert space;Iterative algorithms;Kernel;Laboratories;Machine learning;Paper technology;Software engineering;Statistical learning;Support vector machines","learning (artificial intelligence);regression analysis;support vector machines","multi-output regression;online learning;support vector machine","","0","","7","","","12-14 Dec. 2008","","IEEE","IEEE Conference Publications"
"Electrofused magnesium oxide classification using digital image processing and machine learning techniques","A. B. M. S. Ali; W. K. D. Pun","School of Computing Sciences, CQ University Australia, Queensland 4702 Australia","2009 IEEE International Conference on Industrial Technology","20090519","2009","","","1","6","This research is focused on using digital image processing and machine learning techniques to classify electrofused magnesia for industry automation. We generate the data from different images by using a modern digital image process. This research proposes a new method to construct the digital image database. The proposed new method is based on simple histogram mode and intensity deviation. A group of six popular machine learning algorithms has been tested to build up an automatic system for industry. We have concluded that the best suited algorithm for magnesia industry automation from this group is the PART algorithm.","","POD:978-1-4244-3506-7","10.1109/ICIT.2009.4939738","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4939738","","Automatic testing;Automation;Digital images;Histograms;Image databases;Machine learning;Machine learning algorithms;Magnesium compounds;Magnesium oxide;System testing","image classification;learning (artificial intelligence);magnesium compounds;mineral processing industry","MgO;PART algorithm;digital image database;digital image processing;electrofused magnesium oxide classification;machine learning algorithm testing;machine learning technique;magnesia industry automation;simple histogram mode","","1","","9","","","10-13 Feb. 2009","","IEEE","IEEE Conference Publications"
"Improving mispronunciation detection using machine learning","Y. Chen; C. Huang; F. Soong","Department of Computer Science and Engineering, Shanghai Jiao Tong University, China","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","4865","4868","In this paper, we investigate the problem of mispronunciation detection by considering the influence of speaker and syllables. Machine learning techniques are used to make our method more convenient and flexible for new features, such as syllables normalization. The experimental results on our database, consisting of 9898 syllables pronounced by 100 speakers, show the effectiveness of our method by reducing the average false acceptance rate (FAR) by 42.5% using data set generated by model without adaptation to observation set and reducing average FAR by 32.5% using data set generated by model with adaptation to observation set.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960721","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960721","Automatic Mispronunciation Detection (AMD);Computer Aided Language Learning (CALL);Machine Learning","Adaptation model;Asia;Chaos;Computer science;Hidden Markov models;Knowledge engineering;Learning systems;Machine learning;Machine learning algorithms;Support vector machines","computer aided instruction;learning (artificial intelligence);speech processing","Mandarin;automatic mispronunciation detection;computer assisted language learning;database;false acceptance rate;machine learning;syllables normalization","","6","","7","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Genetics-Based Machine Learning Approach for Rule Acquisition in an AGV Transportation System","K. Sakakibara; Y. Fukui; I. Nishikawa","Ritsumeikan Univ., Kusatsu","2008 Eighth International Conference on Intelligent Systems Design and Applications","20081208","2008","3","","115","120","We propose an autonomous decentralized method for multiple AGV robots under uncertain delivery requests. Transportation route plans of AGV robots are expected to minimize the transportation time without collisions among the robots in the systems. In our proposed methods, each robot as an agent computes its transportation route by referring to the static path information, and it exchanges its route plan each other. Once collisions are detected, one of the two agents chosen by a negotiation rule modifies its route plan. The rule consists of a condition-part and an action-part, and one rule which matches to the conditions of two agents under negotiation is selected from a set of rules. The rules are generated and improved by a genetic based machine learning approach, where a set of rules is represented symbolically as an individual of genetic algorithms, and fitness of each individual is determined according to the total travel time of the AGVs and the adequacy of the condition-parts of the rules.","2164-7143;21647143","POD:978-0-7695-3382-7","10.1109/ISDA.2008.329","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696447","Automated guided vehicle;Autonomous decentralized system;Genetics-based machine learning;Pitt approach;Transportation","Cities and towns;Genetic algorithms;Intelligent robots;Intelligent transportation systems;Learning systems;Machine learning;Production planning;Production systems;Routing;Vehicles","collision avoidance;control engineering computing;genetic algorithms;intelligent robots;knowledge acquisition;learning (artificial intelligence);mobile robots;transportation","automated guided vehicle transportation system;autonomous decentralized method;genetic algorithms;genetics-based machine learning approach;multiple automated guided vehicle robots;rule acquisition;transportation route planning","","4","","10","","","26-28 Nov. 2008","","IEEE","IEEE Conference Publications"
"Research on Semi-Automatic Construction of Domain Ontology Based on Machine Learning and Clustering Technique","L. He; H. q. Hou","Dept. of Inf. Manage., Nanjing Agric. Univ., Nanjing","2008 International Symposium on Intelligent Information Technology Application Workshops","20081230","2008","","","345","348","In this paper we take the approach that constructed the ontology automatically, which attempted to take a method that extremely beneficial for the knowledge acquisition task was the integration of knowledge acquisition with machine learning techniques to increase the ontology construction effect, including domain concepts acquisition, taxonomy relation recognition, non-taxonomy relation recognition and ontology formalization description. This paper adopted an approach of non-dictionary Chinese word Segmentation techniques based on N-Gram to acquire domain candidate concepts, take the method based of NLP in the recognition of domain concept property relation, extracted subject, predicate and object of sentences. This triangle data can be treated as the triplet of data and object type property.","","POD:978-0-7695-3505-0","10.1109/IITA.Workshops.2008.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731948","Domain Ontology;Hierarchy Relationship;Semi-Automatic Construction;concept Acquisition;domain Relationship","Buildings;Clustering algorithms;Data mining;Decision trees;Knowledge acquisition;Machine learning;Ontologies;Pattern matching;Semantic Web;Vocabulary","knowledge acquisition;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);word processing","N-Gram;NLP;clustering technique;knowledge acquisition;machine learning techniques;natural language processing;nondictionary Chinese word segmentation techniques;ontology formalization description;semi-automatic domain ontology construction","","0","","8","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Cross-Input Learning and Discriminative Prediction in Evolvable Virtual Machines","F. Mao; X. Shen","Comput. Sci. Dept., Coll. of William & Mary, Williamsburg, VA","2009 International Symposium on Code Generation and Optimization","20090505","2009","","","92","101","Modern languages like Java and C# rely on dynamic optimizations in virtual machines for better performance. Current dynamic optimizations are reactive. Their performance is constrained by the dependence on runtime sampling and the partial knowledge of the execution. This work tackles the problems by developing a set of techniques that make a virtual machine evolve across production runs. The virtual machine incrementally learns the relation between program inputs and optimization strategies so that it proactively predicts the optimizations suitable for a new run. The prediction is discriminative, guarded by confidence measurement through dynamic self-evaluation. We employ an enriched extensible specification language to resolve the complexities in program inputs. These techniques, implemented in Jikes RVM, produce significant performance improvement on a set of Java applications.","","POD:978-0-7695-3576-0","10.1109/CGO.2009.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907654","Adaptive Optimization;Cross-Input Learning;Discriminative Prediction;Evolvable Computing;Input-Centric Optimization;Java Virtual Machine","Computer science;Feature extraction;Java;Machine learning;Predictive models;Production;Programming profession;Runtime;Sampling methods;Virtual machining","learning (artificial intelligence);optimising compilers;specification languages;virtual machines","C# language;Java application;cross-input learning;discriminative prediction;dynamic optimization;incremental learning;specification language;virtual machine","","3","","19","","","22-25 March 2009","","IEEE","IEEE Conference Publications"
"Learning Finite-State Machine Controllers From Motion Capture Data","M. Gillies","Dept. of Comput., Univ. of London, London","IEEE Transactions on Computational Intelligence and AI in Games","20090502","2009","1","1","63","72","With characters in computer games and interactive media increasingly being based on real actors, the individuality of an actor's performance should not only be reflected in the appearance and animation of the character but also in the AI that governs the character's behavior and interactions with the environment. Machine learning methods applied to motion capture data provide a way of doing this. This paper presents a method for learning the parameters of a finite-state machine (FSM) controller. The method learns both the transition probabilities of the FSM and also how to select animations based on the current state.","1943-068X;1943068X","","10.1109/TCIAIG.2009.2019630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812072","3-D animation;Game AI;machine learning;motion capture","","computer animation;finite state machines;learning (artificial intelligence);motion estimation","animations;learning finite-state machine controllers;machine learning methods;motion capture data;transition probabilities","","1","","31","","20090407","March 2009","","IEEE","IEEE Journals & Magazines"
"Adaptive Neuro-Fuzzy Control with Fuzzy Supervisory Learning Algorithm for Speed Regulation of 4-Switch Inverter Brushless DC Machines","A. H. Niasar; H. Moghbelli; A. Vahedi","Department of Electrical Engineering, Iran University of Science & Technology, Tehran, Iran. halvai@iust.ac.ir","2006 CES/IEEE 5th International Power Electronics and Motion Control Conference","20090210","2006","1","","1","5","Principle of a new adaptive neuro-fuzzy inference system (ANFIS) with supervisory learning algorithm is introduced and is used to regulate the speed of a four-switch, three-phase inverter (FSTPI) brushless DC (BLDC) drive. The proposed algorithm has advantages of neural and fuzzy networks. To enhance of drive's performance, instead of well-known back propagation learning method, a fuzzy based supervisory learning algorithm is used. This newly developed design leads to a controller with minimum structure and improved dynamic performance. System implementation is relatively easy since it has minimum fuzzy rules and membership functions as compared with the conventional fuzzy and/or neural networks, used for electrical drive applications. In order to demonstrate the proposed ANFIS controller abilities to follow the reference speed and to reject disturbances, its performance is simulated and compared with that of a conventional PI controller","","POD:1-4244-0448-7","10.1109/IPEMC.2006.4778053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4778053","","Adaptive control;Adaptive systems;DC machines;Fuzzy control;Fuzzy neural networks;Fuzzy systems;Inference algorithms;Inverters;Machine learning;Programmable control","DC motor drives;adaptive control;angular velocity control;backpropagation;brushless DC motors;fuzzy control;fuzzy neural nets;inference mechanisms;invertors;machine control;neurocontrollers;switching convertors","ANFIS controller;adaptive neuro-fuzzy inference system;dynamic performance;four-switch three-phase inverter brushless DC drive;fuzzy supervisory learning algorithm;speed regulation","","2","","16","","","14-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Microarray Analysis of Autoimmune Diseases by Machine Learning Procedures","R. ArmaÑanzas; B. Calvo; I. Inza; M. LÓpez-Hoyos; V. MartÍnez-Taboada; E. Ucar; I. Bernales; A. Fullaondo; P. LarraÑaga; A. M. Zubiaga","Dept. of Comput. Sci. & Artificial Intell., Univ. of the Basque Country, San Sebastian","IEEE Transactions on Information Technology in Biomedicine","20090505","2009","13","3","341","350","Microarray-based global gene expression profiling, with the use of sophisticated statistical algorithms is providing new insights into the pathogenesis of autoimmune diseases. We have applied a novel statistical technique for gene selection based on machine learning approaches to analyze microarray expression data gathered from patients with systemic lupus erythematosus (SLE) and primary antiphospholipid syndrome (PAPS), two autoimmune diseases of unknown genetic origin that share many common features. The methodology included a combination of three data discretization policies, a consensus gene selection method, and a multivariate correlation measurement. A set of 150 genes was found to discriminate SLE and PAPS patients from healthy individuals. Statistical validations demonstrate the relevance of this gene set from an univariate and multivariate perspective. Moreover, functional characterization of these genes identified an interferon-regulated gene signature, consistent with previous reports. It also revealed the existence of other regulatory pathways, including those regulated by PTEN, TNF, and BCL-2, which are altered in SLE and PAPS. Remarkably, a significant number of these genes carry E2F binding motifs in their promoters, projecting a role for E2F in the regulation of autoimmunity.","1089-7771;10897771","","10.1109/TITB.2008.2011984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4909497","Antiphospholipid syndrome;DNA microarrays;gene profiling;machine learning;systemic lupus erythematosus","Algorithm design and analysis;DNA;Data analysis;Diseases;Gene expression;Genetics;Hospitals;Machine learning;Machine learning algorithms;Pathogens","cellular biophysics;diseases;genetics;learning (artificial intelligence);medical expert systems;molecular biophysics","autoimmune diseases;data discretization policy;gene selection method;global gene expression profiling;machine learning;microarray analysis;microarray expression;multivariate correlation measurement;pathogenesis;primary antiphospholipid syndrome;statistical algorithms;systemic lupus erythematosus","Analysis of Variance;Antiphospholipid Syndrome;Artificial Intelligence;Bayes Theorem;Cluster Analysis;Female;Gene Expression Profiling;Gene Expression Regulation;Humans;Logistic Models;Lupus Erythematosus, Systemic;Models, Genetic;Oligonucleotide Array Sequence Analysis;Reproducibility of Results;Reverse Transcriptase Polymerase Chain Reaction","8","","78","","","May 2009","","IEEE","IEEE Journals & Magazines"
"An ASM fitting method based on machine learning that provides a robust parameter initialization for AAM fitting","M. Wimmer; S. Fujie; F. Stulp; T. Kobayashi; B. Radig","Perceptual Computing Lab, Waseda University, Tokyo, Japan","2008 8th IEEE International Conference on Automatic Face & Gesture Recognition","20090410","2008","","","1","6","Due to their use of information contained in texture, active appearance models (AAM) generally outperform active shape models (ASM) in terms of fitting accuracy. Although many extensions and improvements over the original AAM have been proposed, on of the main drawbacks of AAMs remains its dependence on good initial model parameters to achieve accurate fitting results. In this paper, we determine the initial model parameters for AAM fitting with ASM fitting, and use machine learning techniques to improve the scope and accuracy of ASM fitting. Combining the precision of AAM fitting with the large radius of convergence of learned ASM fitting improves the results by an order of magnitude, as our empirical evaluation on a database of publicly available benchmark images demonstrates.","","CD-ROM:978-1-4244-2154-1; POD:978-1-4244-2153-4","10.1109/AFGR.2008.4813465","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813465","","Active appearance model;Active shape model;Convergence;Data mining;Deformable models;Image databases;Machine learning;Optimization methods;Parameter estimation;Robustness","approximation theory;image sequences;image texture;learning (artificial intelligence)","AAM fitting;ASM fitting;active appearance model fitting method;active shape model fitting method;approximation theory;image sequence;image texture;machine learning;robust parameter initialization","","1","","25","","","17-19 Sept. 2008","","IEEE","IEEE Conference Publications"
"Performance evaluation of a machine learning algorithm for early application identification","G. Verticale; P. Giacomazzi","Dipartimento di Elettronica e Informazione, Politecnico di Milano, Italy","2008 International Multiconference on Computer Science and Information Technology","20090109","2008","","","845","849","The early identification of applications through the observation and fast analysis of the associated packet flows is a critical building block of intrusion detection and policy enforcement systems. The simple techniques currently used in practice, such as looking at the transport port numbers or at the application payload, are increasingly less effective for new applications using random port numbers and/or encryption. Therefore, there is increasing interest in machine learning techniques capable of identifying applications by examining features of the associated traffic process such as packet lengths and inter-arrival times. However, these techniques require that the classification algorithm is trained with examples of the traffic generated by the applications to be identified, possibly on the link where the the classifier will operate. In this paper we provide two new contributions. First, we apply the C4.5 decision tree algorithm to the problem of early application identification (i.e. looking at the first packets of the flow) and show that it has better performance than the algorithms proposed in the literature. Moreover, we evaluate the performance of the classifier when training is performed on a link different from the link where the classifier operates. This is an important issue, as a pre-trained portable classifier would greatly facilitate the deployment and management of the classification infrastructure.","","POD:978-83-60810-14-9","10.1109/IMCSIT.2008.4747340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4747340","","Bayesian methods;Classification algorithms;Clustering algorithms;Computer science;Hidden Markov models;Inspection;Machine learning;Machine learning algorithms;Payloads;Peer to peer computing","cryptography;decision trees;learning (artificial intelligence);software performance evaluation;telecommunication traffic","C4.5 decision tree algorithm;associated packet flows;associated traffic process;classification algorithm;encryption;intrusion detection;machine learning algorithm;performance evaluation;policy enforcement systems;random port numbers;transport port numbers","","5","","17","","","20-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Machine Learning Tools to Time Series Forecasting","K. Ramírez-Amaro; J. C. Chimal-Eguía","Centro de Investig. en Comput., Inst. Politec. Nac., Mexico City","2007 Sixth Mexican International Conference on Artificial Intelligence, Special Session (MICAI)","20081028","2007","","","91","101","In this paper a new input representation of the data of the time series and a new learning approach is presented. The input data representation is based on the information obtained by the division of image axis of the time series into boxes. Then, this new information is implemented in a new learning technique which through probabilistic mechanism this learning could be applied to the interesting forecasting problem. The results indicate that using the methodology proposed in this article it is possible to obtain forecasting results with good enough accuracy.","","POD:978-0-7695-3124-3","10.1109/MICAI.2007.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4659299","Forecasting;Machine Learning;Time Series","Artificial intelligence;Cities and towns;Economic forecasting;Machine learning;Mathematical model;Temperature;Time measurement;Upper bound","data structures;forecasting theory;learning (artificial intelligence);time series","image axis;machine learning tools;probabilistic mechanism;time series forecasting","","0","","11","","","4-10 Nov. 2007","","IEEE","IEEE Conference Publications"
"A Chinese Word Segmentation Based on Machine Learning","W. Hongsheng; C. Mingming","Coll. of Inf. Sci. & Eng., Shenyang Univ. of Technol., Shenyang","2009 First International Workshop on Education Technology and Computer Science","20090526","2009","2","","610","613","Different from English, there are no interval marks between words in Chinese. Segmenting Chinese text to words is the first job for every kind of Chinese information processing, so Chinese word segmentation is a basal and difficult issue in the field of Chinese information processing. Traditional word segmentation systems have to establish the dictionary and add unknown words out of the dictionary with manual work. This paper proposes a new Chinese word segmentation model which can automatically establish a dictionary, gradually update it and perfect it based on machine learning. Four modules of the machine learning model for Chinese word segmentation system are introduced in detail and some improvements of the algorithms are made on some module to improve system performance. After the test of closed corpus and open corpus, the results show that the method alleviates the workload of building and maintaining the dictionary, furthermore, it resolves the issues of ambiguity processing and unknown words recognition.","","POD:978-0-7695-3557-9","10.1109/ETCS.2009.397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959112","Chinese word segmentation;ambiguity processing;artificial dictionary;machine learning;unknown words recognition","Dictionaries;Educational institutions;Educational technology;Information processing;Information science;Machine learning;Machine learning algorithms;Natural languages;Probability;Speech recognition","learning (artificial intelligence);natural language processing;word processing","Chinese information processing;Chinese word segmentation;English;dictionary;machine learning","","0","","4","","","7-8 March 2009","","IEEE","IEEE Conference Publications"
"Self Learning and its Implications for Machine Understanding","W. Dinalankara; D. De Silva; D. Alahakoon","Cognitive and Connectionist Systems Lab, Monash University, Victoria, Australia. wikumdina@yahoo.com","2008 4th International Conference on Information and Automation for Sustainability","20090213","2008","","","507","512","Contemporary machine intelligence is far from realizing prominent hallmarks of human understanding and consciousness. The primary shortcoming of current methods can be attributed to the difficulty or implausibility of foreseeing and pre-programming each and every piece of information or knowledge. Emergent intelligence methods based on principles of self learning and self organization have been successful in infusing traits of understanding in machines. This understanding is in contrast to the constrained intelligence permeated on machines by classical approaches of intelligence following supervised knowledge acquisition mechanisms. The primary objective of this paper is to review current work in emergent intelligence methods and discuss means of orchestrating these in to a practical model that resembles the process of human understanding. The paper delineates intricacies of self-learning in humans from both biological and psychological perspectives. Following a discussion of several artificial models of the human mind that have been researched and documented at the conceptual level, we propose a comparatively pragmatic approach based on a novel unsupervised learning algorithm, the GSOM algorithm. This algorithm has been successfully applied to many real world knowledge acquisition and pattern discovery problems. The paper concludes with a further discussion of research developments in emergent systems, which we perceive to be the stepping stones in the search for true machine understanding.","2151-1802;21511802","CD-ROM:978-1-4244-2900-4; POD:978-1-4244-2899-1","10.1109/ICIAFS.2008.4783985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4783985","artificial cognition;growing self organising map algorithm;multi-modal data fusion;self learning;unsupervised learning","Artificial intelligence;Biological system modeling;Cognition;Humans;Image recognition;Knowledge acquisition;Learning systems;Machine learning;Supervised learning;Unsupervised learning","emergent phenomena;knowledge acquisition;learning (artificial intelligence);self-adjusting systems","GSOM algorithm;artificial model;biological perspective;constrained intelligence;contemporary machine intelligence;emergent intelligence;emergent systems;machine understanding;pattern discovery;pragmatic approach;psychological perspective;self learning;self organization;supervised knowledge acquisition;unsupervised learning","","0","","16","","","12-14 Dec. 2008","","IEEE","IEEE Conference Publications"
"support vector machine learning based traffic sign detection and shape classification using Distance to Borders and Distance from Center features","C. G. Kiran; L. V. Prabhu; V. Abdu Rahiman; K. Rajeev; A. Sreekumar","Technology Development Center, Network Systems & Technologies (P) Ltd., Technopark Campus, Thiruvananthapuram, India","TENCON 2008 - 2008 IEEE Region 10 Conference","20090127","2008","","","1","6","A vision based vehicle guidance system deals with the detection and recognition of traffic signs. Traffic sign recognition system collects information ahead on the road and helps the driver to make timely decisions, making driving safer and easier. This paper deals with the detection and shape classification of traffic signs from image sequences using color information. Color based segmentation techniques are employed for traffic sign detection. In this work, hue and saturation components are enhanced using look up tables. In order to improve the performance of segmentation, we used the product of enhanced hue and saturation components. Shape classification is performed using linear support vector machine. Better shape classification performance is obtained using Distance to Border and Distance from Center features of the segmented blobs.","2159-3442;21593442","CD-ROM:978-1-4244-2409-2; POD:978-1-4244-2408-5","10.1109/TENCON.2008.4766535","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4766535","","Driver circuits;Image segmentation;Image sequences;Machine learning;Roads;Shape;Support vector machine classification;Support vector machines;Telecommunication traffic;Vehicle detection","driver information systems;image classification;image colour analysis;image segmentation;image sequences;learning (artificial intelligence);support vector machines","color based segmentation;color information;enhanced hue;image sequences;linear support vector machine learning;segmented blobs;shape classification performance;traffic sign detection;traffic sign recognition system;vision based vehicle guidance system","","5","1","15","","","19-21 Nov. 2008","","IEEE","IEEE Conference Publications"
"Genre identification of Chinese finance text using machine learning method","Jun Xu; Yuxin Ding; X. Wang; Yonghui Wu","Department of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","455","459","Document genre information is one of the most distinguishing features in information retrieval, which brings order to the search results. What the genre classification concerned is not the topic but the genre of document. In this paper, we examine the effectiveness of using machine learning techniques to solve genre classification of Chinese text with the same topic, viz. finance. Based on the likelihood ratio test, we present a new method for selecting feature terms, which can improve the performance clearly and perform better than others with up to 80% terms removal. In empirical results with SVMs classifier on the real world corpora, we find that this method can gain a better selecting effect and likelihood ratio is a reliable measure for selecting informative features.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811318","Genre Classification;Likelihood Ratio Test;Support Vector Machines","Computer science;Finance;Gain measurement;IEEE news;Information retrieval;Learning systems;Machine learning;Performance evaluation;Search engines;Testing","financial data processing;learning (artificial intelligence);pattern classification;support vector machines;text analysis","Chinese finance text;SVMs classifier;genre classification;genre identification;likelihood ratio test;machine learning method;support vector machine","","1","","14","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Machine learning based online performance prediction for runtime parallelization and task scheduling","J. Li; X. Ma; K. Singh; M. Schulz; B. R. de Supinski; S. A. McKee","Dept. of Computer Science, North Carolina State University, Raleigh, 27606, USA","2009 IEEE International Symposium on Performance Analysis of Systems and Software","20090512","2009","","","89","100","With the emerging many-core paradigm, parallel programming must extend beyond its traditional realm of scientific applications. Converting existing sequential applications as well as developing next-generation software requires assistance from hardware, compilers and runtime systems to exploit parallelism transparently within applications. These systems must decompose applications into tasks that can be executed in parallel and then schedule those tasks to minimize load imbalance. However, many systems lack a priori knowledge about the execution time of all tasks to perform effective load balancing with low scheduling overhead. In this paper, we approach this fundamental problem using machine learning techniques first to generate performance models for all tasks and then applying those models to perform automatic performance prediction across program executions. We also extend an existing scheduling algorithm to use generated task cost estimates for online task partitioning and scheduling. We implement the above techniques in the pR framework, which transparently parallelizes scripts in the popular R language, and evaluate their performance and overhead with both a real-world application and a large number of synthetic representative test scripts. Our experimental results show that our proposed approach significantly improves task partitioning and scheduling, with maximum improvements of 21.8%, 40.3% and 22.1% and average improvements of 15.9%, 16.9% and 4.2% for LMM (a real R application) and synthetic test cases with independent and dependent tasks, respectively.","","POD:978-1-4244-4184-6","10.1109/ISPASS.2009.4919641","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4919641","Artificial Neural Networks;Automatic Task Scheduling;Performance Prediction;Scripting Languages","Application software;Costs;Hardware;Load management;Machine learning;Parallel programming;Predictive models;Runtime;Scheduling algorithm;Testing","authoring languages;learning (artificial intelligence);parallel programming;scheduling;task analysis","R language;automatic performance prediction;machine learning;next-generation software;online performance prediction;online task partitioning;pR framework;parallel programming;program execution;runtime parallelization;scripting language;task cost estimates;task scheduling","","7","","46","","","26-28 April 2009","","IEEE","IEEE Conference Publications"
"Supporting Customer Searches in E-marketplaces by Means of Fuzzy Logic-Based Machine Learning","J. Albusac; L. M. López-López; J. M. Murillo; J. J. Castro-Schez","Escuela Super. de Inf., Univ. de Castilla-La Mancha, Ciudad Real","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","892","896","Machine learning algorithms can be used to discover patterns in data into e-commerce C2C portals and this knowledge can then be useful to help customers to refine their searches and to choose what to buy. In this work, it is proposed a new machine learning algorithm based on fuzzy logic. We describe the proposed algorithm for supporting customer searches in e-marketplaces and show the results obtained on simulated examples.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740571","C2C;decision support;e-Marketplace;e-commerce;fuzzy logic;machine learning;soft computing","Electronic commerce;Fuzzy logic;Fuzzy systems;Intelligent agent;Learning systems;Machine learning;Machine learning algorithms;Marketing and sales;Portals;Uncertainty","data mining;electronic commerce;fuzzy logic;information retrieval;learning (artificial intelligence);portals","C2C portal;customer search support;data mining;e-commerce;e-marketplace;fuzzy logic;machine learning;pattern discovery","","3","","12","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Boltzmann Machine Topology Learning for Distributed Sensor Networks Using Loopy Belief Propagation Inference","C. Picus; L. Cambrini; W. Herzner","Austrian Res. Centers GmbH (ARC), Vienna, Austria","2008 Seventh International Conference on Machine Learning and Applications","20081222","2008","","","344","349","Distributed sensor networks, as opposed to centralized networks, offer several advantages in terms of versatility and increased safety, which make their use particularly relevant for applications of security surveillance. A challenge of such systems is how to build autonomously a global description of the sensed environment without supervision of a central processing unit and with minimal configuration effort. We present an approach to ubiquitous computing, based on a semantic representation of the world view in terms of correlation of local information learned at the local level. There, a statistical description of the sensed activity is provided. Correlations of events among nodes are learned using a Boltzmann machine approach and used in order to establish neighborhood correspondences. Moreover, the communication between nodes is used to enrich the local description of the sensed environment by approximating the a-posterior distributions by marginal distributions computed with the loopy belief propagation algorithm. We present results of simulations emulating a security surveillance environment in which the sensors are cameras and activity is learned by processing video data.","","POD:978-0-7695-3495-4","10.1109/ICMLA.2008.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724996","Boltzmann machine;distributed sensor networks;loopy belief propagation;topology learning","Belief propagation;Central Processing Unit;Computational modeling;Data security;Distributed computing;Machine learning;Network topology;Safety;Surveillance;Ubiquitous computing","Boltzmann machines;distributed sensors;learning (artificial intelligence);topology;ubiquitous computing","Boltzmann machine topology learning;distributed sensor networks;loopy belief propagation inference;ubiquitous computing;video data","","2","","12","","","11-13 Dec. 2008","","IEEE","IEEE Conference Publications"
"Fuzzy Neuro Systems for Machine Learning for Large Data Sets","R. Kala; A. Shulkla; R. Tiwari","rahulkalaiiitm@yahoo.co.in, Department of Information Tecehology, Indian Institute of Information Technology and Management Gwalior","2009 IEEE International Advance Computing Conference","20090331","2009","","","541","545","Artificial Neural Networks have found a variety of applications that cover almost every domain. The increasing use of Artificial Neural Networks and machine learning has led to a huge amount of research and making in of large data sets that are used for training purposes. Handwriting recognition, speech recognition, speaker recognition, face recognition are some of the varied areas of applications of artificial neural networks. The larger training data sets are a big boon to these systems as the performance gets better and better with the increase in data sets. The higher training data set although drastically increases the training time. Also it is possible that the artificial neural network does not train at all with the large data sets. This paper proposes a novel concept of dealing with these scenarios. The paper proposes the use of a hierarchical model where the training data set is first clustered into clusters. Each cluster has its own neural network. When an unknown input is given to the system, the system first finds out the cluster to which the input belongs. Then the input is processed by the individual neural network of that system. The general structure of the algorithm is similar to a hybrid system consisting of fuzzy logic and artificial neural network being applied one after the other. The system has huge applications in all the areas where Artificial Neural Network is being used extensively.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809069","Artificial Neural Networks;Clustering;Fuzy Logic;High dimensionality data;Machine Learning;Neuro Fuzz Systems","Artificial neural networks;Clustering algorithms;Face recognition;Fuzzy sets;Fuzzy systems;Handwriting recognition;Machine learning;Speaker recognition;Speech recognition;Training data","fuzzy neural nets;fuzzy set theory;learning (artificial intelligence);pattern clustering","artificial neural network;data set clustering;fuzzy logic;fuzzy neuro system;large data set training;machine learning","","5","","27","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"The Intelligent Fault Diagnosis for Composite Systems Based on Machine Learning","L. h. Wu; Y. f. Jiang; W. Huang; A. x. Chen; X. n. Zhang","The Software Institute, Zhongshan University, Guangzhou 510275, China; School of Mathematics and Computational Science, Zhongshan University, Guangzhou 510275, China. E-MAIL: wulihua@mail.sysu.edu.cn","2006 International Conference on Machine Learning and Cybernetics","20090304","2006","","","571","575","Nowadays, electronic devices are getting more complex, which make it also more difficult to use a single reasoning technique to meet the demands of the fault diagnosis. Integrating two or more reasoning techniques becomes a trend in developing intelligent diagnosis. In this paper we discuss the intelligent diagnosis problems and propose a diagnosis architecture for composite systems, which combines rule-based diagnosis and model-based diagnosis. These two diagnosis programs not only work efficiently with machine learning in different stages of the fault diagnosis process, but also efficiently improve the process by making the best use of their individual advantages","2160-133X;2160133X","POD:1-4244-0061-9","10.1109/ICMLC.2006.258337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028129","Composite system;Knowledge base;MBD;Machine learning;RBD","Artificial intelligence;Computational intelligence;Cybernetics;Diagnostic expert systems;Fault diagnosis;Inference mechanisms;Intelligent control;Interconnected systems;Learning systems;Machine learning;Mathematics;Medical diagnostic imaging;Power system modeling","electronic engineering computing;fault diagnosis;inference mechanisms;knowledge based systems;learning (artificial intelligence)","composite system;electronic device;intelligent fault diagnosis;machine learning;model-based diagnosis;reasoning technique;rule-based diagnosis","","0","","9","","","13-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Exploring machine learning techniques for fault localization","L. C. Ascari; L. Y. Araki; A. R. T. Pozo; S. R. Vergilio","Federal University of Parana (UFPR), Computer Science Department, CP: 19081, CEP 19031-970, Centro Politecnico, Jardim das Americas, Curitiba- Brazil","2009 10th Latin American Test Workshop","20090410","2009","","","1","6","Debugging is the most important task related to the testing activity. It has the goal of locating and removing a fault after a failure occurred during test. However, it is not a trivial task and generally consumes effort and time. Debugging techniques generally use testing information but usually they are very specific for certain domains, languages and development paradigms. Because of this, a neural network (NN) approach has been investigated with this goal. It is independent of the context and presented promising results for procedural code. However it was not validated in the context of object-oriented (OO) applications. In addition to this, the use of other machine learning techniques is also interesting, because they can be more efficient. With this in mind, the present work adapts the NN approach to the OO context and also explores the use of support vector machines (SVMs). Results from the use of both techniques are presented and analysed. They show that their use contributes for easing the fault localization task.","2373-0862;23730862","POD:978-1-4244-4207-2","10.1109/LATW.2009.4813783","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813783","","Art;Backpropagation;Computer science;Costs;Machine learning;Neural networks;Software debugging;Software testing;Support vector machines;System testing","fault location;learning (artificial intelligence);neural nets;support vector machines","SVM;debugging;fault localization;machine learning;neural network;support vector machines","","2","","33","","","2-5 March 2009","","IEEE","IEEE Conference Publications"
"Machine Learning Methodologies in Brain-Computer Interface Systems","A. E. Selim; M. A. Wahed; Y. M. Kadah","CTDC (Cairo Technology Development Center), IBM Egypt; Systems and Biomedical Engineering Department, Cairo University, Egypt. E-mail: abeers@eg.ibm.com","2008 Cairo International Biomedical Engineering Conference","20090220","2008","","","1","5","Brain-Computer Interfaces (BCI) is a one kind of communication system that enables control of devices or communication with others only through brain signal activities without using motor activities. The main application for BCI is to provide an alternative channel for helping disabled persons, hereafter mentioned as subjects, to communicate with the external world. This paper tries to demonstrate the performance of different machine learning algorithms based on classification accuracy. Performance has been evaluated on dataset II from BCI Competition III for the year 2004 for two subjects 'A' & 'B' and dataset IIb from BCI Competition II for the year 2003 for one subject 'C'. As a primary stage, a preprocessing was applied on the samples in order to extract the most significant features before introducing them to machine learning algorithms. The algorithms applied are Bayesian Linear Discriminant Analysis (BLDA), linear Support Vector Machine (SVM), Fisher Linear Discriminant Analysis (FLDA), Generalized Anderson's Task linear classifier (GAT), Linear Discriminant Analysis (LDA). BLDA and SVM yielded the highest accuracy for all 3 subjects. BLDA algorithm achieved classification accuracy 98%, 98% and 100%, SVM algorithm achieved 98%, 96% and 100% for subjects 'A', 'B' and 'C' respectively.","2156-6097;21566097","CD-ROM:978-1-4244-2695-9; POD:978-1-4244-2694-2","10.1109/CIBEC.2008.4786106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786106","BCI;BLDA;Linear Classifiers;SVM","Bayesian methods;Brain computer interfaces;Classification algorithms;Communication system control;Control systems;Linear discriminant analysis;Machine learning;Machine learning algorithms;Support vector machine classification;Support vector machines","belief networks;brain-computer interfaces;handicapped aids;learning (artificial intelligence);medical control systems","Bayesian linear discriminant analysis;Fisher linear discriminant analysis;brain signal activity;brain-computer interface systems;communication system;generalized Anderson task linear classifier;linear support vector machine;machine learning algorithms;motor activities;motor activity","","7","","15","","","18-20 Dec. 2008","","IEEE","IEEE Conference Publications"
"Bio-mimetic machine learning based on compound control","S. Shimoda; H. Kimura","RIKEN BSI-Toyota Collaboration Cebter, JAPAN","2008 2nd IEEE RAS & EMBS International Conference on Biomedical Robotics and Biomechatronics","20090127","2008","","","144","151","Tacit learning is a new machine learning paradigm that attempts to implement the superb adaptation capability of living organisms to unexpected environmental changes. It emphasizes body/environment interactions and is equipped with some elementary sets of action rules and appropriate initial conditions of the neural states that correspond to elementary survival reflexes. Along this line, we propose a new scheme of neural computation based on compound control which represents a typical feature of biological controls. This scheme is based on a classical neuron model where macroscopic purposeful behavior emerges as the result of the interaction of local rules. This scheme is applied to a bipedal robot and generates the rhythm of walking without any model of robot dynamics and environments.","2155-1774;21551774","CD-ROM:978-1-4244-2883-0; POD:978-1-4244-2882-3","10.1109/BIOROB.2008.4762828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4762828","","Biological control systems;Biological system modeling;Biology computing;Evolution (biology);Legged locomotion;Machine learning;Motor drives;Neurons;Organisms;Robot control","biomimetics;gait analysis;humanoid robots;learning (artificial intelligence);legged locomotion;neural nets;robot dynamics","biomimetic machine learning;bipedal robot;body-environment interaction;classical neuron model;compound control;elementary survival reflex;environmental changes;neural computation;robot dynamics;tacit learning;walking","","0","","25","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Dimension Reduction via Unsupervised Learning Yields Significant Computational Improvements for Support Vector Machine Based Protein Family Classification","B. J. M. Webb-Robertson; M. M. Matzke; C. S. Oehmen","","2008 Seventh International Conference on Machine Learning and Applications","20081222","2008","","","457","462","Reducing the dimension of vectors used in training support vector machines (SVMs) results in a proportional speedup in training time. For large-scale problems this can make the difference between tractable and intractable training tasks. However, it is critical that classifiers trained on reduced datasets perform as reliably as their counterparts trained on high-dimensional data. We assessed principal component analysis (PCA) and sequential project pursuit (SPP) as dimension reduction strategies in the biology application of classifying proteins into well-defined functional dasiafamiliespsila (SVM-based protein family classification) by their impact on run-time, sensitivity and selectivity. Homology vectors of 4352 elements were reduced to approximately 2% of the original data size using PCA and SPP without significantly affecting accuracy, while leading to approximately a 28-fold speedup in run-time.","","POD:978-0-7695-3495-4","10.1109/ICMLA.2008.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725013","dimension reduction;machine leraning;protein homology detection;support vector machine","Bioinformatics;Floods;Genomics;Principal component analysis;Proteins;Runtime;Sequences;Support vector machine classification;Support vector machines;Unsupervised learning","biology computing;data reduction;genetics;pattern classification;principal component analysis;proteins;support vector machines;unsupervised learning","PCA;automated genome sequencing technology;high-dimensional data training;homology vector dimension reduction;intractable training task;principal component analysis;protein family classification;sequential project pursuit;support vector machine;unsupervised learning","","0","","23","","","11-13 Dec. 2008","","IEEE","IEEE Conference Publications"
"Neural Control and Learning for Versatile, Adaptive, Autonomous Behavior of Walking Machines","P. Manoonpong; F. Wörgötter","Bernstein Center for Comput. Neurosci. (BCCN), Univ. of Gottingen, Gottingen","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","24","28","This article presents two different types of walking machines: an insect-like robot and a biped robot which have been developed during last years. Both walking machines are attractive in the way that they now combine three key aspects: versatility, adaptivity, and autonomy. Versatility in this sense means a variety of reactive behaviors, while adaptivity implies to online learning capabilities, and autonomy is an ability to function without continuous human guidance. These three key elements are achieved under neural control and an online learning mechanism. In addition, this contribution will point out that such control technique is shown to be a power method of solving sensor-motor coordination problems of high complexity systems.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736917","","Adaptive control;Centralized control;Control systems;Humans;Leg;Legged locomotion;Machine learning;Programmable control;Robot kinematics;Robot sensing systems","learning (artificial intelligence);legged locomotion;neurocontrollers","autonomy;biped robot;high complexity systems;insect-like robot;neural control;online learning capabilities;sensor-motor coordination problems;versatility;walking machines","","0","","12","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A new approach for automatic quality control of fried potatoes using machine learning","E. Lotfi; M. Yaghoobi; H. R. Pourreza","Islamic Azad University, Mashad Branch, Iran","2008 7th IEEE International Conference on Cybernetic Intelligent Systems","20090306","2008","","","1","4","Frying of potatoes causes some changes in their microstructures. By studying these changes we have presented quite suitable features for automatic analysis of microscopic images taken from fried potatoes, and have also introduced a new mechanism based on machine learning for automatic quality control of fried potatoes. Experimental results show that the presented structure may well be used for controlling the quality of related products.","","CD-ROM:978-1-4244-2915-8; POD:978-1-4244-2914-1","10.1109/UKRICIS.2008.4798934","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4798934","Machine Vision;Neural networks;Potato microstructures;Quality control;Texture recognition","Automatic control;Image analysis;Image color analysis;Image texture analysis;Machine learning;Microscopy;Microstructure;Neural networks;Quality control;Temperature","food products;image recognition;image texture;learning (artificial intelligence);production engineering computing;quality control","automatic quality control;fried potatoes;machine learning;machine vision;microscopic image;potato microstructure;texture recognition","","0","","12","","","9-10 Sept. 2008","","IEEE","IEEE Conference Publications"
"Machine Learning: The State of the Art","J. Wang; Q. Tao","Chinese Academy of Sciences","IEEE Intelligent Systems","20090109","2008","23","6","49","55","The two fundamental problems in machine learning (ML) are statistical analysis and algorithm design. The former tells us the principles of the mathematical models that we establish from the observation data. The latter defines the conditions on which implementation of data models and data sets rely. A newly discovered challenge to ML is the Rashomon effect, which means that data are possibly generated from a mixture of heterogeneous sources. A simple classification standard can shed light on emerging forms of ML. This article is part of a special issue on AI in China.","1541-1672;15411672","","10.1109/MIS.2008.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4747609","Rashomon effect;algorithm design;feature selection;learning to rank;machine learning;manifold learning;metric learning;multi-instance learning;nonlinear backpropagation;perceptron;relational learning;rule + exception learning;semisupervised learning;statistical analysis;statistical learning methods;structural learning;supervised learning;symbolic learning methods;unsupervised learning","","learning (artificial intelligence)","algorithm design;classification standard;machine learning;statistical analysis","","1","","47","","","Nov.-Dec. 2008","","IEEE","IEEE Journals & Magazines"
"Prediction of Skin Penetration Using Machine Learning Methods","Y. Sun; G. P. Moss; M. Prapopoulou; R. Adams; M. B. Brown; N. Davey","Sci. & Technol. Res. Sch., Univ. of Hertfordshire, Hatfield","2008 Eighth IEEE International Conference on Data Mining","20090210","2008","","","1049","1054","Improving predictions of the skin permeability coefficient is a difficult problem. It is also an important issue with the increasing use of skin patches as a means of drug delivery. In this work, we apply K-nearest-neighbour regression, single layer networks, mixture of experts and Gaussian processes to predict the permeability coefficient. We obtain a considerable improvement over the quantitative structure-activity relationship (QSARs) predictors. We show that using five features, which are molecular weight, solubility parameter, lipophilicity, the number of hydrogen bonding acceptor and donor groups, can produce better predictions than the one using only lipophilicity and the molecular weight. The Gaussian process regression with five compound features gives the best performance in this work.","1550-4786;15504786","POD:978-0-7695-3502-9","10.1109/ICDM.2008.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4781223","Gaussian processes;regression;skin permeability coefficient","Absorption;Bonding;Drug delivery;Gaussian processes;Hydrogen;Learning systems;Lipidomics;Medical treatment;Permeability;Skin","learning (artificial intelligence);medical computing","Gaussian processes;K-nearest-neighbour regression;machine learning methods;permeability coefficient;quantitative structure-activity relationship;skin penetration","","1","","15","","","15-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"A New Method to Alarm Large Scale of Flights Delay Based on Machine Learning","L. Zonglei; W. Jiandong; Z. Guansheng","Coll. of Inf. Sci. & Technol., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","589","592","A new method to alarm large scale of flight delays based on machine learning is presented in this paper. This new method first does unsupervised learning on the data of the flights collected from the airport. The standard of each class of delay can be gotten after the learning process. With these classes of delay, the supervised learning method can be used on the data so that the alarm model could be built. Comparing with the recent manual alarm standard, this model synthesizes more factors to do alarm. Since the recent delay standard is only related to the number of flights, which is helpful only in serious delay case, the new model performs will be more practical value than recent ones.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732894","Classification;Clustering;Flights Delay;Machine Learning;Unsupervised Learning","Airports;Delay effects;Educational institutions;Information science;Knowledge acquisition;Large-scale systems;Learning systems;Machine learning;Space technology;Unsupervised learning","aerospace computing;unsupervised learning","flight delays;flights data;machine learning;supervised learning method;unsupervised learning","","8","2","12","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Coordinated management of multiple interacting resources in chip multiprocessors: A machine learning approach","R. Bitirgen; E. Ipek; J. F. Martinez","Computer Systems Laboratory, Cornell University, Ithaca, NY 14853 USA","2008 41st IEEE/ACM International Symposium on Microarchitecture","20090202","2008","","","318","329","Efficient sharing of system resources is critical to obtaining high utilization and enforcing system-level performance objectives on chip multiprocessors (CMPs). Although several proposals that address the management of a single microarchitectural resource have been published in the literature, coordinated management of multiple interacting resources on CMPs remains an open problem. We propose a framework that manages multiple shared CMP resources in a coordinated fashion to enforce higher-level performance objectives. We formulate global resource allocation as a machine learning problem. At runtime, our resource management scheme monitors the execution of each application, and learns a predictive model of system performance as a function of allocation decisions. By learning each application's performance response to different resource distributions, our approach makes it possible to anticipate the system-level performance impact of allocation decisions at runtime with little runtime overhead. As a result, it becomes possible to make reliable comparisons among different points in a vast and dynamically changing allocation space, allowing us to adapt our allocation decisions as applications undergo phase changes. Our evaluation concludes that a coordinated approach to managing multiple interacting resources is key to delivering high performance in multiprogrammed workloads, but this is possible only if accompanied by efficient search mechanisms. We also show that it is possible to build a single mechanism that consistently delivers high performance under various important performance metrics.","1072-4451;10724451","CD-ROM:978-1-4244-2837-3; POD:978-1-4244-2836-6","10.1109/MICRO.2008.4771801","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4771801","","Bandwidth;High performance computing;Laboratories;Machine learning;Measurement;Microarchitecture;Proposals;Quality of service;Resource management;Runtime","learning (artificial intelligence);microprocessor chips","chip multiprocessors;coordinated management;global resource allocation;machine learning;microarchitectural resource;multiple interacting resources;open problem;resource management scheme;system-level performance objectives","","52","7","27","","","8-12 Nov. 2008","","IEEE","IEEE Conference Publications"
"Decision Fusion of Machine Learning Models to Predict Radiotherapy-Induced Lung Pneumonitis","S. K. Das; S. Chen; J. O. Deasy; S. Zhou; F. F. Yin; L. B. Marks","Dept. of Radiat. Oncology, Duke Univ. Med. Center, Durham, NC, USA","2008 Seventh International Conference on Machine Learning and Applications","20081222","2008","","","545","550","Combining different machine learning models (decision fusion) has been shown to be an effective method for estimating the underlying physical mechanism by allowing the models to reinforce each other when consensus exists, or, conversely, negate each other when there is no consensus. To be effective, decision fusion requires that the different models provide some degree of complementary information. In this work, we fuse the results of four different machine learning models (Boosted Decision Trees, Neural Networks, Support Vector Machines, Self Organizing Maps) to predict the risk of lung pneumonitis in patients undergoing thoracic radiotherapy. Fusion was achieved by simple averaging of the 10-fold cross validated predictions for each patient from all four models. To reduce prediction dependence on the manner in which the data set was split, 10-fold cross-validation was repeated 100 times for random data splitting. The area under the receiver operating characteristics curve for the fused cross-validated results was 0.79, higher than the individual models and with (generally) lower variance. The fusion extracted three important features as the consensus among all four models in predicting radiation pneumonitis risk: chemotherapy prior to radiotherapy, equivalent Uniform Dose (EUD) for exponent a = 1.2 to 3, and female gender. The results show great promise for machine learning in radiotherapy outcomes modeling.","","POD:978-0-7695-3495-4","10.1109/ICMLA.2008.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725027","decision fusion;machine learning;modeling;pneumonitis;radiotherapy","Data mining;Decision trees;Feature extraction;Fuses;Lungs;Machine learning;Neural networks;Predictive models;Self organizing feature maps;Support vector machines","decision trees;diseases;medical computing;neural nets;patient treatment;radiation therapy;self-organising feature maps;support vector machines","boosted decision trees;complementary information;decision fusion;machine learning;neural networks;radiotherapy-induced lung pneumonitis;self organizing maps;support vector machines;thoracic radiotherapy","","0","","18","","","11-13 Dec. 2008","","IEEE","IEEE Conference Publications"
"Email classification and summarization: A machine learning approach","T. Ayodele; R. Khusainov; D. Ndzi","Department of Electronics and Computer Engineering, University of Portsmouth, United Kingdom","2007 IET Conference on Wireless, Mobile and Sensor Networks (CCWMSN07)","20090220","2007","","","805","808","This paper presents the design and implementation of a system to group and summarize email messages. The system uses the subject and content of email messages to classify emails based on users' activities and generate summaries of each incoming message with unsupervised learning approach. Our framework solves the problem of email overload, congestion, difficulties in prioritizing and difficulties in finding previously archived messages in the mail box.","0537-9989;05379989","Paper:978-0-86341-836-5","10.1049/cp:20070271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786325","Classification;Email;activities;algorithms;email summarization","","classification;electronic mail;electronic messaging;unsupervised learning","email classification;email congestion;email message summarization;email overload;unsupervised machine learning approach","","0","4","","","","12-14 Dec. 2007","","IET","IET Conference Publications"
"Signal processing and machine learning for real-time classification of ergonomic posture with unobtrusive on-body sensors; application in dental practice","G. F. Olsen; S. S. Brilliant; D. Primeaux; K. Najarian","Virginia Commonwealth University, Richmond, 23285 USA","2009 ICME International Conference on Complex Medical Engineering","20090502","2009","","","1","11","Over 80% of dentists report having some type of back, neck or shoulder pain. Research has identified significant costs linked to a very high rate of Work-Related Musculoskeletal Disorders (WMSDs) associated with poor ergonomic positioning in dentists. The annual costs of WMSDs across all occupations are estimated to be between 13 and 54 billion dollars. Little research has been done to explore the design of portable, inexpensive, non-invasive and unobtrusive real-time systems to measure posture. This paper details the design and testing of our proposed system that applies signal processing and robust machine learning techniques to improve the ergonomics of dental practitioners. We outline a number of different signal processing and classification techniques tested and analytically compared with our proposed system. Our system makes use of commercial inclinometers embedded into a standard laboratory coat. The ability of the system to measure posture accurately in practical settings, without needing exact and obtrusive placement of sensors or extensive calibration, is demonstrated through a set of experiments with human subjects.","","POD:978-1-4244-3315-5","10.1109/ICCME.2009.4906675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906675","","Costs;Dentistry;Ergonomics;Machine learning;Musculoskeletal system;Neck;Pain;Real time systems;Signal processing;System testing","biomechanics;biomedical measurement;body area networks;ergonomics;learning (artificial intelligence);medical signal processing;occupational health;signal classification;spatial variables measurement","WMSD;dental practice;dentists;machine learning;poor ergonomic positioning;posture measurement;real time ergonomic posture classification;signal classification techniques;signal processing techniques;unobtrusive on body sensors;work related musculoskeletal disorders","","0","","28","","","9-11 April 2009","","IEEE","IEEE Conference Publications"
"Improved machine learning techniques for low complexity MPEG-2 to H.264 transcoding using optimized codecs","C. Holder; Tao Pin; H. Kalva","Department of Computer Science and Engineering, Florida Atlantic University, Boca Raton, USA","2009 Digest of Technical Papers International Conference on Consumer Electronics","20090529","2009","","","1","2","This paper discusses techniques for efficiently implementing a Mpeg-2 to H.264 video transcoder. The transcoding results reported in the literature are based on a reference implementation and may not reflect the true performance gains obtained in real world systems. We have developed low complexity transcoding algorithms and have implemented these solutions using highly optimized encoder and decoder implementations available from Intel. The transcoding algorithms are based on exploiting the mode decision knowledge inherent in the decoded MPEG-2 data. Machine learning techniques are used to make accurate and low-complexity H.264 MB encoding mode decisions. The results show that the proposed transcoder reduces the complexity by 50% without a significant loss in PSNR. This performance improvement in production quality transcoders, and demonstrates the practicality of machine learning based video transcoding algorithms.","2158-3994;21583994","POD:978-1-4244-2558-7","10.1109/ICCE.2009.5012345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5012345","H.264;Mpeg-2;machine learning;transcoding","Codecs;Computer science;Decoding;Encoding;Machine learning;Machine learning algorithms;Performance gain;Production;Testing;Transcoding","learning (artificial intelligence);transcoding;video codecs;video coding","H.264 video transcoding;Intel;decoder implementations;low-complexity MPEG-2 encoding mode decisions;machine learning techniques;mode decision knowledge;optimized codecs","","3","","6","","","10-14 Jan. 2009","","IEEE","IEEE Conference Publications"
"Development of a New Broadcast Protocol Based on Machine Learning for Wide-Ranging MANET Environments","Y. Deng; Y. Shen; G. Zhang; X. Zhang","Sch. of Inf. Sci. & Eng., Lanzhou Univ., Lanzhou","2008 International Symposium on Information Science and Engineering","20081230","2008","1","","206","209","A new broadcast protocol have been developed in this paper. Itpsilas based on a new method in which rebroadcasting a packet is decided by an intelligent classification scheme. Each MN builds a classifier and uses it on data collected from the network environment. For an input vector describing a broadcast packet and current network conditions, the classifier returns a result of ""rebroadcast"" or ""drop"". Through the simulation, we can identify a more energetic communication protocol and more efficient use because of each MNpsilas fitting various network condition.","2160-1283;21601283","POD:978-0-7695-3494-7","10.1109/ISISE.2008.185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732201","Naïve Bayes;broadcast;machine learning;protocol","","learning (artificial intelligence);protocols","MANET environment;broadcast packet;broadcast protocol;energetic communication protocol;intelligent classification;machine learning","","0","","11","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A machine learning based scheme for double JPEG compression detection","C. Chen; Y. Q. Shi; W. Su","New Jersey Institute of Technology, Newark, USA 07102","2008 19th International Conference on Pattern Recognition","20090123","2008","","","1","4","Double JPEG compression detection is of significance in digital forensics. We propose an effective machine learning based scheme to distinguish between double and single JPEG compressed images. Firstly, difference JPEG 2D arrays, i.e., the difference between the magnitude of JPEG coefficient 2D array of a given JPEG image and its shifted versions along various directions, are used to enhance double JPEG compression artifacts. Markov random process is then applied to modeling difference 2-D arrays so as to utilize the second-order statistics. In addition, a thresholding technique is used to reduce the size of the transition probability matrices, which characterize the Markov random processes. All elements of these matrices are collected as features for double JPEG compression detection. The support vector machine is employed as the classifier. Experiments have demonstrated that our proposed scheme has outperformed the prior arts.","1051-4651;10514651","CD-ROM:978-1-4244-2175-6; POD:978-1-4244-2174-9","10.1109/ICPR.2008.4761645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4761645","","Art;Digital forensics;Image coding;Machine learning;Probability;Random processes;Statistics;Support vector machine classification;Support vector machines;Transform coding","Markov processes;data compression;higher order statistics;image classification;image coding;image segmentation;learning (artificial intelligence);probability;random processes;support vector machines","JPEG 2D array;Markov random process;double JPEG compression detection;image classification;machine learning based scheme;probability matrix;second-order statistic;support vector machine;thresholding technique","","22","1","9","","","8-11 Dec. 2008","","IEEE","IEEE Conference Publications"
"Cognitive ecology and social learning inspired machine learning: with particular reference to the evolving of resilient Airborne Networks (AN)","Zhanshan Ma","Computer Science Department, University of Idaho Moscow, 83844, USA","2009 IEEE Aerospace conference","20090424","2009","","","1","14","This paper tries to bring together three seemingly only remotely related fields: animal cognition in biology, machine learning in computer science, and the planning and deployment of resilient Airborne Networks. The underlying motivation is that the latest advances in animal behavior ecology such as social learning, innovation, and cognitive ecology may offer some meaningful insights for computational intelligence such as machine learning. Motivated by this expectation, I first review some of the latest advances in the field of animal cognition, with focusing on social learning, teaching, innovation and cognitive ecology. The justification for this focus is not only because they are interesting and are among the most actively studied topics in behavior biology, but also because the existing machine learning research, which from time to time takes cues from cognitive science, seems to only incorporate the traditional learning theory such as associative learning and reinforcement learning. After a briefly review of the major advances in animal learning and cognitive ecology, I look into the possibility to incorporate the principles and mechanisms from social learning and cognitive ecology into a typical machine learning architecture. By examining the Gadanho's (2001, 2003) ALEC (asynchronous learning by emotion and cognition) architecture, I propose to add a high layer to the ALEC architecture, and the resulting CEML (cognitive ecology and social learning inspired machine learning) offers a framework that uses a population of agents and can readily consider social learning, teaching, and innovation as well as the influences of environment in a comprehensive manner. Finally, I consider the problem of planning and deployment of airborne networks (AN) and suggests that the new CEML should be ideal for tackling the AN problem.","1095-323X;1095323X","POD:978-1-4244-2621-8","10.1109/AERO.2009.4839429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839429","","Animal behavior;Biology;Cognition;Cognitive science;Computational intelligence;Computer science;Education;Environmental factors;Machine learning;Technological innovation","cognition;learning (artificial intelligence);network theory (graphs);zoology","animal behavior ecology;animal cognition;animal learning;associative learning;behavior biology;cognitive ecology;computational intelligence;computer science;learning theory;machine learning architecture;reinforcement learning;remotely related fields;resilient airborne networks;social learning;teaching","","1","","52","","","7-14 March 2009","","IEEE","IEEE Conference Publications"
"Chinese New Words Extraction Based on Machine Learning Approach","Z. r. Zhang; Q. j. Wang; X. d. Tian","College of Humanities, Hebei University, Baoding 071002, China. E-MAIL: zhangziruls@sohu.com","2006 International Conference on Machine Learning and Cybernetics","20090304","2006","","","3380","3384","Chinese new words extraction is an important problem for Chinese information processing. In this paper a new words extraction method based on machine learning is proposed, where the context information, the word construction rules and statistic information are combined to extract new words. An experiment, based on two-character-nouns, shows that this method can well improve the efficiency and accuracy of extracting new words","2160-133X;2160133X","POD:1-4244-0061-9","10.1109/ICMLC.2006.258498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028652","New words extraction;machine learning;word construction rules;word segmentation","Cybernetics;Data mining;Dictionaries;Educational institutions;Information processing;Machine learning;Mathematics;Natural languages;Probability;Statistics;Text processing","dictionaries;learning (artificial intelligence);natural languages;text analysis","Chinese information processing;Chinese new word extraction;context information;dictionary;machine learning approach;statistic information;two-character-nouns;word construction rules","","1","","9","","","13-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Research on ""Inaccurate Learning"" and Its Countermeasure in Machine Learning","G. C. Li","Coll. of Econ. & Manage., Hebei Univ. of Sci. & Technol., Shijiazhuang","2008 Fourth International Conference on Natural Computation","20081107","2008","1","","227","231","The knowledge you gained after learning is false, this learning is ""inaccurate learning"". The false knowledge is the knowledge not according to practice. Human always have ""inaccurate learning"" in learning, though they through more learning and study will correct the false knowledge they had learned, Compared to human learning, the machine learning is simple, so deal with ldquoinaccurate learningrdquo is easy. Aim at the ""inaccurate learning"" in machine learning, this paper discussed its characteristic and solve method, and improve the knowledge quality of machine learning.","2157-9555;21579555","POD:978-0-7695-3304-9","10.1109/ICNC.2008.879","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4666844","","Conference management;Educational institutions;Eyes;Feeds;Fires;Humans;Knowledge management;Machine learning;Pain;Technology management","learning (artificial intelligence)","false knowledge;inaccurate learning;knowledge quality;machine learning","","0","","4","","","18-20 Oct. 2008","","IEEE","IEEE Conference Publications"
"Learning from errors: A bio-inspired approach for hypothesis-based machine learning","D. Gamrad; D. Soffker","Chair of Dynamics and Control, University of Duisburg-Essen, Germany","2008 SICE Annual Conference","20081021","2008","","","647","652","This contribution present an approach extending existing learning strategies based on situation-operator-modeling (SOM), which can be used to model interactions with the environment and to represent the knowledge of cognitive systems. The approach proposes a planning process using hypotheses to bridge the gap of knowledge, which is refined by a following check of the applied hypothesis. The hypotheses are inspired by human errors according to Dornerpsilas classification, which is related to the interaction within complex dynamic systems. The programmed implementation of the approach is based on an experimental environment using a software tool for high-level Petri nets.","","CD-ROM:978-4-907764-29-6; POD:978-4-907764-30-2","10.1109/SICE.2008.4654736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4654736","Autonomous Systems;Cognitive Technical Systems;Human Error","Bridges;Cognitive science;Electronic mail;Error correction;Humans;Layout;Machine learning;Petri nets;Process planning;Software tools","Petri nets;cognitive systems;large-scale systems;learning (artificial intelligence);man-machine systems;planning (artificial intelligence)","cognitive systems;complex dynamic systems;high-level Petri Nets;hypothesis-based machine learning;planning process;situation-operator-modeling","","1","","12","","","20-22 Aug. 2008","","IEEE","IEEE Conference Publications"
"Application of machine learning approaches on quantitative structure activity relationships","M. Butkiewicz; R. Mueller; D. Selic; E. Dawson; J. Meiler","Center for Structural Biology at Vanderbilt University, Nashville TN, 37232, USA","2009 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology","20090515","2009","","","255","262","Machine Learning techniques are successfully applied to establish quantitative relations between chemical structure and biological activity (QSAR), i.e. classify compounds as active or inactive with respect to a specific target biological system. This paper presents a comparison of artificial neural networks (ANN), support vector machines (SVM), and decision trees (DT) in an effort to identify potentiators of metabotropic glutamate receptor 5 (mGluR5), compounds that have potential as novel treatments against schizophrenia. When training and testing each of the three techniques on the same dataset enrichments of 61, 64, and 43 were obtained and an area under the curve (AUC) of 0.77, 0.78, and 0.63 was determined for ANNs, SVMs, and DTs, respectively. For the top percentile of predicted active compounds, the true positives for all three methods were highly similar, while the inactives were diverse offering the potential use of jury approaches to improve prediction accuracy.","","POD:978-1-4244-2756-7","10.1109/CIBCB.2009.4925736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4925736","Artificial Neural Network (ANN);Decision Trees (DT);Machine Learning;Support Vector Machine (SVM);area under the curve (AUC);high-throughput screening (HTS);quantitative structure activity relationship (QSAR);receiver operator characteristics (ROC)","Amino acids;Artificial neural networks;Data mining;Decision trees;High temperature superconductors;Human immunodeficiency virus;Machine learning;Support vector machine classification;Support vector machines;Testing","decision trees;drugs;learning (artificial intelligence);medical computing;neural nets;support vector machines","ANN;SVM;area under the curve;artificial neural networks;biological activity;chemical structure;decision trees;machine learning;metabotropic glutamate receptor 5;quantitative structure activity relationships;schizophrenia;support vector machines","","6","","40","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Research on Multi-Agent Automatic Negotiation Based on Machine Learning","J. Hua; Y. Jing","Sch. of Econ. & Manage., Hebei Univ. of Eng., Handan, China","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","186","191","At present, applying machine learning theory to the multi-agent automatic negotiation system has become the latest research focus in e-commerce area. The paper aimed at using Bayesian rules to update the environmental information in negotiation, using the Q-learning algorithm of reinforcement-learning to generate the negotiation proposals, and established a multi-agent automatic negotiation model based on machine learning, and expanded the traditional Q-learning algorithm, and designed the dynamic Q-learning algorithm based on the current belief and the recent exploring surplus. Furthermore, the convergence of the algorithm has been verified by experiments.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739561","Machine Learning;Multi-Agent Automatic Negotiation","Bayesian methods;Environmental economics;Information technology;Learning systems;Machine learning;Machine learning algorithms;Multiagent systems;Proposals;Protocols;Technology management","Bayes methods;learning (artificial intelligence);multi-agent systems","Bayesian rule;dynamic Q-learning algorithm;e-commerce;machine learning theory;multiagent automatic negotiation model;reinforcement learning","","0","","8","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Image processing and machine learning for diagnostic analysis of microcirculation","S. Demir; N. Mirshahi; M. H. Tiba; G. Draucker; K. Ward; R. Hobson; K. Najarian","Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, 23284 USA","2009 ICME International Conference on Complex Medical Engineering","20090502","2009","","","1","5","This study focuses on detection of capillaries and small blood vessels in the videos recorded from the lingual surface using Microscan SDF system. The purpose of this study is to quantitatively monitor and assess the changes that occur in microcirculation during resuscitation period. The results assist physicians in making diagnostically and therapeutically important decisions such as determination of the effectiveness of the resuscitation process. The proposed algorithm applies advanced digital image processing methods to provide quantitative assessment of video signals for detection and characterization of capillaries. The objective of the algorithm is to segment capillaries, estimate the presence and velocity of Red Blood Cells (RBCs), and identify the distribution of blood flow in capillaries for a variety of normal and abnormal cases. The algorithm first, stabilizes each frame to follow the variations in the consecutive frames. Then, time-averaging techniques are applied to the frames to reduce the motion artifact. Histogram equalization, wavelet transform, and median filtering are the subsequent steps applied to accurately detect the blood vessels in each frame. In order to estimate the velocity of RBCs, space time diagrams are obtained through cross-correlation calculations. This study aims to reduce the human interaction as well as the computation time.","","POD:978-1-4244-3315-5","10.1109/ICCME.2009.4906669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906669","","Biomedical imaging;Blood vessels;Digital images;Image analysis;Image processing;Machine learning;Monitoring;Signal detection;Signal processing;Videos","blood flow measurement;blood vessels;image segmentation;learning (artificial intelligence);median filters;medical computing;medical image processing;video signal processing;wavelet transforms","Microscan SDF system;advanced digital image processing methods;capillary blood flow distribution;capillary characterization;capillary detection;capillary segmentation;histogram equalisation;lingual surface;machine learning;median filtering;medical video recording;microcirculation diagnostic analysis;motion artifact reduction;red blood cells;resuscitation microcirculation changes;small blood vessel detection;space-time diagrams;time averaging techniques;video signal assessment;wavelet transform","","4","","17","","","9-11 April 2009","","IEEE","IEEE Conference Publications"
"Study on Parameter Distribution in Structure Reliability Analysis: Machine Learning Algorithm and Application","Y. Wan; Y. Zhang","Coll. of Comput. Sci. & Eng., Wenzhou Univ. Wenzhou, Wenzhou","2009 Second International Workshop on Knowledge Discovery and Data Mining","20090202","2009","","","833","836","The discrimination of parameter probability distribution type is the key to structure reliability analysis. A support vector machine (SVM) intelligent recognition model of probability distribution law is presented aiming at traditional method disadvantage. The intelligent recognition model of probability distribution is constructed by SVM algorithm realization, network design and feature extraction, inward stress probability distribution type of a stem structural member is recognized by the model, recognition result is Weibull distribution, SVM has a good generalization ability and clustering ability by comparison between network recognition result and regression analysis, the experiment result shows total recognition rate achieved 98.25%, it provides a good new method for structure reliability analysis.","","POD:978-0-7695-3543-2","10.1109/WKDD.2009.169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4772064","SVM;intelligent recognition model;probability distribution law;structure reliability","Algorithm design and analysis;Clustering algorithms;Feature extraction;Intelligent networks;Intelligent structures;Learning systems;Machine learning algorithms;Probability distribution;Stress;Support vector machines","feature extraction;generalisation (artificial intelligence);reliability;statistical distributions;structural engineering computing;support vector machines","Weibull distribution;feature extraction;intelligent recognition model;inward stress probability distribution type;machine learning algorithm;parameter distribution;probability distribution law;stem structural member;structure reliability analysis;support vector machine","","2","","10","","","23-25 Jan. 2009","","IEEE","IEEE Conference Publications"
"Research on the Key technologies of Simulation Grid Resource Scheduling Based on Machine Learning","X. Xu; X. Yan; Q. Ding","Coll. of Inf. Sci. & Technol., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing","2009 International Workshop on Intelligent Systems and Applications","20090612","2009","","","1","5","According to characteristics of simulation grid resources (SGR), an extend Web service description language (WSDL) was adopted to describe the attributes of SGRs, in order to facilitate the application of machine learning algorithms for SGR scheduling on a centralized-distributed SGR management model. By analyzing the specific requirements of distributed interactive simulation (DIS) task, a SGR scheduling model based on machine learning was proposed. Support vector machine (SVM) and incremental SVM were applied to implement SGRs classification when the features vectors were extracted from the WSDL documents. Scheduling agents can then carried out the SGR scheduling on classified SGRs. Experiments showed that the scheduling model can get federation overall optimal result with better performance.","","POD:978-1-4244-3893-8","10.1109/IWISA.2009.5073088","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5073088","","Aerospace simulation;Computational modeling;Environmental economics;Machine learning;Machine learning algorithms;Resource management;Space technology;Support vector machine classification;Support vector machines;Technology management","Web services;grid computing;learning (artificial intelligence);scheduling;support vector machines","Web service description language;centralized-distributed management model;distributed interactive simulation;machine learning algorithms;simulation grid resource scheduling;support vector machine","","0","","19","","","23-24 May 2009","","IEEE","IEEE Conference Publications"
"Identifying Spectrum Usage by Unknown Systems using Experiments in Machine Learning","N. Shetty; S. Pollin; P. Pawelczak","Dept. of EECS, Univ. of California, Berkeley, CA","2009 IEEE Wireless Communications and Networking Conference","20090512","2009","","","1","6","We adopt a machine learning approach towards the problem of identifying wireless systems present in a dynamic radio environment with heterogeneous usage. To classify the wireless systems, we utilize two features that typify spectrum use-center frequency and the frequency spread-and cluster the measurement data in this space. Since the systems are unknown prior to clustering, we use an unsupervised clustering method that uses the Chinese restaurant process implemented using Gibbs sampling. The system identification is divided into two parts: training and online classification. In the training phase, we assign wireless systems present in the surrounding to the clusters while the online classification uses this trained data to perform classification. By means of an extensive measurement campaign, we show that the proposed machine learning process achieves up to 90% correctness in classifying the wireless systems considered here.","1525-3511;15253511","POD:978-1-4244-2947-9","10.1109/WCNC.2009.4917741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4917741","","Bluetooth;Communications Society;Extraterrestrial measurements;Frequency measurement;Machine learning;Radiofrequency identification;System identification;USA Councils;Wideband;Wireless LAN","frequency allocation;learning (artificial intelligence);pattern classification;pattern clustering;sampling methods;telecommunication computing","Chinese restaurant process;Gibbs sampling;dynamic radio environment;frequency spread-and cluster;heterogeneous usage;machine learning;online classification;spectrum usage identification;spectrum use-center frequency;training phase;unsupervised clustering method;wireless system identification","","9","","11","","","5-8 April 2009","","IEEE","IEEE Conference Publications"
"Study on the Application of Rough Sets Theory in Machine Learning","J. Hua","Sch. of Econ. & Manage., Hebei Univ. of Eng., Handan","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","192","196","As a broad subfield of artificial intelligence, machine learning is concerned with the design and development of algorithms and techniques that allow computers to ""learn"". Machine learning has a wide spectrum of applications and has been paid many attentions by researchers. However, the quantitative measurement problem of the learning quality and the completeness of the supervisor's knowledge under incomplete information haven't been solved very well. Rough sets theory is a mathematical tool for extracting knowledge from uncertain and incomplete information. The paper firstly introduced some related concepts about machine learning and supervised learning, then, from the perspective of rough sets theory, studied the learning quality of machine learning and the completeness of supervisor's knowledge, which may provide some new ideas for studying the machine learning.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739562","Machine Learning;Rough Sets","Algorithm design and analysis;Application software;Artificial intelligence;Data mining;Learning systems;Machine learning;Machine learning algorithms;Rough sets;Speech analysis;Supervised learning","knowledge acquisition;learning (artificial intelligence);rough set theory","artificial intelligence;knowledge extraction;learning quality;machine learning;quantitative measurement problem;rough sets theory;supervised learning","","6","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"An extreme learning machine approach for training Time Variant Neural Networks","C. Cingolani; S. Squartini; F. Piazza","Dipartimento di Elettronica, Intelligenza Artificiale e Telecomunicazioni, Universit&#224; Politecnica delle Marche, Ancona 60131, Italy","APCCAS 2008 - 2008 IEEE Asia Pacific Conference on Circuits and Systems","20090109","2008","","","384","387","A remarkable attention has been paid in the recent past on the employment of suitable neural architectures able to work properly in non-stationary environments: the Time Variant Neural Networks (TV-NN) represent a relevant example in the field. Such kind of NNs have time variant weights, each being a linear combination of a certain set of basis functions. This inevitably increases the number of free parameters w.r.t. common feedforward architectures, resulting in an augmented complexity of the learning procedure. In this paper an Extreme Learning Machine (ELM) approach is developed with the aim of accelerating the training procedure for TV-NN, by extending the ELM approach already available for time-invariant neural structures. Some computer simulations have been carried out and related results seem to confirm the effectiveness of the idea, showing that learning time can be significantly reduced without affecting the NN performances in the testing phase.","","Electronic:978-1-4244-2342-2; POD:978-1-4244-2341-5","10.1109/APCCAS.2008.4746040","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4746040","","Artificial intelligence;Artificial neural networks;Computer architecture;Computer simulation;Intelligent networks;Learning systems;Machine learning;Neural networks;Signal processing algorithms;Telecommunications","feedforward neural nets;learning (artificial intelligence);neural net architecture","common feedforward architectures;extreme learning machine;neural architectures;time variant neural networks training","","3","","9","","","Nov. 30 2008-Dec. 3 2008","","IEEE","IEEE Conference Publications"
"Regularized Extreme Learning Machine","W. Deng; Q. Zheng; L. Chen","MOE KLINNS Lab and SKLMS Lab, Xi'an Jiaotong University, China","2009 IEEE Symposium on Computational Intelligence and Data Mining","20090515","2009","","","389","395","Extreme learning machine proposed by Huang G-B has attracted many attentions for its extremely fast training speed and good generalization performance. But it still can be considered as empirical risk minimization theme and tends to generate over-fitting model. Additionally, since ELM doesn't considering heteroskedasticity in real applications, its performance will be affected seriously when outliers exist in the dataset. In order to address these drawbacks, we propose a novel algorithm called regularized extreme learning machine based on structural risk minimization principle and weighted least square. The generalization performance of the proposed algorithm was improved significantly in most cases without increasing training time.","","POD:978-1-4244-2765-9","10.1109/CIDM.2009.4938676","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4938676","Least Square","Computer science;Feedforward neural networks;Joining processes;Least squares methods;Machine learning;Mathematical model;Multi-layer neural network;Neural networks;Neurons;Risk management","feedforward neural nets;learning (artificial intelligence);minimisation","over-fitting model;regularized extreme learning machine;risk minimization;structural risk minimization;weighted least square","","63","","17","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Spatio–Temporal Memories for Machine Learning: A Long-Term Memory Organization","J. A. Starzyk; H. He","Sch. of Electr. Eng. & Comput. Sci., Ohio Univ., Athens, OH","IEEE Transactions on Neural Networks","20090428","2009","20","5","768","780","Design of artificial neural structures capable of reliable and flexible long-term spatio-temporal memory is of paramount importance in machine intelligence. To this end, we propose a novel, biologically inspired, long-term memory (LTM) architecture. We intend to use it as a building block of a neuron-level architecture that is able to mimic natural intelligence through learning, anticipation, and goal-driven behavior. A mutual input enhancement and blocking structure is proposed, and its operation is discussed in detail. The paper focuses on a hierarchical memory organization, storage, recognition, and recall mechanisms. Simulation results of the proposed memory show its effectiveness, adaptability, and robustness. Accuracy of the proposed method is compared to other methods including Levenshtein distance method and a Markov chain.","1045-9227;10459227","","10.1109/TNN.2009.2012854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806127","Embodied intelligence;hierarchical structure;long-term memory (LTM);memory robustness;spatio–temporal memory","","Markov processes;learning (artificial intelligence);neural nets","Levenshtein distance method;Markov chain;artificial neural structures;blocking structure;long-term memory organization;machine intelligence;machine learning;mutual input enhancement;spatio-temporal memories","Algorithms;Artificial Intelligence;Brain;Cognition;Computer Simulation;Feedback;Goals;Humans;Learning;Memory;Models, Neurological;Motivation;Neural Networks (Computer);Neurons;Space Perception;Time Perception","14","24","51","","20090327","May 2009","","IEEE","IEEE Journals & Magazines"
"Sentiment Classification for Chinese Reviews Using Machine Learning Methods Based on String Kernel","C. Zhang; W. Zuo; T. Peng; F. He","Coll. of Comput. Sci. & Technol., Jilin Univ., Changchun","2008 Third International Conference on Convergence and Hybrid Information Technology","20081118","2008","2","","909","914","Sentiment classification aims at mining reviews of people for a certain event's topic or product by automatic classifying the reviews into positive or negative opinions. With the fast developing of World Wide Web applications, sentiment classification would have huge opportunity to help people automatic analysis of customers' opinions from the web information. Automatic opinion mining will benefit to both decision maker and ordinary people. Up to now, it is still a complicated task with great challenge. There are mainly two types of approaches for sentiment classification, machine learning methods and semantic orientation methods. Though some pioneer researches explored the approaches for English reviews classification, few jobs have been done on sentiment classification for Chinese reviews. The machine learning approach Based on string kernel for sentiment classification on reviews written in Chinese was proposed in this paper. Data experiment shows the capability of this approach.","","POD:978-0-7695-3407-7","10.1109/ICCIT.2008.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4682362","machine learning;opinion mining;semantic orientation;sentiment classification;string kernel","Educational institutions;Information analysis;Information retrieval;Kernel;Learning systems;Machine learning;Machine learning algorithms;Mutual information;Support vector machines;Text categorization","Internet;classification;data mining;decision making;learning (artificial intelligence)","Chinese reviews;World Wide Web;automatic opinion mining;decision making;machine learning;sentiment classification;string kernel","","4","","13","","","11-13 Nov. 2008","","IEEE","IEEE Conference Publications"
"Music emotion annotation by machine learning","Wai Ling Cheung; Guojun Lu","Gippsland School of Information Technology, Monash University, Churchill, Victoria 3842, Australia","2008 IEEE 10th Workshop on Multimedia Signal Processing","20081105","2008","","","580","585","Music emotion annotation is a task of attaching emotional terms to musical works. As volume of online musical contents expands rapidly in recent years, demands for retrieval by emotion are emerging. Currently, literature on music retrieval using emotional terms is rare. Emotion annotated data are scarce in existing music databases because annotation is still a manual task. Automating music emotion annotation is an essential prerequisite to research in music retrieval by emotion, for without which even sophisticated retrieval methods may not be very useful in a data deficient environment. This paper describes a machine learning approach to annotate music using a large number of emotional terms. We also estimate the training data size requirements for a workable annotation system. Our empirical result shows that 1) the task of music emotion annotation could be modelled using machine learning techniques to support a large number of emotional terms, 2) the combination of sampling method and data-driven detection threshold is highly effective in optimizing the use of existing annotated data in training machine learning models, 3) synonymous relationships enhance the annotation performance and 4) the training data size requirement is within reach for a workable annotation system. Essentially, automatic music emotion annotation enables music retrieval by emotion to be performed as a text retrieval task.","","POD:978-1-4244-2294-4","10.1109/MMSP.2008.4665144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665144","","Australia;Content based retrieval;Databases;Humans;Information technology;Joining processes;Machine learning;Mood;Music information retrieval;Training data","emotion recognition;information retrieval;information retrieval systems;learning (artificial intelligence);music;sampling methods","automatic music emotion annotation system;data-driven detection threshold;machine learning;music database;music retrieval;sampling method;synonymous relationship;text retrieval","","2","","24","","","8-10 Oct. 2008","","IEEE","IEEE Conference Publications"
