"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7292979,7293425,7293429,7294105,7292397,7294263,7289294,7280620,7281719,7279549,7279511,7280334,7284428,7284453,7280093,7280428,7280068,7276725,7275767,7275614,7275974,7276754,7275970,7275714,7063936,7273529,7273365,7273424,7272933,7273653,7273357,7273318,7273789,7271592,7266621,7266654,7257262,7259379,7255222,7260941,7263651,7259381,7110549,7249515,7244654,7244890,7250211,7253978,7238043,7230519,7231023,7230461,7238143,7237185,7230444,6880767,7060704,7225753,7225395,7219853,7224592,7225403,7226077,7223242,7219777,7208643,7182735,7207212,7207126,7163526,7207248,7207337,7061463,7203092,7196537,7193182,7193070,7193195,7192841,7182488,7177418,7176206,7176204,7177825,6926746,7169319,7171706,7172034,7164502,7167507,7166115,7167456,7131531,7165133,7164918,7164721,7163956,7164783,6874569,7140733",2017/05/04 23:30:13
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Classification vs. Regression - Machine Learning Approaches for Service Recommendation Based on Measured Consumer Experiences","J. Kirchner; A. Heberle; W. LÃ¶we","Karlsruhe Univ. of Appl. Sci., Karlsruhe, Germany","2015 IEEE World Congress on Services","20150817","2015","","","278","285","Service functionality can be provided by more than one service consumer. In order to choose the service which creates the most benefit before its consumption, a selection based on previous measurable experiences by other consumers is beneficial. In this paper, we present the results of our analysis of two machine learning approaches to predict the best service within this selection problem. The first approach focuses on classification, predicting the best performing service, while the second approach focuses on regression, predicting service performances which can then be used for the determination of the best candidate. We assessed and compared both approaches for service recommendation w.r.t. The performance gain when selecting the recommended instead of a random service. Our evaluation is based on data measured on real Web services as well as on simulated data. The latter is needed for a more profound analysis of the strengths and weaknesses of each approach. The simulated data has similar statistical properties as the data measured on real Web services. In the real-world case, regression achieved a response time gain of over 92% of the optimum and classification over 83%. In case of simulated data, we could achieve an overall gain of up to 95% using classification, while regression achieved 89%.","2378-3818;23783818","Electronic:978-1-4673-7275-6; POD:978-1-4673-7276-3","10.1109/SERVICES.2015.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7196537","Machine Learning;Service Recommendation;Service Selection","Accuracy;Approximation methods;Context;Data models;Optimization;Standards;Time factors","Web services;learning (artificial intelligence);pattern classification;recommender systems;regression analysis","Web services;classification approach;machine learning approaches;measured consumer experiences;regression approach;service functionality;service performance prediction;service recommendation","","0","","19","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Network intrusion classification based on extreme learning machine","Z. Ye; Y. Yu","Department of Mathematics and Computer Science, Fuzhou University, China","2015 IEEE International Conference on Information and Automation","20151001","2015","","","1642","1647","Extreme learning machine (ELM) is an efficient learning algorithm which can be easily used with least human intervene. But when ELM is applied as multiclass classifier, the results of some classes are not satisfactory and it's hard to adjust the parameters for these classes without affecting other classes. To overcome these limitations, a novel method is proposed. In proposed approach, binary ELM classifiers for each class are combined into an ensemble classifier using one-to-all strategy. The experiment on NSL-KDD data shows that the proposed approach outperforms ELM multiclass classifier, decision tree, neural network (NN) and support vector machines (SVM).","","Electronic:978-1-4673-9104-7; POD:978-1-4673-9105-4; USB:978-1-4673-9103-0","10.1109/ICInfA.2015.7279549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279549","Extreme Learning Machine;NSL-KDD;Network Intrusion Classification","Accuracy;Artificial neural networks;Biological neural networks;Decision trees;Machine learning algorithms;Support vector machines;Training","learning (artificial intelligence);pattern classification;security of data","ELM algorithm;ELM multiclass classifier;NN;NSL-KDD data;SVM;binary ELM classifiers;decision tree;ensemble classifier;extreme learning machine;network intrusion classification;neural network;one-to-all strategy;support vector machines","","","","16","","","8-10 Aug. 2015","","IEEE","IEEE Conference Publications"
"Correlation Analysis of Big Data to Support Machine Learning","R. Pandey; M. Dhoundiyal; A. Kumar","Amity Inst. of Inf. Technol., Amity Univ., Lucknow, India","2015 Fifth International Conference on Communication Systems and Network Technologies","20151001","2015","","","996","999","The large size and complexity of datasets in Big Data need specialized statistical tools for analysis and we use R for correlation analysis of our data set. This paper explores the correlation analysis through best fit linear regression of quantitative variables with help of the demonstration based on scatter plots and linear regression best fit line. The analysis demonstrated in this paper is scalable to Big Data in any other context where the quantitative variables are clearly delineated. R provides multiple techniques and inferences to statistical analysis of dataset, this paper however explores the correlation between quantitative variable establishing the extent of dependability between them using R functions. The correlation and best fit line functions of R i.e. Cor () and abline(lmout) respectively are significantly explored.","","Electronic:978-1-4799-1797-6; POD:978-1-4799-1798-3","10.1109/CSNT.2015.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280068","Big Data;Correlation analysis;Linear Model;Linear Regression;Quantitative Variables;R","Big data;Complexity theory;Correlation;Data analysis;Data mining;Education;Linear regression","Big Data;correlation methods;learning (artificial intelligence);regression analysis","Big Data;best fit linear regression;correlation analysis;data set;linear regression best fit line;machine learning;quantitative variables;scatter plots;statistical analysis;statistical tools","","1","","11","","","4-6 April 2015","","IEEE","IEEE Conference Publications"
"Effects of heuristic rule generation from multiple patterns in multiobjective fuzzy genetics-based machine learning","Y. Nojima; K. Watanabe; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan","2015 IEEE Congress on Evolutionary Computation (CEC)","20150914","2015","","","2996","3003","Fuzzy genetics-based machine learning (FGBML) has frequently been used for fuzzy classifier design. It is one of the promising evolutionary machine learning (EML) techniques from the viewpoint of data mining. This is because FGBML can generate accurate classifiers with linguistically interpretable fuzzy if-then rules. Of course, a classifier with tens of thousands of if-then rules is not linguistically understandable. Thus, the complexity minimization of fuzzy classifiers should be considered together with the accuracy maximization. In previous studies, we proposed hybrid FGBML and its multiobjective formulation (MoFGBML) to handle both the accuracy maximization and the complexity minimization simultaneously. MoFGBML can obtain a number of non-dominated classifiers with different tradeoffs between accuracy and complexity. In this paper, we focus on heuristic rule generation in MoFGBML to improve the search performance. In the original heuristic rule generation, each if-then rule is generated from a randomly-selected training pattern in a heuristic manner. This operation is performed at population initialization and during evolution. To generate more generalized rules according to the training data, we propose new heuristic rule generation where each rule is generated from multiple training patterns. Through computational experiments using some benchmark data sets, we discuss the effects of the proposed operation on the search performance of our MoFGBML.","1089-778X;1089778X","Electronic:978-1-4799-7492-4; POD:978-1-4799-7493-1","10.1109/CEC.2015.7257262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7257262","Fuzzy genetics-based machine learning;evolutionary multiobjective optimization;heuristic rule generation","Accuracy;Complexity theory;Fuzzy sets;Genetics;Probabilistic logic;Training;Training data","computational complexity;data mining;fuzzy reasoning;genetic algorithms;learning (artificial intelligence);minimisation;pattern classification","EML techniques;MoFGBML;complexity minimization;data mining;evolutionary machine learning techniques;fuzzy classifier design;heuristic rule generation effects;linguistically interpretable fuzzy if-then rules;multiobjective fuzzy genetics-based machine learning;multiple training patterns;nondominated classifiers;randomly-selected training pattern;search performance","","3","","25","","","25-28 May 2015","","IEEE","IEEE Conference Publications"
"Extreme learning machines in the field of text classification","R. K. Roul; A. Nanda; V. Patel; S. K. Sahay","Department of Computer Science, BITS Pilani-K.K. Birla Goa Campus","2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20150806","2015","","","1","7","The World Wide Web serves as a huge repository of information that is highly dynamic, diverse and growing at an exponential rate in a lightening speed. In order to speed-up and further improve tasks like information search and retrieval, personalization etc; it is highly important to develop techniques to classify text documents more accurately and efficiently than before. This paper is an effort in that direction, where the effectiveness of Extreme Learning Machines(ELM) in the domain of text classification is studied and compared with many of the existing relevant techniques like Support Vector Machines(SVM), which are currently one of the most popular and effective techniques for classifying text documents. Ours is one of the few works that highlight the high performance of ELM in the field of text classification, by implementing classifiers based on different interpretations of ELM, analyzing their performance, and studying which feature selection techniques are most suited to improve their accuracy. In our multi-class classification problem, we studied a single ELM classifier based on the one-against-all scheme, and a multi-layer ELM classifier inspired from deep networks, and then perform extensive experiments on different datasets to demonstrate the applicability and effectiveness of our approach. Results show that ELM based classifiers can outperform many of the traditional classification techniques including the most powerful state-of-the-art technique such as SVM.","","Electronic:978-1-4799-8676-7; POD:978-1-4799-8677-4","10.1109/SNPD.2015.7176204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7176204","Extreme Learning Machine;Feature Selection;Multi-layer ELM;Support Vector Machine;Text Classification","Computer science;Electronic mail;Machine learning algorithms;Support vector machines;Training;Training data;Tuning","feature selection;learning (artificial intelligence);parallel processing;pattern classification;support vector machines;text analysis","SVM;World Wide Web;extreme learning machine;feature selection technique;multiclass classification problem;multilayer ELM classifier;support vector machine;text document classification","","0","","15","","","1-3 June 2015","","IEEE","IEEE Conference Publications"
"A machine learning approach to detect occluded faces in unconstrained crowd scene","S. Gul; H. Farooq","Department of Computer & Software Engineering, Bahria University, Karachi, Pakistan","2015 IEEE 14th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","20150914","2015","","","149","155","The face verification systems gained significant attention in the last few years due to the increased security concern in public and private places. Face detection is the most important and initial stage in the automatic face verification system. It helps to determine the existence of faces in an image and return the position and location of the face. The face verification system's accuracy depends on face detection. The human faces are not always frontal and have many variations, therefore, face detection is challenging in unconstrained scenarios. One main challenge of face detection is occlusion. The proposed work is an attempt to illustrate the cognitive informatics approach using machine learning and present an occluded face detection method. The proposed method uses Adaboost[1] machine learning approach. The Viola-Jones[2] algorithm along with free rectangular features[3] has been adopted in the proposed approach in order to detect faces. the machine learning methods require two operation namely training and testing. Two cascade classifiers are used in which one is trained on holistic faces and the second is trained on half occluded faces; both of the classifiers are used in parallel to work in unconfined scene. Additionally, for improvement the correctness and adeptness of the system, the skin color models are applied which are used for removing of the false positive detection. The experiment has been performed on FDDB[4] dataset. The results shows that the proposed method achieve desirable results in the detection of half occluded faces.","","CD-ROM:978-1-4673-7289-3; Electronic:978-1-4673-7290-9; POD:978-1-4673-7291-6","10.1109/ICCI-CC.2015.7259379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7259379","blur;free rectangular features;occlusion;style;unconstrained face detection","","face recognition;image colour analysis;learning (artificial intelligence)","Adaboost machine learning approach;FDDB dataset;Viola-Jones algorithm;automatic face verification system;cascade classifiers;cognitive informatics approach;free rectangular features;occluded face detection method;private places;public places;skin color models;unconstrained crowd scene","","3","","32","","","6-8 July 2015","","IEEE","IEEE Conference Publications"
"Efficient domain module from electronic textbooks using machine learning method","Yogadinesh S.; Srihari K.","Department of Computer Science and Engineering, Sri Ramakrishna Institute of Technology, Coimbatore, India","2015 International Conference on Soft-Computing and Networks Security (ICSNS)","20151008","2015","","","1","5","In modern days technologies supported learning system (TSLS), intelligent tutoring systems (ITS), adaptive hypermedia systems (AHS), learning management systems (LMS), and system are used. Moodle and other educational motivation tools are used in institution. DOM-Sortze is a technique where many educational NLP are implemented. The electronic book are taken as input and from these book thee searching is done. The keywords are searched in the whole e-book Instead of using Moodle, and other educational motivation tools, DOM-Sortze is implemented and being used for the search purpose.","","Electronic:978-1-4799-1753-2; POD:978-1-4799-1754-9","10.1109/ICSNS.2015.7292397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7292397","Ontology;Preprocessing;Searching","Communication networks;Learning systems;Ontologies;Portable document format;Security;Speech","electronic publishing;hypermedia;intelligent tutoring systems;learning (artificial intelligence);learning management systems","AHS;DOM-Sortze;ITS;LMS;Moodle;TSLS;adaptive hypermedia systems;domain module;e-book;educational NLP;educational motivation tools;electronic book;electronic textbooks;intelligent tutoring systems;learning management systems;machine learning method;technologies supported learning system","","","","13","","","25-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"A Machine Learning-Based Framework for Building Application Failure Prediction Models","A. Pellegrini; P. D. Sanzo; D. R. Avresky","DIAG, Sapienza, Univ. of Rome, Rome, Italy","2015 IEEE International Parallel and Distributed Processing Symposium Workshop","20151001","2015","","","1072","1081","In this paper, we present the Framework for building Failure Prediction Models (F<sup>2</sup>PM), a Machine Learning-based Framework to build models for predicting the Remaining Time to Failure (RTTF) of applications in the presence of software anomalies. F<sup>2</sup>PM uses measurements of a number of system features in order to create a knowledge base, which is then used to build prediction models. F<sup>2</sup>PM is application-independent, i.e. It solely exploits measurements of system-level features. Thus, it can be used in differentiated contexts, without the need for any manual modification or intervention to the running applications. To generate optimized models, F<sup>2</sup>PM can perform a feature selection to identify, among all the measured system features, which have a major impact in the prediction of the RTTF. This allows to produce different models, which use different set of input features. Generated models can be compared by the user by using a set of metrics produced by F<sup>2</sup>PM, which are related to the model prediction accuracy, as well as to the model building time. We also present experimental results of a successful application of F<sup>2</sup>PM, using the standard TPC-W e-commerce benchmark.","","Electronic:978-1-4673-7684-6; POD:978-1-4673-7685-3","10.1109/IPDPSW.2015.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284428","machine learning;modeling;remaining time to fail;system failure prediction","Buildings;Computer crashes;Measurement;Monitoring;Predictive models;Software;Training","electronic commerce;fault tolerant computing;learning (artificial intelligence)","F<sup>2</sup>PM;RTTF;TPC-W e-commerce benchmark;application failure prediction models;framework for building failure prediction models;generated models;machine learning-based framework;model building time;model prediction accuracy;optimized models;remaining time to failure;system-level features","","3","","24","","","25-29 May 2015","","IEEE","IEEE Conference Publications"
"Advanced machine learning and textural methods in monitoring cell death using quantitative ultrasound spectroscopy","M. J. Gangeh; A. E. Kaffas; A. Hashim; A. Giles; G. J. Czarnota","Depts. of Medical Biophysics and Radiation Oncology, University of Toronto, Toronto, ON, Canada","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","646","650","A computer-aided-prognosis system is demonstrated based on quantitative ultrasound spectroscopy methods, textural features using local binary patterns (LBPs), and estimation of the distance between âpre-â and âpost-treatmentâ samples using a kernel-based metric. The proposed method estimates the level of cell death, non-invasively, in preclinical animal models. In this study, sarcoma xenograft tumour-bearing mice were injected with microbubbles followed by ultrasound and X-ray radiation therapy successively as a new anti-vascular treatment. High frequency (central frequency 25 MHz) ultrasound imaging was performed before and 24 hours after treatment. Quantitative ultrasound spectral parametric maps were subsequently generated. Textural features were extracted by applying LBPs to the 2D parametric maps. Finally a supervised learning paradigm was used to classify the level of cell death to less/more than two threshold levels, i.e., 20% and 40%, by using the distance between the âpre-â and âpost-treatmentâ images computed using a kernel-based metric. A maximum accuracy of 88% was achieved for both cell death level thresholds using the computer-aided-prognosis system and demonstrated the success of the system to identify the level of cell death, non-invasively in order to evaluate the effectiveness of cancer treatment administration.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163956","Cancer therapy;kernel methods;local binary patterns;microbubble;quantitative ultrasound;supervised learning;texture","Biomedical imaging;Cancer;Measurement;Medical treatment;Tumors;Ultrasonic imaging","biomedical ultrasonics;bubbles;cancer;cellular biophysics;feature extraction;image texture;learning (artificial intelligence);medical image processing;radiation therapy;tumours;ultrasonic therapy","2D parametric maps;LBP;X-ray radiation therapy;advanced machine learning;antivascular treatment;cancer treatment administration;cell death level thresholds;cell death monitoring;computer-aided-prognosis system;frequency 25 MHz;high frequency ultrasound imaging;kernel-based metric;local binary patterns;microbubbles;posttreatment images;preclinical animal models;pretreatment images;quantitative ultrasound spectral parametric maps;quantitative ultrasound spectroscopy methods;sarcoma xenograft tumour-bearing mice;supervised learning paradigm;textural feature extraction;time 24 hr;ultrasound therapy","","1","","23","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Malware detection via API calls, topic models and machine learning","G. G. Sundarkumar; V. Ravi; I. Nwogu; V. Govindaraju","Institute for Development and Research in Banking Technology and University of Hyderabad, Hyderabad-500046 (AP), India","2015 IEEE International Conference on Automation Science and Engineering (CASE)","20151008","2015","","","1212","1217","Dissemination of malicious code, also known as malware, poses severe challenges to cyber security. Malware authors embed software in seemingly innocuous executables, unknown to a user. The malware subsequently interacts with security-critical OS resources on the host system or network, in order to destroy their information or to gather sensitive information such as passwords and credit card numbers. Malware authors typically use Application Programming Interface (API) calls to perpetrate these crimes. We present a model that uses text mining and topic modeling to detect malware, based on the types of API call sequences. We evaluated our technique on two publicly available datasets. We observed that Decision Tree and Support Vector Machine yielded significant results. We performed t-test with respect to sensitivity for the two models and found that statistically there is no significant difference between these models. We recommend Decision Tree as it yields `if-then' rules, which could be used as an early warning expert system.","2161-8070;21618070","Electronic:978-1-4673-8183-3; POD:978-1-4673-8184-0","10.1109/CoASE.2015.7294263","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294263","","Feature extraction;Grippers;Sensitivity;Support vector machines;Text mining;Trojan horses","application program interfaces;data mining;decision trees;expert systems;invasive software;learning (artificial intelligence);support vector machines","API calls;application programming interface calls;cyber security;decision tree;early warning expert system;if-then rules;machine learning;malicious code dissemination;malware detection;security-critical OS resources;support vector machine;text mining;topic modeling;topic models","","1","","35","","","24-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"Intelligent data mining and machine learning for mental health diagnosis using genetic algorithm","G. Azar; C. Gloster; N. El-Bathy; S. Yu; R. H. Neela; I. Alothman","Lawrence Technological University, Southfield, MI, USA","2015 IEEE International Conference on Electro/Information Technology (EIT)","20151008","2015","","","201","206","Inappropriate diagnosis of mental health illnesses leads to wrong treatment and causes irreversible deterioration in the client's mental health status including hospitalization and/or premature death. About 12 million patients are misdiagnosed annually in US. In this paper, a novel study introduces a semi-automated system that aids in preliminary diagnosis of the psychological disorder patient. This is accomplished based on matching description of a patient's mental health status with the mental illnesses illustrated in DSM-IV-TR, Fourth Edition Text Revision. The study constructs the semi-automated system based on an integration of the technology of genetic algorithm, classification data mining and machine learning. The goal is not to fully automate the classification process of mentally ill individuals, but to ensure that a classifier is aware of all possible mental health illnesses could match patient's symptoms. The classifier/psychological analyst will be able to make an informed, intelligent and appropriate assessment that will lead to an accurate prognosis. The analyst will be the ultimate selector of the diagnosis and treatment plan.","2154-0357;21540357","Electronic:978-1-4799-8802-0; POD:978-1-4799-8803-7; USB:978-1-4799-8801-3","10.1109/EIT.2015.7293425","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293425","","Algorithm design and analysis;Biological cells;Data mining;Databases;Genetic algorithms;Sociology;Statistics","data mining;genetic algorithms;learning (artificial intelligence);medical diagnostic computing;pattern classification","classification data mining;genetic algorithm;intelligent data mining;machine learning;mental health diagnosis;mental health status;psychological disorder patient diagnosis","","","","10","","","21-23 May 2015","","IEEE","IEEE Conference Publications"
"Applying Natural Language Processing, Information Retrieval and Machine Learning to Decision Support in Medical Coordination in an Emergency Medicine Context","J. T. Pollettini; H. C. Pessotti; A. P. Filho; E. E. S. Ruiz; M. S. A. Junior","Univ. of Sao Paulo, Ribeira&#x0303;o Preto, Brazil","2015 IEEE 28th International Symposium on Computer-Based Medical Systems","20150727","2015","","","316","319","The Medical Coordination, which is the application of logistics techniques to emergency context, is responsible for providing appropriate resources, in appropriate conditions to appropriate patients. A system for medical coordination of emergency requests was developed in 2009, although some activities related to medical coordination decision making are extremely subjective. Aiming to decrease subjectivity on activities like prioritization of requests and coordination flow, new technologies of decision support were incorporated to that system. These technologies include textual and semantic processing of clinical summaries and machine learning tools. Results indicate that automated tools could support decision on medical coordination process, allowing coordinators to focus attention on critical cases. These features may streamline the medical coordination, avoiding mistakes and increasing the chances of saving lives.","1063-7125;10637125","Electronic:978-1-4673-6775-2; POD:978-1-4673-6776-9","10.1109/CBMS.2015.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167507","Emergency Medicine;Information Retrieval;Machine Learning;Medical Coordination;Natural Language Processing","Accuracy;Information retrieval;Machine learning algorithms;Medical services;Natural language processing;Semantics;Unified modeling language","decision support systems;information retrieval;learning (artificial intelligence);medical diagnostic computing;natural language processing","clinical summaries;coordination flow;decision support;emergency medicine context;information retrieval;logistics techniques;machine learning;medical coordination decision making;medical coordination process;natural language processing;semantic processing;textual processing","","0","","16","","","22-25 June 2015","","IEEE","IEEE Conference Publications"
"SI for free: machine learning of interconnect coupling delay and transition effects","A. B. Kahng; M. Luo; S. Nath","ECE UC San Diego, La Jolla, CA, USA","2015 ACM/IEEE International Workshop on System Level Interconnect Prediction (SLIP)","20150730","2015","","","1","8","In advanced technology nodes, incremental delay due to coupling is a serious concern. Design companies spend significant resources on static timing analysis (STA) tool licenses with signal integrity (SI) enabled. The runtime of the STA tools in SI mode is typically large due to complex algorithms and iterative calculation of timing windows to accurately determine aggressor and victim alignments, as well as delay and slew estimations. In this work, we develop machine learning-based predictors of timing in SI mode based on timing reports from non-SI mode. Timing analysis in non-SI mode is faster and the license costs can be several times less than those of SI mode. We determine electrical and logic structure parameters that affect the incremental arc delay/slew and path delay (i.e., the difference in arrival times at the clock pin of the launch flip-flop and the D pin of the capture flip-flop) in SI mode, and develop models that can predict these SI-aware delays. We report worst-case error of 7.0ps and average error of 0.7ps for our models to predict incremental transition time, worst-case error of 5.2ps and average error of 1.2ps for our models to predict incremental delay, and worst-case error of 8.2ps and average error of 1.7ps for our models to predict path delay, in 28nm FDSOI technology. We also demonstrate that our models are robust across designs and signoff constraints at a particular technology node.","","Electronic:978-1-4673-8189-5; POD:978-1-4673-8190-1","10.1109/SLIP.2015.7171706","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7171706","SI-aware path delay;Signal integrity (SI);incremental delay;incremental transition time;machine learning","Capacitance;Clocks;Couplings;Delays;Predictive models;Silicon","delays;electronic engineering computing;integrated circuit design;integrated circuit interconnections;learning (artificial intelligence);timing","FDSOI technology;complex algorithms;incremental delay;interconnect coupling delay;iterative calculation;machine learning based predictors;path delay prediction;signal integrity enabled analysis;size 28 nm;static timing analysis tool;transition effects","","1","","28","","","6-6 June 2015","","IEEE","IEEE Conference Publications"
"A Novel Approach Towards Context Sensitive Recommendations Based on Machine Learning Methodology","A. A. Kothari; W. D. Patel","Dept. of Comput. Sci. & Eng., Parul Inst. of Technol., Vadodara, India","2015 Fifth International Conference on Communication Systems and Network Technologies","20151001","2015","","","1114","1118","Contexts and aspects have been distinguished as the significant factors in fabricating recommender systems. Most recommender systems aim at utilizing either non-contextual preferences or contextual preferences distinctly, while very few endeavors have been made to identify the significance of both. Hence an attempt has been made to study the influence of both, users' context dependent and context independent preferences in the single recommender system. In this case, accuracy has always been a challenge. Therefore, there exists a need for such a classification technique which can be commonly applied to both types of preferences that helps enhance the accuracy of the retrieved results. For this purpose, use of a standard Machine learning technique well known as Support Vector Machines was proposed. The idea behind using Support vector machines is to split the data in an optimal way and classify the data precisely to aid prediction purpose. For generating recommendations, these context-dependent preferences are further combined with users' context-independent preferences. Finally this technique is applied on a real-life dataset to demonstrate that our method is proficient in dealing with contextual preferences of users and well classify them to achieve better recommendation accuracy than the relative works.","","Electronic:978-1-4799-1797-6; POD:978-1-4799-1798-3","10.1109/CSNT.2015.191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280093","Context;Opinion mining;Recommender System;Support Vector Machine","Accuracy;Context;Data mining;Recommender systems;Support vector machines;Training","data mining;learning (artificial intelligence);recommender systems","context independent preferences;context sensitive recommendations;machine learning methodology;noncontextual preferences;prediction purpose;recommender systems;support vector machines","","","","20","","","4-6 April 2015","","IEEE","IEEE Conference Publications"
"Energy detection and machine learning for the identification of wireless MAC technologies","S. A. Rajab; W. Balid; M. O. Al Kalaa; H. H. Refai","Electrical and Computer Engineering Department University of Oklahoma Tulsa, USA","2015 International Wireless Communications and Mobile Computing Conference (IWCMC)","20151005","2015","","","1440","1446","ISM spectrum is becoming increasingly populated with various wireless technologies, rendering it a scarce resource. Consequently, wireless coexistence is increasingly vulnerable to new wireless devices attempting to access the same spectrum. This paper presents a novel method for identifying wireless technologies through the use of simple energy detection techniques. Energy detection is used to measure the channel statistical temporal characteristics including activity and inactivity probability distributions. Features uniquely belonging to specific wireless technologies are extracted from the probability distributions and fed into a machine-learning algorithm to identify the technologies under evaluation. Wireless technology identification enables situational awareness to improve coexistence and reduce interference among the devices. An intelligent wireless device is capable of detecting wireless technologies operating within same vicinity. This can be performed by scanning energy levels without the need for signal demodulation and decoding. In this work, a wireless technology identification algorithm was assessed experimentally. Temporal traffic pattern for 802.11b/g/n homogeneous and heterogeneous networks were measured and used as algorithm input. Identification accuracies of up to 96.83% and 85.9% were achieved for homogeneous and heterogeneous networks, respectively.","2376-6492;23766492","CD-ROM:978-1-4799-5343-1; Electronic:978-1-4799-5344-8; POD:978-1-4799-5345-5","10.1109/IWCMC.2015.7289294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7289294","cognitive radio;energy detection;machine learning;wireless coexistence;wireless technology identification","Accuracy;Feature extraction;IEEE 802.11n Standard;Wireless communication;Wireless sensor networks","learning (artificial intelligence);radio networks;statistical distributions","ISM spectrum;activity probability distributions;channel statistical temporal characteristics;energy detection techniques;inactivity probability distributions;intelligent wireless device;machine learning;wireless MAC technologies;wireless coexistence","","2","","21","","","24-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"Multimodal Segmentation of Optic Disc and Cup From SD-OCT and Color Fundus Photographs Using a Machine-Learning Graph-Based Approach","M. S. Miri; M. D. AbrÃ moff; K. Lee; M. Niemeijer; J. K. Wang; Y. H. Kwon; M. K. Garvin","Department of Electrical and Computer Engineering, The University of Iowa, Iowa City","IEEE Transactions on Medical Imaging","20150828","2015","34","9","1854","1866","In this work, a multimodal approach is proposed to use the complementary information from fundus photographs and spectral domain optical coherence tomography (SD-OCT) volumes in order to segment the optic disc and cup boundaries. The problem is formulated as an optimization problem where the optimal solution is obtained using a machine-learning theoretical graph-based method. In particular, first the fundus photograph is registered to the 2D projection of the SD-OCT volume. Three in-region cost functions are designed using a random forest classifier corresponding to three regions of cup, rim, and background. Next, the volumes are resampled to create radial scans in which the Bruch's Membrane Opening (BMO) endpoints are easier to detect. Similar to in-region cost function design, the disc-boundary cost function is designed using a random forest classifier for which the features are created by applying the Haar Stationary Wavelet Transform (SWT) to the radial projection image. A multisurface graph-based approach utilizes the in-region and disc-boundary cost images to segment the boundaries of optic disc and cup under feasibility constraints. The approach is evaluated on 25 multimodal image pairs from 25 subjects in a leave-one-out fashion (by subject). The performances of the graph-theoretic approach using three sets of cost functions are compared: 1) using unimodal (OCT only) in-region costs, 2) using multimodal in-region costs, and 3) using multimodal in-region and disc-boundary costs. Results show that the multimodal approaches outperform the unimodal approach in segmenting the optic disc and cup.","0278-0062;02780062","","10.1109/TMI.2015.2412881","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060704","Bruch's membrane opening;SD-OCT;multimodal;ophthalmology;optic disc;retina;segmentation","Biomedical optical imaging;Cost function;Feature extraction;Image color analysis;Image segmentation;Optical imaging;Urban areas","Haar transforms;biomedical optical imaging;eye;graph theory;image classification;image registration;image sampling;image segmentation;learning (artificial intelligence);medical image processing;optical tomography;wavelet transforms","2D projection;Bruch membrane opening endpoints;Haar stationary wavelet transform;SD-OCT volume;color fundus photographs;cup boundaries;disc-boundary cost function;in-region cost functions;machine-learning theoretical graph-based method;multimodal image pairs;multimodal segmentation;multisurface graph-based approach;optic disc boundaries;optimization problem;radial projection image;radial scans;random forest classifier;spectral domain optical coherence tomography volumes","0","5","","32","","20150313","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Semi-automatic building of Domain Module by use of novel machine learning approach","Deepika Raj K; Saani H","Dept. of Computer Science and Engineering, MEA Engineering College, Perinthalmanna, India","2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)","20150813","2015","","","1","5","The Domain Module is considered the core of any TSLSs as it represents the knowledge about a subject matter to be communicated to the learner. In the existing system, proposed a DOM-Sortze is a system that uses natural language processing techniques, heuristic reasoning, and ontologies for the semiautomatic construction of the Domain Module from electronic textbooks. But in this system, still lack in the identification of pedagogical relationships. This is needed to improve in this system. To overcome this issue, Here using learning techniques to learn the new rules in the pedagogical relationships. In this proposed system, proposing the SVM (support vector machine) learning approach intended for learning process. The machine learning methods are used to infer new rules in order to improve the identification of pedagogical relationships or the DRs in the electronic textbooks.","","Electronic:978-1-4799-6818-3; POD:978-1-4799-6819-0","10.1109/ICIIECS.2015.7193195","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7193195","Domain Module;Knowledge acquisition;Ontology;domain engineering;ontology design","Buildings;Data mining;Databases;Learning systems;Ontologies;Support vector machines;Training","computer aided instruction;electronic publishing;learning (artificial intelligence);support vector machines","DOM-Sortze;SVM learning;TSLS;electronic textbooks;heuristic reasoning;machine learning methods;natural language processing;ontologies;semiautomatic domain module building;support vector machine;technology-supported learning systems","","0","","6","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Comparison of two multi-step ahead forecasting mechanisms for wind speed based on machine learning models","Z. Chi; W. Haikun; Z. Tingting; Z. Kanjian; L. Tianhong","Key Laboratory of Measurement and Control of CSE, Ministry of Education, School of Automation, Southeast University, Nanjing 210096, P.R. China","2015 34th Chinese Control Conference (CCC)","20150914","2015","","","8183","8187","Accurate wind speed forecasts are important to the realtime optimization of wind farm operation and the scheduling of a power system. In the case of multi-step ahead forecasting, two mechanisms, namely, iterative and direct, are commonly adopted. In this paper, a comprehensive comparison study is presented on the applicability of these two methods, based on the wind speed datasets from three wind farms in China. Three representative machine learning models, linear regression (LR), multi-layer perceptron (MLP) and support vector machine (SVM) are developed, respectively. The results show that neither direct nor iterative forecasting can always outperform each other in terms of all the error measures. But in most cases, the performance of the direct forecasting is better than that of the iterative forecasting, especially when the prediction horizon is large and combined with the non-linear models (MLP or SVM).","","Electronic:978-9-8815-6389-7; POD:978-1-4673-7443-9","10.1109/ChiCC.2015.7260941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7260941","Direct forecasting;Iterative forecasting;Linear regression;Multi-layer perceptron;Support vector machine;Wind speed prediction","Forecasting;Linear regression;Mathematical model;Predictive models;Support vector machines;Wind forecasting;Wind speed","iterative methods;learning (artificial intelligence);multilayer perceptrons;power engineering computing;power system management;regression analysis;support vector machines;wind power plants","China;LR;MLP;SVM;direct multistep ahead forecasting;iterative multistep ahead forecasting;linear regression;machine learning;multilayer perceptron;multistep ahead forecasting mechanism;power system scheduling;support vector machine;wind farm operation;wind speed dataset;wind speed forecast","","","","20","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Web Server Protection against Application Layer DDoS Attacks Using Machine Learning and Traffic Authentication","J. D. Ndibwile; A. Govardhan; K. Okada; Y. Kadobayashi","Sch. of IT, Jawaharlal Nehru Technol. Univ., Hyderabad, India","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","3","","261","267","Application layer Distributed Denial of Service (DDoS) attacks are among the deadliest kinds of attacks that have significant impact on destination servers and networks due to their ability to be launched with minimal computational resources to cause an effect of high magnitude. Commercial and government Web servers have become the primary target of these kinds of attacks, with the recent mitigation efforts struggling to deaden the problem efficiently. Most application layer DDoS attacks can successfully mimic legitimate traffic without being detected by Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS). IDSs and IPSs can also mistake a normal and legitimate activity for a malicious one, producing a False Positive (FP) that affects Web users if it is ignored or dropped. False positives in a large and complex network topology can potentially be dangerous as they may cause IDS/IPS to block the user's benign traffic. Our focus and contributions in this paper are first, to mitigate the undetected malicious traffic mimicking legitimate traffic and developing a special anti-DDoS module for general and specific DDoS tools attacks by using a trained classifier in a random tree machine-learning algorithm. We use labeled datasets to generate rules to incorporate and fine-tune existing IDS/IPS such as Snort. Secondly, we further assist IDS/IPS by processing traffic that is classified as malicious by the IDS/IPS in order to identify FPs and route them to their intended destinations. To achieve this, our approach uses active authentication of traffic source of both legitimate and malicious traffic at the Bait and Decoy server respectively before destined to the Web server.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.240","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273365","DDoS Mitigation;False Positives;IDS/IPS;Java Script;Machine Learning","Authentication;Computer crime;Logic gates;Training;Web servers","Internet;computer network security;file servers;learning (artificial intelligence);pattern classification;telecommunication traffic","FP;IDS;IPS;Web server protection;Web users;application layer DDoS attacks;bait-and-decoy server;destination servers;distributed denial of service;false positive;government Web servers;intrusion detection systems;intrusion prevention systems;legitimate traffic;malicious traffic;minimal computational resources;mitigation efforts;random tree machine-learning algorithm;traffic authentication;traffic source active authentication;trained classifier","","1","","13","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Handwritten character recognition using machine learning approach - A survey","S. R. Patel; J. Jha","L.J.I.E.T. PG Department, Ahmedabad, Gujarat - India","2015 International Conference on Electrical, Electronics, Signals, Communication and Optimization (EESCO)","20150910","2015","","","1","5","The document that should appear here is unavailable. This DOI was registered to an article that will not be disseminated via IEEE Xplore. IEEE has chosen to exclude this article from distribution after the conference for reasons that fall within the guidelines specified in section 8.2.1.B.13 of IEEE's ""Publication Services and Products Board Operations Manual."" We regret any inconvenience.","","DVD:978-1-4799-7675-1; Electronic:978-1-4799-7678-2; POD:978-1-4799-7679-9","10.1109/EESCO.2015.7253978","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7253978","","","","","","1","","28","","","24-25 Jan. 2015","","IEEE","IEEE Conference Publications"
"Drug-Drug Interactions prediction from enzyme action crossing through machine learning approaches","S. Hunta; N. Aunsri; T. Yooyativong","Mae Fah Luang University, Chiangrai, Thailand","2015 12th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","20150820","2015","","","1","4","Drug-Drug Interactions (DDIs) are major causes of morbidity and treatment inefficacy. The prediction of DDIs for avoiding the adverse effects is an important issue. There are many drug-drug interaction pairs, it is impossible to do in vitro or in vivo experiments for all the possible pairs. The limitation of DDIs research is the high costs. Many drug interactions are due to alterations in drug metabolism by enzymes. The most common among these enzymes are cytochrome P450 enzymes (CYP450). Drugs can be substrate, inhibitor or inducer of CYP450 which will affect metabolite of other drugs. This paper proposes enzyme action crossing attribute creation for DDIs prediction. Machine learning techniques, k-Nearest Neighbor (k-NN), Neural Networks (NNs), and Support Vector Machine (SVM) were used to find DDIs for simvastatin based on enzyme action crossing. SVM preformed the best providing the predictions at the accuracy of 70.40 % and of 81.85 % with balance and unbalance class label datasets respectively. Enzyme action crossing method provided the new attribute that can be used to predict drug-drug interactions.","","Electronic:978-1-4799-7961-5; POD:978-1-4799-7962-2","10.1109/ECTICon.2015.7207126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207126","cytochrome P450;drug-drug interaction;enzyme action;maching learning","Accuracy;Biochemistry;Drugs;Inhibitors;Predictive models;Substrates;Support vector machines","data analysis;enzymes;learning (artificial intelligence);medical computing;neural nets;support vector machines","CYP450;DDI;NN;SVM;balance class label datasets;cytochrome P450 enzymes;drug metabolism;drug-drug interactions prediction;enzyme action crossing attribute creation;inducer;inhibitor;k-nearest neighbor;machine learning approaches;metabolite;neural networks;simvastatin;substrate;support vector machine;unbalance class label datasets","","0","","10","","","24-27 June 2015","","IEEE","IEEE Conference Publications"
"A model recommends best machine learning algorithm to classify learners based on their interactivity with moodle","S. Hassan; A. El Fattah Hegazy","Information Systems and Multimedia, The Egyptian Cabinet, IDSC, Cairo, Egypt","2015 Second International Conference on Computing Technology and Information Management (ICCTIM)","20150827","2015","","","49","54","In big data universities, an understanding of how the individual learning style and preferences interacts with the instructional medium presented is needed. In this study we examined the VARK learning style inventory using the variable-centered, person-centered and social approaches. We worked on a big âdata setâ which encompasses two data sources the first was LMS while the second was social media portals associated with that LMS. In order to make classification as well as prediction for the learner's learning style LS, we applied âWEKAâ as we established a comparative analysis among different machine learning algorithms in order to know which one is the fit for the used âdata setâ.","","CD-ROM:978-1-4799-6210-5; Electronic:978-1-4799-6211-2; POD:978-1-4799-6212-9","10.1109/ICCTIM.2015.7224592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224592","âWEKAâ;Classification;EDM;Hyper Pipes;IBK;JRIP;LMS;Simple Logistics;VARK","Accuracy;Classification algorithms;Data mining;Data models;Least squares approximations;Logistics;Mathematical model","computer aided instruction;learning (artificial intelligence);pattern classification","Big Data universities;Moodle;VARK learning style inventory;WEKA;individual learning perference;individual learning style;learners classification;machine learning algorithm;person-centered approach;social approach;social media portals;variable-centered approach","","0","","12","","","21-23 April 2015","","IEEE","IEEE Conference Publications"
"Machine learning based cognitive skills calculations for different emotional conditions","S. Ahmad; A. Adnan","Dept: Computer Science, IM&#x007C;Sciences, Peshawar, Pakistan","2015 IEEE 14th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","20150914","2015","","","162","168","Advance measurement of cognitive skills of a human being is a challenging research works because these skills have a great relation with emotions, age and gender. Working with emotions in cognitive computing is challenging but we cannot ignore the importance of cognitive skills during critical tasks as flying, fire fighting and driving public transports. During our previous published works we have conducted experiment on 8 participants of both genders. We have investigated that emotions, age, gender and cognitive skills have dependencies on one another. This paper investigate literature review of other researchers belong to psychology, neuroscience, HCI, as well as computer science which shows that emotions and EEG signal patterns have a great concern with cognitive skills. We have found evidence that emotions, age, gender and cognitive skills have great relations with each other.","","CD-ROM:978-1-4673-7289-3; Electronic:978-1-4673-7290-9; POD:978-1-4673-7291-6","10.1109/ICCI-CC.2015.7259381","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7259381","Cognitive skills;Computational Intelligence;Data Mining;F P Growth Algorithm;Human Emotion","Brain modeling;Computational modeling;Electroencephalography;Iron;Phase measurement;Physiology;Robots","cognition;electroencephalography;human computer interaction;learning (artificial intelligence);psychology","EEG signal patterns;HCI;age;computer science;emotional conditions;emotions;gender;machine learning based cognitive skills calculations;neuroscience;psychology","","","","34","","","6-8 July 2015","","IEEE","IEEE Conference Publications"
"Adversarial Biometric Recognition : A review on biometric system security from the adversarial machine-learning perspective","B. Biggio; g. fumera; P. Russu; L. Didaci; F. Roli","Dept. of Electr. & Electron. Eng., Univ. of Cagliari, Cagliari, Italy","IEEE Signal Processing Magazine","20150812","2015","32","5","31","41","In this article, we review previous work on biometric security under a recent framework proposed in the field of adversarial machine learning. This allows us to highlight novel insights on the security of biometric systems when operating in the presence of intelligent and adaptive attackers that manipulate data to compromise normal system operation. We show how this framework enables the categorization of known and novel vulnerabilities of biometric recognition systems, along with the corresponding attacks, countermeasures, and defense mechanisms. We report two application examples, respectively showing how to fabricate a more effective face spoofing attack, and how to counter an attack that exploits an unknown vulnerability of an adaptive face-recognition system to compromise its face templates.","1053-5888;10535888","","10.1109/MSP.2015.2426728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192841","","Behavioral science;Biometrics (access control);Feature extraction;Machine learning algorithms;Pattern recognition;Security;Signal processing algorithms","biometrics (access control);image recognition;learning (artificial intelligence)","adaptive face-recognition system;adversarial biometric recognition;biometric recognition systems;biometric security;biometric system security;biometric systems;face spoofing attack;machine learning;machine-learning","","3","","30","","","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Proposal and Evaluation of Methods Using the Quantification Theory and Machine Learning for Detecting C&amp;C Server Used in a Botnet","S. Okayasu; R. Sasaki","Tokyo Denki Univ., Tokyo, Japan","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","3","","24","29","In recent years, the damage caused by botnets has increased and become a big problem. To solve this problem, we proposed a method to detect unjust C&C servers by using Hayashi's quantification theory class II. This method is able to detect unjust C&C servers, even if they are not included in a blacklist. However, it was predicted that the detection rate for this method decreases with passing time. Therefore, we have been continuing the investigation of the detection rate and adjusting the optimal detection method in different time periods. This paper deals with the results of an investigation for 2014. In addition, we newly introduce a method using a support vector machine (SVM) for comparison with quantification theory class II. We found that the detection rates by using quantification theory class II and those by the SVM are both very good, with very little difference in accuracy between them.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273318","Botnet;C&amp;C Server;DNS;Hayashi's quantification methods;SVM","Accuracy;Data models;Electronic mail;Malware;Mathematical model;Servers;Support vector machines","invasive software;learning (artificial intelligence);support vector machines","C&C server;Hayashi quantification theory class II;SVM;botnet;detection rate;machine learning;optimal detection method;support vector machine","","","","20","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Predictive data analytics and machine learning enabling metrology and process control for advanced node IC fabrication","N. Rana; Y. Zhang; D. Wall; B. Dirahoui","IBM Semiconductor Research & Development Center, Hopewell Junction, NY-12533, USA","2015 26th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)","20150727","2015","","","313","319","Processor technology is going through multiple changes in terms of patterning techniques (multipatterning, EUV and DSA), device architectures (FinFET, nanowire, graphene) and patterning scale (few nanometers). These changes require tighter controls on processes and measurements to achieve the required device performance, and challenge the metrology and process control in terms of capability and quality. Predictive metrology and analytics offer Multivariate data with non-linear trends and complex correlations generally cannot be described well by mathematical models but can be relatively easily learned by computing machines and used to predict or extrapolate. In this paper we present the application of machine learning and analytics to accurately predict the electrical performance of deep trenches and metal lines. Machine learning models can be used in process control where, for example, the electrical test results are predicted early in the processing flow invoking appropriate actionable decisions. It is demonstrated that metal line resistance can be modeled directly by the raw reflectance spectra obtained using scatterometry tool. This obviates the need to make complex geometrical models to measure the CDs and then establishing the correlation of CDs to resistance. It is shown that dimensional parameters such as height and CD can be derived from the predicted electrical measurements. Such information can be used in feedforward or feedback flow to optimize, control or monitor processes in fab. Results show improved correlation of neural network model predicted deep trench capacitance to the measured capacitance compared to the capacitance predicted by multivariate linear regression model that is currently in use. This paper presents the concept of predictive metrology with the use of machine learning and predictive analytics for CD and electrical test predictions. Predictive metrology can be used in conjunction with hybrid metrology to enable APC and novel metrolog- pathways in gap areas in the advanced semiconductor research, development and manufacturing.","1078-8743;10788743","Electronic:978-1-4799-9930-9; POD:978-1-4799-9931-6","10.1109/ASMC.2015.7164502","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164502","Critical Dimension Atomic Force Microscopy (CD-AFM);Critical Dimension Scanning Electron Microscopy (CD-SEM);Deep Trench Capacitance and Metal Line Resistance;Electrical CD (ECD);Hybrid Metrology (HM);Machine Learning (ML);Model Based Infrared Reflectometry (MBIR);Neural Network (NN);Optical Critical Dimension Metrology (OCD);PM: Predictive Metrology (PM);Partial Least Square regression (PLS);Principal Components Analysis (PCA)","Capacitance;Data models;Metrology;Neural networks;Predictive models;Resistance;Semiconductor device modeling","learning (artificial intelligence);process control;regression analysis","DSA;EUV;FinFET;advanced node IC fabrication;deep trench capacitance;graphene;machine learning;multipatterning;multivariate linear regression model;nanowire;neural network model;patterning scale;predictive data analytics;process control;scatterometry tool","","2","","7","","","3-6 May 2015","","IEEE","IEEE Conference Publications"
"A machine learning approach for constrained sensor placement","K. Kasper; L. Mathelin; H. Abou-Kandil","SATIE, Ecole Normale Sup&#x00E9;rieure de Cachan, 94235 cedex, France","2015 American Control Conference (ACC)","20150730","2015","","","4479","4484","Sensor placement is of pivotal importance in closed-loop control as measurements are key to design the control laws. In this article, a novel machine learning-based sensor placement algorithm is proposed in order to recover a high-dimensional field from a limited amount of local measurements with a linear estimator. Unlike many other methods, our algorithm does not rely on a reduced order model and achieves good results even with a small number of sensors. In many situations, sensors cannot be placed arbitrarily, either because of their geometry or because of the environment they are in. Our algorithm naturally accounts for these constraints as well as being robust to noise. Its performance is illustrated on a fluid flow example and compared to two state of the art methods, Effective Independence and FrameSense, on the recovery of the pressure field from limited noisy pressure measurements.","0743-1619;07431619","CD-ROM:978-1-4799-8685-9; Electronic:978-1-4799-8684-2; POD:978-1-4799-1773-0","10.1109/ACC.2015.7172034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7172034","","Actuators;Algorithm design and analysis;Geometry;Machine learning algorithms;Noise;Noise measurement;Robustness","closed loop systems;learning (artificial intelligence);pressure measurement;reduced order systems;sensor placement","FrameSense;closed-loop control;constrained sensor placement;control laws;high-dimensional field;linear estimator;machine learning-based sensor placement algorithm;noisy pressure measurements;pressure field recovery;reduced order model","","0","","18","","","1-3 July 2015","","IEEE","IEEE Conference Publications"
"Using the Extreme Learning Machine (ELM) technique for heart disease diagnosis","S. Ismaeel; A. Miri; D. Chourishi","Department Computer Science, Ryerson University, Toronto, Canada","2015 IEEE Canada International Humanitarian Technology Conference (IHTC2015)","20150903","2015","","","1","3","One of the most important applications of machine learning systems is the diagnosis of heart disease which affect the lives of millions of people. Patients suffering from heart disease have lot of independent factors such as age, sex, serum cholesterol, blood sugar, etc. in common which can be used very effectively for diagnosis. In this paper an Extreme Learning Machine (ELM) algorithm is used to model these factors. The proposed system can replace a costly medical checkups with a warning system for patients of the probable presence of heart disease. The system is implemented on real data collected by the Cleveland Clinic Foundation where around 300 patients information has been collected. Simulation results show this architecture has about 80% accuracy in determining heart disease.","","Electronic:978-1-4799-8963-8; POD:978-1-4799-8964-5","10.1109/IHTC.2015.7238043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238043","Extreme learning machine (ELM);Heart Disease;Neural Networks;Pattern Classification;Prediction and Diagnosis Systems","Computer architecture;Databases;Diseases;Heart;Mathematical model;Neural networks;Neurons","cardiology;diseases;learning (artificial intelligence);medical diagnostic computing;patient diagnosis","Cleveland Clinic Foundation;age;blood sugar;data collection;extreme learning machine technique;heart disease diagnosis;serum cholesterol;sex","","3","","18","","","May 31 2015-June 4 2015","","IEEE","IEEE Conference Publications"
"A Novel Weighted Hierarchical Adaptive Voting Ensemble Machine Learning Method for Breast Cancer Detection","C. Deng; M. Perkowski","Dept. of Electr. & Comput. Eng., Portland State Univ., Portland, OR, USA","2015 IEEE International Symposium on Multiple-Valued Logic","20150903","2015","","","115","120","A novel Weighted Hierarchical Adaptive Voting Ensemble (WHAVE) machine learning (ML) method was developed for breast cancer detection. It was constructed using three individual ML methods based on Multiple-Valued Logic: Disjunctive Normal Form (DNF) rule based method, Decision Trees, NaiÌve Bays, and one method based on continuous representation: Support Vector Machines (SVM). Results were compared with other methods and show that the WHAVE method accuracy was noticeably higher than the individual ML methods tested. This paper demonstrates that the WHAVE method proposed outperforms all methods researched, and shows the advantage of using WHAVE method for ML in breast cancer detection.","0195-623X;0195623X","Electronic:978-1-4799-1777-8; POD:978-1-4799-1778-5","10.1109/ISMVL.2015.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238143","Ensemble;Machine Learning;Majority Voting System;Multi-Valued Logic","Accuracy;Breast cancer;Decision trees;Learning systems;Support vector machines;Testing;Training","Bayes methods;cancer;decision trees;learning (artificial intelligence);medical computing;multivalued logic;support vector machines","DNF rule based method;Naive Bayes;SVM;WHAVE ML method;breast cancer detection;continuous representation;decision trees;disjunctive normal form rule based method;multiple-valued logic;support vector machines;weighted hierarchical adaptive voting ensemble machine learning method","","0","","30","","","18-20 May 2015","","IEEE","IEEE Conference Publications"
"Machine learning for seizure prediction: A revamped approach","S. Kumar A; L. Nigam; D. Karnam; S. K. Murthy; P. Fedorovych; V. Kalidindi","Quadratic Insights Pvt Ltd, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","1159","1164","Occurrence of multiple seizures is a common phenomenon observed in patients with epilepsy: a neurological malfunction that affects approximately 50 million people in the world. Seizure prediction is widely acknowledged as an important problem in the neurological domain, as it holds promise to improve the quality of life for patients with epilepsy. A noticeable number of clinical studies showed evidence of symptoms (patterns) before seizures and thus, there is large research on predicting seizures. There is very little existing literature that systematically illustrates the steps in machine learning for seizure prediction, limited training data and class imbalance are a few challenges. In this paper, we propose a novel way to overcome these challenges. We present the improved results for various classification algorithms. An average of 21.71% improvement in accuracy is attained using our approach.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275767","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275767","Data Imbalance;Epilepsy;Machine Learning;Seizure Prediction","Accuracy;Classification algorithms;Electroencephalography;Epilepsy;Feature extraction;Machine learning algorithms;Predictive models","learning (artificial intelligence);medical computing;neurophysiology;pattern classification","classification algorithms;epilepsy patient;machine learning;neurological domain;quality of life;seizure prediction","","","","35","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Sentiment Analysis of Malayalam film review using machine learning techniques","D. S. Nair; J. P. Jayan; Rajeev R. R; E. Sherly","Virtual Resource Center for Language Computing, Indian Institute of Information Technology and Management- Kerala, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","2381","2384","The unprecedented growth of data in web, social media and the attempt to make the cognitive process using computers make Sentiment Analysis a challenging and interesting research problem. Sentiment Analysis mainly deals with the process of analyzing the sentiments or feelings from someone's expression or piece of information, and also in discovering the cognitive behavior of humans. The usage of computers to get feedback, opinion or remarks about a product, entertainment or political view of the public is very common. This paper demonstrates how Sentiment Analysis can be used in reviewing Malayalam films by using machine learning techniques. It is a hybrid approach comprising of machine learning techniques and rule based approach. This work would help the users to analyze the film criticism and also to assign the rank and popularity of new arrival films. In this work, the system checks the polarity at the sentence level, resulted in an accuracy of 91%.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275974","Conditional Random Field;Sentiment Analysis;Support Vector Machine","Accuracy;Context;Motion pictures;Semantics;Sentiment analysis;Support vector machines;Training","entertainment;learning (artificial intelligence);social aspects of automation;social networking (online)","Malayalam film review;cognitive process;machine learning techniques;sentiment analysis;social media;web","","1","","9","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Buffer Overflow Vulnerability Prediction from x86 Executables Using Static Analysis and Machine Learning","B. M. Padmanabhuni; H. B. K. Tan","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","2","","450","459","Mining static code attributes for predicting software vulnerabilities has received some attention recently. There are a number of approaches for detecting vulnerabilities from source code, but commercial off the shelf components are, in general, distributed in binary form. Before using such third-party components it is imperative to check for presence of vulnerabilities. We investigate the use of static analysis and machine learning for predicting buffer overflow vulnerabilities from binaries in this study. To mitigate buffer overflows, developers typically perform size checks and input validation. We propose static code attributes characterizing buffer usage and defense mechanisms implemented in the code for preventing buffer overflows. The proposed approach starts by identifying potential vulnerable statement constructs during binary program analysis and extracts static code attributes for each of them as per proposed characterization scheme to capture buffer usage patterns and defensive mechanisms employed in the code. Data mining methods are then used on these collected code attributes for predicting buffer overflows. Our experimental evaluation on standard buffer overflow benchmark binaries shows that the proposed static code attributes are effective in predicting buffer overflow vulnerabilities.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273653","binary static analysis;buffer overflow;buffer usage pattern;control and data dependency;disassembly;static code attributes;vulnerability prediction","Buffer overflows;Containers;Filling;Libraries;Registers;Semantics;Software","data mining;learning (artificial intelligence);program diagnostics;security of data;source code (software)","binary program analysis;buffer overflow vulnerability prediction;buffer usage patterns;data mining methods;machine learning;software vulnerability prediction;source code;static analysis;static code attributes;x86 executables","","","","27","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Estimation of Water Demand in Residential Building Using Machine Learning Approach","D. Suh; H. Kim; J. Kim","KAIST Inst. for Inf. Technol. Convergence, Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea","2015 5th International Conference on IT Convergence and Security (ICITCS)","20151008","2015","","","1","2","This paper shows an estimation model for residential water consumption using machine learning approach in Korea. We verify the diversifying elements constituting apartment buildings as input datasets for the Back- Propagation Neural Network (BPNN), the most novel supervised learning neural network based model in accordance with the empirical water use data. A water use prediction for residential buildings is a complex and nonlinear function of geographic, climatic, and morphological variables of buildings. For the verification purpose, empirical data sets consisting of water usage data retrieved from multiple residential apartment buildings in Korea were analyzed as case studies. The proposed model accurately forecast water uses for each examined residential apartment buildings. The results of the proposed models could offer a reliable water supply to meet the useful needs of customers and the local community while facilitating the efficient consumption of water.","","Electronic:978-1-4673-6537-6; POD:978-1-4673-6538-3","10.1109/ICITCS.2015.7292979","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7292979","","Buildings;Estimation;Neural networks;Predictive models;Reliability;Water conservation;Water resources","backpropagation;neural nets;nonlinear functions;water supply","BPNN;Korea;back-propagation neural network;climatic variables;empirical data sets;estimation model;geographic variables;machine learning approach;morphological variables;nonlinear function;residential apartment buildings;residential water consumption;supervised learning neural network based model;verification purpose;water demand estimation;water supply;water usage data;water use data;water use prediction;water uses forecasting","","","","5","","","24-27 Aug. 2015","","IEEE","IEEE Conference Publications"
"Crop Selection Method to maximize crop yield rate using machine learning technique","R. Kumar; M. P. Singh; P. Kumar; J. P. Singh","Dept. of CSE NIT Patna, India","2015 International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM)","20150827","2015","","","138","145","Agriculture planning plays a significant role in economic growth and food security of agro-based country. Se- lection of crop(s) is an important issue for agriculture planning. It depends on various parameters such as production rate, market price and government policies. Many researchers studied prediction of yield rate of crop, prediction of weather, soil classification and crop classification for agriculture planning using statistics methods or machine learning techniques. If there is more than one option to plant a crop at a time using limited land resource, then selection of crop is a puzzle. This paper proposed a method named Crop Selection Method (CSM) to solve crop selection problem, and maximize net yield rate of crop over season and subsequently achieves maximum economic growth of the country. The proposed method may improve net yield rate of crops.","","CD:978-1-4799-9853-1; Electronic:978-1-4799-9855-5; Paper:978-1-4799-9854-8","10.1109/ICSTM.2015.7225403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225403","CSM (Crop Selection Method);Climate;GBDT (Gradient Boosted Decision Tree);RGF (Regularized Greedy Forest);Soil composition;regression problem;regularization","Agriculture;Decision trees;Prediction algorithms;Predictive models;Production;Support vector machines;Vegetation","crops;economics;learning (artificial intelligence);optimisation;pattern classification;production planning;soil","CSM;agriculture planning;agro-based country;crop classification;crop selection method;crop yield rate maximization;economic growth;food security;government policies;land resource;machine learning technique;market price;production rate;soil classification;statistics;weather prediction","","0","","34","","","6-8 May 2015","","IEEE","IEEE Conference Publications"
"An alternative evaluation of post traumatic stress disorder with machine learning methods","S. Ä°. Omurca; E. Ekinci","Computer Engineering Department, Kocaeli University, Kocaeli, Turkey","2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA)","20150928","2015","","","1","7","In the world we live in, people from different professions are at increased risk for depressive symptoms and posttraumatic stress disorder (PTSD) due to hard working or extreme environmental conditions. Accurate diagnosis and determining the causes are very important to solve these kinds of psychological problems. Machine learning (ML) techniques are gaining popularity in neuroscience due to their high diagnostic capability and effective classification ability. In this paper, alternative hybrid systems which allowed us to develop automatic classifiers for finding the Posttraumatic stress disorder (PTSD) patients are proposed and compared. With the proposed system, not only the PTSD individuals are classified by ML techniques such as sequential minimal optimization (SMO), multilayer perceptron (MLP), NaiÌve Bayes (NB) but also the important indications of patients' trauma are determined by three popular feature selection methods such as chi-square, principal component analysis (PCA) and correlation based-feature selection (CFS). The effectiveness of the proposed system is examined on a real world dataset. Due to obtained results we can estimate the individuals as PTSD or NONPTSD patients with 74-79% accuracy range, further to that instead of 39 features 7 features are remarked as the most critical symptoms for PTSD.","","Electronic:978-1-4673-7751-5; POD:978-1-4673-7752-2; USB:978-1-4673-9096-5","10.1109/INISTA.2015.7276754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7276754","feature selection;intelligent diagnosis;machine learning;posttraumatic stress disorder","Algorithm design and analysis;Classification algorithms;Medical services;Niobium;Principal component analysis;Stress;Support vector machines","Bayes methods;feature selection;learning (artificial intelligence);medical computing;multilayer perceptrons;patient diagnosis;pattern classification;principal component analysis;psychology","CFS;MLP;NB;PCA;PTSD;SMO;alternative hybrid systems;chi-square;classification ability;correlation based-feature selection;depressive symptoms;diagnostic capability;feature selection methods;machine learning methods;multilayer perceptron;naiÌve Bayes;neuroscience;post traumatic stress disorder evaluation;posttraumatic stress disorder;principal component analysis;psychological problems;sequential minimal optimization","","","","46","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"Multi-scale local shape analysis and feature selection in machine learning applications","P. Bendich; E. Gasparovic; J. Harer; R. Izmailov; L. Ness","Department of Mathematics, Duke University, Durham, NC 27708, USA","2015 International Joint Conference on Neural Networks (IJCNN)","20151001","2015","","","1","8","We introduce a method called multi-scale local shape analysis for extracting features that describe the local structure of points within a dataset. The method uses both geometric and topological features at multiple levels of granularity to capture diverse types of local information for subsequent machine learning algorithms operating on the dataset. Using synthetic and real dataset examples, we demonstrate significant performance improvement of classification algorithms constructed for these datasets with correspondingly augmented features.","2161-4393;21614393","Electronic:978-1-4799-1960-4; POD:978-1-4799-1961-1","10.1109/IJCNN.2015.7280428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280428","","Stability analysis","data analysis;feature extraction;feature selection;learning (artificial intelligence);pattern classification","classification algorithms;feature extraction;feature selection;geometric feature;machine learning applications;multiscale local shape analysis;topological feature","","1","","30","","","12-17 July 2015","","IEEE","IEEE Conference Publications"
"Applications of four machine learning algorithms in identifying bacterial essential genes based on composition features","Y. Y. Deng; F. B. Guo","Health big data science research center, big data research center, University of Electronic Science and Technology of China, Chengdu, 610054, China","2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)","20150903","2015","","","821","825","Essential genes play vital roles in bacterial survival and they are potential antimicrobial targets and cornerstones of synthetic biology. Accurate recognition of bacterial essential genes by computational methods becomes necessary because of high economical and time consumption in wet experiments. In this paper, we evaluated the effectiveness of four machine learning methods that are Support Vector Machine (SVM), SVM after student's t test (ttSVM), Principal Component Regression (PCR) and Kernel Principal Component Regression (KPCR), in identifying bacterial essential genes. A total of 24 bacterial genomes were involved and 544 compositional features, generated from the primary genome sequence in each genome. For convenience of the majority of experimental scientists to compare the effectiveness of the four methods, a web server has been constructed, which is freely available at http://cefg.uestc.edu.cn/ibeg.","","Electronic:978-1-4799-1948-2; POD:978-1-4799-1949-9; USB:978-1-4799-1947-5","10.1109/ChinaSIP.2015.7230519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230519","Balance dataset;Compositional features;Identifying essential genes;Machine learning methods;Unbalance dataset","Decision support systems;Genetics;Indexes;Intelligent systems;Kernel;Microorganisms","biology computing;genetics;learning (artificial intelligence);principal component analysis;regression analysis;support vector machines","KPCR;SVM after student's t test;Web server;antimicrobial targets;bacterial essential gene identification;bacterial essential gene recognition;bacterial survival;composition features;computational methods;kernel principal component regression;machine learning algorithms;primary genome sequence;support vector machine;synthetic biology;ttSVM","","0","","16","","","12-15 July 2015","","IEEE","IEEE Conference Publications"
"A comparative study on machine learning algorithms for indoor positioning","S. Bozkurt; G. Elibol; S. Gunal; U. Yayan","Dept. of Computer Engineering, Eskisehir Osmangazi University, Eskisehir, Turkiye","2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA)","20150928","2015","","","1","8","Fingerprinting based positioning is commonly used for indoor positioning. In this method, initially a radio map is created using Received Signal Strength (RSS) values that are measured from predefined reference points. During the positioning, the best match between the observed RSS values and existing RSS values in the radio map is established as the predicted position. In the positioning literature, machine learning algorithms have widespread usage in estimating positions. One of the main problems in indoor positioning systems is to find out appropriate machine learning algorithm. In this paper, selected machine learning algorithms are compared in terms of positioning accuracy and computation time. In the experiments, UJIIndoorLoc indoor positioning database is used. Experimental results reveal that k-Nearest Neighbor (k-NN) algorithm is the most suitable one during the positioning. Additionally, ensemble algorithms such as AdaBoost and Bagging are applied to improve the decision tree classifier performance nearly same as k-NN that is resulted as the best classifier for indoor positioning.","","Electronic:978-1-4673-7751-5; POD:978-1-4673-7752-2; USB:978-1-4673-9096-5","10.1109/INISTA.2015.7276725","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7276725","AdaBoost;Bagging;Bayes Net;Localization;NaÃ¯ve Bayes;RF Map;Received Signal Strength (RSS);SMO;WEKA;classification;decision tree (J48);indoor positioning;machine learning algorithms;nearest neighbor (NN)","Accuracy;Classification algorithms;Decision trees;Floors;Machine learning algorithms;Training","RSSI;decision trees;indoor navigation;learning (artificial intelligence);pattern classification","AdaBoost ensemble algorithms;RSS values;UJIIndoorLoc indoor positioning database;bagging ensemble algorithms;decision tree classifier;fingerprinting based positioning;indoor positioning systems;k-NN algorithm;k-nearest neighbor algorithm;machine learning algorithms;position estimation;radio map;received signal strength values","","3","","35","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"HeteroSpark: A heterogeneous CPU/GPU Spark platform for machine learning algorithms","Peilong Li; Yan Luo; Ning Zhang; Yu Cao","Dept. of Electrical and Computer Engineering, University of Massachusetts Lowell, USA","2015 IEEE International Conference on Networking, Architecture and Storage (NAS)","20150914","2015","","","347","348","Analytics algorithms on big data sets require tremendous computational capabilities. Spark is a recent development that addresses big data challenges with data and computation distribution and in-memory caching. However, as a CPU only framework, Spark cannot leverage GPUs and a growing set of GPU libraries to achieve better performance and energy efficiency. We present HeteroSpark, a GPU-accelerated heterogeneous architecture integrated with Spark, which combines the massive compute power of GPUs and scalability of CPUs and system memory resources for applications that are both data and compute intensive. We make the following contributions in this work: (1) we integrate the GPU accelerator into current Spark framework to further leverage data parallelism and achieve algorithm acceleration; (2) we provide a plug-n-play design by augmenting Spark platform so that current Spark applications can choose to enable/disable GPU acceleration; (3) application acceleration is transparent to developers, therefore existing Spark applications can be easily ported to this heterogeneous platform without code modifications. The evaluation of HeteroSpark demonstrates up to 18Ã speedup on a number of machine learning applications.","","Electronic:978-1-4673-7891-8; POD:978-1-4673-7892-5; USB:978-1-4673-7890-1","10.1109/NAS.2015.7255222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7255222","","Acceleration;Big data;Computer architecture;Graphics processing units;Libraries;Machine learning algorithms;Sparks","Big Data;cache storage;graphics processing units;learning (artificial intelligence)","GPU libraries;GPU-accelerated heterogeneous architecture;HeteroSpark;Spark applications;analytics algorithms;big data sets;computation distribution;computational capabilities;data parallelism;energy efficiency;heterogeneous CPU-GPU spark platform;in-memory caching;machine learning algorithms;plug-n-play design;system memory resources","","2","","3","","","6-7 Aug. 2015","","IEEE","IEEE Conference Publications"
"Multivariate Machine Learning Methods for Fusing Multimodal Functional Neuroimaging Data","S. DÃ¤hne; F. BieÃmann; W. Samek; S. Haufe; D. Goltz; C. Gundlach; A. Villringer; S. Fazli; K. R. MÃ¼ller","Dept. of Comput. Sci., Berlin Inst. of Technol., Berlin, Germany","Proceedings of the IEEE","20150820","2015","103","9","1507","1530","Multimodal data are ubiquitous in engineering, communications, robotics, computer vision, or more generally speaking in industry and the sciences. All disciplines have developed their respective sets of analytic tools to fuse the information that is available in all measured modalities. In this paper, we provide a review of classical as well as recent machine learning methods (specifically factor models) for fusing information from functional neuroimaging techniques such as: LFP, EEG, MEG, fNIRS, and fMRI. Early and late fusion scenarios are distinguished, and appropriate factor models for the respective scenarios are presented along with example applications from selected multimodal neuroimaging studies. Further emphasis is given to the interpretability of the resulting model parameters, in particular by highlighting how factor models relate to physical models needed for source localization. The methods we discuss allow for the extraction of information from neural data, which ultimately contributes to 1) better neuroscientific understanding; 2) enhance diagnostic performance; and 3) discover neural signals of interest that correlate maximally with a given cognitive paradigm. While we clearly study the multimodal functional neuroimaging challenge, the discussed machine learning techniques have a wide applicability, i.e., in general data fusion, and may thus be informative to the general interested reader.","0018-9219;00189219","","10.1109/JPROC.2015.2425807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7182735","EEG;MEG;Machine learning;data fusion;fMRI;fNIRS;multimodal neuroimaging;review","Brain models;Data mining;Data models;Feature extraction;Multimodal sensors;Neuroimaging","biomedical MRI;electroencephalography;feature extraction;image fusion;infrared spectroscopy;learning (artificial intelligence);magnetoencephalography;medical image processing","EEG technique;LFP technique;MEG technique;analytic tools;cognitive paradigm;data fusion;diagnostic performance;electroencephalography;fMRI technique;fNIRS technique;factor models;functional near-infrared spectroscopy;information extraction;magnetic resonance imaging;multimodal functional neuroimaging data;multivariate machine learning methods;neural signals discovery;neuroscientific understanding","","11","","169","","20150810","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Road marking detection and classification using machine learning algorithms","T. Chen; Z. Chen; Q. Shi; X. Huang","Worcester Polytechnic Institute, Worcester, MA 01609, USA","2015 IEEE Intelligent Vehicles Symposium (IV)","20150827","2015","","","617","621","This paper presents a novel approach for road marking detection and classification based on machine learning algorithms. Road marking recognition is an important feature of an intelligent transportation system (ITS). Previous works are mostly developed using image processing and decisions are often made using empirical functions, which makes it difficult to be generalized. Hereby, we propose a general framework for object detection and classification, aimed at video-based intelligent transportation applications. It is a two-step approach. The detection is carried out using binarized normed gradient (BING) method. PCA network (PCANet) is employed for object classification. Both BING and PCANet are among the latest algorithms in the field of machine learning. Practically the proposed method is applied to a road marking dataset with 1,443 road images. We randomly choose 60% images for training and use the remaining 40% images for testing. Upon training, the system can detect 9 classes of road markings with an accuracy better than 96.8%. The proposed approach is readily applicable to other ITS applications.","1931-0587;19310587","Electronic:978-1-4673-7266-4; POD:978-1-4673-7267-1","10.1109/IVS.2015.7225753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225753","BING;PCANet;machine learning;road marking","Feature extraction;Machine learning algorithms;Neural networks;Object detection;Principal component analysis;Roads;Training","gradient methods;image classification;intelligent transportation systems;learning (artificial intelligence);object detection;principal component analysis","BING method;ITS;PCA network;PCANet;binarized normed gradient method;intelligent transportation system;machine learning algorithms;object classification;principal component analysis;road marking classification;road marking detection;road marking recognition","","2","","20","","","June 28 2015-July 1 2015","","IEEE","IEEE Conference Publications"
"Comparative analysis of machine learning algorithms along with classifiers for network intrusion detection","S. Choudhury; A. Bhowal","Department of Information Technology, Indian Institute of Information Technology, Allahabad, India","2015 International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM)","20150827","2015","","","89","95","Intrusion detection is one of the challenging problems encountered by the modern network security industry. A network has to be continuously monitored for detecting policy violation or suspicious traffic. So an intrusion detection system needs to be developed which can monitor network for any harmful activities and generate results to the management authority. Data mining can play a massive role in the development of a system which can detect network intrusion. Data mining is a technique through which important information can be extracted from huge data repositories. In order to spot intrusion, the traffic created in the network can be broadly categorized into following two categories- normal and anomalous. In our proposed paper, several classification techniques and machine learning algorithms have been considered to categorize the network traffic. Out of the classification techniques, we have found nine suitable classifiers like BayesNet, Logistic, IBK, J48, PART, JRip, Random Tree, Random Forest and REPTree. Out of the several machine learning algorithms, we have worked on Boosting, Bagging and Blending (Stacking) and compared their accuracies as well. The comparison of these algorithms has been performed using WEKA tool and listed below according to certain performance metrics. Simulation of these classification models has been performed using 10-fold cross validation. NSL-KDD based data set has been used for this simulation in WEKA.","","CD:978-1-4799-9853-1; Electronic:978-1-4799-9855-5; Paper:978-1-4799-9854-8","10.1109/ICSTM.2015.7225395","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225395","classification;data mining;intrusion detection;machine learning;network","Accuracy;Classification algorithms;Intrusion detection;Logistics;Machine learning algorithms;Prediction algorithms;Training","data mining;learning (artificial intelligence);pattern classification;security of data","BayesNet classifiers;IBK classifiers;J48 classifiers;JRip classifiers;NSL-KDD based data set;PART classifiers;REPTree classifiers;WEKA tool;classification techniques;data mining;data repository;logistic classifiers;machine learning algorithms;management authority;network intrusion detection;network security industry;network traffic;policy violation detection;random forest classifiers;random tree classifiers","","2","","14","","","6-8 May 2015","","IEEE","IEEE Conference Publications"
"A survey and evaluation of supervised machine learning techniques for spam e-mail filtering","T. Vyas; P. Prajapati; S. Gadhwal","Institute of Technology, Nirma University. Ahmedabad, India","2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)","20150827","2015","","","1","7","Emails are used in most of the fields of education and business. They can be classified into ham and spam and with their increasing use, the ratio of spam is increasing day by day. There are several machine learning techniques, which provides spam mail filtering methods, such as Clustering, J48, NaiÌve Bayes etc. This paper considers different classification techniques using WEKA to filter spam mails. Result shows that NaiÌve Bayes technique provides good accuracy (near to highest) and take least time among other techniques. Also a comparative study of each technique in terms of accuracy and time taken is provided.","","Electronic:978-1-4799-6085-9; POD:978-1-4799-6086-6","10.1109/ICECCT.2015.7226077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226077","blacklists;spam mail filtering;true negative rate;true positive rate","Accuracy;Filtering;Unsolicited electronic mail","information filtering;learning (artificial intelligence);security of data;unsolicited e-mail","NaiÌve Bayes technique;WEKA;spam e-mail filtering method;supervised machine learning techniques","","1","","11","","","5-7 March 2015","","IEEE","IEEE Conference Publications"
"Human activity detection based on multiple smart phone sensors and machine learning algorithms","X. Yin; W. Shen; J. Samarabandu; X. Wang","Dept, of Electrical & Computer Engineering, University of Western Ontario, London, Canada","2015 IEEE 19th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20150903","2015","","","582","587","This paper presents our recent work on human activity detection based on smart phone embedded sensors and learning algorithms. The proposed human activity detection system recognizes human activities including walking, running, and sitting. While walking and running can be recorded as daily fitness activities, falling will also be detected as anomalous situations and alerting messages can be sent as needed. Embedded sensors including a tri-axial accelerometer, tri-axial linear accelerometer, gyroscope sensor, and orientation sensors are used for motion data collection. A two-stage data analysis approach is used for prediction model generation: short period statistical analysis (max, min, mean, and standard deviation) and long period data analysis using machine learning. The system is implemented in an Android smart phone platform.","","CD-ROM:978-1-4799-2001-3; Electronic:978-1-4799-2002-0; POD:978-1-4799-8541-8","10.1109/CSCWD.2015.7231023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7231023","activity detection;machine learning;sensors;smartphones","Accuracy;Legged locomotion;Multilayer perceptrons;Support vector machines;Training","data analysis;image recognition;intelligent sensors;learning (artificial intelligence);object detection;smart phones;statistical analysis","Android smart phone platform;daily fitness activity;gyroscope sensor;human activity detection system;human activity recognition;long period data analysis;machine learning algorithms;motion data collection;multiple smart phone embedded sensors;orientation sensors;prediction model generation;short period statistical analysis;tri-axial accelerometer;tri-axial linear accelerometer;two-stage data analysis approach","","2","","14","","","6-8 May 2015","","IEEE","IEEE Conference Publications"
"A generalized pruning algorithm for extreme learning machine","K. Sun; Y. Yu; Z. Huang","Faculty of Mathematics and Computer Science, Fuzhou University, Fujian, 350116, China","2015 IEEE International Conference on Information and Automation","20151001","2015","","","1431","1436","This paper presents a generalized pruning extreme learning machine (GP-ELM) algorithm which can generate a compact single-hidden-layer neural network (SLNN) by automatically pruning the number of hidden nodes iteratively while keep high accuracy. The proposed GP-ELM algorithm initializes a SLNN by using extreme learning algorithm (ELM) algorithm given superfluous number of hidden nodes. The following of GP-ELM algorithm consists of two iterative processes. First, the significance of each hidden nodes is estimated and the insignificant nodes are removed. Secondly, the existing hidden nodes are updated by using ELM algorithm. These two processes continue until the stop condition is satisfied such that a reasonably compact network is achieved. Compared against other state-of-the-art algorithms, GP-ELM algorithm has mainly two improvements. First, a supervised training process is integrated into the pruning process such that significance of each hidden node can be estimated more precisely in the next iteration. Secondly, the pruning threshold is set based on the input data dimension such that the threshold can accommodate any data type. Experimental results have shown that the GP-ELM algorithm can automatically achieve a reasonable compact network structure while keep comparable or much higher accuracy in classification and regression.","","Electronic:978-1-4673-9104-7; POD:978-1-4673-9105-4; USB:978-1-4673-9103-0","10.1109/ICInfA.2015.7279511","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279511","Generalized pruning;extreme learning machine;single-hidden-layer neural network","Accuracy;Cost function;Diabetes;Machine learning algorithms;Neural networks;Support vector machines;Training","decision trees;estimation theory;iterative methods;learning (artificial intelligence);neural nets","GP-ELM algorithm;SLNN;generalized pruning extreme learning machine;hidden node estimation;iterative process;single-hidden-layer neural network;supervised training process","","","","21","","","8-10 Aug. 2015","","IEEE","IEEE Conference Publications"
"A heuristic machine learning-based algorithm for power and thermal management of heterogeneous MPSoCs","A. Iranfar; S. N. Shahsavani; M. Kamal; A. Afzali-Kusha","School of Electrical and Computer Engineering, University of Tehran, Iran","2015 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)","20150924","2015","","","291","296","In this work, we propose a power and thermal management algorithm based on machine learning to control the thermal stresses and power consumption of the heterogeneous MPSoCs. The objectives of the proposed algorithm are increasing the performance and decreasing the spatial and temporal temperature gradients along with the thermal cycling under the power and temperature constraints. Our proposed power and thermal management method is based on a heuristic approach to speed up the convergence of the machine learning algorithm which makes it applicable for general purpose processors. Adopting Q-Learning as the machine learning algorithm, the heuristic approach aids to limit the learning space by suggesting the most appropriate actions to the agent in each decision epoch. The heuristic algorithm employs the current and previous states of the machine learning, as well as the amount of the temperature stress and power consumption of each core to determine the appropriate action for each core, independently. The proposed algorithm is evaluated on 4-core, 8-core and 16-core homogeneous and heterogeneous MPSoCs for some benchmarks in the Splash2 benchmark package. The results reveal a faster convergence of machine learning and more thermal stresses reduction.","","CD-ROM:978-1-4673-8008-9; Electronic:978-1-4673-8009-6; POD:978-1-4673-8010-2","10.1109/ISLPED.2015.7273529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273529","Power and thermal management;machine learning;thermal stress","","learning (artificial intelligence);low-power electronics;system-on-chip;thermal stresses","Q-learning;Splash2 benchmark package;decision epoch;general purpose processors;heterogeneous MPSoC;heuristic machine learning;homogeneous MPSoC;multiprocessor system-on-chips;power consumption;power management;temperature stress;thermal cycling;thermal management;thermal stress control","","","","19","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Kernel centric machine learning classifiers for anomaly detection with real bank datasets","G. R. Jidiga; S. Porika","JNTU Hyderabad, Government of Telangana, India","2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)","20150813","2015","","","1","5","The machine learning is more effective today in anomaly detection to improve the classification accuracy. The use of powerful kernel based learning is very practical in current trends may expose accurate results in real time database applications. In this context, we need to use the new and adorned machine learning classifiers. In this paper we have given very successful and emerged kernels SVM (Support Vector Machines) which uses the marginal hyperplane uniquely determine the classes by mapping of data and KPCA (Kernel Principal Component Analysis) is an extension to PCA. Both used to classify the data and detecting anomalies by transforming input space into high dimensional feature space. The SVM kernel is use non-linear mapping function and inner product replace with kernel ingredients. KPCA extract principal components from set of corresponding eigenvectors and used as threshold with reference to kernel width. The SVM and KPCA are implemented by taking one real-time bank dataset and other from UCI machine learning repository sets. Finally performance compared with non-kernel techniques (CART, k-NN, PLSDA, PCA) applied on same datasets using training and test set combinations.","","Electronic:978-1-4799-6818-3; POD:978-1-4799-6819-0","10.1109/ICIIECS.2015.7193182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7193182","Anomaly detection;KPCA;Kernel;Machine learning;SVM","Classification algorithms;Conferences;Feature extraction;Kernel;Principal component analysis;Support vector machines;Training","bank data processing;learning (artificial intelligence);pattern classification;principal component analysis;security of data;support vector machines","KPCA;SVM;anomaly detection;bank dataset;kernel centric machine learning classifier;kernel principal component analysis;support vector machine","","0","","24","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"High-Performance Extreme Learning Machines: A Complete Toolbox for Big Data Applications","A. Akusok; K. M. BjÃ¶rk; Y. Miche; A. Lendasse","Department of Mechanical and Industrial Engineering and the Iowa Informatics Initiative, The University of Iowa, Iowa, IA, USA","IEEE Access","20150721","2015","3","","1011","1025","This paper presents a complete approach to a successful utilization of a high-performance extreme learning machines (ELMs) Toolbox for Big Data. It summarizes recent advantages in algorithmic performance; gives a fresh view on the ELM solution in relation to the traditional linear algebraic performance; and reaps the latest software and hardware performance achievements. The results are applicable to a wide range of machine learning problems and thus provide a solid ground for tackling numerous Big Data challenges. The included toolbox is targeted at enabling the full potential of ELMs to the widest range of users.","2169-3536;21693536","","10.1109/ACCESS.2015.2450498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140733","","Learning systems;Machine learning;Performance evaluation","","","","18","","43","","20150630","2015","","IEEE","IEEE Journals & Magazines"
"An empirical study on email classification using supervised machine learning in real environments","W. Li; W. Meng","Department of Computer Science, City University of Hong Kong, Hong Kong","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","7438","7443","Spam emails are considered as one of the biggest challenges for the Internet. Thus email classification, which aims to correctly classify legitimate and spam emails, becomes an important topic for both industry and academia. To achieve this goal, machine learning techniques, especially supervised machine learning algorithms, have been extensively applied to this field. In literature, several studies reveal that supervised machine learning (SML) suffers from some limitations such as performance fluctuation, hence many works start focusing on designing more complex algorithms. However, we identify that most existing research efforts are based on datasets, while more research should be conducted to investigate the performance of SML in real environments. In this paper, we thus perform an empirical study with three different environments and over 1,000 users regarding this issue. In the study, we find that SML classifiers like decision tree and SVMs are acceptable by users in real email classification. In addition, we discuss promising directions and provide new insights in this area.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7249515","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7249515","Email Classification;Empirical Study;Spam Detection;Supervised Machine Learning","Companies;Decision trees;Electronic mail;Feature extraction;Machine learning algorithms;Security;Support vector machines","Internet;decision trees;learning (artificial intelligence);pattern classification;support vector machines;unsolicited e-mail","Internet;SML;SVM;decision tree;email classification;spam email;supervised machine learning","","0","","26","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Unified Programming Model and Software Framework for Big Data Machine Learning and Data Analytics","R. Gu; Y. Tang; Q. Dong; Z. Wang; Z. Liu; S. Wang; C. Yuan; Y. Huang","Collaborative Innovation Center of Novel Software Technol. & Industrialization, Nanjing Univ., Nanjing, China","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","3","","562","567","In a new era of Big Data, the rapid growth of the applications, such as social media and web-search, requires efficient and scalable machine learning and statistical analytical algorithms. However, there lacks easy-to-use and efficient software frameworks or systems that can support fast development of such big data analytical algorithms. To solve these problems, we propose Octopus, an easy-to-use and efficient analytical system for big data. Octopus allows data analysts conduct complex data analytics for big data with traditional programming languages and methods in an easy and efficient way. To achieve the goal of ease-to-use, we propose a matrix-based unified programming model, which is the core of many data-intensive statistical applications such as numerical analysis and data mining. Further, in order to improve the performance, the Octopus software framework adopts various distributed computing platforms, including Hadoop MapReduce, Spark and MPI. On these computing platforms, we design several parallel matrix computation algorithms, which are suitable for various scenarios. Finally, the features of Octopus are encapsulated into a library with matrix-based APIs and exposed to users as an R package. R is a widely-used statistical programming language and supports diversified data analysis tasks through extension packages. Experimental results show that Octopus achieves efficient performance and near linear scalability.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273424","big data analysis;ease-to-use;matrix computation;parallel algorithm","Big data;Distributed databases;Libraries;Machine learning algorithms;Programming;Scalability;Sparks","Big Data;application program interfaces;data analysis;learning (artificial intelligence);matrix algebra;message passing;parallel processing;statistical analysis","Big Data machine learning;Hadoop MapReduce;MPI;Octopus software framework;R package;Spark;Web-search;data analytics;data mining;data-intensive statistical applications;distributed computing platforms;matrix-based APIs;matrix-based unified programming model;numerical analysis;parallel matrix computation algorithms;social media;statistical analytical algorithms;statistical programming language","","","","11","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Segmenting music library for generation of playlist using machine learning","T. S. Bohra; V. Kumar; S. Ganesan","Bipin Tripathi Kumaon Institute of Technology, Dwarahat, India","2015 IEEE International Conference on Electro/Information Technology (EIT)","20151008","2015","","","421","425","People like listening music primarily due to the emotion it evokes. Any activity or work that a person performs also generates emotions. Considering the above two statements it can assume that people tend to associate music with certain activity if it induces emotions that are in sync with it. In today's world of infinite storage, the number of songs that a user has is ever increasing. With the increased number of songs, listening music in a way one likes has become difficult. Playlist provide us a way to better organize our music library. These can be created manually or by using various smart playlist creators that generates them by analyzing various components of music files used by the user. In the current scenario the playlist created has a specific number of tracks which are played over and over again, with the only variation occurring being in the order in which songs are played. Also the songs that are not part of any playlist are left redundant, occupying useful memory. Our work focuses on the reducing the number of redundant songs in the music library while creating playlist. We have worked on grouping songs with similar emotional effect together in a segment, and then creating a dynamic playlist every time the user plays music. The results show that as the system is provided with required input, we get a robust playlist for each segment, which consist of diverse mix of songs having similar emotional perception. The playlist created is a non monotonous collection of music which is emotionally supportive to the listener towards the work he is doing.","2154-0357;21540357","Electronic:978-1-4799-8802-0; POD:978-1-4799-8803-7; USB:978-1-4799-8801-3","10.1109/EIT.2015.7293429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293429","Machine Learning;activity;emotion;music;music library;playlist;segmentation","Accuracy;Libraries;Multimedia communication;Music;Robustness;Standards;Synchronization","learning (artificial intelligence);music","emotional perception;machine learning;music file;music listening;playlist generation;segmenting music library;smart playlist creator","","","","8","","","21-23 May 2015","","IEEE","IEEE Conference Publications"
"Mechanical Fault Diagnosis Method Based on Machine Learning","Z. Nan","Handan Vocational & Tech. Coll., Handan, China","2015 Seventh International Conference on Measuring Technology and Mechatronics Automation","20150914","2015","","","626","629","This paper proposes a novel mechanical fault diagnosis method using a hybrid QPSO and SVM model. Mechanical fault diagnosis refers to the recognition and diagnosis of fault mechanism, fault causes, and the fault positions. Particularly, five types of mechanical faults are considered in this paper, which are 1) quality not balancing, 2) Rotor thermal bending, 3) Shaft crack, 4) Bearing fault and 5) Permanent bending. The main innovations of this paper lie in that we introduce the SVM classifier to solve the mechanical fault diagnosis problem, and then Quantum behaved particle swarm optimization is utilized to optimized the parameters of SVM. Experimental results demonstrate that, using the proposed algorithm, the accuracy of mechanical fault diagnosis is greatly enhanced than SVM and PSO-SVM model.","2157-1473;21571473","CD-ROM:978-1-4673-7142-1; Electronic:978-1-4673-7143-8; POD:978-1-4673-7144-5","10.1109/ICMTMA.2015.157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7263651","Machine Learning;Mechanical Fault Diagnosis;Quantum behaved particle swarm optimization;Support vector machine","Accuracy;Fault diagnosis;Particle swarm optimization;Quantum mechanics;Rotors;Shafts;Support vector machines","bending;cracks;fault diagnosis;learning (artificial intelligence);machine bearings;mechanical engineering computing;particle swarm optimisation;pattern classification;quantum computing;rotors (mechanical);shafts;support vector machines","SVM classifier;SVM model;bearing fault;fault causes;fault mechanism recognition;fault positions;hybrid QPSO;machine learning;mechanical fault diagnosis method;permanent bending;quality not balancing;quantum behaved particle swarm optimization;rotor thermal bending;shaft crack","","","","13","","","13-14 June 2015","","IEEE","IEEE Conference Publications"
"High-Speed Security Analytics Powered by In-Memory Machine Learning Engine","A. Sapegin; M. Gawron; D. Jaeger; F. Cheng; C. Meinel","Hasso Plattner Inst. (HPI), Univ. of Potsdam, Potsdam, Germany","2015 14th International Symposium on Parallel and Distributed Computing","20150723","2015","","","74","81","Modern Security Information and Event Management systems should be capable to store and process high amount of events or log messages in different formats and from different sources. This requirement often prevents such systems from usage of computational-heavy algorithms for security analysis. To deal with this issue, we built our system based on an in-memory data base with an integrated machine learning library, namely SAP HANA. Three approaches, i.e. (1) deep normalisation of log messages (2) storing data in the main memory and (3) running data analysis directly in the database, allow us to increase processing speed in such a way, that machine learning analysis of security events becomes possible nearly in real-time. To prove our concepts, we measured the processing speed for the developed system on the data generated using Active Directory tested and showed the efficiency of our approach for high-speed analysis of security events.","2379-5352;23795352","Electronic:978-1-4673-7148-3; POD:978-1-4673-7149-0","10.1109/ISPDC.2015.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165133","SAP HANA;in-memory;intrusion detection;machine learning;security","Algorithm design and analysis;Computers;Databases;Libraries;Machine learning algorithms;Prediction algorithms;Security","data analysis;learning (artificial intelligence);security of data","SAP HANA;active directory;computational-heavy algorithms;data analysis;deep log message normalisation;high-speed security analytics;high-speed security event analysis;in-memory database;in-memory machine learning engine;integrated machine learning library;machine learning analysis;security information and event management systems","","1","","27","","","June 29 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Analysis of Malware behavior: Type classification using machine learning","R. S. Pirscoveanu; S. S. Hansen; T. M. T. Larsen; M. Stevanovic; J. M. Pedersen; A. Czech","Aalborg University, Denmark","2015 International Conference on Cyber Situational Awareness, Data Analytics and Assessment (CyberSA)","20150727","2015","","","1","7","Malicious software has become a major threat to modern society, not only due to the increased complexity of the malware itself but also due to the exponential increase of new malware each day. This study tackles the problem of analyzing and classifying a high amount of malware in a scalable and automatized manner. We have developed a distributed malware testing environment by extending Cuckoo Sandbox that was used to test an extensive number of malware samples and trace their behavioral data. The extracted data was used for the development of a novel type classification approach based on supervised machine learning. The proposed classification approach employs a novel combination of features that achieves a high classification rate with a weighted average AUC value of 0.98 using Random Forests classifier. The approach has been extensively tested on a total of 42,000 malware samples. Based on the above results it is believed that the developed system can be used to pre-filter novel from known malware in a future malware analysis system.","","Electronic:978-0-9932-3380-7; POD:978-1-4673-6797-4","10.1109/CyberSA.2015.7166115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7166115","API call;Cuckoo sandbox;Malware;Random Forests;dynamic analysis;feature selection;scalability;supervised machine learning;type-classification","Data mining;Feature extraction;Testing;Training;Trojan horses;Vegetation","invasive software;learning (artificial intelligence);pattern classification","Cuckoo Sandbox;behavioral data;distributed malware testing environment;machine learning;malicious software;malware analysis system;malware behavior analysis;malware samples;random forest classifier;supervised machine learning;type classification approach;weighted average AUC value","","1","","16","","","8-9 June 2015","","IEEE","IEEE Conference Publications"
"Overcoming Computational Errors in Sensing Platforms Through Embedded Machine-Learning Kernels","Z. Wang; K. H. Lee; N. Verma","Department of Electrical Engineering, Princeton University, Princeton, NJ, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20150722","2015","23","8","1459","1470","We present an approach for overcoming computational errors at run time that originate from static hardware faults in digital processors. The approach is based on embedded machine-learning stages that learn and model the statistics of the computational outputs in the presence of errors, resulting in an error-aware model for embedded analysis. We demonstrate, in hardware, two systems for analyzing sensor data: 1) an EEG-based seizure detector and 2) an ECG-based cardiac arrhythmia detector. The systems use a small kernel of fault-free hardware (constituting <;7.0% and <;31% of the total areas respectively) to construct and apply the error-aware model. The systems construct their own error-aware models with minimal overhead through the use of an embedded active-learning framework. Via an field-programmable gate array implementation for hardware experiments, stuck-at faults are injected at controllable rates within synthesized gate-level netlists to permit characterization. The seizure detector demonstrates restored performance despite faults on 0.018% of the circuit nodes [causing bit error rates (BERs) up to 45%], and the arrhythmia detector demonstrates restored performance despite faults on 2.7% of the circuit nodes (causing BERs up to 50%).","1063-8210;10638210","","10.1109/TVLSI.2014.2342153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6874569","Embedded sensing;fault tolerance;hardware resiliency;machine learning;run-time error correction","Brain modeling;Circuit faults;Data models;Hardware;Kernel;Support vector machines;Training","electrocardiography;electroencephalography;embedded systems;fault diagnosis;field programmable gate arrays;learning (artificial intelligence);medical signal processing","ECG-based cardiac arrhythmia detector;EEG-based seizure detector;arrhythmia detector;computational errors;computational outputs;digital processors;embedded analysis;embedded machine-learning kernels;error-aware model;fault-free hardware;field-programmable gate array implementation;hardware experiments;sensing platforms;sensor data;static hardware faults;stuck-at faults;synthesized gate-level netlists","","4","","46","","20140808","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Rotation effects of objective functions in parallel distributed multiobjective fuzzy genetics-based machine learning","Y. Takahashi; Y. Nojima; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Osaka Prefecture University, Sakai, Osaka, Japan","2015 10th Asian Control Conference (ASCC)","20150910","2015","","","1","6","Fuzzy genetics-based machine learning (FGBML) is one of data mining techniques using evolutionary computation. It can obtain fuzzy rule-based classifiers that are accurate and linguistically interpretable for human users. However, there are two major problems. One is that it is impossible to design the best classifier with respect to both accuracy and interpretability due to their tradeoff. To solve this problem, we proposed multiobjective FGBML (MoFGBML) where an evolutionary multiobjective optimization algorithm is used to obtain a number of classifiers with different tradeoffs between accuracy and complexity. The other is the heavy computational load of FGBML for large data sets. In the previous study, we applied parallel distributed implementation to our MoFGBML to overcome this problem. We examined the effects of the parallel distributed implementation on the search ability. Although the computational time became much shorter, the number of the obtained non-dominated classifiers became small. As a result, accurate classifiers were not obtained for some data sets. In this paper, we propose a simple idea to bias the search direction of our MoFGBML. We rotate one or two objective functions. This rotation changes the dominance relation in multiobjective optimization. Through computational experiments, we examine the effects of the rotated objective functions on the search ability of our MoFGBML for large data sets.","","Electronic:978-1-4799-7862-5; POD:978-1-4799-7863-2","10.1109/ASCC.2015.7244890","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244890","Fuzzy genetics-based machine learning;multiobjective optimization;parallel distributed implementation","Accuracy;Data models;Error analysis;Linear programming;Sociology;Statistics;Training data","data mining;fuzzy set theory;genetic algorithms;learning (artificial intelligence);search problems","MoFGBML;computational load;computational time;data mining techniques;distributed multiobjective fuzzy genetics-based machine learning;evolutionary computation;fuzzy rule-based classifiers;multiobjective FGBML;nondominated classifiers;objective functions;rotation effects;search ability","","1","","20","","","May 31 2015-June 3 2015","","IEEE","IEEE Conference Publications"
"Video saliency prediction through machine learning with semantic information","X. Fu; L. Su; L. Qin","University of Chinese Academy of Sciences, Beijing, China","2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)","20150903","2015","","","539","543","Saliency prediction is valuable in many video applications, such as intelligent retrieval, advertisement design and delivering, video coding and video summarization generating. Although image saliency is well explored, less works have been done on videos. Compared to images, the semantic orientation is more obvious for video saliency. In this paper, we propose a method to predict video saliency by introducing semantic information. Different from existing approaches, we simultaneously consider the bottom-up and top-down factors in a machine learning framework and utilize a semantic object learning model to compute the semantic related saliency map. The proposed method is tested on two datasets. The experiment results show that the proposed method keeps higher consistent with human's gaze tracks data on various video contents. Furthermore, the computation efficiency is also improved as we don't need to process every pixel of each frame during prediction features extraction.","","Electronic:978-1-4799-1948-2; POD:978-1-4799-1949-9; USB:978-1-4799-1947-5","10.1109/ChinaSIP.2015.7230461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230461","bottom-up;machine learning;semantic orientation information;top-down;video saliency","Decision support systems;Feature extraction;Indexes;Semantics;Training;Training data;Videos","learning (artificial intelligence);semantic networks;video coding","advertisement design;bottom-up factor;feature extraction;image saliency;intelligent retrieval;machine learning;saliency map;semantic information;semantic object learning model;semantic orientation;top-down factor;video coding;video saliency prediction;video summarization","","0","","23","","","12-15 July 2015","","IEEE","IEEE Conference Publications"
"Modelling time-varying delays in networked automation systems with heterogeneous networks using machine learning techniques","S. Srinivasan; F. Buonopane; G. Saravanakumar; B. Subathra; S. Ramaswamy","Department of Engineering, University of Sannio, Benevento, Italy","2015 IEEE International Conference on Automation Science and Engineering (CASE)","20151008","2015","","","362","368","Time-varying delays affect the performance and reliability of networked automation systems (NAS). Recent trend to use wired and wireless networks within NAS induces network delays that vary depending on many factors such as loading, sharing, length of the channel, protocol, and so on. As these factors are inherently time-varying, developing analytical models capturing the effect of all these parameters is complex. This investigation presents a methodology that combines experiments with machine learning techniques to model time-varying delays in networked automation systems integrated with heterogeneous networks. Experiments are conducted on NAS by varying the factors that influence delays and time stamping obtained using Wireshark are used to compute the delay. The data collected on the factors influencing the delays and the corresponding delay values are used to model the delays. In data-mining techniques, the accuracy of the estimates varies with the number of computing elements in the hidden layer and selecting them using trial-and-error approach is cumbersome. The minimum resource allocation network (MRAN) over comes the short-coming as it decides the number of computing elements (neurons) in the hidden layer using error thresholds and pruning strategy. The data collected from the experiment is the input training set to the MRAN. Once trained, the MRAN model gives a functional representation relating the factors affecting delays and the estimated delay for a given network condition. During testing, MRAN estimates are validated using error measurements. Results show that the MRAN delay model can capture delays with good accuracy and can be used a tool to assist design decisions on engineering automation systems with heterogeneous networks. The proposed model gives a framework to model time-varying delays as a function of factors influencing them and can be modified to include any number of parameters. This is a significant benefit against existing models in lite- ature that capture the delays only for particular conditions.","2161-8070;21618070","Electronic:978-1-4673-8183-3; POD:978-1-4673-8184-0","10.1109/CoASE.2015.7294105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294105","","Automation;Data models;Delays;Hidden Markov models;Load modeling;Loading;Neurons","control engineering computing;data mining;delays;learning (artificial intelligence);reliability;resource allocation;time-varying systems","MRAN;NAS;Wireshark;data mining techniques;error thresholds;heterogeneous networks;machine learning techniques;minimum resource allocation network;networked automation systems;pruning strategy;reliability;time stamping;time-varying delays;wired networks;wireless networks","","1","","27","","","24-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"A 128 channel 290 GMACs/W machine learning based co-processor for intention decoding in brain machine interfaces","Y. Chen; E. Yao; A. Basu","School of Electrical and Electronic Engineering Nanyang Technological University, Singapore 639798","2015 IEEE International Symposium on Circuits and Systems (ISCAS)","20150730","2015","","","3004","3007","A machine learning co-processor in 0.35Î¼m CMOS for motor intention decoding in the brain-machine interfaces is presented in this paper. Using Extreme Learning Machine algorithm, time delayed sample based feature dimension enhancement, low-power analog processing and massive parallelism, it achieves an energy efficiency of 290 GMACs/W at a classification rate of 50 Hz. A portable external unit based on the proposed co-processor is verified with neural data recorded in monkey finger movements experiment, achieving a decoding accuracy of 99.3%. With time-delayed feature dimension enhancement, the classification accuracy can be increased by 5% with limited number of input channels.","0271-4302;02714302","Electronic:978-1-4799-8391-9; POD:978-1-4799-8392-6","10.1109/ISCAS.2015.7169319","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169319","","Accuracy;Brain-computer interfaces;Decoding;Mirrors;Neurons;Radiation detectors;Wireless communication","CMOS integrated circuits;brain-computer interfaces;coprocessors;decoding;delay circuits;encoding;learning (artificial intelligence)","CMOS;brain machine interfaces;low-power analog processing;machine learning based co-processor;massive parallelism;motor intention decoding;size 0.35 mum;time delayed sample based feature dimension enhancement","","6","","11","","","24-27 May 2015","","IEEE","IEEE Conference Publications"
"Bank note authentication using decision tree rules and machine learning techniques","C. Kumar; A. K. Dudyala","Department of Computer Science & Engineering, National Institute Of Technology, Patna, India","2015 International Conference on Advances in Computer Engineering and Applications","20150723","2015","","","310","314","Banknotes are currencies used by any nation to carry-out financial activities and are every countries asset which every nation wants it (bank-note) to be genuine. Lot of miscreants induces fake notes into the market which resemble exactly the original note. Hence, there is a need for an efficient authentication system which predicts accurately whether the given note is genuine or not. Exhaustive experiments have been conducted using different machine learning techniques and found that Decision tree and MLP techniques are effective for banknote authentication which efficiently classifies a given banknote data. The rules given by Decision Tree are also tested and found that they are accurate enough to be used for prediction.","","DVD:978-1-4673-6910-7; Electronic:978-1-4673-6911-4; POD:978-1-4673-6912-1","10.1109/ICACEA.2015.7164721","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164721","Banknote Authentication;Decision Tree;Decision tree rules;Multilayer Perceptron;NaÃ¯ve Base;Probabilistic Neural Network;Radial Basis Function","Accuracy;Authentication;Decision trees;Neural networks;Sensitivity;Support vector machines","bank data processing;decision trees;learning (artificial intelligence);security of data","MLP technique;bank note authentication system;currencies;decision tree rule;financial activities;machine learning technique","","0","","18","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Twitter sentiment classification using machine learning techniques for stock markets","M. Qasem; R. Thulasiram; P. Thulasiram","Department of Computer Science, University of Manitoba, Winnipeg, Canada","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","834","840","Sentiment classification of Twitter data has been successfully applied in finding predictions in a variety of domains. However, using sentiment classification to predict stock market variables is still challenging and ongoing research. The main objective of this study is to compare the overall accuracy of two machine learning techniques (logistic regression and neural network) with respect to providing a positive, negative and neutral sentiment for stock-related tweets. Both classifiers are compared using Bigram term frequency (TF) and Unigram term frequency - inverse document term frequency (TF-IDF) weighting schemes. Classifiers are trained using a dataset that contains 42,000 automatically annotated tweets. The training dataset forms positive, negative and neutral tweets covering four technology-related stocks (Twitter, Google, Facebook, and Tesla) collected using Twitter Search API. Classifiers give the same results in terms of overall accuracy (58%). However, empirical experiments show that using Unigram TF-IDF outperforms TF.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275714","Inverse Document Term Frequency;Logistic Regression;Neural Networks;Predictive Modeling;Sentiment;Stock Market;Term Frequency;Twitter","Accuracy;Cloud computing;Computational modeling;Logistics;Sentiment analysis;Support vector machines;Twitter","application program interfaces;learning (artificial intelligence);logistics;neural nets;social aspects of automation;social networking (online);stock markets","Facebook;Google;Tesla;Twitter data;Twitter search API;Twitter sentiment classification;Unigram TF-IDF;bigram term frequency;inverse document term frequency weighting scheme;logistic regression;machine learning techniques;neural network;stock market variable prediction;stock markets;stock-related tweets;technology-related stocks;training dataset;unigram term frequency weighting scheme","","","","24","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Machine Learning Based Hybrid Behavior Models for Android Malware Analysis","H. Y. Chuang; S. D. Wang","Dept. of Electr. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2015 IEEE International Conference on Software Quality, Reliability and Security","20150924","2015","","","201","206","Malware analysis on the Android platform has been an important issue as the platform became prevalent. The paper proposes a malware detection approach based on static analysis and machine learning techniques. By conducting SVM training on two different feature sets, malicious-preferred features and normal-preferred features, we built a hybrid-model classifier to improve the detection accuracy. With the consideration of normal behavior features, the ability of detecting unknown malwares can be improved. The experiments show that the accuracy is as high as 96.69% in predicting unknown applications. Further, the proposed approach can be applied to make confident decisions on labeling unknown applications. The experiment results show that the proposed hybrid model classifier can label 79.4% applications without false positive and false negative occurred in the labeling process.","","Electronic:978-1-4673-7989-2; POD:978-1-4673-7990-8","10.1109/QRS.2015.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272933","Android;classification;machine learning;malware detection;static analysis","Accuracy;Androids;Feature extraction;Humanoid robots;Malware;Smart phones;Support vector machines","Android (operating system);invasive software;learning (artificial intelligence);pattern classification;program diagnostics;support vector machines","Android malware analysis;SVM training;hybrid-model classifier;machine learning based hybrid behavior models;malware detection approach;static analysis","","1","","43","","","3-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Wavelet transform processing for cellular traffic prediction in machine learning networks","Y. Zang; F. Ni; Z. Feng; S. Cui; Z. Ding","School of Information Science and Technology, ShanghaiTech University, Shanghai, China","2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)","20150903","2015","","","458","462","The ability for cellular operators to closely predict the network traffic volume at various locations can be very important for their resource management and dynamic network control including offloading. This work investigate the analysis of the spatial-temporal information of cellular traffic flow and the prediction of cell-station traffic volumes. Based on the integration of K-means clustering, Elman Neural Network (Elman-NN), and wavelet decomposition methods, we characterize the performance comparison of traffic volume prediction. We tested our wavelet decomposition based machine learning approach using the real traffic data recorded at a district in a big city and demonstrated the gain over traditional approaches.","","Electronic:978-1-4799-1948-2; POD:978-1-4799-1949-9; USB:978-1-4799-1947-5","10.1109/ChinaSIP.2015.7230444","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230444","Elman neural network;traffic flow prediction;wavelet decomposition","Base stations;Correlation;Neural networks;Predictive models;Time series analysis;Wavelet transforms","cellular radio;learning (artificial intelligence);neural nets;pattern clustering;telecommunication computing;telecommunication network management;wavelet transforms","Elman neural network;Elman-NN;K-means clustering;cell-station traffic volume prediction;cellular operators;cellular traffic prediction;dynamic network control;machine learning networks;network traffic volume prediction;resource management;wavelet decomposition methods;wavelet transform processing","","3","","22","","","12-15 July 2015","","IEEE","IEEE Conference Publications"
"Classification of ECG signals using machine learning techniques: A survey","S. H. Jambukia; V. K. Dabhi; H. B. Prajapati","Department of Information Technology, Dharmsinh Desai University, Nadiad, India","2015 International Conference on Advances in Computer Engineering and Applications","20150723","2015","","","714","721","Classification of electrocardiogram (ECG) signals plays an important role in diagnoses of heart diseases. An accurate ECG classification is a challenging problem. This paper presents a survey of ECG classification into arrhythmia types. Early and accurate detection of arrhythmia types is important in detecting heart diseases and choosing appropriate treatment for a patient. Different classifiers are available for ECG classification. Amongst all classifiers, artificial neural networks (ANNs) have become very popular and most widely used for ECG classification. This paper discusses the issues involved in ECG classification and presents a detailed survey of preprocessing techniques, ECG databases, feature extraction techniques, ANN based classifiers, and performance measures to address the mentioned issues. Furthermore, for each surveyed paper, our paper also presents detailed analysis of input beat selection and output of the classifiers.","","DVD:978-1-4673-6910-7; Electronic:978-1-4673-6911-4; POD:978-1-4673-6912-1","10.1109/ICACEA.2015.7164783","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164783","ECG classification;feature extraction;mit-bih database;neural network;pan-tompkins algorithm;preprocessing;survey","Accuracy;Classification algorithms;Discrete wavelet transforms;Electrocardiography;Feature extraction;Heart;Training","diseases;electrocardiography;feature extraction;learning (artificial intelligence);medical signal detection;medical signal processing;neural nets;signal classification","ANN based classifiers;ECG databases;ECG signal classification;arrhythmia type detection;artificial neural networks;electrocardiogram;feature extraction techniques;heart disease detection;heart disease diagnosis;machine learning techniques;patient treatment;performance measures","","2","","41","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Analysis of Machine Learning Techniques to Classify News for Information Management in Coffee Market","P. Oliveira Lima Junior; L. Gonzada de Castro Junior; A. Luiz Zambalde","Centro Fed. de Educ. Tecnol. de Minas Gerais (CEFET-MG), Nepomuceno, Brazil","IEEE Latin America Transactions","20150922","2015","13","7","2285","2291","This paper presents an empirical study of machine learn techniques to text categorization. Specifically aim to classify news about coffee market according with categories from coffee supply chain. The objective is to measure the performance of three types of algorithms: NaiÌve Bayes based, Tree bases and Support Vector Machine (SVM). A database with news collected from web and labeled by human expert analysts is used in a learning phase. Then automatic classify news extracted from web following the same steps and terms as human according to their relevance for each learned category. The test in a real database shows a better performance by NaiÌve Bayes based Algorithms for this specific case.","1548-0992;15480992","","10.1109/TLA.2015.7273789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273789","Information Management;Machine Learning;Text Categorization","Algorithm design and analysis;Bayes methods;Classification algorithms;Information management;Machine learning algorithms;Support vector machines;Text categorization","belief networks;beverage industry;information resources;learning (artificial intelligence);support vector machines;text analysis","Naive Bayes;SVM;coffee market;coffee supply chain;information management;machine learning techniques;news classification;support vector machine;text categorization;tree bases","","","","","","","July 2015","","IEEE","IEEE Journals & Magazines"
"Estimating complex networks centrality via neural networks and machine learning","F. Grando; L. C. Lamb","Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil","2015 International Joint Conference on Neural Networks (IJCNN)","20151001","2015","","","1","8","Vertex centrality measures are important analysis elements in complex networks and systems. These metrics have high space and time complexity, which is a severe problem in applications that typically involve large networks. To apply such high complexity metrics in large networks we trained and tested off-the-shelf machine learning algorithms on several generated networks using five well-known complex network models. Our main hypothesis is that if one uses low complexity metrics as inputs to train the algorithms, one will achieve good approximations of high complexity measures. Our results show that the regression output of the machine learning algorithms applied in our experiments successfully approximate the real metric values and are a robust alternative in real world applications, in particular in complex and social network analysis.","2161-4393;21614393","Electronic:978-1-4799-1960-4; POD:978-1-4799-1961-1","10.1109/IJCNN.2015.7280334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280334","Complex networks;Machine learning;Regression;Vertex centrality measures","Optimization;Robustness","complex networks;computational complexity;estimation theory;graph theory;learning (artificial intelligence);mathematics computing;network theory (graphs);neural nets","complex network centrality estimation;machine learning;neural network;space complexity;time complexity;vertex centrality measure","","1","","40","","","12-17 July 2015","","IEEE","IEEE Conference Publications"
"Privacy-Preserving Machine Learning Algorithms for Big Data Systems","K. Xu; H. Yue; L. Guo; Y. Guo; Y. Fang","Dept. of Electr. & Comput. Eng., Univ. of Florida, Gainesville, FL, USA","2015 IEEE 35th International Conference on Distributed Computing Systems","20150723","2015","","","318","327","Machine learning has played an increasing important role in big data systems due to its capability of efficiently discovering valuable knowledge and hidden information. Often times big data such as healthcare systems or financial systems may involve with multiple organizations who may have different privacy policy, and may not explicitly share their data publicly while joint data processing may be a must. Thus, how to share big data among distributed data processing entities while mitigating privacy concerns becomes a challenging problem. Traditional methods rely on cryptographic tools and/or randomization to preserve privacy. Unfortunately, this alone may be inadequate for the emerging big data systems because they are mainly designed for traditional small-scale data sets. In this paper, we propose a novel framework to achieve privacy-preserving machine learning where the training data are distributed and each shared data portion is of large volume. Specifically, we utilize the data locality property of Apache Hadoop architecture and only a limited number of cryptographic operations at the Reduce() procedures to achieve privacy-preservation. We show that the proposed scheme is secure in the semi-honest model and use extensive simulations to demonstrate its scalability and correctness.","1063-6927;10636927","Electronic:978-1-4673-7214-5; POD:978-1-4673-7215-2","10.1109/ICDCS.2015.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164918","","Big data;Data mining;Kernel;Protocols;Support vector machines;Training;Training data","Big Data;data privacy;learning (artificial intelligence);parallel processing","Apache Hadoop architecture;Big Data systems;cryptographic operations;data locality property;privacy-preserving machine learning","","6","","31","","","June 29 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Machine learning approach for detection of cyber-aggressive comments by peers on social media network","V. S. Chavan; Shylaja S S","Department of Information Science and Engineering, P.E.S Institute of Technology, Bangalore, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","2354","2358","The fast growing use of social networking sites among the teens have made them vulnerable to get exposed to bullying. Cyberbullying is the use of computers and mobiles for bullying activities. Comments containing abusive words effect psychology of teens and demoralizes them. In this paper we have devised methods to detect cyberbullying using supervised learning techniques. We present two new hypotheses for feature extraction to detect offensive comments directed towards peers which are perceived more negatively and result in cyberbullying. Our initial experiments show that using features from our hypotheses in addition to traditional feature extraction techniques like TF-IDF and N-gram increases the accuracy of the system.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275970","cyber-aggressive;machine learning;supervised","Accuracy;Dictionaries;Feature extraction;Logistics;Machine learning algorithms;Standards;Support vector machines","feature extraction;learning (artificial intelligence);psychology;social networking (online)","N-gram;TF-IDF;cyber-aggressive comment detection;cyberbullying;feature extraction;machine learning approach;psychology;social media network;social networking sites;supervised learning techniques","","","","11","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Evaluating model drift in machine learning algorithms","K. Nelson; G. Corbin; M. Anania; M. Kovacs; J. Tobias; M. Blowers","BAE Systems, Rome, NY, USA","2015 IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA)","20150820","2015","","","1","8","Machine learning is rapidly emerging as a valuable technology thanks to its ability to learn patterns from large data sets and solve problems that are impossible to model using conventional programming logic. As machine learning techniques become more mainstream, they are being applied to a wider range of application domains. These algorithms are now trusted to make critical decisions in secure and adversarial environments such as healthcare, fraud detection, and network security, in which mistakes can be incredibly costly. They are also a critical component to most modern autonomous systems. However, the data driven approach utilized by these machine learning methods can prove to be a weakness if the data on which the models rely are corrupted by either nefarious or accidental means. Models that utilize on-line learning or periodic retraining to learn new patterns and account for data distribution changes are particularly susceptible to corruption through model drift. In modeling this type of scenario, specially crafted data points are added to the training set over time to adversely influence the system, inducing model drift which leads to incorrect classifications. Our work is focused on exploring the resistance of various machine learning algorithms to such an approach. In this paper we present an experimental framework designed to measure the susceptibility of anomaly detection algorithms to model drift. We also exhibit our preliminary results using various machine learning algorithms commonly found in intrusion detection research.","2329-6267;23296267","CD-ROM:978-1-4673-7556-6; Electronic:978-1-4673-7557-3; POD:978-1-4673-7558-0","10.1109/CISDA.2015.7208643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7208643","adversarial machine learning;cyber security;intrusion detection systems;model drift","Algorithm design and analysis;Data models;Hidden Markov models;Image color analysis;Machine learning algorithms;Security;Training","learning (artificial intelligence);pattern recognition;security of data","anomaly detection algorithms;autonomous systems;data distribution;data driven approach;intrusion detection research;machine learning algorithms;machine learning techniques;model drift evaluation;on-line learning;periodic retraining;programming logic","","0","","19","","","26-28 May 2015","","IEEE","IEEE Conference Publications"
"Discover trending domains using fusion of supervised machine learning with natural language processing","S. Lakhanpal; A. Gupta; R. Agrawal","Western Michigan University, Kalamazoo, MI, U.S.A","2015 18th International Conference on Information Fusion (Fusion)","20150917","2015","","","893","900","In this paper, a new technique is presented for mining key domain areas from scientific publications. A domain refers to a particular branch of scientific knowledge and hence largely defines the theme of any scientific research paper. The proposed technique stems from a fusion of knowledge derived from natural language processing and machine learning. Some words or phrases are extracted based on their meaning inferred by the application of preposition disambiguation. These key words or phrases are then classified as domain areas using supervised learning. Various experiments and their analyses yield concrete results validating the efficacy and application of our methodology. The fusion technique therefore extracts an interesting aspect of research from scientific text and hence propounds a hybrid methodology for deriving meaning from underlying text. This approach thus takes a definitive step in advancing text analytics.","","Electronic:978-0-9824-4386-6; POD:978-1-4799-7404-7; USB:978-0-9824-4387-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266654","NLP;NaÃ¯ve Bayes classifier;Preposition Disambiguation;Supervised Classification","Computers;Data mining;Feature extraction;Hidden Markov models;Mathematical model;Natural language processing;Supervised learning","data mining;learning (artificial intelligence);natural language processing;scientific information systems;text analysis","natural language processing;phrase extraction;preposition disambiguation;scientific knowledge;scientific publication mining;scientific research paper;scientific text analytics;supervised machine learning fusion;trending domain discovery","","","","15","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"Circuit Performance Classification With Active Learning Guided Sampling for Support Vector Machines","H. Lin; P. Li","Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20150818","2015","34","9","1467","1480","Leveraging machine learning has been proven as a promising avenue for addressing many practical circuit design and verification challenges. We demonstrate a novel active learning guided machine learning approach for characterizing circuit performance. When employed under the context of support vector machines (SVMs), the proposed probabilistically weighted active learning approach is able to dramatically reduce the size of the training data, leading to significant reduction of the overall training cost. The proposed active learning approach is extended to the training of asymmetric SVM classifiers, which is further sped up by a global acceleration scheme. We demonstrate the excellent performance of the proposed techniques using four case studies: 1) dc/dc converter ripple noise analysis; 2) phase-locked loop lock-time verification; 3) reliability analysis of a ring oscillator with respect to process variations and initial conditions; and 4) prediction of chip peak temperature using a limited number of on-chip temperature sensors.","0278-0070;02780070","","10.1109/TCAD.2015.2413840","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061463","Active learning;active learning;circuit performance classification;support vector machine;support vector machine (SVM)","Circuit optimization;Kernel;Probabilistic logic;Support vector machines;Training;Training data;Vectors","DC-DC power convertors;integrated circuit reliability;learning (artificial intelligence);phase locked loops;support vector machines;temperature sensors","active learning guided sampling;asymmetric SVM classifiers;chip peak temperature;circuit performance classification;dc-dc converter ripple noise analysis;global acceleration scheme;lock-time verification;machine learning;on-chip temperature sensors;phase-locked loop;probabilistically weighted active learning approach;reliability analysis;ring oscillator;support vector machines;training cost;training data","","1","","32","","20150316","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Short-term traffic predictions on large urban traffic networks: Applications of network-based machine learning models and dynamic traffic assignment models","G. Fusco; C. Colombaroni; L. Comelli; N. Isaenko","Department of Civil, Constructional and Environmental Engineering, Sapienza University of Rome, Rome, Italy","2015 International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS)","20150827","2015","","","93","101","The paper discusses the issues to face in applications of short-term traffic predictions on urban road networks and the opportunities provided by explicit and implicit models. Different specifications of Bayesian Networks and Artificial Neural Networks are applied for prediction of road link speed and are tested on a large floating car data set. Moreover, two traffic assignment models of different complexity are applied on a sub-area of the road network of Rome and validated on the same floating car data set.","","Electronic:978-9-6331-3142-8; POD:978-1-4799-8223-3","10.1109/MTITS.2015.7223242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223242","Bayesian Networks;Dynamic Traffic Assignment;Floating Car Data;Neural Networks;Short-term traffic predictions","Artificial neural networks;Bayes methods;Forecasting;Measurement uncertainty;Predictive models;Reliability;Roads","belief networks;learning (artificial intelligence);neural nets;road traffic;traffic engineering computing","Bayesian networks;Italy;Rome;artificial neural networks;dynamic traffic assignment models;explicit model;implicit model;network-based machine learning models;road link speed prediction;short-term traffic prediction;urban traffic networks","","0","","20","","","3-5 June 2015","","IEEE","IEEE Conference Publications"
"A Case of Lightweight PUF Constructions: Cryptanalysis and Machine Learning Attacks","D. P. Sahoo; P. H. Nguyen; D. Mukhopadhyay; R. S. Chakraborty","Department of Computer Science and EngineeringSecured Embedded Architecture Laboratory, Indian Institute of Technology Kharagpur, Kharagpur, India","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20150724","2015","34","8","1334","1343","Due to their unique physical properties, physically unclonable functions (PUF) have been proposed widely as versatile cryptographic primitives. It is desirable that silicon PUF circuits should be lightweight, i.e., have low-hardware resource requirements. However, it is also of primary importance that such demands of low hardware overhead should not compromise the security aspects of PUF circuits. In this paper, we develop two different mathematical attacks on previously proposed lightweight PUF circuits, namely composite PUF and the multibit output lightweight secure PUF (LSPUF). We show that independence of various components of composite PUF can be used to develop divide and conquer attacks which can be used to determine the responses to unknown challenges. We reduce the complexity of the attack using a machine learning-based modeling analysis. In addition, we elucidate a special property of the output network of LSPUF to show how such feature can be leveraged by an adversary to perform an intelligent model building attack. The theoretical inferences are validated through experimental results. More specifically, proposed attacks on composite PUF are validated using the challenge-response pairs (CRPs) from its field programmable gate array (FPGA) implementation, and attack on LSPUF is validated using the CRPs of both simulated and FPGA implemented LSPUF.","0278-0070;02780070","","10.1109/TCAD.2015.2448677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131531","Composite PUF;PUF;cryptanalysis;lightweight secure;modeling attack","Computational modeling;Cryptography;Hardware;Integrated circuit reliability;Partitioning algorithms","","","","4","","11","","20150623","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Cubic spline as an alternative to methods of machine learning","J. Richardson; P. Reiner; B. M. Wilamowski","Department of Electrical and Computer Engineering, Auburn University, Auburn, USA","2015 IEEE 13th International Conference on Industrial Informatics (INDIN)","20151001","2015","","","110","115","Approximation of unknown functions in multiple dimensions is an important topic in many areas of industrial engineering, such as nonlinear control. Currently, approaches such as neural networks or fuzzy systems are used to create highly nonlinear surfaces from data. Here we show the capabilities of a very simple classical numerical method such as cubic spline to compete with state of the art machine learning techniques such as Artificial Neural Networks (ANN), Fuzzy Systems (FS), Support Vector Machine (SVM), and Extreme Learning Machines (ELM). Machine learning techniques have many issues such as choosing rules or building a network architecture that can be avoided. Without randomness in the initialization process, there is no need to run the same problem hundreds of times to get a good result. The proposed methods are tested on a variety of problems pertaining to industrial applications against many popular algorithms. Experimental results show that simple cubic splines are indeed competitive in terms of computation time and approximation accuracy when compared with adaptive methods.","1935-4576;19354576","Electronic:978-1-4799-6649-3; POD:978-1-4799-6650-9; USB:978-1-4799-6648-6","10.1109/INDIN.2015.7281719","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281719","Artificial Neural Networks;Control Systems;Function Approximation;Fuzzy Systems;Industrial Control;Machine Learning;Support Vector Machines","Approximation methods;FCC;Fuzzy systems;Neurons;Splines (mathematics);Support vector machines;Training","fuzzy set theory;learning (artificial intelligence);neural nets;splines (mathematics);support vector machines","ANN;ELM;FS;SVM;artificial neural networks;cubic spline;extreme learning machines;fuzzy systems;machine learning;support vector machine","","","","29","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Pattern Recognition of Lower Member Skin Ulcers in Medical Images with Machine Learning Algorithms","J. L. Seixas; S. Barbon; R. G. Mantovani","Univ. Estadual de Londrina - UEL, Londrina, Brazil","2015 IEEE 28th International Symposium on Computer-Based Medical Systems","20150727","2015","","","50","53","Misleading diagnosis of skin diseases may result in complications during the healing process. Skin images provide an important contribution to medical staff on storing and exchanging information to try preventing misdiagnosis. For such, image segmentation process may benefit from use of machine learning techniques, increasing simplicity of procedure, reducing computational costs and improving the diagnosis. This paper presents a comparison among different paradigms of machine learning to validate the segmentation of medical images of lower members ulcers, this segmentation allows wound pattern recognition to determinate injury region aiming at reducing the subjectivity of human evaluation.","1063-7125;10637125","Electronic:978-1-4673-6775-2; POD:978-1-4673-6776-9","10.1109/CBMS.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167456","Image segmentation;Machine learning classifiers;Medical images;Pattern recognition","Accuracy;Biomedical imaging;Image color analysis;Image segmentation;Radio frequency;Support vector machines;Wounds","biomedical optical imaging;diseases;image classification;image segmentation;injuries;learning (artificial intelligence);medical image processing;skin;wounds","healing process;human evaluation;image segmentation;information exchange;information storage;injury region;lower member skin ulcers;machine learning algorithms;medical images;medical staff;pattern recognition;skin disease diagnosis;wound pattern recognition","","0","","10","","","22-25 June 2015","","IEEE","IEEE Conference Publications"
"Survey of unsupervised machine learning algorithms on precision agricultural data","P. Mehta; H. Shah; V. Kori; V. Vikani; S. Shukla; M. Shenoy","MPSTME, NMIMS University, Mumbai, India","2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)","20150813","2015","","","1","8","Machine learning is a branch of computer science, which oversees the study and construction of algorithms that learn from data. Out of the various machine-learning concepts, this paper talks about 6 clustering algorithms: k-means, DBSCAN, OPTICS, Agglomerative, Divisive and COBWEB. The paper incorporates the performance analysis of these clustering algorithms when applied to FAO Soya bean dataset. The algorithms are compared on the basis of various parameters, such as time taken for completion, number of iterations, and number of clusters formed and the complexity of the algorithms. Finally, based on the analysis, the paper determines the best befitting algorithm for the FAO Soya bean dataset.","","Electronic:978-1-4799-6818-3; POD:978-1-4799-6819-0","10.1109/ICIIECS.2015.7193070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7193070","COBWEB;K means;OPTICS;agglomerative;clustering DBSCAN;divisive","Agriculture;Algorithm design and analysis;Clustering algorithms;Complexity theory;Conferences;Machine learning algorithms;Optics","crops;learning (artificial intelligence);pattern clustering","COBWEB algorithm;DBSCAN algorithm;FAO soya bean dataset;OPTICS algorithm;agglomerative algorithm;clustering algorithm;computer science;divisive algorithm;k-means algorithm;machine-learning concept;performance analysis;precision agricultural data;unsupervised machine learning algorithm","","0","","61","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Applying Machine Learning Techniques to Transportation Mode Recognition Using Mobile Phone Sensor Data","A. Jahangiri; H. A. Rakha","Center for Sustainable Mobility, Virginia Tech Transp. Inst., Blacksburg, VA, USA","IEEE Transactions on Intelligent Transportation Systems","20150925","2015","16","5","2406","2417","This paper adopts different supervised learning methods from the field of machine learning to develop multiclass classifiers that identify the transportation mode, including driving a car, riding a bicycle, riding a bus, walking, and running. Methods that were considered include K-nearest neighbor, support vector machines (SVMs), and tree-based models that comprise a single decision tree, bagging, and random forest (RF) methods. For training and validating purposes, data were obtained from smartphone sensors, including accelerometer, gyroscope, and rotation vector sensors. K-fold cross-validation as well as out-of-bag error was used for model selection and validation purposes. Several features were created from which a subset was identified through the minimum redundancy maximum relevance method. Data obtained from the smartphone sensors were found to provide important information to distinguish between transportation modes. The performance of different methods was evaluated and compared. The RF and SVM methods were found to produce the best performance. Furthermore, an effort was made to develop a new additional feature that entails creating a combination of other features by adopting a simulated annealing algorithm and a random forest method.","1524-9050;15249050","","10.1109/TITS.2015.2405759","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063936","Cellular phone sensor data;machine learning algorithms;transportation mode recognition","Accelerometers;Data models;Global Positioning System;Gyroscopes;Kernel;Support vector machines;Transportation","decision trees;feature selection;intelligent transportation systems;learning (artificial intelligence);pattern classification;simulated annealing;smart phones;support vector machines","RF method;SVM;decision tree;k-nearest neighbor;machine learning technique;model selection;multiclass classifier;random forest method;simulated annealing algorithm;smart phone sensor data;supervised learning method;support vector machine;transportation mode recognition;tree-based model","","7","","48","","20150319","Oct. 2015","","IEEE","IEEE Journals & Magazines"
"A machine learning strategy for predicting march madness winners","J. Gumm; A. Barrett; G. Hu","Department of Computer Science, Central Michigan University, Mount Pleasant, Michigan 48859, USA","2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20150806","2015","","","1","6","The Division I NCAA Men's Basketball Tournament is a popular sporting event held annually to determine the leagues National Champion. Over the past several years the betting scene surrounding the tournament has become arguably more popular than the tournament itself, drawing in fans who bet billions overall on its outcome. In this paper, we discuss the statistical challenges in correctly predicting winners in the tournament and present a machine learning strategy for predicting the games. The Kaggle Machine Learning March Mania Competition was used to test the effectiveness of the model by comparing it against other machine-learning-based models submitted to the competition. Overall, the project was considered successful as it scored in the top 15 percentile of all submissions.","","Electronic:978-1-4799-8676-7; POD:978-1-4799-8677-4","10.1109/SNPD.2015.7176206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7176206","Kaggle Machine Learning contest;NCAA Men's basketball tournament;non-linear regression;predictive modeling","Algorithm design and analysis;Correlation;Economic indicators;Games;Indexes;Prediction algorithms;Predictive models","learning (artificial intelligence);sport","Kaggle Machine Learning March Mania Competition;March Madness winner prediction;game winner prediction;machine learning strategy","","0","","13","","","1-3 June 2015","","IEEE","IEEE Conference Publications"
"Movement Detection of Human Body Segments: Passive radio-frequency identification and machine-learning technologies.","S. Amendola; L. Bianchi; G. Marrocco","Comput. Sci., Robot., & Electromagn, Univ. of Roma Tor Vergata, Rome, Italy","IEEE Antennas and Propagation Magazine","20150820","2015","57","3","23","37","Movement detection of human body segments is a fertile research topic in human-computer interaction, as well as in medical and entertainment applications. In spite of the fact that most of the current methods to track motion are based on optoelectronic systems and wearable inertial sensors, promising solutions could spring from the application of passive radio-frequency identification (RFID) technology. When the human body's limbs move within an electromagnetic field radiated by an interrogating antenna, a movement-dependent modulation of the backscattered field is sensed by the remote receiver. The collected signals, properly conditioned by wearable electromagnetic markers (tags), may therefore carry intrinsic information about human motion. This article investigates the potentiality of the synergy between electromagnetics and machine-learning technologies to classify gestures of arms and legs by using only passive and sensorless transponders. The electromagnetic signals, backscattered from the tags during gestures, are collected by a fixed reader antenna and processed by the support vector machine (SVM) algorithm to recognize periodic limb movements and classify more complex random motion patterns. Experimental sessions demonstrated a classification accuracy higher than 80-90%, which is comparable to more complex systems involving active wearable transceivers. The results further indicate that the achievable bit rate is 48 b/min, suggesting that the platform could be used to input coded controls to a gesture-oriented user interface.","1045-9243;10459243","","10.1109/MAP.2015.2437274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163526","","Antenna measurements;Frequency measurement;Human computer interaction;Motion detection;Radio frequency;Radiofrequency identification;Support vector machines","gesture recognition;human computer interaction;image classification;image motion analysis;learning (artificial intelligence);radiofrequency identification;support vector machines;transceivers;transponders","RFID technology;SVM algorithm;active wearable transceivers;backscattered field;complex random motion pattern classification;electromagnetic field;electromagnetic signals;entertainment application;fixed reader antenna;gesture classification;gesture-oriented user interface;human body segments;human-computer interaction;interrogating antenna;machine learning;medical application;motion tracking;movement detection;movement-dependent modulation;optoelectronic systems;passive radio-frequency identification technology;passive transponder;periodic limb movement recognition;remote receiver;sensorless transponder;support vector machine algorithm;wearable electromagnetic markers;wearable inertial sensors","","2","","24","","20150721","June 2015","","IEEE","IEEE Journals & Magazines"
"An Event Data Extraction Method Based on HTML Structure Analysis and Machine Learning","C. Liao; K. Hiroi; K. Kaji; N. Kawaguchi","Grad. Sch. Eng., Nagoya Univ., Nagoya, Japan","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","3","","217","222","This paper proposes an event data extraction method that extracts business event data, such as coupons, tickets, sales campaigns, etc., from a homepage or blog of shops and pushes them to users. Users no longer need to browse their favorite shops' homepage one by one. The method supports comprehensiveness and effectiveness for event data obtainment. This proposition works into two tasks: web page block segmentation and event data identification. The first task segments the web page into blocks. Each of the blocks includes information, such as title, notification, date, etc. Relating to event information. Many related works suppose web page block segmentation based on specific tags, vision, function, etc. In this research, we propose a web page block segmentation method based on HTML document structure analysis. The second task is used to identity event data from segmented blocks. We propose a method to implement event data identification based on machine learning. We show the results of a verification experiment. Experimental data are from 96 shops located in two underground shopping streets UNIMALL and ESCA, at a train station in the city of Nagoya (Japan). Because the event data identification depends on the Japanese language, this method is available for all the Japanese home page.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273357","Knowledge Processing;Text Classification;Ubiquitous Computing;Web Mining","Data mining;Erbium;HTML;Layout;Support vector machines;Training;Web pages","Internet;Web sites;data mining;hypermedia markup languages;learning (artificial intelligence);natural language processing;retail data processing","ESCA;HTML document structure analysis;HTML structure analysis;Japanese home page;Japanese language;UNIMALL;Web page block segmentation;blog;business event data;event data extraction method;event data identification;event data obtainment;machine learning;segmented block;shop homepage;underground shopping street","","","","21","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Poster: Software Development Risk Management: Using Machine Learning for Generating Risk Prompts","H. R. Joseph","Dept. of Electr. Eng., Indian Inst. of Technol. Madras, Chennai, India","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","20150817","2015","2","","833","834","Software risk management is a critical component of software development management. Due to the magnitude of potential losses, risk identification and mitigation early on become paramount. Lists containing hundreds of possible risk prompts are available both in academic literature as well as in practice. Given the large number of risks documented, scanning the lists for risks and pinning down relevant risks, though comprehensive, becomes impractical. In this work, a machine learning algorithm is developed to generate risk prompts, based on software project characteristics and other factors. The work also explores the utility of post-classification tagging of risks.","0270-5257;02705257","Electronic:978-1-4799-1934-5; POD:978-1-4799-1935-2","10.1109/ICSE.2015.271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203092","Software risk;machine learning;risk prompts;software management","Distance measurement;Machine learning algorithms;Neural networks;Risk management;Software;Tagging;Taxonomy","identification technology;learning (artificial intelligence);risk management;software development management","machine learning;post-classification tagging;risk identification;risk mitigation;software development management;software risk management","","0","","10","","","16-24 May 2015","","IEEE","IEEE Conference Publications"
"Identification of the Best Anthropometric Predictors of Serum High- and Low-Density Lipoproteins Using Machine Learning","B. J. Lee; J. Y. Kim","Korea Institute of Oriental Medicine, Daejeon, South Korea","IEEE Journal of Biomedical and Health Informatics","20150901","2015","19","5","1747","1756","Serum high-density lipoprotein (HDL) and low-density lipoprotein (LDL) cholesterol levels are associated with risk factors for various diseases and are related to anthropometric measures. However, controversy remains regarding the best anthropometric indicators of the HDL and LDL cholesterol levels. The objectives of this study were to identify the best predictors of HDL and LDL cholesterol using statistical analyses and two machine learning algorithms and to compare the predictive power of combined anthropometric measures in Korean adults. A total of 13 014 subjects participated in this study. The anthropometric measures were assessed with binary logistic regression (LR) to evaluate statistically significant differences between the subjects with normal and high LDL cholesterol levels and between the subjects with normal and low HDL cholesterol levels. LR and the naive Bayes algorithm (NB), which provides more reasonable and reliable results, were used in the analyses of the predictive power of individual and combined measures. The best predictor of HDL was the rib to hip ratio (p = <; 0.0001; odds ratio (OR) = 1.895; area under curve (AUC) = 0.681) in women and the waist to hip ratio (WHR) (p = <;0.0001; (OR) = 1.624; AUC = 0.633) in men. In women, the strongest indicator of LDL was age (p = <;0.0001; OR = 1.662; AUC by NB = 0.653); AUC byLR = 0.636. Among the anthropometric measures, the body mass index (BMI), WHR, forehead to waist ratio, forehead to rib ratio, and forehead to chest ratio were the strongest predictors of LDL; these measures had similar predictive powers. The strongest predictor in men was BMI (p = <;0.0001; OR = 1.369; AUC by NB = 0.594; AUC by LR = 0.595). The predictive power of almost all individual anthrop- metric measures was higher for HDL than for LDL, and the predictive power for both HDL and LDL in women was higher than for men. A combination of anthropometric measures slightly improved the predictive power for both HDL and LDL cholesterol. The best indicator for HDL and LDL might differ according to the type of cholesterol and the gender. In women, but not men, age was the variable that strongly predicted HDL and LDL cholesterol levels. Our findings provide new information for the development of better initial screening tools for HDL and LDL cholesterol.","2168-2194;21682194","","10.1109/JBHI.2014.2350014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6880767","Anthropometry;classification;data mining;high-density lipoproteins (HDLs);low-density lipoproteins (LDLs);machine learning;predictor;statistical data analysis","Biomedical measurement;Forehead;Hardware design languages;Hip;Neck;Niobium;Power measurement","anthropometry;biochemistry;biomedical measurement;diseases;learning (artificial intelligence);molecular biophysics;proteins;sensitivity analysis;statistical analysis","anthropometric predictor identification;area under curve;binary logistic regression;body mass index;diseases;forehead-chest ratio;forehead-rib ratio;forehead-waist ratio;machine learning algorithms and;naive Bayes algorithm;rib-hip ratio;serum high-density lipoprotein cholesterol levels;serum low-density lipoprotein cholesterol levels;statistical analysis;waist-hip ratio","0","0","","56","","20140820","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Enhanced automatic 2Dâ3D conversion using retinex in machine learning framework","J. L. Herrera; C. R. del-Blanco; N. GarcÃ­a","Grupo de Tratamiento de Im&#x00E1;genes, ETSI Telecomunicaci&#x00F3;n, Universidad Polit&#x00E9;cnica de Madrid, Spain","2015 International Symposium on Consumer Electronics (ISCE)","20150806","2015","","","1","2","In this paper, we present an approach for automatically convert images from 2D to 3D. The algorithm uses a color + depth dataset to estimate a depth map of a query color image by searching structurally similar images in the dataset and fusing them. Our experimental results indicate that the inclusion of a retinex based stage for the query image and the dataset images improves the performance of the system on commonly-used databases and for different image descriptors.","0747-668X;0747668X","Electronic:978-1-4673-7365-4; POD:978-1-4673-7366-1","10.1109/ISCE.2015.7177825","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177825","2D-to-3D image conversion;depth maps;retinex","Color;Databases;Image color analysis;Lighting;Machine learning algorithms;Measurement;Three-dimensional displays","image colour analysis","automatically convert images;commonly-used databases;dataset images;enhanced automatic 2D-3D conversion;image descriptors;machine learning framework;query color image;retinex","","0","","8","","","24-26 June 2015","","IEEE","IEEE Conference Publications"
"A machine-learning based approach to model user occupancy and activity patterns for energy saving in buildings","J. L. G. Ortega; L. Han; N. Whittacker; N. Bowring","School of Computing, Mathematics and Digital Technology","2015 Science and Information Conference (SAI)","20150903","2015","","","474","482","Recently it has been noted that user behaviour can have a large impact on the final energy consumption in buildings. Through the combination of mathematical modelling and data from wireless ambient sensors, we can model human behaviour patterns and use the information to regulate building management systems (BMS) in order to achieve the best trade-off between user comfort and energy efficiency. In this work, we have modelled user occupancy and activity patterns using Machine Learning approaches. We have applied non-linear multiclass Support Vector Machines (SVMs) to deal with the complex nature of the data collected from various sensors to accurately identify user occupancy and activities of daily living (ADL) patterns. To validate our results, we also used other methodologies (i.e. Hidden-Markov Model and k-Nearest Neighbours). The experimental results show that our proposed approach outperforms the other methods for the scenarios evaluated.","","Electronic:978-1-4799-8547-0; POD:978-1-4799-8548-7; USB:978-1-4799-8546-3","10.1109/SAI.2015.7237185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237185","Activity recognition;Machine Learning;Mathematical modelling;Occupancy detection;SVMs","Buildings;Hidden Markov models;Kernel;Mathematical model;Support vector machines;Temperature sensors","ambient intelligence;building management systems;control engineering computing;energy consumption;hidden Markov models;learning (artificial intelligence);support vector machines;user modelling","ADL pattern;BMS;SVM;activities of daily living;building management system;energy saving;hidden Markov model;k-nearest neighbour;machine learning;support vector machine;user occupancy modelling;wireless ambient sensor","","3","","35","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"Machine Learning-Based Configuration Parameter Tuning on Hadoop System","C. O. Chen; Y. Q. Zhuo; C. C. Yeh; C. M. Lin; S. W. Liao","Comput. Intell. Technol. Center, Ind. Technol. Res. Inst., Hsinchu, Taiwan","2015 IEEE International Congress on Big Data","20150820","2015","","","386","392","Apache Hadoop system is a software framework with the capability to process large-scale datasets across a cluster of distributed machines using MapReduce programming model. However, there are two main challenges for system administrators to manage the Hadoop system, (1) system administrators are difficult to tune the parameters appropriately since the behaviors and characteristics of large-scale distributed systems are too complicated, (2) there are dozens of configuration parameters affecting the system performance which makes the configuration parameters tuning task becomes troublesome. In this paper, we focus on optimizing the Hadoop MapReduce job performance by tuning configuration parameters, and then we propose an analytical method to help system administrators choose approximately optimal configuration parameters depending on the characteristics of each application. Our approach has two key phases: prediction and optimization phase. The prediction phase is to estimate the performance of a MapReduce job, whereas the optimization phase is to search the approximately optimal configuration parameters strategically by invoking the predictor repeatedly. In our evaluation results, our work can help system administrators to improve the performance about 2X to 8X better than traditional methods.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207248","Distributed System;Machine Learning;Optimization Problem","Accuracy;Approximation methods;Optimization;Predictive models;Regression tree analysis;System performance;Tuning","learning (artificial intelligence);parallel processing","Apache Hadoop system;Hadoop MapReduce job performance;MapReduce programming model;approximately optimal configuration parameter;configuration parameters tuning task;distributed machine;large-scale dataset;large-scale distributed system;machine learning-based configuration parameter tuning;software framework;system administrator;system performance","","0","","36","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Comparative studies on breast cancer classifications with k-fold cross validations using machine learning techniques","Z. Nematzadeh; R. Ibrahim; A. Selamat","Faculty of computing, UTM, Skudai, Malaysia","2015 10th Asian Control Conference (ASCC)","20150910","2015","","","1","6","In the past years there are several machine learning techniques have been proposed to design precise classification systems for several medical issues. This paper compares and analyses breast cancer classifications with different machine learning algorithms using k-Fold Cross Validation (KCV) technique. Decision Tree, NaiÌve Bayes, Neural Network and Support Vector Machine algorithm with three different kernel functions are used as classifier to classify original and prognostic Wisconsin breast cancer. The comparative analysis of the studies are focusing on the impact of k in k-fold cross validation and achieve higher accuracy. We have used the benchmarking dataset in UCI in the experiments. In theory the common choice is to select k=10 for KCV. However this comes at an increased computational cost whereby the more the folds the more models you need to train. The overall results showed important conclusion; we cannot always expect to have more accurate result by having greater value of k in k-fold cross validation.","","Electronic:978-1-4799-7862-5; POD:978-1-4799-7863-2","10.1109/ASCC.2015.7244654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244654","breast cancer diagnosis;classification;cross validation;machine learning","Accuracy;Breast cancer;Decision trees;Kernel;Neural networks;Support vector machines","Bayes methods;cancer;decision trees;learning (artificial intelligence);medical computing;neural nets;pattern classification;support vector machines","KCV technique;NaiÌve Bayes;UCI;breast cancer classification system;decision tree;k-fold cross validation techniques;kernel functions;machine learning techniques;neural network;prognostic Wisconsin breast cancer;support vector machine algorithm","","0","","22","","","May 31 2015-June 3 2015","","IEEE","IEEE Conference Publications"
"Extreme Learning Machine With Composite Kernels for Hyperspectral Image Classification","Y. Zhou; J. Peng; C. L. P. Chen","Department of Computer and Information Science, University of Macau, Macau, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20150803","2015","8","6","2351","2360","Due to its simple, fast, and good generalization ability, extreme learning machine (ELM) has recently drawn increasing attention in the pattern recognition and machine learning fields. To investigate the performance of ELM on the hyperspectral images (HSIs), this paper proposes two spatial-spectral composite kernel (CK) ELM classification methods. In the proposed CK framework, the single spatial or spectral kernel consists of activation-function-based kernel and general Gaussian kernel, respectively. The proposed methods inherit the advantages of ELM and have an analytic solution to directly implement the multiclass classification. Experimental results on three benchmark hyperspectral datasets demonstrate that the proposed ELM with CK methods outperform the general ELM, SVM, and SVM with CK methods.","1939-1404;19391404","","10.1109/JSTARS.2014.2359965","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926746","Composite kernel (CK);extreme learning machine (ELM);hyperspectral image (HSI) classification","Educational institutions;Feature extraction;Hyperspectral imaging;Kernel;Support vector machines;Training","hyperspectral imaging;image classification;learning (artificial intelligence)","ELM classification methods;HSI;activation-function-based kernel;extreme learning machine;general Gaussian kernel;hyperspectral datasets;hyperspectral image classification;machine learning;multiclass classification;pattern recognition;spatial-spectral composite kernel","","9","","43","","20141016","June 2015","","IEEE","IEEE Journals & Magazines"
"Bank direct marketing analysis of asymmetric information based on machine learning","P. Ruangthong; S. Jaiyen","Department of Computer Science, Faculty of Science, King Mongkut's Institute of Technology Ladkrabang, Thailand","2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20150827","2015","","","93","96","The bank direct marketing campaign for offering products that meet the customers' needs is the challenge problems. The bank direct marketing data analysis is important work that helps the banks predict whether customers will sign a long term deposits with the banks. The method that can predict such customers' needs can be profitable to the banks for improving their marketing campaign strategies. Unfortunately, it is very hard to predict the customers' needs because the available information is asymmetric. In this paper, we propose the method to analyze asymmetric information using SMOTE algorithm and Rotation Forest (PCA)-J48. The SMOTE method is used to modify the data and improve the accuracy of the prediction. The performance of the proposed method is evaluated and compared to Decision Tree, Rotation Forest, Navie Bayes, BayesNet, Multilayer Perceptron Neural Network, RBF Neural Network. The experimental results show the predicting accuracies of all predictors. The experiments show that Rotation Forest (PCA)- J48 can achieve the highest value of accuracy and specificity. However, the sensitivity of Rotation Forest (PCA)-J48 is higher than all methods except BayesNet and Rotation Forest (PCA) RandomTree.","","Electronic:978-1-4799-1966-6; POD:978-1-4799-1967-3","10.1109/JCSSE.2015.7219777","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219777","BayesNet;Decision Tree;Direct Marketing;MLP (MultilayerPerceptron);NavieBayes;RBFNetwork;Rotation Forest(PCA);SMOTE","Accuracy;Classification algorithms;Decision trees;Neural networks;Prediction algorithms;Principal component analysis;Sensitivity","banking;data analysis;learning (artificial intelligence)","SMOTE algorithm;asymmetric information;bank direct marketing data analysis;machine learning;rotation forest (PCA)-J48","","1","","18","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Machine Learning Based Auto-Tuning for Enhanced OpenCL Performance Portability","T. L. Falch; A. C. Elster","Dept. of Comput. & Inf. Sci., Norwegian Univ. of Sci. & Technol., Trondheim, Norway","2015 IEEE International Parallel and Distributed Processing Symposium Workshop","20151001","2015","","","1231","1240","Heterogeneous computing, which combines devices with different architectures, is rising in popularity, and promises increased performance combined with reduced energy consumption. OpenCL has been proposed as a standard for programing such systems, and offers functional portability. It does, however, suffer from poor performance portability, code tuned for one device must be re-tuned to achieve good performance on another device. In this paper, we use machine learning-based auto-tuning to address this problem. Benchmarks are run on a random subset of the entire tuning parameter configuration space, and the results are used to build an artificial neural network based model. The model can then be used to find interesting parts of the parameter space for further search. We evaluate our method with different benchmarks, on several devices, including an Intel i7 3770 CPU, an Nvidia K40 GPU and an AMD Radeon HD 7970 GPU. Our model achieves a mean relative error as low as 6.1%, and is able to find configurations as little as 1.3% worse than the global minimum.","","Electronic:978-1-4673-7684-6; POD:978-1-4673-7685-3","10.1109/IPDPSW.2015.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284453","OpenCL;artificial neural networks;auto-tuning;heterogeneous computing;machine learning","Benchmark testing;Graphics processing units;Kernel;Neurons;Performance evaluation;Predictive models;Tuning","learning (artificial intelligence);neural nets;power aware computing;software portability","AMD Radeon HD 7970 GPU;Intel i7 3770 CPU;Nvidia K40 GPU;artificial neural network based model;enhanced OpenCL performance portability;functional portability;heterogeneous computing;machine learning based auto-tuning;reduced energy consumption;tuning parameter configuration space","","1","","41","","","25-29 May 2015","","IEEE","IEEE Conference Publications"
"Machine learning based rate adaptation with elastic feature selection for HTTP-based streaming","Y. L. Chien; K. C. J. Lin; M. S. Chen","Department of Electrical Engineering, National Taiwan University, Taiwan","2015 IEEE International Conference on Multimedia and Expo (ICME)","20150806","2015","","","1","6","Dynamic Adaptive Streaming over HTTP (DASH) has become an emerging application nowadays. Video rate adaptation is a key to determine the video quality of HTTP-based media streaming. Recent works have proposed several algorithms that allow a DASH client to adapt its video encoding rate to network dynamics. While network conditions are typically affected by many different factors, these algorithms however usually consider only a few representative information, e.g., predicted available bandwidth or fullness of its playback buffer. In addition, the error in bandwidth estimation could significantly degrade their performance. Therefore, this paper presents Machine Learning-based Adaptive Streaming over HTTP (MLASH), an elastic framework that exploits a wide range of useful network-related features to train a rate classification model. The distinct properties of MLASH are that its machine learning-based framework can be incorporated with any existing adaptation algorithm and utilize big data characteristics to improve prediction accuracy. We show via trace-based simulations that machine learning-based adaptation can achieve a better performance than traditional adaptation algorithms in terms of their target quality of experience (QoE) metrics.","1945-7871;19457871","Electronic:978-1-4799-7082-7; POD:978-1-4799-7083-4","10.1109/ICME.2015.7177418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177418","HTTP Streaming;Machine Learning;Rate Adaptation","Bandwidth;Lead;Servers;Streaming media;Training","feature selection;hypermedia;learning (artificial intelligence);media streaming;pattern classification;quality of experience;video coding","DASH client;HTTP-based media streaming;HTTP-based streaming;MLASH;QoE metrics;adaptation algorithm;bandwidth estimation;big data characteristics;dynamic adaptive streaming over HTTP;elastic feature selection;machine learning based rate adaptation;machine learning-based adaptation;machine learning-based adaptive streaming over HTTP;machine learning-based framework;network condition;network dynamics;network-related feature;playback buffer;prediction accuracy;rate classification model;representative information;target quality of experience metrics;trace-based simulation;video encoding rate;video quality;video rate adaptation","","2","","10","","","June 29 2015-July 3 2015","","IEEE","IEEE Conference Publications"
"MDP and Machine Learning-Based Cost-Optimization of Dynamic Resource Allocation for Network Function Virtualization","R. Shi; J. Zhang; W. Chu; Q. Bao; X. Jin; C. Gong; Q. Zhu; C. Yu; S. Rosenberg","Dell Res., USA","2015 IEEE International Conference on Services Computing","20150820","2015","","","65","73","The introduction of Network Functions Virtualization (NFV) enables service providers to offer software-defined network functions with elasticity and flexibility. Its core technique, dynamic allocation procedure of NFV components onto cloud resources requires rapid response to changes on-demand to remain cost and QoS effective. In this paper, Markov Decision Process (MDP) is applied to the NP-hard problem to dynamically allocate cloud resources for NFV components. In addition, Bayesian learning method is applied to monitor the historical resource usage in order to predict future resource reliability. Experimental results show that our proposed strategy outperforms related approaches.","","Electronic:978-1-4673-7281-7; POD:978-1-4673-7282-4","10.1109/SCC.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207337","Bayesian Learning;Markov Decision Process;Network Functions Virtualization;Resource Allocation","Bayes methods;Dynamic scheduling;Reliability;Resource management;Servers;Synchronization","Markov processes;cloud computing;learning (artificial intelligence);optimisation;quality of service;resource allocation;software defined networking;virtualisation","MDP;Markov decision process;NFV;NP-hard problem;QoS;cloud resources;cost optimization;dynamic resource allocation;elasticity;flexibility;machine learning;network function virtualization;software-defined network functions","","0","","36","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Supervised Machine Learning Model for High Dimensional Gene Data in Colon Cancer Detection","H. Chen; H. Zhao; J. Shen; R. Zhou; Q. Zhou","Sch. of Inf. Sci. & Eng., Lanzhou Univ., Lanzhou, China","2015 IEEE International Congress on Big Data","20150820","2015","","","134","141","With well-developed methods in gene level data extraction, there are huge amount of gene expression data, including normal composition and abnormal ones. Therefore, mining gene expression data is currently an urgent research question, for detecting a corresponding pattern, such as cancer species, quickly and accurately. Since gene expression data classification problem has been widely studied accompanying with the development of gene technology, by far numerous methods, mainly neural network related, have been deployed in medical data analysis, which is mainly dealing with the high dimension and small quantity. A lot of research has been conducted on clustering approaches, extreme learning machine and so on. They are usually applied in a shallow neural network model. Recently deep learning has shown its power and good performance on high dimensional datasets. Unlike current popular deep neural network, we will continue to apply shallow neural network but develop an innovative algorithm for shallow neural network. In the supervised model, we demonstrate a shallow neural network model with a batch of parameters, and narrow its computational process into several positive parts, which process smoothly for a better result and finally achieve an optimal goal. It shows a stable and excellent result comparable to deep neural network. An analysis of the algorithm is also presented in this paper.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207212","Monte Carlo;Neural Network;high dimensional data","Cancer;Colon;Cost function;Gene expression;Monte Carlo methods;Neural networks;Support vector machines","cancer;data analysis;data mining;genetics;learning (artificial intelligence);medical information systems;neural nets;pattern classification;pattern clustering","cancer species;clustering approaches;colon cancer detection;deep neural network;extreme learning machine;gene expression data classification problem;gene expression data mining;gene level data extraction;high dimensional gene data;medical data analysis;neural network model;shallow neural network;supervised machine learning model","","1","","24","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Secure and resilient distributed machine learning under adversarial environments","R. Zhang; Q. Zhu","Dept. of Electr. & Comput. Eng., New York Univ., New York, NY, USA","2015 18th International Conference on Information Fusion (Fusion)","20150917","2015","","","644","651","With a large number of sensors and control units in networked systems, the decentralized computing algorithms play a key role in scalable and efficient data processing for detection and estimation. The well-known algorithms are vulnerable to adversaries who can modify and generate data to deceive the system to misclassify or misestimate the information from the distributed data processing. This work aims to develop secure, resilient and distributed machine learning algorithms under adversarial environment. We establish a game-theoretic framework to capture the conflicting interests between the adversary and a set of distributed data processing units. The Nash equilibrium of the game allows predicting the outcome of learning algorithms in adversarial environment, and enhancing the resilience of the machine learning through dynamic distributed learning algorithms. We use Spambase Dataset to illustrate and corroborate our results.","","Electronic:978-0-9824-4386-6; POD:978-1-4799-7404-7; USB:978-0-9824-4387-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266621","","Games;Heuristic algorithms;Machine learning algorithms;Security;Training;Training data","distributed processing;game theory;learning (artificial intelligence);sensors","Nash equilibrium;Spambase Dataset;adversarial environments;decentralized computing algorithms;distributed data processing units;distributed machine learning algorithms;dynamic distributed learning algorithm;game-theoretic framework;information misclassification;information misestimation;networked systems;sensors","","","","","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"A user customized service provider framework based on machine learning","S. Kim; E. Hong; B. Park; H. Park","Department of Electronics Engineering, Ewha Womans University, Seoul, Korea","2015 Seventh International Conference on Ubiquitous and Future Networks","20150810","2015","","","23","25","In this paper, we propose a user customized service provider framework based on machine learning. The framework consists of mobile stations, data collector, analysis tools and service applications. As an analysis tool, we deploy machine learning techniques, in particular, support vector machine which generates learning model and precise classifiers. Moreover, K-fold cross-validation is used to achieve better accurate inference from the collected data. Then, we develop a predictor that predicts users' behavior patterns from the information of time connections and APs. This enables to provide adaptive services customized for end-users, e.g., smart phone push notifications services.","2165-8528;21658528","Electronic:978-1-4799-8993-5; POD:978-1-4799-8994-2; USB:978-1-4799-8992-8","10.1109/ICUFN.2015.7182488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7182488","K-fold cross-validation;Machine learning;location based service;support vector machine","Algorithm design and analysis;Kernel;Mobile communication;Predictive models;Support vector machines;Training;Training data","learning (artificial intelligence);mobile computing;support vector machines;user interfaces","K-fold cross-validation;analysis tools;data collector;machine learning;mobile stations;service applications;support vector machine;user customized service provider framework","","0","","11","","","7-10 July 2015","","IEEE","IEEE Conference Publications"
"A Machine Learning Framework for Detecting Landslides on Earthen Levees Using Spaceborne SAR Imagery","M. Mahrooghy; J. V. Aanstoos; R. A. A. Nobrega; K. Hasan; S. Prasad; N. H. Younan","Department of Radiology, University of Pennsylvania, Philadelphia, PA, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20150911","2015","8","8","3791","3801","Earthen levees have a significant role in protecting large areas of inhabited and cultivated land in the United States from flooding. Failure of the levees can result in loss of life and property. Slough slides are among the problems which can lead to complete levee failure during a high water event. In this paper, we develop a method to detect such slides using X-band synthetic aperture radar (SAR) data. Our proposed methodology includes: radiometric normalization of the TerraSAR image using high-resolution digital elevation map (DEM) data; extraction of features including backscatter and texture features from the levee; a feature selection method based on minimum redundancy maximum relevance (mRMR); and training a support vector machine (SVM) classifier and testing on the area of interest. To validate the proposed methodology, ground-truth data are collected from slides and healthy areas of the levee. The study area is part of the levee system along the lower Mississippi River in the United States. The output classes are healthy and slide areas of the levee. The results show the average classification accuracies of approximately 0.92 and Cohen's kappa measures of 0.85 for both healthy and slide pixels using ten optimal features selected by mRMR with a sigmoid SVM. A comparison of the SVM performance to the maximum likelihood (ML) and back propagation neural network (BPNN) shows that the average accuracy of the SVM is superior to that of the BPNN and ML classifiers.","1939-1404;19391404","","10.1109/JSTARS.2015.2427337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7110549","Feature extraction;feature selection;hazards;support vector machine (SVM);synthetic aperture radar (SAR)","Accuracy;Feature extraction;Levee;Remote sensing;Support vector machines;Synthetic aperture radar;Terrain factors","backpropagation;digital elevation models;feature extraction;feature selection;geomorphology;geophysical image processing;image classification;image resolution;image texture;maximum likelihood estimation;neural nets;radar imaging;radar resolution;radiometry;spaceborne radar;support vector machines;synthetic aperture radar","BPNN;Cohen kappa;DEM;Earthen levees;ML classifier;Mississippi river;TerraSAR imaging;United States;X-band synthetic aperture radar data;back propagation neural network;backscatter;feature extraction;high-resolution digital elevation map;landslide detection;mRMR;machine learning framework;maximum likelihood classifier;minimum redundancy maximum relevance;radiometric normalization;sigmoid SVM classifier;spaceborne SAR imagery;support vector machine classifier;texture feature selection method;training","","1","","40","","20150520","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Analysing graduation project rubrics using machine learning techniques","G. Tuysuzoglu; N. Moarref; Z. Cataltepe; A. T. Misirli; Y. Yaslan","Comput. Eng. Dept., Istanbul Tech. Univ., Istanbul, Turkey","2015 10th International Conference on Computer Science & Education (ICCSE)","20150910","2015","","","19","24","When grading a student's performance, determining the assessment factors is a substantial step in course evaluation. The aim of this paper is to improve the quality of the assessment criteria for our Computer Engineering Department's graduation reports. We employ machine learning methods to identify the most important evaluation rubrics that affect the overall grade given to graduation projects. First, we eliminate the redundant factors by computing the correlations between them. Second, we apply K-Means & Hierarchical Clustering methods and third, we analyze the proportion of variance values to find the sufficient amount of eigen values to explain the data. Our results show that Overall Performance is the most important, whereas References is the least important evaluation rubric affecting the graduation project grades. The techniques we use can be used to analyze the graduation rubric grading practices and also to come up with an equivalent rubric with smaller set of questions.","","Electronic:978-1-4799-6600-4; POD:978-1-4799-6601-1; USB:978-1-4799-6599-1","10.1109/ICCSE.2015.7250211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7250211","ABET;Clustering;Correlation;Graduation Project Rubrics;Hierarchical Clustering;K-Means Clustering;Proportion of Variance","Accreditation;Computers;Correlation;Covariance matrices;Euclidean distance;Learning systems;Reliability","computer science education;educational computing;educational courses;learning (artificial intelligence);pattern clustering","Computer Engineering Department graduation reports;assessment criteria quality;assessment factors;course evaluation;graduation project rubrics analysis;hierarchical clustering methods;k-means clustering methods;machine learning techniques;student performance grading","","0","","11","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Mining the impact of object oriented metrics for change prediction using Machine Learning and Search-based techniques","R. Malhotra; M. Khanna","Delhi Technological University, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","228","234","Change in a software is crucial to incorporate defect correction and continuous evolution of requirements and technology. Thus, development of quality models to predict the change proneness attribute of a software is important to effectively utilize and plan the finite resources during maintenance and testing phase of a software. In the current scenario, a variety of techniques like the statistical techniques, the Machine Learning (ML) techniques and the Search-based techniques (SBT) are available to develop models to predict software quality attributes. In this work, we assess the performance of ten machine learning and search-based techniques using data collected from three open source software. We first develop a change prediction model using one data set and then we perform inter-project validation using two other data sets in order to obtain unbiased and generalized results. The results of the study indicate comparable performance of SBT with other employed statistical and ML techniques. This study also supports inter project validation as we successfully applied the model created using the training data of one project on other similar projects and yield good results.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275614","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275614","Change proneness;Empirical validation;Inter project validation;Machine learning techniques;Search-based techniques;Software Quality","Accuracy;Computational modeling;Data models;Predictive models;Sensitivity;Software","data mining;learning (artificial intelligence);object-oriented programming;public domain software;search problems;software maintenance;software metrics;software quality;statistical analysis","SBT;continuous requirements evolution;defect correction;interproject validation;machine learning;object oriented metrics;open source software;quality model;search-based technique;software change proneness attribute prediction;software maintenance;software quality attribute prediction;software testing;statistical technique","","2","","34","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Machine learning approach to corrosion assessment in subsea pipelines","G. De Masi; M. Gentile; R. Vichi; R. Bruschi; G. Gabetta","ADVEN Dept. Saipem Spa, Fano, Italy","OCEANS 2015 - Genova","20150921","2015","","","1","6","Integrity of pipelines transporting hydrocarbons over long distances is a growing and challenging problem for Oil&Gas companies, since the age of plants and components is worldwide increasing. Internal corrosion is one of the most dangerous damage mechanisms active in pipelines. Since it is due to interaction of different mechanisms, a large degree of uncertainty is associated with the attempt of quantifying a prediction for the future evolution of damage. Existing models rarely reproduce field data. Given high nonlinearity of the corrosion process, a Machine Learning approach has been investigated, focusing on Artificial Neural Networks (ANN). In particular, an ensemble of ANNs is generated. This strategy strongly improves the results obtained not only by deterministic models, usually considered in literature, but also by single ANN models. Given the high uncertainty inherent to real internal corrosion problem, results from Machine Learning approach are promising.","","Electronic:978-1-4799-8736-8; POD:978-1-4799-8737-5","10.1109/OCEANS-Genova.2015.7271592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271592","artificial neural networks;ensemble averaging;machine learning;pipeline corrosion","Artificial neural networks;Corrosion;Fitting;Loss measurement;Metals;Pipelines;Predictive models","corrosion;learning (artificial intelligence);neural nets;pipelines","artificial neural networks;corrosion assessment;damage mechanisms;hydrocarbons;internal corrosion;machine learning approach;subsea pipelines","","","","12","","","18-21 May 2015","","IEEE","IEEE Conference Publications"
"Online sequential classification of imbalanced data by combining extreme learning machine and improved SMOTE algorithm","Wentao Mao; J. Wang; L. Wang","School of Computer and Information Engineering, Henan Normal University, Xinxiang, CHINA, 453007","2015 International Joint Conference on Neural Networks (IJCNN)","20151001","2015","","","1","8","Presently, the data imbalance problems become more pronounced in the applications of machine learning and pattern recognition. However, many traditional machine learning methods suffer from the imbalanced data which are also collected in online sequential manner. To get fast and efficient classification for this special problem, a new online sequential extreme learning machine method with sequential SMOTE strategy is proposed. The key idea of this method is to reduce the randomness while generating virtual minority samples by means of the distribution characteristic of online sequential data. Utilizing online-sequential extreme learning machine as baseline algorithm, this method contains two stages. In offline stage, principal curve is introduced to model the each class's distribution based on which some virtual samples are generated by synthetic minority over-sampling technique(SMOTE). In online stage, each class's membership is determined according to the projection distance of sample to principal curve. With the help of these memberships, the redundant majority samples as well as unreasonable virtual minority samples are all excluded to lighten the imbalance level in online stage. The proposed method is evaluated on four UCI datasets and the real-world air pollutant forecasting dataset. The experimental results show that, the proposed method outperforms the classical ELM, OS-ELM and SMOTE-based OS-ELM in terms of generalization performance and numerical stability.","2161-4393;21614393","Electronic:978-1-4799-1960-4; POD:978-1-4799-1961-1","10.1109/IJCNN.2015.7280620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280620","","Classification algorithms;Niobium;Prediction algorithms;Standards","learning (artificial intelligence);pattern classification;sampling methods","UCI datasets;air pollutant forecasting dataset;data imbalance problems;imbalanced data online sequential classification;machine learning;online sequential extreme learning machine method;pattern recognition;redundant majority samples;sequential SMOTE strategy;synthetic minority oversampling technique;virtual minority samples","","","","14","","","12-17 July 2015","","IEEE","IEEE Conference Publications"
"Comparative study of Principal Component Analysis based Intrusion Detection approach using machine learning algorithms","K. J. Chabathula; C. D. Jaidhar; M. A. Ajay Kumara","Department of IT, NITK Surathkal, Mangalore, India","2015 3rd International Conference on Signal Processing, Communication and Networking (ICSCN)","20150827","2015","","","1","6","This paper induces the prominence of variegated machine learning techniques adapted so far for the identifying different network attacks and suggests a preferable Intrusion Detection System (IDS) with the available system resources while optimizing the speed and accuracy. With booming number of intruders and hackers in todays vast and sophisticated computerized world, it is unceasingly challenging to identify unknown attacks in promising time with no false positive and no false negative. Principal Component Analysis (PCA) curtails the amount of data to be compared by reducing their dimensions prior to classification that results in reduction of detection time. In this paper, PCA is adopted to reduce higher dimension dataset to lower dimension dataset. It is accomplished by converting network packet header fields into a vector then PCA applied over high dimensional dataset to reduce the dimension. The reduced dimension dataset is tested with Support Vector Machines (SVM), K-Nearest Neighbors (KNN), J48 Tree algorithm, Random Forest Tree classification algorithm, Adaboost algorihm, Nearest Neighbors generalized Exemplars algorithm, Navebayes probabilistic classifier and Voting Features Interval classification algorithm. Obtained results demonstrates detection accuracy, computational efficiency with minimal false alarms, less system resources utilization. Experimental results are compared with respect to detection rate and detection time and found that TREE classification algorithms achieved superior results over other algorithms. The whole experiment is conducted by using KDD99 data set.","","CD-ROM:978-1-4673-6822-3; Electronic:978-1-4673-6823-0; POD:978-1-4673-6824-7","10.1109/ICSCN.2015.7219853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219853","Intrusion Detection Systems;Machine Learning Algorithms;Principal Component Analysis","Accuracy;Machine learning algorithms;Mathematical model;Principal component analysis;Signal processing algorithms;Support vector machines;Vegetation","computer crime;learning (artificial intelligence);principal component analysis","Adaboost algorihm;IDS;J48 tree algorithm;KNN;PCA;SVM;hackers;higher dimension dataset;intruders;intrusion detection approach;intrusion detection system;k-nearest neighbors;lower dimension dataset;machine learning algorithms;naive Bayes probabilistic classifier;nearest neighbors generalized exemplars algorithm;network attacks;network packet header;principal component analysis;random forest tree classification algorithm;support vector machines;system resources;voting features interval classification algorithm","","0","","19","","","26-28 March 2015","","IEEE","IEEE Conference Publications"
