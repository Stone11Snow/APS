"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7336538,7475234,7476070,7474362,7474069,7476236,7475160,7476124,7476869,7476075,7474646,7458793,7476683,7474354,7476092,7476638,7475902,7472923,7448389,7472872,7471819,7470808,7472911,7472933,7470774,7473265,7471174,7473231,7471810,7472848,7471286,7470791,7275129,7302557,7450141,7470609,7374673,7137658,7469999,7113889,7469138,7467133,7463770,7463763,7404017,7279156,7358157,7404285,7460390,7459571,7459447,7459885,7150321,7457853,7373532,7458142,7456936,7457151,7456010,7294704,7457438,7456931,7454846,7271021,7454310,7453357,7454506,7453783,7405265,7451799,7451561,7449906,7449857,7449180,7449681,7450524,7449849,7374686,7447961,6917066,7051290,7445391,7445321,7439613,7128730,7444731,7443889,7443981,7443827,7349228,7346456,7444537,7359134,7442393,7438633,7437681,7438504,7437603,7437973,7439486",2017/05/05 21:46:46
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"QuizMonitor: A learning platform that leverages student monitoring","C. Gómez; D. E. Singh; J. Carretero","Computer Science Department, Carlos III University of Madrid, Legan&#233;s, Madrid, Spain","2016 IEEE Global Engineering Education Conference (EDUCON)","20160523","2016","","","808","817","This work presents the design, implementation, and evaluation of a learning platform that addresses two main objectives: first it provides and on-line quiz tool for students which can be used as a complementary learning approach to the classroom courses. Secondly, this tool performs a detailed analysis of learners use, considering not only the number of mistakes students have made but also the student temporal use distribution and opinion (obtained by a survey) about the difficulty of the learning contents. All this information is processed and used to provide feedback to the teachers identifying the most difficult contents of the area of study and the students with a low learning performance. We have developed and evaluated this tool in two university degree subjects. The obtained results are promising, showing that students can improve their final grades through its use and that teachers can identify the student learning problems, in order to assess where students may require more support or challenge. In addition, we analyze the impact of different metrics obtained by this tool (academic performance, intensity of study and student proactivity) in the final subject grades.","","Electronic:978-1-4673-8633-3; POD:978-1-4673-8634-0","10.1109/EDUCON.2016.7474646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474646","e-learning;learning analytic;machine learning;student academic performance","Browsers;Computer architecture;Computer science;Databases;Measurement;Monitoring;Standards","computer science education","QuizMonitor;classroom courses;complementary learning approach;learning platform;student temporal use distribution","","","","14","","","10-13 April 2016","","IEEE","IEEE Conference Publications"
"No-reference video quality assessment by HEVC codec analysis","X. Huang; J. S⊘gaard; S. Forchhammer","DTU Fotonik, Technical University of Denmark, &#8856;rsteds Plads 343, Kgs. Lyngby, Denmark","2015 Visual Communications and Image Processing (VCIP)","20160425","2015","","","1","4","This paper proposes a No-Reference (NR) Video Quality Assessment (VQA) method for videos subject to the distortion given by High Efficiency Video Coding (HEVC). The proposed assessment can be performed either as a Bitstream-Based (BB) method or as a Pixel-Based (PB). It extracts or estimates the transform coefficients, estimates the distortion, and assesses the video quality. The proposed scheme generates VQA features based on Intra coded frames, and then maps features using an Elastic Net to predict subjective video quality. A set of HEVC coded 4K UHD sequences are tested. Results show that the quality scores computed by the proposed method are highly correlated with the subjective assessment.","","Electronic:978-1-4673-7314-2; POD:978-1-4673-7315-9; USB:978-1-4673-7313-5","10.1109/VCIP.2015.7457853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457853","Elastic Net;HEVC analysis;Machine Learning;No-Reference;Video Quality Assessment","","video codecs;video coding","HEVC codec analysis;bitstream-based method;high efficiency video coding;no-reference video quality assessment;pixel-based method;transform coefficients","","2","","16","","","13-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"BAT-ELM: A bio inspired model for prediction of breast cancer data","Doreswamy; M. U. Salma","Department of Computer Science, Mangalore University, Mangalagangothri, Mangalore 574199","2015 International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)","20160421","2015","","","501","506","Medical informatics mainly deals with finding solutions for the issues related to the diagnosis and prognosis of various deadly diseases using machine learning and data mining approaches. One such disease is breast cancer, killing millions of people, especially women. In this paper we propose a bio inspired model called BATELM which is a combination of Bat algorithm (BAT) and Extreme Learning Machines (ELM) which is first of its kind in the study of non image breast cancer data analysis. The concept of BAT and ELM which has many advantages when compared to the existing algorithms of their genre have motivated us to build a model that can predict the medical data with high accuracy and minimal error. Here we make use of BAT to optimize the parameters of ELM so that the prediction task is carried out efficiently. The main aim of ELM is to predict the data with minimum error. For attaining a minimal error we have tested Wisconsin Breast Cancer Prognostic (WBCP) dataset upon three different learning functions (sigmoid, sin and tanh) and the function which produces the best result has been considered as the final. We carried out two case studies to support our model. In case study I the objective was to predict whether the breast cancer is recurrent or non-recurrent. The accuracy obtained for this case is found to be 95.7% with an RMSE of 0.32. In case study II our objective was to predict the time of recurrence, the result obtained for this case were found to be 93.75% accurate with an RMSE of 0.30. In both the cases tanh function performed better.","","Electronic:978-1-4673-9223-5; POD:978-1-4673-9224-2; USB:978-1-4673-9222-8","10.1109/ICATCCT.2015.7456936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456936","Bat Algorithm;Breast Cancer;Data Mining;Extreme Learning Machines;Prediction","Biological neural networks;Biomedical imaging;Breast cancer;Correlation;Data mining;Data models;Mathematical model","cancer;data mining;learning (artificial intelligence);mean square error methods;medical diagnostic computing","BAT-ELM;Bat algorithm;RMSE;WBCP dataset;Wisconsin breast cancer prognostic;bioinspired model;breast cancer data;data mining;disease diagnosis;disease prognosis;extreme learning machine;machine learning;medical informatics","","","","25","","","29-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"Opinion mining using Naïve Bayes","K. M. A. Hasan; M. S. Sabuj; Z. Afrin","Dept. of Computer Science and Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh","2015 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE)","20160331","2015","","","511","514","The opinion of other person is an important information for decision making. People share useful information to others as the growth of social media through Internet. This information is used to organize, explore and analyze for better decision making. Opinion Mining is a Natural Language Processing task which aims to determine the attitude of a person by identifying and extracting information. The major task in opinion mining is to classify the polarity of a review at sentence level, whether the expressed opinion is positive or negative. In this paper, we design a classifier using Naïve Bayes as a machine learning approach to determine the opinion expressed both in English and Bangla. We label the polarity of each opinion as weak, steady and strong. The performances are evaluated and the comparative results are analyzed.","","DVD:978-1-4673-8785-9; Electronic:978-1-4673-8786-6; POD:978-1-4673-8787-3","10.1109/WIECON-ECE.2015.7443981","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443981","Naïve Bayes;document probability;machine learning;opinion mining;sentiment detection;text classifier","Data mining;Dictionaries;Google;Sentiment analysis;Testing;Thumb;Training","data mining;learning (artificial intelligence);social sciences computing","Bangla language;English language;decision making;information extraction;information identification;information sharing;internet;machine learning approach;naive Bayes;natural language processing task;opinion mining;social media","","","","14","","","19-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"An intelligent vision system for monitoring security and surveillance of ATM","S. Ray; S. Das; A. Sen","Dept. of Electronics & Communication, Heritage Institute of Technology, Kolkata, India","2015 Annual IEEE India Conference (INDICON)","20160331","2015","","","1","5","This paper presents an automated system to increase the security and surveillance of ATM kiosks. Due to the increase of robbery in ATM kiosks, it is important to employ an automated surveillance system to protect and secure the ATM machine from threats. Currently, a camera attached with the ATM unit, records and transmits the video feed to the main server of the bank. Around the clock, this manual surveillance utilizes a lot of bandwidth for transmission. There is waste of memory and late response to emergency situation. Consequently, early detection of the situation is necessary to take preventive measures against an ongoing burglary. In this paper it is possible to detect whether a person is wearing a mask or not. The proposed system is also capable of counting the number of people present inside the ATM kiosk and generate a warning signal, thereby removes a constant human supervision, reducing the storage of unnecessary video feed and transmitting only an anomalous situation, a faster response to a threat by shutting down the ATM machine as soon the system detects the threat.","","Electronic:978-1-4673-7399-9; POD:978-1-4673-7400-2","10.1109/INDICON.2015.7443827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443827","Viola-Jones Algorithm;computer vision;image processing algorithm;machine learning;surveillance","Face;Feeds;Manuals;Online banking;Robustness;Security;Surveillance","automatic teller machines;banking;computer vision;object detection;video cameras;video surveillance","ATM kiosks;ATM machine;automated surveillance system;bank;camera;constant human supervision removal;emergency situation;intelligent vision system;security monitoring;surveillance monitoring;video feed;warning signal generation","","","","13","","","17-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"SpinSafe: An unsupervised smartphone-based wheelchair path monitoring system","F. Seraj; P. J. M. Havinga; N. Meratnia","Pervasive Systems Research Group, Faculty of EEMCS, University of Twente, Enschede, 7500EA NL","2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)","20160421","2016","","","1","6","Movement and social life of wheelchair users are constrained by their disability and suitability of paths they can move on. Modern electric wheelchairs offer them assisted drive, making their movement easier and longer. They, however, do not prevent accidents, injuries, and inconveniences caused by path roughness and ramp slopes. Providing information about suitability and accessibility of paths and buildings for wheelchair users will enable them to beforehand plan their trip to not to be caught by surprises or not to take a trip all together. The recent emergence of smartphones equipped with inertial sensors offers new opportunities for provision of information regarding quality and accessibility of paths and buildings for wheelchair users. To this end, we propose a smartphone-based participatory system incorporating a hybrid unsupervised machine learning technique based on Self Organized Maps (SOM) to identify path conditions and to create clusters of similar path types. Our solution provides useful information about the angle of the ramp and curb slopes as well as pavement quality and roughness and path types.","","Electronic:978-1-5090-1941-0; POD:978-1-5090-1942-7","10.1109/PERCOMW.2016.7457151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457151","Unsupervised machine learning;anomaly detection;data analysis;signal processing;visualization;wavelet decomposition","Accelerometers;Neurons;Sensors;Smart phones;Vibrations;Wheelchairs;Wheels","accidents;computerised monitoring;data visualisation;handicapped aids;injuries;mobile computing;self-organising feature maps;unsupervised learning;wheelchairs","SpinSafe;accidents;assisted drive;curb slopes;hybrid unsupervised machine learning technique;inertial sensors;injuries;modern electric wheelchairs;path accessibility;path roughness;path suitability;pavement quality;ramp slopes;self organized maps;smartphone-based participatory system;unsupervised smartphone-based wheelchair path monitoring system","","","","12","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"PAT: A power-aware decision tree algorithm for mobile activity recognition","L. G. Jaimes; Y. De La Hoz; C. Eggert; I. J. Vergara-Laurens","College of Science, Engineering, and Mathematics, Bethune-Cookman University, Daytona-Beach, FL, United States","2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC)","20160331","2016","","","54","59","Mobile context recognition attempts to infer the context of a mobile phone user. Machine learning algorithms exhibit high classification accuracy in these applications. Most approaches are very power-inefficient because they record data from all sensors at all time. Intelligently cycling sensors could greatly improve the power efficiency of context recognition services. We propose a decision tree-based machine learning algorithm which optimizes not only on classification accuracy, but also on data retrieval costs based on power efficiency. We show that in a simple physical activity recognition application, the use of this new algorithm results in a significant decrease in power consumption while maintaining a high classification accuracy.","","Electronic:978-1-4673-9292-1; POD:978-1-4673-9293-8","10.1109/CCNC.2016.7444731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444731","Human activity recognition;machine learning","Context;Decision trees;Medical services;Power demand;Sensor phenomena and characterization;Testing","decision trees;learning (artificial intelligence);mobile radio;power consumption;telecommunication power management","PAT;context recognition services;cycling sensors;data retrieval costs;machine learning;mobile activity recognition;mobile context recognition;mobile phone user;power consumption;power-aware decision tree algorithm;simple physical activity recognition","","","","12","","","9-12 Jan. 2016","","IEEE","IEEE Conference Publications"
"Deep 3D Convolutional Encoder Networks With Shortcuts for Multiscale Feature Integration Applied to Multiple Sclerosis Lesion Segmentation","T. Brosch; L. Y. W. Tang; Y. Yoo; D. K. B. Li; A. Traboulsee; R. Tam","Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, The University of British Columbia, Vancouver, Canada","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1229","1239","We propose a novel segmentation approach based on deep 3D convolutional encoder networks with shortcut connections and apply it to the segmentation of multiple sclerosis (MS) lesions in magnetic resonance images. Our model is a neural network that consists of two interconnected pathways, a convolutional pathway, which learns increasingly more abstract and higher-level image features, and a deconvolutional pathway, which predicts the final segmentation at the voxel level. The joint training of the feature extraction and prediction pathways allows for the automatic learning of features at different scales that are optimized for accuracy for any given combination of image types and segmentation task. In addition, shortcut connections between the two pathways allow high- and low-level features to be integrated, which enables the segmentation of lesions across a wide range of sizes. We have evaluated our method on two publicly available data sets (MICCAI 2008 and ISBI 2015 challenges) with the results showing that our method performs comparably to the top-ranked state-of-the-art methods, even when only relatively small data sets are available for training. In addition, we have compared our method with five freely available and widely used MS lesion segmentation methods (EMS, LST-LPA, LST-LGA, Lesion-TOADS, and SLS) on a large data set from an MS clinical trial. The results show that our method consistently outperforms these other methods across a wide range of lesion sizes.","0278-0062;02780062","","10.1109/TMI.2016.2528821","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404285","Convolutional neural networks;deep learning;machine learning;magnetic resonance imaging (MRI);multiple sclerosis lesions;segmentation","Convolution;Feature extraction;Image segmentation;Imaging;Lesions;Neural networks;Training","biomedical MRI;feature extraction;image segmentation;medical image processing;neural nets","EMS;ISBI 2015 challenges;LST-LGA;LST-LPA;Lesion-TOADS;MICCAI 2008 challenges;MS clinical trial;MS lesion segmentation methods;SLS;automatic feature learning;convolutional pathway;deconvolutional pathway;deep 3D convolutional encoder networks;feature extraction;higher-level image features;interconnected pathways;low-level features;magnetic resonance images;multiple sclerosis lesion segmentation;multiscale feature integration;neural network;prediction pathways;publicly available data sets;segmentation task;shortcut connections;top-ranked state-of-the-art methods;voxel level","","10","","47","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Integrating Internet-of-Things with the power of Cloud Computing and the intelligence of Big Data analytics — A three layered approach","M. T. Khorshed; N. A. Sharma; K. Kumar; M. Prasad; A. B. M. S. Ali; Y. Xiang","School of Information Technology, Deakin University, Australia","2015 2nd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE)","20160523","2015","","","1","8","This paper is written through the vision on integrating Internet-of-Things (IoT) with the power of Cloud Computing and the intelligence of Big Data analytics. But integration of all these three cutting edge technologies is complex to understand. In this research we first provide a security centric view of three layered approach for understanding the technology, gaps and security issues. Then with a series of lab experiments on different hardware, we have collected performance data from all these three layers, combined these data together and finally applied modern machine learning algorithms to distinguish 18 different activities and cyber-attacks. From our experiments we find classification algorithm RandomForest can identify 93.9% attacks and activities in this complex environment. From the existing literature, no one has ever attempted similar experiment for cyber-attack detection for IoT neither with performance data nor with a three layered approach.","","Electronic:978-1-5090-0713-4; POD:978-1-5090-0714-1","10.1109/APWCCSE.2015.7476124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476124","Big Data;Cloud Computing;Cyber-attack;Hadoop;Internet of Things;IoT;Machine Learning;Network Security","Big data;Cloud computing;Decision support systems;Handheld computers;Hardware;Internet of things;Security","Big Data;Internet of Things;cloud computing;learning (artificial intelligence);pattern classification;random processes;security of data","Internet-of-Things;IoT;big data analytics;classification algorithm;cloud computing;cyber-attack detection;machine learning algorithm;random forest;security centric view","","","","37","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"GLAsT: Learning formal grammars to translate natural language specifications into hardware assertions","C. B. Harris; I. G. Harris","Dept. of Electrical Engineering and Computer Science, University of California - Irvine, USA","2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)","20160428","2016","","","966","971","The purpose of functional verification is to ensure that a design conforms to its specification. However, large written specifications can contain hundreds of statements describing correct operation which an engineer must use to create sets of correctness properties. This laborious manual process increases both verification time and cost. In this work we present GLAsT, a new learning algorithm which accepts a small set of sentences describing correctness properties and corresponding SystemVerilog Assertions (SVAs). GLAsT creates a custom formal grammar which captures the writing style and sentence structure of a specification and facilitates the automatic translation of English specification sentences into formal SystemVerilog Assertions. We evaluate GLAsT on English sentences from two ARM AMBA bus protocols. Results show that a translation system using the formal grammar generated by GLAsT automatically generates correctly formed SVAs from the targeted AMBA specification as well as from a second, different AMBA bus specification.","","Electronic:978-3-9815-3707-9; POD:978-1-4673-9228-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459447","hardware design;machine learning;natural language processing;verification","Algorithm design and analysis;Grammar;Hardware;Inference algorithms;Natural languages;Production;Semantics","formal specification;formal verification;grammars;hardware description languages;language translation;learning (artificial intelligence);natural language processing","GLAsT learning algorithm;SVA;SystemVerilog assertion;formal grammar;functional verification;natural language specification translation;sentence structure;writing style","","","","23","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Opinion mining from student feedback data using supervised learning algorithms","V. Dhanalakshmi; D. Bino; A. M. Saravanan","Department of Computing, Middle East College, Muscat, Oman","2016 3rd MEC International Conference on Big Data and Smart City (ICBDSC)","20160428","2016","","","1","5","This paper explores opinion mining using supervised learning algorithms to find the polarity of the student feedback based on pre-defined features of teaching and learning. The study conducted involves the application of a combination of machine learning and natural language processing techniques on student feedback data gathered from module evaluation survey results of Middle East College, Oman. In addition to providing a step by step explanation of the process of implementation of opinion mining from student comments using the open source data analytics tool Rapid Miner, this paper also presents a comparative performance study of the algorithms like SVM, Naïve Bayes, K Nearest Neighbor and Neural Network classifier. The data set extracted from the survey is subjected to data preprocessing which is then used to train the algorithms for binomial classification. The trained models are also capable of predicting the polarity of the student comments based on extracted features like examination, teaching etc. The results are compared to find the better performance with respect to various evaluation criteria for the different algorithms.","","Electronic:978-1-4673-9584-7; POD:978-1-4673-9585-4","10.1109/ICBDSC.2016.7460390","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460390","Learning Analytics;Machine Learning;Natural Language Processing;Opinion mining;Rapid Miner;Sentiment analysis;Supervised learning;Text Analytics","Classification algorithms;Data mining;Education;Feature extraction;Niobium;Supervised learning;Support vector machines","Bayes methods;data mining;learning (artificial intelligence);natural language processing;neural nets;pattern classification;public domain software;support vector machines","Naïve Bayes;Rapid Miner open source data analytics tool;SVM;binomial classification;data preprocessing;k nearest neighbor;machine learning;natural language processing techniques;neural network classifier;opinion mining;student feedback data;supervised learning algorithms;teaching","","","","23","","","15-16 March 2016","","IEEE","IEEE Conference Publications"
"RedEye: Preventing Collisions Caused by Red-Light Running Scooters With Smartphones","K. S. Huang; P. J. Chiu; H. M. Tsai; C. C. Kuo; H. Y. Lee; Y. C. F. Wang","Department of Computer Science and Information Engineering, College of Electrical Engineering and Computer Science, National Taiwan University, Taipei","IEEE Transactions on Intelligent Transportation Systems","20160429","2016","17","5","1243","1257","In this paper, we present a scooter collision avoidance system that can identify red-light runners (RLRs) at intersections. When the RLR behavior is detected, the system would advise the RLR to slow down immediately and warn nearby vehicles on the intersecting road in real time. In particular, we do not consider infrastructure-based solutions such as those utilizing a radar or a camera. This is because, in addition to high implementation costs, collisions can be only avoided at intersections where such infrastructure configurations are deployed. Instead, we advance an on-scooter solution using smartphones carried by scooter riders. Smartphones provide a useful platform that has a high penetration rate, more than sufficient computational power, inertial sensors to reflect the driving behavior, and the communication capability to transmit or receive information from other vehicles. In our system, we utilize a support vector machine and design an RLR classifier for learning and predicting RLR behaviors. The evaluation results show that our system is able to achieve over 70% recognition rates when distinguishing between RLR and non-RLR cases, as compared with approximately 80% recognition rates of the infrastructure-based (and higher cost) solution using a laser range finder (LADAR).","1524-9050;15249050","","10.1109/TITS.2015.2502142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358157","Machine learning;collision avoidance;motorcycle;red-light runner;scooter","Accidents;Motorcycles;Roads;Safety;Sensors;Smart phones","collision avoidance;mobile computing;motorcycles;support vector machines;traffic engineering computing","RLR classifier;RedEye;collision prevention;driving behavior;intersecting road;on-scooter solution;red-light runners;red-light running scooters;scooter collision avoidance system;smartphones;support vector machine","","1","","44","","20151217","May 2016","","IEEE","IEEE Journals & Magazines"
"Toward better keywords extraction","Shihua Xu; Fang Kong","School of Computer Science & Technology, Soochow university, Suzhou, Jiangsu Province, China","2015 International Conference on Asian Language Processing (IALP)","20160414","2015","","","181","184","Automatic keyword extraction is the task to identify a small set of keywords from a given document that can describe the meaning of the document. It plays an important role in information retrieval. In this paper, a clustering-based approach to do this task is proposed. And the impacts of keyword length, the window size of centroid on the performance of AKE system are discussed. Then by introducing keyword length constraint and extending the number of centroid of every cluster, the performance of our AKE system is improved by 7.5% in F-score.","","CD-ROM:978-1-4673-9594-6; Electronic:978-1-4673-9596-0; POD:978-1-4673-9597-7","10.1109/IALP.2015.7451561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451561","Affinity propagation clustering;Keywords extraction;Machine learning","Sun","information retrieval;pattern clustering","AKE system;automatic keyword extraction;centroid;clustering-based approach;information retrieval;keyword length constraint","","","","14","","","24-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"Meta-learning within Projective Simulation","A. Makmal; A. A. Melnikov; V. Dunjko; H. J. Briegel","Institute for Theoretical Physics, University of Innsbruck, Innsbruck, Austria","IEEE Access","20160523","2016","4","","2110","2122","Learning models of artificial intelligence can nowadays perform very well on a large variety of tasks. However, in practice, different task environments are best handled by different learning models, rather than a single universal approach. Most non-trivial models thus require the adjustment of several to many learning parameters, which is often done on a case-by-case basis by an external party. Meta-learning refers to the ability of an agent to autonomously and dynamically adjust its own learning parameters or meta-parameters. In this paper, we show how projective simulation, a recently developed model of artificial intelligence, can naturally be extended to account for meta-learning in reinforcement learning settings. The projective simulation approach is based on a random walk process over a network of clips. The suggested meta-learning scheme builds upon the same design and employs clip networks to monitor the agent's performance and to adjust its meta-parameters on the fly. We distinguish between reflex-type adaptation and adaptation through learning, and show the utility of both approaches. In addition, a trade-off between flexibility and learning-time is addressed. The extended model is examined on three different kinds of reinforcement learning tasks, in which the agent has different optimal values of the meta-parameters, and is shown to perform well, reaching near-optimal to optimal success rates in all of them, without ever needing to manually adjust any meta-parameter.","2169-3536;21693536","","10.1109/ACCESS.2016.2556579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458793","Machine learning;adaptive algorithm;learning;meta-learning;quantum mechanics;random processes;reinforcement learning","Adaptation models;Context modeling;Electronic countermeasures;Learning (artificial intelligence);Optimization;Supervised learning","learning (artificial intelligence);multi-agent systems","agent performance;artificial intelligence;clip networks;learning models;learning parameters;meta-learning scheme;projective simulation approach;random walk process;reflex-type adaptation;reinforcement learning","","1","","49","","20160425","2016","","IEEE","IEEE Journals & Magazines"
"Intelligent online sensor monitoring and fault alarm system in heating ventilation and air conditioning systems","Y. Guo; J. Wall; J. Li; S. West","Digital Productivity Flagship, The Commonwealth Scientific and Industrial Research Organisation, Marsfield, NSW 2122, Australia","2015 9th International Conference on Sensing Technology (ICST)","20160324","2015","","","789","794","The heating, ventilation, and air conditioning (HVAC) system is designed to provide thermal comfort and acceptable indoor air quality. A variety of sensing devices (such as temperature, humidity, velocity, or pressure sensors) are installed in the HVAC systems. In a realistic situation, the HVAC system can fail to satisfy performance expectations envisioned because of a variety of problems. This paper presents online sensor monitoring and fault detection techniques, as well as the key sensor sets selection approach to optimise the fault detection results. The methodology presented is also implemented in commercial buildings and experimental results show that different types of faults are detected successfully.","","Electronic:978-1-4799-6314-0; POD:978-1-4799-6315-7","10.1109/ICSensT.2015.7438504","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438504","HVAC system;energy;fault alarm;fault detection;machine learning;sensor monitoring","Buildings;Fault detection;Hidden Markov models;Monitoring;Temperature sensors;Training","HVAC;alarm systems;fault diagnosis;intelligent sensors","HVAC systems;air conditioning systems;fault alarm system;fault detection techniques;heating ventilation;intelligent online sensor monitoring","","","","16","","","8-10 Dec. 2015","","IEEE","IEEE Conference Publications"
"Topic Modelling for Songs","N. Laitonjam; V. Padmanabhan; A. K. Pujari; R. P. Lal","Sch. of Comput. & Inf. Sci., Univ. of Hyderabad, Hyderabad, India","2015 International Conference on Information Technology (ICIT)","20160324","2015","","","130","135","Topic Modeling has been a useful tool for finding abstract topics (which are collections of words) governing a collection of documents. Each document is then expressed as a collection of generated topics. The most basic topic model is Latent Dirichlet Allocation (LDA). In this paper, we have developed Gibbs Sampling algorithm for Hierarchical Latent Dirichlet Allocation (HLDA) by incorporating time into our topic model. We call our model Hierarchical Latent Dirichlet Allocation with Topic Over Time (HLDA-TOT). We find topics for a collection of songs taken during the period 1990 to 2010. The dataset we used is taken from the Million Songs Dataset (MSD) consisting of a collection of 1000 songs. We have used Gibbs Sampling algorithm for inference in both HLDA and HLDA-TOT. Our experimental results demonstrates a comparison in the performances of HLDA and HLDA-TOT and it is shown that HLDA-TOT performs better in terms of 1) Number of topics generated for different depths 2) Number of empty topics generated for different depths and 3) held-out log likelihood for different depths.","","Electronic:978-1-5090-0487-4; POD:978-1-5090-0488-1","10.1109/ICIT.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437603","Graphical models;Machine Learning;Topic Modelling","Computational modeling;Graphical models;Inference algorithms;Information technology;Probabilistic logic;Resource management;Semantics","Markov processes;Monte Carlo methods;document handling;music;natural language processing","Gibbs sampling algorithm;HLDA-TOT;MSD;Million Songs Dataset;abstract topics;document collection;empty topic number;held-out log likelihood;hierarchical latent Dirichlet allocation;topic modelling;topic over time;word collection","","","","13","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Perfect error compensation via algorithmic error cancellation","S. K. Gonugondla; B. Shim; N. R. Shanbhag","Dept. of Electrical and Computer Engineering, University of Illinois at Urbana Champaign","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","966","970","This paper presents a novel statistical error compensation (SEC) technique - algorithmic error cancellation (AEC)-for designing robust and energy-efficient signal processing and machine learning kernels on scaled process technologies. AEC exhibits a perfect error compensation (PEC) property, i.e., it is able to achieve a post-compensation error rate equal to zero. AEC generates a maximum likelihood (ML) estimate of the hardware error and employs it for error cancellation. AEC is applied to a voltage overscaled 45-tap, 45nm CMOS finite impulse response (FIR) filter employed in a EEG seizure detection system. AEC is shown to perfectly compensate for errors in the main FIR block and its reduced precision replica when they make errors at a rate of up to 73% and 98%, respectively. The AEC-based FIR is compared with an uncompensated architecture, and a fast architecture. AEC's error compensation capability enables it to achieve a 31.5% (at same supply voltage) and 19.7% (at same energy) speed-up over the uncompensated architecture, and a 8. 9% speed-up over a fast architecture at the same energy consumption. At fd, k = 452.3 MHz, AEC results in a 27.7% and 12.4% energy savings over the uncompensated and fast architectures, respectively.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471819","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471819","biomedical;energy efficiency;error resiliency;low-power;machine learning","Computer architecture;Delays;Error analysis;Error compensation;Finite impulse response filters;Kernel;Signal processing algorithms","CMOS integrated circuits;FIR filters;electroencephalography;error compensation;learning (artificial intelligence);maximum likelihood estimation;medical signal processing;power consumption","AEC;CMOS finite impulse response filter;EEG seizure detection system;FIR filter;SEC;algorithmic error cancellation;energy consumption;frequency 452.3 MHz;hardware error;machine learning kernels;maximum likelihood estimate;perfect error compensation;scaled process technology;signal processing;size 45 nm;statistical error compensation;voltage overscale","","1","","","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"DCCC-MAC: A Dynamic Common-Control-Channel-Based MAC Protocol for Cellular Cognitive Radio Networks","K. G. M. Thilina; E. Hossain; D. I. Kim","Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, MB, Canada","IEEE Transactions on Vehicular Technology","20160512","2016","65","5","3597","3613","We propose a novel dynamic common-control-channel-based medium access control (DCCC-MAC) protocol for cellular (centralized) cognitive radio (CR) networks. Specifically, unlike the traditional dedicated-control-channel-based medium access control (MAC) protocols, the proposed MAC protocol eliminates the requirement of a dedicated channel for control information exchange. During a given transmission frame, the common control channel (CCC) is selected by a cooperating set of secondary users (SUs) by using a support-vector-machine (SVM)-based learning technique. In the DCCC-MAC protocol, the frame duration is divided into four main phases as follows: spectrum sensing, CCC selection, data transmission, and beaconing. The SUs that participate in the CCC selection process are allocated channels for data transmission during a frame interval using a scheduling process, whereas the other SUs have to contend to access the channels. We present an analytical approach to calculate the minimum required number of minislots in the transmission frame for a given number of SUs in the CCC selection process. The saturation throughput of the proposed MAC protocol is analyzed in closed form. To this end, the numerical and simulation results are presented to quantify the performance of the proposed DCCC-MAC protocol. We also compare the performance of the DCCC-MAC protocol with that of two other state-of-the-art CR MAC protocols that use CCCs.","0018-9545;00189545","","10.1109/TVT.2015.2438058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113889","Cognitive radio network (CRN);common control channel (CCC);machine learning;medium access control (MAC);support vector machine (SVM)","Cognitive radio;Data communication;Media Access Protocol;Sensors;Support vector machines;Vehicle dynamics","access protocols;cellular radio;cognitive radio;learning (artificial intelligence);support vector machines","CCC selection;DCCC-MAC protocol;cellular cognitive radio networks;common control channel;data transmission;frame interval;novel dynamic common-control-channel-based MAC protocol;secondary users;spectrum sensing;support-vector-machine based learning technique","","3","","35","","20150601","May 2016","","IEEE","IEEE Journals & Magazines"
"Human Visual System-Based Fundus Image Quality Assessment of Portable Fundus Camera Photographs","S. Wang; K. Jin; H. Lu; C. Cheng; J. Ye; D. Qian","Institute of VLSI Design, Zhejiang University, Hangzhou, China","IEEE Transactions on Medical Imaging","20160331","2016","35","4","1046","1055","Telemedicine and the medical “big data” era in ophthalmology highlight the use of non-mydriatic ocular fundus photography, which has given rise to indispensable applications of portable fundus cameras. However, in the case of portable fundus photography, non-mydriatic image quality is more vulnerable to distortions, such as uneven illumination, color distortion, blur, and low contrast. Such distortions are called generic quality distortions. This paper proposes an algorithm capable of selecting images of fair generic quality that would be especially useful to assist inexperienced individuals in collecting meaningful and interpretable data with consistency. The algorithm is based on three characteristics of the human visual system-multi-channel sensation, just noticeable blur, and the contrast sensitivity function to detect illumination and color distortion, blur, and low contrast distortion, respectively. A total of 536 retinal images, 280 from proprietary databases and 256 from public databases, were graded independently by one senior and two junior ophthalmologists, such that three partial measures of quality and generic overall quality were classified into two categories. Binary classification was implemented by the support vector machine and the decision tree, and receiver operating characteristic (ROC) curves were obtained and plotted to analyze the performance of the proposed algorithm. The experimental results revealed that the generic overall quality classification achieved a sensitivity of 87.45% at a specificity of 91.66%, with an area under the ROC curve of 0.9452, indicating the value of applying the algorithm, which is based on the human vision system, to assess the image quality of non-mydriatic photography, especially for low-cost ophthalmological telemedicine applications.","0278-0062;02780062","","10.1109/TMI.2015.2506902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349228","Human visual system;machine learning;portable fundus photography;quality assessment","Biomedical imaging;Cameras;Distortion;Image quality;Lighting;Photography;Retina","biomedical optical imaging;decision trees;eye;medical image processing;photography;sensitivity analysis;support vector machines;telemedicine","ROC curve;decision tree;fundus image quality assessment;human visual system;low-cost ophthalmological telemedicine applications;portable fundus camera photographs;receiver operating characteristic curves;support vector machine","","","","35","","20151208","April 2016","","IEEE","IEEE Journals & Magazines"
"Contextual Atlas Regression Forests: Multiple-Atlas-Based Automated Dose Prediction in Radiation Therapy","C. McIntosh; T. G. Purdie","Radiation Medicine Program at the Princess Margaret Cancer Centre, University Health Network (UHN), Toronto, Canada","IEEE Transactions on Medical Imaging","20160331","2016","35","4","1000","1012","Radiation therapy is an integral part of cancer treatment, but to date it remains highly manual. Plans are created through optimization of dose volume objectives that specify intent to minimize, maximize, or achieve a prescribed dose level to clinical targets and organs. Optimization is NP-hard, requiring highly iterative and manual initialization procedures. We present a proof-of-concept for a method to automatically infer the radiation dose directly from the patient's treatment planning image based on a database of previous patients with corresponding clinical treatment plans. Our method uses regression forests augmented with density estimation over the most informative features to learn an automatic atlas-selection metric that is tailored to dose prediction. We validate our approach on 276 patients from 3 clinical treatment plan sites (whole breast, breast cavity, and prostate), with an overall dose prediction accuracies of 78.68%, 64.76%, 86.83% under the Gamma metric.","0278-0062;02780062","","10.1109/TMI.2015.2505188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346456","Radiation therapy;atlas selection;decision forests;machine learning;multi-atlas based segmentation;random forests","Breast;Cancer;Cavity resonators;Lungs;Manifolds;Optimization;Planning","biological organs;cancer;computerised tomography;dosimetry;feature selection;image segmentation;iterative methods;medical image processing;optimisation;radiation therapy;regression analysis;tumours","Gamma metric;NP-hard optimization;automatic atlas-selection metric;breast cavity;cancer treatment;clinical targets;clinical treatment plan sites;clinical treatment plans;computerised tomography;contextual atlas regression forests;database;density estimation;dose prediction;dose volume optimization;informative features;iterative initialization procedures;manual initialization procedures;multiple-atlas-based automated dose prediction;organs;overall dose prediction accuracies;patient treatment planning image;prescribed dose level;prostate;radiation therapy;regression forest augmentation","","2","","46","","20151203","April 2016","","IEEE","IEEE Journals & Magazines"
"Movement Primitive Segmentation for Human Motion Modeling: A Framework for Analysis","J. F. S. Lin; M. Karg; D. Kulić","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Human-Machine Systems","20160513","2016","46","3","325","339","Movement primitive segmentation enables long sequences of human movement observation data to be segmented into smaller components, termed movement primitives, to facilitate movement identification, modeling, and learning. It has been applied to exercise monitoring, gesture recognition, human-machine interaction, and robot imitation learning. This paper proposes a segmentation framework to categorize and compare different segmentation algorithms considering segment definitions, data sources, application-specific requirements, algorithm mechanics, and validation techniques. The framework is applied to human motion segmentation methods by grouping them into online, semionline, and offline approaches. Among the online approaches, distance-based methods provide the best performance, while stochastic dynamic models work best in the semionline and offline settings. However, most algorithms to date are tested with small datasets, and algorithm generalization across participants and to movement changes remains largely untested.","2168-2291;21682291","","10.1109/THMS.2015.2493536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374673","Algorithm design and analysis;classification algorithms;machine learning algorithms;physiology;time series analysis","Algorithm design and analysis;Cameras;Data collection;Databases;Image segmentation;Manuals;Motion segmentation","image motion analysis;image segmentation","algorithm mechanics;application-specific requirements;data sources;distance-based methods;exercise monitoring;gesture recognition;human motion modeling;human movement observation data sequences;human-machine interaction;movement identification;movement learning;movement modeling;movement primitive segmentation;robot imitation learning;segment definitions;segmentation algorithms;stochastic dynamic models;validation techniques","","4","","121","","20160107","June 2016","","IEEE","IEEE Journals & Magazines"
"Dynamic student assessment to advocate personalized learning plan","A. S. Shminan; M. K. Othman","Faculty of Cognitive Science and Human Development, University Malaysia Sarawak, 94300 Kota Samarahan, Malaysia","2015 International Conference on Information Technology Systems and Innovation (ICITSI)","20160324","2015","","","1","6","A central challenge in education is to match instruction to the characteristics and learning styles of students in order to optimize learning. In this article, we intend to outline our approach to supporting personalized learning strategies by constructing dynamical student profiling using ubiquitous computing capability. This profiling includes recorded data on students' affective responses to learning to discern students' level of motivation and details from generic student profiles to describe and predict student learning patterns. Learning pattern data analysis derives conclusions using decision trees. Through this process, information can be extracted from students' affective responses and students' profile data and relevant correlations between the two data sets can be recognized automatically. A personalized learning component uses this information to offer proactive support to students. This is achieved by recommending personalized courses of action which are beneficial to students. Our proposed model has been tested in a classroom simulation. Issues of sample limitations and promising directions for future research are elaborated towards the end of this paper.","","Electronic:978-1-4673-6664-9; POD:978-1-4673-6665-6","10.1109/ICITSI.2015.7437681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437681","decision tree;machine learning;personalized learning;student profiling","Analytical models;Context;Data analysis;Data mining;Data models;Decision trees;Education","data analysis;decision trees;digital simulation;educational administrative data processing;learning (artificial intelligence);ubiquitous computing","classroom simulation;decision tree;dynamic student assessment;dynamical student profiling;learning pattern data analysis;machine learning;personalized learning strategy;student learning pattern prediction;ubiquitous computing","","","","19","","","16-19 Nov. 2015","","IEEE","IEEE Conference Publications"
"Tree-based data aggregation approach in wireless sensor network using fitting functions","I. Atoui; A. Ahmad; M. Medlej; A. Makhoul; S. Tawbe; A. Hijazi","University of Franche-Comt&#233;, 19 Av. Mar&#233;chal Juin, 90000 Belfort, France","2016 Sixth International Conference on Digital Information Processing and Communications (ICDIPC)","20160519","2016","","","146","150","Sensor networks are a collection of sensor nodes that co-operatively transmit sensed data to a base station. One of the well-known characteristics of Wireless Sensor Networks (WSN) is its limited resources. Energy consumption of the network's nodes is considered one of the major challenges faced by researchers nowadays. On the other hand, data aggregation helps in reducing the redundant data transferred through the WSN. This fact implies that aggregation of data is considered a very crucial technique for reducing the energy consumption across the WSN. Local aggregation and Prefix filtering are two methods used in which they utilize a tree based bi-level periodic data aggregation approach implemented on the source node and on the aggregator levels. In this paper our goal is to apply data aggregation on two nodes levels. We worked on sending fewer data from aggregator to the sink, along with the equation that expresses all data. We applied Bayesian belief network algorithm to measure the accuracy of this method.","","CD-ROM:978-1-4673-7503-0; Electronic:978-1-4673-7504-7; POD:978-1-4673-7505-4","10.1109/ICDIPC.2016.7470808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470808","Data aggregation;Machine learning;Wireless sensor Network “WSN”;fitting functions;optimization;similarity functions","Artificial intelligence;Clustering algorithms;Filtering;Fitting;Machine learning algorithms;Wireless sensor networks","belief networks;data aggregation;filters;tree data structures;wireless sensor networks","Bayesian belief network algorithm;WSN;bilevel periodic data aggregation;fitting functions;local aggregation;prefix filtering;tree based data aggregation;wireless sensor network","","","","21","","","21-23 April 2016","","IEEE","IEEE Conference Publications"
"Using bagging and boosting algorithms for 3D object labeling","O. Herouane; L. Moumoun; T. Gadi","Laboratory Informatics, Imaging and Modeling of Complex Systems (IIMSC) Faculty of Science and Technology, University Hassan 1st, Settat, Morocco","2016 7th International Conference on Information and Communication Systems (ICICS)","20160523","2016","","","310","315","Machine learning has recently become an interesting research field in 3D objects preprocessing. However, few algorithms using this automatic technique have been proposed to learn 3D objects parts. The aim of this paper is to present two simple and efficient approaches to learn parts of a 3D object. These approaches use Bagging or multiclass Boosting algorithms and the Shape Spectrum Descriptor (SSD) to build the classification models. The trained models will assign an appropriate label to each part of the 3D object of the database. The high quality of the quantitative and qualitative results obtained demonstrated the efficiency and the performance of the proposed approaches.","","Electronic:978-1-4673-8614-2; POD:978-1-4673-8615-9","10.1109/IACS.2016.7476070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476070","3D objects;Bagging;Multiclass boosting;Shape Index;machine learning","Bagging;Classification algorithms;Indexes;Labeling;Machine learning algorithms;Shape;Three-dimensional displays","image classification;learning (artificial intelligence);object detection;solid modelling","3D object labeling;bagging algorithm;classification model;machine learning;multiclass boosting algorithm;shape spectrum descriptor","","","","25","","","5-7 April 2016","","IEEE","IEEE Conference Publications"
"Monocular vision based autonomous indoor mobile service robot","S. Emarose; M. D. Ranganathan; M. Siranjeevi; M. Sugadev","Department of Electronics & Communication, Sathyabama University, Chennai, India","2015 Online International Conference on Green Engineering and Technologies (IC-GET)","20160419","2015","","","1","5","A low cost vision guided robot was developed to perform indoor service operations. The robot uses a webcam to localize and track the object of interest and a SONAR is used in conjunction with the camera to estimate distance between the robot and the object. A 3 DOF robotic arm is mounted on the robot to manipulate the objects within its workspace. The robot is capable of operating at different lighting conditions. A Visual feedback loop is established between the object and the robot for continuous tracking. Path planning of the robot is done based on the mean of the object location from 5 frames to obtain smooth maneuver.","","Electronic:978-1-4673-9781-0; POD:978-1-4673-9782-7","10.1109/GET.2015.7453783","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7453783","First responder;Human detection;Machine learning;Object recognition","DC motors;Face detection;Robot kinematics;Robot sensing systems;Switches;Webcams","feedback;manipulators;mobile robots;object tracking;path planning;robot vision;service robots;sonar","3 DOF robotic arm;autonomous indoor mobile service robot;continuous tracking;monocular vision;object localization;object tracking;path planning;sonar;vision guided robot;visual feedback loop;webcam","","","","9","","","27-27 Nov. 2015","","IEEE","IEEE Conference Publications"
"Image quality assessment using nonlinear learning methods","R. Alhakim; G. T. Tchendjou; E. Simeu; F. Lebowsky","TIMA Laboratory, Grenoble University, 38031 Cedex, France","2015 27th International Conference on Microelectronics (ICM)","20160324","2015","","","5","8","Objective image quality assessment plays an important role in various image processing applications, where the goal of this process is to automatically evaluate the image quality in agreement with human visual perception. In this paper, we propose three different nonlinear learning approaches in order to design image quality assessment models, which serve to predict the perceived image quality. The nonlinear learning approaches used for the aforementioned purpose are nonlinear regression, artificial neural network and regression tree. The largest publicly available image quality database TID2013 is used to benchmark and evaluate the prediction models. The image quality metrics, provided by this TID2013, are not independent and have the redundant information of image quality. This issue might have a negative impact on the training performance and cause overfitting. To avoid this problem and to simplify the model structure, we select the most significant image quality metrics, based on Pearson's correlation measure and principal component analysis. Simulation results confirm that the three nonlinear learning models have high efficiency in predicting image quality. In addition, the regression tree model has low complexity and easy implementation, comparing to the two other prediction models.","","Electronic:978-1-4673-8759-0; POD:978-1-4673-8760-6","10.1109/ICM.2015.7437973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437973","Image Quality Assessment;Machine Learning;Neural Network;Non-linear Regression;Regression Tree","Artificial neural networks;Correlation;Databases;Image quality;Measurement;Predictive models;Regression tree analysis","correlation methods;image processing;learning (artificial intelligence);neural nets;prediction theory;principal component analysis;regression analysis;trees (mathematics)","Pearson ncorrelation;TID2013 database;artificial neural network;human visual perception;image processing;nonlinear learning method;nonlinear regression tree model;objective image quality assessment;prediction model;principal component analysis","","1","","15","","","20-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Urban Street Lighting Infrastructure Monitoring Using a Mobile Sensor Platform","S. Kumar; A. Deshpande; S. S. Ho; J. S. Ku; S. E. Sarma","Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, USA","IEEE Sensors Journal","20160518","2016","16","12","4981","4994","We present a system for collecting and analyzing information on street lighting infrastructure. We develop a car-mounted sensor platform that enables collection and logging of data on street lights during night-time drive-bys. We address several signal processing problems that are key to mapping street illumination levels, identifying street lamps, estimating their heights, and geotagging them. Specifically, we highlight an image recognition algorithm to identify street lamps from the video data collected by the sensor platform and its subsequent use in estimating the heights of street lamps. We also outline a framework to improve vehicle location estimates by combining sensor observations in an extended Kalman filter framework. Our eventual goal is to develop a semi-live virtual 3-D street lighting model at urban scale that enables citizens and decision makers to assess and optimize performance of nighttime street lighting.","1530-437X;1530437X","","10.1109/JSEN.2016.2552249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450141","Sensors;automation;geotagging;image recognition;machine learning;machine vision;mobile sensing;urban sensing","Cameras;Global Positioning System;Lighting;Microcontrollers;Monitoring;Sensor systems","Kalman filters;image recognition;nonlinear filters;sensors;signal processing;street lighting;vehicles","car-mounted sensor platform;extended Kalman filter framework;image recognition;mobile sensor platform;semi-live virtual 3-D street lighting model;signal processing problems;street illumination levels;street lamps;urban street lighting infrastructure monitoring;vehicle location estimates","","","","64","","20160408","June15, 2016","","IEEE","IEEE Journals & Magazines"
"Density based support vector machine classification for a synchronous EEG path tracing virtual training environment","B. Senzio-Savino; M. R. Alsharif; C. E. Gutierrez; K. Yamashita; J. Noble","Department of Information Engineering, University of the Ryukyus, Okinawa, Japan","2015 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)","20160324","2015","","","223","226","The use of Brain-Computer Interface (BCI) has been increasing exponentially in the recent years due to the use of low-cost commercial Fast Fourier Transform (FFT) based EEG reading devices with non-clinical accuracy for consumer application development. Also, the design and implementation of 3D virtual environments for BCI training purposes has proven to be effective due to the high interaction with the end user and the assistance for recreating a specific type of signal or behavior. The aim of this paper is to present a method and the results of applying a binary Density Based Support Vector Machine (DBSVM) Classifier in a 3D virtual environment designed for interacting with EEG predefined signal patterns. The environment trains the classifier by taking 180 second EPOCHs and classifying them into a successful/unsuccessful attempt per test subject. The applications can be extended for implementing a mind-wave pattern password or tracing a specific set of mind-based commands for virtual path tracing purposes. The tested SVM had a success rate of 60%. Further work includes the study of different classifier features and implementation of a dynamic classifier.","","Electronic:978-1-4799-8562-3; POD:978-1-4799-8563-0; USB:978-1-4799-8561-6","10.1109/ICIIBMS.2015.7439486","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439486","3D visual training;BMI;Machine learning;MindWave;SVM;pattern recognition","Brain modeling;Electroencephalography;Mathematical model;Support vector machines;Three-dimensional displays;Training;Virtual environments","brain-computer interfaces;electroencephalography;signal classification;support vector machines","3D virtual environment;BCI;DBSVM classifier;EEG predefined signal patterns;EPOCH;binary density based support vector machine;brain-computer interface;density based support vector machine classification;mind-based commands;mind-wave pattern password;synchronous EEG path tracing virtual training environment;virtual path tracing","","","","12","","","28-30 Nov. 2015","","IEEE","IEEE Conference Publications"
"Effects of Gender on Perception and Interpretation of Video Game Character Behavior and Emotion","N. Desai; R. Zhao; D. Szafron","","IEEE Transactions on Computational Intelligence and AI in Games","","2016","PP","99","1","1","Gender in video games is a popular topic. However, the focus is usually on how gender is portrayed within games. In this paper, we examine the effects of players' gender on the perception of virtual character behavior and emotion based on the results of two user studies involving story-based games. The first study compared players' perception of virtual character behaviors. We analyzed perceived differences both by gender and by gaming experience. In this study we found that female gamers were more appreciative of complex behaviors than male gamers. In the second study, we examined the influence of gender on player' ability to identify the emotion being displayed by a virtual character. We found that most emotions were identified comparably, with the exception of anger. Female players were significantly better at identifying angry characters compared to male players. We also investigated any perception differences between emotions expressed by male and female virtual characters, but we did not identify any statistically significant differences. Overall, the studies suggest that there are differences in how male and female players perceive virtual characters, and if game designers want players to perceive these characters in a certain way, they should consider the gender of targeted players.","1943-068X;1943068X","","10.1109/TCIAIG.2016.2570006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470609","character behavior;character emotion;gaming experience;gender;machine learning","Adaptation models;Artificial intelligence;Biology;Games;Hidden Markov models;Psychology;Training","","","","","","","","20160518","","","IEEE","IEEE Early Access Articles"
"Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","H. C. Shin; H. R. Roth; M. Gao; L. Lu; Z. Xu; I. Nogues; J. Yao; D. Mollura; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory","IEEE Transactions on Medical Imaging","20160503","2016","35","5","1285","1298","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.","0278-0062;02780062","","10.1109/TMI.2016.2528162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404017","Biomedical imaging;computer aided diagnosis;image analysis;machine learning;neural networks","Biomedical imaging;Computational modeling;Computed tomography;Diseases;Lungs;Lymph nodes;Solid modeling","computerised tomography;diseases;image classification;image representation;learning (artificial intelligence);lung;medical image processing;neurophysiology;reviews","CNN architectures;CNN model analysis;axial CT slices;computer-aided detection;computer-aided detection problems;dataset characteristics;deep convolutional neural networks;fine-tuning CNN models;five-fold cross-validation classification;high performance CAD systems;highly representative hierarchical image features;image recognition;interstitial lung disease classification;learning data-driven;mediastinal LN detection;medical image classification;medical image tasks;medical imaging domain;natural image dataset;off-the-shelf pretrained CNN features;pretrained imagenet;spatial image context;state-of-the-art performance;supervised fine-tuning;thoraco-abdominal lymph node detection;transfer learning;unsupervised CNN pretraining","","20","","73","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"On classification of biological data using outlier detection","Y. Qiu; X. Cheng; W. Hou; W. K. Ching","Advanced Modeling and Applied Computing Laboratory, Department of Mathematics, University of Hong Kong, Hong Kong","12th International Symposium on Operations Research and its Applications in Engineering, Technology and Management (ISORA 2015)","20160421","2015","","","1","7","With the rapid development of information technology, the number of datasets, as well as their complexity and dimension, have been growing dramatically. This dramatic growth of biology data and non-biological commercial databases becomes a challenging issue in data mining. Classification technique is one of the major tools in the captured research area. However, the performance of classification may be degraded when there exists noise in the captured databases. Therefore, outlier detection becomes an urgent need and the issue of how to integrate outlier detection method and classification techniques is an important and challenging issue. In this paper, we proposed a novel and effective approach based on k-means clustering to identify outliers in the databases. In particular, we employed one of famous classification techniques, Support Vector Machine (SVM), owing to its ability to handle highdimensional data set. We also compare the classification results with the multivariate outlier detection method. Numerical results on two different data sets indicate that the classification results after removing the outliers by our proposed method are much better than the multivariate outlier detection method.","","Paper|Electronic:978-1-78561-085-1|978-1-78561-086-8","10.1049/cp.2015.0617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456010","Classification;Machine Learning;Outlier Detection;Support Vector Machine (SVM).","","biology computing;data mining;database management systems;pattern classification;pattern clustering;support vector machines","SVM;biological data classification;captured databases;data mining;high dimensional data set handling;information technology;k-means clustering;multivariate outlier detection method;nonbiological commercial databases;support vector machine","","","","","","","21-24 Aug. 2015","","IET","IET Conference Publications"
"Hardware accelerator for analytics of sparse data","E. Nurvitadhi; A. Mishra; Y. Wang; G. Venkatesh; D. Marr","Intel Corporation, Hillsboro, OR USA","2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)","20160428","2016","","","1616","1621","Rapid growth of Internet led to web applications that produce large unstructured sparse datasets (e.g., texts, ratings). Machine learning (ML) algorithms are the basis for many important analytics workloads that extract knowledge from these datasets. This paper characterizes such workloads on a high-end server for real-world datasets and shows that a set of sparse matrix operations dominates runtime. Further, they run inefficiently due to low compute-per-byte and challenging thread scaling behavior. As such, we propose a hardware accelerator to perform these operations with extreme efficiency. Simulations and RTL synthesis to 14nm ASIC demonstrate significant performance and performance/Watt improvements over conventional processors, with only a small area overhead.","","Electronic:978-3-9815-3707-9; POD:978-1-4673-9228-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459571","Hardware accelerator;analytics;machine learning","Algorithm design and analysis;Hardware;Program processors;Runtime;Servers;Sparse matrices;Uniform resource locators","data analysis;learning (artificial intelligence)","ML algorithm;hardware accelerator;machine learning algorithms;sparse data analytics;sparse matrix operations;thread scaling behavior","","1","","21","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Change detection analysis of tornado disaster using conditional copulas and Data Fusion for cost-effective disaster management","B. Gokaraju; A. C. Turlapaty; D. A. Doss; R. L. King; N. H. Younan","The University of West Alabama, 35470, United States","2015 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","20160331","2015","","","1","8","The up-to-date results are presented from an ongoing study of the Data Fusion of multi-temporal and multi-sensor satellite datasets for near real time damage and debris assessment after a tornado disaster event. The space-borne sensor datasets comprising of: (i) C-band SAR dataset from RADARSAT-2; (ii) Multi-Spectral (MS) optical dataset including NIR from RapidEye; (iii) MS and panchromatic dataset of Advanced Linear Imaging (ALI), are studied for multi-sensor data fusion. A combined approach of multi-polarized radiometric and textural feature extraction, and statistical learning based feature classification is devised for fine tuning of the complex and generalized change detection model. We also investigated the use of multi-variate conditional copula as a classifier technique, by formulating the change and no-change as a binary-class classification problem in this study. The classification results from the above technique are used for assessment of damage and debris cover after the tornado disaster event. The performance of the above approach yields a very significant Kappa accuracy up to 75%. A 10-fold cross validation strategy is used for quantitative analysis of the performance of the classification model. This study will be further extended for modelling the effect of incidence angle discrepancies or climatic condition variances, which will address the heterogeneity factor in terms of local statistics of the dataset.","","Electronic:978-1-4673-9558-8; POD:978-1-4673-9559-5","10.1109/AIPR.2015.7444537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444537","change detection;conditional Copula;data fusion;disaster management;machine learning","Data integration;Disaster management;Feature extraction;Remote sensing;Spatial resolution;Synthetic aperture radar;Tornadoes","emergency management;feature extraction;image classification;learning (artificial intelligence);radar imaging;remote sensing;sensor fusion;statistical distributions;storms","ALI;C-band SAR dataset;NIR;RADARSAT-2;RapidEye;advanced linear imaging;change detection analysis;conditional copula;feature classification;feature extraction;multisensor data fusion;statistical learning;tornado disaster management","","","","19","","","13-15 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Practical Approach to Hard Disk Failure Prediction in Cloud Platforms: Big Data Model for Failure Management in Datacenters","S. Ganguly; A. Consul; A. Khan; B. Bussone; J. Richards; A. Miguel","Microsoft Corp., Redmond, CA, USA","2016 IEEE Second International Conference on Big Data Computing Service and Applications (BigDataService)","20160523","2016","","","105","116","Large scale cloud platforms can benefit from a service that runs a machine learning model to predict disk drive failures. Unlike previous studies in this space, we have combined multiple data inputs for the model and obtained a better model performance compared to earlier published models. In this paper we explain how we developed and deployed the predictive model in a large scale cloud service. To build the model, we used a combination of two open data sources - Self-Monitoring, Analysis and Reporting technology (S.M.A.R.T or SMART) data and Windows performance counters. The nature of both these data sources is different and complex. The paper provides unique ways of parsing and transforming the data to make it most suited for a classification problem. Trails with different machine learning (ML) and statistical modeling techniques led us to the best performing two-stage ensemble model. We implemented this model to be configurable such that it could be deployed on large scale distributed cloud management systems and iterated on with minimal code impact. We provide a glimpse of the complex cloud hardware ecosystem and how a predictive model would impact such an ecosystem. Although our study focused on hard disk drives, we believe a similar modeling approach can apply to other hardware components as well. A successfully executed hard disk failure prediction model can pre-empt negative impact to client workloads and improve the economics of running a large scale cloud service. We provide the details of our model as a possible template for future extensions and improvements towards building more robust hardware fault prediction services. Finally we give a staged approach to operationalizing the model in large scale cloud systems.","","Electronic:978-1-5090-2251-9; POD:978-1-5090-2252-6","10.1109/BigDataService.2016.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474362","Azure;DevOps;ML;SMART;big data;cloud;cloud compute;datacenter;diagnostics;disk;machine learning","Data models;Hard disks;Hardware;Maintenance engineering;Predictive models;Radiation detectors;Servers","cloud computing;disc drives;hard discs;learning (artificial intelligence)","ML;SMART data;Windows performance counters;big data model;classification problem;cloud systems;complex cloud hardware ecosystem;datacenters;disk drive failures;ensemble model;failure management;hard disk drives;hard disk failure prediction model;hardware components;large scale cloud platforms;large scale cloud service;large scale distributed cloud management systems;machine learning model;minimal code impact;multiple data inputs;open data sources;predictive model;reporting technology;robust hardware fault prediction services;self-monitoring;statistical modeling techniques","","","","12","","","March 29 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Wearable SpO2 and sleep posture monitoring system for Obstructive Sleep Apnea patients","R. Brugarolas; J. M. Valero-Sarmiento; A. Brna","Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27697-7911, USA","2015 IEEE Virtual Conference on Applications of Commercial Sensors (VCACS)","20160404","2015","","","1","6","Obstructive Sleep Apnea (OSA) affects 20% of adults in the world and is caused by a collapse of the soft tissue surrounding the upper airway, obstructing airflow. The vast majority of mild and moderate OSA patients are positional patients, which means that these patients show most of their breathing abnormalities while sleeping in supine position. For these patients positional therapy may be a simple and effective treatment solution. In this study we present a training system for positional patients to alert them when a SpO<sub>2</sub> desaturation is occurring, or when they spend a long period of time sleeping in supine position. The alert is given to the patient initially as a smooth vibration in their wrist band, but if the condition persists, a buzzer is used for auditory indication. The system uses an accelerometer on the chest or abdomen to determine the sleeping posture and a commercial finger clip pulse oximeter to monitor heart rate and SpO<sub>2</sub>.","","Electronic:978-1-4673-6957-2; POD:978-1-4673-6958-9","10.1109/VCACS.2015.7439613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439613","Bluetooth low energy;accelerometer;machine learning;pulse oximetry","Decision support systems","acceleration measurement;accelerometers;body sensor networks;medical disorders;oximetry;patient monitoring;pneumodynamics;sleep","SpO<sub>2</sub> desaturation;abdomen;accelerometer;auditory indication;breathing abnormalities;buzzer;chest;commercial finger clip pulse oximeter;heart rate monitoring;moderate OSA patients;obstructing airflow;obstructive sleep apnea patients;patients positional therapy;positional patients;sleep posture monitoring system;smooth vibration;soft tissue;supine position;training system;treatment solution;upper airway;wearable SpO<sub>2</sub>;wrist band","","1","","9","","","March 15 2015-Oct. 15 2015","","IEEE","IEEE Conference Publications"
"Statistical Framework and Built-In Self-Speed-Binning System for Speed Binning Using On-Chip Ring Oscillators","S. P. Mu; M. C. T. Chao; S. H. Chen; Y. M. Wang","Department of Electronics EngineeringInstitute of Electronics, National Chiao Tung University, Hsinchu, Taiwan","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20160421","2016","24","5","1675","1687","This paper presents a model-fitting framework to correlate the on-chip measured ring-oscillator counts to the chip's maximum operating speed. This learned model can be included in an auto test equipment (ATE) software to predict the chip speed for speed binning. Such a speed-binning method can avoid the use of applying any functional test and, hence, result in a third-order test time reduction with a limited portion of chips placed into a slower bin compared with the conventional functional-test binning. This paper further presents a novel built-in self-speed-binning system, which embeds the learned chip-speed model with a built-in circuit such that the chip speed can be directly calculated on-chip without going through any offline ATE software, achieving a fourth-order test-time reduction compared with the conventional speed binning. The experiments were conducted based on 360 test chips of a 28-nm, 0.9 V, 1.6-GHz mobile-application system-on-chip.","1063-8210;10638210","","10.1109/TVLSI.2015.2478921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294704","Machine learning;rind oscillator;speed binning;speed binning.","Bayes methods;Delays;Frequency measurement;Linear regression;Mathematical model;Semiconductor device measurement;System-on-chip","automatic test equipment;built-in self test;integrated circuit modelling;integrated circuit testing;oscillators;statistical analysis;system-on-chip","ATE software;autotest equipment;built-in circuit;built-in self speed-binning system;frequency 1.6 GHz;functional-test binning;learned chip speed model;mobile-application system-on-chip;model-fitting framework;on-chip ring oscillator;size 28 nm;statistical framework;third-order test time reduction;voltage 0.9 V","","","","32","","20151008","May 2016","","IEEE","IEEE Journals & Magazines"
"Domain knowledge and feature representation","M. S. Cohen","University of California, Los Angeles Laboratory of Integrative Neuroimaging Technology Los Angeles, CA, United States","2016 4th International Winter Conference on Brain-Computer Interface (BCI)","20160421","2016","","","1","3","Identifying covert internal brain by their expression in neural images, particularly from magnetic resonance imaging, is a popular, powerful, and important area of research whose ultimate expression is known now as “brain reading.” The nature of the imaging data is challenging however, in that they typically have two orders of magnitude more features than observations. We propose that it is many ways useful to apply prior knowledge of brain organization - both physical and mental. We note that sparsity offers quantitative leverage, and that this, itself, may provide insight into the nature of human cognition.","","Electronic:978-1-4673-7842-0; POD:978-1-4673-7843-7","10.1109/IWW-BCI.2016.7457438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457438","ICA;brain;cognition;fMRI;machine learning;mind reading;searchlight (key words)","Brain modeling;Cognition;Decoding;Hidden Markov models;Magnetic resonance imaging;Neuroimaging","biomedical MRI;medical image processing","covert internal brain;domain knowledge;feature representation;human cognition;magnetic resonance imaging;neural images","","","","16","","","22-24 Feb. 2016","","IEEE","IEEE Conference Publications"
"Speech enhancement based on neural networks applied to cochlear implant coding strategies","F. Bolner; T. Goehring; J. Monaghan; B. van Dijk; J. Wouters; S. Bleeck","ExpORL, KU Leuven, Leuven, Belgium","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6520","6524","Traditionally, algorithms that attempt to significantly improve speech intelligibility in noise for cochlear implant (CI) users have met with limited success, particularly in the presence of a fluctuating masker. In the present study, a speech enhancement algorithm integrating an artificial neural network (NN) into CI coding strategies is proposed. The algorithm decomposes the noisy input signal into time-frequency units, extracts a set of auditory-inspired features and feeds them to the NN to produce an estimation of which CI channels contain more perceptually important information (higher signal-to-noise ratio, SNR). This estimate is then used accordingly to retain a subset of channels for electrical stimulation, as in traditional n-of-m coding strategies. The proposed algorithm was tested with 10 normal-hearing participants listening to CI noise-vocoder simulations against a conventional Wiener filter based enhancement algorithm. Significant improvements in speech intelligibility in stationary and fluctuating noise were found over both unprocessed and Wiener filter processed conditions.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472933","Cochlear implants;machine learning;neural networks;noise reduction;speech enhancement","Artificial neural networks;Estimation;Feature extraction;Noise measurement;Signal to noise ratio;Speech;Speech enhancement","Wiener filters;channel estimation;cochlear implants;feature extraction;neural nets;speech coding;speech enhancement;speech intelligibility;vocoders","CI channel estimation;CI coding strategy;CI noise-vocoder simulation;NN;SNR;Wiener filter;artificial neural network;auditory-inspired feature extraction;cochlear implant coding strategy;decomposition;electrical stimulation;n-of-m coding strategy;neural network;signal-to-noise ratio;speech enhancement algorithm;speech intelligibility;time frequency analysis","","2","","22","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Efficient Board-Level Functional Fault Diagnosis With Missing Syndromes","S. Jin; F. Ye; Z. Zhang; K. Chakrabarty; X. Gu","Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20160518","2016","35","6","985","998","Functional fault diagnosis is widely used in board manufacturing to ensure product quality and improve product yield. Advanced machine-learning techniques have recently been advocated for reasoning-based diagnosis; these techniques are based on the historical record of successfully repaired boards. However, traditional diagnosis systems fail to provide appropriate repair suggestions when the diagnostic logs are fragmented and some error outcomes, or syndromes, are not available during diagnosis. We describe the design of a diagnosis system that can handle missing syndromes and can be applied to four widely used machine-learning techniques. Several imputation methods are discussed and compared in terms of their effectiveness for addressing missing syndromes. Moreover, a syndrome-selection technique based on the minimum-redundancy-maximum-relevance criteria is also incorporated to further improve the efficiency of the proposed methods. Two large-scale synthetic data sets generated from the log information of complex industrial boards in volume production are used to validate the proposed diagnosis system in terms of diagnosis accuracy and training time.","0278-0070;02780070","","10.1109/TCAD.2015.2481859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275129","Board-level functional fault diagnosis;feature selection;machine-learning techniques;missing syndromes","Accuracy;Circuit faults;Fault diagnosis;Maintenance engineering;Niobium;Training;Training data","circuit analysis computing;fault diagnosis;learning (artificial intelligence);printed circuit design;printed circuit manufacture","advanced machine-learning techniques;board manufacturing;board-level functional fault diagnosis;complex industrial board information;diagnostic log fragmentation;large-scale synthetic data sets;minimum-redundancy-maximum-relevance criteria;missing syndromes;product quality;product yield;reasoning-based diagnosis;syndrome-selection technique;volume production","","","","30","","20150924","June 2016","","IEEE","IEEE Journals & Magazines"
"Effective and adaptive technological solution to block spam E-mails","A. U. Surwade; M. P. Patil; S. R. Kolhe","School of Computer Sciences, North Maharashtra University, Jalgaon, India","2016 International Conference on Advances in Human Machine Interaction (HMI)","20160409","2016","","","1","10","The internet E-mail infrastructure has become famous and widely used means of communication for personal, business and academic purposes just because it is fast, cheap and very efficient. People are using this E-mail infrastructure for their day-to-day work. The users are receiving many unwanted E-mails from the unknown senders. These unwanted E-mails are called as spam E-mails. In this paper technological solution for blocking spam E-mail is discussed. This technological solution consists of combination of origin based filters (OBF) and content based filters (CBF) which is adaptive in nature. The CBF Filter contains two components machine learning based classifier (MLC) and semantic similarity with edge based classifier (SSC). This technological solution is tested on the standard dataset such as Enron, LingSpam along with personal E-mail messages (PEM). The results empirically prove the strength of this solution.","","Electronic:978-1-4673-8810-8; POD:978-1-4673-8811-5","10.1109/HMI.2016.7449180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449180","Black-list;Content based Filter;Machine Learning Classifier;Origin based Filter;Semantic Similarity;Spam Classification;White-list","Bayes methods;Classification algorithms;Filtering;Filtering algorithms;Semantics;Unsolicited electronic mail","Internet;e-mail filters;learning (artificial intelligence);pattern classification;unsolicited e-mail","CBF;Enron;Internet e-mail infrastructure;LingSpam;MLC;OBF;PEM;SSC;adaptive technological solution;content based filters;machine learning based classifier;origin based filters;personal e-mail messages;semantic similarity-with-edge based classifier;spam e-mail blocking","","","","68","","","3-5 March 2016","","IEEE","IEEE Conference Publications"
"Multiple Vital-Sign-Based Infection Screening Outperforms Thermography Independent of the Classification Algorithm","Y. Yao; G. Sun; T. Matsui; Y. Hakozaki; S. van Waasen; M. Schiek","Central Institute, ZEA-2, Electronic Systems, Research Center J&#252;lich, J&#x00FC;lich, Germany","IEEE Transactions on Biomedical Engineering","20160420","2016","63","5","1025","1033","Goal: Thermography-based infection screening at international airports plays an important role in the prevention of pandemics. However, studies show that thermography suffers from low sensitivity and specificity. To achieve higher screening accuracy, we developed a screening system based on the acquisition of multiple vital-signs. This multimodal approach increases accuracy, but introduces the need for sophisticated classification methods. This paper presents a comprehensive analysis of the multimodal approach to infection screening from a machine learning perspective. Methods: We conduct an empirical study applying six classification algorithms to measurements from the multimodal screening system and comparing their performance among each other, as well as to the performance of thermography. In addition, we provide an information theoretic view on the use of multiple vital-signs for infection screening. The classification methods are tested using the same clinical data, which has been analyzed in our previous study using linear discriminant analysis. A total of 92 subjects were recruited for influenza screening using the system, consisting of 57 inpatients diagnosed to have seasonal influenza and 35 healthy controls. Results: Our study revealed that the multimodal screening system reduces the misclassification rate by more than 50% compared to thermography. At the same time, none of the multimodal classifiers needed more than 6 ms for classification, which is negligible for practical purposes. Conclusion: Among the tested classifiers k-nearest neighbors, support vector machine and quadratic discriminant analysis achieved the highest cross-validated sensitivity score of 93%. Significance: Multimodal infection screening might be able to address the shortcomings of thermography.","0018-9294;00189294","","10.1109/TBME.2015.2479716","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271021","Classification;Infection screening;classification;infection screening;machine learning;supervised learning","Biomedical measurement;Mutual information;Sensitivity;Support vector machines;Temperature measurement;Training;Training data","biomedical optical imaging;diseases;image classification;infrared imaging;learning (artificial intelligence);medical image processing;support vector machines","cross-validated sensitivity score;influenza screening;k-nearest neighbors;linear discriminant analysis;machine learning perspective;multiple vital-sign acquisition;multiple vital-sign-based infection screening;pandemic prevention;quadratic discriminant analysis;support vector machine;thermography-based infection screening","","","","18","","20150917","May 2016","","IEEE","IEEE Journals & Magazines"
"Adaptive traffic management and dynamic optimal redirection using particle swarm optimization","N. Thiruverahan; P. Ravi; S. G. Jacob","CSE Department, SSN College of Engineering, Kalavakkam, Chennai","2015 International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)","20160421","2015","","","477","480","Intelligent Traffic Monitoring has been an area of avid research in the past decade. The aim of this research paper is to present a novel design of an adaptive traffic control system that ensures fair scheduling and provides dynamic suggestions of optimal routes to neighbourhoods based on traffic intensity information collected by piezoelectric strips installed on the road. The time slice for each of the four directions of traffic movement at a signal junction is dependent on the traffic intensity in that direction and a state machine is used to adjust the time slices while a round-robin fashion of scheduling traffic movement is maintained. Swarm particle optimization algorithm is employed by a centralized control unit that has the traffic intensity information from all neighbourhoods to provide optimal route suggestions to different neighbouring areas, at each signal.","","Electronic:978-1-4673-9223-5; POD:978-1-4673-9224-2; USB:978-1-4673-9222-8","10.1109/ICATCCT.2015.7456931","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456931","fair scheduling;machine learning;optimal route;particle swarm optimization;traffic management","Communications technology;Conferences","adaptive control;finite state machines;particle swarm optimisation;piezoelectric transducers;road traffic control;scheduling","adaptive traffic control system;adaptive traffic management;centralized control unit;dynamic optimal redirection;fair scheduling;particle swarm optimization;piezoelectric strips;road;round-robin scheduling;state machine;traffic intensity information;traffic movement scheduling","","","","9","","","29-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"Authorship recognition in a multiparty chat scenario","R. S. Kuzu; K. Balci; A. A. Salah","Bogazici University, Bebek - Istanbul, TURKEY","2016 4th International Conference on Biometrics and Forensics (IWBF)","20160409","2016","","","1","6","Users of online social networks often use multiple identities. This paper investigates the possibility of identifying a user from his or her chat behavior in such a setting. We have collected a large corpus of multiparty chat records in Turkish, obtained from a multiplayer game database. The most active 978 users are selected according to their participation in game chat sessions. This corpus is used in a biometric identification experiment where we seek each user among a gallery of users. Character matrices for each player are used as features, and re-centered local profiles and cosine similarity measure are preferred as identification methods. We systematically assess the effect of text normalization on identification. We report comparative results, the best of which reach around 75% rank-1 accuracy for a gallery size of 978.","","Electronic:978-1-4673-9448-2; POD:978-1-4673-9449-9","10.1109/IWBF.2016.7449681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449681","Authorship recognition;Chat biometrics;Chat mining;Machine learning;Multiparty chat;Text classification;Text information retrieval","Databases;Feature extraction;Games;Semantics;Syntactics;Text recognition;Training","computer games;computer mediated communication;social networking (online);text analysis","Turkish;biometric identification experiment;character matrices;cosine similarity measure;gallery size;game chat sessions;identification methods;multiparty chat records;multiplayer game database;online social networks;recentered local profiles;text normalization","","","","22","","","3-4 March 2016","","IEEE","IEEE Conference Publications"
"Physical Activity Recognition From Smartphone Accelerometer Data for User Context Awareness Sensing","J. Wannenburg; R. Malekian","Department of Electrical, Electronic, and Computer Engineering, University of Pretoria, Pretoria 0002, South Africa.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2016","PP","99","1","8","Physical activity recognition of everyday activities such as sitting, standing, laying, walking, and jogging was performed, through the use of smartphone accelerometer data. Activity classification was done on a remote server through the use of machine learning algorithms, data was received from the smartphone wirelessly. The smartphone was placed in the subject's trouser pocket while data was gathered. A large sample set was used to train the classifiers and then a test set was used to verify the algorithm accuracies. Ten different classifier algorithm configurations were evaluated to determine which performed best overall, as well as, which algorithms performed best for specific activity classes. Based on the results obtained, very accurate predictions could be made for offline activity recognition. The kNN and kStar algorithms both obtained an overall accuracy of 99.01%.","2168-2216;21682216","","10.1109/TSMC.2016.2562509","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476869","Accelerometer;activity recognition;machine learning;smartphone","Accelerometers;Feature extraction;Hidden Markov models;Legged locomotion;Machine learning algorithms;Sensors;Servers","","","","1","","","","20160523","","","IEEE","IEEE Early Access Articles"
"Comparison between multi-class classifiers and deep learning with focus on industry 4.0","M. Miškuf; I. Zolotová","Dept. of Cybernetics and Artificial Intelligence, Faculty of Electrical Engineering and Informatics, Technical University of Ko&#353;ice, Slovakia","2016 Cybernetics & Informatics (K&I)","20160324","2016","","","1","5","Growing amounts of data will be one of consequences in Industry 4.0. This paper deals about mining frequent patterns and important factors in data. Classification is one of the most common assignments in data analytics. We used letter recognition data from the UCI repository as data set for our experiment. Data set contains more than 20000 instances of 26 classes. In our case, it represents multi-class classification. This idea can be transformed into industrial environment. Deep learning is a new area of machine learning research. We decided to use Deep learning from open source H2O machine learning framework and compare it with four multi-class classification algorithms available as services on Microsoft Azure. We are focusing this idea on Industrial systems, cloud architecture and data analytics, which will be fundamental pillars of Industry 4.0.","","Electronic:978-1-5090-1834-5; POD:978-1-5090-1835-2; USB:978-1-5090-1833-8","10.1109/CYBERI.2016.7438633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438633","Big data;Data mining;Deep learning;H2O machine learning;Industry 4.0;Microsoft Azure;multi-class classification","Cloud computing;Computational modeling;Data mining;Data models;Machine learning;Training;Water","cloud computing;data mining;learning (artificial intelligence);manufacturing data processing;pattern classification;production engineering computing","Microsoft Azure;cloud architecture;data analytics;deep learning;frequent patterns mining;industry 4.0;multiclass classification;multiclass classifier;open source H2O machine learning","","","","22","","","2-5 Feb. 2016","","IEEE","IEEE Conference Publications"
"Sentiment Analysis and Classification for Software as a Service Reviews","A. M. Alkalbani; A. M. Ghamry; F. K. Hussain; O. K. Hussain","Sch. of Software, Univ. of Technol. Sydney, Sydney, NSW, Australia","2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)","20160523","2016","","","53","58","With the rapid growth of cloud services, there has been a significant increase in the number of online consumer reviews and opinions on these services on different social media platforms. These reviews are a source of valuable information in regard to cloud market position and cloud consumer satisfaction. This study explores cloud consumers' reviews that reflect the user's experience with Software as a Service (SaaS) applications. The reviews were collected from different web portals, and around 4000 online reviews were analysed using sentiment analysis to identify the polarity of each review, that is, whether the sentiment being expressed is positive, negative, or neutral. Also, this research develops a model for predicting the sentiment of Software as a Service consumers' reviews using a supervised learning machine called a support vector machine (SVM). The sentiment results show that 62% of the reviews are positive which indicates that consumers are most likely satisfied with SaaS services. The results show that the prediction accuracy of the SVM-based Binary Occurrence approach (3-fold crossvalidation testing) is 92.30%, indicating it performs better in determining sentiment compared with other approaches (Term Occurrences, TFIDF). This work also provides valuable insight into online SaaS reviews and offers the research community the first SaaS polarity dataset.","1550-445X;1550445X","Electronic:978-1-5090-1858-1; POD:978-1-5090-1859-8","10.1109/AINA.2016.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474069","SaaS polarity dataset;SaaS reviews;sentiment analysis;sentiment classification;supervised machine learning","Cloud computing;Data mining;Portals;Sentiment analysis;Software as a service;Support vector machines","classification;cloud computing;consumer behaviour;customer satisfaction;learning (artificial intelligence);portals;sentiment analysis;social networking (online);support vector machines","SVM;SaaS;Web portals;binary occurrence approach;cloud consumer satisfaction;cloud market position;cloud services;online consumer reviews;sentiment analysis;sentiment classification;social media;software as a service;supervised learning machine;support vector machine","","2","","28","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"A fault-tolerant classifier for prognostics and health management","S. Bhattacharya; L. Fiondella","University of Massachusetts, Dartmouth","2016 Annual Reliability and Maintainability Symposium (RAMS)","20160407","2016","","","1","6","Given recent advances in sensing technology, including performance improvements, as well as reduction in size and cost, prognostics and health management is gaining increased popularity as a method to ensure reliability and safety of engineered systems. While many methods have been developed for a wide range of systems, relatively little research has examined the potential benefits of concepts from reliability engineering such as fault-tolerance. This paper applies majority fault tolerance to improve the accuracy of classifications made by machine learning algorithms. Support vector machine, artificial neural network, and naive Bayes algorithms are applied to a single data set. The reliability and correlations between the individual classifiers are analyzed. Our results suggest that fault-tolerance can improve the accuracy of classification, but that correlation between the individual algorithms can lower the overall effectiveness of the approach. Thus, detailed assessment of alternative algorithms will be necessary before the full potential of fault tolerant classification can be achieved.","","Electronic:978-1-5090-0249-8; POD:978-1-5090-0250-4","10.1109/RAMS.2016.7447961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447961","Machine learning;artificial neural network;fault-tolerance;naive Bayes;support vector machine","Artificial neural networks;Classification algorithms;Fault tolerance;Fault tolerant systems;Machine learning algorithms;Prognostics and health management;Support vector machines","Bayes methods;fault tolerant computing;learning (artificial intelligence);neural nets;pattern classification;reliability","artificial neural network;cost reduction;engineered system reliability;engineered system safety;fault tolerant classification accuracy;fault-tolerant classifier;health management;machine learning algorithms;naïve Bayes algorithms;performance improvements;prognostic management;reliability engineering;sensing technology;single data set;size reduction;support vector machine","","","","13","","","25-28 Jan. 2016","","IEEE","IEEE Conference Publications"
"Performance analysis of recent Word Sense Disambiguation techniques","H. Singh; V. Gupta","UIET, Panjab University, Chandigarh, India","2015 2nd International Conference on Recent Advances in Engineering & Computational Sciences (RAECS)","20160419","2015","","","1","6","This paper presents recent advances in the in the area of Word Sense Disambiguation (WSD). While the supervised machine learning techniques have proven to be most efficient with the problem of availability of sense tagged data. While describing a few important techniques the paper then represents a comparative analysis among them. There is very less commonality among the data sets which have been used but it has been found out that the Genetic Algorithm based approach has the capability to beat other milestone techniques in the literature.","","CD-ROM:978-1-4673-8251-9; Electronic:978-1-4673-8253-3; POD:978-1-4673-8254-0","10.1109/RAECS.2015.7453357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7453357","Conceptual Density;Machine Learning;Natural Language Processing;WSD","Context;Dictionaries;Electronic mail;Genetic algorithms;Semantics;Sociology;Statistics","genetic algorithms;learning (artificial intelligence);natural language processing","WSD;comparative analysis;genetic algorithm based approach;performance analysis;sense tagged data;supervised machine learning techniques;word sense disambiguation techniques","","","","18","","","21-22 Dec. 2015","","IEEE","IEEE Conference Publications"
"Improving accuracy in noninvasive telemonitoring of progression of Parkinson'S Disease using two-step predictive model","S. Jain; S. Shetty","Department of Computer Science Engineering, BITS Pilani Dubai Campus, UAE","2016 Third International Conference on Electrical, Electronics, Computer Engineering and their Applications (EECEA)","20160519","2016","","","104","109","Parkinson's disease has affected over 6.3 million people across the globe. It is estimated that by 2030, the number would rise to 9 million. Almost twenty percent of the people still remain undiagnosed. Parkinson's is the second most common neurodegenerative disease after Alzheimer's. It not only claims the lives of the patients suffering from it but also adversely impacts the lives of their loved ones. A lot of research is being conducted to find modern medical techniques to tackle the ill effects of the disease. Monitoring the progression of the disease plays a vital role in controlling its various symptoms. Non-conventional ways of monitoring PD (Parkinson's Disease) provide an edge over the existing techniques as it reduces the financial burden and also limits the number of clinical visits required for it. In this research paper, we aim to build a predictive model that accurately predicts the UPDRS (Unified Parkinson's Disease Rating Scale) of patients using the data collected through noninvasive speech tests. The research hopes to propose a more efficient technique to monitor Parkinson's disease leading to beneficial treatment of the patients.","","CD-ROM:978-1-4673-6941-1; Electronic:978-1-4673-6942-8; POD:978-1-4673-6943-5","10.1109/EECEA.2016.7470774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470774","Parkinson's Disease;classification;machine learning;regression;speech test;telemonitoring","Diseases;Estimation;Jitter;Speech;Visualization","diseases;medical disorders;medical information systems;neurophysiology;patient monitoring;patient treatment;speech;telemedicine","Parkinson's disease progression;data collection;neurodegenerative disease;noninvasive speech testing;noninvasive telemonitoring;patient treatment;two-step predictive model;unified Parkinson's disease rating scale","","","","9","","","21-23 April 2016","","IEEE","IEEE Conference Publications"
"SVM-based association rules for knowledge discovery and classification","A. Anaissi; M. Goyal","Center of Quantum Computation and Intelligent Systems (QCIS), Faculty of Engineering and Information Technology (FEIT), University of Technology Sydney (UTS) Broadway NSW 2007, Australia","2015 2nd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE)","20160523","2015","","","1","5","Improving analysis of market basket data requires the development of approaches that lead to recommendation systems that are tailored to specifically benefit grocery chain. The main purpose of that is to find relationships existing among the sales of the products that can help retailer identify new opportunities for cross-selling their products to customers. This paper aims to discover knowledge patterns hidden in large data set that can yield more understanding to the data holders and identify new opportunities for imperative tasks including strategic planning and decision making. This paper delivers a strategy for the implementation of a systematic analysis framework built on the established principles used in data mining and machine learning. The primary goal of that is to form the foundation of what we envisage will be a new recommendation system in the market. Uniquely, our strategy seeks to implement data mining tools that will allow the analyst to interact with the data and address business questions such as promotions advertisement. We employ Apriori algorithm and support vector machine to implement our recommendation systems. Experiments are done using a real market dataset and the 0.632+ bootstrap method is used here in order to evaluate our framework. The obtained results suggest that the proposed framework will be able to generate benefits for grocery chain using a real-world grocery store data.","","Electronic:978-1-5090-0713-4; POD:978-1-5090-0714-1","10.1109/APWCCSE.2015.7476236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476236","Apriori algorithm;SVM;association rules;data mining;machine learning","Algorithm design and analysis;Clustering algorithms;Data mining;Decision making;Itemsets;Support vector machines","data mining;decision making;learning (artificial intelligence);pattern classification;recommender systems;retail data processing;strategic planning;support vector machines","Apriori algorithm;SVM-based association rules;bootstrap method;data mining;decision making;knowledge classification;knowledge discovery;machine learning;market basket data;real-world grocery store data;recommendation systems;strategic planning;support vector machine","","","","","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"User Emotion Recognition Based on Multi-class Sensors of Smartphone","D. Shi; X. Chen; J. Wei; R. Yang","Nat. Lab. for Parallel & Distrib. Process., Nat. Univ. of Defense Technol., Changsha, China","2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)","20160505","2015","","","478","485","In this paper, we study about the problem of how to recognize the user emotion based on smartphone data more really. With single data used in the previous studies, it cannot make a comprehensive response of user behavior patterns. So we collected fine-grained sensing data which could reflect user daily behavior fully from multiple dimensions based on smartphone, and then used multidimensional data feature fusion method and six classification methods such as Support Vector Machine (SVM) and Random Forests. Finally, we carried out contrast experiment with twelve volunteers' hybrid data and personal data respectively to recognized user emotion based on discrete emotion model and circumplex emotion model. The results show that the multidimensional data feature fusion method we mentioned which could reflect user behavior comprehensively present high accuracy. The initial use of the hybrid data train only have 72.73% accuracy rate, but after personal data training the accuracy rate can reach 79.78%. In the experimental of different emotion model, circumplex emotion model is better than discrete emotion model.","","Electronic:978-1-5090-1893-2; POD:978-1-5090-1894-9","10.1109/SmartCity.2015.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463770","emotion model;emotion recognition;machine learning;smartphone","Data collection;Emotion recognition;Feature extraction;Mobile handsets;Physiology;Sensors;Support vector machines","emotion recognition;pattern classification;random processes;sensor fusion;smart phones;support vector machines","SVM;circumplex emotion model;classification method;discrete emotion model;multiclass sensor;multidimensional data feature fusion;random forest;smartphone;support vector machine;user behavior pattern;user emotion recognition","","","","22","","","19-21 Dec. 2015","","IEEE","IEEE Conference Publications"
"Pathological speech processing: State-of-the-art, current challenges, and future directions","R. Gupta; T. Chaspari; J. Kim; N. Kumar; D. Bone; S. Narayanan","Signal Analysis and Interpretation Lab, University of Southern California, Los Angeles, CA, USA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6470","6474","The study of speech pathology involves evaluation and treatment of speech production related disorders affecting phonation, fluency, intonation and aeromechanical components of respiration. Recently, speech pathology has garnered special interest amongst machine learning and signal processing (ML-SP) scientists. This growth in interest is led by advances in novel data collection technology, data science, speech processing and computational modeling. These in turn have enabled scientists in better understanding both the causes and effects of pathological speech conditions. In this paper, we review the application of machine learning and signal processing techniques to speech pathology and specifically focus on three different aspects. First, we list challenges such as controlling subjectivity in pathological speech assessments and patient variability in the application of ML-SP tools to the domain. Second, we discuss feature design methods and machine learning algorithms using a combination of domain knowledge and data driven methods. Finally, we present some case studies related to analysis of pathological speech and discuss their design.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472923","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472923","Pathological speech disorders;machine learning;signal processing","Pathology;Planning;Production;Reliability;Speech;Speech processing","diseases;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;speech;speech processing;speech synthesis","ML-SP tools;aeromechanical components;computational modeling;data collection technology;data driven methods;data science;domain knowledge;feature design methods;fluency;intonation;machine learning;pathological speech assessments;pathological speech conditions;pathological speech processing;phonation;respiration;signal processing;speech production related disorders","","","","56","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Identifying Utility Functions Using Random Forests","T. Mendes; M. T. Valente; A. Hora; A. Serebrenik","UFMG, Belo Horizonte, Brazil","2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","20160523","2016","1","","614","618","Utility functions are general purpose functions, which are useful in many parts of a system. To facilitate reuse, they are usually implemented in specific libraries. However, developers frequently miss opportunities to implement general-purpose functions in utility libraries, which decreases the chances of reuse. In this paper, we describe our ongoing investigation on using Random Forest classifiers to automatically identify utility functions. Using a list of static source code metrics we train a classifier to identify such functions, both in Java (using 84 projects from the Qualitas Corpus) and in JavaScript (using 22 popular projects from GitHub). We achieve the following median results for Java: 0.90 (AUC), 0.83 (precision), 0.88 (recall), and 0.84 (F-measure). For JavaScript, the median results are 0.80 (AUC), 0.75 (precision), 0.89 (recall), and 0.76 (F-measure).","","Electronic:978-1-5090-1855-0; POD:978-1-5090-1856-7","10.1109/SANER.2016.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476683","Machine Learning;Refactoring;Remodularization;Utility Functions","Complexity theory;Java;Libraries;Measurement;Rockets;Testing;Training","Java;learning (artificial intelligence);pattern classification;software libraries;software metrics;source code (software);utility programs","JavaScript;random forest classifiers;static source code metrics;utility function identification;utility libraries","","1","","19","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Using healthcare analytics to determine an effective diagnostic model for ADHD in students","D. Mitchnick; V. Kumar; Kinshuk; S. Fraser","School of Computing and Information Systems, Athabasca University, Athabasca, Alberta, Canada","2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)","20160512","2016","","","1","4","Attention Deficit Hyperactivity Disorder (ADHD) is a mental health disorder. People diagnosed with ADHD are often inattentive (have difficulty focusing on a task for a considerable period of time), overly impulsive (make rash decisions), and are hyperactive (moving excessively, often at inappropriate times). ADHD is often diagnosed through psychiatric assessments with additional input from physical/neurological evaluations. Current tools designed for ADHD screening collect data manually and do not interoperate with each other. This paper will first review the effectiveness of common screening tools in relation to the Diagnostic and Statistical Manual of Mental Disorders (DSM) for ADHD classifier. This paper will also introduce the concept of using written performance data as a method of screening, since previous research has linked written language disorder (WLD) to ADHD as well. The current phase of this research proposes that an integrated computational model that combines outcomes from these screening tools will have a more effective diagnosis of ADHD in adult students than from the diagnosis of any individual screening tool. The integrated computational model, based on neural networks, will be built and tested in a future phase with each of the datasets (physical, behavior and learning performance) being collected from students.","","Electronic:978-1-5090-2455-1; POD:978-1-5090-2456-8","10.1109/BHI.2016.7467133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467133","data mining;healthcare data analysis;learning analytics;machine learning;neural networks","Biological neural networks;Computational modeling;Correlation coefficient;Magnetic resonance imaging;Standards;Testing;Writing","geriatrics;health care;medical disorders;neurophysiology;patient diagnosis;psychology;statistical analysis","ADHD classifier;ADHD screening collect data;adult students;attention deficit hyperactivity disorder;current phase;diagnostic model;healthcare analytics;integrated computational model;mental health disorder;neural networks;neurological evaluations;psychiatric assessments;screening tools;statistical analysis;written language disorder;written performance data","","","","21","","","24-27 Feb. 2016","","IEEE","IEEE Conference Publications"
"Detection of Manhole Covers in High-Resolution Aerial Images of Urban Areas by Combining Two Methods","J. Pasquet; T. Desert; O. Bartoli; M. Chaumont; C. Delenne; G. Subsol; M. Derras; N. Chahinian","Berger-Levrault, Lab&#x00E8;ge, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20160422","2016","9","5","1802","1807","Mispositioning of buried utilities is an increasingly important problem both in industrialized and developing countries because of urban sprawl and technological advances. However, some of these networks have surface access traps, which may be visible on high-resolution airborne or satellite images and could serve as presence indicators. We put forward a methodology to detect manhole covers and grates on very high-resolution aerial and satellite images. Two methods are tested: the first is based on a geometrical circular filter, whereas the second one uses machine learning to retrieve some patterns. The results are compared and combined to benefit from the two approaches.","1939-1404;19391404","","10.1109/JSTARS.2015.2504401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373532","Buried utility network;circular object detection;geometrical filter;high resolution;machine learning","Image resolution;Indexes;Object detection;Roads;Satellites;Testing;Vegetation mapping","buried object detection;image filtering;image resolution;image retrieval;learning (artificial intelligence)","buried utilities;developing countries;geometrical circular filter;high-resolution airborne images;high-resolution satellite images;industrialized countries;machine learning;manhole cover detection;mispositioning;surface access traps;technological advances;urban areas;urban sprawl","","","","19","","20160106","May 2016","","IEEE","IEEE Journals & Magazines"
"Introduction to the special session on Topological Data Analysis, ICASSP 2016","H. Chintakunta; M. Robinson; H. Krim","Coordinated Science Lab., University of Illinois, Urbana Champaign","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6410","6414","Topological Data Analysis (TDA) is a topic which has recently seen many applications. The goal of this special session is to highlight the bridge between signal processing, machine learning and techniques in topological data analysis. In this way, we hope to encourage more engineers to start exploring TDA and its applications. This paper briefly introduces the standard techniques used in this area, delineates the common theme connecting the works presented in this session, and concludes with a brief summary of each of the papers presented.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472911","Topology;algebraic topology;data analysis;graph theory;machine learning;network processing;signal processing","Data analysis;Extraterrestrial measurements;Robustness;Shape;Signal processing;Three-dimensional displays;Topology","","","","","","26","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Sensing and Classifying Roadway Obstacles in Smart Cities: The Street Bump System","T. S. Brisimi; C. G. Cassandras; C. Osgood; I. C. Paschalidis; Y. Zhang","Department of Electrical and Computer Engineering, Division of Systems Engineering, Center for Information and Systems Engineering, Boston University, Boston, MA, USA","IEEE Access","20160414","2016","4","","1301","1312","We develop an infrastructure-free approach for anomaly detection and identification based on data collected through a smartphone application (Street Bump). The approach is capable of effectively classifying roadway obstacles into predefined categories using machine learning algorithms, as well as prioritizing actionable ones in need of immediate attention based on a proposed anomaly index. We explore some novel variants of classification algorithms that combine clustering with classification and introduce appropriate regularization in order to concentrate on a sparse set of most relevant features, which has the effect of reducing overfitting. Furthermore, the anomaly index we introduce combines novel metrics of obstacle irregularity computed based on the data captured by the Street Bump smartphone application. Results on an actual data set provided by the City of Boston illustrate the feasibility and the effectiveness of our system in practice.","2169-3536;21693536","","10.1109/ACCESS.2016.2529562","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405265","Classification;anomaly detection;machine learning;smart cities","Anomaly detection;Classification algorithms;Data models;Machine learning;Machine learning algorithms;Remote sensing;Smart cities;Smart phones;Urban areas","learning (artificial intelligence);mobile computing;pattern clustering;road traffic;smart cities;smart phones;traffic engineering computing","Boston City;Street Bump smartphone application;anomaly detection;anomaly index;infrastructure-free approach;machine learning algorithms;roadway obstacle classification;roadway obstacle sensing;smart cities;street bump system","","","","25","","20160211","2016","","IEEE","IEEE Journals & Magazines"
"Improving Access Point Association Protocols Through Channel Utilization and Adaptive Probing","T. Sun; Y. Zhang; W. Trappe","WINLAB, Rutgers University Technology Center of New Jersey 671 Route 1 South North Brunswick, NJ","IEEE Transactions on Mobile Computing","20160401","2016","15","5","1157","1167","We propose a distributed access point selection scheme by which nodes select an appropriate access point to associate with based upon each individual device's channel utilization. In this paper, we define channel utilization as the ratio of required bandwidth to estimated available bandwidth. By incorporating channel utilization into the access point selection protocol, we can effectively reduce unnecessary reassociations and improve upper layer performance such as throughput and packet delivery delay. We have further enhanced our association protocol by using reinforcement learning to dynamically schedule the probing of neighboring access points (APs), ultimately bringing down the probing overhead by learning from past experience. When channel utilization is combined with adaptive probing, we observe a significant performance improvement compared to traditional association approaches.","1536-1233;15361233","","10.1109/TMC.2015.2442254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128730","Wireless network;access point association;machine learning","Bandwidth;Downlink;Estimation;IEEE 802.11 Standards;Protocols;Switches;Throughput","learning (artificial intelligence);protocols","access point association protocols;access points;adaptive probing;association protocol;bandwidth estimation;channel utilization;distributed access point selection scheme;reinforcement learning","","0","","21","","20150619","May 1 2016","","IEEE","IEEE Journals & Magazines"
"An Extensible Framework for Predictive Analytics on Cost and Performance in the Cloud","S. Li; Y. Cao; S. Tao; X. Guo; Z. Dong; R. Sun","EMC Labs. China, EMC Corp., Beijing, China","2015 International Conference on Cloud Computing and Big Data (CCBD)","20160409","2015","","","13","20","As we are moving to the cloud, one challenge is the pressure to provide an accurate picture of ongoing resource costs and associated application performance. While cloud offerings give great flexibility to elastic applications, tenants lack guidance for choosing between multiple offerings. The lack of knowledge could lead to tenants over-provisioning and paying for resource that they do not actually need, or under-provisioning with suffering performance issues. In this work, we propose an extensible framework for predictive analytics on cost and performance in the cloud. Resource consumption data is collected and placed at readiness for enabling immediate analysis such as billing with the models of pay-as-you-go and lease. The time series data stored in a tiering object store supporting fast retrieve, as well as the heterogeneous types of data on application events and performance, are utilized to facilitate pattern analysis. These data aggregation, meanwhile, is put into considerations concerning correlation between cost and performance and their changing trends over time. Thus, by leveraging what-if analysis and real-time prediction, the framework gives a quite precise view of current status on cost and performance, as well as future perspectives, so as to support decision making on resource configuration with satisfaction of application's Service Level Agreement (SLA) requirements.","","Electronic:978-1-4673-8350-9; POD:978-1-4673-8351-6","10.1109/CCBD.2015.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450524","Application Performance;Cloud Computing;Machine Learning;Predictive Analytics;Resource Cost","Analytical models;Cloud computing;Data models;Monitoring;Predictive models;Real-time systems;Time series analysis","cloud computing;costing;performance evaluation","SLA requirements;application performance;cloud offerings;lease model;pay-as-you-go model;predictive analytics;resource consumption;resource costs;service level agreement;time series data;what-if analysis","","","","18","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Finding Demand for Products in the Social Web","P. Berger; P. Hennig; S. Bunk; D. Korsch; D. Kurzynski; C. Meinel","Hasso-Plattner-Inst., Univ. of Potsdam, Potsdam, Germany","2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)","20160505","2015","","","432","439","Finding potential customers in social networks is a hard challenge for today's businesses. But by listening to the noise of social network posts, we identify users, who express a demand for a certain product. We achieve this identification with a two-stage text categorization classifier: First, we detect whether the post expresses a demand for some product in general. Second, we detect, which product the post is about. By using the company's brochures, we minimize the integration effort for our system. However, this approach is difficult, because brochures differ from social network posts in style and length and only few brochures exist for each product. By employing feature selection and document sampling we are able to cope with these issues. Our evaluation has shown the practicability of this approach and supports our decisions for a two-stage classifier, document sampling and strict feature selection.","","Electronic:978-1-5090-1893-2; POD:978-1-5090-1894-9","10.1109/SmartCity.2015.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463763","demand;machine learning;product relevance;small corpus;text categorization","Advertising;Companies;Customer relationship management;Search engines;Social network services;Software;Training","business data processing;feature selection;pattern classification;social networking (online);text analysis","document sampling;feature selection;product brochures;product demand;social Web;social networks;two-stage text categorization classifier","","","","19","","","19-21 Dec. 2015","","IEEE","IEEE Conference Publications"
"Automatic Content Curation System for Multiple Live Sport Video Streams","K. Fujisawa; Y. Hirabe; H. Suwa; Y. Arakawa; K. Yasumoto","Nara Inst. of Sci. & Technol., Nara, Japan","2015 IEEE International Symposium on Multimedia (ISM)","20160328","2015","","","541","546","In this paper, we aim to develop a method to create personalized and high-presence multi-channel contents for a sport game through realtime content curation from various media streams captured/created by spectators. We use the live TV broadcast as a ground truth data and construct a machine learning-based model to automatically conduct curation from multiple videos which spectators captured from different angles and zoom levels. The live TV broadcast of a baseball game has some curation rules which select a specific angle camera for some specific scenes (e.g., a pitcher throwing a ball). As inputs for constructing a model, we use meta data such as image feature data (e.g., a pitcher is on the screen) in each fixed interval of baseball videos and game progress data (e.g., the inning number and the batting order). Output is the camera ID (among multiple cameras of spectators) at each point of time. For evaluation, we targeted Spring-Selection high-school baseball games. As training data, we used image features, game progress data, and the camera position at each point of time in the TV broadcast. We used videos of a baseball game captured from 7 different points in Hanshin Koshien Stadium with handy video cameras and generated sample data set by dividing the videos to fixed interval segments. We divided the sample data set into the training data set and the test data set and evaluated our method through two validation methods: (1) 10-fold crossvalidation method and (2) hold-out methods (e.g., learning first and second innings and testing third inning). As a result, our method predicted the camera switching timings with accuracy (F-measure) of 72.53% on weighted average for the base camera work and 92.1% for the fixed camera work.","","Electronic:978-1-5090-0379-2; POD:978-1-5090-0380-8; USB:978-1-5090-0378-5","10.1109/ISM.2015.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442393","CGM (Consumer Generated Media);artificial intelligence;live sport broadcast;machine learning;real-time video content curation;supervised learning","Cameras;Games;Metadata;Sports equipment;Streaming media;Switches;TV broadcasting","learning (artificial intelligence);video streaming","Hanshin Koshien Stadium;automatic content curation system;base camera;camera position;cross-validation method;fixed camera work;ground truth data;high-presence multichannel contents;hold-out methods;live TV broadcast;machine learning-based model;media streams;multiple live sport video streams;personalized contents;realtime content curation;spring-selection high-school baseball games","","","","14","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Exploring Parallel Implementations of the Bayesian Probabilistic Matrix Factorization","I. Chakroun; T. Haber; T. V. Aa; T. Kovac","ExaScience Life Lab. - IMEC, Leuven, Belgium","2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)","20160404","2016","","","119","126","Using the matrix factorization technique in machine learning is very common mainly in areas like recommender systems. Despite its high prediction accuracy and its ability to avoid over-fitting of the data, the Bayesian Probabilistic Matrix Factorization algorithm (BPMF) has not been widely used because of the prohibitive cost. In this paper, we propose a comprehensive parallel implementation of the BPMF using Gibbs sampling on shared and distributed architectures. We also propose an insight of a GPU-based implementation of this algorithm.","","Electronic:978-1-4673-8776-7; POD:978-1-4673-8777-4","10.1109/PDP.2016.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7445321","Collaborative filtering;Machine learning;PGAS;Probabilistic matrix factorization algorithm;multicore","Bayes methods;Electronics packaging;Instruction sets;Motion pictures;Multicore processing;Probabilistic logic;Recommender systems","Bayes methods;graphics processing units;learning (artificial intelligence);matrix decomposition;recommender systems","BPMF algorithm;Bayesian probabilistic matrix factorization algorithm;GPU-based implementation;Gibbs sampling;distributed architectures;machine learning;recommender systems","","","","18","","","17-19 Feb. 2016","","IEEE","IEEE Conference Publications"
"Visual Cultural Symbol Recognition Based on Muti-Feature Extracting","X. Tan; X. Wu; C. Yang","Sch. of Inf. Eng., Commun. Univ. of China, Beijing, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","2","","306","310","Visual cultural symbol (VCS) is common around us, and it's very important for cultural study. Especially, it's useful and efficient if we can study VCS through CS. In the Internet, Mostly VCS display as an image. Machine learning is emerging, but image recognition is focused on face or man detective, it's lack of VCS recognition study. Content based image classification techniques are gaining increasing popularity in the visual contents of the images for classifying images to their categories of interest which has been accomplished using various techniques. Feature extraction is an important part of the classification process. In this paper, we mainly using HOG (Histogram of Oriented Gradient), LBP (Local Binary Pattern), RGB, to extract the VCS's contour, texture, color features, respectively, and also comprehend them. The efficiency of feature extraction techniques to implement according to above methodologies are tested using the Support Vector Machines (SVM) Classifier. In all these techniques different degrees of image classification precision and recall has been calculated. There are some impressive conclusions which are made from our experiments.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.304","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469138","HOG;LBP;RGB;SVM;culture symbol recognition;machine learning","Cultural differences;Databases;Feature extraction;Histograms;Image color analysis;Support vector machines;Visualization","cultural aspects;feature extraction;image classification;image colour analysis;image texture;learning (artificial intelligence);support vector machines","HOG;LBP;RGB;SVM classifier;VCS;VCS color feature extraction;VCS contour feature extraction;VCS texture feature extraction;content-based image classification;histogram-of-oriented gradient;image classification precision;image classification recall;image recognition;local binary pattern;machine learning;mutifeature extraction;support vector machine classifier;visual cultural symbol recognition","","1","","12","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Automated Crack Detection on Concrete Bridges","P. Prasanna; K. J. Dana; N. Gucunski; B. B. Basily; H. M. La; R. S. Lim; H. Parvardeh","Department of Electrical and Computer Engineering, Rutgers University, Piscataway, NJ, USA","IEEE Transactions on Automation Science and Engineering","20160405","2016","13","2","591","599","Detection of cracks on bridge decks is a vital task for maintaining the structural health and reliability of concrete bridges. Robotic imaging can be used to obtain bridge surface image sets for automated on-site analysis. We present a novel automated crack detection algorithm, the STRUM (spatially tuned robust multifeature) classifier, and demonstrate results on real bridge data using a state-of-the-art robotic bridge scanning system. By using machine learning classification, we eliminate the need for manually tuning threshold parameters. The algorithm uses robust curve fitting to spatially localize potential crack regions even in the presence of noise. Multiple visual features that are spatially tuned to these regions are computed. Feature computation includes examining the scale-space of the local feature in order to represent the information and the unknown salient scale of the crack. The classification results are obtained with real bridge data from hundreds of crack regions over two bridges. This comprehensive analysis shows a peak STRUM classifier performance of 95% compared with 69% accuracy from a more typical image-based approach. In order to create a composite global view of a large bridge span, an image sequence from the robot is aligned computationally to create a continuous mosaic. A crack density map for the bridge mosaic provides a computational description as well as a global view of the spatial patterns of bridge deck cracking. The bridges surveyed for data collection and testing include Long-Term Bridge Performance program's (LTBP) pilot project bridges at Haymarket, VA, USA, and Sacramento, CA, USA.","1545-5955;15455955","","10.1109/TASE.2014.2354314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6917066","Adaboost;Laplacian pyramid;STRUM classifier;Seekur robot;bridge deck inspection;bridge maintenance;computer vision;concrete;crack detection;crack pattern recognition;homography;image mosaic;image stitching;machine learning;random forest;robotic imaging;robotic inspection;structural health monitoring;structure from motion;support vector machine","Bridges;Concrete;Image segmentation;Laplace equations;Robots;Robustness;Visualization","bridges (structures);condition monitoring;crack detection;curve fitting;image classification;image segmentation;learning (artificial intelligence);structural engineering computing","Haymarket;Robotic imaging;STRUM classifier;Sacramento;USA;automated crack detection;bridge mosaic;bridge surface image;concrete bridges;curve fitting;image thresholding;long-term bridge performance program;machine learning classification;reliability;spatially tuned robust multifeature classifier;structural health","","4","","31","","20141007","April 2016","","IEEE","IEEE Journals & Magazines"
"Using N-Gram Graphs for Sentiment Analysis: An Extended Study on Twitter","F. Aisopos; D. Tzannetos; J. Violos; T. Varvarigou","Knowledge & Media Syst. Group, Nat. Tech. Univ. of Athens, Athens, Greece","2016 IEEE Second International Conference on Big Data Computing Service and Applications (BigDataService)","20160523","2016","","","44","51","Tackling the challenges posed by Social Networking content and addressing its casual nature, n-gram graphs technique provides a language-independent supervised approach for text mining. Adopting this data analysis model, this paper provides an extended study of sentiment analysis, using a multilingual and multi-topic environment, employing and combining different classification algorithms, and attempting various configuration approaches on classification parameters to increase the efficiency. Compared to results found on big corpora used in previous studies, the outcome of the current paper implies a high classification accuracy and an enhanced validity, since the current experiments use datasets processed by human annotators.","","Electronic:978-1-5090-2251-9; POD:978-1-5090-2252-6","10.1109/BigDataService.2016.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474354","Sentiment Analysis;n-gram graphs;opinion mining;social media;supervised machine-learning","Analytical models;Big data;Dictionaries;Semantics;Sentiment analysis;Training;Twitter","classification;data mining;graph theory;social networking (online);text analysis","N-gram graphs;Twitter;big corpora;classification algorithms;classification parameters;data analysis model;high classification accuracy;human annotators;language-independent supervised;multilingual environment;multitopic environment;n-gram graphs technique;sentiment analysis;social networking content;text mining","","","","31","","","March 29 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Efficient Small Blob Detection Based on Local Convexity, Intensity and Shape Information","M. Zhang; T. Wu; S. C. Beeman; L. Cullen-McEwen; J. F. Bertram; J. R. Charlton; E. Baldelomar; K. M. Bennett","Department of Radiology, Mayo Clinic, Scottsdale","IEEE Transactions on Medical Imaging","20160331","2016","35","4","1127","1137","The identification of small structures (blobs) from medical images to quantify clinically relevant features, such as size and shape, is important in many medical applications. One particular application explored here is the automated detection of kidney glomeruli after targeted contrast enhancement and magnetic resonance imaging. We propose a computationally efficient algorithm, termed the Hessian-based Difference of Gaussians (HDoG), to segment small blobs (e.g. glomeruli from kidney) from 3D medical images based on local convexity, intensity and shape information. The image is first smoothed and pre-segmented into small blob candidate regions based on local convexity. Two novel 3D regional features (regional blobness and regional flatness) are then extracted from the candidate regions. Together with regional intensity, the three features are used in an unsupervised learning algorithm for auto post-pruning. HDoG is first validated in a 2D form and compared with other three blob detectors from literature, which are generally for 2D images only. To test the detectability of blobs from 3D images, 240 sets of simulated images are rendered for scenarios mimicking the renal nephron distribution observed in contrast-enhanced, 3D MRI. The results show a satisfactory performance of HDoG in detecting large numbers of small blobs. Two sets of real kidney 3D MR images (6 rats, 3 human) are then used to validate the applicability of HDoG for glomeruli detection. By comparing MRI to stereological measurements, we verify that HDoG is a robust and efficient unsupervised technique for 3D blobs segmentation.","0278-0062;02780062","","10.1109/TMI.2015.2509463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359134","Kidney;machine learning;quantification and estimation;segmentation;shape analysis","Biomedical imaging;Detectors;Feature extraction;Kidney;Magnetic resonance imaging;Shape;Three-dimensional displays","biomedical MRI;image segmentation;kidney;medical image processing;unsupervised learning","2D imaging;3D blob segmentation;3D medical imaging;3D regional features;Hessian-based Gaussian difference;auto post-pruning;automated detection;computationally efficient algorithm;contrast-enhanced 3D MR imaging;image segmentation;kidney;kidney glomeruli;local convexity;local intensity;magnetic resonance imaging;real kidney 3D MR imaging;renal nephron distribution;shape information;simulated imaging;small blob detection;stereological measurements;targeted contrast enhancement;unsupervised learning algorithm","","2","","29","","20151217","April 2016","","IEEE","IEEE Journals & Magazines"
"Hybrid <inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula>-Nearest Neighbor Classifier","Z. Yu; H. Chen; J. Liu; J. You; H. Leung; G. Han","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Cybernetics","20160513","2016","46","6","1263","1275","Conventional k-nearest neighbor (KNN) classification approaches have several limitations when dealing with some problems caused by the special datasets, such as the sparse problem, the imbalance problem, and the noise problem. In this paper, we first perform a brief survey on the recent progress of the KNN classification approaches. Then, the hybrid KNN (HBKNN) classification approach, which takes into account the local and global information of the query sample, is designed to address the problems raised from the special datasets. In the following, the random subspace ensemble framework based on HBKNN (RS-HBKNN) classifier is proposed to perform classification on the datasets with noisy attributes in the high-dimensional space. Finally, the nonparametric tests are proposed to be adopted to compare the proposed method with other classification approaches over multiple datasets. The experiments on the real-world datasets from the Knowledge Extraction based on Evolutionary Learning dataset repository demonstrate that RS-HBKNN works well on real datasets, and outperforms most of the state-of-the-art classification approaches.","2168-2267;21682267","","10.1109/TCYB.2015.2443857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7137658","Classification;ensemble learning;machine learning;nearest neighbor classifier;supervised learning","Computational efficiency;Euclidean distance;Noise;Noise measurement;Remote sensing;Training","knowledge acquisition;learning (artificial intelligence);pattern classification","KNN classification;RS-HBKNN;evolutionary learning dataset repository;high-dimensional space;hybrid k-nearest neighbor classifier;imbalance problem;knowledge extraction;noise problem;query sample;special datasets","","7","","102","","20150626","June 2016","","IEEE","IEEE Journals & Magazines"
"Learning to Detect Visual Grasp Affordance","H. O. Song; M. Fritz; D. Goehring; T. Darrell","Department of Computer Science, UC Berkeley, CA, USA","IEEE Transactions on Automation Science and Engineering","20160405","2016","13","2","798","809","Appearance-based estimation of grasp affordances is desirable when 3-D scans become unreliable due to clutter or material properties. We develop a general framework for estimating grasp affordances from 2-D sources, including local texture-like measures as well as object-category measures that capture previously learned grasp strategies. Local approaches to estimating grasp positions have been shown to be effective in real-world scenarios, but are unable to impart object-level biases and can be prone to false positives. We describe how global cues can be used to compute continuous pose estimates and corresponding grasp point locations, using a max-margin optimization for category-level continuous pose regression. We provide a novel dataset to evaluate visual grasp affordance estimation; on this dataset we show that a fused method outperforms either local or global methods alone, and that continuous pose estimation improves over discrete output models. Finally, we demonstrate our autonomous object detection and grasping system on the Willow Garage PR2 robot.","1545-5955;15455955","","10.1109/TASE.2015.2396014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051290","Affordance;autonomous agent;grasping;machine learning;object detection;pose estimation","Estimation;Grasping;Object detection;Pipelines;Robots;Training;Training data","image texture;object detection;pose estimation;regression analysis;robot vision","Willow Garage PR2 robot;autonomous object detection;category-level continuous pose regression;continuous pose estimates;grasp point locations;grasping system;local texture-like measures;max-margin optimization;object-category measures;visual grasp affordance estimation","","1","","33","","20150227","April 2016","","IEEE","IEEE Journals & Magazines"
"Emergency Informatics: Using Computing to Improve Disaster Management","R. R. Murphy","Texas A&amp;M University","Computer","20160513","2016","49","5","19","27","Three case studies of how two new emergency informatics tools--unmanned aerial vehicles and social media--were used to manage the 2015 Memorial Day weekend floods in Texas illustrate fundamental challenges and opportunities for computing research.","0018-9162;00189162","","10.1109/MC.2016.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469999","ESFs;UAVs;autonomous vehicles;computer vision;data analysis;data mining;decision support;disaster management;emergency informatics;emergency support functions;machine learning;project management;robotics;social media;unmanned aerial vehicles","Decision making;Disaster management;Emergency services;Floods;Informatics;Mobile communication;Stakeholders","autonomous aerial vehicles;disasters;emergency management;floods;social networking (online)","Memorial Day weekend floods;Texas;disaster management improvement;emergency informatics tools;social media;unmanned aerial vehicles","","2","","8","","","May 2016","","IEEE","IEEE Journals & Magazines"
"Neural Networks for Modeling and Control of Particle Accelerators","A. L. Edelen; S. G. Biedron; B. E. Chase; D. Edstrom; S. V. Milton; P. Stabile","Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO, USA","IEEE Transactions on Nuclear Science","20160420","2016","63","2","878","897","Particle accelerators are host to myriad nonlinear and complex physical phenomena. They often involve a multitude of interacting systems, are subject to tight performance demands, and should be able to run for extended periods of time with minimal interruptions. Often times, traditional control techniques cannot fully meet these requirements. One promising avenue is to introduce machine learning and sophisticated control techniques inspired by artificial intelligence, particularly in light of recent theoretical and practical advances in these fields. Within machine learning and artificial intelligence, neural networks are particularly well-suited to modeling, control, and diagnostic analysis of complex, nonlinear, and time-varying systems, as well as systems with large parameter spaces. Consequently, the use of neural network-based modeling and control techniques could be of significant benefit to particle accelerators. For the same reasons, particle accelerators are also ideal test-beds for these techniques. Many early attempts to apply neural networks to particle accelerators yielded mixed results due to the relative immaturity of the technology for such tasks. The purpose of this paper is to re-introduce neural networks to the particle accelerator community and report on some work in neural network control that is being conducted as part of a dedicated collaboration between Fermilab and Colorado State University (CSU). We describe some of the challenges of particle accelerator control, highlight recent advances in neural network techniques, discuss some promising avenues for incorporating neural networks into particle accelerator control systems, and describe a neural network-based control system that is being developed for resonance control of an RF electron gun at the Fermilab Accelerator Science and Technology (FAST) facility, including initial experimental results from a benchmark controller.","0018-9499;00189499","","10.1109/TNS.2016.2543203","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454846","Adaptive control;artificial intelligence;control systems;machine learning;neural networks;particle accelerators;predictive control","Analytical models;Artificial intelligence;Artificial neural networks;Control systems;Linear particle accelerator;Particle accelerators","accelerator RF systems;high energy physics instrumentation computing;learning (artificial intelligence);neural nets","Colorado State University;Fermilab Accelerator Science and Technology facility;Fermilab facility;RF electron gun;artificial intelligence;benchmark controller;complex physical phenomena;control techniques;diagnostic analysis;interacting systems;machine learning;myriad nonlinear phenomena;neural network control;neural network techniques;neural network-based control system;neural network-based modeling;nonlinear system;parameter spaces;particle accelerator community;particle accelerator control;particle accelerator control systems;particle accelerator modeling;resonance control;test-beds;tight performance demands;time-varying system","","","","127","","","April 2016","","IEEE","IEEE Journals & Magazines"
"Sentiment classification techniques for Arabic language: A survey","M. Biltawi; W. Etaiwi; S. Tedmori; A. Hudaib; A. Awajan","Princess Sumaya University for Technology, Amman. Jordan","2016 7th International Conference on Information and Communication Systems (ICICS)","20160523","2016","","","339","346","With the advent of online data, sentiment analysis has received growing attention in recent years. Sentiment analysis aims to determine the overall sentiment orientation of a speaker or writer towards a specific entity or towards a specific feature of a specific entity. A fundamental task of sentiment analysis is sentiment classification, which aims to automatically classify opinionated text as being positive, negative, or neutral. Although the literature on sentiment classification is quite extensive, only a few endeavors to classify opinionated text written in the Arabic language can be found. This paper provides a comprehensive survey of existing lexicon, machine learning, and hybrid sentiment classification techniques for Arabic language.","","Electronic:978-1-4673-8614-2; POD:978-1-4673-8615-9","10.1109/IACS.2016.7476075","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476075","Classification;Lexicon;Machine learning;Opinion;Sentiment","Classification algorithms;Dictionaries;Niobium;Semantics;Sentiment analysis;Standards;Support vector machines","learning (artificial intelligence);natural language processing;pattern classification;sentiment analysis","Arabic language;lexicon;machine learning;online data;opinionated text classification;sentiment analysis;sentiment classification techniques;sentiment orientation;speaker;writer","","1","","47","","","5-7 April 2016","","IEEE","IEEE Conference Publications"
"Analysis of Overlapping Voltammograms of Nitrophenols Combining Genetic Algorithms and Support Vector Machines","G. Ling; R. Shouxin","Dept. of Chem., Inner Mongolia Univ., Huhhot, China","2015 8th International Conference on Intelligent Computation Technology and Automation (ICICTA)","20160519","2015","","","182","185","This paper suggests a novel method named GA-LSSVM, combines genetic algorithms (GA) and least squares support vector machines (LS-SVM) techniques to provide a powerful model for improving the regression quality and to enhance the ability to extract characteristic information. Simultaneous differential pulse voltammetric multi-component determination of o-nitro phenol, m-nitro phenol and pnitrophenol was conducted for the first time by using the proposed method. The LS-SVM technique broadens the application of SVM by reducing the computational complexity since only the solution of a set of linear equations is required instead of a quadratic programming problem. Thus, LS-SVM has the capability of solving linear and nonlinear multivariate calibrations in a relatively fast way. Genetic algorithms (GA) introduced are probabilistic optimization techniques based on natural evolution and genetics and Darwin's theory of survival of the best. The GA-LS-SVM method is proven to be successful even when severe overlap of voltammograms existed.","","Electronic:978-1-4673-7644-0; POD:978-1-4673-7645-7","10.1109/ICICTA.2015.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7473265","Genetic algorithms;Machine learning;Nitrophenols;Overlapping voltammograms;Support vector machines","Biological cells;Genetic algorithms;Mathematical model;Optimization;Sociology;Statistics;Support vector machines","calibration;chemical engineering computing;computational complexity;genetic algorithms;least squares approximations;probability;quadratic programming;regression analysis;support vector machines","Darwin's theory;GA-LSSVM;LS-SVM;computational complexity;differential pulse voltammetric multicomponent determination;genetic algorithms;least squares support vector machines;linear equations;linear multivariate calibration;m-nitro phenol;natural evolution;nitrophenols;nonlinear multivariate calibration;o-nitrophenol;overlapping voltammograms;p-nitrophenol;probabilistic optimization;quadratic programming problem;regression quality improvement","","","","9","","","14-15 June 2015","","IEEE","IEEE Conference Publications"
"Generating iconic gestures based on graphic data analysis and clustering","Y. Kadono; Y. Takase; Y. I. Nakano","Guraduate School of Science and Technology, Seikei University, Musashino-shi, Tokyo, Japan","2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","20160414","2016","","","447","448","Gesture generation is one of the most important tasks in humanoid interfaces because hand gestures by humanoid robots and animated agents are useful in improving the comprehensibility of conversation content. This study proposes a method for automatically generating iconic drawing gestures using image processing and machine learning techniques. First, we collected a set of graphic images for over 1000 objects and classified the objects into 4 types of shapes; these shapes were used as the drawing gesture shapes. By implementing a gesture shape decision mechanism, we also built a system that takes a sentence as the system input and produces hand gesture animations that are synchronized with synthetic speech.","","Electronic:978-1-4673-8370-7; POD:978-1-4673-8371-4","10.1109/HRI.2016.7451799","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451799","drawing gesture;gesture generation;iconic;image processing;machine learning","Animation;Dictionaries;Image processing;Shape;Speech;Synchronization;Visualization","computer animation;gesture recognition;graphical user interfaces;image classification;learning (artificial intelligence);pattern clustering;speech-based user interfaces","animated agents;automatic iconic drawing gesture generation;conversation content comprehensibility improvement;gesture shape decision mechanism;gesture shape drawing;graphic data analysis;graphic data clustering;graphic images;hand gesture animations;hand gestures;humanoid interfaces;humanoid robots;image processing;machine learning;object classification;object shapes;synthetic speech;system input","","","","6","","","7-10 March 2016","","IEEE","IEEE Conference Publications"
"Unsupervised SPITters Detection Scheme for Unbalanced Callers","K. Toyoda; M. Park; O. Naonobu","Kanagawa Inst. of Technol., Atsugi, Japan","2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)","20160519","2016","","","64","68","As the IP-based telephony service is getting popular, new attackers called SPITters (Spam over Internet Telephony callers) who advertise products and conduct a survey is being emerged and it is urgent demand to detect them. Recently, a novel unsupervised SPITters detection scheme, which leverages a clustering algorithm, has been proposed. However, this scheme does not work well when the SPITters account for a small fraction of the entire caller. In this paper, we propose a new unsupervised SPITters detection scheme by adding artificial data to solve such unbalanced situation. Our scheme will avoid some of the legitimate callers from being clustered into the SPITters' cluster and the classification performance will be improved. We show the efficiency of the proposed scheme by means of computer simulation with real and artificial call log datasets.","","Electronic:978-1-5090-2461-2; POD:978-1-5090-2462-9","10.1109/WAINA.2016.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471174","SPIT;VoIP;security;unsupervised machine learning","Clustering algorithms;Computer simulation;Feature extraction;IEEE merchandise;Internet telephony;Privacy;Telephony","Internet telephony;computer network security;unsolicited e-mail","IP-based telephony service;artificial call log datasets;classification performance improvement;clustering algorithm;computer simulation;product advertisement;real call log datasets;spam-over-Internet telephony callers;survey conducting;unbalanced callers;unsupervised SPITters detection scheme","","","","14","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Weighted-guided-filter-aided texture classification using recursive feature elimination-based fusion of feature sets","D. Choudhury; A. Bhattacharya","Dept. Of Electrical Engineering, Jadavpur University, Jadavpur, Kolkata","2015 IEEE International Conference on Computer Graphics, Vision and Information Security (CGVIS)","20160409","2015","","","126","130","In this work, a method is proposed for classification of texture images using a fusion of feature sets. Weighted guided filter based preprocessing technique has been performed using optimized cost function to enhance the discriminative property of different texture images. A hybrid model of normalized symmetrical gray level co-occurrence matrix parameters, histogram of oriented gradients, and Gabor features is used to extract the feature from the preprocessed images. The fusion model is fed to recursive feature elimination algorithm to select the appropriate feature sets for efficient classification. These feature vectors have been trained in two machine learning algorithms namely, multiclass support vector machine and extreme learning machine. It is experimentally demonstrated that proposed method achieves satisfactory efficiency on Outex, XU_HR, and UIUC texture image database. This method is also successfully applied on TEXDC database to identify the material of textile from images by recognizing the fibrous pattern of various textile images.","","CD-ROM:978-1-4673-7436-1; Electronic:978-1-4673-7437-8; POD:978-1-4673-7438-5","10.1109/CGVIS.2015.7449906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449906","Extreme learning machine;Gabor feature;Gray level co-occurrence matrix;Histogram of oriented gradient;Multiclass support vector machine;Recursive Feature Elimination;Texture classification;Weighted guided filter","Databases;Feature extraction;Filter banks;Filtering algorithms;Gabor filters;Histograms;Kernel","feature extraction;filtering theory;image classification;image texture;learning (artificial intelligence);support vector machines","Outex texture image database;TEXDC database;UIUC texture image database;XU_HR texture image database;extreme learning machine;feature extraction;histogram of oriented gradients;image texture classification;machine learning algorithms;multiclass support vector machine;normalized symmetrical gray level co-occurrence matrix parameter;recursive feature elimination algorithm;recursive feature elimination-based fusion;weighted guided filter based preprocessing technique;weighted-guided-filter-aided texture classification","","","","23","","","2-3 Nov. 2015","","IEEE","IEEE Conference Publications"
"Estimation of Seismic Vulnerability Levels of Urban Structures With Multisensor Remote Sensing","C. Geiß; M. Jilge; T. Lakes; H. Taubenböck","German Aerospace Center (DLR), German Remote Sensing Data Center (DFD), Oberpfaffenhofen-We&#x00DF;ling, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20160425","2016","9","5","1913","1936","The ongoing global transformation of human habitats from rural villages to ever growing urban agglomerations induces unprecedented seismic risks in earthquake prone regions. To mitigate affiliated perils requires the seismic assessment of built environments. Numerous studies emphasize that remote sensing can play a valuable role in supporting the extraction of relevant features for preevent vulnerability analysis. However, the majority of approaches operate on building level. This induces the deployment of very high spatial resolution remote sensing data, which hampers, nowadays, utilization capabilities for larger areas due to data costs and processing requirements. In this paper, we alter the spatial scale of analysis and propose concepts and methods to estimate the seismic vulnerability level of homogeneous urban structures. A procedure is designed, which comprises four main steps dedicated to: 1) delineation of urban structures by means of a tailored unsupervised data segmentation procedure with scale optimization; 2) characterization of urban structures by a joint exploitation of multisensor data; 3) selection of most feasible features under consideration of in situ vulnerability information; and 4) estimation of seismic vulnerability levels of urban structures within a supervised learning framework. We render the prediction problem in three ways to address operational requirements that can evolve in real-life situations. 1) To discriminate two or more classes based on labeled samples of all classes present in the data under investigation, we use the framework of soft margin support vector machines (C-SVM). 2) To consider situations, where solely labeled samples are available for the class(es) of interest and not for all classes present in the data, we deploy ensembles of ν-one-class SVM (ν-OC-SVM). and 3) To fit data with a higher statistical level of measurement (interval or ratio scal- ), we utilize a support vector regression (SVR) approach to estimate a regression function from the training samples. Experimental results are obtained for the earthquake-prone mega city Istanbul, Turkey. We use multispectral data from the RapidEye constellation, elevation measurements from the TanDEM-X mission, and spatiotemporal analyses based on data from the Landsat archive to characterize the urban environment. In addition, different in situ data sets are incorporated for Istanbul's district Zeytinburnu and the residual settlement area of Istanbul. When estimating damage grades for Zeytinburnu with SVR, best models are characterized by mean absolute percentage errors less than 11%, and fairly strong goodness of fit (R > 0.75). When aiming to identify different types of urban structures for the remaining settlement area of Istanbul (i.e., urban structures determined by large industrial/commercial buildings and tall detached residential buildings, which can be considered here as highly and slightly vulnerable, respectively), results obtained with C-SVM show a distinctive increase of accuracy compared to results obtained with ensembles of ν-OC-SVM. The latter were not able to exceed moderate agreements, with κ statistics slightly above 0.45. Instead, C-SVM allowed obtaining ν statistics expressing substantial and even excellent agreements (κ > 0.6 up to κ > 0.8). Overall, analyzes provide very promising empirical evidence, which confirms the potential of remote sensing to support seismic vulnerability assessment.","1939-1404;19391404","","10.1109/JSTARS.2015.2442584","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150321","Earthquakes;Istanbul;Landsat;RapidEye;TanDEM-X;machine learning;object-based image analysis;seismic vulnerability assessment;support vector machines (SVM)","Buildings;Earth;Earthquakes;Remote sensing;Satellites;Spatial resolution;Time division multiplexing","earthquakes;geophysical image processing;geophysical techniques;remote sensing;seismology;support vector machines","Landsat archive;RapidEye constellation;TanDEM-X mission;Turkey;Zeytinburnu;data processing;earthquake prone region;earthquake-prone mega city Istanbul;high spatial resolution remote sensing data;homogeneous urban structures;human habitats;multisensor remote sensing;ongoing global transformation;rural villages;seismic assessment;seismic vulnerability assessment;seismic vulnerability level estimation;soft margin support vector machines;spatiotemporal analysis;supervised learning framework;support vector regression;tailored unsupervised data segmentation procedure;unprecedented seismic risks;urban agglomerations;urban environment;urban structures","","2","","103","","20150706","May 2016","","IEEE","IEEE Journals & Magazines"
"A Methodology for Automatically 3D Geological Modeling Based on Geophysical Data Grids","X. Yu; Y. Xu","Hubei Subsurface Multi-scale Imaging Key Lab., China Univ. of Geosci., Wuhan, China","2015 8th International Conference on Intelligent Computation Technology and Automation (ICICTA)","20160519","2015","","","40","43","Using 3D visualization models to exhibit geological structure has become a trend in geological studies. Compared to 2D geological mapping, 3D geological modeling is dependent on more geological sampling information. In many cases, however, the geological sampling information is difficult to acquire by drilling (especially for deep subsurface information). Geophysical methods (e.g., Gravity, seismic, and electric) have become the major tools in geological modeling. Because the geophysical data are recorded in a data grid, people must extract the geological information from various data grids acquired through different geophysical methods and subsequently integrate the information to manually construct a 3D geological model. This approach usually causes inconvenience and inefficiencies in practice. Therefore, we propose a methodology of automatically 3D geological modeling based on geophysical data grids. The method first constructs visualization models from different geophysical data grids and subsequently integrates these models for interpretation using mapping rules learned from physical properties of rock samples measured in a laboratory and finally converts the interpreted visualization model to a 3D geological model. With the application in the practical work, the result demonstrates that the methodology can effectively solve problems of 3D geological modeling in the case of enriched geophysical data lacking sufficient geological sampling information.","","Electronic:978-1-4673-7644-0; POD:978-1-4673-7645-7","10.1109/ICICTA.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7473231","3D geological modeling;data visualization;machine learning","Data mining;Data models;Data visualization;Geology;Geophysical measurements;Solid modeling;Three-dimensional displays","data visualisation;geology;geophysical techniques;geophysics computing;rocks","3D visualization models;automatically 3D geological modeling;geological sampling information;geophysical data grids;geophysical methods;rock physical properties","","","","16","","","14-15 June 2015","","IEEE","IEEE Conference Publications"
"Empirical evaluation of K-Means, Bisecting K-Means, Fuzzy C-Means and Genetic K-Means clustering algorithms","S. Banerjee; A. Choudhary; S. Pal","Department of Computer Science and Technology, Indian Institute of Engineering Science and Technology, Shibpur, Howrah, India","2015 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE)","20160331","2015","","","168","172","Clustering is one of the most widely studied problem in machine learning and data mining. The algorithms for clustering depend on the application scenario and data domain. K-Means algorithm is one of the most popular clustering techniques that depend on distance measure. In this work, an extensive empirical evaluation of three significant variations of K-Means algorithm is carried out on the basis of six internal and external validity indices. It has been seen that performance of K-Means and Bisecting K-Means are similar, while Fuzzy C-Means gives better performance and Genetic K-Means performs the best. On the light of empirical result obtained in this paper, method for further improvement of the performance of Genetic K-Means is suggested.","","DVD:978-1-4673-8785-9; Electronic:978-1-4673-8786-6; POD:978-1-4673-8787-3","10.1109/WIECON-ECE.2015.7443889","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443889","K-Means algorithm;clustering;distance measure;internal and external validity indices;machine learning","Algorithm design and analysis;Clustering algorithms;Genetic algorithms;Genetics;Indexes;Machine learning algorithms;Partitioning algorithms","data mining;fuzzy set theory;genetic algorithms;learning (artificial intelligence);pattern clustering","bisecting k-means clustering algorithms;data domain;data mining;distance measure;external validity indices;fuzzy c-means clustering algorithms;genetic algorithm;genetic k-means clustering algorithms;internal validity indices;machine learning","","","","18","","","19-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"AlgorithmSeer: A System for Extracting and Searching for Algorithms in Scholarly Big Data","S. Tuarob; S. Bhatia; P. Mitra; C. L. Giles","Faculty of Information and Communication Technology, Mahidol University, Salaya, Thailand","IEEE Transactions on Big Data","20160519","2016","2","1","3","17","Algorithms are usually published in scholarly articles, especially in the computational sciences and related disciplines. The ability to automatically find and extract these algorithms in this increasingly vast collection of scholarly digital documents would enable algorithm indexing, searching, discovery, and analysis. Recently, AlgorithmSeer, a search engine for algorithms, has been investigated as part of CiteSeer' with the intent of providing a large algorithm database. Currently, over 200,000 algorithms have been extracted from over 2 million scholarly documents. This paper proposes a novel set of scalable techniques used by AlgorithmSeer to identify and extract algorithm representations in a heterogeneous pool of scholarly documents. Specifically, hybrid machine learning approaches are proposed to discover algorithm representations. Then, techniques to extract textual metadata for each algorithm are discussed. Finally, a demonstration version of AlgorithmSeer that is built on Solr/Lucene open source indexing and search system is presented.","","","10.1109/TBDATA.2016.2546302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448389","Algorithm search engine;ensemble machine learning;scholarly big data","Algorithm design and analysis;Big data;Data mining;Machine learning algorithms;Metadata;Search engines;Software algorithms","Big Data;database indexing;document handling;learning (artificial intelligence);meta data;public domain software;search engines","AlgorithmSeer;CiteSeer;Solr/Lucene open source indexing and search system;algorithm analysis;algorithm discovery;algorithm indexing;algorithm representation extraction;algorithm representation identification;algorithm searching;hybrid machine learning approach;large algorithm database;scholarly digital documents;search engine;textual metadata extraction","","1","","39","","20160406","March 1 2016","","IEEE","IEEE Journals & Magazines"
"Severity prediction of software bugs","A. F. Otoom; D. Al-Shdaifat; M. Hammad; E. E. Abdallah","Faculty of Prince Al-Hussein Bin Abdullah II for Information Technology, The Hashemite University, Zarqa, Jordan","2016 7th International Conference on Information and Communication Systems (ICICS)","20160523","2016","","","92","95","We target the problem of identifying the severity of a bug report. Our main aim is to develop an intelligent system that is capable of predicting the severity of a newly submitted bug report through a bug tracking system. For this purpose, we build a dataset consisting of 59 features characterizing 163 instances that belong to two classes: severe and non-severe. We combine the proposed feature set with strong classification algorithms to assist in predicting the severity of bugs. Moreover, the proposed algorithms are integrated within a boosting algorithm for an enhanced performance. Our results show that the proposed technique has proved successful with a classification performance accuracy of more than 76% with the AdaBoost algorithm and cross validation test. Moreover, boosting has been effective in enhancing the performance of its base classifiers with improvements of up to 4.9%.","","Electronic:978-1-4673-8614-2; POD:978-1-4673-8615-9","10.1109/IACS.2016.7476092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476092","Adaboost;machine learning;severity predection;software bugs","Boosting;Classification algorithms;Computer bugs;Feature extraction;Radial basis function networks;Software;Vegetation","knowledge based systems;learning (artificial intelligence);pattern classification;program debugging","AdaBoost algorithm;bug tracking system;classification algorithms;intelligent system;severity prediction;software bugs","","","","12","","","5-7 April 2016","","IEEE","IEEE Conference Publications"
"An approach to face shape classification for hairstyle recommendation","W. Sunhem; K. Pasupa","Faculty of Information Technology, King Mongkut's Institute of Technology Ladkrabang, Bangkok 10520, Thailand","2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)","20160409","2016","","","390","394","It is important to choose a good hairstyle for women because it can enhance their beauty, personality, and confidence. One of the most important factors to consider for choosing the right hairstyle is the individuals face shape. An effective face shape classification can be used for constructing a hairstyle recommendation system. This paper presents a classification approach that divides face shapes into 5 different shapes: round, oval, oblong, square, and heart. This approach, which is based on an Active Appearance Model (AAM) and a face segmentation technique, produces a set of features that can be evaluated by several popular machine learning methods, namely, Linear Discriminant Analysis (LDA), Artificial Neural Networks (ANN), and Support Vector Machine (SVM). Our results show that the Support Vector Machine with Radial Basis function kernel was the best algorithm that predicted accurately up to 72%.","","CD-ROM:978-1-4673-7778-2; Electronic:978-1-4673-7782-9; POD:978-1-4673-7783-6","10.1109/ICACI.2016.7449857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449857","face shape classification;hairstyle recommendation;machine learning","Active appearance model;Face;Feature extraction;Heart;Shape;Support vector machines;Training","face recognition;image classification;neural nets;statistical analysis;support vector machines","AAM;ANN;LDA;SVM;active appearance model;artificial neural networks;face segmentation technique;face shape classification approach;hairstyle recommendation system;linear discriminant analysis;machine learning methods;support vector machine","","1","","9","","","14-16 Feb. 2016","","IEEE","IEEE Conference Publications"
"Improving Computer-Aided Detection Using Convolutional Neural Networks and Random View Aggregation","H. R. Roth; L. Lu; J. Liu; J. Yao; A. Seff; K. Cherry; L. Kim; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, MD, USA","IEEE Transactions on Medical Imaging","20160503","2016","35","5","1170","1181","Automated computer-aided detection (CADe) has been an important tool in clinical practice and research. State-of-the-art methods often show high sensitivities at the cost of high false-positives (FP) per patient rates. We design a two-tiered coarse-to-fine cascade framework that first operates a candidate generation system at sensitivities ~ 100% of but at high FP levels. By leveraging existing CADe systems, coordinates of regions or volumes of interest (ROI or VOI) are generated and function as input for a second tier, which is our focus in this study. In this second stage, we generate 2D (two-dimensional) or 2.5D views via sampling through scale transformations, random translations and rotations. These random views are used to train deep convolutional neural network (ConvNet) classifiers. In testing, the ConvNets assign class (e.g., lesion, pathology) probabilities for a new set of random views that are then averaged to compute a final per-candidate classification probability. This second tier behaves as a highly selective process to reject difficult false positives while preserving high sensitivities. The methods are evaluated on three data sets: 59 patients for sclerotic metastasis detection, 176 patients for lymph node detection, and 1,186 patients for colonic polyp detection. Experimental results show the ability of ConvNets to generalize well to different medical imaging CADe applications and scale elegantly to various data sets. Our proposed methods improve performance markedly in all cases. Sensitivities improved from 57% to 70%, 43% to 77%, and 58% to 75% at 3 FPs per patient for sclerotic metastases, lymph nodes and colonic polyps, respectively.","0278-0062;02780062","","10.1109/TMI.2015.2482920","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279156","Computer aided diagnosis;artificial neural networks;computed tomography;deep learning;machine learning;medical diagnostic imaging;multi-layer neural network;object detection","Colonic polyps;Computed tomography;Feature extraction;Lymph nodes;Three-dimensional displays;Training","computerised tomography;image classification;learning (artificial intelligence);medical image processing;neural nets;probability","classification probability;colonic polyp detection;computed tomography;computer-aided detection;deep convolutional neural network classifier training;false positives;lymph node detection;medical imaging;random rotations;random translations;random view aggregation;scale transformations;sclerotic metastasis detection;two-tiered coarse-to-fine cascade framework","","6","","60","","20150928","May 2016","","IEEE","IEEE Journals & Magazines"
"Active learning for magnetic resonance image quality assessment","A. Liebgott; T. Küstner; S. Gatidis; F. Schick; B. Yang","Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","922","926","In medical imaging, the acquired images are usually analyzed by a human observer and rated with respect to a diagnostic question. However, this procedure is time-demanding and expensive. Further more, the lack of a reference image makes this task challenging. In order to support the human observer in assessing image quality and to ensure an objective evaluation, we extend in this paper our previous no-reference magnetic resonance (MR) image quality assessment system with an active learning loop to reduce the amount of necessary labeled training data. We employ two different active learning query strategies based on uncertainty sampling. Since the classification task is performed on 2D image slices, but the human observer labels complete 3D image volumes, we present a method to select representative 3D images instead of independant 2D image slices. The performance is evaluated on in-vivo MR image data.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471810","active learning;blind image quality assessment;machine-learning;magnetic resonance imaging","Distortion;Image quality;Labeling;Magnetic resonance imaging;Support vector machines;Three-dimensional displays;Training","biomedical MRI;image classification;image sampling;learning (artificial intelligence);medical image processing;query processing","2D image slices;3D image volumes;active learning loop;active learning query strategies;classification task;magnetic resonance image quality assessment;medical imaging;uncertainty sampling","","","","34","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Distributed Differentially Private Stochastic Gradient Descent: An Empirical Study","I. Hegedus; M. Jelasity","MTA-SZTE Res. Group on AI, Univ. of Szeged, Szeged, Hungary","2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)","20160404","2016","","","566","573","In fault-prone large-scale distributed environments stochastic gradient descent (SGD) is a popular approach to implement machine learning algorithms. Data privacy is a key concern in such environments, which is often addressed within the framework of differential privacy. The output quality of differentially private SGD implementations as a function of design choices has not yet been thoroughly evaluated. In this study, we examine this problem experimentally. We assume that every data record is stored by an independent node, which is a typical setup in networks of mobile devices or Internet of things (IoT) applications. In this model we identify a set of possible distributed differentially private SGD implementations. In these implementations all the sensitive computations are strictly local, and any public information is protected by differentially private mechanisms. This means that personal information can leak only if the corresponding node is directly compromised. We then perform a set of experiments to evaluate these implementations over several machine learning problems with both logistic regression and support vector machine (SVM) loss functions. Depending on the parameter setting and the choice of the algorithm, the performance of the noise-free algorithm can be closely approximated by differentially private variants.","","Electronic:978-1-4673-8776-7; POD:978-1-4673-8777-4","10.1109/PDP.2016.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7445391","distributed differential privacy;machine learning;stochastic gradient descent","Computational modeling;Data privacy;Databases;Peer-to-peer computing;Privacy;Support vector machines;Training","Internet of Things;data privacy;gradient methods;learning (artificial intelligence);support vector machines","Internet of things applications;IoT;SVM;data privacy;design choices;differential privacy;differentially private variants;distributed differentially private SGD implementations;distributed differentially private stochastic gradient descent;fault-prone large-scale distributed environments stochastic gradient descent;machine learning algorithms;noise-free algorithm;private SGD implementations;support vector machine loss functions","","","","23","","","17-19 Feb. 2016","","IEEE","IEEE Conference Publications"
"An Unlicensed Taxi Identification Model Based on Big Data Analysis","W. Yuan; P. Deng; T. Taleb; J. Wan; C. Bi","Institute of Software, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Intelligent Transportation Systems","20160526","2016","17","6","1703","1713","Social networks and mobile networks are exposing human beings to a big data era. With the support of big data analytics, conventional intelligent transportation systems (ITS) are gradually changing into data-driven ITS (D<sup>2</sup> ITS). Along with traffic growth, D<sup>2</sup>ITS need to solve more real-life problems, including the issue of unlicensed taxis and their identification, which potentially disrupts the taxi business sector and endangers society safety. As a remedy to this issue, a smart model is proposed in this paper to identify unlicensed taxis. The proposed model consists of two submodel components, namely, candidate selection model and candidate refined model. The former is used to screen out a coarse-grained suspected unlicensed taxi candidate list. The list is taken as an input for the candidate refined model, which is based on machine learning to get a fine-grained list of suspected unlicensed taxis. The proposed model is evaluated using real-life data, and the obtained results are encouraging, demonstrating its efficiency and accuracy in identifying unlicensed taxis, helping governments to better regulate the traffic operation and reduce associated costs.","1524-9050;15249050","","10.1109/TITS.2015.2498180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336538","Big data;data-driven ITS;intelligent transportation systems;machine learning;unlicensed taxi","Big data;Data models;Licenses;Public transportation;Real-time systems;Vehicles","Big Data;cost reduction;data analysis;intelligent transportation systems;learning (artificial intelligence);mobile computing;road vehicles;social networking (online)","Big Data analysis;Big Data analytics;D<sup>2</sup> ITS;associated cost reduction;candidate refined model;candidate selection model;coarse-grained suspected unlicensed taxi candidate list;data-driven ITS;intelligent transportation systems;machine learning;mobile networks;smart model;social networks;submodel components;taxi business sector;traffic operation;unlicensed taxi identification model","","10","","47","","20151124","June 2016","","IEEE","IEEE Journals & Magazines"
"Haze detection and haze degree estimation using dark channels and contrast histograms","C. W. Wang; J. J. Ding; L. A. Chen","Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan","2015 10th International Conference on Information, Communications and Signal Processing (ICICS)","20160428","2015","","","1","5","Haze and mist always affect the quality of vision. If an image is suffered from haze or mist, then the object is unclear and the image seems whiter than the original one. There are several haze removal algorithms that can reduce the effect of haze and mist. However, if an image is not suffered from the haze and mist, applying the haze removal algorithm may darken the image. Therefore, in computer vision, it is important to determine whether an image is suffered from haze or mist. In this paper, we propose an algorithm that applies the histograms of contrast and dark channels together with the support vector machine to determine whether an image is interfered by haze or mist and the degree of the interference. Simulations show that the proposed algorithm can well distinguish the haze/ mist image from a normal image and accurately determine the haze degree of each image.","","Electronic:978-1-4673-7218-3; POD:978-1-4673-7219-0; USB:978-1-4673-7217-6","10.1109/ICICS.2015.7459885","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459885","Computer Vision;Dark Channel;Haze Detection;Machine Learning","Classification algorithms;Computational modeling;Estimation;Kernel;Support vector machines;Testing;Training","computer vision;estimation theory;object detection;support vector machines","computer vision;contrast histograms;dark channels;haze degree estimation;haze detection;haze removal algorithms;interference;support vector machine","","","","13","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"Localizing Multiple Faults in Simulink Models","B. Liu; Lucia; S. Nejati; L. Briand; T. Bruckmann","SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg","2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","20160523","2016","1","","146","156","As Simulink is a widely used language in the embedded industry, there is a growing need to support debugging activities for Simulink models. In this work, we propose an approach to localize multiple faults in Simulink models. Our approach builds on statistical debugging and is iterative. At each iteration, we identify and resolve one fault and re-test models to focus on localizing faults that might have been masked before. We use decision trees to cluster together failures that satisfy similar (logical) conditions on model blocks or inputs. We then present two alternative selection criteria to choose a cluster that is more likely to yield the best fault localization results among the clusters produced by our decision trees. Engineers are expected to inspect the ranked list obtained from the selected cluster to identify faults. We evaluate our approach on 240 multi-fault models obtained from three different industrial subjects. We compare our approach with two baselines: (1) Statistical debugging without clustering, and (2) State-of-the-art clustering-based statistical debugging. Our results show that our approach significantly reduces the number of blocks that engineers need to inspect in order to localize all faults, when compared with the two baselines. Furthermore, with our approach, there is less performance degradation than in the baselines when increasing the number of faults in the underlying models.","","Electronic:978-1-5090-1855-0; POD:978-1-5090-1856-7","10.1109/SANER.2016.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476638","Fault localization;Simulink models;decision trees;machine learning;statistical debugging","Adaptation models;Debugging;Decision trees;Fault diagnosis;Numerical models;Software packages;Testing","decision trees;digital simulation;pattern clustering;program debugging;software fault tolerance","Simulink models;clustering-based statistical debugging;decision trees;multifault models;multiple fault localization","","","","41","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"Developing a Model-Based Drinking Water Decision Support System Featuring Remote Sensing and Fast Learning Techniques","S. Imen; N. B. Chang; Y. J. Yang; A. Golchubian","S. Imen and N.B. Chang are with the Department of Civil, Environmental, and Construction Engineering, University of Central Florida, Orlando, FL 32816 USA (e-mail: nchang@ucf.edu).","IEEE Systems Journal","","2016","PP","99","1","11","Timely adjustment of operating strategies in drinking water treatment in response to water quality variations in both natural and anthropogenic causes is a grand technical challenge. One essential approach is to develop and apply integrated sensing, monitoring, and modeling technologies to provide early warning messages to plant operators. This paper presents a thorough literature review of the technical methods, followed by the development of a model-based decision support system (DSS). The DSS aims to aid water treatment plant operators by analyzing source water impacts. This model-based DSS features remote sensing and fast learning techniques that can be easily applied by end-users and provide a visual depiction of spatiotemporal variations in source water quality parameters of interest. The system is able to forecast the trend of water quality one day into the future at a specific location and nowcast water quality at water intake locations, thus helping the assessment of water quality in finished water against treatment objectives. The model-based DSS was assessed in a case study at a water treatment plant in Las Vegas, United States.","1932-8184;19328184","","10.1109/JSYST.2016.2538082","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458142","Data fusion;decision support systems (DSSs);drinking water;forecasting models;machine learning;remote sensing","Decision support systems;Monitoring;Predictive models;Satellites;Sensors;Water pollution;Water resources","","","","","","","","20160422","","","IEEE","IEEE Early Access Articles"
"An Efficient Tracking System by Orthogonalized Templates","X. Yang; M. Wang; L. Zhang; F. Sun; R. Hong; M. Qi","School of Computer and Information, Hefei University of Technology, Hefei, China","IEEE Transactions on Industrial Electronics","20160408","2016","63","5","3187","3197","Sparse representation (SR)-based tracking systems have become popular in the past recent years for its effectiveness. However, the underlying assumption of these tracking systems is that the target appearance can be linearly represented by a sparse approximation over a set of templates and a residual term, which usually needs to solve ℓ<sub>1</sub> norm minimization for many times and brings a heavy computational cost. This paper introduces an efficient tracking system by discovering orthogonalized templates. By orthogonalizing templates from previous frames and removing their correlation, we show that the sparsity of template weights is not necessary in target appearance modeling and thus a least squares regularization can be employed. We also decompose the residual term into two components in observation model to take occlusion cases into consideration. We demonstrate that, in comparison with the SR-based tracking systems that use ℓ<sub>1</sub> learning, our tracking system is much more computationally efficient while getting an even better performance. Experiments on a variety of challenging video sequences demonstrate both the effectiveness and efficiency of the system.","0278-0046;02780046","","10.1109/TIE.2016.2515559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374686","Computer vision;machine learning;sparse representation (SR);tracking system","Computational modeling;Correlation;Image reconstruction;Optimization;Robustness;Target tracking;Visualization","computer vision;decorrelation;least squares approximations;object tracking","computationally efficient method;decorrelation method;efficient tracking system;least squares regularization;orthogonalized templates","","1","","46","","20160107","May 2016","","IEEE","IEEE Journals & Magazines"
"Semisupervised Feature Selection Based on Relevance and Redundancy Criteria","J. Xu; B. Tang; H. He; H. Man","Vulcan Inc, Seattle, WA, 98104.","IEEE Transactions on Neural Networks and Learning Systems","","2016","PP","99","1","11","Feature selection aims to gain relevant features for improved classification performance and remove redundant features for reduced computational cost. How to balance these two factors is a problem especially when the categorical labels are costly to obtain. In this paper, we address this problem using semisupervised learning method and propose a max-relevance and min-redundancy criterion based on Pearson's correlation (RRPC) coefficient. This new method uses the incremental search technique to select optimal feature subsets. The new selected features have strong relevance to the labels in supervised manner, and avoid redundancy to the selected feature subsets under unsupervised constraints. Comparative studies are performed on binary data and multicategory data from benchmark data sets. The results show that the RRPC can achieve a good balance between relevance and redundancy in semisupervised feature selection. We also compare the RRPC with classic supervised feature selection criteria (such as mRMR and Fisher score), unsupervised feature selection criteria (such as Laplacian score), and semisupervised feature selection criteria (such as sSelect and locality sensitive). Experimental results demonstrate the effectiveness of our method.","2162-237X;2162237X","","10.1109/TNNLS.2016.2562670","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475902","Feature selection;Pearson correlation coefficients;machine learning;max-relevance;min-redundancy;semisupervised learning.","Computational complexity;Computational modeling;Correlation;Measurement;Redundancy;Search methods;Semisupervised learning","","","","","","","","20160520","","","IEEE","IEEE Early Access Articles"
"Automatic identification and multi-translatable translation of vocabulary terms with a combined approach","J. Qu; Y. Lu","School of Information Technology, Shinawatra International University, Pathum Thani, Thailand","2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)","20160409","2016","","","342","348","Automatic translation of out of vocabulary (OOV) terms has been extensively studied in the past, but multi-translatable OOV terms have received little attention. Multi-translatable OOV terms are OOV terms with some possible OOV synonyms, thus they have more than one correct translations. Traditional methods usually ignore such problem and neither identify/extract multi-translatable OOV terms nor translate them. This paper proposes a web-based OOV term translation method by utilizing a novel automatic multi-translatable OOV term identification and extraction approach. This approach integrates synonymous features and pattern matching to solve multi-translatable OOV term problems. A combined translation method is proposed for extracting translation candidates. To achieve high translation selection quality, we conducted statistical feature extraction, an artificial neural network combined with backward feature selection, and evolutionary parameter optimization is trained for selecting correct translations. Our method outperforms existing method with an accuracy of 82.61%.","","CD-ROM:978-1-4673-7778-2; Electronic:978-1-4673-7782-9; POD:978-1-4673-7783-6","10.1109/ICACI.2016.7449849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449849","automatic identification and extraction of multi-translatable OOV terms;biomedical OOV terms;combined approach for translation;machine learning","Artificial neural networks;Data collection;Data mining;Diseases;Feature extraction;Pattern matching;Vocabulary","Internet;evolutionary computation;feature selection;language translation;neural nets;statistical analysis;vocabulary","OOV synonyms;Web-based OOV term translation method;artificial neural network;automatic OOV term translation;automatic multitranslatable OOV term extraction approach;automatic multitranslatable OOV term identification appraoch;automatic out of vocabulary term translation;backward feature selection;evolutionary parameter optimization;statistical feature extraction;translation candidate extraction;translation selection quality","","","","","","","14-16 Feb. 2016","","IEEE","IEEE Conference Publications"
"A study of computer-based learning model for students with dyslexia","S. S. Abdul Hamid; N. Admodisastro; A. Kamaruddin","Faculty of Computer Science & Information Technology, Universiti Putra Malaysia, 43400 UPM Serdang, Selangor, Malaysia","2015 9th Malaysian Software Engineering Conference (MySEC)","20160523","2015","","","284","289","Dyslexia is one of the most common Specific Learning Difficulties (SpLDs) in the world. Students with dyslexia have poor fluency in reading, writing, spelling, speech, short-term memory, and also other related disorders. In addition emotion is recognised as important as the cognitive difficulty that affects dyslexia learning. Students with dyslexia often suffer emotions like frustration and low self-esteem due to lack of achievement. As a result, they may develop behaviour difficulty or perceive by others as misbehaviours. In order to address the dyslexia learning difficulties several computer-based learning models have been introduced. The computer-based learning model found to be interesting, user-friendly, attractive and supportive. In this paper, we present a study of computer-based learning model to support dyslexia students. The work is crucial to provide a basis for developing a computer-based learning model that addresses dyslexia language-based learning difficulties that considers both student's cognitive and emotion. In addition, the study also explores the uses of machine learning (ML) approach to improve effectiveness of the learning process.","","Electronic:978-1-4673-8227-4; POD:978-1-4673-8228-1","10.1109/MySEC.2015.7475234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475234","behaviour;cognitive;dyslexia;learning model;machine learning","Computational modeling;Computers;Data models;Education;Emotion recognition;Visualization;Writing","cognition;computer aided instruction;handicapped aids;learning (artificial intelligence);student experiments","ML approach;SpLDs;cognitive difficulty;computer-based learning model;dyslexia;machine learning;specific learning difficulties;students","","","","36","","","16-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"Discourse connective detection in spoken conversations","G. Riccardi; E. A. Stepanov; S. A. Chowdhury","Signals and Interactive Systems Lab, Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6095","6099","Discourse parsing is an important task in Language Understanding with applications to human-human and human-machine communication modeling. However, most of the research has focused on written text, and parsers heavily rely on syntactic parsers that themselves have low performance on dialog data. In our work, we address the problem of analyzing the semantic relations between discourse units in human-human spoken conversations. In particular, in this paper we focus on the detection of discourse connectives which are the predicate of such relations. The discourse relations are drawn from the Penn Discourse Treebank annotation model and adapted to a domain-specific Italian human-human spoken conversations. We study the relevance of lexical and acoustic context in predicting discourse connectives. We observe that both lexical and acoustic context have mixed effect on the prediction of specific connectives. While the oracle of using lexical and acoustic contextual feature combinations is F1 = 68.53, the lexical context alone significantly outperforms the baseline by more than 10 points with F<sub>1</sub> = 64.93.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472848","Discourse Analysis;Machine Learning;Speech Processing","Acoustics;Context;Data mining;Feature extraction;Speech;Syntactics;Training","grammars;natural language processing;program compilers;speech processing;text analysis","Penn Discourse Treebank annotation model;acoustic contextual feature combination;discourse connective detection;discourse parsing;domain-specific Italian human-human spoken conversation;human-human communication modeling;human-machine communication modeling;lexical contextual feature combination;semantic relation;spoken conversation","","","","13","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Using k-means clustering with transfer and Q learning for spectrum, load and energy optimization in opportunistic mobile broadband networks","Q. Zhao; D. Grace; A. Vilhar; T. Javornik","Department of Electronics, University of York, YO10 5DD, United Kingdom","2015 International Symposium on Wireless Communication Systems (ISWCS)","20160419","2015","","","116","120","In this paper, we investigate the use of an integrated machine learning algorithm to jointly optimize the spectrum allocation, load balancing and energy saving aspects in the opportunistic mobile broadband network for temporary event and disaster relief scenarios. A novel k-means algorithm has been developed to dynamically partition the users in a cell into clusters, to improve interference mitigation and spectrum reuse. It is integrated with a Q learning algorithm for resource allocation and transfer learning algorithm for cell selection. Topology management is developed using Q learning to improve BS placement and sleep mode operation. System simulation is carried out using a practical Ljubljana scenario. Compared to the classical LTE resource allocation and cell selection approach, clustered Q learning and transfer learning achieves significant QoS improvement in terms of spectrum and load optimization. With topology management, the learning algorithms show an effective balance between energy saving and QoS.","","Electronic:978-1-4673-6540-6; POD:978-1-4673-6541-3","10.1109/ISWCS.2015.7454310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454310","Energy Saving;K-means Clustering;Load Balancing;Machine Learning;Radio Resource Management","Clustering algorithms;Heuristic algorithms;Interference;Load management;Machine learning algorithms;Partitioning algorithms;Resource management","broadband networks;cellular radio;energy conservation;learning (artificial intelligence);mobile computing;pattern clustering;quality of service;radio spectrum management;radiofrequency interference;resource allocation;telecommunication computing;telecommunication network management;telecommunication network topology","BS placement improvement;Ljubljana scenario;Q learning algorithm;QoS improvement;cell selection;energy saving optimization;integrated machine learning algorithm;interference mitigation improvement;k-means clustering;load balancing optimization;opportunistic mobile broadband networks;resource allocation;sleep mode operation improvement;spectrum allocation optimization;spectrum reuse improvement;system simulation;topology management;transfer learning algorithm","","","","17","","","25-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"Random projections through multiple optical scattering: Approximating Kernels at the speed of light","A. Saade; F. Caltagirone; I. Carron; L. Daudet; A. Drémeau; S. Gigan; F. Krzakala","Laboratoire de Physique Statistique, CNRS UMR 8550 & &#x00C9;cole Normale Sup&#x00E9;rieure, Paris, France","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6215","6219","Random projections have proven extremely useful in many signal processing and machine learning applications. However, they often require either to store a very large random matrix, or to use a different, structured matrix to reduce the computational and memory costs. Here, we overcome this difficulty by proposing an analog, optical device, that performs the random projections literally at the speed of light without having to store any matrix in memory. This is achieved using the physical properties of multiple coherent scattering of coherent light in random media. We use this device on a simple task of classification with a kernel machine, and we show that, on the MNIST database, the experimental results closely match the theoretical performance of the corresponding kernel. This framework can help make kernel methods practical for applications that have large training sets and/or require real-time prediction. We discuss possible extensions of the method in terms of a class of kernels, speed, memory consumption and different problems.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472872","Kernel methods;large-scale data processing;machine learning;optical computing;random projections","Kernel;Nonlinear optics;Optical scattering;Paints;Performance evaluation;Training","light scattering;micromirrors;random media","MNIST database;analog optical device;coherent light;coherent scattering;computational costs;kernel machine;kernel methods;machine learning applications;memory consumption;memory costs;optical scattering;random matrix;random media;signal processing","","","","18","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Applying matrix factorization in data reconstruction for heart disease patient classification","Huaxia Wang; Y. D. Yao; Wei Qian; Fleming Lure","Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, USA","2015 17th International Conference on E-health Networking, Application & Services (HealthCom)","20160419","2015","","","245","249","Heart disease is one of the most severe health illnesses. Developing accurate and efficient methods to diagnose heart disease is crucial in providing good heart healthcare to patients. In this paper, a data mining based technique for diagnosing heart disease is introduced, in which heart disease related patient data sets are utilized. A matrix factorization based technique for missing data reconstruction is presented. Numerical results show that recovery data sets are able to achieve reliable diagnosis or classification performance comparable to using original completed patient datasets.","","Electronic:978-1-4673-8325-7; POD:978-1-4673-8326-4","10.1109/HealthCom.2015.7454506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454506","Classification;Data mining;Machine learning;Matrix factorization","Data mining;Diseases;Heart;Machine learning algorithms;Matrix converters;Matrix decomposition;Support vector machines","cardiology;data mining;diseases;health care;matrix decomposition;numerical analysis;patient diagnosis;pattern classification","classification performance;data mining-based technique;data reconstruction;diagnosis performance;health illnesses;heart disease diagnosis;heart disease patient classification;matrix factorization;patient datasets","","","","14","","","14-17 Oct. 2015","","IEEE","IEEE Conference Publications"
"Design of an Ambient Intelligence Testbed for Improving Quality of Life","R. Obukata; T. Oda; L. Barolli","Grad. Sch. of Eng., Fukuoka Inst. of Technol., Fukuoka, Japan","2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)","20160519","2016","","","714","719","Ambient intelligence (AmI) deals with a new world of ubiquitous computing devices, where physical environments interact intelligently and unobtrusively with people. AmI environments can be diverse, such as homes, offices, meeting rooms, schools, hospitals, control centers, vehicles, tourist attractions, stores, sports facilities, and music devices. In this paper, we present the design and implementation of a testbed for AmI using Raspberry Pi mounted on Raspbian OS. We analyze the performance of Optimized Link State Routing (OLSR) and Wired Equivalent Privacy (WEP) protocol in an indoor scenario. For evaluation we considered throughput, delay and jitter metrics. The experimental results show that the nodes in the testbed were communicating smoothly.","","Electronic:978-1-5090-2461-2; POD:978-1-5090-2462-9","10.1109/WAINA.2016.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471286","Ambient Intelligence;Machine Learning;OLSR;Quality of Life;Raspberry Pi;Testbed;WEP","Delays;Jitter;Routing;Routing protocols;Throughput","ambient intelligence;data privacy;learning (artificial intelligence)","AmI;OLSR;Raspberry Pi;Raspbian OS;WEP protocol;ambient intelligence testbed design;delay;jitter metrics;optimized link state routing;physical environments;quality of life;throughput;ubiquitous computing devices;wired equivalent privacy protocol","","1","","19","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"TDTD: Thyroid disease type diagnostics","J. Ahmed; M. A. R. Soomrani","Department of Computer Science, Sukkur Institute of Business Administration (Sukkur IBA), Pakistan","2016 International Conference on Intelligent Systems Engineering (ICISE)","20160523","2016","","","44","50","Recently; medical data mining has become one of the well-established research areas of machine learning and AI base techniques have been used to solve the complex classification problem of thyroid disease. Due to the existence of non-palpable nodules it is very hard to detect the structural changes of thyroid disease by assessing the thyroid functional changes. For instance at structural level “Euthyroid” is normal thyroid hormonal functional state but this would be involved in initial structural changes such as goiter, cold nodule, MNG (multiple nodule goiter) and cancer (Grave's Disease and so on). The ideal system should not only identify all the thyroid disease types but also recommend state of structural levels; otherwise it would be converted into serious disease, such like cancer. In-order to mitigate such problems, this paper proposes a framework TDTD (Thyroid Disease Types Diagnostics) that aims to assist the physicians during the diagnostic process of thyroid diseases in a very structured and transparent manner. Proposed system TDTD presents a novel method MDC (Medical data cleaning) for filling of missing values in medical datasets by building classifier based upon the Bayesian isotonic regression algorithm because missing values of medical data (i.e. blood tests) are different in nature and they could not be filled with normal procedures. In second phase two classifiers are trained to classify the functional and structural levels of thyroid disease at granular level using multi and binary SVM (support vector machine) algorithms, in final phase performance and evaluation is approximated using confusion matrix, precision and recall measures.","","Electronic:978-1-4673-8753-8; POD:978-1-4673-8754-5","10.1109/INTELSE.2016.7475160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475160","Datamining;goiters;machine learning;missing values;thyroid hormone","Biochemistry;Blood;Classification algorithms;Diseases;Glands;Medical diagnostic imaging;Support vector machines","Bayes methods;data mining;diseases;learning (artificial intelligence);medical diagnostic computing;regression analysis;support vector machines","AI base technique;Bayesian isotonic regression algorithm;TDTD;binary SVM;cancer;cold nodule;euthyroid;machine learning;medical data cleaning;medical data mining;multiple nodule goiter;nonpalpable nodule;support vector machine;thyroid disease type diagnostics;thyroid functional change;thyroid hormonal functional state","","","","18","","","15-17 Jan. 2016","","IEEE","IEEE Conference Publications"
"Detecting Arabic spammers and content polluters on Twitter","N. El-Mawass; S. Alaboodi","College of Computer and Information Sciences, King Saud University (Riyadh, Saudi Arabia)","2016 Sixth International Conference on Digital Information Processing and Communications (ICDIPC)","20160519","2016","","","53","58","Spam is thriving on Arabic Twitter. With a large online population, a mounting political unrest, and an undersized and unspecialized response effort, the current state of Arabic online social networks (OSNs) offers a perfect target for the spam industry, bringing both abuse and manipulation to the scene. The result is a ubiquitous spam presence that redefines the signal to noise ratio, and makes spam a de facto component of the online social platforms. English spam on online social networks has been heavily studied in the literature. To date however, social spam in other languages has been largely ignored. Our own analysis of spam content on Arabic trending hashtags in Saudi Arabia results in an estimate of about three quarters of the total generated content. This alarming rate, backed by independent concurrent estimates, makes the development of adaptive spam detection techniques a very real and pressing need. In this study, we present a first attempt at detecting accounts that promote spam and content pollution on Arabic Twitter. Using a large crawled dataset of more than 23 million Arabic tweets, and a manually labeled sample of more than 5000 tweets, we analyze the spam content on Saudi Twitter, and assess the performance of previous spam detection features on our recently gathered dataset. We also adapt the previously proposed features to respond to spammers evading techniques, and use these features to build a new highly accurate data-driven detection system.","","CD-ROM:978-1-4673-7503-0; Electronic:978-1-4673-7504-7; POD:978-1-4673-7505-4","10.1109/ICDIPC.2016.7470791","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470791","Arabic Spam;Machine Learning;Online Social Networks;Social Spam Detection;Supervised Classification;Twitter","Feature extraction;Sociology;Statistics;Tagging;Twitter;Unsolicited electronic mail","security of data;social networking (online);unsolicited e-mail","Arabic Twitter;Arabic online social networks;Arabic spammers;Arabic trending hashtags;Arabic tweets;English spam;OSN;Saudi Arabia;Saudi Twitter;adaptive spam detection techniques;content polluters;data-driven detection system;online population;social spam;spam industry;ubiquitous spam presence","","","","19","","","21-23 April 2016","","IEEE","IEEE Conference Publications"
"Unsupervised Trajectory Segmentation for Surgical Gesture Recognition in Robotic Training","F. Despinoy; D. Bouget; G. Forestier; C. Penet; N. Zemiti; P. Poignet; P. Jannin","LIRMM-CNRS, UMR 5506, Universit&#233; Montpellier, Montpellier, France","IEEE Transactions on Biomedical Engineering","20160518","2016","63","6","1280","1291","Dexterity and procedural knowledge are two critical skills that surgeons need to master to perform accurate and safe surgical interventions. However, current training systems do not allow us to provide an in-depth analysis of surgical gestures to precisely assess these skills. Our objective is to develop a method for the automatic and quantitative assessment of surgical gestures. To reach this goal, we propose a new unsupervised algorithm that can automatically segment kinematic data from robotic training sessions. Without relying on any prior information or model, this algorithm detects critical points in the kinematic data that define relevant spatio-temporal segments. Based on the association of these segments, we obtain an accurate recognition of the gestures involved in the surgical training task. We, then, perform an advanced analysis and assess our algorithm using datasets recorded during real expert training sessions. After comparing our approach with the manual annotations of the surgical gestures, we observe 97.4% accuracy for the learning purpose and an average matching score of 81.9% for the fully automated gesture recognition process. Our results show that trainees workflow can be followed and surgical gestures may be automatically evaluated according to an expert database. This approach tends toward improving training efficiency by minimizing the learning curve.","0018-9294;00189294","","10.1109/TBME.2015.2493100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7302557","Classification;Machine Learning;Robotic Surgery;Surgical Gesture Recognition;Surgical Skills Training;Teleoperation;Unsupervised Trajectory Segmentation;machine learning;robotic surgery;surgical gesture recognition;surgical skills training;teleoperation;unsupervised trajectory segmentation","Gesture recognition;Kinematics;Measurement;Robots;Surgery;Training;Trajectory","gesture recognition;intelligent robots;learning (artificial intelligence);manipulator kinematics;medical robotics;medical signal processing;spatiotemporal phenomena;surgery","automated gesture recognition process;kinematic data;learning curve;robotic training;spatiotemporal segments;surgical gesture recognition;unsupervised algorithm;unsupervised trajectory segmentation","","2","","45","","20151026","June 2016","","IEEE","IEEE Journals & Magazines"
